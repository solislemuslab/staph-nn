{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This file implements neural networks and logistic regression on p002ypresabs_quant.\n",
    "## Due to the imbalanced dataset, we implement the over-sampling method and the combination of over- and under-sampling\n",
    "## method.\n",
    "## To deal with overfitting problem, we include both dropout and regularizer when set up layers in neural networks.\n",
    "## For fully-connected neural networks, the accuracy is 100% for combination data, and 99.32% for over-sampling data.\n",
    "## For logistic regression, the accuracy is 100% for combination data, and 100% for over-sampling data.\n",
    "## Since the accuracy scores are pretty high in logistic regression, we further construct random forest models, which \n",
    "## are relatively less likely to bring overfitting compared to decision tree.\n",
    "## For random forest, the accuracy is 100% for combination data, and 100% for over-sampling data.\n",
    "## For random forest with cross-validation, the mean accuracy is 99.4% for combination data, and 98.83% for over-sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(100)\n",
    "import tensorflow\n",
    "tensorflow.random.set_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(255, 1759)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/Users/Rebecca/Desktop/Claudia/neural network/phage_quant/p002ypresabs_quant.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'Unnamed: 0':'id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.194875\n",
       "1      0.265250\n",
       "2      0.440625\n",
       "3      0.175500\n",
       "4      0.173625\n",
       "5      0.270375\n",
       "6      0.171000\n",
       "7      0.182500\n",
       "8      0.278875\n",
       "9      0.174375\n",
       "10     0.176250\n",
       "11     0.411125\n",
       "12     0.178250\n",
       "13     0.191500\n",
       "14     0.164875\n",
       "15     0.181875\n",
       "16     0.394125\n",
       "17     0.364875\n",
       "18     0.409875\n",
       "19     0.191875\n",
       "20     0.236125\n",
       "21     0.277000\n",
       "22     0.169875\n",
       "23     0.171625\n",
       "24     0.523625\n",
       "25     0.169500\n",
       "26     0.381000\n",
       "27     0.170000\n",
       "28     0.160750\n",
       "29     0.389750\n",
       "         ...   \n",
       "225    0.230500\n",
       "226    0.279800\n",
       "227    0.319500\n",
       "228    0.424100\n",
       "229    0.460500\n",
       "230    0.304750\n",
       "231    0.193875\n",
       "232    0.243000\n",
       "233    0.195750\n",
       "234    0.184750\n",
       "235    0.329125\n",
       "236    0.160000\n",
       "237    0.157500\n",
       "238    0.176375\n",
       "239    0.326750\n",
       "240    0.355750\n",
       "241    0.281375\n",
       "242    0.181875\n",
       "243    0.174125\n",
       "244    0.359250\n",
       "245    0.161375\n",
       "246    0.185875\n",
       "247    0.172750\n",
       "248    0.167750\n",
       "249    0.179875\n",
       "250    0.365375\n",
       "251    0.223500\n",
       "252    0.170750\n",
       "253    0.261125\n",
       "254    0.231000\n",
       "Name: pheno, Length: 255, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pheno']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0.5 in df['pheno']:\n",
    "    print: \"0.5 is in the list\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pheno'] = [1 if i>0.5 else 0 for i in df['pheno']] # convert pheno into binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    244\n",
       "1     11\n",
       "Name: pheno, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pheno']\n",
    "df['pheno'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(255, 1759)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.drop(columns=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(255, 1758)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(255, 1757) (255,)\n"
     ]
    }
   ],
   "source": [
    "X = df_clean.loc[:, df_clean.columns != 'pheno'].values\n",
    "y = df_clean['pheno'].values\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 235), (1, 241)]\n"
     ]
    }
   ],
   "source": [
    "# combination of under- and over- sampling\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.combine import SMOTEENN\n",
    "smote_enn = SMOTEENN(random_state=100)\n",
    "X_comb, y_comb = smote_enn.fit_resample(X, y)\n",
    "print(sorted(Counter(y_comb).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 244), (1, 244)]\n"
     ]
    }
   ],
   "source": [
    "# over-sampling\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "overS = RandomOverSampler(random_state=100)\n",
    "X_over, y_over = overS.fit_resample(X, y)\n",
    "print(sorted(Counter(y_over).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, validation, and test data (combination)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_comb, X_test_comb, y_train_comb, y_test_comb = train_test_split(X_comb, y_comb,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=123,\n",
    "                                                    stratify=y_comb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=123,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in /Users/Rebecca/anaconda3/lib/python3.7/site-packages (2.3.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /Users/Rebecca/anaconda3/lib/python3.7/site-packages (from keras) (1.1.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /Users/Rebecca/anaconda3/lib/python3.7/site-packages (from keras) (1.0.8)\n",
      "Requirement already satisfied: pyyaml in /Users/Rebecca/anaconda3/lib/python3.7/site-packages (from keras) (5.1)\n",
      "Requirement already satisfied: six>=1.9.0 in /Users/Rebecca/anaconda3/lib/python3.7/site-packages (from keras) (1.12.0)\n",
      "Requirement already satisfied: h5py in /Users/Rebecca/anaconda3/lib/python3.7/site-packages (from keras) (2.9.0)\n",
      "Requirement already satisfied: scipy>=0.14 in /Users/Rebecca/anaconda3/lib/python3.7/site-packages (from keras) (1.2.1)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /Users/Rebecca/anaconda3/lib/python3.7/site-packages (from keras) (1.16.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# Fully-Connected Neural Network ################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.regularizers import l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### neural network on combination data\n",
    "model1_comb = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_comb.shape[1],), activity_regularizer=l1(0.001)),\n",
    "    Dense(1, activation='sigmoid'),\n",
    "    Dropout(0.2, ),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_comb.compile(optimizer='sgd',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 333 samples, validate on 143 samples\n",
      "Epoch 1/100\n",
      "333/333 [==============================] - 0s 539us/step - loss: 2.2505 - accuracy: 0.7087 - val_loss: 0.5751 - val_accuracy: 0.8462\n",
      "Epoch 2/100\n",
      "333/333 [==============================] - 0s 97us/step - loss: 2.1204 - accuracy: 0.8408 - val_loss: 0.5304 - val_accuracy: 0.8741\n",
      "Epoch 3/100\n",
      "333/333 [==============================] - 0s 105us/step - loss: 1.9491 - accuracy: 0.8649 - val_loss: 0.5339 - val_accuracy: 0.8531\n",
      "Epoch 4/100\n",
      "333/333 [==============================] - 0s 97us/step - loss: 2.1956 - accuracy: 0.8589 - val_loss: 0.4814 - val_accuracy: 0.9301\n",
      "Epoch 5/100\n",
      "333/333 [==============================] - 0s 97us/step - loss: 1.6437 - accuracy: 0.8949 - val_loss: 0.4635 - val_accuracy: 0.8951\n",
      "Epoch 6/100\n",
      "333/333 [==============================] - 0s 93us/step - loss: 1.9998 - accuracy: 0.8859 - val_loss: 0.4603 - val_accuracy: 0.8951\n",
      "Epoch 7/100\n",
      "333/333 [==============================] - 0s 95us/step - loss: 2.2141 - accuracy: 0.8589 - val_loss: 0.4328 - val_accuracy: 0.9371\n",
      "Epoch 8/100\n",
      "333/333 [==============================] - 0s 91us/step - loss: 1.7891 - accuracy: 0.8889 - val_loss: 0.4346 - val_accuracy: 0.9021\n",
      "Epoch 9/100\n",
      "333/333 [==============================] - 0s 107us/step - loss: 1.9618 - accuracy: 0.8799 - val_loss: 0.4148 - val_accuracy: 0.9441\n",
      "Epoch 10/100\n",
      "333/333 [==============================] - 0s 95us/step - loss: 1.9110 - accuracy: 0.8829 - val_loss: 0.4054 - val_accuracy: 0.9720\n",
      "Epoch 11/100\n",
      "333/333 [==============================] - 0s 89us/step - loss: 1.8062 - accuracy: 0.8919 - val_loss: 0.4101 - val_accuracy: 0.9231\n",
      "Epoch 12/100\n",
      "333/333 [==============================] - 0s 99us/step - loss: 2.0288 - accuracy: 0.8769 - val_loss: 0.3903 - val_accuracy: 0.9720\n",
      "Epoch 13/100\n",
      "333/333 [==============================] - 0s 100us/step - loss: 1.9267 - accuracy: 0.8859 - val_loss: 0.3785 - val_accuracy: 0.9930\n",
      "Epoch 14/100\n",
      "333/333 [==============================] - 0s 94us/step - loss: 1.6053 - accuracy: 0.9069 - val_loss: 0.3973 - val_accuracy: 0.9510\n",
      "Epoch 15/100\n",
      "333/333 [==============================] - 0s 100us/step - loss: 1.5108 - accuracy: 0.9099 - val_loss: 0.3654 - val_accuracy: 0.9860\n",
      "Epoch 16/100\n",
      "333/333 [==============================] - 0s 97us/step - loss: 1.0907 - accuracy: 0.9429 - val_loss: 0.3778 - val_accuracy: 0.9580\n",
      "Epoch 17/100\n",
      "333/333 [==============================] - 0s 104us/step - loss: 1.4482 - accuracy: 0.9159 - val_loss: 0.3551 - val_accuracy: 0.9930\n",
      "Epoch 18/100\n",
      "333/333 [==============================] - 0s 108us/step - loss: 1.7159 - accuracy: 0.9009 - val_loss: 0.3469 - val_accuracy: 0.9930\n",
      "Epoch 19/100\n",
      "333/333 [==============================] - 0s 96us/step - loss: 2.0443 - accuracy: 0.8799 - val_loss: 0.3442 - val_accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "333/333 [==============================] - 0s 95us/step - loss: 1.7983 - accuracy: 0.8979 - val_loss: 0.3378 - val_accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "333/333 [==============================] - 0s 94us/step - loss: 1.4784 - accuracy: 0.9159 - val_loss: 0.3325 - val_accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "333/333 [==============================] - 0s 95us/step - loss: 1.3851 - accuracy: 0.9219 - val_loss: 0.3312 - val_accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "333/333 [==============================] - 0s 113us/step - loss: 1.7469 - accuracy: 0.8979 - val_loss: 0.3259 - val_accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "333/333 [==============================] - 0s 104us/step - loss: 1.9318 - accuracy: 0.8859 - val_loss: 0.3299 - val_accuracy: 0.9860\n",
      "Epoch 25/100\n",
      "333/333 [==============================] - 0s 101us/step - loss: 1.6990 - accuracy: 0.9009 - val_loss: 0.3230 - val_accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "333/333 [==============================] - 0s 92us/step - loss: 1.8821 - accuracy: 0.8859 - val_loss: 0.3196 - val_accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "333/333 [==============================] - 0s 90us/step - loss: 1.8312 - accuracy: 0.8889 - val_loss: 0.3146 - val_accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "333/333 [==============================] - 0s 91us/step - loss: 1.5025 - accuracy: 0.9129 - val_loss: 0.3091 - val_accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "333/333 [==============================] - 0s 99us/step - loss: 1.8657 - accuracy: 0.8919 - val_loss: 0.3139 - val_accuracy: 0.9930\n",
      "Epoch 30/100\n",
      "333/333 [==============================] - 0s 89us/step - loss: 1.5367 - accuracy: 0.9099 - val_loss: 0.3047 - val_accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "333/333 [==============================] - 0s 92us/step - loss: 1.7259 - accuracy: 0.8979 - val_loss: 0.3005 - val_accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "333/333 [==============================] - 0s 97us/step - loss: 1.3037 - accuracy: 0.9249 - val_loss: 0.3007 - val_accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "333/333 [==============================] - 0s 102us/step - loss: 1.5341 - accuracy: 0.9099 - val_loss: 0.2987 - val_accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "333/333 [==============================] - 0s 87us/step - loss: 2.0814 - accuracy: 0.8739 - val_loss: 0.2986 - val_accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "333/333 [==============================] - 0s 101us/step - loss: 1.4436 - accuracy: 0.9159 - val_loss: 0.2939 - val_accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "333/333 [==============================] - 0s 101us/step - loss: 1.6681 - accuracy: 0.9039 - val_loss: 0.2948 - val_accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "333/333 [==============================] - 0s 89us/step - loss: 1.9421 - accuracy: 0.8829 - val_loss: 0.2870 - val_accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "333/333 [==============================] - 0s 88us/step - loss: 1.8004 - accuracy: 0.8949 - val_loss: 0.2897 - val_accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "333/333 [==============================] - 0s 97us/step - loss: 1.4335 - accuracy: 0.9159 - val_loss: 0.2811 - val_accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "333/333 [==============================] - 0s 97us/step - loss: 1.7541 - accuracy: 0.8949 - val_loss: 0.2822 - val_accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "333/333 [==============================] - 0s 97us/step - loss: 1.5188 - accuracy: 0.9099 - val_loss: 0.2793 - val_accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "333/333 [==============================] - 0s 98us/step - loss: 1.8898 - accuracy: 0.8859 - val_loss: 0.2831 - val_accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "333/333 [==============================] - 0s 102us/step - loss: 1.8847 - accuracy: 0.8889 - val_loss: 0.2768 - val_accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "333/333 [==============================] - 0s 92us/step - loss: 1.9806 - accuracy: 0.8829 - val_loss: 0.2708 - val_accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "333/333 [==============================] - 0s 97us/step - loss: 1.3741 - accuracy: 0.9189 - val_loss: 0.2726 - val_accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "333/333 [==============================] - 0s 95us/step - loss: 1.8813 - accuracy: 0.8859 - val_loss: 0.2667 - val_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "333/333 [==============================] - 0s 96us/step - loss: 1.6006 - accuracy: 0.9039 - val_loss: 0.2645 - val_accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "333/333 [==============================] - 0s 99us/step - loss: 1.5565 - accuracy: 0.9069 - val_loss: 0.2695 - val_accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "333/333 [==============================] - 0s 100us/step - loss: 2.1110 - accuracy: 0.8709 - val_loss: 0.2637 - val_accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "333/333 [==============================] - 0s 99us/step - loss: 1.8740 - accuracy: 0.8889 - val_loss: 0.2616 - val_accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "333/333 [==============================] - 0s 101us/step - loss: 1.7338 - accuracy: 0.8979 - val_loss: 0.2646 - val_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "333/333 [==============================] - 0s 93us/step - loss: 1.5063 - accuracy: 0.9129 - val_loss: 0.2558 - val_accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "333/333 [==============================] - 0s 91us/step - loss: 1.9618 - accuracy: 0.8799 - val_loss: 0.2557 - val_accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "333/333 [==============================] - 0s 100us/step - loss: 1.7305 - accuracy: 0.8979 - val_loss: 0.2547 - val_accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "333/333 [==============================] - 0s 86us/step - loss: 1.3148 - accuracy: 0.9219 - val_loss: 0.2582 - val_accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "333/333 [==============================] - 0s 95us/step - loss: 1.1780 - accuracy: 0.9339 - val_loss: 0.2538 - val_accuracy: 1.0000\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "333/333 [==============================] - 0s 97us/step - loss: 2.0515 - accuracy: 0.8769 - val_loss: 0.2561 - val_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "333/333 [==============================] - 0s 93us/step - loss: 1.7686 - accuracy: 0.8949 - val_loss: 0.2512 - val_accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "333/333 [==============================] - 0s 93us/step - loss: 1.8179 - accuracy: 0.8919 - val_loss: 0.2522 - val_accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "333/333 [==============================] - 0s 94us/step - loss: 1.6303 - accuracy: 0.9039 - val_loss: 0.2510 - val_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "333/333 [==============================] - 0s 95us/step - loss: 1.4458 - accuracy: 0.9159 - val_loss: 0.2492 - val_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "333/333 [==============================] - 0s 97us/step - loss: 1.5349 - accuracy: 0.9099 - val_loss: 0.2513 - val_accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "333/333 [==============================] - 0s 93us/step - loss: 1.8594 - accuracy: 0.8889 - val_loss: 0.2454 - val_accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "333/333 [==============================] - 0s 96us/step - loss: 1.7636 - accuracy: 0.8949 - val_loss: 0.2498 - val_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "333/333 [==============================] - 0s 98us/step - loss: 1.6742 - accuracy: 0.9009 - val_loss: 0.2399 - val_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "333/333 [==============================] - 0s 92us/step - loss: 1.6691 - accuracy: 0.9009 - val_loss: 0.2395 - val_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "333/333 [==============================] - 0s 101us/step - loss: 1.5822 - accuracy: 0.9069 - val_loss: 0.2438 - val_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "333/333 [==============================] - 0s 97us/step - loss: 1.9496 - accuracy: 0.8829 - val_loss: 0.2365 - val_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "333/333 [==============================] - 0s 87us/step - loss: 1.5322 - accuracy: 0.9099 - val_loss: 0.2455 - val_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "333/333 [==============================] - 0s 99us/step - loss: 1.5769 - accuracy: 0.9069 - val_loss: 0.2384 - val_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "333/333 [==============================] - 0s 100us/step - loss: 1.2056 - accuracy: 0.9309 - val_loss: 0.2386 - val_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "333/333 [==============================] - 0s 100us/step - loss: 1.8973 - accuracy: 0.8859 - val_loss: 0.2377 - val_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "333/333 [==============================] - 0s 93us/step - loss: 2.0826 - accuracy: 0.8739 - val_loss: 0.2343 - val_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "333/333 [==============================] - 0s 93us/step - loss: 1.7575 - accuracy: 0.8949 - val_loss: 0.2304 - val_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "333/333 [==============================] - 0s 96us/step - loss: 1.2480 - accuracy: 0.9279 - val_loss: 0.2286 - val_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "333/333 [==============================] - 0s 93us/step - loss: 1.4786 - accuracy: 0.9129 - val_loss: 0.2326 - val_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "333/333 [==============================] - 0s 91us/step - loss: 1.6623 - accuracy: 0.9009 - val_loss: 0.2330 - val_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "333/333 [==============================] - 0s 105us/step - loss: 1.3340 - accuracy: 0.9219 - val_loss: 0.2288 - val_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "333/333 [==============================] - 0s 102us/step - loss: 1.2449 - accuracy: 0.9279 - val_loss: 0.2286 - val_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "333/333 [==============================] - 0s 98us/step - loss: 1.2902 - accuracy: 0.9249 - val_loss: 0.2282 - val_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "333/333 [==============================] - 0s 97us/step - loss: 1.5659 - accuracy: 0.9069 - val_loss: 0.2278 - val_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "333/333 [==============================] - 0s 98us/step - loss: 1.6571 - accuracy: 0.9009 - val_loss: 0.2292 - val_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "333/333 [==============================] - 0s 93us/step - loss: 1.8882 - accuracy: 0.8859 - val_loss: 0.2301 - val_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "333/333 [==============================] - 0s 95us/step - loss: 1.8396 - accuracy: 0.8889 - val_loss: 0.2285 - val_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "333/333 [==============================] - 0s 90us/step - loss: 2.0258 - accuracy: 0.8769 - val_loss: 0.2243 - val_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "333/333 [==============================] - 0s 94us/step - loss: 2.0718 - accuracy: 0.8739 - val_loss: 0.2302 - val_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "333/333 [==============================] - 0s 92us/step - loss: 2.2567 - accuracy: 0.8619 - val_loss: 0.2275 - val_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "333/333 [==============================] - 0s 97us/step - loss: 1.4666 - accuracy: 0.9129 - val_loss: 0.2273 - val_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "333/333 [==============================] - 0s 95us/step - loss: 1.3743 - accuracy: 0.9189 - val_loss: 0.2289 - val_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "333/333 [==============================] - 0s 93us/step - loss: 1.6527 - accuracy: 0.9009 - val_loss: 0.2209 - val_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "333/333 [==============================] - 0s 93us/step - loss: 1.4669 - accuracy: 0.9129 - val_loss: 0.2214 - val_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "333/333 [==============================] - 0s 100us/step - loss: 2.3472 - accuracy: 0.8559 - val_loss: 0.2223 - val_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "333/333 [==============================] - 0s 94us/step - loss: 1.0943 - accuracy: 0.9369 - val_loss: 0.2231 - val_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "333/333 [==============================] - 0s 95us/step - loss: 1.6528 - accuracy: 0.9009 - val_loss: 0.2208 - val_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "333/333 [==============================] - 0s 105us/step - loss: 1.6482 - accuracy: 0.9009 - val_loss: 0.2191 - val_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "333/333 [==============================] - 0s 93us/step - loss: 1.6030 - accuracy: 0.9039 - val_loss: 0.2135 - val_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "333/333 [==============================] - 0s 96us/step - loss: 1.6483 - accuracy: 0.9009 - val_loss: 0.2200 - val_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "333/333 [==============================] - 0s 97us/step - loss: 1.2292 - accuracy: 0.9279 - val_loss: 0.2209 - val_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "333/333 [==============================] - 0s 86us/step - loss: 1.7410 - accuracy: 0.8949 - val_loss: 0.2194 - val_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "333/333 [==============================] - 0s 94us/step - loss: 1.7845 - accuracy: 0.8919 - val_loss: 0.2168 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a42913e10>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_comb.fit(X_train_comb, y_train_comb,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_comb, y_test_comb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 116us/step\n",
      "combination test accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "acc_test_comb = model1_comb.evaluate(X_test_comb, y_test_comb)[1]\n",
    "print('combination test accuracy: %.2f%%' % (acc_test_comb*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### neural network on over-sampling data\n",
    "model1_over = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],), activity_regularizer=l1(0.001)),\n",
    "    Dense(1, activation='sigmoid'),\n",
    "    Dropout(0.2, ),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over.compile(optimizer='sgd',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 341 samples, validate on 147 samples\n",
      "Epoch 1/100\n",
      "341/341 [==============================] - 0s 654us/step - loss: 1.6251 - accuracy: 0.6745 - val_loss: 0.6403 - val_accuracy: 0.7551\n",
      "Epoch 2/100\n",
      "341/341 [==============================] - 0s 89us/step - loss: 2.0915 - accuracy: 0.7507 - val_loss: 0.5943 - val_accuracy: 0.7823\n",
      "Epoch 3/100\n",
      "341/341 [==============================] - 0s 97us/step - loss: 1.8977 - accuracy: 0.7771 - val_loss: 0.5682 - val_accuracy: 0.7823\n",
      "Epoch 4/100\n",
      "341/341 [==============================] - 0s 92us/step - loss: 2.2811 - accuracy: 0.7683 - val_loss: 0.5476 - val_accuracy: 0.8299\n",
      "Epoch 5/100\n",
      "341/341 [==============================] - 0s 138us/step - loss: 2.3734 - accuracy: 0.7713 - val_loss: 0.5351 - val_accuracy: 0.8912\n",
      "Epoch 6/100\n",
      "341/341 [==============================] - 0s 101us/step - loss: 1.7037 - accuracy: 0.8270 - val_loss: 0.5160 - val_accuracy: 0.8844\n",
      "Epoch 7/100\n",
      "341/341 [==============================] - 0s 95us/step - loss: 2.0775 - accuracy: 0.7977 - val_loss: 0.5235 - val_accuracy: 0.7891\n",
      "Epoch 8/100\n",
      "341/341 [==============================] - 0s 91us/step - loss: 1.8232 - accuracy: 0.8299 - val_loss: 0.5102 - val_accuracy: 0.9184\n",
      "Epoch 9/100\n",
      "341/341 [==============================] - 0s 91us/step - loss: 1.8398 - accuracy: 0.8152 - val_loss: 0.4902 - val_accuracy: 0.8912\n",
      "Epoch 10/100\n",
      "341/341 [==============================] - 0s 97us/step - loss: 1.9812 - accuracy: 0.8094 - val_loss: 0.5052 - val_accuracy: 0.8639\n",
      "Epoch 11/100\n",
      "341/341 [==============================] - 0s 89us/step - loss: 2.4265 - accuracy: 0.7918 - val_loss: 0.4738 - val_accuracy: 0.8912\n",
      "Epoch 12/100\n",
      "341/341 [==============================] - 0s 90us/step - loss: 2.0998 - accuracy: 0.8182 - val_loss: 0.4821 - val_accuracy: 0.9184\n",
      "Epoch 13/100\n",
      "341/341 [==============================] - 0s 108us/step - loss: 2.0048 - accuracy: 0.8240 - val_loss: 0.4556 - val_accuracy: 0.9252\n",
      "Epoch 14/100\n",
      "341/341 [==============================] - 0s 92us/step - loss: 1.9618 - accuracy: 0.8211 - val_loss: 0.4468 - val_accuracy: 0.9048\n",
      "Epoch 15/100\n",
      "341/341 [==============================] - 0s 95us/step - loss: 1.8693 - accuracy: 0.8182 - val_loss: 0.4462 - val_accuracy: 0.9116\n",
      "Epoch 16/100\n",
      "341/341 [==============================] - 0s 100us/step - loss: 1.7196 - accuracy: 0.8446 - val_loss: 0.4372 - val_accuracy: 0.9116\n",
      "Epoch 17/100\n",
      "341/341 [==============================] - 0s 97us/step - loss: 1.6680 - accuracy: 0.8446 - val_loss: 0.4291 - val_accuracy: 0.9116\n",
      "Epoch 18/100\n",
      "341/341 [==============================] - 0s 96us/step - loss: 1.8527 - accuracy: 0.8182 - val_loss: 0.4243 - val_accuracy: 0.9388\n",
      "Epoch 19/100\n",
      "341/341 [==============================] - 0s 96us/step - loss: 1.9259 - accuracy: 0.8387 - val_loss: 0.4419 - val_accuracy: 0.9184\n",
      "Epoch 20/100\n",
      "341/341 [==============================] - 0s 103us/step - loss: 1.8727 - accuracy: 0.8328 - val_loss: 0.4307 - val_accuracy: 0.9184\n",
      "Epoch 21/100\n",
      "341/341 [==============================] - 0s 109us/step - loss: 1.6862 - accuracy: 0.8592 - val_loss: 0.4190 - val_accuracy: 0.9184\n",
      "Epoch 22/100\n",
      "341/341 [==============================] - 0s 93us/step - loss: 1.6609 - accuracy: 0.8328 - val_loss: 0.4364 - val_accuracy: 0.9184\n",
      "Epoch 23/100\n",
      "341/341 [==============================] - 0s 96us/step - loss: 1.9610 - accuracy: 0.8387 - val_loss: 0.4019 - val_accuracy: 0.9388\n",
      "Epoch 24/100\n",
      "341/341 [==============================] - 0s 90us/step - loss: 1.6758 - accuracy: 0.8680 - val_loss: 0.3946 - val_accuracy: 0.9388\n",
      "Epoch 25/100\n",
      "341/341 [==============================] - 0s 91us/step - loss: 1.9913 - accuracy: 0.8387 - val_loss: 0.3972 - val_accuracy: 0.9116\n",
      "Epoch 26/100\n",
      "341/341 [==============================] - 0s 90us/step - loss: 1.8624 - accuracy: 0.8504 - val_loss: 0.3862 - val_accuracy: 0.9456\n",
      "Epoch 27/100\n",
      "341/341 [==============================] - 0s 102us/step - loss: 1.9320 - accuracy: 0.8592 - val_loss: 0.3952 - val_accuracy: 0.9184\n",
      "Epoch 28/100\n",
      "341/341 [==============================] - 0s 93us/step - loss: 2.0243 - accuracy: 0.8328 - val_loss: 0.3750 - val_accuracy: 0.9388\n",
      "Epoch 29/100\n",
      "341/341 [==============================] - 0s 89us/step - loss: 1.8011 - accuracy: 0.8651 - val_loss: 0.3797 - val_accuracy: 0.9184\n",
      "Epoch 30/100\n",
      "341/341 [==============================] - 0s 89us/step - loss: 1.8328 - accuracy: 0.8592 - val_loss: 0.3688 - val_accuracy: 0.9864\n",
      "Epoch 31/100\n",
      "341/341 [==============================] - 0s 98us/step - loss: 2.3173 - accuracy: 0.8416 - val_loss: 0.3772 - val_accuracy: 0.9864\n",
      "Epoch 32/100\n",
      "341/341 [==============================] - 0s 89us/step - loss: 1.4112 - accuracy: 0.9003 - val_loss: 0.3643 - val_accuracy: 0.9592\n",
      "Epoch 33/100\n",
      "341/341 [==============================] - 0s 92us/step - loss: 2.0058 - accuracy: 0.8622 - val_loss: 0.3542 - val_accuracy: 0.9864\n",
      "Epoch 34/100\n",
      "341/341 [==============================] - 0s 95us/step - loss: 1.9173 - accuracy: 0.8680 - val_loss: 0.3681 - val_accuracy: 0.9184\n",
      "Epoch 35/100\n",
      "341/341 [==============================] - 0s 113us/step - loss: 1.8198 - accuracy: 0.8739 - val_loss: 0.3470 - val_accuracy: 0.9388\n",
      "Epoch 36/100\n",
      "341/341 [==============================] - 0s 97us/step - loss: 1.7747 - accuracy: 0.8710 - val_loss: 0.3496 - val_accuracy: 0.9184\n",
      "Epoch 37/100\n",
      "341/341 [==============================] - 0s 89us/step - loss: 2.1570 - accuracy: 0.8592 - val_loss: 0.3439 - val_accuracy: 0.9184\n",
      "Epoch 38/100\n",
      "341/341 [==============================] - 0s 113us/step - loss: 1.5789 - accuracy: 0.8974 - val_loss: 0.3441 - val_accuracy: 0.9864\n",
      "Epoch 39/100\n",
      "341/341 [==============================] - 0s 95us/step - loss: 2.0775 - accuracy: 0.8563 - val_loss: 0.3355 - val_accuracy: 0.9932\n",
      "Epoch 40/100\n",
      "341/341 [==============================] - 0s 105us/step - loss: 1.8016 - accuracy: 0.8827 - val_loss: 0.3344 - val_accuracy: 0.9932\n",
      "Epoch 41/100\n",
      "341/341 [==============================] - 0s 96us/step - loss: 1.6557 - accuracy: 0.8944 - val_loss: 0.3303 - val_accuracy: 0.9932\n",
      "Epoch 42/100\n",
      "341/341 [==============================] - 0s 87us/step - loss: 1.6677 - accuracy: 0.8886 - val_loss: 0.3506 - val_accuracy: 0.9184\n",
      "Epoch 43/100\n",
      "341/341 [==============================] - 0s 88us/step - loss: 1.8953 - accuracy: 0.8739 - val_loss: 0.3369 - val_accuracy: 0.9456\n",
      "Epoch 44/100\n",
      "341/341 [==============================] - 0s 100us/step - loss: 1.7888 - accuracy: 0.8856 - val_loss: 0.3404 - val_accuracy: 0.8503\n",
      "Epoch 45/100\n",
      "341/341 [==============================] - ETA: 0s - loss: 2.1579 - accuracy: 0.87 - 0s 89us/step - loss: 1.6579 - accuracy: 0.8974 - val_loss: 0.3242 - val_accuracy: 0.9864\n",
      "Epoch 46/100\n",
      "341/341 [==============================] - 0s 94us/step - loss: 1.4641 - accuracy: 0.9120 - val_loss: 0.3276 - val_accuracy: 0.9864\n",
      "Epoch 47/100\n",
      "341/341 [==============================] - 0s 103us/step - loss: 1.6103 - accuracy: 0.8944 - val_loss: 0.3426 - val_accuracy: 0.9864\n",
      "Epoch 48/100\n",
      "341/341 [==============================] - 0s 96us/step - loss: 1.7277 - accuracy: 0.8915 - val_loss: 0.3119 - val_accuracy: 0.9864\n",
      "Epoch 49/100\n",
      "341/341 [==============================] - 0s 89us/step - loss: 1.7286 - accuracy: 0.8886 - val_loss: 0.3206 - val_accuracy: 0.9660\n",
      "Epoch 50/100\n",
      "341/341 [==============================] - 0s 88us/step - loss: 1.2405 - accuracy: 0.9179 - val_loss: 0.3357 - val_accuracy: 0.9864\n",
      "Epoch 51/100\n",
      "341/341 [==============================] - 0s 86us/step - loss: 1.6473 - accuracy: 0.8886 - val_loss: 0.3064 - val_accuracy: 0.9932\n",
      "Epoch 52/100\n",
      "341/341 [==============================] - 0s 92us/step - loss: 1.9565 - accuracy: 0.8710 - val_loss: 0.3051 - val_accuracy: 0.9932\n",
      "Epoch 53/100\n",
      "341/341 [==============================] - 0s 93us/step - loss: 1.8259 - accuracy: 0.8798 - val_loss: 0.3015 - val_accuracy: 0.9932\n",
      "Epoch 54/100\n",
      "341/341 [==============================] - 0s 86us/step - loss: 1.6750 - accuracy: 0.8915 - val_loss: 0.2983 - val_accuracy: 0.9932\n",
      "Epoch 55/100\n",
      "341/341 [==============================] - 0s 90us/step - loss: 1.8961 - accuracy: 0.8798 - val_loss: 0.3088 - val_accuracy: 0.9864\n",
      "Epoch 56/100\n",
      "341/341 [==============================] - 0s 91us/step - loss: 1.9542 - accuracy: 0.8739 - val_loss: 0.2984 - val_accuracy: 0.9864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "341/341 [==============================] - 0s 89us/step - loss: 1.6792 - accuracy: 0.8915 - val_loss: 0.2925 - val_accuracy: 0.9932\n",
      "Epoch 58/100\n",
      "341/341 [==============================] - 0s 86us/step - loss: 1.9401 - accuracy: 0.8768 - val_loss: 0.3075 - val_accuracy: 0.9864\n",
      "Epoch 59/100\n",
      "341/341 [==============================] - 0s 83us/step - loss: 1.9547 - accuracy: 0.8710 - val_loss: 0.3064 - val_accuracy: 0.9932\n",
      "Epoch 60/100\n",
      "341/341 [==============================] - 0s 84us/step - loss: 1.8559 - accuracy: 0.8768 - val_loss: 0.2975 - val_accuracy: 0.9932\n",
      "Epoch 61/100\n",
      "341/341 [==============================] - 0s 84us/step - loss: 1.7951 - accuracy: 0.8886 - val_loss: 0.2839 - val_accuracy: 0.9932\n",
      "Epoch 62/100\n",
      "341/341 [==============================] - 0s 88us/step - loss: 1.9673 - accuracy: 0.8768 - val_loss: 0.2812 - val_accuracy: 0.9932\n",
      "Epoch 63/100\n",
      "341/341 [==============================] - 0s 89us/step - loss: 1.5359 - accuracy: 0.9003 - val_loss: 0.2890 - val_accuracy: 0.9932\n",
      "Epoch 64/100\n",
      "341/341 [==============================] - 0s 90us/step - loss: 1.6316 - accuracy: 0.8886 - val_loss: 0.3002 - val_accuracy: 0.9660\n",
      "Epoch 65/100\n",
      "341/341 [==============================] - 0s 92us/step - loss: 1.6254 - accuracy: 0.8886 - val_loss: 0.3014 - val_accuracy: 0.9932\n",
      "Epoch 66/100\n",
      "341/341 [==============================] - 0s 88us/step - loss: 1.7677 - accuracy: 0.8798 - val_loss: 0.2804 - val_accuracy: 0.9932\n",
      "Epoch 67/100\n",
      "341/341 [==============================] - 0s 84us/step - loss: 1.8424 - accuracy: 0.8798 - val_loss: 0.2789 - val_accuracy: 0.9932\n",
      "Epoch 68/100\n",
      "341/341 [==============================] - 0s 83us/step - loss: 1.7124 - accuracy: 0.8827 - val_loss: 0.2836 - val_accuracy: 0.9932\n",
      "Epoch 69/100\n",
      "341/341 [==============================] - 0s 84us/step - loss: 1.9900 - accuracy: 0.8680 - val_loss: 0.2715 - val_accuracy: 0.9932\n",
      "Epoch 70/100\n",
      "341/341 [==============================] - 0s 83us/step - loss: 1.4786 - accuracy: 0.9032 - val_loss: 0.2712 - val_accuracy: 0.9932\n",
      "Epoch 71/100\n",
      "341/341 [==============================] - 0s 88us/step - loss: 1.3386 - accuracy: 0.9120 - val_loss: 0.2688 - val_accuracy: 0.9932\n",
      "Epoch 72/100\n",
      "341/341 [==============================] - 0s 86us/step - loss: 1.9336 - accuracy: 0.8680 - val_loss: 0.2781 - val_accuracy: 0.9932\n",
      "Epoch 73/100\n",
      "341/341 [==============================] - 0s 86us/step - loss: 1.8837 - accuracy: 0.8768 - val_loss: 0.2681 - val_accuracy: 0.9932\n",
      "Epoch 74/100\n",
      "341/341 [==============================] - 0s 84us/step - loss: 1.5178 - accuracy: 0.9003 - val_loss: 0.2685 - val_accuracy: 0.9932\n",
      "Epoch 75/100\n",
      "341/341 [==============================] - 0s 86us/step - loss: 1.6992 - accuracy: 0.8886 - val_loss: 0.2661 - val_accuracy: 0.9932\n",
      "Epoch 76/100\n",
      "341/341 [==============================] - 0s 87us/step - loss: 1.5172 - accuracy: 0.9032 - val_loss: 0.2650 - val_accuracy: 0.9932\n",
      "Epoch 77/100\n",
      "341/341 [==============================] - 0s 92us/step - loss: 1.5567 - accuracy: 0.9003 - val_loss: 0.2626 - val_accuracy: 0.9932\n",
      "Epoch 78/100\n",
      "341/341 [==============================] - 0s 88us/step - loss: 2.3677 - accuracy: 0.8446 - val_loss: 0.2656 - val_accuracy: 0.9932\n",
      "Epoch 79/100\n",
      "341/341 [==============================] - 0s 87us/step - loss: 1.9375 - accuracy: 0.8710 - val_loss: 0.2622 - val_accuracy: 0.9932\n",
      "Epoch 80/100\n",
      "341/341 [==============================] - 0s 84us/step - loss: 1.8418 - accuracy: 0.8768 - val_loss: 0.2632 - val_accuracy: 0.9932\n",
      "Epoch 81/100\n",
      "341/341 [==============================] - 0s 88us/step - loss: 1.6137 - accuracy: 0.8915 - val_loss: 0.2621 - val_accuracy: 0.9932\n",
      "Epoch 82/100\n",
      "341/341 [==============================] - 0s 86us/step - loss: 1.4186 - accuracy: 0.9062 - val_loss: 0.2606 - val_accuracy: 0.9932\n",
      "Epoch 83/100\n",
      "341/341 [==============================] - 0s 89us/step - loss: 1.8314 - accuracy: 0.8768 - val_loss: 0.2590 - val_accuracy: 0.9932\n",
      "Epoch 84/100\n",
      "341/341 [==============================] - 0s 84us/step - loss: 1.7933 - accuracy: 0.8798 - val_loss: 0.2656 - val_accuracy: 0.9932\n",
      "Epoch 85/100\n",
      "341/341 [==============================] - 0s 93us/step - loss: 2.0029 - accuracy: 0.8680 - val_loss: 0.2576 - val_accuracy: 0.9932\n",
      "Epoch 86/100\n",
      "341/341 [==============================] - 0s 91us/step - loss: 1.7339 - accuracy: 0.8886 - val_loss: 0.2592 - val_accuracy: 0.9932\n",
      "Epoch 87/100\n",
      "341/341 [==============================] - 0s 91us/step - loss: 1.4218 - accuracy: 0.9062 - val_loss: 0.2558 - val_accuracy: 0.9932\n",
      "Epoch 88/100\n",
      "341/341 [==============================] - 0s 96us/step - loss: 1.6864 - accuracy: 0.8944 - val_loss: 0.2642 - val_accuracy: 0.9864\n",
      "Epoch 89/100\n",
      "341/341 [==============================] - 0s 87us/step - loss: 1.4652 - accuracy: 0.9003 - val_loss: 0.2567 - val_accuracy: 0.9932\n",
      "Epoch 90/100\n",
      "341/341 [==============================] - 0s 91us/step - loss: 1.3330 - accuracy: 0.9120 - val_loss: 0.2524 - val_accuracy: 0.9932\n",
      "Epoch 91/100\n",
      "341/341 [==============================] - 0s 99us/step - loss: 1.9159 - accuracy: 0.8739 - val_loss: 0.2525 - val_accuracy: 0.9932\n",
      "Epoch 92/100\n",
      "341/341 [==============================] - 0s 89us/step - loss: 1.8265 - accuracy: 0.8768 - val_loss: 0.2933 - val_accuracy: 0.9932\n",
      "Epoch 93/100\n",
      "341/341 [==============================] - 0s 92us/step - loss: 1.4217 - accuracy: 0.9062 - val_loss: 0.2577 - val_accuracy: 0.9932\n",
      "Epoch 94/100\n",
      "341/341 [==============================] - 0s 98us/step - loss: 1.7744 - accuracy: 0.8827 - val_loss: 0.2601 - val_accuracy: 0.9932\n",
      "Epoch 95/100\n",
      "341/341 [==============================] - 0s 92us/step - loss: 1.4194 - accuracy: 0.9062 - val_loss: 0.2518 - val_accuracy: 0.9932\n",
      "Epoch 96/100\n",
      "341/341 [==============================] - 0s 98us/step - loss: 1.8626 - accuracy: 0.8798 - val_loss: 0.2522 - val_accuracy: 0.9932\n",
      "Epoch 97/100\n",
      "341/341 [==============================] - 0s 93us/step - loss: 2.2189 - accuracy: 0.8534 - val_loss: 0.2510 - val_accuracy: 0.9932\n",
      "Epoch 98/100\n",
      "341/341 [==============================] - 0s 87us/step - loss: 1.6030 - accuracy: 0.8915 - val_loss: 0.2476 - val_accuracy: 0.9932\n",
      "Epoch 99/100\n",
      "341/341 [==============================] - 0s 94us/step - loss: 1.6362 - accuracy: 0.8944 - val_loss: 0.2508 - val_accuracy: 0.9932\n",
      "Epoch 100/100\n",
      "341/341 [==============================] - 0s 94us/step - loss: 1.7714 - accuracy: 0.8856 - val_loss: 0.2510 - val_accuracy: 0.9932\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a3d7f2f98>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147/147 [==============================] - 0s 72us/step\n",
      "over-sampling test accuracy: 99.32%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over = model1_over.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ Logistic Regression ############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=123, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###### logistics on combination data\n",
    "log_comb = LogisticRegression(random_state=123)\n",
    "log_comb.fit(X_train_comb, y_train_comb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combination logistic test accuracy 100.00%\n"
     ]
    }
   ],
   "source": [
    "y_pred_comb = log_comb.predict(X_test_comb)\n",
    "print('combination logistic test accuracy %.2f%%' % (log_comb.score(X_test_comb, y_test_comb)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=123, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### logistics on over-sampling data\n",
    "log_over = LogisticRegression(random_state=123)\n",
    "log_over.fit(X_train_over, y_train_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling logistic test accuracy 100.00%\n"
     ]
    }
   ],
   "source": [
    "y_pred_over = log_over.predict(X_test_over)\n",
    "print('over-sampling logistic test accuracy %.2f%%' % (log_over.score(X_test_over, y_test_over)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## Random Forest ##############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=123,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###### random forest on combination data\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_comb = RandomForestClassifier(n_estimators=100, random_state=123)\n",
    "rf_comb.fit(X_train_comb,y_train_comb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combination test accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred_comb = rf_comb.predict(X_test_comb)\n",
    "print('combination test accuracy: %.2f%%' % (accuracy_score(y_test_comb, y_pred_comb)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=123,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###### random forest on over-sampling data\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_over = RandomForestClassifier(n_estimators=100, random_state=123)\n",
    "rf_over.fit(X_train_over,y_train_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling test accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred_over = rf_over.predict(X_test_over)\n",
    "print('over-sampling test accuracy: %.2f%%' % (accuracy_score(y_test_over, y_pred_over)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Random forest with cross-validation\n",
    "## Retrieved from https://stackabuse.com/cross-validation-and-grid-search-for-model-selection-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.98507463 0.98507463 1.         1.         1.        ]\n",
      "0.9940298507462686\n"
     ]
    }
   ],
   "source": [
    "## random forest model with CV on combination data\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# rfcv_comb = RandomForestClassifier(n_estimators=100, random_state=123)\n",
    "\n",
    "accs_comb = cross_val_score(estimator=rf_comb, X=X_train_comb, y=y_train_comb, cv=5)\n",
    "print(accs_comb)\n",
    "print(accs_comb.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.98550725 0.98529412 0.98529412 0.98529412 1.        ]\n",
      "0.9882779198635976\n"
     ]
    }
   ],
   "source": [
    "## random forest model with CV on over-sampling data\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# rfcv_over = RandomForestClassifier(n_estimators=100, random_state=123)\n",
    "\n",
    "accs_over = cross_val_score(estimator=rf_over, X=X_train_over, y=y_train_over, cv=5)\n",
    "print(accs_over)\n",
    "print(accs_over.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
