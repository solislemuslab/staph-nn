{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This file implements neural networks and logistic regression on p002ypresabs_quant.\n",
    "## Due to the imbalanced dataset, we implement the over-sampling method and the combination of over- and under-sampling\n",
    "## method.\n",
    "## To deal with overfitting problem, we include both dropout and regularizer when set up layers in neural networks.\n",
    "## For fully-connected neural networks, the accuracy is 99% for combination data, and 100% for over-sampling data.\n",
    "## For logistic regression, the accuracy is 99.3% for combination data, and 100% for over-sampling data.\n",
    "## Since the accuracy scores are pretty high in logistic regression, we further construct random forest models, which \n",
    "## are relatively less likely to bring overfitting compared to decision tree.\n",
    "## For random forest, the accuracy is 99.3% for combination data, and 100% for over-sampling data.\n",
    "## For random forest with cross-validation, the mean accuracy is 99.6% for combination data, and 97.4% for over-sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(255, 1759)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/Users/Rebecca/Desktop/Claudia/neural network/phage_quant/p002ypresabs_quant.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'Unnamed: 0':'id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.194875\n",
       "1      0.265250\n",
       "2      0.440625\n",
       "3      0.175500\n",
       "4      0.173625\n",
       "5      0.270375\n",
       "6      0.171000\n",
       "7      0.182500\n",
       "8      0.278875\n",
       "9      0.174375\n",
       "10     0.176250\n",
       "11     0.411125\n",
       "12     0.178250\n",
       "13     0.191500\n",
       "14     0.164875\n",
       "15     0.181875\n",
       "16     0.394125\n",
       "17     0.364875\n",
       "18     0.409875\n",
       "19     0.191875\n",
       "20     0.236125\n",
       "21     0.277000\n",
       "22     0.169875\n",
       "23     0.171625\n",
       "24     0.523625\n",
       "25     0.169500\n",
       "26     0.381000\n",
       "27     0.170000\n",
       "28     0.160750\n",
       "29     0.389750\n",
       "         ...   \n",
       "225    0.230500\n",
       "226    0.279800\n",
       "227    0.319500\n",
       "228    0.424100\n",
       "229    0.460500\n",
       "230    0.304750\n",
       "231    0.193875\n",
       "232    0.243000\n",
       "233    0.195750\n",
       "234    0.184750\n",
       "235    0.329125\n",
       "236    0.160000\n",
       "237    0.157500\n",
       "238    0.176375\n",
       "239    0.326750\n",
       "240    0.355750\n",
       "241    0.281375\n",
       "242    0.181875\n",
       "243    0.174125\n",
       "244    0.359250\n",
       "245    0.161375\n",
       "246    0.185875\n",
       "247    0.172750\n",
       "248    0.167750\n",
       "249    0.179875\n",
       "250    0.365375\n",
       "251    0.223500\n",
       "252    0.170750\n",
       "253    0.261125\n",
       "254    0.231000\n",
       "Name: pheno, Length: 255, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pheno']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0.5 in df['pheno']:\n",
    "    print: \"0.5 is in the list\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pheno'] = [1 if i>0.5 else 0 for i in df['pheno']] # convert pheno into binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    244\n",
       "1     11\n",
       "Name: pheno, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pheno']\n",
    "df['pheno'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(255, 1759)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.drop(columns=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(255, 1758)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(255, 1757) (255,)\n"
     ]
    }
   ],
   "source": [
    "X = df_clean.loc[:, df_clean.columns != 'pheno'].values\n",
    "y = df_clean['pheno'].values\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 235), (1, 241)]\n"
     ]
    }
   ],
   "source": [
    "# combination of under- and over- sampling\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.combine import SMOTEENN\n",
    "smote_enn = SMOTEENN(random_state=100)\n",
    "X_comb, y_comb = smote_enn.fit_resample(X, y)\n",
    "print(sorted(Counter(y_comb).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 244), (1, 244)]\n"
     ]
    }
   ],
   "source": [
    "# over-sampling\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "overS = RandomOverSampler(random_state=100)\n",
    "X_over, y_over = overS.fit_resample(X, y)\n",
    "print(sorted(Counter(y_over).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, validation, and test data (combination)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_comb, X_test_comb, y_train_comb, y_test_comb = train_test_split(X_comb, y_comb,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=123,\n",
    "                                                    stratify=y_comb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=123,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/fd/6bfe87920d7f4fd475acd28500a42482b6b84479832bdc0fe9e589a60ceb/Keras-2.3.1-py2.py3-none-any.whl (377kB)\n",
      "\u001b[K    100% |████████████████████████████████| 378kB 5.8MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.9.0 in /Users/Rebecca/anaconda3/lib/python3.7/site-packages (from keras) (1.12.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /Users/Rebecca/anaconda3/lib/python3.7/site-packages (from keras) (1.1.0)\n",
      "Requirement already satisfied: h5py in /Users/Rebecca/anaconda3/lib/python3.7/site-packages (from keras) (2.9.0)\n",
      "Requirement already satisfied: scipy>=0.14 in /Users/Rebecca/anaconda3/lib/python3.7/site-packages (from keras) (1.2.1)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /Users/Rebecca/anaconda3/lib/python3.7/site-packages (from keras) (1.16.2)\n",
      "Requirement already satisfied: pyyaml in /Users/Rebecca/anaconda3/lib/python3.7/site-packages (from keras) (5.1)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /Users/Rebecca/anaconda3/lib/python3.7/site-packages (from keras) (1.0.8)\n",
      "Installing collected packages: keras\n",
      "Successfully installed keras-2.3.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# Fully-Connected Neural Network ################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.regularizers import l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### neural network on combination data\n",
    "model1_comb = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_comb.shape[1],), activity_regularizer=l1(0.001)),\n",
    "    Dense(1, activation='sigmoid'),\n",
    "    Dropout(0.2, ),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_comb.compile(optimizer='sgd',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 233 samples, validate on 100 samples\n",
      "Epoch 1/100\n",
      "233/233 [==============================] - 0s 789us/step - loss: 2.5003 - accuracy: 0.7382 - val_loss: 0.6567 - val_accuracy: 0.8100\n",
      "Epoch 2/100\n",
      "233/233 [==============================] - 0s 126us/step - loss: 1.9409 - accuracy: 0.8455 - val_loss: 0.6123 - val_accuracy: 0.8100\n",
      "Epoch 3/100\n",
      "233/233 [==============================] - 0s 133us/step - loss: 1.4230 - accuracy: 0.8798 - val_loss: 0.5722 - val_accuracy: 0.8800\n",
      "Epoch 4/100\n",
      "233/233 [==============================] - 0s 163us/step - loss: 1.9825 - accuracy: 0.8369 - val_loss: 0.5522 - val_accuracy: 0.9000\n",
      "Epoch 5/100\n",
      "233/233 [==============================] - 0s 156us/step - loss: 1.7706 - accuracy: 0.8627 - val_loss: 0.5388 - val_accuracy: 0.8900\n",
      "Epoch 6/100\n",
      "233/233 [==============================] - 0s 137us/step - loss: 1.8079 - accuracy: 0.8755 - val_loss: 0.5289 - val_accuracy: 0.8500\n",
      "Epoch 7/100\n",
      "233/233 [==============================] - 0s 131us/step - loss: 2.0737 - accuracy: 0.8412 - val_loss: 0.5139 - val_accuracy: 0.8800\n",
      "Epoch 8/100\n",
      "233/233 [==============================] - 0s 140us/step - loss: 1.7170 - accuracy: 0.8841 - val_loss: 0.5022 - val_accuracy: 0.8800\n",
      "Epoch 9/100\n",
      "233/233 [==============================] - 0s 137us/step - loss: 2.5578 - accuracy: 0.8326 - val_loss: 0.4930 - val_accuracy: 0.8800\n",
      "Epoch 10/100\n",
      "233/233 [==============================] - 0s 132us/step - loss: 1.7612 - accuracy: 0.8884 - val_loss: 0.4884 - val_accuracy: 0.9300\n",
      "Epoch 11/100\n",
      "233/233 [==============================] - 0s 164us/step - loss: 2.3490 - accuracy: 0.8455 - val_loss: 0.4826 - val_accuracy: 0.9200\n",
      "Epoch 12/100\n",
      "233/233 [==============================] - 0s 128us/step - loss: 2.0779 - accuracy: 0.8798 - val_loss: 0.4693 - val_accuracy: 0.9300\n",
      "Epoch 13/100\n",
      "233/233 [==============================] - 0s 128us/step - loss: 1.8752 - accuracy: 0.8841 - val_loss: 0.4625 - val_accuracy: 0.9000\n",
      "Epoch 14/100\n",
      "233/233 [==============================] - 0s 129us/step - loss: 1.7344 - accuracy: 0.8970 - val_loss: 0.4536 - val_accuracy: 0.9000\n",
      "Epoch 15/100\n",
      "233/233 [==============================] - 0s 132us/step - loss: 1.8625 - accuracy: 0.8927 - val_loss: 0.4477 - val_accuracy: 0.9400\n",
      "Epoch 16/100\n",
      "233/233 [==============================] - 0s 137us/step - loss: 1.9184 - accuracy: 0.8841 - val_loss: 0.4563 - val_accuracy: 0.9200\n",
      "Epoch 17/100\n",
      "233/233 [==============================] - 0s 135us/step - loss: 1.7806 - accuracy: 0.8970 - val_loss: 0.4327 - val_accuracy: 0.9400\n",
      "Epoch 18/100\n",
      "233/233 [==============================] - 0s 164us/step - loss: 2.0338 - accuracy: 0.8798 - val_loss: 0.4308 - val_accuracy: 0.9200\n",
      "Epoch 19/100\n",
      "233/233 [==============================] - 0s 137us/step - loss: 1.9729 - accuracy: 0.8841 - val_loss: 0.4259 - val_accuracy: 0.9200\n",
      "Epoch 20/100\n",
      "233/233 [==============================] - 0s 133us/step - loss: 1.7566 - accuracy: 0.8970 - val_loss: 0.4135 - val_accuracy: 0.9500\n",
      "Epoch 21/100\n",
      "233/233 [==============================] - 0s 134us/step - loss: 1.7571 - accuracy: 0.8970 - val_loss: 0.4091 - val_accuracy: 0.9600\n",
      "Epoch 22/100\n",
      "233/233 [==============================] - 0s 130us/step - loss: 1.6895 - accuracy: 0.9013 - val_loss: 0.4043 - val_accuracy: 0.9500\n",
      "Epoch 23/100\n",
      "233/233 [==============================] - 0s 137us/step - loss: 1.1628 - accuracy: 0.9356 - val_loss: 0.3974 - val_accuracy: 0.9600\n",
      "Epoch 24/100\n",
      "233/233 [==============================] - 0s 132us/step - loss: 1.2847 - accuracy: 0.9270 - val_loss: 0.3993 - val_accuracy: 0.9300\n",
      "Epoch 25/100\n",
      "233/233 [==============================] - 0s 135us/step - loss: 1.5405 - accuracy: 0.9099 - val_loss: 0.3849 - val_accuracy: 0.9600\n",
      "Epoch 26/100\n",
      "233/233 [==============================] - 0s 143us/step - loss: 1.2773 - accuracy: 0.9270 - val_loss: 0.3866 - val_accuracy: 0.9300\n",
      "Epoch 27/100\n",
      "233/233 [==============================] - 0s 132us/step - loss: 1.7985 - accuracy: 0.8927 - val_loss: 0.3762 - val_accuracy: 0.9800\n",
      "Epoch 28/100\n",
      "233/233 [==============================] - 0s 142us/step - loss: 1.8565 - accuracy: 0.8884 - val_loss: 0.3731 - val_accuracy: 0.9800\n",
      "Epoch 29/100\n",
      "233/233 [==============================] - 0s 196us/step - loss: 1.6522 - accuracy: 0.9056 - val_loss: 0.3703 - val_accuracy: 0.9500\n",
      "Epoch 30/100\n",
      "233/233 [==============================] - 0s 271us/step - loss: 1.8458 - accuracy: 0.8884 - val_loss: 0.3647 - val_accuracy: 0.9500\n",
      "Epoch 31/100\n",
      "233/233 [==============================] - 0s 136us/step - loss: 1.7195 - accuracy: 0.8970 - val_loss: 0.3681 - val_accuracy: 0.9600\n",
      "Epoch 32/100\n",
      "233/233 [==============================] - 0s 157us/step - loss: 2.3663 - accuracy: 0.8541 - val_loss: 0.3576 - val_accuracy: 0.9800\n",
      "Epoch 33/100\n",
      "233/233 [==============================] - 0s 162us/step - loss: 1.6463 - accuracy: 0.9013 - val_loss: 0.3657 - val_accuracy: 0.9400\n",
      "Epoch 34/100\n",
      "233/233 [==============================] - 0s 161us/step - loss: 2.0396 - accuracy: 0.8755 - val_loss: 0.3491 - val_accuracy: 0.9700\n",
      "Epoch 35/100\n",
      "233/233 [==============================] - 0s 212us/step - loss: 1.7029 - accuracy: 0.8970 - val_loss: 0.3457 - val_accuracy: 0.9800\n",
      "Epoch 36/100\n",
      "233/233 [==============================] - 0s 175us/step - loss: 1.6429 - accuracy: 0.9013 - val_loss: 0.3415 - val_accuracy: 0.9800\n",
      "Epoch 37/100\n",
      "233/233 [==============================] - 0s 178us/step - loss: 1.4340 - accuracy: 0.9142 - val_loss: 0.3389 - val_accuracy: 0.9800\n",
      "Epoch 38/100\n",
      "233/233 [==============================] - 0s 168us/step - loss: 2.0967 - accuracy: 0.8712 - val_loss: 0.3426 - val_accuracy: 0.9700\n",
      "Epoch 39/100\n",
      "233/233 [==============================] - 0s 148us/step - loss: 1.9608 - accuracy: 0.8798 - val_loss: 0.3340 - val_accuracy: 0.9700\n",
      "Epoch 40/100\n",
      "233/233 [==============================] - 0s 159us/step - loss: 1.8282 - accuracy: 0.8884 - val_loss: 0.3299 - val_accuracy: 0.9700\n",
      "Epoch 41/100\n",
      "233/233 [==============================] - 0s 173us/step - loss: 1.6866 - accuracy: 0.8970 - val_loss: 0.3382 - val_accuracy: 0.9700\n",
      "Epoch 42/100\n",
      "233/233 [==============================] - 0s 145us/step - loss: 1.2294 - accuracy: 0.9270 - val_loss: 0.3276 - val_accuracy: 0.9900\n",
      "Epoch 43/100\n",
      "233/233 [==============================] - 0s 154us/step - loss: 1.6833 - accuracy: 0.9013 - val_loss: 0.3298 - val_accuracy: 0.9900\n",
      "Epoch 44/100\n",
      "233/233 [==============================] - 0s 167us/step - loss: 1.7546 - accuracy: 0.8970 - val_loss: 0.3310 - val_accuracy: 0.9800\n",
      "Epoch 45/100\n",
      "233/233 [==============================] - 0s 147us/step - loss: 1.9438 - accuracy: 0.8798 - val_loss: 0.3196 - val_accuracy: 0.9900\n",
      "Epoch 46/100\n",
      "233/233 [==============================] - 0s 149us/step - loss: 1.6135 - accuracy: 0.9013 - val_loss: 0.3190 - val_accuracy: 0.9900\n",
      "Epoch 47/100\n",
      "233/233 [==============================] - 0s 158us/step - loss: 2.5946 - accuracy: 0.8412 - val_loss: 0.3178 - val_accuracy: 0.9900\n",
      "Epoch 48/100\n",
      "233/233 [==============================] - 0s 154us/step - loss: 1.8765 - accuracy: 0.8884 - val_loss: 0.3171 - val_accuracy: 0.9900\n",
      "Epoch 49/100\n",
      "233/233 [==============================] - 0s 146us/step - loss: 2.0079 - accuracy: 0.8755 - val_loss: 0.3195 - val_accuracy: 0.9900\n",
      "Epoch 50/100\n",
      "233/233 [==============================] - 0s 154us/step - loss: 1.9393 - accuracy: 0.8798 - val_loss: 0.3199 - val_accuracy: 0.9900\n",
      "Epoch 51/100\n",
      "233/233 [==============================] - 0s 164us/step - loss: 1.3459 - accuracy: 0.9227 - val_loss: 0.3086 - val_accuracy: 0.9900\n",
      "Epoch 52/100\n",
      "233/233 [==============================] - 0s 146us/step - loss: 2.1400 - accuracy: 0.8712 - val_loss: 0.3366 - val_accuracy: 0.9700\n",
      "Epoch 53/100\n",
      "233/233 [==============================] - 0s 144us/step - loss: 1.8110 - accuracy: 0.8927 - val_loss: 0.3081 - val_accuracy: 0.9900\n",
      "Epoch 54/100\n",
      "233/233 [==============================] - 0s 164us/step - loss: 1.4732 - accuracy: 0.9099 - val_loss: 0.3037 - val_accuracy: 0.9900\n",
      "Epoch 55/100\n",
      "233/233 [==============================] - 0s 159us/step - loss: 1.3359 - accuracy: 0.9227 - val_loss: 0.3106 - val_accuracy: 0.9900\n",
      "Epoch 56/100\n",
      "233/233 [==============================] - 0s 145us/step - loss: 1.5361 - accuracy: 0.9056 - val_loss: 0.3040 - val_accuracy: 0.9900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "233/233 [==============================] - 0s 143us/step - loss: 1.2060 - accuracy: 0.9313 - val_loss: 0.2973 - val_accuracy: 0.9900\n",
      "Epoch 58/100\n",
      "233/233 [==============================] - 0s 129us/step - loss: 2.0630 - accuracy: 0.8755 - val_loss: 0.2968 - val_accuracy: 0.9900\n",
      "Epoch 59/100\n",
      "233/233 [==============================] - 0s 108us/step - loss: 1.5976 - accuracy: 0.9056 - val_loss: 0.3052 - val_accuracy: 0.9900\n",
      "Epoch 60/100\n",
      "233/233 [==============================] - 0s 145us/step - loss: 1.7982 - accuracy: 0.8927 - val_loss: 0.3044 - val_accuracy: 0.9900\n",
      "Epoch 61/100\n",
      "233/233 [==============================] - 0s 112us/step - loss: 2.1283 - accuracy: 0.8712 - val_loss: 0.2990 - val_accuracy: 0.9900\n",
      "Epoch 62/100\n",
      "233/233 [==============================] - 0s 115us/step - loss: 2.0586 - accuracy: 0.8755 - val_loss: 0.2894 - val_accuracy: 0.9900\n",
      "Epoch 63/100\n",
      "233/233 [==============================] - 0s 106us/step - loss: 1.5299 - accuracy: 0.9099 - val_loss: 0.2870 - val_accuracy: 0.9900\n",
      "Epoch 64/100\n",
      "233/233 [==============================] - 0s 110us/step - loss: 1.7906 - accuracy: 0.8927 - val_loss: 0.3031 - val_accuracy: 0.9900\n",
      "Epoch 65/100\n",
      "233/233 [==============================] - 0s 136us/step - loss: 1.8558 - accuracy: 0.8884 - val_loss: 0.2940 - val_accuracy: 0.9900\n",
      "Epoch 66/100\n",
      "233/233 [==============================] - 0s 113us/step - loss: 2.0512 - accuracy: 0.8755 - val_loss: 0.2900 - val_accuracy: 0.9900\n",
      "Epoch 67/100\n",
      "233/233 [==============================] - 0s 104us/step - loss: 1.5245 - accuracy: 0.9099 - val_loss: 0.2872 - val_accuracy: 0.9900\n",
      "Epoch 68/100\n",
      "233/233 [==============================] - 0s 126us/step - loss: 1.6576 - accuracy: 0.9013 - val_loss: 0.2927 - val_accuracy: 0.9900\n",
      "Epoch 69/100\n",
      "233/233 [==============================] - 0s 125us/step - loss: 1.6543 - accuracy: 0.9013 - val_loss: 0.2911 - val_accuracy: 0.9900\n",
      "Epoch 70/100\n",
      "233/233 [==============================] - 0s 115us/step - loss: 1.9818 - accuracy: 0.8798 - val_loss: 0.2854 - val_accuracy: 0.9900\n",
      "Epoch 71/100\n",
      "233/233 [==============================] - 0s 112us/step - loss: 1.3932 - accuracy: 0.9185 - val_loss: 0.2967 - val_accuracy: 0.9900\n",
      "Epoch 72/100\n",
      "233/233 [==============================] - 0s 112us/step - loss: 1.8494 - accuracy: 0.8884 - val_loss: 0.2869 - val_accuracy: 0.9900\n",
      "Epoch 73/100\n",
      "233/233 [==============================] - 0s 121us/step - loss: 1.3857 - accuracy: 0.9185 - val_loss: 0.2916 - val_accuracy: 0.9900\n",
      "Epoch 74/100\n",
      "233/233 [==============================] - 0s 113us/step - loss: 1.6511 - accuracy: 0.9013 - val_loss: 0.2806 - val_accuracy: 0.9900\n",
      "Epoch 75/100\n",
      "233/233 [==============================] - 0s 126us/step - loss: 1.4521 - accuracy: 0.9142 - val_loss: 0.2841 - val_accuracy: 0.9900\n",
      "Epoch 76/100\n",
      "233/233 [==============================] - 0s 128us/step - loss: 1.9794 - accuracy: 0.8798 - val_loss: 0.2809 - val_accuracy: 0.9900\n",
      "Epoch 77/100\n",
      "233/233 [==============================] - 0s 117us/step - loss: 1.7794 - accuracy: 0.8927 - val_loss: 0.2770 - val_accuracy: 0.9900\n",
      "Epoch 78/100\n",
      "233/233 [==============================] - 0s 116us/step - loss: 1.5151 - accuracy: 0.9099 - val_loss: 0.2823 - val_accuracy: 0.9900\n",
      "Epoch 79/100\n",
      "233/233 [==============================] - 0s 109us/step - loss: 1.5140 - accuracy: 0.9099 - val_loss: 0.2848 - val_accuracy: 0.9900\n",
      "Epoch 80/100\n",
      "233/233 [==============================] - 0s 110us/step - loss: 1.4489 - accuracy: 0.9142 - val_loss: 0.2832 - val_accuracy: 0.9900\n",
      "Epoch 81/100\n",
      "233/233 [==============================] - 0s 116us/step - loss: 1.9108 - accuracy: 0.8841 - val_loss: 0.2907 - val_accuracy: 0.9900\n",
      "Epoch 82/100\n",
      "233/233 [==============================] - 0s 107us/step - loss: 1.6448 - accuracy: 0.9013 - val_loss: 0.2742 - val_accuracy: 0.9900\n",
      "Epoch 83/100\n",
      "233/233 [==============================] - 0s 128us/step - loss: 1.3812 - accuracy: 0.9185 - val_loss: 0.2771 - val_accuracy: 0.9900\n",
      "Epoch 84/100\n",
      "233/233 [==============================] - 0s 142us/step - loss: 1.7113 - accuracy: 0.8970 - val_loss: 0.2740 - val_accuracy: 0.9900\n",
      "Epoch 85/100\n",
      "233/233 [==============================] - 0s 112us/step - loss: 1.4466 - accuracy: 0.9142 - val_loss: 0.2713 - val_accuracy: 0.9900\n",
      "Epoch 86/100\n",
      "233/233 [==============================] - 0s 116us/step - loss: 1.9744 - accuracy: 0.8798 - val_loss: 0.2706 - val_accuracy: 0.9900\n",
      "Epoch 87/100\n",
      "233/233 [==============================] - 0s 105us/step - loss: 1.0503 - accuracy: 0.9399 - val_loss: 0.2774 - val_accuracy: 0.9900\n",
      "Epoch 88/100\n",
      "233/233 [==============================] - 0s 110us/step - loss: 1.3116 - accuracy: 0.9227 - val_loss: 0.2752 - val_accuracy: 0.9900\n",
      "Epoch 89/100\n",
      "233/233 [==============================] - 0s 111us/step - loss: 1.5722 - accuracy: 0.9056 - val_loss: 0.2736 - val_accuracy: 0.9900\n",
      "Epoch 90/100\n",
      "233/233 [==============================] - 0s 113us/step - loss: 1.7745 - accuracy: 0.8927 - val_loss: 0.2682 - val_accuracy: 0.9900\n",
      "Epoch 91/100\n",
      "233/233 [==============================] - 0s 116us/step - loss: 1.7066 - accuracy: 0.8970 - val_loss: 0.2628 - val_accuracy: 0.9900\n",
      "Epoch 92/100\n",
      "233/233 [==============================] - 0s 113us/step - loss: 1.7742 - accuracy: 0.8927 - val_loss: 0.2812 - val_accuracy: 0.9900\n",
      "Epoch 93/100\n",
      "233/233 [==============================] - 0s 113us/step - loss: 1.7713 - accuracy: 0.8927 - val_loss: 0.2739 - val_accuracy: 0.9900\n",
      "Epoch 94/100\n",
      "233/233 [==============================] - 0s 111us/step - loss: 1.5051 - accuracy: 0.9099 - val_loss: 0.2701 - val_accuracy: 0.9900\n",
      "Epoch 95/100\n",
      "233/233 [==============================] - 0s 209us/step - loss: 1.3085 - accuracy: 0.9227 - val_loss: 0.2714 - val_accuracy: 0.9900\n",
      "Epoch 96/100\n",
      "233/233 [==============================] - 0s 122us/step - loss: 1.9672 - accuracy: 0.8798 - val_loss: 0.2671 - val_accuracy: 0.9900\n",
      "Epoch 97/100\n",
      "233/233 [==============================] - 0s 107us/step - loss: 1.7037 - accuracy: 0.8970 - val_loss: 0.2743 - val_accuracy: 0.9900\n",
      "Epoch 98/100\n",
      "233/233 [==============================] - 0s 113us/step - loss: 1.5695 - accuracy: 0.9056 - val_loss: 0.2702 - val_accuracy: 0.9900\n",
      "Epoch 99/100\n",
      "233/233 [==============================] - 0s 115us/step - loss: 1.2369 - accuracy: 0.9270 - val_loss: 0.2649 - val_accuracy: 0.9900\n",
      "Epoch 100/100\n",
      "233/233 [==============================] - 0s 106us/step - loss: 1.5046 - accuracy: 0.9099 - val_loss: 0.2665 - val_accuracy: 0.9900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a46746fd0>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_comb.fit(X_train_comb, y_train_comb,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_comb, y_test_comb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 116us/step\n",
      "combination validation accuracy: 99.00%\n"
     ]
    }
   ],
   "source": [
    "acc_test_comb = model1_comb.evaluate(X_test_comb, y_test_comb)[1]\n",
    "print('combination test accuracy: %.2f%%' % (acc_test_comb*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### neural network on over-sampling data\n",
    "model1_over = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over.compile(optimizer='sgd',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 238 samples, validate on 147 samples\n",
      "Epoch 1/100\n",
      "238/238 [==============================] - 0s 177us/step - loss: 0.0507 - accuracy: 0.9958 - val_loss: 0.0358 - val_accuracy: 0.9932\n",
      "Epoch 2/100\n",
      "238/238 [==============================] - 0s 165us/step - loss: 0.0512 - accuracy: 0.9832 - val_loss: 0.0330 - val_accuracy: 0.9932\n",
      "Epoch 3/100\n",
      "238/238 [==============================] - 0s 148us/step - loss: 0.0439 - accuracy: 0.9958 - val_loss: 0.0289 - val_accuracy: 0.9932\n",
      "Epoch 4/100\n",
      "238/238 [==============================] - 0s 134us/step - loss: 0.0418 - accuracy: 0.9958 - val_loss: 0.0295 - val_accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "238/238 [==============================] - 0s 128us/step - loss: 0.0422 - accuracy: 0.9958 - val_loss: 0.0312 - val_accuracy: 0.9932\n",
      "Epoch 6/100\n",
      "238/238 [==============================] - 0s 127us/step - loss: 0.0456 - accuracy: 0.9958 - val_loss: 0.0322 - val_accuracy: 0.9932\n",
      "Epoch 7/100\n",
      "238/238 [==============================] - 0s 128us/step - loss: 0.0406 - accuracy: 0.9958 - val_loss: 0.0288 - val_accuracy: 0.9932\n",
      "Epoch 8/100\n",
      "238/238 [==============================] - 0s 170us/step - loss: 0.0478 - accuracy: 0.9916 - val_loss: 0.0313 - val_accuracy: 0.9932\n",
      "Epoch 9/100\n",
      "238/238 [==============================] - 0s 131us/step - loss: 0.0424 - accuracy: 0.9958 - val_loss: 0.0282 - val_accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "238/238 [==============================] - 0s 143us/step - loss: 0.0409 - accuracy: 0.9958 - val_loss: 0.0285 - val_accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "238/238 [==============================] - 0s 136us/step - loss: 0.0411 - accuracy: 0.9958 - val_loss: 0.0301 - val_accuracy: 0.9932\n",
      "Epoch 12/100\n",
      "238/238 [==============================] - 0s 148us/step - loss: 0.0485 - accuracy: 0.9874 - val_loss: 0.0655 - val_accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "238/238 [==============================] - 0s 137us/step - loss: 0.0430 - accuracy: 0.9916 - val_loss: 0.0329 - val_accuracy: 0.9932\n",
      "Epoch 14/100\n",
      "238/238 [==============================] - 0s 152us/step - loss: 0.0422 - accuracy: 0.9916 - val_loss: 0.0278 - val_accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "238/238 [==============================] - 0s 158us/step - loss: 0.0480 - accuracy: 0.9916 - val_loss: 0.0277 - val_accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "238/238 [==============================] - 0s 164us/step - loss: 0.0397 - accuracy: 0.9958 - val_loss: 0.0275 - val_accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "238/238 [==============================] - 0s 164us/step - loss: 0.0397 - accuracy: 0.9958 - val_loss: 0.0267 - val_accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "238/238 [==============================] - 0s 205us/step - loss: 0.0432 - accuracy: 0.9958 - val_loss: 0.0298 - val_accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "238/238 [==============================] - 0s 178us/step - loss: 0.0424 - accuracy: 0.9916 - val_loss: 0.0258 - val_accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "238/238 [==============================] - 0s 147us/step - loss: 0.0366 - accuracy: 0.9958 - val_loss: 0.0683 - val_accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "238/238 [==============================] - 0s 142us/step - loss: 0.0548 - accuracy: 0.9916 - val_loss: 0.0234 - val_accuracy: 0.9932\n",
      "Epoch 22/100\n",
      "238/238 [==============================] - 0s 145us/step - loss: 0.0469 - accuracy: 0.9916 - val_loss: 0.0274 - val_accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "238/238 [==============================] - 0s 138us/step - loss: 0.0390 - accuracy: 0.9916 - val_loss: 0.0324 - val_accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "238/238 [==============================] - 0s 128us/step - loss: 0.0366 - accuracy: 0.9958 - val_loss: 0.0263 - val_accuracy: 0.9932\n",
      "Epoch 25/100\n",
      "238/238 [==============================] - 0s 132us/step - loss: 0.0362 - accuracy: 0.9958 - val_loss: 0.0266 - val_accuracy: 0.9932\n",
      "Epoch 26/100\n",
      "238/238 [==============================] - 0s 126us/step - loss: 0.0394 - accuracy: 0.9958 - val_loss: 0.0682 - val_accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "238/238 [==============================] - 0s 141us/step - loss: 0.0346 - accuracy: 0.9958 - val_loss: 0.0288 - val_accuracy: 0.9932\n",
      "Epoch 28/100\n",
      "238/238 [==============================] - 0s 129us/step - loss: 0.0388 - accuracy: 0.9958 - val_loss: 0.0230 - val_accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "238/238 [==============================] - 0s 132us/step - loss: 0.0358 - accuracy: 0.9958 - val_loss: 0.0228 - val_accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "238/238 [==============================] - 0s 140us/step - loss: 0.0405 - accuracy: 0.9916 - val_loss: 0.0233 - val_accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "238/238 [==============================] - 0s 157us/step - loss: 0.0387 - accuracy: 0.9916 - val_loss: 0.0233 - val_accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "238/238 [==============================] - 0s 170us/step - loss: 0.0340 - accuracy: 0.9958 - val_loss: 0.0220 - val_accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "238/238 [==============================] - 0s 174us/step - loss: 0.0403 - accuracy: 0.9958 - val_loss: 0.0256 - val_accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "238/238 [==============================] - 0s 174us/step - loss: 0.0358 - accuracy: 0.9958 - val_loss: 0.0207 - val_accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "238/238 [==============================] - 0s 193us/step - loss: 0.0367 - accuracy: 0.9958 - val_loss: 0.0215 - val_accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "238/238 [==============================] - 0s 169us/step - loss: 0.0370 - accuracy: 0.9916 - val_loss: 0.0279 - val_accuracy: 0.9932\n",
      "Epoch 37/100\n",
      "238/238 [==============================] - 0s 162us/step - loss: 0.0389 - accuracy: 0.9958 - val_loss: 0.0220 - val_accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "238/238 [==============================] - 0s 180us/step - loss: 0.0363 - accuracy: 0.9958 - val_loss: 0.0253 - val_accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "238/238 [==============================] - 0s 151us/step - loss: 0.0350 - accuracy: 0.9958 - val_loss: 0.0211 - val_accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "238/238 [==============================] - 0s 170us/step - loss: 0.0341 - accuracy: 0.9958 - val_loss: 0.0221 - val_accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "238/238 [==============================] - 0s 146us/step - loss: 0.0362 - accuracy: 0.9958 - val_loss: 0.0207 - val_accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "238/238 [==============================] - 0s 140us/step - loss: 0.0354 - accuracy: 0.9958 - val_loss: 0.0260 - val_accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "238/238 [==============================] - 0s 154us/step - loss: 0.0354 - accuracy: 0.9916 - val_loss: 0.0317 - val_accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "238/238 [==============================] - 0s 151us/step - loss: 0.0341 - accuracy: 0.9958 - val_loss: 0.0217 - val_accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "238/238 [==============================] - 0s 161us/step - loss: 0.0324 - accuracy: 0.9958 - val_loss: 0.0198 - val_accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "238/238 [==============================] - 0s 153us/step - loss: 0.0369 - accuracy: 0.9958 - val_loss: 0.0213 - val_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "238/238 [==============================] - 0s 143us/step - loss: 0.0350 - accuracy: 0.9958 - val_loss: 0.0250 - val_accuracy: 0.9932\n",
      "Epoch 48/100\n",
      "238/238 [==============================] - 0s 171us/step - loss: 0.0334 - accuracy: 0.9958 - val_loss: 0.0224 - val_accuracy: 0.9932\n",
      "Epoch 49/100\n",
      "238/238 [==============================] - 0s 210us/step - loss: 0.0332 - accuracy: 0.9958 - val_loss: 0.0217 - val_accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "238/238 [==============================] - 0s 180us/step - loss: 0.0336 - accuracy: 0.9958 - val_loss: 0.0204 - val_accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "238/238 [==============================] - 0s 169us/step - loss: 0.0348 - accuracy: 0.9958 - val_loss: 0.0188 - val_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "238/238 [==============================] - 0s 174us/step - loss: 0.0309 - accuracy: 0.9958 - val_loss: 0.0220 - val_accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "238/238 [==============================] - 0s 177us/step - loss: 0.0315 - accuracy: 0.9958 - val_loss: 0.0180 - val_accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "238/238 [==============================] - 0s 174us/step - loss: 0.0340 - accuracy: 0.9958 - val_loss: 0.0189 - val_accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "238/238 [==============================] - 0s 175us/step - loss: 0.0372 - accuracy: 0.9958 - val_loss: 0.0212 - val_accuracy: 0.9932\n",
      "Epoch 56/100\n",
      "238/238 [==============================] - 0s 186us/step - loss: 0.0314 - accuracy: 0.9916 - val_loss: 0.1055 - val_accuracy: 0.9592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "238/238 [==============================] - 0s 160us/step - loss: 0.0435 - accuracy: 0.9874 - val_loss: 0.0263 - val_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "238/238 [==============================] - 0s 99us/step - loss: 0.0321 - accuracy: 0.9958 - val_loss: 0.0204 - val_accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "238/238 [==============================] - 0s 147us/step - loss: 0.0330 - accuracy: 0.9916 - val_loss: 0.0220 - val_accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "238/238 [==============================] - 0s 216us/step - loss: 0.0309 - accuracy: 0.9958 - val_loss: 0.0494 - val_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "238/238 [==============================] - 0s 170us/step - loss: 0.0414 - accuracy: 0.9958 - val_loss: 0.0183 - val_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "238/238 [==============================] - 0s 162us/step - loss: 0.0291 - accuracy: 0.9958 - val_loss: 0.0282 - val_accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "238/238 [==============================] - 0s 167us/step - loss: 0.0312 - accuracy: 0.9958 - val_loss: 0.0178 - val_accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "238/238 [==============================] - 0s 171us/step - loss: 0.0306 - accuracy: 0.9958 - val_loss: 0.0193 - val_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "238/238 [==============================] - 0s 129us/step - loss: 0.0316 - accuracy: 0.9958 - val_loss: 0.0180 - val_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "238/238 [==============================] - 0s 127us/step - loss: 0.0313 - accuracy: 0.9958 - val_loss: 0.0186 - val_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "238/238 [==============================] - 0s 140us/step - loss: 0.0328 - accuracy: 0.9958 - val_loss: 0.0163 - val_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "238/238 [==============================] - 0s 127us/step - loss: 0.0298 - accuracy: 0.9958 - val_loss: 0.0222 - val_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "238/238 [==============================] - 0s 111us/step - loss: 0.0278 - accuracy: 0.9958 - val_loss: 0.1031 - val_accuracy: 0.8912\n",
      "Epoch 70/100\n",
      "238/238 [==============================] - 0s 110us/step - loss: 0.0344 - accuracy: 0.9874 - val_loss: 0.0554 - val_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "238/238 [==============================] - 0s 145us/step - loss: 0.0322 - accuracy: 0.9958 - val_loss: 0.0174 - val_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "238/238 [==============================] - 0s 168us/step - loss: 0.0296 - accuracy: 0.9958 - val_loss: 0.0172 - val_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "238/238 [==============================] - 0s 149us/step - loss: 0.0288 - accuracy: 0.9958 - val_loss: 0.0164 - val_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "238/238 [==============================] - 0s 145us/step - loss: 0.0286 - accuracy: 0.9958 - val_loss: 0.0180 - val_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "238/238 [==============================] - 0s 123us/step - loss: 0.0279 - accuracy: 0.9958 - val_loss: 0.0162 - val_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "238/238 [==============================] - 0s 122us/step - loss: 0.0306 - accuracy: 0.9958 - val_loss: 0.0154 - val_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "238/238 [==============================] - 0s 125us/step - loss: 0.0317 - accuracy: 0.9958 - val_loss: 0.0153 - val_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "238/238 [==============================] - 0s 114us/step - loss: 0.0296 - accuracy: 0.9958 - val_loss: 0.0157 - val_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "238/238 [==============================] - 0s 120us/step - loss: 0.0280 - accuracy: 0.9958 - val_loss: 0.0160 - val_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "238/238 [==============================] - 0s 126us/step - loss: 0.0303 - accuracy: 0.9958 - val_loss: 0.0181 - val_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "238/238 [==============================] - 0s 122us/step - loss: 0.0273 - accuracy: 0.9958 - val_loss: 0.0165 - val_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "238/238 [==============================] - 0s 144us/step - loss: 0.0312 - accuracy: 0.9958 - val_loss: 0.0156 - val_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "238/238 [==============================] - 0s 154us/step - loss: 0.0310 - accuracy: 0.9958 - val_loss: 0.0175 - val_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "238/238 [==============================] - 0s 143us/step - loss: 0.0328 - accuracy: 0.9958 - val_loss: 0.0161 - val_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "238/238 [==============================] - 0s 135us/step - loss: 0.0280 - accuracy: 0.9958 - val_loss: 0.0166 - val_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "238/238 [==============================] - 0s 132us/step - loss: 0.0297 - accuracy: 0.9958 - val_loss: 0.0187 - val_accuracy: 0.9932\n",
      "Epoch 87/100\n",
      "238/238 [==============================] - 0s 171us/step - loss: 0.0267 - accuracy: 0.9958 - val_loss: 0.0163 - val_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "238/238 [==============================] - 0s 130us/step - loss: 0.0265 - accuracy: 0.9958 - val_loss: 0.0155 - val_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "238/238 [==============================] - 0s 132us/step - loss: 0.0279 - accuracy: 0.9958 - val_loss: 0.0146 - val_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "238/238 [==============================] - 0s 132us/step - loss: 0.0268 - accuracy: 0.9958 - val_loss: 0.0182 - val_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "238/238 [==============================] - 0s 127us/step - loss: 0.0261 - accuracy: 0.9958 - val_loss: 0.0284 - val_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "238/238 [==============================] - 0s 121us/step - loss: 0.0321 - accuracy: 0.9958 - val_loss: 0.0145 - val_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "238/238 [==============================] - 0s 104us/step - loss: 0.0242 - accuracy: 0.9958 - val_loss: 0.0173 - val_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "238/238 [==============================] - 0s 146us/step - loss: 0.0269 - accuracy: 0.9958 - val_loss: 0.0551 - val_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "238/238 [==============================] - 0s 105us/step - loss: 0.0356 - accuracy: 0.9958 - val_loss: 0.0151 - val_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "238/238 [==============================] - 0s 114us/step - loss: 0.0273 - accuracy: 0.9958 - val_loss: 0.0140 - val_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "238/238 [==============================] - 0s 128us/step - loss: 0.0244 - accuracy: 0.9958 - val_loss: 0.0221 - val_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "238/238 [==============================] - 0s 135us/step - loss: 0.0256 - accuracy: 0.9958 - val_loss: 0.0962 - val_accuracy: 0.9592\n",
      "Epoch 99/100\n",
      "238/238 [==============================] - 0s 136us/step - loss: 0.0436 - accuracy: 0.9832 - val_loss: 0.0153 - val_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "238/238 [==============================] - 0s 134us/step - loss: 0.0259 - accuracy: 0.9958 - val_loss: 0.0142 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a46147080>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147/147 [==============================] - 0s 93us/step\n",
      "over-sampling test accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over = model1_over.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ Logistic Regression ############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###### logistics on combination data\n",
    "log_comb = LogisticRegression()\n",
    "log_comb.fit(X_train_comb, y_train_comb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combination logistic test accuracy 99.30%\n"
     ]
    }
   ],
   "source": [
    "y_pred_comb = log_comb.predict(X_test_comb)\n",
    "print('combination logistic test accuracy %.2f%%' % (log_comb.score(X_test_comb, y_test_comb)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### logistics on over-sampling data\n",
    "log_over = LogisticRegression()\n",
    "log_over.fit(X_train_over, y_train_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling logistic test accuracy 100.00%\n"
     ]
    }
   ],
   "source": [
    "y_pred_over = log_over.predict(X_test_over)\n",
    "print('over-sampling logistic test accuracy %.2f%%' % (log_over.score(X_test_over, y_test_over)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.        1.        0.9787234 1.        1.       ]\n",
      "0.9957446808510639\n",
      "0.008510638297872353\n"
     ]
    }
   ],
   "source": [
    "############## Random Forest ##############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### random forest on combination data\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_comb = RandomForestClassifier(n_estimators=100)\n",
    "rf_comb.fit(X_train_comb,y_train_comb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combination test accuracy: 99.30%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred_comb = rf_comb.predict(X_test_comb)\n",
    "print('combination test accuracy: %.2f%%' % (accuracy_score(y_test_comb, y_pred_comb)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###### random forest on over-sampling data\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_over = RandomForestClassifier(n_estimators=100)\n",
    "rf_over.fit(X_train_over,y_train_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combination test accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred_over = rf_over.predict(X_test_over)\n",
    "print('over-sampling test accuracy: %.2f%%' % (accuracy_score(y_test_over, y_pred_over)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Random forest with cross-validation\n",
    "## Retrieved from https://stackabuse.com/cross-validation-and-grid-search-for-model-selection-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.        1.        0.9787234 1.        1.       ]\n",
      "0.9957446808510639\n"
     ]
    }
   ],
   "source": [
    "## random forest model with CV on combination data\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "rfcv_comb = RandomForestClassifier(n_estimators=100, random_state=123)\n",
    "\n",
    "accs_comb = cross_val_score(estimator=rfcv_comb, X=X_train_comb, y=y_train_comb, cv=5)\n",
    "print(accs_comb)\n",
    "print(accs_comb.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.97916667 1.         0.97916667 0.97916667 0.93478261]\n",
      "0.9744565217391303\n"
     ]
    }
   ],
   "source": [
    "## random forest model with CV on over-sampling data\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "rfcv_over = RandomForestClassifier(n_estimators=100, random_state=123)\n",
    "\n",
    "accs_over = cross_val_score(estimator=rfcv_over, X=X_train_over, y=y_train_over, cv=5)\n",
    "print(accs_over)\n",
    "print(accs_over.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
