{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This file implements neural networks and logistic regression on p0017presabs_quant.\n",
    "## For fully-connected neural networks, the accuracy is 64.94%, and 66.23% after improvememt.\n",
    "## To improve accuracy, we construct lasso regression to select important features, and thus form a new dataset.\n",
    "## With the new dataset, the accuracy is 66.23%, and keeps 66.23% after improvement.\n",
    "## For logistic regression, the accuracy is 62.34%.\n",
    "## We further construct random forest models, which are relatively less likely to bring overfitting \n",
    "## compared to decision tree.\n",
    "## For random forest, the accuracy is 62.34%.\n",
    "## For random forest with cross-validation, the mean accuracy is 75.26%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(100)\n",
    "import tensorflow\n",
    "tensorflow.random.set_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(255, 7004)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/Users/Rebecca/Desktop/Claudia/neural network/phage_quant/p0017presabs_quant.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'Unnamed: 0':'id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.871375\n",
       "1      0.364375\n",
       "2      0.803000\n",
       "3      0.952625\n",
       "4      1.012875\n",
       "5      0.936750\n",
       "6      0.745375\n",
       "7      0.348375\n",
       "8      0.571750\n",
       "9      0.637125\n",
       "10     0.670500\n",
       "11     0.731250\n",
       "12     0.865125\n",
       "13     0.569375\n",
       "14     0.327000\n",
       "15     0.175750\n",
       "16     0.964000\n",
       "17     1.104167\n",
       "18     0.223667\n",
       "19     0.340167\n",
       "20     0.438500\n",
       "21     0.271833\n",
       "22     0.248833\n",
       "23     0.739333\n",
       "24     0.232833\n",
       "25     0.601500\n",
       "26     0.251000\n",
       "27     0.202833\n",
       "28     0.599833\n",
       "29     0.260667\n",
       "         ...   \n",
       "225    0.459500\n",
       "226    0.825333\n",
       "227    0.763167\n",
       "228    0.334500\n",
       "229    0.998833\n",
       "230    0.491125\n",
       "231    0.405750\n",
       "232    0.875375\n",
       "233    0.761500\n",
       "234    0.255000\n",
       "235    0.455125\n",
       "236    0.234125\n",
       "237    0.340125\n",
       "238    0.952750\n",
       "239    0.238500\n",
       "240    0.294500\n",
       "241    0.172125\n",
       "242    0.221500\n",
       "243    0.989875\n",
       "244    0.763000\n",
       "245    0.229875\n",
       "246    0.215125\n",
       "247    0.805375\n",
       "248    0.184875\n",
       "249    0.663250\n",
       "250    0.803125\n",
       "251    0.443875\n",
       "252    0.207500\n",
       "253    0.933875\n",
       "254    0.873375\n",
       "Name: pheno, Length: 255, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pheno']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>TTTTTTTTATTTTACTCACCTCTAAAGCATAATTCCATATAAACTTGTTATTATCCGAAATTTTTGTATAATAGATTATTTTTGTTGGAGTAATTATTAG</th>\n",
       "      <th>TTTTTTTGTAAATCTTTTCCATTTATTTCTTCGCTTTTCTCGCTACAATTTACAAATGGACTTGTTATCAACGTTAGGGCAATAAATGAAAGTAGTATAA</th>\n",
       "      <th>TTTTTTTGATAATTT</th>\n",
       "      <th>TTTTTTTCTTATTATACGAAATTTTCATATCATAGTAAAGTTTTTTACGAAAAAAACGTATTTAATGTTGACAATACGAAAATTTCGTATTATATTAGGT</th>\n",
       "      <th>TTTTTTTCGTAAAAAACTTTACTATGATATGAAAATTTCGTATAATAAGAAAAAAAGGAGGTAAGTAATATGAACAAAGAAAGAAATATTATTATAGCCA</th>\n",
       "      <th>TTTTTTTATTTTGCAATTTTTTATTTTCATTATAAACTTCCTTTCAAACACTGCTGAAATAGACGTCTTTTTCAAATAAGCATGATTAATACTTCAATTC</th>\n",
       "      <th>TTTTTTTATTTTACTCACCTCTAAAGCATAATTCCATATAAACTTGTTATTATCCGAAATTTTTGTATAATAGATTATTTTTGTTGGAGTAATTATTAGT</th>\n",
       "      <th>TTTTTTTATGTTATTATAATTAAAGTTTTCCATTGTTTTCCTCCTATAATAGCTTATCTGCAATCATCACAGCTAATAAATCGTTTTGTCTTATTGCTTC</th>\n",
       "      <th>TTTTTTTATGTTATAATCTTTCTAGACGTATTCAAAGGACGTCTTTTTAGATTGTATGTTATAGCTAGCCTTCCGGTTAATTTTTTGTTATGATGTGTTA</th>\n",
       "      <th>...</th>\n",
       "      <th>group_315</th>\n",
       "      <th>group_381</th>\n",
       "      <th>group_426</th>\n",
       "      <th>group_4770</th>\n",
       "      <th>group_8913</th>\n",
       "      <th>group_9224</th>\n",
       "      <th>group_9493</th>\n",
       "      <th>group_9494</th>\n",
       "      <th>group_9905</th>\n",
       "      <th>pheno</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.871375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>109</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.364375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.803000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>120335</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.952625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120337</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.012875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7004 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  \\\n",
       "0     107   \n",
       "1     109   \n",
       "2     115   \n",
       "3  120335   \n",
       "4  120337   \n",
       "\n",
       "   TTTTTTTTATTTTACTCACCTCTAAAGCATAATTCCATATAAACTTGTTATTATCCGAAATTTTTGTATAATAGATTATTTTTGTTGGAGTAATTATTAG  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   TTTTTTTGTAAATCTTTTCCATTTATTTCTTCGCTTTTCTCGCTACAATTTACAAATGGACTTGTTATCAACGTTAGGGCAATAAATGAAAGTAGTATAA  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   TTTTTTTGATAATTT  \\\n",
       "0                0   \n",
       "1                1   \n",
       "2                1   \n",
       "3                0   \n",
       "4                0   \n",
       "\n",
       "   TTTTTTTCTTATTATACGAAATTTTCATATCATAGTAAAGTTTTTTACGAAAAAAACGTATTTAATGTTGACAATACGAAAATTTCGTATTATATTAGGT  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   TTTTTTTCGTAAAAAACTTTACTATGATATGAAAATTTCGTATAATAAGAAAAAAAGGAGGTAAGTAATATGAACAAAGAAAGAAATATTATTATAGCCA  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   TTTTTTTATTTTGCAATTTTTTATTTTCATTATAAACTTCCTTTCAAACACTGCTGAAATAGACGTCTTTTTCAAATAAGCATGATTAATACTTCAATTC  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   TTTTTTTATTTTACTCACCTCTAAAGCATAATTCCATATAAACTTGTTATTATCCGAAATTTTTGTATAATAGATTATTTTTGTTGGAGTAATTATTAGT  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   TTTTTTTATGTTATTATAATTAAAGTTTTCCATTGTTTTCCTCCTATAATAGCTTATCTGCAATCATCACAGCTAATAAATCGTTTTGTCTTATTGCTTC  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   TTTTTTTATGTTATAATCTTTCTAGACGTATTCAAAGGACGTCTTTTTAGATTGTATGTTATAGCTAGCCTTCCGGTTAATTTTTTGTTATGATGTGTTA  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   ...  group_315  group_381  group_426  group_4770  group_8913  group_9224  \\\n",
       "0  ...          0          0          0           0           0           0   \n",
       "1  ...          0          0          0           0           0           0   \n",
       "2  ...          0          0          0           0           0           0   \n",
       "3  ...          0          0          0           0           0           0   \n",
       "4  ...          0          0          0           0           0           0   \n",
       "\n",
       "   group_9493  group_9494  group_9905     pheno  \n",
       "0           0           0           0  0.871375  \n",
       "1           0           0           0  0.364375  \n",
       "2           0           0           0  0.803000  \n",
       "3           0           0           0  0.952625  \n",
       "4           0           0           0  1.012875  \n",
       "\n",
       "[5 rows x 7004 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0.5 in df['pheno']:\n",
    "    print: \"0.5 is in the list\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pheno'] = [1 if i>0.5 else 0 for i in df['pheno']] # convert pheno into binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    135\n",
       "0    120\n",
       "Name: pheno, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pheno']\n",
    "df['pheno'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(255, 7004)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.drop(columns=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(255, 7003)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TTTTTTTTATTTTACTCACCTCTAAAGCATAATTCCATATAAACTTGTTATTATCCGAAATTTTTGTATAATAGATTATTTTTGTTGGAGTAATTATTAG</th>\n",
       "      <th>TTTTTTTGTAAATCTTTTCCATTTATTTCTTCGCTTTTCTCGCTACAATTTACAAATGGACTTGTTATCAACGTTAGGGCAATAAATGAAAGTAGTATAA</th>\n",
       "      <th>TTTTTTTGATAATTT</th>\n",
       "      <th>TTTTTTTCTTATTATACGAAATTTTCATATCATAGTAAAGTTTTTTACGAAAAAAACGTATTTAATGTTGACAATACGAAAATTTCGTATTATATTAGGT</th>\n",
       "      <th>TTTTTTTCGTAAAAAACTTTACTATGATATGAAAATTTCGTATAATAAGAAAAAAAGGAGGTAAGTAATATGAACAAAGAAAGAAATATTATTATAGCCA</th>\n",
       "      <th>TTTTTTTATTTTGCAATTTTTTATTTTCATTATAAACTTCCTTTCAAACACTGCTGAAATAGACGTCTTTTTCAAATAAGCATGATTAATACTTCAATTC</th>\n",
       "      <th>TTTTTTTATTTTACTCACCTCTAAAGCATAATTCCATATAAACTTGTTATTATCCGAAATTTTTGTATAATAGATTATTTTTGTTGGAGTAATTATTAGT</th>\n",
       "      <th>TTTTTTTATGTTATTATAATTAAAGTTTTCCATTGTTTTCCTCCTATAATAGCTTATCTGCAATCATCACAGCTAATAAATCGTTTTGTCTTATTGCTTC</th>\n",
       "      <th>TTTTTTTATGTTATAATCTTTCTAGACGTATTCAAAGGACGTCTTTTTAGATTGTATGTTATAGCTAGCCTTCCGGTTAATTTTTTGTTATGATGTGTTA</th>\n",
       "      <th>TTTTTTTATAACATTCAAAGTCTCACCATTGTCATTTGAATGATCATCAATAATAATTAATTCGTAATCAGTACTCTTCATTGTTTGATTTAATACAGAA</th>\n",
       "      <th>...</th>\n",
       "      <th>group_315</th>\n",
       "      <th>group_381</th>\n",
       "      <th>group_426</th>\n",
       "      <th>group_4770</th>\n",
       "      <th>group_8913</th>\n",
       "      <th>group_9224</th>\n",
       "      <th>group_9493</th>\n",
       "      <th>group_9494</th>\n",
       "      <th>group_9905</th>\n",
       "      <th>pheno</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7003 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TTTTTTTTATTTTACTCACCTCTAAAGCATAATTCCATATAAACTTGTTATTATCCGAAATTTTTGTATAATAGATTATTTTTGTTGGAGTAATTATTAG  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   TTTTTTTGTAAATCTTTTCCATTTATTTCTTCGCTTTTCTCGCTACAATTTACAAATGGACTTGTTATCAACGTTAGGGCAATAAATGAAAGTAGTATAA  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   TTTTTTTGATAATTT  \\\n",
       "0                0   \n",
       "1                1   \n",
       "2                1   \n",
       "3                0   \n",
       "4                0   \n",
       "\n",
       "   TTTTTTTCTTATTATACGAAATTTTCATATCATAGTAAAGTTTTTTACGAAAAAAACGTATTTAATGTTGACAATACGAAAATTTCGTATTATATTAGGT  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   TTTTTTTCGTAAAAAACTTTACTATGATATGAAAATTTCGTATAATAAGAAAAAAAGGAGGTAAGTAATATGAACAAAGAAAGAAATATTATTATAGCCA  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   TTTTTTTATTTTGCAATTTTTTATTTTCATTATAAACTTCCTTTCAAACACTGCTGAAATAGACGTCTTTTTCAAATAAGCATGATTAATACTTCAATTC  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   TTTTTTTATTTTACTCACCTCTAAAGCATAATTCCATATAAACTTGTTATTATCCGAAATTTTTGTATAATAGATTATTTTTGTTGGAGTAATTATTAGT  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   TTTTTTTATGTTATTATAATTAAAGTTTTCCATTGTTTTCCTCCTATAATAGCTTATCTGCAATCATCACAGCTAATAAATCGTTTTGTCTTATTGCTTC  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   TTTTTTTATGTTATAATCTTTCTAGACGTATTCAAAGGACGTCTTTTTAGATTGTATGTTATAGCTAGCCTTCCGGTTAATTTTTTGTTATGATGTGTTA  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   TTTTTTTATAACATTCAAAGTCTCACCATTGTCATTTGAATGATCATCAATAATAATTAATTCGTAATCAGTACTCTTCATTGTTTGATTTAATACAGAA  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   ...  group_315  group_381  group_426  group_4770  group_8913  group_9224  \\\n",
       "0  ...          0          0          0           0           0           0   \n",
       "1  ...          0          0          0           0           0           0   \n",
       "2  ...          0          0          0           0           0           0   \n",
       "3  ...          0          0          0           0           0           0   \n",
       "4  ...          0          0          0           0           0           0   \n",
       "\n",
       "   group_9493  group_9494  group_9905  pheno  \n",
       "0           0           0           0      1  \n",
       "1           0           0           0      0  \n",
       "2           0           0           0      1  \n",
       "3           0           0           0      1  \n",
       "4           0           0           0      1  \n",
       "\n",
       "[5 rows x 7003 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(255, 7002) (255,)\n"
     ]
    }
   ],
   "source": [
    "X = df_clean.loc[:, df_clean.columns != 'pheno'].values\n",
    "y = df_clean['pheno'].values\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, validation, and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=123,\n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# Fully-Connected Neural Network ################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.regularizers import l1\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### neural network\n",
    "model1 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(1, activation='sigmoid'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(optimizer='sgd',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 178 samples, validate on 77 samples\n",
      "Epoch 1/100\n",
      "178/178 [==============================] - 0s 811us/step - loss: 0.6350 - accuracy: 0.6067 - val_loss: 0.6466 - val_accuracy: 0.5455\n",
      "Epoch 2/100\n",
      "178/178 [==============================] - 0s 188us/step - loss: 0.5690 - accuracy: 0.6798 - val_loss: 0.6667 - val_accuracy: 0.5455\n",
      "Epoch 3/100\n",
      "178/178 [==============================] - 0s 199us/step - loss: 0.5427 - accuracy: 0.7079 - val_loss: 0.6464 - val_accuracy: 0.5844\n",
      "Epoch 4/100\n",
      "178/178 [==============================] - 0s 207us/step - loss: 0.5203 - accuracy: 0.7584 - val_loss: 0.6593 - val_accuracy: 0.5974\n",
      "Epoch 5/100\n",
      "178/178 [==============================] - 0s 197us/step - loss: 0.5046 - accuracy: 0.7753 - val_loss: 0.6974 - val_accuracy: 0.6234\n",
      "Epoch 6/100\n",
      "178/178 [==============================] - 0s 194us/step - loss: 0.4997 - accuracy: 0.7528 - val_loss: 0.6619 - val_accuracy: 0.5974\n",
      "Epoch 7/100\n",
      "178/178 [==============================] - 0s 178us/step - loss: 0.4786 - accuracy: 0.7697 - val_loss: 0.6637 - val_accuracy: 0.6104\n",
      "Epoch 8/100\n",
      "178/178 [==============================] - 0s 179us/step - loss: 0.4709 - accuracy: 0.7865 - val_loss: 0.6816 - val_accuracy: 0.6104\n",
      "Epoch 9/100\n",
      "178/178 [==============================] - 0s 181us/step - loss: 0.4558 - accuracy: 0.7921 - val_loss: 0.6674 - val_accuracy: 0.6234\n",
      "Epoch 10/100\n",
      "178/178 [==============================] - 0s 202us/step - loss: 0.4503 - accuracy: 0.7809 - val_loss: 0.6759 - val_accuracy: 0.5974\n",
      "Epoch 11/100\n",
      "178/178 [==============================] - 0s 199us/step - loss: 0.4414 - accuracy: 0.7978 - val_loss: 0.6714 - val_accuracy: 0.5974\n",
      "Epoch 12/100\n",
      "178/178 [==============================] - 0s 214us/step - loss: 0.4410 - accuracy: 0.7921 - val_loss: 0.6763 - val_accuracy: 0.5974\n",
      "Epoch 13/100\n",
      "178/178 [==============================] - 0s 188us/step - loss: 0.4297 - accuracy: 0.7921 - val_loss: 0.6773 - val_accuracy: 0.6104\n",
      "Epoch 14/100\n",
      "178/178 [==============================] - 0s 210us/step - loss: 0.4229 - accuracy: 0.8090 - val_loss: 0.6772 - val_accuracy: 0.6104\n",
      "Epoch 15/100\n",
      "178/178 [==============================] - 0s 181us/step - loss: 0.4201 - accuracy: 0.7978 - val_loss: 0.6823 - val_accuracy: 0.6104\n",
      "Epoch 16/100\n",
      "178/178 [==============================] - 0s 194us/step - loss: 0.4109 - accuracy: 0.8090 - val_loss: 0.7035 - val_accuracy: 0.6494\n",
      "Epoch 17/100\n",
      "178/178 [==============================] - 0s 191us/step - loss: 0.4077 - accuracy: 0.8427 - val_loss: 0.6982 - val_accuracy: 0.6234\n",
      "Epoch 18/100\n",
      "178/178 [==============================] - 0s 193us/step - loss: 0.4088 - accuracy: 0.8371 - val_loss: 0.6852 - val_accuracy: 0.6104\n",
      "Epoch 19/100\n",
      "178/178 [==============================] - 0s 177us/step - loss: 0.3969 - accuracy: 0.8258 - val_loss: 0.6881 - val_accuracy: 0.6104\n",
      "Epoch 20/100\n",
      "178/178 [==============================] - 0s 172us/step - loss: 0.3926 - accuracy: 0.8315 - val_loss: 0.6937 - val_accuracy: 0.6104\n",
      "Epoch 21/100\n",
      "178/178 [==============================] - 0s 171us/step - loss: 0.3878 - accuracy: 0.8371 - val_loss: 0.6854 - val_accuracy: 0.6234\n",
      "Epoch 22/100\n",
      "178/178 [==============================] - 0s 170us/step - loss: 0.3827 - accuracy: 0.8427 - val_loss: 0.7017 - val_accuracy: 0.6234\n",
      "Epoch 23/100\n",
      "178/178 [==============================] - 0s 168us/step - loss: 0.3813 - accuracy: 0.8539 - val_loss: 0.6909 - val_accuracy: 0.6234\n",
      "Epoch 24/100\n",
      "178/178 [==============================] - 0s 181us/step - loss: 0.3791 - accuracy: 0.8483 - val_loss: 0.6959 - val_accuracy: 0.6234\n",
      "Epoch 25/100\n",
      "178/178 [==============================] - 0s 206us/step - loss: 0.3750 - accuracy: 0.8258 - val_loss: 0.7016 - val_accuracy: 0.6234\n",
      "Epoch 26/100\n",
      "178/178 [==============================] - 0s 181us/step - loss: 0.3697 - accuracy: 0.8539 - val_loss: 0.6916 - val_accuracy: 0.6234\n",
      "Epoch 27/100\n",
      "178/178 [==============================] - 0s 179us/step - loss: 0.3666 - accuracy: 0.8539 - val_loss: 0.7033 - val_accuracy: 0.6234\n",
      "Epoch 28/100\n",
      "178/178 [==============================] - 0s 183us/step - loss: 0.3656 - accuracy: 0.8708 - val_loss: 0.6979 - val_accuracy: 0.6364\n",
      "Epoch 29/100\n",
      "178/178 [==============================] - 0s 187us/step - loss: 0.3602 - accuracy: 0.8539 - val_loss: 0.7066 - val_accuracy: 0.6364\n",
      "Epoch 30/100\n",
      "178/178 [==============================] - 0s 233us/step - loss: 0.3569 - accuracy: 0.8539 - val_loss: 0.7168 - val_accuracy: 0.6364\n",
      "Epoch 31/100\n",
      "178/178 [==============================] - 0s 200us/step - loss: 0.3602 - accuracy: 0.8708 - val_loss: 0.7036 - val_accuracy: 0.6234\n",
      "Epoch 32/100\n",
      "178/178 [==============================] - 0s 165us/step - loss: 0.3545 - accuracy: 0.8596 - val_loss: 0.7139 - val_accuracy: 0.6623\n",
      "Epoch 33/100\n",
      "178/178 [==============================] - 0s 174us/step - loss: 0.3510 - accuracy: 0.8820 - val_loss: 0.7112 - val_accuracy: 0.6234\n",
      "Epoch 34/100\n",
      "178/178 [==============================] - 0s 165us/step - loss: 0.3463 - accuracy: 0.8820 - val_loss: 0.7184 - val_accuracy: 0.6234\n",
      "Epoch 35/100\n",
      "178/178 [==============================] - 0s 161us/step - loss: 0.3445 - accuracy: 0.8708 - val_loss: 0.7162 - val_accuracy: 0.6234\n",
      "Epoch 36/100\n",
      "178/178 [==============================] - 0s 173us/step - loss: 0.3414 - accuracy: 0.8764 - val_loss: 0.7137 - val_accuracy: 0.6234\n",
      "Epoch 37/100\n",
      "178/178 [==============================] - 0s 195us/step - loss: 0.3398 - accuracy: 0.8764 - val_loss: 0.7142 - val_accuracy: 0.6104\n",
      "Epoch 38/100\n",
      "178/178 [==============================] - 0s 172us/step - loss: 0.3473 - accuracy: 0.8820 - val_loss: 0.7196 - val_accuracy: 0.6364\n",
      "Epoch 39/100\n",
      "178/178 [==============================] - 0s 171us/step - loss: 0.3383 - accuracy: 0.8764 - val_loss: 0.7275 - val_accuracy: 0.6364\n",
      "Epoch 40/100\n",
      "178/178 [==============================] - 0s 168us/step - loss: 0.3321 - accuracy: 0.8820 - val_loss: 0.7343 - val_accuracy: 0.6364\n",
      "Epoch 41/100\n",
      "178/178 [==============================] - 0s 181us/step - loss: 0.3274 - accuracy: 0.8933 - val_loss: 0.7332 - val_accuracy: 0.6364\n",
      "Epoch 42/100\n",
      "178/178 [==============================] - 0s 170us/step - loss: 0.3260 - accuracy: 0.8933 - val_loss: 0.7323 - val_accuracy: 0.6364\n",
      "Epoch 43/100\n",
      "178/178 [==============================] - 0s 180us/step - loss: 0.3261 - accuracy: 0.8876 - val_loss: 0.7460 - val_accuracy: 0.6364\n",
      "Epoch 44/100\n",
      "178/178 [==============================] - 0s 180us/step - loss: 0.3164 - accuracy: 0.8989 - val_loss: 0.7320 - val_accuracy: 0.6234\n",
      "Epoch 45/100\n",
      "178/178 [==============================] - 0s 180us/step - loss: 0.3323 - accuracy: 0.8764 - val_loss: 0.7419 - val_accuracy: 0.6494\n",
      "Epoch 46/100\n",
      "178/178 [==============================] - 0s 179us/step - loss: 0.3157 - accuracy: 0.8989 - val_loss: 0.7493 - val_accuracy: 0.6494\n",
      "Epoch 47/100\n",
      "178/178 [==============================] - 0s 170us/step - loss: 0.3137 - accuracy: 0.8820 - val_loss: 0.7433 - val_accuracy: 0.6364\n",
      "Epoch 48/100\n",
      "178/178 [==============================] - 0s 185us/step - loss: 0.3116 - accuracy: 0.8820 - val_loss: 0.7499 - val_accuracy: 0.6364\n",
      "Epoch 49/100\n",
      "178/178 [==============================] - 0s 164us/step - loss: 0.3070 - accuracy: 0.8933 - val_loss: 0.7417 - val_accuracy: 0.6364\n",
      "Epoch 50/100\n",
      "178/178 [==============================] - 0s 182us/step - loss: 0.3084 - accuracy: 0.8933 - val_loss: 0.7492 - val_accuracy: 0.6623\n",
      "Epoch 51/100\n",
      "178/178 [==============================] - 0s 190us/step - loss: 0.3068 - accuracy: 0.8933 - val_loss: 0.7520 - val_accuracy: 0.6234\n",
      "Epoch 52/100\n",
      "178/178 [==============================] - 0s 179us/step - loss: 0.3056 - accuracy: 0.8708 - val_loss: 0.7496 - val_accuracy: 0.6623\n",
      "Epoch 53/100\n",
      "178/178 [==============================] - 0s 181us/step - loss: 0.3054 - accuracy: 0.8989 - val_loss: 0.7503 - val_accuracy: 0.6234\n",
      "Epoch 54/100\n",
      "178/178 [==============================] - 0s 177us/step - loss: 0.3045 - accuracy: 0.8820 - val_loss: 0.7608 - val_accuracy: 0.6494\n",
      "Epoch 55/100\n",
      "178/178 [==============================] - 0s 164us/step - loss: 0.2978 - accuracy: 0.8820 - val_loss: 0.7623 - val_accuracy: 0.6234\n",
      "Epoch 56/100\n",
      "178/178 [==============================] - 0s 191us/step - loss: 0.2955 - accuracy: 0.8820 - val_loss: 0.7659 - val_accuracy: 0.6364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "178/178 [==============================] - 0s 162us/step - loss: 0.2959 - accuracy: 0.8820 - val_loss: 0.7655 - val_accuracy: 0.6364\n",
      "Epoch 58/100\n",
      "178/178 [==============================] - 0s 177us/step - loss: 0.2939 - accuracy: 0.8989 - val_loss: 0.7627 - val_accuracy: 0.6494\n",
      "Epoch 59/100\n",
      "178/178 [==============================] - 0s 172us/step - loss: 0.2955 - accuracy: 0.9045 - val_loss: 0.8018 - val_accuracy: 0.6364\n",
      "Epoch 60/100\n",
      "178/178 [==============================] - 0s 171us/step - loss: 0.3002 - accuracy: 0.8989 - val_loss: 0.7707 - val_accuracy: 0.6494\n",
      "Epoch 61/100\n",
      "178/178 [==============================] - 0s 170us/step - loss: 0.2910 - accuracy: 0.9045 - val_loss: 0.7779 - val_accuracy: 0.6364\n",
      "Epoch 62/100\n",
      "178/178 [==============================] - 0s 174us/step - loss: 0.2891 - accuracy: 0.8876 - val_loss: 0.7695 - val_accuracy: 0.6364\n",
      "Epoch 63/100\n",
      "178/178 [==============================] - 0s 171us/step - loss: 0.2826 - accuracy: 0.9157 - val_loss: 0.7655 - val_accuracy: 0.6494\n",
      "Epoch 64/100\n",
      "178/178 [==============================] - 0s 185us/step - loss: 0.2872 - accuracy: 0.8989 - val_loss: 0.7889 - val_accuracy: 0.6623\n",
      "Epoch 65/100\n",
      "178/178 [==============================] - 0s 170us/step - loss: 0.2847 - accuracy: 0.8876 - val_loss: 0.7873 - val_accuracy: 0.6364\n",
      "Epoch 66/100\n",
      "178/178 [==============================] - 0s 171us/step - loss: 0.2840 - accuracy: 0.8989 - val_loss: 0.7811 - val_accuracy: 0.6364\n",
      "Epoch 67/100\n",
      "178/178 [==============================] - 0s 168us/step - loss: 0.2797 - accuracy: 0.9045 - val_loss: 0.7733 - val_accuracy: 0.6494\n",
      "Epoch 68/100\n",
      "178/178 [==============================] - 0s 174us/step - loss: 0.2858 - accuracy: 0.8933 - val_loss: 0.7787 - val_accuracy: 0.6364\n",
      "Epoch 69/100\n",
      "178/178 [==============================] - 0s 166us/step - loss: 0.2870 - accuracy: 0.8933 - val_loss: 0.7869 - val_accuracy: 0.6364\n",
      "Epoch 70/100\n",
      "178/178 [==============================] - 0s 152us/step - loss: 0.2756 - accuracy: 0.9045 - val_loss: 0.7933 - val_accuracy: 0.6364\n",
      "Epoch 71/100\n",
      "178/178 [==============================] - 0s 159us/step - loss: 0.2713 - accuracy: 0.8989 - val_loss: 0.7968 - val_accuracy: 0.6364\n",
      "Epoch 72/100\n",
      "178/178 [==============================] - 0s 159us/step - loss: 0.2800 - accuracy: 0.8876 - val_loss: 0.7885 - val_accuracy: 0.6494\n",
      "Epoch 73/100\n",
      "178/178 [==============================] - 0s 157us/step - loss: 0.2781 - accuracy: 0.9045 - val_loss: 0.8039 - val_accuracy: 0.6364\n",
      "Epoch 74/100\n",
      "178/178 [==============================] - 0s 154us/step - loss: 0.2723 - accuracy: 0.8933 - val_loss: 0.7931 - val_accuracy: 0.6623\n",
      "Epoch 75/100\n",
      "178/178 [==============================] - 0s 157us/step - loss: 0.2679 - accuracy: 0.8989 - val_loss: 0.8041 - val_accuracy: 0.6494\n",
      "Epoch 76/100\n",
      "178/178 [==============================] - 0s 165us/step - loss: 0.2651 - accuracy: 0.9213 - val_loss: 0.8207 - val_accuracy: 0.6234\n",
      "Epoch 77/100\n",
      "178/178 [==============================] - 0s 163us/step - loss: 0.2674 - accuracy: 0.9045 - val_loss: 0.8023 - val_accuracy: 0.6623\n",
      "Epoch 78/100\n",
      "178/178 [==============================] - 0s 155us/step - loss: 0.2675 - accuracy: 0.9045 - val_loss: 0.7960 - val_accuracy: 0.6364\n",
      "Epoch 79/100\n",
      "178/178 [==============================] - 0s 167us/step - loss: 0.2636 - accuracy: 0.9157 - val_loss: 0.8001 - val_accuracy: 0.6623\n",
      "Epoch 80/100\n",
      "178/178 [==============================] - 0s 159us/step - loss: 0.2643 - accuracy: 0.8933 - val_loss: 0.8112 - val_accuracy: 0.6494\n",
      "Epoch 81/100\n",
      "178/178 [==============================] - 0s 152us/step - loss: 0.2586 - accuracy: 0.8989 - val_loss: 0.8094 - val_accuracy: 0.6494\n",
      "Epoch 82/100\n",
      "178/178 [==============================] - 0s 157us/step - loss: 0.2571 - accuracy: 0.9045 - val_loss: 0.8246 - val_accuracy: 0.6364\n",
      "Epoch 83/100\n",
      "178/178 [==============================] - 0s 158us/step - loss: 0.2572 - accuracy: 0.9101 - val_loss: 0.8235 - val_accuracy: 0.6494\n",
      "Epoch 84/100\n",
      "178/178 [==============================] - 0s 161us/step - loss: 0.2540 - accuracy: 0.9157 - val_loss: 0.8193 - val_accuracy: 0.6494\n",
      "Epoch 85/100\n",
      "178/178 [==============================] - 0s 155us/step - loss: 0.2502 - accuracy: 0.9101 - val_loss: 0.8143 - val_accuracy: 0.6494\n",
      "Epoch 86/100\n",
      "178/178 [==============================] - 0s 153us/step - loss: 0.2533 - accuracy: 0.9157 - val_loss: 0.8284 - val_accuracy: 0.6494\n",
      "Epoch 87/100\n",
      "178/178 [==============================] - 0s 160us/step - loss: 0.2523 - accuracy: 0.9213 - val_loss: 0.8181 - val_accuracy: 0.6364\n",
      "Epoch 88/100\n",
      "178/178 [==============================] - 0s 159us/step - loss: 0.2521 - accuracy: 0.9213 - val_loss: 0.8220 - val_accuracy: 0.6364\n",
      "Epoch 89/100\n",
      "178/178 [==============================] - 0s 160us/step - loss: 0.2485 - accuracy: 0.9101 - val_loss: 0.8313 - val_accuracy: 0.6494\n",
      "Epoch 90/100\n",
      "178/178 [==============================] - 0s 157us/step - loss: 0.2447 - accuracy: 0.8989 - val_loss: 0.8263 - val_accuracy: 0.6364\n",
      "Epoch 91/100\n",
      "178/178 [==============================] - 0s 154us/step - loss: 0.2469 - accuracy: 0.9157 - val_loss: 0.8216 - val_accuracy: 0.6494\n",
      "Epoch 92/100\n",
      "178/178 [==============================] - 0s 157us/step - loss: 0.2457 - accuracy: 0.9213 - val_loss: 0.8385 - val_accuracy: 0.6623\n",
      "Epoch 93/100\n",
      "178/178 [==============================] - 0s 157us/step - loss: 0.2456 - accuracy: 0.8933 - val_loss: 0.8341 - val_accuracy: 0.6494\n",
      "Epoch 94/100\n",
      "178/178 [==============================] - 0s 162us/step - loss: 0.2421 - accuracy: 0.9101 - val_loss: 0.8378 - val_accuracy: 0.6364\n",
      "Epoch 95/100\n",
      "178/178 [==============================] - 0s 158us/step - loss: 0.2395 - accuracy: 0.9101 - val_loss: 0.8536 - val_accuracy: 0.6494\n",
      "Epoch 96/100\n",
      "178/178 [==============================] - 0s 154us/step - loss: 0.2403 - accuracy: 0.9101 - val_loss: 0.8438 - val_accuracy: 0.6623\n",
      "Epoch 97/100\n",
      "178/178 [==============================] - 0s 157us/step - loss: 0.2462 - accuracy: 0.9101 - val_loss: 0.8560 - val_accuracy: 0.6494\n",
      "Epoch 98/100\n",
      "178/178 [==============================] - 0s 160us/step - loss: 0.2431 - accuracy: 0.9213 - val_loss: 0.8491 - val_accuracy: 0.6364\n",
      "Epoch 99/100\n",
      "178/178 [==============================] - 0s 162us/step - loss: 0.2451 - accuracy: 0.9157 - val_loss: 0.8467 - val_accuracy: 0.6364\n",
      "Epoch 100/100\n",
      "178/178 [==============================] - 0s 155us/step - loss: 0.2358 - accuracy: 0.9101 - val_loss: 0.8406 - val_accuracy: 0.6494\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0xb3cb462e8>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(X_train, y_train,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 0s 111us/step\n",
      "test accuracy: 64.94%\n"
     ]
    }
   ],
   "source": [
    "acc_test = model1.evaluate(X_test, y_test)[1]\n",
    "print('test accuracy: %.2f%%' % (acc_test*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### improve neural network\n",
    "model2 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(optimizer='sgd',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 178 samples, validate on 77 samples\n",
      "Epoch 1/1000\n",
      "178/178 [==============================] - 0s 749us/step - loss: 0.6947 - accuracy: 0.4719 - val_loss: 0.6342 - val_accuracy: 0.6234\n",
      "Epoch 2/1000\n",
      "178/178 [==============================] - 0s 164us/step - loss: 0.6284 - accuracy: 0.6292 - val_loss: 0.6301 - val_accuracy: 0.5974\n",
      "Epoch 3/1000\n",
      "178/178 [==============================] - 0s 182us/step - loss: 0.6086 - accuracy: 0.6685 - val_loss: 0.6292 - val_accuracy: 0.6104\n",
      "Epoch 4/1000\n",
      "178/178 [==============================] - 0s 181us/step - loss: 0.5953 - accuracy: 0.7022 - val_loss: 0.6297 - val_accuracy: 0.6104\n",
      "Epoch 5/1000\n",
      "178/178 [==============================] - 0s 195us/step - loss: 0.5833 - accuracy: 0.7079 - val_loss: 0.6284 - val_accuracy: 0.6104\n",
      "Epoch 6/1000\n",
      "178/178 [==============================] - 0s 208us/step - loss: 0.5755 - accuracy: 0.7191 - val_loss: 0.6278 - val_accuracy: 0.6364\n",
      "Epoch 7/1000\n",
      "178/178 [==============================] - 0s 190us/step - loss: 0.5658 - accuracy: 0.7135 - val_loss: 0.6312 - val_accuracy: 0.6494\n",
      "Epoch 8/1000\n",
      "178/178 [==============================] - 0s 189us/step - loss: 0.5577 - accuracy: 0.7191 - val_loss: 0.6310 - val_accuracy: 0.6494\n",
      "Epoch 9/1000\n",
      "178/178 [==============================] - 0s 173us/step - loss: 0.5505 - accuracy: 0.7303 - val_loss: 0.6341 - val_accuracy: 0.6494\n",
      "Epoch 10/1000\n",
      "178/178 [==============================] - 0s 187us/step - loss: 0.5432 - accuracy: 0.7303 - val_loss: 0.6332 - val_accuracy: 0.6494\n",
      "Epoch 11/1000\n",
      "178/178 [==============================] - 0s 179us/step - loss: 0.5364 - accuracy: 0.7416 - val_loss: 0.6318 - val_accuracy: 0.6364\n",
      "Epoch 12/1000\n",
      "178/178 [==============================] - 0s 199us/step - loss: 0.5303 - accuracy: 0.7584 - val_loss: 0.6364 - val_accuracy: 0.6494\n",
      "Epoch 13/1000\n",
      "178/178 [==============================] - 0s 202us/step - loss: 0.5263 - accuracy: 0.7303 - val_loss: 0.6423 - val_accuracy: 0.6364\n",
      "Epoch 14/1000\n",
      "178/178 [==============================] - 0s 199us/step - loss: 0.5204 - accuracy: 0.7416 - val_loss: 0.6301 - val_accuracy: 0.6234\n",
      "Epoch 15/1000\n",
      "178/178 [==============================] - 0s 176us/step - loss: 0.5164 - accuracy: 0.7640 - val_loss: 0.6352 - val_accuracy: 0.6234\n",
      "Epoch 16/1000\n",
      "178/178 [==============================] - 0s 182us/step - loss: 0.5060 - accuracy: 0.7753 - val_loss: 0.6381 - val_accuracy: 0.6234\n",
      "Epoch 17/1000\n",
      "178/178 [==============================] - 0s 179us/step - loss: 0.5030 - accuracy: 0.7921 - val_loss: 0.6387 - val_accuracy: 0.6234\n",
      "Epoch 18/1000\n",
      "178/178 [==============================] - 0s 188us/step - loss: 0.4959 - accuracy: 0.7865 - val_loss: 0.6382 - val_accuracy: 0.6364\n",
      "Epoch 19/1000\n",
      "178/178 [==============================] - 0s 189us/step - loss: 0.4922 - accuracy: 0.7978 - val_loss: 0.6467 - val_accuracy: 0.6104\n",
      "Epoch 20/1000\n",
      "178/178 [==============================] - 0s 182us/step - loss: 0.4906 - accuracy: 0.7809 - val_loss: 0.6397 - val_accuracy: 0.6234\n",
      "Epoch 21/1000\n",
      "178/178 [==============================] - 0s 175us/step - loss: 0.4837 - accuracy: 0.7978 - val_loss: 0.6464 - val_accuracy: 0.6364\n",
      "Epoch 22/1000\n",
      "178/178 [==============================] - 0s 181us/step - loss: 0.4881 - accuracy: 0.7921 - val_loss: 0.6410 - val_accuracy: 0.6364\n",
      "Epoch 23/1000\n",
      "178/178 [==============================] - 0s 175us/step - loss: 0.4761 - accuracy: 0.7809 - val_loss: 0.6541 - val_accuracy: 0.6234\n",
      "Epoch 24/1000\n",
      "178/178 [==============================] - 0s 174us/step - loss: 0.4729 - accuracy: 0.7978 - val_loss: 0.6532 - val_accuracy: 0.6364\n",
      "Epoch 25/1000\n",
      "178/178 [==============================] - 0s 176us/step - loss: 0.4678 - accuracy: 0.7978 - val_loss: 0.6534 - val_accuracy: 0.6364\n",
      "Epoch 26/1000\n",
      "178/178 [==============================] - 0s 179us/step - loss: 0.4637 - accuracy: 0.7978 - val_loss: 0.6521 - val_accuracy: 0.6234\n",
      "Epoch 27/1000\n",
      "178/178 [==============================] - 0s 189us/step - loss: 0.4602 - accuracy: 0.8034 - val_loss: 0.6529 - val_accuracy: 0.6234\n",
      "Epoch 28/1000\n",
      "178/178 [==============================] - 0s 183us/step - loss: 0.4616 - accuracy: 0.7978 - val_loss: 0.6664 - val_accuracy: 0.6234\n",
      "Epoch 29/1000\n",
      "178/178 [==============================] - 0s 206us/step - loss: 0.4558 - accuracy: 0.7978 - val_loss: 0.6623 - val_accuracy: 0.6364\n",
      "Epoch 30/1000\n",
      "178/178 [==============================] - 0s 197us/step - loss: 0.4513 - accuracy: 0.8034 - val_loss: 0.6586 - val_accuracy: 0.6364\n",
      "Epoch 31/1000\n",
      "178/178 [==============================] - 0s 200us/step - loss: 0.4458 - accuracy: 0.8146 - val_loss: 0.6643 - val_accuracy: 0.6234\n",
      "Epoch 32/1000\n",
      "178/178 [==============================] - 0s 180us/step - loss: 0.4435 - accuracy: 0.8090 - val_loss: 0.6688 - val_accuracy: 0.6364\n",
      "Epoch 33/1000\n",
      "178/178 [==============================] - 0s 157us/step - loss: 0.4442 - accuracy: 0.8034 - val_loss: 0.6581 - val_accuracy: 0.6494\n",
      "Epoch 34/1000\n",
      "178/178 [==============================] - 0s 181us/step - loss: 0.4446 - accuracy: 0.7978 - val_loss: 0.6652 - val_accuracy: 0.6364\n",
      "Epoch 35/1000\n",
      "178/178 [==============================] - 0s 182us/step - loss: 0.4379 - accuracy: 0.8202 - val_loss: 0.6701 - val_accuracy: 0.6364\n",
      "Epoch 36/1000\n",
      "178/178 [==============================] - 0s 187us/step - loss: 0.4338 - accuracy: 0.8146 - val_loss: 0.6653 - val_accuracy: 0.6494\n",
      "Epoch 37/1000\n",
      "178/178 [==============================] - 0s 191us/step - loss: 0.4353 - accuracy: 0.8146 - val_loss: 0.6654 - val_accuracy: 0.6494\n",
      "Epoch 38/1000\n",
      "178/178 [==============================] - 0s 176us/step - loss: 0.4321 - accuracy: 0.8034 - val_loss: 0.6716 - val_accuracy: 0.6364\n",
      "Epoch 39/1000\n",
      "178/178 [==============================] - 0s 184us/step - loss: 0.4239 - accuracy: 0.8202 - val_loss: 0.6711 - val_accuracy: 0.6364\n",
      "Epoch 40/1000\n",
      "178/178 [==============================] - 0s 216us/step - loss: 0.4227 - accuracy: 0.8202 - val_loss: 0.6688 - val_accuracy: 0.6494\n",
      "Epoch 41/1000\n",
      "178/178 [==============================] - 0s 190us/step - loss: 0.4266 - accuracy: 0.8315 - val_loss: 0.6690 - val_accuracy: 0.6494\n",
      "Epoch 42/1000\n",
      "178/178 [==============================] - 0s 179us/step - loss: 0.4271 - accuracy: 0.8146 - val_loss: 0.6789 - val_accuracy: 0.6234\n",
      "Epoch 43/1000\n",
      "178/178 [==============================] - 0s 180us/step - loss: 0.4158 - accuracy: 0.8483 - val_loss: 0.6729 - val_accuracy: 0.6494\n",
      "Epoch 44/1000\n",
      "178/178 [==============================] - 0s 165us/step - loss: 0.4100 - accuracy: 0.8315 - val_loss: 0.6780 - val_accuracy: 0.6364\n",
      "Epoch 45/1000\n",
      "178/178 [==============================] - 0s 188us/step - loss: 0.4076 - accuracy: 0.8371 - val_loss: 0.6811 - val_accuracy: 0.6234\n",
      "Epoch 46/1000\n",
      "178/178 [==============================] - 0s 189us/step - loss: 0.4050 - accuracy: 0.8315 - val_loss: 0.6858 - val_accuracy: 0.6234\n",
      "Epoch 47/1000\n",
      "178/178 [==============================] - 0s 186us/step - loss: 0.4042 - accuracy: 0.8483 - val_loss: 0.6918 - val_accuracy: 0.6234\n",
      "Epoch 48/1000\n",
      "178/178 [==============================] - 0s 176us/step - loss: 0.4042 - accuracy: 0.8371 - val_loss: 0.6981 - val_accuracy: 0.6364\n",
      "Epoch 49/1000\n",
      "178/178 [==============================] - 0s 186us/step - loss: 0.4033 - accuracy: 0.8483 - val_loss: 0.6963 - val_accuracy: 0.6234\n",
      "Epoch 50/1000\n",
      "178/178 [==============================] - 0s 180us/step - loss: 0.4022 - accuracy: 0.8539 - val_loss: 0.6906 - val_accuracy: 0.6234\n",
      "Epoch 51/1000\n",
      "178/178 [==============================] - 0s 208us/step - loss: 0.3936 - accuracy: 0.8483 - val_loss: 0.6918 - val_accuracy: 0.6234\n",
      "Epoch 52/1000\n",
      "178/178 [==============================] - 0s 192us/step - loss: 0.3914 - accuracy: 0.8483 - val_loss: 0.6911 - val_accuracy: 0.6234\n",
      "Epoch 53/1000\n",
      "178/178 [==============================] - 0s 189us/step - loss: 0.3908 - accuracy: 0.8483 - val_loss: 0.6863 - val_accuracy: 0.6494\n",
      "Epoch 54/1000\n",
      "178/178 [==============================] - 0s 189us/step - loss: 0.3885 - accuracy: 0.8427 - val_loss: 0.7014 - val_accuracy: 0.6234\n",
      "Epoch 55/1000\n",
      "178/178 [==============================] - 0s 183us/step - loss: 0.3845 - accuracy: 0.8539 - val_loss: 0.6943 - val_accuracy: 0.6234\n",
      "Epoch 56/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 214us/step - loss: 0.3830 - accuracy: 0.8483 - val_loss: 0.6973 - val_accuracy: 0.6234\n",
      "Epoch 57/1000\n",
      "178/178 [==============================] - 0s 184us/step - loss: 0.3798 - accuracy: 0.8483 - val_loss: 0.7022 - val_accuracy: 0.6234\n",
      "Epoch 58/1000\n",
      "178/178 [==============================] - 0s 192us/step - loss: 0.3810 - accuracy: 0.8483 - val_loss: 0.7000 - val_accuracy: 0.6234\n",
      "Epoch 59/1000\n",
      "178/178 [==============================] - 0s 171us/step - loss: 0.3762 - accuracy: 0.8483 - val_loss: 0.7011 - val_accuracy: 0.6234\n",
      "Epoch 60/1000\n",
      "178/178 [==============================] - 0s 182us/step - loss: 0.3731 - accuracy: 0.8539 - val_loss: 0.7074 - val_accuracy: 0.6234\n",
      "Epoch 61/1000\n",
      "178/178 [==============================] - 0s 205us/step - loss: 0.3708 - accuracy: 0.8539 - val_loss: 0.7035 - val_accuracy: 0.6234\n",
      "Epoch 62/1000\n",
      "178/178 [==============================] - 0s 164us/step - loss: 0.3701 - accuracy: 0.8539 - val_loss: 0.7130 - val_accuracy: 0.6234\n",
      "Epoch 63/1000\n",
      "178/178 [==============================] - 0s 168us/step - loss: 0.3697 - accuracy: 0.8539 - val_loss: 0.7184 - val_accuracy: 0.6234\n",
      "Epoch 64/1000\n",
      "178/178 [==============================] - 0s 162us/step - loss: 0.3696 - accuracy: 0.8539 - val_loss: 0.7151 - val_accuracy: 0.6234\n",
      "Epoch 65/1000\n",
      "178/178 [==============================] - 0s 206us/step - loss: 0.3624 - accuracy: 0.8596 - val_loss: 0.7097 - val_accuracy: 0.6234\n",
      "Epoch 66/1000\n",
      "178/178 [==============================] - 0s 176us/step - loss: 0.3657 - accuracy: 0.8596 - val_loss: 0.7190 - val_accuracy: 0.6234\n",
      "Epoch 67/1000\n",
      "178/178 [==============================] - 0s 159us/step - loss: 0.3589 - accuracy: 0.8539 - val_loss: 0.7073 - val_accuracy: 0.6234\n",
      "Epoch 68/1000\n",
      "178/178 [==============================] - 0s 176us/step - loss: 0.3609 - accuracy: 0.8539 - val_loss: 0.7142 - val_accuracy: 0.6234\n",
      "Epoch 69/1000\n",
      "178/178 [==============================] - 0s 179us/step - loss: 0.3657 - accuracy: 0.8539 - val_loss: 0.7077 - val_accuracy: 0.6364\n",
      "Epoch 70/1000\n",
      "178/178 [==============================] - 0s 147us/step - loss: 0.3544 - accuracy: 0.8652 - val_loss: 0.7179 - val_accuracy: 0.6234\n",
      "Epoch 71/1000\n",
      "178/178 [==============================] - 0s 170us/step - loss: 0.3515 - accuracy: 0.8539 - val_loss: 0.7167 - val_accuracy: 0.6234\n",
      "Epoch 72/1000\n",
      "178/178 [==============================] - 0s 177us/step - loss: 0.3484 - accuracy: 0.8539 - val_loss: 0.7185 - val_accuracy: 0.6234\n",
      "Epoch 73/1000\n",
      "178/178 [==============================] - 0s 197us/step - loss: 0.3476 - accuracy: 0.8596 - val_loss: 0.7238 - val_accuracy: 0.6234\n",
      "Epoch 74/1000\n",
      "178/178 [==============================] - 0s 172us/step - loss: 0.3436 - accuracy: 0.8652 - val_loss: 0.7202 - val_accuracy: 0.6234\n",
      "Epoch 75/1000\n",
      "178/178 [==============================] - 0s 173us/step - loss: 0.3481 - accuracy: 0.8596 - val_loss: 0.7138 - val_accuracy: 0.6494\n",
      "Epoch 76/1000\n",
      "178/178 [==============================] - 0s 177us/step - loss: 0.3433 - accuracy: 0.8764 - val_loss: 0.7310 - val_accuracy: 0.6364\n",
      "Epoch 77/1000\n",
      "178/178 [==============================] - 0s 163us/step - loss: 0.3391 - accuracy: 0.8596 - val_loss: 0.7282 - val_accuracy: 0.6234\n",
      "Epoch 78/1000\n",
      "178/178 [==============================] - 0s 171us/step - loss: 0.3372 - accuracy: 0.8652 - val_loss: 0.7288 - val_accuracy: 0.6234\n",
      "Epoch 79/1000\n",
      "178/178 [==============================] - 0s 190us/step - loss: 0.3402 - accuracy: 0.8652 - val_loss: 0.7233 - val_accuracy: 0.6364\n",
      "Epoch 80/1000\n",
      "178/178 [==============================] - 0s 197us/step - loss: 0.3356 - accuracy: 0.8708 - val_loss: 0.7297 - val_accuracy: 0.6234\n",
      "Epoch 81/1000\n",
      "178/178 [==============================] - 0s 171us/step - loss: 0.3353 - accuracy: 0.8652 - val_loss: 0.7289 - val_accuracy: 0.6234\n",
      "Epoch 82/1000\n",
      "178/178 [==============================] - 0s 166us/step - loss: 0.3314 - accuracy: 0.8652 - val_loss: 0.7317 - val_accuracy: 0.6234\n",
      "Epoch 83/1000\n",
      "178/178 [==============================] - 0s 189us/step - loss: 0.3271 - accuracy: 0.8652 - val_loss: 0.7414 - val_accuracy: 0.6364\n",
      "Epoch 84/1000\n",
      "178/178 [==============================] - 0s 165us/step - loss: 0.3318 - accuracy: 0.8708 - val_loss: 0.7330 - val_accuracy: 0.6364\n",
      "Epoch 85/1000\n",
      "178/178 [==============================] - 0s 176us/step - loss: 0.3234 - accuracy: 0.8652 - val_loss: 0.7541 - val_accuracy: 0.6364\n",
      "Epoch 86/1000\n",
      "178/178 [==============================] - 0s 165us/step - loss: 0.3248 - accuracy: 0.8708 - val_loss: 0.7347 - val_accuracy: 0.6364\n",
      "Epoch 87/1000\n",
      "178/178 [==============================] - 0s 197us/step - loss: 0.3187 - accuracy: 0.8708 - val_loss: 0.7388 - val_accuracy: 0.6104\n",
      "Epoch 88/1000\n",
      "178/178 [==============================] - 0s 180us/step - loss: 0.3154 - accuracy: 0.8764 - val_loss: 0.7416 - val_accuracy: 0.6104\n",
      "Epoch 89/1000\n",
      "178/178 [==============================] - 0s 153us/step - loss: 0.3140 - accuracy: 0.8708 - val_loss: 0.7408 - val_accuracy: 0.6234\n",
      "Epoch 90/1000\n",
      "178/178 [==============================] - 0s 177us/step - loss: 0.3142 - accuracy: 0.8708 - val_loss: 0.7474 - val_accuracy: 0.6234\n",
      "Epoch 91/1000\n",
      "178/178 [==============================] - 0s 206us/step - loss: 0.3129 - accuracy: 0.8708 - val_loss: 0.7470 - val_accuracy: 0.6234\n",
      "Epoch 92/1000\n",
      "178/178 [==============================] - 0s 173us/step - loss: 0.3090 - accuracy: 0.8708 - val_loss: 0.7586 - val_accuracy: 0.6234\n",
      "Epoch 93/1000\n",
      "178/178 [==============================] - 0s 180us/step - loss: 0.3065 - accuracy: 0.8764 - val_loss: 0.7538 - val_accuracy: 0.6234\n",
      "Epoch 94/1000\n",
      "178/178 [==============================] - 0s 162us/step - loss: 0.3061 - accuracy: 0.8764 - val_loss: 0.7621 - val_accuracy: 0.6104\n",
      "Epoch 95/1000\n",
      "178/178 [==============================] - 0s 164us/step - loss: 0.3076 - accuracy: 0.8764 - val_loss: 0.7542 - val_accuracy: 0.6104\n",
      "Epoch 96/1000\n",
      "178/178 [==============================] - 0s 161us/step - loss: 0.3085 - accuracy: 0.8708 - val_loss: 0.7520 - val_accuracy: 0.6234\n",
      "Epoch 97/1000\n",
      "178/178 [==============================] - 0s 186us/step - loss: 0.3118 - accuracy: 0.8764 - val_loss: 0.7554 - val_accuracy: 0.6234\n",
      "Epoch 98/1000\n",
      "178/178 [==============================] - 0s 181us/step - loss: 0.3031 - accuracy: 0.8764 - val_loss: 0.7552 - val_accuracy: 0.6104\n",
      "Epoch 99/1000\n",
      "178/178 [==============================] - 0s 176us/step - loss: 0.3044 - accuracy: 0.8764 - val_loss: 0.7544 - val_accuracy: 0.6104\n",
      "Epoch 100/1000\n",
      "178/178 [==============================] - 0s 164us/step - loss: 0.3010 - accuracy: 0.8764 - val_loss: 0.7703 - val_accuracy: 0.6234\n",
      "Epoch 101/1000\n",
      "178/178 [==============================] - 0s 181us/step - loss: 0.2925 - accuracy: 0.8820 - val_loss: 0.7644 - val_accuracy: 0.6104\n",
      "Epoch 102/1000\n",
      "178/178 [==============================] - 0s 158us/step - loss: 0.2899 - accuracy: 0.8820 - val_loss: 0.7669 - val_accuracy: 0.6364\n",
      "Epoch 103/1000\n",
      "178/178 [==============================] - 0s 171us/step - loss: 0.2902 - accuracy: 0.8764 - val_loss: 0.7640 - val_accuracy: 0.6104\n",
      "Epoch 104/1000\n",
      "178/178 [==============================] - 0s 202us/step - loss: 0.2920 - accuracy: 0.8933 - val_loss: 0.7694 - val_accuracy: 0.6234\n",
      "Epoch 105/1000\n",
      "178/178 [==============================] - 0s 178us/step - loss: 0.2855 - accuracy: 0.8933 - val_loss: 0.7752 - val_accuracy: 0.6364\n",
      "Epoch 106/1000\n",
      "178/178 [==============================] - 0s 166us/step - loss: 0.2843 - accuracy: 0.8933 - val_loss: 0.7713 - val_accuracy: 0.6104\n",
      "Epoch 107/1000\n",
      "178/178 [==============================] - 0s 182us/step - loss: 0.2833 - accuracy: 0.8876 - val_loss: 0.7802 - val_accuracy: 0.6364\n",
      "Epoch 108/1000\n",
      "178/178 [==============================] - 0s 170us/step - loss: 0.2821 - accuracy: 0.8820 - val_loss: 0.7782 - val_accuracy: 0.6364\n",
      "Epoch 109/1000\n",
      "178/178 [==============================] - 0s 174us/step - loss: 0.2782 - accuracy: 0.8933 - val_loss: 0.7851 - val_accuracy: 0.6234\n",
      "Epoch 110/1000\n",
      "178/178 [==============================] - 0s 182us/step - loss: 0.2836 - accuracy: 0.8876 - val_loss: 0.7773 - val_accuracy: 0.6364\n",
      "Epoch 111/1000\n",
      "178/178 [==============================] - 0s 180us/step - loss: 0.2764 - accuracy: 0.8933 - val_loss: 0.7900 - val_accuracy: 0.6494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/1000\n",
      "178/178 [==============================] - 0s 180us/step - loss: 0.2838 - accuracy: 0.8989 - val_loss: 0.7873 - val_accuracy: 0.6494\n",
      "Epoch 113/1000\n",
      "178/178 [==============================] - 0s 161us/step - loss: 0.2735 - accuracy: 0.9157 - val_loss: 0.7814 - val_accuracy: 0.6364\n",
      "Epoch 114/1000\n",
      "178/178 [==============================] - 0s 198us/step - loss: 0.2727 - accuracy: 0.8989 - val_loss: 0.7848 - val_accuracy: 0.6364\n",
      "Epoch 115/1000\n",
      "178/178 [==============================] - 0s 162us/step - loss: 0.2786 - accuracy: 0.8989 - val_loss: 0.8003 - val_accuracy: 0.6364\n",
      "Epoch 116/1000\n",
      "178/178 [==============================] - 0s 192us/step - loss: 0.2754 - accuracy: 0.9101 - val_loss: 0.7994 - val_accuracy: 0.6494\n",
      "Epoch 117/1000\n",
      "178/178 [==============================] - 0s 174us/step - loss: 0.2683 - accuracy: 0.9157 - val_loss: 0.8020 - val_accuracy: 0.6494\n",
      "Epoch 118/1000\n",
      "178/178 [==============================] - 0s 175us/step - loss: 0.2685 - accuracy: 0.8989 - val_loss: 0.7979 - val_accuracy: 0.6234\n",
      "Epoch 119/1000\n",
      "178/178 [==============================] - 0s 172us/step - loss: 0.2663 - accuracy: 0.9045 - val_loss: 0.8072 - val_accuracy: 0.6494\n",
      "Epoch 120/1000\n",
      "178/178 [==============================] - 0s 164us/step - loss: 0.2623 - accuracy: 0.9101 - val_loss: 0.7927 - val_accuracy: 0.6623\n",
      "Epoch 121/1000\n",
      "178/178 [==============================] - 0s 183us/step - loss: 0.2799 - accuracy: 0.9101 - val_loss: 0.8089 - val_accuracy: 0.6364\n",
      "Epoch 122/1000\n",
      "178/178 [==============================] - 0s 196us/step - loss: 0.2612 - accuracy: 0.9157 - val_loss: 0.7944 - val_accuracy: 0.6623\n",
      "Epoch 123/1000\n",
      "178/178 [==============================] - 0s 179us/step - loss: 0.2712 - accuracy: 0.9157 - val_loss: 0.7985 - val_accuracy: 0.6364\n",
      "Epoch 124/1000\n",
      "178/178 [==============================] - 0s 162us/step - loss: 0.2637 - accuracy: 0.9213 - val_loss: 0.8003 - val_accuracy: 0.6623\n",
      "Epoch 125/1000\n",
      "178/178 [==============================] - 0s 161us/step - loss: 0.2532 - accuracy: 0.9157 - val_loss: 0.8137 - val_accuracy: 0.6364\n",
      "Epoch 126/1000\n",
      "178/178 [==============================] - 0s 194us/step - loss: 0.2564 - accuracy: 0.9157 - val_loss: 0.8065 - val_accuracy: 0.6234\n",
      "Epoch 127/1000\n",
      "178/178 [==============================] - 0s 152us/step - loss: 0.2789 - accuracy: 0.9157 - val_loss: 0.8070 - val_accuracy: 0.6623\n",
      "Epoch 128/1000\n",
      "178/178 [==============================] - 0s 186us/step - loss: 0.2529 - accuracy: 0.9045 - val_loss: 0.8151 - val_accuracy: 0.6364\n",
      "Epoch 129/1000\n",
      "178/178 [==============================] - 0s 194us/step - loss: 0.2545 - accuracy: 0.9157 - val_loss: 0.8267 - val_accuracy: 0.6234\n",
      "Epoch 130/1000\n",
      "178/178 [==============================] - 0s 177us/step - loss: 0.2509 - accuracy: 0.9213 - val_loss: 0.8107 - val_accuracy: 0.6623\n",
      "Epoch 131/1000\n",
      "178/178 [==============================] - 0s 149us/step - loss: 0.2460 - accuracy: 0.9157 - val_loss: 0.8215 - val_accuracy: 0.6364\n",
      "Epoch 132/1000\n",
      "178/178 [==============================] - 0s 172us/step - loss: 0.2452 - accuracy: 0.9157 - val_loss: 0.8139 - val_accuracy: 0.6623\n",
      "Epoch 133/1000\n",
      "178/178 [==============================] - 0s 179us/step - loss: 0.2460 - accuracy: 0.9101 - val_loss: 0.8525 - val_accuracy: 0.6234\n",
      "Epoch 134/1000\n",
      "178/178 [==============================] - 0s 170us/step - loss: 0.2612 - accuracy: 0.9157 - val_loss: 0.8222 - val_accuracy: 0.6364\n",
      "Epoch 135/1000\n",
      "178/178 [==============================] - 0s 186us/step - loss: 0.2469 - accuracy: 0.9270 - val_loss: 0.8363 - val_accuracy: 0.6364\n",
      "Epoch 136/1000\n",
      "178/178 [==============================] - 0s 184us/step - loss: 0.2725 - accuracy: 0.8989 - val_loss: 0.8273 - val_accuracy: 0.6494\n",
      "Epoch 137/1000\n",
      "178/178 [==============================] - 0s 179us/step - loss: 0.2402 - accuracy: 0.9101 - val_loss: 0.8368 - val_accuracy: 0.6364\n",
      "Epoch 138/1000\n",
      "178/178 [==============================] - 0s 158us/step - loss: 0.2429 - accuracy: 0.9270 - val_loss: 0.8454 - val_accuracy: 0.6234\n",
      "Epoch 139/1000\n",
      "178/178 [==============================] - 0s 173us/step - loss: 0.2404 - accuracy: 0.9213 - val_loss: 0.8472 - val_accuracy: 0.6234\n",
      "Epoch 140/1000\n",
      "178/178 [==============================] - 0s 178us/step - loss: 0.2489 - accuracy: 0.9270 - val_loss: 0.8328 - val_accuracy: 0.6494\n",
      "Epoch 141/1000\n",
      "178/178 [==============================] - 0s 196us/step - loss: 0.2397 - accuracy: 0.9270 - val_loss: 0.8366 - val_accuracy: 0.6494\n",
      "Epoch 142/1000\n",
      "178/178 [==============================] - 0s 183us/step - loss: 0.2362 - accuracy: 0.9270 - val_loss: 0.8339 - val_accuracy: 0.6364\n",
      "Epoch 143/1000\n",
      "178/178 [==============================] - 0s 164us/step - loss: 0.2475 - accuracy: 0.9213 - val_loss: 0.8365 - val_accuracy: 0.6234\n",
      "Epoch 144/1000\n",
      "178/178 [==============================] - 0s 169us/step - loss: 0.2356 - accuracy: 0.9213 - val_loss: 0.8452 - val_accuracy: 0.6364\n",
      "Epoch 145/1000\n",
      "178/178 [==============================] - 0s 175us/step - loss: 0.2296 - accuracy: 0.9270 - val_loss: 0.8470 - val_accuracy: 0.6364\n",
      "Epoch 146/1000\n",
      "178/178 [==============================] - 0s 188us/step - loss: 0.2337 - accuracy: 0.9213 - val_loss: 0.8489 - val_accuracy: 0.6364\n",
      "Epoch 147/1000\n",
      "178/178 [==============================] - 0s 164us/step - loss: 0.2273 - accuracy: 0.9157 - val_loss: 0.8520 - val_accuracy: 0.6364\n",
      "Epoch 148/1000\n",
      "178/178 [==============================] - 0s 188us/step - loss: 0.2270 - accuracy: 0.9213 - val_loss: 0.8426 - val_accuracy: 0.6494\n",
      "Epoch 149/1000\n",
      "178/178 [==============================] - 0s 184us/step - loss: 0.2305 - accuracy: 0.9157 - val_loss: 0.8474 - val_accuracy: 0.6494\n",
      "Epoch 150/1000\n",
      "178/178 [==============================] - 0s 173us/step - loss: 0.2229 - accuracy: 0.9213 - val_loss: 0.8633 - val_accuracy: 0.6234\n",
      "Epoch 151/1000\n",
      "178/178 [==============================] - 0s 171us/step - loss: 0.2256 - accuracy: 0.9213 - val_loss: 0.8533 - val_accuracy: 0.6494\n",
      "Epoch 152/1000\n",
      "178/178 [==============================] - 0s 162us/step - loss: 0.2273 - accuracy: 0.9213 - val_loss: 0.8561 - val_accuracy: 0.6364\n",
      "Epoch 153/1000\n",
      "178/178 [==============================] - 0s 174us/step - loss: 0.2323 - accuracy: 0.9157 - val_loss: 0.8596 - val_accuracy: 0.6494\n",
      "Epoch 154/1000\n",
      "178/178 [==============================] - 0s 160us/step - loss: 0.2279 - accuracy: 0.9270 - val_loss: 0.8591 - val_accuracy: 0.6494\n",
      "Epoch 155/1000\n",
      "178/178 [==============================] - 0s 198us/step - loss: 0.2168 - accuracy: 0.9270 - val_loss: 0.8867 - val_accuracy: 0.6234\n",
      "Epoch 156/1000\n",
      "178/178 [==============================] - 0s 169us/step - loss: 0.2207 - accuracy: 0.9326 - val_loss: 0.8704 - val_accuracy: 0.6364\n",
      "Epoch 157/1000\n",
      "178/178 [==============================] - 0s 181us/step - loss: 0.2369 - accuracy: 0.9213 - val_loss: 0.8651 - val_accuracy: 0.6494\n",
      "Epoch 158/1000\n",
      "178/178 [==============================] - 0s 173us/step - loss: 0.2157 - accuracy: 0.9213 - val_loss: 0.8696 - val_accuracy: 0.6494\n",
      "Epoch 159/1000\n",
      "178/178 [==============================] - 0s 189us/step - loss: 0.2239 - accuracy: 0.9213 - val_loss: 0.8824 - val_accuracy: 0.6234\n",
      "Epoch 160/1000\n",
      "178/178 [==============================] - 0s 189us/step - loss: 0.2136 - accuracy: 0.9326 - val_loss: 0.8708 - val_accuracy: 0.6494\n",
      "Epoch 161/1000\n",
      "178/178 [==============================] - 0s 180us/step - loss: 0.2148 - accuracy: 0.9213 - val_loss: 0.8777 - val_accuracy: 0.6494\n",
      "Epoch 162/1000\n",
      "178/178 [==============================] - 0s 205us/step - loss: 0.2199 - accuracy: 0.9270 - val_loss: 0.9000 - val_accuracy: 0.6234\n",
      "Epoch 163/1000\n",
      "178/178 [==============================] - 0s 201us/step - loss: 0.2134 - accuracy: 0.9326 - val_loss: 0.8884 - val_accuracy: 0.6364\n",
      "Epoch 164/1000\n",
      "178/178 [==============================] - 0s 257us/step - loss: 0.2342 - accuracy: 0.9213 - val_loss: 0.8857 - val_accuracy: 0.6494\n",
      "Epoch 165/1000\n",
      "178/178 [==============================] - 0s 269us/step - loss: 0.2151 - accuracy: 0.9157 - val_loss: 0.9102 - val_accuracy: 0.6234\n",
      "Epoch 166/1000\n",
      "178/178 [==============================] - 0s 192us/step - loss: 0.2239 - accuracy: 0.9326 - val_loss: 0.8999 - val_accuracy: 0.6364\n",
      "Epoch 167/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 169us/step - loss: 0.2107 - accuracy: 0.9213 - val_loss: 0.8952 - val_accuracy: 0.6364\n",
      "Epoch 168/1000\n",
      "178/178 [==============================] - 0s 178us/step - loss: 0.2066 - accuracy: 0.9270 - val_loss: 0.8962 - val_accuracy: 0.6364\n",
      "Epoch 169/1000\n",
      "178/178 [==============================] - 0s 174us/step - loss: 0.2183 - accuracy: 0.9101 - val_loss: 0.8892 - val_accuracy: 0.6364\n",
      "Epoch 170/1000\n",
      "178/178 [==============================] - 0s 175us/step - loss: 0.2083 - accuracy: 0.9270 - val_loss: 0.9052 - val_accuracy: 0.6364\n",
      "Epoch 171/1000\n",
      "178/178 [==============================] - 0s 206us/step - loss: 0.2047 - accuracy: 0.9326 - val_loss: 0.9039 - val_accuracy: 0.6234\n",
      "Epoch 172/1000\n",
      "178/178 [==============================] - 0s 178us/step - loss: 0.2199 - accuracy: 0.9270 - val_loss: 0.8969 - val_accuracy: 0.6494\n",
      "Epoch 173/1000\n",
      "178/178 [==============================] - 0s 166us/step - loss: 0.2021 - accuracy: 0.9326 - val_loss: 0.9000 - val_accuracy: 0.6494\n",
      "Epoch 174/1000\n",
      "178/178 [==============================] - 0s 192us/step - loss: 0.1989 - accuracy: 0.9270 - val_loss: 0.9025 - val_accuracy: 0.6494\n",
      "Epoch 175/1000\n",
      "178/178 [==============================] - 0s 196us/step - loss: 0.2022 - accuracy: 0.9326 - val_loss: 0.8958 - val_accuracy: 0.6494\n",
      "Epoch 176/1000\n",
      "178/178 [==============================] - 0s 153us/step - loss: 0.2065 - accuracy: 0.9213 - val_loss: 0.9274 - val_accuracy: 0.6234\n",
      "Epoch 177/1000\n",
      "178/178 [==============================] - 0s 196us/step - loss: 0.2052 - accuracy: 0.9326 - val_loss: 0.9248 - val_accuracy: 0.6234\n",
      "Epoch 178/1000\n",
      "178/178 [==============================] - 0s 160us/step - loss: 0.1986 - accuracy: 0.9326 - val_loss: 0.9033 - val_accuracy: 0.6494\n",
      "Epoch 179/1000\n",
      "178/178 [==============================] - 0s 180us/step - loss: 0.1981 - accuracy: 0.9382 - val_loss: 0.9039 - val_accuracy: 0.6494\n",
      "Epoch 180/1000\n",
      "178/178 [==============================] - 0s 161us/step - loss: 0.1944 - accuracy: 0.9270 - val_loss: 0.9073 - val_accuracy: 0.6494\n",
      "Epoch 181/1000\n",
      "178/178 [==============================] - 0s 175us/step - loss: 0.1958 - accuracy: 0.9438 - val_loss: 0.9091 - val_accuracy: 0.6494\n",
      "Epoch 182/1000\n",
      "178/178 [==============================] - 0s 179us/step - loss: 0.1956 - accuracy: 0.9494 - val_loss: 0.9332 - val_accuracy: 0.6234\n",
      "Epoch 183/1000\n",
      "178/178 [==============================] - 0s 192us/step - loss: 0.2001 - accuracy: 0.9438 - val_loss: 0.9258 - val_accuracy: 0.6234\n",
      "Epoch 184/1000\n",
      "178/178 [==============================] - 0s 180us/step - loss: 0.1976 - accuracy: 0.9326 - val_loss: 0.9313 - val_accuracy: 0.6234\n",
      "Epoch 185/1000\n",
      "178/178 [==============================] - 0s 174us/step - loss: 0.1899 - accuracy: 0.9382 - val_loss: 0.9162 - val_accuracy: 0.6364\n",
      "Epoch 186/1000\n",
      "178/178 [==============================] - 0s 152us/step - loss: 0.1942 - accuracy: 0.9382 - val_loss: 0.9215 - val_accuracy: 0.6623\n",
      "Epoch 187/1000\n",
      "178/178 [==============================] - 0s 192us/step - loss: 0.1903 - accuracy: 0.9438 - val_loss: 0.9279 - val_accuracy: 0.6494\n",
      "Epoch 188/1000\n",
      "178/178 [==============================] - 0s 173us/step - loss: 0.1870 - accuracy: 0.9438 - val_loss: 0.9298 - val_accuracy: 0.6494\n",
      "Epoch 189/1000\n",
      "178/178 [==============================] - 0s 153us/step - loss: 0.1861 - accuracy: 0.9326 - val_loss: 0.9234 - val_accuracy: 0.6494\n",
      "Epoch 190/1000\n",
      "178/178 [==============================] - 0s 199us/step - loss: 0.1874 - accuracy: 0.9382 - val_loss: 0.9247 - val_accuracy: 0.6494\n",
      "Epoch 191/1000\n",
      "178/178 [==============================] - 0s 163us/step - loss: 0.1865 - accuracy: 0.9438 - val_loss: 0.9256 - val_accuracy: 0.6494\n",
      "Epoch 192/1000\n",
      "178/178 [==============================] - 0s 197us/step - loss: 0.1895 - accuracy: 0.9494 - val_loss: 0.9272 - val_accuracy: 0.6494\n",
      "Epoch 193/1000\n",
      "178/178 [==============================] - 0s 178us/step - loss: 0.1904 - accuracy: 0.9494 - val_loss: 0.9309 - val_accuracy: 0.6364\n",
      "Epoch 194/1000\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.1822 - accuracy: 0.95 - 0s 176us/step - loss: 0.1900 - accuracy: 0.9270 - val_loss: 0.9354 - val_accuracy: 0.6494\n",
      "Epoch 195/1000\n",
      "178/178 [==============================] - 0s 172us/step - loss: 0.1848 - accuracy: 0.9438 - val_loss: 0.9636 - val_accuracy: 0.6234\n",
      "Epoch 196/1000\n",
      "178/178 [==============================] - 0s 176us/step - loss: 0.1990 - accuracy: 0.9326 - val_loss: 0.9334 - val_accuracy: 0.6364\n",
      "Epoch 197/1000\n",
      "178/178 [==============================] - 0s 154us/step - loss: 0.1935 - accuracy: 0.9326 - val_loss: 0.9430 - val_accuracy: 0.6364\n",
      "Epoch 198/1000\n",
      "178/178 [==============================] - 0s 189us/step - loss: 0.1835 - accuracy: 0.9438 - val_loss: 0.9425 - val_accuracy: 0.6494\n",
      "Epoch 199/1000\n",
      "178/178 [==============================] - 0s 178us/step - loss: 0.1777 - accuracy: 0.9438 - val_loss: 0.9437 - val_accuracy: 0.6494\n",
      "Epoch 200/1000\n",
      "178/178 [==============================] - 0s 182us/step - loss: 0.1792 - accuracy: 0.9438 - val_loss: 0.9622 - val_accuracy: 0.6234\n",
      "Epoch 201/1000\n",
      "178/178 [==============================] - 0s 186us/step - loss: 0.1812 - accuracy: 0.9326 - val_loss: 0.9574 - val_accuracy: 0.6234\n",
      "Epoch 202/1000\n",
      "178/178 [==============================] - 0s 172us/step - loss: 0.1888 - accuracy: 0.9382 - val_loss: 0.9619 - val_accuracy: 0.6234\n",
      "Epoch 203/1000\n",
      "178/178 [==============================] - 0s 189us/step - loss: 0.1861 - accuracy: 0.9382 - val_loss: 0.9498 - val_accuracy: 0.6494\n",
      "Epoch 204/1000\n",
      "178/178 [==============================] - 0s 169us/step - loss: 0.1761 - accuracy: 0.9551 - val_loss: 0.9532 - val_accuracy: 0.6494\n",
      "Epoch 205/1000\n",
      "178/178 [==============================] - 0s 154us/step - loss: 0.1745 - accuracy: 0.9438 - val_loss: 0.9592 - val_accuracy: 0.6364\n",
      "Epoch 206/1000\n",
      "178/178 [==============================] - 0s 177us/step - loss: 0.1831 - accuracy: 0.9494 - val_loss: 0.9554 - val_accuracy: 0.6494\n",
      "Epoch 207/1000\n",
      "178/178 [==============================] - 0s 186us/step - loss: 0.1746 - accuracy: 0.9494 - val_loss: 0.9621 - val_accuracy: 0.6494\n",
      "Epoch 208/1000\n",
      "178/178 [==============================] - 0s 183us/step - loss: 0.1734 - accuracy: 0.9551 - val_loss: 0.9609 - val_accuracy: 0.6494\n",
      "Epoch 209/1000\n",
      "178/178 [==============================] - 0s 178us/step - loss: 0.1772 - accuracy: 0.9382 - val_loss: 0.9631 - val_accuracy: 0.6234\n",
      "Epoch 210/1000\n",
      "178/178 [==============================] - 0s 179us/step - loss: 0.1874 - accuracy: 0.9326 - val_loss: 0.9631 - val_accuracy: 0.6364\n",
      "Epoch 211/1000\n",
      "178/178 [==============================] - 0s 172us/step - loss: 0.1764 - accuracy: 0.9551 - val_loss: 0.9627 - val_accuracy: 0.6234\n",
      "Epoch 212/1000\n",
      "178/178 [==============================] - 0s 163us/step - loss: 0.1689 - accuracy: 0.9551 - val_loss: 0.9828 - val_accuracy: 0.6234\n",
      "Epoch 213/1000\n",
      "178/178 [==============================] - 0s 196us/step - loss: 0.1715 - accuracy: 0.9382 - val_loss: 0.9694 - val_accuracy: 0.6494\n",
      "Epoch 214/1000\n",
      "178/178 [==============================] - 0s 159us/step - loss: 0.1681 - accuracy: 0.9494 - val_loss: 0.9665 - val_accuracy: 0.6364\n",
      "Epoch 215/1000\n",
      "178/178 [==============================] - 0s 190us/step - loss: 0.1664 - accuracy: 0.9494 - val_loss: 0.9892 - val_accuracy: 0.6234\n",
      "Epoch 216/1000\n",
      "178/178 [==============================] - 0s 170us/step - loss: 0.1875 - accuracy: 0.9438 - val_loss: 1.0004 - val_accuracy: 0.6234\n",
      "Epoch 217/1000\n",
      "178/178 [==============================] - 0s 182us/step - loss: 0.1692 - accuracy: 0.9551 - val_loss: 0.9818 - val_accuracy: 0.6364\n",
      "Epoch 218/1000\n",
      "178/178 [==============================] - 0s 180us/step - loss: 0.1655 - accuracy: 0.9551 - val_loss: 0.9782 - val_accuracy: 0.6364\n",
      "Epoch 219/1000\n",
      "178/178 [==============================] - 0s 167us/step - loss: 0.1646 - accuracy: 0.9551 - val_loss: 0.9735 - val_accuracy: 0.6494\n",
      "Epoch 220/1000\n",
      "178/178 [==============================] - 0s 184us/step - loss: 0.1638 - accuracy: 0.9438 - val_loss: 0.9768 - val_accuracy: 0.6494\n",
      "Epoch 221/1000\n",
      "178/178 [==============================] - 0s 171us/step - loss: 0.1618 - accuracy: 0.9494 - val_loss: 0.9993 - val_accuracy: 0.6234\n",
      "Epoch 222/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 190us/step - loss: 0.1771 - accuracy: 0.9326 - val_loss: 0.9809 - val_accuracy: 0.6494\n",
      "Epoch 223/1000\n",
      "178/178 [==============================] - 0s 181us/step - loss: 0.1621 - accuracy: 0.9494 - val_loss: 0.9803 - val_accuracy: 0.6364\n",
      "Epoch 224/1000\n",
      "178/178 [==============================] - 0s 179us/step - loss: 0.1737 - accuracy: 0.9438 - val_loss: 1.0013 - val_accuracy: 0.6364\n",
      "Epoch 225/1000\n",
      "178/178 [==============================] - 0s 170us/step - loss: 0.1583 - accuracy: 0.9551 - val_loss: 0.9898 - val_accuracy: 0.6364\n",
      "Epoch 226/1000\n",
      "178/178 [==============================] - 0s 159us/step - loss: 0.1615 - accuracy: 0.9551 - val_loss: 0.9879 - val_accuracy: 0.6234\n",
      "Epoch 227/1000\n",
      "178/178 [==============================] - 0s 173us/step - loss: 0.1704 - accuracy: 0.9438 - val_loss: 1.0278 - val_accuracy: 0.6364\n",
      "Epoch 228/1000\n",
      "178/178 [==============================] - 0s 186us/step - loss: 0.1846 - accuracy: 0.9326 - val_loss: 1.0043 - val_accuracy: 0.6234\n",
      "Epoch 229/1000\n",
      "178/178 [==============================] - 0s 184us/step - loss: 0.1600 - accuracy: 0.9494 - val_loss: 1.0153 - val_accuracy: 0.6364\n",
      "Epoch 230/1000\n",
      "178/178 [==============================] - 0s 179us/step - loss: 0.1605 - accuracy: 0.9551 - val_loss: 0.9942 - val_accuracy: 0.6364\n",
      "Epoch 231/1000\n",
      "178/178 [==============================] - 0s 177us/step - loss: 0.1611 - accuracy: 0.9494 - val_loss: 1.0094 - val_accuracy: 0.6234\n",
      "Epoch 232/1000\n",
      "178/178 [==============================] - 0s 181us/step - loss: 0.1589 - accuracy: 0.9551 - val_loss: 0.9920 - val_accuracy: 0.6364\n",
      "Epoch 233/1000\n",
      "178/178 [==============================] - 0s 173us/step - loss: 0.1648 - accuracy: 0.9551 - val_loss: 1.0002 - val_accuracy: 0.6364\n",
      "Epoch 234/1000\n",
      "178/178 [==============================] - 0s 161us/step - loss: 0.1560 - accuracy: 0.9551 - val_loss: 1.0382 - val_accuracy: 0.6364\n",
      "Epoch 235/1000\n",
      "178/178 [==============================] - 0s 177us/step - loss: 0.1529 - accuracy: 0.9551 - val_loss: 0.9996 - val_accuracy: 0.6234\n",
      "Epoch 236/1000\n",
      "178/178 [==============================] - 0s 154us/step - loss: 0.1664 - accuracy: 0.9551 - val_loss: 1.0154 - val_accuracy: 0.6364\n",
      "Epoch 237/1000\n",
      "178/178 [==============================] - 0s 194us/step - loss: 0.1551 - accuracy: 0.9551 - val_loss: 1.0109 - val_accuracy: 0.6364\n",
      "Epoch 238/1000\n",
      "178/178 [==============================] - 0s 183us/step - loss: 0.1527 - accuracy: 0.9663 - val_loss: 1.0127 - val_accuracy: 0.6494\n",
      "Epoch 239/1000\n",
      "178/178 [==============================] - 0s 190us/step - loss: 0.1513 - accuracy: 0.9551 - val_loss: 1.0411 - val_accuracy: 0.6364\n",
      "Epoch 240/1000\n",
      "178/178 [==============================] - 0s 188us/step - loss: 0.1678 - accuracy: 0.9494 - val_loss: 1.0226 - val_accuracy: 0.6364\n",
      "Epoch 241/1000\n",
      "178/178 [==============================] - 0s 184us/step - loss: 0.1511 - accuracy: 0.9551 - val_loss: 1.0117 - val_accuracy: 0.6234\n",
      "Epoch 242/1000\n",
      "178/178 [==============================] - 0s 179us/step - loss: 0.1560 - accuracy: 0.9607 - val_loss: 1.0130 - val_accuracy: 0.6234\n",
      "Epoch 243/1000\n",
      "178/178 [==============================] - 0s 167us/step - loss: 0.1480 - accuracy: 0.9551 - val_loss: 1.0344 - val_accuracy: 0.6364\n",
      "Epoch 244/1000\n",
      "178/178 [==============================] - 0s 181us/step - loss: 0.1542 - accuracy: 0.9494 - val_loss: 1.0582 - val_accuracy: 0.6364\n",
      "Epoch 245/1000\n",
      "178/178 [==============================] - 0s 207us/step - loss: 0.1606 - accuracy: 0.9494 - val_loss: 1.0349 - val_accuracy: 0.6494\n",
      "Epoch 246/1000\n",
      "178/178 [==============================] - 0s 168us/step - loss: 0.1492 - accuracy: 0.9551 - val_loss: 1.0404 - val_accuracy: 0.6494\n",
      "Epoch 247/1000\n",
      "178/178 [==============================] - 0s 164us/step - loss: 0.1501 - accuracy: 0.9607 - val_loss: 1.0534 - val_accuracy: 0.6234\n",
      "Epoch 248/1000\n",
      "178/178 [==============================] - 0s 163us/step - loss: 0.1578 - accuracy: 0.9551 - val_loss: 1.0305 - val_accuracy: 0.6494\n",
      "Epoch 249/1000\n",
      "178/178 [==============================] - 0s 180us/step - loss: 0.1531 - accuracy: 0.9607 - val_loss: 1.0367 - val_accuracy: 0.6234\n",
      "Epoch 250/1000\n",
      "178/178 [==============================] - 0s 196us/step - loss: 0.1552 - accuracy: 0.9494 - val_loss: 1.0434 - val_accuracy: 0.6494\n",
      "Epoch 251/1000\n",
      "178/178 [==============================] - 0s 160us/step - loss: 0.1421 - accuracy: 0.9551 - val_loss: 1.0621 - val_accuracy: 0.6364\n",
      "Epoch 252/1000\n",
      "178/178 [==============================] - 0s 197us/step - loss: 0.1460 - accuracy: 0.9607 - val_loss: 1.0599 - val_accuracy: 0.6234\n",
      "Epoch 253/1000\n",
      "178/178 [==============================] - 0s 176us/step - loss: 0.1520 - accuracy: 0.9551 - val_loss: 1.0646 - val_accuracy: 0.6364\n",
      "Epoch 254/1000\n",
      "178/178 [==============================] - 0s 152us/step - loss: 0.1487 - accuracy: 0.9607 - val_loss: 1.0449 - val_accuracy: 0.6234\n",
      "Epoch 255/1000\n",
      "178/178 [==============================] - 0s 182us/step - loss: 0.1647 - accuracy: 0.9494 - val_loss: 1.0404 - val_accuracy: 0.6494\n",
      "Epoch 256/1000\n",
      "178/178 [==============================] - 0s 176us/step - loss: 0.1400 - accuracy: 0.9607 - val_loss: 1.0581 - val_accuracy: 0.6494\n",
      "Epoch 257/1000\n",
      "178/178 [==============================] - 0s 158us/step - loss: 0.1449 - accuracy: 0.9494 - val_loss: 1.0787 - val_accuracy: 0.6364\n",
      "Epoch 258/1000\n",
      "178/178 [==============================] - 0s 182us/step - loss: 0.1492 - accuracy: 0.9551 - val_loss: 1.0560 - val_accuracy: 0.6234\n",
      "Epoch 259/1000\n",
      "178/178 [==============================] - 0s 183us/step - loss: 0.1649 - accuracy: 0.9438 - val_loss: 1.0640 - val_accuracy: 0.6234\n",
      "Epoch 260/1000\n",
      "178/178 [==============================] - 0s 182us/step - loss: 0.1387 - accuracy: 0.9551 - val_loss: 1.0527 - val_accuracy: 0.6494\n",
      "Epoch 261/1000\n",
      "178/178 [==============================] - 0s 168us/step - loss: 0.1377 - accuracy: 0.9607 - val_loss: 1.0536 - val_accuracy: 0.6494\n",
      "Epoch 262/1000\n",
      "178/178 [==============================] - 0s 187us/step - loss: 0.1384 - accuracy: 0.9551 - val_loss: 1.0568 - val_accuracy: 0.6494\n",
      "Epoch 263/1000\n",
      "178/178 [==============================] - 0s 169us/step - loss: 0.1383 - accuracy: 0.9607 - val_loss: 1.0551 - val_accuracy: 0.6494\n",
      "Epoch 264/1000\n",
      "178/178 [==============================] - 0s 183us/step - loss: 0.1352 - accuracy: 0.9663 - val_loss: 1.0772 - val_accuracy: 0.6234\n",
      "Epoch 265/1000\n",
      "178/178 [==============================] - 0s 163us/step - loss: 0.1476 - accuracy: 0.9607 - val_loss: 1.0580 - val_accuracy: 0.6494\n",
      "Epoch 266/1000\n",
      "178/178 [==============================] - 0s 182us/step - loss: 0.1405 - accuracy: 0.9551 - val_loss: 1.0733 - val_accuracy: 0.6364\n",
      "Epoch 267/1000\n",
      "178/178 [==============================] - 0s 178us/step - loss: 0.1409 - accuracy: 0.9607 - val_loss: 1.0879 - val_accuracy: 0.6364\n",
      "Epoch 268/1000\n",
      "178/178 [==============================] - 0s 168us/step - loss: 0.1393 - accuracy: 0.9607 - val_loss: 1.0720 - val_accuracy: 0.6494\n",
      "Epoch 269/1000\n",
      "178/178 [==============================] - 0s 185us/step - loss: 0.1331 - accuracy: 0.9607 - val_loss: 1.0723 - val_accuracy: 0.6494\n",
      "Epoch 270/1000\n",
      "178/178 [==============================] - 0s 167us/step - loss: 0.1421 - accuracy: 0.9607 - val_loss: 1.0727 - val_accuracy: 0.6104\n",
      "Epoch 271/1000\n",
      "178/178 [==============================] - 0s 173us/step - loss: 0.1511 - accuracy: 0.9551 - val_loss: 1.0821 - val_accuracy: 0.6494\n",
      "Epoch 272/1000\n",
      "178/178 [==============================] - 0s 178us/step - loss: 0.1375 - accuracy: 0.9551 - val_loss: 1.0710 - val_accuracy: 0.6104\n",
      "Epoch 273/1000\n",
      "178/178 [==============================] - 0s 179us/step - loss: 0.1388 - accuracy: 0.9551 - val_loss: 1.0750 - val_accuracy: 0.6494\n",
      "Epoch 274/1000\n",
      "178/178 [==============================] - 0s 176us/step - loss: 0.1315 - accuracy: 0.9607 - val_loss: 1.0834 - val_accuracy: 0.6494\n",
      "Epoch 275/1000\n",
      "178/178 [==============================] - 0s 173us/step - loss: 0.1312 - accuracy: 0.9607 - val_loss: 1.0775 - val_accuracy: 0.6234\n",
      "Epoch 276/1000\n",
      "178/178 [==============================] - 0s 188us/step - loss: 0.1329 - accuracy: 0.9551 - val_loss: 1.1073 - val_accuracy: 0.6364\n",
      "Epoch 277/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 173us/step - loss: 0.1349 - accuracy: 0.9551 - val_loss: 1.1129 - val_accuracy: 0.6364\n",
      "Epoch 278/1000\n",
      "178/178 [==============================] - 0s 165us/step - loss: 0.1334 - accuracy: 0.9607 - val_loss: 1.0843 - val_accuracy: 0.6494\n",
      "Epoch 279/1000\n",
      "178/178 [==============================] - 0s 168us/step - loss: 0.1354 - accuracy: 0.9607 - val_loss: 1.0925 - val_accuracy: 0.6494\n",
      "Epoch 280/1000\n",
      "178/178 [==============================] - 0s 187us/step - loss: 0.1275 - accuracy: 0.9663 - val_loss: 1.1063 - val_accuracy: 0.6364\n",
      "Epoch 281/1000\n",
      "178/178 [==============================] - 0s 184us/step - loss: 0.1378 - accuracy: 0.9551 - val_loss: 1.0950 - val_accuracy: 0.6494\n",
      "Epoch 282/1000\n",
      "178/178 [==============================] - 0s 189us/step - loss: 0.1267 - accuracy: 0.9719 - val_loss: 1.0959 - val_accuracy: 0.6494\n",
      "Epoch 283/1000\n",
      "178/178 [==============================] - 0s 151us/step - loss: 0.1279 - accuracy: 0.9607 - val_loss: 1.1392 - val_accuracy: 0.6364\n",
      "Epoch 284/1000\n",
      "178/178 [==============================] - 0s 185us/step - loss: 0.1333 - accuracy: 0.9663 - val_loss: 1.1128 - val_accuracy: 0.6234\n",
      "Epoch 285/1000\n",
      "178/178 [==============================] - 0s 177us/step - loss: 0.1261 - accuracy: 0.9663 - val_loss: 1.0967 - val_accuracy: 0.6494\n",
      "Epoch 286/1000\n",
      "178/178 [==============================] - 0s 219us/step - loss: 0.1311 - accuracy: 0.9551 - val_loss: 1.1198 - val_accuracy: 0.6364\n",
      "Epoch 287/1000\n",
      "178/178 [==============================] - 0s 177us/step - loss: 0.1310 - accuracy: 0.9607 - val_loss: 1.1076 - val_accuracy: 0.6364\n",
      "Epoch 288/1000\n",
      "178/178 [==============================] - 0s 181us/step - loss: 0.1329 - accuracy: 0.9607 - val_loss: 1.1137 - val_accuracy: 0.6364\n",
      "Epoch 289/1000\n",
      "178/178 [==============================] - 0s 184us/step - loss: 0.1220 - accuracy: 0.9663 - val_loss: 1.0950 - val_accuracy: 0.6234\n",
      "Epoch 290/1000\n",
      "178/178 [==============================] - 0s 169us/step - loss: 0.1231 - accuracy: 0.9663 - val_loss: 1.1055 - val_accuracy: 0.6494\n",
      "Epoch 291/1000\n",
      "178/178 [==============================] - 0s 174us/step - loss: 0.1214 - accuracy: 0.9663 - val_loss: 1.1132 - val_accuracy: 0.6494\n",
      "Epoch 292/1000\n",
      "178/178 [==============================] - 0s 162us/step - loss: 0.1199 - accuracy: 0.9663 - val_loss: 1.1090 - val_accuracy: 0.6494\n",
      "Epoch 293/1000\n",
      "178/178 [==============================] - 0s 182us/step - loss: 0.1225 - accuracy: 0.9663 - val_loss: 1.1062 - val_accuracy: 0.6494\n",
      "Epoch 294/1000\n",
      "178/178 [==============================] - 0s 175us/step - loss: 0.1308 - accuracy: 0.9551 - val_loss: 1.1116 - val_accuracy: 0.6494\n",
      "Epoch 295/1000\n",
      "178/178 [==============================] - 0s 176us/step - loss: 0.1211 - accuracy: 0.9663 - val_loss: 1.1180 - val_accuracy: 0.6494\n",
      "Epoch 296/1000\n",
      "178/178 [==============================] - 0s 173us/step - loss: 0.1206 - accuracy: 0.9663 - val_loss: 1.1312 - val_accuracy: 0.6364\n",
      "Epoch 297/1000\n",
      "178/178 [==============================] - 0s 177us/step - loss: 0.1202 - accuracy: 0.9607 - val_loss: 1.1101 - val_accuracy: 0.6494\n",
      "Epoch 298/1000\n",
      "178/178 [==============================] - 0s 176us/step - loss: 0.1203 - accuracy: 0.9719 - val_loss: 1.1209 - val_accuracy: 0.6494\n",
      "Epoch 299/1000\n",
      "178/178 [==============================] - 0s 176us/step - loss: 0.1211 - accuracy: 0.9719 - val_loss: 1.1138 - val_accuracy: 0.6234\n",
      "Epoch 300/1000\n",
      "178/178 [==============================] - 0s 180us/step - loss: 0.1209 - accuracy: 0.9719 - val_loss: 1.1428 - val_accuracy: 0.6364\n",
      "Epoch 301/1000\n",
      "178/178 [==============================] - 0s 179us/step - loss: 0.1261 - accuracy: 0.9607 - val_loss: 1.1149 - val_accuracy: 0.6234\n",
      "Epoch 302/1000\n",
      "178/178 [==============================] - 0s 181us/step - loss: 0.1221 - accuracy: 0.9551 - val_loss: 1.1238 - val_accuracy: 0.6494\n",
      "Epoch 303/1000\n",
      "178/178 [==============================] - 0s 165us/step - loss: 0.1208 - accuracy: 0.9663 - val_loss: 1.1184 - val_accuracy: 0.6234\n",
      "Epoch 304/1000\n",
      "178/178 [==============================] - 0s 159us/step - loss: 0.1254 - accuracy: 0.9663 - val_loss: 1.1610 - val_accuracy: 0.6364\n",
      "Epoch 305/1000\n",
      "178/178 [==============================] - 0s 186us/step - loss: 0.1217 - accuracy: 0.9663 - val_loss: 1.1452 - val_accuracy: 0.6364\n",
      "Epoch 306/1000\n",
      "178/178 [==============================] - 0s 163us/step - loss: 0.1176 - accuracy: 0.9719 - val_loss: 1.1276 - val_accuracy: 0.6234\n",
      "Epoch 307/1000\n",
      "178/178 [==============================] - 0s 173us/step - loss: 0.1335 - accuracy: 0.9551 - val_loss: 1.1336 - val_accuracy: 0.6494\n",
      "Epoch 308/1000\n",
      "178/178 [==============================] - 0s 195us/step - loss: 0.1177 - accuracy: 0.9719 - val_loss: 1.1552 - val_accuracy: 0.6364\n",
      "Epoch 309/1000\n",
      "178/178 [==============================] - 0s 178us/step - loss: 0.1257 - accuracy: 0.9607 - val_loss: 1.1251 - val_accuracy: 0.6234\n",
      "Epoch 310/1000\n",
      "178/178 [==============================] - 0s 179us/step - loss: 0.1226 - accuracy: 0.9663 - val_loss: 1.1419 - val_accuracy: 0.6494\n",
      "Epoch 311/1000\n",
      "178/178 [==============================] - 0s 152us/step - loss: 0.1206 - accuracy: 0.9663 - val_loss: 1.2077 - val_accuracy: 0.6623\n",
      "Epoch 312/1000\n",
      "178/178 [==============================] - 0s 196us/step - loss: 0.1254 - accuracy: 0.9663 - val_loss: 1.1730 - val_accuracy: 0.6364\n",
      "Epoch 313/1000\n",
      "178/178 [==============================] - 0s 172us/step - loss: 0.1127 - accuracy: 0.9607 - val_loss: 1.1367 - val_accuracy: 0.6234\n",
      "Epoch 314/1000\n",
      "178/178 [==============================] - 0s 190us/step - loss: 0.1137 - accuracy: 0.9719 - val_loss: 1.1373 - val_accuracy: 0.6234\n",
      "Epoch 315/1000\n",
      "178/178 [==============================] - 0s 237us/step - loss: 0.1131 - accuracy: 0.9719 - val_loss: 1.1464 - val_accuracy: 0.6494\n",
      "Epoch 316/1000\n",
      "178/178 [==============================] - 0s 190us/step - loss: 0.1132 - accuracy: 0.9719 - val_loss: 1.1582 - val_accuracy: 0.6494\n",
      "Epoch 317/1000\n",
      "178/178 [==============================] - 0s 166us/step - loss: 0.1105 - accuracy: 0.9719 - val_loss: 1.1584 - val_accuracy: 0.6494\n",
      "Epoch 318/1000\n",
      "178/178 [==============================] - 0s 187us/step - loss: 0.1143 - accuracy: 0.9719 - val_loss: 1.2109 - val_accuracy: 0.6623\n",
      "Epoch 319/1000\n",
      "178/178 [==============================] - 0s 189us/step - loss: 0.1408 - accuracy: 0.9607 - val_loss: 1.1639 - val_accuracy: 0.6494\n",
      "Epoch 320/1000\n",
      "178/178 [==============================] - 0s 183us/step - loss: 0.1317 - accuracy: 0.9551 - val_loss: 1.1742 - val_accuracy: 0.6234\n",
      "Epoch 321/1000\n",
      "178/178 [==============================] - 0s 176us/step - loss: 0.1113 - accuracy: 0.9663 - val_loss: 1.1723 - val_accuracy: 0.6494\n",
      "Epoch 322/1000\n",
      "178/178 [==============================] - 0s 176us/step - loss: 0.1110 - accuracy: 0.9719 - val_loss: 1.1613 - val_accuracy: 0.6494\n",
      "Epoch 323/1000\n",
      "178/178 [==============================] - 0s 199us/step - loss: 0.1094 - accuracy: 0.9719 - val_loss: 1.1576 - val_accuracy: 0.6364\n",
      "Epoch 324/1000\n",
      "178/178 [==============================] - 0s 186us/step - loss: 0.1124 - accuracy: 0.9719 - val_loss: 1.1568 - val_accuracy: 0.6234\n",
      "Epoch 325/1000\n",
      "178/178 [==============================] - 0s 198us/step - loss: 0.1088 - accuracy: 0.9719 - val_loss: 1.1783 - val_accuracy: 0.6494\n",
      "Epoch 326/1000\n",
      "178/178 [==============================] - 0s 199us/step - loss: 0.1084 - accuracy: 0.9719 - val_loss: 1.1793 - val_accuracy: 0.6494\n",
      "Epoch 327/1000\n",
      "178/178 [==============================] - 0s 172us/step - loss: 0.1095 - accuracy: 0.9719 - val_loss: 1.1782 - val_accuracy: 0.6494\n",
      "Epoch 328/1000\n",
      "178/178 [==============================] - 0s 184us/step - loss: 0.1088 - accuracy: 0.9663 - val_loss: 1.1864 - val_accuracy: 0.6364\n",
      "Epoch 329/1000\n",
      "178/178 [==============================] - 0s 182us/step - loss: 0.1086 - accuracy: 0.9719 - val_loss: 1.1787 - val_accuracy: 0.6494\n",
      "Epoch 330/1000\n",
      "178/178 [==============================] - 0s 181us/step - loss: 0.1171 - accuracy: 0.9494 - val_loss: 1.1926 - val_accuracy: 0.6364\n",
      "Epoch 331/1000\n",
      "178/178 [==============================] - 0s 172us/step - loss: 0.1233 - accuracy: 0.9607 - val_loss: 1.1704 - val_accuracy: 0.6494\n",
      "Epoch 332/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 181us/step - loss: 0.1099 - accuracy: 0.9719 - val_loss: 1.1968 - val_accuracy: 0.6364\n",
      "Epoch 333/1000\n",
      "178/178 [==============================] - 0s 197us/step - loss: 0.1082 - accuracy: 0.9719 - val_loss: 1.1832 - val_accuracy: 0.6494\n",
      "Epoch 334/1000\n",
      "178/178 [==============================] - 0s 210us/step - loss: 0.1291 - accuracy: 0.9494 - val_loss: 1.2062 - val_accuracy: 0.6364\n",
      "Epoch 335/1000\n",
      "178/178 [==============================] - 0s 187us/step - loss: 0.1047 - accuracy: 0.9775 - val_loss: 1.1857 - val_accuracy: 0.6494\n",
      "Epoch 336/1000\n",
      "178/178 [==============================] - 0s 158us/step - loss: 0.1170 - accuracy: 0.9607 - val_loss: 1.2417 - val_accuracy: 0.6623\n",
      "Epoch 337/1000\n",
      "178/178 [==============================] - 0s 189us/step - loss: 0.1076 - accuracy: 0.9719 - val_loss: 1.1767 - val_accuracy: 0.6494\n",
      "Epoch 338/1000\n",
      "178/178 [==============================] - 0s 154us/step - loss: 0.1026 - accuracy: 0.9719 - val_loss: 1.2004 - val_accuracy: 0.6364\n",
      "Epoch 339/1000\n",
      "178/178 [==============================] - 0s 198us/step - loss: 0.1034 - accuracy: 0.9719 - val_loss: 1.1780 - val_accuracy: 0.6234\n",
      "Epoch 340/1000\n",
      "178/178 [==============================] - 0s 188us/step - loss: 0.1120 - accuracy: 0.9663 - val_loss: 1.1786 - val_accuracy: 0.6234\n",
      "Epoch 341/1000\n",
      "178/178 [==============================] - 0s 169us/step - loss: 0.1066 - accuracy: 0.9663 - val_loss: 1.2038 - val_accuracy: 0.6494\n",
      "Epoch 342/1000\n",
      "178/178 [==============================] - 0s 190us/step - loss: 0.1092 - accuracy: 0.9719 - val_loss: 1.2411 - val_accuracy: 0.6494\n",
      "Epoch 343/1000\n",
      "178/178 [==============================] - 0s 190us/step - loss: 0.1079 - accuracy: 0.9719 - val_loss: 1.2141 - val_accuracy: 0.6364\n",
      "Epoch 344/1000\n",
      "178/178 [==============================] - 0s 212us/step - loss: 0.1035 - accuracy: 0.9719 - val_loss: 1.1976 - val_accuracy: 0.6494\n",
      "Epoch 345/1000\n",
      "178/178 [==============================] - 0s 160us/step - loss: 0.1082 - accuracy: 0.9719 - val_loss: 1.2320 - val_accuracy: 0.6494\n",
      "Epoch 346/1000\n",
      "178/178 [==============================] - 0s 166us/step - loss: 0.1067 - accuracy: 0.9775 - val_loss: 1.2072 - val_accuracy: 0.6494\n",
      "Epoch 347/1000\n",
      "178/178 [==============================] - 0s 172us/step - loss: 0.1006 - accuracy: 0.9775 - val_loss: 1.2081 - val_accuracy: 0.6623\n",
      "Epoch 348/1000\n",
      "178/178 [==============================] - 0s 183us/step - loss: 0.1051 - accuracy: 0.9719 - val_loss: 1.2243 - val_accuracy: 0.6494\n",
      "Epoch 349/1000\n",
      "178/178 [==============================] - 0s 170us/step - loss: 0.1017 - accuracy: 0.9719 - val_loss: 1.1999 - val_accuracy: 0.6364\n",
      "Epoch 350/1000\n",
      "178/178 [==============================] - 0s 179us/step - loss: 0.1020 - accuracy: 0.9775 - val_loss: 1.1953 - val_accuracy: 0.6494\n",
      "Epoch 351/1000\n",
      "178/178 [==============================] - 0s 187us/step - loss: 0.1025 - accuracy: 0.9775 - val_loss: 1.1952 - val_accuracy: 0.6364\n",
      "Epoch 352/1000\n",
      "178/178 [==============================] - 0s 203us/step - loss: 0.1019 - accuracy: 0.9775 - val_loss: 1.2113 - val_accuracy: 0.6623\n",
      "Epoch 353/1000\n",
      "178/178 [==============================] - 0s 150us/step - loss: 0.1046 - accuracy: 0.9775 - val_loss: 1.2209 - val_accuracy: 0.6494\n",
      "Epoch 354/1000\n",
      "178/178 [==============================] - 0s 166us/step - loss: 0.0975 - accuracy: 0.9719 - val_loss: 1.2124 - val_accuracy: 0.6494\n",
      "Epoch 355/1000\n",
      "178/178 [==============================] - 0s 180us/step - loss: 0.0987 - accuracy: 0.9719 - val_loss: 1.2218 - val_accuracy: 0.6494\n",
      "Epoch 356/1000\n",
      "178/178 [==============================] - 0s 183us/step - loss: 0.1022 - accuracy: 0.9719 - val_loss: 1.2226 - val_accuracy: 0.6494\n",
      "Epoch 357/1000\n",
      "178/178 [==============================] - 0s 173us/step - loss: 0.0964 - accuracy: 0.9775 - val_loss: 1.2208 - val_accuracy: 0.6494\n",
      "Epoch 358/1000\n",
      "178/178 [==============================] - 0s 193us/step - loss: 0.1017 - accuracy: 0.9719 - val_loss: 1.2099 - val_accuracy: 0.6234\n",
      "Epoch 359/1000\n",
      "178/178 [==============================] - 0s 182us/step - loss: 0.1081 - accuracy: 0.9775 - val_loss: 1.2320 - val_accuracy: 0.6623\n",
      "Epoch 360/1000\n",
      "178/178 [==============================] - 0s 150us/step - loss: 0.0960 - accuracy: 0.9719 - val_loss: 1.2225 - val_accuracy: 0.6494\n",
      "Epoch 361/1000\n",
      "178/178 [==============================] - 0s 184us/step - loss: 0.1054 - accuracy: 0.9719 - val_loss: 1.2431 - val_accuracy: 0.6364\n",
      "Epoch 362/1000\n",
      "178/178 [==============================] - 0s 197us/step - loss: 0.1013 - accuracy: 0.9663 - val_loss: 1.2197 - val_accuracy: 0.6494\n",
      "Epoch 363/1000\n",
      "178/178 [==============================] - 0s 155us/step - loss: 0.0963 - accuracy: 0.9663 - val_loss: 1.2188 - val_accuracy: 0.6364\n",
      "Epoch 364/1000\n",
      "178/178 [==============================] - 0s 182us/step - loss: 0.0995 - accuracy: 0.9719 - val_loss: 1.2183 - val_accuracy: 0.6234\n",
      "Epoch 365/1000\n",
      "178/178 [==============================] - 0s 167us/step - loss: 0.1181 - accuracy: 0.9663 - val_loss: 1.3589 - val_accuracy: 0.6883\n",
      "Epoch 366/1000\n",
      "178/178 [==============================] - 0s 183us/step - loss: 0.1241 - accuracy: 0.9607 - val_loss: 1.2457 - val_accuracy: 0.6364\n",
      "Epoch 367/1000\n",
      "178/178 [==============================] - 0s 169us/step - loss: 0.0991 - accuracy: 0.9719 - val_loss: 1.2244 - val_accuracy: 0.6364\n",
      "Epoch 368/1000\n",
      "178/178 [==============================] - 0s 173us/step - loss: 0.0980 - accuracy: 0.9719 - val_loss: 1.2251 - val_accuracy: 0.6364\n",
      "Epoch 369/1000\n",
      "178/178 [==============================] - 0s 198us/step - loss: 0.0974 - accuracy: 0.9775 - val_loss: 1.2499 - val_accuracy: 0.6494\n",
      "Epoch 370/1000\n",
      "178/178 [==============================] - 0s 163us/step - loss: 0.0968 - accuracy: 0.9775 - val_loss: 1.2232 - val_accuracy: 0.6234\n",
      "Epoch 371/1000\n",
      "178/178 [==============================] - 0s 185us/step - loss: 0.0960 - accuracy: 0.9719 - val_loss: 1.2445 - val_accuracy: 0.6494\n",
      "Epoch 372/1000\n",
      "178/178 [==============================] - 0s 164us/step - loss: 0.0981 - accuracy: 0.9775 - val_loss: 1.2550 - val_accuracy: 0.6364\n",
      "Epoch 373/1000\n",
      "178/178 [==============================] - 0s 166us/step - loss: 0.1067 - accuracy: 0.9663 - val_loss: 1.2447 - val_accuracy: 0.6494\n",
      "Epoch 374/1000\n",
      "178/178 [==============================] - 0s 214us/step - loss: 0.0965 - accuracy: 0.9719 - val_loss: 1.2421 - val_accuracy: 0.6494\n",
      "Epoch 375/1000\n",
      "178/178 [==============================] - 0s 173us/step - loss: 0.0974 - accuracy: 0.9775 - val_loss: 1.3049 - val_accuracy: 0.6623\n",
      "Epoch 376/1000\n",
      "178/178 [==============================] - 0s 193us/step - loss: 0.0945 - accuracy: 0.9719 - val_loss: 1.2396 - val_accuracy: 0.6364\n",
      "Epoch 377/1000\n",
      "178/178 [==============================] - 0s 190us/step - loss: 0.0915 - accuracy: 0.9719 - val_loss: 1.2751 - val_accuracy: 0.6364\n",
      "Epoch 378/1000\n",
      "178/178 [==============================] - 0s 185us/step - loss: 0.0971 - accuracy: 0.9719 - val_loss: 1.2580 - val_accuracy: 0.6494\n",
      "Epoch 379/1000\n",
      "178/178 [==============================] - 0s 176us/step - loss: 0.0907 - accuracy: 0.9775 - val_loss: 1.2769 - val_accuracy: 0.6364\n",
      "Epoch 380/1000\n",
      "178/178 [==============================] - 0s 174us/step - loss: 0.0912 - accuracy: 0.9831 - val_loss: 1.2581 - val_accuracy: 0.6494\n",
      "Epoch 381/1000\n",
      "178/178 [==============================] - 0s 187us/step - loss: 0.0934 - accuracy: 0.9775 - val_loss: 1.2875 - val_accuracy: 0.6364\n",
      "Epoch 382/1000\n",
      "178/178 [==============================] - 0s 177us/step - loss: 0.0987 - accuracy: 0.9663 - val_loss: 1.2554 - val_accuracy: 0.6494\n",
      "Epoch 383/1000\n",
      "178/178 [==============================] - 0s 187us/step - loss: 0.0895 - accuracy: 0.9775 - val_loss: 1.2588 - val_accuracy: 0.6494\n",
      "Epoch 384/1000\n",
      "178/178 [==============================] - 0s 179us/step - loss: 0.0987 - accuracy: 0.9663 - val_loss: 1.2727 - val_accuracy: 0.6494\n",
      "Epoch 385/1000\n",
      "178/178 [==============================] - 0s 161us/step - loss: 0.0881 - accuracy: 0.9775 - val_loss: 1.2586 - val_accuracy: 0.6494\n",
      "Epoch 386/1000\n",
      "178/178 [==============================] - 0s 165us/step - loss: 0.0928 - accuracy: 0.9775 - val_loss: 1.2559 - val_accuracy: 0.6494\n",
      "Epoch 387/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 182us/step - loss: 0.0899 - accuracy: 0.9775 - val_loss: 1.2769 - val_accuracy: 0.6623\n",
      "Epoch 388/1000\n",
      "178/178 [==============================] - 0s 183us/step - loss: 0.0936 - accuracy: 0.9775 - val_loss: 1.3025 - val_accuracy: 0.6494\n",
      "Epoch 389/1000\n",
      "178/178 [==============================] - 0s 177us/step - loss: 0.0920 - accuracy: 0.9719 - val_loss: 1.2915 - val_accuracy: 0.6364\n",
      "Epoch 390/1000\n",
      "178/178 [==============================] - 0s 228us/step - loss: 0.0909 - accuracy: 0.9775 - val_loss: 1.2954 - val_accuracy: 0.6364\n",
      "Epoch 391/1000\n",
      "178/178 [==============================] - 0s 190us/step - loss: 0.0870 - accuracy: 0.9775 - val_loss: 1.2615 - val_accuracy: 0.6364\n",
      "Epoch 392/1000\n",
      "178/178 [==============================] - 0s 187us/step - loss: 0.0922 - accuracy: 0.9719 - val_loss: 1.2539 - val_accuracy: 0.6234\n",
      "Epoch 393/1000\n",
      "178/178 [==============================] - 0s 193us/step - loss: 0.0988 - accuracy: 0.9719 - val_loss: 1.2660 - val_accuracy: 0.6494\n",
      "Epoch 394/1000\n",
      "178/178 [==============================] - 0s 151us/step - loss: 0.0866 - accuracy: 0.9719 - val_loss: 1.2887 - val_accuracy: 0.6623\n",
      "Epoch 395/1000\n",
      "178/178 [==============================] - 0s 180us/step - loss: 0.0867 - accuracy: 0.9775 - val_loss: 1.2633 - val_accuracy: 0.6234\n",
      "Epoch 396/1000\n",
      "178/178 [==============================] - 0s 182us/step - loss: 0.1019 - accuracy: 0.9719 - val_loss: 1.2753 - val_accuracy: 0.6494\n",
      "Epoch 397/1000\n",
      "178/178 [==============================] - 0s 166us/step - loss: 0.0848 - accuracy: 0.9775 - val_loss: 1.2830 - val_accuracy: 0.6494\n",
      "Epoch 398/1000\n",
      "178/178 [==============================] - 0s 185us/step - loss: 0.0893 - accuracy: 0.9719 - val_loss: 1.2995 - val_accuracy: 0.6494\n",
      "Epoch 399/1000\n",
      "178/178 [==============================] - 0s 188us/step - loss: 0.0875 - accuracy: 0.9775 - val_loss: 1.2943 - val_accuracy: 0.6494\n",
      "Epoch 400/1000\n",
      "178/178 [==============================] - 0s 184us/step - loss: 0.0870 - accuracy: 0.9775 - val_loss: 1.2784 - val_accuracy: 0.6364\n",
      "Epoch 401/1000\n",
      "178/178 [==============================] - 0s 153us/step - loss: 0.0902 - accuracy: 0.9831 - val_loss: 1.2777 - val_accuracy: 0.6364\n",
      "Epoch 402/1000\n",
      "178/178 [==============================] - 0s 173us/step - loss: 0.0889 - accuracy: 0.9775 - val_loss: 1.2730 - val_accuracy: 0.6234\n",
      "Epoch 403/1000\n",
      "178/178 [==============================] - 0s 171us/step - loss: 0.0931 - accuracy: 0.9663 - val_loss: 1.2801 - val_accuracy: 0.6364\n",
      "Epoch 404/1000\n",
      "178/178 [==============================] - 0s 170us/step - loss: 0.0890 - accuracy: 0.9775 - val_loss: 1.3169 - val_accuracy: 0.6494\n",
      "Epoch 405/1000\n",
      "178/178 [==============================] - 0s 207us/step - loss: 0.0876 - accuracy: 0.9831 - val_loss: 1.3152 - val_accuracy: 0.6364\n",
      "Epoch 406/1000\n",
      "178/178 [==============================] - 0s 165us/step - loss: 0.0985 - accuracy: 0.9719 - val_loss: 1.3142 - val_accuracy: 0.6494\n",
      "Epoch 407/1000\n",
      "178/178 [==============================] - 0s 161us/step - loss: 0.0851 - accuracy: 0.9831 - val_loss: 1.3083 - val_accuracy: 0.6364\n",
      "Epoch 408/1000\n",
      "178/178 [==============================] - 0s 167us/step - loss: 0.0859 - accuracy: 0.9775 - val_loss: 1.2934 - val_accuracy: 0.6494\n",
      "Epoch 409/1000\n",
      "178/178 [==============================] - 0s 193us/step - loss: 0.0840 - accuracy: 0.9775 - val_loss: 1.2899 - val_accuracy: 0.6494\n",
      "Epoch 410/1000\n",
      "178/178 [==============================] - 0s 161us/step - loss: 0.0850 - accuracy: 0.9775 - val_loss: 1.3088 - val_accuracy: 0.6494\n",
      "Epoch 411/1000\n",
      "178/178 [==============================] - 0s 164us/step - loss: 0.0830 - accuracy: 0.9775 - val_loss: 1.2863 - val_accuracy: 0.6234\n",
      "Epoch 412/1000\n",
      "178/178 [==============================] - 0s 197us/step - loss: 0.0972 - accuracy: 0.9663 - val_loss: 1.3104 - val_accuracy: 0.6494\n",
      "Epoch 413/1000\n",
      "178/178 [==============================] - 0s 150us/step - loss: 0.0954 - accuracy: 0.9775 - val_loss: 1.2832 - val_accuracy: 0.6234\n",
      "Epoch 414/1000\n",
      "178/178 [==============================] - 0s 192us/step - loss: 0.0958 - accuracy: 0.9775 - val_loss: 1.2873 - val_accuracy: 0.6104\n",
      "Epoch 415/1000\n",
      "178/178 [==============================] - 0s 163us/step - loss: 0.0982 - accuracy: 0.9663 - val_loss: 1.2861 - val_accuracy: 0.6234\n",
      "Epoch 416/1000\n",
      "178/178 [==============================] - 0s 197us/step - loss: 0.0869 - accuracy: 0.9775 - val_loss: 1.3055 - val_accuracy: 0.6494\n",
      "Epoch 417/1000\n",
      "178/178 [==============================] - 0s 160us/step - loss: 0.0813 - accuracy: 0.9775 - val_loss: 1.2971 - val_accuracy: 0.6364\n",
      "Epoch 418/1000\n",
      "178/178 [==============================] - 0s 149us/step - loss: 0.0871 - accuracy: 0.9719 - val_loss: 1.3158 - val_accuracy: 0.6494\n",
      "Epoch 419/1000\n",
      "178/178 [==============================] - 0s 199us/step - loss: 0.0830 - accuracy: 0.9775 - val_loss: 1.3061 - val_accuracy: 0.6494\n",
      "Epoch 420/1000\n",
      "178/178 [==============================] - 0s 168us/step - loss: 0.0960 - accuracy: 0.9775 - val_loss: 1.3328 - val_accuracy: 0.6494\n",
      "Epoch 421/1000\n",
      "178/178 [==============================] - 0s 176us/step - loss: 0.0801 - accuracy: 0.9831 - val_loss: 1.2997 - val_accuracy: 0.6364\n",
      "Epoch 422/1000\n",
      "178/178 [==============================] - 0s 190us/step - loss: 0.0884 - accuracy: 0.9775 - val_loss: 1.3827 - val_accuracy: 0.6623\n",
      "Epoch 423/1000\n",
      "178/178 [==============================] - 0s 191us/step - loss: 0.0888 - accuracy: 0.9775 - val_loss: 1.3070 - val_accuracy: 0.6364\n",
      "Epoch 424/1000\n",
      "178/178 [==============================] - 0s 165us/step - loss: 0.0848 - accuracy: 0.9775 - val_loss: 1.3114 - val_accuracy: 0.6234\n",
      "Epoch 425/1000\n",
      "178/178 [==============================] - 0s 191us/step - loss: 0.0944 - accuracy: 0.9775 - val_loss: 1.3278 - val_accuracy: 0.6494\n",
      "Epoch 426/1000\n",
      "178/178 [==============================] - 0s 168us/step - loss: 0.0866 - accuracy: 0.9719 - val_loss: 1.3411 - val_accuracy: 0.6364\n",
      "Epoch 427/1000\n",
      "178/178 [==============================] - 0s 166us/step - loss: 0.0785 - accuracy: 0.9831 - val_loss: 1.3158 - val_accuracy: 0.6494\n",
      "Epoch 428/1000\n",
      "178/178 [==============================] - 0s 174us/step - loss: 0.0824 - accuracy: 0.9775 - val_loss: 1.3222 - val_accuracy: 0.6494\n",
      "Epoch 429/1000\n",
      "178/178 [==============================] - 0s 198us/step - loss: 0.0805 - accuracy: 0.9831 - val_loss: 1.3151 - val_accuracy: 0.6234\n",
      "Epoch 430/1000\n",
      "178/178 [==============================] - 0s 181us/step - loss: 0.0852 - accuracy: 0.9719 - val_loss: 1.3188 - val_accuracy: 0.6364\n",
      "Epoch 431/1000\n",
      "178/178 [==============================] - 0s 166us/step - loss: 0.0916 - accuracy: 0.9719 - val_loss: 1.3379 - val_accuracy: 0.6494\n",
      "Epoch 432/1000\n",
      "178/178 [==============================] - 0s 185us/step - loss: 0.0796 - accuracy: 0.9775 - val_loss: 1.3525 - val_accuracy: 0.6494\n",
      "Epoch 433/1000\n",
      "178/178 [==============================] - 0s 168us/step - loss: 0.0792 - accuracy: 0.9775 - val_loss: 1.3361 - val_accuracy: 0.6494\n",
      "Epoch 434/1000\n",
      "178/178 [==============================] - 0s 180us/step - loss: 0.0913 - accuracy: 0.9775 - val_loss: 1.3686 - val_accuracy: 0.6364\n",
      "Epoch 435/1000\n",
      "178/178 [==============================] - 0s 170us/step - loss: 0.0827 - accuracy: 0.9831 - val_loss: 1.3192 - val_accuracy: 0.6234\n",
      "Epoch 436/1000\n",
      "178/178 [==============================] - 0s 184us/step - loss: 0.0907 - accuracy: 0.9775 - val_loss: 1.3690 - val_accuracy: 0.6494\n",
      "Epoch 437/1000\n",
      "178/178 [==============================] - 0s 178us/step - loss: 0.0806 - accuracy: 0.9719 - val_loss: 1.3256 - val_accuracy: 0.6494\n",
      "Epoch 438/1000\n",
      "178/178 [==============================] - 0s 171us/step - loss: 0.0804 - accuracy: 0.9775 - val_loss: 1.3294 - val_accuracy: 0.6494\n",
      "Epoch 439/1000\n",
      "178/178 [==============================] - 0s 178us/step - loss: 0.0757 - accuracy: 0.9775 - val_loss: 1.3463 - val_accuracy: 0.6623\n",
      "Epoch 440/1000\n",
      "178/178 [==============================] - 0s 172us/step - loss: 0.0814 - accuracy: 0.9775 - val_loss: 1.3610 - val_accuracy: 0.6364\n",
      "Epoch 441/1000\n",
      "178/178 [==============================] - 0s 182us/step - loss: 0.0777 - accuracy: 0.9831 - val_loss: 1.3462 - val_accuracy: 0.6623\n",
      "Epoch 442/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 185us/step - loss: 0.0816 - accuracy: 0.9775 - val_loss: 1.3237 - val_accuracy: 0.6234\n",
      "Epoch 443/1000\n",
      "178/178 [==============================] - 0s 181us/step - loss: 0.0882 - accuracy: 0.9775 - val_loss: 1.3249 - val_accuracy: 0.6364\n",
      "Epoch 444/1000\n",
      "178/178 [==============================] - 0s 170us/step - loss: 0.0772 - accuracy: 0.9719 - val_loss: 1.3423 - val_accuracy: 0.6494\n",
      "Epoch 445/1000\n",
      "178/178 [==============================] - 0s 152us/step - loss: 0.0753 - accuracy: 0.9775 - val_loss: 1.3726 - val_accuracy: 0.6494\n",
      "Epoch 446/1000\n",
      "178/178 [==============================] - 0s 179us/step - loss: 0.0784 - accuracy: 0.9831 - val_loss: 1.3581 - val_accuracy: 0.6494\n",
      "Epoch 447/1000\n",
      "178/178 [==============================] - 0s 177us/step - loss: 0.0799 - accuracy: 0.9831 - val_loss: 1.3411 - val_accuracy: 0.6623\n",
      "Epoch 448/1000\n",
      "178/178 [==============================] - 0s 195us/step - loss: 0.0801 - accuracy: 0.9775 - val_loss: 1.3415 - val_accuracy: 0.6494\n",
      "Epoch 449/1000\n",
      "178/178 [==============================] - 0s 173us/step - loss: 0.0775 - accuracy: 0.9775 - val_loss: 1.3496 - val_accuracy: 0.6623\n",
      "Epoch 450/1000\n",
      "178/178 [==============================] - 0s 175us/step - loss: 0.0767 - accuracy: 0.9831 - val_loss: 1.3294 - val_accuracy: 0.6234\n",
      "Epoch 451/1000\n",
      "178/178 [==============================] - 0s 158us/step - loss: 0.0936 - accuracy: 0.9607 - val_loss: 1.3585 - val_accuracy: 0.6494\n",
      "Epoch 452/1000\n",
      "178/178 [==============================] - 0s 165us/step - loss: 0.0849 - accuracy: 0.9775 - val_loss: 1.3673 - val_accuracy: 0.6364\n",
      "Epoch 453/1000\n",
      "178/178 [==============================] - 0s 180us/step - loss: 0.0765 - accuracy: 0.9775 - val_loss: 1.3589 - val_accuracy: 0.6623\n",
      "Epoch 454/1000\n",
      "178/178 [==============================] - 0s 166us/step - loss: 0.0775 - accuracy: 0.9831 - val_loss: 1.3966 - val_accuracy: 0.6494\n",
      "Epoch 455/1000\n",
      "178/178 [==============================] - 0s 192us/step - loss: 0.1002 - accuracy: 0.9551 - val_loss: 1.3488 - val_accuracy: 0.6494\n",
      "Epoch 456/1000\n",
      "178/178 [==============================] - 0s 184us/step - loss: 0.0752 - accuracy: 0.9775 - val_loss: 1.3442 - val_accuracy: 0.6364\n",
      "Epoch 457/1000\n",
      "178/178 [==============================] - 0s 161us/step - loss: 0.0771 - accuracy: 0.9775 - val_loss: 1.3461 - val_accuracy: 0.6364\n",
      "Epoch 458/1000\n",
      "178/178 [==============================] - 0s 160us/step - loss: 0.0845 - accuracy: 0.9775 - val_loss: 1.3862 - val_accuracy: 0.6494\n",
      "Epoch 459/1000\n",
      "178/178 [==============================] - 0s 179us/step - loss: 0.0800 - accuracy: 0.9775 - val_loss: 1.3824 - val_accuracy: 0.6494\n",
      "Epoch 460/1000\n",
      "178/178 [==============================] - 0s 173us/step - loss: 0.0813 - accuracy: 0.9719 - val_loss: 1.3669 - val_accuracy: 0.6494\n",
      "Epoch 461/1000\n",
      "178/178 [==============================] - 0s 168us/step - loss: 0.0761 - accuracy: 0.9831 - val_loss: 1.3597 - val_accuracy: 0.6494\n",
      "Epoch 462/1000\n",
      "178/178 [==============================] - 0s 202us/step - loss: 0.0797 - accuracy: 0.9719 - val_loss: 1.3668 - val_accuracy: 0.6494\n",
      "Epoch 463/1000\n",
      "178/178 [==============================] - 0s 147us/step - loss: 0.0722 - accuracy: 0.9775 - val_loss: 1.3611 - val_accuracy: 0.6494\n",
      "Epoch 464/1000\n",
      "178/178 [==============================] - 0s 194us/step - loss: 0.0744 - accuracy: 0.9831 - val_loss: 1.3571 - val_accuracy: 0.6494\n",
      "Epoch 465/1000\n",
      "178/178 [==============================] - 0s 151us/step - loss: 0.0720 - accuracy: 0.9775 - val_loss: 1.4086 - val_accuracy: 0.6494\n",
      "Epoch 466/1000\n",
      "178/178 [==============================] - 0s 194us/step - loss: 0.0757 - accuracy: 0.9831 - val_loss: 1.3555 - val_accuracy: 0.6364\n",
      "Epoch 467/1000\n",
      "178/178 [==============================] - 0s 181us/step - loss: 0.0710 - accuracy: 0.9775 - val_loss: 1.3834 - val_accuracy: 0.6623\n",
      "Epoch 468/1000\n",
      "178/178 [==============================] - 0s 167us/step - loss: 0.0834 - accuracy: 0.9775 - val_loss: 1.4705 - val_accuracy: 0.6753\n",
      "Epoch 469/1000\n",
      "178/178 [==============================] - 0s 180us/step - loss: 0.0846 - accuracy: 0.9719 - val_loss: 1.4019 - val_accuracy: 0.6494\n",
      "Epoch 470/1000\n",
      "178/178 [==============================] - 0s 177us/step - loss: 0.0763 - accuracy: 0.9775 - val_loss: 1.3891 - val_accuracy: 0.6494\n",
      "Epoch 471/1000\n",
      "178/178 [==============================] - 0s 188us/step - loss: 0.0745 - accuracy: 0.9775 - val_loss: 1.3576 - val_accuracy: 0.6494\n",
      "Epoch 472/1000\n",
      "178/178 [==============================] - 0s 162us/step - loss: 0.0751 - accuracy: 0.9775 - val_loss: 1.3676 - val_accuracy: 0.6494\n",
      "Epoch 473/1000\n",
      "178/178 [==============================] - 0s 187us/step - loss: 0.0709 - accuracy: 0.9775 - val_loss: 1.3718 - val_accuracy: 0.6494\n",
      "Epoch 474/1000\n",
      "178/178 [==============================] - 0s 181us/step - loss: 0.0721 - accuracy: 0.9775 - val_loss: 1.3705 - val_accuracy: 0.6494\n",
      "Epoch 475/1000\n",
      "178/178 [==============================] - 0s 166us/step - loss: 0.0693 - accuracy: 0.9775 - val_loss: 1.3930 - val_accuracy: 0.6623\n",
      "Epoch 476/1000\n",
      "178/178 [==============================] - 0s 183us/step - loss: 0.0782 - accuracy: 0.9775 - val_loss: 1.3847 - val_accuracy: 0.6494\n",
      "Epoch 477/1000\n",
      "178/178 [==============================] - 0s 176us/step - loss: 0.0732 - accuracy: 0.9775 - val_loss: 1.3696 - val_accuracy: 0.6364\n",
      "Epoch 478/1000\n",
      "178/178 [==============================] - 0s 190us/step - loss: 0.0724 - accuracy: 0.9775 - val_loss: 1.3807 - val_accuracy: 0.6494\n",
      "Epoch 479/1000\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0621 - accuracy: 0.98 - 0s 176us/step - loss: 0.0691 - accuracy: 0.9775 - val_loss: 1.3761 - val_accuracy: 0.6494\n",
      "Epoch 480/1000\n",
      "178/178 [==============================] - 0s 169us/step - loss: 0.0703 - accuracy: 0.9775 - val_loss: 1.3730 - val_accuracy: 0.6364\n",
      "Epoch 481/1000\n",
      "178/178 [==============================] - 0s 156us/step - loss: 0.0730 - accuracy: 0.9831 - val_loss: 1.3937 - val_accuracy: 0.6623\n",
      "Epoch 482/1000\n",
      "178/178 [==============================] - 0s 198us/step - loss: 0.0695 - accuracy: 0.9775 - val_loss: 1.4089 - val_accuracy: 0.6494\n",
      "Epoch 483/1000\n",
      "178/178 [==============================] - 0s 152us/step - loss: 0.0730 - accuracy: 0.9775 - val_loss: 1.4120 - val_accuracy: 0.6494\n",
      "Epoch 484/1000\n",
      "178/178 [==============================] - 0s 183us/step - loss: 0.0751 - accuracy: 0.9775 - val_loss: 1.4052 - val_accuracy: 0.6623\n",
      "Epoch 485/1000\n",
      "178/178 [==============================] - 0s 177us/step - loss: 0.0721 - accuracy: 0.9775 - val_loss: 1.4035 - val_accuracy: 0.6494\n",
      "Epoch 486/1000\n",
      "178/178 [==============================] - 0s 190us/step - loss: 0.0689 - accuracy: 0.9775 - val_loss: 1.4355 - val_accuracy: 0.6494\n",
      "Epoch 487/1000\n",
      "178/178 [==============================] - 0s 169us/step - loss: 0.0734 - accuracy: 0.9775 - val_loss: 1.4206 - val_accuracy: 0.6623\n",
      "Epoch 488/1000\n",
      "178/178 [==============================] - 0s 181us/step - loss: 0.0698 - accuracy: 0.9831 - val_loss: 1.3891 - val_accuracy: 0.6234\n",
      "Epoch 489/1000\n",
      "178/178 [==============================] - 0s 181us/step - loss: 0.0750 - accuracy: 0.9775 - val_loss: 1.3882 - val_accuracy: 0.6364\n",
      "Epoch 490/1000\n",
      "178/178 [==============================] - 0s 172us/step - loss: 0.0761 - accuracy: 0.9719 - val_loss: 1.3875 - val_accuracy: 0.6364\n",
      "Epoch 491/1000\n",
      "178/178 [==============================] - 0s 184us/step - loss: 0.0715 - accuracy: 0.9831 - val_loss: 1.3857 - val_accuracy: 0.6364\n",
      "Epoch 492/1000\n",
      "178/178 [==============================] - 0s 157us/step - loss: 0.0758 - accuracy: 0.9719 - val_loss: 1.3899 - val_accuracy: 0.6364\n",
      "Epoch 493/1000\n",
      "178/178 [==============================] - 0s 188us/step - loss: 0.0719 - accuracy: 0.9775 - val_loss: 1.4267 - val_accuracy: 0.6494\n",
      "Epoch 494/1000\n",
      "178/178 [==============================] - 0s 165us/step - loss: 0.0716 - accuracy: 0.9775 - val_loss: 1.3924 - val_accuracy: 0.6364\n",
      "Epoch 495/1000\n",
      "178/178 [==============================] - 0s 193us/step - loss: 0.0660 - accuracy: 0.9719 - val_loss: 1.4278 - val_accuracy: 0.6494\n",
      "Epoch 496/1000\n",
      "178/178 [==============================] - 0s 169us/step - loss: 0.0781 - accuracy: 0.9831 - val_loss: 1.4427 - val_accuracy: 0.6494\n",
      "Epoch 497/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 189us/step - loss: 0.0684 - accuracy: 0.9831 - val_loss: 1.4213 - val_accuracy: 0.6494\n",
      "Epoch 498/1000\n",
      "178/178 [==============================] - 0s 154us/step - loss: 0.0690 - accuracy: 0.9831 - val_loss: 1.4158 - val_accuracy: 0.6494\n",
      "Epoch 499/1000\n",
      "178/178 [==============================] - 0s 186us/step - loss: 0.0675 - accuracy: 0.9831 - val_loss: 1.4021 - val_accuracy: 0.6494\n",
      "Epoch 500/1000\n",
      "178/178 [==============================] - 0s 167us/step - loss: 0.0691 - accuracy: 0.9775 - val_loss: 1.4309 - val_accuracy: 0.6494\n",
      "Epoch 501/1000\n",
      "178/178 [==============================] - 0s 169us/step - loss: 0.0689 - accuracy: 0.9831 - val_loss: 1.4126 - val_accuracy: 0.6494\n",
      "Epoch 502/1000\n",
      "178/178 [==============================] - 0s 194us/step - loss: 0.0746 - accuracy: 0.9831 - val_loss: 1.4315 - val_accuracy: 0.6623\n",
      "Epoch 503/1000\n",
      "178/178 [==============================] - 0s 181us/step - loss: 0.0689 - accuracy: 0.9775 - val_loss: 1.3959 - val_accuracy: 0.6364\n",
      "Epoch 504/1000\n",
      "178/178 [==============================] - 0s 159us/step - loss: 0.0685 - accuracy: 0.9719 - val_loss: 1.4141 - val_accuracy: 0.6623\n",
      "Epoch 505/1000\n",
      "178/178 [==============================] - 0s 180us/step - loss: 0.0729 - accuracy: 0.9831 - val_loss: 1.4106 - val_accuracy: 0.6494\n",
      "Epoch 506/1000\n",
      "178/178 [==============================] - 0s 196us/step - loss: 0.0656 - accuracy: 0.9831 - val_loss: 1.4090 - val_accuracy: 0.6364\n",
      "Epoch 507/1000\n",
      "178/178 [==============================] - 0s 146us/step - loss: 0.0667 - accuracy: 0.9775 - val_loss: 1.4889 - val_accuracy: 0.6623\n",
      "Epoch 508/1000\n",
      "178/178 [==============================] - 0s 191us/step - loss: 0.0709 - accuracy: 0.9831 - val_loss: 1.4170 - val_accuracy: 0.6494\n",
      "Epoch 509/1000\n",
      "178/178 [==============================] - 0s 167us/step - loss: 0.0713 - accuracy: 0.9831 - val_loss: 1.4054 - val_accuracy: 0.6364\n",
      "Epoch 510/1000\n",
      "178/178 [==============================] - 0s 187us/step - loss: 0.0705 - accuracy: 0.9775 - val_loss: 1.4163 - val_accuracy: 0.6494\n",
      "Epoch 511/1000\n",
      "178/178 [==============================] - 0s 152us/step - loss: 0.0675 - accuracy: 0.9775 - val_loss: 1.4544 - val_accuracy: 0.6494\n",
      "Epoch 512/1000\n",
      "178/178 [==============================] - 0s 181us/step - loss: 0.0676 - accuracy: 0.9831 - val_loss: 1.4194 - val_accuracy: 0.6364\n",
      "Epoch 513/1000\n",
      "178/178 [==============================] - 0s 199us/step - loss: 0.0769 - accuracy: 0.9719 - val_loss: 1.4079 - val_accuracy: 0.6234\n",
      "Epoch 514/1000\n",
      "178/178 [==============================] - 0s 174us/step - loss: 0.0789 - accuracy: 0.9719 - val_loss: 1.4132 - val_accuracy: 0.6234\n",
      "Epoch 515/1000\n",
      "178/178 [==============================] - 0s 160us/step - loss: 0.0749 - accuracy: 0.9831 - val_loss: 1.4280 - val_accuracy: 0.6494\n",
      "Epoch 516/1000\n",
      "178/178 [==============================] - 0s 205us/step - loss: 0.0671 - accuracy: 0.9775 - val_loss: 1.4373 - val_accuracy: 0.6494\n",
      "Epoch 517/1000\n",
      "178/178 [==============================] - 0s 166us/step - loss: 0.0651 - accuracy: 0.9775 - val_loss: 1.4495 - val_accuracy: 0.6623\n",
      "Epoch 518/1000\n",
      "178/178 [==============================] - 0s 176us/step - loss: 0.0648 - accuracy: 0.9831 - val_loss: 1.4365 - val_accuracy: 0.6494\n",
      "Epoch 519/1000\n",
      "178/178 [==============================] - 0s 163us/step - loss: 0.0650 - accuracy: 0.9775 - val_loss: 1.4448 - val_accuracy: 0.6623\n",
      "Epoch 520/1000\n",
      "178/178 [==============================] - 0s 177us/step - loss: 0.0624 - accuracy: 0.9831 - val_loss: 1.4385 - val_accuracy: 0.6494\n",
      "Epoch 521/1000\n",
      "178/178 [==============================] - 0s 182us/step - loss: 0.0658 - accuracy: 0.9831 - val_loss: 1.4982 - val_accuracy: 0.6494\n",
      "Epoch 522/1000\n",
      "178/178 [==============================] - 0s 178us/step - loss: 0.0658 - accuracy: 0.9831 - val_loss: 1.4315 - val_accuracy: 0.6494\n",
      "Epoch 523/1000\n",
      "178/178 [==============================] - 0s 221us/step - loss: 0.0722 - accuracy: 0.9775 - val_loss: 1.4454 - val_accuracy: 0.6623\n",
      "Epoch 524/1000\n",
      "178/178 [==============================] - 0s 208us/step - loss: 0.0699 - accuracy: 0.9775 - val_loss: 1.4441 - val_accuracy: 0.6623\n",
      "Epoch 525/1000\n",
      "178/178 [==============================] - 0s 218us/step - loss: 0.0628 - accuracy: 0.9888 - val_loss: 1.4532 - val_accuracy: 0.6623\n",
      "Epoch 526/1000\n",
      "178/178 [==============================] - 0s 167us/step - loss: 0.0640 - accuracy: 0.9831 - val_loss: 1.4420 - val_accuracy: 0.6494\n",
      "Epoch 527/1000\n",
      "178/178 [==============================] - 0s 172us/step - loss: 0.0639 - accuracy: 0.9831 - val_loss: 1.4351 - val_accuracy: 0.6364\n",
      "Epoch 528/1000\n",
      "178/178 [==============================] - 0s 166us/step - loss: 0.0649 - accuracy: 0.9775 - val_loss: 1.4366 - val_accuracy: 0.6364\n",
      "Epoch 529/1000\n",
      "178/178 [==============================] - 0s 153us/step - loss: 0.0617 - accuracy: 0.9775 - val_loss: 1.4600 - val_accuracy: 0.6623\n",
      "Epoch 530/1000\n",
      "178/178 [==============================] - 0s 198us/step - loss: 0.0667 - accuracy: 0.9775 - val_loss: 1.4532 - val_accuracy: 0.6494\n",
      "Epoch 531/1000\n",
      "178/178 [==============================] - 0s 166us/step - loss: 0.0710 - accuracy: 0.9719 - val_loss: 1.4680 - val_accuracy: 0.6494\n",
      "Epoch 532/1000\n",
      "178/178 [==============================] - 0s 162us/step - loss: 0.0644 - accuracy: 0.9831 - val_loss: 1.4687 - val_accuracy: 0.6623\n",
      "Epoch 533/1000\n",
      "178/178 [==============================] - 0s 194us/step - loss: 0.0631 - accuracy: 0.9831 - val_loss: 1.4929 - val_accuracy: 0.6623\n",
      "Epoch 534/1000\n",
      "178/178 [==============================] - 0s 178us/step - loss: 0.0662 - accuracy: 0.9831 - val_loss: 1.4457 - val_accuracy: 0.6364\n",
      "Epoch 535/1000\n",
      "178/178 [==============================] - 0s 192us/step - loss: 0.0713 - accuracy: 0.9719 - val_loss: 1.4383 - val_accuracy: 0.6234\n",
      "Epoch 536/1000\n",
      "178/178 [==============================] - 0s 170us/step - loss: 0.0639 - accuracy: 0.9831 - val_loss: 1.4558 - val_accuracy: 0.6494\n",
      "Epoch 537/1000\n",
      "178/178 [==============================] - 0s 189us/step - loss: 0.0646 - accuracy: 0.9775 - val_loss: 1.4731 - val_accuracy: 0.6623\n",
      "Epoch 538/1000\n",
      "178/178 [==============================] - 0s 160us/step - loss: 0.0603 - accuracy: 0.9831 - val_loss: 1.4457 - val_accuracy: 0.6364\n",
      "Epoch 539/1000\n",
      "178/178 [==============================] - 0s 175us/step - loss: 0.0714 - accuracy: 0.9719 - val_loss: 1.4652 - val_accuracy: 0.6494\n",
      "Epoch 540/1000\n",
      "178/178 [==============================] - 0s 181us/step - loss: 0.0627 - accuracy: 0.9775 - val_loss: 1.4985 - val_accuracy: 0.6494\n",
      "Epoch 541/1000\n",
      "178/178 [==============================] - 0s 152us/step - loss: 0.0681 - accuracy: 0.9831 - val_loss: 1.4687 - val_accuracy: 0.6623\n",
      "Epoch 542/1000\n",
      "178/178 [==============================] - 0s 180us/step - loss: 0.0612 - accuracy: 0.9831 - val_loss: 1.4688 - val_accuracy: 0.6494\n",
      "Epoch 543/1000\n",
      "178/178 [==============================] - 0s 195us/step - loss: 0.0612 - accuracy: 0.9831 - val_loss: 1.4798 - val_accuracy: 0.6494\n",
      "Epoch 544/1000\n",
      "178/178 [==============================] - 0s 180us/step - loss: 0.0689 - accuracy: 0.9775 - val_loss: 1.5104 - val_accuracy: 0.6494\n",
      "Epoch 545/1000\n",
      "178/178 [==============================] - 0s 171us/step - loss: 0.0684 - accuracy: 0.9775 - val_loss: 1.4946 - val_accuracy: 0.6494\n",
      "Epoch 546/1000\n",
      "178/178 [==============================] - 0s 165us/step - loss: 0.0652 - accuracy: 0.9831 - val_loss: 1.4614 - val_accuracy: 0.6364\n",
      "Epoch 547/1000\n",
      "178/178 [==============================] - 0s 169us/step - loss: 0.0614 - accuracy: 0.9831 - val_loss: 1.4847 - val_accuracy: 0.6494\n",
      "Epoch 548/1000\n",
      "178/178 [==============================] - 0s 179us/step - loss: 0.0629 - accuracy: 0.9831 - val_loss: 1.4580 - val_accuracy: 0.6234\n",
      "Epoch 549/1000\n",
      "178/178 [==============================] - 0s 169us/step - loss: 0.0666 - accuracy: 0.9775 - val_loss: 1.4583 - val_accuracy: 0.6364\n",
      "Epoch 550/1000\n",
      "178/178 [==============================] - 0s 187us/step - loss: 0.0614 - accuracy: 0.9831 - val_loss: 1.4586 - val_accuracy: 0.6364\n",
      "Epoch 551/1000\n",
      "178/178 [==============================] - 0s 182us/step - loss: 0.0636 - accuracy: 0.9831 - val_loss: 1.4544 - val_accuracy: 0.6234\n",
      "Epoch 552/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 171us/step - loss: 0.0791 - accuracy: 0.9663 - val_loss: 1.4537 - val_accuracy: 0.6364\n",
      "Epoch 553/1000\n",
      "178/178 [==============================] - 0s 187us/step - loss: 0.0602 - accuracy: 0.9775 - val_loss: 1.4897 - val_accuracy: 0.6623\n",
      "Epoch 554/1000\n",
      "178/178 [==============================] - 0s 162us/step - loss: 0.0620 - accuracy: 0.9831 - val_loss: 1.4781 - val_accuracy: 0.6494\n",
      "Epoch 555/1000\n",
      "178/178 [==============================] - 0s 209us/step - loss: 0.0595 - accuracy: 0.9831 - val_loss: 1.4717 - val_accuracy: 0.6364\n",
      "Epoch 556/1000\n",
      "178/178 [==============================] - 0s 175us/step - loss: 0.0588 - accuracy: 0.9775 - val_loss: 1.5320 - val_accuracy: 0.6494\n",
      "Epoch 557/1000\n",
      "178/178 [==============================] - 0s 156us/step - loss: 0.0647 - accuracy: 0.9831 - val_loss: 1.4921 - val_accuracy: 0.6623\n",
      "Epoch 558/1000\n",
      "178/178 [==============================] - 0s 179us/step - loss: 0.0592 - accuracy: 0.9831 - val_loss: 1.4680 - val_accuracy: 0.6364\n",
      "Epoch 559/1000\n",
      "178/178 [==============================] - 0s 162us/step - loss: 0.0618 - accuracy: 0.9831 - val_loss: 1.4735 - val_accuracy: 0.6364\n",
      "Epoch 560/1000\n",
      "178/178 [==============================] - 0s 195us/step - loss: 0.0622 - accuracy: 0.9831 - val_loss: 1.4823 - val_accuracy: 0.6494\n",
      "Epoch 561/1000\n",
      "178/178 [==============================] - 0s 164us/step - loss: 0.0612 - accuracy: 0.9831 - val_loss: 1.4912 - val_accuracy: 0.6494\n",
      "Epoch 562/1000\n",
      "178/178 [==============================] - 0s 197us/step - loss: 0.0585 - accuracy: 0.9831 - val_loss: 1.4705 - val_accuracy: 0.6364\n",
      "Epoch 563/1000\n",
      "178/178 [==============================] - 0s 172us/step - loss: 0.0580 - accuracy: 0.9888 - val_loss: 1.5084 - val_accuracy: 0.6623\n",
      "Epoch 564/1000\n",
      "178/178 [==============================] - 0s 152us/step - loss: 0.0623 - accuracy: 0.9719 - val_loss: 1.5455 - val_accuracy: 0.6494\n",
      "Epoch 565/1000\n",
      "178/178 [==============================] - 0s 192us/step - loss: 0.0708 - accuracy: 0.9775 - val_loss: 1.4749 - val_accuracy: 0.6623\n",
      "Epoch 566/1000\n",
      "178/178 [==============================] - 0s 175us/step - loss: 0.0605 - accuracy: 0.9719 - val_loss: 1.5069 - val_accuracy: 0.6623\n",
      "Epoch 567/1000\n",
      "178/178 [==============================] - 0s 165us/step - loss: 0.0594 - accuracy: 0.9831 - val_loss: 1.4739 - val_accuracy: 0.6234\n",
      "Epoch 568/1000\n",
      "178/178 [==============================] - 0s 197us/step - loss: 0.0625 - accuracy: 0.9831 - val_loss: 1.5094 - val_accuracy: 0.6623\n",
      "Epoch 569/1000\n",
      "178/178 [==============================] - 0s 179us/step - loss: 0.0594 - accuracy: 0.9831 - val_loss: 1.5030 - val_accuracy: 0.6623\n",
      "Epoch 570/1000\n",
      "178/178 [==============================] - 0s 176us/step - loss: 0.0582 - accuracy: 0.9831 - val_loss: 1.4945 - val_accuracy: 0.6494\n",
      "Epoch 571/1000\n",
      "178/178 [==============================] - 0s 163us/step - loss: 0.0582 - accuracy: 0.9831 - val_loss: 1.5011 - val_accuracy: 0.6494\n",
      "Epoch 572/1000\n",
      "178/178 [==============================] - 0s 184us/step - loss: 0.0579 - accuracy: 0.9831 - val_loss: 1.5040 - val_accuracy: 0.6494\n",
      "Epoch 573/1000\n",
      "178/178 [==============================] - 0s 198us/step - loss: 0.0575 - accuracy: 0.9831 - val_loss: 1.5174 - val_accuracy: 0.6623\n",
      "Epoch 574/1000\n",
      "178/178 [==============================] - 0s 161us/step - loss: 0.0660 - accuracy: 0.9775 - val_loss: 1.4879 - val_accuracy: 0.6364\n",
      "Epoch 575/1000\n",
      "178/178 [==============================] - 0s 164us/step - loss: 0.0587 - accuracy: 0.9719 - val_loss: 1.4937 - val_accuracy: 0.6494\n",
      "Epoch 576/1000\n",
      "178/178 [==============================] - 0s 183us/step - loss: 0.0570 - accuracy: 0.9831 - val_loss: 1.5001 - val_accuracy: 0.6494\n",
      "Epoch 577/1000\n",
      "178/178 [==============================] - 0s 172us/step - loss: 0.0552 - accuracy: 0.9831 - val_loss: 1.5162 - val_accuracy: 0.6623\n",
      "Epoch 578/1000\n",
      "178/178 [==============================] - 0s 185us/step - loss: 0.0572 - accuracy: 0.9831 - val_loss: 1.4854 - val_accuracy: 0.6364\n",
      "Epoch 579/1000\n",
      "178/178 [==============================] - 0s 181us/step - loss: 0.0655 - accuracy: 0.9719 - val_loss: 1.5076 - val_accuracy: 0.6494\n",
      "Epoch 580/1000\n",
      "178/178 [==============================] - 0s 165us/step - loss: 0.0575 - accuracy: 0.9831 - val_loss: 1.5031 - val_accuracy: 0.6494\n",
      "Epoch 581/1000\n",
      "178/178 [==============================] - 0s 188us/step - loss: 0.0559 - accuracy: 0.9888 - val_loss: 1.5040 - val_accuracy: 0.6494\n",
      "Epoch 582/1000\n",
      "178/178 [==============================] - 0s 156us/step - loss: 0.0544 - accuracy: 0.9831 - val_loss: 1.5313 - val_accuracy: 0.6623\n",
      "Epoch 583/1000\n",
      "178/178 [==============================] - 0s 181us/step - loss: 0.0565 - accuracy: 0.9831 - val_loss: 1.5060 - val_accuracy: 0.6494\n",
      "Epoch 584/1000\n",
      "178/178 [==============================] - 0s 185us/step - loss: 0.0582 - accuracy: 0.9831 - val_loss: 1.5005 - val_accuracy: 0.6494\n",
      "Epoch 585/1000\n",
      "178/178 [==============================] - 0s 176us/step - loss: 0.0560 - accuracy: 0.9831 - val_loss: 1.4940 - val_accuracy: 0.6494\n",
      "Epoch 586/1000\n",
      "178/178 [==============================] - 0s 192us/step - loss: 0.0649 - accuracy: 0.9775 - val_loss: 1.5193 - val_accuracy: 0.6623\n",
      "Epoch 587/1000\n",
      "178/178 [==============================] - 0s 163us/step - loss: 0.0581 - accuracy: 0.9775 - val_loss: 1.5189 - val_accuracy: 0.6623\n",
      "Epoch 588/1000\n",
      "178/178 [==============================] - 0s 174us/step - loss: 0.0569 - accuracy: 0.9831 - val_loss: 1.4942 - val_accuracy: 0.6494\n",
      "Epoch 589/1000\n",
      "178/178 [==============================] - 0s 190us/step - loss: 0.0559 - accuracy: 0.9831 - val_loss: 1.5023 - val_accuracy: 0.6623\n",
      "Epoch 590/1000\n",
      "178/178 [==============================] - 0s 197us/step - loss: 0.0548 - accuracy: 0.9831 - val_loss: 1.5221 - val_accuracy: 0.6623\n",
      "Epoch 591/1000\n",
      "178/178 [==============================] - 0s 200us/step - loss: 0.0636 - accuracy: 0.9775 - val_loss: 1.5577 - val_accuracy: 0.6494\n",
      "Epoch 592/1000\n",
      "178/178 [==============================] - 0s 175us/step - loss: 0.0630 - accuracy: 0.9775 - val_loss: 1.5384 - val_accuracy: 0.6494\n",
      "Epoch 593/1000\n",
      "178/178 [==============================] - 0s 179us/step - loss: 0.0540 - accuracy: 0.9831 - val_loss: 1.5161 - val_accuracy: 0.6494\n",
      "Epoch 594/1000\n",
      "178/178 [==============================] - 0s 177us/step - loss: 0.0540 - accuracy: 0.9888 - val_loss: 1.5276 - val_accuracy: 0.6623\n",
      "Epoch 595/1000\n",
      "178/178 [==============================] - 0s 182us/step - loss: 0.0557 - accuracy: 0.9831 - val_loss: 1.5446 - val_accuracy: 0.6623\n",
      "Epoch 596/1000\n",
      "178/178 [==============================] - 0s 208us/step - loss: 0.0548 - accuracy: 0.9831 - val_loss: 1.5058 - val_accuracy: 0.6494\n",
      "Epoch 597/1000\n",
      "178/178 [==============================] - 0s 158us/step - loss: 0.0580 - accuracy: 0.9775 - val_loss: 1.5061 - val_accuracy: 0.6364\n",
      "Epoch 598/1000\n",
      "178/178 [==============================] - 0s 180us/step - loss: 0.0560 - accuracy: 0.9831 - val_loss: 1.5260 - val_accuracy: 0.6753\n",
      "Epoch 599/1000\n",
      "178/178 [==============================] - 0s 185us/step - loss: 0.0552 - accuracy: 0.9944 - val_loss: 1.5270 - val_accuracy: 0.6494\n",
      "Epoch 600/1000\n",
      "178/178 [==============================] - 0s 176us/step - loss: 0.0589 - accuracy: 0.9775 - val_loss: 1.5363 - val_accuracy: 0.6623\n",
      "Epoch 601/1000\n",
      "178/178 [==============================] - 0s 165us/step - loss: 0.0574 - accuracy: 0.9775 - val_loss: 1.5326 - val_accuracy: 0.6494\n",
      "Epoch 602/1000\n",
      "178/178 [==============================] - 0s 184us/step - loss: 0.0563 - accuracy: 0.9831 - val_loss: 1.5082 - val_accuracy: 0.6494\n",
      "Epoch 603/1000\n",
      "178/178 [==============================] - 0s 174us/step - loss: 0.0632 - accuracy: 0.9831 - val_loss: 1.6019 - val_accuracy: 0.6494\n",
      "Epoch 604/1000\n",
      "178/178 [==============================] - 0s 161us/step - loss: 0.0689 - accuracy: 0.9775 - val_loss: 1.5426 - val_accuracy: 0.6623\n",
      "Epoch 605/1000\n",
      "178/178 [==============================] - 0s 198us/step - loss: 0.0528 - accuracy: 0.9831 - val_loss: 1.5397 - val_accuracy: 0.6623\n",
      "Epoch 606/1000\n",
      "178/178 [==============================] - 0s 178us/step - loss: 0.0533 - accuracy: 0.9831 - val_loss: 1.5150 - val_accuracy: 0.6494\n",
      "Epoch 607/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 166us/step - loss: 0.0556 - accuracy: 0.9944 - val_loss: 1.5736 - val_accuracy: 0.6494\n",
      "Epoch 608/1000\n",
      "178/178 [==============================] - 0s 161us/step - loss: 0.0571 - accuracy: 0.9831 - val_loss: 1.5535 - val_accuracy: 0.6623\n",
      "Epoch 609/1000\n",
      "178/178 [==============================] - 0s 178us/step - loss: 0.0569 - accuracy: 0.9775 - val_loss: 1.5515 - val_accuracy: 0.6494\n",
      "Epoch 610/1000\n",
      "178/178 [==============================] - 0s 190us/step - loss: 0.0548 - accuracy: 0.9831 - val_loss: 1.5572 - val_accuracy: 0.6623\n",
      "Epoch 611/1000\n",
      "178/178 [==============================] - 0s 179us/step - loss: 0.0588 - accuracy: 0.9831 - val_loss: 1.5544 - val_accuracy: 0.6753\n",
      "Epoch 612/1000\n",
      "178/178 [==============================] - 0s 167us/step - loss: 0.0529 - accuracy: 0.9888 - val_loss: 1.5152 - val_accuracy: 0.6494\n",
      "Epoch 613/1000\n",
      "178/178 [==============================] - 0s 180us/step - loss: 0.0624 - accuracy: 0.9719 - val_loss: 1.5463 - val_accuracy: 0.6753\n",
      "Epoch 614/1000\n",
      "178/178 [==============================] - 0s 164us/step - loss: 0.0619 - accuracy: 0.9775 - val_loss: 1.5556 - val_accuracy: 0.6623\n",
      "Epoch 615/1000\n",
      "178/178 [==============================] - 0s 248us/step - loss: 0.0550 - accuracy: 0.9831 - val_loss: 1.5573 - val_accuracy: 0.6753\n",
      "Epoch 616/1000\n",
      "178/178 [==============================] - 0s 262us/step - loss: 0.0589 - accuracy: 0.9888 - val_loss: 1.5764 - val_accuracy: 0.6623\n",
      "Epoch 617/1000\n",
      "178/178 [==============================] - 0s 182us/step - loss: 0.0554 - accuracy: 0.9831 - val_loss: 1.5280 - val_accuracy: 0.6623\n",
      "Epoch 618/1000\n",
      "178/178 [==============================] - 0s 191us/step - loss: 0.0537 - accuracy: 0.9831 - val_loss: 1.5513 - val_accuracy: 0.6623\n",
      "Epoch 619/1000\n",
      "178/178 [==============================] - 0s 201us/step - loss: 0.0520 - accuracy: 0.9944 - val_loss: 1.5458 - val_accuracy: 0.6494\n",
      "Epoch 620/1000\n",
      "178/178 [==============================] - 0s 150us/step - loss: 0.0526 - accuracy: 0.9831 - val_loss: 1.5342 - val_accuracy: 0.6364\n",
      "Epoch 621/1000\n",
      "178/178 [==============================] - 0s 176us/step - loss: 0.0538 - accuracy: 0.9888 - val_loss: 1.5435 - val_accuracy: 0.6623\n",
      "Epoch 622/1000\n",
      "178/178 [==============================] - 0s 170us/step - loss: 0.0511 - accuracy: 0.9831 - val_loss: 1.5508 - val_accuracy: 0.6623\n",
      "Epoch 623/1000\n",
      "178/178 [==============================] - 0s 194us/step - loss: 0.0524 - accuracy: 0.9831 - val_loss: 1.5468 - val_accuracy: 0.6494\n",
      "Epoch 624/1000\n",
      "178/178 [==============================] - 0s 163us/step - loss: 0.0496 - accuracy: 0.9831 - val_loss: 1.5592 - val_accuracy: 0.6623\n",
      "Epoch 625/1000\n",
      "178/178 [==============================] - 0s 167us/step - loss: 0.0517 - accuracy: 0.9888 - val_loss: 1.5786 - val_accuracy: 0.6753\n",
      "Epoch 626/1000\n",
      "178/178 [==============================] - 0s 200us/step - loss: 0.0574 - accuracy: 0.9831 - val_loss: 1.5780 - val_accuracy: 0.6753\n",
      "Epoch 627/1000\n",
      "178/178 [==============================] - 0s 157us/step - loss: 0.0506 - accuracy: 0.9831 - val_loss: 1.5536 - val_accuracy: 0.6494\n",
      "Epoch 628/1000\n",
      "178/178 [==============================] - 0s 166us/step - loss: 0.0622 - accuracy: 0.9831 - val_loss: 1.5408 - val_accuracy: 0.6494\n",
      "Epoch 629/1000\n",
      "178/178 [==============================] - 0s 194us/step - loss: 0.0552 - accuracy: 0.9831 - val_loss: 1.5770 - val_accuracy: 0.6753\n",
      "Epoch 630/1000\n",
      "178/178 [==============================] - 0s 181us/step - loss: 0.0529 - accuracy: 0.9831 - val_loss: 1.5965 - val_accuracy: 0.6494\n",
      "Epoch 631/1000\n",
      "178/178 [==============================] - 0s 151us/step - loss: 0.0532 - accuracy: 0.9831 - val_loss: 1.5445 - val_accuracy: 0.6364\n",
      "Epoch 632/1000\n",
      "178/178 [==============================] - 0s 207us/step - loss: 0.0600 - accuracy: 0.9775 - val_loss: 1.5682 - val_accuracy: 0.6623\n",
      "Epoch 633/1000\n",
      "178/178 [==============================] - 0s 162us/step - loss: 0.0496 - accuracy: 0.9831 - val_loss: 1.5695 - val_accuracy: 0.6623\n",
      "Epoch 634/1000\n",
      "178/178 [==============================] - 0s 164us/step - loss: 0.0519 - accuracy: 0.9831 - val_loss: 1.5423 - val_accuracy: 0.6494\n",
      "Epoch 635/1000\n",
      "178/178 [==============================] - 0s 196us/step - loss: 0.0509 - accuracy: 0.9888 - val_loss: 1.5731 - val_accuracy: 0.6623\n",
      "Epoch 636/1000\n",
      "178/178 [==============================] - 0s 152us/step - loss: 0.0512 - accuracy: 0.9831 - val_loss: 1.5859 - val_accuracy: 0.6494\n",
      "Epoch 637/1000\n",
      "178/178 [==============================] - 0s 182us/step - loss: 0.0508 - accuracy: 0.9888 - val_loss: 1.5837 - val_accuracy: 0.6623\n",
      "Epoch 638/1000\n",
      "178/178 [==============================] - 0s 176us/step - loss: 0.0521 - accuracy: 0.9831 - val_loss: 1.5647 - val_accuracy: 0.6494\n",
      "Epoch 639/1000\n",
      "178/178 [==============================] - 0s 197us/step - loss: 0.0499 - accuracy: 0.9831 - val_loss: 1.5705 - val_accuracy: 0.6623\n",
      "Epoch 640/1000\n",
      "178/178 [==============================] - 0s 167us/step - loss: 0.0499 - accuracy: 0.9944 - val_loss: 1.5832 - val_accuracy: 0.6623\n",
      "Epoch 641/1000\n",
      "178/178 [==============================] - 0s 173us/step - loss: 0.0496 - accuracy: 0.9831 - val_loss: 1.5799 - val_accuracy: 0.6623\n",
      "Epoch 642/1000\n",
      "178/178 [==============================] - 0s 176us/step - loss: 0.0506 - accuracy: 0.9831 - val_loss: 1.5882 - val_accuracy: 0.6623\n",
      "Epoch 643/1000\n",
      "178/178 [==============================] - 0s 163us/step - loss: 0.0500 - accuracy: 0.9831 - val_loss: 1.5643 - val_accuracy: 0.6494\n",
      "Epoch 644/1000\n",
      "178/178 [==============================] - 0s 197us/step - loss: 0.0545 - accuracy: 0.9831 - val_loss: 1.5754 - val_accuracy: 0.6623\n",
      "Epoch 645/1000\n",
      "178/178 [==============================] - 0s 152us/step - loss: 0.0538 - accuracy: 0.9719 - val_loss: 1.6430 - val_accuracy: 0.6494\n",
      "Epoch 646/1000\n",
      "178/178 [==============================] - 0s 187us/step - loss: 0.0556 - accuracy: 0.9831 - val_loss: 1.5780 - val_accuracy: 0.6623\n",
      "Epoch 647/1000\n",
      "178/178 [==============================] - 0s 193us/step - loss: 0.0487 - accuracy: 0.9831 - val_loss: 1.5575 - val_accuracy: 0.6494\n",
      "Epoch 648/1000\n",
      "178/178 [==============================] - 0s 163us/step - loss: 0.0503 - accuracy: 0.9831 - val_loss: 1.5600 - val_accuracy: 0.6494\n",
      "Epoch 649/1000\n",
      "178/178 [==============================] - 0s 185us/step - loss: 0.0567 - accuracy: 0.9888 - val_loss: 1.5892 - val_accuracy: 0.6623\n",
      "Epoch 650/1000\n",
      "178/178 [==============================] - 0s 156us/step - loss: 0.0544 - accuracy: 0.9775 - val_loss: 1.6059 - val_accuracy: 0.6623\n",
      "Epoch 651/1000\n",
      "178/178 [==============================] - 0s 202us/step - loss: 0.0494 - accuracy: 0.9831 - val_loss: 1.5709 - val_accuracy: 0.6494\n",
      "Epoch 652/1000\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0423 - accuracy: 0.98 - 0s 170us/step - loss: 0.0479 - accuracy: 0.9831 - val_loss: 1.5996 - val_accuracy: 0.6623\n",
      "Epoch 653/1000\n",
      "178/178 [==============================] - 0s 180us/step - loss: 0.0509 - accuracy: 0.9831 - val_loss: 1.5807 - val_accuracy: 0.6494\n",
      "Epoch 654/1000\n",
      "178/178 [==============================] - 0s 183us/step - loss: 0.0477 - accuracy: 0.9831 - val_loss: 1.5871 - val_accuracy: 0.6623\n",
      "Epoch 655/1000\n",
      "178/178 [==============================] - 0s 164us/step - loss: 0.0524 - accuracy: 0.9831 - val_loss: 1.6139 - val_accuracy: 0.6623\n",
      "Epoch 656/1000\n",
      "178/178 [==============================] - 0s 186us/step - loss: 0.0497 - accuracy: 0.9888 - val_loss: 1.5799 - val_accuracy: 0.6494\n",
      "Epoch 657/1000\n",
      "178/178 [==============================] - 0s 166us/step - loss: 0.0518 - accuracy: 0.9775 - val_loss: 1.5943 - val_accuracy: 0.6623\n",
      "Epoch 658/1000\n",
      "178/178 [==============================] - 0s 185us/step - loss: 0.0515 - accuracy: 0.9775 - val_loss: 1.6096 - val_accuracy: 0.6623\n",
      "Epoch 659/1000\n",
      "178/178 [==============================] - 0s 168us/step - loss: 0.0530 - accuracy: 0.9775 - val_loss: 1.6079 - val_accuracy: 0.6494\n",
      "Epoch 660/1000\n",
      "178/178 [==============================] - 0s 183us/step - loss: 0.0527 - accuracy: 0.9775 - val_loss: 1.6096 - val_accuracy: 0.6494\n",
      "Epoch 661/1000\n",
      "178/178 [==============================] - 0s 170us/step - loss: 0.0517 - accuracy: 0.9831 - val_loss: 1.6090 - val_accuracy: 0.6623\n",
      "Epoch 662/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 185us/step - loss: 0.0532 - accuracy: 0.9775 - val_loss: 1.6331 - val_accuracy: 0.6623\n",
      "Epoch 663/1000\n",
      "178/178 [==============================] - 0s 160us/step - loss: 0.0590 - accuracy: 0.9775 - val_loss: 1.6107 - val_accuracy: 0.6623\n",
      "Epoch 664/1000\n",
      "178/178 [==============================] - 0s 198us/step - loss: 0.0482 - accuracy: 0.9831 - val_loss: 1.5879 - val_accuracy: 0.6494\n",
      "Epoch 665/1000\n",
      "178/178 [==============================] - 0s 180us/step - loss: 0.0513 - accuracy: 0.9775 - val_loss: 1.6246 - val_accuracy: 0.6623\n",
      "Epoch 666/1000\n",
      "178/178 [==============================] - 0s 147us/step - loss: 0.0541 - accuracy: 0.9831 - val_loss: 1.6230 - val_accuracy: 0.6753\n",
      "Epoch 667/1000\n",
      "178/178 [==============================] - 0s 180us/step - loss: 0.0525 - accuracy: 0.9831 - val_loss: 1.5708 - val_accuracy: 0.6494\n",
      "Epoch 668/1000\n",
      "178/178 [==============================] - 0s 195us/step - loss: 0.0542 - accuracy: 0.9888 - val_loss: 1.5674 - val_accuracy: 0.6494\n",
      "Epoch 669/1000\n",
      "178/178 [==============================] - 0s 160us/step - loss: 0.0458 - accuracy: 0.9944 - val_loss: 1.6229 - val_accuracy: 0.6623\n",
      "Epoch 670/1000\n",
      "178/178 [==============================] - 0s 181us/step - loss: 0.0502 - accuracy: 0.9831 - val_loss: 1.5875 - val_accuracy: 0.6623\n",
      "Epoch 671/1000\n",
      "178/178 [==============================] - 0s 166us/step - loss: 0.0503 - accuracy: 0.9831 - val_loss: 1.5806 - val_accuracy: 0.6623\n",
      "Epoch 672/1000\n",
      "178/178 [==============================] - 0s 214us/step - loss: 0.0465 - accuracy: 0.9831 - val_loss: 1.6255 - val_accuracy: 0.6623\n",
      "Epoch 673/1000\n",
      "178/178 [==============================] - 0s 185us/step - loss: 0.0474 - accuracy: 0.9888 - val_loss: 1.6035 - val_accuracy: 0.6623\n",
      "Epoch 674/1000\n",
      "178/178 [==============================] - 0s 185us/step - loss: 0.0488 - accuracy: 0.9831 - val_loss: 1.6088 - val_accuracy: 0.6623\n",
      "Epoch 675/1000\n",
      "178/178 [==============================] - 0s 193us/step - loss: 0.0538 - accuracy: 0.9775 - val_loss: 1.6530 - val_accuracy: 0.6494\n",
      "Epoch 676/1000\n",
      "178/178 [==============================] - 0s 175us/step - loss: 0.0503 - accuracy: 0.9831 - val_loss: 1.6314 - val_accuracy: 0.6623\n",
      "Epoch 677/1000\n",
      "178/178 [==============================] - 0s 173us/step - loss: 0.0489 - accuracy: 0.9831 - val_loss: 1.6183 - val_accuracy: 0.6623\n",
      "Epoch 678/1000\n",
      "178/178 [==============================] - 0s 176us/step - loss: 0.0500 - accuracy: 0.9831 - val_loss: 1.6100 - val_accuracy: 0.6623\n",
      "Epoch 679/1000\n",
      "178/178 [==============================] - 0s 198us/step - loss: 0.0486 - accuracy: 0.9775 - val_loss: 1.6220 - val_accuracy: 0.6623\n",
      "Epoch 680/1000\n",
      "178/178 [==============================] - 0s 165us/step - loss: 0.0472 - accuracy: 0.9831 - val_loss: 1.6102 - val_accuracy: 0.6623\n",
      "Epoch 681/1000\n",
      "178/178 [==============================] - 0s 202us/step - loss: 0.0452 - accuracy: 0.9831 - val_loss: 1.6080 - val_accuracy: 0.6623\n",
      "Epoch 682/1000\n",
      "178/178 [==============================] - 0s 150us/step - loss: 0.0474 - accuracy: 0.9888 - val_loss: 1.6205 - val_accuracy: 0.6623\n",
      "Epoch 683/1000\n",
      "178/178 [==============================] - 0s 182us/step - loss: 0.0517 - accuracy: 0.9831 - val_loss: 1.6352 - val_accuracy: 0.6623\n",
      "Epoch 684/1000\n",
      "178/178 [==============================] - 0s 172us/step - loss: 0.0494 - accuracy: 0.9831 - val_loss: 1.6386 - val_accuracy: 0.6623\n",
      "Epoch 685/1000\n",
      "178/178 [==============================] - 0s 182us/step - loss: 0.0510 - accuracy: 0.9831 - val_loss: 1.6306 - val_accuracy: 0.6753\n",
      "Epoch 686/1000\n",
      "178/178 [==============================] - 0s 197us/step - loss: 0.0490 - accuracy: 0.9831 - val_loss: 1.6323 - val_accuracy: 0.6623\n",
      "Epoch 687/1000\n",
      "178/178 [==============================] - 0s 160us/step - loss: 0.0531 - accuracy: 0.9831 - val_loss: 1.6373 - val_accuracy: 0.6753\n",
      "Epoch 688/1000\n",
      "178/178 [==============================] - 0s 174us/step - loss: 0.0486 - accuracy: 0.9775 - val_loss: 1.6319 - val_accuracy: 0.6623\n",
      "Epoch 689/1000\n",
      "178/178 [==============================] - 0s 161us/step - loss: 0.0450 - accuracy: 0.9831 - val_loss: 1.6169 - val_accuracy: 0.6494\n",
      "Epoch 690/1000\n",
      "178/178 [==============================] - 0s 176us/step - loss: 0.0485 - accuracy: 0.9831 - val_loss: 1.5993 - val_accuracy: 0.6494\n",
      "Epoch 691/1000\n",
      "178/178 [==============================] - 0s 205us/step - loss: 0.0532 - accuracy: 0.9888 - val_loss: 1.6255 - val_accuracy: 0.6494\n",
      "Epoch 692/1000\n",
      "178/178 [==============================] - 0s 176us/step - loss: 0.0479 - accuracy: 0.9831 - val_loss: 1.5999 - val_accuracy: 0.6494\n",
      "Epoch 693/1000\n",
      "178/178 [==============================] - 0s 183us/step - loss: 0.0446 - accuracy: 1.0000 - val_loss: 1.6404 - val_accuracy: 0.6623\n",
      "Epoch 694/1000\n",
      "178/178 [==============================] - 0s 166us/step - loss: 0.0500 - accuracy: 0.9831 - val_loss: 1.6018 - val_accuracy: 0.6494\n",
      "Epoch 695/1000\n",
      "178/178 [==============================] - 0s 164us/step - loss: 0.0518 - accuracy: 0.9831 - val_loss: 1.6043 - val_accuracy: 0.6364\n",
      "Epoch 696/1000\n",
      "178/178 [==============================] - 0s 160us/step - loss: 0.0526 - accuracy: 0.9944 - val_loss: 1.6239 - val_accuracy: 0.6494\n",
      "Epoch 697/1000\n",
      "178/178 [==============================] - 0s 199us/step - loss: 0.0499 - accuracy: 0.9831 - val_loss: 1.6255 - val_accuracy: 0.6494\n",
      "Epoch 698/1000\n",
      "178/178 [==============================] - 0s 177us/step - loss: 0.0519 - accuracy: 0.9831 - val_loss: 1.6725 - val_accuracy: 0.6494\n",
      "Epoch 699/1000\n",
      "178/178 [==============================] - 0s 181us/step - loss: 0.0482 - accuracy: 0.9831 - val_loss: 1.6511 - val_accuracy: 0.6623\n",
      "Epoch 700/1000\n",
      "178/178 [==============================] - 0s 182us/step - loss: 0.0490 - accuracy: 0.9831 - val_loss: 1.6393 - val_accuracy: 0.6753\n",
      "Epoch 701/1000\n",
      "178/178 [==============================] - 0s 173us/step - loss: 0.0463 - accuracy: 0.9831 - val_loss: 1.6259 - val_accuracy: 0.6753\n",
      "Epoch 702/1000\n",
      "178/178 [==============================] - 0s 168us/step - loss: 0.0487 - accuracy: 0.9775 - val_loss: 1.6399 - val_accuracy: 0.6753\n",
      "Epoch 703/1000\n",
      "178/178 [==============================] - 0s 161us/step - loss: 0.0472 - accuracy: 0.9944 - val_loss: 1.6328 - val_accuracy: 0.6623\n",
      "Epoch 704/1000\n",
      "178/178 [==============================] - 0s 178us/step - loss: 0.0452 - accuracy: 0.9831 - val_loss: 1.6253 - val_accuracy: 0.6494\n",
      "Epoch 705/1000\n",
      "178/178 [==============================] - 0s 178us/step - loss: 0.0455 - accuracy: 0.9831 - val_loss: 1.6781 - val_accuracy: 0.6623\n",
      "Epoch 706/1000\n",
      "178/178 [==============================] - 0s 312us/step - loss: 0.0459 - accuracy: 0.9831 - val_loss: 1.6157 - val_accuracy: 0.6364\n",
      "Epoch 707/1000\n",
      "178/178 [==============================] - 0s 509us/step - loss: 0.0503 - accuracy: 0.9775 - val_loss: 1.6199 - val_accuracy: 0.6364\n",
      "Epoch 708/1000\n",
      "178/178 [==============================] - 0s 374us/step - loss: 0.0466 - accuracy: 0.9888 - val_loss: 1.6330 - val_accuracy: 0.6623\n",
      "Epoch 709/1000\n",
      "178/178 [==============================] - 0s 231us/step - loss: 0.0483 - accuracy: 0.9888 - val_loss: 1.6384 - val_accuracy: 0.6623\n",
      "Epoch 710/1000\n",
      "178/178 [==============================] - 0s 290us/step - loss: 0.0436 - accuracy: 0.9888 - val_loss: 1.6574 - val_accuracy: 0.6753\n",
      "Epoch 711/1000\n",
      "178/178 [==============================] - 0s 271us/step - loss: 0.0560 - accuracy: 0.9775 - val_loss: 1.6412 - val_accuracy: 0.6494\n",
      "Epoch 712/1000\n",
      "178/178 [==============================] - 0s 868us/step - loss: 0.0508 - accuracy: 0.9775 - val_loss: 1.6444 - val_accuracy: 0.6494\n",
      "Epoch 713/1000\n",
      "178/178 [==============================] - 0s 319us/step - loss: 0.0432 - accuracy: 0.9888 - val_loss: 1.6415 - val_accuracy: 0.6494\n",
      "Epoch 714/1000\n",
      "178/178 [==============================] - 0s 261us/step - loss: 0.0470 - accuracy: 0.9831 - val_loss: 1.6175 - val_accuracy: 0.6234\n",
      "Epoch 715/1000\n",
      "178/178 [==============================] - 0s 247us/step - loss: 0.0510 - accuracy: 0.9831 - val_loss: 1.6425 - val_accuracy: 0.6494\n",
      "Epoch 716/1000\n",
      "178/178 [==============================] - 0s 199us/step - loss: 0.0452 - accuracy: 0.9831 - val_loss: 1.6411 - val_accuracy: 0.6494\n",
      "Epoch 717/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 187us/step - loss: 0.0448 - accuracy: 0.9888 - val_loss: 1.6351 - val_accuracy: 0.6494\n",
      "Epoch 718/1000\n",
      "178/178 [==============================] - 0s 167us/step - loss: 0.0435 - accuracy: 0.9888 - val_loss: 1.6631 - val_accuracy: 0.6623\n",
      "Epoch 719/1000\n",
      "178/178 [==============================] - 0s 182us/step - loss: 0.0466 - accuracy: 0.9831 - val_loss: 1.6713 - val_accuracy: 0.6623\n",
      "Epoch 720/1000\n",
      "178/178 [==============================] - 0s 185us/step - loss: 0.0478 - accuracy: 0.9831 - val_loss: 1.6441 - val_accuracy: 0.6494\n",
      "Epoch 721/1000\n",
      "178/178 [==============================] - 0s 163us/step - loss: 0.0480 - accuracy: 0.9888 - val_loss: 1.6777 - val_accuracy: 0.6623\n",
      "Epoch 722/1000\n",
      "178/178 [==============================] - 0s 168us/step - loss: 0.0500 - accuracy: 0.9831 - val_loss: 1.6977 - val_accuracy: 0.6623\n",
      "Epoch 723/1000\n",
      "178/178 [==============================] - 0s 175us/step - loss: 0.0470 - accuracy: 0.9831 - val_loss: 1.6472 - val_accuracy: 0.6494\n",
      "Epoch 724/1000\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0434 - accuracy: 0.98 - 0s 205us/step - loss: 0.0433 - accuracy: 0.9831 - val_loss: 1.6532 - val_accuracy: 0.6494\n",
      "Epoch 725/1000\n",
      "178/178 [==============================] - 0s 168us/step - loss: 0.0429 - accuracy: 0.9831 - val_loss: 1.6318 - val_accuracy: 0.6364\n",
      "Epoch 726/1000\n",
      "178/178 [==============================] - 0s 147us/step - loss: 0.0513 - accuracy: 0.9831 - val_loss: 1.6628 - val_accuracy: 0.6623\n",
      "Epoch 727/1000\n",
      "178/178 [==============================] - 0s 184us/step - loss: 0.0424 - accuracy: 0.9831 - val_loss: 1.6740 - val_accuracy: 0.6753\n",
      "Epoch 728/1000\n",
      "178/178 [==============================] - 0s 199us/step - loss: 0.0435 - accuracy: 0.9831 - val_loss: 1.6506 - val_accuracy: 0.6494\n",
      "Epoch 729/1000\n",
      "178/178 [==============================] - 0s 179us/step - loss: 0.0445 - accuracy: 0.9831 - val_loss: 1.6610 - val_accuracy: 0.6494\n",
      "Epoch 730/1000\n",
      "178/178 [==============================] - 0s 173us/step - loss: 0.0418 - accuracy: 0.9831 - val_loss: 1.6614 - val_accuracy: 0.6623\n",
      "Epoch 731/1000\n",
      "178/178 [==============================] - 0s 174us/step - loss: 0.0421 - accuracy: 0.9831 - val_loss: 1.6409 - val_accuracy: 0.6364\n",
      "Epoch 732/1000\n",
      "178/178 [==============================] - 0s 153us/step - loss: 0.0415 - accuracy: 0.9888 - val_loss: 1.6725 - val_accuracy: 0.6623\n",
      "Epoch 733/1000\n",
      "178/178 [==============================] - 0s 167us/step - loss: 0.0443 - accuracy: 0.9831 - val_loss: 1.6524 - val_accuracy: 0.6623\n",
      "Epoch 734/1000\n",
      "178/178 [==============================] - 0s 180us/step - loss: 0.0416 - accuracy: 0.9944 - val_loss: 1.6594 - val_accuracy: 0.6494\n",
      "Epoch 735/1000\n",
      "178/178 [==============================] - 0s 188us/step - loss: 0.0421 - accuracy: 0.9831 - val_loss: 1.6602 - val_accuracy: 0.6494\n",
      "Epoch 736/1000\n",
      "178/178 [==============================] - 0s 203us/step - loss: 0.0420 - accuracy: 0.9831 - val_loss: 1.6797 - val_accuracy: 0.6753\n",
      "Epoch 737/1000\n",
      "178/178 [==============================] - 0s 180us/step - loss: 0.0413 - accuracy: 0.9888 - val_loss: 1.6473 - val_accuracy: 0.6364\n",
      "Epoch 738/1000\n",
      "178/178 [==============================] - 0s 165us/step - loss: 0.0439 - accuracy: 0.9831 - val_loss: 1.6652 - val_accuracy: 0.6753\n",
      "Epoch 739/1000\n",
      "178/178 [==============================] - 0s 167us/step - loss: 0.0436 - accuracy: 0.9888 - val_loss: 1.6592 - val_accuracy: 0.6623\n",
      "Epoch 740/1000\n",
      "178/178 [==============================] - 0s 165us/step - loss: 0.0404 - accuracy: 0.9944 - val_loss: 1.6625 - val_accuracy: 0.6623\n",
      "Epoch 741/1000\n",
      "178/178 [==============================] - 0s 181us/step - loss: 0.0482 - accuracy: 0.9775 - val_loss: 1.6964 - val_accuracy: 0.6623\n",
      "Epoch 742/1000\n",
      "178/178 [==============================] - 0s 168us/step - loss: 0.0487 - accuracy: 0.9775 - val_loss: 1.6848 - val_accuracy: 0.6623\n",
      "Epoch 743/1000\n",
      "178/178 [==============================] - 0s 201us/step - loss: 0.0424 - accuracy: 0.9831 - val_loss: 1.6716 - val_accuracy: 0.6623\n",
      "Epoch 744/1000\n",
      "178/178 [==============================] - 0s 175us/step - loss: 0.0462 - accuracy: 0.9775 - val_loss: 1.7049 - val_accuracy: 0.6623\n",
      "Epoch 745/1000\n",
      "178/178 [==============================] - 0s 163us/step - loss: 0.0484 - accuracy: 0.9831 - val_loss: 1.6807 - val_accuracy: 0.6623\n",
      "Epoch 746/1000\n",
      "178/178 [==============================] - 0s 160us/step - loss: 0.0458 - accuracy: 0.9831 - val_loss: 1.6498 - val_accuracy: 0.6364\n",
      "Epoch 747/1000\n",
      "178/178 [==============================] - 0s 178us/step - loss: 0.0421 - accuracy: 1.0000 - val_loss: 1.6965 - val_accuracy: 0.6623\n",
      "Epoch 748/1000\n",
      "178/178 [==============================] - 0s 175us/step - loss: 0.0418 - accuracy: 0.9831 - val_loss: 1.6666 - val_accuracy: 0.6623\n",
      "Epoch 749/1000\n",
      "178/178 [==============================] - 0s 173us/step - loss: 0.0399 - accuracy: 0.9944 - val_loss: 1.6860 - val_accuracy: 0.6753\n",
      "Epoch 750/1000\n",
      "178/178 [==============================] - 0s 172us/step - loss: 0.0435 - accuracy: 0.9831 - val_loss: 1.6801 - val_accuracy: 0.6623\n",
      "Epoch 751/1000\n",
      "178/178 [==============================] - 0s 177us/step - loss: 0.0405 - accuracy: 0.9831 - val_loss: 1.6499 - val_accuracy: 0.6494\n",
      "Epoch 752/1000\n",
      "178/178 [==============================] - 0s 207us/step - loss: 0.0444 - accuracy: 0.9888 - val_loss: 1.6827 - val_accuracy: 0.6623\n",
      "Epoch 753/1000\n",
      "178/178 [==============================] - 0s 153us/step - loss: 0.0435 - accuracy: 0.9775 - val_loss: 1.6969 - val_accuracy: 0.6753\n",
      "Epoch 754/1000\n",
      "178/178 [==============================] - 0s 164us/step - loss: 0.0465 - accuracy: 0.9831 - val_loss: 1.6913 - val_accuracy: 0.6623\n",
      "Epoch 755/1000\n",
      "178/178 [==============================] - 0s 171us/step - loss: 0.0458 - accuracy: 0.9831 - val_loss: 1.7066 - val_accuracy: 0.6623\n",
      "Epoch 756/1000\n",
      "178/178 [==============================] - 0s 186us/step - loss: 0.0411 - accuracy: 0.9831 - val_loss: 1.6690 - val_accuracy: 0.6364\n",
      "Epoch 757/1000\n",
      "178/178 [==============================] - 0s 163us/step - loss: 0.0420 - accuracy: 0.9831 - val_loss: 1.6689 - val_accuracy: 0.6623\n",
      "Epoch 758/1000\n",
      "178/178 [==============================] - 0s 197us/step - loss: 0.0402 - accuracy: 0.9944 - val_loss: 1.6801 - val_accuracy: 0.6494\n",
      "Epoch 759/1000\n",
      "178/178 [==============================] - 0s 164us/step - loss: 0.0459 - accuracy: 0.9888 - val_loss: 1.6676 - val_accuracy: 0.6234\n",
      "Epoch 760/1000\n",
      "178/178 [==============================] - 0s 175us/step - loss: 0.0461 - accuracy: 0.9831 - val_loss: 1.6676 - val_accuracy: 0.6494\n",
      "Epoch 761/1000\n",
      "178/178 [==============================] - 0s 164us/step - loss: 0.0399 - accuracy: 0.9944 - val_loss: 1.6903 - val_accuracy: 0.6623\n",
      "Epoch 762/1000\n",
      "178/178 [==============================] - 0s 199us/step - loss: 0.0395 - accuracy: 0.9944 - val_loss: 1.6959 - val_accuracy: 0.6623\n",
      "Epoch 763/1000\n",
      "178/178 [==============================] - 0s 152us/step - loss: 0.0415 - accuracy: 0.9831 - val_loss: 1.6669 - val_accuracy: 0.6364\n",
      "Epoch 764/1000\n",
      "178/178 [==============================] - 0s 185us/step - loss: 0.0490 - accuracy: 0.9775 - val_loss: 1.7473 - val_accuracy: 0.6494\n",
      "Epoch 765/1000\n",
      "178/178 [==============================] - 0s 169us/step - loss: 0.0461 - accuracy: 0.9944 - val_loss: 1.6949 - val_accuracy: 0.6623\n",
      "Epoch 766/1000\n",
      "178/178 [==============================] - 0s 193us/step - loss: 0.0422 - accuracy: 0.9831 - val_loss: 1.6925 - val_accuracy: 0.6623\n",
      "Epoch 767/1000\n",
      "178/178 [==============================] - 0s 170us/step - loss: 0.0402 - accuracy: 0.9831 - val_loss: 1.6880 - val_accuracy: 0.6753\n",
      "Epoch 768/1000\n",
      "178/178 [==============================] - 0s 172us/step - loss: 0.0406 - accuracy: 0.9944 - val_loss: 1.6867 - val_accuracy: 0.6623\n",
      "Epoch 769/1000\n",
      "178/178 [==============================] - 0s 175us/step - loss: 0.0420 - accuracy: 0.9944 - val_loss: 1.7033 - val_accuracy: 0.6623\n",
      "Epoch 770/1000\n",
      "178/178 [==============================] - 0s 163us/step - loss: 0.0420 - accuracy: 0.9831 - val_loss: 1.7058 - val_accuracy: 0.6753\n",
      "Epoch 771/1000\n",
      "178/178 [==============================] - 0s 179us/step - loss: 0.0438 - accuracy: 0.9831 - val_loss: 1.7127 - val_accuracy: 0.6753\n",
      "Epoch 772/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 202us/step - loss: 0.0435 - accuracy: 0.9888 - val_loss: 1.7169 - val_accuracy: 0.6753\n",
      "Epoch 773/1000\n",
      "178/178 [==============================] - 0s 152us/step - loss: 0.0440 - accuracy: 0.9831 - val_loss: 1.6994 - val_accuracy: 0.6623\n",
      "Epoch 774/1000\n",
      "178/178 [==============================] - 0s 174us/step - loss: 0.0397 - accuracy: 0.9831 - val_loss: 1.6738 - val_accuracy: 0.6494\n",
      "Epoch 775/1000\n",
      "178/178 [==============================] - 0s 180us/step - loss: 0.0519 - accuracy: 0.9775 - val_loss: 1.6911 - val_accuracy: 0.6753\n",
      "Epoch 776/1000\n",
      "178/178 [==============================] - 0s 199us/step - loss: 0.0396 - accuracy: 0.9831 - val_loss: 1.6741 - val_accuracy: 0.6494\n",
      "Epoch 777/1000\n",
      "178/178 [==============================] - 0s 172us/step - loss: 0.0455 - accuracy: 0.9831 - val_loss: 1.6957 - val_accuracy: 0.6623\n",
      "Epoch 778/1000\n",
      "178/178 [==============================] - 0s 163us/step - loss: 0.0408 - accuracy: 0.9944 - val_loss: 1.7110 - val_accuracy: 0.6623\n",
      "Epoch 779/1000\n",
      "178/178 [==============================] - 0s 192us/step - loss: 0.0413 - accuracy: 0.9831 - val_loss: 1.7479 - val_accuracy: 0.6623\n",
      "Epoch 780/1000\n",
      "178/178 [==============================] - 0s 172us/step - loss: 0.0458 - accuracy: 0.9831 - val_loss: 1.7251 - val_accuracy: 0.6753\n",
      "Epoch 781/1000\n",
      "178/178 [==============================] - 0s 174us/step - loss: 0.0393 - accuracy: 0.9944 - val_loss: 1.6867 - val_accuracy: 0.6364\n",
      "Epoch 782/1000\n",
      "178/178 [==============================] - 0s 148us/step - loss: 0.0557 - accuracy: 0.9775 - val_loss: 1.6879 - val_accuracy: 0.6494\n",
      "Epoch 783/1000\n",
      "178/178 [==============================] - 0s 203us/step - loss: 0.0438 - accuracy: 0.9888 - val_loss: 1.7200 - val_accuracy: 0.6623\n",
      "Epoch 784/1000\n",
      "178/178 [==============================] - 0s 160us/step - loss: 0.0412 - accuracy: 0.9831 - val_loss: 1.6830 - val_accuracy: 0.6364\n",
      "Epoch 785/1000\n",
      "178/178 [==============================] - 0s 169us/step - loss: 0.0424 - accuracy: 0.9831 - val_loss: 1.6901 - val_accuracy: 0.6364\n",
      "Epoch 786/1000\n",
      "178/178 [==============================] - 0s 193us/step - loss: 0.0397 - accuracy: 0.9831 - val_loss: 1.6984 - val_accuracy: 0.6364\n",
      "Epoch 787/1000\n",
      "178/178 [==============================] - 0s 189us/step - loss: 0.0388 - accuracy: 0.9831 - val_loss: 1.7184 - val_accuracy: 0.6623\n",
      "Epoch 788/1000\n",
      "178/178 [==============================] - 0s 164us/step - loss: 0.0376 - accuracy: 0.9831 - val_loss: 1.6973 - val_accuracy: 0.6364\n",
      "Epoch 789/1000\n",
      "178/178 [==============================] - 0s 147us/step - loss: 0.0389 - accuracy: 0.9888 - val_loss: 1.7290 - val_accuracy: 0.6753\n",
      "Epoch 790/1000\n",
      "178/178 [==============================] - 0s 191us/step - loss: 0.0411 - accuracy: 0.9831 - val_loss: 1.6883 - val_accuracy: 0.6234\n",
      "Epoch 791/1000\n",
      "178/178 [==============================] - 0s 158us/step - loss: 0.0425 - accuracy: 0.9944 - val_loss: 1.7395 - val_accuracy: 0.6623\n",
      "Epoch 792/1000\n",
      "178/178 [==============================] - 0s 177us/step - loss: 0.0388 - accuracy: 0.9831 - val_loss: 1.7019 - val_accuracy: 0.6364\n",
      "Epoch 793/1000\n",
      "178/178 [==============================] - 0s 186us/step - loss: 0.0379 - accuracy: 0.9888 - val_loss: 1.7109 - val_accuracy: 0.6494\n",
      "Epoch 794/1000\n",
      "178/178 [==============================] - 0s 199us/step - loss: 0.0378 - accuracy: 0.9831 - val_loss: 1.7259 - val_accuracy: 0.6623\n",
      "Epoch 795/1000\n",
      "178/178 [==============================] - 0s 148us/step - loss: 0.0407 - accuracy: 0.9831 - val_loss: 1.7219 - val_accuracy: 0.6623\n",
      "Epoch 796/1000\n",
      "178/178 [==============================] - 0s 182us/step - loss: 0.0407 - accuracy: 0.9775 - val_loss: 1.7607 - val_accuracy: 0.6623\n",
      "Epoch 797/1000\n",
      "178/178 [==============================] - 0s 183us/step - loss: 0.0450 - accuracy: 0.9831 - val_loss: 1.7258 - val_accuracy: 0.6623\n",
      "Epoch 798/1000\n",
      "178/178 [==============================] - 0s 175us/step - loss: 0.0375 - accuracy: 0.9944 - val_loss: 1.7041 - val_accuracy: 0.6364\n",
      "Epoch 799/1000\n",
      "178/178 [==============================] - 0s 177us/step - loss: 0.0386 - accuracy: 0.9888 - val_loss: 1.7458 - val_accuracy: 0.6623\n",
      "Epoch 800/1000\n",
      "178/178 [==============================] - 0s 181us/step - loss: 0.0424 - accuracy: 0.9888 - val_loss: 1.7240 - val_accuracy: 0.6623\n",
      "Epoch 801/1000\n",
      "178/178 [==============================] - 0s 172us/step - loss: 0.0402 - accuracy: 0.9831 - val_loss: 1.6961 - val_accuracy: 0.6494\n",
      "Epoch 802/1000\n",
      "178/178 [==============================] - 0s 151us/step - loss: 0.0466 - accuracy: 0.9831 - val_loss: 1.7369 - val_accuracy: 0.6623\n",
      "Epoch 803/1000\n",
      "178/178 [==============================] - 0s 186us/step - loss: 0.0403 - accuracy: 0.9831 - val_loss: 1.7203 - val_accuracy: 0.6753\n",
      "Epoch 804/1000\n",
      "178/178 [==============================] - 0s 195us/step - loss: 0.0376 - accuracy: 0.9944 - val_loss: 1.7164 - val_accuracy: 0.6753\n",
      "Epoch 805/1000\n",
      "178/178 [==============================] - 0s 172us/step - loss: 0.0420 - accuracy: 0.9831 - val_loss: 1.7200 - val_accuracy: 0.6753\n",
      "Epoch 806/1000\n",
      "178/178 [==============================] - 0s 176us/step - loss: 0.0371 - accuracy: 0.9944 - val_loss: 1.7187 - val_accuracy: 0.6494\n",
      "Epoch 807/1000\n",
      "178/178 [==============================] - 0s 186us/step - loss: 0.0398 - accuracy: 0.9831 - val_loss: 1.7342 - val_accuracy: 0.6623\n",
      "Epoch 808/1000\n",
      "178/178 [==============================] - 0s 176us/step - loss: 0.0399 - accuracy: 0.9831 - val_loss: 1.7477 - val_accuracy: 0.6753\n",
      "Epoch 809/1000\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0478 - accuracy: 1.00 - 0s 174us/step - loss: 0.0389 - accuracy: 0.9944 - val_loss: 1.7332 - val_accuracy: 0.6623\n",
      "Epoch 810/1000\n",
      "178/178 [==============================] - 0s 191us/step - loss: 0.0439 - accuracy: 0.9831 - val_loss: 1.7999 - val_accuracy: 0.6494\n",
      "Epoch 811/1000\n",
      "178/178 [==============================] - 0s 164us/step - loss: 0.0404 - accuracy: 0.9831 - val_loss: 1.7225 - val_accuracy: 0.6494\n",
      "Epoch 812/1000\n",
      "178/178 [==============================] - 0s 169us/step - loss: 0.0414 - accuracy: 0.9831 - val_loss: 1.7785 - val_accuracy: 0.6623\n",
      "Epoch 813/1000\n",
      "178/178 [==============================] - 0s 183us/step - loss: 0.0414 - accuracy: 0.9888 - val_loss: 1.7288 - val_accuracy: 0.6494\n",
      "Epoch 814/1000\n",
      "178/178 [==============================] - 0s 187us/step - loss: 0.0418 - accuracy: 0.9831 - val_loss: 1.7273 - val_accuracy: 0.6623\n",
      "Epoch 815/1000\n",
      "178/178 [==============================] - 0s 193us/step - loss: 0.0385 - accuracy: 0.9888 - val_loss: 1.7093 - val_accuracy: 0.6364\n",
      "Epoch 816/1000\n",
      "178/178 [==============================] - 0s 184us/step - loss: 0.0417 - accuracy: 0.9944 - val_loss: 1.7169 - val_accuracy: 0.6364\n",
      "Epoch 817/1000\n",
      "178/178 [==============================] - 0s 200us/step - loss: 0.0409 - accuracy: 0.9775 - val_loss: 1.7289 - val_accuracy: 0.6494\n",
      "Epoch 818/1000\n",
      "178/178 [==============================] - 0s 181us/step - loss: 0.0370 - accuracy: 0.9888 - val_loss: 1.7251 - val_accuracy: 0.6494\n",
      "Epoch 819/1000\n",
      "178/178 [==============================] - 0s 179us/step - loss: 0.0497 - accuracy: 0.9888 - val_loss: 1.7110 - val_accuracy: 0.6494\n",
      "Epoch 820/1000\n",
      "178/178 [==============================] - 0s 174us/step - loss: 0.0413 - accuracy: 0.9944 - val_loss: 1.7083 - val_accuracy: 0.6364\n",
      "Epoch 821/1000\n",
      "178/178 [==============================] - 0s 177us/step - loss: 0.0375 - accuracy: 0.9944 - val_loss: 1.7529 - val_accuracy: 0.6623\n",
      "Epoch 822/1000\n",
      "178/178 [==============================] - 0s 193us/step - loss: 0.0358 - accuracy: 0.9944 - val_loss: 1.7247 - val_accuracy: 0.6494\n",
      "Epoch 823/1000\n",
      "178/178 [==============================] - 0s 181us/step - loss: 0.0403 - accuracy: 0.9944 - val_loss: 1.7583 - val_accuracy: 0.6753\n",
      "Epoch 824/1000\n",
      "178/178 [==============================] - 0s 170us/step - loss: 0.0379 - accuracy: 0.9831 - val_loss: 1.7454 - val_accuracy: 0.6623\n",
      "Epoch 825/1000\n",
      "178/178 [==============================] - 0s 172us/step - loss: 0.0384 - accuracy: 0.9944 - val_loss: 1.7608 - val_accuracy: 0.6753\n",
      "Epoch 826/1000\n",
      "178/178 [==============================] - 0s 194us/step - loss: 0.0389 - accuracy: 0.9831 - val_loss: 1.7310 - val_accuracy: 0.6494\n",
      "Epoch 827/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 168us/step - loss: 0.0353 - accuracy: 1.0000 - val_loss: 1.7531 - val_accuracy: 0.6623\n",
      "Epoch 828/1000\n",
      "178/178 [==============================] - 0s 153us/step - loss: 0.0363 - accuracy: 0.9831 - val_loss: 1.7232 - val_accuracy: 0.6494\n",
      "Epoch 829/1000\n",
      "178/178 [==============================] - 0s 182us/step - loss: 0.0412 - accuracy: 0.9944 - val_loss: 1.7527 - val_accuracy: 0.6623\n",
      "Epoch 830/1000\n",
      "178/178 [==============================] - 0s 180us/step - loss: 0.0391 - accuracy: 0.9775 - val_loss: 1.7667 - val_accuracy: 0.6753\n",
      "Epoch 831/1000\n",
      "178/178 [==============================] - 0s 182us/step - loss: 0.0358 - accuracy: 0.9944 - val_loss: 1.7485 - val_accuracy: 0.6623\n",
      "Epoch 832/1000\n",
      "178/178 [==============================] - 0s 163us/step - loss: 0.0364 - accuracy: 0.9888 - val_loss: 1.7732 - val_accuracy: 0.6623\n",
      "Epoch 833/1000\n",
      "178/178 [==============================] - 0s 185us/step - loss: 0.0379 - accuracy: 0.9831 - val_loss: 1.7589 - val_accuracy: 0.6623\n",
      "Epoch 834/1000\n",
      "178/178 [==============================] - 0s 195us/step - loss: 0.0376 - accuracy: 0.9831 - val_loss: 1.7514 - val_accuracy: 0.6623\n",
      "Epoch 835/1000\n",
      "178/178 [==============================] - 0s 173us/step - loss: 0.0358 - accuracy: 0.9888 - val_loss: 1.7389 - val_accuracy: 0.6494\n",
      "Epoch 836/1000\n",
      "178/178 [==============================] - 0s 175us/step - loss: 0.0341 - accuracy: 0.9944 - val_loss: 1.7483 - val_accuracy: 0.6623\n",
      "Epoch 837/1000\n",
      "178/178 [==============================] - 0s 152us/step - loss: 0.0350 - accuracy: 0.9944 - val_loss: 1.7720 - val_accuracy: 0.6753\n",
      "Epoch 838/1000\n",
      "178/178 [==============================] - 0s 194us/step - loss: 0.0402 - accuracy: 0.9831 - val_loss: 1.7210 - val_accuracy: 0.6494\n",
      "Epoch 839/1000\n",
      "178/178 [==============================] - 0s 177us/step - loss: 0.0476 - accuracy: 0.9888 - val_loss: 1.7374 - val_accuracy: 0.6364\n",
      "Epoch 840/1000\n",
      "178/178 [==============================] - 0s 167us/step - loss: 0.0381 - accuracy: 0.9831 - val_loss: 1.7308 - val_accuracy: 0.6364\n",
      "Epoch 841/1000\n",
      "178/178 [==============================] - 0s 198us/step - loss: 0.0433 - accuracy: 0.9888 - val_loss: 1.7635 - val_accuracy: 0.6623\n",
      "Epoch 842/1000\n",
      "178/178 [==============================] - 0s 185us/step - loss: 0.0366 - accuracy: 0.9831 - val_loss: 1.7610 - val_accuracy: 0.6623\n",
      "Epoch 843/1000\n",
      "178/178 [==============================] - 0s 162us/step - loss: 0.0378 - accuracy: 0.9888 - val_loss: 1.7847 - val_accuracy: 0.6623\n",
      "Epoch 844/1000\n",
      "178/178 [==============================] - 0s 181us/step - loss: 0.0392 - accuracy: 0.9944 - val_loss: 1.7760 - val_accuracy: 0.6753\n",
      "Epoch 845/1000\n",
      "178/178 [==============================] - 0s 172us/step - loss: 0.0401 - accuracy: 0.9944 - val_loss: 1.7706 - val_accuracy: 0.6623\n",
      "Epoch 846/1000\n",
      "178/178 [==============================] - 0s 176us/step - loss: 0.0397 - accuracy: 0.9831 - val_loss: 1.7504 - val_accuracy: 0.6753\n",
      "Epoch 847/1000\n",
      "178/178 [==============================] - 0s 167us/step - loss: 0.0402 - accuracy: 0.9944 - val_loss: 1.7706 - val_accuracy: 0.6623\n",
      "Epoch 848/1000\n",
      "178/178 [==============================] - 0s 180us/step - loss: 0.0371 - accuracy: 0.9888 - val_loss: 1.7380 - val_accuracy: 0.6364\n",
      "Epoch 849/1000\n",
      "178/178 [==============================] - 0s 184us/step - loss: 0.0419 - accuracy: 0.9831 - val_loss: 1.7448 - val_accuracy: 0.6364\n",
      "Epoch 850/1000\n",
      "178/178 [==============================] - 0s 175us/step - loss: 0.0365 - accuracy: 0.9831 - val_loss: 1.7426 - val_accuracy: 0.6364\n",
      "Epoch 851/1000\n",
      "178/178 [==============================] - 0s 175us/step - loss: 0.0419 - accuracy: 0.9831 - val_loss: 1.7371 - val_accuracy: 0.6364\n",
      "Epoch 852/1000\n",
      "178/178 [==============================] - 0s 187us/step - loss: 0.0345 - accuracy: 1.0000 - val_loss: 1.7893 - val_accuracy: 0.6753\n",
      "Epoch 853/1000\n",
      "178/178 [==============================] - 0s 166us/step - loss: 0.0387 - accuracy: 0.9831 - val_loss: 1.7885 - val_accuracy: 0.6753\n",
      "Epoch 854/1000\n",
      "178/178 [==============================] - 0s 165us/step - loss: 0.0349 - accuracy: 0.9831 - val_loss: 1.7481 - val_accuracy: 0.6364\n",
      "Epoch 855/1000\n",
      "178/178 [==============================] - 0s 185us/step - loss: 0.0427 - accuracy: 0.9944 - val_loss: 1.7457 - val_accuracy: 0.6364\n",
      "Epoch 856/1000\n",
      "178/178 [==============================] - 0s 165us/step - loss: 0.0441 - accuracy: 0.9775 - val_loss: 1.7866 - val_accuracy: 0.6753\n",
      "Epoch 857/1000\n",
      "178/178 [==============================] - 0s 197us/step - loss: 0.0394 - accuracy: 0.9831 - val_loss: 1.7944 - val_accuracy: 0.6623\n",
      "Epoch 858/1000\n",
      "178/178 [==============================] - 0s 180us/step - loss: 0.0394 - accuracy: 0.9831 - val_loss: 1.7836 - val_accuracy: 0.6753\n",
      "Epoch 859/1000\n",
      "178/178 [==============================] - 0s 177us/step - loss: 0.0361 - accuracy: 0.9831 - val_loss: 1.7911 - val_accuracy: 0.6623\n",
      "Epoch 860/1000\n",
      "178/178 [==============================] - 0s 153us/step - loss: 0.0409 - accuracy: 0.9944 - val_loss: 1.7733 - val_accuracy: 0.6623\n",
      "Epoch 861/1000\n",
      "178/178 [==============================] - 0s 186us/step - loss: 0.0397 - accuracy: 0.9831 - val_loss: 1.7739 - val_accuracy: 0.6623\n",
      "Epoch 862/1000\n",
      "178/178 [==============================] - 0s 174us/step - loss: 0.0401 - accuracy: 0.9775 - val_loss: 1.8108 - val_accuracy: 0.6623\n",
      "Epoch 863/1000\n",
      "178/178 [==============================] - 0s 172us/step - loss: 0.0349 - accuracy: 0.9888 - val_loss: 1.7583 - val_accuracy: 0.6364\n",
      "Epoch 864/1000\n",
      "178/178 [==============================] - 0s 188us/step - loss: 0.0360 - accuracy: 0.9831 - val_loss: 1.7857 - val_accuracy: 0.6623\n",
      "Epoch 865/1000\n",
      "178/178 [==============================] - 0s 177us/step - loss: 0.0351 - accuracy: 0.9831 - val_loss: 1.7673 - val_accuracy: 0.6623\n",
      "Epoch 866/1000\n",
      "178/178 [==============================] - 0s 174us/step - loss: 0.0351 - accuracy: 0.9831 - val_loss: 1.7670 - val_accuracy: 0.6753\n",
      "Epoch 867/1000\n",
      "178/178 [==============================] - 0s 169us/step - loss: 0.0342 - accuracy: 0.9944 - val_loss: 1.7791 - val_accuracy: 0.6623\n",
      "Epoch 868/1000\n",
      "178/178 [==============================] - 0s 183us/step - loss: 0.0344 - accuracy: 0.9831 - val_loss: 1.7845 - val_accuracy: 0.6623\n",
      "Epoch 869/1000\n",
      "178/178 [==============================] - 0s 164us/step - loss: 0.0370 - accuracy: 0.9831 - val_loss: 1.7699 - val_accuracy: 0.6364\n",
      "Epoch 870/1000\n",
      "178/178 [==============================] - 0s 190us/step - loss: 0.0417 - accuracy: 0.9831 - val_loss: 1.7665 - val_accuracy: 0.6494\n",
      "Epoch 871/1000\n",
      "178/178 [==============================] - 0s 189us/step - loss: 0.0376 - accuracy: 0.9831 - val_loss: 1.7895 - val_accuracy: 0.6753\n",
      "Epoch 872/1000\n",
      "178/178 [==============================] - 0s 149us/step - loss: 0.0422 - accuracy: 0.9888 - val_loss: 1.7776 - val_accuracy: 0.6623\n",
      "Epoch 873/1000\n",
      "178/178 [==============================] - 0s 193us/step - loss: 0.0332 - accuracy: 0.9944 - val_loss: 1.7949 - val_accuracy: 0.6623\n",
      "Epoch 874/1000\n",
      "178/178 [==============================] - 0s 175us/step - loss: 0.0326 - accuracy: 0.9831 - val_loss: 1.7751 - val_accuracy: 0.6623\n",
      "Epoch 875/1000\n",
      "178/178 [==============================] - 0s 194us/step - loss: 0.0342 - accuracy: 0.9888 - val_loss: 1.7589 - val_accuracy: 0.6364\n",
      "Epoch 876/1000\n",
      "178/178 [==============================] - 0s 174us/step - loss: 0.0378 - accuracy: 0.9944 - val_loss: 1.8309 - val_accuracy: 0.6623\n",
      "Epoch 877/1000\n",
      "178/178 [==============================] - 0s 166us/step - loss: 0.0425 - accuracy: 0.9831 - val_loss: 1.8005 - val_accuracy: 0.6753\n",
      "Epoch 878/1000\n",
      "178/178 [==============================] - 0s 179us/step - loss: 0.0376 - accuracy: 0.9888 - val_loss: 1.7843 - val_accuracy: 0.6623\n",
      "Epoch 879/1000\n",
      "178/178 [==============================] - 0s 169us/step - loss: 0.0352 - accuracy: 0.9888 - val_loss: 1.7753 - val_accuracy: 0.6623\n",
      "Epoch 880/1000\n",
      "178/178 [==============================] - 0s 168us/step - loss: 0.0380 - accuracy: 0.9831 - val_loss: 1.7713 - val_accuracy: 0.6494\n",
      "Epoch 881/1000\n",
      "178/178 [==============================] - 0s 183us/step - loss: 0.0316 - accuracy: 1.0000 - val_loss: 1.7847 - val_accuracy: 0.6623\n",
      "Epoch 882/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 174us/step - loss: 0.0350 - accuracy: 0.9888 - val_loss: 1.7684 - val_accuracy: 0.6623\n",
      "Epoch 883/1000\n",
      "178/178 [==============================] - 0s 186us/step - loss: 0.0363 - accuracy: 0.9944 - val_loss: 1.7734 - val_accuracy: 0.6364\n",
      "Epoch 884/1000\n",
      "178/178 [==============================] - 0s 177us/step - loss: 0.0321 - accuracy: 0.9888 - val_loss: 1.8065 - val_accuracy: 0.6753\n",
      "Epoch 885/1000\n",
      "178/178 [==============================] - 0s 166us/step - loss: 0.0356 - accuracy: 0.9944 - val_loss: 1.7608 - val_accuracy: 0.6364\n",
      "Epoch 886/1000\n",
      "178/178 [==============================] - 0s 148us/step - loss: 0.0332 - accuracy: 0.9944 - val_loss: 1.8311 - val_accuracy: 0.6623\n",
      "Epoch 887/1000\n",
      "178/178 [==============================] - 0s 203us/step - loss: 0.0413 - accuracy: 0.9831 - val_loss: 1.8034 - val_accuracy: 0.6623\n",
      "Epoch 888/1000\n",
      "178/178 [==============================] - 0s 148us/step - loss: 0.0367 - accuracy: 0.9831 - val_loss: 1.7709 - val_accuracy: 0.6364\n",
      "Epoch 889/1000\n",
      "178/178 [==============================] - 0s 181us/step - loss: 0.0445 - accuracy: 0.9775 - val_loss: 1.8186 - val_accuracy: 0.6623\n",
      "Epoch 890/1000\n",
      "178/178 [==============================] - 0s 199us/step - loss: 0.0355 - accuracy: 0.9944 - val_loss: 1.8190 - val_accuracy: 0.6623\n",
      "Epoch 891/1000\n",
      "178/178 [==============================] - 0s 170us/step - loss: 0.0354 - accuracy: 0.9831 - val_loss: 1.7787 - val_accuracy: 0.6364\n",
      "Epoch 892/1000\n",
      "178/178 [==============================] - 0s 144us/step - loss: 0.0374 - accuracy: 0.9888 - val_loss: 1.7861 - val_accuracy: 0.6364\n",
      "Epoch 893/1000\n",
      "178/178 [==============================] - 0s 180us/step - loss: 0.0348 - accuracy: 0.9888 - val_loss: 1.7806 - val_accuracy: 0.6364\n",
      "Epoch 894/1000\n",
      "178/178 [==============================] - 0s 200us/step - loss: 0.0334 - accuracy: 0.9888 - val_loss: 1.8304 - val_accuracy: 0.6623\n",
      "Epoch 895/1000\n",
      "178/178 [==============================] - 0s 177us/step - loss: 0.0376 - accuracy: 0.9888 - val_loss: 1.7984 - val_accuracy: 0.6623\n",
      "Epoch 896/1000\n",
      "178/178 [==============================] - 0s 174us/step - loss: 0.0320 - accuracy: 0.9888 - val_loss: 1.7964 - val_accuracy: 0.6623\n",
      "Epoch 897/1000\n",
      "178/178 [==============================] - 0s 175us/step - loss: 0.0344 - accuracy: 0.9944 - val_loss: 1.7950 - val_accuracy: 0.6623\n",
      "Epoch 898/1000\n",
      "178/178 [==============================] - 0s 183us/step - loss: 0.0314 - accuracy: 1.0000 - val_loss: 1.8125 - val_accuracy: 0.6623\n",
      "Epoch 899/1000\n",
      "178/178 [==============================] - 0s 149us/step - loss: 0.0366 - accuracy: 0.9944 - val_loss: 1.7754 - val_accuracy: 0.6364\n",
      "Epoch 900/1000\n",
      "178/178 [==============================] - 0s 188us/step - loss: 0.0365 - accuracy: 1.0000 - val_loss: 1.8258 - val_accuracy: 0.6623\n",
      "Epoch 901/1000\n",
      "178/178 [==============================] - 0s 174us/step - loss: 0.0333 - accuracy: 0.9944 - val_loss: 1.7985 - val_accuracy: 0.6623\n",
      "Epoch 902/1000\n",
      "178/178 [==============================] - 0s 174us/step - loss: 0.0325 - accuracy: 0.9944 - val_loss: 1.8229 - val_accuracy: 0.6623\n",
      "Epoch 903/1000\n",
      "178/178 [==============================] - 0s 158us/step - loss: 0.0393 - accuracy: 0.9888 - val_loss: 1.8096 - val_accuracy: 0.6623\n",
      "Epoch 904/1000\n",
      "178/178 [==============================] - 0s 204us/step - loss: 0.0344 - accuracy: 0.9944 - val_loss: 1.8176 - val_accuracy: 0.6753\n",
      "Epoch 905/1000\n",
      "178/178 [==============================] - 0s 167us/step - loss: 0.0336 - accuracy: 0.9944 - val_loss: 1.7797 - val_accuracy: 0.6494\n",
      "Epoch 906/1000\n",
      "178/178 [==============================] - 0s 168us/step - loss: 0.0329 - accuracy: 0.9944 - val_loss: 1.7918 - val_accuracy: 0.6364\n",
      "Epoch 907/1000\n",
      "178/178 [==============================] - 0s 177us/step - loss: 0.0319 - accuracy: 0.9944 - val_loss: 1.8308 - val_accuracy: 0.6623\n",
      "Epoch 908/1000\n",
      "178/178 [==============================] - 0s 163us/step - loss: 0.0340 - accuracy: 0.9944 - val_loss: 1.8033 - val_accuracy: 0.6623\n",
      "Epoch 909/1000\n",
      "178/178 [==============================] - 0s 182us/step - loss: 0.0306 - accuracy: 0.9888 - val_loss: 1.8106 - val_accuracy: 0.6623\n",
      "Epoch 910/1000\n",
      "178/178 [==============================] - 0s 186us/step - loss: 0.0317 - accuracy: 0.9944 - val_loss: 1.8082 - val_accuracy: 0.6623\n",
      "Epoch 911/1000\n",
      "178/178 [==============================] - 0s 164us/step - loss: 0.0390 - accuracy: 0.9831 - val_loss: 1.8238 - val_accuracy: 0.6623\n",
      "Epoch 912/1000\n",
      "178/178 [==============================] - 0s 201us/step - loss: 0.0335 - accuracy: 0.9944 - val_loss: 1.8163 - val_accuracy: 0.6623\n",
      "Epoch 913/1000\n",
      "178/178 [==============================] - 0s 153us/step - loss: 0.0311 - accuracy: 0.9944 - val_loss: 1.8245 - val_accuracy: 0.6623\n",
      "Epoch 914/1000\n",
      "178/178 [==============================] - 0s 175us/step - loss: 0.0311 - accuracy: 0.9888 - val_loss: 1.8150 - val_accuracy: 0.6623\n",
      "Epoch 915/1000\n",
      "178/178 [==============================] - 0s 181us/step - loss: 0.0335 - accuracy: 0.9831 - val_loss: 1.7950 - val_accuracy: 0.6364\n",
      "Epoch 916/1000\n",
      "178/178 [==============================] - 0s 184us/step - loss: 0.0358 - accuracy: 0.9888 - val_loss: 1.8362 - val_accuracy: 0.6623\n",
      "Epoch 917/1000\n",
      "178/178 [==============================] - 0s 160us/step - loss: 0.0337 - accuracy: 0.9831 - val_loss: 1.8301 - val_accuracy: 0.6623\n",
      "Epoch 918/1000\n",
      "178/178 [==============================] - 0s 167us/step - loss: 0.0320 - accuracy: 0.9888 - val_loss: 1.8216 - val_accuracy: 0.6623\n",
      "Epoch 919/1000\n",
      "178/178 [==============================] - 0s 200us/step - loss: 0.0325 - accuracy: 0.9888 - val_loss: 1.8297 - val_accuracy: 0.6753\n",
      "Epoch 920/1000\n",
      "178/178 [==============================] - 0s 165us/step - loss: 0.0359 - accuracy: 0.9888 - val_loss: 1.8485 - val_accuracy: 0.6623\n",
      "Epoch 921/1000\n",
      "178/178 [==============================] - 0s 167us/step - loss: 0.0325 - accuracy: 0.9944 - val_loss: 1.8163 - val_accuracy: 0.6623\n",
      "Epoch 922/1000\n",
      "178/178 [==============================] - 0s 182us/step - loss: 0.0303 - accuracy: 0.9888 - val_loss: 1.7980 - val_accuracy: 0.6364\n",
      "Epoch 923/1000\n",
      "178/178 [==============================] - 0s 181us/step - loss: 0.0300 - accuracy: 1.0000 - val_loss: 1.8278 - val_accuracy: 0.6623\n",
      "Epoch 924/1000\n",
      "178/178 [==============================] - 0s 171us/step - loss: 0.0322 - accuracy: 0.9831 - val_loss: 1.7907 - val_accuracy: 0.6494\n",
      "Epoch 925/1000\n",
      "178/178 [==============================] - 0s 151us/step - loss: 0.0345 - accuracy: 0.9888 - val_loss: 1.8029 - val_accuracy: 0.6364\n",
      "Epoch 926/1000\n",
      "178/178 [==============================] - 0s 183us/step - loss: 0.0311 - accuracy: 0.9944 - val_loss: 1.8033 - val_accuracy: 0.6364\n",
      "Epoch 927/1000\n",
      "178/178 [==============================] - 0s 177us/step - loss: 0.0325 - accuracy: 0.9944 - val_loss: 1.8255 - val_accuracy: 0.6623\n",
      "Epoch 928/1000\n",
      "178/178 [==============================] - 0s 189us/step - loss: 0.0337 - accuracy: 0.9944 - val_loss: 1.8367 - val_accuracy: 0.6753\n",
      "Epoch 929/1000\n",
      "178/178 [==============================] - 0s 182us/step - loss: 0.0322 - accuracy: 0.9888 - val_loss: 1.7964 - val_accuracy: 0.6494\n",
      "Epoch 930/1000\n",
      "178/178 [==============================] - 0s 186us/step - loss: 0.0334 - accuracy: 1.0000 - val_loss: 1.8498 - val_accuracy: 0.6623\n",
      "Epoch 931/1000\n",
      "178/178 [==============================] - 0s 169us/step - loss: 0.0319 - accuracy: 0.9944 - val_loss: 1.7961 - val_accuracy: 0.6364\n",
      "Epoch 932/1000\n",
      "178/178 [==============================] - 0s 183us/step - loss: 0.0322 - accuracy: 0.9944 - val_loss: 1.8260 - val_accuracy: 0.6623\n",
      "Epoch 933/1000\n",
      "178/178 [==============================] - 0s 166us/step - loss: 0.0329 - accuracy: 0.9944 - val_loss: 1.8204 - val_accuracy: 0.6623\n",
      "Epoch 934/1000\n",
      "178/178 [==============================] - 0s 192us/step - loss: 0.0311 - accuracy: 1.0000 - val_loss: 1.8519 - val_accuracy: 0.6753\n",
      "Epoch 935/1000\n",
      "178/178 [==============================] - 0s 179us/step - loss: 0.0334 - accuracy: 0.9831 - val_loss: 1.8234 - val_accuracy: 0.6623\n",
      "Epoch 936/1000\n",
      "178/178 [==============================] - 0s 155us/step - loss: 0.0310 - accuracy: 1.0000 - val_loss: 1.8529 - val_accuracy: 0.6753\n",
      "Epoch 937/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 176us/step - loss: 0.0362 - accuracy: 0.9831 - val_loss: 1.8481 - val_accuracy: 0.6753\n",
      "Epoch 938/1000\n",
      "178/178 [==============================] - 0s 187us/step - loss: 0.0318 - accuracy: 0.9888 - val_loss: 1.8055 - val_accuracy: 0.6364\n",
      "Epoch 939/1000\n",
      "178/178 [==============================] - 0s 168us/step - loss: 0.0299 - accuracy: 1.0000 - val_loss: 1.8427 - val_accuracy: 0.6623\n",
      "Epoch 940/1000\n",
      "178/178 [==============================] - 0s 163us/step - loss: 0.0302 - accuracy: 0.9888 - val_loss: 1.8326 - val_accuracy: 0.6623\n",
      "Epoch 941/1000\n",
      "178/178 [==============================] - 0s 197us/step - loss: 0.0324 - accuracy: 0.9944 - val_loss: 1.8283 - val_accuracy: 0.6623\n",
      "Epoch 942/1000\n",
      "178/178 [==============================] - 0s 178us/step - loss: 0.0293 - accuracy: 1.0000 - val_loss: 1.8368 - val_accuracy: 0.6623\n",
      "Epoch 943/1000\n",
      "178/178 [==============================] - 0s 147us/step - loss: 0.0293 - accuracy: 0.9944 - val_loss: 1.8410 - val_accuracy: 0.6623\n",
      "Epoch 944/1000\n",
      "178/178 [==============================] - 0s 194us/step - loss: 0.0316 - accuracy: 0.9888 - val_loss: 1.8158 - val_accuracy: 0.6364\n",
      "Epoch 945/1000\n",
      "178/178 [==============================] - 0s 180us/step - loss: 0.0291 - accuracy: 1.0000 - val_loss: 1.8410 - val_accuracy: 0.6623\n",
      "Epoch 946/1000\n",
      "178/178 [==============================] - 0s 159us/step - loss: 0.0323 - accuracy: 1.0000 - val_loss: 1.8720 - val_accuracy: 0.6623\n",
      "Epoch 947/1000\n",
      "178/178 [==============================] - 0s 210us/step - loss: 0.0303 - accuracy: 0.9944 - val_loss: 1.8150 - val_accuracy: 0.6364\n",
      "Epoch 948/1000\n",
      "178/178 [==============================] - 0s 158us/step - loss: 0.0305 - accuracy: 1.0000 - val_loss: 1.8338 - val_accuracy: 0.6623\n",
      "Epoch 949/1000\n",
      "178/178 [==============================] - 0s 160us/step - loss: 0.0295 - accuracy: 0.9944 - val_loss: 1.8412 - val_accuracy: 0.6623\n",
      "Epoch 950/1000\n",
      "178/178 [==============================] - 0s 183us/step - loss: 0.0327 - accuracy: 0.9944 - val_loss: 1.8840 - val_accuracy: 0.6623\n",
      "Epoch 951/1000\n",
      "178/178 [==============================] - 0s 170us/step - loss: 0.0380 - accuracy: 0.9831 - val_loss: 1.9051 - val_accuracy: 0.6494\n",
      "Epoch 952/1000\n",
      "178/178 [==============================] - 0s 199us/step - loss: 0.0365 - accuracy: 0.9944 - val_loss: 1.8502 - val_accuracy: 0.6623\n",
      "Epoch 953/1000\n",
      "178/178 [==============================] - 0s 150us/step - loss: 0.0326 - accuracy: 0.9831 - val_loss: 1.8479 - val_accuracy: 0.6623\n",
      "Epoch 954/1000\n",
      "178/178 [==============================] - 0s 196us/step - loss: 0.0310 - accuracy: 0.9944 - val_loss: 1.8439 - val_accuracy: 0.6623\n",
      "Epoch 955/1000\n",
      "178/178 [==============================] - 0s 173us/step - loss: 0.0300 - accuracy: 0.9944 - val_loss: 1.8131 - val_accuracy: 0.6364\n",
      "Epoch 956/1000\n",
      "178/178 [==============================] - 0s 161us/step - loss: 0.0343 - accuracy: 0.9888 - val_loss: 1.8403 - val_accuracy: 0.6623\n",
      "Epoch 957/1000\n",
      "178/178 [==============================] - 0s 239us/step - loss: 0.0308 - accuracy: 0.9831 - val_loss: 1.8201 - val_accuracy: 0.6364\n",
      "Epoch 958/1000\n",
      "178/178 [==============================] - 0s 204us/step - loss: 0.0291 - accuracy: 1.0000 - val_loss: 1.8524 - val_accuracy: 0.6623\n",
      "Epoch 959/1000\n",
      "178/178 [==============================] - 0s 213us/step - loss: 0.0305 - accuracy: 0.9944 - val_loss: 1.8241 - val_accuracy: 0.6364\n",
      "Epoch 960/1000\n",
      "178/178 [==============================] - 0s 171us/step - loss: 0.0301 - accuracy: 1.0000 - val_loss: 1.8667 - val_accuracy: 0.6753\n",
      "Epoch 961/1000\n",
      "178/178 [==============================] - 0s 176us/step - loss: 0.0349 - accuracy: 0.9944 - val_loss: 1.8551 - val_accuracy: 0.6753\n",
      "Epoch 962/1000\n",
      "178/178 [==============================] - 0s 176us/step - loss: 0.0307 - accuracy: 0.9944 - val_loss: 1.8183 - val_accuracy: 0.6364\n",
      "Epoch 963/1000\n",
      "178/178 [==============================] - 0s 172us/step - loss: 0.0316 - accuracy: 1.0000 - val_loss: 1.8462 - val_accuracy: 0.6623\n",
      "Epoch 964/1000\n",
      "178/178 [==============================] - 0s 206us/step - loss: 0.0295 - accuracy: 0.9944 - val_loss: 1.8234 - val_accuracy: 0.6364\n",
      "Epoch 965/1000\n",
      "178/178 [==============================] - 0s 173us/step - loss: 0.0296 - accuracy: 1.0000 - val_loss: 1.8808 - val_accuracy: 0.6753\n",
      "Epoch 966/1000\n",
      "178/178 [==============================] - 0s 171us/step - loss: 0.0311 - accuracy: 0.9831 - val_loss: 1.8392 - val_accuracy: 0.6623\n",
      "Epoch 967/1000\n",
      "178/178 [==============================] - 0s 181us/step - loss: 0.0287 - accuracy: 1.0000 - val_loss: 1.8484 - val_accuracy: 0.6623\n",
      "Epoch 968/1000\n",
      "178/178 [==============================] - 0s 184us/step - loss: 0.0311 - accuracy: 0.9888 - val_loss: 1.8241 - val_accuracy: 0.6364\n",
      "Epoch 969/1000\n",
      "178/178 [==============================] - 0s 161us/step - loss: 0.0379 - accuracy: 0.9775 - val_loss: 1.8232 - val_accuracy: 0.6364\n",
      "Epoch 970/1000\n",
      "178/178 [==============================] - 0s 180us/step - loss: 0.0310 - accuracy: 0.9944 - val_loss: 1.8849 - val_accuracy: 0.6623\n",
      "Epoch 971/1000\n",
      "178/178 [==============================] - 0s 194us/step - loss: 0.0353 - accuracy: 0.9888 - val_loss: 1.8500 - val_accuracy: 0.6623\n",
      "Epoch 972/1000\n",
      "178/178 [==============================] - 0s 172us/step - loss: 0.0292 - accuracy: 0.9944 - val_loss: 1.8644 - val_accuracy: 0.6623\n",
      "Epoch 973/1000\n",
      "178/178 [==============================] - 0s 178us/step - loss: 0.0292 - accuracy: 0.9944 - val_loss: 1.8443 - val_accuracy: 0.6623\n",
      "Epoch 974/1000\n",
      "178/178 [==============================] - 0s 163us/step - loss: 0.0273 - accuracy: 1.0000 - val_loss: 1.8606 - val_accuracy: 0.6623\n",
      "Epoch 975/1000\n",
      "178/178 [==============================] - 0s 199us/step - loss: 0.0300 - accuracy: 0.9888 - val_loss: 1.8551 - val_accuracy: 0.6623\n",
      "Epoch 976/1000\n",
      "178/178 [==============================] - 0s 154us/step - loss: 0.0338 - accuracy: 0.9831 - val_loss: 1.8910 - val_accuracy: 0.6623\n",
      "Epoch 977/1000\n",
      "178/178 [==============================] - 0s 174us/step - loss: 0.0293 - accuracy: 0.9944 - val_loss: 1.8412 - val_accuracy: 0.6494\n",
      "Epoch 978/1000\n",
      "178/178 [==============================] - 0s 183us/step - loss: 0.0281 - accuracy: 1.0000 - val_loss: 1.8933 - val_accuracy: 0.6623\n",
      "Epoch 979/1000\n",
      "178/178 [==============================] - 0s 171us/step - loss: 0.0298 - accuracy: 0.9944 - val_loss: 1.8590 - val_accuracy: 0.6623\n",
      "Epoch 980/1000\n",
      "178/178 [==============================] - 0s 189us/step - loss: 0.0283 - accuracy: 0.9888 - val_loss: 1.8372 - val_accuracy: 0.6364\n",
      "Epoch 981/1000\n",
      "178/178 [==============================] - 0s 166us/step - loss: 0.0307 - accuracy: 0.9944 - val_loss: 1.8526 - val_accuracy: 0.6753\n",
      "Epoch 982/1000\n",
      "178/178 [==============================] - 0s 191us/step - loss: 0.0309 - accuracy: 0.9944 - val_loss: 1.8524 - val_accuracy: 0.6494\n",
      "Epoch 983/1000\n",
      "178/178 [==============================] - 0s 155us/step - loss: 0.0276 - accuracy: 1.0000 - val_loss: 1.8611 - val_accuracy: 0.6623\n",
      "Epoch 984/1000\n",
      "178/178 [==============================] - 0s 255us/step - loss: 0.0287 - accuracy: 0.9944 - val_loss: 1.8778 - val_accuracy: 0.6753\n",
      "Epoch 985/1000\n",
      "178/178 [==============================] - 0s 198us/step - loss: 0.0287 - accuracy: 0.9888 - val_loss: 1.8488 - val_accuracy: 0.6753\n",
      "Epoch 986/1000\n",
      "178/178 [==============================] - 0s 178us/step - loss: 0.0296 - accuracy: 1.0000 - val_loss: 1.8709 - val_accuracy: 0.6623\n",
      "Epoch 987/1000\n",
      "178/178 [==============================] - 0s 182us/step - loss: 0.0307 - accuracy: 0.9944 - val_loss: 1.8530 - val_accuracy: 0.6623\n",
      "Epoch 988/1000\n",
      "178/178 [==============================] - 0s 176us/step - loss: 0.0332 - accuracy: 0.9888 - val_loss: 1.8804 - val_accuracy: 0.6753\n",
      "Epoch 989/1000\n",
      "178/178 [==============================] - 0s 186us/step - loss: 0.0309 - accuracy: 0.9888 - val_loss: 1.8646 - val_accuracy: 0.6623\n",
      "Epoch 990/1000\n",
      "178/178 [==============================] - 0s 185us/step - loss: 0.0284 - accuracy: 1.0000 - val_loss: 1.8957 - val_accuracy: 0.6753\n",
      "Epoch 991/1000\n",
      "178/178 [==============================] - 0s 183us/step - loss: 0.0330 - accuracy: 0.9944 - val_loss: 1.8781 - val_accuracy: 0.6623\n",
      "Epoch 992/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 273us/step - loss: 0.0328 - accuracy: 0.9944 - val_loss: 1.8749 - val_accuracy: 0.6623\n",
      "Epoch 993/1000\n",
      "178/178 [==============================] - 0s 173us/step - loss: 0.0276 - accuracy: 0.9944 - val_loss: 1.8726 - val_accuracy: 0.6623\n",
      "Epoch 994/1000\n",
      "178/178 [==============================] - 0s 163us/step - loss: 0.0333 - accuracy: 0.9831 - val_loss: 1.8700 - val_accuracy: 0.6623\n",
      "Epoch 995/1000\n",
      "178/178 [==============================] - 0s 162us/step - loss: 0.0305 - accuracy: 0.9888 - val_loss: 1.8460 - val_accuracy: 0.6364\n",
      "Epoch 996/1000\n",
      "178/178 [==============================] - 0s 157us/step - loss: 0.0268 - accuracy: 1.0000 - val_loss: 1.8834 - val_accuracy: 0.6753\n",
      "Epoch 997/1000\n",
      "178/178 [==============================] - 0s 185us/step - loss: 0.0317 - accuracy: 0.9944 - val_loss: 1.8942 - val_accuracy: 0.6753\n",
      "Epoch 998/1000\n",
      "178/178 [==============================] - 0s 171us/step - loss: 0.0281 - accuracy: 0.9888 - val_loss: 1.8482 - val_accuracy: 0.6364\n",
      "Epoch 999/1000\n",
      "178/178 [==============================] - 0s 180us/step - loss: 0.0329 - accuracy: 0.9944 - val_loss: 1.8942 - val_accuracy: 0.6753\n",
      "Epoch 1000/1000\n",
      "178/178 [==============================] - 0s 196us/step - loss: 0.0307 - accuracy: 0.9944 - val_loss: 1.9042 - val_accuracy: 0.6623\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a44404fd0>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(X_train, y_train,\n",
    "          batch_size=64, epochs=1000,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 0s 259us/step\n",
      "test accuracy: 66.23%\n"
     ]
    }
   ],
   "source": [
    "acc_test2 = model2.evaluate(X_test, y_test)[1]\n",
    "print('test accuracy: %.2f%%' % (acc_test2*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### add regularizer and dropout\n",
    "model3 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train.shape[1],), activity_regularizer=l1(0.001)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid'),\n",
    "    Dropout(0.2, ),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.compile(optimizer='sgd',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 178 samples, validate on 77 samples\n",
      "Epoch 1/1000\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 2.2379 - accuracy: 0.5506 - val_loss: 0.8462 - val_accuracy: 0.5584\n",
      "Epoch 2/1000\n",
      "178/178 [==============================] - 0s 192us/step - loss: 2.0706 - accuracy: 0.5169 - val_loss: 0.7707 - val_accuracy: 0.5844\n",
      "Epoch 3/1000\n",
      "178/178 [==============================] - 0s 204us/step - loss: 2.2832 - accuracy: 0.4831 - val_loss: 0.7429 - val_accuracy: 0.5844\n",
      "Epoch 4/1000\n",
      "178/178 [==============================] - 0s 175us/step - loss: 2.2249 - accuracy: 0.5281 - val_loss: 0.7283 - val_accuracy: 0.5584\n",
      "Epoch 5/1000\n",
      "178/178 [==============================] - 0s 181us/step - loss: 2.2909 - accuracy: 0.5281 - val_loss: 0.7217 - val_accuracy: 0.5844\n",
      "Epoch 6/1000\n",
      "178/178 [==============================] - 0s 207us/step - loss: 2.6518 - accuracy: 0.4775 - val_loss: 0.7194 - val_accuracy: 0.5584\n",
      "Epoch 7/1000\n",
      "178/178 [==============================] - 0s 190us/step - loss: 1.6347 - accuracy: 0.5449 - val_loss: 0.7179 - val_accuracy: 0.5844\n",
      "Epoch 8/1000\n",
      "178/178 [==============================] - 0s 186us/step - loss: 2.5345 - accuracy: 0.5112 - val_loss: 0.7139 - val_accuracy: 0.5714\n",
      "Epoch 9/1000\n",
      "178/178 [==============================] - 0s 183us/step - loss: 2.1192 - accuracy: 0.5337 - val_loss: 0.7122 - val_accuracy: 0.5714\n",
      "Epoch 10/1000\n",
      "178/178 [==============================] - 0s 179us/step - loss: 2.1258 - accuracy: 0.5225 - val_loss: 0.7111 - val_accuracy: 0.5844\n",
      "Epoch 11/1000\n",
      "178/178 [==============================] - 0s 185us/step - loss: 2.6430 - accuracy: 0.4719 - val_loss: 0.7097 - val_accuracy: 0.5714\n",
      "Epoch 12/1000\n",
      "178/178 [==============================] - 0s 170us/step - loss: 2.8106 - accuracy: 0.4607 - val_loss: 0.7095 - val_accuracy: 0.5714\n",
      "Epoch 13/1000\n",
      "178/178 [==============================] - 0s 182us/step - loss: 2.1447 - accuracy: 0.4944 - val_loss: 0.7085 - val_accuracy: 0.5714\n",
      "Epoch 14/1000\n",
      "178/178 [==============================] - 0s 184us/step - loss: 1.8260 - accuracy: 0.4944 - val_loss: 0.7080 - val_accuracy: 0.5714\n",
      "Epoch 15/1000\n",
      "178/178 [==============================] - 0s 208us/step - loss: 1.6083 - accuracy: 0.5618 - val_loss: 0.7075 - val_accuracy: 0.5714\n",
      "Epoch 16/1000\n",
      "178/178 [==============================] - 0s 218us/step - loss: 2.1919 - accuracy: 0.5281 - val_loss: 0.7069 - val_accuracy: 0.5714\n",
      "Epoch 17/1000\n",
      "178/178 [==============================] - 0s 172us/step - loss: 1.8594 - accuracy: 0.5449 - val_loss: 0.7065 - val_accuracy: 0.5714\n",
      "Epoch 18/1000\n",
      "178/178 [==============================] - 0s 203us/step - loss: 1.7739 - accuracy: 0.5506 - val_loss: 0.7059 - val_accuracy: 0.5714\n",
      "Epoch 19/1000\n",
      "178/178 [==============================] - 0s 175us/step - loss: 2.1908 - accuracy: 0.5281 - val_loss: 0.7056 - val_accuracy: 0.5714\n",
      "Epoch 20/1000\n",
      "178/178 [==============================] - 0s 183us/step - loss: 2.7134 - accuracy: 0.4663 - val_loss: 0.7056 - val_accuracy: 0.5714\n",
      "Epoch 21/1000\n",
      "178/178 [==============================] - 0s 182us/step - loss: 1.8740 - accuracy: 0.5225 - val_loss: 0.7058 - val_accuracy: 0.5714\n",
      "Epoch 22/1000\n",
      "178/178 [==============================] - 0s 181us/step - loss: 2.1240 - accuracy: 0.5056 - val_loss: 0.7054 - val_accuracy: 0.5714\n",
      "Epoch 23/1000\n",
      "178/178 [==============================] - 0s 215us/step - loss: 1.9568 - accuracy: 0.6011 - val_loss: 0.7051 - val_accuracy: 0.5714\n",
      "Epoch 24/1000\n",
      "178/178 [==============================] - 0s 205us/step - loss: 2.6171 - accuracy: 0.4831 - val_loss: 0.7054 - val_accuracy: 0.5714\n",
      "Epoch 25/1000\n",
      "178/178 [==============================] - 0s 184us/step - loss: 2.1968 - accuracy: 0.5112 - val_loss: 0.7058 - val_accuracy: 0.5714\n",
      "Epoch 26/1000\n",
      "178/178 [==============================] - 0s 166us/step - loss: 1.3399 - accuracy: 0.5843 - val_loss: 0.7060 - val_accuracy: 0.5714\n",
      "Epoch 27/1000\n",
      "178/178 [==============================] - 0s 179us/step - loss: 2.5167 - accuracy: 0.5000 - val_loss: 0.7061 - val_accuracy: 0.5714\n",
      "Epoch 28/1000\n",
      "178/178 [==============================] - 0s 163us/step - loss: 2.1441 - accuracy: 0.5730 - val_loss: 0.7047 - val_accuracy: 0.5714\n",
      "Epoch 29/1000\n",
      "178/178 [==============================] - 0s 168us/step - loss: 1.8396 - accuracy: 0.5562 - val_loss: 0.7046 - val_accuracy: 0.5714\n",
      "Epoch 30/1000\n",
      "178/178 [==============================] - 0s 201us/step - loss: 2.1207 - accuracy: 0.5000 - val_loss: 0.7044 - val_accuracy: 0.5714\n",
      "Epoch 31/1000\n",
      "178/178 [==============================] - 0s 185us/step - loss: 2.6107 - accuracy: 0.4888 - val_loss: 0.7032 - val_accuracy: 0.5714\n",
      "Epoch 32/1000\n",
      "178/178 [==============================] - 0s 178us/step - loss: 1.8589 - accuracy: 0.5562 - val_loss: 0.7038 - val_accuracy: 0.5714\n",
      "Epoch 33/1000\n",
      "178/178 [==============================] - 0s 185us/step - loss: 2.2071 - accuracy: 0.5506 - val_loss: 0.7043 - val_accuracy: 0.5714\n",
      "Epoch 34/1000\n",
      "178/178 [==============================] - 0s 181us/step - loss: 2.2572 - accuracy: 0.5899 - val_loss: 0.7039 - val_accuracy: 0.5714\n",
      "Epoch 35/1000\n",
      "178/178 [==============================] - 0s 209us/step - loss: 2.4211 - accuracy: 0.5787 - val_loss: 0.7031 - val_accuracy: 0.5714\n",
      "Epoch 36/1000\n",
      "178/178 [==============================] - 0s 202us/step - loss: 1.7691 - accuracy: 0.6124 - val_loss: 0.7029 - val_accuracy: 0.5714\n",
      "Epoch 37/1000\n",
      "178/178 [==============================] - 0s 207us/step - loss: 2.2920 - accuracy: 0.5899 - val_loss: 0.7031 - val_accuracy: 0.5714\n",
      "Epoch 38/1000\n",
      "178/178 [==============================] - 0s 188us/step - loss: 2.6034 - accuracy: 0.5899 - val_loss: 0.7036 - val_accuracy: 0.5714\n",
      "Epoch 39/1000\n",
      "178/178 [==============================] - 0s 208us/step - loss: 2.2899 - accuracy: 0.5955 - val_loss: 0.7023 - val_accuracy: 0.5844\n",
      "Epoch 40/1000\n",
      "178/178 [==============================] - 0s 215us/step - loss: 1.7468 - accuracy: 0.6629 - val_loss: 0.7035 - val_accuracy: 0.5714\n",
      "Epoch 41/1000\n",
      "178/178 [==============================] - 0s 207us/step - loss: 2.7774 - accuracy: 0.5787 - val_loss: 0.7022 - val_accuracy: 0.5844\n",
      "Epoch 42/1000\n",
      "178/178 [==============================] - 0s 224us/step - loss: 2.5972 - accuracy: 0.5955 - val_loss: 0.7012 - val_accuracy: 0.5844\n",
      "Epoch 43/1000\n",
      "178/178 [==============================] - 0s 231us/step - loss: 1.8402 - accuracy: 0.6573 - val_loss: 0.7013 - val_accuracy: 0.5844\n",
      "Epoch 44/1000\n",
      "178/178 [==============================] - 0s 219us/step - loss: 1.6857 - accuracy: 0.6517 - val_loss: 0.7015 - val_accuracy: 0.6104\n",
      "Epoch 45/1000\n",
      "178/178 [==============================] - 0s 195us/step - loss: 1.7992 - accuracy: 0.6966 - val_loss: 0.7020 - val_accuracy: 0.5714\n",
      "Epoch 46/1000\n",
      "178/178 [==============================] - 0s 225us/step - loss: 2.1836 - accuracy: 0.6236 - val_loss: 0.7009 - val_accuracy: 0.5974\n",
      "Epoch 47/1000\n",
      "178/178 [==============================] - 0s 190us/step - loss: 1.5833 - accuracy: 0.6854 - val_loss: 0.7014 - val_accuracy: 0.5974\n",
      "Epoch 48/1000\n",
      "178/178 [==============================] - 0s 206us/step - loss: 2.0986 - accuracy: 0.6236 - val_loss: 0.7017 - val_accuracy: 0.6104\n",
      "Epoch 49/1000\n",
      "178/178 [==============================] - 0s 217us/step - loss: 2.0889 - accuracy: 0.6292 - val_loss: 0.7019 - val_accuracy: 0.5844\n",
      "Epoch 50/1000\n",
      "178/178 [==============================] - 0s 231us/step - loss: 2.0623 - accuracy: 0.6573 - val_loss: 0.7001 - val_accuracy: 0.5844\n",
      "Epoch 51/1000\n",
      "178/178 [==============================] - 0s 221us/step - loss: 1.9169 - accuracy: 0.6461 - val_loss: 0.7002 - val_accuracy: 0.5844\n",
      "Epoch 52/1000\n",
      "178/178 [==============================] - 0s 200us/step - loss: 1.9298 - accuracy: 0.6461 - val_loss: 0.7010 - val_accuracy: 0.6234\n",
      "Epoch 53/1000\n",
      "178/178 [==============================] - 0s 192us/step - loss: 2.0317 - accuracy: 0.6124 - val_loss: 0.7008 - val_accuracy: 0.6104\n",
      "Epoch 54/1000\n",
      "178/178 [==============================] - 0s 207us/step - loss: 1.6531 - accuracy: 0.6798 - val_loss: 0.7015 - val_accuracy: 0.6234\n",
      "Epoch 55/1000\n",
      "178/178 [==============================] - 0s 233us/step - loss: 3.1079 - accuracy: 0.5562 - val_loss: 0.7013 - val_accuracy: 0.5974\n",
      "Epoch 56/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 232us/step - loss: 2.3512 - accuracy: 0.6067 - val_loss: 0.7000 - val_accuracy: 0.6234\n",
      "Epoch 57/1000\n",
      "178/178 [==============================] - 0s 236us/step - loss: 2.6732 - accuracy: 0.6011 - val_loss: 0.7008 - val_accuracy: 0.6234\n",
      "Epoch 58/1000\n",
      "178/178 [==============================] - 0s 199us/step - loss: 2.7034 - accuracy: 0.5674 - val_loss: 0.7010 - val_accuracy: 0.5974\n",
      "Epoch 59/1000\n",
      "178/178 [==============================] - 0s 202us/step - loss: 1.8286 - accuracy: 0.6517 - val_loss: 0.7011 - val_accuracy: 0.6104\n",
      "Epoch 60/1000\n",
      "178/178 [==============================] - 0s 177us/step - loss: 2.5796 - accuracy: 0.6180 - val_loss: 0.7007 - val_accuracy: 0.5974\n",
      "Epoch 61/1000\n",
      "178/178 [==============================] - 0s 177us/step - loss: 2.2587 - accuracy: 0.5955 - val_loss: 0.7021 - val_accuracy: 0.5844\n",
      "Epoch 62/1000\n",
      "178/178 [==============================] - 0s 165us/step - loss: 2.0316 - accuracy: 0.6124 - val_loss: 0.7014 - val_accuracy: 0.6234\n",
      "Epoch 63/1000\n",
      "178/178 [==============================] - 0s 169us/step - loss: 2.6526 - accuracy: 0.6067 - val_loss: 0.7009 - val_accuracy: 0.5974\n",
      "Epoch 64/1000\n",
      "178/178 [==============================] - 0s 195us/step - loss: 2.4183 - accuracy: 0.6292 - val_loss: 0.7006 - val_accuracy: 0.6234\n",
      "Epoch 65/1000\n",
      "178/178 [==============================] - 0s 167us/step - loss: 1.9088 - accuracy: 0.6404 - val_loss: 0.7004 - val_accuracy: 0.5974\n",
      "Epoch 66/1000\n",
      "178/178 [==============================] - 0s 167us/step - loss: 2.4878 - accuracy: 0.6236 - val_loss: 0.7012 - val_accuracy: 0.6104\n",
      "Epoch 67/1000\n",
      "178/178 [==============================] - 0s 196us/step - loss: 1.9947 - accuracy: 0.6517 - val_loss: 0.6998 - val_accuracy: 0.6234\n",
      "Epoch 68/1000\n",
      "178/178 [==============================] - 0s 177us/step - loss: 2.5177 - accuracy: 0.5955 - val_loss: 0.7003 - val_accuracy: 0.6104\n",
      "Epoch 69/1000\n",
      "178/178 [==============================] - 0s 178us/step - loss: 2.4028 - accuracy: 0.6292 - val_loss: 0.6996 - val_accuracy: 0.6234\n",
      "Epoch 70/1000\n",
      "178/178 [==============================] - 0s 156us/step - loss: 2.2703 - accuracy: 0.6124 - val_loss: 0.6994 - val_accuracy: 0.6494\n",
      "Epoch 71/1000\n",
      "178/178 [==============================] - 0s 200us/step - loss: 2.6572 - accuracy: 0.6067 - val_loss: 0.6988 - val_accuracy: 0.6494\n",
      "Epoch 72/1000\n",
      "178/178 [==============================] - 0s 151us/step - loss: 1.9877 - accuracy: 0.6685 - val_loss: 0.7003 - val_accuracy: 0.6494\n",
      "Epoch 73/1000\n",
      "178/178 [==============================] - 0s 198us/step - loss: 1.9237 - accuracy: 0.6404 - val_loss: 0.6999 - val_accuracy: 0.6494\n",
      "Epoch 74/1000\n",
      "178/178 [==============================] - 0s 180us/step - loss: 1.6591 - accuracy: 0.6742 - val_loss: 0.6998 - val_accuracy: 0.6494\n",
      "Epoch 75/1000\n",
      "178/178 [==============================] - 0s 149us/step - loss: 1.8169 - accuracy: 0.6685 - val_loss: 0.6987 - val_accuracy: 0.6494\n",
      "Epoch 76/1000\n",
      "178/178 [==============================] - 0s 202us/step - loss: 1.8268 - accuracy: 0.6629 - val_loss: 0.6994 - val_accuracy: 0.6494\n",
      "Epoch 77/1000\n",
      "178/178 [==============================] - 0s 177us/step - loss: 1.7455 - accuracy: 0.6461 - val_loss: 0.6992 - val_accuracy: 0.6494\n",
      "Epoch 78/1000\n",
      "178/178 [==============================] - 0s 166us/step - loss: 2.2325 - accuracy: 0.6517 - val_loss: 0.6992 - val_accuracy: 0.6623\n",
      "Epoch 79/1000\n",
      "178/178 [==============================] - 0s 150us/step - loss: 1.8306 - accuracy: 0.6629 - val_loss: 0.6985 - val_accuracy: 0.6494\n",
      "Epoch 80/1000\n",
      "178/178 [==============================] - 0s 195us/step - loss: 1.8912 - accuracy: 0.6629 - val_loss: 0.6982 - val_accuracy: 0.6364\n",
      "Epoch 81/1000\n",
      "178/178 [==============================] - 0s 176us/step - loss: 2.3953 - accuracy: 0.6348 - val_loss: 0.6980 - val_accuracy: 0.6364\n",
      "Epoch 82/1000\n",
      "178/178 [==============================] - 0s 155us/step - loss: 1.6959 - accuracy: 0.7079 - val_loss: 0.6969 - val_accuracy: 0.6494\n",
      "Epoch 83/1000\n",
      "178/178 [==============================] - 0s 203us/step - loss: 2.2439 - accuracy: 0.6404 - val_loss: 0.6960 - val_accuracy: 0.6494\n",
      "Epoch 84/1000\n",
      "178/178 [==============================] - 0s 183us/step - loss: 1.8189 - accuracy: 0.6742 - val_loss: 0.6964 - val_accuracy: 0.6364\n",
      "Epoch 85/1000\n",
      "178/178 [==============================] - 0s 175us/step - loss: 2.1441 - accuracy: 0.6629 - val_loss: 0.6960 - val_accuracy: 0.6494\n",
      "Epoch 86/1000\n",
      "178/178 [==============================] - 0s 180us/step - loss: 2.0652 - accuracy: 0.6629 - val_loss: 0.6966 - val_accuracy: 0.6494\n",
      "Epoch 87/1000\n",
      "178/178 [==============================] - 0s 188us/step - loss: 1.8085 - accuracy: 0.6742 - val_loss: 0.6984 - val_accuracy: 0.6623\n",
      "Epoch 88/1000\n",
      "178/178 [==============================] - 0s 179us/step - loss: 2.6898 - accuracy: 0.6573 - val_loss: 0.6951 - val_accuracy: 0.6753\n",
      "Epoch 89/1000\n",
      "178/178 [==============================] - 0s 177us/step - loss: 2.0801 - accuracy: 0.6461 - val_loss: 0.6968 - val_accuracy: 0.6494\n",
      "Epoch 90/1000\n",
      "178/178 [==============================] - 0s 173us/step - loss: 2.8078 - accuracy: 0.6292 - val_loss: 0.6964 - val_accuracy: 0.6623\n",
      "Epoch 91/1000\n",
      "178/178 [==============================] - 0s 186us/step - loss: 2.0869 - accuracy: 0.6404 - val_loss: 0.6969 - val_accuracy: 0.6494\n",
      "Epoch 92/1000\n",
      "178/178 [==============================] - 0s 183us/step - loss: 2.5811 - accuracy: 0.6067 - val_loss: 0.6969 - val_accuracy: 0.6623\n",
      "Epoch 93/1000\n",
      "178/178 [==============================] - 0s 173us/step - loss: 1.7181 - accuracy: 0.6910 - val_loss: 0.6959 - val_accuracy: 0.6623\n",
      "Epoch 94/1000\n",
      "178/178 [==============================] - 0s 199us/step - loss: 2.2330 - accuracy: 0.6517 - val_loss: 0.6965 - val_accuracy: 0.6753\n",
      "Epoch 95/1000\n",
      "178/178 [==============================] - 0s 197us/step - loss: 1.8124 - accuracy: 0.6629 - val_loss: 0.6972 - val_accuracy: 0.6753\n",
      "Epoch 96/1000\n",
      "178/178 [==============================] - 0s 196us/step - loss: 2.2269 - accuracy: 0.6573 - val_loss: 0.6984 - val_accuracy: 0.6623\n",
      "Epoch 97/1000\n",
      "178/178 [==============================] - 0s 182us/step - loss: 2.1538 - accuracy: 0.6461 - val_loss: 0.6969 - val_accuracy: 0.6623\n",
      "Epoch 98/1000\n",
      "178/178 [==============================] - 0s 159us/step - loss: 2.4623 - accuracy: 0.6573 - val_loss: 0.6969 - val_accuracy: 0.6623\n",
      "Epoch 99/1000\n",
      "178/178 [==============================] - 0s 179us/step - loss: 2.1525 - accuracy: 0.6461 - val_loss: 0.6974 - val_accuracy: 0.6623\n",
      "Epoch 100/1000\n",
      "178/178 [==============================] - 0s 169us/step - loss: 2.2066 - accuracy: 0.6517 - val_loss: 0.6954 - val_accuracy: 0.6753\n",
      "Epoch 101/1000\n",
      "178/178 [==============================] - 0s 186us/step - loss: 1.8161 - accuracy: 0.6685 - val_loss: 0.6990 - val_accuracy: 0.6753\n",
      "Epoch 102/1000\n",
      "178/178 [==============================] - 0s 169us/step - loss: 1.8054 - accuracy: 0.6629 - val_loss: 0.6964 - val_accuracy: 0.6623\n",
      "Epoch 103/1000\n",
      "178/178 [==============================] - 0s 197us/step - loss: 2.1137 - accuracy: 0.6798 - val_loss: 0.6968 - val_accuracy: 0.6753\n",
      "Epoch 104/1000\n",
      "178/178 [==============================] - 0s 171us/step - loss: 2.4049 - accuracy: 0.6236 - val_loss: 0.6964 - val_accuracy: 0.6753\n",
      "Epoch 105/1000\n",
      "178/178 [==============================] - 0s 161us/step - loss: 2.6429 - accuracy: 0.6404 - val_loss: 0.6976 - val_accuracy: 0.6623\n",
      "Epoch 106/1000\n",
      "178/178 [==============================] - 0s 180us/step - loss: 2.8884 - accuracy: 0.6124 - val_loss: 0.6976 - val_accuracy: 0.6623\n",
      "Epoch 107/1000\n",
      "178/178 [==============================] - 0s 183us/step - loss: 2.0323 - accuracy: 0.6742 - val_loss: 0.6952 - val_accuracy: 0.6623\n",
      "Epoch 108/1000\n",
      "178/178 [==============================] - 0s 189us/step - loss: 2.4719 - accuracy: 0.6461 - val_loss: 0.6961 - val_accuracy: 0.6753\n",
      "Epoch 109/1000\n",
      "178/178 [==============================] - 0s 181us/step - loss: 1.9685 - accuracy: 0.6685 - val_loss: 0.6963 - val_accuracy: 0.6623\n",
      "Epoch 110/1000\n",
      "178/178 [==============================] - 0s 180us/step - loss: 2.2068 - accuracy: 0.6854 - val_loss: 0.6964 - val_accuracy: 0.6623\n",
      "Epoch 111/1000\n",
      "178/178 [==============================] - 0s 173us/step - loss: 1.8029 - accuracy: 0.6742 - val_loss: 0.6964 - val_accuracy: 0.6623\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/1000\n",
      "178/178 [==============================] - 0s 194us/step - loss: 1.6891 - accuracy: 0.7022 - val_loss: 0.6975 - val_accuracy: 0.6623\n",
      "Epoch 113/1000\n",
      "178/178 [==============================] - 0s 167us/step - loss: 2.3093 - accuracy: 0.6404 - val_loss: 0.6960 - val_accuracy: 0.6623\n",
      "Epoch 114/1000\n",
      "178/178 [==============================] - 0s 181us/step - loss: 1.5493 - accuracy: 0.7191 - val_loss: 0.6967 - val_accuracy: 0.6623\n",
      "Epoch 115/1000\n",
      "178/178 [==============================] - 0s 179us/step - loss: 2.0318 - accuracy: 0.6798 - val_loss: 0.6943 - val_accuracy: 0.6623\n",
      "Epoch 116/1000\n",
      "178/178 [==============================] - 0s 167us/step - loss: 2.4439 - accuracy: 0.6742 - val_loss: 0.6948 - val_accuracy: 0.6623\n",
      "Epoch 117/1000\n",
      "178/178 [==============================] - 0s 181us/step - loss: 2.1443 - accuracy: 0.6517 - val_loss: 0.6976 - val_accuracy: 0.6623\n",
      "Epoch 118/1000\n",
      "178/178 [==============================] - 0s 182us/step - loss: 2.0637 - accuracy: 0.6685 - val_loss: 0.6959 - val_accuracy: 0.6623\n",
      "Epoch 119/1000\n",
      "178/178 [==============================] - 0s 179us/step - loss: 1.7684 - accuracy: 0.7079 - val_loss: 0.6948 - val_accuracy: 0.6623\n",
      "Epoch 120/1000\n",
      "178/178 [==============================] - 0s 199us/step - loss: 1.9313 - accuracy: 0.7135 - val_loss: 0.6954 - val_accuracy: 0.6623\n",
      "Epoch 121/1000\n",
      "178/178 [==============================] - 0s 191us/step - loss: 2.1001 - accuracy: 0.6854 - val_loss: 0.6951 - val_accuracy: 0.6623\n",
      "Epoch 122/1000\n",
      "178/178 [==============================] - 0s 176us/step - loss: 2.2870 - accuracy: 0.6685 - val_loss: 0.6946 - val_accuracy: 0.6623\n",
      "Epoch 123/1000\n",
      "178/178 [==============================] - 0s 182us/step - loss: 2.1041 - accuracy: 0.7079 - val_loss: 0.6967 - val_accuracy: 0.6623\n",
      "Epoch 124/1000\n",
      "178/178 [==============================] - 0s 181us/step - loss: 2.1918 - accuracy: 0.7135 - val_loss: 0.6949 - val_accuracy: 0.6623\n",
      "Epoch 125/1000\n",
      "178/178 [==============================] - 0s 175us/step - loss: 2.0532 - accuracy: 0.6966 - val_loss: 0.6947 - val_accuracy: 0.6623\n",
      "Epoch 126/1000\n",
      "178/178 [==============================] - 0s 171us/step - loss: 2.1832 - accuracy: 0.7079 - val_loss: 0.6945 - val_accuracy: 0.6623\n",
      "Epoch 127/1000\n",
      "178/178 [==============================] - 0s 193us/step - loss: 2.2789 - accuracy: 0.7135 - val_loss: 0.6959 - val_accuracy: 0.6623\n",
      "Epoch 128/1000\n",
      "178/178 [==============================] - 0s 168us/step - loss: 2.1115 - accuracy: 0.7191 - val_loss: 0.6956 - val_accuracy: 0.6623\n",
      "Epoch 129/1000\n",
      "178/178 [==============================] - 0s 153us/step - loss: 1.7660 - accuracy: 0.7416 - val_loss: 0.6942 - val_accuracy: 0.6623\n",
      "Epoch 130/1000\n",
      "178/178 [==============================] - 0s 194us/step - loss: 1.6057 - accuracy: 0.7303 - val_loss: 0.6945 - val_accuracy: 0.6623\n",
      "Epoch 131/1000\n",
      "178/178 [==============================] - 0s 182us/step - loss: 2.0343 - accuracy: 0.7079 - val_loss: 0.6944 - val_accuracy: 0.6623\n",
      "Epoch 132/1000\n",
      "178/178 [==============================] - 0s 177us/step - loss: 2.4630 - accuracy: 0.6854 - val_loss: 0.6944 - val_accuracy: 0.6623\n",
      "Epoch 133/1000\n",
      "178/178 [==============================] - 0s 173us/step - loss: 2.0905 - accuracy: 0.7303 - val_loss: 0.6944 - val_accuracy: 0.6623\n",
      "Epoch 134/1000\n",
      "178/178 [==============================] - 0s 171us/step - loss: 2.0663 - accuracy: 0.7528 - val_loss: 0.6936 - val_accuracy: 0.6623\n",
      "Epoch 135/1000\n",
      "178/178 [==============================] - 0s 191us/step - loss: 1.5028 - accuracy: 0.7865 - val_loss: 0.6957 - val_accuracy: 0.6364\n",
      "Epoch 136/1000\n",
      "178/178 [==============================] - 0s 176us/step - loss: 2.0292 - accuracy: 0.7135 - val_loss: 0.6938 - val_accuracy: 0.6623\n",
      "Epoch 137/1000\n",
      "178/178 [==============================] - 0s 167us/step - loss: 2.2565 - accuracy: 0.7360 - val_loss: 0.6938 - val_accuracy: 0.6494\n",
      "Epoch 138/1000\n",
      "178/178 [==============================] - 0s 180us/step - loss: 1.8466 - accuracy: 0.7360 - val_loss: 0.6921 - val_accuracy: 0.6623\n",
      "Epoch 139/1000\n",
      "178/178 [==============================] - 0s 180us/step - loss: 2.1742 - accuracy: 0.7191 - val_loss: 0.6926 - val_accuracy: 0.6364\n",
      "Epoch 140/1000\n",
      "178/178 [==============================] - 0s 157us/step - loss: 1.5957 - accuracy: 0.7416 - val_loss: 0.6916 - val_accuracy: 0.6623\n",
      "Epoch 141/1000\n",
      "178/178 [==============================] - 0s 191us/step - loss: 1.8455 - accuracy: 0.7360 - val_loss: 0.6927 - val_accuracy: 0.6364\n",
      "Epoch 142/1000\n",
      "178/178 [==============================] - 0s 172us/step - loss: 1.9381 - accuracy: 0.7360 - val_loss: 0.6930 - val_accuracy: 0.6494\n",
      "Epoch 143/1000\n",
      "178/178 [==============================] - 0s 183us/step - loss: 1.9293 - accuracy: 0.7528 - val_loss: 0.6913 - val_accuracy: 0.6494\n",
      "Epoch 144/1000\n",
      "178/178 [==============================] - 0s 178us/step - loss: 2.4944 - accuracy: 0.7360 - val_loss: 0.6919 - val_accuracy: 0.6364\n",
      "Epoch 145/1000\n",
      "178/178 [==============================] - 0s 170us/step - loss: 2.3764 - accuracy: 0.6966 - val_loss: 0.6930 - val_accuracy: 0.6364\n",
      "Epoch 146/1000\n",
      "178/178 [==============================] - 0s 164us/step - loss: 1.3209 - accuracy: 0.7865 - val_loss: 0.6905 - val_accuracy: 0.6364\n",
      "Epoch 147/1000\n",
      "178/178 [==============================] - 0s 168us/step - loss: 2.2074 - accuracy: 0.7022 - val_loss: 0.6909 - val_accuracy: 0.6494\n",
      "Epoch 148/1000\n",
      "178/178 [==============================] - 0s 177us/step - loss: 1.7040 - accuracy: 0.7360 - val_loss: 0.6908 - val_accuracy: 0.6494\n",
      "Epoch 149/1000\n",
      "178/178 [==============================] - 0s 192us/step - loss: 1.5111 - accuracy: 0.7865 - val_loss: 0.6912 - val_accuracy: 0.6494\n",
      "Epoch 150/1000\n",
      "178/178 [==============================] - 0s 189us/step - loss: 1.9304 - accuracy: 0.7360 - val_loss: 0.6905 - val_accuracy: 0.6494\n",
      "Epoch 151/1000\n",
      "178/178 [==============================] - 0s 169us/step - loss: 1.6716 - accuracy: 0.7697 - val_loss: 0.6906 - val_accuracy: 0.6364\n",
      "Epoch 152/1000\n",
      "178/178 [==============================] - 0s 174us/step - loss: 1.4861 - accuracy: 0.7697 - val_loss: 0.6908 - val_accuracy: 0.6364\n",
      "Epoch 153/1000\n",
      "178/178 [==============================] - 0s 162us/step - loss: 2.9523 - accuracy: 0.6573 - val_loss: 0.6902 - val_accuracy: 0.6494\n",
      "Epoch 154/1000\n",
      "178/178 [==============================] - 0s 157us/step - loss: 2.0030 - accuracy: 0.7416 - val_loss: 0.6908 - val_accuracy: 0.6364\n",
      "Epoch 155/1000\n",
      "178/178 [==============================] - 0s 209us/step - loss: 2.1582 - accuracy: 0.7528 - val_loss: 0.6910 - val_accuracy: 0.6364\n",
      "Epoch 156/1000\n",
      "178/178 [==============================] - 0s 186us/step - loss: 2.2343 - accuracy: 0.7416 - val_loss: 0.6912 - val_accuracy: 0.6364\n",
      "Epoch 157/1000\n",
      "178/178 [==============================] - 0s 199us/step - loss: 2.4176 - accuracy: 0.7360 - val_loss: 0.6916 - val_accuracy: 0.6364\n",
      "Epoch 158/1000\n",
      "178/178 [==============================] - 0s 181us/step - loss: 1.9313 - accuracy: 0.7360 - val_loss: 0.6924 - val_accuracy: 0.6364\n",
      "Epoch 159/1000\n",
      "178/178 [==============================] - 0s 184us/step - loss: 2.4235 - accuracy: 0.7191 - val_loss: 0.6900 - val_accuracy: 0.6364\n",
      "Epoch 160/1000\n",
      "178/178 [==============================] - 0s 187us/step - loss: 1.4825 - accuracy: 0.7865 - val_loss: 0.6912 - val_accuracy: 0.6364\n",
      "Epoch 161/1000\n",
      "178/178 [==============================] - 0s 200us/step - loss: 1.7281 - accuracy: 0.7697 - val_loss: 0.6909 - val_accuracy: 0.6364\n",
      "Epoch 162/1000\n",
      "178/178 [==============================] - 0s 185us/step - loss: 2.0753 - accuracy: 0.7472 - val_loss: 0.6901 - val_accuracy: 0.6364\n",
      "Epoch 163/1000\n",
      "178/178 [==============================] - 0s 178us/step - loss: 2.3475 - accuracy: 0.7303 - val_loss: 0.6908 - val_accuracy: 0.6494\n",
      "Epoch 164/1000\n",
      "178/178 [==============================] - 0s 182us/step - loss: 1.8305 - accuracy: 0.7640 - val_loss: 0.6909 - val_accuracy: 0.6364\n",
      "Epoch 165/1000\n",
      "178/178 [==============================] - 0s 167us/step - loss: 1.3038 - accuracy: 0.8258 - val_loss: 0.6909 - val_accuracy: 0.6364\n",
      "Epoch 166/1000\n",
      "178/178 [==============================] - 0s 178us/step - loss: 3.3414 - accuracy: 0.6910 - val_loss: 0.6899 - val_accuracy: 0.6364\n",
      "Epoch 167/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 200us/step - loss: 1.8340 - accuracy: 0.7921 - val_loss: 0.6914 - val_accuracy: 0.6364\n",
      "Epoch 168/1000\n",
      "178/178 [==============================] - 0s 175us/step - loss: 2.1479 - accuracy: 0.7753 - val_loss: 0.6903 - val_accuracy: 0.6364\n",
      "Epoch 169/1000\n",
      "178/178 [==============================] - 0s 167us/step - loss: 1.8076 - accuracy: 0.8034 - val_loss: 0.6907 - val_accuracy: 0.6364\n",
      "Epoch 170/1000\n",
      "178/178 [==============================] - 0s 168us/step - loss: 2.7689 - accuracy: 0.7191 - val_loss: 0.6905 - val_accuracy: 0.6364\n",
      "Epoch 171/1000\n",
      "178/178 [==============================] - 0s 197us/step - loss: 2.0754 - accuracy: 0.7978 - val_loss: 0.6924 - val_accuracy: 0.6364\n",
      "Epoch 172/1000\n",
      "178/178 [==============================] - 0s 168us/step - loss: 2.1472 - accuracy: 0.7809 - val_loss: 0.6928 - val_accuracy: 0.6364\n",
      "Epoch 173/1000\n",
      "178/178 [==============================] - 0s 177us/step - loss: 1.8180 - accuracy: 0.8034 - val_loss: 0.6913 - val_accuracy: 0.6364\n",
      "Epoch 174/1000\n",
      "178/178 [==============================] - 0s 180us/step - loss: 1.9916 - accuracy: 0.7978 - val_loss: 0.6902 - val_accuracy: 0.6364\n",
      "Epoch 175/1000\n",
      "178/178 [==============================] - 0s 182us/step - loss: 1.3099 - accuracy: 0.8258 - val_loss: 0.6921 - val_accuracy: 0.6364\n",
      "Epoch 176/1000\n",
      "178/178 [==============================] - 0s 163us/step - loss: 1.8879 - accuracy: 0.8146 - val_loss: 0.6886 - val_accuracy: 0.6364\n",
      "Epoch 177/1000\n",
      "178/178 [==============================] - 0s 179us/step - loss: 2.4199 - accuracy: 0.7697 - val_loss: 0.6904 - val_accuracy: 0.6364\n",
      "Epoch 178/1000\n",
      "178/178 [==============================] - 0s 191us/step - loss: 2.6749 - accuracy: 0.7584 - val_loss: 0.6937 - val_accuracy: 0.6364\n",
      "Epoch 179/1000\n",
      "178/178 [==============================] - 0s 166us/step - loss: 2.2521 - accuracy: 0.8090 - val_loss: 0.6902 - val_accuracy: 0.6364\n",
      "Epoch 180/1000\n",
      "178/178 [==============================] - 0s 167us/step - loss: 2.2416 - accuracy: 0.7978 - val_loss: 0.6907 - val_accuracy: 0.6364\n",
      "Epoch 181/1000\n",
      "178/178 [==============================] - 0s 193us/step - loss: 1.6196 - accuracy: 0.8258 - val_loss: 0.6896 - val_accuracy: 0.6364\n",
      "Epoch 182/1000\n",
      "178/178 [==============================] - 0s 179us/step - loss: 2.1514 - accuracy: 0.8034 - val_loss: 0.6908 - val_accuracy: 0.6364\n",
      "Epoch 183/1000\n",
      "178/178 [==============================] - 0s 178us/step - loss: 1.9107 - accuracy: 0.8090 - val_loss: 0.6905 - val_accuracy: 0.6364\n",
      "Epoch 184/1000\n",
      "178/178 [==============================] - 0s 154us/step - loss: 2.0528 - accuracy: 0.7978 - val_loss: 0.6906 - val_accuracy: 0.6364\n",
      "Epoch 185/1000\n",
      "178/178 [==============================] - 0s 198us/step - loss: 1.9730 - accuracy: 0.8090 - val_loss: 0.6904 - val_accuracy: 0.6364\n",
      "Epoch 186/1000\n",
      "178/178 [==============================] - 0s 155us/step - loss: 1.8203 - accuracy: 0.7921 - val_loss: 0.6902 - val_accuracy: 0.6364\n",
      "Epoch 187/1000\n",
      "178/178 [==============================] - 0s 192us/step - loss: 2.3117 - accuracy: 0.7921 - val_loss: 0.6897 - val_accuracy: 0.6364\n",
      "Epoch 188/1000\n",
      "178/178 [==============================] - 0s 192us/step - loss: 1.5507 - accuracy: 0.8315 - val_loss: 0.6902 - val_accuracy: 0.6364\n",
      "Epoch 189/1000\n",
      "178/178 [==============================] - 0s 172us/step - loss: 2.3957 - accuracy: 0.7865 - val_loss: 0.6905 - val_accuracy: 0.6364\n",
      "Epoch 190/1000\n",
      "178/178 [==============================] - 0s 192us/step - loss: 1.7273 - accuracy: 0.8202 - val_loss: 0.6880 - val_accuracy: 0.6364\n",
      "Epoch 191/1000\n",
      "178/178 [==============================] - 0s 177us/step - loss: 1.9555 - accuracy: 0.8258 - val_loss: 0.6913 - val_accuracy: 0.6364\n",
      "Epoch 192/1000\n",
      "178/178 [==============================] - 0s 178us/step - loss: 2.2191 - accuracy: 0.7865 - val_loss: 0.6905 - val_accuracy: 0.6364\n",
      "Epoch 193/1000\n",
      "178/178 [==============================] - 0s 175us/step - loss: 1.6205 - accuracy: 0.8596 - val_loss: 0.6923 - val_accuracy: 0.6364\n",
      "Epoch 194/1000\n",
      "178/178 [==============================] - 0s 176us/step - loss: 1.6418 - accuracy: 0.8315 - val_loss: 0.6938 - val_accuracy: 0.6364\n",
      "Epoch 195/1000\n",
      "178/178 [==============================] - 0s 181us/step - loss: 2.2196 - accuracy: 0.7921 - val_loss: 0.6919 - val_accuracy: 0.6364\n",
      "Epoch 196/1000\n",
      "178/178 [==============================] - 0s 170us/step - loss: 2.1640 - accuracy: 0.7865 - val_loss: 0.6915 - val_accuracy: 0.6364\n",
      "Epoch 197/1000\n",
      "178/178 [==============================] - 0s 182us/step - loss: 1.9689 - accuracy: 0.8146 - val_loss: 0.6910 - val_accuracy: 0.6364\n",
      "Epoch 198/1000\n",
      "178/178 [==============================] - 0s 189us/step - loss: 2.3832 - accuracy: 0.7921 - val_loss: 0.6918 - val_accuracy: 0.6364\n",
      "Epoch 199/1000\n",
      "178/178 [==============================] - 0s 184us/step - loss: 2.0439 - accuracy: 0.8202 - val_loss: 0.6920 - val_accuracy: 0.6364\n",
      "Epoch 200/1000\n",
      "178/178 [==============================] - 0s 189us/step - loss: 1.5229 - accuracy: 0.8427 - val_loss: 0.6898 - val_accuracy: 0.6364\n",
      "Epoch 201/1000\n",
      "178/178 [==============================] - 0s 197us/step - loss: 1.8566 - accuracy: 0.8371 - val_loss: 0.6897 - val_accuracy: 0.6364\n",
      "Epoch 202/1000\n",
      "178/178 [==============================] - 0s 189us/step - loss: 2.0154 - accuracy: 0.8202 - val_loss: 0.6896 - val_accuracy: 0.6364\n",
      "Epoch 203/1000\n",
      "178/178 [==============================] - 0s 166us/step - loss: 2.4590 - accuracy: 0.7921 - val_loss: 0.6891 - val_accuracy: 0.6364\n",
      "Epoch 204/1000\n",
      "178/178 [==============================] - 0s 176us/step - loss: 2.2037 - accuracy: 0.8146 - val_loss: 0.6910 - val_accuracy: 0.6364\n",
      "Epoch 205/1000\n",
      "178/178 [==============================] - 0s 168us/step - loss: 1.9410 - accuracy: 0.8258 - val_loss: 0.6916 - val_accuracy: 0.6364\n",
      "Epoch 206/1000\n",
      "178/178 [==============================] - 0s 188us/step - loss: 1.5941 - accuracy: 0.8258 - val_loss: 0.6883 - val_accuracy: 0.6364\n",
      "Epoch 207/1000\n",
      "178/178 [==============================] - 0s 192us/step - loss: 2.0228 - accuracy: 0.8090 - val_loss: 0.6887 - val_accuracy: 0.6364\n",
      "Epoch 208/1000\n",
      "178/178 [==============================] - 0s 170us/step - loss: 2.1063 - accuracy: 0.8146 - val_loss: 0.6892 - val_accuracy: 0.6364\n",
      "Epoch 209/1000\n",
      "178/178 [==============================] - 0s 155us/step - loss: 2.1217 - accuracy: 0.8090 - val_loss: 0.6894 - val_accuracy: 0.6364\n",
      "Epoch 210/1000\n",
      "178/178 [==============================] - 0s 191us/step - loss: 1.8430 - accuracy: 0.8315 - val_loss: 0.6925 - val_accuracy: 0.6364\n",
      "Epoch 211/1000\n",
      "178/178 [==============================] - 0s 157us/step - loss: 1.9599 - accuracy: 0.8034 - val_loss: 0.6901 - val_accuracy: 0.6364\n",
      "Epoch 212/1000\n",
      "178/178 [==============================] - 0s 187us/step - loss: 2.3715 - accuracy: 0.7865 - val_loss: 0.6909 - val_accuracy: 0.6364\n",
      "Epoch 213/1000\n",
      "178/178 [==============================] - 0s 158us/step - loss: 2.2940 - accuracy: 0.7865 - val_loss: 0.6912 - val_accuracy: 0.6364\n",
      "Epoch 214/1000\n",
      "178/178 [==============================] - 0s 206us/step - loss: 2.6477 - accuracy: 0.7584 - val_loss: 0.6900 - val_accuracy: 0.6364\n",
      "Epoch 215/1000\n",
      "178/178 [==============================] - 0s 173us/step - loss: 1.5051 - accuracy: 0.8539 - val_loss: 0.6910 - val_accuracy: 0.6364\n",
      "Epoch 216/1000\n",
      "178/178 [==============================] - 0s 181us/step - loss: 1.7642 - accuracy: 0.8371 - val_loss: 0.6912 - val_accuracy: 0.6364\n",
      "Epoch 217/1000\n",
      "178/178 [==============================] - 0s 178us/step - loss: 1.8643 - accuracy: 0.8202 - val_loss: 0.6902 - val_accuracy: 0.6364\n",
      "Epoch 218/1000\n",
      "178/178 [==============================] - 0s 172us/step - loss: 2.1335 - accuracy: 0.7978 - val_loss: 0.6914 - val_accuracy: 0.6364\n",
      "Epoch 219/1000\n",
      "178/178 [==============================] - 0s 171us/step - loss: 2.6006 - accuracy: 0.7809 - val_loss: 0.6940 - val_accuracy: 0.6234\n",
      "Epoch 220/1000\n",
      "178/178 [==============================] - 0s 179us/step - loss: 1.7002 - accuracy: 0.8258 - val_loss: 0.6942 - val_accuracy: 0.6364\n",
      "Epoch 221/1000\n",
      "178/178 [==============================] - 0s 174us/step - loss: 1.8377 - accuracy: 0.8258 - val_loss: 0.6929 - val_accuracy: 0.6364\n",
      "Epoch 222/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 186us/step - loss: 1.9406 - accuracy: 0.8146 - val_loss: 0.6915 - val_accuracy: 0.6364\n",
      "Epoch 223/1000\n",
      "178/178 [==============================] - 0s 193us/step - loss: 2.2008 - accuracy: 0.7978 - val_loss: 0.6917 - val_accuracy: 0.6364\n",
      "Epoch 224/1000\n",
      "178/178 [==============================] - 0s 171us/step - loss: 1.7787 - accuracy: 0.8202 - val_loss: 0.6921 - val_accuracy: 0.6364\n",
      "Epoch 225/1000\n",
      "178/178 [==============================] - 0s 169us/step - loss: 2.3534 - accuracy: 0.7809 - val_loss: 0.6925 - val_accuracy: 0.6234\n",
      "Epoch 226/1000\n",
      "178/178 [==============================] - 0s 166us/step - loss: 2.4634 - accuracy: 0.7865 - val_loss: 0.6918 - val_accuracy: 0.6364\n",
      "Epoch 227/1000\n",
      "178/178 [==============================] - 0s 178us/step - loss: 2.2647 - accuracy: 0.7865 - val_loss: 0.6917 - val_accuracy: 0.6364\n",
      "Epoch 228/1000\n",
      "178/178 [==============================] - 0s 179us/step - loss: 2.0242 - accuracy: 0.8090 - val_loss: 0.6934 - val_accuracy: 0.6364\n",
      "Epoch 229/1000\n",
      "178/178 [==============================] - 0s 180us/step - loss: 2.2774 - accuracy: 0.7978 - val_loss: 0.6909 - val_accuracy: 0.6364\n",
      "Epoch 230/1000\n",
      "178/178 [==============================] - 0s 185us/step - loss: 1.9320 - accuracy: 0.7978 - val_loss: 0.6914 - val_accuracy: 0.6234\n",
      "Epoch 231/1000\n",
      "178/178 [==============================] - 0s 180us/step - loss: 2.2046 - accuracy: 0.7978 - val_loss: 0.6944 - val_accuracy: 0.6234\n",
      "Epoch 232/1000\n",
      "178/178 [==============================] - 0s 167us/step - loss: 2.1687 - accuracy: 0.8202 - val_loss: 0.6957 - val_accuracy: 0.6364\n",
      "Epoch 233/1000\n",
      "178/178 [==============================] - 0s 176us/step - loss: 1.8244 - accuracy: 0.8146 - val_loss: 0.6946 - val_accuracy: 0.6364\n",
      "Epoch 234/1000\n",
      "178/178 [==============================] - 0s 171us/step - loss: 1.8305 - accuracy: 0.8258 - val_loss: 0.6941 - val_accuracy: 0.6234\n",
      "Epoch 235/1000\n",
      "178/178 [==============================] - 0s 180us/step - loss: 1.8357 - accuracy: 0.8202 - val_loss: 0.6943 - val_accuracy: 0.6364\n",
      "Epoch 236/1000\n",
      "178/178 [==============================] - 0s 176us/step - loss: 2.0995 - accuracy: 0.8034 - val_loss: 0.6935 - val_accuracy: 0.6364\n",
      "Epoch 237/1000\n",
      "178/178 [==============================] - 0s 182us/step - loss: 2.0004 - accuracy: 0.8146 - val_loss: 0.6943 - val_accuracy: 0.6364\n",
      "Epoch 238/1000\n",
      "178/178 [==============================] - 0s 179us/step - loss: 2.0061 - accuracy: 0.8146 - val_loss: 0.6969 - val_accuracy: 0.6364\n",
      "Epoch 239/1000\n",
      "178/178 [==============================] - 0s 183us/step - loss: 2.0834 - accuracy: 0.8090 - val_loss: 0.6955 - val_accuracy: 0.6364\n",
      "Epoch 240/1000\n",
      "178/178 [==============================] - 0s 189us/step - loss: 2.6949 - accuracy: 0.7753 - val_loss: 0.6950 - val_accuracy: 0.6364\n",
      "Epoch 241/1000\n",
      "178/178 [==============================] - 0s 175us/step - loss: 2.1854 - accuracy: 0.8034 - val_loss: 0.6916 - val_accuracy: 0.6364\n",
      "Epoch 242/1000\n",
      "178/178 [==============================] - 0s 181us/step - loss: 1.7401 - accuracy: 0.8371 - val_loss: 0.6956 - val_accuracy: 0.6364\n",
      "Epoch 243/1000\n",
      "178/178 [==============================] - 0s 192us/step - loss: 2.3452 - accuracy: 0.7978 - val_loss: 0.6977 - val_accuracy: 0.6364\n",
      "Epoch 244/1000\n",
      "178/178 [==============================] - 0s 205us/step - loss: 2.1777 - accuracy: 0.7809 - val_loss: 0.6941 - val_accuracy: 0.6364\n",
      "Epoch 245/1000\n",
      "178/178 [==============================] - 0s 187us/step - loss: 1.8041 - accuracy: 0.8371 - val_loss: 0.6951 - val_accuracy: 0.6364\n",
      "Epoch 246/1000\n",
      "178/178 [==============================] - 0s 181us/step - loss: 2.1812 - accuracy: 0.8146 - val_loss: 0.6959 - val_accuracy: 0.6364\n",
      "Epoch 247/1000\n",
      "178/178 [==============================] - 0s 171us/step - loss: 1.7361 - accuracy: 0.8427 - val_loss: 0.6967 - val_accuracy: 0.6234\n",
      "Epoch 248/1000\n",
      "178/178 [==============================] - 0s 165us/step - loss: 1.8226 - accuracy: 0.8202 - val_loss: 0.6960 - val_accuracy: 0.6364\n",
      "Epoch 249/1000\n",
      "178/178 [==============================] - 0s 200us/step - loss: 1.4896 - accuracy: 0.8371 - val_loss: 0.6967 - val_accuracy: 0.6364\n",
      "Epoch 250/1000\n",
      "178/178 [==============================] - 0s 180us/step - loss: 2.2515 - accuracy: 0.7865 - val_loss: 0.6956 - val_accuracy: 0.6234\n",
      "Epoch 251/1000\n",
      "178/178 [==============================] - 0s 166us/step - loss: 2.1016 - accuracy: 0.8090 - val_loss: 0.6949 - val_accuracy: 0.6364\n",
      "Epoch 252/1000\n",
      "178/178 [==============================] - 0s 156us/step - loss: 1.7453 - accuracy: 0.8090 - val_loss: 0.6955 - val_accuracy: 0.6234\n",
      "Epoch 253/1000\n",
      "178/178 [==============================] - 0s 185us/step - loss: 1.8108 - accuracy: 0.8371 - val_loss: 0.6971 - val_accuracy: 0.6234\n",
      "Epoch 254/1000\n",
      "178/178 [==============================] - 0s 186us/step - loss: 2.2406 - accuracy: 0.7753 - val_loss: 0.6954 - val_accuracy: 0.6364\n",
      "Epoch 255/1000\n",
      "178/178 [==============================] - 0s 184us/step - loss: 1.7530 - accuracy: 0.8371 - val_loss: 0.6937 - val_accuracy: 0.6364\n",
      "Epoch 256/1000\n",
      "178/178 [==============================] - 0s 187us/step - loss: 2.0123 - accuracy: 0.7978 - val_loss: 0.6962 - val_accuracy: 0.6234\n",
      "Epoch 257/1000\n",
      "178/178 [==============================] - 0s 174us/step - loss: 2.0782 - accuracy: 0.8146 - val_loss: 0.6985 - val_accuracy: 0.6234\n",
      "Epoch 258/1000\n",
      "178/178 [==============================] - 0s 195us/step - loss: 1.9193 - accuracy: 0.8090 - val_loss: 0.6949 - val_accuracy: 0.6364\n",
      "Epoch 259/1000\n",
      "178/178 [==============================] - 0s 169us/step - loss: 2.1655 - accuracy: 0.7921 - val_loss: 0.6956 - val_accuracy: 0.6234\n",
      "Epoch 260/1000\n",
      "178/178 [==============================] - 0s 181us/step - loss: 2.3329 - accuracy: 0.8034 - val_loss: 0.6994 - val_accuracy: 0.6364\n",
      "Epoch 261/1000\n",
      "178/178 [==============================] - 0s 167us/step - loss: 2.2249 - accuracy: 0.8090 - val_loss: 0.6987 - val_accuracy: 0.6364\n",
      "Epoch 262/1000\n",
      "178/178 [==============================] - 0s 206us/step - loss: 2.2450 - accuracy: 0.8034 - val_loss: 0.6953 - val_accuracy: 0.6234\n",
      "Epoch 263/1000\n",
      "178/178 [==============================] - 0s 170us/step - loss: 1.9834 - accuracy: 0.8202 - val_loss: 0.6975 - val_accuracy: 0.6234\n",
      "Epoch 264/1000\n",
      "178/178 [==============================] - 0s 180us/step - loss: 2.0607 - accuracy: 0.8090 - val_loss: 0.6967 - val_accuracy: 0.6364\n",
      "Epoch 265/1000\n",
      "178/178 [==============================] - 0s 155us/step - loss: 1.7144 - accuracy: 0.8258 - val_loss: 0.6954 - val_accuracy: 0.6234\n",
      "Epoch 266/1000\n",
      "178/178 [==============================] - 0s 166us/step - loss: 1.9885 - accuracy: 0.8146 - val_loss: 0.6961 - val_accuracy: 0.6234\n",
      "Epoch 267/1000\n",
      "178/178 [==============================] - 0s 184us/step - loss: 2.8969 - accuracy: 0.7753 - val_loss: 0.6991 - val_accuracy: 0.6364\n",
      "Epoch 268/1000\n",
      "178/178 [==============================] - 0s 180us/step - loss: 1.3862 - accuracy: 0.8539 - val_loss: 0.6967 - val_accuracy: 0.6234\n",
      "Epoch 269/1000\n",
      "178/178 [==============================] - 0s 177us/step - loss: 1.9132 - accuracy: 0.7978 - val_loss: 0.6988 - val_accuracy: 0.6234\n",
      "Epoch 270/1000\n",
      "178/178 [==============================] - 0s 210us/step - loss: 2.1530 - accuracy: 0.8146 - val_loss: 0.6984 - val_accuracy: 0.6234\n",
      "Epoch 271/1000\n",
      "178/178 [==============================] - 0s 183us/step - loss: 1.8043 - accuracy: 0.8371 - val_loss: 0.7021 - val_accuracy: 0.6234\n",
      "Epoch 272/1000\n",
      "178/178 [==============================] - 0s 179us/step - loss: 1.5477 - accuracy: 0.8315 - val_loss: 0.6976 - val_accuracy: 0.6234\n",
      "Epoch 273/1000\n",
      "178/178 [==============================] - 0s 171us/step - loss: 1.9816 - accuracy: 0.8146 - val_loss: 0.6976 - val_accuracy: 0.6234\n",
      "Epoch 274/1000\n",
      "178/178 [==============================] - 0s 182us/step - loss: 2.0726 - accuracy: 0.7978 - val_loss: 0.6986 - val_accuracy: 0.6104\n",
      "Epoch 275/1000\n",
      "178/178 [==============================] - 0s 175us/step - loss: 1.7039 - accuracy: 0.8483 - val_loss: 0.6979 - val_accuracy: 0.6104\n",
      "Epoch 276/1000\n",
      "178/178 [==============================] - 0s 187us/step - loss: 1.7940 - accuracy: 0.8258 - val_loss: 0.7015 - val_accuracy: 0.6234\n",
      "Epoch 277/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 187us/step - loss: 1.9056 - accuracy: 0.8090 - val_loss: 0.6960 - val_accuracy: 0.6234\n",
      "Epoch 278/1000\n",
      "178/178 [==============================] - 0s 191us/step - loss: 1.4733 - accuracy: 0.8427 - val_loss: 0.7025 - val_accuracy: 0.6104\n",
      "Epoch 279/1000\n",
      "178/178 [==============================] - 0s 191us/step - loss: 2.5550 - accuracy: 0.7978 - val_loss: 0.6981 - val_accuracy: 0.6104\n",
      "Epoch 280/1000\n",
      "178/178 [==============================] - 0s 183us/step - loss: 1.7119 - accuracy: 0.8427 - val_loss: 0.6985 - val_accuracy: 0.6104\n",
      "Epoch 281/1000\n",
      "178/178 [==============================] - 0s 175us/step - loss: 1.5462 - accuracy: 0.8371 - val_loss: 0.7006 - val_accuracy: 0.6104\n",
      "Epoch 282/1000\n",
      "178/178 [==============================] - 0s 190us/step - loss: 1.7963 - accuracy: 0.8258 - val_loss: 0.6974 - val_accuracy: 0.6104\n",
      "Epoch 283/1000\n",
      "178/178 [==============================] - 0s 169us/step - loss: 2.0549 - accuracy: 0.8034 - val_loss: 0.7049 - val_accuracy: 0.6104\n",
      "Epoch 284/1000\n",
      "178/178 [==============================] - 0s 169us/step - loss: 1.8646 - accuracy: 0.8315 - val_loss: 0.7036 - val_accuracy: 0.6104\n",
      "Epoch 285/1000\n",
      "178/178 [==============================] - 0s 191us/step - loss: 1.7149 - accuracy: 0.8427 - val_loss: 0.6999 - val_accuracy: 0.6364\n",
      "Epoch 286/1000\n",
      "178/178 [==============================] - 0s 154us/step - loss: 1.5369 - accuracy: 0.8371 - val_loss: 0.6962 - val_accuracy: 0.6234\n",
      "Epoch 287/1000\n",
      "178/178 [==============================] - 0s 171us/step - loss: 1.8774 - accuracy: 0.8202 - val_loss: 0.6982 - val_accuracy: 0.6104\n",
      "Epoch 288/1000\n",
      "178/178 [==============================] - 0s 184us/step - loss: 2.4916 - accuracy: 0.7865 - val_loss: 0.6956 - val_accuracy: 0.6234\n",
      "Epoch 289/1000\n",
      "178/178 [==============================] - 0s 183us/step - loss: 2.3136 - accuracy: 0.7921 - val_loss: 0.6981 - val_accuracy: 0.6104\n",
      "Epoch 290/1000\n",
      "178/178 [==============================] - 0s 176us/step - loss: 2.0370 - accuracy: 0.8258 - val_loss: 0.7035 - val_accuracy: 0.6104\n",
      "Epoch 291/1000\n",
      "178/178 [==============================] - 0s 169us/step - loss: 1.7985 - accuracy: 0.8427 - val_loss: 0.7022 - val_accuracy: 0.6104\n",
      "Epoch 292/1000\n",
      "178/178 [==============================] - 0s 190us/step - loss: 2.3136 - accuracy: 0.7921 - val_loss: 0.7037 - val_accuracy: 0.6364\n",
      "Epoch 293/1000\n",
      "178/178 [==============================] - 0s 154us/step - loss: 1.5276 - accuracy: 0.8539 - val_loss: 0.6950 - val_accuracy: 0.6104\n",
      "Epoch 294/1000\n",
      "178/178 [==============================] - 0s 182us/step - loss: 1.9609 - accuracy: 0.8258 - val_loss: 0.7010 - val_accuracy: 0.6104\n",
      "Epoch 295/1000\n",
      "178/178 [==============================] - 0s 254us/step - loss: 1.7085 - accuracy: 0.8315 - val_loss: 0.7058 - val_accuracy: 0.6104\n",
      "Epoch 296/1000\n",
      "178/178 [==============================] - 0s 245us/step - loss: 1.7768 - accuracy: 0.8315 - val_loss: 0.7050 - val_accuracy: 0.6104\n",
      "Epoch 297/1000\n",
      "178/178 [==============================] - 0s 248us/step - loss: 1.5491 - accuracy: 0.8427 - val_loss: 0.7036 - val_accuracy: 0.6104\n",
      "Epoch 298/1000\n",
      "178/178 [==============================] - 0s 175us/step - loss: 2.0548 - accuracy: 0.8202 - val_loss: 0.7054 - val_accuracy: 0.6104\n",
      "Epoch 299/1000\n",
      "178/178 [==============================] - 0s 181us/step - loss: 1.9628 - accuracy: 0.8034 - val_loss: 0.7021 - val_accuracy: 0.6234\n",
      "Epoch 300/1000\n",
      "178/178 [==============================] - 0s 170us/step - loss: 1.8644 - accuracy: 0.8371 - val_loss: 0.7020 - val_accuracy: 0.6234\n",
      "Epoch 301/1000\n",
      "178/178 [==============================] - 0s 177us/step - loss: 1.0135 - accuracy: 0.8820 - val_loss: 0.7069 - val_accuracy: 0.6104\n",
      "Epoch 302/1000\n",
      "178/178 [==============================] - 0s 169us/step - loss: 1.5199 - accuracy: 0.8652 - val_loss: 0.7045 - val_accuracy: 0.6234\n",
      "Epoch 303/1000\n",
      "178/178 [==============================] - 0s 167us/step - loss: 1.4639 - accuracy: 0.8258 - val_loss: 0.7075 - val_accuracy: 0.6234\n",
      "Epoch 304/1000\n",
      "178/178 [==============================] - 0s 183us/step - loss: 1.8578 - accuracy: 0.8258 - val_loss: 0.7054 - val_accuracy: 0.6104\n",
      "Epoch 305/1000\n",
      "178/178 [==============================] - 0s 182us/step - loss: 2.2938 - accuracy: 0.7978 - val_loss: 0.7090 - val_accuracy: 0.6104\n",
      "Epoch 306/1000\n",
      "178/178 [==============================] - 0s 181us/step - loss: 1.2618 - accuracy: 0.8764 - val_loss: 0.7081 - val_accuracy: 0.6104\n",
      "Epoch 307/1000\n",
      "178/178 [==============================] - 0s 180us/step - loss: 1.8550 - accuracy: 0.8371 - val_loss: 0.7080 - val_accuracy: 0.6104\n",
      "Epoch 308/1000\n",
      "178/178 [==============================] - 0s 181us/step - loss: 1.6868 - accuracy: 0.8483 - val_loss: 0.7057 - val_accuracy: 0.6104\n",
      "Epoch 309/1000\n",
      "178/178 [==============================] - 0s 168us/step - loss: 1.6890 - accuracy: 0.8539 - val_loss: 0.7082 - val_accuracy: 0.6104\n",
      "Epoch 310/1000\n",
      "178/178 [==============================] - 0s 176us/step - loss: 2.1224 - accuracy: 0.8258 - val_loss: 0.7118 - val_accuracy: 0.6104\n",
      "Epoch 311/1000\n",
      "178/178 [==============================] - 0s 173us/step - loss: 1.9415 - accuracy: 0.8371 - val_loss: 0.7074 - val_accuracy: 0.6104\n",
      "Epoch 312/1000\n",
      "178/178 [==============================] - 0s 186us/step - loss: 2.0380 - accuracy: 0.8202 - val_loss: 0.7036 - val_accuracy: 0.6104\n",
      "Epoch 313/1000\n",
      "178/178 [==============================] - 0s 180us/step - loss: 1.8651 - accuracy: 0.8427 - val_loss: 0.7088 - val_accuracy: 0.6104\n",
      "Epoch 314/1000\n",
      "178/178 [==============================] - 0s 186us/step - loss: 2.1161 - accuracy: 0.8202 - val_loss: 0.7077 - val_accuracy: 0.6104\n",
      "Epoch 315/1000\n",
      "178/178 [==============================] - 0s 194us/step - loss: 1.5075 - accuracy: 0.8483 - val_loss: 0.7091 - val_accuracy: 0.6104\n",
      "Epoch 316/1000\n",
      "178/178 [==============================] - 0s 203us/step - loss: 1.8570 - accuracy: 0.8371 - val_loss: 0.7103 - val_accuracy: 0.6104\n",
      "Epoch 317/1000\n",
      "178/178 [==============================] - 0s 168us/step - loss: 1.7023 - accuracy: 0.8371 - val_loss: 0.7196 - val_accuracy: 0.6104\n",
      "Epoch 318/1000\n",
      "178/178 [==============================] - 0s 183us/step - loss: 1.9486 - accuracy: 0.8315 - val_loss: 0.7106 - val_accuracy: 0.6104\n",
      "Epoch 319/1000\n",
      "178/178 [==============================] - 0s 172us/step - loss: 1.6715 - accuracy: 0.8596 - val_loss: 0.7084 - val_accuracy: 0.6104\n",
      "Epoch 320/1000\n",
      "178/178 [==============================] - 0s 179us/step - loss: 2.0128 - accuracy: 0.8258 - val_loss: 0.7132 - val_accuracy: 0.6104\n",
      "Epoch 321/1000\n",
      "178/178 [==============================] - 0s 183us/step - loss: 1.5821 - accuracy: 0.8708 - val_loss: 0.7094 - val_accuracy: 0.6104\n",
      "Epoch 322/1000\n",
      "178/178 [==============================] - 0s 180us/step - loss: 2.6908 - accuracy: 0.7978 - val_loss: 0.7133 - val_accuracy: 0.6104\n",
      "Epoch 323/1000\n",
      "178/178 [==============================] - 0s 157us/step - loss: 1.8582 - accuracy: 0.8146 - val_loss: 0.7117 - val_accuracy: 0.6104\n",
      "Epoch 324/1000\n",
      "178/178 [==============================] - 0s 179us/step - loss: 1.6847 - accuracy: 0.8427 - val_loss: 0.7115 - val_accuracy: 0.6104\n",
      "Epoch 325/1000\n",
      "178/178 [==============================] - 0s 204us/step - loss: 2.4584 - accuracy: 0.7978 - val_loss: 0.7109 - val_accuracy: 0.6104\n",
      "Epoch 326/1000\n",
      "178/178 [==============================] - 0s 202us/step - loss: 2.1171 - accuracy: 0.8258 - val_loss: 0.7073 - val_accuracy: 0.6104\n",
      "Epoch 327/1000\n",
      "178/178 [==============================] - 0s 199us/step - loss: 2.2702 - accuracy: 0.8258 - val_loss: 0.7110 - val_accuracy: 0.6104\n",
      "Epoch 328/1000\n",
      "178/178 [==============================] - 0s 182us/step - loss: 1.8304 - accuracy: 0.8539 - val_loss: 0.7145 - val_accuracy: 0.6104\n",
      "Epoch 329/1000\n",
      "178/178 [==============================] - 0s 191us/step - loss: 2.0934 - accuracy: 0.8315 - val_loss: 0.7112 - val_accuracy: 0.6104\n",
      "Epoch 330/1000\n",
      "178/178 [==============================] - 0s 183us/step - loss: 2.3572 - accuracy: 0.8034 - val_loss: 0.7193 - val_accuracy: 0.6104\n",
      "Epoch 331/1000\n",
      "178/178 [==============================] - 0s 166us/step - loss: 1.7602 - accuracy: 0.8483 - val_loss: 0.7099 - val_accuracy: 0.6234\n",
      "Epoch 332/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 167us/step - loss: 2.2646 - accuracy: 0.8258 - val_loss: 0.7175 - val_accuracy: 0.6104\n",
      "Epoch 333/1000\n",
      "178/178 [==============================] - 0s 179us/step - loss: 1.3444 - accuracy: 0.8652 - val_loss: 0.7112 - val_accuracy: 0.6104\n",
      "Epoch 334/1000\n",
      "178/178 [==============================] - 0s 200us/step - loss: 2.1816 - accuracy: 0.8315 - val_loss: 0.7163 - val_accuracy: 0.6104\n",
      "Epoch 335/1000\n",
      "178/178 [==============================] - 0s 146us/step - loss: 1.5042 - accuracy: 0.8539 - val_loss: 0.7169 - val_accuracy: 0.6104\n",
      "Epoch 336/1000\n",
      "178/178 [==============================] - 0s 175us/step - loss: 2.0849 - accuracy: 0.8258 - val_loss: 0.7127 - val_accuracy: 0.6234\n",
      "Epoch 337/1000\n",
      "178/178 [==============================] - 0s 185us/step - loss: 1.2534 - accuracy: 0.8708 - val_loss: 0.7138 - val_accuracy: 0.6234\n",
      "Epoch 338/1000\n",
      "178/178 [==============================] - 0s 165us/step - loss: 2.1109 - accuracy: 0.8258 - val_loss: 0.7106 - val_accuracy: 0.6104\n",
      "Epoch 339/1000\n",
      "178/178 [==============================] - 0s 164us/step - loss: 1.7683 - accuracy: 0.8596 - val_loss: 0.7169 - val_accuracy: 0.6364\n",
      "Epoch 340/1000\n",
      "178/178 [==============================] - 0s 189us/step - loss: 1.3387 - accuracy: 0.8764 - val_loss: 0.7153 - val_accuracy: 0.6104\n",
      "Epoch 341/1000\n",
      "178/178 [==============================] - 0s 166us/step - loss: 2.1820 - accuracy: 0.8427 - val_loss: 0.7141 - val_accuracy: 0.6104\n",
      "Epoch 342/1000\n",
      "178/178 [==============================] - 0s 197us/step - loss: 1.6883 - accuracy: 0.8596 - val_loss: 0.7161 - val_accuracy: 0.6104\n",
      "Epoch 343/1000\n",
      "178/178 [==============================] - 0s 153us/step - loss: 2.5295 - accuracy: 0.8146 - val_loss: 0.7127 - val_accuracy: 0.6234\n",
      "Epoch 344/1000\n",
      "178/178 [==============================] - 0s 193us/step - loss: 1.4206 - accuracy: 0.8708 - val_loss: 0.7168 - val_accuracy: 0.6104\n",
      "Epoch 345/1000\n",
      "178/178 [==============================] - 0s 166us/step - loss: 2.0131 - accuracy: 0.8315 - val_loss: 0.7211 - val_accuracy: 0.6104\n",
      "Epoch 346/1000\n",
      "178/178 [==============================] - 0s 183us/step - loss: 1.7696 - accuracy: 0.8483 - val_loss: 0.7226 - val_accuracy: 0.6234\n",
      "Epoch 347/1000\n",
      "178/178 [==============================] - 0s 168us/step - loss: 1.7398 - accuracy: 0.8820 - val_loss: 0.7264 - val_accuracy: 0.6234\n",
      "Epoch 348/1000\n",
      "178/178 [==============================] - 0s 195us/step - loss: 2.2572 - accuracy: 0.8090 - val_loss: 0.7181 - val_accuracy: 0.6234\n",
      "Epoch 349/1000\n",
      "178/178 [==============================] - 0s 175us/step - loss: 1.8193 - accuracy: 0.8539 - val_loss: 0.7113 - val_accuracy: 0.6234\n",
      "Epoch 350/1000\n",
      "178/178 [==============================] - 0s 180us/step - loss: 1.6412 - accuracy: 0.8764 - val_loss: 0.7118 - val_accuracy: 0.6234\n",
      "Epoch 351/1000\n",
      "178/178 [==============================] - 0s 165us/step - loss: 1.8261 - accuracy: 0.8483 - val_loss: 0.7161 - val_accuracy: 0.6234\n",
      "Epoch 352/1000\n",
      "178/178 [==============================] - 0s 163us/step - loss: 2.2368 - accuracy: 0.8371 - val_loss: 0.7207 - val_accuracy: 0.6104\n",
      "Epoch 353/1000\n",
      "178/178 [==============================] - 0s 197us/step - loss: 1.7541 - accuracy: 0.8483 - val_loss: 0.7156 - val_accuracy: 0.6364\n",
      "Epoch 354/1000\n",
      "178/178 [==============================] - 0s 176us/step - loss: 2.1763 - accuracy: 0.8371 - val_loss: 0.7212 - val_accuracy: 0.6234\n",
      "Epoch 355/1000\n",
      "178/178 [==============================] - 0s 186us/step - loss: 2.0645 - accuracy: 0.8539 - val_loss: 0.7224 - val_accuracy: 0.6364\n",
      "Epoch 356/1000\n",
      "178/178 [==============================] - 0s 176us/step - loss: 1.6595 - accuracy: 0.8708 - val_loss: 0.7195 - val_accuracy: 0.6234\n",
      "Epoch 357/1000\n",
      "178/178 [==============================] - 0s 169us/step - loss: 2.1508 - accuracy: 0.8427 - val_loss: 0.7191 - val_accuracy: 0.6364\n",
      "Epoch 358/1000\n",
      "178/178 [==============================] - 0s 189us/step - loss: 2.3148 - accuracy: 0.8371 - val_loss: 0.7197 - val_accuracy: 0.6364\n",
      "Epoch 359/1000\n",
      "178/178 [==============================] - 0s 183us/step - loss: 2.1641 - accuracy: 0.8371 - val_loss: 0.7204 - val_accuracy: 0.6234\n",
      "Epoch 360/1000\n",
      "178/178 [==============================] - 0s 167us/step - loss: 1.9866 - accuracy: 0.8596 - val_loss: 0.7223 - val_accuracy: 0.6364\n",
      "Epoch 361/1000\n",
      "178/178 [==============================] - 0s 195us/step - loss: 1.7536 - accuracy: 0.8371 - val_loss: 0.7182 - val_accuracy: 0.6364\n",
      "Epoch 362/1000\n",
      "178/178 [==============================] - 0s 181us/step - loss: 1.2906 - accuracy: 0.9045 - val_loss: 0.7207 - val_accuracy: 0.6364\n",
      "Epoch 363/1000\n",
      "178/178 [==============================] - 0s 175us/step - loss: 2.0710 - accuracy: 0.8427 - val_loss: 0.7165 - val_accuracy: 0.6234\n",
      "Epoch 364/1000\n",
      "178/178 [==============================] - 0s 171us/step - loss: 1.1254 - accuracy: 0.9045 - val_loss: 0.7197 - val_accuracy: 0.6364\n",
      "Epoch 365/1000\n",
      "178/178 [==============================] - 0s 183us/step - loss: 1.7167 - accuracy: 0.8764 - val_loss: 0.7238 - val_accuracy: 0.6364\n",
      "Epoch 366/1000\n",
      "178/178 [==============================] - 0s 172us/step - loss: 1.9746 - accuracy: 0.8539 - val_loss: 0.7261 - val_accuracy: 0.6234\n",
      "Epoch 367/1000\n",
      "178/178 [==============================] - 0s 174us/step - loss: 1.4655 - accuracy: 0.8820 - val_loss: 0.7218 - val_accuracy: 0.6234\n",
      "Epoch 368/1000\n",
      "178/178 [==============================] - 0s 178us/step - loss: 1.6462 - accuracy: 0.8596 - val_loss: 0.7211 - val_accuracy: 0.6364\n",
      "Epoch 369/1000\n",
      "178/178 [==============================] - ETA: 0s - loss: 2.1982 - accuracy: 0.81 - 0s 187us/step - loss: 2.2523 - accuracy: 0.8258 - val_loss: 0.7219 - val_accuracy: 0.6234\n",
      "Epoch 370/1000\n",
      "178/178 [==============================] - 0s 188us/step - loss: 2.2512 - accuracy: 0.8371 - val_loss: 0.7193 - val_accuracy: 0.6364\n",
      "Epoch 371/1000\n",
      "178/178 [==============================] - 0s 196us/step - loss: 1.3983 - accuracy: 0.8764 - val_loss: 0.7147 - val_accuracy: 0.6494\n",
      "Epoch 372/1000\n",
      "178/178 [==============================] - 0s 173us/step - loss: 1.9768 - accuracy: 0.8539 - val_loss: 0.7180 - val_accuracy: 0.6234\n",
      "Epoch 373/1000\n",
      "178/178 [==============================] - 0s 187us/step - loss: 2.0698 - accuracy: 0.8483 - val_loss: 0.7199 - val_accuracy: 0.6364\n",
      "Epoch 374/1000\n",
      "178/178 [==============================] - 0s 166us/step - loss: 2.1629 - accuracy: 0.8371 - val_loss: 0.7234 - val_accuracy: 0.6234\n",
      "Epoch 375/1000\n",
      "178/178 [==============================] - 0s 176us/step - loss: 2.0833 - accuracy: 0.8483 - val_loss: 0.7206 - val_accuracy: 0.6364\n",
      "Epoch 376/1000\n",
      "178/178 [==============================] - 0s 178us/step - loss: 1.5583 - accuracy: 0.8820 - val_loss: 0.7244 - val_accuracy: 0.6364\n",
      "Epoch 377/1000\n",
      "178/178 [==============================] - 0s 180us/step - loss: 1.9787 - accuracy: 0.8539 - val_loss: 0.7264 - val_accuracy: 0.6104\n",
      "Epoch 378/1000\n",
      "178/178 [==============================] - 0s 197us/step - loss: 2.4917 - accuracy: 0.8090 - val_loss: 0.7215 - val_accuracy: 0.6234\n",
      "Epoch 379/1000\n",
      "178/178 [==============================] - 0s 213us/step - loss: 1.7264 - accuracy: 0.8539 - val_loss: 0.7174 - val_accuracy: 0.6234\n",
      "Epoch 380/1000\n",
      "178/178 [==============================] - 0s 230us/step - loss: 2.0683 - accuracy: 0.8371 - val_loss: 0.7195 - val_accuracy: 0.6364\n",
      "Epoch 381/1000\n",
      "178/178 [==============================] - 0s 232us/step - loss: 1.7167 - accuracy: 0.8820 - val_loss: 0.7212 - val_accuracy: 0.6364\n",
      "Epoch 382/1000\n",
      "178/178 [==============================] - 0s 257us/step - loss: 1.9763 - accuracy: 0.8427 - val_loss: 0.7311 - val_accuracy: 0.6234\n",
      "Epoch 383/1000\n",
      "178/178 [==============================] - 0s 234us/step - loss: 1.8912 - accuracy: 0.8539 - val_loss: 0.7223 - val_accuracy: 0.6104\n",
      "Epoch 384/1000\n",
      "178/178 [==============================] - 0s 228us/step - loss: 2.2114 - accuracy: 0.8483 - val_loss: 0.7233 - val_accuracy: 0.6364\n",
      "Epoch 385/1000\n",
      "178/178 [==============================] - 0s 194us/step - loss: 1.7137 - accuracy: 0.8652 - val_loss: 0.7267 - val_accuracy: 0.6234\n",
      "Epoch 386/1000\n",
      "178/178 [==============================] - 0s 183us/step - loss: 2.1619 - accuracy: 0.8258 - val_loss: 0.7210 - val_accuracy: 0.6364\n",
      "Epoch 387/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 187us/step - loss: 1.7100 - accuracy: 0.8708 - val_loss: 0.7219 - val_accuracy: 0.6364\n",
      "Epoch 388/1000\n",
      "178/178 [==============================] - 0s 200us/step - loss: 1.7258 - accuracy: 0.8652 - val_loss: 0.7270 - val_accuracy: 0.6364\n",
      "Epoch 389/1000\n",
      "178/178 [==============================] - 0s 215us/step - loss: 1.8123 - accuracy: 0.8652 - val_loss: 0.7193 - val_accuracy: 0.6494\n",
      "Epoch 390/1000\n",
      "178/178 [==============================] - 0s 170us/step - loss: 1.9750 - accuracy: 0.8371 - val_loss: 0.7216 - val_accuracy: 0.6364\n",
      "Epoch 391/1000\n",
      "178/178 [==============================] - 0s 168us/step - loss: 1.1065 - accuracy: 0.9157 - val_loss: 0.7272 - val_accuracy: 0.6234\n",
      "Epoch 392/1000\n",
      "178/178 [==============================] - 0s 186us/step - loss: 2.2262 - accuracy: 0.8371 - val_loss: 0.7271 - val_accuracy: 0.6364\n",
      "Epoch 393/1000\n",
      "178/178 [==============================] - 0s 184us/step - loss: 1.3679 - accuracy: 0.8876 - val_loss: 0.7223 - val_accuracy: 0.6364\n",
      "Epoch 394/1000\n",
      "178/178 [==============================] - 0s 213us/step - loss: 2.2276 - accuracy: 0.8371 - val_loss: 0.7293 - val_accuracy: 0.6364\n",
      "Epoch 395/1000\n",
      "178/178 [==============================] - 0s 194us/step - loss: 2.0499 - accuracy: 0.8596 - val_loss: 0.7323 - val_accuracy: 0.6104\n",
      "Epoch 396/1000\n",
      "178/178 [==============================] - 0s 195us/step - loss: 1.9744 - accuracy: 0.8539 - val_loss: 0.7205 - val_accuracy: 0.6364\n",
      "Epoch 397/1000\n",
      "178/178 [==============================] - 0s 203us/step - loss: 2.5763 - accuracy: 0.8146 - val_loss: 0.7229 - val_accuracy: 0.6364\n",
      "Epoch 398/1000\n",
      "178/178 [==============================] - 0s 183us/step - loss: 1.8073 - accuracy: 0.8652 - val_loss: 0.7268 - val_accuracy: 0.6364\n",
      "Epoch 399/1000\n",
      "178/178 [==============================] - 0s 179us/step - loss: 1.7109 - accuracy: 0.8708 - val_loss: 0.7203 - val_accuracy: 0.6234\n",
      "Epoch 400/1000\n",
      "178/178 [==============================] - 0s 178us/step - loss: 2.1363 - accuracy: 0.8427 - val_loss: 0.7269 - val_accuracy: 0.6364\n",
      "Epoch 401/1000\n",
      "178/178 [==============================] - 0s 187us/step - loss: 1.8591 - accuracy: 0.8708 - val_loss: 0.7224 - val_accuracy: 0.6364\n",
      "Epoch 402/1000\n",
      "178/178 [==============================] - 0s 183us/step - loss: 1.9685 - accuracy: 0.8596 - val_loss: 0.7297 - val_accuracy: 0.6623\n",
      "Epoch 403/1000\n",
      "178/178 [==============================] - 0s 181us/step - loss: 1.6201 - accuracy: 0.8708 - val_loss: 0.7204 - val_accuracy: 0.6494\n",
      "Epoch 404/1000\n",
      "178/178 [==============================] - 0s 200us/step - loss: 2.1321 - accuracy: 0.8483 - val_loss: 0.7323 - val_accuracy: 0.6494\n",
      "Epoch 405/1000\n",
      "178/178 [==============================] - 0s 196us/step - loss: 1.9703 - accuracy: 0.8371 - val_loss: 0.7232 - val_accuracy: 0.6364\n",
      "Epoch 406/1000\n",
      "178/178 [==============================] - 0s 269us/step - loss: 2.2956 - accuracy: 0.8483 - val_loss: 0.7240 - val_accuracy: 0.6234\n",
      "Epoch 407/1000\n",
      "178/178 [==============================] - 0s 182us/step - loss: 2.4811 - accuracy: 0.8202 - val_loss: 0.7233 - val_accuracy: 0.6494\n",
      "Epoch 408/1000\n",
      "178/178 [==============================] - 0s 162us/step - loss: 1.5384 - accuracy: 0.8876 - val_loss: 0.7248 - val_accuracy: 0.6364\n",
      "Epoch 409/1000\n",
      "178/178 [==============================] - 0s 158us/step - loss: 2.0520 - accuracy: 0.8483 - val_loss: 0.7255 - val_accuracy: 0.6364\n",
      "Epoch 410/1000\n",
      "178/178 [==============================] - 0s 155us/step - loss: 2.0639 - accuracy: 0.8483 - val_loss: 0.7253 - val_accuracy: 0.6623\n",
      "Epoch 411/1000\n",
      "178/178 [==============================] - 0s 166us/step - loss: 1.6998 - accuracy: 0.8764 - val_loss: 0.7361 - val_accuracy: 0.6364\n",
      "Epoch 412/1000\n",
      "178/178 [==============================] - 0s 166us/step - loss: 2.3078 - accuracy: 0.8202 - val_loss: 0.7285 - val_accuracy: 0.6364\n",
      "Epoch 413/1000\n",
      "178/178 [==============================] - 0s 155us/step - loss: 2.3960 - accuracy: 0.8258 - val_loss: 0.7233 - val_accuracy: 0.6364\n",
      "Epoch 414/1000\n",
      "178/178 [==============================] - 0s 170us/step - loss: 2.1427 - accuracy: 0.8427 - val_loss: 0.7320 - val_accuracy: 0.6623\n",
      "Epoch 415/1000\n",
      "178/178 [==============================] - 0s 204us/step - loss: 2.3150 - accuracy: 0.8371 - val_loss: 0.7260 - val_accuracy: 0.6494\n",
      "Epoch 416/1000\n",
      "178/178 [==============================] - 0s 202us/step - loss: 1.7754 - accuracy: 0.8708 - val_loss: 0.7287 - val_accuracy: 0.6494\n",
      "Epoch 417/1000\n",
      "178/178 [==============================] - 0s 206us/step - loss: 1.9447 - accuracy: 0.8539 - val_loss: 0.7311 - val_accuracy: 0.6494\n",
      "Epoch 418/1000\n",
      "178/178 [==============================] - 0s 218us/step - loss: 2.1984 - accuracy: 0.8539 - val_loss: 0.7240 - val_accuracy: 0.6234\n",
      "Epoch 419/1000\n",
      "178/178 [==============================] - 0s 212us/step - loss: 2.2343 - accuracy: 0.8258 - val_loss: 0.7293 - val_accuracy: 0.6364\n",
      "Epoch 420/1000\n",
      "178/178 [==============================] - 0s 220us/step - loss: 1.3894 - accuracy: 0.8764 - val_loss: 0.7356 - val_accuracy: 0.6623\n",
      "Epoch 421/1000\n",
      "178/178 [==============================] - 0s 222us/step - loss: 1.7062 - accuracy: 0.8708 - val_loss: 0.7327 - val_accuracy: 0.6753\n",
      "Epoch 422/1000\n",
      "178/178 [==============================] - 0s 217us/step - loss: 1.7844 - accuracy: 0.8652 - val_loss: 0.7278 - val_accuracy: 0.6364\n",
      "Epoch 423/1000\n",
      "178/178 [==============================] - 0s 439us/step - loss: 1.7756 - accuracy: 0.8764 - val_loss: 0.7307 - val_accuracy: 0.6494\n",
      "Epoch 424/1000\n",
      "178/178 [==============================] - 0s 353us/step - loss: 2.2177 - accuracy: 0.8315 - val_loss: 0.7373 - val_accuracy: 0.6234\n",
      "Epoch 425/1000\n",
      "178/178 [==============================] - 0s 199us/step - loss: 1.8956 - accuracy: 0.8539 - val_loss: 0.7332 - val_accuracy: 0.6494\n",
      "Epoch 426/1000\n",
      "178/178 [==============================] - 0s 187us/step - loss: 2.1267 - accuracy: 0.8483 - val_loss: 0.7339 - val_accuracy: 0.6494\n",
      "Epoch 427/1000\n",
      "178/178 [==============================] - 0s 184us/step - loss: 2.3201 - accuracy: 0.8258 - val_loss: 0.7370 - val_accuracy: 0.6494\n",
      "Epoch 428/1000\n",
      "178/178 [==============================] - 0s 200us/step - loss: 1.6083 - accuracy: 0.8764 - val_loss: 0.7356 - val_accuracy: 0.6753\n",
      "Epoch 429/1000\n",
      "178/178 [==============================] - 0s 191us/step - loss: 1.9586 - accuracy: 0.8539 - val_loss: 0.7381 - val_accuracy: 0.6623\n",
      "Epoch 430/1000\n",
      "178/178 [==============================] - 0s 195us/step - loss: 2.4807 - accuracy: 0.8315 - val_loss: 0.7366 - val_accuracy: 0.6494\n",
      "Epoch 431/1000\n",
      "178/178 [==============================] - 0s 188us/step - loss: 1.5249 - accuracy: 0.8820 - val_loss: 0.7362 - val_accuracy: 0.6494\n",
      "Epoch 432/1000\n",
      "178/178 [==============================] - 0s 185us/step - loss: 2.0187 - accuracy: 0.8539 - val_loss: 0.7373 - val_accuracy: 0.6753\n",
      "Epoch 433/1000\n",
      "178/178 [==============================] - 0s 193us/step - loss: 1.9665 - accuracy: 0.8596 - val_loss: 0.7410 - val_accuracy: 0.6494\n",
      "Epoch 434/1000\n",
      "178/178 [==============================] - 0s 192us/step - loss: 1.2658 - accuracy: 0.8933 - val_loss: 0.7421 - val_accuracy: 0.6364\n",
      "Epoch 435/1000\n",
      "178/178 [==============================] - 0s 200us/step - loss: 1.6127 - accuracy: 0.8764 - val_loss: 0.7393 - val_accuracy: 0.6494\n",
      "Epoch 436/1000\n",
      "178/178 [==============================] - 0s 190us/step - loss: 2.2049 - accuracy: 0.8483 - val_loss: 0.7360 - val_accuracy: 0.6494\n",
      "Epoch 437/1000\n",
      "178/178 [==============================] - 0s 182us/step - loss: 2.3876 - accuracy: 0.8146 - val_loss: 0.7368 - val_accuracy: 0.6234\n",
      "Epoch 438/1000\n",
      "178/178 [==============================] - 0s 204us/step - loss: 1.7011 - accuracy: 0.8652 - val_loss: 0.7367 - val_accuracy: 0.6753\n",
      "Epoch 439/1000\n",
      "178/178 [==============================] - 0s 190us/step - loss: 1.7929 - accuracy: 0.8708 - val_loss: 0.7377 - val_accuracy: 0.6753\n",
      "Epoch 440/1000\n",
      "178/178 [==============================] - 0s 180us/step - loss: 2.2103 - accuracy: 0.8315 - val_loss: 0.7355 - val_accuracy: 0.6623\n",
      "Epoch 441/1000\n",
      "178/178 [==============================] - 0s 197us/step - loss: 1.5970 - accuracy: 0.8708 - val_loss: 0.7336 - val_accuracy: 0.6623\n",
      "Epoch 442/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 190us/step - loss: 1.4419 - accuracy: 0.8933 - val_loss: 0.7432 - val_accuracy: 0.6494\n",
      "Epoch 443/1000\n",
      "178/178 [==============================] - 0s 182us/step - loss: 1.4308 - accuracy: 0.8933 - val_loss: 0.7405 - val_accuracy: 0.6623\n",
      "Epoch 444/1000\n",
      "178/178 [==============================] - 0s 202us/step - loss: 2.2102 - accuracy: 0.8427 - val_loss: 0.7384 - val_accuracy: 0.6494\n",
      "Epoch 445/1000\n",
      "178/178 [==============================] - 0s 202us/step - loss: 1.8546 - accuracy: 0.8596 - val_loss: 0.7394 - val_accuracy: 0.6753\n",
      "Epoch 446/1000\n",
      "178/178 [==============================] - 0s 184us/step - loss: 2.0240 - accuracy: 0.8539 - val_loss: 0.7443 - val_accuracy: 0.6494\n",
      "Epoch 447/1000\n",
      "178/178 [==============================] - 0s 183us/step - loss: 2.0421 - accuracy: 0.8371 - val_loss: 0.7427 - val_accuracy: 0.6623\n",
      "Epoch 448/1000\n",
      "178/178 [==============================] - 0s 182us/step - loss: 1.8628 - accuracy: 0.8483 - val_loss: 0.7493 - val_accuracy: 0.6494\n",
      "Epoch 449/1000\n",
      "178/178 [==============================] - 0s 191us/step - loss: 1.9497 - accuracy: 0.8539 - val_loss: 0.7496 - val_accuracy: 0.6494\n",
      "Epoch 450/1000\n",
      "178/178 [==============================] - 0s 195us/step - loss: 1.6033 - accuracy: 0.8596 - val_loss: 0.7444 - val_accuracy: 0.6494\n",
      "Epoch 451/1000\n",
      "178/178 [==============================] - 0s 186us/step - loss: 1.5209 - accuracy: 0.8820 - val_loss: 0.7374 - val_accuracy: 0.6494\n",
      "Epoch 452/1000\n",
      "178/178 [==============================] - 0s 186us/step - loss: 1.6828 - accuracy: 0.8820 - val_loss: 0.7376 - val_accuracy: 0.6364\n",
      "Epoch 453/1000\n",
      "178/178 [==============================] - 0s 180us/step - loss: 2.1167 - accuracy: 0.8427 - val_loss: 0.7456 - val_accuracy: 0.6364\n",
      "Epoch 454/1000\n",
      "178/178 [==============================] - 0s 171us/step - loss: 1.9451 - accuracy: 0.8596 - val_loss: 0.7456 - val_accuracy: 0.6494\n",
      "Epoch 455/1000\n",
      "178/178 [==============================] - 0s 153us/step - loss: 1.5964 - accuracy: 0.8820 - val_loss: 0.7399 - val_accuracy: 0.6364\n",
      "Epoch 456/1000\n",
      "178/178 [==============================] - 0s 168us/step - loss: 1.6779 - accuracy: 0.8820 - val_loss: 0.7394 - val_accuracy: 0.6494\n",
      "Epoch 457/1000\n",
      "178/178 [==============================] - 0s 172us/step - loss: 1.0593 - accuracy: 0.9213 - val_loss: 0.7433 - val_accuracy: 0.6494\n",
      "Epoch 458/1000\n",
      "178/178 [==============================] - 0s 173us/step - loss: 1.8548 - accuracy: 0.8652 - val_loss: 0.7502 - val_accuracy: 0.6494\n",
      "Epoch 459/1000\n",
      "178/178 [==============================] - 0s 206us/step - loss: 2.1956 - accuracy: 0.8371 - val_loss: 0.7539 - val_accuracy: 0.6364\n",
      "Epoch 460/1000\n",
      "178/178 [==============================] - 0s 184us/step - loss: 1.8913 - accuracy: 0.8427 - val_loss: 0.7498 - val_accuracy: 0.6494\n",
      "Epoch 461/1000\n",
      "178/178 [==============================] - 0s 188us/step - loss: 1.6953 - accuracy: 0.8764 - val_loss: 0.7415 - val_accuracy: 0.6494\n",
      "Epoch 462/1000\n",
      "178/178 [==============================] - 0s 170us/step - loss: 1.6962 - accuracy: 0.8652 - val_loss: 0.7510 - val_accuracy: 0.6494\n",
      "Epoch 463/1000\n",
      "178/178 [==============================] - 0s 179us/step - loss: 1.6797 - accuracy: 0.8708 - val_loss: 0.7518 - val_accuracy: 0.6494\n",
      "Epoch 464/1000\n",
      "178/178 [==============================] - 0s 175us/step - loss: 2.1887 - accuracy: 0.8371 - val_loss: 0.7503 - val_accuracy: 0.6364\n",
      "Epoch 465/1000\n",
      "178/178 [==============================] - 0s 181us/step - loss: 2.5164 - accuracy: 0.8315 - val_loss: 0.7514 - val_accuracy: 0.6494\n",
      "Epoch 466/1000\n",
      "178/178 [==============================] - 0s 170us/step - loss: 2.3746 - accuracy: 0.8258 - val_loss: 0.7481 - val_accuracy: 0.6494\n",
      "Epoch 467/1000\n",
      "178/178 [==============================] - 0s 230us/step - loss: 1.9547 - accuracy: 0.8483 - val_loss: 0.7506 - val_accuracy: 0.6753\n",
      "Epoch 468/1000\n",
      "178/178 [==============================] - 0s 185us/step - loss: 1.2511 - accuracy: 0.8933 - val_loss: 0.7552 - val_accuracy: 0.6623\n",
      "Epoch 469/1000\n",
      "178/178 [==============================] - 0s 174us/step - loss: 1.7634 - accuracy: 0.8652 - val_loss: 0.7368 - val_accuracy: 0.6104\n",
      "Epoch 470/1000\n",
      "178/178 [==============================] - 0s 172us/step - loss: 2.0208 - accuracy: 0.8596 - val_loss: 0.7430 - val_accuracy: 0.6494\n",
      "Epoch 471/1000\n",
      "178/178 [==============================] - 0s 197us/step - loss: 2.3733 - accuracy: 0.8146 - val_loss: 0.7497 - val_accuracy: 0.6494\n",
      "Epoch 472/1000\n",
      "178/178 [==============================] - 0s 182us/step - loss: 1.3366 - accuracy: 0.8764 - val_loss: 0.7554 - val_accuracy: 0.6364\n",
      "Epoch 473/1000\n",
      "178/178 [==============================] - 0s 177us/step - loss: 2.1964 - accuracy: 0.8202 - val_loss: 0.7503 - val_accuracy: 0.6494\n",
      "Epoch 474/1000\n",
      "178/178 [==============================] - 0s 191us/step - loss: 2.6149 - accuracy: 0.8202 - val_loss: 0.7567 - val_accuracy: 0.6494\n",
      "Epoch 475/1000\n",
      "178/178 [==============================] - 0s 184us/step - loss: 1.8445 - accuracy: 0.8596 - val_loss: 0.7362 - val_accuracy: 0.6623\n",
      "Epoch 476/1000\n",
      "178/178 [==============================] - 0s 196us/step - loss: 1.9243 - accuracy: 0.8596 - val_loss: 0.7407 - val_accuracy: 0.6364\n",
      "Epoch 477/1000\n",
      "178/178 [==============================] - 0s 190us/step - loss: 1.4162 - accuracy: 0.8933 - val_loss: 0.7508 - val_accuracy: 0.6883\n",
      "Epoch 478/1000\n",
      "178/178 [==============================] - 0s 187us/step - loss: 2.3593 - accuracy: 0.8371 - val_loss: 0.7533 - val_accuracy: 0.6623\n",
      "Epoch 479/1000\n",
      "178/178 [==============================] - 0s 160us/step - loss: 2.0213 - accuracy: 0.8483 - val_loss: 0.7456 - val_accuracy: 0.6234\n",
      "Epoch 480/1000\n",
      "178/178 [==============================] - 0s 188us/step - loss: 0.9834 - accuracy: 0.9326 - val_loss: 0.7500 - val_accuracy: 0.6753\n",
      "Epoch 481/1000\n",
      "178/178 [==============================] - 0s 166us/step - loss: 1.6514 - accuracy: 0.8820 - val_loss: 0.7551 - val_accuracy: 0.6364\n",
      "Epoch 482/1000\n",
      "178/178 [==============================] - 0s 185us/step - loss: 2.0244 - accuracy: 0.8539 - val_loss: 0.7491 - val_accuracy: 0.6494\n",
      "Epoch 483/1000\n",
      "178/178 [==============================] - 0s 175us/step - loss: 2.2942 - accuracy: 0.8258 - val_loss: 0.7562 - val_accuracy: 0.6364\n",
      "Epoch 484/1000\n",
      "178/178 [==============================] - 0s 199us/step - loss: 1.5014 - accuracy: 0.8876 - val_loss: 0.7478 - val_accuracy: 0.6364\n",
      "Epoch 485/1000\n",
      "178/178 [==============================] - 0s 170us/step - loss: 1.9274 - accuracy: 0.8652 - val_loss: 0.7582 - val_accuracy: 0.6494\n",
      "Epoch 486/1000\n",
      "178/178 [==============================] - 0s 172us/step - loss: 1.4904 - accuracy: 0.8876 - val_loss: 0.7495 - val_accuracy: 0.6494\n",
      "Epoch 487/1000\n",
      "178/178 [==============================] - 0s 157us/step - loss: 1.9312 - accuracy: 0.8596 - val_loss: 0.7498 - val_accuracy: 0.6494\n",
      "Epoch 488/1000\n",
      "178/178 [==============================] - ETA: 0s - loss: 1.9215 - accuracy: 0.81 - 0s 191us/step - loss: 1.4905 - accuracy: 0.8876 - val_loss: 0.7523 - val_accuracy: 0.6364\n",
      "Epoch 489/1000\n",
      "178/178 [==============================] - 0s 188us/step - loss: 1.5697 - accuracy: 0.8876 - val_loss: 0.7540 - val_accuracy: 0.6883\n",
      "Epoch 490/1000\n",
      "178/178 [==============================] - 0s 178us/step - loss: 2.0342 - accuracy: 0.8483 - val_loss: 0.7567 - val_accuracy: 0.6753\n",
      "Epoch 491/1000\n",
      "178/178 [==============================] - 0s 192us/step - loss: 1.9151 - accuracy: 0.8652 - val_loss: 0.7531 - val_accuracy: 0.6494\n",
      "Epoch 492/1000\n",
      "178/178 [==============================] - 0s 171us/step - loss: 1.8456 - accuracy: 0.8596 - val_loss: 0.7564 - val_accuracy: 0.6753\n",
      "Epoch 493/1000\n",
      "178/178 [==============================] - 0s 172us/step - loss: 1.5638 - accuracy: 0.8876 - val_loss: 0.7554 - val_accuracy: 0.6623\n",
      "Epoch 494/1000\n",
      "178/178 [==============================] - 0s 164us/step - loss: 1.4805 - accuracy: 0.8989 - val_loss: 0.7626 - val_accuracy: 0.6494\n",
      "Epoch 495/1000\n",
      "178/178 [==============================] - 0s 197us/step - loss: 1.6705 - accuracy: 0.8596 - val_loss: 0.7559 - val_accuracy: 0.6623\n",
      "Epoch 496/1000\n",
      "178/178 [==============================] - 0s 175us/step - loss: 1.0596 - accuracy: 0.9157 - val_loss: 0.7496 - val_accuracy: 0.6623\n",
      "Epoch 497/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 171us/step - loss: 1.5908 - accuracy: 0.8708 - val_loss: 0.7552 - val_accuracy: 0.6623\n",
      "Epoch 498/1000\n",
      "178/178 [==============================] - 0s 191us/step - loss: 1.5780 - accuracy: 0.8876 - val_loss: 0.7814 - val_accuracy: 0.6364\n",
      "Epoch 499/1000\n",
      "178/178 [==============================] - 0s 171us/step - loss: 1.6835 - accuracy: 0.8708 - val_loss: 0.7563 - val_accuracy: 0.6494\n",
      "Epoch 500/1000\n",
      "178/178 [==============================] - 0s 169us/step - loss: 1.5657 - accuracy: 0.8820 - val_loss: 0.7529 - val_accuracy: 0.6494\n",
      "Epoch 501/1000\n",
      "178/178 [==============================] - 0s 185us/step - loss: 1.8367 - accuracy: 0.8539 - val_loss: 0.7520 - val_accuracy: 0.6623\n",
      "Epoch 502/1000\n",
      "178/178 [==============================] - 0s 182us/step - loss: 1.3317 - accuracy: 0.8933 - val_loss: 0.7484 - val_accuracy: 0.6883\n",
      "Epoch 503/1000\n",
      "178/178 [==============================] - 0s 181us/step - loss: 2.4293 - accuracy: 0.8315 - val_loss: 0.7499 - val_accuracy: 0.6753\n",
      "Epoch 504/1000\n",
      "178/178 [==============================] - 0s 167us/step - loss: 2.6053 - accuracy: 0.8146 - val_loss: 0.7645 - val_accuracy: 0.6364\n",
      "Epoch 505/1000\n",
      "178/178 [==============================] - 0s 181us/step - loss: 1.5749 - accuracy: 0.8876 - val_loss: 0.7637 - val_accuracy: 0.6494\n",
      "Epoch 506/1000\n",
      "178/178 [==============================] - 0s 176us/step - loss: 2.4512 - accuracy: 0.8202 - val_loss: 0.7532 - val_accuracy: 0.6623\n",
      "Epoch 507/1000\n",
      "178/178 [==============================] - 0s 171us/step - loss: 2.1010 - accuracy: 0.8483 - val_loss: 0.7616 - val_accuracy: 0.6623\n",
      "Epoch 508/1000\n",
      "178/178 [==============================] - 0s 174us/step - loss: 1.1367 - accuracy: 0.9101 - val_loss: 0.7723 - val_accuracy: 0.6364\n",
      "Epoch 509/1000\n",
      "178/178 [==============================] - 0s 182us/step - loss: 2.5171 - accuracy: 0.8202 - val_loss: 0.7704 - val_accuracy: 0.6364\n",
      "Epoch 510/1000\n",
      "178/178 [==============================] - 0s 182us/step - loss: 1.8268 - accuracy: 0.8764 - val_loss: 0.7595 - val_accuracy: 0.6753\n",
      "Epoch 511/1000\n",
      "178/178 [==============================] - 0s 166us/step - loss: 1.6722 - accuracy: 0.8708 - val_loss: 0.7553 - val_accuracy: 0.6494\n",
      "Epoch 512/1000\n",
      "178/178 [==============================] - 0s 180us/step - loss: 1.5704 - accuracy: 0.8876 - val_loss: 0.7638 - val_accuracy: 0.6364\n",
      "Epoch 513/1000\n",
      "178/178 [==============================] - 0s 183us/step - loss: 1.7368 - accuracy: 0.8820 - val_loss: 0.7618 - val_accuracy: 0.6623\n",
      "Epoch 514/1000\n",
      "178/178 [==============================] - 0s 178us/step - loss: 1.8392 - accuracy: 0.8539 - val_loss: 0.7631 - val_accuracy: 0.6494\n",
      "Epoch 515/1000\n",
      "178/178 [==============================] - 0s 166us/step - loss: 1.9254 - accuracy: 0.8652 - val_loss: 0.7601 - val_accuracy: 0.6753\n",
      "Epoch 516/1000\n",
      "178/178 [==============================] - 0s 181us/step - loss: 1.5868 - accuracy: 0.8820 - val_loss: 0.7664 - val_accuracy: 0.6753\n",
      "Epoch 517/1000\n",
      "178/178 [==============================] - 0s 179us/step - loss: 1.6420 - accuracy: 0.8933 - val_loss: 0.7668 - val_accuracy: 0.6364\n",
      "Epoch 518/1000\n",
      "178/178 [==============================] - 0s 170us/step - loss: 1.6634 - accuracy: 0.8820 - val_loss: 0.7645 - val_accuracy: 0.6234\n",
      "Epoch 519/1000\n",
      "178/178 [==============================] - 0s 179us/step - loss: 1.7432 - accuracy: 0.8652 - val_loss: 0.7556 - val_accuracy: 0.6104\n",
      "Epoch 520/1000\n",
      "178/178 [==============================] - 0s 181us/step - loss: 2.1735 - accuracy: 0.8427 - val_loss: 0.7651 - val_accuracy: 0.6494\n",
      "Epoch 521/1000\n",
      "178/178 [==============================] - 0s 185us/step - loss: 2.0080 - accuracy: 0.8483 - val_loss: 0.7717 - val_accuracy: 0.6364\n",
      "Epoch 522/1000\n",
      "178/178 [==============================] - 0s 169us/step - loss: 1.3890 - accuracy: 0.9101 - val_loss: 0.7624 - val_accuracy: 0.6234\n",
      "Epoch 523/1000\n",
      "178/178 [==============================] - 0s 181us/step - loss: 1.9973 - accuracy: 0.8483 - val_loss: 0.7607 - val_accuracy: 0.6623\n",
      "Epoch 524/1000\n",
      "178/178 [==============================] - 0s 183us/step - loss: 1.7516 - accuracy: 0.8708 - val_loss: 0.7644 - val_accuracy: 0.6364\n",
      "Epoch 525/1000\n",
      "178/178 [==============================] - 0s 183us/step - loss: 1.8272 - accuracy: 0.8764 - val_loss: 0.7614 - val_accuracy: 0.6494\n",
      "Epoch 526/1000\n",
      "178/178 [==============================] - 0s 180us/step - loss: 2.1051 - accuracy: 0.8427 - val_loss: 0.7771 - val_accuracy: 0.6494\n",
      "Epoch 527/1000\n",
      "178/178 [==============================] - 0s 182us/step - loss: 2.2492 - accuracy: 0.8427 - val_loss: 0.7655 - val_accuracy: 0.6753\n",
      "Epoch 528/1000\n",
      "178/178 [==============================] - 0s 188us/step - loss: 2.1729 - accuracy: 0.8427 - val_loss: 0.7641 - val_accuracy: 0.6623\n",
      "Epoch 529/1000\n",
      "178/178 [==============================] - 0s 198us/step - loss: 2.0839 - accuracy: 0.8483 - val_loss: 0.7830 - val_accuracy: 0.6364\n",
      "Epoch 530/1000\n",
      "178/178 [==============================] - 0s 182us/step - loss: 1.8120 - accuracy: 0.8820 - val_loss: 0.7585 - val_accuracy: 0.6364\n",
      "Epoch 531/1000\n",
      "178/178 [==============================] - 0s 173us/step - loss: 1.9104 - accuracy: 0.8652 - val_loss: 0.7618 - val_accuracy: 0.6623\n",
      "Epoch 532/1000\n",
      "178/178 [==============================] - 0s 196us/step - loss: 1.5754 - accuracy: 0.8876 - val_loss: 0.7760 - val_accuracy: 0.6364\n",
      "Epoch 533/1000\n",
      "178/178 [==============================] - 0s 174us/step - loss: 1.5818 - accuracy: 0.8820 - val_loss: 0.7633 - val_accuracy: 0.6623\n",
      "Epoch 534/1000\n",
      "178/178 [==============================] - 0s 181us/step - loss: 1.3056 - accuracy: 0.9045 - val_loss: 0.7669 - val_accuracy: 0.6494\n",
      "Epoch 535/1000\n",
      "178/178 [==============================] - 0s 180us/step - loss: 1.8227 - accuracy: 0.8596 - val_loss: 0.7653 - val_accuracy: 0.6364\n",
      "Epoch 536/1000\n",
      "178/178 [==============================] - 0s 155us/step - loss: 1.7434 - accuracy: 0.8708 - val_loss: 0.7509 - val_accuracy: 0.6753\n",
      "Epoch 537/1000\n",
      "178/178 [==============================] - 0s 203us/step - loss: 2.0813 - accuracy: 0.8539 - val_loss: 0.7657 - val_accuracy: 0.6753\n",
      "Epoch 538/1000\n",
      "178/178 [==============================] - 0s 168us/step - loss: 1.5695 - accuracy: 0.8764 - val_loss: 0.7773 - val_accuracy: 0.6623\n",
      "Epoch 539/1000\n",
      "178/178 [==============================] - 0s 181us/step - loss: 1.6579 - accuracy: 0.8764 - val_loss: 0.7701 - val_accuracy: 0.6753\n",
      "Epoch 540/1000\n",
      "178/178 [==============================] - 0s 176us/step - loss: 1.8909 - accuracy: 0.8708 - val_loss: 0.7697 - val_accuracy: 0.6753\n",
      "Epoch 541/1000\n",
      "178/178 [==============================] - 0s 184us/step - loss: 1.8910 - accuracy: 0.8708 - val_loss: 0.7690 - val_accuracy: 0.6364\n",
      "Epoch 542/1000\n",
      "178/178 [==============================] - 0s 155us/step - loss: 1.7994 - accuracy: 0.8764 - val_loss: 0.7719 - val_accuracy: 0.6364\n",
      "Epoch 543/1000\n",
      "178/178 [==============================] - 0s 184us/step - loss: 1.9993 - accuracy: 0.8483 - val_loss: 0.7724 - val_accuracy: 0.6364\n",
      "Epoch 544/1000\n",
      "178/178 [==============================] - 0s 184us/step - loss: 1.8162 - accuracy: 0.8764 - val_loss: 0.7677 - val_accuracy: 0.6753\n",
      "Epoch 545/1000\n",
      "178/178 [==============================] - 0s 184us/step - loss: 1.6499 - accuracy: 0.8764 - val_loss: 0.7709 - val_accuracy: 0.6623\n",
      "Epoch 546/1000\n",
      "178/178 [==============================] - 0s 185us/step - loss: 2.0873 - accuracy: 0.8483 - val_loss: 0.7897 - val_accuracy: 0.6364\n",
      "Epoch 547/1000\n",
      "178/178 [==============================] - 0s 167us/step - loss: 1.7330 - accuracy: 0.8652 - val_loss: 0.7729 - val_accuracy: 0.6234\n",
      "Epoch 548/1000\n",
      "178/178 [==============================] - 0s 173us/step - loss: 2.1612 - accuracy: 0.8483 - val_loss: 0.7707 - val_accuracy: 0.6364\n",
      "Epoch 549/1000\n",
      "178/178 [==============================] - 0s 166us/step - loss: 1.7267 - accuracy: 0.8820 - val_loss: 0.7722 - val_accuracy: 0.6623\n",
      "Epoch 550/1000\n",
      "178/178 [==============================] - 0s 248us/step - loss: 1.8304 - accuracy: 0.8596 - val_loss: 0.7708 - val_accuracy: 0.6623\n",
      "Epoch 551/1000\n",
      "178/178 [==============================] - 0s 246us/step - loss: 1.9915 - accuracy: 0.8539 - val_loss: 0.7812 - val_accuracy: 0.6494\n",
      "Epoch 552/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 266us/step - loss: 1.9995 - accuracy: 0.8596 - val_loss: 0.7750 - val_accuracy: 0.6753\n",
      "Epoch 553/1000\n",
      "178/178 [==============================] - 0s 268us/step - loss: 2.0963 - accuracy: 0.8483 - val_loss: 0.7703 - val_accuracy: 0.6234\n",
      "Epoch 554/1000\n",
      "178/178 [==============================] - 0s 268us/step - loss: 2.0732 - accuracy: 0.8596 - val_loss: 0.7770 - val_accuracy: 0.6623\n",
      "Epoch 555/1000\n",
      "178/178 [==============================] - 0s 262us/step - loss: 1.5810 - accuracy: 0.8652 - val_loss: 0.7759 - val_accuracy: 0.6364\n",
      "Epoch 556/1000\n",
      "178/178 [==============================] - 0s 243us/step - loss: 1.8148 - accuracy: 0.8708 - val_loss: 0.7668 - val_accuracy: 0.6494\n",
      "Epoch 557/1000\n",
      "178/178 [==============================] - 0s 223us/step - loss: 1.7370 - accuracy: 0.8652 - val_loss: 0.7729 - val_accuracy: 0.6494\n",
      "Epoch 558/1000\n",
      "178/178 [==============================] - 0s 193us/step - loss: 1.7342 - accuracy: 0.8764 - val_loss: 0.7781 - val_accuracy: 0.6494\n",
      "Epoch 559/1000\n",
      "178/178 [==============================] - 0s 206us/step - loss: 2.1513 - accuracy: 0.8539 - val_loss: 0.7643 - val_accuracy: 0.6494\n",
      "Epoch 560/1000\n",
      "178/178 [==============================] - 0s 230us/step - loss: 1.7222 - accuracy: 0.8652 - val_loss: 0.7673 - val_accuracy: 0.6883\n",
      "Epoch 561/1000\n",
      "178/178 [==============================] - 0s 218us/step - loss: 2.2490 - accuracy: 0.8371 - val_loss: 0.7828 - val_accuracy: 0.6494\n",
      "Epoch 562/1000\n",
      "178/178 [==============================] - 0s 243us/step - loss: 1.2195 - accuracy: 0.9045 - val_loss: 0.7753 - val_accuracy: 0.6753\n",
      "Epoch 563/1000\n",
      "178/178 [==============================] - 0s 194us/step - loss: 1.6460 - accuracy: 0.8764 - val_loss: 0.7768 - val_accuracy: 0.6883\n",
      "Epoch 564/1000\n",
      "178/178 [==============================] - 0s 171us/step - loss: 1.2856 - accuracy: 0.9045 - val_loss: 0.7811 - val_accuracy: 0.6494\n",
      "Epoch 565/1000\n",
      "178/178 [==============================] - 0s 179us/step - loss: 1.3830 - accuracy: 0.8933 - val_loss: 0.7908 - val_accuracy: 0.6364\n",
      "Epoch 566/1000\n",
      "178/178 [==============================] - 0s 169us/step - loss: 1.1379 - accuracy: 0.9045 - val_loss: 0.7775 - val_accuracy: 0.6234\n",
      "Epoch 567/1000\n",
      "178/178 [==============================] - 0s 170us/step - loss: 1.7279 - accuracy: 0.8820 - val_loss: 0.7758 - val_accuracy: 0.6364\n",
      "Epoch 568/1000\n",
      "178/178 [==============================] - 0s 181us/step - loss: 1.6459 - accuracy: 0.8820 - val_loss: 0.7702 - val_accuracy: 0.6364\n",
      "Epoch 569/1000\n",
      "178/178 [==============================] - 0s 181us/step - loss: 2.2393 - accuracy: 0.8483 - val_loss: 0.7676 - val_accuracy: 0.6364\n",
      "Epoch 570/1000\n",
      "178/178 [==============================] - 0s 179us/step - loss: 1.8070 - accuracy: 0.8764 - val_loss: 0.7816 - val_accuracy: 0.6364\n",
      "Epoch 571/1000\n",
      "178/178 [==============================] - 0s 193us/step - loss: 1.8202 - accuracy: 0.8652 - val_loss: 0.7739 - val_accuracy: 0.6623\n",
      "Epoch 572/1000\n",
      "178/178 [==============================] - 0s 179us/step - loss: 2.0664 - accuracy: 0.8652 - val_loss: 0.7742 - val_accuracy: 0.6494\n",
      "Epoch 573/1000\n",
      "178/178 [==============================] - 0s 184us/step - loss: 1.8986 - accuracy: 0.8708 - val_loss: 0.7764 - val_accuracy: 0.6883\n",
      "Epoch 574/1000\n",
      "178/178 [==============================] - 0s 177us/step - loss: 1.8172 - accuracy: 0.8764 - val_loss: 0.7728 - val_accuracy: 0.6623\n",
      "Epoch 575/1000\n",
      "178/178 [==============================] - 0s 254us/step - loss: 1.1243 - accuracy: 0.9157 - val_loss: 0.7729 - val_accuracy: 0.6623\n",
      "Epoch 576/1000\n",
      "178/178 [==============================] - ETA: 0s - loss: 1.1185 - accuracy: 0.92 - 0s 256us/step - loss: 1.3831 - accuracy: 0.8933 - val_loss: 0.7851 - val_accuracy: 0.6234\n",
      "Epoch 577/1000\n",
      "178/178 [==============================] - 0s 241us/step - loss: 1.9019 - accuracy: 0.8652 - val_loss: 0.7803 - val_accuracy: 0.6234\n",
      "Epoch 578/1000\n",
      "178/178 [==============================] - 0s 245us/step - loss: 2.1713 - accuracy: 0.8258 - val_loss: 0.7864 - val_accuracy: 0.6234\n",
      "Epoch 579/1000\n",
      "178/178 [==============================] - 0s 264us/step - loss: 2.1706 - accuracy: 0.8371 - val_loss: 0.7862 - val_accuracy: 0.6104\n",
      "Epoch 580/1000\n",
      "178/178 [==============================] - 0s 248us/step - loss: 1.9804 - accuracy: 0.8539 - val_loss: 0.7824 - val_accuracy: 0.6364\n",
      "Epoch 581/1000\n",
      "178/178 [==============================] - 0s 277us/step - loss: 2.4114 - accuracy: 0.8371 - val_loss: 0.7867 - val_accuracy: 0.6623\n",
      "Epoch 582/1000\n",
      "178/178 [==============================] - 0s 258us/step - loss: 1.6445 - accuracy: 0.8708 - val_loss: 0.7780 - val_accuracy: 0.6753\n",
      "Epoch 583/1000\n",
      "178/178 [==============================] - 0s 260us/step - loss: 2.3181 - accuracy: 0.8483 - val_loss: 0.7733 - val_accuracy: 0.6753\n",
      "Epoch 584/1000\n",
      "178/178 [==============================] - 0s 262us/step - loss: 1.9801 - accuracy: 0.8596 - val_loss: 0.7821 - val_accuracy: 0.6364\n",
      "Epoch 585/1000\n",
      "178/178 [==============================] - 0s 241us/step - loss: 1.4556 - accuracy: 0.8933 - val_loss: 0.7930 - val_accuracy: 0.6494\n",
      "Epoch 586/1000\n",
      "178/178 [==============================] - 0s 178us/step - loss: 2.1732 - accuracy: 0.8427 - val_loss: 0.7902 - val_accuracy: 0.6234\n",
      "Epoch 587/1000\n",
      "178/178 [==============================] - 0s 156us/step - loss: 1.7270 - accuracy: 0.8764 - val_loss: 0.7825 - val_accuracy: 0.6364\n",
      "Epoch 588/1000\n",
      "178/178 [==============================] - 0s 184us/step - loss: 2.3201 - accuracy: 0.8427 - val_loss: 0.7719 - val_accuracy: 0.6623\n",
      "Epoch 589/1000\n",
      "178/178 [==============================] - 0s 195us/step - loss: 2.1288 - accuracy: 0.8652 - val_loss: 0.7838 - val_accuracy: 0.6623\n",
      "Epoch 590/1000\n",
      "178/178 [==============================] - 0s 174us/step - loss: 1.6405 - accuracy: 0.8764 - val_loss: 0.7913 - val_accuracy: 0.6753\n",
      "Epoch 591/1000\n",
      "178/178 [==============================] - 0s 156us/step - loss: 1.7355 - accuracy: 0.8708 - val_loss: 0.7951 - val_accuracy: 0.6234\n",
      "Epoch 592/1000\n",
      "178/178 [==============================] - 0s 189us/step - loss: 1.9142 - accuracy: 0.8539 - val_loss: 0.8318 - val_accuracy: 0.6104\n",
      "Epoch 593/1000\n",
      "178/178 [==============================] - 0s 185us/step - loss: 1.6541 - accuracy: 0.8652 - val_loss: 0.7837 - val_accuracy: 0.6494\n",
      "Epoch 594/1000\n",
      "178/178 [==============================] - 0s 155us/step - loss: 1.1185 - accuracy: 0.9101 - val_loss: 0.7744 - val_accuracy: 0.6623\n",
      "Epoch 595/1000\n",
      "178/178 [==============================] - 0s 203us/step - loss: 1.6462 - accuracy: 0.8764 - val_loss: 0.7786 - val_accuracy: 0.6623\n",
      "Epoch 596/1000\n",
      "178/178 [==============================] - 0s 184us/step - loss: 1.2025 - accuracy: 0.9045 - val_loss: 0.7855 - val_accuracy: 0.6364\n",
      "Epoch 597/1000\n",
      "178/178 [==============================] - 0s 177us/step - loss: 1.3686 - accuracy: 0.9045 - val_loss: 0.7890 - val_accuracy: 0.6494\n",
      "Epoch 598/1000\n",
      "178/178 [==============================] - 0s 182us/step - loss: 1.8766 - accuracy: 0.8820 - val_loss: 0.7863 - val_accuracy: 0.6753\n",
      "Epoch 599/1000\n",
      "178/178 [==============================] - 0s 185us/step - loss: 1.9042 - accuracy: 0.8596 - val_loss: 0.7877 - val_accuracy: 0.6753\n",
      "Epoch 600/1000\n",
      "178/178 [==============================] - 0s 175us/step - loss: 1.7963 - accuracy: 0.8764 - val_loss: 0.7713 - val_accuracy: 0.6753\n",
      "Epoch 601/1000\n",
      "178/178 [==============================] - 0s 167us/step - loss: 1.3763 - accuracy: 0.8933 - val_loss: 0.7818 - val_accuracy: 0.6753\n",
      "Epoch 602/1000\n",
      "178/178 [==============================] - 0s 186us/step - loss: 1.5681 - accuracy: 0.8764 - val_loss: 0.7850 - val_accuracy: 0.6494\n",
      "Epoch 603/1000\n",
      "178/178 [==============================] - 0s 168us/step - loss: 1.6367 - accuracy: 0.8764 - val_loss: 0.7972 - val_accuracy: 0.6623\n",
      "Epoch 604/1000\n",
      "178/178 [==============================] - 0s 192us/step - loss: 1.8007 - accuracy: 0.8652 - val_loss: 0.7887 - val_accuracy: 0.6623\n",
      "Epoch 605/1000\n",
      "178/178 [==============================] - 0s 175us/step - loss: 2.4276 - accuracy: 0.8258 - val_loss: 0.8005 - val_accuracy: 0.6364\n",
      "Epoch 606/1000\n",
      "178/178 [==============================] - 0s 172us/step - loss: 1.4560 - accuracy: 0.9045 - val_loss: 0.7926 - val_accuracy: 0.6623\n",
      "Epoch 607/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 183us/step - loss: 2.1514 - accuracy: 0.8427 - val_loss: 0.7806 - val_accuracy: 0.6623\n",
      "Epoch 608/1000\n",
      "178/178 [==============================] - 0s 189us/step - loss: 1.6240 - accuracy: 0.8876 - val_loss: 0.8000 - val_accuracy: 0.6234\n",
      "Epoch 609/1000\n",
      "178/178 [==============================] - 0s 206us/step - loss: 1.9692 - accuracy: 0.8652 - val_loss: 0.7857 - val_accuracy: 0.6364\n",
      "Epoch 610/1000\n",
      "178/178 [==============================] - 0s 188us/step - loss: 1.4683 - accuracy: 0.8933 - val_loss: 0.7891 - val_accuracy: 0.6623\n",
      "Epoch 611/1000\n",
      "178/178 [==============================] - 0s 169us/step - loss: 1.7947 - accuracy: 0.8708 - val_loss: 0.7931 - val_accuracy: 0.6494\n",
      "Epoch 612/1000\n",
      "178/178 [==============================] - 0s 172us/step - loss: 2.1478 - accuracy: 0.8483 - val_loss: 0.7865 - val_accuracy: 0.6623\n",
      "Epoch 613/1000\n",
      "178/178 [==============================] - 0s 189us/step - loss: 1.5409 - accuracy: 0.8933 - val_loss: 0.7847 - val_accuracy: 0.6494\n",
      "Epoch 614/1000\n",
      "178/178 [==============================] - 0s 153us/step - loss: 1.4593 - accuracy: 0.8989 - val_loss: 0.7885 - val_accuracy: 0.6494\n",
      "Epoch 615/1000\n",
      "178/178 [==============================] - 0s 194us/step - loss: 1.6289 - accuracy: 0.8876 - val_loss: 0.8054 - val_accuracy: 0.6234\n",
      "Epoch 616/1000\n",
      "178/178 [==============================] - 0s 168us/step - loss: 1.7103 - accuracy: 0.8708 - val_loss: 0.7977 - val_accuracy: 0.6234\n",
      "Epoch 617/1000\n",
      "178/178 [==============================] - 0s 153us/step - loss: 2.2509 - accuracy: 0.8371 - val_loss: 0.8056 - val_accuracy: 0.6494\n",
      "Epoch 618/1000\n",
      "178/178 [==============================] - 0s 188us/step - loss: 1.5342 - accuracy: 0.8989 - val_loss: 0.7912 - val_accuracy: 0.6104\n",
      "Epoch 619/1000\n",
      "178/178 [==============================] - 0s 179us/step - loss: 1.8144 - accuracy: 0.8764 - val_loss: 0.7915 - val_accuracy: 0.6494\n",
      "Epoch 620/1000\n",
      "178/178 [==============================] - 0s 199us/step - loss: 1.9746 - accuracy: 0.8539 - val_loss: 0.7924 - val_accuracy: 0.6234\n",
      "Epoch 621/1000\n",
      "178/178 [==============================] - 0s 176us/step - loss: 2.3175 - accuracy: 0.8427 - val_loss: 0.7871 - val_accuracy: 0.6364\n",
      "Epoch 622/1000\n",
      "178/178 [==============================] - 0s 150us/step - loss: 1.3806 - accuracy: 0.8989 - val_loss: 0.7995 - val_accuracy: 0.6753\n",
      "Epoch 623/1000\n",
      "178/178 [==============================] - 0s 195us/step - loss: 2.0673 - accuracy: 0.8596 - val_loss: 0.7974 - val_accuracy: 0.6234\n",
      "Epoch 624/1000\n",
      "178/178 [==============================] - 0s 184us/step - loss: 1.7159 - accuracy: 0.8708 - val_loss: 0.7886 - val_accuracy: 0.6104\n",
      "Epoch 625/1000\n",
      "178/178 [==============================] - 0s 180us/step - loss: 1.6261 - accuracy: 0.8820 - val_loss: 0.7943 - val_accuracy: 0.6234\n",
      "Epoch 626/1000\n",
      "178/178 [==============================] - 0s 175us/step - loss: 1.8960 - accuracy: 0.8539 - val_loss: 0.7921 - val_accuracy: 0.6623\n",
      "Epoch 627/1000\n",
      "178/178 [==============================] - 0s 187us/step - loss: 1.3204 - accuracy: 0.8933 - val_loss: 0.7988 - val_accuracy: 0.6494\n",
      "Epoch 628/1000\n",
      "178/178 [==============================] - 0s 167us/step - loss: 2.3136 - accuracy: 0.8371 - val_loss: 0.8020 - val_accuracy: 0.6364\n",
      "Epoch 629/1000\n",
      "178/178 [==============================] - 0s 181us/step - loss: 1.5339 - accuracy: 0.9045 - val_loss: 0.8117 - val_accuracy: 0.6364\n",
      "Epoch 630/1000\n",
      "178/178 [==============================] - 0s 183us/step - loss: 0.8473 - accuracy: 0.9438 - val_loss: 0.7846 - val_accuracy: 0.6753\n",
      "Epoch 631/1000\n",
      "178/178 [==============================] - 0s 177us/step - loss: 1.6502 - accuracy: 0.8708 - val_loss: 0.8056 - val_accuracy: 0.6883\n",
      "Epoch 632/1000\n",
      "178/178 [==============================] - 0s 168us/step - loss: 1.3817 - accuracy: 0.8933 - val_loss: 0.7925 - val_accuracy: 0.6234\n",
      "Epoch 633/1000\n",
      "178/178 [==============================] - 0s 178us/step - loss: 1.7962 - accuracy: 0.8820 - val_loss: 0.8075 - val_accuracy: 0.6623\n",
      "Epoch 634/1000\n",
      "178/178 [==============================] - 0s 182us/step - loss: 1.9728 - accuracy: 0.8539 - val_loss: 0.7927 - val_accuracy: 0.6623\n",
      "Epoch 635/1000\n",
      "178/178 [==============================] - 0s 164us/step - loss: 2.4816 - accuracy: 0.8258 - val_loss: 0.7894 - val_accuracy: 0.6753\n",
      "Epoch 636/1000\n",
      "178/178 [==============================] - 0s 187us/step - loss: 1.8956 - accuracy: 0.8708 - val_loss: 0.7863 - val_accuracy: 0.6494\n",
      "Epoch 637/1000\n",
      "178/178 [==============================] - 0s 185us/step - loss: 2.1535 - accuracy: 0.8427 - val_loss: 0.7865 - val_accuracy: 0.6494\n",
      "Epoch 638/1000\n",
      "178/178 [==============================] - 0s 177us/step - loss: 1.6209 - accuracy: 0.8876 - val_loss: 0.7861 - val_accuracy: 0.6753\n",
      "Epoch 639/1000\n",
      "178/178 [==============================] - 0s 179us/step - loss: 1.3663 - accuracy: 0.8989 - val_loss: 0.7861 - val_accuracy: 0.6753\n",
      "Epoch 640/1000\n",
      "178/178 [==============================] - 0s 168us/step - loss: 1.7087 - accuracy: 0.8764 - val_loss: 0.7920 - val_accuracy: 0.6753\n",
      "Epoch 641/1000\n",
      "178/178 [==============================] - 0s 181us/step - loss: 2.0611 - accuracy: 0.8427 - val_loss: 0.7873 - val_accuracy: 0.6753\n",
      "Epoch 642/1000\n",
      "178/178 [==============================] - 0s 170us/step - loss: 1.5282 - accuracy: 0.8876 - val_loss: 0.7932 - val_accuracy: 0.6364\n",
      "Epoch 643/1000\n",
      "178/178 [==============================] - 0s 183us/step - loss: 1.7961 - accuracy: 0.8764 - val_loss: 0.8039 - val_accuracy: 0.6364\n",
      "Epoch 644/1000\n",
      "178/178 [==============================] - 0s 185us/step - loss: 2.2349 - accuracy: 0.8427 - val_loss: 0.8069 - val_accuracy: 0.6364\n",
      "Epoch 645/1000\n",
      "178/178 [==============================] - 0s 170us/step - loss: 2.0601 - accuracy: 0.8596 - val_loss: 0.7927 - val_accuracy: 0.6623\n",
      "Epoch 646/1000\n",
      "178/178 [==============================] - 0s 184us/step - loss: 1.8727 - accuracy: 0.8764 - val_loss: 0.7966 - val_accuracy: 0.6494\n",
      "Epoch 647/1000\n",
      "178/178 [==============================] - 0s 174us/step - loss: 1.4310 - accuracy: 0.9045 - val_loss: 0.7921 - val_accuracy: 0.6494\n",
      "Epoch 648/1000\n",
      "178/178 [==============================] - 0s 186us/step - loss: 1.8858 - accuracy: 0.8652 - val_loss: 0.8004 - val_accuracy: 0.6753\n",
      "Epoch 649/1000\n",
      "178/178 [==============================] - 0s 164us/step - loss: 1.9718 - accuracy: 0.8596 - val_loss: 0.7909 - val_accuracy: 0.6753\n",
      "Epoch 650/1000\n",
      "178/178 [==============================] - 0s 181us/step - loss: 1.9676 - accuracy: 0.8596 - val_loss: 0.8038 - val_accuracy: 0.6364\n",
      "Epoch 651/1000\n",
      "178/178 [==============================] - 0s 190us/step - loss: 2.0318 - accuracy: 0.8764 - val_loss: 0.7918 - val_accuracy: 0.6494\n",
      "Epoch 652/1000\n",
      "178/178 [==============================] - 0s 171us/step - loss: 1.8873 - accuracy: 0.8652 - val_loss: 0.8139 - val_accuracy: 0.6364\n",
      "Epoch 653/1000\n",
      "178/178 [==============================] - 0s 178us/step - loss: 2.1485 - accuracy: 0.8539 - val_loss: 0.8041 - val_accuracy: 0.6364\n",
      "Epoch 654/1000\n",
      "178/178 [==============================] - 0s 172us/step - loss: 2.3107 - accuracy: 0.8427 - val_loss: 0.8148 - val_accuracy: 0.6234\n",
      "Epoch 655/1000\n",
      "178/178 [==============================] - 0s 184us/step - loss: 2.0478 - accuracy: 0.8652 - val_loss: 0.8010 - val_accuracy: 0.6623\n",
      "Epoch 656/1000\n",
      "178/178 [==============================] - 0s 181us/step - loss: 1.8887 - accuracy: 0.8652 - val_loss: 0.8114 - val_accuracy: 0.6104\n",
      "Epoch 657/1000\n",
      "178/178 [==============================] - 0s 171us/step - loss: 1.2737 - accuracy: 0.9157 - val_loss: 0.8049 - val_accuracy: 0.6623\n",
      "Epoch 658/1000\n",
      "178/178 [==============================] - 0s 179us/step - loss: 2.0470 - accuracy: 0.8483 - val_loss: 0.8063 - val_accuracy: 0.6494\n",
      "Epoch 659/1000\n",
      "178/178 [==============================] - 0s 193us/step - loss: 1.8032 - accuracy: 0.8596 - val_loss: 0.8010 - val_accuracy: 0.6364\n",
      "Epoch 660/1000\n",
      "178/178 [==============================] - 0s 195us/step - loss: 2.0571 - accuracy: 0.8483 - val_loss: 0.8104 - val_accuracy: 0.6364\n",
      "Epoch 661/1000\n",
      "178/178 [==============================] - 0s 203us/step - loss: 1.8001 - accuracy: 0.8820 - val_loss: 0.8108 - val_accuracy: 0.6623\n",
      "Epoch 662/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 166us/step - loss: 1.1308 - accuracy: 0.9157 - val_loss: 0.8036 - val_accuracy: 0.6623\n",
      "Epoch 663/1000\n",
      "178/178 [==============================] - 0s 186us/step - loss: 1.9954 - accuracy: 0.8539 - val_loss: 0.7908 - val_accuracy: 0.6883\n",
      "Epoch 664/1000\n",
      "178/178 [==============================] - 0s 169us/step - loss: 2.1265 - accuracy: 0.8596 - val_loss: 0.8021 - val_accuracy: 0.6883\n",
      "Epoch 665/1000\n",
      "178/178 [==============================] - 0s 192us/step - loss: 1.9563 - accuracy: 0.8652 - val_loss: 0.8047 - val_accuracy: 0.6623\n",
      "Epoch 666/1000\n",
      "178/178 [==============================] - 0s 168us/step - loss: 1.7087 - accuracy: 0.8764 - val_loss: 0.8223 - val_accuracy: 0.6364\n",
      "Epoch 667/1000\n",
      "178/178 [==============================] - 0s 196us/step - loss: 2.1401 - accuracy: 0.8427 - val_loss: 0.8069 - val_accuracy: 0.6494\n",
      "Epoch 668/1000\n",
      "178/178 [==============================] - 0s 157us/step - loss: 2.1403 - accuracy: 0.8596 - val_loss: 0.8169 - val_accuracy: 0.6364\n",
      "Epoch 669/1000\n",
      "178/178 [==============================] - 0s 167us/step - loss: 1.7856 - accuracy: 0.8764 - val_loss: 0.8085 - val_accuracy: 0.6494\n",
      "Epoch 670/1000\n",
      "178/178 [==============================] - 0s 198us/step - loss: 1.5443 - accuracy: 0.8933 - val_loss: 0.8118 - val_accuracy: 0.6753\n",
      "Epoch 671/1000\n",
      "178/178 [==============================] - 0s 175us/step - loss: 1.4860 - accuracy: 0.8820 - val_loss: 0.8047 - val_accuracy: 0.6753\n",
      "Epoch 672/1000\n",
      "178/178 [==============================] - 0s 154us/step - loss: 2.1487 - accuracy: 0.8483 - val_loss: 0.8296 - val_accuracy: 0.6494\n",
      "Epoch 673/1000\n",
      "178/178 [==============================] - 0s 194us/step - loss: 2.4071 - accuracy: 0.8258 - val_loss: 0.8267 - val_accuracy: 0.6234\n",
      "Epoch 674/1000\n",
      "178/178 [==============================] - 0s 185us/step - loss: 1.4536 - accuracy: 0.8989 - val_loss: 0.8015 - val_accuracy: 0.6104\n",
      "Epoch 675/1000\n",
      "178/178 [==============================] - 0s 171us/step - loss: 1.5326 - accuracy: 0.8820 - val_loss: 0.8092 - val_accuracy: 0.6753\n",
      "Epoch 676/1000\n",
      "178/178 [==============================] - 0s 169us/step - loss: 1.8793 - accuracy: 0.8652 - val_loss: 0.8087 - val_accuracy: 0.6364\n",
      "Epoch 677/1000\n",
      "178/178 [==============================] - 0s 177us/step - loss: 2.1263 - accuracy: 0.8596 - val_loss: 0.8277 - val_accuracy: 0.6234\n",
      "Epoch 678/1000\n",
      "178/178 [==============================] - 0s 194us/step - loss: 1.5389 - accuracy: 0.8876 - val_loss: 0.8008 - val_accuracy: 0.6753\n",
      "Epoch 679/1000\n",
      "178/178 [==============================] - 0s 162us/step - loss: 1.6217 - accuracy: 0.8820 - val_loss: 0.8311 - val_accuracy: 0.6364\n",
      "Epoch 680/1000\n",
      "178/178 [==============================] - 0s 178us/step - loss: 1.4632 - accuracy: 0.8933 - val_loss: 0.8080 - val_accuracy: 0.6623\n",
      "Epoch 681/1000\n",
      "178/178 [==============================] - 0s 185us/step - loss: 1.7022 - accuracy: 0.8764 - val_loss: 0.8239 - val_accuracy: 0.6364\n",
      "Epoch 682/1000\n",
      "178/178 [==============================] - 0s 167us/step - loss: 1.1997 - accuracy: 0.9213 - val_loss: 0.8248 - val_accuracy: 0.6364\n",
      "Epoch 683/1000\n",
      "178/178 [==============================] - 0s 155us/step - loss: 1.8018 - accuracy: 0.8652 - val_loss: 0.8180 - val_accuracy: 0.6234\n",
      "Epoch 684/1000\n",
      "178/178 [==============================] - 0s 196us/step - loss: 1.4662 - accuracy: 0.8876 - val_loss: 0.7894 - val_accuracy: 0.6494\n",
      "Epoch 685/1000\n",
      "178/178 [==============================] - 0s 180us/step - loss: 1.7894 - accuracy: 0.8708 - val_loss: 0.8070 - val_accuracy: 0.6623\n",
      "Epoch 686/1000\n",
      "178/178 [==============================] - 0s 149us/step - loss: 1.9043 - accuracy: 0.8652 - val_loss: 0.8074 - val_accuracy: 0.6623\n",
      "Epoch 687/1000\n",
      "178/178 [==============================] - 0s 199us/step - loss: 1.3503 - accuracy: 0.9045 - val_loss: 0.8100 - val_accuracy: 0.6623\n",
      "Epoch 688/1000\n",
      "178/178 [==============================] - 0s 184us/step - loss: 1.9831 - accuracy: 0.8596 - val_loss: 0.8161 - val_accuracy: 0.6234\n",
      "Epoch 689/1000\n",
      "178/178 [==============================] - 0s 181us/step - loss: 1.8606 - accuracy: 0.8876 - val_loss: 0.8075 - val_accuracy: 0.6364\n",
      "Epoch 690/1000\n",
      "178/178 [==============================] - 0s 180us/step - loss: 2.0365 - accuracy: 0.8652 - val_loss: 0.8078 - val_accuracy: 0.6623\n",
      "Epoch 691/1000\n",
      "178/178 [==============================] - 0s 167us/step - loss: 1.3566 - accuracy: 0.8989 - val_loss: 0.8165 - val_accuracy: 0.6494\n",
      "Epoch 692/1000\n",
      "178/178 [==============================] - 0s 182us/step - loss: 1.6102 - accuracy: 0.8876 - val_loss: 0.8247 - val_accuracy: 0.6234\n",
      "Epoch 693/1000\n",
      "178/178 [==============================] - 0s 181us/step - loss: 1.4284 - accuracy: 0.9101 - val_loss: 0.8095 - val_accuracy: 0.6623\n",
      "Epoch 694/1000\n",
      "178/178 [==============================] - 0s 168us/step - loss: 1.5275 - accuracy: 0.8933 - val_loss: 0.8178 - val_accuracy: 0.6753\n",
      "Epoch 695/1000\n",
      "178/178 [==============================] - 0s 180us/step - loss: 1.9585 - accuracy: 0.8596 - val_loss: 0.8209 - val_accuracy: 0.6104\n",
      "Epoch 696/1000\n",
      "178/178 [==============================] - 0s 181us/step - loss: 1.6929 - accuracy: 0.8820 - val_loss: 0.8141 - val_accuracy: 0.6364\n",
      "Epoch 697/1000\n",
      "178/178 [==============================] - 0s 184us/step - loss: 1.8914 - accuracy: 0.8652 - val_loss: 0.8563 - val_accuracy: 0.6104\n",
      "Epoch 698/1000\n",
      "178/178 [==============================] - 0s 170us/step - loss: 1.7284 - accuracy: 0.8539 - val_loss: 0.8130 - val_accuracy: 0.6494\n",
      "Epoch 699/1000\n",
      "178/178 [==============================] - 0s 182us/step - loss: 1.9714 - accuracy: 0.8539 - val_loss: 0.8260 - val_accuracy: 0.6234\n",
      "Epoch 700/1000\n",
      "178/178 [==============================] - 0s 178us/step - loss: 1.7831 - accuracy: 0.8820 - val_loss: 0.8222 - val_accuracy: 0.6364\n",
      "Epoch 701/1000\n",
      "178/178 [==============================] - 0s 168us/step - loss: 0.9155 - accuracy: 0.9382 - val_loss: 0.8097 - val_accuracy: 0.6364\n",
      "Epoch 702/1000\n",
      "178/178 [==============================] - 0s 191us/step - loss: 1.6086 - accuracy: 0.8876 - val_loss: 0.8048 - val_accuracy: 0.6623\n",
      "Epoch 703/1000\n",
      "178/178 [==============================] - 0s 167us/step - loss: 1.9588 - accuracy: 0.8708 - val_loss: 0.8299 - val_accuracy: 0.6234\n",
      "Epoch 704/1000\n",
      "178/178 [==============================] - 0s 181us/step - loss: 1.7906 - accuracy: 0.8708 - val_loss: 0.8285 - val_accuracy: 0.6494\n",
      "Epoch 705/1000\n",
      "178/178 [==============================] - 0s 168us/step - loss: 2.1390 - accuracy: 0.8539 - val_loss: 0.8234 - val_accuracy: 0.6494\n",
      "Epoch 706/1000\n",
      "178/178 [==============================] - 0s 183us/step - loss: 1.6107 - accuracy: 0.8820 - val_loss: 0.8160 - val_accuracy: 0.6104\n",
      "Epoch 707/1000\n",
      "178/178 [==============================] - 0s 184us/step - loss: 2.1230 - accuracy: 0.8596 - val_loss: 0.8038 - val_accuracy: 0.6494\n",
      "Epoch 708/1000\n",
      "178/178 [==============================] - 0s 176us/step - loss: 1.4424 - accuracy: 0.8933 - val_loss: 0.8214 - val_accuracy: 0.6753\n",
      "Epoch 709/1000\n",
      "178/178 [==============================] - 0s 186us/step - loss: 1.0180 - accuracy: 0.9213 - val_loss: 0.8238 - val_accuracy: 0.6364\n",
      "Epoch 710/1000\n",
      "178/178 [==============================] - 0s 184us/step - loss: 2.1310 - accuracy: 0.8539 - val_loss: 0.8221 - val_accuracy: 0.6364\n",
      "Epoch 711/1000\n",
      "178/178 [==============================] - 0s 185us/step - loss: 1.7767 - accuracy: 0.8933 - val_loss: 0.8152 - val_accuracy: 0.6494\n",
      "Epoch 712/1000\n",
      "178/178 [==============================] - 0s 200us/step - loss: 2.0458 - accuracy: 0.8539 - val_loss: 0.8206 - val_accuracy: 0.6623\n",
      "Epoch 713/1000\n",
      "178/178 [==============================] - 0s 187us/step - loss: 1.6137 - accuracy: 0.8876 - val_loss: 0.8227 - val_accuracy: 0.6623\n",
      "Epoch 714/1000\n",
      "178/178 [==============================] - 0s 161us/step - loss: 1.6178 - accuracy: 0.8820 - val_loss: 0.8218 - val_accuracy: 0.6494\n",
      "Epoch 715/1000\n",
      "178/178 [==============================] - 0s 191us/step - loss: 1.5264 - accuracy: 0.8876 - val_loss: 0.8064 - val_accuracy: 0.6494\n",
      "Epoch 716/1000\n",
      "178/178 [==============================] - 0s 181us/step - loss: 1.5151 - accuracy: 0.8933 - val_loss: 0.8099 - val_accuracy: 0.6364\n",
      "Epoch 717/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 174us/step - loss: 2.2098 - accuracy: 0.8483 - val_loss: 0.8118 - val_accuracy: 0.6364\n",
      "Epoch 718/1000\n",
      "178/178 [==============================] - 0s 197us/step - loss: 1.8634 - accuracy: 0.8708 - val_loss: 0.8132 - val_accuracy: 0.6494\n",
      "Epoch 719/1000\n",
      "178/178 [==============================] - 0s 166us/step - loss: 1.3397 - accuracy: 0.9101 - val_loss: 0.8174 - val_accuracy: 0.6494\n",
      "Epoch 720/1000\n",
      "178/178 [==============================] - 0s 168us/step - loss: 1.8734 - accuracy: 0.8708 - val_loss: 0.8264 - val_accuracy: 0.6494\n",
      "Epoch 721/1000\n",
      "178/178 [==============================] - 0s 191us/step - loss: 1.9532 - accuracy: 0.8652 - val_loss: 0.8663 - val_accuracy: 0.6364\n",
      "Epoch 722/1000\n",
      "178/178 [==============================] - 0s 153us/step - loss: 1.3644 - accuracy: 0.9045 - val_loss: 0.8443 - val_accuracy: 0.6753\n",
      "Epoch 723/1000\n",
      "178/178 [==============================] - 0s 194us/step - loss: 1.8815 - accuracy: 0.8652 - val_loss: 0.8432 - val_accuracy: 0.6753\n",
      "Epoch 724/1000\n",
      "178/178 [==============================] - 0s 180us/step - loss: 1.5401 - accuracy: 0.8876 - val_loss: 0.8322 - val_accuracy: 0.6753\n",
      "Epoch 725/1000\n",
      "178/178 [==============================] - 0s 175us/step - loss: 1.7884 - accuracy: 0.8764 - val_loss: 0.8158 - val_accuracy: 0.6234\n",
      "Epoch 726/1000\n",
      "178/178 [==============================] - 0s 154us/step - loss: 1.7793 - accuracy: 0.8764 - val_loss: 0.8105 - val_accuracy: 0.6494\n",
      "Epoch 727/1000\n",
      "178/178 [==============================] - 0s 203us/step - loss: 1.8700 - accuracy: 0.8652 - val_loss: 0.8079 - val_accuracy: 0.6623\n",
      "Epoch 728/1000\n",
      "178/178 [==============================] - 0s 184us/step - loss: 2.2191 - accuracy: 0.8539 - val_loss: 0.8236 - val_accuracy: 0.6494\n",
      "Epoch 729/1000\n",
      "178/178 [==============================] - 0s 163us/step - loss: 1.6067 - accuracy: 0.8820 - val_loss: 0.8193 - val_accuracy: 0.6364\n",
      "Epoch 730/1000\n",
      "178/178 [==============================] - 0s 189us/step - loss: 1.9590 - accuracy: 0.8596 - val_loss: 0.8316 - val_accuracy: 0.6364\n",
      "Epoch 731/1000\n",
      "178/178 [==============================] - 0s 182us/step - loss: 2.3007 - accuracy: 0.8427 - val_loss: 0.8161 - val_accuracy: 0.6494\n",
      "Epoch 732/1000\n",
      "178/178 [==============================] - 0s 148us/step - loss: 2.0351 - accuracy: 0.8596 - val_loss: 0.8482 - val_accuracy: 0.6234\n",
      "Epoch 733/1000\n",
      "178/178 [==============================] - 0s 182us/step - loss: 1.9511 - accuracy: 0.8652 - val_loss: 0.8133 - val_accuracy: 0.6364\n",
      "Epoch 734/1000\n",
      "178/178 [==============================] - 0s 181us/step - loss: 2.2187 - accuracy: 0.8483 - val_loss: 0.8210 - val_accuracy: 0.6494\n",
      "Epoch 735/1000\n",
      "178/178 [==============================] - 0s 194us/step - loss: 1.2683 - accuracy: 0.9045 - val_loss: 0.8285 - val_accuracy: 0.6494\n",
      "Epoch 736/1000\n",
      "178/178 [==============================] - 0s 168us/step - loss: 2.0426 - accuracy: 0.8596 - val_loss: 0.8290 - val_accuracy: 0.6364\n",
      "Epoch 737/1000\n",
      "178/178 [==============================] - 0s 163us/step - loss: 2.0503 - accuracy: 0.8596 - val_loss: 0.8341 - val_accuracy: 0.6753\n",
      "Epoch 738/1000\n",
      "178/178 [==============================] - 0s 193us/step - loss: 1.7809 - accuracy: 0.8708 - val_loss: 0.8212 - val_accuracy: 0.6623\n",
      "Epoch 739/1000\n",
      "178/178 [==============================] - 0s 150us/step - loss: 1.6787 - accuracy: 0.8933 - val_loss: 0.8194 - val_accuracy: 0.6364\n",
      "Epoch 740/1000\n",
      "178/178 [==============================] - 0s 201us/step - loss: 1.6954 - accuracy: 0.8820 - val_loss: 0.8293 - val_accuracy: 0.6234\n",
      "Epoch 741/1000\n",
      "178/178 [==============================] - 0s 169us/step - loss: 1.7759 - accuracy: 0.8764 - val_loss: 0.8273 - val_accuracy: 0.6494\n",
      "Epoch 742/1000\n",
      "178/178 [==============================] - 0s 166us/step - loss: 2.6468 - accuracy: 0.8202 - val_loss: 0.8187 - val_accuracy: 0.6494\n",
      "Epoch 743/1000\n",
      "178/178 [==============================] - 0s 196us/step - loss: 2.0335 - accuracy: 0.8596 - val_loss: 0.8228 - val_accuracy: 0.6623\n",
      "Epoch 744/1000\n",
      "178/178 [==============================] - 0s 149us/step - loss: 1.6055 - accuracy: 0.8876 - val_loss: 0.8225 - val_accuracy: 0.6494\n",
      "Epoch 745/1000\n",
      "178/178 [==============================] - 0s 205us/step - loss: 1.7176 - accuracy: 0.8708 - val_loss: 0.8373 - val_accuracy: 0.6104\n",
      "Epoch 746/1000\n",
      "178/178 [==============================] - 0s 177us/step - loss: 1.5148 - accuracy: 0.8989 - val_loss: 0.8263 - val_accuracy: 0.6364\n",
      "Epoch 747/1000\n",
      "178/178 [==============================] - 0s 182us/step - loss: 1.8558 - accuracy: 0.8708 - val_loss: 0.8238 - val_accuracy: 0.6364\n",
      "Epoch 748/1000\n",
      "178/178 [==============================] - 0s 171us/step - loss: 1.5175 - accuracy: 0.8876 - val_loss: 0.8112 - val_accuracy: 0.6623\n",
      "Epoch 749/1000\n",
      "178/178 [==============================] - 0s 159us/step - loss: 1.6957 - accuracy: 0.8708 - val_loss: 0.8264 - val_accuracy: 0.6623\n",
      "Epoch 750/1000\n",
      "178/178 [==============================] - 0s 198us/step - loss: 1.8694 - accuracy: 0.8708 - val_loss: 0.8296 - val_accuracy: 0.6364\n",
      "Epoch 751/1000\n",
      "178/178 [==============================] - 0s 180us/step - loss: 2.1246 - accuracy: 0.8539 - val_loss: 0.8224 - val_accuracy: 0.6623\n",
      "Epoch 752/1000\n",
      "178/178 [==============================] - 0s 176us/step - loss: 1.5068 - accuracy: 0.8989 - val_loss: 0.8219 - val_accuracy: 0.6234\n",
      "Epoch 753/1000\n",
      "178/178 [==============================] - 0s 167us/step - loss: 1.4317 - accuracy: 0.8933 - val_loss: 0.8181 - val_accuracy: 0.6753\n",
      "Epoch 754/1000\n",
      "178/178 [==============================] - 0s 186us/step - loss: 1.9516 - accuracy: 0.8652 - val_loss: 0.8174 - val_accuracy: 0.6753\n",
      "Epoch 755/1000\n",
      "178/178 [==============================] - 0s 174us/step - loss: 1.7837 - accuracy: 0.8764 - val_loss: 0.8344 - val_accuracy: 0.6104\n",
      "Epoch 756/1000\n",
      "178/178 [==============================] - 0s 173us/step - loss: 1.2564 - accuracy: 0.9157 - val_loss: 0.8235 - val_accuracy: 0.6623\n",
      "Epoch 757/1000\n",
      "178/178 [==============================] - 0s 187us/step - loss: 1.4404 - accuracy: 0.8876 - val_loss: 0.8243 - val_accuracy: 0.6364\n",
      "Epoch 758/1000\n",
      "178/178 [==============================] - 0s 178us/step - loss: 1.8607 - accuracy: 0.8764 - val_loss: 0.8332 - val_accuracy: 0.6234\n",
      "Epoch 759/1000\n",
      "178/178 [==============================] - 0s 182us/step - loss: 1.9512 - accuracy: 0.8596 - val_loss: 0.8212 - val_accuracy: 0.6623\n",
      "Epoch 760/1000\n",
      "178/178 [==============================] - 0s 179us/step - loss: 1.9522 - accuracy: 0.8596 - val_loss: 0.8242 - val_accuracy: 0.6234\n",
      "Epoch 761/1000\n",
      "178/178 [==============================] - 0s 181us/step - loss: 1.2623 - accuracy: 0.9045 - val_loss: 0.8361 - val_accuracy: 0.6753\n",
      "Epoch 762/1000\n",
      "178/178 [==============================] - 0s 175us/step - loss: 2.0449 - accuracy: 0.8652 - val_loss: 0.8494 - val_accuracy: 0.6494\n",
      "Epoch 763/1000\n",
      "178/178 [==============================] - 0s 169us/step - loss: 1.5465 - accuracy: 0.8876 - val_loss: 0.8318 - val_accuracy: 0.6883\n",
      "Epoch 764/1000\n",
      "178/178 [==============================] - 0s 193us/step - loss: 1.1811 - accuracy: 0.9157 - val_loss: 0.8307 - val_accuracy: 0.6494\n",
      "Epoch 765/1000\n",
      "178/178 [==============================] - 0s 173us/step - loss: 1.1716 - accuracy: 0.9101 - val_loss: 0.8196 - val_accuracy: 0.6364\n",
      "Epoch 766/1000\n",
      "178/178 [==============================] - 0s 181us/step - loss: 1.1690 - accuracy: 0.9157 - val_loss: 0.8194 - val_accuracy: 0.6364\n",
      "Epoch 767/1000\n",
      "178/178 [==============================] - 0s 199us/step - loss: 1.9490 - accuracy: 0.8596 - val_loss: 0.8219 - val_accuracy: 0.6364\n",
      "Epoch 768/1000\n",
      "178/178 [==============================] - 0s 185us/step - loss: 1.6855 - accuracy: 0.8820 - val_loss: 0.8365 - val_accuracy: 0.6234\n",
      "Epoch 769/1000\n",
      "178/178 [==============================] - 0s 193us/step - loss: 2.1972 - accuracy: 0.8539 - val_loss: 0.8221 - val_accuracy: 0.6494\n",
      "Epoch 770/1000\n",
      "178/178 [==============================] - 0s 171us/step - loss: 1.6734 - accuracy: 0.8876 - val_loss: 0.8295 - val_accuracy: 0.6494\n",
      "Epoch 771/1000\n",
      "178/178 [==============================] - 0s 188us/step - loss: 1.5948 - accuracy: 0.8876 - val_loss: 0.8406 - val_accuracy: 0.6494\n",
      "Epoch 772/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 176us/step - loss: 1.3559 - accuracy: 0.8989 - val_loss: 0.8322 - val_accuracy: 0.6753\n",
      "Epoch 773/1000\n",
      "178/178 [==============================] - 0s 166us/step - loss: 1.6029 - accuracy: 0.8876 - val_loss: 0.8397 - val_accuracy: 0.6234\n",
      "Epoch 774/1000\n",
      "178/178 [==============================] - 0s 201us/step - loss: 1.6868 - accuracy: 0.8876 - val_loss: 0.8162 - val_accuracy: 0.6234\n",
      "Epoch 775/1000\n",
      "178/178 [==============================] - 0s 180us/step - loss: 1.7825 - accuracy: 0.8708 - val_loss: 0.8743 - val_accuracy: 0.6883\n",
      "Epoch 776/1000\n",
      "178/178 [==============================] - 0s 153us/step - loss: 2.2264 - accuracy: 0.8539 - val_loss: 0.8643 - val_accuracy: 0.6494\n",
      "Epoch 777/1000\n",
      "178/178 [==============================] - 0s 176us/step - loss: 1.4316 - accuracy: 0.8989 - val_loss: 0.8464 - val_accuracy: 0.6494\n",
      "Epoch 778/1000\n",
      "178/178 [==============================] - 0s 201us/step - loss: 1.7816 - accuracy: 0.8708 - val_loss: 0.8405 - val_accuracy: 0.6623\n",
      "Epoch 779/1000\n",
      "178/178 [==============================] - 0s 165us/step - loss: 1.6124 - accuracy: 0.8820 - val_loss: 0.8433 - val_accuracy: 0.6234\n",
      "Epoch 780/1000\n",
      "178/178 [==============================] - 0s 165us/step - loss: 1.2570 - accuracy: 0.9157 - val_loss: 0.8319 - val_accuracy: 0.6234\n",
      "Epoch 781/1000\n",
      "178/178 [==============================] - 0s 195us/step - loss: 2.2932 - accuracy: 0.8427 - val_loss: 0.8358 - val_accuracy: 0.6364\n",
      "Epoch 782/1000\n",
      "178/178 [==============================] - 0s 178us/step - loss: 2.0358 - accuracy: 0.8596 - val_loss: 0.8609 - val_accuracy: 0.6623\n",
      "Epoch 783/1000\n",
      "178/178 [==============================] - 0s 170us/step - loss: 2.0372 - accuracy: 0.8596 - val_loss: 0.8622 - val_accuracy: 0.6364\n",
      "Epoch 784/1000\n",
      "178/178 [==============================] - 0s 166us/step - loss: 2.2960 - accuracy: 0.8483 - val_loss: 0.8487 - val_accuracy: 0.6364\n",
      "Epoch 785/1000\n",
      "178/178 [==============================] - 0s 199us/step - loss: 1.2557 - accuracy: 0.9101 - val_loss: 0.8313 - val_accuracy: 0.6494\n",
      "Epoch 786/1000\n",
      "178/178 [==============================] - 0s 153us/step - loss: 2.2875 - accuracy: 0.8483 - val_loss: 0.8421 - val_accuracy: 0.6234\n",
      "Epoch 787/1000\n",
      "178/178 [==============================] - 0s 186us/step - loss: 1.3459 - accuracy: 0.9045 - val_loss: 0.8264 - val_accuracy: 0.6623\n",
      "Epoch 788/1000\n",
      "178/178 [==============================] - 0s 173us/step - loss: 1.7732 - accuracy: 0.8820 - val_loss: 0.8350 - val_accuracy: 0.6494\n",
      "Epoch 789/1000\n",
      "178/178 [==============================] - 0s 170us/step - loss: 1.5986 - accuracy: 0.8933 - val_loss: 0.8326 - val_accuracy: 0.6234\n",
      "Epoch 790/1000\n",
      "178/178 [==============================] - 0s 185us/step - loss: 1.9363 - accuracy: 0.8708 - val_loss: 0.8431 - val_accuracy: 0.6234\n",
      "Epoch 791/1000\n",
      "178/178 [==============================] - 0s 155us/step - loss: 1.8509 - accuracy: 0.8708 - val_loss: 0.8538 - val_accuracy: 0.6234\n",
      "Epoch 792/1000\n",
      "178/178 [==============================] - 0s 185us/step - loss: 1.7861 - accuracy: 0.8652 - val_loss: 0.8532 - val_accuracy: 0.6494\n",
      "Epoch 793/1000\n",
      "178/178 [==============================] - 0s 187us/step - loss: 2.5471 - accuracy: 0.8371 - val_loss: 0.8361 - val_accuracy: 0.6494\n",
      "Epoch 794/1000\n",
      "178/178 [==============================] - 0s 189us/step - loss: 1.5120 - accuracy: 0.8876 - val_loss: 0.8499 - val_accuracy: 0.6104\n",
      "Epoch 795/1000\n",
      "178/178 [==============================] - 0s 198us/step - loss: 1.5877 - accuracy: 0.8989 - val_loss: 0.8373 - val_accuracy: 0.6364\n",
      "Epoch 796/1000\n",
      "178/178 [==============================] - 0s 187us/step - loss: 1.5910 - accuracy: 0.8933 - val_loss: 0.8394 - val_accuracy: 0.6104\n",
      "Epoch 797/1000\n",
      "178/178 [==============================] - 0s 190us/step - loss: 2.2972 - accuracy: 0.8371 - val_loss: 0.8394 - val_accuracy: 0.6494\n",
      "Epoch 798/1000\n",
      "178/178 [==============================] - 0s 201us/step - loss: 1.6930 - accuracy: 0.8820 - val_loss: 0.8561 - val_accuracy: 0.6364\n",
      "Epoch 799/1000\n",
      "178/178 [==============================] - 0s 223us/step - loss: 2.0336 - accuracy: 0.8539 - val_loss: 0.8518 - val_accuracy: 0.6234\n",
      "Epoch 800/1000\n",
      "178/178 [==============================] - 0s 211us/step - loss: 1.7801 - accuracy: 0.8764 - val_loss: 0.8422 - val_accuracy: 0.6494\n",
      "Epoch 801/1000\n",
      "178/178 [==============================] - 0s 225us/step - loss: 1.5074 - accuracy: 0.8933 - val_loss: 0.8411 - val_accuracy: 0.6364\n",
      "Epoch 802/1000\n",
      "178/178 [==============================] - 0s 207us/step - loss: 1.6802 - accuracy: 0.8876 - val_loss: 0.8288 - val_accuracy: 0.6104\n",
      "Epoch 803/1000\n",
      "178/178 [==============================] - 0s 191us/step - loss: 1.5105 - accuracy: 0.8989 - val_loss: 0.8326 - val_accuracy: 0.6234\n",
      "Epoch 804/1000\n",
      "178/178 [==============================] - 0s 170us/step - loss: 2.5425 - accuracy: 0.8315 - val_loss: 0.8414 - val_accuracy: 0.6234\n",
      "Epoch 805/1000\n",
      "178/178 [==============================] - 0s 208us/step - loss: 1.6884 - accuracy: 0.8933 - val_loss: 0.8361 - val_accuracy: 0.6364\n",
      "Epoch 806/1000\n",
      "178/178 [==============================] - 0s 206us/step - loss: 1.1732 - accuracy: 0.9101 - val_loss: 0.8640 - val_accuracy: 0.6364\n",
      "Epoch 807/1000\n",
      "178/178 [==============================] - 0s 211us/step - loss: 1.6829 - accuracy: 0.8820 - val_loss: 0.8327 - val_accuracy: 0.6623\n",
      "Epoch 808/1000\n",
      "178/178 [==============================] - 0s 189us/step - loss: 2.3018 - accuracy: 0.8427 - val_loss: 0.8208 - val_accuracy: 0.6364\n",
      "Epoch 809/1000\n",
      "178/178 [==============================] - 0s 177us/step - loss: 2.0354 - accuracy: 0.8596 - val_loss: 0.8350 - val_accuracy: 0.6623\n",
      "Epoch 810/1000\n",
      "178/178 [==============================] - 0s 179us/step - loss: 1.8576 - accuracy: 0.8708 - val_loss: 0.8443 - val_accuracy: 0.6753\n",
      "Epoch 811/1000\n",
      "178/178 [==============================] - 0s 178us/step - loss: 1.8552 - accuracy: 0.8764 - val_loss: 0.8398 - val_accuracy: 0.6364\n",
      "Epoch 812/1000\n",
      "178/178 [==============================] - 0s 202us/step - loss: 2.0272 - accuracy: 0.8596 - val_loss: 0.8449 - val_accuracy: 0.6623\n",
      "Epoch 813/1000\n",
      "178/178 [==============================] - 0s 193us/step - loss: 1.5965 - accuracy: 0.8933 - val_loss: 0.8461 - val_accuracy: 0.6623\n",
      "Epoch 814/1000\n",
      "178/178 [==============================] - 0s 194us/step - loss: 2.0299 - accuracy: 0.8652 - val_loss: 0.8601 - val_accuracy: 0.6364\n",
      "Epoch 815/1000\n",
      "178/178 [==============================] - 0s 197us/step - loss: 1.6148 - accuracy: 0.8820 - val_loss: 0.8365 - val_accuracy: 0.6623\n",
      "Epoch 816/1000\n",
      "178/178 [==============================] - 0s 181us/step - loss: 1.2565 - accuracy: 0.9045 - val_loss: 0.8306 - val_accuracy: 0.6623\n",
      "Epoch 817/1000\n",
      "178/178 [==============================] - 0s 176us/step - loss: 1.9329 - accuracy: 0.8708 - val_loss: 0.8395 - val_accuracy: 0.6753\n",
      "Epoch 818/1000\n",
      "178/178 [==============================] - 0s 181us/step - loss: 1.8588 - accuracy: 0.8764 - val_loss: 0.8327 - val_accuracy: 0.6494\n",
      "Epoch 819/1000\n",
      "178/178 [==============================] - 0s 198us/step - loss: 1.9311 - accuracy: 0.8708 - val_loss: 0.8427 - val_accuracy: 0.6234\n",
      "Epoch 820/1000\n",
      "178/178 [==============================] - 0s 217us/step - loss: 1.2424 - accuracy: 0.9101 - val_loss: 0.8431 - val_accuracy: 0.6104\n",
      "Epoch 821/1000\n",
      "178/178 [==============================] - 0s 184us/step - loss: 1.4292 - accuracy: 0.9045 - val_loss: 0.8460 - val_accuracy: 0.6364\n",
      "Epoch 822/1000\n",
      "178/178 [==============================] - 0s 182us/step - loss: 1.5932 - accuracy: 0.8876 - val_loss: 0.8413 - val_accuracy: 0.6364\n",
      "Epoch 823/1000\n",
      "178/178 [==============================] - 0s 178us/step - loss: 1.6693 - accuracy: 0.8876 - val_loss: 0.8547 - val_accuracy: 0.6104\n",
      "Epoch 824/1000\n",
      "178/178 [==============================] - 0s 182us/step - loss: 2.4574 - accuracy: 0.8371 - val_loss: 0.8616 - val_accuracy: 0.6104\n",
      "Epoch 825/1000\n",
      "178/178 [==============================] - 0s 200us/step - loss: 2.0292 - accuracy: 0.8596 - val_loss: 0.8395 - val_accuracy: 0.6234\n",
      "Epoch 826/1000\n",
      "178/178 [==============================] - 0s 194us/step - loss: 1.9320 - accuracy: 0.8708 - val_loss: 0.8545 - val_accuracy: 0.6104\n",
      "Epoch 827/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 191us/step - loss: 1.7620 - accuracy: 0.8820 - val_loss: 0.8403 - val_accuracy: 0.6494\n",
      "Epoch 828/1000\n",
      "178/178 [==============================] - 0s 182us/step - loss: 1.9299 - accuracy: 0.8708 - val_loss: 0.8427 - val_accuracy: 0.6234\n",
      "Epoch 829/1000\n",
      "178/178 [==============================] - 0s 202us/step - loss: 2.0149 - accuracy: 0.8708 - val_loss: 0.8534 - val_accuracy: 0.6494\n",
      "Epoch 830/1000\n",
      "178/178 [==============================] - 0s 183us/step - loss: 2.1972 - accuracy: 0.8483 - val_loss: 0.8349 - val_accuracy: 0.6494\n",
      "Epoch 831/1000\n",
      "178/178 [==============================] - 0s 183us/step - loss: 2.1945 - accuracy: 0.8483 - val_loss: 0.8540 - val_accuracy: 0.6494\n",
      "Epoch 832/1000\n",
      "178/178 [==============================] - 0s 202us/step - loss: 1.8606 - accuracy: 0.8764 - val_loss: 0.8390 - val_accuracy: 0.6364\n",
      "Epoch 833/1000\n",
      "178/178 [==============================] - 0s 197us/step - loss: 2.0291 - accuracy: 0.8539 - val_loss: 0.8744 - val_accuracy: 0.6234\n",
      "Epoch 834/1000\n",
      "178/178 [==============================] - 0s 175us/step - loss: 1.9552 - accuracy: 0.8652 - val_loss: 0.8850 - val_accuracy: 0.6494\n",
      "Epoch 835/1000\n",
      "178/178 [==============================] - 0s 181us/step - loss: 1.6786 - accuracy: 0.8989 - val_loss: 0.8658 - val_accuracy: 0.6364\n",
      "Epoch 836/1000\n",
      "178/178 [==============================] - 0s 190us/step - loss: 1.1670 - accuracy: 0.9157 - val_loss: 0.8475 - val_accuracy: 0.6494\n",
      "Epoch 837/1000\n",
      "178/178 [==============================] - 0s 176us/step - loss: 1.7688 - accuracy: 0.8764 - val_loss: 0.8555 - val_accuracy: 0.6104\n",
      "Epoch 838/1000\n",
      "178/178 [==============================] - 0s 171us/step - loss: 2.0314 - accuracy: 0.8539 - val_loss: 0.8578 - val_accuracy: 0.6104\n",
      "Epoch 839/1000\n",
      "178/178 [==============================] - 0s 176us/step - loss: 1.5881 - accuracy: 0.8989 - val_loss: 0.8462 - val_accuracy: 0.6104\n",
      "Epoch 840/1000\n",
      "178/178 [==============================] - 0s 211us/step - loss: 1.6705 - accuracy: 0.8933 - val_loss: 0.8529 - val_accuracy: 0.6234\n",
      "Epoch 841/1000\n",
      "178/178 [==============================] - 0s 196us/step - loss: 2.1128 - accuracy: 0.8539 - val_loss: 0.8517 - val_accuracy: 0.6364\n",
      "Epoch 842/1000\n",
      "178/178 [==============================] - 0s 177us/step - loss: 2.4619 - accuracy: 0.8258 - val_loss: 0.8474 - val_accuracy: 0.6494\n",
      "Epoch 843/1000\n",
      "178/178 [==============================] - 0s 177us/step - loss: 2.5408 - accuracy: 0.8315 - val_loss: 0.8605 - val_accuracy: 0.6234\n",
      "Epoch 844/1000\n",
      "178/178 [==============================] - 0s 180us/step - loss: 2.4581 - accuracy: 0.8315 - val_loss: 0.8695 - val_accuracy: 0.6623\n",
      "Epoch 845/1000\n",
      "178/178 [==============================] - 0s 196us/step - loss: 1.8633 - accuracy: 0.8708 - val_loss: 0.8476 - val_accuracy: 0.6494\n",
      "Epoch 846/1000\n",
      "178/178 [==============================] - 0s 183us/step - loss: 1.7744 - accuracy: 0.8652 - val_loss: 0.8610 - val_accuracy: 0.6623\n",
      "Epoch 847/1000\n",
      "178/178 [==============================] - 0s 192us/step - loss: 1.8444 - accuracy: 0.8820 - val_loss: 0.8658 - val_accuracy: 0.6494\n",
      "Epoch 848/1000\n",
      "178/178 [==============================] - 0s 188us/step - loss: 1.6837 - accuracy: 0.8764 - val_loss: 0.8480 - val_accuracy: 0.6364\n",
      "Epoch 849/1000\n",
      "178/178 [==============================] - 0s 202us/step - loss: 1.9192 - accuracy: 0.8764 - val_loss: 0.8456 - val_accuracy: 0.6623\n",
      "Epoch 850/1000\n",
      "178/178 [==============================] - 0s 191us/step - loss: 1.9238 - accuracy: 0.8820 - val_loss: 0.8463 - val_accuracy: 0.6234\n",
      "Epoch 851/1000\n",
      "178/178 [==============================] - 0s 195us/step - loss: 1.9231 - accuracy: 0.8708 - val_loss: 0.8657 - val_accuracy: 0.6234\n",
      "Epoch 852/1000\n",
      "178/178 [==============================] - 0s 202us/step - loss: 1.7600 - accuracy: 0.8820 - val_loss: 0.8515 - val_accuracy: 0.6494\n",
      "Epoch 853/1000\n",
      "178/178 [==============================] - 0s 201us/step - loss: 2.3717 - accuracy: 0.8371 - val_loss: 0.8377 - val_accuracy: 0.6623\n",
      "Epoch 854/1000\n",
      "178/178 [==============================] - 0s 182us/step - loss: 1.3195 - accuracy: 0.9101 - val_loss: 0.8528 - val_accuracy: 0.6364\n",
      "Epoch 855/1000\n",
      "178/178 [==============================] - 0s 225us/step - loss: 1.9258 - accuracy: 0.8708 - val_loss: 0.8584 - val_accuracy: 0.6494\n",
      "Epoch 856/1000\n",
      "178/178 [==============================] - 0s 252us/step - loss: 2.5273 - accuracy: 0.8427 - val_loss: 0.8643 - val_accuracy: 0.6234\n",
      "Epoch 857/1000\n",
      "178/178 [==============================] - 0s 237us/step - loss: 2.1145 - accuracy: 0.8539 - val_loss: 0.8643 - val_accuracy: 0.6494\n",
      "Epoch 858/1000\n",
      "178/178 [==============================] - 0s 203us/step - loss: 1.7609 - accuracy: 0.8876 - val_loss: 0.8526 - val_accuracy: 0.6494\n",
      "Epoch 859/1000\n",
      "178/178 [==============================] - 0s 205us/step - loss: 1.9326 - accuracy: 0.8652 - val_loss: 0.8466 - val_accuracy: 0.6234\n",
      "Epoch 860/1000\n",
      "178/178 [==============================] - 0s 229us/step - loss: 1.5925 - accuracy: 0.8820 - val_loss: 0.8684 - val_accuracy: 0.6234\n",
      "Epoch 861/1000\n",
      "178/178 [==============================] - 0s 213us/step - loss: 2.2158 - accuracy: 0.8427 - val_loss: 0.8663 - val_accuracy: 0.6364\n",
      "Epoch 862/1000\n",
      "178/178 [==============================] - 0s 216us/step - loss: 1.3318 - accuracy: 0.9045 - val_loss: 0.8670 - val_accuracy: 0.6494\n",
      "Epoch 863/1000\n",
      "178/178 [==============================] - 0s 205us/step - loss: 1.9301 - accuracy: 0.8764 - val_loss: 0.8519 - val_accuracy: 0.6364\n",
      "Epoch 864/1000\n",
      "178/178 [==============================] - 0s 192us/step - loss: 1.6891 - accuracy: 0.8820 - val_loss: 0.8595 - val_accuracy: 0.6494\n",
      "Epoch 865/1000\n",
      "178/178 [==============================] - 0s 213us/step - loss: 1.6705 - accuracy: 0.8876 - val_loss: 0.8701 - val_accuracy: 0.6494\n",
      "Epoch 866/1000\n",
      "178/178 [==============================] - 0s 192us/step - loss: 1.9295 - accuracy: 0.8708 - val_loss: 0.8523 - val_accuracy: 0.6623\n",
      "Epoch 867/1000\n",
      "178/178 [==============================] - 0s 209us/step - loss: 1.6757 - accuracy: 0.8876 - val_loss: 0.8563 - val_accuracy: 0.6494\n",
      "Epoch 868/1000\n",
      "178/178 [==============================] - 0s 182us/step - loss: 1.6665 - accuracy: 0.8876 - val_loss: 0.8565 - val_accuracy: 0.6494\n",
      "Epoch 869/1000\n",
      "178/178 [==============================] - 0s 215us/step - loss: 1.7699 - accuracy: 0.8708 - val_loss: 0.8476 - val_accuracy: 0.6494\n",
      "Epoch 870/1000\n",
      "178/178 [==============================] - 0s 234us/step - loss: 1.5882 - accuracy: 0.8933 - val_loss: 0.8496 - val_accuracy: 0.6494\n",
      "Epoch 871/1000\n",
      "178/178 [==============================] - 0s 258us/step - loss: 2.2793 - accuracy: 0.8483 - val_loss: 0.8581 - val_accuracy: 0.6494\n",
      "Epoch 872/1000\n",
      "178/178 [==============================] - 0s 215us/step - loss: 1.9239 - accuracy: 0.8708 - val_loss: 0.8471 - val_accuracy: 0.6494\n",
      "Epoch 873/1000\n",
      "178/178 [==============================] - 0s 205us/step - loss: 1.6636 - accuracy: 0.8933 - val_loss: 0.8494 - val_accuracy: 0.6494\n",
      "Epoch 874/1000\n",
      "178/178 [==============================] - 0s 223us/step - loss: 1.5869 - accuracy: 0.8876 - val_loss: 0.8489 - val_accuracy: 0.6494\n",
      "Epoch 875/1000\n",
      "178/178 [==============================] - 0s 225us/step - loss: 1.8486 - accuracy: 0.8708 - val_loss: 0.8463 - val_accuracy: 0.6364\n",
      "Epoch 876/1000\n",
      "178/178 [==============================] - 0s 206us/step - loss: 1.0703 - accuracy: 0.9157 - val_loss: 0.8584 - val_accuracy: 0.6494\n",
      "Epoch 877/1000\n",
      "178/178 [==============================] - 0s 195us/step - loss: 1.7529 - accuracy: 0.8876 - val_loss: 0.8555 - val_accuracy: 0.6623\n",
      "Epoch 878/1000\n",
      "178/178 [==============================] - 0s 207us/step - loss: 2.1085 - accuracy: 0.8539 - val_loss: 0.8564 - val_accuracy: 0.6753\n",
      "Epoch 879/1000\n",
      "178/178 [==============================] - 0s 198us/step - loss: 1.7580 - accuracy: 0.8820 - val_loss: 0.8516 - val_accuracy: 0.6494\n",
      "Epoch 880/1000\n",
      "178/178 [==============================] - 0s 186us/step - loss: 1.3289 - accuracy: 0.9045 - val_loss: 0.8592 - val_accuracy: 0.6234\n",
      "Epoch 881/1000\n",
      "178/178 [==============================] - 0s 175us/step - loss: 1.6732 - accuracy: 0.8820 - val_loss: 0.8506 - val_accuracy: 0.6494\n",
      "Epoch 882/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 176us/step - loss: 1.4914 - accuracy: 0.9045 - val_loss: 0.8579 - val_accuracy: 0.6234\n",
      "Epoch 883/1000\n",
      "178/178 [==============================] - 0s 184us/step - loss: 1.6770 - accuracy: 0.8820 - val_loss: 0.8875 - val_accuracy: 0.6104\n",
      "Epoch 884/1000\n",
      "178/178 [==============================] - 0s 166us/step - loss: 1.9451 - accuracy: 0.8652 - val_loss: 0.8601 - val_accuracy: 0.6623\n",
      "Epoch 885/1000\n",
      "178/178 [==============================] - 0s 166us/step - loss: 1.9227 - accuracy: 0.8764 - val_loss: 0.8626 - val_accuracy: 0.6623\n",
      "Epoch 886/1000\n",
      "178/178 [==============================] - 0s 177us/step - loss: 2.1874 - accuracy: 0.8596 - val_loss: 0.8607 - val_accuracy: 0.6753\n",
      "Epoch 887/1000\n",
      "178/178 [==============================] - 0s 177us/step - loss: 1.7963 - accuracy: 0.8596 - val_loss: 0.8765 - val_accuracy: 0.6364\n",
      "Epoch 888/1000\n",
      "178/178 [==============================] - 0s 178us/step - loss: 1.7798 - accuracy: 0.8764 - val_loss: 0.8487 - val_accuracy: 0.6364\n",
      "Epoch 889/1000\n",
      "178/178 [==============================] - 0s 182us/step - loss: 1.1604 - accuracy: 0.9101 - val_loss: 0.8555 - val_accuracy: 0.6234\n",
      "Epoch 890/1000\n",
      "178/178 [==============================] - 0s 181us/step - loss: 1.6781 - accuracy: 0.8708 - val_loss: 0.8595 - val_accuracy: 0.6234\n",
      "Epoch 891/1000\n",
      "178/178 [==============================] - 0s 180us/step - loss: 1.5849 - accuracy: 0.8933 - val_loss: 0.9019 - val_accuracy: 0.6364\n",
      "Epoch 892/1000\n",
      "178/178 [==============================] - 0s 182us/step - loss: 1.3327 - accuracy: 0.9045 - val_loss: 0.8837 - val_accuracy: 0.6494\n",
      "Epoch 893/1000\n",
      "178/178 [==============================] - 0s 169us/step - loss: 1.9329 - accuracy: 0.8708 - val_loss: 0.8852 - val_accuracy: 0.6234\n",
      "Epoch 894/1000\n",
      "178/178 [==============================] - 0s 180us/step - loss: 1.4193 - accuracy: 0.9045 - val_loss: 0.8649 - val_accuracy: 0.6494\n",
      "Epoch 895/1000\n",
      "178/178 [==============================] - 0s 182us/step - loss: 1.4942 - accuracy: 0.9045 - val_loss: 0.8658 - val_accuracy: 0.6623\n",
      "Epoch 896/1000\n",
      "178/178 [==============================] - 0s 198us/step - loss: 1.2437 - accuracy: 0.9101 - val_loss: 0.8457 - val_accuracy: 0.6364\n",
      "Epoch 897/1000\n",
      "178/178 [==============================] - 0s 170us/step - loss: 2.0152 - accuracy: 0.8596 - val_loss: 0.8632 - val_accuracy: 0.6494\n",
      "Epoch 898/1000\n",
      "178/178 [==============================] - 0s 182us/step - loss: 2.0205 - accuracy: 0.8596 - val_loss: 0.8475 - val_accuracy: 0.6364\n",
      "Epoch 899/1000\n",
      "178/178 [==============================] - 0s 183us/step - loss: 1.2520 - accuracy: 0.9045 - val_loss: 0.8801 - val_accuracy: 0.6494\n",
      "Epoch 900/1000\n",
      "178/178 [==============================] - 0s 226us/step - loss: 1.5153 - accuracy: 0.8933 - val_loss: 0.8529 - val_accuracy: 0.6234\n",
      "Epoch 901/1000\n",
      "178/178 [==============================] - 0s 152us/step - loss: 1.5873 - accuracy: 0.8820 - val_loss: 0.8642 - val_accuracy: 0.6623\n",
      "Epoch 902/1000\n",
      "178/178 [==============================] - 0s 173us/step - loss: 2.7121 - accuracy: 0.8202 - val_loss: 0.8544 - val_accuracy: 0.6364\n",
      "Epoch 903/1000\n",
      "178/178 [==============================] - 0s 196us/step - loss: 1.5064 - accuracy: 0.8876 - val_loss: 0.8671 - val_accuracy: 0.6494\n",
      "Epoch 904/1000\n",
      "178/178 [==============================] - 0s 150us/step - loss: 2.0985 - accuracy: 0.8652 - val_loss: 0.8902 - val_accuracy: 0.6883\n",
      "Epoch 905/1000\n",
      "178/178 [==============================] - 0s 181us/step - loss: 1.7631 - accuracy: 0.8764 - val_loss: 0.8949 - val_accuracy: 0.6494\n",
      "Epoch 906/1000\n",
      "178/178 [==============================] - 0s 177us/step - loss: 2.2805 - accuracy: 0.8427 - val_loss: 0.8811 - val_accuracy: 0.6234\n",
      "Epoch 907/1000\n",
      "178/178 [==============================] - 0s 198us/step - loss: 1.3385 - accuracy: 0.9045 - val_loss: 0.8771 - val_accuracy: 0.6494\n",
      "Epoch 908/1000\n",
      "178/178 [==============================] - 0s 151us/step - loss: 2.3816 - accuracy: 0.8371 - val_loss: 0.8504 - val_accuracy: 0.6494\n",
      "Epoch 909/1000\n",
      "178/178 [==============================] - 0s 198us/step - loss: 2.2716 - accuracy: 0.8483 - val_loss: 0.8552 - val_accuracy: 0.6494\n",
      "Epoch 910/1000\n",
      "178/178 [==============================] - 0s 177us/step - loss: 1.4948 - accuracy: 0.9045 - val_loss: 0.8379 - val_accuracy: 0.6364\n",
      "Epoch 911/1000\n",
      "178/178 [==============================] - 0s 156us/step - loss: 1.4080 - accuracy: 0.8989 - val_loss: 0.8578 - val_accuracy: 0.6364\n",
      "Epoch 912/1000\n",
      "178/178 [==============================] - 0s 201us/step - loss: 0.9795 - accuracy: 0.9213 - val_loss: 0.8739 - val_accuracy: 0.6364\n",
      "Epoch 913/1000\n",
      "178/178 [==============================] - 0s 176us/step - loss: 2.1797 - accuracy: 0.8596 - val_loss: 0.8668 - val_accuracy: 0.6364\n",
      "Epoch 914/1000\n",
      "178/178 [==============================] - 0s 185us/step - loss: 1.7609 - accuracy: 0.8820 - val_loss: 0.8618 - val_accuracy: 0.6494\n",
      "Epoch 915/1000\n",
      "178/178 [==============================] - 0s 181us/step - loss: 1.9294 - accuracy: 0.8652 - val_loss: 0.8604 - val_accuracy: 0.6364\n",
      "Epoch 916/1000\n",
      "178/178 [==============================] - 0s 176us/step - loss: 1.5818 - accuracy: 0.8933 - val_loss: 0.8676 - val_accuracy: 0.6623\n",
      "Epoch 917/1000\n",
      "178/178 [==============================] - 0s 192us/step - loss: 1.3255 - accuracy: 0.9101 - val_loss: 0.8668 - val_accuracy: 0.6494\n",
      "Epoch 918/1000\n",
      "178/178 [==============================] - 0s 163us/step - loss: 2.0109 - accuracy: 0.8652 - val_loss: 0.8690 - val_accuracy: 0.6883\n",
      "Epoch 919/1000\n",
      "178/178 [==============================] - 0s 191us/step - loss: 1.7626 - accuracy: 0.8764 - val_loss: 0.8766 - val_accuracy: 0.6494\n",
      "Epoch 920/1000\n",
      "178/178 [==============================] - 0s 166us/step - loss: 2.2040 - accuracy: 0.8483 - val_loss: 0.8812 - val_accuracy: 0.6623\n",
      "Epoch 921/1000\n",
      "178/178 [==============================] - 0s 197us/step - loss: 1.6692 - accuracy: 0.8876 - val_loss: 0.8783 - val_accuracy: 0.6364\n",
      "Epoch 922/1000\n",
      "178/178 [==============================] - 0s 178us/step - loss: 1.4983 - accuracy: 0.8876 - val_loss: 0.8564 - val_accuracy: 0.6494\n",
      "Epoch 923/1000\n",
      "178/178 [==============================] - 0s 171us/step - loss: 1.4990 - accuracy: 0.8876 - val_loss: 0.8717 - val_accuracy: 0.6494\n",
      "Epoch 924/1000\n",
      "178/178 [==============================] - 0s 190us/step - loss: 1.5857 - accuracy: 0.8820 - val_loss: 0.8968 - val_accuracy: 0.6234\n",
      "Epoch 925/1000\n",
      "178/178 [==============================] - 0s 176us/step - loss: 1.7546 - accuracy: 0.8876 - val_loss: 0.8615 - val_accuracy: 0.6234\n",
      "Epoch 926/1000\n",
      "178/178 [==============================] - 0s 184us/step - loss: 2.0185 - accuracy: 0.8596 - val_loss: 0.8547 - val_accuracy: 0.6364\n",
      "Epoch 927/1000\n",
      "178/178 [==============================] - 0s 192us/step - loss: 1.4117 - accuracy: 0.8989 - val_loss: 0.8689 - val_accuracy: 0.6494\n",
      "Epoch 928/1000\n",
      "178/178 [==============================] - 0s 194us/step - loss: 1.5027 - accuracy: 0.8933 - val_loss: 0.8710 - val_accuracy: 0.6494\n",
      "Epoch 929/1000\n",
      "178/178 [==============================] - 0s 195us/step - loss: 1.8381 - accuracy: 0.8820 - val_loss: 0.8698 - val_accuracy: 0.6234\n",
      "Epoch 930/1000\n",
      "178/178 [==============================] - 0s 195us/step - loss: 1.4901 - accuracy: 0.8933 - val_loss: 0.8739 - val_accuracy: 0.6364\n",
      "Epoch 931/1000\n",
      "178/178 [==============================] - 0s 181us/step - loss: 1.7487 - accuracy: 0.8820 - val_loss: 0.8799 - val_accuracy: 0.6364\n",
      "Epoch 932/1000\n",
      "178/178 [==============================] - 0s 169us/step - loss: 1.8491 - accuracy: 0.8708 - val_loss: 0.8938 - val_accuracy: 0.6364\n",
      "Epoch 933/1000\n",
      "178/178 [==============================] - 0s 182us/step - loss: 1.6705 - accuracy: 0.8876 - val_loss: 0.8883 - val_accuracy: 0.6234\n",
      "Epoch 934/1000\n",
      "178/178 [==============================] - 0s 161us/step - loss: 1.5818 - accuracy: 0.8876 - val_loss: 0.8807 - val_accuracy: 0.6623\n",
      "Epoch 935/1000\n",
      "178/178 [==============================] - 0s 187us/step - loss: 1.5687 - accuracy: 0.9045 - val_loss: 0.8636 - val_accuracy: 0.6623\n",
      "Epoch 936/1000\n",
      "178/178 [==============================] - 0s 176us/step - loss: 0.9766 - accuracy: 0.9326 - val_loss: 0.8573 - val_accuracy: 0.6494\n",
      "Epoch 937/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 186us/step - loss: 1.8589 - accuracy: 0.8596 - val_loss: 0.8657 - val_accuracy: 0.6623\n",
      "Epoch 938/1000\n",
      "178/178 [==============================] - 0s 195us/step - loss: 1.4044 - accuracy: 0.9045 - val_loss: 0.8625 - val_accuracy: 0.6364\n",
      "Epoch 939/1000\n",
      "178/178 [==============================] - 0s 166us/step - loss: 1.4897 - accuracy: 0.8989 - val_loss: 0.8825 - val_accuracy: 0.6494\n",
      "Epoch 940/1000\n",
      "178/178 [==============================] - 0s 167us/step - loss: 1.6574 - accuracy: 0.8933 - val_loss: 0.8588 - val_accuracy: 0.6234\n",
      "Epoch 941/1000\n",
      "178/178 [==============================] - 0s 177us/step - loss: 2.2665 - accuracy: 0.8483 - val_loss: 0.8938 - val_accuracy: 0.6364\n",
      "Epoch 942/1000\n",
      "178/178 [==============================] - 0s 186us/step - loss: 1.5147 - accuracy: 0.8933 - val_loss: 0.8870 - val_accuracy: 0.6364\n",
      "Epoch 943/1000\n",
      "178/178 [==============================] - 0s 167us/step - loss: 1.5001 - accuracy: 0.8933 - val_loss: 0.8872 - val_accuracy: 0.6234\n",
      "Epoch 944/1000\n",
      "178/178 [==============================] - 0s 186us/step - loss: 2.2067 - accuracy: 0.8539 - val_loss: 0.8720 - val_accuracy: 0.6753\n",
      "Epoch 945/1000\n",
      "178/178 [==============================] - 0s 176us/step - loss: 1.4158 - accuracy: 0.8989 - val_loss: 0.8601 - val_accuracy: 0.6234\n",
      "Epoch 946/1000\n",
      "178/178 [==============================] - 0s 181us/step - loss: 1.5021 - accuracy: 0.8933 - val_loss: 0.8906 - val_accuracy: 0.6364\n",
      "Epoch 947/1000\n",
      "178/178 [==============================] - 0s 174us/step - loss: 1.9333 - accuracy: 0.8708 - val_loss: 0.8802 - val_accuracy: 0.6364\n",
      "Epoch 948/1000\n",
      "178/178 [==============================] - 0s 173us/step - loss: 1.3351 - accuracy: 0.8876 - val_loss: 0.8687 - val_accuracy: 0.6494\n",
      "Epoch 949/1000\n",
      "178/178 [==============================] - 0s 179us/step - loss: 1.8377 - accuracy: 0.8708 - val_loss: 0.8968 - val_accuracy: 0.6364\n",
      "Epoch 950/1000\n",
      "178/178 [==============================] - 0s 166us/step - loss: 1.2167 - accuracy: 0.9270 - val_loss: 0.8822 - val_accuracy: 0.6364\n",
      "Epoch 951/1000\n",
      "178/178 [==============================] - 0s 179us/step - loss: 1.4910 - accuracy: 0.8933 - val_loss: 0.8767 - val_accuracy: 0.6364\n",
      "Epoch 952/1000\n",
      "178/178 [==============================] - 0s 176us/step - loss: 1.9265 - accuracy: 0.8652 - val_loss: 0.8713 - val_accuracy: 0.6494\n",
      "Epoch 953/1000\n",
      "178/178 [==============================] - 0s 166us/step - loss: 1.5680 - accuracy: 0.8933 - val_loss: 0.8901 - val_accuracy: 0.6104\n",
      "Epoch 954/1000\n",
      "178/178 [==============================] - 0s 194us/step - loss: 2.1058 - accuracy: 0.8596 - val_loss: 0.8886 - val_accuracy: 0.6494\n",
      "Epoch 955/1000\n",
      "178/178 [==============================] - 0s 177us/step - loss: 1.4952 - accuracy: 0.8989 - val_loss: 0.8634 - val_accuracy: 0.6364\n",
      "Epoch 956/1000\n",
      "178/178 [==============================] - 0s 183us/step - loss: 2.0195 - accuracy: 0.8652 - val_loss: 0.8605 - val_accuracy: 0.6234\n",
      "Epoch 957/1000\n",
      "178/178 [==============================] - 0s 183us/step - loss: 1.9257 - accuracy: 0.8596 - val_loss: 0.8701 - val_accuracy: 0.6234\n",
      "Epoch 958/1000\n",
      "178/178 [==============================] - 0s 173us/step - loss: 1.4118 - accuracy: 0.8933 - val_loss: 0.8815 - val_accuracy: 0.6234\n",
      "Epoch 959/1000\n",
      "178/178 [==============================] - 0s 181us/step - loss: 1.5078 - accuracy: 0.8876 - val_loss: 0.8728 - val_accuracy: 0.6234\n",
      "Epoch 960/1000\n",
      "178/178 [==============================] - 0s 169us/step - loss: 1.4118 - accuracy: 0.8989 - val_loss: 0.8796 - val_accuracy: 0.6494\n",
      "Epoch 961/1000\n",
      "178/178 [==============================] - ETA: 0s - loss: 1.0689 - accuracy: 0.92 - 0s 183us/step - loss: 1.6723 - accuracy: 0.8764 - val_loss: 0.8811 - val_accuracy: 0.6494\n",
      "Epoch 962/1000\n",
      "178/178 [==============================] - 0s 183us/step - loss: 1.2424 - accuracy: 0.9157 - val_loss: 0.8739 - val_accuracy: 0.6623\n",
      "Epoch 963/1000\n",
      "178/178 [==============================] - 0s 180us/step - loss: 1.7569 - accuracy: 0.8876 - val_loss: 0.8867 - val_accuracy: 0.6494\n",
      "Epoch 964/1000\n",
      "178/178 [==============================] - 0s 174us/step - loss: 1.8452 - accuracy: 0.8764 - val_loss: 0.8892 - val_accuracy: 0.6104\n",
      "Epoch 965/1000\n",
      "178/178 [==============================] - 0s 162us/step - loss: 1.6676 - accuracy: 0.8820 - val_loss: 0.8842 - val_accuracy: 0.6494\n",
      "Epoch 966/1000\n",
      "178/178 [==============================] - 0s 187us/step - loss: 1.7395 - accuracy: 0.8933 - val_loss: 0.8656 - val_accuracy: 0.6234\n",
      "Epoch 967/1000\n",
      "178/178 [==============================] - 0s 174us/step - loss: 1.8446 - accuracy: 0.8596 - val_loss: 0.8963 - val_accuracy: 0.6234\n",
      "Epoch 968/1000\n",
      "178/178 [==============================] - 0s 184us/step - loss: 1.9343 - accuracy: 0.8596 - val_loss: 0.8999 - val_accuracy: 0.6753\n",
      "Epoch 969/1000\n",
      "178/178 [==============================] - 0s 179us/step - loss: 1.6595 - accuracy: 0.8933 - val_loss: 0.8984 - val_accuracy: 0.6494\n",
      "Epoch 970/1000\n",
      "178/178 [==============================] - 0s 183us/step - loss: 2.0068 - accuracy: 0.8652 - val_loss: 0.8896 - val_accuracy: 0.6234\n",
      "Epoch 971/1000\n",
      "178/178 [==============================] - 0s 196us/step - loss: 1.5841 - accuracy: 0.8876 - val_loss: 0.8739 - val_accuracy: 0.6234\n",
      "Epoch 972/1000\n",
      "178/178 [==============================] - 0s 207us/step - loss: 1.8408 - accuracy: 0.8764 - val_loss: 0.8676 - val_accuracy: 0.6364\n",
      "Epoch 973/1000\n",
      "178/178 [==============================] - 0s 189us/step - loss: 1.5795 - accuracy: 0.8820 - val_loss: 0.9049 - val_accuracy: 0.6234\n",
      "Epoch 974/1000\n",
      "178/178 [==============================] - 0s 168us/step - loss: 1.6908 - accuracy: 0.8652 - val_loss: 0.8709 - val_accuracy: 0.6494\n",
      "Epoch 975/1000\n",
      "178/178 [==============================] - 0s 170us/step - loss: 1.7485 - accuracy: 0.8764 - val_loss: 0.8852 - val_accuracy: 0.6234\n",
      "Epoch 976/1000\n",
      "178/178 [==============================] - 0s 174us/step - loss: 2.7089 - accuracy: 0.8090 - val_loss: 0.8971 - val_accuracy: 0.6104\n",
      "Epoch 977/1000\n",
      "178/178 [==============================] - 0s 187us/step - loss: 1.6742 - accuracy: 0.8764 - val_loss: 0.8964 - val_accuracy: 0.6623\n",
      "Epoch 978/1000\n",
      "178/178 [==============================] - 0s 197us/step - loss: 1.6772 - accuracy: 0.8820 - val_loss: 0.8795 - val_accuracy: 0.6234\n",
      "Epoch 979/1000\n",
      "178/178 [==============================] - 0s 158us/step - loss: 1.1500 - accuracy: 0.9101 - val_loss: 0.8806 - val_accuracy: 0.6494\n",
      "Epoch 980/1000\n",
      "178/178 [==============================] - 0s 193us/step - loss: 2.2741 - accuracy: 0.8427 - val_loss: 0.8622 - val_accuracy: 0.6623\n",
      "Epoch 981/1000\n",
      "178/178 [==============================] - 0s 175us/step - loss: 1.3259 - accuracy: 0.9045 - val_loss: 0.9120 - val_accuracy: 0.6623\n",
      "Epoch 982/1000\n",
      "178/178 [==============================] - 0s 175us/step - loss: 1.3321 - accuracy: 0.9045 - val_loss: 0.8906 - val_accuracy: 0.6623\n",
      "Epoch 983/1000\n",
      "178/178 [==============================] - 0s 171us/step - loss: 1.7585 - accuracy: 0.8764 - val_loss: 0.8930 - val_accuracy: 0.6364\n",
      "Epoch 984/1000\n",
      "178/178 [==============================] - 0s 170us/step - loss: 1.6717 - accuracy: 0.8876 - val_loss: 0.8867 - val_accuracy: 0.6364\n",
      "Epoch 985/1000\n",
      "178/178 [==============================] - 0s 182us/step - loss: 1.8416 - accuracy: 0.8652 - val_loss: 0.8741 - val_accuracy: 0.6753\n",
      "Epoch 986/1000\n",
      "178/178 [==============================] - 0s 200us/step - loss: 1.2823 - accuracy: 0.8820 - val_loss: 0.8888 - val_accuracy: 0.6494\n",
      "Epoch 987/1000\n",
      "178/178 [==============================] - 0s 169us/step - loss: 1.4901 - accuracy: 0.8989 - val_loss: 0.8795 - val_accuracy: 0.6364\n",
      "Epoch 988/1000\n",
      "178/178 [==============================] - 0s 188us/step - loss: 2.4388 - accuracy: 0.8427 - val_loss: 0.8719 - val_accuracy: 0.6623\n",
      "Epoch 989/1000\n",
      "178/178 [==============================] - 0s 164us/step - loss: 1.1382 - accuracy: 0.9213 - val_loss: 0.8597 - val_accuracy: 0.6364\n",
      "Epoch 990/1000\n",
      "178/178 [==============================] - 0s 196us/step - loss: 1.0596 - accuracy: 0.9213 - val_loss: 0.8988 - val_accuracy: 0.6234\n",
      "Epoch 991/1000\n",
      "178/178 [==============================] - 0s 179us/step - loss: 2.0136 - accuracy: 0.8708 - val_loss: 0.8817 - val_accuracy: 0.6753\n",
      "Epoch 992/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 186us/step - loss: 1.7549 - accuracy: 0.8820 - val_loss: 0.8656 - val_accuracy: 0.6623\n",
      "Epoch 993/1000\n",
      "178/178 [==============================] - 0s 191us/step - loss: 1.1409 - accuracy: 0.9213 - val_loss: 0.8495 - val_accuracy: 0.6364\n",
      "Epoch 994/1000\n",
      "178/178 [==============================] - 0s 213us/step - loss: 1.9321 - accuracy: 0.8652 - val_loss: 0.8650 - val_accuracy: 0.6494\n",
      "Epoch 995/1000\n",
      "178/178 [==============================] - 0s 173us/step - loss: 1.1345 - accuracy: 0.9213 - val_loss: 0.8800 - val_accuracy: 0.6364\n",
      "Epoch 996/1000\n",
      "178/178 [==============================] - 0s 189us/step - loss: 1.9340 - accuracy: 0.8596 - val_loss: 0.8735 - val_accuracy: 0.6494\n",
      "Epoch 997/1000\n",
      "178/178 [==============================] - 0s 180us/step - loss: 2.3502 - accuracy: 0.8427 - val_loss: 0.8714 - val_accuracy: 0.6364\n",
      "Epoch 998/1000\n",
      "178/178 [==============================] - 0s 168us/step - loss: 2.1799 - accuracy: 0.8539 - val_loss: 0.8768 - val_accuracy: 0.6494\n",
      "Epoch 999/1000\n",
      "178/178 [==============================] - 0s 153us/step - loss: 2.2645 - accuracy: 0.8427 - val_loss: 0.8814 - val_accuracy: 0.6234\n",
      "Epoch 1000/1000\n",
      "178/178 [==============================] - 0s 180us/step - loss: 1.7632 - accuracy: 0.8764 - val_loss: 0.8835 - val_accuracy: 0.6234\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a46077f98>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.fit(X_train, y_train,\n",
    "          batch_size=64, epochs=1000,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 0s 161us/step\n",
      "test accuracy: 62.34%\n"
     ]
    }
   ],
   "source": [
    "acc_test3 = model3.evaluate(X_test, y_test)[1]\n",
    "print('test accuracy: %.2f%%' % (acc_test3*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ Feature selection using lasso ##########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Retrieved from https://towardsdatascience.com/feature-selection-using-regularisation-a3678b71e499\n",
    "from sklearn.linear_model import Lasso, LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SelectFromModel(estimator=LogisticRegression(C=1, class_weight=None, dual=False,\n",
       "                                             fit_intercept=True,\n",
       "                                             intercept_scaling=1, l1_ratio=None,\n",
       "                                             max_iter=100, multi_class='warn',\n",
       "                                             n_jobs=None, penalty='l1',\n",
       "                                             random_state=None, solver='warn',\n",
       "                                             tol=0.0001, verbose=0,\n",
       "                                             warm_start=False),\n",
       "                max_features=None, norm_order=1, prefit=False, threshold=None)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selection = SelectFromModel(LogisticRegression(C=1, penalty='l1'))\n",
    "selection.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = np.array(df_clean.columns).tolist()\n",
    "names.remove('pheno')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_features = np.vstack((names, X_train))\n",
    "X_train_features = pd.DataFrame(X_train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total features: 7002\n",
      "selected features: 136\n"
     ]
    }
   ],
   "source": [
    "sel_features = X_train_features.columns[(selection.get_support())]\n",
    "print('total features: {}'.format((X_train_features.shape[1])))\n",
    "print('selected features: {}'.format(len(sel_features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 354,  403,  633,  634,  647,  672,  861,  874,  883,  991,  994,\n",
       "         998, 1290, 1372, 1390, 1402, 1521, 1537, 1561, 1576, 1606, 1696,\n",
       "        1817, 1899, 1947, 2089, 2104, 2106, 2117, 2235, 2283, 2289, 2292,\n",
       "        2326, 2370, 2420, 2511, 2520, 2546, 2587, 2630, 2666, 2746, 2830,\n",
       "        2884, 3013, 3046, 3065, 3109, 3161, 3173, 3354, 3391, 3556, 3584,\n",
       "        3586, 3623, 3686, 3703, 3752, 3817, 3825, 3874, 3882, 4031, 4047,\n",
       "        4096, 4227, 4278, 4331, 4344, 4350, 4449, 4463, 4544, 4545, 4605,\n",
       "        4623, 4665, 4736, 4761, 4762, 4842, 4957, 5047, 5068, 5100, 5128,\n",
       "        5133, 5143, 5189, 5290, 5382, 5487, 5543, 5639, 5658, 5729, 5745,\n",
       "        5758, 5799, 5824, 5825, 5890, 5955, 5982, 6005, 6024, 6109, 6187,\n",
       "        6192, 6215, 6285, 6298, 6393, 6421, 6424, 6533, 6581, 6616, 6745,\n",
       "        6755, 6914, 6926, 6933, 6935, 6941, 6960, 6965, 6972, 6976, 6977,\n",
       "        6980, 6983, 6984, 6986]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = sel_features.values\n",
    "cols.reshape((1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['TTTGGAACAAAAC',\n",
       "       'TTTGAATGCTAACGTAACTATTTCCATCTCTTCGTTTAACTAAGTTGAATTTGCCCATACCTGATTCAATTGTAGTGTCTCCGCCTGTAGCATAGTCACC',\n",
       "       'TTTAGACTTAAT', 'TTTAGACTTAATCG',\n",
       "       'TTTACTGCCGTCATCTTGCCAAAACGTTTCGTAACATGTTCAATTACAAGTCCCATACTTTGCCTCCTAAAAAAATATGTATTTATCTTAATATAACATT',\n",
       "       'TTTACAATTGCTTATAAGAAATCTGAAACATTTAGAAATTTTGTTAATGGTGCAATTGAAAGTGTTAAACAAACATTTAGTAATTTTATTCAATTTATTC',\n",
       "       'TTGGAGTAATT',\n",
       "       'TTGCTTATAAGAAATCTGAAACATTTAGAAATTTTGTTAATGGTGCAATTGAAAGTGTTAAACAAACATTTAGTAATTTTATTCAATTTATTCAACCTTT',\n",
       "       'TTGCTACTATAA',\n",
       "       'TTGAATGCTAACGTAACTATTTCCATCTCTTCGTTTAACTAAGTTGAATTTGCCCATACCTGATTCAATTGTAGTGTCTCCGCCTGTAGCATAGTCACCA',\n",
       "       'TTGAATCAGGTATGGGCAAATTCAACTTAGTTAAACGAAGAGATGGAAATAGTTACGTTAGCATTCAAAGTTATGATTTATTGGCGGTAGGTTCTGATAA',\n",
       "       'TTGAATAAATTGAATAAAATTACTAAATGTTTGTTTAACACTTTCAATTGCACCATTAACAAAATTTCTAAATGTTTCAGATTTCTTATAAGCAATTGTA',\n",
       "       'TTATTTTATTACTA', 'TTATCCGAAATTT',\n",
       "       'TTATATTAAGATAAATACATATTTTTTTAGGAGGCAAAGTATGGGACTTGTAATTGAACATGTTACGAAACGTTTTGGCAAGATGACGGCAGTAAATGAT',\n",
       "       'TTATAGTAGCA',\n",
       "       'TTACTGCCGTCATCTTGCCAAAACGTTTCGTAACATGTTCAATTACAAGTCCCATACTTTGCCTCCTAAAAAAATATGTATTTATCTTAATATAACATTT',\n",
       "       'TTACTACTATGACGAAGAATGTAATAGACGACCCGTTAATATTCAATACAACGATGGCTACGACTTAATGATAGACCAGCGTTTTATTGAAATGACGCTT',\n",
       "       'TTACATTATGCA',\n",
       "       'TTACAATTGCTTATAAGAAATCTGAAACATTTAGAAATTTTGTTAATGGTGCAATTGAAAGTGTTAAACAAACATTTAGTAATTTTATTCAATTTATTCA',\n",
       "       'TTAATGGTGACTATGCTACAGGCGGAGACACTACAATTGAATCAGGTATGGGCAAATTCAACTTAGTTAAACGAAGAGATGGAAATAGTTACGTTAGCAT',\n",
       "       'TTAAATGCGGATGTCTTTCAAGCGTCATTTCAATAAAACGCTGGTCTATCATTAAGTCGTAGCCATCGTTGTATTGAATATTAACGGGTCGTCTATTACA',\n",
       "       'TGTTATATTAAGATAAATACATATTTTTTTAGGAGGCAAAGTATGGGACTTGTAATTGAACATGTTACGAAACGTTTTGGCAAGATGACGGCAGTAAATG',\n",
       "       'TGTATTGCTCCT', 'TGTAATAGACGACC',\n",
       "       'TGCTTATAAGAAATCTGAAACATTTAGAAATTTTGTTAATGGTGCAATTGAAAGTGTTAAACAAACATTTAGTAATTTTATTCAATTTATTCAACCTTTC',\n",
       "       'TGCTACAGGCGGAGACACTACAATTGAATCAGGTATGGGCAAATTCAACTTAGTTAAACGAAGAGATGGAAATAGTTACGTTAGCATTCAAAGTTATGAT',\n",
       "       'TGCTAACGTAACTATTTCCATCTCTTCGTTTAACTAAGTTGAATTTGCCCATACCTGATTCAATTGTAGTGTCTCCGCCTGTAGCATAGTCACCATTAAC',\n",
       "       'TGCGGATGTCTTTCAAGCGTCATTTCAATAAAACGCTGGTCTATCATTAAGTCGTAGCCATCGTTGTATTGAATATTAACGGGTCGTCTATTACATTCTT',\n",
       "       'TGATAGTAAAGGA',\n",
       "       'TGACTATGCTACAGGCGGAGACACTACAATTGAATCAGGTATGGGCAAATTCAACTTAGTTAAACGAAGAGATGGAAATAGTTACGTTAGCATTCAAAGT',\n",
       "       'TGACGAAGAATGTAATAGACGACCCGTTAATATTCAATACAACGATGGCTACGACTTAATGATAGACCAGCGTTTTATTGAAATGACGCTTGAAAGACAT',\n",
       "       'TGACCGTGTCT',\n",
       "       'TGAATCAGGTATGGGCAAATTCAACTTAGTTAAACGAAGAGATGGAAATAGTTACGTTAGCATTCAAAGTTATGATTTATTGGCGGTAGGTTCTGATAAT',\n",
       "       'TGAAATATCATTTACTGCCGTCATCTTGCCAAAACGTTTCGTAACATGTTCAATTACAAGTCCCATACTTTGCCTCCTAAAAAAATATGTATTTATCTTA',\n",
       "       'TCTTTCAAGCGTCATTTCAATAAAACGCTGGTCTATCATTAAGTCGTAGCCATCGTTGTATTGAATATTAACGGGTCGTCTATTACATTCTTCGTCATAG',\n",
       "       'TCTATTATACAT', 'TCTATCGCCAG', 'TCTAATGTATTTTC',\n",
       "       'TCGTTAATGGTGACTATGCTACAGGCGGAGACACTACAATTGAATCAGGTATGGGCAAATTCAACTTAGTTAAACGAAGAGATGGAAATAGTTACGTTAG',\n",
       "       'TCGCATTTACAATTGCTTATAAGAAATCTGAAACATTTAGAAATTTTGTTAATGGTGCAATTGAAAGTGTTAAACAAACATTTAGTAATTTTATTCAATT',\n",
       "       'TCCTGTACTTT',\n",
       "       'TCATTTACTGCCGTCATCTTGCCAAAACGTTTCGTAACATGTTCAATTACAAGTCCCATACTTTGCCTCCTAAAAAAATATGTATTTATCTTAATATAAC',\n",
       "       'TCAGAACCTACCGCCAATAAATCATAACTTTGAATGCTAACGTAACTATTTCCATCTCTTCGTTTAACTAAGTTGAATTTGCCCATACCTGATTCAATTG',\n",
       "       'TCAAGCGTCATTTCAATAAAACGCTGGTCTATCATTAAGTCGTAGCCATCGTTGTATTGAATATTAACGGGTCGTCTATTACATTCTTCGTCATAGTAGT',\n",
       "       'TATTGAACTTGGCG',\n",
       "       'TATTACTACTATGACGAAGAATGTAATAGACGACCCGTTAATATTCAATACAACGATGGCTACGACTTAATGATAGACCAGCGTTTTATTGAAATGACGC',\n",
       "       'TATTAAGATAAATACATATTTTTTTAGGAGGCAAAGTATGGGACTTGTAATTGAACATGTTACGAAACGTTTTGGCAAGATGACGGCAGTAAATGATATT',\n",
       "       'TATGCTACAGGCGGAGACACTACAATTGAATCAGGTATGGGCAAATTCAACTTAGTTAAACGAAGAGATGGAAATAGTTACGTTAGCATTCAAAGTTATG',\n",
       "       'TATCATTTACTGCCGTCATCTTGCCAAAACGTTTCGTAACATGTTCAATTACAAGTCCCATACTTTGCCTCCTAAAAAAATATGTATTTATCTTAATATA',\n",
       "       'TATCAGAACCTACCGCCAATAAATCATAACTTTGAATGCTAACGTAACTATTTCCATCTCTTCGTTTAACTAAGTTGAATTTGCCCATACCTGATTCAAT',\n",
       "       'TAGTCTTGTG', 'TAGGTACTTTATTA',\n",
       "       'TACTACTATGACGAAGAATGTAATAGACGACCCGTTAATATTCAATACAACGATGGCTACGACTTAATGATAGACCAGCGTTTTATTGAAATGACGCTTG',\n",
       "       'TACCGCCAATAAATCATAACTTTGAATGCTAACGTAACTATTTCCATCTCTTCGTTTAACTAAGTTGAATTTGCCCATACCTGATTCAATTGTAGTGTCT',\n",
       "       'TACCCTTTTTG',\n",
       "       'TACAATTGAATCAGGTATGGGCAAATTCAACTTAGTTAAACGAAGAGATGGAAATAGTTACGTTAGCATTCAAAGTTATGATTTATTGGCGGTAGGTTCT',\n",
       "       'TAATGGTGACTATGCTACAGGCGGAGACACTACAATTGAATCAGGTATGGGCAAATTCAACTTAGTTAAACGAAGAGATGGAAATAGTTACGTTAGCATT',\n",
       "       'TAATGAAATATCATTTACTGCCGTCATCTTGCCAAAACGTTTCGTAACATGTTCAATTACAAGTCCCATACTTTGCCTCCTAAAAAAATATGTATTTATC',\n",
       "       'TAATAATTACTC',\n",
       "       'TAACTTTGAATGCTAACGTAACTATTTCCATCTCTTCGTTTAACTAAGTTGAATTTGCCCATACCTGATTCAATTGTAGTGTCTCCGCCTGTAGCATAGT',\n",
       "       'TAACGTAACTATTTCCATCTCTTCGTTTAACTAAGTTGAATTTGCCCATACCTGATTCAATTGTAGTGTCTCCGCCTGTAGCATAGTCACCATTAACGAC',\n",
       "       'TAAATTGAATAAAATTACTAAATGTTTGTTTAACACTTTCAATTGCACCATTAACAAAATTTCTAAATGTTTCAGATTTCTTATAAGCAATTGTAAATGC',\n",
       "       'TAAATGCGGATGTCTTTCAAGCGTCATTTCAATAAAACGCTGGTCTATCATTAAGTCGTAGCCATCGTTGTATTGAATATTAACGGGTCGTCTATTACAT',\n",
       "       'GTTTTATTATCTC', 'GTTTATTTTAATAT',\n",
       "       'GTTGAATAAATTGAATAAAATTACTAAATGTTTGTTTAACACTTTCAATTGCACCATTAACAAAATTTCTAAATGTTTCAGATTTCTTATAAGCAATTGT',\n",
       "       'GTGACTATGCTACAGGCGGAGACACTACAATTGAATCAGGTATGGGCAAATTCAACTTAGTTAAACGAAGAGATGGAAATAGTTACGTTAGCATTCAAAG',\n",
       "       'GTCGCATTTACAATTGCTTATAAGAAATCTGAAACATTTAGAAATTTTGTTAATGGTGCAATTGAAAGTGTTAAACAAACATTTAGTAATTTTATTCAAT',\n",
       "       'GTATGTTAAG', 'GTATATATGCTTT', 'GTATATAAATATATAT', 'GTAAAACTAATG',\n",
       "       'GGTTGAATAAATTGAATAAAATTACTAAATGTTTGTTTAACACTTTCAATTGCACCATTAACAAAATTTCTAAATGTTTCAGATTTCTTATAAGCAATTG',\n",
       "       'GGGCAAAAAGGG', 'GGGCAAAAAGGGT',\n",
       "       'GGATGTCTTTCAAGCGTCATTTCAATAAAACGCTGGTCTATCATTAAGTCGTAGCCATCGTTGTATTGAATATTAACGGGTCGTCTATTACATTCTTCGT',\n",
       "       'GGAGACACTACAATTGAATCAGGTATGGGCAAATTCAACTTAGTTAAACGAAGAGATGGAAATAGTTACGTTAGCATTCAAAGTTATGATTTATTGGCGG',\n",
       "       'GCTTTGCTCATT',\n",
       "       'GCTACAGGCGGAGACACTACAATTGAATCAGGTATGGGCAAATTCAACTTAGTTAAACGAAGAGATGGAAATAGTTACGTTAGCATTCAAAGTTATGATT',\n",
       "       'GCGGATGTCTTTCAAGCGTCATTTCAATAAAACGCTGGTCTATCATTAAGTCGTAGCCATCGTTGTATTGAATATTAACGGGTCGTCTATTACATTCTTC',\n",
       "       'GCGGAGACACTACAATTGAATCAGGTATGGGCAAATTCAACTTAGTTAAACGAAGAGATGGAAATAGTTACGTTAGCATTCAAAGTTATGATTTATTGGC',\n",
       "       'GCATTATCAGAACCTACCGCCAATAAATCATAACTTTGAATGCTAACGTAACTATTTCCATCTCTTCGTTTAACTAAGTTGAATTTGCCCATACCTGATT',\n",
       "       'GATGTCTTTCAAGCGTCATTTCAATAAAACGCTGGTCTATCATTAAGTCGTAGCCATCGTTGTATTGAATATTAACGGGTCGTCTATTACATTCTTCGTC',\n",
       "       'GAGACACTACAATTGAATCAGGTATGGGCAAATTCAACTTAGTTAAACGAAGAGATGGAAATAGTTACGTTAGCATTCAAAGTTATGATTTATTGGCGGT',\n",
       "       'GACTATGCTACAGGCGGAGACACTACAATTGAATCAGGTATGGGCAAATTCAACTTAGTTAAACGAAGAGATGGAAATAGTTACGTTAGCATTCAAAGTT',\n",
       "       'GACACTACAATTGAATCAGGTATGGGCAAATTCAACTTAGTTAAACGAAGAGATGGAAATAGTTACGTTAGCATTCAAAGTTATGATTTATTGGCGGTAG',\n",
       "       'GAATGTAATAGACGACCCGTTAATATTCAATACAACGATGGCTACGACTTAATGATAGACCAGCGTTTTATTGAAATGACGCTTGAAAGACATCCGCATT',\n",
       "       'GAATGCTAACGTAACTATTTCCATCTCTTCGTTTAACTAAGTTGAATTTGCCCATACCTGATTCAATTGTAGTGTCTCCGCCTGTAGCATAGTCACCATT',\n",
       "       'GAATCAGGTATGGGCAAATTCAACTTAGTTAAACGAAGAGATGGAAATAGTTACGTTAGCATTCAAAGTTATGATTTATTGGCGGTAGGTTCTGATAATG',\n",
       "       'GAACCTACCGCCAATAAATCATAACTTTGAATGCTAACGTAACTATTTCCATCTCTTCGTTTAACTAAGTTGAATTTGCCCATACCTGATTCAATTGTAG',\n",
       "       'CTTTCAAGCGTCATTTCAATAAAACGCTGGTCTATCATTAAGTCGTAGCCATCGTTGTATTGAATATTAACGGGTCGTCTATTACATTCTTCGTCATAGT',\n",
       "       'CTTAACATACG',\n",
       "       'CTATTACTACTATGACGAAGAATGTAATAGACGACCCGTTAATATTCAATACAACGATGGCTACGACTTAATGATAGACCAGCGTTTTATTGAAATGACG',\n",
       "       'CTACAGGCGGAGACACTACAATTGAATCAGGTATGGGCAAATTCAACTTAGTTAAACGAAGAGATGGAAATAGTTACGTTAGCATTCAAAGTTATGATTT',\n",
       "       'CGGAGACACTACAATTGAATCAGGTATGGGCAAATTCAACTTAGTTAAACGAAGAGATGGAAATAGTTACGTTAGCATTCAAAGTTATGATTTATTGGCG',\n",
       "       'CGCATTTACAATTGCTTATAAGAAATCTGAAACATTTAGAAATTTTGTTAATGGTGCAATTGAAAGTGTTAAACAAACATTTAGTAATTTTATTCAATTT',\n",
       "       'CCTTCAACTCCAT', 'CCTCTTAGAT',\n",
       "       'CCTACCGCCAATAAATCATAACTTTGAATGCTAACGTAACTATTTCCATCTCTTCGTTTAACTAAGTTGAATTTGCCCATACCTGATTCAATTGTAGTGT',\n",
       "       'CCCGGCAAGT', 'CCATTCATACCACT', 'CCATTCATACCACTATCACT',\n",
       "       'CATTTACAATTGCTTATAAGAAATCTGAAACATTTAGAAATTTTGTTAATGGTGCAATTGAAAGTGTTAAACAAACATTTAGTAATTTTATTCAATTTAT',\n",
       "       'CATAGTTCTGT',\n",
       "       'CAGGCGGAGACACTACAATTGAATCAGGTATGGGCAAATTCAACTTAGTTAAACGAAGAGATGGAAATAGTTACGTTAGCATTCAAAGTTATGATTTATT',\n",
       "       'CAGAACCTACCGCCAATAAATCATAACTTTGAATGCTAACGTAACTATTTCCATCTCTTCGTTTAACTAAGTTGAATTTGCCCATACCTGATTCAATTGT',\n",
       "       'CACTACAATTGAATCAGGTATGGGCAAATTCAACTTAGTTAAACGAAGAGATGGAAATAGTTACGTTAGCATTCAAAGTTATGATTTATTGGCGGTAGGT',\n",
       "       'CAAATCTTCAAAAAT',\n",
       "       'ATTTACTGCCGTCATCTTGCCAAAACGTTTCGTAACATGTTCAATTACAAGTCCCATACTTTGCCTCCTAAAAAAATATGTATTTATCTTAATATAACAT',\n",
       "       'ATTTACAATTGCTTATAAGAAATCTGAAACATTTAGAAATTTTGTTAATGGTGCAATTGAAAGTGTTAAACAAACATTTAGTAATTTTATTCAATTTATT',\n",
       "       'ATTGCTTATAAGAAATCTGAAACATTTAGAAATTTTGTTAATGGTGCAATTGAAAGTGTTAAACAAACATTTAGTAATTTTATTCAATTTATTCAACCTT',\n",
       "       'ATTACTACTATGACGAAGAATGTAATAGACGACCCGTTAATATTCAATACAACGATGGCTACGACTTAATGATAGACCAGCGTTTTATTGAAATGACGCT',\n",
       "       'ATTAAGATAAATACATATTTTTTTAGGAGGCAAAGTATGGGACTTGTAATTGAACATGTTACGAAACGTTTTGGCAAGATGACGGCAGTAAATGATATTT',\n",
       "       'ATCTCCGCTTT',\n",
       "       'ATCAGGTATGGGCAAATTCAACTTAGTTAAACGAAGAGATGGAAATAGTTACGTTAGCATTCAAAGTTATGATTTATTGGCGGTAGGTTCTGATAATGCT',\n",
       "       'ATCAGAACCTACCGCCAATAAATCATAACTTTGAATGCTAACGTAACTATTTCCATCTCTTCGTTTAACTAAGTTGAATTTGCCCATACCTGATTCAATT',\n",
       "       'ATAAGCGGTTTT', 'AGTTATGATTTATT',\n",
       "       'AGGTTGAATAAATTGAATAAAATTACTAAATGTTTGTTTAACACTTTCAATTGCACCATTAACAAAATTTCTAAATGTTTCAGATTTCTTATAAGCAATT',\n",
       "       'ACTACAATTGAATCAGGTATGGGCAAATTCAACTTAGTTAAACGAAGAGATGGAAATAGTTACGTTAGCATTCAAAGTTATGATTTATTGGCGGTAGGTT',\n",
       "       'ACGTAACTATTTCCATCTCTTCGTTTAACTAAGTTGAATTTGCCCATACCTGATTCAATTGTAGTGTCTCCGCCTGTAGCATAGTCACCATTAACGACTT',\n",
       "       'AAATTTCGGGTAGCTCGCCTACCCTTATTATTTTTT', 'X1_54622_G_A',\n",
       "       'group_3693', 'group_1537', 'group_7734', 'group_4731',\n",
       "       'group_8018', 'group_2541', 'group_2397', 'group_8685',\n",
       "       'group_6972', 'group_6962', 'group_2534', 'group_4093'],\n",
       "      dtype='<U100')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names_arr = np.array(names)\n",
    "names_arr[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,\n",
       "            ...\n",
       "            6992, 6993, 6994, 6995, 6996, 6997, 6998, 6999, 7000, 7001],\n",
       "           dtype='int64', length=6865)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "removed_features = X_train_features.columns[(selection.estimator_.coef_ == 0).ravel().tolist()]\n",
    "removed_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6865"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(removed_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(255, 136) (255,) (255, 137)\n"
     ]
    }
   ],
   "source": [
    "###### keep selected variables as a new dataframe\n",
    "df_sel = df_clean.loc[:,names_arr[cols]].copy()\n",
    "df_sel['pheno'] = df_clean['pheno']\n",
    "X_sel = df_sel.loc[:, df_sel.columns != 'pheno'].values\n",
    "y_sel = df_sel['pheno'].values\n",
    "print(X_sel.shape, y_sel.shape, df_sel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, validation, and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_sel_train, X_sel_test, y_sel_train, y_sel_test = train_test_split(X_sel, y_sel,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=123,\n",
    "                                                    stratify=y_sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### neural network\n",
    "model_sel1 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_sel_train.shape[1],)),\n",
    "    Dense(1, activation='sigmoid'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sel1.compile(optimizer='sgd',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 178 samples, validate on 77 samples\n",
      "Epoch 1/1000\n",
      "178/178 [==============================] - 0s 791us/step - loss: 0.6346 - accuracy: 0.6124 - val_loss: 0.6497 - val_accuracy: 0.5714\n",
      "Epoch 2/1000\n",
      "178/178 [==============================] - 0s 203us/step - loss: 0.6247 - accuracy: 0.6180 - val_loss: 0.6470 - val_accuracy: 0.5714\n",
      "Epoch 3/1000\n",
      "178/178 [==============================] - 0s 220us/step - loss: 0.6157 - accuracy: 0.6180 - val_loss: 0.6454 - val_accuracy: 0.5714\n",
      "Epoch 4/1000\n",
      "178/178 [==============================] - 0s 155us/step - loss: 0.6093 - accuracy: 0.6067 - val_loss: 0.6445 - val_accuracy: 0.5584\n",
      "Epoch 5/1000\n",
      "178/178 [==============================] - 0s 116us/step - loss: 0.6027 - accuracy: 0.6348 - val_loss: 0.6434 - val_accuracy: 0.5584\n",
      "Epoch 6/1000\n",
      "178/178 [==============================] - 0s 120us/step - loss: 0.5970 - accuracy: 0.6517 - val_loss: 0.6419 - val_accuracy: 0.5584\n",
      "Epoch 7/1000\n",
      "178/178 [==============================] - 0s 104us/step - loss: 0.5916 - accuracy: 0.6629 - val_loss: 0.6413 - val_accuracy: 0.5714\n",
      "Epoch 8/1000\n",
      "178/178 [==============================] - 0s 101us/step - loss: 0.5866 - accuracy: 0.6629 - val_loss: 0.6401 - val_accuracy: 0.5714\n",
      "Epoch 9/1000\n",
      "178/178 [==============================] - 0s 120us/step - loss: 0.5819 - accuracy: 0.6742 - val_loss: 0.6405 - val_accuracy: 0.5584\n",
      "Epoch 10/1000\n",
      "178/178 [==============================] - 0s 219us/step - loss: 0.5772 - accuracy: 0.6798 - val_loss: 0.6408 - val_accuracy: 0.5584\n",
      "Epoch 11/1000\n",
      "178/178 [==============================] - 0s 150us/step - loss: 0.5727 - accuracy: 0.6798 - val_loss: 0.6406 - val_accuracy: 0.5584\n",
      "Epoch 12/1000\n",
      "178/178 [==============================] - 0s 118us/step - loss: 0.5683 - accuracy: 0.6798 - val_loss: 0.6406 - val_accuracy: 0.5584\n",
      "Epoch 13/1000\n",
      "178/178 [==============================] - 0s 101us/step - loss: 0.5643 - accuracy: 0.6966 - val_loss: 0.6406 - val_accuracy: 0.5584\n",
      "Epoch 14/1000\n",
      "178/178 [==============================] - 0s 114us/step - loss: 0.5601 - accuracy: 0.7022 - val_loss: 0.6403 - val_accuracy: 0.5455\n",
      "Epoch 15/1000\n",
      "178/178 [==============================] - 0s 105us/step - loss: 0.5560 - accuracy: 0.7022 - val_loss: 0.6403 - val_accuracy: 0.5455\n",
      "Epoch 16/1000\n",
      "178/178 [==============================] - 0s 126us/step - loss: 0.5522 - accuracy: 0.7079 - val_loss: 0.6385 - val_accuracy: 0.5455\n",
      "Epoch 17/1000\n",
      "178/178 [==============================] - 0s 118us/step - loss: 0.5484 - accuracy: 0.7079 - val_loss: 0.6392 - val_accuracy: 0.5455\n",
      "Epoch 18/1000\n",
      "178/178 [==============================] - 0s 102us/step - loss: 0.5448 - accuracy: 0.7191 - val_loss: 0.6380 - val_accuracy: 0.5455\n",
      "Epoch 19/1000\n",
      "178/178 [==============================] - 0s 101us/step - loss: 0.5413 - accuracy: 0.7191 - val_loss: 0.6383 - val_accuracy: 0.5455\n",
      "Epoch 20/1000\n",
      "178/178 [==============================] - 0s 95us/step - loss: 0.5379 - accuracy: 0.7191 - val_loss: 0.6377 - val_accuracy: 0.5584\n",
      "Epoch 21/1000\n",
      "178/178 [==============================] - 0s 109us/step - loss: 0.5346 - accuracy: 0.7247 - val_loss: 0.6385 - val_accuracy: 0.5584\n",
      "Epoch 22/1000\n",
      "178/178 [==============================] - 0s 92us/step - loss: 0.5314 - accuracy: 0.7303 - val_loss: 0.6369 - val_accuracy: 0.5584\n",
      "Epoch 23/1000\n",
      "178/178 [==============================] - 0s 115us/step - loss: 0.5277 - accuracy: 0.7472 - val_loss: 0.6369 - val_accuracy: 0.5844\n",
      "Epoch 24/1000\n",
      "178/178 [==============================] - 0s 103us/step - loss: 0.5248 - accuracy: 0.7472 - val_loss: 0.6367 - val_accuracy: 0.5974\n",
      "Epoch 25/1000\n",
      "178/178 [==============================] - 0s 115us/step - loss: 0.5217 - accuracy: 0.7528 - val_loss: 0.6356 - val_accuracy: 0.5974\n",
      "Epoch 26/1000\n",
      "178/178 [==============================] - 0s 107us/step - loss: 0.5186 - accuracy: 0.7528 - val_loss: 0.6357 - val_accuracy: 0.5974\n",
      "Epoch 27/1000\n",
      "178/178 [==============================] - 0s 108us/step - loss: 0.5152 - accuracy: 0.7584 - val_loss: 0.6352 - val_accuracy: 0.6104\n",
      "Epoch 28/1000\n",
      "178/178 [==============================] - 0s 97us/step - loss: 0.5119 - accuracy: 0.7584 - val_loss: 0.6342 - val_accuracy: 0.5974\n",
      "Epoch 29/1000\n",
      "178/178 [==============================] - 0s 106us/step - loss: 0.5090 - accuracy: 0.7640 - val_loss: 0.6319 - val_accuracy: 0.5974\n",
      "Epoch 30/1000\n",
      "178/178 [==============================] - 0s 114us/step - loss: 0.5060 - accuracy: 0.7640 - val_loss: 0.6313 - val_accuracy: 0.5974\n",
      "Epoch 31/1000\n",
      "178/178 [==============================] - 0s 207us/step - loss: 0.5031 - accuracy: 0.7697 - val_loss: 0.6311 - val_accuracy: 0.5974\n",
      "Epoch 32/1000\n",
      "178/178 [==============================] - 0s 208us/step - loss: 0.5006 - accuracy: 0.7697 - val_loss: 0.6307 - val_accuracy: 0.6104\n",
      "Epoch 33/1000\n",
      "178/178 [==============================] - 0s 178us/step - loss: 0.4969 - accuracy: 0.7809 - val_loss: 0.6293 - val_accuracy: 0.5974\n",
      "Epoch 34/1000\n",
      "178/178 [==============================] - 0s 172us/step - loss: 0.4942 - accuracy: 0.7921 - val_loss: 0.6291 - val_accuracy: 0.5974\n",
      "Epoch 35/1000\n",
      "178/178 [==============================] - 0s 156us/step - loss: 0.4913 - accuracy: 0.7921 - val_loss: 0.6299 - val_accuracy: 0.5974\n",
      "Epoch 36/1000\n",
      "178/178 [==============================] - 0s 237us/step - loss: 0.4885 - accuracy: 0.7865 - val_loss: 0.6289 - val_accuracy: 0.5974\n",
      "Epoch 37/1000\n",
      "178/178 [==============================] - 0s 131us/step - loss: 0.4860 - accuracy: 0.7921 - val_loss: 0.6268 - val_accuracy: 0.5974\n",
      "Epoch 38/1000\n",
      "178/178 [==============================] - 0s 126us/step - loss: 0.4827 - accuracy: 0.7978 - val_loss: 0.6275 - val_accuracy: 0.5974\n",
      "Epoch 39/1000\n",
      "178/178 [==============================] - 0s 124us/step - loss: 0.4797 - accuracy: 0.7978 - val_loss: 0.6280 - val_accuracy: 0.5974\n",
      "Epoch 40/1000\n",
      "178/178 [==============================] - 0s 103us/step - loss: 0.4769 - accuracy: 0.7978 - val_loss: 0.6279 - val_accuracy: 0.5974\n",
      "Epoch 41/1000\n",
      "178/178 [==============================] - 0s 118us/step - loss: 0.4745 - accuracy: 0.8034 - val_loss: 0.6269 - val_accuracy: 0.6104\n",
      "Epoch 42/1000\n",
      "178/178 [==============================] - 0s 96us/step - loss: 0.4718 - accuracy: 0.8090 - val_loss: 0.6274 - val_accuracy: 0.6234\n",
      "Epoch 43/1000\n",
      "178/178 [==============================] - 0s 88us/step - loss: 0.4690 - accuracy: 0.8090 - val_loss: 0.6262 - val_accuracy: 0.6234\n",
      "Epoch 44/1000\n",
      "178/178 [==============================] - 0s 97us/step - loss: 0.4670 - accuracy: 0.8090 - val_loss: 0.6248 - val_accuracy: 0.6234\n",
      "Epoch 45/1000\n",
      "178/178 [==============================] - 0s 87us/step - loss: 0.4641 - accuracy: 0.8090 - val_loss: 0.6255 - val_accuracy: 0.6234\n",
      "Epoch 46/1000\n",
      "178/178 [==============================] - 0s 106us/step - loss: 0.4615 - accuracy: 0.8146 - val_loss: 0.6253 - val_accuracy: 0.6234\n",
      "Epoch 47/1000\n",
      "178/178 [==============================] - 0s 137us/step - loss: 0.4590 - accuracy: 0.8146 - val_loss: 0.6251 - val_accuracy: 0.5974\n",
      "Epoch 48/1000\n",
      "178/178 [==============================] - 0s 172us/step - loss: 0.4565 - accuracy: 0.8090 - val_loss: 0.6262 - val_accuracy: 0.5974\n",
      "Epoch 49/1000\n",
      "178/178 [==============================] - 0s 171us/step - loss: 0.4538 - accuracy: 0.8146 - val_loss: 0.6261 - val_accuracy: 0.5974\n",
      "Epoch 50/1000\n",
      "178/178 [==============================] - 0s 129us/step - loss: 0.4515 - accuracy: 0.8090 - val_loss: 0.6263 - val_accuracy: 0.5974\n",
      "Epoch 51/1000\n",
      "178/178 [==============================] - 0s 115us/step - loss: 0.4494 - accuracy: 0.8146 - val_loss: 0.6256 - val_accuracy: 0.5974\n",
      "Epoch 52/1000\n",
      "178/178 [==============================] - 0s 313us/step - loss: 0.4465 - accuracy: 0.8146 - val_loss: 0.6266 - val_accuracy: 0.5974\n",
      "Epoch 53/1000\n",
      "178/178 [==============================] - 0s 169us/step - loss: 0.4441 - accuracy: 0.8146 - val_loss: 0.6279 - val_accuracy: 0.5974\n",
      "Epoch 54/1000\n",
      "178/178 [==============================] - 0s 125us/step - loss: 0.4420 - accuracy: 0.8146 - val_loss: 0.6278 - val_accuracy: 0.5974\n",
      "Epoch 55/1000\n",
      "178/178 [==============================] - 0s 152us/step - loss: 0.4398 - accuracy: 0.8146 - val_loss: 0.6293 - val_accuracy: 0.6104\n",
      "Epoch 56/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 176us/step - loss: 0.4375 - accuracy: 0.8202 - val_loss: 0.6287 - val_accuracy: 0.5844\n",
      "Epoch 57/1000\n",
      "178/178 [==============================] - 0s 172us/step - loss: 0.4354 - accuracy: 0.8146 - val_loss: 0.6292 - val_accuracy: 0.5844\n",
      "Epoch 58/1000\n",
      "178/178 [==============================] - 0s 115us/step - loss: 0.4330 - accuracy: 0.8146 - val_loss: 0.6285 - val_accuracy: 0.5844\n",
      "Epoch 59/1000\n",
      "178/178 [==============================] - 0s 170us/step - loss: 0.4311 - accuracy: 0.8146 - val_loss: 0.6265 - val_accuracy: 0.5844\n",
      "Epoch 60/1000\n",
      "178/178 [==============================] - 0s 134us/step - loss: 0.4286 - accuracy: 0.8146 - val_loss: 0.6265 - val_accuracy: 0.5844\n",
      "Epoch 61/1000\n",
      "178/178 [==============================] - 0s 99us/step - loss: 0.4266 - accuracy: 0.8090 - val_loss: 0.6278 - val_accuracy: 0.5844\n",
      "Epoch 62/1000\n",
      "178/178 [==============================] - 0s 134us/step - loss: 0.4248 - accuracy: 0.8202 - val_loss: 0.6277 - val_accuracy: 0.5844\n",
      "Epoch 63/1000\n",
      "178/178 [==============================] - 0s 120us/step - loss: 0.4225 - accuracy: 0.8202 - val_loss: 0.6269 - val_accuracy: 0.5844\n",
      "Epoch 64/1000\n",
      "178/178 [==============================] - 0s 104us/step - loss: 0.4202 - accuracy: 0.8202 - val_loss: 0.6271 - val_accuracy: 0.5844\n",
      "Epoch 65/1000\n",
      "178/178 [==============================] - 0s 185us/step - loss: 0.4180 - accuracy: 0.8202 - val_loss: 0.6276 - val_accuracy: 0.5844\n",
      "Epoch 66/1000\n",
      "178/178 [==============================] - 0s 634us/step - loss: 0.4159 - accuracy: 0.8202 - val_loss: 0.6270 - val_accuracy: 0.5844\n",
      "Epoch 67/1000\n",
      "178/178 [==============================] - 0s 183us/step - loss: 0.4143 - accuracy: 0.8202 - val_loss: 0.6279 - val_accuracy: 0.5844\n",
      "Epoch 68/1000\n",
      "178/178 [==============================] - 0s 80us/step - loss: 0.4124 - accuracy: 0.8202 - val_loss: 0.6274 - val_accuracy: 0.5844\n",
      "Epoch 69/1000\n",
      "178/178 [==============================] - 0s 152us/step - loss: 0.4096 - accuracy: 0.8258 - val_loss: 0.6297 - val_accuracy: 0.5714\n",
      "Epoch 70/1000\n",
      "178/178 [==============================] - 0s 67us/step - loss: 0.4077 - accuracy: 0.8202 - val_loss: 0.6295 - val_accuracy: 0.5714\n",
      "Epoch 71/1000\n",
      "178/178 [==============================] - 0s 108us/step - loss: 0.4058 - accuracy: 0.8202 - val_loss: 0.6289 - val_accuracy: 0.5714\n",
      "Epoch 72/1000\n",
      "178/178 [==============================] - 0s 99us/step - loss: 0.4037 - accuracy: 0.8202 - val_loss: 0.6296 - val_accuracy: 0.5714\n",
      "Epoch 73/1000\n",
      "178/178 [==============================] - 0s 114us/step - loss: 0.4018 - accuracy: 0.8315 - val_loss: 0.6300 - val_accuracy: 0.5714\n",
      "Epoch 74/1000\n",
      "178/178 [==============================] - 0s 251us/step - loss: 0.3999 - accuracy: 0.8315 - val_loss: 0.6293 - val_accuracy: 0.5714\n",
      "Epoch 75/1000\n",
      "178/178 [==============================] - 0s 140us/step - loss: 0.3988 - accuracy: 0.8315 - val_loss: 0.6299 - val_accuracy: 0.5844\n",
      "Epoch 76/1000\n",
      "178/178 [==============================] - 0s 116us/step - loss: 0.3963 - accuracy: 0.8315 - val_loss: 0.6314 - val_accuracy: 0.5844\n",
      "Epoch 77/1000\n",
      "178/178 [==============================] - 0s 216us/step - loss: 0.3950 - accuracy: 0.8315 - val_loss: 0.6319 - val_accuracy: 0.5844\n",
      "Epoch 78/1000\n",
      "178/178 [==============================] - 0s 146us/step - loss: 0.3931 - accuracy: 0.8315 - val_loss: 0.6323 - val_accuracy: 0.5844\n",
      "Epoch 79/1000\n",
      "178/178 [==============================] - 0s 121us/step - loss: 0.3915 - accuracy: 0.8315 - val_loss: 0.6328 - val_accuracy: 0.5844\n",
      "Epoch 80/1000\n",
      "178/178 [==============================] - 0s 193us/step - loss: 0.3893 - accuracy: 0.8315 - val_loss: 0.6318 - val_accuracy: 0.5844\n",
      "Epoch 81/1000\n",
      "178/178 [==============================] - 0s 119us/step - loss: 0.3878 - accuracy: 0.8315 - val_loss: 0.6323 - val_accuracy: 0.5844\n",
      "Epoch 82/1000\n",
      "178/178 [==============================] - 0s 129us/step - loss: 0.3864 - accuracy: 0.8315 - val_loss: 0.6317 - val_accuracy: 0.5844\n",
      "Epoch 83/1000\n",
      "178/178 [==============================] - 0s 124us/step - loss: 0.3847 - accuracy: 0.8315 - val_loss: 0.6320 - val_accuracy: 0.5844\n",
      "Epoch 84/1000\n",
      "178/178 [==============================] - 0s 129us/step - loss: 0.3835 - accuracy: 0.8371 - val_loss: 0.6330 - val_accuracy: 0.5844\n",
      "Epoch 85/1000\n",
      "178/178 [==============================] - 0s 118us/step - loss: 0.3817 - accuracy: 0.8315 - val_loss: 0.6332 - val_accuracy: 0.5974\n",
      "Epoch 86/1000\n",
      "178/178 [==============================] - 0s 146us/step - loss: 0.3808 - accuracy: 0.8371 - val_loss: 0.6347 - val_accuracy: 0.5844\n",
      "Epoch 87/1000\n",
      "178/178 [==============================] - 0s 285us/step - loss: 0.3786 - accuracy: 0.8427 - val_loss: 0.6369 - val_accuracy: 0.5844\n",
      "Epoch 88/1000\n",
      "178/178 [==============================] - 0s 209us/step - loss: 0.3775 - accuracy: 0.8371 - val_loss: 0.6379 - val_accuracy: 0.5714\n",
      "Epoch 89/1000\n",
      "178/178 [==============================] - 0s 106us/step - loss: 0.3757 - accuracy: 0.8427 - val_loss: 0.6386 - val_accuracy: 0.5714\n",
      "Epoch 90/1000\n",
      "178/178 [==============================] - 0s 105us/step - loss: 0.3739 - accuracy: 0.8427 - val_loss: 0.6382 - val_accuracy: 0.5844\n",
      "Epoch 91/1000\n",
      "178/178 [==============================] - 0s 101us/step - loss: 0.3731 - accuracy: 0.8371 - val_loss: 0.6390 - val_accuracy: 0.5844\n",
      "Epoch 92/1000\n",
      "178/178 [==============================] - 0s 82us/step - loss: 0.3716 - accuracy: 0.8427 - val_loss: 0.6393 - val_accuracy: 0.5844\n",
      "Epoch 93/1000\n",
      "178/178 [==============================] - 0s 95us/step - loss: 0.3710 - accuracy: 0.8371 - val_loss: 0.6389 - val_accuracy: 0.5844\n",
      "Epoch 94/1000\n",
      "178/178 [==============================] - 0s 104us/step - loss: 0.3690 - accuracy: 0.8427 - val_loss: 0.6397 - val_accuracy: 0.5844\n",
      "Epoch 95/1000\n",
      "178/178 [==============================] - 0s 83us/step - loss: 0.3679 - accuracy: 0.8427 - val_loss: 0.6403 - val_accuracy: 0.5844\n",
      "Epoch 96/1000\n",
      "178/178 [==============================] - 0s 88us/step - loss: 0.3661 - accuracy: 0.8427 - val_loss: 0.6406 - val_accuracy: 0.5844\n",
      "Epoch 97/1000\n",
      "178/178 [==============================] - 0s 87us/step - loss: 0.3648 - accuracy: 0.8427 - val_loss: 0.6425 - val_accuracy: 0.5844\n",
      "Epoch 98/1000\n",
      "178/178 [==============================] - 0s 87us/step - loss: 0.3638 - accuracy: 0.8427 - val_loss: 0.6431 - val_accuracy: 0.5844\n",
      "Epoch 99/1000\n",
      "178/178 [==============================] - 0s 93us/step - loss: 0.3622 - accuracy: 0.8427 - val_loss: 0.6439 - val_accuracy: 0.5844\n",
      "Epoch 100/1000\n",
      "178/178 [==============================] - 0s 83us/step - loss: 0.3610 - accuracy: 0.8427 - val_loss: 0.6446 - val_accuracy: 0.5844\n",
      "Epoch 101/1000\n",
      "178/178 [==============================] - 0s 105us/step - loss: 0.3599 - accuracy: 0.8427 - val_loss: 0.6449 - val_accuracy: 0.5844\n",
      "Epoch 102/1000\n",
      "178/178 [==============================] - 0s 108us/step - loss: 0.3583 - accuracy: 0.8427 - val_loss: 0.6430 - val_accuracy: 0.5974\n",
      "Epoch 103/1000\n",
      "178/178 [==============================] - 0s 128us/step - loss: 0.3575 - accuracy: 0.8427 - val_loss: 0.6433 - val_accuracy: 0.5974\n",
      "Epoch 104/1000\n",
      "178/178 [==============================] - 0s 107us/step - loss: 0.3569 - accuracy: 0.8427 - val_loss: 0.6450 - val_accuracy: 0.5844\n",
      "Epoch 105/1000\n",
      "178/178 [==============================] - 0s 100us/step - loss: 0.3550 - accuracy: 0.8427 - val_loss: 0.6469 - val_accuracy: 0.5844\n",
      "Epoch 106/1000\n",
      "178/178 [==============================] - 0s 111us/step - loss: 0.3547 - accuracy: 0.8539 - val_loss: 0.6471 - val_accuracy: 0.5974\n",
      "Epoch 107/1000\n",
      "178/178 [==============================] - 0s 103us/step - loss: 0.3522 - accuracy: 0.8483 - val_loss: 0.6475 - val_accuracy: 0.5974\n",
      "Epoch 108/1000\n",
      "178/178 [==============================] - 0s 149us/step - loss: 0.3507 - accuracy: 0.8539 - val_loss: 0.6467 - val_accuracy: 0.5974\n",
      "Epoch 109/1000\n",
      "178/178 [==============================] - 0s 132us/step - loss: 0.3501 - accuracy: 0.8483 - val_loss: 0.6485 - val_accuracy: 0.6494\n",
      "Epoch 110/1000\n",
      "178/178 [==============================] - 0s 119us/step - loss: 0.3494 - accuracy: 0.8539 - val_loss: 0.6500 - val_accuracy: 0.6494\n",
      "Epoch 111/1000\n",
      "178/178 [==============================] - 0s 110us/step - loss: 0.3475 - accuracy: 0.8652 - val_loss: 0.6501 - val_accuracy: 0.6494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/1000\n",
      "178/178 [==============================] - 0s 117us/step - loss: 0.3460 - accuracy: 0.8652 - val_loss: 0.6507 - val_accuracy: 0.6494\n",
      "Epoch 113/1000\n",
      "178/178 [==============================] - 0s 92us/step - loss: 0.3452 - accuracy: 0.8652 - val_loss: 0.6516 - val_accuracy: 0.6494\n",
      "Epoch 114/1000\n",
      "178/178 [==============================] - 0s 144us/step - loss: 0.3452 - accuracy: 0.8708 - val_loss: 0.6520 - val_accuracy: 0.6494\n",
      "Epoch 115/1000\n",
      "178/178 [==============================] - 0s 99us/step - loss: 0.3427 - accuracy: 0.8652 - val_loss: 0.6523 - val_accuracy: 0.6494\n",
      "Epoch 116/1000\n",
      "178/178 [==============================] - 0s 102us/step - loss: 0.3419 - accuracy: 0.8708 - val_loss: 0.6540 - val_accuracy: 0.6494\n",
      "Epoch 117/1000\n",
      "178/178 [==============================] - 0s 99us/step - loss: 0.3404 - accuracy: 0.8708 - val_loss: 0.6551 - val_accuracy: 0.6494\n",
      "Epoch 118/1000\n",
      "178/178 [==============================] - 0s 112us/step - loss: 0.3394 - accuracy: 0.8708 - val_loss: 0.6555 - val_accuracy: 0.6494\n",
      "Epoch 119/1000\n",
      "178/178 [==============================] - 0s 120us/step - loss: 0.3388 - accuracy: 0.8708 - val_loss: 0.6551 - val_accuracy: 0.6494\n",
      "Epoch 120/1000\n",
      "178/178 [==============================] - 0s 118us/step - loss: 0.3371 - accuracy: 0.8708 - val_loss: 0.6556 - val_accuracy: 0.6494\n",
      "Epoch 121/1000\n",
      "178/178 [==============================] - 0s 93us/step - loss: 0.3364 - accuracy: 0.8708 - val_loss: 0.6570 - val_accuracy: 0.6494\n",
      "Epoch 122/1000\n",
      "178/178 [==============================] - 0s 97us/step - loss: 0.3351 - accuracy: 0.8708 - val_loss: 0.6564 - val_accuracy: 0.6623\n",
      "Epoch 123/1000\n",
      "178/178 [==============================] - 0s 93us/step - loss: 0.3341 - accuracy: 0.8820 - val_loss: 0.6593 - val_accuracy: 0.6494\n",
      "Epoch 124/1000\n",
      "178/178 [==============================] - 0s 80us/step - loss: 0.3330 - accuracy: 0.8764 - val_loss: 0.6606 - val_accuracy: 0.6494\n",
      "Epoch 125/1000\n",
      "178/178 [==============================] - 0s 83us/step - loss: 0.3323 - accuracy: 0.8764 - val_loss: 0.6593 - val_accuracy: 0.6623\n",
      "Epoch 126/1000\n",
      "178/178 [==============================] - 0s 104us/step - loss: 0.3314 - accuracy: 0.8820 - val_loss: 0.6606 - val_accuracy: 0.6623\n",
      "Epoch 127/1000\n",
      "178/178 [==============================] - 0s 80us/step - loss: 0.3307 - accuracy: 0.8764 - val_loss: 0.6623 - val_accuracy: 0.6494\n",
      "Epoch 128/1000\n",
      "178/178 [==============================] - 0s 100us/step - loss: 0.3291 - accuracy: 0.8764 - val_loss: 0.6629 - val_accuracy: 0.6623\n",
      "Epoch 129/1000\n",
      "178/178 [==============================] - 0s 136us/step - loss: 0.3283 - accuracy: 0.8764 - val_loss: 0.6613 - val_accuracy: 0.6623\n",
      "Epoch 130/1000\n",
      "178/178 [==============================] - 0s 116us/step - loss: 0.3269 - accuracy: 0.8820 - val_loss: 0.6621 - val_accuracy: 0.6623\n",
      "Epoch 131/1000\n",
      "178/178 [==============================] - 0s 97us/step - loss: 0.3258 - accuracy: 0.8820 - val_loss: 0.6637 - val_accuracy: 0.6623\n",
      "Epoch 132/1000\n",
      "178/178 [==============================] - 0s 95us/step - loss: 0.3254 - accuracy: 0.8820 - val_loss: 0.6672 - val_accuracy: 0.6494\n",
      "Epoch 133/1000\n",
      "178/178 [==============================] - 0s 101us/step - loss: 0.3243 - accuracy: 0.8708 - val_loss: 0.6674 - val_accuracy: 0.6494\n",
      "Epoch 134/1000\n",
      "178/178 [==============================] - 0s 103us/step - loss: 0.3233 - accuracy: 0.8876 - val_loss: 0.6685 - val_accuracy: 0.6494\n",
      "Epoch 135/1000\n",
      "178/178 [==============================] - 0s 85us/step - loss: 0.3223 - accuracy: 0.8820 - val_loss: 0.6687 - val_accuracy: 0.6494\n",
      "Epoch 136/1000\n",
      "178/178 [==============================] - 0s 90us/step - loss: 0.3213 - accuracy: 0.8764 - val_loss: 0.6685 - val_accuracy: 0.6623\n",
      "Epoch 137/1000\n",
      "178/178 [==============================] - 0s 93us/step - loss: 0.3199 - accuracy: 0.8876 - val_loss: 0.6683 - val_accuracy: 0.6623\n",
      "Epoch 138/1000\n",
      "178/178 [==============================] - 0s 87us/step - loss: 0.3191 - accuracy: 0.8820 - val_loss: 0.6702 - val_accuracy: 0.6623\n",
      "Epoch 139/1000\n",
      "178/178 [==============================] - 0s 101us/step - loss: 0.3180 - accuracy: 0.8876 - val_loss: 0.6724 - val_accuracy: 0.6623\n",
      "Epoch 140/1000\n",
      "178/178 [==============================] - 0s 89us/step - loss: 0.3171 - accuracy: 0.8820 - val_loss: 0.6710 - val_accuracy: 0.6623\n",
      "Epoch 141/1000\n",
      "178/178 [==============================] - 0s 108us/step - loss: 0.3161 - accuracy: 0.8820 - val_loss: 0.6725 - val_accuracy: 0.6623\n",
      "Epoch 142/1000\n",
      "178/178 [==============================] - 0s 124us/step - loss: 0.3151 - accuracy: 0.8820 - val_loss: 0.6748 - val_accuracy: 0.6623\n",
      "Epoch 143/1000\n",
      "178/178 [==============================] - 0s 97us/step - loss: 0.3144 - accuracy: 0.8820 - val_loss: 0.6740 - val_accuracy: 0.6623\n",
      "Epoch 144/1000\n",
      "178/178 [==============================] - 0s 95us/step - loss: 0.3135 - accuracy: 0.8820 - val_loss: 0.6723 - val_accuracy: 0.6623\n",
      "Epoch 145/1000\n",
      "178/178 [==============================] - 0s 93us/step - loss: 0.3124 - accuracy: 0.8820 - val_loss: 0.6746 - val_accuracy: 0.6623\n",
      "Epoch 146/1000\n",
      "178/178 [==============================] - 0s 105us/step - loss: 0.3117 - accuracy: 0.8820 - val_loss: 0.6767 - val_accuracy: 0.6623\n",
      "Epoch 147/1000\n",
      "178/178 [==============================] - 0s 104us/step - loss: 0.3108 - accuracy: 0.8820 - val_loss: 0.6765 - val_accuracy: 0.6623\n",
      "Epoch 148/1000\n",
      "178/178 [==============================] - 0s 126us/step - loss: 0.3108 - accuracy: 0.8820 - val_loss: 0.6758 - val_accuracy: 0.6623\n",
      "Epoch 149/1000\n",
      "178/178 [==============================] - 0s 106us/step - loss: 0.3098 - accuracy: 0.8820 - val_loss: 0.6756 - val_accuracy: 0.6623\n",
      "Epoch 150/1000\n",
      "178/178 [==============================] - 0s 99us/step - loss: 0.3085 - accuracy: 0.8820 - val_loss: 0.6771 - val_accuracy: 0.6623\n",
      "Epoch 151/1000\n",
      "178/178 [==============================] - 0s 100us/step - loss: 0.3077 - accuracy: 0.8820 - val_loss: 0.6789 - val_accuracy: 0.6623\n",
      "Epoch 152/1000\n",
      "178/178 [==============================] - 0s 94us/step - loss: 0.3065 - accuracy: 0.8820 - val_loss: 0.6810 - val_accuracy: 0.6623\n",
      "Epoch 153/1000\n",
      "178/178 [==============================] - 0s 99us/step - loss: 0.3060 - accuracy: 0.8820 - val_loss: 0.6837 - val_accuracy: 0.6623\n",
      "Epoch 154/1000\n",
      "178/178 [==============================] - 0s 107us/step - loss: 0.3051 - accuracy: 0.8820 - val_loss: 0.6835 - val_accuracy: 0.6623\n",
      "Epoch 155/1000\n",
      "178/178 [==============================] - 0s 125us/step - loss: 0.3039 - accuracy: 0.8820 - val_loss: 0.6860 - val_accuracy: 0.6623\n",
      "Epoch 156/1000\n",
      "178/178 [==============================] - 0s 167us/step - loss: 0.3029 - accuracy: 0.8820 - val_loss: 0.6869 - val_accuracy: 0.6623\n",
      "Epoch 157/1000\n",
      "178/178 [==============================] - 0s 169us/step - loss: 0.3025 - accuracy: 0.8820 - val_loss: 0.6885 - val_accuracy: 0.6623\n",
      "Epoch 158/1000\n",
      "178/178 [==============================] - 0s 112us/step - loss: 0.3018 - accuracy: 0.8820 - val_loss: 0.6885 - val_accuracy: 0.6623\n",
      "Epoch 159/1000\n",
      "178/178 [==============================] - 0s 129us/step - loss: 0.3014 - accuracy: 0.8820 - val_loss: 0.6886 - val_accuracy: 0.6623\n",
      "Epoch 160/1000\n",
      "178/178 [==============================] - 0s 104us/step - loss: 0.3006 - accuracy: 0.8820 - val_loss: 0.6890 - val_accuracy: 0.6623\n",
      "Epoch 161/1000\n",
      "178/178 [==============================] - 0s 133us/step - loss: 0.2993 - accuracy: 0.8820 - val_loss: 0.6911 - val_accuracy: 0.6623\n",
      "Epoch 162/1000\n",
      "178/178 [==============================] - 0s 117us/step - loss: 0.2987 - accuracy: 0.8820 - val_loss: 0.6924 - val_accuracy: 0.6623\n",
      "Epoch 163/1000\n",
      "178/178 [==============================] - 0s 103us/step - loss: 0.2977 - accuracy: 0.8820 - val_loss: 0.6951 - val_accuracy: 0.6623\n",
      "Epoch 164/1000\n",
      "178/178 [==============================] - 0s 114us/step - loss: 0.2973 - accuracy: 0.8820 - val_loss: 0.6977 - val_accuracy: 0.6623\n",
      "Epoch 165/1000\n",
      "178/178 [==============================] - 0s 115us/step - loss: 0.2962 - accuracy: 0.8820 - val_loss: 0.6974 - val_accuracy: 0.6623\n",
      "Epoch 166/1000\n",
      "178/178 [==============================] - 0s 107us/step - loss: 0.2955 - accuracy: 0.8820 - val_loss: 0.6974 - val_accuracy: 0.6623\n",
      "Epoch 167/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 107us/step - loss: 0.2950 - accuracy: 0.8820 - val_loss: 0.6982 - val_accuracy: 0.6623\n",
      "Epoch 168/1000\n",
      "178/178 [==============================] - 0s 106us/step - loss: 0.2942 - accuracy: 0.8820 - val_loss: 0.6987 - val_accuracy: 0.6623\n",
      "Epoch 169/1000\n",
      "178/178 [==============================] - 0s 297us/step - loss: 0.2932 - accuracy: 0.8820 - val_loss: 0.6997 - val_accuracy: 0.6623\n",
      "Epoch 170/1000\n",
      "178/178 [==============================] - 0s 135us/step - loss: 0.2924 - accuracy: 0.8820 - val_loss: 0.7010 - val_accuracy: 0.6623\n",
      "Epoch 171/1000\n",
      "178/178 [==============================] - 0s 141us/step - loss: 0.2922 - accuracy: 0.8820 - val_loss: 0.7010 - val_accuracy: 0.6623\n",
      "Epoch 172/1000\n",
      "178/178 [==============================] - 0s 128us/step - loss: 0.2918 - accuracy: 0.8820 - val_loss: 0.7025 - val_accuracy: 0.6623\n",
      "Epoch 173/1000\n",
      "178/178 [==============================] - 0s 133us/step - loss: 0.2906 - accuracy: 0.8820 - val_loss: 0.7015 - val_accuracy: 0.6753\n",
      "Epoch 174/1000\n",
      "178/178 [==============================] - 0s 100us/step - loss: 0.2897 - accuracy: 0.8820 - val_loss: 0.7037 - val_accuracy: 0.6623\n",
      "Epoch 175/1000\n",
      "178/178 [==============================] - 0s 110us/step - loss: 0.2888 - accuracy: 0.8820 - val_loss: 0.7023 - val_accuracy: 0.6623\n",
      "Epoch 176/1000\n",
      "178/178 [==============================] - 0s 93us/step - loss: 0.2882 - accuracy: 0.8820 - val_loss: 0.7034 - val_accuracy: 0.6623\n",
      "Epoch 177/1000\n",
      "178/178 [==============================] - 0s 84us/step - loss: 0.2876 - accuracy: 0.8820 - val_loss: 0.7050 - val_accuracy: 0.6623\n",
      "Epoch 178/1000\n",
      "178/178 [==============================] - 0s 87us/step - loss: 0.2868 - accuracy: 0.8820 - val_loss: 0.7037 - val_accuracy: 0.6753\n",
      "Epoch 179/1000\n",
      "178/178 [==============================] - 0s 82us/step - loss: 0.2860 - accuracy: 0.8820 - val_loss: 0.7053 - val_accuracy: 0.6753\n",
      "Epoch 180/1000\n",
      "178/178 [==============================] - 0s 84us/step - loss: 0.2851 - accuracy: 0.8820 - val_loss: 0.7072 - val_accuracy: 0.6753\n",
      "Epoch 181/1000\n",
      "178/178 [==============================] - 0s 85us/step - loss: 0.2842 - accuracy: 0.8820 - val_loss: 0.7082 - val_accuracy: 0.6753\n",
      "Epoch 182/1000\n",
      "178/178 [==============================] - 0s 84us/step - loss: 0.2837 - accuracy: 0.8820 - val_loss: 0.7074 - val_accuracy: 0.6753\n",
      "Epoch 183/1000\n",
      "178/178 [==============================] - 0s 83us/step - loss: 0.2837 - accuracy: 0.8820 - val_loss: 0.7101 - val_accuracy: 0.6753\n",
      "Epoch 184/1000\n",
      "178/178 [==============================] - 0s 80us/step - loss: 0.2826 - accuracy: 0.8820 - val_loss: 0.7110 - val_accuracy: 0.6753\n",
      "Epoch 185/1000\n",
      "178/178 [==============================] - 0s 88us/step - loss: 0.2817 - accuracy: 0.8820 - val_loss: 0.7121 - val_accuracy: 0.6753\n",
      "Epoch 186/1000\n",
      "178/178 [==============================] - 0s 93us/step - loss: 0.2811 - accuracy: 0.8820 - val_loss: 0.7123 - val_accuracy: 0.6753\n",
      "Epoch 187/1000\n",
      "178/178 [==============================] - 0s 86us/step - loss: 0.2809 - accuracy: 0.8820 - val_loss: 0.7141 - val_accuracy: 0.6753\n",
      "Epoch 188/1000\n",
      "178/178 [==============================] - 0s 86us/step - loss: 0.2799 - accuracy: 0.8820 - val_loss: 0.7150 - val_accuracy: 0.6753\n",
      "Epoch 189/1000\n",
      "178/178 [==============================] - 0s 81us/step - loss: 0.2791 - accuracy: 0.8820 - val_loss: 0.7165 - val_accuracy: 0.6753\n",
      "Epoch 190/1000\n",
      "178/178 [==============================] - 0s 127us/step - loss: 0.2795 - accuracy: 0.8820 - val_loss: 0.7179 - val_accuracy: 0.6753\n",
      "Epoch 191/1000\n",
      "178/178 [==============================] - 0s 91us/step - loss: 0.2777 - accuracy: 0.8820 - val_loss: 0.7191 - val_accuracy: 0.6753\n",
      "Epoch 192/1000\n",
      "178/178 [==============================] - 0s 86us/step - loss: 0.2774 - accuracy: 0.8820 - val_loss: 0.7209 - val_accuracy: 0.6753\n",
      "Epoch 193/1000\n",
      "178/178 [==============================] - 0s 85us/step - loss: 0.2767 - accuracy: 0.8876 - val_loss: 0.7199 - val_accuracy: 0.6753\n",
      "Epoch 194/1000\n",
      "178/178 [==============================] - 0s 89us/step - loss: 0.2762 - accuracy: 0.8820 - val_loss: 0.7211 - val_accuracy: 0.6753\n",
      "Epoch 195/1000\n",
      "178/178 [==============================] - 0s 87us/step - loss: 0.2753 - accuracy: 0.8820 - val_loss: 0.7213 - val_accuracy: 0.6753\n",
      "Epoch 196/1000\n",
      "178/178 [==============================] - 0s 90us/step - loss: 0.2745 - accuracy: 0.8820 - val_loss: 0.7235 - val_accuracy: 0.6753\n",
      "Epoch 197/1000\n",
      "178/178 [==============================] - 0s 138us/step - loss: 0.2741 - accuracy: 0.8820 - val_loss: 0.7237 - val_accuracy: 0.6753\n",
      "Epoch 198/1000\n",
      "178/178 [==============================] - 0s 167us/step - loss: 0.2732 - accuracy: 0.8820 - val_loss: 0.7259 - val_accuracy: 0.6753\n",
      "Epoch 199/1000\n",
      "178/178 [==============================] - 0s 132us/step - loss: 0.2730 - accuracy: 0.8876 - val_loss: 0.7257 - val_accuracy: 0.6753\n",
      "Epoch 200/1000\n",
      "178/178 [==============================] - 0s 133us/step - loss: 0.2723 - accuracy: 0.8876 - val_loss: 0.7266 - val_accuracy: 0.6753\n",
      "Epoch 201/1000\n",
      "178/178 [==============================] - 0s 111us/step - loss: 0.2724 - accuracy: 0.8876 - val_loss: 0.7275 - val_accuracy: 0.6753\n",
      "Epoch 202/1000\n",
      "178/178 [==============================] - 0s 162us/step - loss: 0.2707 - accuracy: 0.8876 - val_loss: 0.7265 - val_accuracy: 0.6753\n",
      "Epoch 203/1000\n",
      "178/178 [==============================] - 0s 134us/step - loss: 0.2704 - accuracy: 0.8876 - val_loss: 0.7275 - val_accuracy: 0.6753\n",
      "Epoch 204/1000\n",
      "178/178 [==============================] - 0s 154us/step - loss: 0.2701 - accuracy: 0.8876 - val_loss: 0.7295 - val_accuracy: 0.6753\n",
      "Epoch 205/1000\n",
      "178/178 [==============================] - 0s 144us/step - loss: 0.2690 - accuracy: 0.8876 - val_loss: 0.7306 - val_accuracy: 0.6753\n",
      "Epoch 206/1000\n",
      "178/178 [==============================] - 0s 173us/step - loss: 0.2680 - accuracy: 0.8876 - val_loss: 0.7320 - val_accuracy: 0.6753\n",
      "Epoch 207/1000\n",
      "178/178 [==============================] - 0s 130us/step - loss: 0.2681 - accuracy: 0.8876 - val_loss: 0.7321 - val_accuracy: 0.6753\n",
      "Epoch 208/1000\n",
      "178/178 [==============================] - 0s 138us/step - loss: 0.2673 - accuracy: 0.8876 - val_loss: 0.7325 - val_accuracy: 0.6753\n",
      "Epoch 209/1000\n",
      "178/178 [==============================] - 0s 122us/step - loss: 0.2668 - accuracy: 0.8876 - val_loss: 0.7332 - val_accuracy: 0.6753\n",
      "Epoch 210/1000\n",
      "178/178 [==============================] - 0s 129us/step - loss: 0.2661 - accuracy: 0.8876 - val_loss: 0.7354 - val_accuracy: 0.6753\n",
      "Epoch 211/1000\n",
      "178/178 [==============================] - 0s 133us/step - loss: 0.2657 - accuracy: 0.8876 - val_loss: 0.7345 - val_accuracy: 0.6753\n",
      "Epoch 212/1000\n",
      "178/178 [==============================] - 0s 169us/step - loss: 0.2648 - accuracy: 0.8876 - val_loss: 0.7367 - val_accuracy: 0.6753\n",
      "Epoch 213/1000\n",
      "178/178 [==============================] - 0s 140us/step - loss: 0.2650 - accuracy: 0.8876 - val_loss: 0.7378 - val_accuracy: 0.6753\n",
      "Epoch 214/1000\n",
      "178/178 [==============================] - 0s 151us/step - loss: 0.2635 - accuracy: 0.8876 - val_loss: 0.7395 - val_accuracy: 0.6753\n",
      "Epoch 215/1000\n",
      "178/178 [==============================] - 0s 141us/step - loss: 0.2636 - accuracy: 0.8876 - val_loss: 0.7375 - val_accuracy: 0.6753\n",
      "Epoch 216/1000\n",
      "178/178 [==============================] - 0s 118us/step - loss: 0.2625 - accuracy: 0.8876 - val_loss: 0.7387 - val_accuracy: 0.6753\n",
      "Epoch 217/1000\n",
      "178/178 [==============================] - 0s 134us/step - loss: 0.2619 - accuracy: 0.8876 - val_loss: 0.7377 - val_accuracy: 0.6753\n",
      "Epoch 218/1000\n",
      "178/178 [==============================] - 0s 108us/step - loss: 0.2610 - accuracy: 0.8933 - val_loss: 0.7384 - val_accuracy: 0.6753\n",
      "Epoch 219/1000\n",
      "178/178 [==============================] - 0s 116us/step - loss: 0.2610 - accuracy: 0.8933 - val_loss: 0.7418 - val_accuracy: 0.6753\n",
      "Epoch 220/1000\n",
      "178/178 [==============================] - 0s 112us/step - loss: 0.2598 - accuracy: 0.8876 - val_loss: 0.7435 - val_accuracy: 0.6753\n",
      "Epoch 221/1000\n",
      "178/178 [==============================] - 0s 137us/step - loss: 0.2592 - accuracy: 0.8876 - val_loss: 0.7440 - val_accuracy: 0.6753\n",
      "Epoch 222/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 124us/step - loss: 0.2589 - accuracy: 0.8933 - val_loss: 0.7454 - val_accuracy: 0.6753\n",
      "Epoch 223/1000\n",
      "178/178 [==============================] - 0s 116us/step - loss: 0.2578 - accuracy: 0.8933 - val_loss: 0.7464 - val_accuracy: 0.6753\n",
      "Epoch 224/1000\n",
      "178/178 [==============================] - 0s 97us/step - loss: 0.2580 - accuracy: 0.8876 - val_loss: 0.7464 - val_accuracy: 0.6753\n",
      "Epoch 225/1000\n",
      "178/178 [==============================] - 0s 93us/step - loss: 0.2571 - accuracy: 0.8933 - val_loss: 0.7478 - val_accuracy: 0.6753\n",
      "Epoch 226/1000\n",
      "178/178 [==============================] - 0s 102us/step - loss: 0.2566 - accuracy: 0.8933 - val_loss: 0.7476 - val_accuracy: 0.6753\n",
      "Epoch 227/1000\n",
      "178/178 [==============================] - 0s 97us/step - loss: 0.2558 - accuracy: 0.8933 - val_loss: 0.7469 - val_accuracy: 0.6753\n",
      "Epoch 228/1000\n",
      "178/178 [==============================] - 0s 116us/step - loss: 0.2553 - accuracy: 0.8933 - val_loss: 0.7493 - val_accuracy: 0.6753\n",
      "Epoch 229/1000\n",
      "178/178 [==============================] - 0s 125us/step - loss: 0.2544 - accuracy: 0.8933 - val_loss: 0.7506 - val_accuracy: 0.6753\n",
      "Epoch 230/1000\n",
      "178/178 [==============================] - 0s 122us/step - loss: 0.2544 - accuracy: 0.8933 - val_loss: 0.7510 - val_accuracy: 0.6753\n",
      "Epoch 231/1000\n",
      "178/178 [==============================] - 0s 153us/step - loss: 0.2537 - accuracy: 0.8933 - val_loss: 0.7532 - val_accuracy: 0.6753\n",
      "Epoch 232/1000\n",
      "178/178 [==============================] - 0s 147us/step - loss: 0.2528 - accuracy: 0.8933 - val_loss: 0.7547 - val_accuracy: 0.6753\n",
      "Epoch 233/1000\n",
      "178/178 [==============================] - 0s 158us/step - loss: 0.2532 - accuracy: 0.8933 - val_loss: 0.7544 - val_accuracy: 0.6753\n",
      "Epoch 234/1000\n",
      "178/178 [==============================] - 0s 178us/step - loss: 0.2527 - accuracy: 0.8989 - val_loss: 0.7553 - val_accuracy: 0.6753\n",
      "Epoch 235/1000\n",
      "178/178 [==============================] - 0s 185us/step - loss: 0.2514 - accuracy: 0.8933 - val_loss: 0.7554 - val_accuracy: 0.6753\n",
      "Epoch 236/1000\n",
      "178/178 [==============================] - 0s 119us/step - loss: 0.2511 - accuracy: 0.8933 - val_loss: 0.7570 - val_accuracy: 0.6753\n",
      "Epoch 237/1000\n",
      "178/178 [==============================] - 0s 138us/step - loss: 0.2504 - accuracy: 0.8989 - val_loss: 0.7580 - val_accuracy: 0.6753\n",
      "Epoch 238/1000\n",
      "178/178 [==============================] - 0s 198us/step - loss: 0.2499 - accuracy: 0.8989 - val_loss: 0.7592 - val_accuracy: 0.6753\n",
      "Epoch 239/1000\n",
      "178/178 [==============================] - 0s 112us/step - loss: 0.2492 - accuracy: 0.8989 - val_loss: 0.7600 - val_accuracy: 0.6753\n",
      "Epoch 240/1000\n",
      "178/178 [==============================] - 0s 151us/step - loss: 0.2490 - accuracy: 0.8989 - val_loss: 0.7602 - val_accuracy: 0.6753\n",
      "Epoch 241/1000\n",
      "178/178 [==============================] - 0s 126us/step - loss: 0.2484 - accuracy: 0.8989 - val_loss: 0.7621 - val_accuracy: 0.6753\n",
      "Epoch 242/1000\n",
      "178/178 [==============================] - 0s 125us/step - loss: 0.2480 - accuracy: 0.9045 - val_loss: 0.7633 - val_accuracy: 0.6753\n",
      "Epoch 243/1000\n",
      "178/178 [==============================] - 0s 239us/step - loss: 0.2471 - accuracy: 0.8989 - val_loss: 0.7642 - val_accuracy: 0.6753\n",
      "Epoch 244/1000\n",
      "178/178 [==============================] - 0s 131us/step - loss: 0.2479 - accuracy: 0.8989 - val_loss: 0.7671 - val_accuracy: 0.6753\n",
      "Epoch 245/1000\n",
      "178/178 [==============================] - 0s 112us/step - loss: 0.2467 - accuracy: 0.8989 - val_loss: 0.7661 - val_accuracy: 0.6753\n",
      "Epoch 246/1000\n",
      "178/178 [==============================] - 0s 123us/step - loss: 0.2453 - accuracy: 0.8989 - val_loss: 0.7671 - val_accuracy: 0.6753\n",
      "Epoch 247/1000\n",
      "178/178 [==============================] - 0s 216us/step - loss: 0.2451 - accuracy: 0.8989 - val_loss: 0.7678 - val_accuracy: 0.6753\n",
      "Epoch 248/1000\n",
      "178/178 [==============================] - 0s 136us/step - loss: 0.2444 - accuracy: 0.8989 - val_loss: 0.7689 - val_accuracy: 0.6753\n",
      "Epoch 249/1000\n",
      "178/178 [==============================] - 0s 432us/step - loss: 0.2447 - accuracy: 0.8989 - val_loss: 0.7707 - val_accuracy: 0.6753\n",
      "Epoch 250/1000\n",
      "178/178 [==============================] - 0s 178us/step - loss: 0.2435 - accuracy: 0.8989 - val_loss: 0.7712 - val_accuracy: 0.6753\n",
      "Epoch 251/1000\n",
      "178/178 [==============================] - 0s 198us/step - loss: 0.2437 - accuracy: 0.8989 - val_loss: 0.7702 - val_accuracy: 0.6753\n",
      "Epoch 252/1000\n",
      "178/178 [==============================] - 0s 177us/step - loss: 0.2424 - accuracy: 0.8989 - val_loss: 0.7727 - val_accuracy: 0.6753\n",
      "Epoch 253/1000\n",
      "178/178 [==============================] - 0s 149us/step - loss: 0.2424 - accuracy: 0.8989 - val_loss: 0.7727 - val_accuracy: 0.6753\n",
      "Epoch 254/1000\n",
      "178/178 [==============================] - 0s 170us/step - loss: 0.2420 - accuracy: 0.9045 - val_loss: 0.7748 - val_accuracy: 0.6753\n",
      "Epoch 255/1000\n",
      "178/178 [==============================] - 0s 216us/step - loss: 0.2420 - accuracy: 0.9045 - val_loss: 0.7722 - val_accuracy: 0.6753\n",
      "Epoch 256/1000\n",
      "178/178 [==============================] - 0s 165us/step - loss: 0.2409 - accuracy: 0.9045 - val_loss: 0.7724 - val_accuracy: 0.6753\n",
      "Epoch 257/1000\n",
      "178/178 [==============================] - 0s 135us/step - loss: 0.2402 - accuracy: 0.9045 - val_loss: 0.7742 - val_accuracy: 0.6753\n",
      "Epoch 258/1000\n",
      "178/178 [==============================] - 0s 139us/step - loss: 0.2405 - accuracy: 0.9045 - val_loss: 0.7772 - val_accuracy: 0.6753\n",
      "Epoch 259/1000\n",
      "178/178 [==============================] - 0s 130us/step - loss: 0.2395 - accuracy: 0.9101 - val_loss: 0.7786 - val_accuracy: 0.6753\n",
      "Epoch 260/1000\n",
      "178/178 [==============================] - 0s 128us/step - loss: 0.2387 - accuracy: 0.9045 - val_loss: 0.7771 - val_accuracy: 0.6753\n",
      "Epoch 261/1000\n",
      "178/178 [==============================] - 0s 154us/step - loss: 0.2391 - accuracy: 0.9157 - val_loss: 0.7787 - val_accuracy: 0.6753\n",
      "Epoch 262/1000\n",
      "178/178 [==============================] - 0s 132us/step - loss: 0.2375 - accuracy: 0.9157 - val_loss: 0.7770 - val_accuracy: 0.6753\n",
      "Epoch 263/1000\n",
      "178/178 [==============================] - 0s 137us/step - loss: 0.2369 - accuracy: 0.9101 - val_loss: 0.7793 - val_accuracy: 0.6753\n",
      "Epoch 264/1000\n",
      "178/178 [==============================] - 0s 266us/step - loss: 0.2369 - accuracy: 0.9157 - val_loss: 0.7803 - val_accuracy: 0.6753\n",
      "Epoch 265/1000\n",
      "178/178 [==============================] - 0s 162us/step - loss: 0.2359 - accuracy: 0.9101 - val_loss: 0.7823 - val_accuracy: 0.6753\n",
      "Epoch 266/1000\n",
      "178/178 [==============================] - 0s 202us/step - loss: 0.2357 - accuracy: 0.9157 - val_loss: 0.7831 - val_accuracy: 0.6753\n",
      "Epoch 267/1000\n",
      "178/178 [==============================] - 0s 199us/step - loss: 0.2366 - accuracy: 0.9045 - val_loss: 0.7830 - val_accuracy: 0.6753\n",
      "Epoch 268/1000\n",
      "178/178 [==============================] - 0s 98us/step - loss: 0.2345 - accuracy: 0.9157 - val_loss: 0.7845 - val_accuracy: 0.6753\n",
      "Epoch 269/1000\n",
      "178/178 [==============================] - 0s 89us/step - loss: 0.2344 - accuracy: 0.9101 - val_loss: 0.7827 - val_accuracy: 0.6753\n",
      "Epoch 270/1000\n",
      "178/178 [==============================] - 0s 88us/step - loss: 0.2338 - accuracy: 0.9157 - val_loss: 0.7814 - val_accuracy: 0.6753\n",
      "Epoch 271/1000\n",
      "178/178 [==============================] - 0s 86us/step - loss: 0.2333 - accuracy: 0.9101 - val_loss: 0.7838 - val_accuracy: 0.6753\n",
      "Epoch 272/1000\n",
      "178/178 [==============================] - 0s 94us/step - loss: 0.2327 - accuracy: 0.9157 - val_loss: 0.7850 - val_accuracy: 0.6753\n",
      "Epoch 273/1000\n",
      "178/178 [==============================] - 0s 82us/step - loss: 0.2325 - accuracy: 0.9157 - val_loss: 0.7848 - val_accuracy: 0.6753\n",
      "Epoch 274/1000\n",
      "178/178 [==============================] - 0s 98us/step - loss: 0.2319 - accuracy: 0.9157 - val_loss: 0.7851 - val_accuracy: 0.6753\n",
      "Epoch 275/1000\n",
      "178/178 [==============================] - 0s 90us/step - loss: 0.2317 - accuracy: 0.9101 - val_loss: 0.7875 - val_accuracy: 0.6753\n",
      "Epoch 276/1000\n",
      "178/178 [==============================] - 0s 84us/step - loss: 0.2310 - accuracy: 0.9157 - val_loss: 0.7892 - val_accuracy: 0.6753\n",
      "Epoch 277/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 97us/step - loss: 0.2303 - accuracy: 0.9157 - val_loss: 0.7900 - val_accuracy: 0.6753\n",
      "Epoch 278/1000\n",
      "178/178 [==============================] - 0s 100us/step - loss: 0.2304 - accuracy: 0.9213 - val_loss: 0.7917 - val_accuracy: 0.6753\n",
      "Epoch 279/1000\n",
      "178/178 [==============================] - 0s 99us/step - loss: 0.2300 - accuracy: 0.9157 - val_loss: 0.7949 - val_accuracy: 0.6753\n",
      "Epoch 280/1000\n",
      "178/178 [==============================] - 0s 86us/step - loss: 0.2292 - accuracy: 0.9270 - val_loss: 0.7955 - val_accuracy: 0.6753\n",
      "Epoch 281/1000\n",
      "178/178 [==============================] - 0s 95us/step - loss: 0.2287 - accuracy: 0.9213 - val_loss: 0.7954 - val_accuracy: 0.6753\n",
      "Epoch 282/1000\n",
      "178/178 [==============================] - 0s 95us/step - loss: 0.2279 - accuracy: 0.9157 - val_loss: 0.7951 - val_accuracy: 0.6753\n",
      "Epoch 283/1000\n",
      "178/178 [==============================] - 0s 85us/step - loss: 0.2275 - accuracy: 0.9157 - val_loss: 0.7963 - val_accuracy: 0.6753\n",
      "Epoch 284/1000\n",
      "178/178 [==============================] - 0s 92us/step - loss: 0.2271 - accuracy: 0.9270 - val_loss: 0.7976 - val_accuracy: 0.6883\n",
      "Epoch 285/1000\n",
      "178/178 [==============================] - 0s 81us/step - loss: 0.2264 - accuracy: 0.9157 - val_loss: 0.7997 - val_accuracy: 0.6753\n",
      "Epoch 286/1000\n",
      "178/178 [==============================] - 0s 89us/step - loss: 0.2262 - accuracy: 0.9157 - val_loss: 0.8011 - val_accuracy: 0.6623\n",
      "Epoch 287/1000\n",
      "178/178 [==============================] - 0s 90us/step - loss: 0.2261 - accuracy: 0.9270 - val_loss: 0.8005 - val_accuracy: 0.6753\n",
      "Epoch 288/1000\n",
      "178/178 [==============================] - 0s 93us/step - loss: 0.2257 - accuracy: 0.9213 - val_loss: 0.8016 - val_accuracy: 0.6753\n",
      "Epoch 289/1000\n",
      "178/178 [==============================] - 0s 98us/step - loss: 0.2255 - accuracy: 0.9157 - val_loss: 0.8047 - val_accuracy: 0.6623\n",
      "Epoch 290/1000\n",
      "178/178 [==============================] - 0s 105us/step - loss: 0.2245 - accuracy: 0.9270 - val_loss: 0.8053 - val_accuracy: 0.6623\n",
      "Epoch 291/1000\n",
      "178/178 [==============================] - 0s 358us/step - loss: 0.2243 - accuracy: 0.9213 - val_loss: 0.8053 - val_accuracy: 0.6753\n",
      "Epoch 292/1000\n",
      "178/178 [==============================] - 0s 100us/step - loss: 0.2238 - accuracy: 0.9157 - val_loss: 0.8069 - val_accuracy: 0.6623\n",
      "Epoch 293/1000\n",
      "178/178 [==============================] - 0s 102us/step - loss: 0.2228 - accuracy: 0.9270 - val_loss: 0.8091 - val_accuracy: 0.6623\n",
      "Epoch 294/1000\n",
      "178/178 [==============================] - 0s 117us/step - loss: 0.2235 - accuracy: 0.9213 - val_loss: 0.8103 - val_accuracy: 0.6623\n",
      "Epoch 295/1000\n",
      "178/178 [==============================] - 0s 98us/step - loss: 0.2218 - accuracy: 0.9270 - val_loss: 0.8111 - val_accuracy: 0.6623\n",
      "Epoch 296/1000\n",
      "178/178 [==============================] - 0s 99us/step - loss: 0.2216 - accuracy: 0.9157 - val_loss: 0.8126 - val_accuracy: 0.6623\n",
      "Epoch 297/1000\n",
      "178/178 [==============================] - 0s 101us/step - loss: 0.2212 - accuracy: 0.9270 - val_loss: 0.8134 - val_accuracy: 0.6623\n",
      "Epoch 298/1000\n",
      "178/178 [==============================] - 0s 97us/step - loss: 0.2213 - accuracy: 0.9270 - val_loss: 0.8134 - val_accuracy: 0.6623\n",
      "Epoch 299/1000\n",
      "178/178 [==============================] - 0s 142us/step - loss: 0.2209 - accuracy: 0.9213 - val_loss: 0.8143 - val_accuracy: 0.6623\n",
      "Epoch 300/1000\n",
      "178/178 [==============================] - 0s 122us/step - loss: 0.2200 - accuracy: 0.9326 - val_loss: 0.8147 - val_accuracy: 0.6623\n",
      "Epoch 301/1000\n",
      "178/178 [==============================] - 0s 125us/step - loss: 0.2194 - accuracy: 0.9270 - val_loss: 0.8133 - val_accuracy: 0.6623\n",
      "Epoch 302/1000\n",
      "178/178 [==============================] - 0s 126us/step - loss: 0.2192 - accuracy: 0.9270 - val_loss: 0.8132 - val_accuracy: 0.6623\n",
      "Epoch 303/1000\n",
      "178/178 [==============================] - 0s 141us/step - loss: 0.2184 - accuracy: 0.9270 - val_loss: 0.8150 - val_accuracy: 0.6623\n",
      "Epoch 304/1000\n",
      "178/178 [==============================] - 0s 123us/step - loss: 0.2185 - accuracy: 0.9326 - val_loss: 0.8148 - val_accuracy: 0.6623\n",
      "Epoch 305/1000\n",
      "178/178 [==============================] - 0s 149us/step - loss: 0.2177 - accuracy: 0.9326 - val_loss: 0.8158 - val_accuracy: 0.6623\n",
      "Epoch 306/1000\n",
      "178/178 [==============================] - 0s 126us/step - loss: 0.2176 - accuracy: 0.9326 - val_loss: 0.8179 - val_accuracy: 0.6623\n",
      "Epoch 307/1000\n",
      "178/178 [==============================] - 0s 130us/step - loss: 0.2183 - accuracy: 0.9326 - val_loss: 0.8202 - val_accuracy: 0.6623\n",
      "Epoch 308/1000\n",
      "178/178 [==============================] - 0s 109us/step - loss: 0.2169 - accuracy: 0.9326 - val_loss: 0.8203 - val_accuracy: 0.6623\n",
      "Epoch 309/1000\n",
      "178/178 [==============================] - 0s 113us/step - loss: 0.2161 - accuracy: 0.9270 - val_loss: 0.8203 - val_accuracy: 0.6623\n",
      "Epoch 310/1000\n",
      "178/178 [==============================] - 0s 119us/step - loss: 0.2164 - accuracy: 0.9382 - val_loss: 0.8211 - val_accuracy: 0.6623\n",
      "Epoch 311/1000\n",
      "178/178 [==============================] - 0s 127us/step - loss: 0.2154 - accuracy: 0.9326 - val_loss: 0.8228 - val_accuracy: 0.6623\n",
      "Epoch 312/1000\n",
      "178/178 [==============================] - 0s 128us/step - loss: 0.2152 - accuracy: 0.9326 - val_loss: 0.8261 - val_accuracy: 0.6623\n",
      "Epoch 313/1000\n",
      "178/178 [==============================] - 0s 128us/step - loss: 0.2148 - accuracy: 0.9326 - val_loss: 0.8274 - val_accuracy: 0.6623\n",
      "Epoch 314/1000\n",
      "178/178 [==============================] - 0s 177us/step - loss: 0.2139 - accuracy: 0.9326 - val_loss: 0.8276 - val_accuracy: 0.6623\n",
      "Epoch 315/1000\n",
      "178/178 [==============================] - 0s 135us/step - loss: 0.2138 - accuracy: 0.9382 - val_loss: 0.8291 - val_accuracy: 0.6623\n",
      "Epoch 316/1000\n",
      "178/178 [==============================] - 0s 113us/step - loss: 0.2136 - accuracy: 0.9382 - val_loss: 0.8307 - val_accuracy: 0.6623\n",
      "Epoch 317/1000\n",
      "178/178 [==============================] - 0s 120us/step - loss: 0.2139 - accuracy: 0.9382 - val_loss: 0.8292 - val_accuracy: 0.6623\n",
      "Epoch 318/1000\n",
      "178/178 [==============================] - 0s 106us/step - loss: 0.2127 - accuracy: 0.9382 - val_loss: 0.8299 - val_accuracy: 0.6623\n",
      "Epoch 319/1000\n",
      "178/178 [==============================] - 0s 105us/step - loss: 0.2122 - accuracy: 0.9382 - val_loss: 0.8306 - val_accuracy: 0.6623\n",
      "Epoch 320/1000\n",
      "178/178 [==============================] - 0s 100us/step - loss: 0.2118 - accuracy: 0.9382 - val_loss: 0.8314 - val_accuracy: 0.6623\n",
      "Epoch 321/1000\n",
      "178/178 [==============================] - 0s 96us/step - loss: 0.2118 - accuracy: 0.9326 - val_loss: 0.8333 - val_accuracy: 0.6623\n",
      "Epoch 322/1000\n",
      "178/178 [==============================] - 0s 91us/step - loss: 0.2116 - accuracy: 0.9326 - val_loss: 0.8343 - val_accuracy: 0.6623\n",
      "Epoch 323/1000\n",
      "178/178 [==============================] - 0s 88us/step - loss: 0.2106 - accuracy: 0.9382 - val_loss: 0.8351 - val_accuracy: 0.6623\n",
      "Epoch 324/1000\n",
      "178/178 [==============================] - 0s 82us/step - loss: 0.2108 - accuracy: 0.9382 - val_loss: 0.8359 - val_accuracy: 0.6623\n",
      "Epoch 325/1000\n",
      "178/178 [==============================] - 0s 108us/step - loss: 0.2099 - accuracy: 0.9382 - val_loss: 0.8361 - val_accuracy: 0.6623\n",
      "Epoch 326/1000\n",
      "178/178 [==============================] - 0s 97us/step - loss: 0.2096 - accuracy: 0.9382 - val_loss: 0.8364 - val_accuracy: 0.6753\n",
      "Epoch 327/1000\n",
      "178/178 [==============================] - 0s 87us/step - loss: 0.2094 - accuracy: 0.9270 - val_loss: 0.8396 - val_accuracy: 0.6623\n",
      "Epoch 328/1000\n",
      "178/178 [==============================] - 0s 102us/step - loss: 0.2085 - accuracy: 0.9382 - val_loss: 0.8406 - val_accuracy: 0.6623\n",
      "Epoch 329/1000\n",
      "178/178 [==============================] - 0s 90us/step - loss: 0.2086 - accuracy: 0.9382 - val_loss: 0.8425 - val_accuracy: 0.6623\n",
      "Epoch 330/1000\n",
      "178/178 [==============================] - 0s 101us/step - loss: 0.2081 - accuracy: 0.9382 - val_loss: 0.8416 - val_accuracy: 0.6623\n",
      "Epoch 331/1000\n",
      "178/178 [==============================] - 0s 95us/step - loss: 0.2080 - accuracy: 0.9382 - val_loss: 0.8437 - val_accuracy: 0.6623\n",
      "Epoch 332/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 109us/step - loss: 0.2076 - accuracy: 0.9382 - val_loss: 0.8448 - val_accuracy: 0.6623\n",
      "Epoch 333/1000\n",
      "178/178 [==============================] - 0s 92us/step - loss: 0.2071 - accuracy: 0.9382 - val_loss: 0.8459 - val_accuracy: 0.6623\n",
      "Epoch 334/1000\n",
      "178/178 [==============================] - 0s 96us/step - loss: 0.2066 - accuracy: 0.9382 - val_loss: 0.8447 - val_accuracy: 0.6623\n",
      "Epoch 335/1000\n",
      "178/178 [==============================] - 0s 166us/step - loss: 0.2064 - accuracy: 0.9382 - val_loss: 0.8451 - val_accuracy: 0.6623\n",
      "Epoch 336/1000\n",
      "178/178 [==============================] - 0s 175us/step - loss: 0.2059 - accuracy: 0.9326 - val_loss: 0.8472 - val_accuracy: 0.6623\n",
      "Epoch 337/1000\n",
      "178/178 [==============================] - 0s 216us/step - loss: 0.2057 - accuracy: 0.9382 - val_loss: 0.8465 - val_accuracy: 0.6623\n",
      "Epoch 338/1000\n",
      "178/178 [==============================] - 0s 128us/step - loss: 0.2052 - accuracy: 0.9382 - val_loss: 0.8475 - val_accuracy: 0.6623\n",
      "Epoch 339/1000\n",
      "178/178 [==============================] - 0s 161us/step - loss: 0.2048 - accuracy: 0.9382 - val_loss: 0.8453 - val_accuracy: 0.6623\n",
      "Epoch 340/1000\n",
      "178/178 [==============================] - 0s 110us/step - loss: 0.2043 - accuracy: 0.9382 - val_loss: 0.8476 - val_accuracy: 0.6623\n",
      "Epoch 341/1000\n",
      "178/178 [==============================] - 0s 150us/step - loss: 0.2037 - accuracy: 0.9382 - val_loss: 0.8483 - val_accuracy: 0.6623\n",
      "Epoch 342/1000\n",
      "178/178 [==============================] - 0s 143us/step - loss: 0.2043 - accuracy: 0.9382 - val_loss: 0.8504 - val_accuracy: 0.6623\n",
      "Epoch 343/1000\n",
      "178/178 [==============================] - 0s 173us/step - loss: 0.2036 - accuracy: 0.9382 - val_loss: 0.8522 - val_accuracy: 0.6623\n",
      "Epoch 344/1000\n",
      "178/178 [==============================] - 0s 179us/step - loss: 0.2027 - accuracy: 0.9382 - val_loss: 0.8535 - val_accuracy: 0.6623\n",
      "Epoch 345/1000\n",
      "178/178 [==============================] - 0s 191us/step - loss: 0.2032 - accuracy: 0.9382 - val_loss: 0.8547 - val_accuracy: 0.6623\n",
      "Epoch 346/1000\n",
      "178/178 [==============================] - 0s 174us/step - loss: 0.2020 - accuracy: 0.9382 - val_loss: 0.8554 - val_accuracy: 0.6623\n",
      "Epoch 347/1000\n",
      "178/178 [==============================] - 0s 217us/step - loss: 0.2017 - accuracy: 0.9382 - val_loss: 0.8572 - val_accuracy: 0.6623\n",
      "Epoch 348/1000\n",
      "178/178 [==============================] - 0s 162us/step - loss: 0.2013 - accuracy: 0.9382 - val_loss: 0.8584 - val_accuracy: 0.6623\n",
      "Epoch 349/1000\n",
      "178/178 [==============================] - 0s 173us/step - loss: 0.2013 - accuracy: 0.9382 - val_loss: 0.8586 - val_accuracy: 0.6623\n",
      "Epoch 350/1000\n",
      "178/178 [==============================] - 0s 156us/step - loss: 0.2006 - accuracy: 0.9382 - val_loss: 0.8607 - val_accuracy: 0.6623\n",
      "Epoch 351/1000\n",
      "178/178 [==============================] - 0s 166us/step - loss: 0.2010 - accuracy: 0.9270 - val_loss: 0.8626 - val_accuracy: 0.6623\n",
      "Epoch 352/1000\n",
      "178/178 [==============================] - 0s 139us/step - loss: 0.2001 - accuracy: 0.9382 - val_loss: 0.8655 - val_accuracy: 0.6623\n",
      "Epoch 353/1000\n",
      "178/178 [==============================] - 0s 194us/step - loss: 0.1996 - accuracy: 0.9382 - val_loss: 0.8659 - val_accuracy: 0.6623\n",
      "Epoch 354/1000\n",
      "178/178 [==============================] - 0s 162us/step - loss: 0.1996 - accuracy: 0.9438 - val_loss: 0.8660 - val_accuracy: 0.6623\n",
      "Epoch 355/1000\n",
      "178/178 [==============================] - 0s 111us/step - loss: 0.1989 - accuracy: 0.9382 - val_loss: 0.8665 - val_accuracy: 0.6623\n",
      "Epoch 356/1000\n",
      "178/178 [==============================] - 0s 94us/step - loss: 0.1994 - accuracy: 0.9270 - val_loss: 0.8671 - val_accuracy: 0.6623\n",
      "Epoch 357/1000\n",
      "178/178 [==============================] - 0s 87us/step - loss: 0.1983 - accuracy: 0.9382 - val_loss: 0.8675 - val_accuracy: 0.6623\n",
      "Epoch 358/1000\n",
      "178/178 [==============================] - 0s 81us/step - loss: 0.1989 - accuracy: 0.9438 - val_loss: 0.8659 - val_accuracy: 0.6623\n",
      "Epoch 359/1000\n",
      "178/178 [==============================] - 0s 87us/step - loss: 0.1981 - accuracy: 0.9438 - val_loss: 0.8682 - val_accuracy: 0.6623\n",
      "Epoch 360/1000\n",
      "178/178 [==============================] - 0s 105us/step - loss: 0.1976 - accuracy: 0.9438 - val_loss: 0.8691 - val_accuracy: 0.6623\n",
      "Epoch 361/1000\n",
      "178/178 [==============================] - 0s 92us/step - loss: 0.1968 - accuracy: 0.9382 - val_loss: 0.8707 - val_accuracy: 0.6623\n",
      "Epoch 362/1000\n",
      "178/178 [==============================] - 0s 96us/step - loss: 0.1965 - accuracy: 0.9382 - val_loss: 0.8724 - val_accuracy: 0.6623\n",
      "Epoch 363/1000\n",
      "178/178 [==============================] - 0s 96us/step - loss: 0.1966 - accuracy: 0.9438 - val_loss: 0.8731 - val_accuracy: 0.6623\n",
      "Epoch 364/1000\n",
      "178/178 [==============================] - 0s 161us/step - loss: 0.1957 - accuracy: 0.9438 - val_loss: 0.8754 - val_accuracy: 0.6623\n",
      "Epoch 365/1000\n",
      "178/178 [==============================] - 0s 247us/step - loss: 0.1957 - accuracy: 0.9382 - val_loss: 0.8776 - val_accuracy: 0.6623\n",
      "Epoch 366/1000\n",
      "178/178 [==============================] - 0s 191us/step - loss: 0.1966 - accuracy: 0.9438 - val_loss: 0.8786 - val_accuracy: 0.6623\n",
      "Epoch 367/1000\n",
      "178/178 [==============================] - 0s 245us/step - loss: 0.1947 - accuracy: 0.9438 - val_loss: 0.8794 - val_accuracy: 0.6623\n",
      "Epoch 368/1000\n",
      "178/178 [==============================] - 0s 145us/step - loss: 0.1946 - accuracy: 0.9438 - val_loss: 0.8799 - val_accuracy: 0.6623\n",
      "Epoch 369/1000\n",
      "178/178 [==============================] - 0s 127us/step - loss: 0.1949 - accuracy: 0.9438 - val_loss: 0.8794 - val_accuracy: 0.6623\n",
      "Epoch 370/1000\n",
      "178/178 [==============================] - 0s 130us/step - loss: 0.1940 - accuracy: 0.9438 - val_loss: 0.8819 - val_accuracy: 0.6623\n",
      "Epoch 371/1000\n",
      "178/178 [==============================] - 0s 144us/step - loss: 0.1936 - accuracy: 0.9438 - val_loss: 0.8825 - val_accuracy: 0.6623\n",
      "Epoch 372/1000\n",
      "178/178 [==============================] - 0s 134us/step - loss: 0.1937 - accuracy: 0.9438 - val_loss: 0.8827 - val_accuracy: 0.6623\n",
      "Epoch 373/1000\n",
      "178/178 [==============================] - 0s 149us/step - loss: 0.1933 - accuracy: 0.9438 - val_loss: 0.8827 - val_accuracy: 0.6623\n",
      "Epoch 374/1000\n",
      "178/178 [==============================] - 0s 143us/step - loss: 0.1926 - accuracy: 0.9494 - val_loss: 0.8845 - val_accuracy: 0.6623\n",
      "Epoch 375/1000\n",
      "178/178 [==============================] - 0s 180us/step - loss: 0.1924 - accuracy: 0.9494 - val_loss: 0.8853 - val_accuracy: 0.6623\n",
      "Epoch 376/1000\n",
      "178/178 [==============================] - 0s 168us/step - loss: 0.1922 - accuracy: 0.9494 - val_loss: 0.8868 - val_accuracy: 0.6623\n",
      "Epoch 377/1000\n",
      "178/178 [==============================] - 0s 102us/step - loss: 0.1920 - accuracy: 0.9494 - val_loss: 0.8865 - val_accuracy: 0.6623\n",
      "Epoch 378/1000\n",
      "178/178 [==============================] - 0s 111us/step - loss: 0.1917 - accuracy: 0.9494 - val_loss: 0.8884 - val_accuracy: 0.6623\n",
      "Epoch 379/1000\n",
      "178/178 [==============================] - 0s 98us/step - loss: 0.1917 - accuracy: 0.9494 - val_loss: 0.8884 - val_accuracy: 0.6623\n",
      "Epoch 380/1000\n",
      "178/178 [==============================] - 0s 104us/step - loss: 0.1910 - accuracy: 0.9494 - val_loss: 0.8897 - val_accuracy: 0.6623\n",
      "Epoch 381/1000\n",
      "178/178 [==============================] - 0s 109us/step - loss: 0.1911 - accuracy: 0.9494 - val_loss: 0.8914 - val_accuracy: 0.6623\n",
      "Epoch 382/1000\n",
      "178/178 [==============================] - 0s 117us/step - loss: 0.1902 - accuracy: 0.9438 - val_loss: 0.8914 - val_accuracy: 0.6623\n",
      "Epoch 383/1000\n",
      "178/178 [==============================] - 0s 111us/step - loss: 0.1901 - accuracy: 0.9494 - val_loss: 0.8921 - val_accuracy: 0.6623\n",
      "Epoch 384/1000\n",
      "178/178 [==============================] - 0s 93us/step - loss: 0.1904 - accuracy: 0.9494 - val_loss: 0.8949 - val_accuracy: 0.6623\n",
      "Epoch 385/1000\n",
      "178/178 [==============================] - 0s 107us/step - loss: 0.1893 - accuracy: 0.9494 - val_loss: 0.8957 - val_accuracy: 0.6623\n",
      "Epoch 386/1000\n",
      "178/178 [==============================] - 0s 98us/step - loss: 0.1889 - accuracy: 0.9494 - val_loss: 0.8964 - val_accuracy: 0.6623\n",
      "Epoch 387/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 128us/step - loss: 0.1888 - accuracy: 0.9494 - val_loss: 0.8978 - val_accuracy: 0.6623\n",
      "Epoch 388/1000\n",
      "178/178 [==============================] - 0s 207us/step - loss: 0.1882 - accuracy: 0.9494 - val_loss: 0.8984 - val_accuracy: 0.6623\n",
      "Epoch 389/1000\n",
      "178/178 [==============================] - 0s 168us/step - loss: 0.1880 - accuracy: 0.9494 - val_loss: 0.8983 - val_accuracy: 0.6623\n",
      "Epoch 390/1000\n",
      "178/178 [==============================] - 0s 216us/step - loss: 0.1883 - accuracy: 0.9494 - val_loss: 0.9004 - val_accuracy: 0.6623\n",
      "Epoch 391/1000\n",
      "178/178 [==============================] - 0s 201us/step - loss: 0.1876 - accuracy: 0.9494 - val_loss: 0.9013 - val_accuracy: 0.6623\n",
      "Epoch 392/1000\n",
      "178/178 [==============================] - 0s 148us/step - loss: 0.1870 - accuracy: 0.9494 - val_loss: 0.9009 - val_accuracy: 0.6623\n",
      "Epoch 393/1000\n",
      "178/178 [==============================] - 0s 90us/step - loss: 0.1868 - accuracy: 0.9494 - val_loss: 0.9028 - val_accuracy: 0.6623\n",
      "Epoch 394/1000\n",
      "178/178 [==============================] - 0s 138us/step - loss: 0.1870 - accuracy: 0.9494 - val_loss: 0.9014 - val_accuracy: 0.6623\n",
      "Epoch 395/1000\n",
      "178/178 [==============================] - 0s 215us/step - loss: 0.1871 - accuracy: 0.9494 - val_loss: 0.9030 - val_accuracy: 0.6623\n",
      "Epoch 396/1000\n",
      "178/178 [==============================] - 0s 129us/step - loss: 0.1862 - accuracy: 0.9494 - val_loss: 0.9031 - val_accuracy: 0.6623\n",
      "Epoch 397/1000\n",
      "178/178 [==============================] - 0s 158us/step - loss: 0.1864 - accuracy: 0.9494 - val_loss: 0.9049 - val_accuracy: 0.6623\n",
      "Epoch 398/1000\n",
      "178/178 [==============================] - 0s 171us/step - loss: 0.1859 - accuracy: 0.9494 - val_loss: 0.9069 - val_accuracy: 0.6623\n",
      "Epoch 399/1000\n",
      "178/178 [==============================] - 0s 205us/step - loss: 0.1853 - accuracy: 0.9494 - val_loss: 0.9087 - val_accuracy: 0.6623\n",
      "Epoch 400/1000\n",
      "178/178 [==============================] - 0s 171us/step - loss: 0.1852 - accuracy: 0.9494 - val_loss: 0.9092 - val_accuracy: 0.6623\n",
      "Epoch 401/1000\n",
      "178/178 [==============================] - 0s 195us/step - loss: 0.1856 - accuracy: 0.9551 - val_loss: 0.9107 - val_accuracy: 0.6623\n",
      "Epoch 402/1000\n",
      "178/178 [==============================] - 0s 101us/step - loss: 0.1846 - accuracy: 0.9494 - val_loss: 0.9116 - val_accuracy: 0.6623\n",
      "Epoch 403/1000\n",
      "178/178 [==============================] - 0s 111us/step - loss: 0.1841 - accuracy: 0.9494 - val_loss: 0.9125 - val_accuracy: 0.6623\n",
      "Epoch 404/1000\n",
      "178/178 [==============================] - 0s 95us/step - loss: 0.1841 - accuracy: 0.9494 - val_loss: 0.9137 - val_accuracy: 0.6623\n",
      "Epoch 405/1000\n",
      "178/178 [==============================] - 0s 98us/step - loss: 0.1836 - accuracy: 0.9494 - val_loss: 0.9151 - val_accuracy: 0.6623\n",
      "Epoch 406/1000\n",
      "178/178 [==============================] - 0s 94us/step - loss: 0.1833 - accuracy: 0.9494 - val_loss: 0.9149 - val_accuracy: 0.6623\n",
      "Epoch 407/1000\n",
      "178/178 [==============================] - 0s 112us/step - loss: 0.1834 - accuracy: 0.9494 - val_loss: 0.9174 - val_accuracy: 0.6623\n",
      "Epoch 408/1000\n",
      "178/178 [==============================] - 0s 99us/step - loss: 0.1826 - accuracy: 0.9494 - val_loss: 0.9147 - val_accuracy: 0.6623\n",
      "Epoch 409/1000\n",
      "178/178 [==============================] - 0s 97us/step - loss: 0.1820 - accuracy: 0.9494 - val_loss: 0.9152 - val_accuracy: 0.6623\n",
      "Epoch 410/1000\n",
      "178/178 [==============================] - 0s 97us/step - loss: 0.1823 - accuracy: 0.9494 - val_loss: 0.9163 - val_accuracy: 0.6623\n",
      "Epoch 411/1000\n",
      "178/178 [==============================] - 0s 96us/step - loss: 0.1821 - accuracy: 0.9494 - val_loss: 0.9165 - val_accuracy: 0.6623\n",
      "Epoch 412/1000\n",
      "178/178 [==============================] - 0s 92us/step - loss: 0.1817 - accuracy: 0.9494 - val_loss: 0.9166 - val_accuracy: 0.6623\n",
      "Epoch 413/1000\n",
      "178/178 [==============================] - 0s 121us/step - loss: 0.1815 - accuracy: 0.9494 - val_loss: 0.9177 - val_accuracy: 0.6623\n",
      "Epoch 414/1000\n",
      "178/178 [==============================] - 0s 104us/step - loss: 0.1809 - accuracy: 0.9494 - val_loss: 0.9204 - val_accuracy: 0.6623\n",
      "Epoch 415/1000\n",
      "178/178 [==============================] - 0s 103us/step - loss: 0.1805 - accuracy: 0.9494 - val_loss: 0.9216 - val_accuracy: 0.6623\n",
      "Epoch 416/1000\n",
      "178/178 [==============================] - 0s 110us/step - loss: 0.1805 - accuracy: 0.9494 - val_loss: 0.9237 - val_accuracy: 0.6623\n",
      "Epoch 417/1000\n",
      "178/178 [==============================] - 0s 100us/step - loss: 0.1804 - accuracy: 0.9494 - val_loss: 0.9252 - val_accuracy: 0.6623\n",
      "Epoch 418/1000\n",
      "178/178 [==============================] - 0s 105us/step - loss: 0.1803 - accuracy: 0.9494 - val_loss: 0.9265 - val_accuracy: 0.6623\n",
      "Epoch 419/1000\n",
      "178/178 [==============================] - 0s 180us/step - loss: 0.1795 - accuracy: 0.9494 - val_loss: 0.9251 - val_accuracy: 0.6623\n",
      "Epoch 420/1000\n",
      "178/178 [==============================] - 0s 218us/step - loss: 0.1794 - accuracy: 0.9494 - val_loss: 0.9256 - val_accuracy: 0.6623\n",
      "Epoch 421/1000\n",
      "178/178 [==============================] - 0s 198us/step - loss: 0.1791 - accuracy: 0.9494 - val_loss: 0.9274 - val_accuracy: 0.6623\n",
      "Epoch 422/1000\n",
      "178/178 [==============================] - 0s 124us/step - loss: 0.1787 - accuracy: 0.9494 - val_loss: 0.9285 - val_accuracy: 0.6623\n",
      "Epoch 423/1000\n",
      "178/178 [==============================] - 0s 142us/step - loss: 0.1794 - accuracy: 0.9494 - val_loss: 0.9299 - val_accuracy: 0.6623\n",
      "Epoch 424/1000\n",
      "178/178 [==============================] - 0s 119us/step - loss: 0.1787 - accuracy: 0.9494 - val_loss: 0.9301 - val_accuracy: 0.6623\n",
      "Epoch 425/1000\n",
      "178/178 [==============================] - 0s 126us/step - loss: 0.1784 - accuracy: 0.9494 - val_loss: 0.9325 - val_accuracy: 0.6623\n",
      "Epoch 426/1000\n",
      "178/178 [==============================] - 0s 108us/step - loss: 0.1786 - accuracy: 0.9494 - val_loss: 0.9340 - val_accuracy: 0.6623\n",
      "Epoch 427/1000\n",
      "178/178 [==============================] - 0s 115us/step - loss: 0.1775 - accuracy: 0.9494 - val_loss: 0.9341 - val_accuracy: 0.6623\n",
      "Epoch 428/1000\n",
      "178/178 [==============================] - 0s 109us/step - loss: 0.1774 - accuracy: 0.9494 - val_loss: 0.9348 - val_accuracy: 0.6623\n",
      "Epoch 429/1000\n",
      "178/178 [==============================] - 0s 126us/step - loss: 0.1766 - accuracy: 0.9494 - val_loss: 0.9360 - val_accuracy: 0.6623\n",
      "Epoch 430/1000\n",
      "178/178 [==============================] - 0s 108us/step - loss: 0.1773 - accuracy: 0.9494 - val_loss: 0.9363 - val_accuracy: 0.6623\n",
      "Epoch 431/1000\n",
      "178/178 [==============================] - 0s 108us/step - loss: 0.1768 - accuracy: 0.9494 - val_loss: 0.9374 - val_accuracy: 0.6623\n",
      "Epoch 432/1000\n",
      "178/178 [==============================] - 0s 108us/step - loss: 0.1765 - accuracy: 0.9494 - val_loss: 0.9394 - val_accuracy: 0.6623\n",
      "Epoch 433/1000\n",
      "178/178 [==============================] - 0s 112us/step - loss: 0.1772 - accuracy: 0.9494 - val_loss: 0.9386 - val_accuracy: 0.6623\n",
      "Epoch 434/1000\n",
      "178/178 [==============================] - 0s 114us/step - loss: 0.1758 - accuracy: 0.9494 - val_loss: 0.9402 - val_accuracy: 0.6623\n",
      "Epoch 435/1000\n",
      "178/178 [==============================] - 0s 223us/step - loss: 0.1758 - accuracy: 0.9494 - val_loss: 0.9415 - val_accuracy: 0.6623\n",
      "Epoch 436/1000\n",
      "178/178 [==============================] - 0s 226us/step - loss: 0.1751 - accuracy: 0.9494 - val_loss: 0.9423 - val_accuracy: 0.6623\n",
      "Epoch 437/1000\n",
      "178/178 [==============================] - 0s 180us/step - loss: 0.1755 - accuracy: 0.9494 - val_loss: 0.9425 - val_accuracy: 0.6623\n",
      "Epoch 438/1000\n",
      "178/178 [==============================] - 0s 145us/step - loss: 0.1744 - accuracy: 0.9494 - val_loss: 0.9426 - val_accuracy: 0.6623\n",
      "Epoch 439/1000\n",
      "178/178 [==============================] - 0s 148us/step - loss: 0.1747 - accuracy: 0.9494 - val_loss: 0.9439 - val_accuracy: 0.6623\n",
      "Epoch 440/1000\n",
      "178/178 [==============================] - 0s 178us/step - loss: 0.1742 - accuracy: 0.9494 - val_loss: 0.9448 - val_accuracy: 0.6623\n",
      "Epoch 441/1000\n",
      "178/178 [==============================] - 0s 152us/step - loss: 0.1742 - accuracy: 0.9494 - val_loss: 0.9442 - val_accuracy: 0.6623\n",
      "Epoch 442/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 143us/step - loss: 0.1740 - accuracy: 0.9494 - val_loss: 0.9446 - val_accuracy: 0.6623\n",
      "Epoch 443/1000\n",
      "178/178 [==============================] - 0s 178us/step - loss: 0.1740 - accuracy: 0.9494 - val_loss: 0.9482 - val_accuracy: 0.6623\n",
      "Epoch 444/1000\n",
      "178/178 [==============================] - 0s 152us/step - loss: 0.1733 - accuracy: 0.9494 - val_loss: 0.9493 - val_accuracy: 0.6623\n",
      "Epoch 445/1000\n",
      "178/178 [==============================] - 0s 163us/step - loss: 0.1735 - accuracy: 0.9551 - val_loss: 0.9477 - val_accuracy: 0.6623\n",
      "Epoch 446/1000\n",
      "178/178 [==============================] - 0s 92us/step - loss: 0.1727 - accuracy: 0.9494 - val_loss: 0.9467 - val_accuracy: 0.6623\n",
      "Epoch 447/1000\n",
      "178/178 [==============================] - 0s 93us/step - loss: 0.1728 - accuracy: 0.9494 - val_loss: 0.9485 - val_accuracy: 0.6623\n",
      "Epoch 448/1000\n",
      "178/178 [==============================] - 0s 89us/step - loss: 0.1724 - accuracy: 0.9494 - val_loss: 0.9501 - val_accuracy: 0.6623\n",
      "Epoch 449/1000\n",
      "178/178 [==============================] - 0s 89us/step - loss: 0.1720 - accuracy: 0.9494 - val_loss: 0.9503 - val_accuracy: 0.6623\n",
      "Epoch 450/1000\n",
      "178/178 [==============================] - 0s 96us/step - loss: 0.1724 - accuracy: 0.9494 - val_loss: 0.9516 - val_accuracy: 0.6623\n",
      "Epoch 451/1000\n",
      "178/178 [==============================] - 0s 92us/step - loss: 0.1714 - accuracy: 0.9494 - val_loss: 0.9537 - val_accuracy: 0.6623\n",
      "Epoch 452/1000\n",
      "178/178 [==============================] - 0s 92us/step - loss: 0.1716 - accuracy: 0.9494 - val_loss: 0.9551 - val_accuracy: 0.6623\n",
      "Epoch 453/1000\n",
      "178/178 [==============================] - 0s 90us/step - loss: 0.1719 - accuracy: 0.9494 - val_loss: 0.9556 - val_accuracy: 0.6623\n",
      "Epoch 454/1000\n",
      "178/178 [==============================] - 0s 96us/step - loss: 0.1707 - accuracy: 0.9494 - val_loss: 0.9575 - val_accuracy: 0.6623\n",
      "Epoch 455/1000\n",
      "178/178 [==============================] - 0s 93us/step - loss: 0.1706 - accuracy: 0.9494 - val_loss: 0.9598 - val_accuracy: 0.6623\n",
      "Epoch 456/1000\n",
      "178/178 [==============================] - 0s 89us/step - loss: 0.1704 - accuracy: 0.9494 - val_loss: 0.9610 - val_accuracy: 0.6623\n",
      "Epoch 457/1000\n",
      "178/178 [==============================] - 0s 99us/step - loss: 0.1706 - accuracy: 0.9494 - val_loss: 0.9628 - val_accuracy: 0.6623\n",
      "Epoch 458/1000\n",
      "178/178 [==============================] - 0s 145us/step - loss: 0.1700 - accuracy: 0.9494 - val_loss: 0.9635 - val_accuracy: 0.6623\n",
      "Epoch 459/1000\n",
      "178/178 [==============================] - 0s 112us/step - loss: 0.1698 - accuracy: 0.9494 - val_loss: 0.9652 - val_accuracy: 0.6494\n",
      "Epoch 460/1000\n",
      "178/178 [==============================] - 0s 125us/step - loss: 0.1697 - accuracy: 0.9551 - val_loss: 0.9633 - val_accuracy: 0.6623\n",
      "Epoch 461/1000\n",
      "178/178 [==============================] - 0s 148us/step - loss: 0.1694 - accuracy: 0.9494 - val_loss: 0.9648 - val_accuracy: 0.6623\n",
      "Epoch 462/1000\n",
      "178/178 [==============================] - 0s 224us/step - loss: 0.1689 - accuracy: 0.9494 - val_loss: 0.9644 - val_accuracy: 0.6623\n",
      "Epoch 463/1000\n",
      "178/178 [==============================] - 0s 145us/step - loss: 0.1689 - accuracy: 0.9494 - val_loss: 0.9643 - val_accuracy: 0.6623\n",
      "Epoch 464/1000\n",
      "178/178 [==============================] - 0s 129us/step - loss: 0.1690 - accuracy: 0.9551 - val_loss: 0.9672 - val_accuracy: 0.6623\n",
      "Epoch 465/1000\n",
      "178/178 [==============================] - 0s 135us/step - loss: 0.1686 - accuracy: 0.9494 - val_loss: 0.9684 - val_accuracy: 0.6623\n",
      "Epoch 466/1000\n",
      "178/178 [==============================] - 0s 127us/step - loss: 0.1685 - accuracy: 0.9494 - val_loss: 0.9695 - val_accuracy: 0.6623\n",
      "Epoch 467/1000\n",
      "178/178 [==============================] - 0s 132us/step - loss: 0.1680 - accuracy: 0.9494 - val_loss: 0.9708 - val_accuracy: 0.6623\n",
      "Epoch 468/1000\n",
      "178/178 [==============================] - 0s 122us/step - loss: 0.1683 - accuracy: 0.9551 - val_loss: 0.9702 - val_accuracy: 0.6623\n",
      "Epoch 469/1000\n",
      "178/178 [==============================] - 0s 137us/step - loss: 0.1675 - accuracy: 0.9494 - val_loss: 0.9717 - val_accuracy: 0.6623\n",
      "Epoch 470/1000\n",
      "178/178 [==============================] - 0s 118us/step - loss: 0.1673 - accuracy: 0.9551 - val_loss: 0.9717 - val_accuracy: 0.6623\n",
      "Epoch 471/1000\n",
      "178/178 [==============================] - 0s 124us/step - loss: 0.1671 - accuracy: 0.9494 - val_loss: 0.9733 - val_accuracy: 0.6623\n",
      "Epoch 472/1000\n",
      "178/178 [==============================] - 0s 142us/step - loss: 0.1668 - accuracy: 0.9551 - val_loss: 0.9738 - val_accuracy: 0.6623\n",
      "Epoch 473/1000\n",
      "178/178 [==============================] - 0s 120us/step - loss: 0.1669 - accuracy: 0.9551 - val_loss: 0.9729 - val_accuracy: 0.6623\n",
      "Epoch 474/1000\n",
      "178/178 [==============================] - 0s 163us/step - loss: 0.1671 - accuracy: 0.9494 - val_loss: 0.9740 - val_accuracy: 0.6623\n",
      "Epoch 475/1000\n",
      "178/178 [==============================] - 0s 109us/step - loss: 0.1664 - accuracy: 0.9494 - val_loss: 0.9764 - val_accuracy: 0.6623\n",
      "Epoch 476/1000\n",
      "178/178 [==============================] - 0s 120us/step - loss: 0.1665 - accuracy: 0.9494 - val_loss: 0.9787 - val_accuracy: 0.6494\n",
      "Epoch 477/1000\n",
      "178/178 [==============================] - 0s 135us/step - loss: 0.1666 - accuracy: 0.9551 - val_loss: 0.9789 - val_accuracy: 0.6623\n",
      "Epoch 478/1000\n",
      "178/178 [==============================] - 0s 214us/step - loss: 0.1656 - accuracy: 0.9494 - val_loss: 0.9804 - val_accuracy: 0.6494\n",
      "Epoch 479/1000\n",
      "178/178 [==============================] - 0s 172us/step - loss: 0.1653 - accuracy: 0.9551 - val_loss: 0.9811 - val_accuracy: 0.6494\n",
      "Epoch 480/1000\n",
      "178/178 [==============================] - 0s 124us/step - loss: 0.1652 - accuracy: 0.9551 - val_loss: 0.9802 - val_accuracy: 0.6623\n",
      "Epoch 481/1000\n",
      "178/178 [==============================] - 0s 130us/step - loss: 0.1647 - accuracy: 0.9551 - val_loss: 0.9815 - val_accuracy: 0.6623\n",
      "Epoch 482/1000\n",
      "178/178 [==============================] - 0s 131us/step - loss: 0.1654 - accuracy: 0.9494 - val_loss: 0.9818 - val_accuracy: 0.6623\n",
      "Epoch 483/1000\n",
      "178/178 [==============================] - 0s 101us/step - loss: 0.1644 - accuracy: 0.9551 - val_loss: 0.9817 - val_accuracy: 0.6623\n",
      "Epoch 484/1000\n",
      "178/178 [==============================] - 0s 125us/step - loss: 0.1644 - accuracy: 0.9494 - val_loss: 0.9824 - val_accuracy: 0.6623\n",
      "Epoch 485/1000\n",
      "178/178 [==============================] - 0s 152us/step - loss: 0.1650 - accuracy: 0.9551 - val_loss: 0.9856 - val_accuracy: 0.6623\n",
      "Epoch 486/1000\n",
      "178/178 [==============================] - 0s 108us/step - loss: 0.1636 - accuracy: 0.9551 - val_loss: 0.9858 - val_accuracy: 0.6623\n",
      "Epoch 487/1000\n",
      "178/178 [==============================] - 0s 128us/step - loss: 0.1637 - accuracy: 0.9551 - val_loss: 0.9877 - val_accuracy: 0.6623\n",
      "Epoch 488/1000\n",
      "178/178 [==============================] - 0s 119us/step - loss: 0.1632 - accuracy: 0.9551 - val_loss: 0.9893 - val_accuracy: 0.6494\n",
      "Epoch 489/1000\n",
      "178/178 [==============================] - 0s 123us/step - loss: 0.1631 - accuracy: 0.9551 - val_loss: 0.9905 - val_accuracy: 0.6494\n",
      "Epoch 490/1000\n",
      "178/178 [==============================] - 0s 111us/step - loss: 0.1633 - accuracy: 0.9551 - val_loss: 0.9902 - val_accuracy: 0.6494\n",
      "Epoch 491/1000\n",
      "178/178 [==============================] - 0s 99us/step - loss: 0.1632 - accuracy: 0.9551 - val_loss: 0.9899 - val_accuracy: 0.6623\n",
      "Epoch 492/1000\n",
      "178/178 [==============================] - 0s 88us/step - loss: 0.1628 - accuracy: 0.9551 - val_loss: 0.9920 - val_accuracy: 0.6623\n",
      "Epoch 493/1000\n",
      "178/178 [==============================] - 0s 86us/step - loss: 0.1629 - accuracy: 0.9494 - val_loss: 0.9933 - val_accuracy: 0.6494\n",
      "Epoch 494/1000\n",
      "178/178 [==============================] - 0s 97us/step - loss: 0.1618 - accuracy: 0.9494 - val_loss: 0.9940 - val_accuracy: 0.6623\n",
      "Epoch 495/1000\n",
      "178/178 [==============================] - 0s 95us/step - loss: 0.1623 - accuracy: 0.9494 - val_loss: 0.9951 - val_accuracy: 0.6494\n",
      "Epoch 496/1000\n",
      "178/178 [==============================] - 0s 95us/step - loss: 0.1616 - accuracy: 0.9494 - val_loss: 0.9975 - val_accuracy: 0.6494\n",
      "Epoch 497/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 96us/step - loss: 0.1617 - accuracy: 0.9494 - val_loss: 0.9985 - val_accuracy: 0.6494\n",
      "Epoch 498/1000\n",
      "178/178 [==============================] - 0s 107us/step - loss: 0.1613 - accuracy: 0.9551 - val_loss: 1.0000 - val_accuracy: 0.6494\n",
      "Epoch 499/1000\n",
      "178/178 [==============================] - 0s 244us/step - loss: 0.1612 - accuracy: 0.9551 - val_loss: 0.9986 - val_accuracy: 0.6494\n",
      "Epoch 500/1000\n",
      "178/178 [==============================] - 0s 204us/step - loss: 0.1609 - accuracy: 0.9494 - val_loss: 0.9987 - val_accuracy: 0.6494\n",
      "Epoch 501/1000\n",
      "178/178 [==============================] - 0s 156us/step - loss: 0.1608 - accuracy: 0.9551 - val_loss: 0.9973 - val_accuracy: 0.6623\n",
      "Epoch 502/1000\n",
      "178/178 [==============================] - 0s 249us/step - loss: 0.1610 - accuracy: 0.9551 - val_loss: 0.9978 - val_accuracy: 0.6623\n",
      "Epoch 503/1000\n",
      "178/178 [==============================] - 0s 140us/step - loss: 0.1601 - accuracy: 0.9551 - val_loss: 0.9969 - val_accuracy: 0.6623\n",
      "Epoch 504/1000\n",
      "178/178 [==============================] - 0s 150us/step - loss: 0.1602 - accuracy: 0.9551 - val_loss: 1.0008 - val_accuracy: 0.6623\n",
      "Epoch 505/1000\n",
      "178/178 [==============================] - 0s 158us/step - loss: 0.1598 - accuracy: 0.9494 - val_loss: 1.0022 - val_accuracy: 0.6494\n",
      "Epoch 506/1000\n",
      "178/178 [==============================] - 0s 128us/step - loss: 0.1594 - accuracy: 0.9551 - val_loss: 1.0033 - val_accuracy: 0.6494\n",
      "Epoch 507/1000\n",
      "178/178 [==============================] - 0s 119us/step - loss: 0.1603 - accuracy: 0.9494 - val_loss: 1.0047 - val_accuracy: 0.6494\n",
      "Epoch 508/1000\n",
      "178/178 [==============================] - 0s 261us/step - loss: 0.1598 - accuracy: 0.9551 - val_loss: 1.0072 - val_accuracy: 0.6494\n",
      "Epoch 509/1000\n",
      "178/178 [==============================] - 0s 208us/step - loss: 0.1590 - accuracy: 0.9551 - val_loss: 1.0073 - val_accuracy: 0.6494\n",
      "Epoch 510/1000\n",
      "178/178 [==============================] - 0s 164us/step - loss: 0.1591 - accuracy: 0.9551 - val_loss: 1.0077 - val_accuracy: 0.6494\n",
      "Epoch 511/1000\n",
      "178/178 [==============================] - 0s 126us/step - loss: 0.1595 - accuracy: 0.9494 - val_loss: 1.0074 - val_accuracy: 0.6494\n",
      "Epoch 512/1000\n",
      "178/178 [==============================] - 0s 114us/step - loss: 0.1592 - accuracy: 0.9494 - val_loss: 1.0084 - val_accuracy: 0.6623\n",
      "Epoch 513/1000\n",
      "178/178 [==============================] - 0s 186us/step - loss: 0.1582 - accuracy: 0.9551 - val_loss: 1.0096 - val_accuracy: 0.6494\n",
      "Epoch 514/1000\n",
      "178/178 [==============================] - 0s 116us/step - loss: 0.1583 - accuracy: 0.9551 - val_loss: 1.0121 - val_accuracy: 0.6494\n",
      "Epoch 515/1000\n",
      "178/178 [==============================] - 0s 129us/step - loss: 0.1580 - accuracy: 0.9551 - val_loss: 1.0141 - val_accuracy: 0.6494\n",
      "Epoch 516/1000\n",
      "178/178 [==============================] - 0s 129us/step - loss: 0.1581 - accuracy: 0.9551 - val_loss: 1.0151 - val_accuracy: 0.6494\n",
      "Epoch 517/1000\n",
      "178/178 [==============================] - 0s 143us/step - loss: 0.1580 - accuracy: 0.9551 - val_loss: 1.0142 - val_accuracy: 0.6494\n",
      "Epoch 518/1000\n",
      "178/178 [==============================] - 0s 207us/step - loss: 0.1584 - accuracy: 0.9607 - val_loss: 1.0165 - val_accuracy: 0.6494\n",
      "Epoch 519/1000\n",
      "178/178 [==============================] - 0s 216us/step - loss: 0.1576 - accuracy: 0.9494 - val_loss: 1.0176 - val_accuracy: 0.6494\n",
      "Epoch 520/1000\n",
      "178/178 [==============================] - 0s 226us/step - loss: 0.1569 - accuracy: 0.9551 - val_loss: 1.0186 - val_accuracy: 0.6494\n",
      "Epoch 521/1000\n",
      "178/178 [==============================] - 0s 169us/step - loss: 0.1573 - accuracy: 0.9551 - val_loss: 1.0189 - val_accuracy: 0.6494\n",
      "Epoch 522/1000\n",
      "178/178 [==============================] - 0s 109us/step - loss: 0.1567 - accuracy: 0.9551 - val_loss: 1.0195 - val_accuracy: 0.6494\n",
      "Epoch 523/1000\n",
      "178/178 [==============================] - 0s 108us/step - loss: 0.1567 - accuracy: 0.9551 - val_loss: 1.0189 - val_accuracy: 0.6494\n",
      "Epoch 524/1000\n",
      "178/178 [==============================] - 0s 108us/step - loss: 0.1564 - accuracy: 0.9607 - val_loss: 1.0209 - val_accuracy: 0.6494\n",
      "Epoch 525/1000\n",
      "178/178 [==============================] - 0s 95us/step - loss: 0.1564 - accuracy: 0.9551 - val_loss: 1.0209 - val_accuracy: 0.6494\n",
      "Epoch 526/1000\n",
      "178/178 [==============================] - 0s 107us/step - loss: 0.1561 - accuracy: 0.9551 - val_loss: 1.0226 - val_accuracy: 0.6494\n",
      "Epoch 527/1000\n",
      "178/178 [==============================] - 0s 84us/step - loss: 0.1558 - accuracy: 0.9607 - val_loss: 1.0252 - val_accuracy: 0.6494\n",
      "Epoch 528/1000\n",
      "178/178 [==============================] - 0s 98us/step - loss: 0.1558 - accuracy: 0.9607 - val_loss: 1.0265 - val_accuracy: 0.6494\n",
      "Epoch 529/1000\n",
      "178/178 [==============================] - 0s 100us/step - loss: 0.1554 - accuracy: 0.9494 - val_loss: 1.0277 - val_accuracy: 0.6494\n",
      "Epoch 530/1000\n",
      "178/178 [==============================] - 0s 82us/step - loss: 0.1555 - accuracy: 0.9551 - val_loss: 1.0262 - val_accuracy: 0.6494\n",
      "Epoch 531/1000\n",
      "178/178 [==============================] - 0s 102us/step - loss: 0.1554 - accuracy: 0.9551 - val_loss: 1.0234 - val_accuracy: 0.6494\n",
      "Epoch 532/1000\n",
      "178/178 [==============================] - 0s 116us/step - loss: 0.1548 - accuracy: 0.9551 - val_loss: 1.0257 - val_accuracy: 0.6494\n",
      "Epoch 533/1000\n",
      "178/178 [==============================] - 0s 103us/step - loss: 0.1547 - accuracy: 0.9551 - val_loss: 1.0254 - val_accuracy: 0.6494\n",
      "Epoch 534/1000\n",
      "178/178 [==============================] - 0s 103us/step - loss: 0.1542 - accuracy: 0.9607 - val_loss: 1.0269 - val_accuracy: 0.6494\n",
      "Epoch 535/1000\n",
      "178/178 [==============================] - 0s 88us/step - loss: 0.1551 - accuracy: 0.9551 - val_loss: 1.0276 - val_accuracy: 0.6494\n",
      "Epoch 536/1000\n",
      "178/178 [==============================] - 0s 101us/step - loss: 0.1540 - accuracy: 0.9551 - val_loss: 1.0281 - val_accuracy: 0.6494\n",
      "Epoch 537/1000\n",
      "178/178 [==============================] - 0s 229us/step - loss: 0.1545 - accuracy: 0.9607 - val_loss: 1.0314 - val_accuracy: 0.6494\n",
      "Epoch 538/1000\n",
      "178/178 [==============================] - 0s 204us/step - loss: 0.1538 - accuracy: 0.9551 - val_loss: 1.0330 - val_accuracy: 0.6494\n",
      "Epoch 539/1000\n",
      "178/178 [==============================] - 0s 146us/step - loss: 0.1538 - accuracy: 0.9551 - val_loss: 1.0325 - val_accuracy: 0.6494\n",
      "Epoch 540/1000\n",
      "178/178 [==============================] - 0s 151us/step - loss: 0.1536 - accuracy: 0.9551 - val_loss: 1.0308 - val_accuracy: 0.6494\n",
      "Epoch 541/1000\n",
      "178/178 [==============================] - 0s 138us/step - loss: 0.1534 - accuracy: 0.9607 - val_loss: 1.0341 - val_accuracy: 0.6494\n",
      "Epoch 542/1000\n",
      "178/178 [==============================] - 0s 154us/step - loss: 0.1531 - accuracy: 0.9551 - val_loss: 1.0352 - val_accuracy: 0.6494\n",
      "Epoch 543/1000\n",
      "178/178 [==============================] - 0s 91us/step - loss: 0.1533 - accuracy: 0.9551 - val_loss: 1.0361 - val_accuracy: 0.6494\n",
      "Epoch 544/1000\n",
      "178/178 [==============================] - 0s 91us/step - loss: 0.1526 - accuracy: 0.9551 - val_loss: 1.0366 - val_accuracy: 0.6494\n",
      "Epoch 545/1000\n",
      "178/178 [==============================] - 0s 86us/step - loss: 0.1526 - accuracy: 0.9551 - val_loss: 1.0389 - val_accuracy: 0.6494\n",
      "Epoch 546/1000\n",
      "178/178 [==============================] - 0s 91us/step - loss: 0.1523 - accuracy: 0.9551 - val_loss: 1.0395 - val_accuracy: 0.6494\n",
      "Epoch 547/1000\n",
      "178/178 [==============================] - 0s 105us/step - loss: 0.1521 - accuracy: 0.9551 - val_loss: 1.0384 - val_accuracy: 0.6494\n",
      "Epoch 548/1000\n",
      "178/178 [==============================] - 0s 85us/step - loss: 0.1518 - accuracy: 0.9551 - val_loss: 1.0409 - val_accuracy: 0.6494\n",
      "Epoch 549/1000\n",
      "178/178 [==============================] - 0s 89us/step - loss: 0.1516 - accuracy: 0.9551 - val_loss: 1.0406 - val_accuracy: 0.6494\n",
      "Epoch 550/1000\n",
      "178/178 [==============================] - 0s 86us/step - loss: 0.1516 - accuracy: 0.9551 - val_loss: 1.0437 - val_accuracy: 0.6494\n",
      "Epoch 551/1000\n",
      "178/178 [==============================] - 0s 97us/step - loss: 0.1517 - accuracy: 0.9551 - val_loss: 1.0429 - val_accuracy: 0.6494\n",
      "Epoch 552/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 128us/step - loss: 0.1509 - accuracy: 0.9607 - val_loss: 1.0441 - val_accuracy: 0.6494\n",
      "Epoch 553/1000\n",
      "178/178 [==============================] - 0s 190us/step - loss: 0.1513 - accuracy: 0.9607 - val_loss: 1.0424 - val_accuracy: 0.6494\n",
      "Epoch 554/1000\n",
      "178/178 [==============================] - 0s 234us/step - loss: 0.1508 - accuracy: 0.9607 - val_loss: 1.0428 - val_accuracy: 0.6494\n",
      "Epoch 555/1000\n",
      "178/178 [==============================] - 0s 235us/step - loss: 0.1516 - accuracy: 0.9607 - val_loss: 1.0440 - val_accuracy: 0.6494\n",
      "Epoch 556/1000\n",
      "178/178 [==============================] - 0s 238us/step - loss: 0.1503 - accuracy: 0.9551 - val_loss: 1.0455 - val_accuracy: 0.6494\n",
      "Epoch 557/1000\n",
      "178/178 [==============================] - 0s 300us/step - loss: 0.1503 - accuracy: 0.9607 - val_loss: 1.0486 - val_accuracy: 0.6494\n",
      "Epoch 558/1000\n",
      "178/178 [==============================] - 0s 268us/step - loss: 0.1501 - accuracy: 0.9551 - val_loss: 1.0475 - val_accuracy: 0.6494\n",
      "Epoch 559/1000\n",
      "178/178 [==============================] - 0s 197us/step - loss: 0.1498 - accuracy: 0.9607 - val_loss: 1.0478 - val_accuracy: 0.6494\n",
      "Epoch 560/1000\n",
      "178/178 [==============================] - 0s 144us/step - loss: 0.1499 - accuracy: 0.9607 - val_loss: 1.0502 - val_accuracy: 0.6494\n",
      "Epoch 561/1000\n",
      "178/178 [==============================] - 0s 135us/step - loss: 0.1495 - accuracy: 0.9607 - val_loss: 1.0499 - val_accuracy: 0.6494\n",
      "Epoch 562/1000\n",
      "178/178 [==============================] - 0s 154us/step - loss: 0.1497 - accuracy: 0.9607 - val_loss: 1.0508 - val_accuracy: 0.6494\n",
      "Epoch 563/1000\n",
      "178/178 [==============================] - 0s 166us/step - loss: 0.1494 - accuracy: 0.9607 - val_loss: 1.0534 - val_accuracy: 0.6494\n",
      "Epoch 564/1000\n",
      "178/178 [==============================] - 0s 142us/step - loss: 0.1490 - accuracy: 0.9551 - val_loss: 1.0546 - val_accuracy: 0.6494\n",
      "Epoch 565/1000\n",
      "178/178 [==============================] - 0s 163us/step - loss: 0.1488 - accuracy: 0.9551 - val_loss: 1.0537 - val_accuracy: 0.6494\n",
      "Epoch 566/1000\n",
      "178/178 [==============================] - 0s 145us/step - loss: 0.1488 - accuracy: 0.9551 - val_loss: 1.0551 - val_accuracy: 0.6494\n",
      "Epoch 567/1000\n",
      "178/178 [==============================] - 0s 138us/step - loss: 0.1488 - accuracy: 0.9607 - val_loss: 1.0556 - val_accuracy: 0.6494\n",
      "Epoch 568/1000\n",
      "178/178 [==============================] - 0s 141us/step - loss: 0.1480 - accuracy: 0.9607 - val_loss: 1.0566 - val_accuracy: 0.6494\n",
      "Epoch 569/1000\n",
      "178/178 [==============================] - 0s 144us/step - loss: 0.1481 - accuracy: 0.9551 - val_loss: 1.0568 - val_accuracy: 0.6494\n",
      "Epoch 570/1000\n",
      "178/178 [==============================] - 0s 102us/step - loss: 0.1483 - accuracy: 0.9607 - val_loss: 1.0565 - val_accuracy: 0.6494\n",
      "Epoch 571/1000\n",
      "178/178 [==============================] - 0s 94us/step - loss: 0.1476 - accuracy: 0.9607 - val_loss: 1.0577 - val_accuracy: 0.6494\n",
      "Epoch 572/1000\n",
      "178/178 [==============================] - 0s 93us/step - loss: 0.1477 - accuracy: 0.9607 - val_loss: 1.0593 - val_accuracy: 0.6494\n",
      "Epoch 573/1000\n",
      "178/178 [==============================] - 0s 97us/step - loss: 0.1476 - accuracy: 0.9607 - val_loss: 1.0621 - val_accuracy: 0.6494\n",
      "Epoch 574/1000\n",
      "178/178 [==============================] - 0s 117us/step - loss: 0.1475 - accuracy: 0.9607 - val_loss: 1.0641 - val_accuracy: 0.6494\n",
      "Epoch 575/1000\n",
      "178/178 [==============================] - 0s 149us/step - loss: 0.1474 - accuracy: 0.9607 - val_loss: 1.0643 - val_accuracy: 0.6494\n",
      "Epoch 576/1000\n",
      "178/178 [==============================] - 0s 162us/step - loss: 0.1469 - accuracy: 0.9607 - val_loss: 1.0647 - val_accuracy: 0.6494\n",
      "Epoch 577/1000\n",
      "178/178 [==============================] - 0s 112us/step - loss: 0.1468 - accuracy: 0.9607 - val_loss: 1.0633 - val_accuracy: 0.6494\n",
      "Epoch 578/1000\n",
      "178/178 [==============================] - 0s 132us/step - loss: 0.1467 - accuracy: 0.9551 - val_loss: 1.0644 - val_accuracy: 0.6494\n",
      "Epoch 579/1000\n",
      "178/178 [==============================] - 0s 140us/step - loss: 0.1469 - accuracy: 0.9607 - val_loss: 1.0659 - val_accuracy: 0.6494\n",
      "Epoch 580/1000\n",
      "178/178 [==============================] - 0s 157us/step - loss: 0.1475 - accuracy: 0.9607 - val_loss: 1.0666 - val_accuracy: 0.6494\n",
      "Epoch 581/1000\n",
      "178/178 [==============================] - 0s 155us/step - loss: 0.1464 - accuracy: 0.9607 - val_loss: 1.0674 - val_accuracy: 0.6494\n",
      "Epoch 582/1000\n",
      "178/178 [==============================] - 0s 147us/step - loss: 0.1463 - accuracy: 0.9607 - val_loss: 1.0710 - val_accuracy: 0.6494\n",
      "Epoch 583/1000\n",
      "178/178 [==============================] - 0s 102us/step - loss: 0.1458 - accuracy: 0.9607 - val_loss: 1.0704 - val_accuracy: 0.6494\n",
      "Epoch 584/1000\n",
      "178/178 [==============================] - 0s 96us/step - loss: 0.1465 - accuracy: 0.9607 - val_loss: 1.0701 - val_accuracy: 0.6494\n",
      "Epoch 585/1000\n",
      "178/178 [==============================] - 0s 98us/step - loss: 0.1461 - accuracy: 0.9607 - val_loss: 1.0702 - val_accuracy: 0.6494\n",
      "Epoch 586/1000\n",
      "178/178 [==============================] - 0s 106us/step - loss: 0.1457 - accuracy: 0.9607 - val_loss: 1.0729 - val_accuracy: 0.6494\n",
      "Epoch 587/1000\n",
      "178/178 [==============================] - 0s 102us/step - loss: 0.1455 - accuracy: 0.9607 - val_loss: 1.0736 - val_accuracy: 0.6494\n",
      "Epoch 588/1000\n",
      "178/178 [==============================] - 0s 107us/step - loss: 0.1453 - accuracy: 0.9607 - val_loss: 1.0766 - val_accuracy: 0.6494\n",
      "Epoch 589/1000\n",
      "178/178 [==============================] - 0s 99us/step - loss: 0.1453 - accuracy: 0.9607 - val_loss: 1.0790 - val_accuracy: 0.6494\n",
      "Epoch 590/1000\n",
      "178/178 [==============================] - 0s 98us/step - loss: 0.1447 - accuracy: 0.9607 - val_loss: 1.0801 - val_accuracy: 0.6623\n",
      "Epoch 591/1000\n",
      "178/178 [==============================] - 0s 92us/step - loss: 0.1453 - accuracy: 0.9551 - val_loss: 1.0801 - val_accuracy: 0.6494\n",
      "Epoch 592/1000\n",
      "178/178 [==============================] - 0s 91us/step - loss: 0.1446 - accuracy: 0.9607 - val_loss: 1.0810 - val_accuracy: 0.6623\n",
      "Epoch 593/1000\n",
      "178/178 [==============================] - 0s 91us/step - loss: 0.1446 - accuracy: 0.9607 - val_loss: 1.0814 - val_accuracy: 0.6623\n",
      "Epoch 594/1000\n",
      "178/178 [==============================] - 0s 87us/step - loss: 0.1444 - accuracy: 0.9607 - val_loss: 1.0819 - val_accuracy: 0.6494\n",
      "Epoch 595/1000\n",
      "178/178 [==============================] - 0s 100us/step - loss: 0.1441 - accuracy: 0.9607 - val_loss: 1.0828 - val_accuracy: 0.6494\n",
      "Epoch 596/1000\n",
      "178/178 [==============================] - 0s 97us/step - loss: 0.1440 - accuracy: 0.9607 - val_loss: 1.0835 - val_accuracy: 0.6623\n",
      "Epoch 597/1000\n",
      "178/178 [==============================] - 0s 138us/step - loss: 0.1439 - accuracy: 0.9607 - val_loss: 1.0826 - val_accuracy: 0.6494\n",
      "Epoch 598/1000\n",
      "178/178 [==============================] - 0s 313us/step - loss: 0.1439 - accuracy: 0.9663 - val_loss: 1.0818 - val_accuracy: 0.6494\n",
      "Epoch 599/1000\n",
      "178/178 [==============================] - 0s 293us/step - loss: 0.1439 - accuracy: 0.9607 - val_loss: 1.0825 - val_accuracy: 0.6494\n",
      "Epoch 600/1000\n",
      "178/178 [==============================] - 0s 152us/step - loss: 0.1438 - accuracy: 0.9663 - val_loss: 1.0833 - val_accuracy: 0.6494\n",
      "Epoch 601/1000\n",
      "178/178 [==============================] - 0s 197us/step - loss: 0.1433 - accuracy: 0.9607 - val_loss: 1.0853 - val_accuracy: 0.6494\n",
      "Epoch 602/1000\n",
      "178/178 [==============================] - 0s 261us/step - loss: 0.1430 - accuracy: 0.9663 - val_loss: 1.0884 - val_accuracy: 0.6623\n",
      "Epoch 603/1000\n",
      "178/178 [==============================] - 0s 137us/step - loss: 0.1429 - accuracy: 0.9607 - val_loss: 1.0898 - val_accuracy: 0.6623\n",
      "Epoch 604/1000\n",
      "178/178 [==============================] - 0s 167us/step - loss: 0.1426 - accuracy: 0.9607 - val_loss: 1.0896 - val_accuracy: 0.6623\n",
      "Epoch 605/1000\n",
      "178/178 [==============================] - 0s 218us/step - loss: 0.1426 - accuracy: 0.9663 - val_loss: 1.0896 - val_accuracy: 0.6494\n",
      "Epoch 606/1000\n",
      "178/178 [==============================] - 0s 219us/step - loss: 0.1429 - accuracy: 0.9551 - val_loss: 1.0896 - val_accuracy: 0.6494\n",
      "Epoch 607/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 235us/step - loss: 0.1420 - accuracy: 0.9663 - val_loss: 1.0918 - val_accuracy: 0.6623\n",
      "Epoch 608/1000\n",
      "178/178 [==============================] - 0s 131us/step - loss: 0.1430 - accuracy: 0.9663 - val_loss: 1.0928 - val_accuracy: 0.6623\n",
      "Epoch 609/1000\n",
      "178/178 [==============================] - 0s 139us/step - loss: 0.1430 - accuracy: 0.9607 - val_loss: 1.0935 - val_accuracy: 0.6623\n",
      "Epoch 610/1000\n",
      "178/178 [==============================] - 0s 113us/step - loss: 0.1420 - accuracy: 0.9607 - val_loss: 1.0936 - val_accuracy: 0.6623\n",
      "Epoch 611/1000\n",
      "178/178 [==============================] - 0s 115us/step - loss: 0.1422 - accuracy: 0.9607 - val_loss: 1.0941 - val_accuracy: 0.6494\n",
      "Epoch 612/1000\n",
      "178/178 [==============================] - 0s 112us/step - loss: 0.1415 - accuracy: 0.9607 - val_loss: 1.0935 - val_accuracy: 0.6494\n",
      "Epoch 613/1000\n",
      "178/178 [==============================] - 0s 123us/step - loss: 0.1416 - accuracy: 0.9663 - val_loss: 1.0937 - val_accuracy: 0.6494\n",
      "Epoch 614/1000\n",
      "178/178 [==============================] - 0s 148us/step - loss: 0.1412 - accuracy: 0.9607 - val_loss: 1.0960 - val_accuracy: 0.6494\n",
      "Epoch 615/1000\n",
      "178/178 [==============================] - 0s 202us/step - loss: 0.1409 - accuracy: 0.9663 - val_loss: 1.0970 - val_accuracy: 0.6623\n",
      "Epoch 616/1000\n",
      "178/178 [==============================] - 0s 107us/step - loss: 0.1414 - accuracy: 0.9607 - val_loss: 1.0973 - val_accuracy: 0.6623\n",
      "Epoch 617/1000\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0729 - accuracy: 1.00 - 0s 92us/step - loss: 0.1411 - accuracy: 0.9663 - val_loss: 1.0992 - val_accuracy: 0.6623\n",
      "Epoch 618/1000\n",
      "178/178 [==============================] - 0s 111us/step - loss: 0.1408 - accuracy: 0.9663 - val_loss: 1.0999 - val_accuracy: 0.6623\n",
      "Epoch 619/1000\n",
      "178/178 [==============================] - 0s 91us/step - loss: 0.1408 - accuracy: 0.9663 - val_loss: 1.1002 - val_accuracy: 0.6623\n",
      "Epoch 620/1000\n",
      "178/178 [==============================] - 0s 104us/step - loss: 0.1405 - accuracy: 0.9663 - val_loss: 1.0997 - val_accuracy: 0.6623\n",
      "Epoch 621/1000\n",
      "178/178 [==============================] - 0s 79us/step - loss: 0.1404 - accuracy: 0.9663 - val_loss: 1.1018 - val_accuracy: 0.6623\n",
      "Epoch 622/1000\n",
      "178/178 [==============================] - 0s 79us/step - loss: 0.1408 - accuracy: 0.9663 - val_loss: 1.1035 - val_accuracy: 0.6623\n",
      "Epoch 623/1000\n",
      "178/178 [==============================] - 0s 82us/step - loss: 0.1403 - accuracy: 0.9663 - val_loss: 1.1036 - val_accuracy: 0.6623\n",
      "Epoch 624/1000\n",
      "178/178 [==============================] - 0s 89us/step - loss: 0.1404 - accuracy: 0.9663 - val_loss: 1.1017 - val_accuracy: 0.6494\n",
      "Epoch 625/1000\n",
      "178/178 [==============================] - 0s 84us/step - loss: 0.1411 - accuracy: 0.9663 - val_loss: 1.1039 - val_accuracy: 0.6623\n",
      "Epoch 626/1000\n",
      "178/178 [==============================] - 0s 84us/step - loss: 0.1397 - accuracy: 0.9663 - val_loss: 1.1046 - val_accuracy: 0.6623\n",
      "Epoch 627/1000\n",
      "178/178 [==============================] - 0s 100us/step - loss: 0.1393 - accuracy: 0.9663 - val_loss: 1.1059 - val_accuracy: 0.6623\n",
      "Epoch 628/1000\n",
      "178/178 [==============================] - 0s 89us/step - loss: 0.1395 - accuracy: 0.9607 - val_loss: 1.1074 - val_accuracy: 0.6623\n",
      "Epoch 629/1000\n",
      "178/178 [==============================] - 0s 94us/step - loss: 0.1403 - accuracy: 0.9607 - val_loss: 1.1063 - val_accuracy: 0.6623\n",
      "Epoch 630/1000\n",
      "178/178 [==============================] - 0s 84us/step - loss: 0.1390 - accuracy: 0.9663 - val_loss: 1.1090 - val_accuracy: 0.6623\n",
      "Epoch 631/1000\n",
      "178/178 [==============================] - 0s 83us/step - loss: 0.1389 - accuracy: 0.9663 - val_loss: 1.1080 - val_accuracy: 0.6623\n",
      "Epoch 632/1000\n",
      "178/178 [==============================] - 0s 83us/step - loss: 0.1386 - accuracy: 0.9719 - val_loss: 1.1080 - val_accuracy: 0.6623\n",
      "Epoch 633/1000\n",
      "178/178 [==============================] - 0s 85us/step - loss: 0.1386 - accuracy: 0.9663 - val_loss: 1.1092 - val_accuracy: 0.6494\n",
      "Epoch 634/1000\n",
      "178/178 [==============================] - 0s 84us/step - loss: 0.1386 - accuracy: 0.9719 - val_loss: 1.1104 - val_accuracy: 0.6623\n",
      "Epoch 635/1000\n",
      "178/178 [==============================] - 0s 91us/step - loss: 0.1384 - accuracy: 0.9663 - val_loss: 1.1106 - val_accuracy: 0.6623\n",
      "Epoch 636/1000\n",
      "178/178 [==============================] - 0s 88us/step - loss: 0.1388 - accuracy: 0.9663 - val_loss: 1.1126 - val_accuracy: 0.6623\n",
      "Epoch 637/1000\n",
      "178/178 [==============================] - 0s 86us/step - loss: 0.1379 - accuracy: 0.9719 - val_loss: 1.1125 - val_accuracy: 0.6623\n",
      "Epoch 638/1000\n",
      "178/178 [==============================] - 0s 88us/step - loss: 0.1377 - accuracy: 0.9719 - val_loss: 1.1141 - val_accuracy: 0.6623\n",
      "Epoch 639/1000\n",
      "178/178 [==============================] - 0s 89us/step - loss: 0.1381 - accuracy: 0.9663 - val_loss: 1.1163 - val_accuracy: 0.6623\n",
      "Epoch 640/1000\n",
      "178/178 [==============================] - 0s 88us/step - loss: 0.1381 - accuracy: 0.9663 - val_loss: 1.1159 - val_accuracy: 0.6623\n",
      "Epoch 641/1000\n",
      "178/178 [==============================] - 0s 99us/step - loss: 0.1377 - accuracy: 0.9663 - val_loss: 1.1164 - val_accuracy: 0.6623\n",
      "Epoch 642/1000\n",
      "178/178 [==============================] - 0s 135us/step - loss: 0.1373 - accuracy: 0.9663 - val_loss: 1.1145 - val_accuracy: 0.6623\n",
      "Epoch 643/1000\n",
      "178/178 [==============================] - 0s 176us/step - loss: 0.1371 - accuracy: 0.9719 - val_loss: 1.1160 - val_accuracy: 0.6623\n",
      "Epoch 644/1000\n",
      "178/178 [==============================] - 0s 209us/step - loss: 0.1375 - accuracy: 0.9719 - val_loss: 1.1182 - val_accuracy: 0.6623\n",
      "Epoch 645/1000\n",
      "178/178 [==============================] - 0s 218us/step - loss: 0.1372 - accuracy: 0.9663 - val_loss: 1.1178 - val_accuracy: 0.6623\n",
      "Epoch 646/1000\n",
      "178/178 [==============================] - 0s 171us/step - loss: 0.1369 - accuracy: 0.9719 - val_loss: 1.1163 - val_accuracy: 0.6623\n",
      "Epoch 647/1000\n",
      "178/178 [==============================] - 0s 345us/step - loss: 0.1370 - accuracy: 0.9719 - val_loss: 1.1179 - val_accuracy: 0.6623\n",
      "Epoch 648/1000\n",
      "178/178 [==============================] - 0s 320us/step - loss: 0.1367 - accuracy: 0.9719 - val_loss: 1.1223 - val_accuracy: 0.6623\n",
      "Epoch 649/1000\n",
      "178/178 [==============================] - 0s 176us/step - loss: 0.1367 - accuracy: 0.9663 - val_loss: 1.1212 - val_accuracy: 0.6623\n",
      "Epoch 650/1000\n",
      "178/178 [==============================] - 0s 99us/step - loss: 0.1364 - accuracy: 0.9663 - val_loss: 1.1217 - val_accuracy: 0.6623\n",
      "Epoch 651/1000\n",
      "178/178 [==============================] - 0s 87us/step - loss: 0.1364 - accuracy: 0.9719 - val_loss: 1.1219 - val_accuracy: 0.6623\n",
      "Epoch 652/1000\n",
      "178/178 [==============================] - 0s 78us/step - loss: 0.1360 - accuracy: 0.9719 - val_loss: 1.1242 - val_accuracy: 0.6623\n",
      "Epoch 653/1000\n",
      "178/178 [==============================] - 0s 83us/step - loss: 0.1360 - accuracy: 0.9719 - val_loss: 1.1241 - val_accuracy: 0.6623\n",
      "Epoch 654/1000\n",
      "178/178 [==============================] - 0s 81us/step - loss: 0.1359 - accuracy: 0.9719 - val_loss: 1.1277 - val_accuracy: 0.6623\n",
      "Epoch 655/1000\n",
      "178/178 [==============================] - 0s 80us/step - loss: 0.1356 - accuracy: 0.9719 - val_loss: 1.1293 - val_accuracy: 0.6623\n",
      "Epoch 656/1000\n",
      "178/178 [==============================] - 0s 92us/step - loss: 0.1362 - accuracy: 0.9663 - val_loss: 1.1299 - val_accuracy: 0.6623\n",
      "Epoch 657/1000\n",
      "178/178 [==============================] - 0s 89us/step - loss: 0.1357 - accuracy: 0.9719 - val_loss: 1.1322 - val_accuracy: 0.6623\n",
      "Epoch 658/1000\n",
      "178/178 [==============================] - 0s 81us/step - loss: 0.1353 - accuracy: 0.9663 - val_loss: 1.1326 - val_accuracy: 0.6623\n",
      "Epoch 659/1000\n",
      "178/178 [==============================] - 0s 89us/step - loss: 0.1352 - accuracy: 0.9719 - val_loss: 1.1338 - val_accuracy: 0.6623\n",
      "Epoch 660/1000\n",
      "178/178 [==============================] - 0s 93us/step - loss: 0.1352 - accuracy: 0.9719 - val_loss: 1.1323 - val_accuracy: 0.6623\n",
      "Epoch 661/1000\n",
      "178/178 [==============================] - 0s 92us/step - loss: 0.1351 - accuracy: 0.9719 - val_loss: 1.1324 - val_accuracy: 0.6623\n",
      "Epoch 662/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 99us/step - loss: 0.1349 - accuracy: 0.9719 - val_loss: 1.1346 - val_accuracy: 0.6623\n",
      "Epoch 663/1000\n",
      "178/178 [==============================] - 0s 107us/step - loss: 0.1351 - accuracy: 0.9719 - val_loss: 1.1344 - val_accuracy: 0.6623\n",
      "Epoch 664/1000\n",
      "178/178 [==============================] - 0s 112us/step - loss: 0.1350 - accuracy: 0.9719 - val_loss: 1.1350 - val_accuracy: 0.6623\n",
      "Epoch 665/1000\n",
      "178/178 [==============================] - 0s 98us/step - loss: 0.1343 - accuracy: 0.9719 - val_loss: 1.1357 - val_accuracy: 0.6623\n",
      "Epoch 666/1000\n",
      "178/178 [==============================] - 0s 111us/step - loss: 0.1345 - accuracy: 0.9719 - val_loss: 1.1388 - val_accuracy: 0.6623\n",
      "Epoch 667/1000\n",
      "178/178 [==============================] - 0s 108us/step - loss: 0.1342 - accuracy: 0.9719 - val_loss: 1.1399 - val_accuracy: 0.6623\n",
      "Epoch 668/1000\n",
      "178/178 [==============================] - 0s 84us/step - loss: 0.1340 - accuracy: 0.9719 - val_loss: 1.1409 - val_accuracy: 0.6623\n",
      "Epoch 669/1000\n",
      "178/178 [==============================] - 0s 84us/step - loss: 0.1340 - accuracy: 0.9719 - val_loss: 1.1420 - val_accuracy: 0.6623\n",
      "Epoch 670/1000\n",
      "178/178 [==============================] - 0s 81us/step - loss: 0.1337 - accuracy: 0.9719 - val_loss: 1.1406 - val_accuracy: 0.6623\n",
      "Epoch 671/1000\n",
      "178/178 [==============================] - 0s 92us/step - loss: 0.1339 - accuracy: 0.9719 - val_loss: 1.1427 - val_accuracy: 0.6623\n",
      "Epoch 672/1000\n",
      "178/178 [==============================] - 0s 92us/step - loss: 0.1337 - accuracy: 0.9719 - val_loss: 1.1428 - val_accuracy: 0.6623\n",
      "Epoch 673/1000\n",
      "178/178 [==============================] - 0s 93us/step - loss: 0.1346 - accuracy: 0.9663 - val_loss: 1.1409 - val_accuracy: 0.6623\n",
      "Epoch 674/1000\n",
      "178/178 [==============================] - 0s 80us/step - loss: 0.1345 - accuracy: 0.9719 - val_loss: 1.1410 - val_accuracy: 0.6623\n",
      "Epoch 675/1000\n",
      "178/178 [==============================] - 0s 84us/step - loss: 0.1338 - accuracy: 0.9719 - val_loss: 1.1422 - val_accuracy: 0.6623\n",
      "Epoch 676/1000\n",
      "178/178 [==============================] - 0s 87us/step - loss: 0.1333 - accuracy: 0.9719 - val_loss: 1.1436 - val_accuracy: 0.6623\n",
      "Epoch 677/1000\n",
      "178/178 [==============================] - 0s 87us/step - loss: 0.1333 - accuracy: 0.9719 - val_loss: 1.1436 - val_accuracy: 0.6623\n",
      "Epoch 678/1000\n",
      "178/178 [==============================] - 0s 89us/step - loss: 0.1337 - accuracy: 0.9719 - val_loss: 1.1455 - val_accuracy: 0.6623\n",
      "Epoch 679/1000\n",
      "178/178 [==============================] - 0s 90us/step - loss: 0.1329 - accuracy: 0.9719 - val_loss: 1.1456 - val_accuracy: 0.6623\n",
      "Epoch 680/1000\n",
      "178/178 [==============================] - 0s 95us/step - loss: 0.1323 - accuracy: 0.9719 - val_loss: 1.1484 - val_accuracy: 0.6623\n",
      "Epoch 681/1000\n",
      "178/178 [==============================] - 0s 88us/step - loss: 0.1327 - accuracy: 0.9719 - val_loss: 1.1462 - val_accuracy: 0.6623\n",
      "Epoch 682/1000\n",
      "178/178 [==============================] - 0s 95us/step - loss: 0.1326 - accuracy: 0.9719 - val_loss: 1.1490 - val_accuracy: 0.6623\n",
      "Epoch 683/1000\n",
      "178/178 [==============================] - 0s 94us/step - loss: 0.1321 - accuracy: 0.9719 - val_loss: 1.1502 - val_accuracy: 0.6623\n",
      "Epoch 684/1000\n",
      "178/178 [==============================] - 0s 100us/step - loss: 0.1324 - accuracy: 0.9719 - val_loss: 1.1495 - val_accuracy: 0.6623\n",
      "Epoch 685/1000\n",
      "178/178 [==============================] - 0s 111us/step - loss: 0.1318 - accuracy: 0.9719 - val_loss: 1.1515 - val_accuracy: 0.6623\n",
      "Epoch 686/1000\n",
      "178/178 [==============================] - 0s 93us/step - loss: 0.1321 - accuracy: 0.9719 - val_loss: 1.1534 - val_accuracy: 0.6623\n",
      "Epoch 687/1000\n",
      "178/178 [==============================] - 0s 91us/step - loss: 0.1319 - accuracy: 0.9719 - val_loss: 1.1542 - val_accuracy: 0.6623\n",
      "Epoch 688/1000\n",
      "178/178 [==============================] - 0s 103us/step - loss: 0.1318 - accuracy: 0.9719 - val_loss: 1.1568 - val_accuracy: 0.6623\n",
      "Epoch 689/1000\n",
      "178/178 [==============================] - 0s 105us/step - loss: 0.1319 - accuracy: 0.9719 - val_loss: 1.1574 - val_accuracy: 0.6623\n",
      "Epoch 690/1000\n",
      "178/178 [==============================] - 0s 82us/step - loss: 0.1315 - accuracy: 0.9719 - val_loss: 1.1559 - val_accuracy: 0.6623\n",
      "Epoch 691/1000\n",
      "178/178 [==============================] - 0s 88us/step - loss: 0.1312 - accuracy: 0.9719 - val_loss: 1.1550 - val_accuracy: 0.6623\n",
      "Epoch 692/1000\n",
      "178/178 [==============================] - 0s 102us/step - loss: 0.1314 - accuracy: 0.9719 - val_loss: 1.1565 - val_accuracy: 0.6623\n",
      "Epoch 693/1000\n",
      "178/178 [==============================] - 0s 176us/step - loss: 0.1309 - accuracy: 0.9719 - val_loss: 1.1562 - val_accuracy: 0.6623\n",
      "Epoch 694/1000\n",
      "178/178 [==============================] - 0s 162us/step - loss: 0.1309 - accuracy: 0.9719 - val_loss: 1.1567 - val_accuracy: 0.6623\n",
      "Epoch 695/1000\n",
      "178/178 [==============================] - 0s 197us/step - loss: 0.1310 - accuracy: 0.9719 - val_loss: 1.1573 - val_accuracy: 0.6623\n",
      "Epoch 696/1000\n",
      "178/178 [==============================] - 0s 180us/step - loss: 0.1310 - accuracy: 0.9719 - val_loss: 1.1593 - val_accuracy: 0.6623\n",
      "Epoch 697/1000\n",
      "178/178 [==============================] - 0s 214us/step - loss: 0.1305 - accuracy: 0.9719 - val_loss: 1.1597 - val_accuracy: 0.6623\n",
      "Epoch 698/1000\n",
      "178/178 [==============================] - 0s 192us/step - loss: 0.1304 - accuracy: 0.9719 - val_loss: 1.1614 - val_accuracy: 0.6623\n",
      "Epoch 699/1000\n",
      "178/178 [==============================] - 0s 173us/step - loss: 0.1303 - accuracy: 0.9719 - val_loss: 1.1623 - val_accuracy: 0.6623\n",
      "Epoch 700/1000\n",
      "178/178 [==============================] - 0s 206us/step - loss: 0.1302 - accuracy: 0.9719 - val_loss: 1.1612 - val_accuracy: 0.6623\n",
      "Epoch 701/1000\n",
      "178/178 [==============================] - 0s 184us/step - loss: 0.1302 - accuracy: 0.9719 - val_loss: 1.1624 - val_accuracy: 0.6623\n",
      "Epoch 702/1000\n",
      "178/178 [==============================] - 0s 145us/step - loss: 0.1298 - accuracy: 0.9719 - val_loss: 1.1615 - val_accuracy: 0.6623\n",
      "Epoch 703/1000\n",
      "178/178 [==============================] - 0s 169us/step - loss: 0.1297 - accuracy: 0.9719 - val_loss: 1.1619 - val_accuracy: 0.6623\n",
      "Epoch 704/1000\n",
      "178/178 [==============================] - 0s 160us/step - loss: 0.1297 - accuracy: 0.9719 - val_loss: 1.1608 - val_accuracy: 0.6623\n",
      "Epoch 705/1000\n",
      "178/178 [==============================] - 0s 207us/step - loss: 0.1300 - accuracy: 0.9719 - val_loss: 1.1654 - val_accuracy: 0.6623\n",
      "Epoch 706/1000\n",
      "178/178 [==============================] - 0s 216us/step - loss: 0.1297 - accuracy: 0.9719 - val_loss: 1.1663 - val_accuracy: 0.6623\n",
      "Epoch 707/1000\n",
      "178/178 [==============================] - 0s 173us/step - loss: 0.1292 - accuracy: 0.9719 - val_loss: 1.1661 - val_accuracy: 0.6623\n",
      "Epoch 708/1000\n",
      "178/178 [==============================] - 0s 174us/step - loss: 0.1293 - accuracy: 0.9719 - val_loss: 1.1676 - val_accuracy: 0.6623\n",
      "Epoch 709/1000\n",
      "178/178 [==============================] - 0s 122us/step - loss: 0.1291 - accuracy: 0.9719 - val_loss: 1.1670 - val_accuracy: 0.6623\n",
      "Epoch 710/1000\n",
      "178/178 [==============================] - 0s 159us/step - loss: 0.1294 - accuracy: 0.9719 - val_loss: 1.1671 - val_accuracy: 0.6623\n",
      "Epoch 711/1000\n",
      "178/178 [==============================] - 0s 188us/step - loss: 0.1291 - accuracy: 0.9719 - val_loss: 1.1699 - val_accuracy: 0.6623\n",
      "Epoch 712/1000\n",
      "178/178 [==============================] - 0s 106us/step - loss: 0.1292 - accuracy: 0.9719 - val_loss: 1.1692 - val_accuracy: 0.6623\n",
      "Epoch 713/1000\n",
      "178/178 [==============================] - 0s 142us/step - loss: 0.1291 - accuracy: 0.9719 - val_loss: 1.1709 - val_accuracy: 0.6623\n",
      "Epoch 714/1000\n",
      "178/178 [==============================] - 0s 172us/step - loss: 0.1290 - accuracy: 0.9719 - val_loss: 1.1720 - val_accuracy: 0.6623\n",
      "Epoch 715/1000\n",
      "178/178 [==============================] - 0s 153us/step - loss: 0.1290 - accuracy: 0.9719 - val_loss: 1.1728 - val_accuracy: 0.6623\n",
      "Epoch 716/1000\n",
      "178/178 [==============================] - 0s 116us/step - loss: 0.1284 - accuracy: 0.9719 - val_loss: 1.1731 - val_accuracy: 0.6623\n",
      "Epoch 717/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 151us/step - loss: 0.1289 - accuracy: 0.9719 - val_loss: 1.1753 - val_accuracy: 0.6623\n",
      "Epoch 718/1000\n",
      "178/178 [==============================] - 0s 106us/step - loss: 0.1284 - accuracy: 0.9719 - val_loss: 1.1768 - val_accuracy: 0.6623\n",
      "Epoch 719/1000\n",
      "178/178 [==============================] - 0s 98us/step - loss: 0.1286 - accuracy: 0.9719 - val_loss: 1.1782 - val_accuracy: 0.6623\n",
      "Epoch 720/1000\n",
      "178/178 [==============================] - 0s 98us/step - loss: 0.1284 - accuracy: 0.9719 - val_loss: 1.1774 - val_accuracy: 0.6623\n",
      "Epoch 721/1000\n",
      "178/178 [==============================] - 0s 124us/step - loss: 0.1277 - accuracy: 0.9719 - val_loss: 1.1766 - val_accuracy: 0.6623\n",
      "Epoch 722/1000\n",
      "178/178 [==============================] - 0s 114us/step - loss: 0.1280 - accuracy: 0.9719 - val_loss: 1.1785 - val_accuracy: 0.6623\n",
      "Epoch 723/1000\n",
      "178/178 [==============================] - 0s 115us/step - loss: 0.1277 - accuracy: 0.9719 - val_loss: 1.1777 - val_accuracy: 0.6623\n",
      "Epoch 724/1000\n",
      "178/178 [==============================] - 0s 115us/step - loss: 0.1279 - accuracy: 0.9719 - val_loss: 1.1785 - val_accuracy: 0.6623\n",
      "Epoch 725/1000\n",
      "178/178 [==============================] - 0s 98us/step - loss: 0.1278 - accuracy: 0.9719 - val_loss: 1.1803 - val_accuracy: 0.6623\n",
      "Epoch 726/1000\n",
      "178/178 [==============================] - 0s 116us/step - loss: 0.1275 - accuracy: 0.9719 - val_loss: 1.1807 - val_accuracy: 0.6623\n",
      "Epoch 727/1000\n",
      "178/178 [==============================] - 0s 99us/step - loss: 0.1278 - accuracy: 0.9719 - val_loss: 1.1812 - val_accuracy: 0.6623\n",
      "Epoch 728/1000\n",
      "178/178 [==============================] - 0s 102us/step - loss: 0.1272 - accuracy: 0.9719 - val_loss: 1.1813 - val_accuracy: 0.6623\n",
      "Epoch 729/1000\n",
      "178/178 [==============================] - 0s 100us/step - loss: 0.1269 - accuracy: 0.9719 - val_loss: 1.1821 - val_accuracy: 0.6623\n",
      "Epoch 730/1000\n",
      "178/178 [==============================] - 0s 92us/step - loss: 0.1270 - accuracy: 0.9719 - val_loss: 1.1843 - val_accuracy: 0.6623\n",
      "Epoch 731/1000\n",
      "178/178 [==============================] - 0s 88us/step - loss: 0.1272 - accuracy: 0.9719 - val_loss: 1.1860 - val_accuracy: 0.6623\n",
      "Epoch 732/1000\n",
      "178/178 [==============================] - 0s 84us/step - loss: 0.1265 - accuracy: 0.9719 - val_loss: 1.1856 - val_accuracy: 0.6623\n",
      "Epoch 733/1000\n",
      "178/178 [==============================] - 0s 93us/step - loss: 0.1265 - accuracy: 0.9719 - val_loss: 1.1879 - val_accuracy: 0.6623\n",
      "Epoch 734/1000\n",
      "178/178 [==============================] - 0s 80us/step - loss: 0.1265 - accuracy: 0.9719 - val_loss: 1.1879 - val_accuracy: 0.6623\n",
      "Epoch 735/1000\n",
      "178/178 [==============================] - 0s 80us/step - loss: 0.1263 - accuracy: 0.9719 - val_loss: 1.1889 - val_accuracy: 0.6623\n",
      "Epoch 736/1000\n",
      "178/178 [==============================] - 0s 84us/step - loss: 0.1264 - accuracy: 0.9719 - val_loss: 1.1880 - val_accuracy: 0.6623\n",
      "Epoch 737/1000\n",
      "178/178 [==============================] - 0s 80us/step - loss: 0.1264 - accuracy: 0.9719 - val_loss: 1.1881 - val_accuracy: 0.6623\n",
      "Epoch 738/1000\n",
      "178/178 [==============================] - 0s 96us/step - loss: 0.1261 - accuracy: 0.9719 - val_loss: 1.1894 - val_accuracy: 0.6623\n",
      "Epoch 739/1000\n",
      "178/178 [==============================] - 0s 89us/step - loss: 0.1266 - accuracy: 0.9719 - val_loss: 1.1922 - val_accuracy: 0.6623\n",
      "Epoch 740/1000\n",
      "178/178 [==============================] - 0s 87us/step - loss: 0.1255 - accuracy: 0.9719 - val_loss: 1.1932 - val_accuracy: 0.6623\n",
      "Epoch 741/1000\n",
      "178/178 [==============================] - 0s 85us/step - loss: 0.1258 - accuracy: 0.9719 - val_loss: 1.1932 - val_accuracy: 0.6623\n",
      "Epoch 742/1000\n",
      "178/178 [==============================] - 0s 90us/step - loss: 0.1261 - accuracy: 0.9719 - val_loss: 1.1941 - val_accuracy: 0.6623\n",
      "Epoch 743/1000\n",
      "178/178 [==============================] - 0s 92us/step - loss: 0.1259 - accuracy: 0.9719 - val_loss: 1.1952 - val_accuracy: 0.6623\n",
      "Epoch 744/1000\n",
      "178/178 [==============================] - 0s 90us/step - loss: 0.1252 - accuracy: 0.9719 - val_loss: 1.1957 - val_accuracy: 0.6623\n",
      "Epoch 745/1000\n",
      "178/178 [==============================] - 0s 87us/step - loss: 0.1259 - accuracy: 0.9719 - val_loss: 1.1950 - val_accuracy: 0.6623\n",
      "Epoch 746/1000\n",
      "178/178 [==============================] - 0s 92us/step - loss: 0.1252 - accuracy: 0.9719 - val_loss: 1.1954 - val_accuracy: 0.6623\n",
      "Epoch 747/1000\n",
      "178/178 [==============================] - 0s 92us/step - loss: 0.1251 - accuracy: 0.9719 - val_loss: 1.1954 - val_accuracy: 0.6623\n",
      "Epoch 748/1000\n",
      "178/178 [==============================] - 0s 101us/step - loss: 0.1250 - accuracy: 0.9719 - val_loss: 1.1983 - val_accuracy: 0.6623\n",
      "Epoch 749/1000\n",
      "178/178 [==============================] - 0s 103us/step - loss: 0.1249 - accuracy: 0.9719 - val_loss: 1.1965 - val_accuracy: 0.6623\n",
      "Epoch 750/1000\n",
      "178/178 [==============================] - 0s 107us/step - loss: 0.1249 - accuracy: 0.9719 - val_loss: 1.1987 - val_accuracy: 0.6623\n",
      "Epoch 751/1000\n",
      "178/178 [==============================] - 0s 84us/step - loss: 0.1249 - accuracy: 0.9719 - val_loss: 1.1993 - val_accuracy: 0.6623\n",
      "Epoch 752/1000\n",
      "178/178 [==============================] - 0s 109us/step - loss: 0.1250 - accuracy: 0.9719 - val_loss: 1.2008 - val_accuracy: 0.6623\n",
      "Epoch 753/1000\n",
      "178/178 [==============================] - 0s 123us/step - loss: 0.1245 - accuracy: 0.9719 - val_loss: 1.2002 - val_accuracy: 0.6623\n",
      "Epoch 754/1000\n",
      "178/178 [==============================] - 0s 171us/step - loss: 0.1243 - accuracy: 0.9719 - val_loss: 1.2008 - val_accuracy: 0.6623\n",
      "Epoch 755/1000\n",
      "178/178 [==============================] - 0s 198us/step - loss: 0.1247 - accuracy: 0.9719 - val_loss: 1.2022 - val_accuracy: 0.6623\n",
      "Epoch 756/1000\n",
      "178/178 [==============================] - 0s 184us/step - loss: 0.1244 - accuracy: 0.9719 - val_loss: 1.2028 - val_accuracy: 0.6623\n",
      "Epoch 757/1000\n",
      "178/178 [==============================] - 0s 149us/step - loss: 0.1242 - accuracy: 0.9719 - val_loss: 1.2038 - val_accuracy: 0.6623\n",
      "Epoch 758/1000\n",
      "178/178 [==============================] - 0s 109us/step - loss: 0.1241 - accuracy: 0.9719 - val_loss: 1.2047 - val_accuracy: 0.6623\n",
      "Epoch 759/1000\n",
      "178/178 [==============================] - 0s 96us/step - loss: 0.1242 - accuracy: 0.9719 - val_loss: 1.2068 - val_accuracy: 0.6623\n",
      "Epoch 760/1000\n",
      "178/178 [==============================] - 0s 100us/step - loss: 0.1238 - accuracy: 0.9719 - val_loss: 1.2055 - val_accuracy: 0.6623\n",
      "Epoch 761/1000\n",
      "178/178 [==============================] - 0s 103us/step - loss: 0.1237 - accuracy: 0.9719 - val_loss: 1.2061 - val_accuracy: 0.6623\n",
      "Epoch 762/1000\n",
      "178/178 [==============================] - 0s 76us/step - loss: 0.1235 - accuracy: 0.9719 - val_loss: 1.2075 - val_accuracy: 0.6623\n",
      "Epoch 763/1000\n",
      "178/178 [==============================] - 0s 89us/step - loss: 0.1234 - accuracy: 0.9719 - val_loss: 1.2076 - val_accuracy: 0.6623\n",
      "Epoch 764/1000\n",
      "178/178 [==============================] - 0s 72us/step - loss: 0.1232 - accuracy: 0.9719 - val_loss: 1.2093 - val_accuracy: 0.6623\n",
      "Epoch 765/1000\n",
      "178/178 [==============================] - 0s 79us/step - loss: 0.1238 - accuracy: 0.9719 - val_loss: 1.2107 - val_accuracy: 0.6623\n",
      "Epoch 766/1000\n",
      "178/178 [==============================] - 0s 74us/step - loss: 0.1233 - accuracy: 0.9719 - val_loss: 1.2090 - val_accuracy: 0.6623\n",
      "Epoch 767/1000\n",
      "178/178 [==============================] - 0s 76us/step - loss: 0.1233 - accuracy: 0.9719 - val_loss: 1.2107 - val_accuracy: 0.6623\n",
      "Epoch 768/1000\n",
      "178/178 [==============================] - 0s 78us/step - loss: 0.1230 - accuracy: 0.9719 - val_loss: 1.2107 - val_accuracy: 0.6623\n",
      "Epoch 769/1000\n",
      "178/178 [==============================] - 0s 79us/step - loss: 0.1228 - accuracy: 0.9719 - val_loss: 1.2108 - val_accuracy: 0.6623\n",
      "Epoch 770/1000\n",
      "178/178 [==============================] - 0s 82us/step - loss: 0.1228 - accuracy: 0.9719 - val_loss: 1.2125 - val_accuracy: 0.6623\n",
      "Epoch 771/1000\n",
      "178/178 [==============================] - 0s 109us/step - loss: 0.1232 - accuracy: 0.9719 - val_loss: 1.2127 - val_accuracy: 0.6623\n",
      "Epoch 772/1000\n",
      "178/178 [==============================] - 0s 101us/step - loss: 0.1225 - accuracy: 0.9719 - val_loss: 1.2148 - val_accuracy: 0.6623\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 773/1000\n",
      "178/178 [==============================] - 0s 96us/step - loss: 0.1225 - accuracy: 0.9719 - val_loss: 1.2160 - val_accuracy: 0.6623\n",
      "Epoch 774/1000\n",
      "178/178 [==============================] - 0s 97us/step - loss: 0.1224 - accuracy: 0.9719 - val_loss: 1.2157 - val_accuracy: 0.6623\n",
      "Epoch 775/1000\n",
      "178/178 [==============================] - 0s 102us/step - loss: 0.1224 - accuracy: 0.9719 - val_loss: 1.2155 - val_accuracy: 0.6623\n",
      "Epoch 776/1000\n",
      "178/178 [==============================] - 0s 121us/step - loss: 0.1221 - accuracy: 0.9719 - val_loss: 1.2163 - val_accuracy: 0.6623\n",
      "Epoch 777/1000\n",
      "178/178 [==============================] - 0s 85us/step - loss: 0.1222 - accuracy: 0.9719 - val_loss: 1.2163 - val_accuracy: 0.6623\n",
      "Epoch 778/1000\n",
      "178/178 [==============================] - 0s 85us/step - loss: 0.1227 - accuracy: 0.9719 - val_loss: 1.2161 - val_accuracy: 0.6623\n",
      "Epoch 779/1000\n",
      "178/178 [==============================] - 0s 82us/step - loss: 0.1219 - accuracy: 0.9719 - val_loss: 1.2167 - val_accuracy: 0.6623\n",
      "Epoch 780/1000\n",
      "178/178 [==============================] - 0s 84us/step - loss: 0.1219 - accuracy: 0.9719 - val_loss: 1.2185 - val_accuracy: 0.6623\n",
      "Epoch 781/1000\n",
      "178/178 [==============================] - 0s 84us/step - loss: 0.1218 - accuracy: 0.9719 - val_loss: 1.2207 - val_accuracy: 0.6623\n",
      "Epoch 782/1000\n",
      "178/178 [==============================] - 0s 83us/step - loss: 0.1218 - accuracy: 0.9719 - val_loss: 1.2224 - val_accuracy: 0.6623\n",
      "Epoch 783/1000\n",
      "178/178 [==============================] - 0s 83us/step - loss: 0.1216 - accuracy: 0.9719 - val_loss: 1.2231 - val_accuracy: 0.6623\n",
      "Epoch 784/1000\n",
      "178/178 [==============================] - 0s 102us/step - loss: 0.1221 - accuracy: 0.9719 - val_loss: 1.2216 - val_accuracy: 0.6623\n",
      "Epoch 785/1000\n",
      "178/178 [==============================] - 0s 97us/step - loss: 0.1213 - accuracy: 0.9719 - val_loss: 1.2232 - val_accuracy: 0.6623\n",
      "Epoch 786/1000\n",
      "178/178 [==============================] - 0s 92us/step - loss: 0.1218 - accuracy: 0.9719 - val_loss: 1.2231 - val_accuracy: 0.6623\n",
      "Epoch 787/1000\n",
      "178/178 [==============================] - 0s 109us/step - loss: 0.1211 - accuracy: 0.9719 - val_loss: 1.2230 - val_accuracy: 0.6623\n",
      "Epoch 788/1000\n",
      "178/178 [==============================] - 0s 104us/step - loss: 0.1211 - accuracy: 0.9719 - val_loss: 1.2218 - val_accuracy: 0.6623\n",
      "Epoch 789/1000\n",
      "178/178 [==============================] - 0s 118us/step - loss: 0.1207 - accuracy: 0.9719 - val_loss: 1.2240 - val_accuracy: 0.6623\n",
      "Epoch 790/1000\n",
      "178/178 [==============================] - 0s 161us/step - loss: 0.1212 - accuracy: 0.9719 - val_loss: 1.2254 - val_accuracy: 0.6623\n",
      "Epoch 791/1000\n",
      "178/178 [==============================] - 0s 164us/step - loss: 0.1210 - accuracy: 0.9719 - val_loss: 1.2276 - val_accuracy: 0.6623\n",
      "Epoch 792/1000\n",
      "178/178 [==============================] - 0s 182us/step - loss: 0.1212 - accuracy: 0.9719 - val_loss: 1.2278 - val_accuracy: 0.6623\n",
      "Epoch 793/1000\n",
      "178/178 [==============================] - 0s 158us/step - loss: 0.1207 - accuracy: 0.9719 - val_loss: 1.2279 - val_accuracy: 0.6623\n",
      "Epoch 794/1000\n",
      "178/178 [==============================] - 0s 257us/step - loss: 0.1206 - accuracy: 0.9719 - val_loss: 1.2263 - val_accuracy: 0.6623\n",
      "Epoch 795/1000\n",
      "178/178 [==============================] - 0s 277us/step - loss: 0.1210 - accuracy: 0.9719 - val_loss: 1.2280 - val_accuracy: 0.6623\n",
      "Epoch 796/1000\n",
      "178/178 [==============================] - 0s 197us/step - loss: 0.1207 - accuracy: 0.9719 - val_loss: 1.2268 - val_accuracy: 0.6623\n",
      "Epoch 797/1000\n",
      "178/178 [==============================] - 0s 147us/step - loss: 0.1202 - accuracy: 0.9719 - val_loss: 1.2267 - val_accuracy: 0.6623\n",
      "Epoch 798/1000\n",
      "178/178 [==============================] - 0s 183us/step - loss: 0.1211 - accuracy: 0.9719 - val_loss: 1.2288 - val_accuracy: 0.6623\n",
      "Epoch 799/1000\n",
      "178/178 [==============================] - 0s 147us/step - loss: 0.1202 - accuracy: 0.9719 - val_loss: 1.2316 - val_accuracy: 0.6623\n",
      "Epoch 800/1000\n",
      "178/178 [==============================] - 0s 160us/step - loss: 0.1200 - accuracy: 0.9719 - val_loss: 1.2306 - val_accuracy: 0.6623\n",
      "Epoch 801/1000\n",
      "178/178 [==============================] - 0s 160us/step - loss: 0.1199 - accuracy: 0.9719 - val_loss: 1.2304 - val_accuracy: 0.6623\n",
      "Epoch 802/1000\n",
      "178/178 [==============================] - 0s 164us/step - loss: 0.1199 - accuracy: 0.9719 - val_loss: 1.2312 - val_accuracy: 0.6623\n",
      "Epoch 803/1000\n",
      "178/178 [==============================] - 0s 109us/step - loss: 0.1196 - accuracy: 0.9719 - val_loss: 1.2330 - val_accuracy: 0.6623\n",
      "Epoch 804/1000\n",
      "178/178 [==============================] - 0s 218us/step - loss: 0.1195 - accuracy: 0.9719 - val_loss: 1.2341 - val_accuracy: 0.6623\n",
      "Epoch 805/1000\n",
      "178/178 [==============================] - 0s 155us/step - loss: 0.1198 - accuracy: 0.9719 - val_loss: 1.2326 - val_accuracy: 0.6494\n",
      "Epoch 806/1000\n",
      "178/178 [==============================] - 0s 167us/step - loss: 0.1196 - accuracy: 0.9719 - val_loss: 1.2335 - val_accuracy: 0.6494\n",
      "Epoch 807/1000\n",
      "178/178 [==============================] - 0s 176us/step - loss: 0.1197 - accuracy: 0.9719 - val_loss: 1.2333 - val_accuracy: 0.6494\n",
      "Epoch 808/1000\n",
      "178/178 [==============================] - 0s 115us/step - loss: 0.1196 - accuracy: 0.9719 - val_loss: 1.2333 - val_accuracy: 0.6494\n",
      "Epoch 809/1000\n",
      "178/178 [==============================] - 0s 103us/step - loss: 0.1196 - accuracy: 0.9775 - val_loss: 1.2378 - val_accuracy: 0.6623\n",
      "Epoch 810/1000\n",
      "178/178 [==============================] - 0s 96us/step - loss: 0.1190 - accuracy: 0.9719 - val_loss: 1.2386 - val_accuracy: 0.6623\n",
      "Epoch 811/1000\n",
      "178/178 [==============================] - 0s 92us/step - loss: 0.1191 - accuracy: 0.9719 - val_loss: 1.2388 - val_accuracy: 0.6623\n",
      "Epoch 812/1000\n",
      "178/178 [==============================] - 0s 90us/step - loss: 0.1191 - accuracy: 0.9719 - val_loss: 1.2419 - val_accuracy: 0.6623\n",
      "Epoch 813/1000\n",
      "178/178 [==============================] - 0s 96us/step - loss: 0.1191 - accuracy: 0.9719 - val_loss: 1.2457 - val_accuracy: 0.6623\n",
      "Epoch 814/1000\n",
      "178/178 [==============================] - 0s 101us/step - loss: 0.1191 - accuracy: 0.9719 - val_loss: 1.2449 - val_accuracy: 0.6623\n",
      "Epoch 815/1000\n",
      "178/178 [==============================] - 0s 108us/step - loss: 0.1184 - accuracy: 0.9719 - val_loss: 1.2477 - val_accuracy: 0.6623\n",
      "Epoch 816/1000\n",
      "178/178 [==============================] - 0s 92us/step - loss: 0.1187 - accuracy: 0.9719 - val_loss: 1.2492 - val_accuracy: 0.6623\n",
      "Epoch 817/1000\n",
      "178/178 [==============================] - 0s 92us/step - loss: 0.1183 - accuracy: 0.9719 - val_loss: 1.2468 - val_accuracy: 0.6623\n",
      "Epoch 818/1000\n",
      "178/178 [==============================] - 0s 138us/step - loss: 0.1180 - accuracy: 0.9719 - val_loss: 1.2484 - val_accuracy: 0.6623\n",
      "Epoch 819/1000\n",
      "178/178 [==============================] - 0s 116us/step - loss: 0.1184 - accuracy: 0.9719 - val_loss: 1.2495 - val_accuracy: 0.6623\n",
      "Epoch 820/1000\n",
      "178/178 [==============================] - 0s 111us/step - loss: 0.1181 - accuracy: 0.9719 - val_loss: 1.2500 - val_accuracy: 0.6623\n",
      "Epoch 821/1000\n",
      "178/178 [==============================] - 0s 111us/step - loss: 0.1180 - accuracy: 0.9719 - val_loss: 1.2516 - val_accuracy: 0.6623\n",
      "Epoch 822/1000\n",
      "178/178 [==============================] - 0s 147us/step - loss: 0.1181 - accuracy: 0.9719 - val_loss: 1.2499 - val_accuracy: 0.6623\n",
      "Epoch 823/1000\n",
      "178/178 [==============================] - 0s 265us/step - loss: 0.1181 - accuracy: 0.9719 - val_loss: 1.2505 - val_accuracy: 0.6623\n",
      "Epoch 824/1000\n",
      "178/178 [==============================] - 0s 243us/step - loss: 0.1176 - accuracy: 0.9719 - val_loss: 1.2518 - val_accuracy: 0.6623\n",
      "Epoch 825/1000\n",
      "178/178 [==============================] - 0s 368us/step - loss: 0.1183 - accuracy: 0.9719 - val_loss: 1.2486 - val_accuracy: 0.6623\n",
      "Epoch 826/1000\n",
      "178/178 [==============================] - 0s 253us/step - loss: 0.1178 - accuracy: 0.9719 - val_loss: 1.2484 - val_accuracy: 0.6623\n",
      "Epoch 827/1000\n",
      "178/178 [==============================] - 0s 114us/step - loss: 0.1174 - accuracy: 0.9719 - val_loss: 1.2513 - val_accuracy: 0.6623\n",
      "Epoch 828/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 103us/step - loss: 0.1175 - accuracy: 0.9719 - val_loss: 1.2531 - val_accuracy: 0.6623\n",
      "Epoch 829/1000\n",
      "178/178 [==============================] - 0s 98us/step - loss: 0.1179 - accuracy: 0.9719 - val_loss: 1.2548 - val_accuracy: 0.6623\n",
      "Epoch 830/1000\n",
      "178/178 [==============================] - 0s 90us/step - loss: 0.1170 - accuracy: 0.9719 - val_loss: 1.2539 - val_accuracy: 0.6623\n",
      "Epoch 831/1000\n",
      "178/178 [==============================] - 0s 104us/step - loss: 0.1170 - accuracy: 0.9719 - val_loss: 1.2527 - val_accuracy: 0.6623\n",
      "Epoch 832/1000\n",
      "178/178 [==============================] - 0s 101us/step - loss: 0.1174 - accuracy: 0.9719 - val_loss: 1.2547 - val_accuracy: 0.6623\n",
      "Epoch 833/1000\n",
      "178/178 [==============================] - 0s 101us/step - loss: 0.1168 - accuracy: 0.9719 - val_loss: 1.2568 - val_accuracy: 0.6623\n",
      "Epoch 834/1000\n",
      "178/178 [==============================] - 0s 91us/step - loss: 0.1171 - accuracy: 0.9719 - val_loss: 1.2566 - val_accuracy: 0.6623\n",
      "Epoch 835/1000\n",
      "178/178 [==============================] - 0s 108us/step - loss: 0.1167 - accuracy: 0.9719 - val_loss: 1.2583 - val_accuracy: 0.6623\n",
      "Epoch 836/1000\n",
      "178/178 [==============================] - 0s 121us/step - loss: 0.1172 - accuracy: 0.9719 - val_loss: 1.2616 - val_accuracy: 0.6623\n",
      "Epoch 837/1000\n",
      "178/178 [==============================] - 0s 131us/step - loss: 0.1167 - accuracy: 0.9719 - val_loss: 1.2619 - val_accuracy: 0.6623\n",
      "Epoch 838/1000\n",
      "178/178 [==============================] - 0s 126us/step - loss: 0.1167 - accuracy: 0.9719 - val_loss: 1.2603 - val_accuracy: 0.6623\n",
      "Epoch 839/1000\n",
      "178/178 [==============================] - 0s 128us/step - loss: 0.1163 - accuracy: 0.9719 - val_loss: 1.2617 - val_accuracy: 0.6623\n",
      "Epoch 840/1000\n",
      "178/178 [==============================] - 0s 165us/step - loss: 0.1161 - accuracy: 0.9719 - val_loss: 1.2632 - val_accuracy: 0.6623\n",
      "Epoch 841/1000\n",
      "178/178 [==============================] - 0s 136us/step - loss: 0.1168 - accuracy: 0.9719 - val_loss: 1.2653 - val_accuracy: 0.6623\n",
      "Epoch 842/1000\n",
      "178/178 [==============================] - 0s 127us/step - loss: 0.1162 - accuracy: 0.9719 - val_loss: 1.2661 - val_accuracy: 0.6623\n",
      "Epoch 843/1000\n",
      "178/178 [==============================] - 0s 136us/step - loss: 0.1160 - accuracy: 0.9719 - val_loss: 1.2663 - val_accuracy: 0.6623\n",
      "Epoch 844/1000\n",
      "178/178 [==============================] - 0s 101us/step - loss: 0.1159 - accuracy: 0.9719 - val_loss: 1.2672 - val_accuracy: 0.6623\n",
      "Epoch 845/1000\n",
      "178/178 [==============================] - 0s 101us/step - loss: 0.1163 - accuracy: 0.9719 - val_loss: 1.2685 - val_accuracy: 0.6623\n",
      "Epoch 846/1000\n",
      "178/178 [==============================] - 0s 127us/step - loss: 0.1168 - accuracy: 0.9719 - val_loss: 1.2667 - val_accuracy: 0.6623\n",
      "Epoch 847/1000\n",
      "178/178 [==============================] - 0s 98us/step - loss: 0.1158 - accuracy: 0.9719 - val_loss: 1.2682 - val_accuracy: 0.6623\n",
      "Epoch 848/1000\n",
      "178/178 [==============================] - 0s 109us/step - loss: 0.1160 - accuracy: 0.9719 - val_loss: 1.2671 - val_accuracy: 0.6623\n",
      "Epoch 849/1000\n",
      "178/178 [==============================] - 0s 109us/step - loss: 0.1161 - accuracy: 0.9719 - val_loss: 1.2673 - val_accuracy: 0.6623\n",
      "Epoch 850/1000\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.1985 - accuracy: 0.93 - 0s 106us/step - loss: 0.1155 - accuracy: 0.9719 - val_loss: 1.2689 - val_accuracy: 0.6623\n",
      "Epoch 851/1000\n",
      "178/178 [==============================] - 0s 125us/step - loss: 0.1158 - accuracy: 0.9719 - val_loss: 1.2700 - val_accuracy: 0.6623\n",
      "Epoch 852/1000\n",
      "178/178 [==============================] - 0s 137us/step - loss: 0.1167 - accuracy: 0.9719 - val_loss: 1.2714 - val_accuracy: 0.6623\n",
      "Epoch 853/1000\n",
      "178/178 [==============================] - 0s 143us/step - loss: 0.1164 - accuracy: 0.9719 - val_loss: 1.2706 - val_accuracy: 0.6623\n",
      "Epoch 854/1000\n",
      "178/178 [==============================] - 0s 149us/step - loss: 0.1155 - accuracy: 0.9719 - val_loss: 1.2725 - val_accuracy: 0.6623\n",
      "Epoch 855/1000\n",
      "178/178 [==============================] - 0s 90us/step - loss: 0.1157 - accuracy: 0.9719 - val_loss: 1.2705 - val_accuracy: 0.6623\n",
      "Epoch 856/1000\n",
      "178/178 [==============================] - 0s 108us/step - loss: 0.1160 - accuracy: 0.9719 - val_loss: 1.2702 - val_accuracy: 0.6494\n",
      "Epoch 857/1000\n",
      "178/178 [==============================] - 0s 90us/step - loss: 0.1152 - accuracy: 0.9719 - val_loss: 1.2726 - val_accuracy: 0.6494\n",
      "Epoch 858/1000\n",
      "178/178 [==============================] - 0s 146us/step - loss: 0.1156 - accuracy: 0.9775 - val_loss: 1.2735 - val_accuracy: 0.6623\n",
      "Epoch 859/1000\n",
      "178/178 [==============================] - 0s 97us/step - loss: 0.1149 - accuracy: 0.9719 - val_loss: 1.2734 - val_accuracy: 0.6494\n",
      "Epoch 860/1000\n",
      "178/178 [==============================] - 0s 88us/step - loss: 0.1151 - accuracy: 0.9719 - val_loss: 1.2756 - val_accuracy: 0.6623\n",
      "Epoch 861/1000\n",
      "178/178 [==============================] - 0s 90us/step - loss: 0.1146 - accuracy: 0.9719 - val_loss: 1.2770 - val_accuracy: 0.6623\n",
      "Epoch 862/1000\n",
      "178/178 [==============================] - 0s 111us/step - loss: 0.1145 - accuracy: 0.9719 - val_loss: 1.2794 - val_accuracy: 0.6623\n",
      "Epoch 863/1000\n",
      "178/178 [==============================] - 0s 110us/step - loss: 0.1146 - accuracy: 0.9719 - val_loss: 1.2793 - val_accuracy: 0.6623\n",
      "Epoch 864/1000\n",
      "178/178 [==============================] - 0s 95us/step - loss: 0.1145 - accuracy: 0.9719 - val_loss: 1.2778 - val_accuracy: 0.6623\n",
      "Epoch 865/1000\n",
      "178/178 [==============================] - 0s 104us/step - loss: 0.1146 - accuracy: 0.9775 - val_loss: 1.2809 - val_accuracy: 0.6623\n",
      "Epoch 866/1000\n",
      "178/178 [==============================] - 0s 100us/step - loss: 0.1148 - accuracy: 0.9719 - val_loss: 1.2814 - val_accuracy: 0.6623\n",
      "Epoch 867/1000\n",
      "178/178 [==============================] - 0s 99us/step - loss: 0.1144 - accuracy: 0.9719 - val_loss: 1.2810 - val_accuracy: 0.6623\n",
      "Epoch 868/1000\n",
      "178/178 [==============================] - 0s 88us/step - loss: 0.1142 - accuracy: 0.9719 - val_loss: 1.2825 - val_accuracy: 0.6623\n",
      "Epoch 869/1000\n",
      "178/178 [==============================] - 0s 89us/step - loss: 0.1142 - accuracy: 0.9719 - val_loss: 1.2806 - val_accuracy: 0.6623\n",
      "Epoch 870/1000\n",
      "178/178 [==============================] - 0s 82us/step - loss: 0.1144 - accuracy: 0.9719 - val_loss: 1.2786 - val_accuracy: 0.6494\n",
      "Epoch 871/1000\n",
      "178/178 [==============================] - 0s 89us/step - loss: 0.1142 - accuracy: 0.9775 - val_loss: 1.2808 - val_accuracy: 0.6623\n",
      "Epoch 872/1000\n",
      "178/178 [==============================] - 0s 89us/step - loss: 0.1136 - accuracy: 0.9775 - val_loss: 1.2828 - val_accuracy: 0.6623\n",
      "Epoch 873/1000\n",
      "178/178 [==============================] - 0s 90us/step - loss: 0.1141 - accuracy: 0.9719 - val_loss: 1.2850 - val_accuracy: 0.6623\n",
      "Epoch 874/1000\n",
      "178/178 [==============================] - 0s 86us/step - loss: 0.1135 - accuracy: 0.9719 - val_loss: 1.2850 - val_accuracy: 0.6623\n",
      "Epoch 875/1000\n",
      "178/178 [==============================] - 0s 89us/step - loss: 0.1135 - accuracy: 0.9719 - val_loss: 1.2850 - val_accuracy: 0.6623\n",
      "Epoch 876/1000\n",
      "178/178 [==============================] - 0s 100us/step - loss: 0.1138 - accuracy: 0.9775 - val_loss: 1.2881 - val_accuracy: 0.6623\n",
      "Epoch 877/1000\n",
      "178/178 [==============================] - 0s 99us/step - loss: 0.1132 - accuracy: 0.9719 - val_loss: 1.2886 - val_accuracy: 0.6623\n",
      "Epoch 878/1000\n",
      "178/178 [==============================] - 0s 100us/step - loss: 0.1132 - accuracy: 0.9719 - val_loss: 1.2893 - val_accuracy: 0.6623\n",
      "Epoch 879/1000\n",
      "178/178 [==============================] - 0s 124us/step - loss: 0.1135 - accuracy: 0.9719 - val_loss: 1.2891 - val_accuracy: 0.6623\n",
      "Epoch 880/1000\n",
      "178/178 [==============================] - 0s 89us/step - loss: 0.1129 - accuracy: 0.9719 - val_loss: 1.2891 - val_accuracy: 0.6623\n",
      "Epoch 881/1000\n",
      "178/178 [==============================] - 0s 104us/step - loss: 0.1129 - accuracy: 0.9719 - val_loss: 1.2896 - val_accuracy: 0.6623\n",
      "Epoch 882/1000\n",
      "178/178 [==============================] - 0s 127us/step - loss: 0.1126 - accuracy: 0.9719 - val_loss: 1.2890 - val_accuracy: 0.6623\n",
      "Epoch 883/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 127us/step - loss: 0.1136 - accuracy: 0.9719 - val_loss: 1.2890 - val_accuracy: 0.6623\n",
      "Epoch 884/1000\n",
      "178/178 [==============================] - 0s 204us/step - loss: 0.1129 - accuracy: 0.9775 - val_loss: 1.2909 - val_accuracy: 0.6623\n",
      "Epoch 885/1000\n",
      "178/178 [==============================] - 0s 293us/step - loss: 0.1129 - accuracy: 0.9719 - val_loss: 1.2916 - val_accuracy: 0.6623\n",
      "Epoch 886/1000\n",
      "178/178 [==============================] - 0s 153us/step - loss: 0.1128 - accuracy: 0.9719 - val_loss: 1.2936 - val_accuracy: 0.6623\n",
      "Epoch 887/1000\n",
      "178/178 [==============================] - 0s 125us/step - loss: 0.1125 - accuracy: 0.9719 - val_loss: 1.2920 - val_accuracy: 0.6623\n",
      "Epoch 888/1000\n",
      "178/178 [==============================] - 0s 108us/step - loss: 0.1126 - accuracy: 0.9719 - val_loss: 1.2913 - val_accuracy: 0.6494\n",
      "Epoch 889/1000\n",
      "178/178 [==============================] - 0s 95us/step - loss: 0.1127 - accuracy: 0.9775 - val_loss: 1.2939 - val_accuracy: 0.6623\n",
      "Epoch 890/1000\n",
      "178/178 [==============================] - 0s 91us/step - loss: 0.1122 - accuracy: 0.9775 - val_loss: 1.2940 - val_accuracy: 0.6623\n",
      "Epoch 891/1000\n",
      "178/178 [==============================] - 0s 94us/step - loss: 0.1123 - accuracy: 0.9775 - val_loss: 1.2948 - val_accuracy: 0.6623\n",
      "Epoch 892/1000\n",
      "178/178 [==============================] - 0s 101us/step - loss: 0.1127 - accuracy: 0.9775 - val_loss: 1.2945 - val_accuracy: 0.6623\n",
      "Epoch 893/1000\n",
      "178/178 [==============================] - 0s 84us/step - loss: 0.1125 - accuracy: 0.9775 - val_loss: 1.2962 - val_accuracy: 0.6623\n",
      "Epoch 894/1000\n",
      "178/178 [==============================] - 0s 83us/step - loss: 0.1122 - accuracy: 0.9719 - val_loss: 1.2970 - val_accuracy: 0.6623\n",
      "Epoch 895/1000\n",
      "178/178 [==============================] - 0s 88us/step - loss: 0.1122 - accuracy: 0.9775 - val_loss: 1.2981 - val_accuracy: 0.6623\n",
      "Epoch 896/1000\n",
      "178/178 [==============================] - 0s 83us/step - loss: 0.1117 - accuracy: 0.9775 - val_loss: 1.2999 - val_accuracy: 0.6623\n",
      "Epoch 897/1000\n",
      "178/178 [==============================] - 0s 85us/step - loss: 0.1116 - accuracy: 0.9775 - val_loss: 1.3004 - val_accuracy: 0.6623\n",
      "Epoch 898/1000\n",
      "178/178 [==============================] - 0s 82us/step - loss: 0.1116 - accuracy: 0.9775 - val_loss: 1.3013 - val_accuracy: 0.6623\n",
      "Epoch 899/1000\n",
      "178/178 [==============================] - 0s 89us/step - loss: 0.1115 - accuracy: 0.9775 - val_loss: 1.3021 - val_accuracy: 0.6623\n",
      "Epoch 900/1000\n",
      "178/178 [==============================] - 0s 82us/step - loss: 0.1117 - accuracy: 0.9775 - val_loss: 1.3025 - val_accuracy: 0.6623\n",
      "Epoch 901/1000\n",
      "178/178 [==============================] - 0s 89us/step - loss: 0.1121 - accuracy: 0.9775 - val_loss: 1.3025 - val_accuracy: 0.6623\n",
      "Epoch 902/1000\n",
      "178/178 [==============================] - 0s 85us/step - loss: 0.1112 - accuracy: 0.9775 - val_loss: 1.3046 - val_accuracy: 0.6623\n",
      "Epoch 903/1000\n",
      "178/178 [==============================] - 0s 86us/step - loss: 0.1115 - accuracy: 0.9775 - val_loss: 1.3056 - val_accuracy: 0.6623\n",
      "Epoch 904/1000\n",
      "178/178 [==============================] - 0s 95us/step - loss: 0.1113 - accuracy: 0.9775 - val_loss: 1.3069 - val_accuracy: 0.6623\n",
      "Epoch 905/1000\n",
      "178/178 [==============================] - 0s 183us/step - loss: 0.1113 - accuracy: 0.9719 - val_loss: 1.3060 - val_accuracy: 0.6623\n",
      "Epoch 906/1000\n",
      "178/178 [==============================] - 0s 189us/step - loss: 0.1118 - accuracy: 0.9775 - val_loss: 1.3087 - val_accuracy: 0.6623\n",
      "Epoch 907/1000\n",
      "178/178 [==============================] - 0s 257us/step - loss: 0.1111 - accuracy: 0.9719 - val_loss: 1.3077 - val_accuracy: 0.6623\n",
      "Epoch 908/1000\n",
      "178/178 [==============================] - 0s 184us/step - loss: 0.1110 - accuracy: 0.9719 - val_loss: 1.3052 - val_accuracy: 0.6623\n",
      "Epoch 909/1000\n",
      "178/178 [==============================] - 0s 152us/step - loss: 0.1109 - accuracy: 0.9775 - val_loss: 1.3079 - val_accuracy: 0.6623\n",
      "Epoch 910/1000\n",
      "178/178 [==============================] - 0s 145us/step - loss: 0.1112 - accuracy: 0.9719 - val_loss: 1.3081 - val_accuracy: 0.6623\n",
      "Epoch 911/1000\n",
      "178/178 [==============================] - 0s 160us/step - loss: 0.1105 - accuracy: 0.9775 - val_loss: 1.3082 - val_accuracy: 0.6623\n",
      "Epoch 912/1000\n",
      "178/178 [==============================] - 0s 124us/step - loss: 0.1110 - accuracy: 0.9775 - val_loss: 1.3088 - val_accuracy: 0.6623\n",
      "Epoch 913/1000\n",
      "178/178 [==============================] - 0s 118us/step - loss: 0.1106 - accuracy: 0.9719 - val_loss: 1.3095 - val_accuracy: 0.6623\n",
      "Epoch 914/1000\n",
      "178/178 [==============================] - 0s 101us/step - loss: 0.1105 - accuracy: 0.9775 - val_loss: 1.3104 - val_accuracy: 0.6623\n",
      "Epoch 915/1000\n",
      "178/178 [==============================] - 0s 116us/step - loss: 0.1105 - accuracy: 0.9719 - val_loss: 1.3114 - val_accuracy: 0.6623\n",
      "Epoch 916/1000\n",
      "178/178 [==============================] - 0s 105us/step - loss: 0.1103 - accuracy: 0.9775 - val_loss: 1.3126 - val_accuracy: 0.6623\n",
      "Epoch 917/1000\n",
      "178/178 [==============================] - 0s 90us/step - loss: 0.1100 - accuracy: 0.9775 - val_loss: 1.3120 - val_accuracy: 0.6623\n",
      "Epoch 918/1000\n",
      "178/178 [==============================] - 0s 109us/step - loss: 0.1100 - accuracy: 0.9775 - val_loss: 1.3124 - val_accuracy: 0.6623\n",
      "Epoch 919/1000\n",
      "178/178 [==============================] - 0s 104us/step - loss: 0.1102 - accuracy: 0.9775 - val_loss: 1.3145 - val_accuracy: 0.6623\n",
      "Epoch 920/1000\n",
      "178/178 [==============================] - 0s 91us/step - loss: 0.1102 - accuracy: 0.9775 - val_loss: 1.3123 - val_accuracy: 0.6623\n",
      "Epoch 921/1000\n",
      "178/178 [==============================] - 0s 90us/step - loss: 0.1105 - accuracy: 0.9775 - val_loss: 1.3122 - val_accuracy: 0.6623\n",
      "Epoch 922/1000\n",
      "178/178 [==============================] - 0s 84us/step - loss: 0.1104 - accuracy: 0.9775 - val_loss: 1.3126 - val_accuracy: 0.6623\n",
      "Epoch 923/1000\n",
      "178/178 [==============================] - 0s 81us/step - loss: 0.1100 - accuracy: 0.9775 - val_loss: 1.3132 - val_accuracy: 0.6494\n",
      "Epoch 924/1000\n",
      "178/178 [==============================] - 0s 91us/step - loss: 0.1102 - accuracy: 0.9775 - val_loss: 1.3158 - val_accuracy: 0.6623\n",
      "Epoch 925/1000\n",
      "178/178 [==============================] - 0s 93us/step - loss: 0.1098 - accuracy: 0.9775 - val_loss: 1.3168 - val_accuracy: 0.6623\n",
      "Epoch 926/1000\n",
      "178/178 [==============================] - 0s 91us/step - loss: 0.1097 - accuracy: 0.9775 - val_loss: 1.3169 - val_accuracy: 0.6623\n",
      "Epoch 927/1000\n",
      "178/178 [==============================] - 0s 87us/step - loss: 0.1108 - accuracy: 0.9775 - val_loss: 1.3176 - val_accuracy: 0.6623\n",
      "Epoch 928/1000\n",
      "178/178 [==============================] - 0s 94us/step - loss: 0.1101 - accuracy: 0.9775 - val_loss: 1.3172 - val_accuracy: 0.6623\n",
      "Epoch 929/1000\n",
      "178/178 [==============================] - 0s 90us/step - loss: 0.1098 - accuracy: 0.9775 - val_loss: 1.3172 - val_accuracy: 0.6494\n",
      "Epoch 930/1000\n",
      "178/178 [==============================] - 0s 101us/step - loss: 0.1096 - accuracy: 0.9775 - val_loss: 1.3169 - val_accuracy: 0.6494\n",
      "Epoch 931/1000\n",
      "178/178 [==============================] - 0s 102us/step - loss: 0.1098 - accuracy: 0.9775 - val_loss: 1.3184 - val_accuracy: 0.6623\n",
      "Epoch 932/1000\n",
      "178/178 [==============================] - 0s 110us/step - loss: 0.1099 - accuracy: 0.9775 - val_loss: 1.3207 - val_accuracy: 0.6623\n",
      "Epoch 933/1000\n",
      "178/178 [==============================] - 0s 142us/step - loss: 0.1094 - accuracy: 0.9775 - val_loss: 1.3213 - val_accuracy: 0.6623\n",
      "Epoch 934/1000\n",
      "178/178 [==============================] - 0s 148us/step - loss: 0.1091 - accuracy: 0.9775 - val_loss: 1.3233 - val_accuracy: 0.6623\n",
      "Epoch 935/1000\n",
      "178/178 [==============================] - 0s 237us/step - loss: 0.1088 - accuracy: 0.9775 - val_loss: 1.3224 - val_accuracy: 0.6623\n",
      "Epoch 936/1000\n",
      "178/178 [==============================] - 0s 165us/step - loss: 0.1089 - accuracy: 0.9775 - val_loss: 1.3206 - val_accuracy: 0.6623\n",
      "Epoch 937/1000\n",
      "178/178 [==============================] - 0s 143us/step - loss: 0.1095 - accuracy: 0.9775 - val_loss: 1.3224 - val_accuracy: 0.6623\n",
      "Epoch 938/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 264us/step - loss: 0.1093 - accuracy: 0.9775 - val_loss: 1.3262 - val_accuracy: 0.6623\n",
      "Epoch 939/1000\n",
      "178/178 [==============================] - 0s 178us/step - loss: 0.1088 - accuracy: 0.9775 - val_loss: 1.3256 - val_accuracy: 0.6623\n",
      "Epoch 940/1000\n",
      "178/178 [==============================] - 0s 145us/step - loss: 0.1093 - accuracy: 0.9775 - val_loss: 1.3282 - val_accuracy: 0.6623\n",
      "Epoch 941/1000\n",
      "178/178 [==============================] - 0s 95us/step - loss: 0.1083 - accuracy: 0.9775 - val_loss: 1.3274 - val_accuracy: 0.6623\n",
      "Epoch 942/1000\n",
      "178/178 [==============================] - 0s 102us/step - loss: 0.1090 - accuracy: 0.9775 - val_loss: 1.3281 - val_accuracy: 0.6623\n",
      "Epoch 943/1000\n",
      "178/178 [==============================] - 0s 121us/step - loss: 0.1085 - accuracy: 0.9775 - val_loss: 1.3278 - val_accuracy: 0.6623\n",
      "Epoch 944/1000\n",
      "178/178 [==============================] - 0s 97us/step - loss: 0.1086 - accuracy: 0.9775 - val_loss: 1.3281 - val_accuracy: 0.6623\n",
      "Epoch 945/1000\n",
      "178/178 [==============================] - 0s 100us/step - loss: 0.1084 - accuracy: 0.9775 - val_loss: 1.3319 - val_accuracy: 0.6623\n",
      "Epoch 946/1000\n",
      "178/178 [==============================] - 0s 96us/step - loss: 0.1086 - accuracy: 0.9775 - val_loss: 1.3343 - val_accuracy: 0.6623\n",
      "Epoch 947/1000\n",
      "178/178 [==============================] - 0s 101us/step - loss: 0.1086 - accuracy: 0.9719 - val_loss: 1.3337 - val_accuracy: 0.6623\n",
      "Epoch 948/1000\n",
      "178/178 [==============================] - 0s 99us/step - loss: 0.1082 - accuracy: 0.9719 - val_loss: 1.3323 - val_accuracy: 0.6623\n",
      "Epoch 949/1000\n",
      "178/178 [==============================] - 0s 102us/step - loss: 0.1083 - accuracy: 0.9775 - val_loss: 1.3312 - val_accuracy: 0.6623\n",
      "Epoch 950/1000\n",
      "178/178 [==============================] - 0s 99us/step - loss: 0.1082 - accuracy: 0.9775 - val_loss: 1.3328 - val_accuracy: 0.6623\n",
      "Epoch 951/1000\n",
      "178/178 [==============================] - 0s 113us/step - loss: 0.1078 - accuracy: 0.9719 - val_loss: 1.3320 - val_accuracy: 0.6623\n",
      "Epoch 952/1000\n",
      "178/178 [==============================] - 0s 89us/step - loss: 0.1084 - accuracy: 0.9719 - val_loss: 1.3323 - val_accuracy: 0.6623\n",
      "Epoch 953/1000\n",
      "178/178 [==============================] - 0s 83us/step - loss: 0.1087 - accuracy: 0.9775 - val_loss: 1.3331 - val_accuracy: 0.6623\n",
      "Epoch 954/1000\n",
      "178/178 [==============================] - 0s 100us/step - loss: 0.1084 - accuracy: 0.9775 - val_loss: 1.3340 - val_accuracy: 0.6623\n",
      "Epoch 955/1000\n",
      "178/178 [==============================] - 0s 94us/step - loss: 0.1078 - accuracy: 0.9775 - val_loss: 1.3373 - val_accuracy: 0.6623\n",
      "Epoch 956/1000\n",
      "178/178 [==============================] - 0s 103us/step - loss: 0.1078 - accuracy: 0.9775 - val_loss: 1.3383 - val_accuracy: 0.6623\n",
      "Epoch 957/1000\n",
      "178/178 [==============================] - 0s 90us/step - loss: 0.1080 - accuracy: 0.9775 - val_loss: 1.3378 - val_accuracy: 0.6623\n",
      "Epoch 958/1000\n",
      "178/178 [==============================] - 0s 82us/step - loss: 0.1079 - accuracy: 0.9775 - val_loss: 1.3390 - val_accuracy: 0.6623\n",
      "Epoch 959/1000\n",
      "178/178 [==============================] - 0s 86us/step - loss: 0.1073 - accuracy: 0.9775 - val_loss: 1.3401 - val_accuracy: 0.6623\n",
      "Epoch 960/1000\n",
      "178/178 [==============================] - 0s 85us/step - loss: 0.1078 - accuracy: 0.9775 - val_loss: 1.3421 - val_accuracy: 0.6623\n",
      "Epoch 961/1000\n",
      "178/178 [==============================] - 0s 87us/step - loss: 0.1080 - accuracy: 0.9775 - val_loss: 1.3393 - val_accuracy: 0.6623\n",
      "Epoch 962/1000\n",
      "178/178 [==============================] - 0s 87us/step - loss: 0.1071 - accuracy: 0.9775 - val_loss: 1.3398 - val_accuracy: 0.6623\n",
      "Epoch 963/1000\n",
      "178/178 [==============================] - 0s 108us/step - loss: 0.1075 - accuracy: 0.9775 - val_loss: 1.3406 - val_accuracy: 0.6623\n",
      "Epoch 964/1000\n",
      "178/178 [==============================] - 0s 128us/step - loss: 0.1070 - accuracy: 0.9775 - val_loss: 1.3424 - val_accuracy: 0.6623\n",
      "Epoch 965/1000\n",
      "178/178 [==============================] - 0s 112us/step - loss: 0.1072 - accuracy: 0.9775 - val_loss: 1.3429 - val_accuracy: 0.6623\n",
      "Epoch 966/1000\n",
      "178/178 [==============================] - 0s 112us/step - loss: 0.1073 - accuracy: 0.9775 - val_loss: 1.3425 - val_accuracy: 0.6623\n",
      "Epoch 967/1000\n",
      "178/178 [==============================] - 0s 112us/step - loss: 0.1068 - accuracy: 0.9775 - val_loss: 1.3427 - val_accuracy: 0.6623\n",
      "Epoch 968/1000\n",
      "178/178 [==============================] - 0s 116us/step - loss: 0.1066 - accuracy: 0.9775 - val_loss: 1.3425 - val_accuracy: 0.6494\n",
      "Epoch 969/1000\n",
      "178/178 [==============================] - 0s 108us/step - loss: 0.1068 - accuracy: 0.9775 - val_loss: 1.3443 - val_accuracy: 0.6623\n",
      "Epoch 970/1000\n",
      "178/178 [==============================] - 0s 95us/step - loss: 0.1067 - accuracy: 0.9775 - val_loss: 1.3427 - val_accuracy: 0.6494\n",
      "Epoch 971/1000\n",
      "178/178 [==============================] - 0s 91us/step - loss: 0.1068 - accuracy: 0.9775 - val_loss: 1.3444 - val_accuracy: 0.6494\n",
      "Epoch 972/1000\n",
      "178/178 [==============================] - 0s 90us/step - loss: 0.1069 - accuracy: 0.9775 - val_loss: 1.3461 - val_accuracy: 0.6623\n",
      "Epoch 973/1000\n",
      "178/178 [==============================] - 0s 80us/step - loss: 0.1065 - accuracy: 0.9775 - val_loss: 1.3469 - val_accuracy: 0.6623\n",
      "Epoch 974/1000\n",
      "178/178 [==============================] - 0s 85us/step - loss: 0.1063 - accuracy: 0.9775 - val_loss: 1.3484 - val_accuracy: 0.6623\n",
      "Epoch 975/1000\n",
      "178/178 [==============================] - 0s 97us/step - loss: 0.1066 - accuracy: 0.9775 - val_loss: 1.3494 - val_accuracy: 0.6623\n",
      "Epoch 976/1000\n",
      "178/178 [==============================] - 0s 146us/step - loss: 0.1062 - accuracy: 0.9775 - val_loss: 1.3513 - val_accuracy: 0.6623\n",
      "Epoch 977/1000\n",
      "178/178 [==============================] - 0s 81us/step - loss: 0.1060 - accuracy: 0.9775 - val_loss: 1.3526 - val_accuracy: 0.6623\n",
      "Epoch 978/1000\n",
      "178/178 [==============================] - 0s 100us/step - loss: 0.1065 - accuracy: 0.9775 - val_loss: 1.3496 - val_accuracy: 0.6494\n",
      "Epoch 979/1000\n",
      "178/178 [==============================] - 0s 141us/step - loss: 0.1063 - accuracy: 0.9775 - val_loss: 1.3492 - val_accuracy: 0.6494\n",
      "Epoch 980/1000\n",
      "178/178 [==============================] - 0s 144us/step - loss: 0.1062 - accuracy: 0.9775 - val_loss: 1.3524 - val_accuracy: 0.6623\n",
      "Epoch 981/1000\n",
      "178/178 [==============================] - 0s 166us/step - loss: 0.1060 - accuracy: 0.9775 - val_loss: 1.3538 - val_accuracy: 0.6623\n",
      "Epoch 982/1000\n",
      "178/178 [==============================] - 0s 266us/step - loss: 0.1059 - accuracy: 0.9775 - val_loss: 1.3564 - val_accuracy: 0.6623\n",
      "Epoch 983/1000\n",
      "178/178 [==============================] - 0s 220us/step - loss: 0.1060 - accuracy: 0.9775 - val_loss: 1.3550 - val_accuracy: 0.6623\n",
      "Epoch 984/1000\n",
      "178/178 [==============================] - 0s 244us/step - loss: 0.1057 - accuracy: 0.9775 - val_loss: 1.3558 - val_accuracy: 0.6623\n",
      "Epoch 985/1000\n",
      "178/178 [==============================] - 0s 147us/step - loss: 0.1061 - accuracy: 0.9775 - val_loss: 1.3529 - val_accuracy: 0.6494\n",
      "Epoch 986/1000\n",
      "178/178 [==============================] - 0s 102us/step - loss: 0.1059 - accuracy: 0.9775 - val_loss: 1.3558 - val_accuracy: 0.6623\n",
      "Epoch 987/1000\n",
      "178/178 [==============================] - 0s 94us/step - loss: 0.1057 - accuracy: 0.9775 - val_loss: 1.3570 - val_accuracy: 0.6623\n",
      "Epoch 988/1000\n",
      "178/178 [==============================] - 0s 89us/step - loss: 0.1054 - accuracy: 0.9775 - val_loss: 1.3567 - val_accuracy: 0.6494\n",
      "Epoch 989/1000\n",
      "178/178 [==============================] - 0s 87us/step - loss: 0.1052 - accuracy: 0.9775 - val_loss: 1.3596 - val_accuracy: 0.6623\n",
      "Epoch 990/1000\n",
      "178/178 [==============================] - 0s 83us/step - loss: 0.1052 - accuracy: 0.9775 - val_loss: 1.3623 - val_accuracy: 0.6623\n",
      "Epoch 991/1000\n",
      "178/178 [==============================] - 0s 85us/step - loss: 0.1052 - accuracy: 0.9775 - val_loss: 1.3627 - val_accuracy: 0.6623\n",
      "Epoch 992/1000\n",
      "178/178 [==============================] - 0s 76us/step - loss: 0.1053 - accuracy: 0.9775 - val_loss: 1.3651 - val_accuracy: 0.6623\n",
      "Epoch 993/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 85us/step - loss: 0.1056 - accuracy: 0.9775 - val_loss: 1.3661 - val_accuracy: 0.6623\n",
      "Epoch 994/1000\n",
      "178/178 [==============================] - 0s 86us/step - loss: 0.1054 - accuracy: 0.9775 - val_loss: 1.3679 - val_accuracy: 0.6623\n",
      "Epoch 995/1000\n",
      "178/178 [==============================] - 0s 81us/step - loss: 0.1056 - accuracy: 0.9775 - val_loss: 1.3659 - val_accuracy: 0.6623\n",
      "Epoch 996/1000\n",
      "178/178 [==============================] - 0s 90us/step - loss: 0.1060 - accuracy: 0.9775 - val_loss: 1.3666 - val_accuracy: 0.6623\n",
      "Epoch 997/1000\n",
      "178/178 [==============================] - 0s 79us/step - loss: 0.1053 - accuracy: 0.9775 - val_loss: 1.3642 - val_accuracy: 0.6623\n",
      "Epoch 998/1000\n",
      "178/178 [==============================] - 0s 81us/step - loss: 0.1046 - accuracy: 0.9775 - val_loss: 1.3664 - val_accuracy: 0.6623\n",
      "Epoch 999/1000\n",
      "178/178 [==============================] - 0s 82us/step - loss: 0.1047 - accuracy: 0.9775 - val_loss: 1.3662 - val_accuracy: 0.6623\n",
      "Epoch 1000/1000\n",
      "178/178 [==============================] - 0s 92us/step - loss: 0.1050 - accuracy: 0.9775 - val_loss: 1.3650 - val_accuracy: 0.6623\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a42fc9fd0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sel1.fit(X_sel_train, y_sel_train,\n",
    "          batch_size=32, epochs=1000,\n",
    "          validation_data=(X_sel_test, y_sel_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 0s 112us/step\n",
      "test accuracy: 66.23%\n"
     ]
    }
   ],
   "source": [
    "acc_test_sel1 = model_sel1.evaluate(X_sel_test, y_sel_test)[1]\n",
    "print('test accuracy: %.2f%%' % (acc_test_sel1*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### improve neural network\n",
    "model_sel2 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_sel_train.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sel2.compile(optimizer='sgd',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 178 samples, validate on 77 samples\n",
      "Epoch 1/1000\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.7095 - accuracy: 0.3652 - val_loss: 0.6832 - val_accuracy: 0.4026\n",
      "Epoch 2/1000\n",
      "178/178 [==============================] - 0s 74us/step - loss: 0.6912 - accuracy: 0.4326 - val_loss: 0.6759 - val_accuracy: 0.4935\n",
      "Epoch 3/1000\n",
      "178/178 [==============================] - 0s 96us/step - loss: 0.6746 - accuracy: 0.4831 - val_loss: 0.6721 - val_accuracy: 0.4935\n",
      "Epoch 4/1000\n",
      "178/178 [==============================] - 0s 106us/step - loss: 0.6639 - accuracy: 0.5337 - val_loss: 0.6707 - val_accuracy: 0.5065\n",
      "Epoch 5/1000\n",
      "178/178 [==============================] - 0s 99us/step - loss: 0.6536 - accuracy: 0.5506 - val_loss: 0.6695 - val_accuracy: 0.4935\n",
      "Epoch 6/1000\n",
      "178/178 [==============================] - 0s 107us/step - loss: 0.6458 - accuracy: 0.5618 - val_loss: 0.6687 - val_accuracy: 0.5065\n",
      "Epoch 7/1000\n",
      "178/178 [==============================] - 0s 128us/step - loss: 0.6404 - accuracy: 0.5506 - val_loss: 0.6683 - val_accuracy: 0.5065\n",
      "Epoch 8/1000\n",
      "178/178 [==============================] - 0s 119us/step - loss: 0.6341 - accuracy: 0.5899 - val_loss: 0.6674 - val_accuracy: 0.5065\n",
      "Epoch 9/1000\n",
      "178/178 [==============================] - 0s 126us/step - loss: 0.6293 - accuracy: 0.6011 - val_loss: 0.6673 - val_accuracy: 0.5065\n",
      "Epoch 10/1000\n",
      "178/178 [==============================] - 0s 121us/step - loss: 0.6245 - accuracy: 0.6011 - val_loss: 0.6670 - val_accuracy: 0.5065\n",
      "Epoch 11/1000\n",
      "178/178 [==============================] - 0s 151us/step - loss: 0.6207 - accuracy: 0.6180 - val_loss: 0.6644 - val_accuracy: 0.5195\n",
      "Epoch 12/1000\n",
      "178/178 [==============================] - 0s 121us/step - loss: 0.6159 - accuracy: 0.6348 - val_loss: 0.6643 - val_accuracy: 0.5195\n",
      "Epoch 13/1000\n",
      "178/178 [==============================] - 0s 135us/step - loss: 0.6115 - accuracy: 0.6348 - val_loss: 0.6637 - val_accuracy: 0.5325\n",
      "Epoch 14/1000\n",
      "178/178 [==============================] - 0s 164us/step - loss: 0.6074 - accuracy: 0.6517 - val_loss: 0.6634 - val_accuracy: 0.5195\n",
      "Epoch 15/1000\n",
      "178/178 [==============================] - 0s 130us/step - loss: 0.6033 - accuracy: 0.6854 - val_loss: 0.6625 - val_accuracy: 0.5195\n",
      "Epoch 16/1000\n",
      "178/178 [==============================] - 0s 111us/step - loss: 0.5991 - accuracy: 0.7022 - val_loss: 0.6611 - val_accuracy: 0.5065\n",
      "Epoch 17/1000\n",
      "178/178 [==============================] - 0s 114us/step - loss: 0.5956 - accuracy: 0.7022 - val_loss: 0.6600 - val_accuracy: 0.5065\n",
      "Epoch 18/1000\n",
      "178/178 [==============================] - 0s 96us/step - loss: 0.5918 - accuracy: 0.7135 - val_loss: 0.6594 - val_accuracy: 0.5195\n",
      "Epoch 19/1000\n",
      "178/178 [==============================] - 0s 107us/step - loss: 0.5874 - accuracy: 0.7135 - val_loss: 0.6592 - val_accuracy: 0.5195\n",
      "Epoch 20/1000\n",
      "178/178 [==============================] - 0s 89us/step - loss: 0.5835 - accuracy: 0.7191 - val_loss: 0.6590 - val_accuracy: 0.5195\n",
      "Epoch 21/1000\n",
      "178/178 [==============================] - 0s 100us/step - loss: 0.5798 - accuracy: 0.7416 - val_loss: 0.6586 - val_accuracy: 0.5325\n",
      "Epoch 22/1000\n",
      "178/178 [==============================] - 0s 99us/step - loss: 0.5766 - accuracy: 0.7303 - val_loss: 0.6579 - val_accuracy: 0.5584\n",
      "Epoch 23/1000\n",
      "178/178 [==============================] - 0s 116us/step - loss: 0.5730 - accuracy: 0.7416 - val_loss: 0.6574 - val_accuracy: 0.5455\n",
      "Epoch 24/1000\n",
      "178/178 [==============================] - 0s 164us/step - loss: 0.5688 - accuracy: 0.7528 - val_loss: 0.6567 - val_accuracy: 0.5455\n",
      "Epoch 25/1000\n",
      "178/178 [==============================] - 0s 203us/step - loss: 0.5649 - accuracy: 0.7528 - val_loss: 0.6554 - val_accuracy: 0.5714\n",
      "Epoch 26/1000\n",
      "178/178 [==============================] - 0s 204us/step - loss: 0.5616 - accuracy: 0.7472 - val_loss: 0.6556 - val_accuracy: 0.5714\n",
      "Epoch 27/1000\n",
      "178/178 [==============================] - 0s 188us/step - loss: 0.5571 - accuracy: 0.7640 - val_loss: 0.6544 - val_accuracy: 0.6104\n",
      "Epoch 28/1000\n",
      "178/178 [==============================] - 0s 181us/step - loss: 0.5542 - accuracy: 0.7584 - val_loss: 0.6552 - val_accuracy: 0.6104\n",
      "Epoch 29/1000\n",
      "178/178 [==============================] - 0s 141us/step - loss: 0.5508 - accuracy: 0.7640 - val_loss: 0.6526 - val_accuracy: 0.6364\n",
      "Epoch 30/1000\n",
      "178/178 [==============================] - 0s 109us/step - loss: 0.5462 - accuracy: 0.7753 - val_loss: 0.6520 - val_accuracy: 0.6364\n",
      "Epoch 31/1000\n",
      "178/178 [==============================] - 0s 109us/step - loss: 0.5423 - accuracy: 0.7753 - val_loss: 0.6511 - val_accuracy: 0.6494\n",
      "Epoch 32/1000\n",
      "178/178 [==============================] - 0s 102us/step - loss: 0.5389 - accuracy: 0.7697 - val_loss: 0.6511 - val_accuracy: 0.6494\n",
      "Epoch 33/1000\n",
      "178/178 [==============================] - 0s 85us/step - loss: 0.5355 - accuracy: 0.7697 - val_loss: 0.6517 - val_accuracy: 0.6494\n",
      "Epoch 34/1000\n",
      "178/178 [==============================] - 0s 101us/step - loss: 0.5316 - accuracy: 0.7697 - val_loss: 0.6530 - val_accuracy: 0.6494\n",
      "Epoch 35/1000\n",
      "178/178 [==============================] - 0s 105us/step - loss: 0.5282 - accuracy: 0.7640 - val_loss: 0.6516 - val_accuracy: 0.6494\n",
      "Epoch 36/1000\n",
      "178/178 [==============================] - 0s 173us/step - loss: 0.5241 - accuracy: 0.7753 - val_loss: 0.6510 - val_accuracy: 0.6623\n",
      "Epoch 37/1000\n",
      "178/178 [==============================] - 0s 105us/step - loss: 0.5208 - accuracy: 0.7865 - val_loss: 0.6509 - val_accuracy: 0.6364\n",
      "Epoch 38/1000\n",
      "178/178 [==============================] - 0s 127us/step - loss: 0.5171 - accuracy: 0.7921 - val_loss: 0.6514 - val_accuracy: 0.6494\n",
      "Epoch 39/1000\n",
      "178/178 [==============================] - 0s 122us/step - loss: 0.5132 - accuracy: 0.7921 - val_loss: 0.6510 - val_accuracy: 0.6494\n",
      "Epoch 40/1000\n",
      "178/178 [==============================] - 0s 132us/step - loss: 0.5098 - accuracy: 0.7865 - val_loss: 0.6511 - val_accuracy: 0.6494\n",
      "Epoch 41/1000\n",
      "178/178 [==============================] - 0s 104us/step - loss: 0.5067 - accuracy: 0.7921 - val_loss: 0.6487 - val_accuracy: 0.5844\n",
      "Epoch 42/1000\n",
      "178/178 [==============================] - 0s 102us/step - loss: 0.5029 - accuracy: 0.7753 - val_loss: 0.6483 - val_accuracy: 0.5844\n",
      "Epoch 43/1000\n",
      "178/178 [==============================] - 0s 107us/step - loss: 0.4995 - accuracy: 0.7809 - val_loss: 0.6491 - val_accuracy: 0.5844\n",
      "Epoch 44/1000\n",
      "178/178 [==============================] - 0s 111us/step - loss: 0.4963 - accuracy: 0.7753 - val_loss: 0.6499 - val_accuracy: 0.5844\n",
      "Epoch 45/1000\n",
      "178/178 [==============================] - 0s 115us/step - loss: 0.4925 - accuracy: 0.7809 - val_loss: 0.6500 - val_accuracy: 0.5844\n",
      "Epoch 46/1000\n",
      "178/178 [==============================] - 0s 100us/step - loss: 0.4894 - accuracy: 0.7809 - val_loss: 0.6501 - val_accuracy: 0.5844\n",
      "Epoch 47/1000\n",
      "178/178 [==============================] - 0s 108us/step - loss: 0.4852 - accuracy: 0.7809 - val_loss: 0.6496 - val_accuracy: 0.5844\n",
      "Epoch 48/1000\n",
      "178/178 [==============================] - 0s 88us/step - loss: 0.4817 - accuracy: 0.7865 - val_loss: 0.6488 - val_accuracy: 0.5844\n",
      "Epoch 49/1000\n",
      "178/178 [==============================] - 0s 90us/step - loss: 0.4782 - accuracy: 0.7921 - val_loss: 0.6492 - val_accuracy: 0.5714\n",
      "Epoch 50/1000\n",
      "178/178 [==============================] - 0s 90us/step - loss: 0.4752 - accuracy: 0.7921 - val_loss: 0.6487 - val_accuracy: 0.5844\n",
      "Epoch 51/1000\n",
      "178/178 [==============================] - 0s 87us/step - loss: 0.4718 - accuracy: 0.8034 - val_loss: 0.6473 - val_accuracy: 0.5844\n",
      "Epoch 52/1000\n",
      "178/178 [==============================] - 0s 109us/step - loss: 0.4677 - accuracy: 0.8090 - val_loss: 0.6484 - val_accuracy: 0.5714\n",
      "Epoch 53/1000\n",
      "178/178 [==============================] - 0s 110us/step - loss: 0.4646 - accuracy: 0.8034 - val_loss: 0.6481 - val_accuracy: 0.5714\n",
      "Epoch 54/1000\n",
      "178/178 [==============================] - 0s 127us/step - loss: 0.4608 - accuracy: 0.8090 - val_loss: 0.6488 - val_accuracy: 0.5714\n",
      "Epoch 55/1000\n",
      "178/178 [==============================] - 0s 105us/step - loss: 0.4577 - accuracy: 0.8090 - val_loss: 0.6479 - val_accuracy: 0.5844\n",
      "Epoch 56/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 105us/step - loss: 0.4553 - accuracy: 0.8090 - val_loss: 0.6489 - val_accuracy: 0.5714\n",
      "Epoch 57/1000\n",
      "178/178 [==============================] - 0s 102us/step - loss: 0.4506 - accuracy: 0.8090 - val_loss: 0.6508 - val_accuracy: 0.5714\n",
      "Epoch 58/1000\n",
      "178/178 [==============================] - 0s 100us/step - loss: 0.4476 - accuracy: 0.8090 - val_loss: 0.6501 - val_accuracy: 0.5714\n",
      "Epoch 59/1000\n",
      "178/178 [==============================] - 0s 99us/step - loss: 0.4444 - accuracy: 0.8090 - val_loss: 0.6506 - val_accuracy: 0.5714\n",
      "Epoch 60/1000\n",
      "178/178 [==============================] - 0s 93us/step - loss: 0.4417 - accuracy: 0.8090 - val_loss: 0.6514 - val_accuracy: 0.5714\n",
      "Epoch 61/1000\n",
      "178/178 [==============================] - 0s 97us/step - loss: 0.4382 - accuracy: 0.8090 - val_loss: 0.6514 - val_accuracy: 0.5714\n",
      "Epoch 62/1000\n",
      "178/178 [==============================] - 0s 88us/step - loss: 0.4349 - accuracy: 0.8090 - val_loss: 0.6499 - val_accuracy: 0.5844\n",
      "Epoch 63/1000\n",
      "178/178 [==============================] - 0s 93us/step - loss: 0.4317 - accuracy: 0.8202 - val_loss: 0.6524 - val_accuracy: 0.5714\n",
      "Epoch 64/1000\n",
      "178/178 [==============================] - 0s 92us/step - loss: 0.4289 - accuracy: 0.8090 - val_loss: 0.6490 - val_accuracy: 0.5974\n",
      "Epoch 65/1000\n",
      "178/178 [==============================] - 0s 109us/step - loss: 0.4258 - accuracy: 0.8258 - val_loss: 0.6526 - val_accuracy: 0.5844\n",
      "Epoch 66/1000\n",
      "178/178 [==============================] - 0s 89us/step - loss: 0.4225 - accuracy: 0.8202 - val_loss: 0.6557 - val_accuracy: 0.5844\n",
      "Epoch 67/1000\n",
      "178/178 [==============================] - 0s 90us/step - loss: 0.4195 - accuracy: 0.8202 - val_loss: 0.6566 - val_accuracy: 0.5844\n",
      "Epoch 68/1000\n",
      "178/178 [==============================] - 0s 91us/step - loss: 0.4166 - accuracy: 0.8202 - val_loss: 0.6591 - val_accuracy: 0.5844\n",
      "Epoch 69/1000\n",
      "178/178 [==============================] - 0s 86us/step - loss: 0.4143 - accuracy: 0.8146 - val_loss: 0.6585 - val_accuracy: 0.5844\n",
      "Epoch 70/1000\n",
      "178/178 [==============================] - 0s 102us/step - loss: 0.4120 - accuracy: 0.8315 - val_loss: 0.6633 - val_accuracy: 0.6234\n",
      "Epoch 71/1000\n",
      "178/178 [==============================] - 0s 98us/step - loss: 0.4080 - accuracy: 0.8146 - val_loss: 0.6613 - val_accuracy: 0.5844\n",
      "Epoch 72/1000\n",
      "178/178 [==============================] - 0s 85us/step - loss: 0.4052 - accuracy: 0.8202 - val_loss: 0.6600 - val_accuracy: 0.5844\n",
      "Epoch 73/1000\n",
      "178/178 [==============================] - 0s 94us/step - loss: 0.4029 - accuracy: 0.8315 - val_loss: 0.6614 - val_accuracy: 0.5844\n",
      "Epoch 74/1000\n",
      "178/178 [==============================] - 0s 96us/step - loss: 0.4001 - accuracy: 0.8315 - val_loss: 0.6619 - val_accuracy: 0.5844\n",
      "Epoch 75/1000\n",
      "178/178 [==============================] - 0s 84us/step - loss: 0.3975 - accuracy: 0.8258 - val_loss: 0.6617 - val_accuracy: 0.5844\n",
      "Epoch 76/1000\n",
      "178/178 [==============================] - 0s 96us/step - loss: 0.3944 - accuracy: 0.8315 - val_loss: 0.6662 - val_accuracy: 0.5714\n",
      "Epoch 77/1000\n",
      "178/178 [==============================] - 0s 101us/step - loss: 0.3927 - accuracy: 0.8258 - val_loss: 0.6707 - val_accuracy: 0.6234\n",
      "Epoch 78/1000\n",
      "178/178 [==============================] - 0s 83us/step - loss: 0.3897 - accuracy: 0.8427 - val_loss: 0.6712 - val_accuracy: 0.6234\n",
      "Epoch 79/1000\n",
      "178/178 [==============================] - 0s 94us/step - loss: 0.3872 - accuracy: 0.8202 - val_loss: 0.6741 - val_accuracy: 0.6234\n",
      "Epoch 80/1000\n",
      "178/178 [==============================] - 0s 87us/step - loss: 0.3849 - accuracy: 0.8371 - val_loss: 0.6738 - val_accuracy: 0.6234\n",
      "Epoch 81/1000\n",
      "178/178 [==============================] - 0s 105us/step - loss: 0.3823 - accuracy: 0.8483 - val_loss: 0.6740 - val_accuracy: 0.6364\n",
      "Epoch 82/1000\n",
      "178/178 [==============================] - 0s 79us/step - loss: 0.3798 - accuracy: 0.8371 - val_loss: 0.6763 - val_accuracy: 0.6234\n",
      "Epoch 83/1000\n",
      "178/178 [==============================] - 0s 132us/step - loss: 0.3774 - accuracy: 0.8315 - val_loss: 0.6783 - val_accuracy: 0.6234\n",
      "Epoch 84/1000\n",
      "178/178 [==============================] - 0s 81us/step - loss: 0.3754 - accuracy: 0.8483 - val_loss: 0.6775 - val_accuracy: 0.6364\n",
      "Epoch 85/1000\n",
      "178/178 [==============================] - 0s 83us/step - loss: 0.3720 - accuracy: 0.8539 - val_loss: 0.6816 - val_accuracy: 0.6364\n",
      "Epoch 86/1000\n",
      "178/178 [==============================] - 0s 92us/step - loss: 0.3699 - accuracy: 0.8483 - val_loss: 0.6824 - val_accuracy: 0.6364\n",
      "Epoch 87/1000\n",
      "178/178 [==============================] - 0s 87us/step - loss: 0.3682 - accuracy: 0.8427 - val_loss: 0.6801 - val_accuracy: 0.6494\n",
      "Epoch 88/1000\n",
      "178/178 [==============================] - 0s 87us/step - loss: 0.3661 - accuracy: 0.8539 - val_loss: 0.6835 - val_accuracy: 0.6364\n",
      "Epoch 89/1000\n",
      "178/178 [==============================] - 0s 84us/step - loss: 0.3639 - accuracy: 0.8539 - val_loss: 0.6871 - val_accuracy: 0.6364\n",
      "Epoch 90/1000\n",
      "178/178 [==============================] - 0s 85us/step - loss: 0.3611 - accuracy: 0.8539 - val_loss: 0.6900 - val_accuracy: 0.6364\n",
      "Epoch 91/1000\n",
      "178/178 [==============================] - 0s 118us/step - loss: 0.3594 - accuracy: 0.8596 - val_loss: 0.6923 - val_accuracy: 0.6364\n",
      "Epoch 92/1000\n",
      "178/178 [==============================] - 0s 98us/step - loss: 0.3573 - accuracy: 0.8596 - val_loss: 0.6938 - val_accuracy: 0.6364\n",
      "Epoch 93/1000\n",
      "178/178 [==============================] - 0s 97us/step - loss: 0.3556 - accuracy: 0.8539 - val_loss: 0.6948 - val_accuracy: 0.6364\n",
      "Epoch 94/1000\n",
      "178/178 [==============================] - 0s 110us/step - loss: 0.3530 - accuracy: 0.8539 - val_loss: 0.6990 - val_accuracy: 0.6364\n",
      "Epoch 95/1000\n",
      "178/178 [==============================] - 0s 98us/step - loss: 0.3514 - accuracy: 0.8539 - val_loss: 0.7022 - val_accuracy: 0.6364\n",
      "Epoch 96/1000\n",
      "178/178 [==============================] - 0s 80us/step - loss: 0.3494 - accuracy: 0.8596 - val_loss: 0.7029 - val_accuracy: 0.6364\n",
      "Epoch 97/1000\n",
      "178/178 [==============================] - 0s 98us/step - loss: 0.3471 - accuracy: 0.8596 - val_loss: 0.7058 - val_accuracy: 0.6364\n",
      "Epoch 98/1000\n",
      "178/178 [==============================] - 0s 87us/step - loss: 0.3459 - accuracy: 0.8596 - val_loss: 0.7085 - val_accuracy: 0.6364\n",
      "Epoch 99/1000\n",
      "178/178 [==============================] - 0s 98us/step - loss: 0.3440 - accuracy: 0.8652 - val_loss: 0.7114 - val_accuracy: 0.6364\n",
      "Epoch 100/1000\n",
      "178/178 [==============================] - 0s 92us/step - loss: 0.3422 - accuracy: 0.8708 - val_loss: 0.7134 - val_accuracy: 0.6364\n",
      "Epoch 101/1000\n",
      "178/178 [==============================] - 0s 86us/step - loss: 0.3406 - accuracy: 0.8596 - val_loss: 0.7169 - val_accuracy: 0.6364\n",
      "Epoch 102/1000\n",
      "178/178 [==============================] - 0s 90us/step - loss: 0.3388 - accuracy: 0.8708 - val_loss: 0.7167 - val_accuracy: 0.6364\n",
      "Epoch 103/1000\n",
      "178/178 [==============================] - 0s 86us/step - loss: 0.3364 - accuracy: 0.8596 - val_loss: 0.7200 - val_accuracy: 0.6364\n",
      "Epoch 104/1000\n",
      "178/178 [==============================] - 0s 82us/step - loss: 0.3346 - accuracy: 0.8708 - val_loss: 0.7150 - val_accuracy: 0.6494\n",
      "Epoch 105/1000\n",
      "178/178 [==============================] - 0s 91us/step - loss: 0.3334 - accuracy: 0.8596 - val_loss: 0.7213 - val_accuracy: 0.6494\n",
      "Epoch 106/1000\n",
      "178/178 [==============================] - 0s 91us/step - loss: 0.3317 - accuracy: 0.8596 - val_loss: 0.7261 - val_accuracy: 0.6364\n",
      "Epoch 107/1000\n",
      "178/178 [==============================] - 0s 84us/step - loss: 0.3304 - accuracy: 0.8652 - val_loss: 0.7261 - val_accuracy: 0.6494\n",
      "Epoch 108/1000\n",
      "178/178 [==============================] - 0s 90us/step - loss: 0.3283 - accuracy: 0.8596 - val_loss: 0.7272 - val_accuracy: 0.6494\n",
      "Epoch 109/1000\n",
      "178/178 [==============================] - 0s 82us/step - loss: 0.3260 - accuracy: 0.8596 - val_loss: 0.7293 - val_accuracy: 0.6494\n",
      "Epoch 110/1000\n",
      "178/178 [==============================] - 0s 85us/step - loss: 0.3248 - accuracy: 0.8596 - val_loss: 0.7334 - val_accuracy: 0.6494\n",
      "Epoch 111/1000\n",
      "178/178 [==============================] - 0s 86us/step - loss: 0.3237 - accuracy: 0.8708 - val_loss: 0.7419 - val_accuracy: 0.6364\n",
      "Epoch 112/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 100us/step - loss: 0.3224 - accuracy: 0.8708 - val_loss: 0.7376 - val_accuracy: 0.6494\n",
      "Epoch 113/1000\n",
      "178/178 [==============================] - 0s 87us/step - loss: 0.3195 - accuracy: 0.8764 - val_loss: 0.7401 - val_accuracy: 0.6494\n",
      "Epoch 114/1000\n",
      "178/178 [==============================] - 0s 84us/step - loss: 0.3184 - accuracy: 0.8764 - val_loss: 0.7460 - val_accuracy: 0.6364\n",
      "Epoch 115/1000\n",
      "178/178 [==============================] - 0s 82us/step - loss: 0.3165 - accuracy: 0.8764 - val_loss: 0.7471 - val_accuracy: 0.6364\n",
      "Epoch 116/1000\n",
      "178/178 [==============================] - 0s 83us/step - loss: 0.3151 - accuracy: 0.8708 - val_loss: 0.7456 - val_accuracy: 0.6494\n",
      "Epoch 117/1000\n",
      "178/178 [==============================] - 0s 80us/step - loss: 0.3128 - accuracy: 0.8652 - val_loss: 0.7496 - val_accuracy: 0.6494\n",
      "Epoch 118/1000\n",
      "178/178 [==============================] - 0s 84us/step - loss: 0.3110 - accuracy: 0.8708 - val_loss: 0.7533 - val_accuracy: 0.6364\n",
      "Epoch 119/1000\n",
      "178/178 [==============================] - 0s 87us/step - loss: 0.3099 - accuracy: 0.8876 - val_loss: 0.7551 - val_accuracy: 0.6494\n",
      "Epoch 120/1000\n",
      "178/178 [==============================] - 0s 95us/step - loss: 0.3084 - accuracy: 0.8820 - val_loss: 0.7584 - val_accuracy: 0.6364\n",
      "Epoch 121/1000\n",
      "178/178 [==============================] - 0s 79us/step - loss: 0.3088 - accuracy: 0.8764 - val_loss: 0.7604 - val_accuracy: 0.6364\n",
      "Epoch 122/1000\n",
      "178/178 [==============================] - 0s 81us/step - loss: 0.3071 - accuracy: 0.8708 - val_loss: 0.7616 - val_accuracy: 0.6364\n",
      "Epoch 123/1000\n",
      "178/178 [==============================] - 0s 83us/step - loss: 0.3048 - accuracy: 0.8876 - val_loss: 0.7646 - val_accuracy: 0.6364\n",
      "Epoch 124/1000\n",
      "178/178 [==============================] - 0s 97us/step - loss: 0.3035 - accuracy: 0.8708 - val_loss: 0.7652 - val_accuracy: 0.6623\n",
      "Epoch 125/1000\n",
      "178/178 [==============================] - 0s 94us/step - loss: 0.3018 - accuracy: 0.8820 - val_loss: 0.7705 - val_accuracy: 0.6494\n",
      "Epoch 126/1000\n",
      "178/178 [==============================] - 0s 98us/step - loss: 0.3009 - accuracy: 0.8820 - val_loss: 0.7743 - val_accuracy: 0.6364\n",
      "Epoch 127/1000\n",
      "178/178 [==============================] - 0s 88us/step - loss: 0.2978 - accuracy: 0.8764 - val_loss: 0.7717 - val_accuracy: 0.6623\n",
      "Epoch 128/1000\n",
      "178/178 [==============================] - 0s 132us/step - loss: 0.2970 - accuracy: 0.8820 - val_loss: 0.7741 - val_accuracy: 0.6623\n",
      "Epoch 129/1000\n",
      "178/178 [==============================] - 0s 107us/step - loss: 0.2966 - accuracy: 0.8820 - val_loss: 0.7747 - val_accuracy: 0.6623\n",
      "Epoch 130/1000\n",
      "178/178 [==============================] - 0s 102us/step - loss: 0.2938 - accuracy: 0.8876 - val_loss: 0.7823 - val_accuracy: 0.6364\n",
      "Epoch 131/1000\n",
      "178/178 [==============================] - 0s 92us/step - loss: 0.2933 - accuracy: 0.8989 - val_loss: 0.7794 - val_accuracy: 0.6623\n",
      "Epoch 132/1000\n",
      "178/178 [==============================] - 0s 104us/step - loss: 0.2912 - accuracy: 0.8764 - val_loss: 0.7862 - val_accuracy: 0.6494\n",
      "Epoch 133/1000\n",
      "178/178 [==============================] - 0s 99us/step - loss: 0.2893 - accuracy: 0.8933 - val_loss: 0.7919 - val_accuracy: 0.6364\n",
      "Epoch 134/1000\n",
      "178/178 [==============================] - 0s 88us/step - loss: 0.2889 - accuracy: 0.8933 - val_loss: 0.7930 - val_accuracy: 0.6494\n",
      "Epoch 135/1000\n",
      "178/178 [==============================] - 0s 90us/step - loss: 0.2888 - accuracy: 0.8876 - val_loss: 0.7947 - val_accuracy: 0.6623\n",
      "Epoch 136/1000\n",
      "178/178 [==============================] - 0s 98us/step - loss: 0.2858 - accuracy: 0.8933 - val_loss: 0.7960 - val_accuracy: 0.6623\n",
      "Epoch 137/1000\n",
      "178/178 [==============================] - 0s 94us/step - loss: 0.2841 - accuracy: 0.8820 - val_loss: 0.8012 - val_accuracy: 0.6494\n",
      "Epoch 138/1000\n",
      "178/178 [==============================] - 0s 89us/step - loss: 0.2833 - accuracy: 0.8989 - val_loss: 0.8017 - val_accuracy: 0.6364\n",
      "Epoch 139/1000\n",
      "178/178 [==============================] - 0s 90us/step - loss: 0.2814 - accuracy: 0.8989 - val_loss: 0.8023 - val_accuracy: 0.6494\n",
      "Epoch 140/1000\n",
      "178/178 [==============================] - 0s 86us/step - loss: 0.2803 - accuracy: 0.8989 - val_loss: 0.8072 - val_accuracy: 0.6364\n",
      "Epoch 141/1000\n",
      "178/178 [==============================] - 0s 87us/step - loss: 0.2788 - accuracy: 0.8933 - val_loss: 0.8101 - val_accuracy: 0.6364\n",
      "Epoch 142/1000\n",
      "178/178 [==============================] - 0s 84us/step - loss: 0.2790 - accuracy: 0.9045 - val_loss: 0.8152 - val_accuracy: 0.6364\n",
      "Epoch 143/1000\n",
      "178/178 [==============================] - 0s 93us/step - loss: 0.2766 - accuracy: 0.8933 - val_loss: 0.8140 - val_accuracy: 0.6494\n",
      "Epoch 144/1000\n",
      "178/178 [==============================] - 0s 96us/step - loss: 0.2749 - accuracy: 0.8989 - val_loss: 0.8148 - val_accuracy: 0.6623\n",
      "Epoch 145/1000\n",
      "178/178 [==============================] - 0s 98us/step - loss: 0.2735 - accuracy: 0.9045 - val_loss: 0.8189 - val_accuracy: 0.6494\n",
      "Epoch 146/1000\n",
      "178/178 [==============================] - 0s 102us/step - loss: 0.2733 - accuracy: 0.8989 - val_loss: 0.8216 - val_accuracy: 0.6494\n",
      "Epoch 147/1000\n",
      "178/178 [==============================] - 0s 84us/step - loss: 0.2719 - accuracy: 0.8933 - val_loss: 0.8266 - val_accuracy: 0.6494\n",
      "Epoch 148/1000\n",
      "178/178 [==============================] - 0s 104us/step - loss: 0.2703 - accuracy: 0.8989 - val_loss: 0.8303 - val_accuracy: 0.6364\n",
      "Epoch 149/1000\n",
      "178/178 [==============================] - 0s 94us/step - loss: 0.2694 - accuracy: 0.8933 - val_loss: 0.8301 - val_accuracy: 0.6494\n",
      "Epoch 150/1000\n",
      "178/178 [==============================] - 0s 86us/step - loss: 0.2672 - accuracy: 0.9045 - val_loss: 0.8336 - val_accuracy: 0.6494\n",
      "Epoch 151/1000\n",
      "178/178 [==============================] - 0s 88us/step - loss: 0.2673 - accuracy: 0.9045 - val_loss: 0.8343 - val_accuracy: 0.6494\n",
      "Epoch 152/1000\n",
      "178/178 [==============================] - 0s 100us/step - loss: 0.2667 - accuracy: 0.9101 - val_loss: 0.8390 - val_accuracy: 0.6494\n",
      "Epoch 153/1000\n",
      "178/178 [==============================] - 0s 88us/step - loss: 0.2641 - accuracy: 0.9213 - val_loss: 0.8436 - val_accuracy: 0.6494\n",
      "Epoch 154/1000\n",
      "178/178 [==============================] - 0s 90us/step - loss: 0.2641 - accuracy: 0.9101 - val_loss: 0.8465 - val_accuracy: 0.6494\n",
      "Epoch 155/1000\n",
      "178/178 [==============================] - 0s 82us/step - loss: 0.2620 - accuracy: 0.9045 - val_loss: 0.8471 - val_accuracy: 0.6494\n",
      "Epoch 156/1000\n",
      "178/178 [==============================] - 0s 100us/step - loss: 0.2601 - accuracy: 0.9157 - val_loss: 0.8517 - val_accuracy: 0.6494\n",
      "Epoch 157/1000\n",
      "178/178 [==============================] - 0s 105us/step - loss: 0.2610 - accuracy: 0.8989 - val_loss: 0.8510 - val_accuracy: 0.6494\n",
      "Epoch 158/1000\n",
      "178/178 [==============================] - 0s 84us/step - loss: 0.2587 - accuracy: 0.9101 - val_loss: 0.8562 - val_accuracy: 0.6494\n",
      "Epoch 159/1000\n",
      "178/178 [==============================] - 0s 99us/step - loss: 0.2572 - accuracy: 0.9101 - val_loss: 0.8574 - val_accuracy: 0.6494\n",
      "Epoch 160/1000\n",
      "178/178 [==============================] - 0s 84us/step - loss: 0.2578 - accuracy: 0.9157 - val_loss: 0.8618 - val_accuracy: 0.6494\n",
      "Epoch 161/1000\n",
      "178/178 [==============================] - 0s 90us/step - loss: 0.2559 - accuracy: 0.9101 - val_loss: 0.8626 - val_accuracy: 0.6494\n",
      "Epoch 162/1000\n",
      "178/178 [==============================] - 0s 78us/step - loss: 0.2543 - accuracy: 0.9045 - val_loss: 0.8651 - val_accuracy: 0.6494\n",
      "Epoch 163/1000\n",
      "178/178 [==============================] - 0s 89us/step - loss: 0.2537 - accuracy: 0.9045 - val_loss: 0.8701 - val_accuracy: 0.6494\n",
      "Epoch 164/1000\n",
      "178/178 [==============================] - 0s 100us/step - loss: 0.2529 - accuracy: 0.9045 - val_loss: 0.8715 - val_accuracy: 0.6494\n",
      "Epoch 165/1000\n",
      "178/178 [==============================] - 0s 94us/step - loss: 0.2517 - accuracy: 0.9101 - val_loss: 0.8679 - val_accuracy: 0.6494\n",
      "Epoch 166/1000\n",
      "178/178 [==============================] - 0s 103us/step - loss: 0.2507 - accuracy: 0.9101 - val_loss: 0.8706 - val_accuracy: 0.6494\n",
      "Epoch 167/1000\n",
      "178/178 [==============================] - 0s 98us/step - loss: 0.2483 - accuracy: 0.9101 - val_loss: 0.8720 - val_accuracy: 0.6494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 168/1000\n",
      "178/178 [==============================] - 0s 94us/step - loss: 0.2461 - accuracy: 0.9101 - val_loss: 0.8758 - val_accuracy: 0.6494\n",
      "Epoch 169/1000\n",
      "178/178 [==============================] - 0s 88us/step - loss: 0.2462 - accuracy: 0.9101 - val_loss: 0.8780 - val_accuracy: 0.6494\n",
      "Epoch 170/1000\n",
      "178/178 [==============================] - 0s 82us/step - loss: 0.2451 - accuracy: 0.9101 - val_loss: 0.8788 - val_accuracy: 0.6494\n",
      "Epoch 171/1000\n",
      "178/178 [==============================] - 0s 91us/step - loss: 0.2436 - accuracy: 0.9045 - val_loss: 0.8867 - val_accuracy: 0.6494\n",
      "Epoch 172/1000\n",
      "178/178 [==============================] - 0s 85us/step - loss: 0.2425 - accuracy: 0.9157 - val_loss: 0.8882 - val_accuracy: 0.6494\n",
      "Epoch 173/1000\n",
      "178/178 [==============================] - 0s 87us/step - loss: 0.2417 - accuracy: 0.9045 - val_loss: 0.8891 - val_accuracy: 0.6494\n",
      "Epoch 174/1000\n",
      "178/178 [==============================] - 0s 85us/step - loss: 0.2422 - accuracy: 0.9157 - val_loss: 0.8888 - val_accuracy: 0.6494\n",
      "Epoch 175/1000\n",
      "178/178 [==============================] - 0s 95us/step - loss: 0.2391 - accuracy: 0.9213 - val_loss: 0.8964 - val_accuracy: 0.6494\n",
      "Epoch 176/1000\n",
      "178/178 [==============================] - 0s 101us/step - loss: 0.2405 - accuracy: 0.9101 - val_loss: 0.8964 - val_accuracy: 0.6494\n",
      "Epoch 177/1000\n",
      "178/178 [==============================] - 0s 102us/step - loss: 0.2364 - accuracy: 0.9157 - val_loss: 0.8992 - val_accuracy: 0.6494\n",
      "Epoch 178/1000\n",
      "178/178 [==============================] - 0s 97us/step - loss: 0.2397 - accuracy: 0.9045 - val_loss: 0.8997 - val_accuracy: 0.6494\n",
      "Epoch 179/1000\n",
      "178/178 [==============================] - 0s 97us/step - loss: 0.2362 - accuracy: 0.9213 - val_loss: 0.9031 - val_accuracy: 0.6494\n",
      "Epoch 180/1000\n",
      "178/178 [==============================] - 0s 94us/step - loss: 0.2346 - accuracy: 0.9213 - val_loss: 0.9088 - val_accuracy: 0.6494\n",
      "Epoch 181/1000\n",
      "178/178 [==============================] - 0s 94us/step - loss: 0.2343 - accuracy: 0.9213 - val_loss: 0.9098 - val_accuracy: 0.6494\n",
      "Epoch 182/1000\n",
      "178/178 [==============================] - 0s 92us/step - loss: 0.2318 - accuracy: 0.9157 - val_loss: 0.9086 - val_accuracy: 0.6494\n",
      "Epoch 183/1000\n",
      "178/178 [==============================] - 0s 84us/step - loss: 0.2310 - accuracy: 0.9213 - val_loss: 0.9130 - val_accuracy: 0.6494\n",
      "Epoch 184/1000\n",
      "178/178 [==============================] - 0s 96us/step - loss: 0.2308 - accuracy: 0.9213 - val_loss: 0.9161 - val_accuracy: 0.6494\n",
      "Epoch 185/1000\n",
      "178/178 [==============================] - 0s 87us/step - loss: 0.2307 - accuracy: 0.9213 - val_loss: 0.9174 - val_accuracy: 0.6494\n",
      "Epoch 186/1000\n",
      "178/178 [==============================] - 0s 87us/step - loss: 0.2288 - accuracy: 0.9213 - val_loss: 0.9186 - val_accuracy: 0.6494\n",
      "Epoch 187/1000\n",
      "178/178 [==============================] - 0s 118us/step - loss: 0.2269 - accuracy: 0.9213 - val_loss: 0.9215 - val_accuracy: 0.6494\n",
      "Epoch 188/1000\n",
      "178/178 [==============================] - 0s 106us/step - loss: 0.2267 - accuracy: 0.9213 - val_loss: 0.9239 - val_accuracy: 0.6494\n",
      "Epoch 189/1000\n",
      "178/178 [==============================] - 0s 79us/step - loss: 0.2244 - accuracy: 0.9157 - val_loss: 0.9251 - val_accuracy: 0.6494\n",
      "Epoch 190/1000\n",
      "178/178 [==============================] - 0s 93us/step - loss: 0.2263 - accuracy: 0.9213 - val_loss: 0.9327 - val_accuracy: 0.6494\n",
      "Epoch 191/1000\n",
      "178/178 [==============================] - 0s 81us/step - loss: 0.2246 - accuracy: 0.9157 - val_loss: 0.9344 - val_accuracy: 0.6494\n",
      "Epoch 192/1000\n",
      "178/178 [==============================] - 0s 82us/step - loss: 0.2234 - accuracy: 0.9157 - val_loss: 0.9350 - val_accuracy: 0.6494\n",
      "Epoch 193/1000\n",
      "178/178 [==============================] - 0s 90us/step - loss: 0.2220 - accuracy: 0.9213 - val_loss: 0.9347 - val_accuracy: 0.6494\n",
      "Epoch 194/1000\n",
      "178/178 [==============================] - 0s 94us/step - loss: 0.2213 - accuracy: 0.9213 - val_loss: 0.9387 - val_accuracy: 0.6494\n",
      "Epoch 195/1000\n",
      "178/178 [==============================] - 0s 107us/step - loss: 0.2207 - accuracy: 0.9270 - val_loss: 0.9423 - val_accuracy: 0.6494\n",
      "Epoch 196/1000\n",
      "178/178 [==============================] - 0s 88us/step - loss: 0.2191 - accuracy: 0.9213 - val_loss: 0.9500 - val_accuracy: 0.6494\n",
      "Epoch 197/1000\n",
      "178/178 [==============================] - 0s 84us/step - loss: 0.2172 - accuracy: 0.9157 - val_loss: 0.9478 - val_accuracy: 0.6494\n",
      "Epoch 198/1000\n",
      "178/178 [==============================] - 0s 99us/step - loss: 0.2175 - accuracy: 0.9213 - val_loss: 0.9509 - val_accuracy: 0.6494\n",
      "Epoch 199/1000\n",
      "178/178 [==============================] - 0s 97us/step - loss: 0.2150 - accuracy: 0.9213 - val_loss: 0.9542 - val_accuracy: 0.6494\n",
      "Epoch 200/1000\n",
      "178/178 [==============================] - 0s 103us/step - loss: 0.2174 - accuracy: 0.9270 - val_loss: 0.9551 - val_accuracy: 0.6494\n",
      "Epoch 201/1000\n",
      "178/178 [==============================] - 0s 96us/step - loss: 0.2150 - accuracy: 0.9270 - val_loss: 0.9575 - val_accuracy: 0.6494\n",
      "Epoch 202/1000\n",
      "178/178 [==============================] - 0s 91us/step - loss: 0.2126 - accuracy: 0.9213 - val_loss: 0.9614 - val_accuracy: 0.6494\n",
      "Epoch 203/1000\n",
      "178/178 [==============================] - 0s 90us/step - loss: 0.2122 - accuracy: 0.9326 - val_loss: 0.9630 - val_accuracy: 0.6494\n",
      "Epoch 204/1000\n",
      "178/178 [==============================] - 0s 91us/step - loss: 0.2119 - accuracy: 0.9157 - val_loss: 0.9682 - val_accuracy: 0.6494\n",
      "Epoch 205/1000\n",
      "178/178 [==============================] - 0s 83us/step - loss: 0.2102 - accuracy: 0.9270 - val_loss: 0.9707 - val_accuracy: 0.6494\n",
      "Epoch 206/1000\n",
      "178/178 [==============================] - 0s 106us/step - loss: 0.2127 - accuracy: 0.9213 - val_loss: 0.9728 - val_accuracy: 0.6494\n",
      "Epoch 207/1000\n",
      "178/178 [==============================] - 0s 89us/step - loss: 0.2079 - accuracy: 0.9213 - val_loss: 0.9777 - val_accuracy: 0.6494\n",
      "Epoch 208/1000\n",
      "178/178 [==============================] - 0s 104us/step - loss: 0.2081 - accuracy: 0.9213 - val_loss: 0.9721 - val_accuracy: 0.6494\n",
      "Epoch 209/1000\n",
      "178/178 [==============================] - 0s 106us/step - loss: 0.2075 - accuracy: 0.9270 - val_loss: 0.9776 - val_accuracy: 0.6494\n",
      "Epoch 210/1000\n",
      "178/178 [==============================] - 0s 111us/step - loss: 0.2065 - accuracy: 0.9326 - val_loss: 0.9798 - val_accuracy: 0.6494\n",
      "Epoch 211/1000\n",
      "178/178 [==============================] - 0s 122us/step - loss: 0.2041 - accuracy: 0.9270 - val_loss: 0.9805 - val_accuracy: 0.6494\n",
      "Epoch 212/1000\n",
      "178/178 [==============================] - 0s 109us/step - loss: 0.2053 - accuracy: 0.9382 - val_loss: 0.9839 - val_accuracy: 0.6494\n",
      "Epoch 213/1000\n",
      "178/178 [==============================] - 0s 118us/step - loss: 0.2038 - accuracy: 0.9213 - val_loss: 0.9841 - val_accuracy: 0.6494\n",
      "Epoch 214/1000\n",
      "178/178 [==============================] - 0s 112us/step - loss: 0.2042 - accuracy: 0.9326 - val_loss: 0.9868 - val_accuracy: 0.6494\n",
      "Epoch 215/1000\n",
      "178/178 [==============================] - 0s 114us/step - loss: 0.2032 - accuracy: 0.9382 - val_loss: 0.9863 - val_accuracy: 0.6494\n",
      "Epoch 216/1000\n",
      "178/178 [==============================] - 0s 101us/step - loss: 0.2031 - accuracy: 0.9270 - val_loss: 0.9921 - val_accuracy: 0.6494\n",
      "Epoch 217/1000\n",
      "178/178 [==============================] - 0s 93us/step - loss: 0.2004 - accuracy: 0.9382 - val_loss: 0.9948 - val_accuracy: 0.6494\n",
      "Epoch 218/1000\n",
      "178/178 [==============================] - 0s 93us/step - loss: 0.1994 - accuracy: 0.9438 - val_loss: 1.0009 - val_accuracy: 0.6494\n",
      "Epoch 219/1000\n",
      "178/178 [==============================] - 0s 76us/step - loss: 0.1996 - accuracy: 0.9382 - val_loss: 1.0038 - val_accuracy: 0.6494\n",
      "Epoch 220/1000\n",
      "178/178 [==============================] - 0s 84us/step - loss: 0.1973 - accuracy: 0.9382 - val_loss: 1.0060 - val_accuracy: 0.6494\n",
      "Epoch 221/1000\n",
      "178/178 [==============================] - 0s 85us/step - loss: 0.1972 - accuracy: 0.9438 - val_loss: 1.0106 - val_accuracy: 0.6494\n",
      "Epoch 222/1000\n",
      "178/178 [==============================] - 0s 91us/step - loss: 0.1958 - accuracy: 0.9270 - val_loss: 1.0133 - val_accuracy: 0.6494\n",
      "Epoch 223/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 101us/step - loss: 0.1952 - accuracy: 0.9438 - val_loss: 1.0181 - val_accuracy: 0.6494\n",
      "Epoch 224/1000\n",
      "178/178 [==============================] - 0s 112us/step - loss: 0.1950 - accuracy: 0.9382 - val_loss: 1.0200 - val_accuracy: 0.6494\n",
      "Epoch 225/1000\n",
      "178/178 [==============================] - 0s 83us/step - loss: 0.1935 - accuracy: 0.9438 - val_loss: 1.0239 - val_accuracy: 0.6623\n",
      "Epoch 226/1000\n",
      "178/178 [==============================] - 0s 84us/step - loss: 0.1935 - accuracy: 0.9270 - val_loss: 1.0242 - val_accuracy: 0.6623\n",
      "Epoch 227/1000\n",
      "178/178 [==============================] - 0s 83us/step - loss: 0.1925 - accuracy: 0.9438 - val_loss: 1.0283 - val_accuracy: 0.6623\n",
      "Epoch 228/1000\n",
      "178/178 [==============================] - 0s 102us/step - loss: 0.1911 - accuracy: 0.9326 - val_loss: 1.0287 - val_accuracy: 0.6494\n",
      "Epoch 229/1000\n",
      "178/178 [==============================] - 0s 88us/step - loss: 0.1904 - accuracy: 0.9438 - val_loss: 1.0352 - val_accuracy: 0.6623\n",
      "Epoch 230/1000\n",
      "178/178 [==============================] - 0s 165us/step - loss: 0.1896 - accuracy: 0.9382 - val_loss: 1.0369 - val_accuracy: 0.6623\n",
      "Epoch 231/1000\n",
      "178/178 [==============================] - 0s 177us/step - loss: 0.1898 - accuracy: 0.9326 - val_loss: 1.0321 - val_accuracy: 0.6494\n",
      "Epoch 232/1000\n",
      "178/178 [==============================] - 0s 263us/step - loss: 0.1882 - accuracy: 0.9438 - val_loss: 1.0424 - val_accuracy: 0.6623\n",
      "Epoch 233/1000\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.3019 - accuracy: 0.87 - 0s 208us/step - loss: 0.1890 - accuracy: 0.9382 - val_loss: 1.0456 - val_accuracy: 0.6364\n",
      "Epoch 234/1000\n",
      "178/178 [==============================] - 0s 176us/step - loss: 0.1885 - accuracy: 0.9326 - val_loss: 1.0375 - val_accuracy: 0.6494\n",
      "Epoch 235/1000\n",
      "178/178 [==============================] - 0s 185us/step - loss: 0.1896 - accuracy: 0.9438 - val_loss: 1.0432 - val_accuracy: 0.6494\n",
      "Epoch 236/1000\n",
      "178/178 [==============================] - 0s 187us/step - loss: 0.1867 - accuracy: 0.9438 - val_loss: 1.0485 - val_accuracy: 0.6623\n",
      "Epoch 237/1000\n",
      "178/178 [==============================] - 0s 155us/step - loss: 0.1841 - accuracy: 0.9438 - val_loss: 1.0530 - val_accuracy: 0.6623\n",
      "Epoch 238/1000\n",
      "178/178 [==============================] - 0s 172us/step - loss: 0.1835 - accuracy: 0.9438 - val_loss: 1.0510 - val_accuracy: 0.6494\n",
      "Epoch 239/1000\n",
      "178/178 [==============================] - 0s 111us/step - loss: 0.1840 - accuracy: 0.9382 - val_loss: 1.0574 - val_accuracy: 0.6623\n",
      "Epoch 240/1000\n",
      "178/178 [==============================] - 0s 113us/step - loss: 0.1833 - accuracy: 0.9438 - val_loss: 1.0597 - val_accuracy: 0.6494\n",
      "Epoch 241/1000\n",
      "178/178 [==============================] - 0s 91us/step - loss: 0.1822 - accuracy: 0.9438 - val_loss: 1.0626 - val_accuracy: 0.6494\n",
      "Epoch 242/1000\n",
      "178/178 [==============================] - 0s 152us/step - loss: 0.1833 - accuracy: 0.9382 - val_loss: 1.0647 - val_accuracy: 0.6623\n",
      "Epoch 243/1000\n",
      "178/178 [==============================] - 0s 127us/step - loss: 0.1803 - accuracy: 0.9438 - val_loss: 1.0665 - val_accuracy: 0.6494\n",
      "Epoch 244/1000\n",
      "178/178 [==============================] - 0s 131us/step - loss: 0.1800 - accuracy: 0.9438 - val_loss: 1.0770 - val_accuracy: 0.6623\n",
      "Epoch 245/1000\n",
      "178/178 [==============================] - 0s 100us/step - loss: 0.1792 - accuracy: 0.9438 - val_loss: 1.0759 - val_accuracy: 0.6623\n",
      "Epoch 246/1000\n",
      "178/178 [==============================] - 0s 133us/step - loss: 0.1791 - accuracy: 0.9438 - val_loss: 1.0777 - val_accuracy: 0.6623\n",
      "Epoch 247/1000\n",
      "178/178 [==============================] - 0s 109us/step - loss: 0.1786 - accuracy: 0.9438 - val_loss: 1.0781 - val_accuracy: 0.6623\n",
      "Epoch 248/1000\n",
      "178/178 [==============================] - 0s 108us/step - loss: 0.1785 - accuracy: 0.9438 - val_loss: 1.0825 - val_accuracy: 0.6623\n",
      "Epoch 249/1000\n",
      "178/178 [==============================] - 0s 107us/step - loss: 0.1777 - accuracy: 0.9494 - val_loss: 1.0926 - val_accuracy: 0.6623\n",
      "Epoch 250/1000\n",
      "178/178 [==============================] - 0s 120us/step - loss: 0.1769 - accuracy: 0.9494 - val_loss: 1.0861 - val_accuracy: 0.6494\n",
      "Epoch 251/1000\n",
      "178/178 [==============================] - 0s 93us/step - loss: 0.1758 - accuracy: 0.9438 - val_loss: 1.0941 - val_accuracy: 0.6623\n",
      "Epoch 252/1000\n",
      "178/178 [==============================] - 0s 86us/step - loss: 0.1745 - accuracy: 0.9438 - val_loss: 1.0913 - val_accuracy: 0.6494\n",
      "Epoch 253/1000\n",
      "178/178 [==============================] - 0s 118us/step - loss: 0.1744 - accuracy: 0.9438 - val_loss: 1.0962 - val_accuracy: 0.6623\n",
      "Epoch 254/1000\n",
      "178/178 [==============================] - 0s 88us/step - loss: 0.1736 - accuracy: 0.9438 - val_loss: 1.1002 - val_accuracy: 0.6623\n",
      "Epoch 255/1000\n",
      "178/178 [==============================] - 0s 88us/step - loss: 0.1745 - accuracy: 0.9382 - val_loss: 1.0999 - val_accuracy: 0.6494\n",
      "Epoch 256/1000\n",
      "178/178 [==============================] - 0s 101us/step - loss: 0.1772 - accuracy: 0.9494 - val_loss: 1.1050 - val_accuracy: 0.6623\n",
      "Epoch 257/1000\n",
      "178/178 [==============================] - 0s 81us/step - loss: 0.1719 - accuracy: 0.9438 - val_loss: 1.1084 - val_accuracy: 0.6364\n",
      "Epoch 258/1000\n",
      "178/178 [==============================] - 0s 85us/step - loss: 0.1720 - accuracy: 0.9382 - val_loss: 1.1103 - val_accuracy: 0.6494\n",
      "Epoch 259/1000\n",
      "178/178 [==============================] - 0s 89us/step - loss: 0.1725 - accuracy: 0.9494 - val_loss: 1.1127 - val_accuracy: 0.6623\n",
      "Epoch 260/1000\n",
      "178/178 [==============================] - 0s 94us/step - loss: 0.1698 - accuracy: 0.9382 - val_loss: 1.1091 - val_accuracy: 0.6494\n",
      "Epoch 261/1000\n",
      "178/178 [==============================] - 0s 90us/step - loss: 0.1702 - accuracy: 0.9494 - val_loss: 1.1182 - val_accuracy: 0.6364\n",
      "Epoch 262/1000\n",
      "178/178 [==============================] - 0s 113us/step - loss: 0.1704 - accuracy: 0.9438 - val_loss: 1.1172 - val_accuracy: 0.6623\n",
      "Epoch 263/1000\n",
      "178/178 [==============================] - 0s 121us/step - loss: 0.1704 - accuracy: 0.9382 - val_loss: 1.1205 - val_accuracy: 0.6364\n",
      "Epoch 264/1000\n",
      "178/178 [==============================] - 0s 132us/step - loss: 0.1673 - accuracy: 0.9438 - val_loss: 1.1205 - val_accuracy: 0.6623\n",
      "Epoch 265/1000\n",
      "178/178 [==============================] - 0s 122us/step - loss: 0.1668 - accuracy: 0.9494 - val_loss: 1.1294 - val_accuracy: 0.6364\n",
      "Epoch 266/1000\n",
      "178/178 [==============================] - 0s 159us/step - loss: 0.1669 - accuracy: 0.9382 - val_loss: 1.1324 - val_accuracy: 0.6623\n",
      "Epoch 267/1000\n",
      "178/178 [==============================] - 0s 199us/step - loss: 0.1664 - accuracy: 0.9382 - val_loss: 1.1306 - val_accuracy: 0.6623\n",
      "Epoch 268/1000\n",
      "178/178 [==============================] - 0s 226us/step - loss: 0.1670 - accuracy: 0.9438 - val_loss: 1.1308 - val_accuracy: 0.6623\n",
      "Epoch 269/1000\n",
      "178/178 [==============================] - 0s 152us/step - loss: 0.1667 - accuracy: 0.9494 - val_loss: 1.1350 - val_accuracy: 0.6623\n",
      "Epoch 270/1000\n",
      "178/178 [==============================] - 0s 153us/step - loss: 0.1643 - accuracy: 0.9438 - val_loss: 1.1367 - val_accuracy: 0.6623\n",
      "Epoch 271/1000\n",
      "178/178 [==============================] - 0s 131us/step - loss: 0.1637 - accuracy: 0.9494 - val_loss: 1.1354 - val_accuracy: 0.6623\n",
      "Epoch 272/1000\n",
      "178/178 [==============================] - 0s 158us/step - loss: 0.1634 - accuracy: 0.9494 - val_loss: 1.1395 - val_accuracy: 0.6623\n",
      "Epoch 273/1000\n",
      "178/178 [==============================] - 0s 180us/step - loss: 0.1624 - accuracy: 0.9494 - val_loss: 1.1514 - val_accuracy: 0.6623\n",
      "Epoch 274/1000\n",
      "178/178 [==============================] - 0s 159us/step - loss: 0.1627 - accuracy: 0.9438 - val_loss: 1.1497 - val_accuracy: 0.6623\n",
      "Epoch 275/1000\n",
      "178/178 [==============================] - 0s 115us/step - loss: 0.1627 - accuracy: 0.9494 - val_loss: 1.1485 - val_accuracy: 0.6623\n",
      "Epoch 276/1000\n",
      "178/178 [==============================] - 0s 119us/step - loss: 0.1616 - accuracy: 0.9438 - val_loss: 1.1621 - val_accuracy: 0.6623\n",
      "Epoch 277/1000\n",
      "178/178 [==============================] - 0s 103us/step - loss: 0.1618 - accuracy: 0.9494 - val_loss: 1.1720 - val_accuracy: 0.6364\n",
      "Epoch 278/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 104us/step - loss: 0.1623 - accuracy: 0.9494 - val_loss: 1.1705 - val_accuracy: 0.6364\n",
      "Epoch 279/1000\n",
      "178/178 [==============================] - 0s 91us/step - loss: 0.1603 - accuracy: 0.9494 - val_loss: 1.1632 - val_accuracy: 0.6623\n",
      "Epoch 280/1000\n",
      "178/178 [==============================] - 0s 86us/step - loss: 0.1599 - accuracy: 0.9438 - val_loss: 1.1629 - val_accuracy: 0.6494\n",
      "Epoch 281/1000\n",
      "178/178 [==============================] - 0s 104us/step - loss: 0.1596 - accuracy: 0.9494 - val_loss: 1.1689 - val_accuracy: 0.6623\n",
      "Epoch 282/1000\n",
      "178/178 [==============================] - 0s 94us/step - loss: 0.1590 - accuracy: 0.9494 - val_loss: 1.1745 - val_accuracy: 0.6623\n",
      "Epoch 283/1000\n",
      "178/178 [==============================] - 0s 102us/step - loss: 0.1595 - accuracy: 0.9494 - val_loss: 1.1786 - val_accuracy: 0.6364\n",
      "Epoch 284/1000\n",
      "178/178 [==============================] - 0s 142us/step - loss: 0.1581 - accuracy: 0.9551 - val_loss: 1.1780 - val_accuracy: 0.6623\n",
      "Epoch 285/1000\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.1320 - accuracy: 0.96 - 0s 162us/step - loss: 0.1575 - accuracy: 0.9551 - val_loss: 1.1810 - val_accuracy: 0.6364\n",
      "Epoch 286/1000\n",
      "178/178 [==============================] - 0s 155us/step - loss: 0.1558 - accuracy: 0.9438 - val_loss: 1.1729 - val_accuracy: 0.6494\n",
      "Epoch 287/1000\n",
      "178/178 [==============================] - 0s 144us/step - loss: 0.1564 - accuracy: 0.9494 - val_loss: 1.1833 - val_accuracy: 0.6623\n",
      "Epoch 288/1000\n",
      "178/178 [==============================] - 0s 182us/step - loss: 0.1564 - accuracy: 0.9494 - val_loss: 1.1859 - val_accuracy: 0.6494\n",
      "Epoch 289/1000\n",
      "178/178 [==============================] - 0s 172us/step - loss: 0.1554 - accuracy: 0.9494 - val_loss: 1.1901 - val_accuracy: 0.6623\n",
      "Epoch 290/1000\n",
      "178/178 [==============================] - 0s 153us/step - loss: 0.1544 - accuracy: 0.9551 - val_loss: 1.1945 - val_accuracy: 0.6494\n",
      "Epoch 291/1000\n",
      "178/178 [==============================] - 0s 149us/step - loss: 0.1530 - accuracy: 0.9494 - val_loss: 1.1977 - val_accuracy: 0.6494\n",
      "Epoch 292/1000\n",
      "178/178 [==============================] - 0s 184us/step - loss: 0.1528 - accuracy: 0.9494 - val_loss: 1.2026 - val_accuracy: 0.6623\n",
      "Epoch 293/1000\n",
      "178/178 [==============================] - 0s 166us/step - loss: 0.1527 - accuracy: 0.9551 - val_loss: 1.2060 - val_accuracy: 0.6623\n",
      "Epoch 294/1000\n",
      "178/178 [==============================] - 0s 188us/step - loss: 0.1521 - accuracy: 0.9551 - val_loss: 1.1998 - val_accuracy: 0.6494\n",
      "Epoch 295/1000\n",
      "178/178 [==============================] - 0s 195us/step - loss: 0.1518 - accuracy: 0.9551 - val_loss: 1.2129 - val_accuracy: 0.6623\n",
      "Epoch 296/1000\n",
      "178/178 [==============================] - 0s 206us/step - loss: 0.1511 - accuracy: 0.9551 - val_loss: 1.2136 - val_accuracy: 0.6623\n",
      "Epoch 297/1000\n",
      "178/178 [==============================] - 0s 114us/step - loss: 0.1509 - accuracy: 0.9438 - val_loss: 1.2118 - val_accuracy: 0.6494\n",
      "Epoch 298/1000\n",
      "178/178 [==============================] - 0s 119us/step - loss: 0.1504 - accuracy: 0.9494 - val_loss: 1.2241 - val_accuracy: 0.6364\n",
      "Epoch 299/1000\n",
      "178/178 [==============================] - 0s 166us/step - loss: 0.1497 - accuracy: 0.9607 - val_loss: 1.2264 - val_accuracy: 0.6623\n",
      "Epoch 300/1000\n",
      "178/178 [==============================] - 0s 157us/step - loss: 0.1500 - accuracy: 0.9551 - val_loss: 1.2226 - val_accuracy: 0.6494\n",
      "Epoch 301/1000\n",
      "178/178 [==============================] - 0s 149us/step - loss: 0.1494 - accuracy: 0.9551 - val_loss: 1.2298 - val_accuracy: 0.6623\n",
      "Epoch 302/1000\n",
      "178/178 [==============================] - 0s 132us/step - loss: 0.1487 - accuracy: 0.9494 - val_loss: 1.2265 - val_accuracy: 0.6494\n",
      "Epoch 303/1000\n",
      "178/178 [==============================] - 0s 127us/step - loss: 0.1523 - accuracy: 0.9494 - val_loss: 1.2296 - val_accuracy: 0.6623\n",
      "Epoch 304/1000\n",
      "178/178 [==============================] - 0s 135us/step - loss: 0.1472 - accuracy: 0.9551 - val_loss: 1.2248 - val_accuracy: 0.6494\n",
      "Epoch 305/1000\n",
      "178/178 [==============================] - 0s 138us/step - loss: 0.1484 - accuracy: 0.9494 - val_loss: 1.2386 - val_accuracy: 0.6623\n",
      "Epoch 306/1000\n",
      "178/178 [==============================] - 0s 163us/step - loss: 0.1470 - accuracy: 0.9551 - val_loss: 1.2406 - val_accuracy: 0.6623\n",
      "Epoch 307/1000\n",
      "178/178 [==============================] - 0s 138us/step - loss: 0.1474 - accuracy: 0.9607 - val_loss: 1.2493 - val_accuracy: 0.6494\n",
      "Epoch 308/1000\n",
      "178/178 [==============================] - 0s 151us/step - loss: 0.1487 - accuracy: 0.9551 - val_loss: 1.2503 - val_accuracy: 0.6234\n",
      "Epoch 309/1000\n",
      "178/178 [==============================] - 0s 121us/step - loss: 0.1478 - accuracy: 0.9551 - val_loss: 1.2431 - val_accuracy: 0.6623\n",
      "Epoch 310/1000\n",
      "178/178 [==============================] - 0s 163us/step - loss: 0.1447 - accuracy: 0.9607 - val_loss: 1.2400 - val_accuracy: 0.6623\n",
      "Epoch 311/1000\n",
      "178/178 [==============================] - 0s 145us/step - loss: 0.1464 - accuracy: 0.9607 - val_loss: 1.2414 - val_accuracy: 0.6623\n",
      "Epoch 312/1000\n",
      "178/178 [==============================] - 0s 164us/step - loss: 0.1442 - accuracy: 0.9607 - val_loss: 1.2444 - val_accuracy: 0.6623\n",
      "Epoch 313/1000\n",
      "178/178 [==============================] - 0s 138us/step - loss: 0.1439 - accuracy: 0.9607 - val_loss: 1.2507 - val_accuracy: 0.6623\n",
      "Epoch 314/1000\n",
      "178/178 [==============================] - 0s 116us/step - loss: 0.1443 - accuracy: 0.9551 - val_loss: 1.2553 - val_accuracy: 0.6623\n",
      "Epoch 315/1000\n",
      "178/178 [==============================] - 0s 109us/step - loss: 0.1440 - accuracy: 0.9607 - val_loss: 1.2427 - val_accuracy: 0.6494\n",
      "Epoch 316/1000\n",
      "178/178 [==============================] - 0s 100us/step - loss: 0.1437 - accuracy: 0.9494 - val_loss: 1.2541 - val_accuracy: 0.6623\n",
      "Epoch 317/1000\n",
      "178/178 [==============================] - 0s 121us/step - loss: 0.1418 - accuracy: 0.9607 - val_loss: 1.2599 - val_accuracy: 0.6623\n",
      "Epoch 318/1000\n",
      "178/178 [==============================] - 0s 117us/step - loss: 0.1417 - accuracy: 0.9607 - val_loss: 1.2615 - val_accuracy: 0.6623\n",
      "Epoch 319/1000\n",
      "178/178 [==============================] - 0s 123us/step - loss: 0.1424 - accuracy: 0.9607 - val_loss: 1.2635 - val_accuracy: 0.6623\n",
      "Epoch 320/1000\n",
      "178/178 [==============================] - 0s 116us/step - loss: 0.1420 - accuracy: 0.9607 - val_loss: 1.2699 - val_accuracy: 0.6494\n",
      "Epoch 321/1000\n",
      "178/178 [==============================] - 0s 121us/step - loss: 0.1405 - accuracy: 0.9607 - val_loss: 1.2711 - val_accuracy: 0.6623\n",
      "Epoch 322/1000\n",
      "178/178 [==============================] - 0s 123us/step - loss: 0.1396 - accuracy: 0.9663 - val_loss: 1.2828 - val_accuracy: 0.6364\n",
      "Epoch 323/1000\n",
      "178/178 [==============================] - 0s 114us/step - loss: 0.1399 - accuracy: 0.9663 - val_loss: 1.2741 - val_accuracy: 0.6623\n",
      "Epoch 324/1000\n",
      "178/178 [==============================] - 0s 125us/step - loss: 0.1427 - accuracy: 0.9494 - val_loss: 1.2873 - val_accuracy: 0.6623\n",
      "Epoch 325/1000\n",
      "178/178 [==============================] - 0s 97us/step - loss: 0.1387 - accuracy: 0.9663 - val_loss: 1.2866 - val_accuracy: 0.6494\n",
      "Epoch 326/1000\n",
      "178/178 [==============================] - 0s 89us/step - loss: 0.1387 - accuracy: 0.9663 - val_loss: 1.2767 - val_accuracy: 0.6494\n",
      "Epoch 327/1000\n",
      "178/178 [==============================] - 0s 84us/step - loss: 0.1382 - accuracy: 0.9719 - val_loss: 1.2868 - val_accuracy: 0.6494\n",
      "Epoch 328/1000\n",
      "178/178 [==============================] - 0s 82us/step - loss: 0.1380 - accuracy: 0.9663 - val_loss: 1.2814 - val_accuracy: 0.6494\n",
      "Epoch 329/1000\n",
      "178/178 [==============================] - 0s 83us/step - loss: 0.1375 - accuracy: 0.9607 - val_loss: 1.2882 - val_accuracy: 0.6494\n",
      "Epoch 330/1000\n",
      "178/178 [==============================] - 0s 87us/step - loss: 0.1370 - accuracy: 0.9663 - val_loss: 1.2829 - val_accuracy: 0.6494\n",
      "Epoch 331/1000\n",
      "178/178 [==============================] - 0s 97us/step - loss: 0.1363 - accuracy: 0.9663 - val_loss: 1.3006 - val_accuracy: 0.6623\n",
      "Epoch 332/1000\n",
      "178/178 [==============================] - 0s 94us/step - loss: 0.1366 - accuracy: 0.9719 - val_loss: 1.2972 - val_accuracy: 0.6623\n",
      "Epoch 333/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 85us/step - loss: 0.1352 - accuracy: 0.9663 - val_loss: 1.3038 - val_accuracy: 0.6623\n",
      "Epoch 334/1000\n",
      "178/178 [==============================] - 0s 87us/step - loss: 0.1363 - accuracy: 0.9607 - val_loss: 1.2916 - val_accuracy: 0.6494\n",
      "Epoch 335/1000\n",
      "178/178 [==============================] - 0s 103us/step - loss: 0.1353 - accuracy: 0.9663 - val_loss: 1.3060 - val_accuracy: 0.6623\n",
      "Epoch 336/1000\n",
      "178/178 [==============================] - 0s 88us/step - loss: 0.1349 - accuracy: 0.9663 - val_loss: 1.3093 - val_accuracy: 0.6494\n",
      "Epoch 337/1000\n",
      "178/178 [==============================] - 0s 93us/step - loss: 0.1353 - accuracy: 0.9663 - val_loss: 1.3039 - val_accuracy: 0.6494\n",
      "Epoch 338/1000\n",
      "178/178 [==============================] - 0s 266us/step - loss: 0.1340 - accuracy: 0.9607 - val_loss: 1.3096 - val_accuracy: 0.6623\n",
      "Epoch 339/1000\n",
      "178/178 [==============================] - 0s 134us/step - loss: 0.1366 - accuracy: 0.9663 - val_loss: 1.2977 - val_accuracy: 0.6494\n",
      "Epoch 340/1000\n",
      "178/178 [==============================] - 0s 201us/step - loss: 0.1352 - accuracy: 0.9663 - val_loss: 1.3117 - val_accuracy: 0.6494\n",
      "Epoch 341/1000\n",
      "178/178 [==============================] - 0s 239us/step - loss: 0.1323 - accuracy: 0.9719 - val_loss: 1.3138 - val_accuracy: 0.6623\n",
      "Epoch 342/1000\n",
      "178/178 [==============================] - 0s 240us/step - loss: 0.1358 - accuracy: 0.9663 - val_loss: 1.3188 - val_accuracy: 0.6623\n",
      "Epoch 343/1000\n",
      "178/178 [==============================] - 0s 176us/step - loss: 0.1324 - accuracy: 0.9719 - val_loss: 1.3311 - val_accuracy: 0.6364\n",
      "Epoch 344/1000\n",
      "178/178 [==============================] - 0s 142us/step - loss: 0.1322 - accuracy: 0.9719 - val_loss: 1.3271 - val_accuracy: 0.6623\n",
      "Epoch 345/1000\n",
      "178/178 [==============================] - 0s 211us/step - loss: 0.1316 - accuracy: 0.9719 - val_loss: 1.3245 - val_accuracy: 0.6623\n",
      "Epoch 346/1000\n",
      "178/178 [==============================] - 0s 216us/step - loss: 0.1304 - accuracy: 0.9719 - val_loss: 1.3215 - val_accuracy: 0.6494\n",
      "Epoch 347/1000\n",
      "178/178 [==============================] - 0s 181us/step - loss: 0.1334 - accuracy: 0.9719 - val_loss: 1.3354 - val_accuracy: 0.6623\n",
      "Epoch 348/1000\n",
      "178/178 [==============================] - 0s 151us/step - loss: 0.1310 - accuracy: 0.9719 - val_loss: 1.3358 - val_accuracy: 0.6623\n",
      "Epoch 349/1000\n",
      "178/178 [==============================] - 0s 166us/step - loss: 0.1300 - accuracy: 0.9775 - val_loss: 1.3408 - val_accuracy: 0.6623\n",
      "Epoch 350/1000\n",
      "178/178 [==============================] - 0s 215us/step - loss: 0.1313 - accuracy: 0.9607 - val_loss: 1.3369 - val_accuracy: 0.6623\n",
      "Epoch 351/1000\n",
      "178/178 [==============================] - 0s 159us/step - loss: 0.1289 - accuracy: 0.9719 - val_loss: 1.3404 - val_accuracy: 0.6623\n",
      "Epoch 352/1000\n",
      "178/178 [==============================] - 0s 135us/step - loss: 0.1287 - accuracy: 0.9663 - val_loss: 1.3337 - val_accuracy: 0.6494\n",
      "Epoch 353/1000\n",
      "178/178 [==============================] - 0s 192us/step - loss: 0.1306 - accuracy: 0.9719 - val_loss: 1.3417 - val_accuracy: 0.6623\n",
      "Epoch 354/1000\n",
      "178/178 [==============================] - 0s 141us/step - loss: 0.1298 - accuracy: 0.9775 - val_loss: 1.3519 - val_accuracy: 0.6623\n",
      "Epoch 355/1000\n",
      "178/178 [==============================] - 0s 129us/step - loss: 0.1278 - accuracy: 0.9663 - val_loss: 1.3477 - val_accuracy: 0.6623\n",
      "Epoch 356/1000\n",
      "178/178 [==============================] - 0s 149us/step - loss: 0.1289 - accuracy: 0.9663 - val_loss: 1.3525 - val_accuracy: 0.6623\n",
      "Epoch 357/1000\n",
      "178/178 [==============================] - 0s 110us/step - loss: 0.1283 - accuracy: 0.9775 - val_loss: 1.3612 - val_accuracy: 0.6623\n",
      "Epoch 358/1000\n",
      "178/178 [==============================] - 0s 120us/step - loss: 0.1257 - accuracy: 0.9775 - val_loss: 1.3591 - val_accuracy: 0.6623\n",
      "Epoch 359/1000\n",
      "178/178 [==============================] - 0s 124us/step - loss: 0.1267 - accuracy: 0.9663 - val_loss: 1.3602 - val_accuracy: 0.6623\n",
      "Epoch 360/1000\n",
      "178/178 [==============================] - 0s 140us/step - loss: 0.1259 - accuracy: 0.9775 - val_loss: 1.3586 - val_accuracy: 0.6623\n",
      "Epoch 361/1000\n",
      "178/178 [==============================] - 0s 129us/step - loss: 0.1260 - accuracy: 0.9775 - val_loss: 1.3546 - val_accuracy: 0.6623\n",
      "Epoch 362/1000\n",
      "178/178 [==============================] - 0s 122us/step - loss: 0.1262 - accuracy: 0.9775 - val_loss: 1.3593 - val_accuracy: 0.6623\n",
      "Epoch 363/1000\n",
      "178/178 [==============================] - 0s 174us/step - loss: 0.1260 - accuracy: 0.9775 - val_loss: 1.3708 - val_accuracy: 0.6623\n",
      "Epoch 364/1000\n",
      "178/178 [==============================] - 0s 173us/step - loss: 0.1255 - accuracy: 0.9775 - val_loss: 1.3739 - val_accuracy: 0.6623\n",
      "Epoch 365/1000\n",
      "178/178 [==============================] - 0s 160us/step - loss: 0.1233 - accuracy: 0.9775 - val_loss: 1.3703 - val_accuracy: 0.6623\n",
      "Epoch 366/1000\n",
      "178/178 [==============================] - 0s 139us/step - loss: 0.1260 - accuracy: 0.9775 - val_loss: 1.3779 - val_accuracy: 0.6623\n",
      "Epoch 367/1000\n",
      "178/178 [==============================] - 0s 118us/step - loss: 0.1232 - accuracy: 0.9775 - val_loss: 1.3754 - val_accuracy: 0.6623\n",
      "Epoch 368/1000\n",
      "178/178 [==============================] - 0s 121us/step - loss: 0.1254 - accuracy: 0.9775 - val_loss: 1.3730 - val_accuracy: 0.6623\n",
      "Epoch 369/1000\n",
      "178/178 [==============================] - 0s 119us/step - loss: 0.1245 - accuracy: 0.9775 - val_loss: 1.3810 - val_accuracy: 0.6623\n",
      "Epoch 370/1000\n",
      "178/178 [==============================] - 0s 117us/step - loss: 0.1219 - accuracy: 0.9775 - val_loss: 1.3838 - val_accuracy: 0.6623\n",
      "Epoch 371/1000\n",
      "178/178 [==============================] - 0s 110us/step - loss: 0.1254 - accuracy: 0.9775 - val_loss: 1.3876 - val_accuracy: 0.6623\n",
      "Epoch 372/1000\n",
      "178/178 [==============================] - 0s 98us/step - loss: 0.1220 - accuracy: 0.9719 - val_loss: 1.3815 - val_accuracy: 0.6623\n",
      "Epoch 373/1000\n",
      "178/178 [==============================] - 0s 90us/step - loss: 0.1226 - accuracy: 0.9775 - val_loss: 1.3839 - val_accuracy: 0.6623\n",
      "Epoch 374/1000\n",
      "178/178 [==============================] - 0s 82us/step - loss: 0.1209 - accuracy: 0.9775 - val_loss: 1.3884 - val_accuracy: 0.6623\n",
      "Epoch 375/1000\n",
      "178/178 [==============================] - 0s 101us/step - loss: 0.1215 - accuracy: 0.9775 - val_loss: 1.3893 - val_accuracy: 0.6623\n",
      "Epoch 376/1000\n",
      "178/178 [==============================] - 0s 99us/step - loss: 0.1224 - accuracy: 0.9719 - val_loss: 1.3903 - val_accuracy: 0.6623\n",
      "Epoch 377/1000\n",
      "178/178 [==============================] - 0s 89us/step - loss: 0.1200 - accuracy: 0.9775 - val_loss: 1.3924 - val_accuracy: 0.6623\n",
      "Epoch 378/1000\n",
      "178/178 [==============================] - 0s 89us/step - loss: 0.1206 - accuracy: 0.9775 - val_loss: 1.3950 - val_accuracy: 0.6623\n",
      "Epoch 379/1000\n",
      "178/178 [==============================] - 0s 93us/step - loss: 0.1199 - accuracy: 0.9775 - val_loss: 1.3973 - val_accuracy: 0.6623\n",
      "Epoch 380/1000\n",
      "178/178 [==============================] - 0s 92us/step - loss: 0.1203 - accuracy: 0.9775 - val_loss: 1.4015 - val_accuracy: 0.6623\n",
      "Epoch 381/1000\n",
      "178/178 [==============================] - 0s 97us/step - loss: 0.1191 - accuracy: 0.9775 - val_loss: 1.4047 - val_accuracy: 0.6623\n",
      "Epoch 382/1000\n",
      "178/178 [==============================] - 0s 88us/step - loss: 0.1195 - accuracy: 0.9775 - val_loss: 1.4014 - val_accuracy: 0.6623\n",
      "Epoch 383/1000\n",
      "178/178 [==============================] - 0s 88us/step - loss: 0.1194 - accuracy: 0.9775 - val_loss: 1.4122 - val_accuracy: 0.6623\n",
      "Epoch 384/1000\n",
      "178/178 [==============================] - 0s 92us/step - loss: 0.1201 - accuracy: 0.9775 - val_loss: 1.4141 - val_accuracy: 0.6623\n",
      "Epoch 385/1000\n",
      "178/178 [==============================] - 0s 86us/step - loss: 0.1183 - accuracy: 0.9775 - val_loss: 1.4165 - val_accuracy: 0.6623\n",
      "Epoch 386/1000\n",
      "178/178 [==============================] - 0s 90us/step - loss: 0.1189 - accuracy: 0.9775 - val_loss: 1.4298 - val_accuracy: 0.6364\n",
      "Epoch 387/1000\n",
      "178/178 [==============================] - 0s 95us/step - loss: 0.1169 - accuracy: 0.9719 - val_loss: 1.4185 - val_accuracy: 0.6623\n",
      "Epoch 388/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 89us/step - loss: 0.1184 - accuracy: 0.9775 - val_loss: 1.4171 - val_accuracy: 0.6494\n",
      "Epoch 389/1000\n",
      "178/178 [==============================] - 0s 126us/step - loss: 0.1187 - accuracy: 0.9775 - val_loss: 1.4301 - val_accuracy: 0.6623\n",
      "Epoch 390/1000\n",
      "178/178 [==============================] - 0s 152us/step - loss: 0.1159 - accuracy: 0.9775 - val_loss: 1.4407 - val_accuracy: 0.6623\n",
      "Epoch 391/1000\n",
      "178/178 [==============================] - 0s 167us/step - loss: 0.1174 - accuracy: 0.9775 - val_loss: 1.4363 - val_accuracy: 0.6623\n",
      "Epoch 392/1000\n",
      "178/178 [==============================] - 0s 212us/step - loss: 0.1185 - accuracy: 0.9775 - val_loss: 1.4316 - val_accuracy: 0.6623\n",
      "Epoch 393/1000\n",
      "178/178 [==============================] - 0s 182us/step - loss: 0.1152 - accuracy: 0.9775 - val_loss: 1.4371 - val_accuracy: 0.6623\n",
      "Epoch 394/1000\n",
      "178/178 [==============================] - 0s 172us/step - loss: 0.1157 - accuracy: 0.9775 - val_loss: 1.4337 - val_accuracy: 0.6623\n",
      "Epoch 395/1000\n",
      "178/178 [==============================] - 0s 146us/step - loss: 0.1154 - accuracy: 0.9775 - val_loss: 1.4352 - val_accuracy: 0.6623\n",
      "Epoch 396/1000\n",
      "178/178 [==============================] - 0s 105us/step - loss: 0.1164 - accuracy: 0.9775 - val_loss: 1.4379 - val_accuracy: 0.6623\n",
      "Epoch 397/1000\n",
      "178/178 [==============================] - 0s 104us/step - loss: 0.1146 - accuracy: 0.9775 - val_loss: 1.4471 - val_accuracy: 0.6623\n",
      "Epoch 398/1000\n",
      "178/178 [==============================] - 0s 95us/step - loss: 0.1143 - accuracy: 0.9775 - val_loss: 1.4466 - val_accuracy: 0.6623\n",
      "Epoch 399/1000\n",
      "178/178 [==============================] - 0s 117us/step - loss: 0.1156 - accuracy: 0.9775 - val_loss: 1.4549 - val_accuracy: 0.6623\n",
      "Epoch 400/1000\n",
      "178/178 [==============================] - 0s 92us/step - loss: 0.1163 - accuracy: 0.9775 - val_loss: 1.4541 - val_accuracy: 0.6623\n",
      "Epoch 401/1000\n",
      "178/178 [==============================] - 0s 114us/step - loss: 0.1135 - accuracy: 0.9775 - val_loss: 1.4575 - val_accuracy: 0.6623\n",
      "Epoch 402/1000\n",
      "178/178 [==============================] - 0s 146us/step - loss: 0.1141 - accuracy: 0.9775 - val_loss: 1.4400 - val_accuracy: 0.6494\n",
      "Epoch 403/1000\n",
      "178/178 [==============================] - 0s 115us/step - loss: 0.1137 - accuracy: 0.9775 - val_loss: 1.4531 - val_accuracy: 0.6623\n",
      "Epoch 404/1000\n",
      "178/178 [==============================] - 0s 141us/step - loss: 0.1136 - accuracy: 0.9775 - val_loss: 1.4692 - val_accuracy: 0.6623\n",
      "Epoch 405/1000\n",
      "178/178 [==============================] - 0s 173us/step - loss: 0.1129 - accuracy: 0.9775 - val_loss: 1.4707 - val_accuracy: 0.6623\n",
      "Epoch 406/1000\n",
      "178/178 [==============================] - 0s 165us/step - loss: 0.1148 - accuracy: 0.9775 - val_loss: 1.4680 - val_accuracy: 0.6623\n",
      "Epoch 407/1000\n",
      "178/178 [==============================] - 0s 131us/step - loss: 0.1112 - accuracy: 0.9775 - val_loss: 1.4706 - val_accuracy: 0.6623\n",
      "Epoch 408/1000\n",
      "178/178 [==============================] - 0s 151us/step - loss: 0.1111 - accuracy: 0.9775 - val_loss: 1.4727 - val_accuracy: 0.6623\n",
      "Epoch 409/1000\n",
      "178/178 [==============================] - 0s 158us/step - loss: 0.1110 - accuracy: 0.9775 - val_loss: 1.4713 - val_accuracy: 0.6623\n",
      "Epoch 410/1000\n",
      "178/178 [==============================] - 0s 159us/step - loss: 0.1103 - accuracy: 0.9775 - val_loss: 1.4676 - val_accuracy: 0.6623\n",
      "Epoch 411/1000\n",
      "178/178 [==============================] - 0s 173us/step - loss: 0.1107 - accuracy: 0.9775 - val_loss: 1.4596 - val_accuracy: 0.6623\n",
      "Epoch 412/1000\n",
      "178/178 [==============================] - 0s 113us/step - loss: 0.1116 - accuracy: 0.9775 - val_loss: 1.4631 - val_accuracy: 0.6623\n",
      "Epoch 413/1000\n",
      "178/178 [==============================] - 0s 90us/step - loss: 0.1103 - accuracy: 0.9775 - val_loss: 1.4759 - val_accuracy: 0.6623\n",
      "Epoch 414/1000\n",
      "178/178 [==============================] - 0s 109us/step - loss: 0.1094 - accuracy: 0.9775 - val_loss: 1.4751 - val_accuracy: 0.6623\n",
      "Epoch 415/1000\n",
      "178/178 [==============================] - 0s 95us/step - loss: 0.1098 - accuracy: 0.9775 - val_loss: 1.4810 - val_accuracy: 0.6623\n",
      "Epoch 416/1000\n",
      "178/178 [==============================] - 0s 107us/step - loss: 0.1101 - accuracy: 0.9775 - val_loss: 1.4803 - val_accuracy: 0.6623\n",
      "Epoch 417/1000\n",
      "178/178 [==============================] - 0s 87us/step - loss: 0.1094 - accuracy: 0.9775 - val_loss: 1.4852 - val_accuracy: 0.6623\n",
      "Epoch 418/1000\n",
      "178/178 [==============================] - 0s 90us/step - loss: 0.1104 - accuracy: 0.9775 - val_loss: 1.4931 - val_accuracy: 0.6623\n",
      "Epoch 419/1000\n",
      "178/178 [==============================] - 0s 95us/step - loss: 0.1095 - accuracy: 0.9775 - val_loss: 1.4863 - val_accuracy: 0.6623\n",
      "Epoch 420/1000\n",
      "178/178 [==============================] - 0s 93us/step - loss: 0.1075 - accuracy: 0.9775 - val_loss: 1.4951 - val_accuracy: 0.6623\n",
      "Epoch 421/1000\n",
      "178/178 [==============================] - 0s 92us/step - loss: 0.1100 - accuracy: 0.9775 - val_loss: 1.4858 - val_accuracy: 0.6623\n",
      "Epoch 422/1000\n",
      "178/178 [==============================] - 0s 112us/step - loss: 0.1084 - accuracy: 0.9775 - val_loss: 1.4969 - val_accuracy: 0.6623\n",
      "Epoch 423/1000\n",
      "178/178 [==============================] - 0s 100us/step - loss: 0.1075 - accuracy: 0.9775 - val_loss: 1.4963 - val_accuracy: 0.6623\n",
      "Epoch 424/1000\n",
      "178/178 [==============================] - 0s 107us/step - loss: 0.1089 - accuracy: 0.9775 - val_loss: 1.5020 - val_accuracy: 0.6623\n",
      "Epoch 425/1000\n",
      "178/178 [==============================] - 0s 85us/step - loss: 0.1074 - accuracy: 0.9775 - val_loss: 1.5041 - val_accuracy: 0.6623\n",
      "Epoch 426/1000\n",
      "178/178 [==============================] - 0s 88us/step - loss: 0.1073 - accuracy: 0.9775 - val_loss: 1.5101 - val_accuracy: 0.6623\n",
      "Epoch 427/1000\n",
      "178/178 [==============================] - 0s 90us/step - loss: 0.1086 - accuracy: 0.9775 - val_loss: 1.5127 - val_accuracy: 0.6623\n",
      "Epoch 428/1000\n",
      "178/178 [==============================] - 0s 84us/step - loss: 0.1078 - accuracy: 0.9775 - val_loss: 1.5072 - val_accuracy: 0.6623\n",
      "Epoch 429/1000\n",
      "178/178 [==============================] - 0s 88us/step - loss: 0.1076 - accuracy: 0.9775 - val_loss: 1.5114 - val_accuracy: 0.6623\n",
      "Epoch 430/1000\n",
      "178/178 [==============================] - 0s 91us/step - loss: 0.1072 - accuracy: 0.9775 - val_loss: 1.5151 - val_accuracy: 0.6623\n",
      "Epoch 431/1000\n",
      "178/178 [==============================] - 0s 96us/step - loss: 0.1053 - accuracy: 0.9775 - val_loss: 1.5180 - val_accuracy: 0.6623\n",
      "Epoch 432/1000\n",
      "178/178 [==============================] - 0s 100us/step - loss: 0.1059 - accuracy: 0.9775 - val_loss: 1.5113 - val_accuracy: 0.6623\n",
      "Epoch 433/1000\n",
      "178/178 [==============================] - 0s 105us/step - loss: 0.1067 - accuracy: 0.9775 - val_loss: 1.5245 - val_accuracy: 0.6623\n",
      "Epoch 434/1000\n",
      "178/178 [==============================] - 0s 112us/step - loss: 0.1067 - accuracy: 0.9775 - val_loss: 1.5262 - val_accuracy: 0.6623\n",
      "Epoch 435/1000\n",
      "178/178 [==============================] - 0s 128us/step - loss: 0.1055 - accuracy: 0.9775 - val_loss: 1.5250 - val_accuracy: 0.6623\n",
      "Epoch 436/1000\n",
      "178/178 [==============================] - 0s 190us/step - loss: 0.1043 - accuracy: 0.9775 - val_loss: 1.5325 - val_accuracy: 0.6623\n",
      "Epoch 437/1000\n",
      "178/178 [==============================] - 0s 216us/step - loss: 0.1055 - accuracy: 0.9775 - val_loss: 1.5264 - val_accuracy: 0.6623\n",
      "Epoch 438/1000\n",
      "178/178 [==============================] - 0s 183us/step - loss: 0.1051 - accuracy: 0.9775 - val_loss: 1.5207 - val_accuracy: 0.6623\n",
      "Epoch 439/1000\n",
      "178/178 [==============================] - 0s 193us/step - loss: 0.1045 - accuracy: 0.9775 - val_loss: 1.5314 - val_accuracy: 0.6623\n",
      "Epoch 440/1000\n",
      "178/178 [==============================] - 0s 188us/step - loss: 0.1050 - accuracy: 0.9775 - val_loss: 1.5365 - val_accuracy: 0.6623\n",
      "Epoch 441/1000\n",
      "178/178 [==============================] - 0s 173us/step - loss: 0.1038 - accuracy: 0.9775 - val_loss: 1.5436 - val_accuracy: 0.6623\n",
      "Epoch 442/1000\n",
      "178/178 [==============================] - 0s 185us/step - loss: 0.1057 - accuracy: 0.9775 - val_loss: 1.5535 - val_accuracy: 0.6623\n",
      "Epoch 443/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 159us/step - loss: 0.1061 - accuracy: 0.9775 - val_loss: 1.5303 - val_accuracy: 0.6623\n",
      "Epoch 444/1000\n",
      "178/178 [==============================] - 0s 183us/step - loss: 0.1043 - accuracy: 0.9775 - val_loss: 1.5413 - val_accuracy: 0.6623\n",
      "Epoch 445/1000\n",
      "178/178 [==============================] - 0s 142us/step - loss: 0.1032 - accuracy: 0.9775 - val_loss: 1.5440 - val_accuracy: 0.6623\n",
      "Epoch 446/1000\n",
      "178/178 [==============================] - 0s 134us/step - loss: 0.1028 - accuracy: 0.9775 - val_loss: 1.5483 - val_accuracy: 0.6623\n",
      "Epoch 447/1000\n",
      "178/178 [==============================] - 0s 153us/step - loss: 0.1037 - accuracy: 0.9775 - val_loss: 1.5461 - val_accuracy: 0.6623\n",
      "Epoch 448/1000\n",
      "178/178 [==============================] - 0s 146us/step - loss: 0.1020 - accuracy: 0.9775 - val_loss: 1.5447 - val_accuracy: 0.6623\n",
      "Epoch 449/1000\n",
      "178/178 [==============================] - 0s 117us/step - loss: 0.1031 - accuracy: 0.9775 - val_loss: 1.5472 - val_accuracy: 0.6623\n",
      "Epoch 450/1000\n",
      "178/178 [==============================] - 0s 120us/step - loss: 0.1020 - accuracy: 0.9775 - val_loss: 1.5521 - val_accuracy: 0.6623\n",
      "Epoch 451/1000\n",
      "178/178 [==============================] - 0s 90us/step - loss: 0.1014 - accuracy: 0.9775 - val_loss: 1.5622 - val_accuracy: 0.6623\n",
      "Epoch 452/1000\n",
      "178/178 [==============================] - 0s 88us/step - loss: 0.1019 - accuracy: 0.9775 - val_loss: 1.5643 - val_accuracy: 0.6623\n",
      "Epoch 453/1000\n",
      "178/178 [==============================] - 0s 99us/step - loss: 0.1030 - accuracy: 0.9775 - val_loss: 1.5635 - val_accuracy: 0.6623\n",
      "Epoch 454/1000\n",
      "178/178 [==============================] - 0s 132us/step - loss: 0.1022 - accuracy: 0.9775 - val_loss: 1.5721 - val_accuracy: 0.6623\n",
      "Epoch 455/1000\n",
      "178/178 [==============================] - 0s 148us/step - loss: 0.1013 - accuracy: 0.9775 - val_loss: 1.5617 - val_accuracy: 0.6623\n",
      "Epoch 456/1000\n",
      "178/178 [==============================] - 0s 163us/step - loss: 0.1004 - accuracy: 0.9775 - val_loss: 1.5768 - val_accuracy: 0.6623\n",
      "Epoch 457/1000\n",
      "178/178 [==============================] - 0s 310us/step - loss: 0.1012 - accuracy: 0.9775 - val_loss: 1.5644 - val_accuracy: 0.6623\n",
      "Epoch 458/1000\n",
      "178/178 [==============================] - 0s 167us/step - loss: 0.1006 - accuracy: 0.9775 - val_loss: 1.5903 - val_accuracy: 0.6623\n",
      "Epoch 459/1000\n",
      "178/178 [==============================] - 0s 152us/step - loss: 0.1021 - accuracy: 0.9775 - val_loss: 1.5876 - val_accuracy: 0.6623\n",
      "Epoch 460/1000\n",
      "178/178 [==============================] - 0s 140us/step - loss: 0.1013 - accuracy: 0.9775 - val_loss: 1.5697 - val_accuracy: 0.6623\n",
      "Epoch 461/1000\n",
      "178/178 [==============================] - 0s 133us/step - loss: 0.0994 - accuracy: 0.9775 - val_loss: 1.5876 - val_accuracy: 0.6623\n",
      "Epoch 462/1000\n",
      "178/178 [==============================] - 0s 126us/step - loss: 0.1001 - accuracy: 0.9775 - val_loss: 1.5751 - val_accuracy: 0.6623\n",
      "Epoch 463/1000\n",
      "178/178 [==============================] - 0s 169us/step - loss: 0.1010 - accuracy: 0.9775 - val_loss: 1.5881 - val_accuracy: 0.6623\n",
      "Epoch 464/1000\n",
      "178/178 [==============================] - 0s 213us/step - loss: 0.1000 - accuracy: 0.9775 - val_loss: 1.5815 - val_accuracy: 0.6623\n",
      "Epoch 465/1000\n",
      "178/178 [==============================] - 0s 243us/step - loss: 0.1004 - accuracy: 0.9775 - val_loss: 1.5766 - val_accuracy: 0.6623\n",
      "Epoch 466/1000\n",
      "178/178 [==============================] - 0s 209us/step - loss: 0.0997 - accuracy: 0.9775 - val_loss: 1.5779 - val_accuracy: 0.6623\n",
      "Epoch 467/1000\n",
      "178/178 [==============================] - 0s 121us/step - loss: 0.0999 - accuracy: 0.9775 - val_loss: 1.5878 - val_accuracy: 0.6623\n",
      "Epoch 468/1000\n",
      "178/178 [==============================] - 0s 106us/step - loss: 0.0987 - accuracy: 0.9775 - val_loss: 1.5857 - val_accuracy: 0.6623\n",
      "Epoch 469/1000\n",
      "178/178 [==============================] - 0s 114us/step - loss: 0.0992 - accuracy: 0.9775 - val_loss: 1.5987 - val_accuracy: 0.6623\n",
      "Epoch 470/1000\n",
      "178/178 [==============================] - 0s 104us/step - loss: 0.0989 - accuracy: 0.9775 - val_loss: 1.5883 - val_accuracy: 0.6623\n",
      "Epoch 471/1000\n",
      "178/178 [==============================] - 0s 102us/step - loss: 0.0980 - accuracy: 0.9775 - val_loss: 1.5973 - val_accuracy: 0.6623\n",
      "Epoch 472/1000\n",
      "178/178 [==============================] - 0s 142us/step - loss: 0.0979 - accuracy: 0.9775 - val_loss: 1.5932 - val_accuracy: 0.6623\n",
      "Epoch 473/1000\n",
      "178/178 [==============================] - 0s 94us/step - loss: 0.0982 - accuracy: 0.9775 - val_loss: 1.5958 - val_accuracy: 0.6623\n",
      "Epoch 474/1000\n",
      "178/178 [==============================] - 0s 101us/step - loss: 0.0984 - accuracy: 0.9775 - val_loss: 1.5989 - val_accuracy: 0.6623\n",
      "Epoch 475/1000\n",
      "178/178 [==============================] - 0s 119us/step - loss: 0.0968 - accuracy: 0.9775 - val_loss: 1.6147 - val_accuracy: 0.6623\n",
      "Epoch 476/1000\n",
      "178/178 [==============================] - 0s 123us/step - loss: 0.0967 - accuracy: 0.9775 - val_loss: 1.6113 - val_accuracy: 0.6623\n",
      "Epoch 477/1000\n",
      "178/178 [==============================] - 0s 123us/step - loss: 0.0993 - accuracy: 0.9775 - val_loss: 1.6212 - val_accuracy: 0.6623\n",
      "Epoch 478/1000\n",
      "178/178 [==============================] - 0s 103us/step - loss: 0.0976 - accuracy: 0.9775 - val_loss: 1.6146 - val_accuracy: 0.6623\n",
      "Epoch 479/1000\n",
      "178/178 [==============================] - 0s 117us/step - loss: 0.0961 - accuracy: 0.9775 - val_loss: 1.6141 - val_accuracy: 0.6623\n",
      "Epoch 480/1000\n",
      "178/178 [==============================] - 0s 102us/step - loss: 0.0964 - accuracy: 0.9775 - val_loss: 1.6278 - val_accuracy: 0.6623\n",
      "Epoch 481/1000\n",
      "178/178 [==============================] - 0s 95us/step - loss: 0.0962 - accuracy: 0.9775 - val_loss: 1.6162 - val_accuracy: 0.6623\n",
      "Epoch 482/1000\n",
      "178/178 [==============================] - 0s 124us/step - loss: 0.0979 - accuracy: 0.9775 - val_loss: 1.6122 - val_accuracy: 0.6623\n",
      "Epoch 483/1000\n",
      "178/178 [==============================] - 0s 124us/step - loss: 0.0968 - accuracy: 0.9775 - val_loss: 1.6099 - val_accuracy: 0.6623\n",
      "Epoch 484/1000\n",
      "178/178 [==============================] - 0s 111us/step - loss: 0.0949 - accuracy: 0.9775 - val_loss: 1.6128 - val_accuracy: 0.6623\n",
      "Epoch 485/1000\n",
      "178/178 [==============================] - 0s 106us/step - loss: 0.0962 - accuracy: 0.9775 - val_loss: 1.6221 - val_accuracy: 0.6623\n",
      "Epoch 486/1000\n",
      "178/178 [==============================] - 0s 131us/step - loss: 0.0977 - accuracy: 0.9775 - val_loss: 1.6187 - val_accuracy: 0.6623\n",
      "Epoch 487/1000\n",
      "178/178 [==============================] - 0s 109us/step - loss: 0.0958 - accuracy: 0.9775 - val_loss: 1.6235 - val_accuracy: 0.6623\n",
      "Epoch 488/1000\n",
      "178/178 [==============================] - 0s 116us/step - loss: 0.0953 - accuracy: 0.9775 - val_loss: 1.6192 - val_accuracy: 0.6623\n",
      "Epoch 489/1000\n",
      "178/178 [==============================] - 0s 110us/step - loss: 0.0959 - accuracy: 0.9775 - val_loss: 1.6256 - val_accuracy: 0.6623\n",
      "Epoch 490/1000\n",
      "178/178 [==============================] - 0s 115us/step - loss: 0.0963 - accuracy: 0.9775 - val_loss: 1.6247 - val_accuracy: 0.6623\n",
      "Epoch 491/1000\n",
      "178/178 [==============================] - 0s 113us/step - loss: 0.0961 - accuracy: 0.9775 - val_loss: 1.6382 - val_accuracy: 0.6623\n",
      "Epoch 492/1000\n",
      "178/178 [==============================] - 0s 132us/step - loss: 0.0945 - accuracy: 0.9775 - val_loss: 1.6440 - val_accuracy: 0.6623\n",
      "Epoch 493/1000\n",
      "178/178 [==============================] - 0s 175us/step - loss: 0.0946 - accuracy: 0.9775 - val_loss: 1.6243 - val_accuracy: 0.6623\n",
      "Epoch 494/1000\n",
      "178/178 [==============================] - 0s 169us/step - loss: 0.0960 - accuracy: 0.9775 - val_loss: 1.6337 - val_accuracy: 0.6623\n",
      "Epoch 495/1000\n",
      "178/178 [==============================] - 0s 155us/step - loss: 0.0964 - accuracy: 0.9775 - val_loss: 1.6356 - val_accuracy: 0.6623\n",
      "Epoch 496/1000\n",
      "178/178 [==============================] - 0s 161us/step - loss: 0.0935 - accuracy: 0.9775 - val_loss: 1.6509 - val_accuracy: 0.6623\n",
      "Epoch 497/1000\n",
      "178/178 [==============================] - 0s 131us/step - loss: 0.0945 - accuracy: 0.9775 - val_loss: 1.6350 - val_accuracy: 0.6623\n",
      "Epoch 498/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 104us/step - loss: 0.0957 - accuracy: 0.9775 - val_loss: 1.6330 - val_accuracy: 0.6623\n",
      "Epoch 499/1000\n",
      "178/178 [==============================] - 0s 121us/step - loss: 0.0957 - accuracy: 0.9775 - val_loss: 1.6607 - val_accuracy: 0.6623\n",
      "Epoch 500/1000\n",
      "178/178 [==============================] - 0s 130us/step - loss: 0.0939 - accuracy: 0.9775 - val_loss: 1.6514 - val_accuracy: 0.6623\n",
      "Epoch 501/1000\n",
      "178/178 [==============================] - 0s 116us/step - loss: 0.0927 - accuracy: 0.9775 - val_loss: 1.6535 - val_accuracy: 0.6623\n",
      "Epoch 502/1000\n",
      "178/178 [==============================] - 0s 144us/step - loss: 0.0934 - accuracy: 0.9775 - val_loss: 1.6567 - val_accuracy: 0.6623\n",
      "Epoch 503/1000\n",
      "178/178 [==============================] - 0s 136us/step - loss: 0.0932 - accuracy: 0.9775 - val_loss: 1.6392 - val_accuracy: 0.6623\n",
      "Epoch 504/1000\n",
      "178/178 [==============================] - 0s 122us/step - loss: 0.0944 - accuracy: 0.9775 - val_loss: 1.6622 - val_accuracy: 0.6623\n",
      "Epoch 505/1000\n",
      "178/178 [==============================] - 0s 146us/step - loss: 0.0932 - accuracy: 0.9775 - val_loss: 1.6689 - val_accuracy: 0.6623\n",
      "Epoch 506/1000\n",
      "178/178 [==============================] - 0s 122us/step - loss: 0.0931 - accuracy: 0.9775 - val_loss: 1.6726 - val_accuracy: 0.6623\n",
      "Epoch 507/1000\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.1373 - accuracy: 0.96 - 0s 94us/step - loss: 0.0921 - accuracy: 0.9775 - val_loss: 1.6633 - val_accuracy: 0.6623\n",
      "Epoch 508/1000\n",
      "178/178 [==============================] - 0s 150us/step - loss: 0.0938 - accuracy: 0.9775 - val_loss: 1.6665 - val_accuracy: 0.6623\n",
      "Epoch 509/1000\n",
      "178/178 [==============================] - 0s 184us/step - loss: 0.0921 - accuracy: 0.9775 - val_loss: 1.6819 - val_accuracy: 0.6623\n",
      "Epoch 510/1000\n",
      "178/178 [==============================] - 0s 231us/step - loss: 0.0923 - accuracy: 0.9775 - val_loss: 1.6586 - val_accuracy: 0.6623\n",
      "Epoch 511/1000\n",
      "178/178 [==============================] - 0s 188us/step - loss: 0.0938 - accuracy: 0.9775 - val_loss: 1.6811 - val_accuracy: 0.6623\n",
      "Epoch 512/1000\n",
      "178/178 [==============================] - 0s 173us/step - loss: 0.0919 - accuracy: 0.9775 - val_loss: 1.6774 - val_accuracy: 0.6623\n",
      "Epoch 513/1000\n",
      "178/178 [==============================] - 0s 166us/step - loss: 0.0931 - accuracy: 0.9775 - val_loss: 1.6844 - val_accuracy: 0.6623\n",
      "Epoch 514/1000\n",
      "178/178 [==============================] - 0s 188us/step - loss: 0.0918 - accuracy: 0.9775 - val_loss: 1.6824 - val_accuracy: 0.6623\n",
      "Epoch 515/1000\n",
      "178/178 [==============================] - 0s 147us/step - loss: 0.0916 - accuracy: 0.9775 - val_loss: 1.6637 - val_accuracy: 0.6623\n",
      "Epoch 516/1000\n",
      "178/178 [==============================] - 0s 167us/step - loss: 0.0904 - accuracy: 0.9775 - val_loss: 1.6754 - val_accuracy: 0.6623\n",
      "Epoch 517/1000\n",
      "178/178 [==============================] - 0s 122us/step - loss: 0.0916 - accuracy: 0.9775 - val_loss: 1.6725 - val_accuracy: 0.6623\n",
      "Epoch 518/1000\n",
      "178/178 [==============================] - 0s 143us/step - loss: 0.0912 - accuracy: 0.9775 - val_loss: 1.6901 - val_accuracy: 0.6623\n",
      "Epoch 519/1000\n",
      "178/178 [==============================] - 0s 112us/step - loss: 0.0902 - accuracy: 0.9775 - val_loss: 1.6765 - val_accuracy: 0.6623\n",
      "Epoch 520/1000\n",
      "178/178 [==============================] - 0s 122us/step - loss: 0.0906 - accuracy: 0.9775 - val_loss: 1.6785 - val_accuracy: 0.6623\n",
      "Epoch 521/1000\n",
      "178/178 [==============================] - 0s 110us/step - loss: 0.0921 - accuracy: 0.9775 - val_loss: 1.6774 - val_accuracy: 0.6623\n",
      "Epoch 522/1000\n",
      "178/178 [==============================] - 0s 136us/step - loss: 0.0900 - accuracy: 0.9775 - val_loss: 1.6926 - val_accuracy: 0.6623\n",
      "Epoch 523/1000\n",
      "178/178 [==============================] - 0s 104us/step - loss: 0.0913 - accuracy: 0.9775 - val_loss: 1.6891 - val_accuracy: 0.6623\n",
      "Epoch 524/1000\n",
      "178/178 [==============================] - 0s 109us/step - loss: 0.0921 - accuracy: 0.9775 - val_loss: 1.6844 - val_accuracy: 0.6623\n",
      "Epoch 525/1000\n",
      "178/178 [==============================] - 0s 123us/step - loss: 0.0902 - accuracy: 0.9775 - val_loss: 1.6860 - val_accuracy: 0.6623\n",
      "Epoch 526/1000\n",
      "178/178 [==============================] - 0s 111us/step - loss: 0.0898 - accuracy: 0.9775 - val_loss: 1.6884 - val_accuracy: 0.6623\n",
      "Epoch 527/1000\n",
      "178/178 [==============================] - 0s 91us/step - loss: 0.0886 - accuracy: 0.9775 - val_loss: 1.7092 - val_accuracy: 0.6623\n",
      "Epoch 528/1000\n",
      "178/178 [==============================] - 0s 106us/step - loss: 0.0905 - accuracy: 0.9775 - val_loss: 1.6936 - val_accuracy: 0.6623\n",
      "Epoch 529/1000\n",
      "178/178 [==============================] - 0s 102us/step - loss: 0.0898 - accuracy: 0.9775 - val_loss: 1.6925 - val_accuracy: 0.6623\n",
      "Epoch 530/1000\n",
      "178/178 [==============================] - 0s 111us/step - loss: 0.0888 - accuracy: 0.9775 - val_loss: 1.6969 - val_accuracy: 0.6623\n",
      "Epoch 531/1000\n",
      "178/178 [==============================] - 0s 119us/step - loss: 0.0887 - accuracy: 0.9775 - val_loss: 1.6968 - val_accuracy: 0.6623\n",
      "Epoch 532/1000\n",
      "178/178 [==============================] - 0s 123us/step - loss: 0.0894 - accuracy: 0.9775 - val_loss: 1.7071 - val_accuracy: 0.6623\n",
      "Epoch 533/1000\n",
      "178/178 [==============================] - 0s 144us/step - loss: 0.0884 - accuracy: 0.9775 - val_loss: 1.7116 - val_accuracy: 0.6623\n",
      "Epoch 534/1000\n",
      "178/178 [==============================] - 0s 94us/step - loss: 0.0889 - accuracy: 0.9775 - val_loss: 1.6951 - val_accuracy: 0.6623\n",
      "Epoch 535/1000\n",
      "178/178 [==============================] - 0s 128us/step - loss: 0.0896 - accuracy: 0.9775 - val_loss: 1.7120 - val_accuracy: 0.6623\n",
      "Epoch 536/1000\n",
      "178/178 [==============================] - 0s 86us/step - loss: 0.0879 - accuracy: 0.9775 - val_loss: 1.7303 - val_accuracy: 0.6623\n",
      "Epoch 537/1000\n",
      "178/178 [==============================] - 0s 97us/step - loss: 0.0893 - accuracy: 0.9775 - val_loss: 1.7186 - val_accuracy: 0.6623\n",
      "Epoch 538/1000\n",
      "178/178 [==============================] - 0s 99us/step - loss: 0.0905 - accuracy: 0.9775 - val_loss: 1.7236 - val_accuracy: 0.6623\n",
      "Epoch 539/1000\n",
      "178/178 [==============================] - 0s 87us/step - loss: 0.0876 - accuracy: 0.9775 - val_loss: 1.7074 - val_accuracy: 0.6623\n",
      "Epoch 540/1000\n",
      "178/178 [==============================] - 0s 90us/step - loss: 0.0899 - accuracy: 0.9775 - val_loss: 1.7139 - val_accuracy: 0.6623\n",
      "Epoch 541/1000\n",
      "178/178 [==============================] - 0s 90us/step - loss: 0.0873 - accuracy: 0.9775 - val_loss: 1.7236 - val_accuracy: 0.6623\n",
      "Epoch 542/1000\n",
      "178/178 [==============================] - 0s 91us/step - loss: 0.0873 - accuracy: 0.9775 - val_loss: 1.7204 - val_accuracy: 0.6623\n",
      "Epoch 543/1000\n",
      "178/178 [==============================] - 0s 108us/step - loss: 0.0890 - accuracy: 0.9775 - val_loss: 1.7312 - val_accuracy: 0.6623\n",
      "Epoch 544/1000\n",
      "178/178 [==============================] - 0s 101us/step - loss: 0.0897 - accuracy: 0.9775 - val_loss: 1.7060 - val_accuracy: 0.6623\n",
      "Epoch 545/1000\n",
      "178/178 [==============================] - 0s 101us/step - loss: 0.0891 - accuracy: 0.9775 - val_loss: 1.7382 - val_accuracy: 0.6623\n",
      "Epoch 546/1000\n",
      "178/178 [==============================] - 0s 95us/step - loss: 0.0867 - accuracy: 0.9775 - val_loss: 1.7256 - val_accuracy: 0.6623\n",
      "Epoch 547/1000\n",
      "178/178 [==============================] - 0s 107us/step - loss: 0.0870 - accuracy: 0.9775 - val_loss: 1.7204 - val_accuracy: 0.6623\n",
      "Epoch 548/1000\n",
      "178/178 [==============================] - 0s 154us/step - loss: 0.0886 - accuracy: 0.9775 - val_loss: 1.7329 - val_accuracy: 0.6623\n",
      "Epoch 549/1000\n",
      "178/178 [==============================] - 0s 187us/step - loss: 0.0873 - accuracy: 0.9775 - val_loss: 1.7406 - val_accuracy: 0.6623\n",
      "Epoch 550/1000\n",
      "178/178 [==============================] - 0s 169us/step - loss: 0.0877 - accuracy: 0.9775 - val_loss: 1.7415 - val_accuracy: 0.6623\n",
      "Epoch 551/1000\n",
      "178/178 [==============================] - 0s 203us/step - loss: 0.0874 - accuracy: 0.9775 - val_loss: 1.7361 - val_accuracy: 0.6623\n",
      "Epoch 552/1000\n",
      "178/178 [==============================] - 0s 171us/step - loss: 0.0876 - accuracy: 0.9775 - val_loss: 1.7424 - val_accuracy: 0.6623\n",
      "Epoch 553/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 185us/step - loss: 0.0864 - accuracy: 0.9775 - val_loss: 1.7474 - val_accuracy: 0.6623\n",
      "Epoch 554/1000\n",
      "178/178 [==============================] - 0s 142us/step - loss: 0.0885 - accuracy: 0.9775 - val_loss: 1.7356 - val_accuracy: 0.6623\n",
      "Epoch 555/1000\n",
      "178/178 [==============================] - 0s 99us/step - loss: 0.0865 - accuracy: 0.9775 - val_loss: 1.7552 - val_accuracy: 0.6623\n",
      "Epoch 556/1000\n",
      "178/178 [==============================] - 0s 181us/step - loss: 0.0890 - accuracy: 0.9775 - val_loss: 1.7550 - val_accuracy: 0.6623\n",
      "Epoch 557/1000\n",
      "178/178 [==============================] - 0s 179us/step - loss: 0.0856 - accuracy: 0.9775 - val_loss: 1.7489 - val_accuracy: 0.6623\n",
      "Epoch 558/1000\n",
      "178/178 [==============================] - 0s 98us/step - loss: 0.0851 - accuracy: 0.9775 - val_loss: 1.7448 - val_accuracy: 0.6623\n",
      "Epoch 559/1000\n",
      "178/178 [==============================] - 0s 89us/step - loss: 0.0854 - accuracy: 0.9775 - val_loss: 1.7585 - val_accuracy: 0.6623\n",
      "Epoch 560/1000\n",
      "178/178 [==============================] - 0s 84us/step - loss: 0.0854 - accuracy: 0.9775 - val_loss: 1.7498 - val_accuracy: 0.6623\n",
      "Epoch 561/1000\n",
      "178/178 [==============================] - 0s 87us/step - loss: 0.0848 - accuracy: 0.9775 - val_loss: 1.7380 - val_accuracy: 0.6623\n",
      "Epoch 562/1000\n",
      "178/178 [==============================] - 0s 93us/step - loss: 0.0861 - accuracy: 0.9775 - val_loss: 1.7557 - val_accuracy: 0.6623\n",
      "Epoch 563/1000\n",
      "178/178 [==============================] - 0s 87us/step - loss: 0.0848 - accuracy: 0.9775 - val_loss: 1.7636 - val_accuracy: 0.6623\n",
      "Epoch 564/1000\n",
      "178/178 [==============================] - 0s 83us/step - loss: 0.0851 - accuracy: 0.9775 - val_loss: 1.7612 - val_accuracy: 0.6623\n",
      "Epoch 565/1000\n",
      "178/178 [==============================] - 0s 111us/step - loss: 0.0844 - accuracy: 0.9775 - val_loss: 1.7605 - val_accuracy: 0.6623\n",
      "Epoch 566/1000\n",
      "178/178 [==============================] - 0s 95us/step - loss: 0.0865 - accuracy: 0.9775 - val_loss: 1.7556 - val_accuracy: 0.6623\n",
      "Epoch 567/1000\n",
      "178/178 [==============================] - 0s 91us/step - loss: 0.0858 - accuracy: 0.9775 - val_loss: 1.7708 - val_accuracy: 0.6623\n",
      "Epoch 568/1000\n",
      "178/178 [==============================] - 0s 91us/step - loss: 0.0857 - accuracy: 0.9775 - val_loss: 1.7631 - val_accuracy: 0.6623\n",
      "Epoch 569/1000\n",
      "178/178 [==============================] - 0s 93us/step - loss: 0.0842 - accuracy: 0.9775 - val_loss: 1.7784 - val_accuracy: 0.6623\n",
      "Epoch 570/1000\n",
      "178/178 [==============================] - 0s 94us/step - loss: 0.0836 - accuracy: 0.9775 - val_loss: 1.7689 - val_accuracy: 0.6623\n",
      "Epoch 571/1000\n",
      "178/178 [==============================] - 0s 99us/step - loss: 0.0872 - accuracy: 0.9775 - val_loss: 1.7884 - val_accuracy: 0.6623\n",
      "Epoch 572/1000\n",
      "178/178 [==============================] - 0s 83us/step - loss: 0.0857 - accuracy: 0.9775 - val_loss: 1.7741 - val_accuracy: 0.6623\n",
      "Epoch 573/1000\n",
      "178/178 [==============================] - 0s 84us/step - loss: 0.0850 - accuracy: 0.9775 - val_loss: 1.7676 - val_accuracy: 0.6623\n",
      "Epoch 574/1000\n",
      "178/178 [==============================] - 0s 83us/step - loss: 0.0848 - accuracy: 0.9775 - val_loss: 1.7813 - val_accuracy: 0.6623\n",
      "Epoch 575/1000\n",
      "178/178 [==============================] - 0s 85us/step - loss: 0.0831 - accuracy: 0.9775 - val_loss: 1.7765 - val_accuracy: 0.6623\n",
      "Epoch 576/1000\n",
      "178/178 [==============================] - 0s 86us/step - loss: 0.0834 - accuracy: 0.9775 - val_loss: 1.7839 - val_accuracy: 0.6623\n",
      "Epoch 577/1000\n",
      "178/178 [==============================] - 0s 93us/step - loss: 0.0843 - accuracy: 0.9775 - val_loss: 1.7952 - val_accuracy: 0.6623\n",
      "Epoch 578/1000\n",
      "178/178 [==============================] - 0s 86us/step - loss: 0.0841 - accuracy: 0.9775 - val_loss: 1.7728 - val_accuracy: 0.6623\n",
      "Epoch 579/1000\n",
      "178/178 [==============================] - 0s 88us/step - loss: 0.0842 - accuracy: 0.9775 - val_loss: 1.7921 - val_accuracy: 0.6623\n",
      "Epoch 580/1000\n",
      "178/178 [==============================] - 0s 92us/step - loss: 0.0836 - accuracy: 0.9775 - val_loss: 1.7801 - val_accuracy: 0.6623\n",
      "Epoch 581/1000\n",
      "178/178 [==============================] - 0s 87us/step - loss: 0.0826 - accuracy: 0.9775 - val_loss: 1.7818 - val_accuracy: 0.6623\n",
      "Epoch 582/1000\n",
      "178/178 [==============================] - 0s 103us/step - loss: 0.0828 - accuracy: 0.9775 - val_loss: 1.7863 - val_accuracy: 0.6623\n",
      "Epoch 583/1000\n",
      "178/178 [==============================] - 0s 84us/step - loss: 0.0827 - accuracy: 0.9775 - val_loss: 1.7937 - val_accuracy: 0.6623\n",
      "Epoch 584/1000\n",
      "178/178 [==============================] - 0s 88us/step - loss: 0.0830 - accuracy: 0.9775 - val_loss: 1.7928 - val_accuracy: 0.6623\n",
      "Epoch 585/1000\n",
      "178/178 [==============================] - 0s 96us/step - loss: 0.0826 - accuracy: 0.9775 - val_loss: 1.7845 - val_accuracy: 0.6623\n",
      "Epoch 586/1000\n",
      "178/178 [==============================] - 0s 100us/step - loss: 0.0818 - accuracy: 0.9775 - val_loss: 1.7982 - val_accuracy: 0.6623\n",
      "Epoch 587/1000\n",
      "178/178 [==============================] - 0s 84us/step - loss: 0.0836 - accuracy: 0.9775 - val_loss: 1.7937 - val_accuracy: 0.6623\n",
      "Epoch 588/1000\n",
      "178/178 [==============================] - 0s 93us/step - loss: 0.0832 - accuracy: 0.9775 - val_loss: 1.8048 - val_accuracy: 0.6623\n",
      "Epoch 589/1000\n",
      "178/178 [==============================] - 0s 103us/step - loss: 0.0835 - accuracy: 0.9775 - val_loss: 1.7947 - val_accuracy: 0.6623\n",
      "Epoch 590/1000\n",
      "178/178 [==============================] - 0s 93us/step - loss: 0.0824 - accuracy: 0.9775 - val_loss: 1.8090 - val_accuracy: 0.6623\n",
      "Epoch 591/1000\n",
      "178/178 [==============================] - 0s 104us/step - loss: 0.0816 - accuracy: 0.9775 - val_loss: 1.8078 - val_accuracy: 0.6623\n",
      "Epoch 592/1000\n",
      "178/178 [==============================] - 0s 96us/step - loss: 0.0812 - accuracy: 0.9775 - val_loss: 1.8030 - val_accuracy: 0.6623\n",
      "Epoch 593/1000\n",
      "178/178 [==============================] - 0s 92us/step - loss: 0.0832 - accuracy: 0.9775 - val_loss: 1.8147 - val_accuracy: 0.6623\n",
      "Epoch 594/1000\n",
      "178/178 [==============================] - 0s 90us/step - loss: 0.0816 - accuracy: 0.9775 - val_loss: 1.8236 - val_accuracy: 0.6494\n",
      "Epoch 595/1000\n",
      "178/178 [==============================] - 0s 84us/step - loss: 0.0836 - accuracy: 0.9775 - val_loss: 1.8116 - val_accuracy: 0.6623\n",
      "Epoch 596/1000\n",
      "178/178 [==============================] - 0s 92us/step - loss: 0.0820 - accuracy: 0.9775 - val_loss: 1.8080 - val_accuracy: 0.6623\n",
      "Epoch 597/1000\n",
      "178/178 [==============================] - 0s 98us/step - loss: 0.0819 - accuracy: 0.9775 - val_loss: 1.8139 - val_accuracy: 0.6623\n",
      "Epoch 598/1000\n",
      "178/178 [==============================] - 0s 86us/step - loss: 0.0822 - accuracy: 0.9775 - val_loss: 1.7900 - val_accuracy: 0.6623\n",
      "Epoch 599/1000\n",
      "178/178 [==============================] - 0s 91us/step - loss: 0.0828 - accuracy: 0.9775 - val_loss: 1.7972 - val_accuracy: 0.6623\n",
      "Epoch 600/1000\n",
      "178/178 [==============================] - 0s 92us/step - loss: 0.0827 - accuracy: 0.9775 - val_loss: 1.7932 - val_accuracy: 0.6623\n",
      "Epoch 601/1000\n",
      "178/178 [==============================] - 0s 87us/step - loss: 0.0825 - accuracy: 0.9775 - val_loss: 1.8124 - val_accuracy: 0.6623\n",
      "Epoch 602/1000\n",
      "178/178 [==============================] - 0s 97us/step - loss: 0.0813 - accuracy: 0.9775 - val_loss: 1.7994 - val_accuracy: 0.6623\n",
      "Epoch 603/1000\n",
      "178/178 [==============================] - 0s 94us/step - loss: 0.0810 - accuracy: 0.9775 - val_loss: 1.8306 - val_accuracy: 0.6623\n",
      "Epoch 604/1000\n",
      "178/178 [==============================] - 0s 87us/step - loss: 0.0819 - accuracy: 0.9775 - val_loss: 1.8037 - val_accuracy: 0.6623\n",
      "Epoch 605/1000\n",
      "178/178 [==============================] - 0s 89us/step - loss: 0.0809 - accuracy: 0.9775 - val_loss: 1.8320 - val_accuracy: 0.6623\n",
      "Epoch 606/1000\n",
      "178/178 [==============================] - 0s 100us/step - loss: 0.0818 - accuracy: 0.9775 - val_loss: 1.8319 - val_accuracy: 0.6623\n",
      "Epoch 607/1000\n",
      "178/178 [==============================] - 0s 90us/step - loss: 0.0798 - accuracy: 0.9775 - val_loss: 1.8160 - val_accuracy: 0.6623\n",
      "Epoch 608/1000\n",
      "178/178 [==============================] - 0s 86us/step - loss: 0.0834 - accuracy: 0.9775 - val_loss: 1.8250 - val_accuracy: 0.6623\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 609/1000\n",
      "178/178 [==============================] - 0s 82us/step - loss: 0.0816 - accuracy: 0.9775 - val_loss: 1.8274 - val_accuracy: 0.6623\n",
      "Epoch 610/1000\n",
      "178/178 [==============================] - 0s 89us/step - loss: 0.0812 - accuracy: 0.9775 - val_loss: 1.8314 - val_accuracy: 0.6623\n",
      "Epoch 611/1000\n",
      "178/178 [==============================] - 0s 97us/step - loss: 0.0834 - accuracy: 0.9775 - val_loss: 1.8299 - val_accuracy: 0.6623\n",
      "Epoch 612/1000\n",
      "178/178 [==============================] - 0s 97us/step - loss: 0.0819 - accuracy: 0.9775 - val_loss: 1.8108 - val_accuracy: 0.6623\n",
      "Epoch 613/1000\n",
      "178/178 [==============================] - 0s 98us/step - loss: 0.0823 - accuracy: 0.9775 - val_loss: 1.8360 - val_accuracy: 0.6623\n",
      "Epoch 614/1000\n",
      "178/178 [==============================] - 0s 85us/step - loss: 0.0802 - accuracy: 0.9775 - val_loss: 1.8474 - val_accuracy: 0.6623\n",
      "Epoch 615/1000\n",
      "178/178 [==============================] - 0s 94us/step - loss: 0.0818 - accuracy: 0.9775 - val_loss: 1.8434 - val_accuracy: 0.6623\n",
      "Epoch 616/1000\n",
      "178/178 [==============================] - 0s 95us/step - loss: 0.0790 - accuracy: 0.9775 - val_loss: 1.8289 - val_accuracy: 0.6623\n",
      "Epoch 617/1000\n",
      "178/178 [==============================] - 0s 90us/step - loss: 0.0843 - accuracy: 0.9775 - val_loss: 1.8393 - val_accuracy: 0.6623\n",
      "Epoch 618/1000\n",
      "178/178 [==============================] - 0s 100us/step - loss: 0.0811 - accuracy: 0.9775 - val_loss: 1.8384 - val_accuracy: 0.6623\n",
      "Epoch 619/1000\n",
      "178/178 [==============================] - 0s 100us/step - loss: 0.0794 - accuracy: 0.9775 - val_loss: 1.8480 - val_accuracy: 0.6623\n",
      "Epoch 620/1000\n",
      "178/178 [==============================] - 0s 86us/step - loss: 0.0793 - accuracy: 0.9775 - val_loss: 1.8386 - val_accuracy: 0.6623\n",
      "Epoch 621/1000\n",
      "178/178 [==============================] - 0s 97us/step - loss: 0.0789 - accuracy: 0.9775 - val_loss: 1.8384 - val_accuracy: 0.6623\n",
      "Epoch 622/1000\n",
      "178/178 [==============================] - 0s 83us/step - loss: 0.0793 - accuracy: 0.9775 - val_loss: 1.8499 - val_accuracy: 0.6623\n",
      "Epoch 623/1000\n",
      "178/178 [==============================] - 0s 98us/step - loss: 0.0801 - accuracy: 0.9775 - val_loss: 1.8477 - val_accuracy: 0.6623\n",
      "Epoch 624/1000\n",
      "178/178 [==============================] - 0s 101us/step - loss: 0.0804 - accuracy: 0.9775 - val_loss: 1.8459 - val_accuracy: 0.6623\n",
      "Epoch 625/1000\n",
      "178/178 [==============================] - 0s 88us/step - loss: 0.0787 - accuracy: 0.9775 - val_loss: 1.8691 - val_accuracy: 0.6623\n",
      "Epoch 626/1000\n",
      "178/178 [==============================] - 0s 84us/step - loss: 0.0809 - accuracy: 0.9775 - val_loss: 1.8563 - val_accuracy: 0.6623\n",
      "Epoch 627/1000\n",
      "178/178 [==============================] - 0s 83us/step - loss: 0.0781 - accuracy: 0.9775 - val_loss: 1.8759 - val_accuracy: 0.6623\n",
      "Epoch 628/1000\n",
      "178/178 [==============================] - 0s 106us/step - loss: 0.0786 - accuracy: 0.9775 - val_loss: 1.8737 - val_accuracy: 0.6623\n",
      "Epoch 629/1000\n",
      "178/178 [==============================] - 0s 94us/step - loss: 0.0809 - accuracy: 0.9775 - val_loss: 1.8634 - val_accuracy: 0.6623\n",
      "Epoch 630/1000\n",
      "178/178 [==============================] - 0s 99us/step - loss: 0.0769 - accuracy: 0.9775 - val_loss: 1.8731 - val_accuracy: 0.6623\n",
      "Epoch 631/1000\n",
      "178/178 [==============================] - 0s 100us/step - loss: 0.0782 - accuracy: 0.9775 - val_loss: 1.8820 - val_accuracy: 0.6623\n",
      "Epoch 632/1000\n",
      "178/178 [==============================] - 0s 93us/step - loss: 0.0779 - accuracy: 0.9775 - val_loss: 1.8748 - val_accuracy: 0.6623\n",
      "Epoch 633/1000\n",
      "178/178 [==============================] - 0s 89us/step - loss: 0.0789 - accuracy: 0.9775 - val_loss: 1.8494 - val_accuracy: 0.6623\n",
      "Epoch 634/1000\n",
      "178/178 [==============================] - 0s 83us/step - loss: 0.0818 - accuracy: 0.9775 - val_loss: 1.8545 - val_accuracy: 0.6623\n",
      "Epoch 635/1000\n",
      "178/178 [==============================] - 0s 86us/step - loss: 0.0811 - accuracy: 0.9775 - val_loss: 1.8808 - val_accuracy: 0.6623\n",
      "Epoch 636/1000\n",
      "178/178 [==============================] - 0s 94us/step - loss: 0.0776 - accuracy: 0.9775 - val_loss: 1.8841 - val_accuracy: 0.6623\n",
      "Epoch 637/1000\n",
      "178/178 [==============================] - 0s 83us/step - loss: 0.0772 - accuracy: 0.9775 - val_loss: 1.8757 - val_accuracy: 0.6623\n",
      "Epoch 638/1000\n",
      "178/178 [==============================] - 0s 91us/step - loss: 0.0785 - accuracy: 0.9775 - val_loss: 1.8587 - val_accuracy: 0.6623\n",
      "Epoch 639/1000\n",
      "178/178 [==============================] - 0s 101us/step - loss: 0.0779 - accuracy: 0.9775 - val_loss: 1.8683 - val_accuracy: 0.6623\n",
      "Epoch 640/1000\n",
      "178/178 [==============================] - 0s 104us/step - loss: 0.0790 - accuracy: 0.9775 - val_loss: 1.8665 - val_accuracy: 0.6623\n",
      "Epoch 641/1000\n",
      "178/178 [==============================] - 0s 89us/step - loss: 0.0787 - accuracy: 0.9775 - val_loss: 1.8841 - val_accuracy: 0.6623\n",
      "Epoch 642/1000\n",
      "178/178 [==============================] - 0s 100us/step - loss: 0.0767 - accuracy: 0.9775 - val_loss: 1.8854 - val_accuracy: 0.6623\n",
      "Epoch 643/1000\n",
      "178/178 [==============================] - 0s 91us/step - loss: 0.0764 - accuracy: 0.9775 - val_loss: 1.8837 - val_accuracy: 0.6623\n",
      "Epoch 644/1000\n",
      "178/178 [==============================] - 0s 92us/step - loss: 0.0775 - accuracy: 0.9775 - val_loss: 1.8874 - val_accuracy: 0.6623\n",
      "Epoch 645/1000\n",
      "178/178 [==============================] - 0s 105us/step - loss: 0.0770 - accuracy: 0.9775 - val_loss: 1.8739 - val_accuracy: 0.6623\n",
      "Epoch 646/1000\n",
      "178/178 [==============================] - 0s 99us/step - loss: 0.0778 - accuracy: 0.9775 - val_loss: 1.9021 - val_accuracy: 0.6623\n",
      "Epoch 647/1000\n",
      "178/178 [==============================] - 0s 173us/step - loss: 0.0774 - accuracy: 0.9775 - val_loss: 1.8904 - val_accuracy: 0.6623\n",
      "Epoch 648/1000\n",
      "178/178 [==============================] - 0s 164us/step - loss: 0.0764 - accuracy: 0.9775 - val_loss: 1.9069 - val_accuracy: 0.6623\n",
      "Epoch 649/1000\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0272 - accuracy: 1.00 - 0s 253us/step - loss: 0.0765 - accuracy: 0.9775 - val_loss: 1.8964 - val_accuracy: 0.6623\n",
      "Epoch 650/1000\n",
      "178/178 [==============================] - 0s 178us/step - loss: 0.0779 - accuracy: 0.9775 - val_loss: 1.8965 - val_accuracy: 0.6623\n",
      "Epoch 651/1000\n",
      "178/178 [==============================] - 0s 273us/step - loss: 0.0774 - accuracy: 0.9775 - val_loss: 1.9115 - val_accuracy: 0.6623\n",
      "Epoch 652/1000\n",
      "178/178 [==============================] - 0s 253us/step - loss: 0.0764 - accuracy: 0.9775 - val_loss: 1.9003 - val_accuracy: 0.6623\n",
      "Epoch 653/1000\n",
      "178/178 [==============================] - 0s 139us/step - loss: 0.0758 - accuracy: 0.9775 - val_loss: 1.9017 - val_accuracy: 0.6623\n",
      "Epoch 654/1000\n",
      "178/178 [==============================] - 0s 186us/step - loss: 0.0777 - accuracy: 0.9775 - val_loss: 1.9072 - val_accuracy: 0.6623\n",
      "Epoch 655/1000\n",
      "178/178 [==============================] - 0s 150us/step - loss: 0.0761 - accuracy: 0.9775 - val_loss: 1.8945 - val_accuracy: 0.6623\n",
      "Epoch 656/1000\n",
      "178/178 [==============================] - 0s 136us/step - loss: 0.0763 - accuracy: 0.9775 - val_loss: 1.8823 - val_accuracy: 0.6623\n",
      "Epoch 657/1000\n",
      "178/178 [==============================] - 0s 149us/step - loss: 0.0766 - accuracy: 0.9775 - val_loss: 1.9086 - val_accuracy: 0.6623\n",
      "Epoch 658/1000\n",
      "178/178 [==============================] - 0s 193us/step - loss: 0.0758 - accuracy: 0.9775 - val_loss: 1.9043 - val_accuracy: 0.6623\n",
      "Epoch 659/1000\n",
      "178/178 [==============================] - 0s 167us/step - loss: 0.0763 - accuracy: 0.9775 - val_loss: 1.9089 - val_accuracy: 0.6623\n",
      "Epoch 660/1000\n",
      "178/178 [==============================] - 0s 143us/step - loss: 0.0758 - accuracy: 0.9775 - val_loss: 1.8980 - val_accuracy: 0.6623\n",
      "Epoch 661/1000\n",
      "178/178 [==============================] - 0s 116us/step - loss: 0.0752 - accuracy: 0.9775 - val_loss: 1.9120 - val_accuracy: 0.6623\n",
      "Epoch 662/1000\n",
      "178/178 [==============================] - 0s 123us/step - loss: 0.0758 - accuracy: 0.9775 - val_loss: 1.9178 - val_accuracy: 0.6623\n",
      "Epoch 663/1000\n",
      "178/178 [==============================] - 0s 133us/step - loss: 0.0750 - accuracy: 0.9775 - val_loss: 1.9169 - val_accuracy: 0.6623\n",
      "Epoch 664/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 333us/step - loss: 0.0763 - accuracy: 0.9775 - val_loss: 1.9282 - val_accuracy: 0.6623\n",
      "Epoch 665/1000\n",
      "178/178 [==============================] - 0s 287us/step - loss: 0.0759 - accuracy: 0.9775 - val_loss: 1.9284 - val_accuracy: 0.6623\n",
      "Epoch 666/1000\n",
      "178/178 [==============================] - 0s 169us/step - loss: 0.0754 - accuracy: 0.9831 - val_loss: 1.9212 - val_accuracy: 0.6623\n",
      "Epoch 667/1000\n",
      "178/178 [==============================] - 0s 197us/step - loss: 0.0761 - accuracy: 0.9775 - val_loss: 1.9002 - val_accuracy: 0.6623\n",
      "Epoch 668/1000\n",
      "178/178 [==============================] - 0s 136us/step - loss: 0.0773 - accuracy: 0.9775 - val_loss: 1.8978 - val_accuracy: 0.6623\n",
      "Epoch 669/1000\n",
      "178/178 [==============================] - 0s 195us/step - loss: 0.0760 - accuracy: 0.9775 - val_loss: 1.9091 - val_accuracy: 0.6623\n",
      "Epoch 670/1000\n",
      "178/178 [==============================] - 0s 103us/step - loss: 0.0750 - accuracy: 0.9775 - val_loss: 1.9085 - val_accuracy: 0.6623\n",
      "Epoch 671/1000\n",
      "178/178 [==============================] - 0s 118us/step - loss: 0.0780 - accuracy: 0.9775 - val_loss: 1.9274 - val_accuracy: 0.6623\n",
      "Epoch 672/1000\n",
      "178/178 [==============================] - 0s 93us/step - loss: 0.0751 - accuracy: 0.9775 - val_loss: 1.9249 - val_accuracy: 0.6623\n",
      "Epoch 673/1000\n",
      "178/178 [==============================] - 0s 102us/step - loss: 0.0737 - accuracy: 0.9775 - val_loss: 1.9133 - val_accuracy: 0.6623\n",
      "Epoch 674/1000\n",
      "178/178 [==============================] - 0s 91us/step - loss: 0.0754 - accuracy: 0.9775 - val_loss: 1.9262 - val_accuracy: 0.6623\n",
      "Epoch 675/1000\n",
      "178/178 [==============================] - 0s 128us/step - loss: 0.0770 - accuracy: 0.9775 - val_loss: 1.9225 - val_accuracy: 0.6623\n",
      "Epoch 676/1000\n",
      "178/178 [==============================] - 0s 115us/step - loss: 0.0757 - accuracy: 0.9775 - val_loss: 1.9076 - val_accuracy: 0.6623\n",
      "Epoch 677/1000\n",
      "178/178 [==============================] - 0s 124us/step - loss: 0.0755 - accuracy: 0.9775 - val_loss: 1.9190 - val_accuracy: 0.6623\n",
      "Epoch 678/1000\n",
      "178/178 [==============================] - 0s 131us/step - loss: 0.0738 - accuracy: 0.9775 - val_loss: 1.9488 - val_accuracy: 0.6623\n",
      "Epoch 679/1000\n",
      "178/178 [==============================] - 0s 138us/step - loss: 0.0733 - accuracy: 0.9775 - val_loss: 1.9077 - val_accuracy: 0.6623\n",
      "Epoch 680/1000\n",
      "178/178 [==============================] - 0s 92us/step - loss: 0.0761 - accuracy: 0.9775 - val_loss: 1.9328 - val_accuracy: 0.6623\n",
      "Epoch 681/1000\n",
      "178/178 [==============================] - 0s 88us/step - loss: 0.0755 - accuracy: 0.9775 - val_loss: 1.9308 - val_accuracy: 0.6623\n",
      "Epoch 682/1000\n",
      "178/178 [==============================] - 0s 85us/step - loss: 0.0733 - accuracy: 0.9775 - val_loss: 1.9402 - val_accuracy: 0.6623\n",
      "Epoch 683/1000\n",
      "178/178 [==============================] - 0s 157us/step - loss: 0.0752 - accuracy: 0.9775 - val_loss: 1.9670 - val_accuracy: 0.6494\n",
      "Epoch 684/1000\n",
      "178/178 [==============================] - 0s 232us/step - loss: 0.0752 - accuracy: 0.9831 - val_loss: 1.9249 - val_accuracy: 0.6623\n",
      "Epoch 685/1000\n",
      "178/178 [==============================] - 0s 120us/step - loss: 0.0754 - accuracy: 0.9775 - val_loss: 1.9428 - val_accuracy: 0.6623\n",
      "Epoch 686/1000\n",
      "178/178 [==============================] - 0s 108us/step - loss: 0.0741 - accuracy: 0.9775 - val_loss: 1.9599 - val_accuracy: 0.6623\n",
      "Epoch 687/1000\n",
      "178/178 [==============================] - 0s 101us/step - loss: 0.0747 - accuracy: 0.9775 - val_loss: 1.9365 - val_accuracy: 0.6623\n",
      "Epoch 688/1000\n",
      "178/178 [==============================] - 0s 123us/step - loss: 0.0761 - accuracy: 0.9775 - val_loss: 1.9454 - val_accuracy: 0.6623\n",
      "Epoch 689/1000\n",
      "178/178 [==============================] - 0s 96us/step - loss: 0.0742 - accuracy: 0.9775 - val_loss: 1.9630 - val_accuracy: 0.6623\n",
      "Epoch 690/1000\n",
      "178/178 [==============================] - 0s 96us/step - loss: 0.0744 - accuracy: 0.9831 - val_loss: 1.9196 - val_accuracy: 0.6623\n",
      "Epoch 691/1000\n",
      "178/178 [==============================] - 0s 91us/step - loss: 0.0755 - accuracy: 0.9775 - val_loss: 1.9545 - val_accuracy: 0.6623\n",
      "Epoch 692/1000\n",
      "178/178 [==============================] - 0s 92us/step - loss: 0.0756 - accuracy: 0.9775 - val_loss: 1.9464 - val_accuracy: 0.6623\n",
      "Epoch 693/1000\n",
      "178/178 [==============================] - 0s 90us/step - loss: 0.0749 - accuracy: 0.9775 - val_loss: 1.9681 - val_accuracy: 0.6623\n",
      "Epoch 694/1000\n",
      "178/178 [==============================] - 0s 89us/step - loss: 0.0793 - accuracy: 0.9775 - val_loss: 1.9638 - val_accuracy: 0.6623\n",
      "Epoch 695/1000\n",
      "178/178 [==============================] - 0s 96us/step - loss: 0.0726 - accuracy: 0.9775 - val_loss: 1.9743 - val_accuracy: 0.6623\n",
      "Epoch 696/1000\n",
      "178/178 [==============================] - 0s 97us/step - loss: 0.0748 - accuracy: 0.9831 - val_loss: 1.9573 - val_accuracy: 0.6623\n",
      "Epoch 697/1000\n",
      "178/178 [==============================] - 0s 88us/step - loss: 0.0741 - accuracy: 0.9775 - val_loss: 1.9719 - val_accuracy: 0.6623\n",
      "Epoch 698/1000\n",
      "178/178 [==============================] - 0s 89us/step - loss: 0.0750 - accuracy: 0.9831 - val_loss: 1.9707 - val_accuracy: 0.6623\n",
      "Epoch 699/1000\n",
      "178/178 [==============================] - 0s 89us/step - loss: 0.0734 - accuracy: 0.9775 - val_loss: 1.9798 - val_accuracy: 0.6623\n",
      "Epoch 700/1000\n",
      "178/178 [==============================] - 0s 96us/step - loss: 0.0724 - accuracy: 0.9831 - val_loss: 1.9733 - val_accuracy: 0.6623\n",
      "Epoch 701/1000\n",
      "178/178 [==============================] - 0s 96us/step - loss: 0.0722 - accuracy: 0.9775 - val_loss: 1.9769 - val_accuracy: 0.6623\n",
      "Epoch 702/1000\n",
      "178/178 [==============================] - 0s 98us/step - loss: 0.0722 - accuracy: 0.9775 - val_loss: 1.9789 - val_accuracy: 0.6623\n",
      "Epoch 703/1000\n",
      "178/178 [==============================] - 0s 92us/step - loss: 0.0740 - accuracy: 0.9775 - val_loss: 1.9620 - val_accuracy: 0.6623\n",
      "Epoch 704/1000\n",
      "178/178 [==============================] - 0s 90us/step - loss: 0.0738 - accuracy: 0.9775 - val_loss: 1.9665 - val_accuracy: 0.6623\n",
      "Epoch 705/1000\n",
      "178/178 [==============================] - 0s 91us/step - loss: 0.0740 - accuracy: 0.9831 - val_loss: 1.9751 - val_accuracy: 0.6623\n",
      "Epoch 706/1000\n",
      "178/178 [==============================] - 0s 90us/step - loss: 0.0730 - accuracy: 0.9775 - val_loss: 1.9731 - val_accuracy: 0.6623\n",
      "Epoch 707/1000\n",
      "178/178 [==============================] - 0s 105us/step - loss: 0.0732 - accuracy: 0.9775 - val_loss: 1.9815 - val_accuracy: 0.6623\n",
      "Epoch 708/1000\n",
      "178/178 [==============================] - 0s 94us/step - loss: 0.0724 - accuracy: 0.9831 - val_loss: 1.9474 - val_accuracy: 0.6623\n",
      "Epoch 709/1000\n",
      "178/178 [==============================] - 0s 90us/step - loss: 0.0763 - accuracy: 0.9775 - val_loss: 1.9516 - val_accuracy: 0.6623\n",
      "Epoch 710/1000\n",
      "178/178 [==============================] - 0s 117us/step - loss: 0.0734 - accuracy: 0.9775 - val_loss: 1.9877 - val_accuracy: 0.6623\n",
      "Epoch 711/1000\n",
      "178/178 [==============================] - 0s 106us/step - loss: 0.0726 - accuracy: 0.9775 - val_loss: 1.9994 - val_accuracy: 0.6623\n",
      "Epoch 712/1000\n",
      "178/178 [==============================] - 0s 100us/step - loss: 0.0733 - accuracy: 0.9775 - val_loss: 1.9809 - val_accuracy: 0.6623\n",
      "Epoch 713/1000\n",
      "178/178 [==============================] - 0s 97us/step - loss: 0.0718 - accuracy: 0.9775 - val_loss: 1.9886 - val_accuracy: 0.6623\n",
      "Epoch 714/1000\n",
      "178/178 [==============================] - 0s 98us/step - loss: 0.0725 - accuracy: 0.9775 - val_loss: 1.9832 - val_accuracy: 0.6623\n",
      "Epoch 715/1000\n",
      "178/178 [==============================] - 0s 97us/step - loss: 0.0710 - accuracy: 0.9775 - val_loss: 1.9772 - val_accuracy: 0.6623\n",
      "Epoch 716/1000\n",
      "178/178 [==============================] - 0s 96us/step - loss: 0.0721 - accuracy: 0.9775 - val_loss: 1.9939 - val_accuracy: 0.6623\n",
      "Epoch 717/1000\n",
      "178/178 [==============================] - 0s 103us/step - loss: 0.0727 - accuracy: 0.9775 - val_loss: 1.9772 - val_accuracy: 0.6623\n",
      "Epoch 718/1000\n",
      "178/178 [==============================] - 0s 103us/step - loss: 0.0730 - accuracy: 0.9775 - val_loss: 2.0007 - val_accuracy: 0.6623\n",
      "Epoch 719/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 84us/step - loss: 0.0746 - accuracy: 0.9775 - val_loss: 1.9929 - val_accuracy: 0.6623\n",
      "Epoch 720/1000\n",
      "178/178 [==============================] - 0s 87us/step - loss: 0.0711 - accuracy: 0.9775 - val_loss: 1.9734 - val_accuracy: 0.6623\n",
      "Epoch 721/1000\n",
      "178/178 [==============================] - 0s 88us/step - loss: 0.0721 - accuracy: 0.9775 - val_loss: 1.9992 - val_accuracy: 0.6623\n",
      "Epoch 722/1000\n",
      "178/178 [==============================] - 0s 87us/step - loss: 0.0717 - accuracy: 0.9775 - val_loss: 1.9894 - val_accuracy: 0.6623\n",
      "Epoch 723/1000\n",
      "178/178 [==============================] - 0s 91us/step - loss: 0.0736 - accuracy: 0.9775 - val_loss: 2.0138 - val_accuracy: 0.6623\n",
      "Epoch 724/1000\n",
      "178/178 [==============================] - 0s 94us/step - loss: 0.0708 - accuracy: 0.9831 - val_loss: 2.0001 - val_accuracy: 0.6623\n",
      "Epoch 725/1000\n",
      "178/178 [==============================] - 0s 92us/step - loss: 0.0714 - accuracy: 0.9775 - val_loss: 1.9824 - val_accuracy: 0.6623\n",
      "Epoch 726/1000\n",
      "178/178 [==============================] - 0s 100us/step - loss: 0.0716 - accuracy: 0.9775 - val_loss: 2.0080 - val_accuracy: 0.6623\n",
      "Epoch 727/1000\n",
      "178/178 [==============================] - 0s 105us/step - loss: 0.0707 - accuracy: 0.9775 - val_loss: 2.0083 - val_accuracy: 0.6623\n",
      "Epoch 728/1000\n",
      "178/178 [==============================] - 0s 110us/step - loss: 0.0707 - accuracy: 0.9775 - val_loss: 2.0180 - val_accuracy: 0.6623\n",
      "Epoch 729/1000\n",
      "178/178 [==============================] - 0s 118us/step - loss: 0.0744 - accuracy: 0.9831 - val_loss: 2.0173 - val_accuracy: 0.6623\n",
      "Epoch 730/1000\n",
      "178/178 [==============================] - 0s 91us/step - loss: 0.0717 - accuracy: 0.9831 - val_loss: 2.0078 - val_accuracy: 0.6623\n",
      "Epoch 731/1000\n",
      "178/178 [==============================] - 0s 96us/step - loss: 0.0714 - accuracy: 0.9775 - val_loss: 2.0027 - val_accuracy: 0.6623\n",
      "Epoch 732/1000\n",
      "178/178 [==============================] - 0s 89us/step - loss: 0.0703 - accuracy: 0.9775 - val_loss: 2.0079 - val_accuracy: 0.6623\n",
      "Epoch 733/1000\n",
      "178/178 [==============================] - 0s 90us/step - loss: 0.0728 - accuracy: 0.9775 - val_loss: 2.0362 - val_accuracy: 0.6623\n",
      "Epoch 734/1000\n",
      "178/178 [==============================] - 0s 89us/step - loss: 0.0719 - accuracy: 0.9775 - val_loss: 2.0086 - val_accuracy: 0.6623\n",
      "Epoch 735/1000\n",
      "178/178 [==============================] - 0s 88us/step - loss: 0.0725 - accuracy: 0.9775 - val_loss: 2.0153 - val_accuracy: 0.6623\n",
      "Epoch 736/1000\n",
      "178/178 [==============================] - 0s 92us/step - loss: 0.0704 - accuracy: 0.9775 - val_loss: 2.0349 - val_accuracy: 0.6623\n",
      "Epoch 737/1000\n",
      "178/178 [==============================] - 0s 120us/step - loss: 0.0719 - accuracy: 0.9775 - val_loss: 2.0215 - val_accuracy: 0.6623\n",
      "Epoch 738/1000\n",
      "178/178 [==============================] - 0s 103us/step - loss: 0.0707 - accuracy: 0.9775 - val_loss: 2.0263 - val_accuracy: 0.6623\n",
      "Epoch 739/1000\n",
      "178/178 [==============================] - 0s 100us/step - loss: 0.0712 - accuracy: 0.9831 - val_loss: 2.0397 - val_accuracy: 0.6623\n",
      "Epoch 740/1000\n",
      "178/178 [==============================] - 0s 97us/step - loss: 0.0717 - accuracy: 0.9775 - val_loss: 2.0379 - val_accuracy: 0.6623\n",
      "Epoch 741/1000\n",
      "178/178 [==============================] - 0s 98us/step - loss: 0.0711 - accuracy: 0.9831 - val_loss: 2.0294 - val_accuracy: 0.6623\n",
      "Epoch 742/1000\n",
      "178/178 [==============================] - 0s 98us/step - loss: 0.0715 - accuracy: 0.9775 - val_loss: 2.0365 - val_accuracy: 0.6623\n",
      "Epoch 743/1000\n",
      "178/178 [==============================] - 0s 90us/step - loss: 0.0704 - accuracy: 0.9831 - val_loss: 2.0016 - val_accuracy: 0.6623\n",
      "Epoch 744/1000\n",
      "178/178 [==============================] - 0s 92us/step - loss: 0.0716 - accuracy: 0.9775 - val_loss: 2.0098 - val_accuracy: 0.6623\n",
      "Epoch 745/1000\n",
      "178/178 [==============================] - 0s 90us/step - loss: 0.0710 - accuracy: 0.9775 - val_loss: 2.0134 - val_accuracy: 0.6623\n",
      "Epoch 746/1000\n",
      "178/178 [==============================] - 0s 90us/step - loss: 0.0694 - accuracy: 0.9775 - val_loss: 2.0359 - val_accuracy: 0.6623\n",
      "Epoch 747/1000\n",
      "178/178 [==============================] - 0s 95us/step - loss: 0.0699 - accuracy: 0.9831 - val_loss: 2.0307 - val_accuracy: 0.6623\n",
      "Epoch 748/1000\n",
      "178/178 [==============================] - 0s 89us/step - loss: 0.0709 - accuracy: 0.9775 - val_loss: 2.0356 - val_accuracy: 0.6623\n",
      "Epoch 749/1000\n",
      "178/178 [==============================] - 0s 86us/step - loss: 0.0696 - accuracy: 0.9775 - val_loss: 2.0425 - val_accuracy: 0.6623\n",
      "Epoch 750/1000\n",
      "178/178 [==============================] - 0s 91us/step - loss: 0.0711 - accuracy: 0.9831 - val_loss: 2.0481 - val_accuracy: 0.6623\n",
      "Epoch 751/1000\n",
      "178/178 [==============================] - 0s 103us/step - loss: 0.0708 - accuracy: 0.9831 - val_loss: 2.0483 - val_accuracy: 0.6623\n",
      "Epoch 752/1000\n",
      "178/178 [==============================] - 0s 98us/step - loss: 0.0710 - accuracy: 0.9775 - val_loss: 2.0420 - val_accuracy: 0.6623\n",
      "Epoch 753/1000\n",
      "178/178 [==============================] - 0s 97us/step - loss: 0.0708 - accuracy: 0.9775 - val_loss: 2.0551 - val_accuracy: 0.6623\n",
      "Epoch 754/1000\n",
      "178/178 [==============================] - 0s 101us/step - loss: 0.0710 - accuracy: 0.9831 - val_loss: 2.0413 - val_accuracy: 0.6623\n",
      "Epoch 755/1000\n",
      "178/178 [==============================] - 0s 89us/step - loss: 0.0696 - accuracy: 0.9831 - val_loss: 2.0307 - val_accuracy: 0.6623\n",
      "Epoch 756/1000\n",
      "178/178 [==============================] - 0s 100us/step - loss: 0.0687 - accuracy: 0.9775 - val_loss: 2.0381 - val_accuracy: 0.6623\n",
      "Epoch 757/1000\n",
      "178/178 [==============================] - 0s 89us/step - loss: 0.0699 - accuracy: 0.9775 - val_loss: 2.0461 - val_accuracy: 0.6623\n",
      "Epoch 758/1000\n",
      "178/178 [==============================] - 0s 84us/step - loss: 0.0694 - accuracy: 0.9831 - val_loss: 2.0475 - val_accuracy: 0.6623\n",
      "Epoch 759/1000\n",
      "178/178 [==============================] - 0s 96us/step - loss: 0.0685 - accuracy: 0.9775 - val_loss: 2.0489 - val_accuracy: 0.6623\n",
      "Epoch 760/1000\n",
      "178/178 [==============================] - 0s 96us/step - loss: 0.0712 - accuracy: 0.9775 - val_loss: 2.0558 - val_accuracy: 0.6623\n",
      "Epoch 761/1000\n",
      "178/178 [==============================] - 0s 90us/step - loss: 0.0684 - accuracy: 0.9775 - val_loss: 2.0550 - val_accuracy: 0.6623\n",
      "Epoch 762/1000\n",
      "178/178 [==============================] - 0s 85us/step - loss: 0.0712 - accuracy: 0.9831 - val_loss: 2.0393 - val_accuracy: 0.6623\n",
      "Epoch 763/1000\n",
      "178/178 [==============================] - 0s 98us/step - loss: 0.0695 - accuracy: 0.9831 - val_loss: 2.0550 - val_accuracy: 0.6623\n",
      "Epoch 764/1000\n",
      "178/178 [==============================] - 0s 121us/step - loss: 0.0701 - accuracy: 0.9831 - val_loss: 2.0576 - val_accuracy: 0.6623\n",
      "Epoch 765/1000\n",
      "178/178 [==============================] - 0s 104us/step - loss: 0.0685 - accuracy: 0.9775 - val_loss: 2.0700 - val_accuracy: 0.6623\n",
      "Epoch 766/1000\n",
      "178/178 [==============================] - 0s 115us/step - loss: 0.0710 - accuracy: 0.9775 - val_loss: 2.0799 - val_accuracy: 0.6623\n",
      "Epoch 767/1000\n",
      "178/178 [==============================] - 0s 96us/step - loss: 0.0696 - accuracy: 0.9831 - val_loss: 2.0691 - val_accuracy: 0.6623\n",
      "Epoch 768/1000\n",
      "178/178 [==============================] - 0s 92us/step - loss: 0.0703 - accuracy: 0.9831 - val_loss: 2.0495 - val_accuracy: 0.6623\n",
      "Epoch 769/1000\n",
      "178/178 [==============================] - 0s 103us/step - loss: 0.0697 - accuracy: 0.9775 - val_loss: 2.0545 - val_accuracy: 0.6623\n",
      "Epoch 770/1000\n",
      "178/178 [==============================] - 0s 90us/step - loss: 0.0698 - accuracy: 0.9775 - val_loss: 2.0673 - val_accuracy: 0.6623\n",
      "Epoch 771/1000\n",
      "178/178 [==============================] - 0s 85us/step - loss: 0.0695 - accuracy: 0.9831 - val_loss: 2.0568 - val_accuracy: 0.6623\n",
      "Epoch 772/1000\n",
      "178/178 [==============================] - 0s 84us/step - loss: 0.0697 - accuracy: 0.9775 - val_loss: 2.0666 - val_accuracy: 0.6623\n",
      "Epoch 773/1000\n",
      "178/178 [==============================] - 0s 87us/step - loss: 0.0686 - accuracy: 0.9831 - val_loss: 2.0848 - val_accuracy: 0.6623\n",
      "Epoch 774/1000\n",
      "178/178 [==============================] - 0s 89us/step - loss: 0.0707 - accuracy: 0.9775 - val_loss: 2.0843 - val_accuracy: 0.6623\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 775/1000\n",
      "178/178 [==============================] - 0s 96us/step - loss: 0.0700 - accuracy: 0.9831 - val_loss: 2.0766 - val_accuracy: 0.6623\n",
      "Epoch 776/1000\n",
      "178/178 [==============================] - 0s 102us/step - loss: 0.0679 - accuracy: 0.9775 - val_loss: 2.0736 - val_accuracy: 0.6623\n",
      "Epoch 777/1000\n",
      "178/178 [==============================] - 0s 90us/step - loss: 0.0680 - accuracy: 0.9831 - val_loss: 2.0745 - val_accuracy: 0.6623\n",
      "Epoch 778/1000\n",
      "178/178 [==============================] - 0s 108us/step - loss: 0.0691 - accuracy: 0.9775 - val_loss: 2.1083 - val_accuracy: 0.6364\n",
      "Epoch 779/1000\n",
      "178/178 [==============================] - 0s 107us/step - loss: 0.0711 - accuracy: 0.9831 - val_loss: 2.0821 - val_accuracy: 0.6623\n",
      "Epoch 780/1000\n",
      "178/178 [==============================] - 0s 94us/step - loss: 0.0685 - accuracy: 0.9831 - val_loss: 2.0729 - val_accuracy: 0.6623\n",
      "Epoch 781/1000\n",
      "178/178 [==============================] - 0s 93us/step - loss: 0.0697 - accuracy: 0.9775 - val_loss: 2.0686 - val_accuracy: 0.6623\n",
      "Epoch 782/1000\n",
      "178/178 [==============================] - 0s 105us/step - loss: 0.0690 - accuracy: 0.9831 - val_loss: 2.0753 - val_accuracy: 0.6623\n",
      "Epoch 783/1000\n",
      "178/178 [==============================] - 0s 93us/step - loss: 0.0686 - accuracy: 0.9775 - val_loss: 2.0695 - val_accuracy: 0.6623\n",
      "Epoch 784/1000\n",
      "178/178 [==============================] - 0s 93us/step - loss: 0.0679 - accuracy: 0.9775 - val_loss: 2.0774 - val_accuracy: 0.6623\n",
      "Epoch 785/1000\n",
      "178/178 [==============================] - 0s 104us/step - loss: 0.0678 - accuracy: 0.9831 - val_loss: 2.0890 - val_accuracy: 0.6623\n",
      "Epoch 786/1000\n",
      "178/178 [==============================] - 0s 91us/step - loss: 0.0695 - accuracy: 0.9775 - val_loss: 2.0999 - val_accuracy: 0.6623\n",
      "Epoch 787/1000\n",
      "178/178 [==============================] - 0s 93us/step - loss: 0.0684 - accuracy: 0.9831 - val_loss: 2.0593 - val_accuracy: 0.6623\n",
      "Epoch 788/1000\n",
      "178/178 [==============================] - 0s 91us/step - loss: 0.0684 - accuracy: 0.9775 - val_loss: 2.0847 - val_accuracy: 0.6623\n",
      "Epoch 789/1000\n",
      "178/178 [==============================] - 0s 90us/step - loss: 0.0694 - accuracy: 0.9831 - val_loss: 2.0863 - val_accuracy: 0.6623\n",
      "Epoch 790/1000\n",
      "178/178 [==============================] - 0s 111us/step - loss: 0.0680 - accuracy: 0.9831 - val_loss: 2.0736 - val_accuracy: 0.6623\n",
      "Epoch 791/1000\n",
      "178/178 [==============================] - 0s 116us/step - loss: 0.0693 - accuracy: 0.9775 - val_loss: 2.0919 - val_accuracy: 0.6623\n",
      "Epoch 792/1000\n",
      "178/178 [==============================] - 0s 100us/step - loss: 0.0677 - accuracy: 0.9831 - val_loss: 2.0946 - val_accuracy: 0.6623\n",
      "Epoch 793/1000\n",
      "178/178 [==============================] - 0s 103us/step - loss: 0.0676 - accuracy: 0.9831 - val_loss: 2.0989 - val_accuracy: 0.6623\n",
      "Epoch 794/1000\n",
      "178/178 [==============================] - 0s 98us/step - loss: 0.0697 - accuracy: 0.9831 - val_loss: 2.0987 - val_accuracy: 0.6623\n",
      "Epoch 795/1000\n",
      "178/178 [==============================] - 0s 97us/step - loss: 0.0709 - accuracy: 0.9831 - val_loss: 2.1141 - val_accuracy: 0.6623\n",
      "Epoch 796/1000\n",
      "178/178 [==============================] - 0s 127us/step - loss: 0.0669 - accuracy: 0.9831 - val_loss: 2.0988 - val_accuracy: 0.6623\n",
      "Epoch 797/1000\n",
      "178/178 [==============================] - 0s 95us/step - loss: 0.0674 - accuracy: 0.9831 - val_loss: 2.0975 - val_accuracy: 0.6623\n",
      "Epoch 798/1000\n",
      "178/178 [==============================] - 0s 98us/step - loss: 0.0660 - accuracy: 0.9775 - val_loss: 2.1069 - val_accuracy: 0.6623\n",
      "Epoch 799/1000\n",
      "178/178 [==============================] - 0s 89us/step - loss: 0.0676 - accuracy: 0.9831 - val_loss: 2.0916 - val_accuracy: 0.6623\n",
      "Epoch 800/1000\n",
      "178/178 [==============================] - 0s 90us/step - loss: 0.0687 - accuracy: 0.9831 - val_loss: 2.1039 - val_accuracy: 0.6623\n",
      "Epoch 801/1000\n",
      "178/178 [==============================] - 0s 96us/step - loss: 0.0675 - accuracy: 0.9831 - val_loss: 2.1055 - val_accuracy: 0.6623\n",
      "Epoch 802/1000\n",
      "178/178 [==============================] - 0s 92us/step - loss: 0.0681 - accuracy: 0.9831 - val_loss: 2.0881 - val_accuracy: 0.6623\n",
      "Epoch 803/1000\n",
      "178/178 [==============================] - 0s 87us/step - loss: 0.0688 - accuracy: 0.9775 - val_loss: 2.0949 - val_accuracy: 0.6623\n",
      "Epoch 804/1000\n",
      "178/178 [==============================] - 0s 99us/step - loss: 0.0679 - accuracy: 0.9775 - val_loss: 2.1068 - val_accuracy: 0.6623\n",
      "Epoch 805/1000\n",
      "178/178 [==============================] - 0s 91us/step - loss: 0.0674 - accuracy: 0.9831 - val_loss: 2.0986 - val_accuracy: 0.6623\n",
      "Epoch 806/1000\n",
      "178/178 [==============================] - 0s 90us/step - loss: 0.0656 - accuracy: 0.9831 - val_loss: 2.1027 - val_accuracy: 0.6623\n",
      "Epoch 807/1000\n",
      "178/178 [==============================] - 0s 93us/step - loss: 0.0675 - accuracy: 0.9775 - val_loss: 2.1068 - val_accuracy: 0.6623\n",
      "Epoch 808/1000\n",
      "178/178 [==============================] - 0s 99us/step - loss: 0.0660 - accuracy: 0.9831 - val_loss: 2.1127 - val_accuracy: 0.6623\n",
      "Epoch 809/1000\n",
      "178/178 [==============================] - 0s 95us/step - loss: 0.0679 - accuracy: 0.9831 - val_loss: 2.0988 - val_accuracy: 0.6623\n",
      "Epoch 810/1000\n",
      "178/178 [==============================] - 0s 101us/step - loss: 0.0672 - accuracy: 0.9831 - val_loss: 2.0819 - val_accuracy: 0.6623\n",
      "Epoch 811/1000\n",
      "178/178 [==============================] - 0s 100us/step - loss: 0.0683 - accuracy: 0.9775 - val_loss: 2.1246 - val_accuracy: 0.6623\n",
      "Epoch 812/1000\n",
      "178/178 [==============================] - 0s 90us/step - loss: 0.0666 - accuracy: 0.9831 - val_loss: 2.1324 - val_accuracy: 0.6623\n",
      "Epoch 813/1000\n",
      "178/178 [==============================] - 0s 91us/step - loss: 0.0683 - accuracy: 0.9831 - val_loss: 2.1259 - val_accuracy: 0.6623\n",
      "Epoch 814/1000\n",
      "178/178 [==============================] - 0s 93us/step - loss: 0.0661 - accuracy: 0.9831 - val_loss: 2.1006 - val_accuracy: 0.6623\n",
      "Epoch 815/1000\n",
      "178/178 [==============================] - 0s 94us/step - loss: 0.0647 - accuracy: 0.9775 - val_loss: 2.1267 - val_accuracy: 0.6623\n",
      "Epoch 816/1000\n",
      "178/178 [==============================] - 0s 116us/step - loss: 0.0662 - accuracy: 0.9831 - val_loss: 2.1001 - val_accuracy: 0.6623\n",
      "Epoch 817/1000\n",
      "178/178 [==============================] - 0s 107us/step - loss: 0.0667 - accuracy: 0.9775 - val_loss: 2.1197 - val_accuracy: 0.6623\n",
      "Epoch 818/1000\n",
      "178/178 [==============================] - 0s 97us/step - loss: 0.0674 - accuracy: 0.9775 - val_loss: 2.1257 - val_accuracy: 0.6623\n",
      "Epoch 819/1000\n",
      "178/178 [==============================] - 0s 99us/step - loss: 0.0661 - accuracy: 0.9831 - val_loss: 2.1267 - val_accuracy: 0.6623\n",
      "Epoch 820/1000\n",
      "178/178 [==============================] - 0s 102us/step - loss: 0.0673 - accuracy: 0.9831 - val_loss: 2.1305 - val_accuracy: 0.6623\n",
      "Epoch 821/1000\n",
      "178/178 [==============================] - 0s 103us/step - loss: 0.0665 - accuracy: 0.9831 - val_loss: 2.1070 - val_accuracy: 0.6623\n",
      "Epoch 822/1000\n",
      "178/178 [==============================] - 0s 103us/step - loss: 0.0662 - accuracy: 0.9831 - val_loss: 2.1380 - val_accuracy: 0.6623\n",
      "Epoch 823/1000\n",
      "178/178 [==============================] - 0s 106us/step - loss: 0.0676 - accuracy: 0.9831 - val_loss: 2.1101 - val_accuracy: 0.6623\n",
      "Epoch 824/1000\n",
      "178/178 [==============================] - 0s 95us/step - loss: 0.0683 - accuracy: 0.9831 - val_loss: 2.1109 - val_accuracy: 0.6623\n",
      "Epoch 825/1000\n",
      "178/178 [==============================] - 0s 90us/step - loss: 0.0663 - accuracy: 0.9775 - val_loss: 2.1226 - val_accuracy: 0.6623\n",
      "Epoch 826/1000\n",
      "178/178 [==============================] - 0s 89us/step - loss: 0.0664 - accuracy: 0.9831 - val_loss: 2.1299 - val_accuracy: 0.6623\n",
      "Epoch 827/1000\n",
      "178/178 [==============================] - 0s 94us/step - loss: 0.0665 - accuracy: 0.9831 - val_loss: 2.1393 - val_accuracy: 0.6623\n",
      "Epoch 828/1000\n",
      "178/178 [==============================] - 0s 88us/step - loss: 0.0661 - accuracy: 0.9831 - val_loss: 2.1353 - val_accuracy: 0.6623\n",
      "Epoch 829/1000\n",
      "178/178 [==============================] - 0s 88us/step - loss: 0.0678 - accuracy: 0.9831 - val_loss: 2.1544 - val_accuracy: 0.6623\n",
      "Epoch 830/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 95us/step - loss: 0.0652 - accuracy: 0.9831 - val_loss: 2.1289 - val_accuracy: 0.6623\n",
      "Epoch 831/1000\n",
      "178/178 [==============================] - 0s 92us/step - loss: 0.0653 - accuracy: 0.9831 - val_loss: 2.1425 - val_accuracy: 0.6623\n",
      "Epoch 832/1000\n",
      "178/178 [==============================] - 0s 90us/step - loss: 0.0670 - accuracy: 0.9831 - val_loss: 2.1202 - val_accuracy: 0.6623\n",
      "Epoch 833/1000\n",
      "178/178 [==============================] - 0s 92us/step - loss: 0.0673 - accuracy: 0.9831 - val_loss: 2.1283 - val_accuracy: 0.6623\n",
      "Epoch 834/1000\n",
      "178/178 [==============================] - 0s 97us/step - loss: 0.0671 - accuracy: 0.9831 - val_loss: 2.1361 - val_accuracy: 0.6623\n",
      "Epoch 835/1000\n",
      "178/178 [==============================] - 0s 92us/step - loss: 0.0642 - accuracy: 0.9831 - val_loss: 2.1531 - val_accuracy: 0.6623\n",
      "Epoch 836/1000\n",
      "178/178 [==============================] - 0s 89us/step - loss: 0.0667 - accuracy: 0.9831 - val_loss: 2.1393 - val_accuracy: 0.6623\n",
      "Epoch 837/1000\n",
      "178/178 [==============================] - 0s 109us/step - loss: 0.0683 - accuracy: 0.9831 - val_loss: 2.1458 - val_accuracy: 0.6623\n",
      "Epoch 838/1000\n",
      "178/178 [==============================] - 0s 97us/step - loss: 0.0665 - accuracy: 0.9775 - val_loss: 2.1608 - val_accuracy: 0.6623\n",
      "Epoch 839/1000\n",
      "178/178 [==============================] - 0s 95us/step - loss: 0.0657 - accuracy: 0.9831 - val_loss: 2.1458 - val_accuracy: 0.6623\n",
      "Epoch 840/1000\n",
      "178/178 [==============================] - 0s 90us/step - loss: 0.0655 - accuracy: 0.9831 - val_loss: 2.1649 - val_accuracy: 0.6623\n",
      "Epoch 841/1000\n",
      "178/178 [==============================] - 0s 91us/step - loss: 0.0676 - accuracy: 0.9831 - val_loss: 2.1703 - val_accuracy: 0.6623\n",
      "Epoch 842/1000\n",
      "178/178 [==============================] - 0s 103us/step - loss: 0.0660 - accuracy: 0.9831 - val_loss: 2.1556 - val_accuracy: 0.6623\n",
      "Epoch 843/1000\n",
      "178/178 [==============================] - 0s 112us/step - loss: 0.0652 - accuracy: 0.9831 - val_loss: 2.1606 - val_accuracy: 0.6623\n",
      "Epoch 844/1000\n",
      "178/178 [==============================] - 0s 107us/step - loss: 0.0649 - accuracy: 0.9831 - val_loss: 2.1692 - val_accuracy: 0.6623\n",
      "Epoch 845/1000\n",
      "178/178 [==============================] - 0s 102us/step - loss: 0.0664 - accuracy: 0.9831 - val_loss: 2.1355 - val_accuracy: 0.6623\n",
      "Epoch 846/1000\n",
      "178/178 [==============================] - 0s 101us/step - loss: 0.0674 - accuracy: 0.9775 - val_loss: 2.1381 - val_accuracy: 0.6623\n",
      "Epoch 847/1000\n",
      "178/178 [==============================] - 0s 109us/step - loss: 0.0659 - accuracy: 0.9831 - val_loss: 2.1601 - val_accuracy: 0.6623\n",
      "Epoch 848/1000\n",
      "178/178 [==============================] - 0s 112us/step - loss: 0.0644 - accuracy: 0.9831 - val_loss: 2.1326 - val_accuracy: 0.6623\n",
      "Epoch 849/1000\n",
      "178/178 [==============================] - 0s 109us/step - loss: 0.0668 - accuracy: 0.9831 - val_loss: 2.1444 - val_accuracy: 0.6623\n",
      "Epoch 850/1000\n",
      "178/178 [==============================] - 0s 99us/step - loss: 0.0642 - accuracy: 0.9831 - val_loss: 2.1640 - val_accuracy: 0.6623\n",
      "Epoch 851/1000\n",
      "178/178 [==============================] - 0s 95us/step - loss: 0.0639 - accuracy: 0.9831 - val_loss: 2.1653 - val_accuracy: 0.6623\n",
      "Epoch 852/1000\n",
      "178/178 [==============================] - 0s 91us/step - loss: 0.0670 - accuracy: 0.9831 - val_loss: 2.1803 - val_accuracy: 0.6623\n",
      "Epoch 853/1000\n",
      "178/178 [==============================] - 0s 91us/step - loss: 0.0651 - accuracy: 0.9831 - val_loss: 2.1709 - val_accuracy: 0.6623\n",
      "Epoch 854/1000\n",
      "178/178 [==============================] - 0s 105us/step - loss: 0.0640 - accuracy: 0.9831 - val_loss: 2.1631 - val_accuracy: 0.6623\n",
      "Epoch 855/1000\n",
      "178/178 [==============================] - 0s 94us/step - loss: 0.0640 - accuracy: 0.9831 - val_loss: 2.1426 - val_accuracy: 0.6623\n",
      "Epoch 856/1000\n",
      "178/178 [==============================] - 0s 116us/step - loss: 0.0681 - accuracy: 0.9719 - val_loss: 2.1779 - val_accuracy: 0.6623\n",
      "Epoch 857/1000\n",
      "178/178 [==============================] - 0s 93us/step - loss: 0.0659 - accuracy: 0.9831 - val_loss: 2.1428 - val_accuracy: 0.6623\n",
      "Epoch 858/1000\n",
      "178/178 [==============================] - 0s 101us/step - loss: 0.0677 - accuracy: 0.9831 - val_loss: 2.1721 - val_accuracy: 0.6623\n",
      "Epoch 859/1000\n",
      "178/178 [==============================] - 0s 95us/step - loss: 0.0660 - accuracy: 0.9831 - val_loss: 2.1300 - val_accuracy: 0.6623\n",
      "Epoch 860/1000\n",
      "178/178 [==============================] - 0s 90us/step - loss: 0.0674 - accuracy: 0.9831 - val_loss: 2.1648 - val_accuracy: 0.6623\n",
      "Epoch 861/1000\n",
      "178/178 [==============================] - 0s 97us/step - loss: 0.0651 - accuracy: 0.9831 - val_loss: 2.1690 - val_accuracy: 0.6623\n",
      "Epoch 862/1000\n",
      "178/178 [==============================] - 0s 94us/step - loss: 0.0653 - accuracy: 0.9831 - val_loss: 2.1556 - val_accuracy: 0.6623\n",
      "Epoch 863/1000\n",
      "178/178 [==============================] - 0s 98us/step - loss: 0.0665 - accuracy: 0.9831 - val_loss: 2.1748 - val_accuracy: 0.6623\n",
      "Epoch 864/1000\n",
      "178/178 [==============================] - 0s 87us/step - loss: 0.0644 - accuracy: 0.9831 - val_loss: 2.1880 - val_accuracy: 0.6623\n",
      "Epoch 865/1000\n",
      "178/178 [==============================] - 0s 91us/step - loss: 0.0662 - accuracy: 0.9831 - val_loss: 2.1872 - val_accuracy: 0.6623\n",
      "Epoch 866/1000\n",
      "178/178 [==============================] - 0s 87us/step - loss: 0.0647 - accuracy: 0.9831 - val_loss: 2.1736 - val_accuracy: 0.6623\n",
      "Epoch 867/1000\n",
      "178/178 [==============================] - 0s 102us/step - loss: 0.0661 - accuracy: 0.9831 - val_loss: 2.1804 - val_accuracy: 0.6623\n",
      "Epoch 868/1000\n",
      "178/178 [==============================] - 0s 123us/step - loss: 0.0658 - accuracy: 0.9831 - val_loss: 2.2073 - val_accuracy: 0.6623\n",
      "Epoch 869/1000\n",
      "178/178 [==============================] - 0s 118us/step - loss: 0.0664 - accuracy: 0.9831 - val_loss: 2.1864 - val_accuracy: 0.6623\n",
      "Epoch 870/1000\n",
      "178/178 [==============================] - 0s 104us/step - loss: 0.0638 - accuracy: 0.9831 - val_loss: 2.1521 - val_accuracy: 0.6623\n",
      "Epoch 871/1000\n",
      "178/178 [==============================] - 0s 105us/step - loss: 0.0648 - accuracy: 0.9831 - val_loss: 2.1544 - val_accuracy: 0.6623\n",
      "Epoch 872/1000\n",
      "178/178 [==============================] - 0s 102us/step - loss: 0.0675 - accuracy: 0.9831 - val_loss: 2.1601 - val_accuracy: 0.6623\n",
      "Epoch 873/1000\n",
      "178/178 [==============================] - 0s 129us/step - loss: 0.0661 - accuracy: 0.9775 - val_loss: 2.1856 - val_accuracy: 0.6623\n",
      "Epoch 874/1000\n",
      "178/178 [==============================] - 0s 96us/step - loss: 0.0637 - accuracy: 0.9831 - val_loss: 2.1572 - val_accuracy: 0.6623\n",
      "Epoch 875/1000\n",
      "178/178 [==============================] - 0s 95us/step - loss: 0.0682 - accuracy: 0.9775 - val_loss: 2.1880 - val_accuracy: 0.6623\n",
      "Epoch 876/1000\n",
      "178/178 [==============================] - 0s 90us/step - loss: 0.0634 - accuracy: 0.9831 - val_loss: 2.1650 - val_accuracy: 0.6623\n",
      "Epoch 877/1000\n",
      "178/178 [==============================] - 0s 89us/step - loss: 0.0643 - accuracy: 0.9831 - val_loss: 2.1757 - val_accuracy: 0.6623\n",
      "Epoch 878/1000\n",
      "178/178 [==============================] - 0s 93us/step - loss: 0.0636 - accuracy: 0.9831 - val_loss: 2.1945 - val_accuracy: 0.6623\n",
      "Epoch 879/1000\n",
      "178/178 [==============================] - 0s 167us/step - loss: 0.0650 - accuracy: 0.9831 - val_loss: 2.1771 - val_accuracy: 0.6623\n",
      "Epoch 880/1000\n",
      "178/178 [==============================] - 0s 104us/step - loss: 0.0641 - accuracy: 0.9831 - val_loss: 2.1925 - val_accuracy: 0.6623\n",
      "Epoch 881/1000\n",
      "178/178 [==============================] - 0s 104us/step - loss: 0.0658 - accuracy: 0.9831 - val_loss: 2.1942 - val_accuracy: 0.6623\n",
      "Epoch 882/1000\n",
      "178/178 [==============================] - 0s 108us/step - loss: 0.0645 - accuracy: 0.9831 - val_loss: 2.1938 - val_accuracy: 0.6623\n",
      "Epoch 883/1000\n",
      "178/178 [==============================] - 0s 95us/step - loss: 0.0649 - accuracy: 0.9775 - val_loss: 2.1768 - val_accuracy: 0.6623\n",
      "Epoch 884/1000\n",
      "178/178 [==============================] - 0s 89us/step - loss: 0.0642 - accuracy: 0.9831 - val_loss: 2.1860 - val_accuracy: 0.6623\n",
      "Epoch 885/1000\n",
      "178/178 [==============================] - 0s 93us/step - loss: 0.0648 - accuracy: 0.9831 - val_loss: 2.1869 - val_accuracy: 0.6623\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 886/1000\n",
      "178/178 [==============================] - 0s 91us/step - loss: 0.0642 - accuracy: 0.9831 - val_loss: 2.2093 - val_accuracy: 0.6623\n",
      "Epoch 887/1000\n",
      "178/178 [==============================] - 0s 92us/step - loss: 0.0628 - accuracy: 0.9831 - val_loss: 2.2031 - val_accuracy: 0.6623\n",
      "Epoch 888/1000\n",
      "178/178 [==============================] - 0s 97us/step - loss: 0.0636 - accuracy: 0.9831 - val_loss: 2.1677 - val_accuracy: 0.6623\n",
      "Epoch 889/1000\n",
      "178/178 [==============================] - 0s 91us/step - loss: 0.0642 - accuracy: 0.9775 - val_loss: 2.2065 - val_accuracy: 0.6623\n",
      "Epoch 890/1000\n",
      "178/178 [==============================] - 0s 94us/step - loss: 0.0651 - accuracy: 0.9831 - val_loss: 2.2220 - val_accuracy: 0.6623\n",
      "Epoch 891/1000\n",
      "178/178 [==============================] - 0s 94us/step - loss: 0.0644 - accuracy: 0.9831 - val_loss: 2.2228 - val_accuracy: 0.6623\n",
      "Epoch 892/1000\n",
      "178/178 [==============================] - 0s 94us/step - loss: 0.0667 - accuracy: 0.9831 - val_loss: 2.2087 - val_accuracy: 0.6623\n",
      "Epoch 893/1000\n",
      "178/178 [==============================] - 0s 112us/step - loss: 0.0653 - accuracy: 0.9831 - val_loss: 2.2193 - val_accuracy: 0.6623\n",
      "Epoch 894/1000\n",
      "178/178 [==============================] - 0s 103us/step - loss: 0.0633 - accuracy: 0.9831 - val_loss: 2.1962 - val_accuracy: 0.6623\n",
      "Epoch 895/1000\n",
      "178/178 [==============================] - 0s 101us/step - loss: 0.0636 - accuracy: 0.9831 - val_loss: 2.2119 - val_accuracy: 0.6623\n",
      "Epoch 896/1000\n",
      "178/178 [==============================] - 0s 116us/step - loss: 0.0637 - accuracy: 0.9831 - val_loss: 2.1834 - val_accuracy: 0.6623\n",
      "Epoch 897/1000\n",
      "178/178 [==============================] - 0s 102us/step - loss: 0.0635 - accuracy: 0.9775 - val_loss: 2.2256 - val_accuracy: 0.6623\n",
      "Epoch 898/1000\n",
      "178/178 [==============================] - 0s 112us/step - loss: 0.0652 - accuracy: 0.9831 - val_loss: 2.2128 - val_accuracy: 0.6623\n",
      "Epoch 899/1000\n",
      "178/178 [==============================] - 0s 140us/step - loss: 0.0625 - accuracy: 0.9831 - val_loss: 2.1992 - val_accuracy: 0.6623\n",
      "Epoch 900/1000\n",
      "178/178 [==============================] - 0s 95us/step - loss: 0.0624 - accuracy: 0.9831 - val_loss: 2.2162 - val_accuracy: 0.6623\n",
      "Epoch 901/1000\n",
      "178/178 [==============================] - 0s 94us/step - loss: 0.0627 - accuracy: 0.9831 - val_loss: 2.2135 - val_accuracy: 0.6623\n",
      "Epoch 902/1000\n",
      "178/178 [==============================] - 0s 92us/step - loss: 0.0650 - accuracy: 0.9831 - val_loss: 2.2072 - val_accuracy: 0.6623\n",
      "Epoch 903/1000\n",
      "178/178 [==============================] - 0s 94us/step - loss: 0.0630 - accuracy: 0.9831 - val_loss: 2.1757 - val_accuracy: 0.6623\n",
      "Epoch 904/1000\n",
      "178/178 [==============================] - 0s 99us/step - loss: 0.0658 - accuracy: 0.9775 - val_loss: 2.2275 - val_accuracy: 0.6623\n",
      "Epoch 905/1000\n",
      "178/178 [==============================] - 0s 92us/step - loss: 0.0643 - accuracy: 0.9831 - val_loss: 2.2235 - val_accuracy: 0.6623\n",
      "Epoch 906/1000\n",
      "178/178 [==============================] - 0s 103us/step - loss: 0.0630 - accuracy: 0.9831 - val_loss: 2.2173 - val_accuracy: 0.6623\n",
      "Epoch 907/1000\n",
      "178/178 [==============================] - 0s 115us/step - loss: 0.0638 - accuracy: 0.9831 - val_loss: 2.2038 - val_accuracy: 0.6623\n",
      "Epoch 908/1000\n",
      "178/178 [==============================] - 0s 107us/step - loss: 0.0641 - accuracy: 0.9775 - val_loss: 2.2155 - val_accuracy: 0.6623\n",
      "Epoch 909/1000\n",
      "178/178 [==============================] - 0s 93us/step - loss: 0.0619 - accuracy: 0.9831 - val_loss: 2.2281 - val_accuracy: 0.6623\n",
      "Epoch 910/1000\n",
      "178/178 [==============================] - 0s 95us/step - loss: 0.0618 - accuracy: 0.9831 - val_loss: 2.2351 - val_accuracy: 0.6623\n",
      "Epoch 911/1000\n",
      "178/178 [==============================] - 0s 94us/step - loss: 0.0637 - accuracy: 0.9831 - val_loss: 2.2302 - val_accuracy: 0.6623\n",
      "Epoch 912/1000\n",
      "178/178 [==============================] - 0s 95us/step - loss: 0.0621 - accuracy: 0.9831 - val_loss: 2.2351 - val_accuracy: 0.6623\n",
      "Epoch 913/1000\n",
      "178/178 [==============================] - 0s 96us/step - loss: 0.0618 - accuracy: 0.9831 - val_loss: 2.2327 - val_accuracy: 0.6623\n",
      "Epoch 914/1000\n",
      "178/178 [==============================] - 0s 93us/step - loss: 0.0641 - accuracy: 0.9831 - val_loss: 2.2244 - val_accuracy: 0.6623\n",
      "Epoch 915/1000\n",
      "178/178 [==============================] - 0s 102us/step - loss: 0.0628 - accuracy: 0.9831 - val_loss: 2.1979 - val_accuracy: 0.6623\n",
      "Epoch 916/1000\n",
      "178/178 [==============================] - 0s 87us/step - loss: 0.0656 - accuracy: 0.9831 - val_loss: 2.1932 - val_accuracy: 0.6623\n",
      "Epoch 917/1000\n",
      "178/178 [==============================] - 0s 92us/step - loss: 0.0642 - accuracy: 0.9719 - val_loss: 2.2529 - val_accuracy: 0.6623\n",
      "Epoch 918/1000\n",
      "178/178 [==============================] - 0s 102us/step - loss: 0.0641 - accuracy: 0.9831 - val_loss: 2.2128 - val_accuracy: 0.6623\n",
      "Epoch 919/1000\n",
      "178/178 [==============================] - 0s 113us/step - loss: 0.0617 - accuracy: 0.9831 - val_loss: 2.2406 - val_accuracy: 0.6623\n",
      "Epoch 920/1000\n",
      "178/178 [==============================] - 0s 103us/step - loss: 0.0632 - accuracy: 0.9831 - val_loss: 2.2404 - val_accuracy: 0.6623\n",
      "Epoch 921/1000\n",
      "178/178 [==============================] - 0s 107us/step - loss: 0.0624 - accuracy: 0.9831 - val_loss: 2.2351 - val_accuracy: 0.6623\n",
      "Epoch 922/1000\n",
      "178/178 [==============================] - 0s 100us/step - loss: 0.0620 - accuracy: 0.9831 - val_loss: 2.2413 - val_accuracy: 0.6623\n",
      "Epoch 923/1000\n",
      "178/178 [==============================] - 0s 144us/step - loss: 0.0642 - accuracy: 0.9831 - val_loss: 2.2417 - val_accuracy: 0.6623\n",
      "Epoch 924/1000\n",
      "178/178 [==============================] - 0s 163us/step - loss: 0.0643 - accuracy: 0.9831 - val_loss: 2.2431 - val_accuracy: 0.6623\n",
      "Epoch 925/1000\n",
      "178/178 [==============================] - 0s 195us/step - loss: 0.0611 - accuracy: 0.9831 - val_loss: 2.2582 - val_accuracy: 0.6623\n",
      "Epoch 926/1000\n",
      "178/178 [==============================] - 0s 108us/step - loss: 0.0614 - accuracy: 0.9831 - val_loss: 2.2459 - val_accuracy: 0.6623\n",
      "Epoch 927/1000\n",
      "178/178 [==============================] - 0s 103us/step - loss: 0.0610 - accuracy: 0.9831 - val_loss: 2.2191 - val_accuracy: 0.6623\n",
      "Epoch 928/1000\n",
      "178/178 [==============================] - 0s 104us/step - loss: 0.0631 - accuracy: 0.9831 - val_loss: 2.2281 - val_accuracy: 0.6623\n",
      "Epoch 929/1000\n",
      "178/178 [==============================] - 0s 95us/step - loss: 0.0614 - accuracy: 0.9831 - val_loss: 2.2500 - val_accuracy: 0.6623\n",
      "Epoch 930/1000\n",
      "178/178 [==============================] - 0s 116us/step - loss: 0.0620 - accuracy: 0.9831 - val_loss: 2.2456 - val_accuracy: 0.6623\n",
      "Epoch 931/1000\n",
      "178/178 [==============================] - 0s 99us/step - loss: 0.0616 - accuracy: 0.9831 - val_loss: 2.2431 - val_accuracy: 0.6623\n",
      "Epoch 932/1000\n",
      "178/178 [==============================] - 0s 95us/step - loss: 0.0629 - accuracy: 0.9831 - val_loss: 2.2522 - val_accuracy: 0.6623\n",
      "Epoch 933/1000\n",
      "178/178 [==============================] - 0s 93us/step - loss: 0.0630 - accuracy: 0.9831 - val_loss: 2.2556 - val_accuracy: 0.6623\n",
      "Epoch 934/1000\n",
      "178/178 [==============================] - 0s 89us/step - loss: 0.0626 - accuracy: 0.9831 - val_loss: 2.2600 - val_accuracy: 0.6623\n",
      "Epoch 935/1000\n",
      "178/178 [==============================] - 0s 87us/step - loss: 0.0642 - accuracy: 0.9831 - val_loss: 2.2373 - val_accuracy: 0.6623\n",
      "Epoch 936/1000\n",
      "178/178 [==============================] - 0s 86us/step - loss: 0.0628 - accuracy: 0.9831 - val_loss: 2.2474 - val_accuracy: 0.6623\n",
      "Epoch 937/1000\n",
      "178/178 [==============================] - 0s 96us/step - loss: 0.0619 - accuracy: 0.9831 - val_loss: 2.2468 - val_accuracy: 0.6623\n",
      "Epoch 938/1000\n",
      "178/178 [==============================] - 0s 94us/step - loss: 0.0625 - accuracy: 0.9831 - val_loss: 2.2548 - val_accuracy: 0.6623\n",
      "Epoch 939/1000\n",
      "178/178 [==============================] - 0s 98us/step - loss: 0.0627 - accuracy: 0.9831 - val_loss: 2.2388 - val_accuracy: 0.6623\n",
      "Epoch 940/1000\n",
      "178/178 [==============================] - 0s 94us/step - loss: 0.0625 - accuracy: 0.9831 - val_loss: 2.2440 - val_accuracy: 0.6623\n",
      "Epoch 941/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 101us/step - loss: 0.0626 - accuracy: 0.9831 - val_loss: 2.2666 - val_accuracy: 0.6623\n",
      "Epoch 942/1000\n",
      "178/178 [==============================] - 0s 129us/step - loss: 0.0618 - accuracy: 0.9831 - val_loss: 2.2760 - val_accuracy: 0.6494\n",
      "Epoch 943/1000\n",
      "178/178 [==============================] - 0s 106us/step - loss: 0.0619 - accuracy: 0.9831 - val_loss: 2.2623 - val_accuracy: 0.6623\n",
      "Epoch 944/1000\n",
      "178/178 [==============================] - 0s 100us/step - loss: 0.0612 - accuracy: 0.9831 - val_loss: 2.2494 - val_accuracy: 0.6623\n",
      "Epoch 945/1000\n",
      "178/178 [==============================] - 0s 103us/step - loss: 0.0613 - accuracy: 0.9831 - val_loss: 2.2732 - val_accuracy: 0.6623\n",
      "Epoch 946/1000\n",
      "178/178 [==============================] - 0s 114us/step - loss: 0.0638 - accuracy: 0.9831 - val_loss: 2.2663 - val_accuracy: 0.6623\n",
      "Epoch 947/1000\n",
      "178/178 [==============================] - 0s 106us/step - loss: 0.0639 - accuracy: 0.9831 - val_loss: 2.2284 - val_accuracy: 0.6623\n",
      "Epoch 948/1000\n",
      "178/178 [==============================] - 0s 96us/step - loss: 0.0640 - accuracy: 0.9775 - val_loss: 2.2481 - val_accuracy: 0.6623\n",
      "Epoch 949/1000\n",
      "178/178 [==============================] - 0s 93us/step - loss: 0.0618 - accuracy: 0.9831 - val_loss: 2.2705 - val_accuracy: 0.6623\n",
      "Epoch 950/1000\n",
      "178/178 [==============================] - 0s 91us/step - loss: 0.0615 - accuracy: 0.9831 - val_loss: 2.2398 - val_accuracy: 0.6623\n",
      "Epoch 951/1000\n",
      "178/178 [==============================] - 0s 93us/step - loss: 0.0615 - accuracy: 0.9831 - val_loss: 2.2523 - val_accuracy: 0.6623\n",
      "Epoch 952/1000\n",
      "178/178 [==============================] - 0s 98us/step - loss: 0.0597 - accuracy: 0.9831 - val_loss: 2.2891 - val_accuracy: 0.6623\n",
      "Epoch 953/1000\n",
      "178/178 [==============================] - 0s 99us/step - loss: 0.0624 - accuracy: 0.9831 - val_loss: 2.2903 - val_accuracy: 0.6623\n",
      "Epoch 954/1000\n",
      "178/178 [==============================] - 0s 101us/step - loss: 0.0600 - accuracy: 0.9831 - val_loss: 2.2774 - val_accuracy: 0.6623\n",
      "Epoch 955/1000\n",
      "178/178 [==============================] - 0s 100us/step - loss: 0.0624 - accuracy: 0.9831 - val_loss: 2.2791 - val_accuracy: 0.6623\n",
      "Epoch 956/1000\n",
      "178/178 [==============================] - 0s 93us/step - loss: 0.0618 - accuracy: 0.9831 - val_loss: 2.2677 - val_accuracy: 0.6623\n",
      "Epoch 957/1000\n",
      "178/178 [==============================] - 0s 94us/step - loss: 0.0624 - accuracy: 0.9831 - val_loss: 2.2697 - val_accuracy: 0.6623\n",
      "Epoch 958/1000\n",
      "178/178 [==============================] - 0s 100us/step - loss: 0.0615 - accuracy: 0.9831 - val_loss: 2.2862 - val_accuracy: 0.6623\n",
      "Epoch 959/1000\n",
      "178/178 [==============================] - 0s 94us/step - loss: 0.0617 - accuracy: 0.9831 - val_loss: 2.2743 - val_accuracy: 0.6623\n",
      "Epoch 960/1000\n",
      "178/178 [==============================] - 0s 94us/step - loss: 0.0612 - accuracy: 0.9831 - val_loss: 2.2657 - val_accuracy: 0.6623\n",
      "Epoch 961/1000\n",
      "178/178 [==============================] - 0s 95us/step - loss: 0.0607 - accuracy: 0.9831 - val_loss: 2.2811 - val_accuracy: 0.6623\n",
      "Epoch 962/1000\n",
      "178/178 [==============================] - 0s 94us/step - loss: 0.0627 - accuracy: 0.9831 - val_loss: 2.2731 - val_accuracy: 0.6623\n",
      "Epoch 963/1000\n",
      "178/178 [==============================] - 0s 96us/step - loss: 0.0629 - accuracy: 0.9831 - val_loss: 2.2874 - val_accuracy: 0.6623\n",
      "Epoch 964/1000\n",
      "178/178 [==============================] - 0s 93us/step - loss: 0.0606 - accuracy: 0.9831 - val_loss: 2.2728 - val_accuracy: 0.6623\n",
      "Epoch 965/1000\n",
      "178/178 [==============================] - 0s 109us/step - loss: 0.0610 - accuracy: 0.9831 - val_loss: 2.2808 - val_accuracy: 0.6623\n",
      "Epoch 966/1000\n",
      "178/178 [==============================] - 0s 90us/step - loss: 0.0602 - accuracy: 0.9831 - val_loss: 2.2575 - val_accuracy: 0.6623\n",
      "Epoch 967/1000\n",
      "178/178 [==============================] - 0s 92us/step - loss: 0.0647 - accuracy: 0.9831 - val_loss: 2.3075 - val_accuracy: 0.6623\n",
      "Epoch 968/1000\n",
      "178/178 [==============================] - 0s 112us/step - loss: 0.0607 - accuracy: 0.9831 - val_loss: 2.2929 - val_accuracy: 0.6623\n",
      "Epoch 969/1000\n",
      "178/178 [==============================] - 0s 103us/step - loss: 0.0615 - accuracy: 0.9831 - val_loss: 2.2479 - val_accuracy: 0.6623\n",
      "Epoch 970/1000\n",
      "178/178 [==============================] - 0s 104us/step - loss: 0.0637 - accuracy: 0.9775 - val_loss: 2.3111 - val_accuracy: 0.6623\n",
      "Epoch 971/1000\n",
      "178/178 [==============================] - 0s 103us/step - loss: 0.0611 - accuracy: 0.9831 - val_loss: 2.2911 - val_accuracy: 0.6623\n",
      "Epoch 972/1000\n",
      "178/178 [==============================] - 0s 103us/step - loss: 0.0603 - accuracy: 0.9831 - val_loss: 2.2884 - val_accuracy: 0.6623\n",
      "Epoch 973/1000\n",
      "178/178 [==============================] - 0s 117us/step - loss: 0.0602 - accuracy: 0.9831 - val_loss: 2.2827 - val_accuracy: 0.6623\n",
      "Epoch 974/1000\n",
      "178/178 [==============================] - 0s 142us/step - loss: 0.0615 - accuracy: 0.9831 - val_loss: 2.2844 - val_accuracy: 0.6623\n",
      "Epoch 975/1000\n",
      "178/178 [==============================] - 0s 92us/step - loss: 0.0601 - accuracy: 0.9831 - val_loss: 2.2951 - val_accuracy: 0.6623\n",
      "Epoch 976/1000\n",
      "178/178 [==============================] - 0s 93us/step - loss: 0.0602 - accuracy: 0.9831 - val_loss: 2.3022 - val_accuracy: 0.6623\n",
      "Epoch 977/1000\n",
      "178/178 [==============================] - 0s 91us/step - loss: 0.0608 - accuracy: 0.9831 - val_loss: 2.2988 - val_accuracy: 0.6623\n",
      "Epoch 978/1000\n",
      "178/178 [==============================] - 0s 91us/step - loss: 0.0603 - accuracy: 0.9831 - val_loss: 2.3020 - val_accuracy: 0.6623\n",
      "Epoch 979/1000\n",
      "178/178 [==============================] - 0s 89us/step - loss: 0.0602 - accuracy: 0.9831 - val_loss: 2.3040 - val_accuracy: 0.6623\n",
      "Epoch 980/1000\n",
      "178/178 [==============================] - 0s 102us/step - loss: 0.0608 - accuracy: 0.9831 - val_loss: 2.3105 - val_accuracy: 0.6623\n",
      "Epoch 981/1000\n",
      "178/178 [==============================] - 0s 109us/step - loss: 0.0613 - accuracy: 0.9831 - val_loss: 2.3138 - val_accuracy: 0.6623\n",
      "Epoch 982/1000\n",
      "178/178 [==============================] - 0s 94us/step - loss: 0.0605 - accuracy: 0.9831 - val_loss: 2.3051 - val_accuracy: 0.6623\n",
      "Epoch 983/1000\n",
      "178/178 [==============================] - 0s 102us/step - loss: 0.0598 - accuracy: 0.9831 - val_loss: 2.3161 - val_accuracy: 0.6623\n",
      "Epoch 984/1000\n",
      "178/178 [==============================] - 0s 106us/step - loss: 0.0631 - accuracy: 0.9831 - val_loss: 2.3097 - val_accuracy: 0.6623\n",
      "Epoch 985/1000\n",
      "178/178 [==============================] - 0s 94us/step - loss: 0.0604 - accuracy: 0.9831 - val_loss: 2.2948 - val_accuracy: 0.6623\n",
      "Epoch 986/1000\n",
      "178/178 [==============================] - 0s 89us/step - loss: 0.0597 - accuracy: 0.9831 - val_loss: 2.3053 - val_accuracy: 0.6623\n",
      "Epoch 987/1000\n",
      "178/178 [==============================] - 0s 94us/step - loss: 0.0604 - accuracy: 0.9831 - val_loss: 2.2836 - val_accuracy: 0.6623\n",
      "Epoch 988/1000\n",
      "178/178 [==============================] - 0s 92us/step - loss: 0.0599 - accuracy: 0.9831 - val_loss: 2.2918 - val_accuracy: 0.6623\n",
      "Epoch 989/1000\n",
      "178/178 [==============================] - 0s 93us/step - loss: 0.0593 - accuracy: 0.9831 - val_loss: 2.3202 - val_accuracy: 0.6623\n",
      "Epoch 990/1000\n",
      "178/178 [==============================] - 0s 89us/step - loss: 0.0591 - accuracy: 0.9831 - val_loss: 2.3025 - val_accuracy: 0.6623\n",
      "Epoch 991/1000\n",
      "178/178 [==============================] - 0s 89us/step - loss: 0.0599 - accuracy: 0.9831 - val_loss: 2.3243 - val_accuracy: 0.6623\n",
      "Epoch 992/1000\n",
      "178/178 [==============================] - 0s 93us/step - loss: 0.0610 - accuracy: 0.9831 - val_loss: 2.3319 - val_accuracy: 0.6623\n",
      "Epoch 993/1000\n",
      "178/178 [==============================] - 0s 114us/step - loss: 0.0608 - accuracy: 0.9831 - val_loss: 2.3251 - val_accuracy: 0.6623\n",
      "Epoch 994/1000\n",
      "178/178 [==============================] - 0s 126us/step - loss: 0.0606 - accuracy: 0.9831 - val_loss: 2.3058 - val_accuracy: 0.6623\n",
      "Epoch 995/1000\n",
      "178/178 [==============================] - 0s 106us/step - loss: 0.0594 - accuracy: 0.9831 - val_loss: 2.3082 - val_accuracy: 0.6623\n",
      "Epoch 996/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 101us/step - loss: 0.0616 - accuracy: 0.9831 - val_loss: 2.2907 - val_accuracy: 0.6623\n",
      "Epoch 997/1000\n",
      "178/178 [==============================] - 0s 115us/step - loss: 0.0604 - accuracy: 0.9831 - val_loss: 2.3093 - val_accuracy: 0.6623\n",
      "Epoch 998/1000\n",
      "178/178 [==============================] - 0s 101us/step - loss: 0.0611 - accuracy: 0.9831 - val_loss: 2.3179 - val_accuracy: 0.6623\n",
      "Epoch 999/1000\n",
      "178/178 [==============================] - 0s 96us/step - loss: 0.0599 - accuracy: 0.9831 - val_loss: 2.3375 - val_accuracy: 0.6623\n",
      "Epoch 1000/1000\n",
      "178/178 [==============================] - 0s 90us/step - loss: 0.0636 - accuracy: 0.9831 - val_loss: 2.3239 - val_accuracy: 0.6623\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0xb3c491ac8>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sel2.fit(X_sel_train, y_sel_train,\n",
    "          batch_size=32, epochs=1000,\n",
    "          validation_data=(X_sel_test, y_sel_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 0s 110us/step\n",
      "test accuracy: 66.23%\n"
     ]
    }
   ],
   "source": [
    "acc_test_sel2 = model_sel2.evaluate(X_sel_test, y_sel_test)[1]\n",
    "print('test accuracy: %.2f%%' % (acc_test_sel2*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ Logistic Regression ############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=123, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###### logistics\n",
    "log = LogisticRegression(random_state=123)\n",
    "log.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combination logistic test accuracy 62.34%\n"
     ]
    }
   ],
   "source": [
    "y_pred = log.predict(X_test)\n",
    "print('combination logistic test accuracy %.2f%%' % (log.score(X_test, y_test)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## Random Forest ##############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=123,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=123)\n",
    "rf.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combination test accuracy: 62.34%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = rf.predict(X_test)\n",
    "print('combination test accuracy: %.2f%%' % (accuracy_score(y_test, y_pred)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Random forest with cross-validation\n",
    "## Retrieved from https://stackabuse.com/cross-validation-and-grid-search-for-model-selection-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.80555556 0.80555556 0.63888889 0.77777778 0.73529412]\n",
      "0.7526143790849673\n"
     ]
    }
   ],
   "source": [
    "## random forest model with CV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# rfcv = RandomForestClassifier(n_estimators=100, random_state=123)\n",
    "\n",
    "accs = cross_val_score(estimator=rf, X=X_train, y=y_train, cv=5)\n",
    "print(accs)\n",
    "print(accs.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
