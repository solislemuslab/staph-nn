{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This file implements neural networks and logistic regression on p003ppresabs_quant.\n",
    "## Due to the imbalanced dataset, we implement the over-sampling method and the combination of over- and under-sampling\n",
    "## method.\n",
    "## To deal with overfitting problem, we include both dropout and regularizer when set up layers in neural networks.\n",
    "## For fully-connected neural networks, the accuracy is 97.01% for combination data, and 97.92% for over-sampling data.\n",
    "## For logistic regression, the accuracy is 100% for combination data, and 97.92% for over-sampling data.\n",
    "## Since the accuracy scores are pretty high in logistic regression, we further construct random forest models, which \n",
    "## are relatively less likely to bring overfitting compared to decision tree.\n",
    "## For random forest, the accuracy is 99.25% for combination data, and 100% for over-sampling data.\n",
    "## For random forest with cross-validation, the mean accuracy is 98.41% for combination data, and 97.63% for over-sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(100)\n",
    "import tensorflow\n",
    "tensorflow.random.set_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(255, 866)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/Users/Rebecca/Desktop/Claudia/neural network/phage_quant/p003ppresabs_quant.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'Unnamed: 0':'id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.169500\n",
       "1      0.316500\n",
       "2      0.460000\n",
       "3      0.169000\n",
       "4      0.171333\n",
       "5      0.236333\n",
       "6      0.166500\n",
       "7      0.173333\n",
       "8      0.315833\n",
       "9      0.162167\n",
       "10     0.186167\n",
       "11     0.382833\n",
       "12     0.170667\n",
       "13     0.173333\n",
       "14     0.162833\n",
       "15     0.164333\n",
       "16     0.382667\n",
       "17     0.397000\n",
       "18     0.372667\n",
       "19     0.166333\n",
       "20     0.242333\n",
       "21     0.305833\n",
       "22     0.162333\n",
       "23     0.165500\n",
       "24     0.616833\n",
       "25     0.170167\n",
       "26     0.491500\n",
       "27     0.167833\n",
       "28     0.166500\n",
       "29     0.374833\n",
       "         ...   \n",
       "225    0.267200\n",
       "226    0.293800\n",
       "227    0.383400\n",
       "228    0.513500\n",
       "229    0.507700\n",
       "230    0.311500\n",
       "231    0.236000\n",
       "232    0.228833\n",
       "233    0.219333\n",
       "234    0.167333\n",
       "235    0.265167\n",
       "236    0.160500\n",
       "237    0.159333\n",
       "238    0.165500\n",
       "239    0.327833\n",
       "240    0.342000\n",
       "241    0.308500\n",
       "242    0.170333\n",
       "243    0.165333\n",
       "244    0.340833\n",
       "245    0.162000\n",
       "246    0.170500\n",
       "247    0.164500\n",
       "248    0.164000\n",
       "249    0.180000\n",
       "250    0.348000\n",
       "251    0.232500\n",
       "252    0.166167\n",
       "253    0.276667\n",
       "254    0.225333\n",
       "Name: pheno, Length: 255, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pheno']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0.5 in df['pheno']:\n",
    "    print: \"0.5 is in the list\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pheno'] = [1 if i>0.5 else 0 for i in df['pheno']] # convert pheno into binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    240\n",
       "1     15\n",
       "Name: pheno, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pheno']\n",
    "df['pheno'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(255, 866)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.drop(columns=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(255, 865)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(255, 864) (255,)\n"
     ]
    }
   ],
   "source": [
    "X = df_clean.loc[:, df_clean.columns != 'pheno'].values\n",
    "y = df_clean['pheno'].values\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 209), (1, 235)]\n"
     ]
    }
   ],
   "source": [
    "# combination of under- and over- sampling\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.combine import SMOTEENN\n",
    "smote_enn = SMOTEENN(random_state=100)\n",
    "X_comb, y_comb = smote_enn.fit_resample(X, y)\n",
    "print(sorted(Counter(y_comb).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 240), (1, 240)]\n"
     ]
    }
   ],
   "source": [
    "# over-sampling\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "overS = RandomOverSampler(random_state=100)\n",
    "X_over, y_over = overS.fit_resample(X, y)\n",
    "print(sorted(Counter(y_over).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, validation, and test data (combination)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_comb, X_test_comb, y_train_comb, y_test_comb = train_test_split(X_comb, y_comb,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=123,\n",
    "                                                    stratify=y_comb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=123,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# Fully-Connected Neural Network ################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.regularizers import l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### neural network on combination data\n",
    "model1_comb = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_comb.shape[1],), activity_regularizer=l1(0.001)),\n",
    "    Dense(1, activation='sigmoid'),\n",
    "    Dropout(0.2, ),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_comb.compile(optimizer='sgd',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 310 samples, validate on 134 samples\n",
      "Epoch 1/100\n",
      "310/310 [==============================] - 0s 986us/step - loss: 2.5191 - accuracy: 0.6387 - val_loss: 0.6907 - val_accuracy: 0.7687\n",
      "Epoch 2/100\n",
      "310/310 [==============================] - 0s 154us/step - loss: 2.4748 - accuracy: 0.7774 - val_loss: 0.5912 - val_accuracy: 0.8209\n",
      "Epoch 3/100\n",
      "310/310 [==============================] - 0s 143us/step - loss: 2.0341 - accuracy: 0.7903 - val_loss: 0.5504 - val_accuracy: 0.8955\n",
      "Epoch 4/100\n",
      "310/310 [==============================] - 0s 141us/step - loss: 2.2436 - accuracy: 0.7871 - val_loss: 0.5483 - val_accuracy: 0.8806\n",
      "Epoch 5/100\n",
      "310/310 [==============================] - 0s 139us/step - loss: 1.7846 - accuracy: 0.8226 - val_loss: 0.5158 - val_accuracy: 0.8881\n",
      "Epoch 6/100\n",
      "310/310 [==============================] - 0s 168us/step - loss: 2.2526 - accuracy: 0.8000 - val_loss: 0.4986 - val_accuracy: 0.9030\n",
      "Epoch 7/100\n",
      "310/310 [==============================] - 0s 171us/step - loss: 2.1586 - accuracy: 0.7935 - val_loss: 0.5019 - val_accuracy: 0.9179\n",
      "Epoch 8/100\n",
      "310/310 [==============================] - 0s 171us/step - loss: 1.7958 - accuracy: 0.8258 - val_loss: 0.4866 - val_accuracy: 0.9254\n",
      "Epoch 9/100\n",
      "310/310 [==============================] - 0s 157us/step - loss: 1.9741 - accuracy: 0.8419 - val_loss: 0.4732 - val_accuracy: 0.9328\n",
      "Epoch 10/100\n",
      "310/310 [==============================] - 0s 159us/step - loss: 2.0609 - accuracy: 0.8387 - val_loss: 0.4524 - val_accuracy: 0.9254\n",
      "Epoch 11/100\n",
      "310/310 [==============================] - 0s 287us/step - loss: 2.0351 - accuracy: 0.8355 - val_loss: 0.4418 - val_accuracy: 0.9328\n",
      "Epoch 12/100\n",
      "310/310 [==============================] - 0s 193us/step - loss: 2.6887 - accuracy: 0.8097 - val_loss: 0.4417 - val_accuracy: 0.9478\n",
      "Epoch 13/100\n",
      "310/310 [==============================] - 0s 176us/step - loss: 1.8423 - accuracy: 0.8774 - val_loss: 0.4269 - val_accuracy: 0.9328\n",
      "Epoch 14/100\n",
      "310/310 [==============================] - 0s 151us/step - loss: 1.9396 - accuracy: 0.8613 - val_loss: 0.4188 - val_accuracy: 0.9478\n",
      "Epoch 15/100\n",
      "310/310 [==============================] - 0s 173us/step - loss: 2.1805 - accuracy: 0.8548 - val_loss: 0.4150 - val_accuracy: 0.9478\n",
      "Epoch 16/100\n",
      "310/310 [==============================] - 0s 171us/step - loss: 1.8713 - accuracy: 0.8645 - val_loss: 0.4091 - val_accuracy: 0.9552\n",
      "Epoch 17/100\n",
      "310/310 [==============================] - 0s 166us/step - loss: 1.9164 - accuracy: 0.8677 - val_loss: 0.4024 - val_accuracy: 0.9552\n",
      "Epoch 18/100\n",
      "310/310 [==============================] - 0s 186us/step - loss: 1.8464 - accuracy: 0.8774 - val_loss: 0.3933 - val_accuracy: 0.9552\n",
      "Epoch 19/100\n",
      "310/310 [==============================] - 0s 188us/step - loss: 1.5488 - accuracy: 0.8968 - val_loss: 0.3914 - val_accuracy: 0.9552\n",
      "Epoch 20/100\n",
      "310/310 [==============================] - 0s 183us/step - loss: 2.0455 - accuracy: 0.8677 - val_loss: 0.3869 - val_accuracy: 0.9627\n",
      "Epoch 21/100\n",
      "310/310 [==============================] - 0s 163us/step - loss: 1.9439 - accuracy: 0.8774 - val_loss: 0.3798 - val_accuracy: 0.9552\n",
      "Epoch 22/100\n",
      "310/310 [==============================] - 0s 168us/step - loss: 1.8391 - accuracy: 0.8839 - val_loss: 0.3775 - val_accuracy: 0.9627\n",
      "Epoch 23/100\n",
      "310/310 [==============================] - 0s 193us/step - loss: 1.6782 - accuracy: 0.9000 - val_loss: 0.3740 - val_accuracy: 0.9701\n",
      "Epoch 24/100\n",
      "310/310 [==============================] - 0s 319us/step - loss: 1.6717 - accuracy: 0.9032 - val_loss: 0.3688 - val_accuracy: 0.9627\n",
      "Epoch 25/100\n",
      "310/310 [==============================] - 0s 336us/step - loss: 1.6774 - accuracy: 0.9065 - val_loss: 0.3628 - val_accuracy: 0.9627\n",
      "Epoch 26/100\n",
      "310/310 [==============================] - 0s 178us/step - loss: 1.6737 - accuracy: 0.9000 - val_loss: 0.3595 - val_accuracy: 0.9627\n",
      "Epoch 27/100\n",
      "310/310 [==============================] - 0s 163us/step - loss: 2.3189 - accuracy: 0.8581 - val_loss: 0.3606 - val_accuracy: 0.9701\n",
      "Epoch 28/100\n",
      "310/310 [==============================] - 0s 179us/step - loss: 1.8636 - accuracy: 0.8871 - val_loss: 0.3602 - val_accuracy: 0.9701\n",
      "Epoch 29/100\n",
      "310/310 [==============================] - 0s 162us/step - loss: 1.7134 - accuracy: 0.9000 - val_loss: 0.3505 - val_accuracy: 0.9627\n",
      "Epoch 30/100\n",
      "310/310 [==============================] - 0s 185us/step - loss: 2.0541 - accuracy: 0.8806 - val_loss: 0.3489 - val_accuracy: 0.9627\n",
      "Epoch 31/100\n",
      "310/310 [==============================] - 0s 178us/step - loss: 1.8582 - accuracy: 0.8871 - val_loss: 0.3453 - val_accuracy: 0.9776\n",
      "Epoch 32/100\n",
      "310/310 [==============================] - 0s 121us/step - loss: 1.6971 - accuracy: 0.9000 - val_loss: 0.3485 - val_accuracy: 0.9701\n",
      "Epoch 33/100\n",
      "310/310 [==============================] - 0s 113us/step - loss: 1.6496 - accuracy: 0.9065 - val_loss: 0.3413 - val_accuracy: 0.9776\n",
      "Epoch 34/100\n",
      "310/310 [==============================] - 0s 111us/step - loss: 1.9948 - accuracy: 0.8806 - val_loss: 0.3378 - val_accuracy: 0.9627\n",
      "Epoch 35/100\n",
      "310/310 [==============================] - 0s 164us/step - loss: 1.9014 - accuracy: 0.8839 - val_loss: 0.3366 - val_accuracy: 0.9776\n",
      "Epoch 36/100\n",
      "310/310 [==============================] - 0s 179us/step - loss: 1.8422 - accuracy: 0.8871 - val_loss: 0.3351 - val_accuracy: 0.9776\n",
      "Epoch 37/100\n",
      "310/310 [==============================] - 0s 153us/step - loss: 1.8368 - accuracy: 0.8903 - val_loss: 0.3310 - val_accuracy: 0.9776\n",
      "Epoch 38/100\n",
      "310/310 [==============================] - 0s 166us/step - loss: 2.1391 - accuracy: 0.8742 - val_loss: 0.3310 - val_accuracy: 0.9776\n",
      "Epoch 39/100\n",
      "310/310 [==============================] - 0s 173us/step - loss: 2.1840 - accuracy: 0.8677 - val_loss: 0.3334 - val_accuracy: 0.9776\n",
      "Epoch 40/100\n",
      "310/310 [==============================] - 0s 340us/step - loss: 2.0805 - accuracy: 0.8774 - val_loss: 0.3256 - val_accuracy: 0.9776\n",
      "Epoch 41/100\n",
      "310/310 [==============================] - 0s 163us/step - loss: 1.8822 - accuracy: 0.8903 - val_loss: 0.3254 - val_accuracy: 0.9776\n",
      "Epoch 42/100\n",
      "310/310 [==============================] - 0s 149us/step - loss: 1.8273 - accuracy: 0.8903 - val_loss: 0.3240 - val_accuracy: 0.9776\n",
      "Epoch 43/100\n",
      "310/310 [==============================] - 0s 139us/step - loss: 1.6271 - accuracy: 0.9065 - val_loss: 0.3225 - val_accuracy: 0.9776\n",
      "Epoch 44/100\n",
      "310/310 [==============================] - 0s 161us/step - loss: 1.5808 - accuracy: 0.9097 - val_loss: 0.3224 - val_accuracy: 0.9776\n",
      "Epoch 45/100\n",
      "310/310 [==============================] - 0s 161us/step - loss: 1.9291 - accuracy: 0.8839 - val_loss: 0.3281 - val_accuracy: 0.9701\n",
      "Epoch 46/100\n",
      "310/310 [==============================] - 0s 149us/step - loss: 2.1779 - accuracy: 0.8677 - val_loss: 0.3223 - val_accuracy: 0.9776\n",
      "Epoch 47/100\n",
      "310/310 [==============================] - 0s 135us/step - loss: 2.0217 - accuracy: 0.8774 - val_loss: 0.3153 - val_accuracy: 0.9776\n",
      "Epoch 48/100\n",
      "310/310 [==============================] - 0s 178us/step - loss: 1.8732 - accuracy: 0.8903 - val_loss: 0.3193 - val_accuracy: 0.9776\n",
      "Epoch 49/100\n",
      "310/310 [==============================] - 0s 130us/step - loss: 1.8204 - accuracy: 0.8903 - val_loss: 0.3119 - val_accuracy: 0.9776\n",
      "Epoch 50/100\n",
      "310/310 [==============================] - 0s 134us/step - loss: 1.8740 - accuracy: 0.8871 - val_loss: 0.3099 - val_accuracy: 0.9776\n",
      "Epoch 51/100\n",
      "310/310 [==============================] - 0s 114us/step - loss: 1.6668 - accuracy: 0.9000 - val_loss: 0.3113 - val_accuracy: 0.9776\n",
      "Epoch 52/100\n",
      "310/310 [==============================] - 0s 125us/step - loss: 1.8166 - accuracy: 0.8903 - val_loss: 0.3123 - val_accuracy: 0.9776\n",
      "Epoch 53/100\n",
      "310/310 [==============================] - 0s 130us/step - loss: 1.9140 - accuracy: 0.8839 - val_loss: 0.3085 - val_accuracy: 0.9776\n",
      "Epoch 54/100\n",
      "310/310 [==============================] - 0s 113us/step - loss: 1.7623 - accuracy: 0.8968 - val_loss: 0.3072 - val_accuracy: 0.9776\n",
      "Epoch 55/100\n",
      "310/310 [==============================] - 0s 110us/step - loss: 1.7094 - accuracy: 0.9000 - val_loss: 0.3036 - val_accuracy: 0.9776\n",
      "Epoch 56/100\n",
      "310/310 [==============================] - 0s 132us/step - loss: 1.7140 - accuracy: 0.8968 - val_loss: 0.2997 - val_accuracy: 0.9776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "310/310 [==============================] - 0s 137us/step - loss: 1.5642 - accuracy: 0.9065 - val_loss: 0.3026 - val_accuracy: 0.9776\n",
      "Epoch 58/100\n",
      "310/310 [==============================] - 0s 110us/step - loss: 2.5020 - accuracy: 0.8484 - val_loss: 0.3070 - val_accuracy: 0.9701\n",
      "Epoch 59/100\n",
      "310/310 [==============================] - 0s 108us/step - loss: 1.6561 - accuracy: 0.9000 - val_loss: 0.2994 - val_accuracy: 0.9776\n",
      "Epoch 60/100\n",
      "310/310 [==============================] - 0s 82us/step - loss: 1.8046 - accuracy: 0.8903 - val_loss: 0.2993 - val_accuracy: 0.9776\n",
      "Epoch 61/100\n",
      "310/310 [==============================] - 0s 104us/step - loss: 1.3584 - accuracy: 0.9226 - val_loss: 0.2996 - val_accuracy: 0.9776\n",
      "Epoch 62/100\n",
      "310/310 [==============================] - 0s 99us/step - loss: 1.6017 - accuracy: 0.9065 - val_loss: 0.2958 - val_accuracy: 0.9776\n",
      "Epoch 63/100\n",
      "310/310 [==============================] - 0s 108us/step - loss: 1.7536 - accuracy: 0.8968 - val_loss: 0.2990 - val_accuracy: 0.9701\n",
      "Epoch 64/100\n",
      "310/310 [==============================] - 0s 110us/step - loss: 1.9980 - accuracy: 0.8806 - val_loss: 0.2953 - val_accuracy: 0.9776\n",
      "Epoch 65/100\n",
      "310/310 [==============================] - 0s 100us/step - loss: 1.4551 - accuracy: 0.9161 - val_loss: 0.2913 - val_accuracy: 0.9776\n",
      "Epoch 66/100\n",
      "310/310 [==============================] - 0s 107us/step - loss: 1.7021 - accuracy: 0.9000 - val_loss: 0.2904 - val_accuracy: 0.9776\n",
      "Epoch 67/100\n",
      "310/310 [==============================] - 0s 105us/step - loss: 1.7938 - accuracy: 0.8935 - val_loss: 0.2903 - val_accuracy: 0.9776\n",
      "Epoch 68/100\n",
      "310/310 [==============================] - 0s 134us/step - loss: 1.8445 - accuracy: 0.8903 - val_loss: 0.2927 - val_accuracy: 0.9701\n",
      "Epoch 69/100\n",
      "310/310 [==============================] - 0s 119us/step - loss: 1.7449 - accuracy: 0.8968 - val_loss: 0.2913 - val_accuracy: 0.9776\n",
      "Epoch 70/100\n",
      "310/310 [==============================] - 0s 161us/step - loss: 1.4937 - accuracy: 0.9129 - val_loss: 0.2888 - val_accuracy: 0.9776\n",
      "Epoch 71/100\n",
      "310/310 [==============================] - 0s 136us/step - loss: 1.5955 - accuracy: 0.9065 - val_loss: 0.2845 - val_accuracy: 0.9776\n",
      "Epoch 72/100\n",
      "310/310 [==============================] - 0s 135us/step - loss: 1.5464 - accuracy: 0.9097 - val_loss: 0.2893 - val_accuracy: 0.9701\n",
      "Epoch 73/100\n",
      "310/310 [==============================] - 0s 149us/step - loss: 1.2945 - accuracy: 0.9258 - val_loss: 0.2829 - val_accuracy: 0.9776\n",
      "Epoch 74/100\n",
      "310/310 [==============================] - 0s 124us/step - loss: 1.9420 - accuracy: 0.8839 - val_loss: 0.2816 - val_accuracy: 0.9776\n",
      "Epoch 75/100\n",
      "310/310 [==============================] - 0s 119us/step - loss: 2.1409 - accuracy: 0.8710 - val_loss: 0.2792 - val_accuracy: 0.9776\n",
      "Epoch 76/100\n",
      "310/310 [==============================] - 0s 135us/step - loss: 1.6406 - accuracy: 0.9032 - val_loss: 0.2816 - val_accuracy: 0.9776\n",
      "Epoch 77/100\n",
      "310/310 [==============================] - 0s 111us/step - loss: 1.8894 - accuracy: 0.8871 - val_loss: 0.2776 - val_accuracy: 0.9776\n",
      "Epoch 78/100\n",
      "310/310 [==============================] - 0s 176us/step - loss: 1.6893 - accuracy: 0.9000 - val_loss: 0.2831 - val_accuracy: 0.9701\n",
      "Epoch 79/100\n",
      "310/310 [==============================] - 0s 162us/step - loss: 1.7363 - accuracy: 0.8968 - val_loss: 0.2772 - val_accuracy: 0.9776\n",
      "Epoch 80/100\n",
      "310/310 [==============================] - 0s 191us/step - loss: 2.0334 - accuracy: 0.8774 - val_loss: 0.2736 - val_accuracy: 0.9776\n",
      "Epoch 81/100\n",
      "310/310 [==============================] - 0s 127us/step - loss: 1.9815 - accuracy: 0.8806 - val_loss: 0.2783 - val_accuracy: 0.9701\n",
      "Epoch 82/100\n",
      "310/310 [==============================] - 0s 123us/step - loss: 1.4797 - accuracy: 0.9129 - val_loss: 0.2762 - val_accuracy: 0.9776\n",
      "Epoch 83/100\n",
      "310/310 [==============================] - 0s 184us/step - loss: 1.8862 - accuracy: 0.8871 - val_loss: 0.2747 - val_accuracy: 0.9776\n",
      "Epoch 84/100\n",
      "310/310 [==============================] - 0s 139us/step - loss: 1.8328 - accuracy: 0.8903 - val_loss: 0.2698 - val_accuracy: 0.9776\n",
      "Epoch 85/100\n",
      "310/310 [==============================] - 0s 149us/step - loss: 1.8318 - accuracy: 0.8903 - val_loss: 0.2714 - val_accuracy: 0.9776\n",
      "Epoch 86/100\n",
      "310/310 [==============================] - 0s 158us/step - loss: 1.6317 - accuracy: 0.9032 - val_loss: 0.2701 - val_accuracy: 0.9776\n",
      "Epoch 87/100\n",
      "310/310 [==============================] - 0s 142us/step - loss: 1.6762 - accuracy: 0.9000 - val_loss: 0.2694 - val_accuracy: 0.9776\n",
      "Epoch 88/100\n",
      "310/310 [==============================] - 0s 129us/step - loss: 1.4310 - accuracy: 0.9161 - val_loss: 0.2720 - val_accuracy: 0.9701\n",
      "Epoch 89/100\n",
      "310/310 [==============================] - 0s 118us/step - loss: 1.7778 - accuracy: 0.8935 - val_loss: 0.2682 - val_accuracy: 0.9776\n",
      "Epoch 90/100\n",
      "310/310 [==============================] - 0s 133us/step - loss: 2.1771 - accuracy: 0.8677 - val_loss: 0.2682 - val_accuracy: 0.9776\n",
      "Epoch 91/100\n",
      "310/310 [==============================] - 0s 126us/step - loss: 1.9249 - accuracy: 0.8839 - val_loss: 0.2661 - val_accuracy: 0.9776\n",
      "Epoch 92/100\n",
      "310/310 [==============================] - 0s 102us/step - loss: 1.8244 - accuracy: 0.8903 - val_loss: 0.2668 - val_accuracy: 0.9776\n",
      "Epoch 93/100\n",
      "310/310 [==============================] - 0s 100us/step - loss: 1.9267 - accuracy: 0.8839 - val_loss: 0.2667 - val_accuracy: 0.9776\n",
      "Epoch 94/100\n",
      "310/310 [==============================] - 0s 101us/step - loss: 1.4255 - accuracy: 0.9161 - val_loss: 0.2620 - val_accuracy: 0.9776\n",
      "Epoch 95/100\n",
      "310/310 [==============================] - 0s 136us/step - loss: 1.5268 - accuracy: 0.9097 - val_loss: 0.2650 - val_accuracy: 0.9776\n",
      "Epoch 96/100\n",
      "310/310 [==============================] - 0s 113us/step - loss: 1.3736 - accuracy: 0.9194 - val_loss: 0.2602 - val_accuracy: 0.9776\n",
      "Epoch 97/100\n",
      "310/310 [==============================] - 0s 115us/step - loss: 1.7737 - accuracy: 0.8935 - val_loss: 0.2583 - val_accuracy: 0.9851\n",
      "Epoch 98/100\n",
      "310/310 [==============================] - 0s 133us/step - loss: 1.8705 - accuracy: 0.8871 - val_loss: 0.2640 - val_accuracy: 0.9701\n",
      "Epoch 99/100\n",
      "310/310 [==============================] - 0s 154us/step - loss: 1.7243 - accuracy: 0.8968 - val_loss: 0.2607 - val_accuracy: 0.9776\n",
      "Epoch 100/100\n",
      "310/310 [==============================] - 0s 102us/step - loss: 1.6746 - accuracy: 0.9000 - val_loss: 0.2606 - val_accuracy: 0.9701\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a3ff1dfd0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_comb.fit(X_train_comb, y_train_comb,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_comb, y_test_comb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 0s 68us/step\n",
      "combination test accuracy: 97.01%\n"
     ]
    }
   ],
   "source": [
    "acc_test_comb = model1_comb.evaluate(X_test_comb, y_test_comb)[1]\n",
    "print('combination test accuracy: %.2f%%' % (acc_test_comb*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### neural network on over-sampling data\n",
    "model1_over = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],), activity_regularizer=l1(0.001)),\n",
    "    Dense(1, activation='sigmoid'),\n",
    "    Dropout(0.2, ),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over.compile(optimizer='sgd',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 336 samples, validate on 144 samples\n",
      "Epoch 1/100\n",
      "336/336 [==============================] - 0s 705us/step - loss: 2.7142 - accuracy: 0.6339 - val_loss: 0.7194 - val_accuracy: 0.7222\n",
      "Epoch 2/100\n",
      "336/336 [==============================] - 0s 96us/step - loss: 2.1648 - accuracy: 0.7292 - val_loss: 0.6373 - val_accuracy: 0.7847\n",
      "Epoch 3/100\n",
      "336/336 [==============================] - 0s 99us/step - loss: 2.1670 - accuracy: 0.7560 - val_loss: 0.6098 - val_accuracy: 0.7847\n",
      "Epoch 4/100\n",
      "336/336 [==============================] - 0s 99us/step - loss: 1.9750 - accuracy: 0.7500 - val_loss: 0.5725 - val_accuracy: 0.8264\n",
      "Epoch 5/100\n",
      "336/336 [==============================] - 0s 99us/step - loss: 2.5743 - accuracy: 0.7440 - val_loss: 0.5553 - val_accuracy: 0.8958\n",
      "Epoch 6/100\n",
      "336/336 [==============================] - 0s 98us/step - loss: 1.7486 - accuracy: 0.8185 - val_loss: 0.5423 - val_accuracy: 0.8958\n",
      "Epoch 7/100\n",
      "336/336 [==============================] - 0s 107us/step - loss: 1.9235 - accuracy: 0.7917 - val_loss: 0.5325 - val_accuracy: 0.9028\n",
      "Epoch 8/100\n",
      "336/336 [==============================] - 0s 102us/step - loss: 2.0105 - accuracy: 0.8006 - val_loss: 0.5256 - val_accuracy: 0.9097\n",
      "Epoch 9/100\n",
      "336/336 [==============================] - 0s 102us/step - loss: 1.5014 - accuracy: 0.8363 - val_loss: 0.5087 - val_accuracy: 0.9097\n",
      "Epoch 10/100\n",
      "336/336 [==============================] - 0s 100us/step - loss: 1.7054 - accuracy: 0.8333 - val_loss: 0.4980 - val_accuracy: 0.9097\n",
      "Epoch 11/100\n",
      "336/336 [==============================] - 0s 116us/step - loss: 2.2581 - accuracy: 0.7887 - val_loss: 0.4943 - val_accuracy: 0.9097\n",
      "Epoch 12/100\n",
      "336/336 [==============================] - 0s 129us/step - loss: 2.1125 - accuracy: 0.8065 - val_loss: 0.4827 - val_accuracy: 0.9097\n",
      "Epoch 13/100\n",
      "336/336 [==============================] - 0s 111us/step - loss: 1.7908 - accuracy: 0.8304 - val_loss: 0.5080 - val_accuracy: 0.8681\n",
      "Epoch 14/100\n",
      "336/336 [==============================] - 0s 100us/step - loss: 1.7690 - accuracy: 0.8512 - val_loss: 0.4670 - val_accuracy: 0.9167\n",
      "Epoch 15/100\n",
      "336/336 [==============================] - 0s 130us/step - loss: 1.9102 - accuracy: 0.8452 - val_loss: 0.4632 - val_accuracy: 0.9306\n",
      "Epoch 16/100\n",
      "336/336 [==============================] - 0s 102us/step - loss: 1.8179 - accuracy: 0.8452 - val_loss: 0.4621 - val_accuracy: 0.9306\n",
      "Epoch 17/100\n",
      "336/336 [==============================] - 0s 103us/step - loss: 1.8034 - accuracy: 0.8452 - val_loss: 0.4686 - val_accuracy: 0.9097\n",
      "Epoch 18/100\n",
      "336/336 [==============================] - 0s 107us/step - loss: 1.4282 - accuracy: 0.8780 - val_loss: 0.4434 - val_accuracy: 0.9236\n",
      "Epoch 19/100\n",
      "336/336 [==============================] - 0s 98us/step - loss: 1.8055 - accuracy: 0.8452 - val_loss: 0.4490 - val_accuracy: 0.9306\n",
      "Epoch 20/100\n",
      "336/336 [==============================] - 0s 101us/step - loss: 1.8671 - accuracy: 0.8661 - val_loss: 0.4328 - val_accuracy: 0.9306\n",
      "Epoch 21/100\n",
      "336/336 [==============================] - 0s 89us/step - loss: 1.8653 - accuracy: 0.8542 - val_loss: 0.4284 - val_accuracy: 0.9306\n",
      "Epoch 22/100\n",
      "336/336 [==============================] - 0s 98us/step - loss: 1.7788 - accuracy: 0.8631 - val_loss: 0.4221 - val_accuracy: 0.9583\n",
      "Epoch 23/100\n",
      "336/336 [==============================] - 0s 93us/step - loss: 2.0866 - accuracy: 0.8452 - val_loss: 0.4180 - val_accuracy: 0.9792\n",
      "Epoch 24/100\n",
      "336/336 [==============================] - 0s 95us/step - loss: 2.4016 - accuracy: 0.8274 - val_loss: 0.4121 - val_accuracy: 0.9653\n",
      "Epoch 25/100\n",
      "336/336 [==============================] - 0s 99us/step - loss: 2.0397 - accuracy: 0.8393 - val_loss: 0.4693 - val_accuracy: 0.8750\n",
      "Epoch 26/100\n",
      "336/336 [==============================] - 0s 101us/step - loss: 1.6378 - accuracy: 0.8690 - val_loss: 0.4064 - val_accuracy: 0.9792\n",
      "Epoch 27/100\n",
      "336/336 [==============================] - 0s 97us/step - loss: 1.6592 - accuracy: 0.8780 - val_loss: 0.4067 - val_accuracy: 0.9514\n",
      "Epoch 28/100\n",
      "336/336 [==============================] - 0s 97us/step - loss: 1.7090 - accuracy: 0.8720 - val_loss: 0.3923 - val_accuracy: 0.9653\n",
      "Epoch 29/100\n",
      "336/336 [==============================] - 0s 90us/step - loss: 1.7852 - accuracy: 0.8690 - val_loss: 0.3922 - val_accuracy: 0.9792\n",
      "Epoch 30/100\n",
      "336/336 [==============================] - 0s 97us/step - loss: 1.5592 - accuracy: 0.8869 - val_loss: 0.3906 - val_accuracy: 0.9653\n",
      "Epoch 31/100\n",
      "336/336 [==============================] - 0s 86us/step - loss: 2.1769 - accuracy: 0.8512 - val_loss: 0.3977 - val_accuracy: 0.9861\n",
      "Epoch 32/100\n",
      "336/336 [==============================] - 0s 86us/step - loss: 1.8132 - accuracy: 0.8720 - val_loss: 0.3787 - val_accuracy: 0.9792\n",
      "Epoch 33/100\n",
      "336/336 [==============================] - 0s 104us/step - loss: 1.4521 - accuracy: 0.8929 - val_loss: 0.3716 - val_accuracy: 0.9653\n",
      "Epoch 34/100\n",
      "336/336 [==============================] - 0s 110us/step - loss: 2.3101 - accuracy: 0.8482 - val_loss: 0.3674 - val_accuracy: 0.9722\n",
      "Epoch 35/100\n",
      "336/336 [==============================] - 0s 161us/step - loss: 1.4575 - accuracy: 0.8839 - val_loss: 0.3730 - val_accuracy: 0.9792\n",
      "Epoch 36/100\n",
      "336/336 [==============================] - 0s 131us/step - loss: 1.3566 - accuracy: 0.8988 - val_loss: 0.3632 - val_accuracy: 0.9722\n",
      "Epoch 37/100\n",
      "336/336 [==============================] - 0s 108us/step - loss: 1.4061 - accuracy: 0.8929 - val_loss: 0.3613 - val_accuracy: 0.9792\n",
      "Epoch 38/100\n",
      "336/336 [==============================] - 0s 113us/step - loss: 1.3860 - accuracy: 0.9048 - val_loss: 0.3547 - val_accuracy: 0.9722\n",
      "Epoch 39/100\n",
      "336/336 [==============================] - 0s 116us/step - loss: 1.4815 - accuracy: 0.8899 - val_loss: 0.3555 - val_accuracy: 0.9722\n",
      "Epoch 40/100\n",
      "336/336 [==============================] - 0s 108us/step - loss: 1.7561 - accuracy: 0.8720 - val_loss: 0.3537 - val_accuracy: 0.9861\n",
      "Epoch 41/100\n",
      "336/336 [==============================] - 0s 107us/step - loss: 1.8421 - accuracy: 0.8690 - val_loss: 0.3798 - val_accuracy: 0.9861\n",
      "Epoch 42/100\n",
      "336/336 [==============================] - 0s 159us/step - loss: 1.5666 - accuracy: 0.8899 - val_loss: 0.3459 - val_accuracy: 0.9792\n",
      "Epoch 43/100\n",
      "336/336 [==============================] - 0s 115us/step - loss: 1.8387 - accuracy: 0.8690 - val_loss: 0.3405 - val_accuracy: 0.9653\n",
      "Epoch 44/100\n",
      "336/336 [==============================] - 0s 111us/step - loss: 1.6844 - accuracy: 0.8839 - val_loss: 0.3448 - val_accuracy: 0.9792\n",
      "Epoch 45/100\n",
      "336/336 [==============================] - 0s 104us/step - loss: 1.8715 - accuracy: 0.8661 - val_loss: 0.3384 - val_accuracy: 0.9722\n",
      "Epoch 46/100\n",
      "336/336 [==============================] - 0s 107us/step - loss: 1.6386 - accuracy: 0.8810 - val_loss: 0.3328 - val_accuracy: 0.9722\n",
      "Epoch 47/100\n",
      "336/336 [==============================] - 0s 97us/step - loss: 1.8277 - accuracy: 0.8661 - val_loss: 0.3784 - val_accuracy: 0.9861\n",
      "Epoch 48/100\n",
      "336/336 [==============================] - 0s 89us/step - loss: 1.9740 - accuracy: 0.8601 - val_loss: 0.3532 - val_accuracy: 0.9861\n",
      "Epoch 49/100\n",
      "336/336 [==============================] - 0s 84us/step - loss: 1.8235 - accuracy: 0.8690 - val_loss: 0.3355 - val_accuracy: 0.9861\n",
      "Epoch 50/100\n",
      "336/336 [==============================] - 0s 81us/step - loss: 1.9489 - accuracy: 0.8690 - val_loss: 0.3261 - val_accuracy: 0.9792\n",
      "Epoch 51/100\n",
      "336/336 [==============================] - 0s 81us/step - loss: 1.5503 - accuracy: 0.8810 - val_loss: 0.3480 - val_accuracy: 0.9861\n",
      "Epoch 52/100\n",
      "336/336 [==============================] - 0s 77us/step - loss: 1.9079 - accuracy: 0.8661 - val_loss: 0.3257 - val_accuracy: 0.9861\n",
      "Epoch 53/100\n",
      "336/336 [==============================] - 0s 75us/step - loss: 1.8178 - accuracy: 0.8690 - val_loss: 0.3307 - val_accuracy: 0.9861\n",
      "Epoch 54/100\n",
      "336/336 [==============================] - 0s 76us/step - loss: 2.0974 - accuracy: 0.8512 - val_loss: 0.3222 - val_accuracy: 0.9861\n",
      "Epoch 55/100\n",
      "336/336 [==============================] - 0s 98us/step - loss: 1.7641 - accuracy: 0.8720 - val_loss: 0.3172 - val_accuracy: 0.9792\n",
      "Epoch 56/100\n",
      "336/336 [==============================] - 0s 79us/step - loss: 1.9867 - accuracy: 0.8631 - val_loss: 0.3160 - val_accuracy: 0.9861\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "336/336 [==============================] - 0s 82us/step - loss: 1.5709 - accuracy: 0.8929 - val_loss: 0.3109 - val_accuracy: 0.9722\n",
      "Epoch 58/100\n",
      "336/336 [==============================] - 0s 77us/step - loss: 2.3852 - accuracy: 0.8363 - val_loss: 0.3139 - val_accuracy: 0.9861\n",
      "Epoch 59/100\n",
      "336/336 [==============================] - 0s 75us/step - loss: 2.0401 - accuracy: 0.8571 - val_loss: 0.3139 - val_accuracy: 0.9861\n",
      "Epoch 60/100\n",
      "336/336 [==============================] - 0s 76us/step - loss: 1.8501 - accuracy: 0.8661 - val_loss: 0.3258 - val_accuracy: 0.9861\n",
      "Epoch 61/100\n",
      "336/336 [==============================] - 0s 75us/step - loss: 1.7535 - accuracy: 0.8780 - val_loss: 0.3064 - val_accuracy: 0.9861\n",
      "Epoch 62/100\n",
      "336/336 [==============================] - 0s 78us/step - loss: 1.3445 - accuracy: 0.8958 - val_loss: 0.3014 - val_accuracy: 0.9792\n",
      "Epoch 63/100\n",
      "336/336 [==============================] - 0s 76us/step - loss: 1.8949 - accuracy: 0.8661 - val_loss: 0.3061 - val_accuracy: 0.9722\n",
      "Epoch 64/100\n",
      "336/336 [==============================] - 0s 86us/step - loss: 1.3021 - accuracy: 0.8988 - val_loss: 0.3362 - val_accuracy: 0.9861\n",
      "Epoch 65/100\n",
      "336/336 [==============================] - 0s 78us/step - loss: 1.1596 - accuracy: 0.9167 - val_loss: 0.2978 - val_accuracy: 0.9792\n",
      "Epoch 66/100\n",
      "336/336 [==============================] - 0s 79us/step - loss: 1.1945 - accuracy: 0.9107 - val_loss: 0.2947 - val_accuracy: 0.9722\n",
      "Epoch 67/100\n",
      "336/336 [==============================] - 0s 73us/step - loss: 1.8344 - accuracy: 0.8780 - val_loss: 0.2962 - val_accuracy: 0.9722\n",
      "Epoch 68/100\n",
      "336/336 [==============================] - 0s 100us/step - loss: 1.5671 - accuracy: 0.8899 - val_loss: 0.2970 - val_accuracy: 0.9792\n",
      "Epoch 69/100\n",
      "336/336 [==============================] - 0s 84us/step - loss: 1.8916 - accuracy: 0.8661 - val_loss: 0.3122 - val_accuracy: 0.9861\n",
      "Epoch 70/100\n",
      "336/336 [==============================] - 0s 82us/step - loss: 1.6459 - accuracy: 0.8869 - val_loss: 0.3019 - val_accuracy: 0.9861\n",
      "Epoch 71/100\n",
      "336/336 [==============================] - 0s 79us/step - loss: 1.6945 - accuracy: 0.8839 - val_loss: 0.2947 - val_accuracy: 0.9861\n",
      "Epoch 72/100\n",
      "336/336 [==============================] - 0s 77us/step - loss: 1.2795 - accuracy: 0.9137 - val_loss: 0.2878 - val_accuracy: 0.9861\n",
      "Epoch 73/100\n",
      "336/336 [==============================] - 0s 79us/step - loss: 1.6466 - accuracy: 0.8839 - val_loss: 0.2872 - val_accuracy: 0.9861\n",
      "Epoch 74/100\n",
      "336/336 [==============================] - 0s 81us/step - loss: 1.6065 - accuracy: 0.8899 - val_loss: 0.2991 - val_accuracy: 0.9861\n",
      "Epoch 75/100\n",
      "336/336 [==============================] - 0s 82us/step - loss: 1.7428 - accuracy: 0.8839 - val_loss: 0.2841 - val_accuracy: 0.9861\n",
      "Epoch 76/100\n",
      "336/336 [==============================] - 0s 82us/step - loss: 1.9692 - accuracy: 0.8661 - val_loss: 0.2999 - val_accuracy: 0.9861\n",
      "Epoch 77/100\n",
      "336/336 [==============================] - 0s 87us/step - loss: 1.7849 - accuracy: 0.8839 - val_loss: 0.2788 - val_accuracy: 0.9722\n",
      "Epoch 78/100\n",
      "336/336 [==============================] - 0s 88us/step - loss: 1.2760 - accuracy: 0.9107 - val_loss: 0.2959 - val_accuracy: 0.9861\n",
      "Epoch 79/100\n",
      "336/336 [==============================] - 0s 143us/step - loss: 2.0087 - accuracy: 0.8661 - val_loss: 0.2805 - val_accuracy: 0.9792\n",
      "Epoch 80/100\n",
      "336/336 [==============================] - 0s 170us/step - loss: 1.5395 - accuracy: 0.9018 - val_loss: 0.2767 - val_accuracy: 0.9792\n",
      "Epoch 81/100\n",
      "336/336 [==============================] - 0s 169us/step - loss: 1.5964 - accuracy: 0.8958 - val_loss: 0.2788 - val_accuracy: 0.9792\n",
      "Epoch 82/100\n",
      "336/336 [==============================] - 0s 125us/step - loss: 1.6817 - accuracy: 0.8839 - val_loss: 0.2734 - val_accuracy: 0.9792\n",
      "Epoch 83/100\n",
      "336/336 [==============================] - 0s 131us/step - loss: 1.1317 - accuracy: 0.9196 - val_loss: 0.2783 - val_accuracy: 0.9792\n",
      "Epoch 84/100\n",
      "336/336 [==============================] - 0s 126us/step - loss: 2.1884 - accuracy: 0.8542 - val_loss: 0.2760 - val_accuracy: 0.9792\n",
      "Epoch 85/100\n",
      "336/336 [==============================] - 0s 120us/step - loss: 1.7298 - accuracy: 0.8869 - val_loss: 0.2728 - val_accuracy: 0.9792\n",
      "Epoch 86/100\n",
      "336/336 [==============================] - 0s 120us/step - loss: 2.1952 - accuracy: 0.8542 - val_loss: 0.3266 - val_accuracy: 0.9861\n",
      "Epoch 87/100\n",
      "336/336 [==============================] - 0s 117us/step - loss: 1.7707 - accuracy: 0.8810 - val_loss: 0.2738 - val_accuracy: 0.9792\n",
      "Epoch 88/100\n",
      "336/336 [==============================] - 0s 85us/step - loss: 1.9061 - accuracy: 0.8780 - val_loss: 0.2846 - val_accuracy: 0.9861\n",
      "Epoch 89/100\n",
      "336/336 [==============================] - 0s 81us/step - loss: 1.7248 - accuracy: 0.8839 - val_loss: 0.2677 - val_accuracy: 0.9792\n",
      "Epoch 90/100\n",
      "336/336 [==============================] - 0s 80us/step - loss: 1.4068 - accuracy: 0.9048 - val_loss: 0.2767 - val_accuracy: 0.9792\n",
      "Epoch 91/100\n",
      "336/336 [==============================] - 0s 86us/step - loss: 1.4069 - accuracy: 0.9018 - val_loss: 0.2672 - val_accuracy: 0.9792\n",
      "Epoch 92/100\n",
      "336/336 [==============================] - 0s 83us/step - loss: 1.9127 - accuracy: 0.8720 - val_loss: 0.2796 - val_accuracy: 0.9861\n",
      "Epoch 93/100\n",
      "336/336 [==============================] - 0s 77us/step - loss: 1.0282 - accuracy: 0.9286 - val_loss: 0.3743 - val_accuracy: 0.9583\n",
      "Epoch 94/100\n",
      "336/336 [==============================] - 0s 79us/step - loss: 1.6423 - accuracy: 0.8929 - val_loss: 0.3038 - val_accuracy: 0.9861\n",
      "Epoch 95/100\n",
      "336/336 [==============================] - 0s 85us/step - loss: 1.4904 - accuracy: 0.9018 - val_loss: 0.2687 - val_accuracy: 0.9792\n",
      "Epoch 96/100\n",
      "336/336 [==============================] - 0s 84us/step - loss: 2.0091 - accuracy: 0.8631 - val_loss: 0.2664 - val_accuracy: 0.9792\n",
      "Epoch 97/100\n",
      "336/336 [==============================] - 0s 82us/step - loss: 2.0807 - accuracy: 0.8661 - val_loss: 0.2635 - val_accuracy: 0.9792\n",
      "Epoch 98/100\n",
      "336/336 [==============================] - 0s 82us/step - loss: 1.3576 - accuracy: 0.9107 - val_loss: 0.2626 - val_accuracy: 0.9792\n",
      "Epoch 99/100\n",
      "336/336 [==============================] - 0s 76us/step - loss: 1.8991 - accuracy: 0.8750 - val_loss: 0.2652 - val_accuracy: 0.9861\n",
      "Epoch 100/100\n",
      "336/336 [==============================] - 0s 79us/step - loss: 1.9003 - accuracy: 0.8720 - val_loss: 0.2640 - val_accuracy: 0.9792\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a406cce48>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 0s 66us/step\n",
      "over-sampling test accuracy: 97.92%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over = model1_over.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ Logistic Regression ############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=123, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###### logistics on combination data\n",
    "log_comb = LogisticRegression(random_state=123)\n",
    "log_comb.fit(X_train_comb, y_train_comb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combination logistic test accuracy 100.00%\n"
     ]
    }
   ],
   "source": [
    "y_pred_comb = log_comb.predict(X_test_comb)\n",
    "print('combination logistic test accuracy %.2f%%' % (log_comb.score(X_test_comb, y_test_comb)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=123, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### logistics on over-sampling data\n",
    "log_over = LogisticRegression(random_state=123)\n",
    "log_over.fit(X_train_over, y_train_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling logistic test accuracy 97.92%\n"
     ]
    }
   ],
   "source": [
    "y_pred_over = log_over.predict(X_test_over)\n",
    "print('over-sampling logistic test accuracy %.2f%%' % (log_over.score(X_test_over, y_test_over)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## Random Forest ##############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=123,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###### random forest on combination data\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_comb = RandomForestClassifier(n_estimators=100, random_state=123)\n",
    "rf_comb.fit(X_train_comb,y_train_comb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combination test accuracy: 99.25%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred_comb = rf_comb.predict(X_test_comb)\n",
    "print('combination test accuracy: %.2f%%' % (accuracy_score(y_test_comb, y_pred_comb)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=123,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###### random forest on over-sampling data\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_over = RandomForestClassifier(n_estimators=100, random_state=123)\n",
    "rf_over.fit(X_train_over,y_train_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling test accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred_over = rf_over.predict(X_test_over)\n",
    "print('over-sampling test accuracy: %.2f%%' % (accuracy_score(y_test_over, y_pred_over)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Random forest with cross-validation\n",
    "## Retrieved from https://stackabuse.com/cross-validation-and-grid-search-for-model-selection-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92063492 1.         1.         1.         1.        ]\n",
      "0.9841269841269842\n"
     ]
    }
   ],
   "source": [
    "## random forest model with CV on combination data\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# rfcv_comb = RandomForestClassifier(n_estimators=100, random_state=123)\n",
    "\n",
    "accs_comb = cross_val_score(estimator=rf_comb, X=X_train_comb, y=y_train_comb, cv=5)\n",
    "print(accs_comb)\n",
    "print(accs_comb.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.97058824 0.95588235 0.98529412 1.         0.96969697]\n",
      "0.9762923351158646\n"
     ]
    }
   ],
   "source": [
    "## random forest model with CV on over-sampling data\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# rfcv_over = RandomForestClassifier(n_estimators=100, random_state=123)\n",
    "\n",
    "accs_over = cross_val_score(estimator=rf_over, X=X_train_over, y=y_train_over, cv=5)\n",
    "print(accs_over)\n",
    "print(accs_over.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
