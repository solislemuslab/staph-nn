{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This file implements neural networks and logistic regression on p003ppresabs_quant.\n",
    "## Due to the imbalanced dataset, we implement the over-sampling method and the combination of over- and under-sampling\n",
    "## method.\n",
    "## To deal with overfitting problem, we include both dropout and regularizer when set up layers in neural networks.\n",
    "## For fully-connected neural networks, the accuracy is 99.25% for combination data, and 98.61% for over-sampling data.\n",
    "## For logistic regression, the accuracy is 100% for combination data, and 97.92% for over-sampling data.\n",
    "## Since the accuracy scores are pretty high in logistic regression, we further construct random forest models, which \n",
    "## are relatively less likely to bring overfitting compared to decision tree.\n",
    "## For random forest, the accuracy is 99.25% for combination data, and 100% for over-sampling data.\n",
    "## For random forest with cross-validation, the mean accuracy is 98.41% for combination data, and 97.63% for over-sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(255, 866)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/Users/Rebecca/Desktop/Claudia/neural network/phage_quant/p003ppresabs_quant.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'Unnamed: 0':'id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.169500\n",
       "1      0.316500\n",
       "2      0.460000\n",
       "3      0.169000\n",
       "4      0.171333\n",
       "5      0.236333\n",
       "6      0.166500\n",
       "7      0.173333\n",
       "8      0.315833\n",
       "9      0.162167\n",
       "10     0.186167\n",
       "11     0.382833\n",
       "12     0.170667\n",
       "13     0.173333\n",
       "14     0.162833\n",
       "15     0.164333\n",
       "16     0.382667\n",
       "17     0.397000\n",
       "18     0.372667\n",
       "19     0.166333\n",
       "20     0.242333\n",
       "21     0.305833\n",
       "22     0.162333\n",
       "23     0.165500\n",
       "24     0.616833\n",
       "25     0.170167\n",
       "26     0.491500\n",
       "27     0.167833\n",
       "28     0.166500\n",
       "29     0.374833\n",
       "         ...   \n",
       "225    0.267200\n",
       "226    0.293800\n",
       "227    0.383400\n",
       "228    0.513500\n",
       "229    0.507700\n",
       "230    0.311500\n",
       "231    0.236000\n",
       "232    0.228833\n",
       "233    0.219333\n",
       "234    0.167333\n",
       "235    0.265167\n",
       "236    0.160500\n",
       "237    0.159333\n",
       "238    0.165500\n",
       "239    0.327833\n",
       "240    0.342000\n",
       "241    0.308500\n",
       "242    0.170333\n",
       "243    0.165333\n",
       "244    0.340833\n",
       "245    0.162000\n",
       "246    0.170500\n",
       "247    0.164500\n",
       "248    0.164000\n",
       "249    0.180000\n",
       "250    0.348000\n",
       "251    0.232500\n",
       "252    0.166167\n",
       "253    0.276667\n",
       "254    0.225333\n",
       "Name: pheno, Length: 255, dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pheno']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0.5 in df['pheno']:\n",
    "    print: \"0.5 is in the list\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pheno'] = [1 if i>0.5 else 0 for i in df['pheno']] # convert pheno into binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    240\n",
       "1     15\n",
       "Name: pheno, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pheno']\n",
    "df['pheno'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(255, 866)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.drop(columns=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(255, 865)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(255, 864) (255,)\n"
     ]
    }
   ],
   "source": [
    "X = df_clean.loc[:, df_clean.columns != 'pheno'].values\n",
    "y = df_clean['pheno'].values\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 209), (1, 235)]\n"
     ]
    }
   ],
   "source": [
    "# combination of under- and over- sampling\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.combine import SMOTEENN\n",
    "smote_enn = SMOTEENN(random_state=100)\n",
    "X_comb, y_comb = smote_enn.fit_resample(X, y)\n",
    "print(sorted(Counter(y_comb).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 240), (1, 240)]\n"
     ]
    }
   ],
   "source": [
    "# over-sampling\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "overS = RandomOverSampler(random_state=100)\n",
    "X_over, y_over = overS.fit_resample(X, y)\n",
    "print(sorted(Counter(y_over).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, validation, and test data (combination)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_comb, X_test_comb, y_train_comb, y_test_comb = train_test_split(X_comb, y_comb,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=123,\n",
    "                                                    stratify=y_comb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=123,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# Fully-Connected Neural Network ################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.regularizers import l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### neural network on combination data\n",
    "model1_comb = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_comb.shape[1],), activity_regularizer=l1(0.001)),\n",
    "    Dense(1, activation='sigmoid'),\n",
    "    Dropout(0.2, ),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_comb.compile(optimizer='sgd',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 310 samples, validate on 134 samples\n",
      "Epoch 1/100\n",
      "310/310 [==============================] - 1s 2ms/step - loss: 2.1263 - accuracy: 0.7065 - val_loss: 0.6879 - val_accuracy: 0.8582\n",
      "Epoch 2/100\n",
      "310/310 [==============================] - 0s 145us/step - loss: 1.9910 - accuracy: 0.7935 - val_loss: 0.6045 - val_accuracy: 0.8955\n",
      "Epoch 3/100\n",
      "310/310 [==============================] - 0s 235us/step - loss: 2.0103 - accuracy: 0.7839 - val_loss: 0.5700 - val_accuracy: 0.9030\n",
      "Epoch 4/100\n",
      "310/310 [==============================] - 0s 192us/step - loss: 2.1195 - accuracy: 0.7903 - val_loss: 0.5428 - val_accuracy: 0.8955\n",
      "Epoch 5/100\n",
      "310/310 [==============================] - 0s 344us/step - loss: 1.8438 - accuracy: 0.8000 - val_loss: 0.5307 - val_accuracy: 0.9328\n",
      "Epoch 6/100\n",
      "310/310 [==============================] - 0s 177us/step - loss: 2.3688 - accuracy: 0.7710 - val_loss: 0.5120 - val_accuracy: 0.9403\n",
      "Epoch 7/100\n",
      "310/310 [==============================] - 0s 211us/step - loss: 1.9734 - accuracy: 0.7968 - val_loss: 0.4861 - val_accuracy: 0.9254\n",
      "Epoch 8/100\n",
      "310/310 [==============================] - 0s 313us/step - loss: 1.8549 - accuracy: 0.8000 - val_loss: 0.4707 - val_accuracy: 0.9254\n",
      "Epoch 9/100\n",
      "310/310 [==============================] - 0s 704us/step - loss: 2.1700 - accuracy: 0.7935 - val_loss: 0.4567 - val_accuracy: 0.9328\n",
      "Epoch 10/100\n",
      "310/310 [==============================] - 0s 302us/step - loss: 1.8608 - accuracy: 0.8194 - val_loss: 0.4436 - val_accuracy: 0.9403\n",
      "Epoch 11/100\n",
      "310/310 [==============================] - 0s 331us/step - loss: 1.5628 - accuracy: 0.8387 - val_loss: 0.4322 - val_accuracy: 0.9552\n",
      "Epoch 12/100\n",
      "310/310 [==============================] - 0s 186us/step - loss: 1.8299 - accuracy: 0.8516 - val_loss: 0.4204 - val_accuracy: 0.9403\n",
      "Epoch 13/100\n",
      "310/310 [==============================] - 0s 203us/step - loss: 1.6465 - accuracy: 0.8452 - val_loss: 0.4132 - val_accuracy: 0.9776\n",
      "Epoch 14/100\n",
      "310/310 [==============================] - 0s 214us/step - loss: 2.3750 - accuracy: 0.8194 - val_loss: 0.4065 - val_accuracy: 0.9776\n",
      "Epoch 15/100\n",
      "310/310 [==============================] - 0s 760us/step - loss: 1.7240 - accuracy: 0.8645 - val_loss: 0.3924 - val_accuracy: 0.9552\n",
      "Epoch 16/100\n",
      "310/310 [==============================] - 0s 518us/step - loss: 2.0125 - accuracy: 0.8452 - val_loss: 0.3854 - val_accuracy: 0.9552\n",
      "Epoch 17/100\n",
      "310/310 [==============================] - 0s 178us/step - loss: 1.8075 - accuracy: 0.8742 - val_loss: 0.3806 - val_accuracy: 0.9776\n",
      "Epoch 18/100\n",
      "310/310 [==============================] - 0s 202us/step - loss: 1.5064 - accuracy: 0.8806 - val_loss: 0.3794 - val_accuracy: 0.9701\n",
      "Epoch 19/100\n",
      "310/310 [==============================] - 0s 167us/step - loss: 1.8454 - accuracy: 0.8806 - val_loss: 0.3630 - val_accuracy: 0.9925\n",
      "Epoch 20/100\n",
      "310/310 [==============================] - 0s 148us/step - loss: 1.7294 - accuracy: 0.8774 - val_loss: 0.3564 - val_accuracy: 0.9851\n",
      "Epoch 21/100\n",
      "310/310 [==============================] - 0s 152us/step - loss: 2.0249 - accuracy: 0.8613 - val_loss: 0.3535 - val_accuracy: 0.9851\n",
      "Epoch 22/100\n",
      "310/310 [==============================] - 0s 130us/step - loss: 1.5698 - accuracy: 0.8935 - val_loss: 0.3469 - val_accuracy: 0.9851\n",
      "Epoch 23/100\n",
      "310/310 [==============================] - 0s 132us/step - loss: 1.4695 - accuracy: 0.9065 - val_loss: 0.3417 - val_accuracy: 0.9851\n",
      "Epoch 24/100\n",
      "310/310 [==============================] - 0s 143us/step - loss: 1.8182 - accuracy: 0.8774 - val_loss: 0.3376 - val_accuracy: 0.9925\n",
      "Epoch 25/100\n",
      "310/310 [==============================] - 0s 133us/step - loss: 1.8090 - accuracy: 0.8774 - val_loss: 0.3354 - val_accuracy: 0.9925\n",
      "Epoch 26/100\n",
      "310/310 [==============================] - 0s 146us/step - loss: 1.6599 - accuracy: 0.8903 - val_loss: 0.3267 - val_accuracy: 0.9925\n",
      "Epoch 27/100\n",
      "310/310 [==============================] - 0s 171us/step - loss: 1.8983 - accuracy: 0.8806 - val_loss: 0.3215 - val_accuracy: 0.9851\n",
      "Epoch 28/100\n",
      "310/310 [==============================] - 0s 341us/step - loss: 2.0953 - accuracy: 0.8677 - val_loss: 0.3236 - val_accuracy: 0.9925\n",
      "Epoch 29/100\n",
      "310/310 [==============================] - 0s 159us/step - loss: 1.5430 - accuracy: 0.9065 - val_loss: 0.3146 - val_accuracy: 0.9925\n",
      "Epoch 30/100\n",
      "310/310 [==============================] - 0s 148us/step - loss: 1.6888 - accuracy: 0.8935 - val_loss: 0.3208 - val_accuracy: 0.9851\n",
      "Epoch 31/100\n",
      "310/310 [==============================] - 0s 123us/step - loss: 1.5876 - accuracy: 0.9032 - val_loss: 0.3159 - val_accuracy: 0.9851\n",
      "Epoch 32/100\n",
      "310/310 [==============================] - 0s 136us/step - loss: 2.1279 - accuracy: 0.8677 - val_loss: 0.3130 - val_accuracy: 0.9851\n",
      "Epoch 33/100\n",
      "310/310 [==============================] - 0s 772us/step - loss: 2.0749 - accuracy: 0.8742 - val_loss: 0.3046 - val_accuracy: 0.9925\n",
      "Epoch 34/100\n",
      "310/310 [==============================] - 0s 259us/step - loss: 1.9725 - accuracy: 0.8806 - val_loss: 0.2997 - val_accuracy: 0.9925\n",
      "Epoch 35/100\n",
      "310/310 [==============================] - 0s 223us/step - loss: 1.8172 - accuracy: 0.8839 - val_loss: 0.2957 - val_accuracy: 0.9925\n",
      "Epoch 36/100\n",
      "310/310 [==============================] - 0s 126us/step - loss: 1.7240 - accuracy: 0.8935 - val_loss: 0.2949 - val_accuracy: 0.9925\n",
      "Epoch 37/100\n",
      "310/310 [==============================] - 0s 126us/step - loss: 1.3120 - accuracy: 0.9258 - val_loss: 0.2905 - val_accuracy: 0.9925\n",
      "Epoch 38/100\n",
      "310/310 [==============================] - 0s 138us/step - loss: 1.7120 - accuracy: 0.9000 - val_loss: 0.2927 - val_accuracy: 0.9851\n",
      "Epoch 39/100\n",
      "310/310 [==============================] - 0s 131us/step - loss: 1.9052 - accuracy: 0.8839 - val_loss: 0.2907 - val_accuracy: 0.9851\n",
      "Epoch 40/100\n",
      "310/310 [==============================] - 0s 237us/step - loss: 1.7593 - accuracy: 0.8935 - val_loss: 0.2891 - val_accuracy: 0.9851\n",
      "Epoch 41/100\n",
      "310/310 [==============================] - 0s 197us/step - loss: 1.8080 - accuracy: 0.8935 - val_loss: 0.2836 - val_accuracy: 0.9851\n",
      "Epoch 42/100\n",
      "310/310 [==============================] - 0s 187us/step - loss: 1.5578 - accuracy: 0.9065 - val_loss: 0.2814 - val_accuracy: 0.9851\n",
      "Epoch 43/100\n",
      "310/310 [==============================] - 0s 343us/step - loss: 1.9487 - accuracy: 0.8806 - val_loss: 0.2847 - val_accuracy: 0.9851\n",
      "Epoch 44/100\n",
      "310/310 [==============================] - 0s 162us/step - loss: 1.2040 - accuracy: 0.9258 - val_loss: 0.2845 - val_accuracy: 0.9851\n",
      "Epoch 45/100\n",
      "310/310 [==============================] - 0s 129us/step - loss: 1.8008 - accuracy: 0.8935 - val_loss: 0.2879 - val_accuracy: 0.9851\n",
      "Epoch 46/100\n",
      "310/310 [==============================] - 0s 121us/step - loss: 2.0924 - accuracy: 0.8710 - val_loss: 0.2748 - val_accuracy: 0.9925\n",
      "Epoch 47/100\n",
      "310/310 [==============================] - 0s 180us/step - loss: 1.3996 - accuracy: 0.9194 - val_loss: 0.2699 - val_accuracy: 0.9925\n",
      "Epoch 48/100\n",
      "310/310 [==============================] - 0s 120us/step - loss: 1.5894 - accuracy: 0.9032 - val_loss: 0.2716 - val_accuracy: 0.9851\n",
      "Epoch 49/100\n",
      "310/310 [==============================] - 0s 124us/step - loss: 1.4907 - accuracy: 0.9129 - val_loss: 0.2711 - val_accuracy: 0.9851\n",
      "Epoch 50/100\n",
      "310/310 [==============================] - 0s 133us/step - loss: 2.2371 - accuracy: 0.8613 - val_loss: 0.2660 - val_accuracy: 0.9925\n",
      "Epoch 51/100\n",
      "310/310 [==============================] - 0s 190us/step - loss: 1.4366 - accuracy: 0.9129 - val_loss: 0.2676 - val_accuracy: 0.9851\n",
      "Epoch 52/100\n",
      "310/310 [==============================] - ETA: 0s - loss: 1.1153 - accuracy: 0.93 - 0s 146us/step - loss: 2.0861 - accuracy: 0.8710 - val_loss: 0.2715 - val_accuracy: 0.9851\n",
      "Epoch 53/100\n",
      "310/310 [==============================] - 0s 167us/step - loss: 1.6371 - accuracy: 0.9000 - val_loss: 0.2608 - val_accuracy: 0.9851\n",
      "Epoch 54/100\n",
      "310/310 [==============================] - 0s 124us/step - loss: 1.5884 - accuracy: 0.9065 - val_loss: 0.2646 - val_accuracy: 0.9851\n",
      "Epoch 55/100\n",
      "310/310 [==============================] - 0s 204us/step - loss: 1.9781 - accuracy: 0.8774 - val_loss: 0.2642 - val_accuracy: 0.9851\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "310/310 [==============================] - 0s 183us/step - loss: 1.6858 - accuracy: 0.9000 - val_loss: 0.2542 - val_accuracy: 0.9925\n",
      "Epoch 57/100\n",
      "310/310 [==============================] - 0s 127us/step - loss: 1.4336 - accuracy: 0.9161 - val_loss: 0.2532 - val_accuracy: 0.9925\n",
      "Epoch 58/100\n",
      "310/310 [==============================] - 0s 129us/step - loss: 1.6303 - accuracy: 0.9032 - val_loss: 0.2594 - val_accuracy: 0.9925\n",
      "Epoch 59/100\n",
      "310/310 [==============================] - 0s 154us/step - loss: 1.9282 - accuracy: 0.8839 - val_loss: 0.2614 - val_accuracy: 0.9851\n",
      "Epoch 60/100\n",
      "310/310 [==============================] - 0s 172us/step - loss: 1.5269 - accuracy: 0.9097 - val_loss: 0.2581 - val_accuracy: 0.9851\n",
      "Epoch 61/100\n",
      "310/310 [==============================] - 0s 151us/step - loss: 2.1747 - accuracy: 0.8677 - val_loss: 0.2551 - val_accuracy: 0.9925\n",
      "Epoch 62/100\n",
      "310/310 [==============================] - 0s 120us/step - loss: 2.0208 - accuracy: 0.8774 - val_loss: 0.2497 - val_accuracy: 0.9925\n",
      "Epoch 63/100\n",
      "310/310 [==============================] - 0s 99us/step - loss: 1.5771 - accuracy: 0.9065 - val_loss: 0.2571 - val_accuracy: 0.9851\n",
      "Epoch 64/100\n",
      "310/310 [==============================] - 0s 99us/step - loss: 2.1214 - accuracy: 0.8710 - val_loss: 0.2552 - val_accuracy: 0.9925\n",
      "Epoch 65/100\n",
      "310/310 [==============================] - 0s 479us/step - loss: 1.5738 - accuracy: 0.9065 - val_loss: 0.2451 - val_accuracy: 0.9925\n",
      "Epoch 66/100\n",
      "310/310 [==============================] - 0s 101us/step - loss: 1.5182 - accuracy: 0.9097 - val_loss: 0.2491 - val_accuracy: 0.9925\n",
      "Epoch 67/100\n",
      "310/310 [==============================] - 0s 289us/step - loss: 2.3157 - accuracy: 0.8581 - val_loss: 0.2483 - val_accuracy: 0.9925\n",
      "Epoch 68/100\n",
      "310/310 [==============================] - 0s 165us/step - loss: 1.7659 - accuracy: 0.8935 - val_loss: 0.2501 - val_accuracy: 0.9925\n",
      "Epoch 69/100\n",
      "310/310 [==============================] - 0s 136us/step - loss: 1.9673 - accuracy: 0.8806 - val_loss: 0.2408 - val_accuracy: 0.9925\n",
      "Epoch 70/100\n",
      "310/310 [==============================] - 0s 135us/step - loss: 1.9111 - accuracy: 0.8839 - val_loss: 0.2399 - val_accuracy: 0.9925\n",
      "Epoch 71/100\n",
      "310/310 [==============================] - 0s 126us/step - loss: 1.5140 - accuracy: 0.9097 - val_loss: 0.2446 - val_accuracy: 0.9925\n",
      "Epoch 72/100\n",
      "310/310 [==============================] - 0s 106us/step - loss: 1.6658 - accuracy: 0.9000 - val_loss: 0.2426 - val_accuracy: 0.9925\n",
      "Epoch 73/100\n",
      "310/310 [==============================] - 0s 104us/step - loss: 1.8130 - accuracy: 0.8903 - val_loss: 0.2447 - val_accuracy: 0.9925\n",
      "Epoch 74/100\n",
      "310/310 [==============================] - 0s 133us/step - loss: 1.7157 - accuracy: 0.8968 - val_loss: 0.2398 - val_accuracy: 0.9925\n",
      "Epoch 75/100\n",
      "310/310 [==============================] - 0s 132us/step - loss: 1.5651 - accuracy: 0.9065 - val_loss: 0.2340 - val_accuracy: 0.9925\n",
      "Epoch 76/100\n",
      "310/310 [==============================] - 0s 174us/step - loss: 1.6107 - accuracy: 0.9032 - val_loss: 0.2436 - val_accuracy: 0.9925\n",
      "Epoch 77/100\n",
      "310/310 [==============================] - 0s 108us/step - loss: 1.8111 - accuracy: 0.8903 - val_loss: 0.2384 - val_accuracy: 0.9925\n",
      "Epoch 78/100\n",
      "310/310 [==============================] - 0s 131us/step - loss: 1.8064 - accuracy: 0.8903 - val_loss: 0.2407 - val_accuracy: 0.9925\n",
      "Epoch 79/100\n",
      "310/310 [==============================] - 0s 97us/step - loss: 1.6063 - accuracy: 0.9032 - val_loss: 0.2314 - val_accuracy: 0.9925\n",
      "Epoch 80/100\n",
      "310/310 [==============================] - 0s 491us/step - loss: 1.4604 - accuracy: 0.9129 - val_loss: 0.2336 - val_accuracy: 0.9925\n",
      "Epoch 81/100\n",
      "310/310 [==============================] - 0s 471us/step - loss: 1.4065 - accuracy: 0.9161 - val_loss: 0.2329 - val_accuracy: 0.9925\n",
      "Epoch 82/100\n",
      "310/310 [==============================] - 0s 163us/step - loss: 1.4063 - accuracy: 0.9161 - val_loss: 0.2295 - val_accuracy: 0.9925\n",
      "Epoch 83/100\n",
      "310/310 [==============================] - 0s 101us/step - loss: 1.7498 - accuracy: 0.8935 - val_loss: 0.2376 - val_accuracy: 0.9925\n",
      "Epoch 84/100\n",
      "310/310 [==============================] - 0s 99us/step - loss: 1.4544 - accuracy: 0.9129 - val_loss: 0.2337 - val_accuracy: 0.9925\n",
      "Epoch 85/100\n",
      "310/310 [==============================] - 0s 116us/step - loss: 1.5057 - accuracy: 0.9097 - val_loss: 0.2327 - val_accuracy: 0.9925\n",
      "Epoch 86/100\n",
      "310/310 [==============================] - 0s 101us/step - loss: 1.7522 - accuracy: 0.8935 - val_loss: 0.2294 - val_accuracy: 0.9925\n",
      "Epoch 87/100\n",
      "310/310 [==============================] - 0s 100us/step - loss: 1.3037 - accuracy: 0.9226 - val_loss: 0.2277 - val_accuracy: 0.9925\n",
      "Epoch 88/100\n",
      "310/310 [==============================] - 0s 97us/step - loss: 1.4029 - accuracy: 0.9161 - val_loss: 0.2301 - val_accuracy: 0.9925\n",
      "Epoch 89/100\n",
      "310/310 [==============================] - 0s 104us/step - loss: 1.8521 - accuracy: 0.8871 - val_loss: 0.2283 - val_accuracy: 0.9925\n",
      "Epoch 90/100\n",
      "310/310 [==============================] - 0s 98us/step - loss: 1.6008 - accuracy: 0.9032 - val_loss: 0.2329 - val_accuracy: 0.9925\n",
      "Epoch 91/100\n",
      "310/310 [==============================] - 0s 98us/step - loss: 1.7488 - accuracy: 0.8935 - val_loss: 0.2302 - val_accuracy: 0.9925\n",
      "Epoch 92/100\n",
      "310/310 [==============================] - 0s 110us/step - loss: 1.4493 - accuracy: 0.9129 - val_loss: 0.2310 - val_accuracy: 0.9925\n",
      "Epoch 93/100\n",
      "310/310 [==============================] - 0s 103us/step - loss: 1.7988 - accuracy: 0.8903 - val_loss: 0.2242 - val_accuracy: 0.9925\n",
      "Epoch 94/100\n",
      "310/310 [==============================] - 0s 97us/step - loss: 1.4988 - accuracy: 0.9097 - val_loss: 0.2291 - val_accuracy: 0.9925\n",
      "Epoch 95/100\n",
      "310/310 [==============================] - 0s 100us/step - loss: 1.5512 - accuracy: 0.9065 - val_loss: 0.2296 - val_accuracy: 0.9925\n",
      "Epoch 96/100\n",
      "310/310 [==============================] - 0s 100us/step - loss: 2.3446 - accuracy: 0.8548 - val_loss: 0.2313 - val_accuracy: 0.9925\n",
      "Epoch 97/100\n",
      "310/310 [==============================] - 0s 99us/step - loss: 1.6964 - accuracy: 0.8968 - val_loss: 0.2233 - val_accuracy: 0.9925\n",
      "Epoch 98/100\n",
      "310/310 [==============================] - 0s 94us/step - loss: 2.1404 - accuracy: 0.8677 - val_loss: 0.2223 - val_accuracy: 0.9925\n",
      "Epoch 99/100\n",
      "310/310 [==============================] - 0s 94us/step - loss: 1.9429 - accuracy: 0.8806 - val_loss: 0.2205 - val_accuracy: 0.9925\n",
      "Epoch 100/100\n",
      "310/310 [==============================] - 0s 116us/step - loss: 1.5961 - accuracy: 0.9032 - val_loss: 0.2182 - val_accuracy: 0.9925\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a3c152dd8>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_comb.fit(X_train_comb, y_train_comb,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_comb, y_test_comb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 0s 239us/step\n",
      "combination test accuracy: 99.25%\n"
     ]
    }
   ],
   "source": [
    "acc_test_comb = model1_comb.evaluate(X_test_comb, y_test_comb)[1]\n",
    "print('combination test accuracy: %.2f%%' % (acc_test_comb*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### neural network on over-sampling data\n",
    "model1_over = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],), activity_regularizer=l1(0.001)),\n",
    "    Dense(1, activation='sigmoid'),\n",
    "    Dropout(0.2, ),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over.compile(optimizer='sgd',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 336 samples, validate on 144 samples\n",
      "Epoch 1/100\n",
      "336/336 [==============================] - 1s 2ms/step - loss: 2.1825 - accuracy: 0.6726 - val_loss: 0.6722 - val_accuracy: 0.7500\n",
      "Epoch 2/100\n",
      "336/336 [==============================] - 0s 167us/step - loss: 2.0882 - accuracy: 0.7024 - val_loss: 0.6222 - val_accuracy: 0.7917\n",
      "Epoch 3/100\n",
      "336/336 [==============================] - 0s 407us/step - loss: 1.7454 - accuracy: 0.7500 - val_loss: 0.6186 - val_accuracy: 0.7222\n",
      "Epoch 4/100\n",
      "336/336 [==============================] - ETA: 0s - loss: 1.4456 - accuracy: 0.84 - 0s 122us/step - loss: 2.5586 - accuracy: 0.7500 - val_loss: 0.5840 - val_accuracy: 0.8333\n",
      "Epoch 5/100\n",
      "336/336 [==============================] - 0s 226us/step - loss: 2.0931 - accuracy: 0.7768 - val_loss: 0.5533 - val_accuracy: 0.8333\n",
      "Epoch 6/100\n",
      "336/336 [==============================] - 0s 113us/step - loss: 2.2950 - accuracy: 0.7738 - val_loss: 0.5396 - val_accuracy: 0.8611\n",
      "Epoch 7/100\n",
      "336/336 [==============================] - 0s 145us/step - loss: 1.8503 - accuracy: 0.8155 - val_loss: 0.5243 - val_accuracy: 0.8611\n",
      "Epoch 8/100\n",
      "336/336 [==============================] - 0s 157us/step - loss: 1.6867 - accuracy: 0.8304 - val_loss: 0.5132 - val_accuracy: 0.8542\n",
      "Epoch 9/100\n",
      "336/336 [==============================] - 0s 178us/step - loss: 1.7730 - accuracy: 0.8274 - val_loss: 0.5141 - val_accuracy: 0.8611\n",
      "Epoch 10/100\n",
      "336/336 [==============================] - 0s 148us/step - loss: 1.9435 - accuracy: 0.8274 - val_loss: 0.4964 - val_accuracy: 0.8611\n",
      "Epoch 11/100\n",
      "336/336 [==============================] - 0s 228us/step - loss: 1.8922 - accuracy: 0.8304 - val_loss: 0.4907 - val_accuracy: 0.8611\n",
      "Epoch 12/100\n",
      "336/336 [==============================] - 0s 185us/step - loss: 2.0635 - accuracy: 0.8185 - val_loss: 0.4870 - val_accuracy: 0.8611\n",
      "Epoch 13/100\n",
      "336/336 [==============================] - 0s 280us/step - loss: 2.1446 - accuracy: 0.8214 - val_loss: 0.4728 - val_accuracy: 0.8681\n",
      "Epoch 14/100\n",
      "336/336 [==============================] - 0s 201us/step - loss: 1.4441 - accuracy: 0.8869 - val_loss: 0.4696 - val_accuracy: 0.8681\n",
      "Epoch 15/100\n",
      "336/336 [==============================] - 0s 134us/step - loss: 1.8992 - accuracy: 0.8363 - val_loss: 0.4558 - val_accuracy: 0.8681\n",
      "Epoch 16/100\n",
      "336/336 [==============================] - 0s 129us/step - loss: 2.0696 - accuracy: 0.8363 - val_loss: 0.4493 - val_accuracy: 0.9097\n",
      "Epoch 17/100\n",
      "336/336 [==============================] - 0s 150us/step - loss: 1.5392 - accuracy: 0.8631 - val_loss: 0.4426 - val_accuracy: 0.9097\n",
      "Epoch 18/100\n",
      "336/336 [==============================] - 0s 123us/step - loss: 1.6607 - accuracy: 0.8780 - val_loss: 0.4483 - val_accuracy: 0.8681\n",
      "Epoch 19/100\n",
      "336/336 [==============================] - 0s 125us/step - loss: 2.2992 - accuracy: 0.8244 - val_loss: 0.4369 - val_accuracy: 0.8681\n",
      "Epoch 20/100\n",
      "336/336 [==============================] - 0s 109us/step - loss: 2.1103 - accuracy: 0.8393 - val_loss: 0.4276 - val_accuracy: 0.9097\n",
      "Epoch 21/100\n",
      "336/336 [==============================] - 0s 106us/step - loss: 2.5045 - accuracy: 0.8125 - val_loss: 0.4223 - val_accuracy: 0.9097\n",
      "Epoch 22/100\n",
      "336/336 [==============================] - 0s 109us/step - loss: 1.9519 - accuracy: 0.8601 - val_loss: 0.4224 - val_accuracy: 0.9167\n",
      "Epoch 23/100\n",
      "336/336 [==============================] - 0s 142us/step - loss: 1.4565 - accuracy: 0.8899 - val_loss: 0.4560 - val_accuracy: 0.8750\n",
      "Epoch 24/100\n",
      "336/336 [==============================] - 0s 115us/step - loss: 2.0875 - accuracy: 0.8452 - val_loss: 0.4298 - val_accuracy: 0.8750\n",
      "Epoch 25/100\n",
      "336/336 [==============================] - 0s 110us/step - loss: 1.7077 - accuracy: 0.8810 - val_loss: 0.4006 - val_accuracy: 0.9097\n",
      "Epoch 26/100\n",
      "336/336 [==============================] - 0s 107us/step - loss: 1.8391 - accuracy: 0.8690 - val_loss: 0.3961 - val_accuracy: 0.9097\n",
      "Epoch 27/100\n",
      "336/336 [==============================] - 0s 111us/step - loss: 1.8941 - accuracy: 0.8690 - val_loss: 0.3914 - val_accuracy: 0.9722\n",
      "Epoch 28/100\n",
      "336/336 [==============================] - 0s 117us/step - loss: 1.8880 - accuracy: 0.8601 - val_loss: 0.3953 - val_accuracy: 0.9861\n",
      "Epoch 29/100\n",
      "336/336 [==============================] - 0s 137us/step - loss: 1.6257 - accuracy: 0.8780 - val_loss: 0.3853 - val_accuracy: 0.9792\n",
      "Epoch 30/100\n",
      "336/336 [==============================] - 0s 114us/step - loss: 2.1124 - accuracy: 0.8512 - val_loss: 0.3930 - val_accuracy: 0.9167\n",
      "Epoch 31/100\n",
      "336/336 [==============================] - 0s 281us/step - loss: 1.7435 - accuracy: 0.8750 - val_loss: 0.3806 - val_accuracy: 0.9653\n",
      "Epoch 32/100\n",
      "336/336 [==============================] - 0s 164us/step - loss: 1.9630 - accuracy: 0.8571 - val_loss: 0.3714 - val_accuracy: 0.9792\n",
      "Epoch 33/100\n",
      "336/336 [==============================] - 0s 189us/step - loss: 1.8331 - accuracy: 0.8661 - val_loss: 0.3706 - val_accuracy: 0.9861\n",
      "Epoch 34/100\n",
      "336/336 [==============================] - 0s 177us/step - loss: 2.0367 - accuracy: 0.8631 - val_loss: 0.3741 - val_accuracy: 0.9653\n",
      "Epoch 35/100\n",
      "336/336 [==============================] - 0s 119us/step - loss: 1.8626 - accuracy: 0.8720 - val_loss: 0.3808 - val_accuracy: 0.9167\n",
      "Epoch 36/100\n",
      "336/336 [==============================] - 0s 333us/step - loss: 1.7655 - accuracy: 0.8750 - val_loss: 0.3592 - val_accuracy: 0.9792\n",
      "Epoch 37/100\n",
      "336/336 [==============================] - 0s 153us/step - loss: 1.2628 - accuracy: 0.9048 - val_loss: 0.3911 - val_accuracy: 0.9375\n",
      "Epoch 38/100\n",
      "336/336 [==============================] - 0s 170us/step - loss: 1.9443 - accuracy: 0.8631 - val_loss: 0.3564 - val_accuracy: 0.9861\n",
      "Epoch 39/100\n",
      "336/336 [==============================] - 0s 276us/step - loss: 1.8919 - accuracy: 0.8720 - val_loss: 0.3559 - val_accuracy: 0.9861\n",
      "Epoch 40/100\n",
      "336/336 [==============================] - 0s 490us/step - loss: 1.8852 - accuracy: 0.8690 - val_loss: 0.3466 - val_accuracy: 0.9861\n",
      "Epoch 41/100\n",
      "336/336 [==============================] - 0s 570us/step - loss: 1.7079 - accuracy: 0.8810 - val_loss: 0.3526 - val_accuracy: 0.9861\n",
      "Epoch 42/100\n",
      "336/336 [==============================] - 0s 193us/step - loss: 1.2917 - accuracy: 0.9137 - val_loss: 0.3370 - val_accuracy: 0.9861\n",
      "Epoch 43/100\n",
      "336/336 [==============================] - 0s 218us/step - loss: 1.4826 - accuracy: 0.8899 - val_loss: 0.3404 - val_accuracy: 0.9861\n",
      "Epoch 44/100\n",
      "336/336 [==============================] - 0s 126us/step - loss: 1.7348 - accuracy: 0.8839 - val_loss: 0.3437 - val_accuracy: 0.9861\n",
      "Epoch 45/100\n",
      "336/336 [==============================] - 0s 168us/step - loss: 1.7859 - accuracy: 0.8750 - val_loss: 0.3374 - val_accuracy: 0.9861\n",
      "Epoch 46/100\n",
      "336/336 [==============================] - 0s 142us/step - loss: 2.1042 - accuracy: 0.8601 - val_loss: 0.3289 - val_accuracy: 0.9861\n",
      "Epoch 47/100\n",
      "336/336 [==============================] - 0s 158us/step - loss: 1.7292 - accuracy: 0.8780 - val_loss: 0.3812 - val_accuracy: 0.8750\n",
      "Epoch 48/100\n",
      "336/336 [==============================] - ETA: 0s - loss: 0.7611 - accuracy: 0.96 - 0s 268us/step - loss: 2.0063 - accuracy: 0.8690 - val_loss: 0.3609 - val_accuracy: 0.9861\n",
      "Epoch 49/100\n",
      "336/336 [==============================] - 0s 176us/step - loss: 1.6462 - accuracy: 0.8869 - val_loss: 0.3280 - val_accuracy: 0.9861\n",
      "Epoch 50/100\n",
      "336/336 [==============================] - 0s 333us/step - loss: 1.6743 - accuracy: 0.8899 - val_loss: 0.3226 - val_accuracy: 0.9861\n",
      "Epoch 51/100\n",
      "336/336 [==============================] - 0s 145us/step - loss: 1.6072 - accuracy: 0.8869 - val_loss: 0.3603 - val_accuracy: 0.9653\n",
      "Epoch 52/100\n",
      "336/336 [==============================] - 0s 207us/step - loss: 2.0372 - accuracy: 0.8631 - val_loss: 0.3196 - val_accuracy: 0.9861\n",
      "Epoch 53/100\n",
      "336/336 [==============================] - 0s 142us/step - loss: 2.0840 - accuracy: 0.8661 - val_loss: 0.3118 - val_accuracy: 0.9861\n",
      "Epoch 54/100\n",
      "336/336 [==============================] - 0s 140us/step - loss: 1.7724 - accuracy: 0.8750 - val_loss: 0.3248 - val_accuracy: 0.9861\n",
      "Epoch 55/100\n",
      "336/336 [==============================] - 0s 135us/step - loss: 2.2692 - accuracy: 0.8423 - val_loss: 0.3246 - val_accuracy: 0.9861\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "336/336 [==============================] - 0s 114us/step - loss: 1.6128 - accuracy: 0.8958 - val_loss: 0.3056 - val_accuracy: 0.9861\n",
      "Epoch 57/100\n",
      "336/336 [==============================] - 0s 113us/step - loss: 1.6651 - accuracy: 0.8869 - val_loss: 0.3142 - val_accuracy: 0.9861\n",
      "Epoch 58/100\n",
      "336/336 [==============================] - 0s 111us/step - loss: 1.6629 - accuracy: 0.8869 - val_loss: 0.3425 - val_accuracy: 0.9653\n",
      "Epoch 59/100\n",
      "336/336 [==============================] - 0s 107us/step - loss: 1.9126 - accuracy: 0.8690 - val_loss: 0.3143 - val_accuracy: 0.9861\n",
      "Epoch 60/100\n",
      "336/336 [==============================] - 0s 95us/step - loss: 1.5705 - accuracy: 0.8958 - val_loss: 0.2978 - val_accuracy: 0.9861\n",
      "Epoch 61/100\n",
      "336/336 [==============================] - 0s 95us/step - loss: 1.4443 - accuracy: 0.9018 - val_loss: 0.3013 - val_accuracy: 0.9861\n",
      "Epoch 62/100\n",
      "336/336 [==============================] - 0s 113us/step - loss: 1.4403 - accuracy: 0.8958 - val_loss: 0.3035 - val_accuracy: 0.9861\n",
      "Epoch 63/100\n",
      "336/336 [==============================] - 0s 109us/step - loss: 1.7543 - accuracy: 0.8839 - val_loss: 0.2987 - val_accuracy: 0.9861\n",
      "Epoch 64/100\n",
      "336/336 [==============================] - 0s 127us/step - loss: 1.7485 - accuracy: 0.8810 - val_loss: 0.2999 - val_accuracy: 0.9861\n",
      "Epoch 65/100\n",
      "336/336 [==============================] - 0s 128us/step - loss: 1.6990 - accuracy: 0.8839 - val_loss: 0.3438 - val_accuracy: 0.9861\n",
      "Epoch 66/100\n",
      "336/336 [==============================] - 0s 179us/step - loss: 1.4808 - accuracy: 0.8988 - val_loss: 0.2992 - val_accuracy: 0.9861\n",
      "Epoch 67/100\n",
      "336/336 [==============================] - 0s 151us/step - loss: 1.6211 - accuracy: 0.8929 - val_loss: 0.2927 - val_accuracy: 0.9861\n",
      "Epoch 68/100\n",
      "336/336 [==============================] - 0s 118us/step - loss: 1.6112 - accuracy: 0.8839 - val_loss: 0.2908 - val_accuracy: 0.9861\n",
      "Epoch 69/100\n",
      "336/336 [==============================] - 0s 174us/step - loss: 1.2909 - accuracy: 0.9077 - val_loss: 0.2944 - val_accuracy: 0.9861\n",
      "Epoch 70/100\n",
      "336/336 [==============================] - 0s 133us/step - loss: 1.5632 - accuracy: 0.8929 - val_loss: 0.2929 - val_accuracy: 0.9861\n",
      "Epoch 71/100\n",
      "336/336 [==============================] - 0s 129us/step - loss: 1.8433 - accuracy: 0.8661 - val_loss: 0.2879 - val_accuracy: 0.9861\n",
      "Epoch 72/100\n",
      "336/336 [==============================] - 0s 131us/step - loss: 1.2000 - accuracy: 0.9137 - val_loss: 0.2964 - val_accuracy: 0.9861\n",
      "Epoch 73/100\n",
      "336/336 [==============================] - 0s 135us/step - loss: 1.6571 - accuracy: 0.8869 - val_loss: 0.2875 - val_accuracy: 0.9861\n",
      "Epoch 74/100\n",
      "336/336 [==============================] - 0s 114us/step - loss: 1.5983 - accuracy: 0.8869 - val_loss: 0.2836 - val_accuracy: 0.9861\n",
      "Epoch 75/100\n",
      "336/336 [==============================] - 0s 117us/step - loss: 1.5476 - accuracy: 0.8929 - val_loss: 0.2865 - val_accuracy: 0.9861\n",
      "Epoch 76/100\n",
      "336/336 [==============================] - 0s 111us/step - loss: 1.7255 - accuracy: 0.8899 - val_loss: 0.2794 - val_accuracy: 0.9861\n",
      "Epoch 77/100\n",
      "336/336 [==============================] - 0s 124us/step - loss: 1.9261 - accuracy: 0.8631 - val_loss: 0.2792 - val_accuracy: 0.9861\n",
      "Epoch 78/100\n",
      "336/336 [==============================] - 0s 137us/step - loss: 1.9674 - accuracy: 0.8631 - val_loss: 0.2850 - val_accuracy: 0.9861\n",
      "Epoch 79/100\n",
      "336/336 [==============================] - 0s 108us/step - loss: 1.3713 - accuracy: 0.9048 - val_loss: 0.2811 - val_accuracy: 0.9861\n",
      "Epoch 80/100\n",
      "336/336 [==============================] - 0s 106us/step - loss: 1.9060 - accuracy: 0.8661 - val_loss: 0.3404 - val_accuracy: 0.9861\n",
      "Epoch 81/100\n",
      "336/336 [==============================] - 0s 131us/step - loss: 1.9177 - accuracy: 0.8720 - val_loss: 0.2714 - val_accuracy: 0.9861\n",
      "Epoch 82/100\n",
      "336/336 [==============================] - 0s 96us/step - loss: 1.6801 - accuracy: 0.8869 - val_loss: 0.2758 - val_accuracy: 0.9861\n",
      "Epoch 83/100\n",
      "336/336 [==============================] - 0s 102us/step - loss: 1.6833 - accuracy: 0.8839 - val_loss: 0.3151 - val_accuracy: 0.9861\n",
      "Epoch 84/100\n",
      "336/336 [==============================] - 0s 98us/step - loss: 1.4507 - accuracy: 0.9018 - val_loss: 0.2708 - val_accuracy: 0.9861\n",
      "Epoch 85/100\n",
      "336/336 [==============================] - 0s 124us/step - loss: 1.6801 - accuracy: 0.8810 - val_loss: 0.3935 - val_accuracy: 0.9028\n",
      "Epoch 86/100\n",
      "336/336 [==============================] - 0s 133us/step - loss: 1.6941 - accuracy: 0.8839 - val_loss: 0.2830 - val_accuracy: 0.9861\n",
      "Epoch 87/100\n",
      "336/336 [==============================] - 0s 93us/step - loss: 1.7309 - accuracy: 0.8839 - val_loss: 0.2860 - val_accuracy: 0.9861\n",
      "Epoch 88/100\n",
      "336/336 [==============================] - 0s 114us/step - loss: 2.0441 - accuracy: 0.8631 - val_loss: 0.3689 - val_accuracy: 0.9792\n",
      "Epoch 89/100\n",
      "336/336 [==============================] - 0s 114us/step - loss: 1.7302 - accuracy: 0.8810 - val_loss: 0.2655 - val_accuracy: 0.9861\n",
      "Epoch 90/100\n",
      "336/336 [==============================] - 0s 90us/step - loss: 1.3050 - accuracy: 0.9137 - val_loss: 0.2654 - val_accuracy: 0.9861\n",
      "Epoch 91/100\n",
      "336/336 [==============================] - 0s 104us/step - loss: 1.4987 - accuracy: 0.8929 - val_loss: 0.2677 - val_accuracy: 0.9861\n",
      "Epoch 92/100\n",
      "336/336 [==============================] - 0s 95us/step - loss: 1.8516 - accuracy: 0.8750 - val_loss: 0.2665 - val_accuracy: 0.9861\n",
      "Epoch 93/100\n",
      "336/336 [==============================] - 0s 90us/step - loss: 1.8535 - accuracy: 0.8780 - val_loss: 0.2601 - val_accuracy: 0.9861\n",
      "Epoch 94/100\n",
      "336/336 [==============================] - 0s 91us/step - loss: 1.6793 - accuracy: 0.8899 - val_loss: 0.2615 - val_accuracy: 0.9861\n",
      "Epoch 95/100\n",
      "336/336 [==============================] - 0s 82us/step - loss: 1.5297 - accuracy: 0.8929 - val_loss: 0.2869 - val_accuracy: 0.9861\n",
      "Epoch 96/100\n",
      "336/336 [==============================] - 0s 86us/step - loss: 1.8161 - accuracy: 0.8750 - val_loss: 0.2588 - val_accuracy: 0.9861\n",
      "Epoch 97/100\n",
      "336/336 [==============================] - 0s 109us/step - loss: 1.8120 - accuracy: 0.8810 - val_loss: 0.2576 - val_accuracy: 0.9861\n",
      "Epoch 98/100\n",
      "336/336 [==============================] - 0s 126us/step - loss: 1.4057 - accuracy: 0.9048 - val_loss: 0.2574 - val_accuracy: 0.9861\n",
      "Epoch 99/100\n",
      "336/336 [==============================] - 0s 111us/step - loss: 1.8425 - accuracy: 0.8780 - val_loss: 0.2523 - val_accuracy: 0.9861\n",
      "Epoch 100/100\n",
      "336/336 [==============================] - 0s 103us/step - loss: 1.7055 - accuracy: 0.8929 - val_loss: 0.2599 - val_accuracy: 0.9861\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a3b1d4f60>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 0s 107us/step\n",
      "over-sampling test accuracy: 98.61%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over = model1_over.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ Logistic Regression ############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###### logistics on combination data\n",
    "log_comb = LogisticRegression()\n",
    "log_comb.fit(X_train_comb, y_train_comb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combination logistic test accuracy 100.00%\n"
     ]
    }
   ],
   "source": [
    "y_pred_comb = log_comb.predict(X_test_comb)\n",
    "print('combination logistic test accuracy %.2f%%' % (log_comb.score(X_test_comb, y_test_comb)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### logistics on over-sampling data\n",
    "log_over = LogisticRegression()\n",
    "log_over.fit(X_train_over, y_train_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling logistic test accuracy 97.92%\n"
     ]
    }
   ],
   "source": [
    "y_pred_over = log_over.predict(X_test_over)\n",
    "print('over-sampling logistic test accuracy %.2f%%' % (log_over.score(X_test_over, y_test_over)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.        1.        0.9787234 1.        1.       ]\n",
      "0.9957446808510639\n",
      "0.008510638297872353\n"
     ]
    }
   ],
   "source": [
    "############## Random Forest ##############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###### random forest on combination data\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_comb = RandomForestClassifier(n_estimators=100)\n",
    "rf_comb.fit(X_train_comb,y_train_comb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combination test accuracy: 99.25%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred_comb = rf_comb.predict(X_test_comb)\n",
    "print('combination test accuracy: %.2f%%' % (accuracy_score(y_test_comb, y_pred_comb)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###### random forest on over-sampling data\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_over = RandomForestClassifier(n_estimators=100)\n",
    "rf_over.fit(X_train_over,y_train_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling test accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred_over = rf_over.predict(X_test_over)\n",
    "print('over-sampling test accuracy: %.2f%%' % (accuracy_score(y_test_over, y_pred_over)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Random forest with cross-validation\n",
    "## Retrieved from https://stackabuse.com/cross-validation-and-grid-search-for-model-selection-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92063492 1.         1.         1.         1.        ]\n",
      "0.9841269841269842\n"
     ]
    }
   ],
   "source": [
    "## random forest model with CV on combination data\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "rfcv_comb = RandomForestClassifier(n_estimators=100, random_state=123)\n",
    "\n",
    "accs_comb = cross_val_score(estimator=rfcv_comb, X=X_train_comb, y=y_train_comb, cv=5)\n",
    "print(accs_comb)\n",
    "print(accs_comb.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.97058824 0.95588235 0.98529412 1.         0.96969697]\n",
      "0.9762923351158646\n"
     ]
    }
   ],
   "source": [
    "## random forest model with CV on over-sampling data\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "rfcv_over = RandomForestClassifier(n_estimators=100, random_state=123)\n",
    "\n",
    "accs_over = cross_val_score(estimator=rfcv_over, X=X_train_over, y=y_train_over, cv=5)\n",
    "print(accs_over)\n",
    "print(accs_over.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
