{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This file implements neural networks and random forest on p0017SpresabsSTCC_qual.\n",
    "## Due to the imbalanced data and limited cases for class 2, we implement the over-sampling method.\n",
    "## For fully-connected neural networks, the accuracy is 92.39% for over-sampling data and 90.86% with dropout and regularization.\n",
    "## For random forest, the accuracy is 96.95% for over-sampling data.\n",
    "## For random forest with cross-validation, the mean accuracy is 93.01% for over-sampling data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(100)\n",
    "import tensorflow\n",
    "tensorflow.random.set_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(255, 148)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/Users/Rebecca/Desktop/Claudia/neural network/phage_qual/p0017SpresabsSTCC_qual.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'Unnamed: 0':'id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      1\n",
       "3      0\n",
       "4      0\n",
       "5      0\n",
       "6      0\n",
       "7      0\n",
       "8      1\n",
       "9      0\n",
       "10     0\n",
       "11     1\n",
       "12     0\n",
       "13     0\n",
       "14     0\n",
       "15     0\n",
       "16     1\n",
       "17     1\n",
       "18     0\n",
       "19     0\n",
       "20     0\n",
       "21     0\n",
       "22     0\n",
       "23     0\n",
       "24     0\n",
       "25     0\n",
       "26     0\n",
       "27     0\n",
       "28     0\n",
       "29     1\n",
       "      ..\n",
       "225    0\n",
       "226    0\n",
       "227    1\n",
       "228    0\n",
       "229    1\n",
       "230    0\n",
       "231    0\n",
       "232    0\n",
       "233    0\n",
       "234    0\n",
       "235    0\n",
       "236    0\n",
       "237    0\n",
       "238    0\n",
       "239    0\n",
       "240    0\n",
       "241    0\n",
       "242    0\n",
       "243    0\n",
       "244    1\n",
       "245    0\n",
       "246    0\n",
       "247    0\n",
       "248    0\n",
       "249    0\n",
       "250    1\n",
       "251    0\n",
       "252    0\n",
       "253    0\n",
       "254    0\n",
       "Name: pheno, Length: 255, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pheno']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    218\n",
       "1     35\n",
       "2      2\n",
       "Name: pheno, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pheno'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>TTTTGAAGCATTAAGATTACTTATCATTTTTAAATTTCAATTTAAACTAACAGTAATTTATGTAGCTTTTGTAATTCTCATAATAACCTTTACTTCATTT</th>\n",
       "      <th>TTTTCCAGTAAT</th>\n",
       "      <th>TTTTAATACATAT</th>\n",
       "      <th>TTTTAAATATTATAA</th>\n",
       "      <th>TTTGAAGCATTAAGATTACTTATCATTTTTAAATTTCAATTTAAACTAACAGTAATTTATGTAGCTTTTGTAATTCTCATAATAACCTTTACTTCATTTA</th>\n",
       "      <th>TTTATCTTTATGA</th>\n",
       "      <th>TTTAATTTAGTAAGT</th>\n",
       "      <th>TTTAAAAAGATGAATAATGTAAATGAAGTAAAGGTTATTATGAGAATTACAAAAGCTACATAAATTACTGTTAGTTTAAATTGAAATTTAAAAATGATAA</th>\n",
       "      <th>TTGAAGCATTAAGATTACTTATCATTTTTAAATTTCAATTTAAACTAACAGTAATTTATGTAGCTTTTGTAATTCTCATAATAACCTTTACTTCATTTAC</th>\n",
       "      <th>...</th>\n",
       "      <th>group_3904</th>\n",
       "      <th>group_426</th>\n",
       "      <th>group_475</th>\n",
       "      <th>group_6375</th>\n",
       "      <th>group_7822</th>\n",
       "      <th>group_8071</th>\n",
       "      <th>group_8913</th>\n",
       "      <th>ST</th>\n",
       "      <th>CC</th>\n",
       "      <th>pheno</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>107</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>109</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>120335</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120337</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 148 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  \\\n",
       "0     107   \n",
       "1     109   \n",
       "2     115   \n",
       "3  120335   \n",
       "4  120337   \n",
       "\n",
       "   TTTTGAAGCATTAAGATTACTTATCATTTTTAAATTTCAATTTAAACTAACAGTAATTTATGTAGCTTTTGTAATTCTCATAATAACCTTTACTTCATTT  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  1                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   TTTTCCAGTAAT  TTTTAATACATAT  TTTTAAATATTATAA  \\\n",
       "0             0              0                0   \n",
       "1             1              1                1   \n",
       "2             0              0                0   \n",
       "3             0              0                0   \n",
       "4             0              0                0   \n",
       "\n",
       "   TTTGAAGCATTAAGATTACTTATCATTTTTAAATTTCAATTTAAACTAACAGTAATTTATGTAGCTTTTGTAATTCTCATAATAACCTTTACTTCATTTA  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  1                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   TTTATCTTTATGA  TTTAATTTAGTAAGT  \\\n",
       "0              0                0   \n",
       "1              0                1   \n",
       "2              0                0   \n",
       "3              0                0   \n",
       "4              0                0   \n",
       "\n",
       "   TTTAAAAAGATGAATAATGTAAATGAAGTAAAGGTTATTATGAGAATTACAAAAGCTACATAAATTACTGTTAGTTTAAATTGAAATTTAAAAATGATAA  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  1                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   TTGAAGCATTAAGATTACTTATCATTTTTAAATTTCAATTTAAACTAACAGTAATTTATGTAGCTTTTGTAATTCTCATAATAACCTTTACTTCATTTAC  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  1                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   ...  group_3904  group_426  group_475  group_6375  group_7822  group_8071  \\\n",
       "0  ...           0          0          0           0           0           0   \n",
       "1  ...           0          0          0           0           0           0   \n",
       "2  ...           0          0          0           0           0           0   \n",
       "3  ...           0          0          0           0           0           0   \n",
       "4  ...           0          0          0           0           0           0   \n",
       "\n",
       "   group_8913  ST  CC  pheno  \n",
       "0           0   5   5      0  \n",
       "1           0   8   8      0  \n",
       "2           0   5   5      1  \n",
       "3           0   5   5      0  \n",
       "4           0   5   5      0  \n",
       "\n",
       "[5 rows x 148 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.drop(columns=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(255, 147)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TTTTGAAGCATTAAGATTACTTATCATTTTTAAATTTCAATTTAAACTAACAGTAATTTATGTAGCTTTTGTAATTCTCATAATAACCTTTACTTCATTT</th>\n",
       "      <th>TTTTCCAGTAAT</th>\n",
       "      <th>TTTTAATACATAT</th>\n",
       "      <th>TTTTAAATATTATAA</th>\n",
       "      <th>TTTGAAGCATTAAGATTACTTATCATTTTTAAATTTCAATTTAAACTAACAGTAATTTATGTAGCTTTTGTAATTCTCATAATAACCTTTACTTCATTTA</th>\n",
       "      <th>TTTATCTTTATGA</th>\n",
       "      <th>TTTAATTTAGTAAGT</th>\n",
       "      <th>TTTAAAAAGATGAATAATGTAAATGAAGTAAAGGTTATTATGAGAATTACAAAAGCTACATAAATTACTGTTAGTTTAAATTGAAATTTAAAAATGATAA</th>\n",
       "      <th>TTGAAGCATTAAGATTACTTATCATTTTTAAATTTCAATTTAAACTAACAGTAATTTATGTAGCTTTTGTAATTCTCATAATAACCTTTACTTCATTTAC</th>\n",
       "      <th>TTCCATCGAATCAC</th>\n",
       "      <th>...</th>\n",
       "      <th>group_3904</th>\n",
       "      <th>group_426</th>\n",
       "      <th>group_475</th>\n",
       "      <th>group_6375</th>\n",
       "      <th>group_7822</th>\n",
       "      <th>group_8071</th>\n",
       "      <th>group_8913</th>\n",
       "      <th>ST</th>\n",
       "      <th>CC</th>\n",
       "      <th>pheno</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 147 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TTTTGAAGCATTAAGATTACTTATCATTTTTAAATTTCAATTTAAACTAACAGTAATTTATGTAGCTTTTGTAATTCTCATAATAACCTTTACTTCATTT  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  1                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   TTTTCCAGTAAT  TTTTAATACATAT  TTTTAAATATTATAA  \\\n",
       "0             0              0                0   \n",
       "1             1              1                1   \n",
       "2             0              0                0   \n",
       "3             0              0                0   \n",
       "4             0              0                0   \n",
       "\n",
       "   TTTGAAGCATTAAGATTACTTATCATTTTTAAATTTCAATTTAAACTAACAGTAATTTATGTAGCTTTTGTAATTCTCATAATAACCTTTACTTCATTTA  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  1                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   TTTATCTTTATGA  TTTAATTTAGTAAGT  \\\n",
       "0              0                0   \n",
       "1              0                1   \n",
       "2              0                0   \n",
       "3              0                0   \n",
       "4              0                0   \n",
       "\n",
       "   TTTAAAAAGATGAATAATGTAAATGAAGTAAAGGTTATTATGAGAATTACAAAAGCTACATAAATTACTGTTAGTTTAAATTGAAATTTAAAAATGATAA  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  1                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   TTGAAGCATTAAGATTACTTATCATTTTTAAATTTCAATTTAAACTAACAGTAATTTATGTAGCTTTTGTAATTCTCATAATAACCTTTACTTCATTTAC  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  1                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   TTCCATCGAATCAC  ...  group_3904  group_426  group_475  group_6375  \\\n",
       "0               0  ...           0          0          0           0   \n",
       "1               1  ...           0          0          0           0   \n",
       "2               0  ...           0          0          0           0   \n",
       "3               0  ...           0          0          0           0   \n",
       "4               0  ...           0          0          0           0   \n",
       "\n",
       "   group_7822  group_8071  group_8913  ST  CC  pheno  \n",
       "0           0           0           0   5   5      0  \n",
       "1           0           0           0   8   8      0  \n",
       "2           0           0           0   5   5      1  \n",
       "3           0           0           0   5   5      0  \n",
       "4           0           0           0   5   5      0  \n",
       "\n",
       "[5 rows x 147 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(255, 146) (255,)\n"
     ]
    }
   ],
   "source": [
    "X = df_clean.loc[:, df_clean.columns != 'pheno'].values\n",
    "y = df_clean['pheno'].values\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 218), (1, 218), (2, 218)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# over-sampling\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "overS = RandomOverSampler(random_state=100)\n",
    "X_over, y_over = overS.fit_resample(X, y)\n",
    "print(sorted(Counter(y_over).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=123,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# Fully-Connected Neural Network ################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.regularizers import l1\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### neural network on over-sampling data\n",
    "model1_over = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],)),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 457 samples, validate on 197 samples\n",
      "Epoch 1/100\n",
      "457/457 [==============================] - 0s 325us/step - loss: 3.2248 - accuracy: 0.3195 - val_loss: 1.4198 - val_accuracy: 0.3401\n",
      "Epoch 2/100\n",
      "457/457 [==============================] - 0s 67us/step - loss: 1.2843 - accuracy: 0.4464 - val_loss: 0.9964 - val_accuracy: 0.5279\n",
      "Epoch 3/100\n",
      "457/457 [==============================] - 0s 63us/step - loss: 0.9125 - accuracy: 0.7199 - val_loss: 0.6814 - val_accuracy: 0.7462\n",
      "Epoch 4/100\n",
      "457/457 [==============================] - 0s 75us/step - loss: 0.6833 - accuracy: 0.6565 - val_loss: 0.5691 - val_accuracy: 0.7411\n",
      "Epoch 5/100\n",
      "457/457 [==============================] - 0s 77us/step - loss: 0.5555 - accuracy: 0.7746 - val_loss: 0.5950 - val_accuracy: 0.7513\n",
      "Epoch 6/100\n",
      "457/457 [==============================] - 0s 79us/step - loss: 0.5472 - accuracy: 0.8162 - val_loss: 0.7158 - val_accuracy: 0.8020\n",
      "Epoch 7/100\n",
      "457/457 [==============================] - 0s 79us/step - loss: 0.5253 - accuracy: 0.7505 - val_loss: 0.5285 - val_accuracy: 0.6041\n",
      "Epoch 8/100\n",
      "457/457 [==============================] - 0s 75us/step - loss: 0.4162 - accuracy: 0.8140 - val_loss: 0.4323 - val_accuracy: 0.8274\n",
      "Epoch 9/100\n",
      "457/457 [==============================] - 0s 78us/step - loss: 0.3951 - accuracy: 0.8315 - val_loss: 0.4809 - val_accuracy: 0.7716\n",
      "Epoch 10/100\n",
      "457/457 [==============================] - 0s 61us/step - loss: 0.4103 - accuracy: 0.8337 - val_loss: 0.3679 - val_accuracy: 0.7970\n",
      "Epoch 11/100\n",
      "457/457 [==============================] - 0s 58us/step - loss: 0.3334 - accuracy: 0.8687 - val_loss: 0.3637 - val_accuracy: 0.8985\n",
      "Epoch 12/100\n",
      "457/457 [==============================] - 0s 60us/step - loss: 0.4055 - accuracy: 0.8643 - val_loss: 0.5364 - val_accuracy: 0.8426\n",
      "Epoch 13/100\n",
      "457/457 [==============================] - 0s 80us/step - loss: 0.4785 - accuracy: 0.8118 - val_loss: 0.3559 - val_accuracy: 0.8274\n",
      "Epoch 14/100\n",
      "457/457 [==============================] - 0s 73us/step - loss: 0.3636 - accuracy: 0.8840 - val_loss: 0.3499 - val_accuracy: 0.8579\n",
      "Epoch 15/100\n",
      "457/457 [==============================] - 0s 79us/step - loss: 0.3395 - accuracy: 0.8490 - val_loss: 0.3455 - val_accuracy: 0.8985\n",
      "Epoch 16/100\n",
      "457/457 [==============================] - 0s 73us/step - loss: 0.3681 - accuracy: 0.8818 - val_loss: 0.5203 - val_accuracy: 0.8782\n",
      "Epoch 17/100\n",
      "457/457 [==============================] - 0s 75us/step - loss: 0.4341 - accuracy: 0.8403 - val_loss: 0.9617 - val_accuracy: 0.8325\n",
      "Epoch 18/100\n",
      "457/457 [==============================] - 0s 77us/step - loss: 0.5242 - accuracy: 0.8293 - val_loss: 0.3529 - val_accuracy: 0.8832\n",
      "Epoch 19/100\n",
      "457/457 [==============================] - 0s 78us/step - loss: 0.3767 - accuracy: 0.8775 - val_loss: 0.3393 - val_accuracy: 0.8832\n",
      "Epoch 20/100\n",
      "457/457 [==============================] - 0s 77us/step - loss: 0.2867 - accuracy: 0.8928 - val_loss: 0.3136 - val_accuracy: 0.8934\n",
      "Epoch 21/100\n",
      "457/457 [==============================] - 0s 72us/step - loss: 0.2483 - accuracy: 0.9190 - val_loss: 0.3042 - val_accuracy: 0.9086\n",
      "Epoch 22/100\n",
      "457/457 [==============================] - 0s 60us/step - loss: 0.2357 - accuracy: 0.9147 - val_loss: 0.2996 - val_accuracy: 0.8934\n",
      "Epoch 23/100\n",
      "457/457 [==============================] - 0s 73us/step - loss: 0.2283 - accuracy: 0.9278 - val_loss: 0.2920 - val_accuracy: 0.8985\n",
      "Epoch 24/100\n",
      "457/457 [==============================] - 0s 78us/step - loss: 0.2255 - accuracy: 0.9300 - val_loss: 0.2865 - val_accuracy: 0.8883\n",
      "Epoch 25/100\n",
      "457/457 [==============================] - 0s 84us/step - loss: 0.2189 - accuracy: 0.9300 - val_loss: 0.2861 - val_accuracy: 0.8934\n",
      "Epoch 26/100\n",
      "457/457 [==============================] - 0s 82us/step - loss: 0.2140 - accuracy: 0.9300 - val_loss: 0.2769 - val_accuracy: 0.8934\n",
      "Epoch 27/100\n",
      "457/457 [==============================] - 0s 86us/step - loss: 0.2107 - accuracy: 0.9322 - val_loss: 0.2761 - val_accuracy: 0.8883\n",
      "Epoch 28/100\n",
      "457/457 [==============================] - 0s 84us/step - loss: 0.2188 - accuracy: 0.9125 - val_loss: 0.2814 - val_accuracy: 0.8883\n",
      "Epoch 29/100\n",
      "457/457 [==============================] - 0s 91us/step - loss: 0.2100 - accuracy: 0.9212 - val_loss: 0.2730 - val_accuracy: 0.8934\n",
      "Epoch 30/100\n",
      "457/457 [==============================] - 0s 66us/step - loss: 0.2025 - accuracy: 0.9212 - val_loss: 0.2745 - val_accuracy: 0.8934\n",
      "Epoch 31/100\n",
      "457/457 [==============================] - 0s 78us/step - loss: 0.1992 - accuracy: 0.9278 - val_loss: 0.2678 - val_accuracy: 0.8934\n",
      "Epoch 32/100\n",
      "457/457 [==============================] - 0s 64us/step - loss: 0.1978 - accuracy: 0.9322 - val_loss: 0.2921 - val_accuracy: 0.8934\n",
      "Epoch 33/100\n",
      "457/457 [==============================] - 0s 65us/step - loss: 0.1988 - accuracy: 0.9322 - val_loss: 0.2655 - val_accuracy: 0.8934\n",
      "Epoch 34/100\n",
      "457/457 [==============================] - 0s 68us/step - loss: 0.1948 - accuracy: 0.9278 - val_loss: 0.2543 - val_accuracy: 0.8934\n",
      "Epoch 35/100\n",
      "457/457 [==============================] - 0s 78us/step - loss: 0.2074 - accuracy: 0.9234 - val_loss: 0.2595 - val_accuracy: 0.8934\n",
      "Epoch 36/100\n",
      "457/457 [==============================] - 0s 70us/step - loss: 0.1860 - accuracy: 0.9256 - val_loss: 0.2547 - val_accuracy: 0.8934\n",
      "Epoch 37/100\n",
      "457/457 [==============================] - 0s 61us/step - loss: 0.1868 - accuracy: 0.9300 - val_loss: 0.2553 - val_accuracy: 0.8934\n",
      "Epoch 38/100\n",
      "457/457 [==============================] - 0s 56us/step - loss: 0.1859 - accuracy: 0.9344 - val_loss: 0.2469 - val_accuracy: 0.8934\n",
      "Epoch 39/100\n",
      "457/457 [==============================] - 0s 54us/step - loss: 0.1786 - accuracy: 0.9365 - val_loss: 0.2495 - val_accuracy: 0.8934\n",
      "Epoch 40/100\n",
      "457/457 [==============================] - 0s 50us/step - loss: 0.1811 - accuracy: 0.9475 - val_loss: 0.2694 - val_accuracy: 0.9086\n",
      "Epoch 41/100\n",
      "457/457 [==============================] - 0s 51us/step - loss: 0.1781 - accuracy: 0.9344 - val_loss: 0.2439 - val_accuracy: 0.9036\n",
      "Epoch 42/100\n",
      "457/457 [==============================] - 0s 53us/step - loss: 0.3336 - accuracy: 0.9212 - val_loss: 0.4005 - val_accuracy: 0.8832\n",
      "Epoch 43/100\n",
      "457/457 [==============================] - 0s 53us/step - loss: 0.2703 - accuracy: 0.8993 - val_loss: 0.2769 - val_accuracy: 0.8731\n",
      "Epoch 44/100\n",
      "457/457 [==============================] - 0s 50us/step - loss: 0.2371 - accuracy: 0.9300 - val_loss: 0.2860 - val_accuracy: 0.8883\n",
      "Epoch 45/100\n",
      "457/457 [==============================] - 0s 51us/step - loss: 0.2310 - accuracy: 0.9322 - val_loss: 0.2634 - val_accuracy: 0.8985\n",
      "Epoch 46/100\n",
      "457/457 [==============================] - 0s 48us/step - loss: 0.1784 - accuracy: 0.9365 - val_loss: 0.2468 - val_accuracy: 0.8934\n",
      "Epoch 47/100\n",
      "457/457 [==============================] - 0s 59us/step - loss: 0.1664 - accuracy: 0.9300 - val_loss: 0.2484 - val_accuracy: 0.9188\n",
      "Epoch 48/100\n",
      "457/457 [==============================] - ETA: 0s - loss: 0.2946 - accuracy: 0.87 - 0s 53us/step - loss: 0.1615 - accuracy: 0.9453 - val_loss: 0.2440 - val_accuracy: 0.9036\n",
      "Epoch 49/100\n",
      "457/457 [==============================] - 0s 60us/step - loss: 0.1636 - accuracy: 0.9344 - val_loss: 0.2399 - val_accuracy: 0.8985\n",
      "Epoch 50/100\n",
      "457/457 [==============================] - 0s 53us/step - loss: 0.1596 - accuracy: 0.9409 - val_loss: 0.2395 - val_accuracy: 0.9137\n",
      "Epoch 51/100\n",
      "457/457 [==============================] - 0s 60us/step - loss: 0.1605 - accuracy: 0.9431 - val_loss: 0.2354 - val_accuracy: 0.8985\n",
      "Epoch 52/100\n",
      "457/457 [==============================] - 0s 51us/step - loss: 0.1537 - accuracy: 0.9453 - val_loss: 0.2637 - val_accuracy: 0.9086\n",
      "Epoch 53/100\n",
      "457/457 [==============================] - 0s 49us/step - loss: 0.1572 - accuracy: 0.9475 - val_loss: 0.2386 - val_accuracy: 0.9137\n",
      "Epoch 54/100\n",
      "457/457 [==============================] - 0s 50us/step - loss: 0.1512 - accuracy: 0.9431 - val_loss: 0.2265 - val_accuracy: 0.9137\n",
      "Epoch 55/100\n",
      "457/457 [==============================] - 0s 49us/step - loss: 0.1484 - accuracy: 0.9540 - val_loss: 0.2352 - val_accuracy: 0.9289\n",
      "Epoch 56/100\n",
      "457/457 [==============================] - 0s 51us/step - loss: 0.1501 - accuracy: 0.9387 - val_loss: 0.2381 - val_accuracy: 0.9239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "457/457 [==============================] - 0s 56us/step - loss: 0.1452 - accuracy: 0.9519 - val_loss: 0.2245 - val_accuracy: 0.9239\n",
      "Epoch 58/100\n",
      "457/457 [==============================] - 0s 51us/step - loss: 0.1519 - accuracy: 0.9584 - val_loss: 0.2287 - val_accuracy: 0.9289\n",
      "Epoch 59/100\n",
      "457/457 [==============================] - 0s 53us/step - loss: 0.1576 - accuracy: 0.9431 - val_loss: 0.2291 - val_accuracy: 0.9239\n",
      "Epoch 60/100\n",
      "457/457 [==============================] - 0s 55us/step - loss: 0.1424 - accuracy: 0.9497 - val_loss: 0.2227 - val_accuracy: 0.9442\n",
      "Epoch 61/100\n",
      "457/457 [==============================] - 0s 50us/step - loss: 0.1491 - accuracy: 0.9562 - val_loss: 0.2206 - val_accuracy: 0.9239\n",
      "Epoch 62/100\n",
      "457/457 [==============================] - ETA: 0s - loss: 0.0833 - accuracy: 1.00 - 0s 49us/step - loss: 0.1607 - accuracy: 0.9453 - val_loss: 0.2216 - val_accuracy: 0.9391\n",
      "Epoch 63/100\n",
      "457/457 [==============================] - 0s 56us/step - loss: 0.1644 - accuracy: 0.9409 - val_loss: 0.3566 - val_accuracy: 0.9289\n",
      "Epoch 64/100\n",
      "457/457 [==============================] - 0s 73us/step - loss: 0.3681 - accuracy: 0.9168 - val_loss: 0.2485 - val_accuracy: 0.8782\n",
      "Epoch 65/100\n",
      "457/457 [==============================] - 0s 70us/step - loss: 0.2466 - accuracy: 0.9256 - val_loss: 0.2882 - val_accuracy: 0.9036\n",
      "Epoch 66/100\n",
      "457/457 [==============================] - 0s 60us/step - loss: 0.2658 - accuracy: 0.9256 - val_loss: 0.2675 - val_accuracy: 0.9188\n",
      "Epoch 67/100\n",
      "457/457 [==============================] - 0s 58us/step - loss: 0.1568 - accuracy: 0.9497 - val_loss: 0.2224 - val_accuracy: 0.9188\n",
      "Epoch 68/100\n",
      "457/457 [==============================] - 0s 53us/step - loss: 0.1828 - accuracy: 0.9475 - val_loss: 0.2627 - val_accuracy: 0.9239\n",
      "Epoch 69/100\n",
      "457/457 [==============================] - 0s 52us/step - loss: 0.2362 - accuracy: 0.9431 - val_loss: 0.3727 - val_accuracy: 0.9086\n",
      "Epoch 70/100\n",
      "457/457 [==============================] - 0s 52us/step - loss: 0.3889 - accuracy: 0.9168 - val_loss: 0.5207 - val_accuracy: 0.8782\n",
      "Epoch 71/100\n",
      "457/457 [==============================] - 0s 52us/step - loss: 0.3160 - accuracy: 0.9212 - val_loss: 0.2513 - val_accuracy: 0.9188\n",
      "Epoch 72/100\n",
      "457/457 [==============================] - 0s 52us/step - loss: 0.1569 - accuracy: 0.9431 - val_loss: 0.2266 - val_accuracy: 0.9036\n",
      "Epoch 73/100\n",
      "457/457 [==============================] - 0s 52us/step - loss: 0.1311 - accuracy: 0.9497 - val_loss: 0.2207 - val_accuracy: 0.9289\n",
      "Epoch 74/100\n",
      "457/457 [==============================] - 0s 50us/step - loss: 0.1230 - accuracy: 0.9584 - val_loss: 0.2122 - val_accuracy: 0.9289\n",
      "Epoch 75/100\n",
      "457/457 [==============================] - 0s 50us/step - loss: 0.1272 - accuracy: 0.9584 - val_loss: 0.2199 - val_accuracy: 0.9391\n",
      "Epoch 76/100\n",
      "457/457 [==============================] - 0s 58us/step - loss: 0.1262 - accuracy: 0.9628 - val_loss: 0.2095 - val_accuracy: 0.9239\n",
      "Epoch 77/100\n",
      "457/457 [==============================] - 0s 48us/step - loss: 0.1278 - accuracy: 0.9475 - val_loss: 0.2014 - val_accuracy: 0.9492\n",
      "Epoch 78/100\n",
      "457/457 [==============================] - 0s 54us/step - loss: 0.1214 - accuracy: 0.9584 - val_loss: 0.2014 - val_accuracy: 0.9289\n",
      "Epoch 79/100\n",
      "457/457 [==============================] - 0s 48us/step - loss: 0.1157 - accuracy: 0.9650 - val_loss: 0.2003 - val_accuracy: 0.9239\n",
      "Epoch 80/100\n",
      "457/457 [==============================] - 0s 54us/step - loss: 0.1135 - accuracy: 0.9650 - val_loss: 0.1958 - val_accuracy: 0.9391\n",
      "Epoch 81/100\n",
      "457/457 [==============================] - 0s 55us/step - loss: 0.1143 - accuracy: 0.9606 - val_loss: 0.1972 - val_accuracy: 0.9239\n",
      "Epoch 82/100\n",
      "457/457 [==============================] - 0s 52us/step - loss: 0.1133 - accuracy: 0.9628 - val_loss: 0.2018 - val_accuracy: 0.9391\n",
      "Epoch 83/100\n",
      "457/457 [==============================] - 0s 49us/step - loss: 0.1142 - accuracy: 0.9694 - val_loss: 0.1989 - val_accuracy: 0.9391\n",
      "Epoch 84/100\n",
      "457/457 [==============================] - 0s 57us/step - loss: 0.1109 - accuracy: 0.9716 - val_loss: 0.1929 - val_accuracy: 0.9239\n",
      "Epoch 85/100\n",
      "457/457 [==============================] - 0s 50us/step - loss: 0.1078 - accuracy: 0.9650 - val_loss: 0.1954 - val_accuracy: 0.9239\n",
      "Epoch 86/100\n",
      "457/457 [==============================] - 0s 54us/step - loss: 0.1077 - accuracy: 0.9650 - val_loss: 0.2000 - val_accuracy: 0.9340\n",
      "Epoch 87/100\n",
      "457/457 [==============================] - 0s 50us/step - loss: 0.1092 - accuracy: 0.9672 - val_loss: 0.1936 - val_accuracy: 0.9340\n",
      "Epoch 88/100\n",
      "457/457 [==============================] - 0s 52us/step - loss: 0.1069 - accuracy: 0.9672 - val_loss: 0.1948 - val_accuracy: 0.9340\n",
      "Epoch 89/100\n",
      "457/457 [==============================] - 0s 51us/step - loss: 0.1068 - accuracy: 0.9694 - val_loss: 0.1879 - val_accuracy: 0.9442\n",
      "Epoch 90/100\n",
      "457/457 [==============================] - 0s 50us/step - loss: 0.1060 - accuracy: 0.9694 - val_loss: 0.1821 - val_accuracy: 0.9391\n",
      "Epoch 91/100\n",
      "457/457 [==============================] - 0s 49us/step - loss: 0.1118 - accuracy: 0.9672 - val_loss: 0.2144 - val_accuracy: 0.9239\n",
      "Epoch 92/100\n",
      "457/457 [==============================] - 0s 50us/step - loss: 0.1093 - accuracy: 0.9694 - val_loss: 0.1806 - val_accuracy: 0.9289\n",
      "Epoch 93/100\n",
      "457/457 [==============================] - 0s 53us/step - loss: 0.1040 - accuracy: 0.9694 - val_loss: 0.1837 - val_accuracy: 0.9442\n",
      "Epoch 94/100\n",
      "457/457 [==============================] - 0s 55us/step - loss: 0.1070 - accuracy: 0.9759 - val_loss: 0.1959 - val_accuracy: 0.9442\n",
      "Epoch 95/100\n",
      "457/457 [==============================] - 0s 54us/step - loss: 0.2470 - accuracy: 0.9409 - val_loss: 0.3806 - val_accuracy: 0.9137\n",
      "Epoch 96/100\n",
      "457/457 [==============================] - 0s 57us/step - loss: 0.1749 - accuracy: 0.9584 - val_loss: 0.2207 - val_accuracy: 0.9188\n",
      "Epoch 97/100\n",
      "457/457 [==============================] - 0s 55us/step - loss: 0.1034 - accuracy: 0.9672 - val_loss: 0.1878 - val_accuracy: 0.9086\n",
      "Epoch 98/100\n",
      "457/457 [==============================] - 0s 49us/step - loss: 0.1016 - accuracy: 0.9716 - val_loss: 0.2013 - val_accuracy: 0.9289\n",
      "Epoch 99/100\n",
      "457/457 [==============================] - 0s 58us/step - loss: 0.0974 - accuracy: 0.9694 - val_loss: 0.1884 - val_accuracy: 0.9289\n",
      "Epoch 100/100\n",
      "457/457 [==============================] - 0s 53us/step - loss: 0.1032 - accuracy: 0.9716 - val_loss: 0.1985 - val_accuracy: 0.9239\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a3a5ee2b0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197/197 [==============================] - 0s 72us/step\n",
      "over-sampling test accuracy: 92.39%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over = model1_over.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### add dropout and regularizer\n",
    "model1_over2 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],), activity_regularizer=l1(0.001)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(3, activation='softmax'),\n",
    "    Dropout(0.2, ),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over2.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 457 samples, validate on 197 samples\n",
      "Epoch 1/100\n",
      "457/457 [==============================] - 0s 419us/step - loss: 12.4846 - accuracy: 0.4026 - val_loss: 9.9383 - val_accuracy: 0.5482\n",
      "Epoch 2/100\n",
      "457/457 [==============================] - 0s 71us/step - loss: 10.6719 - accuracy: 0.5164 - val_loss: 7.7851 - val_accuracy: 0.5127\n",
      "Epoch 3/100\n",
      "457/457 [==============================] - 0s 71us/step - loss: 9.4695 - accuracy: 0.5624 - val_loss: 6.4051 - val_accuracy: 0.6497\n",
      "Epoch 4/100\n",
      "457/457 [==============================] - 0s 70us/step - loss: 8.5720 - accuracy: 0.5098 - val_loss: 5.3466 - val_accuracy: 0.7157\n",
      "Epoch 5/100\n",
      "457/457 [==============================] - 0s 69us/step - loss: 7.8174 - accuracy: 0.6039 - val_loss: 4.6412 - val_accuracy: 0.5279\n",
      "Epoch 6/100\n",
      "457/457 [==============================] - 0s 69us/step - loss: 7.0489 - accuracy: 0.6193 - val_loss: 4.1300 - val_accuracy: 0.7259\n",
      "Epoch 7/100\n",
      "457/457 [==============================] - 0s 75us/step - loss: 6.6414 - accuracy: 0.6433 - val_loss: 3.4554 - val_accuracy: 0.7665\n",
      "Epoch 8/100\n",
      "457/457 [==============================] - 0s 71us/step - loss: 5.7315 - accuracy: 0.6783 - val_loss: 3.0538 - val_accuracy: 0.7970\n",
      "Epoch 9/100\n",
      "457/457 [==============================] - 0s 70us/step - loss: 5.6135 - accuracy: 0.6674 - val_loss: 2.7404 - val_accuracy: 0.7563\n",
      "Epoch 10/100\n",
      "457/457 [==============================] - 0s 65us/step - loss: 5.4729 - accuracy: 0.6499 - val_loss: 2.5228 - val_accuracy: 0.7411\n",
      "Epoch 11/100\n",
      "457/457 [==============================] - 0s 67us/step - loss: 5.1012 - accuracy: 0.6455 - val_loss: 2.2039 - val_accuracy: 0.7970\n",
      "Epoch 12/100\n",
      "457/457 [==============================] - 0s 73us/step - loss: 4.4185 - accuracy: 0.7133 - val_loss: 2.0501 - val_accuracy: 0.8325\n",
      "Epoch 13/100\n",
      "457/457 [==============================] - 0s 69us/step - loss: 3.8151 - accuracy: 0.7221 - val_loss: 1.8615 - val_accuracy: 0.7868\n",
      "Epoch 14/100\n",
      "457/457 [==============================] - 0s 65us/step - loss: 4.2914 - accuracy: 0.6740 - val_loss: 1.7308 - val_accuracy: 0.7970\n",
      "Epoch 15/100\n",
      "457/457 [==============================] - 0s 77us/step - loss: 4.1344 - accuracy: 0.6761 - val_loss: 1.6272 - val_accuracy: 0.8122\n",
      "Epoch 16/100\n",
      "457/457 [==============================] - 0s 72us/step - loss: 3.5031 - accuracy: 0.6805 - val_loss: 1.5468 - val_accuracy: 0.7919\n",
      "Epoch 17/100\n",
      "457/457 [==============================] - 0s 63us/step - loss: 3.8193 - accuracy: 0.6740 - val_loss: 1.4789 - val_accuracy: 0.7970\n",
      "Epoch 18/100\n",
      "457/457 [==============================] - 0s 64us/step - loss: 3.1977 - accuracy: 0.7155 - val_loss: 1.3257 - val_accuracy: 0.8020\n",
      "Epoch 19/100\n",
      "457/457 [==============================] - 0s 66us/step - loss: 3.5942 - accuracy: 0.6499 - val_loss: 1.3481 - val_accuracy: 0.8173\n",
      "Epoch 20/100\n",
      "457/457 [==============================] - 0s 63us/step - loss: 3.1827 - accuracy: 0.6871 - val_loss: 1.2272 - val_accuracy: 0.8173\n",
      "Epoch 21/100\n",
      "457/457 [==============================] - 0s 63us/step - loss: 2.7339 - accuracy: 0.7133 - val_loss: 1.1279 - val_accuracy: 0.8071\n",
      "Epoch 22/100\n",
      "457/457 [==============================] - 0s 61us/step - loss: 2.9005 - accuracy: 0.6849 - val_loss: 1.1688 - val_accuracy: 0.8223\n",
      "Epoch 23/100\n",
      "457/457 [==============================] - 0s 62us/step - loss: 2.9143 - accuracy: 0.7090 - val_loss: 1.0491 - val_accuracy: 0.8426\n",
      "Epoch 24/100\n",
      "457/457 [==============================] - 0s 68us/step - loss: 2.9682 - accuracy: 0.6783 - val_loss: 0.9988 - val_accuracy: 0.8629\n",
      "Epoch 25/100\n",
      "457/457 [==============================] - 0s 68us/step - loss: 2.9159 - accuracy: 0.6740 - val_loss: 1.0104 - val_accuracy: 0.8325\n",
      "Epoch 26/100\n",
      "457/457 [==============================] - 0s 67us/step - loss: 2.7328 - accuracy: 0.7133 - val_loss: 1.0067 - val_accuracy: 0.8680\n",
      "Epoch 27/100\n",
      "457/457 [==============================] - 0s 67us/step - loss: 2.8193 - accuracy: 0.6915 - val_loss: 1.0750 - val_accuracy: 0.8071\n",
      "Epoch 28/100\n",
      "457/457 [==============================] - 0s 65us/step - loss: 2.5356 - accuracy: 0.7090 - val_loss: 0.9798 - val_accuracy: 0.8579\n",
      "Epoch 29/100\n",
      "457/457 [==============================] - 0s 64us/step - loss: 2.5302 - accuracy: 0.6783 - val_loss: 0.9976 - val_accuracy: 0.8629\n",
      "Epoch 30/100\n",
      "457/457 [==============================] - 0s 62us/step - loss: 2.1592 - accuracy: 0.7330 - val_loss: 0.9027 - val_accuracy: 0.8629\n",
      "Epoch 31/100\n",
      "457/457 [==============================] - 0s 64us/step - loss: 2.4168 - accuracy: 0.6805 - val_loss: 0.9740 - val_accuracy: 0.8325\n",
      "Epoch 32/100\n",
      "457/457 [==============================] - 0s 61us/step - loss: 2.0149 - accuracy: 0.7309 - val_loss: 0.9096 - val_accuracy: 0.8680\n",
      "Epoch 33/100\n",
      "457/457 [==============================] - 0s 67us/step - loss: 1.8881 - accuracy: 0.7527 - val_loss: 0.8425 - val_accuracy: 0.8731\n",
      "Epoch 34/100\n",
      "457/457 [==============================] - 0s 66us/step - loss: 2.0461 - accuracy: 0.7440 - val_loss: 0.8673 - val_accuracy: 0.8122\n",
      "Epoch 35/100\n",
      "457/457 [==============================] - 0s 65us/step - loss: 2.0004 - accuracy: 0.7265 - val_loss: 0.9231 - val_accuracy: 0.8579\n",
      "Epoch 36/100\n",
      "457/457 [==============================] - 0s 64us/step - loss: 2.2658 - accuracy: 0.7046 - val_loss: 0.9448 - val_accuracy: 0.8426\n",
      "Epoch 37/100\n",
      "457/457 [==============================] - 0s 61us/step - loss: 2.0182 - accuracy: 0.7133 - val_loss: 0.8742 - val_accuracy: 0.8223\n",
      "Epoch 38/100\n",
      "457/457 [==============================] - 0s 62us/step - loss: 2.1240 - accuracy: 0.7265 - val_loss: 0.7942 - val_accuracy: 0.8832\n",
      "Epoch 39/100\n",
      "457/457 [==============================] - 0s 62us/step - loss: 1.7947 - accuracy: 0.7177 - val_loss: 0.8416 - val_accuracy: 0.8629\n",
      "Epoch 40/100\n",
      "457/457 [==============================] - 0s 60us/step - loss: 1.7807 - accuracy: 0.7243 - val_loss: 0.8128 - val_accuracy: 0.8680\n",
      "Epoch 41/100\n",
      "457/457 [==============================] - 0s 65us/step - loss: 2.2316 - accuracy: 0.7155 - val_loss: 0.8231 - val_accuracy: 0.8477\n",
      "Epoch 42/100\n",
      "457/457 [==============================] - 0s 66us/step - loss: 1.8681 - accuracy: 0.7330 - val_loss: 1.0226 - val_accuracy: 0.8680\n",
      "Epoch 43/100\n",
      "457/457 [==============================] - 0s 61us/step - loss: 2.1959 - accuracy: 0.7133 - val_loss: 0.7867 - val_accuracy: 0.8325\n",
      "Epoch 44/100\n",
      "457/457 [==============================] - 0s 63us/step - loss: 1.8121 - accuracy: 0.7418 - val_loss: 0.7867 - val_accuracy: 0.8782\n",
      "Epoch 45/100\n",
      "457/457 [==============================] - 0s 63us/step - loss: 1.9099 - accuracy: 0.7396 - val_loss: 0.7514 - val_accuracy: 0.8782\n",
      "Epoch 46/100\n",
      "457/457 [==============================] - 0s 60us/step - loss: 2.0063 - accuracy: 0.7243 - val_loss: 0.7120 - val_accuracy: 0.8883\n",
      "Epoch 47/100\n",
      "457/457 [==============================] - 0s 60us/step - loss: 1.7643 - accuracy: 0.7440 - val_loss: 0.7770 - val_accuracy: 0.8731\n",
      "Epoch 48/100\n",
      "457/457 [==============================] - 0s 58us/step - loss: 1.9443 - accuracy: 0.7002 - val_loss: 0.7057 - val_accuracy: 0.8832\n",
      "Epoch 49/100\n",
      "457/457 [==============================] - 0s 60us/step - loss: 1.9360 - accuracy: 0.7418 - val_loss: 0.8572 - val_accuracy: 0.8782\n",
      "Epoch 50/100\n",
      "457/457 [==============================] - 0s 62us/step - loss: 1.7790 - accuracy: 0.7221 - val_loss: 0.9975 - val_accuracy: 0.8477\n",
      "Epoch 51/100\n",
      "457/457 [==============================] - 0s 61us/step - loss: 1.9102 - accuracy: 0.7330 - val_loss: 0.8886 - val_accuracy: 0.8883\n",
      "Epoch 52/100\n",
      "457/457 [==============================] - 0s 60us/step - loss: 1.9799 - accuracy: 0.7155 - val_loss: 0.8842 - val_accuracy: 0.8528\n",
      "Epoch 53/100\n",
      "457/457 [==============================] - 0s 62us/step - loss: 1.7328 - accuracy: 0.7090 - val_loss: 1.0669 - val_accuracy: 0.8731\n",
      "Epoch 54/100\n",
      "457/457 [==============================] - 0s 62us/step - loss: 1.6003 - accuracy: 0.7549 - val_loss: 0.9969 - val_accuracy: 0.8985\n",
      "Epoch 55/100\n",
      "457/457 [==============================] - 0s 62us/step - loss: 1.5635 - accuracy: 0.7396 - val_loss: 0.8372 - val_accuracy: 0.8629\n",
      "Epoch 56/100\n",
      "457/457 [==============================] - 0s 61us/step - loss: 1.5484 - accuracy: 0.7484 - val_loss: 0.9086 - val_accuracy: 0.8274\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "457/457 [==============================] - 0s 64us/step - loss: 1.9290 - accuracy: 0.7287 - val_loss: 0.8682 - val_accuracy: 0.8832\n",
      "Epoch 58/100\n",
      "457/457 [==============================] - 0s 63us/step - loss: 1.6305 - accuracy: 0.7462 - val_loss: 0.8880 - val_accuracy: 0.8680\n",
      "Epoch 59/100\n",
      "457/457 [==============================] - 0s 60us/step - loss: 1.6629 - accuracy: 0.7374 - val_loss: 0.7503 - val_accuracy: 0.8883\n",
      "Epoch 60/100\n",
      "457/457 [==============================] - 0s 60us/step - loss: 1.4447 - accuracy: 0.7527 - val_loss: 0.7378 - val_accuracy: 0.8934\n",
      "Epoch 61/100\n",
      "457/457 [==============================] - 0s 59us/step - loss: 1.5071 - accuracy: 0.7571 - val_loss: 0.6849 - val_accuracy: 0.9086\n",
      "Epoch 62/100\n",
      "457/457 [==============================] - 0s 64us/step - loss: 1.5674 - accuracy: 0.7352 - val_loss: 0.7088 - val_accuracy: 0.9137\n",
      "Epoch 63/100\n",
      "457/457 [==============================] - 0s 60us/step - loss: 1.5738 - accuracy: 0.7571 - val_loss: 0.7654 - val_accuracy: 0.8832\n",
      "Epoch 64/100\n",
      "457/457 [==============================] - 0s 61us/step - loss: 1.4968 - accuracy: 0.7615 - val_loss: 1.0840 - val_accuracy: 0.9036\n",
      "Epoch 65/100\n",
      "457/457 [==============================] - 0s 63us/step - loss: 1.6799 - accuracy: 0.7484 - val_loss: 0.8795 - val_accuracy: 0.8934\n",
      "Epoch 66/100\n",
      "457/457 [==============================] - 0s 61us/step - loss: 1.7423 - accuracy: 0.7177 - val_loss: 0.9847 - val_accuracy: 0.8832\n",
      "Epoch 67/100\n",
      "457/457 [==============================] - 0s 60us/step - loss: 1.8325 - accuracy: 0.7265 - val_loss: 0.7599 - val_accuracy: 0.9036\n",
      "Epoch 68/100\n",
      "457/457 [==============================] - 0s 60us/step - loss: 1.5042 - accuracy: 0.7396 - val_loss: 0.7890 - val_accuracy: 0.8883\n",
      "Epoch 69/100\n",
      "457/457 [==============================] - 0s 60us/step - loss: 1.5362 - accuracy: 0.7571 - val_loss: 0.7633 - val_accuracy: 0.9036\n",
      "Epoch 70/100\n",
      "457/457 [==============================] - 0s 62us/step - loss: 1.8673 - accuracy: 0.7352 - val_loss: 1.1983 - val_accuracy: 0.8985\n",
      "Epoch 71/100\n",
      "457/457 [==============================] - 0s 60us/step - loss: 1.6759 - accuracy: 0.7462 - val_loss: 0.9393 - val_accuracy: 0.8629\n",
      "Epoch 72/100\n",
      "457/457 [==============================] - 0s 64us/step - loss: 1.6569 - accuracy: 0.7396 - val_loss: 0.8241 - val_accuracy: 0.8985\n",
      "Epoch 73/100\n",
      "457/457 [==============================] - 0s 66us/step - loss: 1.6376 - accuracy: 0.7133 - val_loss: 0.7403 - val_accuracy: 0.8985\n",
      "Epoch 74/100\n",
      "457/457 [==============================] - 0s 62us/step - loss: 1.2199 - accuracy: 0.7921 - val_loss: 0.8970 - val_accuracy: 0.8731\n",
      "Epoch 75/100\n",
      "457/457 [==============================] - 0s 63us/step - loss: 1.3216 - accuracy: 0.7659 - val_loss: 0.7392 - val_accuracy: 0.9289\n",
      "Epoch 76/100\n",
      "457/457 [==============================] - 0s 63us/step - loss: 1.2744 - accuracy: 0.7681 - val_loss: 0.7412 - val_accuracy: 0.9137\n",
      "Epoch 77/100\n",
      "457/457 [==============================] - 0s 68us/step - loss: 1.0765 - accuracy: 0.7877 - val_loss: 0.8377 - val_accuracy: 0.8934\n",
      "Epoch 78/100\n",
      "457/457 [==============================] - 0s 69us/step - loss: 1.2918 - accuracy: 0.7484 - val_loss: 0.6373 - val_accuracy: 0.8883\n",
      "Epoch 79/100\n",
      "457/457 [==============================] - 0s 65us/step - loss: 1.6047 - accuracy: 0.7440 - val_loss: 0.9020 - val_accuracy: 0.8934\n",
      "Epoch 80/100\n",
      "457/457 [==============================] - 0s 61us/step - loss: 1.2092 - accuracy: 0.7374 - val_loss: 0.7582 - val_accuracy: 0.9188\n",
      "Epoch 81/100\n",
      "457/457 [==============================] - 0s 59us/step - loss: 1.2342 - accuracy: 0.7505 - val_loss: 0.5710 - val_accuracy: 0.8934\n",
      "Epoch 82/100\n",
      "457/457 [==============================] - 0s 61us/step - loss: 1.2698 - accuracy: 0.7790 - val_loss: 0.6849 - val_accuracy: 0.9289\n",
      "Epoch 83/100\n",
      "457/457 [==============================] - 0s 61us/step - loss: 1.2410 - accuracy: 0.7702 - val_loss: 0.8871 - val_accuracy: 0.8985\n",
      "Epoch 84/100\n",
      "457/457 [==============================] - 0s 59us/step - loss: 1.3427 - accuracy: 0.7265 - val_loss: 0.6679 - val_accuracy: 0.9036\n",
      "Epoch 85/100\n",
      "457/457 [==============================] - 0s 63us/step - loss: 1.3488 - accuracy: 0.7527 - val_loss: 0.6236 - val_accuracy: 0.9289\n",
      "Epoch 86/100\n",
      "457/457 [==============================] - 0s 62us/step - loss: 1.2791 - accuracy: 0.7681 - val_loss: 0.6093 - val_accuracy: 0.8934\n",
      "Epoch 87/100\n",
      "457/457 [==============================] - 0s 62us/step - loss: 1.3514 - accuracy: 0.7440 - val_loss: 0.7204 - val_accuracy: 0.9239\n",
      "Epoch 88/100\n",
      "457/457 [==============================] - 0s 60us/step - loss: 1.1277 - accuracy: 0.7615 - val_loss: 0.8194 - val_accuracy: 0.9188\n",
      "Epoch 89/100\n",
      "457/457 [==============================] - 0s 59us/step - loss: 1.2907 - accuracy: 0.7746 - val_loss: 0.6973 - val_accuracy: 0.9137\n",
      "Epoch 90/100\n",
      "457/457 [==============================] - 0s 61us/step - loss: 1.0250 - accuracy: 0.7790 - val_loss: 0.6843 - val_accuracy: 0.9188\n",
      "Epoch 91/100\n",
      "457/457 [==============================] - 0s 62us/step - loss: 1.3026 - accuracy: 0.7396 - val_loss: 0.6797 - val_accuracy: 0.8883\n",
      "Epoch 92/100\n",
      "457/457 [==============================] - 0s 62us/step - loss: 1.4758 - accuracy: 0.7637 - val_loss: 0.7180 - val_accuracy: 0.9239\n",
      "Epoch 93/100\n",
      "457/457 [==============================] - 0s 62us/step - loss: 1.4145 - accuracy: 0.7440 - val_loss: 1.0024 - val_accuracy: 0.9188\n",
      "Epoch 94/100\n",
      "457/457 [==============================] - 0s 63us/step - loss: 1.3480 - accuracy: 0.7637 - val_loss: 0.7040 - val_accuracy: 0.9239\n",
      "Epoch 95/100\n",
      "457/457 [==============================] - 0s 63us/step - loss: 1.1251 - accuracy: 0.7856 - val_loss: 1.0305 - val_accuracy: 0.9036\n",
      "Epoch 96/100\n",
      "457/457 [==============================] - 0s 63us/step - loss: 1.3154 - accuracy: 0.7374 - val_loss: 0.8507 - val_accuracy: 0.9289\n",
      "Epoch 97/100\n",
      "457/457 [==============================] - 0s 62us/step - loss: 1.3459 - accuracy: 0.7943 - val_loss: 0.8326 - val_accuracy: 0.9289\n",
      "Epoch 98/100\n",
      "457/457 [==============================] - 0s 62us/step - loss: 1.1807 - accuracy: 0.7856 - val_loss: 0.8398 - val_accuracy: 0.8934\n",
      "Epoch 99/100\n",
      "457/457 [==============================] - 0s 65us/step - loss: 1.2030 - accuracy: 0.7768 - val_loss: 0.8988 - val_accuracy: 0.9036\n",
      "Epoch 100/100\n",
      "457/457 [==============================] - 0s 64us/step - loss: 1.2124 - accuracy: 0.8009 - val_loss: 0.8231 - val_accuracy: 0.9086\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a3adab358>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over2.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197/197 [==============================] - 0s 72us/step\n",
      "over-sampling test accuracy: 90.86%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over2 = model1_over2.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over2*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## Random Forest ##############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=123,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###### random forest on over-sampling data\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_over = RandomForestClassifier(n_estimators=100, random_state=123)\n",
    "rf_over.fit(X_train_over,y_train_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling test accuracy: 96.95%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred_over = rf_over.predict(X_test_over)\n",
    "print('over-sampling test accuracy: %.2f%%' % (accuracy_score(y_test_over, y_pred_over)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92473118 0.92473118 0.92307692 0.94444444 0.93333333]\n",
      "0.9300634132892197\n"
     ]
    }
   ],
   "source": [
    "## random forest model with CV on over-sampling data\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# rfcv_over = RandomForestClassifier(n_estimators=100, random_state=123)\n",
    "\n",
    "accs_over = cross_val_score(estimator=rf_over, X=X_train_over, y=y_train_over, cv=5)\n",
    "print(accs_over)\n",
    "print(accs_over.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
