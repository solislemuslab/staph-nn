{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This file implements neural networks with/without dropout and regularizer for p0017SpresabsSTCC_qual with four replicates.\n",
    "## We compute the mean and standarad deviation of training and test accuracies.\n",
    "## We also compute the mean and standard deviation of AUC ROC values for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "import numpy as np\n",
    "seed(100)\n",
    "import tensorflow\n",
    "tensorflow.random.set_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(253, 153)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/p0017SpresabsSTCC_qual.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'Unnamed: 0':'id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      1\n",
       "3      0\n",
       "4      0\n",
       "      ..\n",
       "248    1\n",
       "249    0\n",
       "250    0\n",
       "251    0\n",
       "252    0\n",
       "Name: pheno, Length: 253, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pheno']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>TTTTGAAGCATTAAGATTACTTATCATTTTTAAATTTCAATTTAAACTAACAGTAATTTATGTAGCTTTTGTAATTCTCATAATAACCTTTACTTCATTT</th>\n",
       "      <th>TTTTAATACATAT</th>\n",
       "      <th>TTTGAAGCATTAAGATTACTTATCATTTTTAAATTTCAATTTAAACTAACAGTAATTTATGTAGCTTTTGTAATTCTCATAATAACCTTTACTTCATTTA</th>\n",
       "      <th>TTTATCTTTATGA</th>\n",
       "      <th>TTTAATTTAGTAAGT</th>\n",
       "      <th>TTTAAAAAGATGAATAATGTAAATGAAGTAAAGGTTATTATGAGAATTACAAAAGCTACATAAATTACTGTTAGTTTAAATTGAAATTTAAAAATGATAA</th>\n",
       "      <th>TTGAAGCATTAAGATTACTTATCATTTTTAAATTTCAATTTAAACTAACAGTAATTTATGTAGCTTTTGTAATTCTCATAATAACCTTTACTTCATTTAC</th>\n",
       "      <th>TTCCATCGAATCAC</th>\n",
       "      <th>TTCATTTAATGGCTAAGGAAATTGTGCGATTCCACTCAATTATTTGGCCTATTTTATTGATGGCATTAGACTTACCGTTACCTAAAAAAGTCTTTGCACA</th>\n",
       "      <th>...</th>\n",
       "      <th>group_1687</th>\n",
       "      <th>group_3441</th>\n",
       "      <th>group_4225</th>\n",
       "      <th>group_4420</th>\n",
       "      <th>group_7795</th>\n",
       "      <th>group_8042</th>\n",
       "      <th>group_8892</th>\n",
       "      <th>ST</th>\n",
       "      <th>CC</th>\n",
       "      <th>pheno</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>107</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>109</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>120335</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120337</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 153 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  \\\n",
       "0     107   \n",
       "1     109   \n",
       "2     115   \n",
       "3  120335   \n",
       "4  120337   \n",
       "\n",
       "   TTTTGAAGCATTAAGATTACTTATCATTTTTAAATTTCAATTTAAACTAACAGTAATTTATGTAGCTTTTGTAATTCTCATAATAACCTTTACTTCATTT  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  1                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   TTTTAATACATAT  \\\n",
       "0              0   \n",
       "1              0   \n",
       "2              1   \n",
       "3              0   \n",
       "4              0   \n",
       "\n",
       "   TTTGAAGCATTAAGATTACTTATCATTTTTAAATTTCAATTTAAACTAACAGTAATTTATGTAGCTTTTGTAATTCTCATAATAACCTTTACTTCATTTA  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  1                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   TTTATCTTTATGA  TTTAATTTAGTAAGT  \\\n",
       "0              0                0   \n",
       "1              0                0   \n",
       "2              0                1   \n",
       "3              0                0   \n",
       "4              0                0   \n",
       "\n",
       "   TTTAAAAAGATGAATAATGTAAATGAAGTAAAGGTTATTATGAGAATTACAAAAGCTACATAAATTACTGTTAGTTTAAATTGAAATTTAAAAATGATAA  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  1                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   TTGAAGCATTAAGATTACTTATCATTTTTAAATTTCAATTTAAACTAACAGTAATTTATGTAGCTTTTGTAATTCTCATAATAACCTTTACTTCATTTAC  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  1                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   TTCCATCGAATCAC  \\\n",
       "0               0   \n",
       "1               0   \n",
       "2               1   \n",
       "3               0   \n",
       "4               0   \n",
       "\n",
       "   TTCATTTAATGGCTAAGGAAATTGTGCGATTCCACTCAATTATTTGGCCTATTTTATTGATGGCATTAGACTTACCGTTACCTAAAAAAGTCTTTGCACA  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  1                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   ...  group_1687  group_3441  group_4225  group_4420  group_7795  \\\n",
       "0  ...           0           0           0           0           0   \n",
       "1  ...           0           0           0           0           0   \n",
       "2  ...           0           0           0           0           0   \n",
       "3  ...           0           0           0           0           0   \n",
       "4  ...           0           0           0           0           0   \n",
       "\n",
       "   group_8042  group_8892  ST  CC  pheno  \n",
       "0           0           0   5   5      0  \n",
       "1           0           0   8   8      0  \n",
       "2           0           0   5   5      1  \n",
       "3           0           0   5   5      0  \n",
       "4           0           0   5   5      0  \n",
       "\n",
       "[5 rows x 153 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    216\n",
       "1     35\n",
       "2      2\n",
       "Name: pheno, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pheno'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.drop(columns=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(253, 152)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TTTTGAAGCATTAAGATTACTTATCATTTTTAAATTTCAATTTAAACTAACAGTAATTTATGTAGCTTTTGTAATTCTCATAATAACCTTTACTTCATTT</th>\n",
       "      <th>TTTTAATACATAT</th>\n",
       "      <th>TTTGAAGCATTAAGATTACTTATCATTTTTAAATTTCAATTTAAACTAACAGTAATTTATGTAGCTTTTGTAATTCTCATAATAACCTTTACTTCATTTA</th>\n",
       "      <th>TTTATCTTTATGA</th>\n",
       "      <th>TTTAATTTAGTAAGT</th>\n",
       "      <th>TTTAAAAAGATGAATAATGTAAATGAAGTAAAGGTTATTATGAGAATTACAAAAGCTACATAAATTACTGTTAGTTTAAATTGAAATTTAAAAATGATAA</th>\n",
       "      <th>TTGAAGCATTAAGATTACTTATCATTTTTAAATTTCAATTTAAACTAACAGTAATTTATGTAGCTTTTGTAATTCTCATAATAACCTTTACTTCATTTAC</th>\n",
       "      <th>TTCCATCGAATCAC</th>\n",
       "      <th>TTCATTTAATGGCTAAGGAAATTGTGCGATTCCACTCAATTATTTGGCCTATTTTATTGATGGCATTAGACTTACCGTTACCTAAAAAAGTCTTTGCACA</th>\n",
       "      <th>TTCAAGAAGGAGA</th>\n",
       "      <th>...</th>\n",
       "      <th>group_1687</th>\n",
       "      <th>group_3441</th>\n",
       "      <th>group_4225</th>\n",
       "      <th>group_4420</th>\n",
       "      <th>group_7795</th>\n",
       "      <th>group_8042</th>\n",
       "      <th>group_8892</th>\n",
       "      <th>ST</th>\n",
       "      <th>CC</th>\n",
       "      <th>pheno</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 152 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TTTTGAAGCATTAAGATTACTTATCATTTTTAAATTTCAATTTAAACTAACAGTAATTTATGTAGCTTTTGTAATTCTCATAATAACCTTTACTTCATTT  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  1                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   TTTTAATACATAT  \\\n",
       "0              0   \n",
       "1              0   \n",
       "2              1   \n",
       "3              0   \n",
       "4              0   \n",
       "\n",
       "   TTTGAAGCATTAAGATTACTTATCATTTTTAAATTTCAATTTAAACTAACAGTAATTTATGTAGCTTTTGTAATTCTCATAATAACCTTTACTTCATTTA  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  1                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   TTTATCTTTATGA  TTTAATTTAGTAAGT  \\\n",
       "0              0                0   \n",
       "1              0                0   \n",
       "2              0                1   \n",
       "3              0                0   \n",
       "4              0                0   \n",
       "\n",
       "   TTTAAAAAGATGAATAATGTAAATGAAGTAAAGGTTATTATGAGAATTACAAAAGCTACATAAATTACTGTTAGTTTAAATTGAAATTTAAAAATGATAA  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  1                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   TTGAAGCATTAAGATTACTTATCATTTTTAAATTTCAATTTAAACTAACAGTAATTTATGTAGCTTTTGTAATTCTCATAATAACCTTTACTTCATTTAC  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  1                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   TTCCATCGAATCAC  \\\n",
       "0               0   \n",
       "1               0   \n",
       "2               1   \n",
       "3               0   \n",
       "4               0   \n",
       "\n",
       "   TTCATTTAATGGCTAAGGAAATTGTGCGATTCCACTCAATTATTTGGCCTATTTTATTGATGGCATTAGACTTACCGTTACCTAAAAAAGTCTTTGCACA  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  1                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   TTCAAGAAGGAGA  ...  group_1687  group_3441  group_4225  group_4420  \\\n",
       "0              0  ...           0           0           0           0   \n",
       "1              0  ...           0           0           0           0   \n",
       "2              0  ...           0           0           0           0   \n",
       "3              0  ...           0           0           0           0   \n",
       "4              0  ...           0           0           0           0   \n",
       "\n",
       "   group_7795  group_8042  group_8892  ST  CC  pheno  \n",
       "0           0           0           0   5   5      0  \n",
       "1           0           0           0   8   8      0  \n",
       "2           0           0           0   5   5      1  \n",
       "3           0           0           0   5   5      0  \n",
       "4           0           0           0   5   5      0  \n",
       "\n",
       "[5 rows x 152 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(253, 152) (253,)\n"
     ]
    }
   ],
   "source": [
    "X = df.loc[:, df.columns != 'pheno']\n",
    "y = df['pheno']\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.ensemble.bagging module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.ensemble.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.ensemble.forest module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 216), (1, 216), (2, 216)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.utils.testing module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.utils. Anything that cannot be imported from sklearn.utils is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.metrics.classification module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# over-sampling\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "overS = RandomOverSampler(random_state=100)\n",
    "X_over, y_over = overS.fit_resample(X, y)\n",
    "print(sorted(Counter(y_over).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# Fully-Connected Neural Network ################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.regularizers import l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=123,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = pd.DataFrame(X_test_over[:,0])\n",
    "dat['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>312</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CFBRSa27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BCH-SA-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GA27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>NRS235</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>NRS240</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>NRS110</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>NRS063</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0  test\n",
       "0          312     1\n",
       "1     CFBRSa27     0\n",
       "2    BCH-SA-01     1\n",
       "3         GA27     1\n",
       "4       NRS209     2\n",
       "..         ...   ...\n",
       "190     NRS209     2\n",
       "191     NRS235     0\n",
       "192     NRS240     1\n",
       "193     NRS110     2\n",
       "194     NRS063     1\n",
       "\n",
       "[195 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### neural network on over-sampling data\n",
    "model1_over = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],)),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 453 samples, validate on 195 samples\n",
      "Epoch 1/100\n",
      "453/453 [==============================] - 0s 302us/step - loss: 12.5503 - accuracy: 0.4525 - val_loss: 8.7655 - val_accuracy: 0.3487\n",
      "Epoch 2/100\n",
      "453/453 [==============================] - 0s 75us/step - loss: 6.5873 - accuracy: 0.4636 - val_loss: 3.9965 - val_accuracy: 0.3897\n",
      "Epoch 3/100\n",
      "453/453 [==============================] - 0s 84us/step - loss: 3.3724 - accuracy: 0.5519 - val_loss: 1.9124 - val_accuracy: 0.5128\n",
      "Epoch 4/100\n",
      "453/453 [==============================] - 0s 93us/step - loss: 1.3998 - accuracy: 0.5453 - val_loss: 0.9290 - val_accuracy: 0.5949\n",
      "Epoch 5/100\n",
      "453/453 [==============================] - 0s 86us/step - loss: 0.7768 - accuracy: 0.7108 - val_loss: 0.7546 - val_accuracy: 0.7538\n",
      "Epoch 6/100\n",
      "453/453 [==============================] - 0s 79us/step - loss: 0.6967 - accuracy: 0.6777 - val_loss: 0.5473 - val_accuracy: 0.8154\n",
      "Epoch 7/100\n",
      "453/453 [==============================] - 0s 90us/step - loss: 0.5235 - accuracy: 0.8256 - val_loss: 0.4990 - val_accuracy: 0.8359\n",
      "Epoch 8/100\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.4722 - accuracy: 0.8322 - val_loss: 0.5167 - val_accuracy: 0.8205\n",
      "Epoch 9/100\n",
      "453/453 [==============================] - 0s 83us/step - loss: 0.5001 - accuracy: 0.8587 - val_loss: 0.4493 - val_accuracy: 0.8615\n",
      "Epoch 10/100\n",
      "453/453 [==============================] - 0s 90us/step - loss: 0.4710 - accuracy: 0.8477 - val_loss: 0.5270 - val_accuracy: 0.8205\n",
      "Epoch 11/100\n",
      "453/453 [==============================] - 0s 237us/step - loss: 0.4065 - accuracy: 0.8874 - val_loss: 0.4378 - val_accuracy: 0.8462\n",
      "Epoch 12/100\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.3712 - accuracy: 0.8675 - val_loss: 0.3924 - val_accuracy: 0.8821\n",
      "Epoch 13/100\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.3704 - accuracy: 0.8830 - val_loss: 0.3673 - val_accuracy: 0.8872\n",
      "Epoch 14/100\n",
      "453/453 [==============================] - 0s 145us/step - loss: 0.3258 - accuracy: 0.8852 - val_loss: 0.5720 - val_accuracy: 0.8615\n",
      "Epoch 15/100\n",
      "453/453 [==============================] - 0s 134us/step - loss: 0.3173 - accuracy: 0.8985 - val_loss: 0.3502 - val_accuracy: 0.8564\n",
      "Epoch 16/100\n",
      "453/453 [==============================] - 0s 140us/step - loss: 0.2851 - accuracy: 0.8962 - val_loss: 0.3736 - val_accuracy: 0.8564\n",
      "Epoch 17/100\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2693 - accuracy: 0.9117 - val_loss: 0.3353 - val_accuracy: 0.8615\n",
      "Epoch 18/100\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2608 - accuracy: 0.8985 - val_loss: 0.3242 - val_accuracy: 0.8667\n",
      "Epoch 19/100\n",
      "453/453 [==============================] - 0s 149us/step - loss: 0.2510 - accuracy: 0.9051 - val_loss: 0.3192 - val_accuracy: 0.8821\n",
      "Epoch 20/100\n",
      "453/453 [==============================] - 0s 232us/step - loss: 0.2417 - accuracy: 0.9161 - val_loss: 0.3328 - val_accuracy: 0.8821\n",
      "Epoch 21/100\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2444 - accuracy: 0.9117 - val_loss: 0.3059 - val_accuracy: 0.9026\n",
      "Epoch 22/100\n",
      "453/453 [==============================] - 0s 84us/step - loss: 0.2409 - accuracy: 0.9205 - val_loss: 0.3199 - val_accuracy: 0.9026\n",
      "Epoch 23/100\n",
      "453/453 [==============================] - 0s 88us/step - loss: 0.2871 - accuracy: 0.9029 - val_loss: 0.3369 - val_accuracy: 0.8410\n",
      "Epoch 24/100\n",
      "453/453 [==============================] - 0s 93us/step - loss: 0.2356 - accuracy: 0.9007 - val_loss: 0.3404 - val_accuracy: 0.9077\n",
      "Epoch 25/100\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2388 - accuracy: 0.9095 - val_loss: 0.3873 - val_accuracy: 0.8872\n",
      "Epoch 26/100\n",
      "453/453 [==============================] - 0s 99us/step - loss: 1.3086 - accuracy: 0.8168 - val_loss: 1.0187 - val_accuracy: 0.8000\n",
      "Epoch 27/100\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.8534 - accuracy: 0.8631 - val_loss: 0.3922 - val_accuracy: 0.8154\n",
      "Epoch 28/100\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.2782 - accuracy: 0.8852 - val_loss: 0.3544 - val_accuracy: 0.8821\n",
      "Epoch 29/100\n",
      "453/453 [==============================] - 0s 97us/step - loss: 0.2447 - accuracy: 0.9161 - val_loss: 0.4933 - val_accuracy: 0.8462\n",
      "Epoch 30/100\n",
      "453/453 [==============================] - 0s 97us/step - loss: 0.2610 - accuracy: 0.9073 - val_loss: 0.3026 - val_accuracy: 0.8872\n",
      "Epoch 31/100\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.1845 - accuracy: 0.9316 - val_loss: 0.2870 - val_accuracy: 0.9026\n",
      "Epoch 32/100\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.1831 - accuracy: 0.9249 - val_loss: 0.2906 - val_accuracy: 0.9077\n",
      "Epoch 33/100\n",
      "453/453 [==============================] - 0s 141us/step - loss: 0.1766 - accuracy: 0.9382 - val_loss: 0.2842 - val_accuracy: 0.8923\n",
      "Epoch 34/100\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.1709 - accuracy: 0.9492 - val_loss: 0.2973 - val_accuracy: 0.9128\n",
      "Epoch 35/100\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.1823 - accuracy: 0.9338 - val_loss: 0.2771 - val_accuracy: 0.8923\n",
      "Epoch 36/100\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.1699 - accuracy: 0.9470 - val_loss: 0.2973 - val_accuracy: 0.8974\n",
      "Epoch 37/100\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.1835 - accuracy: 0.9272 - val_loss: 0.2902 - val_accuracy: 0.9026\n",
      "Epoch 38/100\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.1864 - accuracy: 0.9382 - val_loss: 0.2806 - val_accuracy: 0.9128\n",
      "Epoch 39/100\n",
      "453/453 [==============================] - 0s 90us/step - loss: 0.1793 - accuracy: 0.9404 - val_loss: 0.2664 - val_accuracy: 0.9231\n",
      "Epoch 40/100\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.1655 - accuracy: 0.9470 - val_loss: 0.2755 - val_accuracy: 0.9077\n",
      "Epoch 41/100\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.1553 - accuracy: 0.9603 - val_loss: 0.2776 - val_accuracy: 0.9231\n",
      "Epoch 42/100\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.1509 - accuracy: 0.9536 - val_loss: 0.2714 - val_accuracy: 0.9179\n",
      "Epoch 43/100\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.1482 - accuracy: 0.9558 - val_loss: 0.2728 - val_accuracy: 0.9231\n",
      "Epoch 44/100\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.1579 - accuracy: 0.9514 - val_loss: 0.2748 - val_accuracy: 0.9077\n",
      "Epoch 45/100\n",
      "453/453 [==============================] - 0s 246us/step - loss: 0.1681 - accuracy: 0.9404 - val_loss: 0.2951 - val_accuracy: 0.9026\n",
      "Epoch 46/100\n",
      "453/453 [==============================] - 0s 133us/step - loss: 0.2097 - accuracy: 0.9360 - val_loss: 0.2995 - val_accuracy: 0.8872\n",
      "Epoch 47/100\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.1443 - accuracy: 0.9448 - val_loss: 0.2561 - val_accuracy: 0.9282\n",
      "Epoch 48/100\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.1421 - accuracy: 0.9581 - val_loss: 0.2800 - val_accuracy: 0.9128\n",
      "Epoch 49/100\n",
      "453/453 [==============================] - 0s 93us/step - loss: 0.1382 - accuracy: 0.9558 - val_loss: 0.2552 - val_accuracy: 0.9179\n",
      "Epoch 50/100\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.1367 - accuracy: 0.9669 - val_loss: 0.2621 - val_accuracy: 0.9179\n",
      "Epoch 51/100\n",
      "453/453 [==============================] - 0s 87us/step - loss: 0.1451 - accuracy: 0.9492 - val_loss: 0.2633 - val_accuracy: 0.9179\n",
      "Epoch 52/100\n",
      "453/453 [==============================] - 0s 90us/step - loss: 0.1450 - accuracy: 0.9470 - val_loss: 0.3491 - val_accuracy: 0.8974\n",
      "Epoch 53/100\n",
      "453/453 [==============================] - 0s 86us/step - loss: 0.1455 - accuracy: 0.9492 - val_loss: 0.2532 - val_accuracy: 0.9179\n",
      "Epoch 54/100\n",
      "453/453 [==============================] - 0s 91us/step - loss: 0.1334 - accuracy: 0.9603 - val_loss: 0.2523 - val_accuracy: 0.9231\n",
      "Epoch 55/100\n",
      "453/453 [==============================] - 0s 89us/step - loss: 0.1409 - accuracy: 0.9492 - val_loss: 0.2710 - val_accuracy: 0.9077\n",
      "Epoch 56/100\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.1270 - accuracy: 0.9514 - val_loss: 0.2578 - val_accuracy: 0.8974\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 93us/step - loss: 0.1298 - accuracy: 0.9603 - val_loss: 0.2599 - val_accuracy: 0.9026\n",
      "Epoch 58/100\n",
      "453/453 [==============================] - 0s 94us/step - loss: 0.1367 - accuracy: 0.9536 - val_loss: 0.2807 - val_accuracy: 0.9026\n",
      "Epoch 59/100\n",
      "453/453 [==============================] - 0s 89us/step - loss: 0.2756 - accuracy: 0.9536 - val_loss: 0.5114 - val_accuracy: 0.8872\n",
      "Epoch 60/100\n",
      "453/453 [==============================] - 0s 85us/step - loss: 0.1777 - accuracy: 0.9382 - val_loss: 0.2978 - val_accuracy: 0.9077\n",
      "Epoch 61/100\n",
      "453/453 [==============================] - 0s 88us/step - loss: 0.1368 - accuracy: 0.9514 - val_loss: 0.2498 - val_accuracy: 0.8974\n",
      "Epoch 62/100\n",
      "453/453 [==============================] - 0s 94us/step - loss: 0.1440 - accuracy: 0.9426 - val_loss: 0.2605 - val_accuracy: 0.9179\n",
      "Epoch 63/100\n",
      "453/453 [==============================] - 0s 208us/step - loss: 0.2898 - accuracy: 0.9205 - val_loss: 0.3388 - val_accuracy: 0.8872\n",
      "Epoch 64/100\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.5137 - accuracy: 0.9051 - val_loss: 0.2749 - val_accuracy: 0.9128\n",
      "Epoch 65/100\n",
      "453/453 [==============================] - 0s 142us/step - loss: 0.1728 - accuracy: 0.9294 - val_loss: 0.3943 - val_accuracy: 0.8769\n",
      "Epoch 66/100\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.1553 - accuracy: 0.9492 - val_loss: 0.3634 - val_accuracy: 0.9026\n",
      "Epoch 67/100\n",
      "453/453 [==============================] - 0s 140us/step - loss: 0.1968 - accuracy: 0.9272 - val_loss: 0.2480 - val_accuracy: 0.9333\n",
      "Epoch 68/100\n",
      "453/453 [==============================] - 0s 465us/step - loss: 0.1318 - accuracy: 0.9492 - val_loss: 0.2886 - val_accuracy: 0.9128\n",
      "Epoch 69/100\n",
      "453/453 [==============================] - 0s 191us/step - loss: 0.1373 - accuracy: 0.9426 - val_loss: 0.2570 - val_accuracy: 0.9231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/keras/callbacks/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.104641). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/100\n",
      "453/453 [==============================] - 0s 171us/step - loss: 0.1174 - accuracy: 0.9536 - val_loss: 0.2653 - val_accuracy: 0.9231\n",
      "Epoch 71/100\n",
      "453/453 [==============================] - 0s 96us/step - loss: 0.1130 - accuracy: 0.9581 - val_loss: 0.2576 - val_accuracy: 0.8923\n",
      "Epoch 72/100\n",
      "453/453 [==============================] - 0s 171us/step - loss: 0.1077 - accuracy: 0.9625 - val_loss: 0.2605 - val_accuracy: 0.9385\n",
      "Epoch 73/100\n",
      "453/453 [==============================] - 0s 146us/step - loss: 0.1063 - accuracy: 0.9669 - val_loss: 0.2508 - val_accuracy: 0.9128\n",
      "Epoch 74/100\n",
      "453/453 [==============================] - 0s 94us/step - loss: 0.1051 - accuracy: 0.9603 - val_loss: 0.2727 - val_accuracy: 0.9282\n",
      "Epoch 75/100\n",
      "453/453 [==============================] - 0s 145us/step - loss: 0.1095 - accuracy: 0.9581 - val_loss: 0.2491 - val_accuracy: 0.9282\n",
      "Epoch 76/100\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.1036 - accuracy: 0.9669 - val_loss: 0.2638 - val_accuracy: 0.9282\n",
      "Epoch 77/100\n",
      "453/453 [==============================] - 0s 181us/step - loss: 0.1079 - accuracy: 0.9603 - val_loss: 0.2461 - val_accuracy: 0.9128\n",
      "Epoch 78/100\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.1066 - accuracy: 0.9647 - val_loss: 0.2559 - val_accuracy: 0.9179\n",
      "Epoch 79/100\n",
      "453/453 [==============================] - 0s 196us/step - loss: 0.1035 - accuracy: 0.9669 - val_loss: 0.2474 - val_accuracy: 0.9436\n",
      "Epoch 80/100\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.1026 - accuracy: 0.9647 - val_loss: 0.2648 - val_accuracy: 0.9282\n",
      "Epoch 81/100\n",
      "453/453 [==============================] - 0s 148us/step - loss: 0.1040 - accuracy: 0.9536 - val_loss: 0.2522 - val_accuracy: 0.9333\n",
      "Epoch 82/100\n",
      "453/453 [==============================] - 0s 168us/step - loss: 0.1008 - accuracy: 0.9669 - val_loss: 0.2535 - val_accuracy: 0.9436\n",
      "Epoch 83/100\n",
      "453/453 [==============================] - 0s 143us/step - loss: 0.0996 - accuracy: 0.9691 - val_loss: 0.2558 - val_accuracy: 0.9333\n",
      "Epoch 84/100\n",
      "453/453 [==============================] - 0s 251us/step - loss: 0.0971 - accuracy: 0.9647 - val_loss: 0.2467 - val_accuracy: 0.9333\n",
      "Epoch 85/100\n",
      "453/453 [==============================] - 0s 233us/step - loss: 0.0968 - accuracy: 0.9647 - val_loss: 0.2572 - val_accuracy: 0.9282\n",
      "Epoch 86/100\n",
      "453/453 [==============================] - 0s 162us/step - loss: 0.0983 - accuracy: 0.9625 - val_loss: 0.2462 - val_accuracy: 0.9436\n",
      "Epoch 87/100\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.1000 - accuracy: 0.9691 - val_loss: 0.2556 - val_accuracy: 0.9231\n",
      "Epoch 88/100\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.1005 - accuracy: 0.9603 - val_loss: 0.2898 - val_accuracy: 0.9179\n",
      "Epoch 89/100\n",
      "453/453 [==============================] - 0s 194us/step - loss: 0.1408 - accuracy: 0.9382 - val_loss: 0.2407 - val_accuracy: 0.9333\n",
      "Epoch 90/100\n",
      "453/453 [==============================] - 0s 144us/step - loss: 0.0985 - accuracy: 0.9647 - val_loss: 0.2586 - val_accuracy: 0.9333\n",
      "Epoch 91/100\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.0982 - accuracy: 0.9669 - val_loss: 0.2635 - val_accuracy: 0.9231\n",
      "Epoch 92/100\n",
      "453/453 [==============================] - 0s 231us/step - loss: 0.0989 - accuracy: 0.9558 - val_loss: 0.2468 - val_accuracy: 0.9436\n",
      "Epoch 93/100\n",
      "453/453 [==============================] - 0s 195us/step - loss: 0.0952 - accuracy: 0.9625 - val_loss: 0.2344 - val_accuracy: 0.9333\n",
      "Epoch 94/100\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.0975 - accuracy: 0.9647 - val_loss: 0.2790 - val_accuracy: 0.9231\n",
      "Epoch 95/100\n",
      "453/453 [==============================] - 0s 243us/step - loss: 0.1004 - accuracy: 0.9536 - val_loss: 0.2401 - val_accuracy: 0.9487\n",
      "Epoch 96/100\n",
      "453/453 [==============================] - 0s 190us/step - loss: 0.0908 - accuracy: 0.9691 - val_loss: 0.2535 - val_accuracy: 0.9385\n",
      "Epoch 97/100\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.0908 - accuracy: 0.9735 - val_loss: 0.2498 - val_accuracy: 0.9436\n",
      "Epoch 98/100\n",
      "453/453 [==============================] - 0s 219us/step - loss: 0.0877 - accuracy: 0.9713 - val_loss: 0.2411 - val_accuracy: 0.9487\n",
      "Epoch 99/100\n",
      "453/453 [==============================] - 0s 250us/step - loss: 0.0973 - accuracy: 0.9713 - val_loss: 0.2791 - val_accuracy: 0.9231\n",
      "Epoch 100/100\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.0937 - accuracy: 0.9558 - val_loss: 0.2402 - val_accuracy: 0.9385\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x12be0b470>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195/195 [==============================] - 0s 220us/step\n",
      "over-sampling test accuracy: 92.82%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over = model1_over.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 2, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 2, 0, 1, 2, 1, 1,\n",
       "       2, 1, 1, 1, 0, 0, 0, 0, 2, 1, 2, 2, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1,\n",
       "       1, 0, 2, 0, 0, 1, 1, 0, 1, 1, 0, 2, 0, 1, 2, 2, 2, 0, 0, 0, 1, 1,\n",
       "       0, 0, 1, 1, 2, 2, 1, 2, 2, 0, 0, 0, 1, 0, 0, 1, 2, 2, 0, 0, 0, 2,\n",
       "       1, 2, 1, 2, 2, 2, 2, 2, 0, 0, 0, 2, 2, 0, 2, 1, 0, 1, 0, 2, 1, 2,\n",
       "       2, 1, 1, 1, 1, 2, 2, 2, 1, 0, 2, 1, 1, 2, 0, 0, 1, 0, 0, 2, 0, 2,\n",
       "       0, 0, 0, 2, 2, 0, 2, 1, 0, 1, 2, 1, 1, 2, 2, 2, 2, 2, 2, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 0, 1, 2, 0, 2, 1, 2, 2, 2, 1, 1, 2, 1, 0, 2,\n",
       "       1, 2, 2, 1, 2, 1, 0, 2, 2, 2, 2, 2, 1, 1, 2, 0, 1, 2, 1])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model1_over.predict_classes(X_test_over)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>312</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CFBRSa27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BCH-SA-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GA27</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>NRS235</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>NRS240</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>NRS110</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>NRS063</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0  test  pred\n",
       "0          312     1     1\n",
       "1     CFBRSa27     0     0\n",
       "2    BCH-SA-01     1     1\n",
       "3         GA27     1     1\n",
       "4       NRS209     2     2\n",
       "..         ...   ...   ...\n",
       "190     NRS209     2     2\n",
       "191     NRS235     0     0\n",
       "192     NRS240     1     1\n",
       "193     NRS110     2     2\n",
       "194     NRS063     1     1\n",
       "\n",
       "[195 rows x 3 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat['pred'] = pred\n",
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba1 = model1_over.predict_proba(X_test_over)\n",
    "dat_proba1 = pd.DataFrame(proba1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.085174</td>\n",
       "      <td>0.914432</td>\n",
       "      <td>3.944692e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>4.954430e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.087625</td>\n",
       "      <td>0.912372</td>\n",
       "      <td>2.741069e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.327130</td>\n",
       "      <td>0.672864</td>\n",
       "      <td>5.658259e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000713</td>\n",
       "      <td>0.005007</td>\n",
       "      <td>9.942797e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>0.000713</td>\n",
       "      <td>0.005007</td>\n",
       "      <td>9.942797e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>0.982151</td>\n",
       "      <td>0.017841</td>\n",
       "      <td>8.293405e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>0.034630</td>\n",
       "      <td>0.965175</td>\n",
       "      <td>1.948009e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>0.000889</td>\n",
       "      <td>0.000444</td>\n",
       "      <td>9.986665e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>0.011739</td>\n",
       "      <td>0.988256</td>\n",
       "      <td>5.054249e-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1             2\n",
       "0    0.085174  0.914432  3.944692e-04\n",
       "1    0.999989  0.000011  4.954430e-09\n",
       "2    0.087625  0.912372  2.741069e-06\n",
       "3    0.327130  0.672864  5.658259e-06\n",
       "4    0.000713  0.005007  9.942797e-01\n",
       "..        ...       ...           ...\n",
       "190  0.000713  0.005007  9.942797e-01\n",
       "191  0.982151  0.017841  8.293405e-06\n",
       "192  0.034630  0.965175  1.948009e-04\n",
       "193  0.000889  0.000444  9.986665e-01\n",
       "194  0.011739  0.988256  5.054249e-06\n",
       "\n",
       "[195 rows x 3 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba1.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba1.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/1p17spST.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 453 samples, validate on 195 samples\n",
      "Epoch 1/100\n",
      "453/453 [==============================] - 0s 201us/step - loss: 0.0959 - accuracy: 0.9647 - val_loss: 0.2845 - val_accuracy: 0.9282\n",
      "Epoch 2/100\n",
      "453/453 [==============================] - 0s 163us/step - loss: 0.0961 - accuracy: 0.9558 - val_loss: 0.2522 - val_accuracy: 0.9436\n",
      "Epoch 3/100\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.0932 - accuracy: 0.9536 - val_loss: 0.2661 - val_accuracy: 0.9231\n",
      "Epoch 4/100\n",
      "453/453 [==============================] - 0s 141us/step - loss: 0.0891 - accuracy: 0.9536 - val_loss: 0.2551 - val_accuracy: 0.9385\n",
      "Epoch 5/100\n",
      "453/453 [==============================] - 0s 151us/step - loss: 0.0872 - accuracy: 0.9647 - val_loss: 0.2750 - val_accuracy: 0.9385\n",
      "Epoch 6/100\n",
      "453/453 [==============================] - 0s 145us/step - loss: 0.0872 - accuracy: 0.9581 - val_loss: 0.2572 - val_accuracy: 0.9385\n",
      "Epoch 7/100\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.0888 - accuracy: 0.9625 - val_loss: 0.2587 - val_accuracy: 0.9538\n",
      "Epoch 8/100\n",
      "453/453 [==============================] - 0s 140us/step - loss: 0.0910 - accuracy: 0.9735 - val_loss: 0.2634 - val_accuracy: 0.9385\n",
      "Epoch 9/100\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.0835 - accuracy: 0.9669 - val_loss: 0.2765 - val_accuracy: 0.9385\n",
      "Epoch 10/100\n",
      "453/453 [==============================] - 0s 196us/step - loss: 0.0836 - accuracy: 0.9625 - val_loss: 0.2607 - val_accuracy: 0.9385\n",
      "Epoch 11/100\n",
      "453/453 [==============================] - 0s 192us/step - loss: 0.0844 - accuracy: 0.9757 - val_loss: 0.2742 - val_accuracy: 0.9282\n",
      "Epoch 12/100\n",
      "453/453 [==============================] - 0s 158us/step - loss: 0.0815 - accuracy: 0.9713 - val_loss: 0.2626 - val_accuracy: 0.9385\n",
      "Epoch 13/100\n",
      "453/453 [==============================] - 0s 144us/step - loss: 0.0832 - accuracy: 0.9581 - val_loss: 0.2571 - val_accuracy: 0.9385\n",
      "Epoch 14/100\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.0856 - accuracy: 0.9669 - val_loss: 0.2500 - val_accuracy: 0.9436\n",
      "Epoch 15/100\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.0821 - accuracy: 0.9647 - val_loss: 0.2864 - val_accuracy: 0.9333\n",
      "Epoch 16/100\n",
      "453/453 [==============================] - 0s 145us/step - loss: 0.0869 - accuracy: 0.9603 - val_loss: 0.2588 - val_accuracy: 0.9436\n",
      "Epoch 17/100\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.0813 - accuracy: 0.9691 - val_loss: 0.2666 - val_accuracy: 0.9436\n",
      "Epoch 18/100\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.0805 - accuracy: 0.9713 - val_loss: 0.2723 - val_accuracy: 0.9436\n",
      "Epoch 19/100\n",
      "453/453 [==============================] - 0s 208us/step - loss: 0.0780 - accuracy: 0.9691 - val_loss: 0.2575 - val_accuracy: 0.9487\n",
      "Epoch 20/100\n",
      "453/453 [==============================] - 0s 259us/step - loss: 0.0759 - accuracy: 0.9779 - val_loss: 0.2631 - val_accuracy: 0.9436\n",
      "Epoch 21/100\n",
      "453/453 [==============================] - 0s 182us/step - loss: 0.0754 - accuracy: 0.9691 - val_loss: 0.2609 - val_accuracy: 0.9436\n",
      "Epoch 22/100\n",
      "453/453 [==============================] - 0s 222us/step - loss: 0.0752 - accuracy: 0.9647 - val_loss: 0.2645 - val_accuracy: 0.9436\n",
      "Epoch 23/100\n",
      "453/453 [==============================] - ETA: 0s - loss: 0.0753 - accuracy: 0.97 - 0s 346us/step - loss: 0.0757 - accuracy: 0.9713 - val_loss: 0.2580 - val_accuracy: 0.9487\n",
      "Epoch 24/100\n",
      "453/453 [==============================] - 0s 366us/step - loss: 0.0723 - accuracy: 0.9823 - val_loss: 0.2870 - val_accuracy: 0.9385\n",
      "Epoch 25/100\n",
      "453/453 [==============================] - 0s 490us/step - loss: 0.0738 - accuracy: 0.9691 - val_loss: 0.2608 - val_accuracy: 0.9487\n",
      "Epoch 26/100\n",
      "453/453 [==============================] - 0s 140us/step - loss: 0.0745 - accuracy: 0.9691 - val_loss: 0.2737 - val_accuracy: 0.9333\n",
      "Epoch 27/100\n",
      "453/453 [==============================] - 0s 337us/step - loss: 0.0704 - accuracy: 0.9735 - val_loss: 0.2602 - val_accuracy: 0.9538\n",
      "Epoch 28/100\n",
      "453/453 [==============================] - 0s 211us/step - loss: 0.0729 - accuracy: 0.9823 - val_loss: 0.2989 - val_accuracy: 0.9128\n",
      "Epoch 29/100\n",
      "453/453 [==============================] - 0s 156us/step - loss: 0.0747 - accuracy: 0.9691 - val_loss: 0.2739 - val_accuracy: 0.9436\n",
      "Epoch 30/100\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.0735 - accuracy: 0.9757 - val_loss: 0.2783 - val_accuracy: 0.9333\n",
      "Epoch 31/100\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2093 - accuracy: 0.9536 - val_loss: 0.2719 - val_accuracy: 0.9385\n",
      "Epoch 32/100\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.1361 - accuracy: 0.9603 - val_loss: 0.2766 - val_accuracy: 0.9385\n",
      "Epoch 33/100\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.0767 - accuracy: 0.9691 - val_loss: 0.2934 - val_accuracy: 0.9282\n",
      "Epoch 34/100\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.0711 - accuracy: 0.9735 - val_loss: 0.2839 - val_accuracy: 0.9385\n",
      "Epoch 35/100\n",
      "453/453 [==============================] - 0s 385us/step - loss: 0.0756 - accuracy: 0.9713 - val_loss: 0.2803 - val_accuracy: 0.9487\n",
      "Epoch 36/100\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.0710 - accuracy: 0.9757 - val_loss: 0.2681 - val_accuracy: 0.9487\n",
      "Epoch 37/100\n",
      "453/453 [==============================] - 0s 528us/step - loss: 0.0681 - accuracy: 0.9713 - val_loss: 0.2725 - val_accuracy: 0.9436\n",
      "Epoch 38/100\n",
      "453/453 [==============================] - 0s 172us/step - loss: 0.0714 - accuracy: 0.9735 - val_loss: 0.2882 - val_accuracy: 0.9385\n",
      "Epoch 39/100\n",
      "453/453 [==============================] - 0s 251us/step - loss: 0.0666 - accuracy: 0.9757 - val_loss: 0.2705 - val_accuracy: 0.9436\n",
      "Epoch 40/100\n",
      "453/453 [==============================] - 0s 180us/step - loss: 0.0678 - accuracy: 0.9845 - val_loss: 0.2976 - val_accuracy: 0.9487\n",
      "Epoch 41/100\n",
      "453/453 [==============================] - 0s 202us/step - loss: 0.0688 - accuracy: 0.9691 - val_loss: 0.2676 - val_accuracy: 0.9538\n",
      "Epoch 42/100\n",
      "453/453 [==============================] - 0s 200us/step - loss: 0.0688 - accuracy: 0.9669 - val_loss: 0.2698 - val_accuracy: 0.9538\n",
      "Epoch 43/100\n",
      "453/453 [==============================] - 0s 222us/step - loss: 0.0689 - accuracy: 0.9757 - val_loss: 0.2832 - val_accuracy: 0.9487\n",
      "Epoch 44/100\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.0663 - accuracy: 0.9647 - val_loss: 0.2664 - val_accuracy: 0.9487\n",
      "Epoch 45/100\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.0638 - accuracy: 0.9735 - val_loss: 0.2778 - val_accuracy: 0.9385\n",
      "Epoch 46/100\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.0621 - accuracy: 0.9779 - val_loss: 0.2719 - val_accuracy: 0.9487\n",
      "Epoch 47/100\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.0638 - accuracy: 0.9757 - val_loss: 0.2665 - val_accuracy: 0.9538\n",
      "Epoch 48/100\n",
      "453/453 [==============================] - 0s 200us/step - loss: 0.0639 - accuracy: 0.9669 - val_loss: 0.2819 - val_accuracy: 0.9385\n",
      "Epoch 49/100\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.0636 - accuracy: 0.9735 - val_loss: 0.2858 - val_accuracy: 0.9385\n",
      "Epoch 50/100\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.0660 - accuracy: 0.9647 - val_loss: 0.2595 - val_accuracy: 0.9590\n",
      "Epoch 51/100\n",
      "453/453 [==============================] - 0s 220us/step - loss: 0.0660 - accuracy: 0.9713 - val_loss: 0.2689 - val_accuracy: 0.9436\n",
      "Epoch 52/100\n",
      "453/453 [==============================] - 0s 141us/step - loss: 0.0610 - accuracy: 0.9779 - val_loss: 0.2765 - val_accuracy: 0.9436\n",
      "Epoch 53/100\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.0592 - accuracy: 0.9691 - val_loss: 0.2770 - val_accuracy: 0.9436\n",
      "Epoch 54/100\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.0594 - accuracy: 0.9801 - val_loss: 0.2933 - val_accuracy: 0.9385\n",
      "Epoch 55/100\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.0608 - accuracy: 0.9691 - val_loss: 0.2617 - val_accuracy: 0.9538\n",
      "Epoch 56/100\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.0609 - accuracy: 0.9801 - val_loss: 0.2865 - val_accuracy: 0.9385\n",
      "Epoch 57/100\n",
      "453/453 [==============================] - 0s 138us/step - loss: 0.0617 - accuracy: 0.9691 - val_loss: 0.2796 - val_accuracy: 0.9487\n",
      "Epoch 58/100\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.0590 - accuracy: 0.9757 - val_loss: 0.2965 - val_accuracy: 0.9385\n",
      "Epoch 59/100\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.0590 - accuracy: 0.9779 - val_loss: 0.2755 - val_accuracy: 0.9487\n",
      "Epoch 60/100\n",
      "453/453 [==============================] - 0s 163us/step - loss: 0.0611 - accuracy: 0.9757 - val_loss: 0.2761 - val_accuracy: 0.9436\n",
      "Epoch 61/100\n",
      "453/453 [==============================] - 0s 171us/step - loss: 0.0595 - accuracy: 0.9691 - val_loss: 0.2719 - val_accuracy: 0.9538\n",
      "Epoch 62/100\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.0576 - accuracy: 0.9757 - val_loss: 0.2683 - val_accuracy: 0.9590\n",
      "Epoch 63/100\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.0586 - accuracy: 0.9823 - val_loss: 0.2804 - val_accuracy: 0.9487\n",
      "Epoch 64/100\n",
      "453/453 [==============================] - 0s 192us/step - loss: 0.1226 - accuracy: 0.9647 - val_loss: 0.5220 - val_accuracy: 0.8974\n",
      "Epoch 65/100\n",
      "453/453 [==============================] - 0s 199us/step - loss: 0.1652 - accuracy: 0.9492 - val_loss: 0.6030 - val_accuracy: 0.9077\n",
      "Epoch 66/100\n",
      "453/453 [==============================] - 0s 147us/step - loss: 0.1236 - accuracy: 0.9669 - val_loss: 0.4498 - val_accuracy: 0.9077\n",
      "Epoch 67/100\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.1318 - accuracy: 0.9625 - val_loss: 0.3427 - val_accuracy: 0.9128\n",
      "Epoch 68/100\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2553 - accuracy: 0.9514 - val_loss: 0.4929 - val_accuracy: 0.8923\n",
      "Epoch 69/100\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.3177 - accuracy: 0.9338 - val_loss: 0.9450 - val_accuracy: 0.8923\n",
      "Epoch 70/100\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2090 - accuracy: 0.9448 - val_loss: 0.4089 - val_accuracy: 0.9026\n",
      "Epoch 71/100\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.1422 - accuracy: 0.9426 - val_loss: 0.3122 - val_accuracy: 0.9436\n",
      "Epoch 72/100\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.1097 - accuracy: 0.9581 - val_loss: 0.3082 - val_accuracy: 0.9385\n",
      "Epoch 73/100\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2006 - accuracy: 0.9360 - val_loss: 0.3445 - val_accuracy: 0.9385\n",
      "Epoch 74/100\n",
      "453/453 [==============================] - 0s 99us/step - loss: 0.0785 - accuracy: 0.9603 - val_loss: 0.2809 - val_accuracy: 0.9333\n",
      "Epoch 75/100\n",
      "453/453 [==============================] - 0s 208us/step - loss: 0.1108 - accuracy: 0.9581 - val_loss: 0.3568 - val_accuracy: 0.9282\n",
      "Epoch 76/100\n",
      "453/453 [==============================] - 0s 185us/step - loss: 0.0658 - accuracy: 0.9713 - val_loss: 0.2908 - val_accuracy: 0.9487\n",
      "Epoch 77/100\n",
      "453/453 [==============================] - 0s 134us/step - loss: 0.0569 - accuracy: 0.9823 - val_loss: 0.2923 - val_accuracy: 0.9487\n",
      "Epoch 78/100\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.0539 - accuracy: 0.9801 - val_loss: 0.2741 - val_accuracy: 0.9487\n",
      "Epoch 79/100\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.0550 - accuracy: 0.9713 - val_loss: 0.2870 - val_accuracy: 0.9436\n",
      "Epoch 80/100\n",
      "453/453 [==============================] - 0s 159us/step - loss: 0.0521 - accuracy: 0.9845 - val_loss: 0.2800 - val_accuracy: 0.9487\n",
      "Epoch 81/100\n",
      "453/453 [==============================] - 0s 275us/step - loss: 0.0511 - accuracy: 0.9801 - val_loss: 0.2917 - val_accuracy: 0.9436\n",
      "Epoch 82/100\n",
      "453/453 [==============================] - 0s 288us/step - loss: 0.0515 - accuracy: 0.9801 - val_loss: 0.2816 - val_accuracy: 0.9487\n",
      "Epoch 83/100\n",
      "453/453 [==============================] - 0s 230us/step - loss: 0.0501 - accuracy: 0.9823 - val_loss: 0.2876 - val_accuracy: 0.9436\n",
      "Epoch 84/100\n",
      "453/453 [==============================] - 0s 231us/step - loss: 0.0522 - accuracy: 0.9779 - val_loss: 0.2743 - val_accuracy: 0.9538\n",
      "Epoch 85/100\n",
      "453/453 [==============================] - 0s 180us/step - loss: 0.0528 - accuracy: 0.9845 - val_loss: 0.2896 - val_accuracy: 0.9436\n",
      "Epoch 86/100\n",
      "453/453 [==============================] - 0s 232us/step - loss: 0.0509 - accuracy: 0.9823 - val_loss: 0.2900 - val_accuracy: 0.9487\n",
      "Epoch 87/100\n",
      "453/453 [==============================] - 0s 181us/step - loss: 0.0492 - accuracy: 0.9845 - val_loss: 0.2843 - val_accuracy: 0.9436\n",
      "Epoch 88/100\n",
      "453/453 [==============================] - 0s 259us/step - loss: 0.0508 - accuracy: 0.9801 - val_loss: 0.2976 - val_accuracy: 0.9385\n",
      "Epoch 89/100\n",
      "453/453 [==============================] - 0s 230us/step - loss: 0.0493 - accuracy: 0.9779 - val_loss: 0.2868 - val_accuracy: 0.9538\n",
      "Epoch 90/100\n",
      "453/453 [==============================] - 0s 179us/step - loss: 0.0492 - accuracy: 0.9823 - val_loss: 0.2941 - val_accuracy: 0.9436\n",
      "Epoch 91/100\n",
      "453/453 [==============================] - 0s 367us/step - loss: 0.0500 - accuracy: 0.9779 - val_loss: 0.2915 - val_accuracy: 0.9385\n",
      "Epoch 92/100\n",
      "453/453 [==============================] - 0s 208us/step - loss: 0.0476 - accuracy: 0.9801 - val_loss: 0.2783 - val_accuracy: 0.9538\n",
      "Epoch 93/100\n",
      "453/453 [==============================] - 0s 187us/step - loss: 0.0491 - accuracy: 0.9801 - val_loss: 0.2890 - val_accuracy: 0.9436\n",
      "Epoch 94/100\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.0481 - accuracy: 0.9779 - val_loss: 0.2834 - val_accuracy: 0.9538\n",
      "Epoch 95/100\n",
      "453/453 [==============================] - 0s 264us/step - loss: 0.0483 - accuracy: 0.9845 - val_loss: 0.2989 - val_accuracy: 0.9385\n",
      "Epoch 96/100\n",
      "453/453 [==============================] - 0s 169us/step - loss: 0.0481 - accuracy: 0.9801 - val_loss: 0.2860 - val_accuracy: 0.9487\n",
      "Epoch 97/100\n",
      "453/453 [==============================] - 0s 179us/step - loss: 0.0504 - accuracy: 0.9801 - val_loss: 0.2975 - val_accuracy: 0.9538\n",
      "Epoch 98/100\n",
      "453/453 [==============================] - 0s 164us/step - loss: 0.0502 - accuracy: 0.9801 - val_loss: 0.2778 - val_accuracy: 0.9590\n",
      "Epoch 99/100\n",
      "453/453 [==============================] - 0s 198us/step - loss: 0.0526 - accuracy: 0.9823 - val_loss: 0.3018 - val_accuracy: 0.9436\n",
      "Epoch 100/100\n",
      "453/453 [==============================] - 0s 337us/step - loss: 0.0497 - accuracy: 0.9801 - val_loss: 0.3104 - val_accuracy: 0.9385\n"
     ]
    }
   ],
   "source": [
    "hist1_over = model1_over.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 97.05%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_2.xlsx\",\n",
    "                        sheet_name=0,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>CFBRSa26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.758914</td>\n",
       "      <td>0.241086</td>\n",
       "      <td>4.638713e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.005361</td>\n",
       "      <td>0.016236</td>\n",
       "      <td>9.784034e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS112</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.726623</td>\n",
       "      <td>0.273376</td>\n",
       "      <td>1.520979e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS216</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.138322</td>\n",
       "      <td>0.861665</td>\n",
       "      <td>1.334123e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS021</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.882176</td>\n",
       "      <td>0.117824</td>\n",
       "      <td>1.414530e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4279</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>9.998934e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4280</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.002048</td>\n",
       "      <td>9.976944e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4281</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS205</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>9.999435e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4282</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.002048</td>\n",
       "      <td>9.976944e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4283</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.000929</td>\n",
       "      <td>9.989737e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4284 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    phage    strain  phenotype  prediction         0  \\\n",
       "0      p002ykpresabs_qual  CFBRSa26          0           0  0.758914   \n",
       "1      p002ykpresabs_qual    NRS109          2           2  0.005361   \n",
       "2      p002ykpresabs_qual    NRS112          0           0  0.726623   \n",
       "3      p002ykpresabs_qual    NRS216          1           1  0.138322   \n",
       "4      p002ykpresabs_qual    NRS021          0           0  0.882176   \n",
       "...                   ...       ...        ...         ...       ...   \n",
       "4279  pyopresabsSTCC_qual    NRS148          2           2  0.000007   \n",
       "4280  pyopresabsSTCC_qual    NRS255          2           2  0.000257   \n",
       "4281  pyopresabsSTCC_qual    NRS205          2           2  0.000011   \n",
       "4282  pyopresabsSTCC_qual    NRS255          2           2  0.000257   \n",
       "4283  pyopresabsSTCC_qual    NRS109          2           2  0.000097   \n",
       "\n",
       "             1             2  \n",
       "0     0.241086  4.638713e-07  \n",
       "1     0.016236  9.784034e-01  \n",
       "2     0.273376  1.520979e-06  \n",
       "3     0.861665  1.334123e-05  \n",
       "4     0.117824  1.414530e-10  \n",
       "...        ...           ...  \n",
       "4279  0.000099  9.998934e-01  \n",
       "4280  0.002048  9.976944e-01  \n",
       "4281  0.000045  9.999435e-01  \n",
       "4282  0.002048  9.976944e-01  \n",
       "4283  0.000929  9.989737e-01  \n",
       "\n",
       "[4284 rows x 7 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.51738400e-02, 9.14431630e-01, 3.94469160e-04],\n",
       "       [9.99988800e-01, 1.12411320e-05, 4.95443000e-09],\n",
       "       [8.76250500e-02, 9.12372200e-01, 2.74106950e-06],\n",
       "       [3.27129750e-01, 6.72864500e-01, 5.65825940e-06],\n",
       "       [7.13185600e-04, 5.00711500e-03, 9.94279740e-01],\n",
       "       [8.51738400e-02, 9.14431630e-01, 3.94469160e-04],\n",
       "       [1.30223260e-06, 9.99764740e-01, 2.33929780e-04],\n",
       "       [5.22255660e-01, 4.36461660e-01, 4.12826900e-02],\n",
       "       [9.99995470e-01, 4.52827770e-06, 1.33635090e-08],\n",
       "       [9.99942540e-01, 5.74940820e-05, 4.88934300e-09],\n",
       "       [6.45482540e-02, 9.35451600e-01, 1.31027520e-07],\n",
       "       [4.06707260e-04, 9.99201600e-01, 3.91805630e-04],\n",
       "       [9.99709550e-01, 2.90217780e-04, 2.59826800e-07],\n",
       "       [9.99980570e-01, 1.94701020e-05, 4.08222340e-09],\n",
       "       [9.99605600e-01, 3.94359400e-04, 1.53632670e-07],\n",
       "       [9.99742700e-01, 2.57298930e-04, 5.37725670e-08],\n",
       "       [7.13185600e-04, 5.00711500e-03, 9.94279740e-01],\n",
       "       [9.99986300e-01, 1.37253830e-05, 1.94603840e-08],\n",
       "       [3.73997700e-04, 9.99566850e-01, 5.90929500e-05],\n",
       "       [8.89436000e-04, 4.44030600e-04, 9.98666500e-01],\n",
       "       [7.19801300e-02, 9.27943770e-01, 7.60633700e-05],\n",
       "       [4.25945520e-01, 5.63181160e-01, 1.08732760e-02],\n",
       "       [8.89436000e-04, 4.44030600e-04, 9.98666500e-01],\n",
       "       [1.76361250e-01, 8.23601070e-01, 3.76862770e-05],\n",
       "       [8.51738400e-02, 9.14431630e-01, 3.94469160e-04],\n",
       "       [1.18634710e-03, 9.98735500e-01, 7.81923500e-05],\n",
       "       [9.95182100e-01, 4.81550070e-03, 2.34722980e-06],\n",
       "       [9.99990800e-01, 9.13840200e-06, 2.21801320e-08],\n",
       "       [9.92618600e-01, 7.37903700e-03, 2.31667470e-06],\n",
       "       [9.99709550e-01, 2.90217780e-04, 2.59826800e-07],\n",
       "       [7.13185600e-04, 5.00711500e-03, 9.94279740e-01],\n",
       "       [1.76361250e-01, 8.23601070e-01, 3.76862770e-05],\n",
       "       [8.89436000e-04, 4.44030600e-04, 9.98666500e-01],\n",
       "       [8.89436000e-04, 4.44030600e-04, 9.98666500e-01],\n",
       "       [1.17387190e-02, 9.88256160e-01, 5.05424940e-06],\n",
       "       [9.99999760e-01, 2.66683200e-07, 3.85611180e-10],\n",
       "       [9.52825500e-01, 4.71161050e-02, 5.83907600e-05],\n",
       "       [7.64633000e-02, 9.21103200e-01, 2.43363550e-03],\n",
       "       [6.49133440e-01, 3.50799650e-01, 6.69288300e-05],\n",
       "       [7.19801300e-02, 9.27943770e-01, 7.60633700e-05],\n",
       "       [1.30223260e-06, 9.99764740e-01, 2.33929780e-04],\n",
       "       [1.09904780e-01, 8.89851870e-01, 2.43350500e-04],\n",
       "       [9.99999640e-01, 3.81277720e-07, 4.29521100e-10],\n",
       "       [2.27616800e-01, 7.72305400e-01, 7.77845400e-05],\n",
       "       [8.76250500e-02, 9.12372200e-01, 2.74106950e-06],\n",
       "       [9.77457500e-01, 2.25380660e-02, 4.39190000e-06],\n",
       "       [8.89436000e-04, 4.44030600e-04, 9.98666500e-01],\n",
       "       [9.46629760e-01, 5.32988570e-02, 7.13394000e-05],\n",
       "       [9.90047500e-01, 9.54997500e-03, 4.02562350e-04],\n",
       "       [1.26392440e-01, 8.73055900e-01, 5.51668300e-04],\n",
       "       [1.76361250e-01, 8.23601070e-01, 3.76862770e-05],\n",
       "       [1.00000000e+00, 5.04064670e-08, 7.04489030e-12],\n",
       "       [3.77789400e-02, 9.62201900e-01, 1.91126220e-05],\n",
       "       [4.85410100e-03, 9.95042800e-01, 1.03031660e-04],\n",
       "       [9.97483100e-01, 2.51572970e-03, 1.24580770e-06],\n",
       "       [7.13185600e-04, 5.00711500e-03, 9.94279740e-01],\n",
       "       [8.07820200e-01, 1.92133440e-01, 4.62889770e-05],\n",
       "       [6.52560600e-03, 9.93429960e-01, 4.43890350e-05],\n",
       "       [8.89436000e-04, 4.44030600e-04, 9.98666500e-01],\n",
       "       [7.13185600e-04, 5.00711500e-03, 9.94279740e-01],\n",
       "       [8.89436000e-04, 4.44030600e-04, 9.98666500e-01],\n",
       "       [9.98584750e-01, 1.40802660e-03, 7.24488650e-06],\n",
       "       [9.99999400e-01, 5.02260400e-07, 9.87883840e-08],\n",
       "       [9.33482600e-01, 6.64967400e-02, 2.06696170e-05],\n",
       "       [4.06707260e-04, 9.99201600e-01, 3.91805630e-04],\n",
       "       [4.52209560e-01, 5.47672150e-01, 1.18364310e-04],\n",
       "       [9.98220600e-01, 1.77907680e-03, 2.60453500e-07],\n",
       "       [4.98609000e-01, 4.62371500e-01, 3.90194730e-02],\n",
       "       [8.51738400e-02, 9.14431630e-01, 3.94469160e-04],\n",
       "       [7.23686740e-02, 9.27249500e-01, 3.81931050e-04],\n",
       "       [7.13185600e-04, 5.00711500e-03, 9.94279740e-01],\n",
       "       [7.13185600e-04, 5.00711500e-03, 9.94279740e-01],\n",
       "       [4.10649000e-01, 5.89340030e-01, 1.08645680e-05],\n",
       "       [7.13185600e-04, 5.00711500e-03, 9.94279740e-01],\n",
       "       [7.13185600e-04, 5.00711500e-03, 9.94279740e-01],\n",
       "       [9.85105300e-01, 1.48034060e-02, 9.11874740e-05],\n",
       "       [9.22961100e-01, 7.69516160e-02, 8.72151900e-05],\n",
       "       [9.43355140e-01, 5.66317600e-02, 1.31485670e-05],\n",
       "       [1.30223260e-06, 9.99764740e-01, 2.33929780e-04],\n",
       "       [6.49133440e-01, 3.50799650e-01, 6.69288300e-05],\n",
       "       [9.96426500e-01, 3.57227630e-03, 1.22122550e-06],\n",
       "       [1.17095076e-01, 8.81730260e-01, 1.17461020e-03],\n",
       "       [8.89436000e-04, 4.44030600e-04, 9.98666500e-01],\n",
       "       [8.89436000e-04, 4.44030600e-04, 9.98666500e-01],\n",
       "       [9.99997140e-01, 2.73580490e-06, 6.25171600e-08],\n",
       "       [9.28809500e-01, 7.11888300e-02, 1.70773580e-06],\n",
       "       [9.25196950e-01, 7.48023500e-02, 7.77753100e-07],\n",
       "       [8.89436000e-04, 4.44030600e-04, 9.98666500e-01],\n",
       "       [3.46297700e-02, 9.65175450e-01, 1.94800900e-04],\n",
       "       [7.13185600e-04, 5.00711500e-03, 9.94279740e-01],\n",
       "       [1.26392440e-01, 8.73055900e-01, 5.51668300e-04],\n",
       "       [7.13185600e-04, 5.00711500e-03, 9.94279740e-01],\n",
       "       [7.13185600e-04, 5.00711500e-03, 9.94279740e-01],\n",
       "       [8.89436000e-04, 4.44030600e-04, 9.98666500e-01],\n",
       "       [8.89436000e-04, 4.44030600e-04, 9.98666500e-01],\n",
       "       [7.13185600e-04, 5.00711500e-03, 9.94279740e-01],\n",
       "       [9.97866450e-01, 2.13312730e-03, 4.89137560e-07],\n",
       "       [9.99983550e-01, 1.64900450e-05, 4.49323740e-08],\n",
       "       [9.99999900e-01, 1.47079550e-07, 1.13306850e-11],\n",
       "       [8.89436000e-04, 4.44030600e-04, 9.98666500e-01],\n",
       "       [8.89436000e-04, 4.44030600e-04, 9.98666500e-01],\n",
       "       [9.99974850e-01, 2.45831920e-05, 6.21883900e-07],\n",
       "       [7.13185600e-04, 5.00711500e-03, 9.94279740e-01],\n",
       "       [7.64633000e-02, 9.21103200e-01, 2.43363550e-03],\n",
       "       [6.31732640e-01, 3.68216250e-01, 5.11448230e-05],\n",
       "       [1.30223260e-06, 9.99764740e-01, 2.33929780e-04],\n",
       "       [9.98329700e-01, 1.66974670e-03, 5.37487550e-07],\n",
       "       [8.89436000e-04, 4.44030600e-04, 9.98666500e-01],\n",
       "       [3.46297700e-02, 9.65175450e-01, 1.94800900e-04],\n",
       "       [8.89436000e-04, 4.44030600e-04, 9.98666500e-01],\n",
       "       [7.13185600e-04, 5.00711500e-03, 9.94279740e-01],\n",
       "       [8.76250500e-02, 9.12372200e-01, 2.74106950e-06],\n",
       "       [8.51738400e-02, 9.14431630e-01, 3.94469160e-04],\n",
       "       [8.76250500e-02, 9.12372200e-01, 2.74106950e-06],\n",
       "       [1.76361250e-01, 8.23601070e-01, 3.76862770e-05],\n",
       "       [7.13185600e-04, 5.00711500e-03, 9.94279740e-01],\n",
       "       [7.13185600e-04, 5.00711500e-03, 9.94279740e-01],\n",
       "       [8.89436000e-04, 4.44030600e-04, 9.98666500e-01],\n",
       "       [7.36747160e-02, 9.26224300e-01, 1.00907910e-04],\n",
       "       [9.43832100e-01, 5.61666700e-02, 1.24104010e-06],\n",
       "       [7.13185600e-04, 5.00711500e-03, 9.94279740e-01],\n",
       "       [4.52209560e-01, 5.47672150e-01, 1.18364310e-04],\n",
       "       [7.19801300e-02, 9.27943770e-01, 7.60633700e-05],\n",
       "       [8.89436000e-04, 4.44030600e-04, 9.98666500e-01],\n",
       "       [9.17969600e-01, 8.12603000e-02, 7.70208600e-04],\n",
       "       [9.89017840e-01, 9.73286200e-03, 1.24928330e-03],\n",
       "       [4.52209560e-01, 5.47672150e-01, 1.18364310e-04],\n",
       "       [9.81206000e-01, 1.87702920e-02, 2.35903430e-05],\n",
       "       [9.92411550e-01, 7.58789060e-03, 4.58259020e-07],\n",
       "       [8.89436000e-04, 4.44030600e-04, 9.98666500e-01],\n",
       "       [8.47518100e-01, 1.52480940e-01, 8.92058670e-07],\n",
       "       [8.89436000e-04, 4.44030600e-04, 9.98666500e-01],\n",
       "       [8.48649740e-01, 1.51319380e-01, 3.08660930e-05],\n",
       "       [6.28529600e-01, 3.67999370e-01, 3.47105480e-03],\n",
       "       [9.93839440e-01, 5.89660040e-03, 2.63992840e-04],\n",
       "       [8.89436000e-04, 4.44030600e-04, 9.98666500e-01],\n",
       "       [7.13185600e-04, 5.00711500e-03, 9.94279740e-01],\n",
       "       [6.38057800e-01, 3.61748340e-01, 1.93868570e-04],\n",
       "       [8.89436000e-04, 4.44030600e-04, 9.98666500e-01],\n",
       "       [1.25719225e-02, 9.86983400e-01, 4.44685630e-04],\n",
       "       [9.71177500e-01, 2.88034960e-02, 1.89928630e-05],\n",
       "       [8.43985900e-02, 8.57537570e-01, 5.80638600e-02],\n",
       "       [8.89436000e-04, 4.44030600e-04, 9.98666500e-01],\n",
       "       [1.25719225e-02, 9.86983400e-01, 4.44685630e-04],\n",
       "       [4.91739200e-01, 5.06815300e-01, 1.44556300e-03],\n",
       "       [7.13185600e-04, 5.00711500e-03, 9.94279740e-01],\n",
       "       [7.13185600e-04, 5.00711500e-03, 9.94279740e-01],\n",
       "       [7.13185600e-04, 5.00711500e-03, 9.94279740e-01],\n",
       "       [8.89436000e-04, 4.44030600e-04, 9.98666500e-01],\n",
       "       [8.89436000e-04, 4.44030600e-04, 9.98666500e-01],\n",
       "       [7.13185600e-04, 5.00711500e-03, 9.94279740e-01],\n",
       "       [4.06707260e-04, 9.99201600e-01, 3.91805630e-04],\n",
       "       [3.11353150e-01, 5.81771900e-01, 1.06874960e-01],\n",
       "       [1.30223260e-06, 9.99764740e-01, 2.33929780e-04],\n",
       "       [4.25621700e-02, 9.57139850e-01, 2.98072670e-04],\n",
       "       [3.77789400e-02, 9.62201900e-01, 1.91126220e-05],\n",
       "       [8.51738400e-02, 9.14431630e-01, 3.94469160e-04],\n",
       "       [4.10649000e-01, 5.89340030e-01, 1.08645680e-05],\n",
       "       [3.19434400e-03, 9.96800400e-01, 5.23695000e-06],\n",
       "       [8.13802060e-01, 1.86164160e-01, 3.37688250e-05],\n",
       "       [6.52560600e-03, 9.93429960e-01, 4.43890350e-05],\n",
       "       [9.98372500e-01, 1.62646920e-03, 1.05348920e-06],\n",
       "       [1.17387190e-02, 9.88256160e-01, 5.05424940e-06],\n",
       "       [7.13185600e-04, 5.00711500e-03, 9.94279740e-01],\n",
       "       [9.99591900e-01, 4.07981630e-04, 8.06759960e-08],\n",
       "       [8.89436000e-04, 4.44030600e-04, 9.98666500e-01],\n",
       "       [1.04855460e-01, 8.91790030e-01, 3.35453780e-03],\n",
       "       [8.89436000e-04, 4.44030600e-04, 9.98666500e-01],\n",
       "       [7.13185600e-04, 5.00711500e-03, 9.94279740e-01],\n",
       "       [7.13185600e-04, 5.00711500e-03, 9.94279740e-01],\n",
       "       [3.27129750e-01, 6.72864500e-01, 5.65825940e-06],\n",
       "       [4.06707260e-04, 9.99201600e-01, 3.91805630e-04],\n",
       "       [8.89436000e-04, 4.44030600e-04, 9.98666500e-01],\n",
       "       [3.77789400e-02, 9.62201900e-01, 1.91126220e-05],\n",
       "       [8.69913760e-01, 1.30049510e-01, 3.67326940e-05],\n",
       "       [8.89436000e-04, 4.44030600e-04, 9.98666500e-01],\n",
       "       [4.10649000e-01, 5.89340030e-01, 1.08645680e-05],\n",
       "       [8.89436000e-04, 4.44030600e-04, 9.98666500e-01],\n",
       "       [8.89436000e-04, 4.44030600e-04, 9.98666500e-01],\n",
       "       [1.26392440e-01, 8.73055900e-01, 5.51668300e-04],\n",
       "       [7.13185600e-04, 5.00711500e-03, 9.94279740e-01],\n",
       "       [3.46297700e-02, 9.65175450e-01, 1.94800900e-04],\n",
       "       [9.99942800e-01, 5.69710500e-05, 2.40184700e-07],\n",
       "       [8.89436000e-04, 4.44030600e-04, 9.98666500e-01],\n",
       "       [7.13185600e-04, 5.00711500e-03, 9.94279740e-01],\n",
       "       [7.13185600e-04, 5.00711500e-03, 9.94279740e-01],\n",
       "       [8.89436000e-04, 4.44030600e-04, 9.98666500e-01],\n",
       "       [8.89436000e-04, 4.44030600e-04, 9.98666500e-01],\n",
       "       [1.04855460e-01, 8.91790030e-01, 3.35453780e-03],\n",
       "       [4.10649000e-01, 5.89340030e-01, 1.08645680e-05],\n",
       "       [7.13185600e-04, 5.00711500e-03, 9.94279740e-01],\n",
       "       [9.82150550e-01, 1.78411530e-02, 8.29340500e-06],\n",
       "       [3.46297700e-02, 9.65175450e-01, 1.94800900e-04],\n",
       "       [8.89436000e-04, 4.44030600e-04, 9.98666500e-01],\n",
       "       [1.17387190e-02, 9.88256160e-01, 5.05424940e-06]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob = df_proba[df_proba['phage']=='p0017SpresabsSTCC_qual'].iloc[:,-3:]\n",
    "y_prob = y_prob.to_numpy()\n",
    "y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Retrieved from https://github.com/scikit-learn/scikit-learn/issues/3298\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "def rocauc_ovo(truth, pred, average=\"macro\", multi_class=\"ovo\"):\n",
    "\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(truth)\n",
    "\n",
    "    truth = lb.transform(truth)   \n",
    "    \n",
    "    return roc_auc_score(truth, pred, average=average, multi_class=multi_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.973491124260355"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo1 = rocauc_ovo(y_test_over, y_prob, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rocauc_ovr(truth, pred, average=\"macro\", multi_class=\"ovr\"):\n",
    "\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(truth)\n",
    "\n",
    "    truth = lb.transform(truth)   \n",
    "\n",
    "    return roc_auc_score(truth, pred, average=average, multi_class=multi_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.973491124260355"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr1 = rocauc_ovr(y_test_over, y_prob, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=234,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat2 = pd.DataFrame(X_test_over[:,0])\n",
    "dat2['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS110</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS254</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BCH-SA-09</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS177</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GA27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>NRS001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>NRS272</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>NRS110</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>NRS204</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0  test\n",
       "0       NRS110     2\n",
       "1       NRS254     1\n",
       "2    BCH-SA-09     0\n",
       "3       NRS177     0\n",
       "4         GA27     1\n",
       "..         ...   ...\n",
       "190     NRS001     1\n",
       "191     NRS209     2\n",
       "192     NRS272     0\n",
       "193     NRS110     2\n",
       "194     NRS204     0\n",
       "\n",
       "[195 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over2 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],)),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over2.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 453 samples, validate on 195 samples\n",
      "Epoch 1/100\n",
      "453/453 [==============================] - 0s 412us/step - loss: 3.7170 - accuracy: 0.3664 - val_loss: 1.2922 - val_accuracy: 0.3590\n",
      "Epoch 2/100\n",
      "453/453 [==============================] - 0s 132us/step - loss: 1.2709 - accuracy: 0.5430 - val_loss: 1.0242 - val_accuracy: 0.5538\n",
      "Epoch 3/100\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.8559 - accuracy: 0.6380 - val_loss: 0.7750 - val_accuracy: 0.7231\n",
      "Epoch 4/100\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.7099 - accuracy: 0.7748 - val_loss: 0.5365 - val_accuracy: 0.8103\n",
      "Epoch 5/100\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.5296 - accuracy: 0.8035 - val_loss: 0.4708 - val_accuracy: 0.8205\n",
      "Epoch 6/100\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.4740 - accuracy: 0.8079 - val_loss: 0.4458 - val_accuracy: 0.8103\n",
      "Epoch 7/100\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.4974 - accuracy: 0.8168 - val_loss: 0.5535 - val_accuracy: 0.8154\n",
      "Epoch 8/100\n",
      "453/453 [==============================] - 0s 93us/step - loss: 0.4043 - accuracy: 0.8499 - val_loss: 0.3857 - val_accuracy: 0.8308\n",
      "Epoch 9/100\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.4321 - accuracy: 0.8411 - val_loss: 0.4071 - val_accuracy: 0.8462\n",
      "Epoch 10/100\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.4589 - accuracy: 0.8366 - val_loss: 0.3875 - val_accuracy: 0.8051\n",
      "Epoch 11/100\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.3812 - accuracy: 0.8411 - val_loss: 0.3563 - val_accuracy: 0.8667\n",
      "Epoch 12/100\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.3068 - accuracy: 0.8653 - val_loss: 0.3741 - val_accuracy: 0.8462\n",
      "Epoch 13/100\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.3018 - accuracy: 0.8896 - val_loss: 0.3383 - val_accuracy: 0.8872\n",
      "Epoch 14/100\n",
      "453/453 [==============================] - 0s 86us/step - loss: 0.3112 - accuracy: 0.8720 - val_loss: 0.3193 - val_accuracy: 0.9077\n",
      "Epoch 15/100\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2773 - accuracy: 0.9095 - val_loss: 0.3343 - val_accuracy: 0.8821\n",
      "Epoch 16/100\n",
      "453/453 [==============================] - 0s 86us/step - loss: 0.3105 - accuracy: 0.8852 - val_loss: 0.3049 - val_accuracy: 0.8821\n",
      "Epoch 17/100\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2936 - accuracy: 0.8808 - val_loss: 0.4142 - val_accuracy: 0.8667\n",
      "Epoch 18/100\n",
      "453/453 [==============================] - 0s 147us/step - loss: 0.3073 - accuracy: 0.8985 - val_loss: 0.3074 - val_accuracy: 0.8718\n",
      "Epoch 19/100\n",
      "453/453 [==============================] - 0s 94us/step - loss: 0.3414 - accuracy: 0.8874 - val_loss: 0.2959 - val_accuracy: 0.9077\n",
      "Epoch 20/100\n",
      "453/453 [==============================] - 0s 74us/step - loss: 0.2938 - accuracy: 0.9029 - val_loss: 0.2904 - val_accuracy: 0.8769\n",
      "Epoch 21/100\n",
      "453/453 [==============================] - 0s 78us/step - loss: 0.3678 - accuracy: 0.8455 - val_loss: 0.2916 - val_accuracy: 0.8923\n",
      "Epoch 22/100\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2570 - accuracy: 0.9007 - val_loss: 0.2904 - val_accuracy: 0.8923\n",
      "Epoch 23/100\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2309 - accuracy: 0.9205 - val_loss: 0.2993 - val_accuracy: 0.8769\n",
      "Epoch 24/100\n",
      "453/453 [==============================] - 0s 99us/step - loss: 0.2254 - accuracy: 0.9382 - val_loss: 0.2904 - val_accuracy: 0.8872\n",
      "Epoch 25/100\n",
      "453/453 [==============================] - 0s 152us/step - loss: 0.2192 - accuracy: 0.9316 - val_loss: 0.2705 - val_accuracy: 0.8974\n",
      "Epoch 26/100\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2167 - accuracy: 0.9316 - val_loss: 0.2679 - val_accuracy: 0.9077\n",
      "Epoch 27/100\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2415 - accuracy: 0.9205 - val_loss: 0.5108 - val_accuracy: 0.8564\n",
      "Epoch 28/100\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2745 - accuracy: 0.9095 - val_loss: 0.2721 - val_accuracy: 0.8974\n",
      "Epoch 29/100\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2114 - accuracy: 0.9227 - val_loss: 0.2804 - val_accuracy: 0.8872\n",
      "Epoch 30/100\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.2047 - accuracy: 0.9294 - val_loss: 0.2748 - val_accuracy: 0.8923\n",
      "Epoch 31/100\n",
      "453/453 [==============================] - 0s 77us/step - loss: 0.1984 - accuracy: 0.9316 - val_loss: 0.2582 - val_accuracy: 0.9077\n",
      "Epoch 32/100\n",
      "453/453 [==============================] - 0s 60us/step - loss: 0.2095 - accuracy: 0.9205 - val_loss: 0.2600 - val_accuracy: 0.8923\n",
      "Epoch 33/100\n",
      "453/453 [==============================] - 0s 64us/step - loss: 0.1911 - accuracy: 0.9426 - val_loss: 0.2610 - val_accuracy: 0.9026\n",
      "Epoch 34/100\n",
      "453/453 [==============================] - 0s 69us/step - loss: 0.1971 - accuracy: 0.9294 - val_loss: 0.2797 - val_accuracy: 0.8872\n",
      "Epoch 35/100\n",
      "453/453 [==============================] - 0s 74us/step - loss: 0.1851 - accuracy: 0.9470 - val_loss: 0.2624 - val_accuracy: 0.9026\n",
      "Epoch 36/100\n",
      "453/453 [==============================] - 0s 196us/step - loss: 0.1827 - accuracy: 0.9316 - val_loss: 0.2588 - val_accuracy: 0.8974\n",
      "Epoch 37/100\n",
      "453/453 [==============================] - 0s 172us/step - loss: 0.1779 - accuracy: 0.9448 - val_loss: 0.2561 - val_accuracy: 0.9231\n",
      "Epoch 38/100\n",
      "453/453 [==============================] - 0s 201us/step - loss: 0.1787 - accuracy: 0.9514 - val_loss: 0.2929 - val_accuracy: 0.8923\n",
      "Epoch 39/100\n",
      "453/453 [==============================] - 0s 161us/step - loss: 0.1918 - accuracy: 0.9294 - val_loss: 0.2506 - val_accuracy: 0.9128\n",
      "Epoch 40/100\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.1734 - accuracy: 0.9404 - val_loss: 0.2474 - val_accuracy: 0.9231\n",
      "Epoch 41/100\n",
      "453/453 [==============================] - 0s 177us/step - loss: 0.1734 - accuracy: 0.9536 - val_loss: 0.2486 - val_accuracy: 0.9231\n",
      "Epoch 42/100\n",
      "453/453 [==============================] - 0s 186us/step - loss: 0.1667 - accuracy: 0.9536 - val_loss: 0.3011 - val_accuracy: 0.8872\n",
      "Epoch 43/100\n",
      "453/453 [==============================] - 0s 172us/step - loss: 0.1762 - accuracy: 0.9404 - val_loss: 0.2782 - val_accuracy: 0.8872\n",
      "Epoch 44/100\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.1640 - accuracy: 0.9536 - val_loss: 0.2500 - val_accuracy: 0.9077\n",
      "Epoch 45/100\n",
      "453/453 [==============================] - 0s 146us/step - loss: 0.1622 - accuracy: 0.9581 - val_loss: 0.2422 - val_accuracy: 0.9231\n",
      "Epoch 46/100\n",
      "453/453 [==============================] - 0s 176us/step - loss: 0.1622 - accuracy: 0.9448 - val_loss: 0.2985 - val_accuracy: 0.8923\n",
      "Epoch 47/100\n",
      "453/453 [==============================] - 0s 181us/step - loss: 0.1637 - accuracy: 0.9404 - val_loss: 0.2615 - val_accuracy: 0.8974\n",
      "Epoch 48/100\n",
      "453/453 [==============================] - 0s 154us/step - loss: 0.1570 - accuracy: 0.9581 - val_loss: 0.2432 - val_accuracy: 0.9179\n",
      "Epoch 49/100\n",
      "453/453 [==============================] - 0s 159us/step - loss: 0.1546 - accuracy: 0.9581 - val_loss: 0.2532 - val_accuracy: 0.9077\n",
      "Epoch 50/100\n",
      "453/453 [==============================] - 0s 177us/step - loss: 0.1528 - accuracy: 0.9603 - val_loss: 0.2355 - val_accuracy: 0.9231\n",
      "Epoch 51/100\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.1498 - accuracy: 0.9581 - val_loss: 0.2546 - val_accuracy: 0.8974\n",
      "Epoch 52/100\n",
      "453/453 [==============================] - 0s 86us/step - loss: 0.1499 - accuracy: 0.9603 - val_loss: 0.2366 - val_accuracy: 0.9128\n",
      "Epoch 53/100\n",
      "453/453 [==============================] - 0s 89us/step - loss: 0.1475 - accuracy: 0.9581 - val_loss: 0.2424 - val_accuracy: 0.9128\n",
      "Epoch 54/100\n",
      "453/453 [==============================] - 0s 66us/step - loss: 0.1478 - accuracy: 0.9603 - val_loss: 0.2523 - val_accuracy: 0.9026\n",
      "Epoch 55/100\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.1433 - accuracy: 0.9514 - val_loss: 0.2295 - val_accuracy: 0.9333\n",
      "Epoch 56/100\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.1436 - accuracy: 0.9558 - val_loss: 0.2505 - val_accuracy: 0.8923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.1389 - accuracy: 0.9581 - val_loss: 0.2253 - val_accuracy: 0.9282\n",
      "Epoch 58/100\n",
      "453/453 [==============================] - 0s 181us/step - loss: 0.1597 - accuracy: 0.9404 - val_loss: 0.2379 - val_accuracy: 0.9077\n",
      "Epoch 59/100\n",
      "453/453 [==============================] - 0s 184us/step - loss: 0.1353 - accuracy: 0.9536 - val_loss: 0.2501 - val_accuracy: 0.8872\n",
      "Epoch 60/100\n",
      "453/453 [==============================] - 0s 191us/step - loss: 0.1375 - accuracy: 0.9492 - val_loss: 0.2255 - val_accuracy: 0.9282\n",
      "Epoch 61/100\n",
      "453/453 [==============================] - 0s 87us/step - loss: 0.1496 - accuracy: 0.9581 - val_loss: 0.2578 - val_accuracy: 0.8923\n",
      "Epoch 62/100\n",
      "453/453 [==============================] - 0s 90us/step - loss: 0.1344 - accuracy: 0.9625 - val_loss: 0.2369 - val_accuracy: 0.9128\n",
      "Epoch 63/100\n",
      "453/453 [==============================] - 0s 66us/step - loss: 0.1303 - accuracy: 0.9625 - val_loss: 0.2309 - val_accuracy: 0.9231\n",
      "Epoch 64/100\n",
      "453/453 [==============================] - 0s 68us/step - loss: 0.1345 - accuracy: 0.9558 - val_loss: 0.3253 - val_accuracy: 0.8872\n",
      "Epoch 65/100\n",
      "453/453 [==============================] - 0s 64us/step - loss: 0.2694 - accuracy: 0.9249 - val_loss: 0.5459 - val_accuracy: 0.8667\n",
      "Epoch 66/100\n",
      "453/453 [==============================] - 0s 64us/step - loss: 0.2978 - accuracy: 0.9095 - val_loss: 0.3955 - val_accuracy: 0.8769\n",
      "Epoch 67/100\n",
      "453/453 [==============================] - 0s 90us/step - loss: 1.2538 - accuracy: 0.8808 - val_loss: 0.8871 - val_accuracy: 0.8718\n",
      "Epoch 68/100\n",
      "453/453 [==============================] - 0s 66us/step - loss: 0.3514 - accuracy: 0.9073 - val_loss: 0.3674 - val_accuracy: 0.8923\n",
      "Epoch 69/100\n",
      "453/453 [==============================] - 0s 86us/step - loss: 0.2811 - accuracy: 0.9294 - val_loss: 0.2221 - val_accuracy: 0.9231\n",
      "Epoch 70/100\n",
      "453/453 [==============================] - 0s 64us/step - loss: 0.1449 - accuracy: 0.9338 - val_loss: 0.2260 - val_accuracy: 0.9333\n",
      "Epoch 71/100\n",
      "453/453 [==============================] - 0s 65us/step - loss: 0.1300 - accuracy: 0.9625 - val_loss: 0.2421 - val_accuracy: 0.9128\n",
      "Epoch 72/100\n",
      "453/453 [==============================] - 0s 96us/step - loss: 0.1255 - accuracy: 0.9625 - val_loss: 0.2254 - val_accuracy: 0.9179\n",
      "Epoch 73/100\n",
      "453/453 [==============================] - 0s 90us/step - loss: 0.1225 - accuracy: 0.9757 - val_loss: 0.2277 - val_accuracy: 0.9128\n",
      "Epoch 74/100\n",
      "453/453 [==============================] - 0s 96us/step - loss: 0.1238 - accuracy: 0.9536 - val_loss: 0.2271 - val_accuracy: 0.9231\n",
      "Epoch 75/100\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.1165 - accuracy: 0.9713 - val_loss: 0.2312 - val_accuracy: 0.9179\n",
      "Epoch 76/100\n",
      "453/453 [==============================] - 0s 88us/step - loss: 0.1178 - accuracy: 0.9581 - val_loss: 0.2337 - val_accuracy: 0.9128\n",
      "Epoch 77/100\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.1139 - accuracy: 0.9625 - val_loss: 0.2242 - val_accuracy: 0.9231\n",
      "Epoch 78/100\n",
      "453/453 [==============================] - 0s 85us/step - loss: 0.1121 - accuracy: 0.9713 - val_loss: 0.2389 - val_accuracy: 0.9179\n",
      "Epoch 79/100\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.1152 - accuracy: 0.9603 - val_loss: 0.2204 - val_accuracy: 0.9231\n",
      "Epoch 80/100\n",
      "453/453 [==============================] - 0s 88us/step - loss: 0.1088 - accuracy: 0.9713 - val_loss: 0.2240 - val_accuracy: 0.9231\n",
      "Epoch 81/100\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.1075 - accuracy: 0.9735 - val_loss: 0.2256 - val_accuracy: 0.9128\n",
      "Epoch 82/100\n",
      "453/453 [==============================] - 0s 69us/step - loss: 0.1070 - accuracy: 0.9669 - val_loss: 0.2212 - val_accuracy: 0.9231\n",
      "Epoch 83/100\n",
      "453/453 [==============================] - 0s 148us/step - loss: 0.1117 - accuracy: 0.9647 - val_loss: 0.2197 - val_accuracy: 0.9231\n",
      "Epoch 84/100\n",
      "453/453 [==============================] - 0s 239us/step - loss: 0.1093 - accuracy: 0.9625 - val_loss: 0.3191 - val_accuracy: 0.8923\n",
      "Epoch 85/100\n",
      "453/453 [==============================] - 0s 148us/step - loss: 0.1412 - accuracy: 0.9382 - val_loss: 0.2574 - val_accuracy: 0.9077\n",
      "Epoch 86/100\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.1246 - accuracy: 0.9581 - val_loss: 0.2201 - val_accuracy: 0.9282\n",
      "Epoch 87/100\n",
      "453/453 [==============================] - 0s 148us/step - loss: 0.1280 - accuracy: 0.9514 - val_loss: 0.2451 - val_accuracy: 0.9077\n",
      "Epoch 88/100\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.1016 - accuracy: 0.9625 - val_loss: 0.2204 - val_accuracy: 0.9333\n",
      "Epoch 89/100\n",
      "453/453 [==============================] - 0s 72us/step - loss: 0.0994 - accuracy: 0.9735 - val_loss: 0.2279 - val_accuracy: 0.9231\n",
      "Epoch 90/100\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.0997 - accuracy: 0.9647 - val_loss: 0.2227 - val_accuracy: 0.9231\n",
      "Epoch 91/100\n",
      "453/453 [==============================] - 0s 202us/step - loss: 0.0980 - accuracy: 0.9691 - val_loss: 0.2188 - val_accuracy: 0.9282\n",
      "Epoch 92/100\n",
      "453/453 [==============================] - 0s 222us/step - loss: 0.0971 - accuracy: 0.9647 - val_loss: 0.2167 - val_accuracy: 0.9231\n",
      "Epoch 93/100\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.0973 - accuracy: 0.9735 - val_loss: 0.2190 - val_accuracy: 0.9179\n",
      "Epoch 94/100\n",
      "453/453 [==============================] - 0s 143us/step - loss: 0.1000 - accuracy: 0.9603 - val_loss: 0.2158 - val_accuracy: 0.9282\n",
      "Epoch 95/100\n",
      "453/453 [==============================] - 0s 94us/step - loss: 0.0976 - accuracy: 0.9669 - val_loss: 0.2188 - val_accuracy: 0.9231\n",
      "Epoch 96/100\n",
      "453/453 [==============================] - 0s 74us/step - loss: 0.0933 - accuracy: 0.9691 - val_loss: 0.2151 - val_accuracy: 0.9231\n",
      "Epoch 97/100\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.0962 - accuracy: 0.9669 - val_loss: 0.2135 - val_accuracy: 0.9282\n",
      "Epoch 98/100\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.0929 - accuracy: 0.9713 - val_loss: 0.2206 - val_accuracy: 0.9179\n",
      "Epoch 99/100\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.0932 - accuracy: 0.9713 - val_loss: 0.2129 - val_accuracy: 0.9282\n",
      "Epoch 100/100\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.0894 - accuracy: 0.9713 - val_loss: 0.2205 - val_accuracy: 0.9231\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a34a81390>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over2.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195/195 [==============================] - 0s 69us/step\n",
      "over-sampling test accuracy: 92.82%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over2 = model1_over2.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over2*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 1, 0, 1, 0, 1, 1, 0, 2, 1, 0, 2, 2, 1, 2, 0, 1, 1, 0, 0, 0,\n",
       "       2, 1, 0, 0, 1, 1, 0, 2, 0, 2, 1, 2, 1, 1, 2, 1, 1, 2, 1, 2, 2, 0,\n",
       "       2, 0, 0, 2, 2, 0, 1, 1, 1, 2, 1, 0, 0, 1, 2, 2, 2, 2, 1, 1, 1, 2,\n",
       "       0, 0, 2, 0, 1, 0, 1, 0, 1, 0, 2, 0, 1, 1, 1, 2, 1, 0, 0, 0, 0, 1,\n",
       "       1, 1, 0, 1, 2, 0, 2, 1, 0, 0, 1, 0, 2, 2, 0, 2, 0, 1, 1, 2, 1, 1,\n",
       "       2, 2, 1, 2, 2, 1, 0, 0, 2, 1, 1, 1, 2, 2, 0, 2, 0, 2, 2, 0, 1, 2,\n",
       "       1, 0, 1, 2, 2, 0, 1, 0, 2, 1, 1, 0, 2, 1, 2, 1, 0, 2, 1, 2, 1, 1,\n",
       "       1, 2, 1, 2, 0, 1, 0, 1, 2, 0, 2, 1, 2, 0, 0, 2, 1, 2, 2, 1, 1, 2,\n",
       "       1, 2, 0, 2, 1, 0, 0, 0, 1, 2, 0, 2, 0, 2, 1, 2, 1, 2, 0])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred2 = model1_over2.predict_classes(X_test_over)\n",
    "pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS110</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS254</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BCH-SA-09</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS177</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GA27</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>NRS001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>NRS272</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>NRS110</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>NRS204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0  test  pred\n",
       "0       NRS110     2     2\n",
       "1       NRS254     1     1\n",
       "2    BCH-SA-09     0     1\n",
       "3       NRS177     0     0\n",
       "4         GA27     1     1\n",
       "..         ...   ...   ...\n",
       "190     NRS001     1     1\n",
       "191     NRS209     2     2\n",
       "192     NRS272     0     1\n",
       "193     NRS110     2     2\n",
       "194     NRS204     0     0\n",
       "\n",
       "[195 rows x 3 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat2['pred'] = pred2\n",
    "dat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba2 = model1_over2.predict_proba(X_test_over)\n",
    "dat_proba2 = pd.DataFrame(proba2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>9.994769e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.999626</td>\n",
       "      <td>3.175176e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.293587</td>\n",
       "      <td>0.706319</td>\n",
       "      <td>9.398517e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.998093</td>\n",
       "      <td>0.001578</td>\n",
       "      <td>3.293598e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.130694</td>\n",
       "      <td>0.869306</td>\n",
       "      <td>3.158125e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>0.060341</td>\n",
       "      <td>0.939657</td>\n",
       "      <td>1.892719e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>0.000835</td>\n",
       "      <td>0.001227</td>\n",
       "      <td>9.979379e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>0.314853</td>\n",
       "      <td>0.622859</td>\n",
       "      <td>6.228807e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>9.994769e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>0.597636</td>\n",
       "      <td>0.401431</td>\n",
       "      <td>9.335179e-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1             2\n",
       "0    0.000125  0.000399  9.994769e-01\n",
       "1    0.000057  0.999626  3.175176e-04\n",
       "2    0.293587  0.706319  9.398517e-05\n",
       "3    0.998093  0.001578  3.293598e-04\n",
       "4    0.130694  0.869306  3.158125e-07\n",
       "..        ...       ...           ...\n",
       "190  0.060341  0.939657  1.892719e-06\n",
       "191  0.000835  0.001227  9.979379e-01\n",
       "192  0.314853  0.622859  6.228807e-02\n",
       "193  0.000125  0.000399  9.994769e-01\n",
       "194  0.597636  0.401431  9.335179e-04\n",
       "\n",
       "[195 rows x 3 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba2.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba2.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat2.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/2p17spST.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 453 samples, validate on 195 samples\n",
      "Epoch 1/100\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.0927 - accuracy: 0.9713 - val_loss: 0.2148 - val_accuracy: 0.9385\n",
      "Epoch 2/100\n",
      "453/453 [==============================] - 0s 147us/step - loss: 0.0938 - accuracy: 0.9713 - val_loss: 0.2843 - val_accuracy: 0.9077\n",
      "Epoch 3/100\n",
      "453/453 [==============================] - 0s 146us/step - loss: 0.0943 - accuracy: 0.9691 - val_loss: 0.2120 - val_accuracy: 0.9385\n",
      "Epoch 4/100\n",
      "453/453 [==============================] - 0s 152us/step - loss: 0.0912 - accuracy: 0.9713 - val_loss: 0.2242 - val_accuracy: 0.9282\n",
      "Epoch 5/100\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.0896 - accuracy: 0.9757 - val_loss: 0.2262 - val_accuracy: 0.9282\n",
      "Epoch 6/100\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.0896 - accuracy: 0.9691 - val_loss: 0.2153 - val_accuracy: 0.9385\n",
      "Epoch 7/100\n",
      "453/453 [==============================] - 0s 144us/step - loss: 0.0963 - accuracy: 0.9801 - val_loss: 0.2387 - val_accuracy: 0.9077\n",
      "Epoch 8/100\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.0908 - accuracy: 0.9691 - val_loss: 0.2238 - val_accuracy: 0.9282\n",
      "Epoch 9/100\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.1425 - accuracy: 0.9713 - val_loss: 0.2203 - val_accuracy: 0.9231\n",
      "Epoch 10/100\n",
      "453/453 [==============================] - 0s 161us/step - loss: 0.0971 - accuracy: 0.9647 - val_loss: 0.2116 - val_accuracy: 0.9436\n",
      "Epoch 11/100\n",
      "453/453 [==============================] - 0s 170us/step - loss: 0.0938 - accuracy: 0.9801 - val_loss: 0.2379 - val_accuracy: 0.9128\n",
      "Epoch 12/100\n",
      "453/453 [==============================] - 0s 201us/step - loss: 0.0883 - accuracy: 0.9735 - val_loss: 0.2219 - val_accuracy: 0.9385\n",
      "Epoch 13/100\n",
      "453/453 [==============================] - 0s 141us/step - loss: 0.0860 - accuracy: 0.9713 - val_loss: 0.2217 - val_accuracy: 0.9385\n",
      "Epoch 14/100\n",
      "453/453 [==============================] - 0s 140us/step - loss: 0.0832 - accuracy: 0.9757 - val_loss: 0.2357 - val_accuracy: 0.9231\n",
      "Epoch 15/100\n",
      "453/453 [==============================] - 0s 169us/step - loss: 0.0879 - accuracy: 0.9669 - val_loss: 0.2217 - val_accuracy: 0.9385\n",
      "Epoch 16/100\n",
      "453/453 [==============================] - 0s 147us/step - loss: 0.0816 - accuracy: 0.9757 - val_loss: 0.2285 - val_accuracy: 0.9333\n",
      "Epoch 17/100\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.0811 - accuracy: 0.9757 - val_loss: 0.2236 - val_accuracy: 0.9333\n",
      "Epoch 18/100\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.0812 - accuracy: 0.9713 - val_loss: 0.2325 - val_accuracy: 0.9282\n",
      "Epoch 19/100\n",
      "453/453 [==============================] - 0s 174us/step - loss: 0.0810 - accuracy: 0.9735 - val_loss: 0.2208 - val_accuracy: 0.9385\n",
      "Epoch 20/100\n",
      "453/453 [==============================] - 0s 368us/step - loss: 0.0918 - accuracy: 0.9735 - val_loss: 0.2569 - val_accuracy: 0.9077\n",
      "Epoch 21/100\n",
      "453/453 [==============================] - 0s 250us/step - loss: 0.0807 - accuracy: 0.9735 - val_loss: 0.2162 - val_accuracy: 0.9436\n",
      "Epoch 22/100\n",
      "453/453 [==============================] - 0s 200us/step - loss: 0.0817 - accuracy: 0.9801 - val_loss: 0.2457 - val_accuracy: 0.9128\n",
      "Epoch 23/100\n",
      "453/453 [==============================] - 0s 217us/step - loss: 0.0773 - accuracy: 0.9757 - val_loss: 0.2201 - val_accuracy: 0.9385\n",
      "Epoch 24/100\n",
      "453/453 [==============================] - 0s 198us/step - loss: 0.0761 - accuracy: 0.9801 - val_loss: 0.2354 - val_accuracy: 0.9231\n",
      "Epoch 25/100\n",
      "453/453 [==============================] - 0s 672us/step - loss: 0.0765 - accuracy: 0.9757 - val_loss: 0.2231 - val_accuracy: 0.9436\n",
      "Epoch 26/100\n",
      "453/453 [==============================] - 0s 333us/step - loss: 0.0759 - accuracy: 0.9735 - val_loss: 0.2242 - val_accuracy: 0.9385\n",
      "Epoch 27/100\n",
      "453/453 [==============================] - 0s 216us/step - loss: 0.0745 - accuracy: 0.9779 - val_loss: 0.2349 - val_accuracy: 0.9231\n",
      "Epoch 28/100\n",
      "453/453 [==============================] - 0s 545us/step - loss: 0.0769 - accuracy: 0.9713 - val_loss: 0.2178 - val_accuracy: 0.9436\n",
      "Epoch 29/100\n",
      "453/453 [==============================] - 0s 255us/step - loss: 0.0729 - accuracy: 0.9823 - val_loss: 0.2704 - val_accuracy: 0.9077\n",
      "Epoch 30/100\n",
      "453/453 [==============================] - 0s 206us/step - loss: 0.0820 - accuracy: 0.9713 - val_loss: 0.2192 - val_accuracy: 0.9436\n",
      "Epoch 31/100\n",
      "453/453 [==============================] - 0s 138us/step - loss: 0.0807 - accuracy: 0.9691 - val_loss: 0.2197 - val_accuracy: 0.9436\n",
      "Epoch 32/100\n",
      "453/453 [==============================] - 0s 159us/step - loss: 0.0768 - accuracy: 0.9823 - val_loss: 0.2634 - val_accuracy: 0.9077\n",
      "Epoch 33/100\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.0751 - accuracy: 0.9801 - val_loss: 0.2281 - val_accuracy: 0.9436\n",
      "Epoch 34/100\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.0736 - accuracy: 0.9735 - val_loss: 0.2349 - val_accuracy: 0.9231\n",
      "Epoch 35/100\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.0725 - accuracy: 0.9757 - val_loss: 0.2314 - val_accuracy: 0.9231\n",
      "Epoch 36/100\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.0703 - accuracy: 0.9823 - val_loss: 0.2488 - val_accuracy: 0.9179\n",
      "Epoch 37/100\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.0715 - accuracy: 0.9779 - val_loss: 0.2372 - val_accuracy: 0.9179\n",
      "Epoch 38/100\n",
      "453/453 [==============================] - 0s 133us/step - loss: 0.0826 - accuracy: 0.9691 - val_loss: 0.2214 - val_accuracy: 0.9333\n",
      "Epoch 39/100\n",
      "453/453 [==============================] - 0s 275us/step - loss: 0.0733 - accuracy: 0.9801 - val_loss: 0.2504 - val_accuracy: 0.9282\n",
      "Epoch 40/100\n",
      "453/453 [==============================] - 0s 218us/step - loss: 0.0719 - accuracy: 0.9823 - val_loss: 0.2371 - val_accuracy: 0.9231\n",
      "Epoch 41/100\n",
      "453/453 [==============================] - 0s 494us/step - loss: 0.0710 - accuracy: 0.9823 - val_loss: 0.2572 - val_accuracy: 0.9077\n",
      "Epoch 42/100\n",
      "453/453 [==============================] - 0s 248us/step - loss: 0.0713 - accuracy: 0.9757 - val_loss: 0.2239 - val_accuracy: 0.9385\n",
      "Epoch 43/100\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.0673 - accuracy: 0.9868 - val_loss: 0.2536 - val_accuracy: 0.9128\n",
      "Epoch 44/100\n",
      "453/453 [==============================] - 0s 220us/step - loss: 0.0748 - accuracy: 0.9757 - val_loss: 0.2379 - val_accuracy: 0.9231\n",
      "Epoch 45/100\n",
      "453/453 [==============================] - 0s 184us/step - loss: 0.0693 - accuracy: 0.9669 - val_loss: 0.2271 - val_accuracy: 0.9333\n",
      "Epoch 46/100\n",
      "453/453 [==============================] - 0s 176us/step - loss: 0.0712 - accuracy: 0.9779 - val_loss: 0.2586 - val_accuracy: 0.9077\n",
      "Epoch 47/100\n",
      "453/453 [==============================] - 0s 175us/step - loss: 0.0653 - accuracy: 0.9823 - val_loss: 0.2336 - val_accuracy: 0.9282\n",
      "Epoch 48/100\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.0652 - accuracy: 0.9823 - val_loss: 0.2380 - val_accuracy: 0.9231\n",
      "Epoch 49/100\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.0654 - accuracy: 0.9801 - val_loss: 0.2381 - val_accuracy: 0.9282\n",
      "Epoch 50/100\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.0654 - accuracy: 0.9801 - val_loss: 0.2530 - val_accuracy: 0.9179\n",
      "Epoch 51/100\n",
      "453/453 [==============================] - 0s 208us/step - loss: 0.0643 - accuracy: 0.9845 - val_loss: 0.2401 - val_accuracy: 0.9231\n",
      "Epoch 52/100\n",
      "453/453 [==============================] - 0s 134us/step - loss: 0.0645 - accuracy: 0.9801 - val_loss: 0.2361 - val_accuracy: 0.9231\n",
      "Epoch 53/100\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.0650 - accuracy: 0.9801 - val_loss: 0.2532 - val_accuracy: 0.9231\n",
      "Epoch 54/100\n",
      "453/453 [==============================] - 0s 187us/step - loss: 0.0635 - accuracy: 0.9823 - val_loss: 0.2425 - val_accuracy: 0.9231\n",
      "Epoch 55/100\n",
      "453/453 [==============================] - 0s 149us/step - loss: 0.0666 - accuracy: 0.9779 - val_loss: 0.2746 - val_accuracy: 0.9128\n",
      "Epoch 56/100\n",
      "453/453 [==============================] - 0s 238us/step - loss: 0.0657 - accuracy: 0.9801 - val_loss: 0.2369 - val_accuracy: 0.9282\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.0618 - accuracy: 0.9868 - val_loss: 0.2595 - val_accuracy: 0.9179\n",
      "Epoch 58/100\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.0712 - accuracy: 0.9757 - val_loss: 0.2299 - val_accuracy: 0.9436\n",
      "Epoch 59/100\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.0654 - accuracy: 0.9823 - val_loss: 0.2849 - val_accuracy: 0.9077\n",
      "Epoch 60/100\n",
      "453/453 [==============================] - 0s 146us/step - loss: 0.0670 - accuracy: 0.9801 - val_loss: 0.2484 - val_accuracy: 0.9179\n",
      "Epoch 61/100\n",
      "453/453 [==============================] - 0s 155us/step - loss: 0.0645 - accuracy: 0.9823 - val_loss: 0.2425 - val_accuracy: 0.9282\n",
      "Epoch 62/100\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.0613 - accuracy: 0.9801 - val_loss: 0.2552 - val_accuracy: 0.9179\n",
      "Epoch 63/100\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.0632 - accuracy: 0.9801 - val_loss: 0.2691 - val_accuracy: 0.9179\n",
      "Epoch 64/100\n",
      "453/453 [==============================] - 0s 142us/step - loss: 0.0686 - accuracy: 0.9779 - val_loss: 0.2428 - val_accuracy: 0.9333\n",
      "Epoch 65/100\n",
      "453/453 [==============================] - 0s 138us/step - loss: 0.0619 - accuracy: 0.9845 - val_loss: 0.2846 - val_accuracy: 0.9179\n",
      "Epoch 66/100\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.0650 - accuracy: 0.9801 - val_loss: 0.2484 - val_accuracy: 0.9231\n",
      "Epoch 67/100\n",
      "453/453 [==============================] - 0s 188us/step - loss: 0.0592 - accuracy: 0.9823 - val_loss: 0.2499 - val_accuracy: 0.9231\n",
      "Epoch 68/100\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.0582 - accuracy: 0.9823 - val_loss: 0.2507 - val_accuracy: 0.9231\n",
      "Epoch 69/100\n",
      "453/453 [==============================] - 0s 190us/step - loss: 0.0580 - accuracy: 0.9801 - val_loss: 0.2487 - val_accuracy: 0.9231\n",
      "Epoch 70/100\n",
      "453/453 [==============================] - 0s 142us/step - loss: 0.0611 - accuracy: 0.9801 - val_loss: 0.2940 - val_accuracy: 0.9077\n",
      "Epoch 71/100\n",
      "453/453 [==============================] - 0s 224us/step - loss: 0.0629 - accuracy: 0.9757 - val_loss: 0.2450 - val_accuracy: 0.9282\n",
      "Epoch 72/100\n",
      "453/453 [==============================] - 0s 134us/step - loss: 0.0574 - accuracy: 0.9823 - val_loss: 0.2494 - val_accuracy: 0.9231\n",
      "Epoch 73/100\n",
      "453/453 [==============================] - 0s 134us/step - loss: 0.0576 - accuracy: 0.9823 - val_loss: 0.2638 - val_accuracy: 0.9231\n",
      "Epoch 74/100\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.0575 - accuracy: 0.9801 - val_loss: 0.2492 - val_accuracy: 0.9231\n",
      "Epoch 75/100\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.0572 - accuracy: 0.9845 - val_loss: 0.2708 - val_accuracy: 0.9179\n",
      "Epoch 76/100\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.0558 - accuracy: 0.9823 - val_loss: 0.2477 - val_accuracy: 0.9231\n",
      "Epoch 77/100\n",
      "453/453 [==============================] - 0s 196us/step - loss: 0.0562 - accuracy: 0.9845 - val_loss: 0.2938 - val_accuracy: 0.9128\n",
      "Epoch 78/100\n",
      "453/453 [==============================] - 0s 216us/step - loss: 0.0574 - accuracy: 0.9801 - val_loss: 0.2457 - val_accuracy: 0.9282\n",
      "Epoch 79/100\n",
      "453/453 [==============================] - 0s 183us/step - loss: 0.0541 - accuracy: 0.9823 - val_loss: 0.2568 - val_accuracy: 0.9231\n",
      "Epoch 80/100\n",
      "453/453 [==============================] - 0s 138us/step - loss: 0.0545 - accuracy: 0.9823 - val_loss: 0.2842 - val_accuracy: 0.9128\n",
      "Epoch 81/100\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.0545 - accuracy: 0.9823 - val_loss: 0.2607 - val_accuracy: 0.9179\n",
      "Epoch 82/100\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.0552 - accuracy: 0.9823 - val_loss: 0.2659 - val_accuracy: 0.9231\n",
      "Epoch 83/100\n",
      "453/453 [==============================] - 0s 154us/step - loss: 0.0553 - accuracy: 0.9757 - val_loss: 0.2600 - val_accuracy: 0.9179\n",
      "Epoch 84/100\n",
      "453/453 [==============================] - 0s 208us/step - loss: 0.0530 - accuracy: 0.9823 - val_loss: 0.2558 - val_accuracy: 0.9231\n",
      "Epoch 85/100\n",
      "453/453 [==============================] - 0s 199us/step - loss: 0.0616 - accuracy: 0.9779 - val_loss: 0.3248 - val_accuracy: 0.9077\n",
      "Epoch 86/100\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.0594 - accuracy: 0.9823 - val_loss: 0.2755 - val_accuracy: 0.9179\n",
      "Epoch 87/100\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.1141 - accuracy: 0.9735 - val_loss: 0.5457 - val_accuracy: 0.9026\n",
      "Epoch 88/100\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2277 - accuracy: 0.9581 - val_loss: 1.1421 - val_accuracy: 0.8821\n",
      "Epoch 89/100\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.4602 - accuracy: 0.9360 - val_loss: 0.7976 - val_accuracy: 0.8769\n",
      "Epoch 90/100\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.7796 - accuracy: 0.9249 - val_loss: 0.5398 - val_accuracy: 0.8821\n",
      "Epoch 91/100\n",
      "453/453 [==============================] - 0s 138us/step - loss: 0.5349 - accuracy: 0.9227 - val_loss: 0.7741 - val_accuracy: 0.8769\n",
      "Epoch 92/100\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.9619 - accuracy: 0.9117 - val_loss: 1.2830 - val_accuracy: 0.8564\n",
      "Epoch 93/100\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.7820 - accuracy: 0.8764 - val_loss: 0.3643 - val_accuracy: 0.8923\n",
      "Epoch 94/100\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.5507 - accuracy: 0.9249 - val_loss: 0.2975 - val_accuracy: 0.9231\n",
      "Epoch 95/100\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.4753 - accuracy: 0.9404 - val_loss: 0.9344 - val_accuracy: 0.8615\n",
      "Epoch 96/100\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.1879 - accuracy: 0.9514 - val_loss: 0.2682 - val_accuracy: 0.9436\n",
      "Epoch 97/100\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.0686 - accuracy: 0.9691 - val_loss: 0.2774 - val_accuracy: 0.9385\n",
      "Epoch 98/100\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.0625 - accuracy: 0.9801 - val_loss: 0.2682 - val_accuracy: 0.9385\n",
      "Epoch 99/100\n",
      "453/453 [==============================] - 0s 167us/step - loss: 0.0548 - accuracy: 0.9823 - val_loss: 0.2695 - val_accuracy: 0.9333\n",
      "Epoch 100/100\n",
      "453/453 [==============================] - 0s 199us/step - loss: 0.0542 - accuracy: 0.9823 - val_loss: 0.2709 - val_accuracy: 0.9333\n"
     ]
    }
   ],
   "source": [
    "hist1_over2 = model1_over2.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 97.33%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over2.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba2 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_2.xlsx\",\n",
    "                        sheet_name=1,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>1.748042e-03</td>\n",
       "      <td>9.981960e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>BCH-SA-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.712007</td>\n",
       "      <td>2.879924e-01</td>\n",
       "      <td>9.646217e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS218</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.006222</td>\n",
       "      <td>9.937732e-01</td>\n",
       "      <td>4.482882e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS036</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.882617</td>\n",
       "      <td>1.173831e-01</td>\n",
       "      <td>2.310933e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS386</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.571179</td>\n",
       "      <td>4.288184e-01</td>\n",
       "      <td>2.444667e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4279</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS112</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001860</td>\n",
       "      <td>9.979747e-01</td>\n",
       "      <td>1.653396e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4280</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>SR1065</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.982940</td>\n",
       "      <td>1.705227e-02</td>\n",
       "      <td>7.349168e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4281</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS203</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.997093</td>\n",
       "      <td>1.962516e-03</td>\n",
       "      <td>9.441347e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4282</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>CFBREBSa129</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.031141e-13</td>\n",
       "      <td>3.208205e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4283</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>CFBRSa25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999833</td>\n",
       "      <td>1.669456e-04</td>\n",
       "      <td>4.411099e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4284 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    phage       strain  phenotype  prediction         0  \\\n",
       "0      p002ykpresabs_qual       NRS148          2           2  0.000056   \n",
       "1      p002ykpresabs_qual    BCH-SA-03          1           0  0.712007   \n",
       "2      p002ykpresabs_qual       NRS218          1           1  0.006222   \n",
       "3      p002ykpresabs_qual       NRS036          0           0  0.882617   \n",
       "4      p002ykpresabs_qual       NRS386          1           0  0.571179   \n",
       "...                   ...          ...        ...         ...       ...   \n",
       "4279  pyopresabsSTCC_qual       NRS112          1           1  0.001860   \n",
       "4280  pyopresabsSTCC_qual       SR1065          0           0  0.982940   \n",
       "4281  pyopresabsSTCC_qual       NRS203          0           0  0.997093   \n",
       "4282  pyopresabsSTCC_qual  CFBREBSa129          0           0  1.000000   \n",
       "4283  pyopresabsSTCC_qual     CFBRSa25          0           0  0.999833   \n",
       "\n",
       "                 1             2  \n",
       "0     1.748042e-03  9.981960e-01  \n",
       "1     2.879924e-01  9.646217e-07  \n",
       "2     9.937732e-01  4.482882e-06  \n",
       "3     1.173831e-01  2.310933e-10  \n",
       "4     4.288184e-01  2.444667e-06  \n",
       "...            ...           ...  \n",
       "4279  9.979747e-01  1.653396e-04  \n",
       "4280  1.705227e-02  7.349168e-06  \n",
       "4281  1.962516e-03  9.441347e-04  \n",
       "4282  3.031141e-13  3.208205e-09  \n",
       "4283  1.669456e-04  4.411099e-08  \n",
       "\n",
       "[4284 rows x 7 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.24710800e-04, 3.98505000e-04, 9.99476850e-01],\n",
       "       [5.68281360e-05, 9.99625560e-01, 3.17517640e-04],\n",
       "       [2.93586900e-01, 7.06319150e-01, 9.39851700e-05],\n",
       "       [9.98092950e-01, 1.57770400e-03, 3.29359800e-04],\n",
       "       [1.30693580e-01, 8.69306100e-01, 3.15812460e-07],\n",
       "       [9.99999170e-01, 8.18356170e-07, 5.11358960e-08],\n",
       "       [1.67183470e-01, 8.32792900e-01, 2.36414290e-05],\n",
       "       [2.11697610e-02, 9.78829500e-01, 7.42307860e-07],\n",
       "       [9.92704500e-01, 7.21716230e-03, 7.83993300e-05],\n",
       "       [1.24710800e-04, 3.98505000e-04, 9.99476850e-01],\n",
       "       [6.03414070e-02, 9.39656600e-01, 1.89271910e-06],\n",
       "       [9.99987100e-01, 1.29095390e-05, 2.82659890e-08],\n",
       "       [8.35038100e-04, 1.22713270e-03, 9.97937860e-01],\n",
       "       [8.35038100e-04, 1.22713270e-03, 9.97937860e-01],\n",
       "       [1.18528580e-05, 9.99873900e-01, 1.14248964e-04],\n",
       "       [1.24710800e-04, 3.98505000e-04, 9.99476850e-01],\n",
       "       [1.00000000e+00, 3.69256000e-08, 4.17103260e-11],\n",
       "       [6.03414070e-02, 9.39656600e-01, 1.89271910e-06],\n",
       "       [1.11336615e-02, 9.88862100e-01, 4.28236850e-06],\n",
       "       [6.06714800e-01, 3.93225070e-01, 6.00671960e-05],\n",
       "       [9.77184240e-01, 2.23492480e-02, 4.66504220e-04],\n",
       "       [9.99926100e-01, 7.39335450e-05, 4.06486130e-09],\n",
       "       [1.24710800e-04, 3.98505000e-04, 9.99476850e-01],\n",
       "       [1.11336615e-02, 9.88862100e-01, 4.28236850e-06],\n",
       "       [9.98438400e-01, 1.56151340e-03, 9.23059700e-08],\n",
       "       [9.99978400e-01, 2.12839060e-05, 1.91864760e-07],\n",
       "       [1.47614800e-01, 8.52382900e-01, 2.24048630e-06],\n",
       "       [5.72144650e-02, 9.42785260e-01, 3.81928660e-07],\n",
       "       [7.94003700e-01, 2.05995460e-01, 8.42040100e-07],\n",
       "       [8.35038100e-04, 1.22713270e-03, 9.97937860e-01],\n",
       "       [9.28263000e-01, 7.16781200e-02, 5.88640360e-05],\n",
       "       [8.35038100e-04, 1.22713270e-03, 9.97937860e-01],\n",
       "       [5.68281360e-05, 9.99625560e-01, 3.17517640e-04],\n",
       "       [1.24710800e-04, 3.98505000e-04, 9.99476850e-01],\n",
       "       [5.68281360e-05, 9.99625560e-01, 3.17517640e-04],\n",
       "       [2.54278240e-02, 9.74572240e-01, 1.42477160e-08],\n",
       "       [8.35038100e-04, 1.22713270e-03, 9.97937860e-01],\n",
       "       [4.19831930e-01, 5.80167530e-01, 5.58119840e-07],\n",
       "       [8.49419700e-02, 9.12119200e-01, 2.93878540e-03],\n",
       "       [1.24710800e-04, 3.98505000e-04, 9.99476850e-01],\n",
       "       [1.16991360e-01, 8.52055700e-01, 3.09529500e-02],\n",
       "       [1.24710800e-04, 3.98505000e-04, 9.99476850e-01],\n",
       "       [8.35038100e-04, 1.22713270e-03, 9.97937860e-01],\n",
       "       [9.99966000e-01, 3.39781580e-05, 5.31630400e-12],\n",
       "       [1.24710800e-04, 3.98505000e-04, 9.99476850e-01],\n",
       "       [9.39930900e-01, 6.00690400e-02, 8.03799700e-09],\n",
       "       [9.89223700e-01, 1.07761910e-02, 1.01533630e-07],\n",
       "       [1.24710800e-04, 3.98505000e-04, 9.99476850e-01],\n",
       "       [1.24710800e-04, 3.98505000e-04, 9.99476850e-01],\n",
       "       [9.99100700e-01, 8.80103600e-04, 1.92747120e-05],\n",
       "       [3.32445440e-03, 9.96675130e-01, 3.84321680e-07],\n",
       "       [1.25630160e-01, 8.74354900e-01, 1.50045950e-05],\n",
       "       [1.95048050e-01, 8.04923600e-01, 2.83347530e-05],\n",
       "       [1.24710800e-04, 3.98505000e-04, 9.99476850e-01],\n",
       "       [2.17550830e-02, 9.78242000e-01, 2.95097650e-06],\n",
       "       [9.45133700e-01, 5.30215900e-02, 1.84468210e-03],\n",
       "       [9.54216200e-01, 4.57808900e-02, 2.98161080e-06],\n",
       "       [1.24998120e-02, 9.87500130e-01, 7.70046600e-08],\n",
       "       [1.24710800e-04, 3.98505000e-04, 9.99476850e-01],\n",
       "       [8.35038100e-04, 1.22713270e-03, 9.97937860e-01],\n",
       "       [1.24710800e-04, 3.98505000e-04, 9.99476850e-01],\n",
       "       [8.35038100e-04, 1.22713270e-03, 9.97937860e-01],\n",
       "       [2.65766230e-01, 7.34101240e-01, 1.32496450e-04],\n",
       "       [1.25630160e-01, 8.74354900e-01, 1.50045950e-05],\n",
       "       [1.24998120e-02, 9.87500130e-01, 7.70046600e-08],\n",
       "       [1.24710800e-04, 3.98505000e-04, 9.99476850e-01],\n",
       "       [8.67145960e-01, 1.32850170e-01, 3.82895770e-06],\n",
       "       [9.88838900e-01, 1.10521870e-02, 1.08892050e-04],\n",
       "       [1.24710800e-04, 3.98505000e-04, 9.99476850e-01],\n",
       "       [9.99996800e-01, 3.14120670e-06, 8.77957900e-08],\n",
       "       [2.54278240e-02, 9.74572240e-01, 1.42477160e-08],\n",
       "       [9.99983300e-01, 1.67223500e-05, 1.65334450e-08],\n",
       "       [2.54670440e-02, 9.74532840e-01, 1.38425350e-07],\n",
       "       [5.49288150e-01, 4.48710830e-01, 2.00103300e-03],\n",
       "       [8.53783640e-02, 9.14621200e-01, 4.72109060e-07],\n",
       "       [9.98658060e-01, 1.34173140e-03, 2.85882980e-07],\n",
       "       [1.24710800e-04, 3.98505000e-04, 9.99476850e-01],\n",
       "       [9.99993440e-01, 6.41778200e-06, 9.87714000e-08],\n",
       "       [1.18407620e-01, 8.81591800e-01, 5.08996950e-07],\n",
       "       [7.49058200e-02, 9.24945800e-01, 1.48413690e-04],\n",
       "       [2.00486900e-02, 9.79030550e-01, 9.20715800e-04],\n",
       "       [8.35038100e-04, 1.22713270e-03, 9.97937860e-01],\n",
       "       [7.49058200e-02, 9.24945800e-01, 1.48413690e-04],\n",
       "       [9.92704500e-01, 7.21716230e-03, 7.83993300e-05],\n",
       "       [5.98072770e-01, 4.01926280e-01, 9.82339200e-07],\n",
       "       [9.31184770e-01, 6.88150000e-02, 2.37968800e-07],\n",
       "       [7.98096500e-01, 2.01892020e-01, 1.14853730e-05],\n",
       "       [1.11336615e-02, 9.88862100e-01, 4.28236850e-06],\n",
       "       [3.72696460e-01, 6.27275800e-01, 2.77749460e-05],\n",
       "       [8.49419700e-02, 9.12119200e-01, 2.93878540e-03],\n",
       "       [9.92522300e-01, 7.47773200e-03, 3.13458700e-08],\n",
       "       [1.95048050e-01, 8.04923600e-01, 2.83347530e-05],\n",
       "       [8.35038100e-04, 1.22713270e-03, 9.97937860e-01],\n",
       "       [9.99999300e-01, 2.06539670e-07, 5.24564260e-07],\n",
       "       [8.35038100e-04, 1.22713270e-03, 9.97937860e-01],\n",
       "       [1.42102510e-01, 8.57609800e-01, 2.87723600e-04],\n",
       "       [9.98990950e-01, 1.00908840e-03, 2.52761900e-08],\n",
       "       [8.15840000e-01, 1.84160000e-01, 4.61357420e-08],\n",
       "       [6.05197700e-04, 9.99338900e-01, 5.58191000e-05],\n",
       "       [5.17228500e-01, 4.80740280e-01, 2.03125640e-03],\n",
       "       [8.35038100e-04, 1.22713270e-03, 9.97937860e-01],\n",
       "       [8.35038100e-04, 1.22713270e-03, 9.97937860e-01],\n",
       "       [9.99761040e-01, 2.38927300e-04, 1.20156110e-08],\n",
       "       [1.24710800e-04, 3.98505000e-04, 9.99476850e-01],\n",
       "       [9.68699460e-01, 2.90589720e-02, 2.24149370e-03],\n",
       "       [1.18407620e-01, 8.81591800e-01, 5.08996950e-07],\n",
       "       [1.67183470e-01, 8.32792900e-01, 2.36414290e-05],\n",
       "       [1.24710800e-04, 3.98505000e-04, 9.99476850e-01],\n",
       "       [1.18528580e-05, 9.99873900e-01, 1.14248964e-04],\n",
       "       [1.81254000e-01, 8.18255800e-01, 4.90160660e-04],\n",
       "       [8.35038100e-04, 1.22713270e-03, 9.97937860e-01],\n",
       "       [1.24710800e-04, 3.98505000e-04, 9.99476850e-01],\n",
       "       [8.49419700e-02, 9.12119200e-01, 2.93878540e-03],\n",
       "       [8.35038100e-04, 1.22713270e-03, 9.97937860e-01],\n",
       "       [8.35038100e-04, 1.22713270e-03, 9.97937860e-01],\n",
       "       [5.72144650e-02, 9.42785260e-01, 3.81928660e-07],\n",
       "       [9.99697700e-01, 2.22491280e-04, 7.98263700e-05],\n",
       "       [9.92704500e-01, 7.21716230e-03, 7.83993300e-05],\n",
       "       [1.24710800e-04, 3.98505000e-04, 9.99476850e-01],\n",
       "       [1.24998120e-02, 9.87500130e-01, 7.70046600e-08],\n",
       "       [1.25630160e-01, 8.74354900e-01, 1.50045950e-05],\n",
       "       [1.18407620e-01, 8.81591800e-01, 5.08996950e-07],\n",
       "       [8.35038100e-04, 1.22713270e-03, 9.97937860e-01],\n",
       "       [8.35038100e-04, 1.22713270e-03, 9.97937860e-01],\n",
       "       [9.14425730e-01, 8.55494500e-02, 2.48813650e-05],\n",
       "       [1.24710800e-04, 3.98505000e-04, 9.99476850e-01],\n",
       "       [6.67979240e-01, 3.32020500e-01, 3.52852280e-07],\n",
       "       [8.35038100e-04, 1.22713270e-03, 9.97937860e-01],\n",
       "       [1.24710800e-04, 3.98505000e-04, 9.99476850e-01],\n",
       "       [9.85392400e-01, 1.46072340e-02, 3.26662670e-07],\n",
       "       [8.40986100e-02, 9.15899900e-01, 1.52843320e-06],\n",
       "       [8.35038100e-04, 1.22713270e-03, 9.97937860e-01],\n",
       "       [2.01600760e-01, 7.98395600e-01, 3.72332780e-06],\n",
       "       [9.99504900e-01, 2.23903760e-04, 2.71198340e-04],\n",
       "       [2.20556000e-05, 9.99098060e-01, 8.79939760e-04],\n",
       "       [8.35038100e-04, 1.22713270e-03, 9.97937860e-01],\n",
       "       [8.35038100e-04, 1.22713270e-03, 9.97937860e-01],\n",
       "       [9.99999500e-01, 5.27982800e-07, 1.53330660e-08],\n",
       "       [1.16991360e-01, 8.52055700e-01, 3.09529500e-02],\n",
       "       [8.60593900e-01, 1.38662380e-01, 7.43699140e-04],\n",
       "       [1.24710800e-04, 3.98505000e-04, 9.99476850e-01],\n",
       "       [2.11697610e-02, 9.78829500e-01, 7.42307860e-07],\n",
       "       [3.72696460e-01, 6.27275800e-01, 2.77749460e-05],\n",
       "       [9.75772860e-01, 2.42050010e-02, 2.21412140e-05],\n",
       "       [1.24710800e-04, 3.98505000e-04, 9.99476850e-01],\n",
       "       [1.18528580e-05, 9.99873900e-01, 1.14248964e-04],\n",
       "       [1.24710800e-04, 3.98505000e-04, 9.99476850e-01],\n",
       "       [4.29647600e-01, 5.70351240e-01, 1.16215890e-06],\n",
       "       [9.98521860e-01, 1.47806670e-03, 1.01855610e-07],\n",
       "       [1.24710800e-04, 3.98505000e-04, 9.99476850e-01],\n",
       "       [7.49058200e-02, 9.24945800e-01, 1.48413690e-04],\n",
       "       [8.35038100e-04, 1.22713270e-03, 9.97937860e-01],\n",
       "       [6.05197700e-04, 9.99338900e-01, 5.58191000e-05],\n",
       "       [2.20556000e-05, 9.99098060e-01, 8.79939760e-04],\n",
       "       [8.49419700e-02, 9.12119200e-01, 2.93878540e-03],\n",
       "       [1.24710800e-04, 3.98505000e-04, 9.99476850e-01],\n",
       "       [1.67183470e-01, 8.32792900e-01, 2.36414290e-05],\n",
       "       [8.35038100e-04, 1.22713270e-03, 9.97937860e-01],\n",
       "       [5.99623740e-01, 4.00373700e-01, 2.65110660e-06],\n",
       "       [1.17669150e-04, 9.97948350e-01, 1.93400130e-03],\n",
       "       [9.11587060e-01, 8.84130100e-02, 1.62471890e-09],\n",
       "       [2.54278240e-02, 9.74572240e-01, 1.42477160e-08],\n",
       "       [8.35038100e-04, 1.22713270e-03, 9.97937860e-01],\n",
       "       [9.55345630e-01, 4.35247420e-02, 1.12967440e-03],\n",
       "       [1.24710800e-04, 3.98505000e-04, 9.99476850e-01],\n",
       "       [8.49419700e-02, 9.12119200e-01, 2.93878540e-03],\n",
       "       [1.24710800e-04, 3.98505000e-04, 9.99476850e-01],\n",
       "       [9.87425150e-01, 1.25748620e-02, 3.53637440e-08],\n",
       "       [9.99770340e-01, 2.29264730e-04, 3.88610740e-07],\n",
       "       [8.35038100e-04, 1.22713270e-03, 9.97937860e-01],\n",
       "       [8.49419700e-02, 9.12119200e-01, 2.93878540e-03],\n",
       "       [8.35038100e-04, 1.22713270e-03, 9.97937860e-01],\n",
       "       [1.24710800e-04, 3.98505000e-04, 9.99476850e-01],\n",
       "       [1.16991360e-01, 8.52055700e-01, 3.09529500e-02],\n",
       "       [2.09860250e-01, 7.90139300e-01, 4.36522380e-07],\n",
       "       [1.24710800e-04, 3.98505000e-04, 9.99476850e-01],\n",
       "       [1.20510590e-01, 8.79481700e-01, 7.70944500e-06],\n",
       "       [1.24710800e-04, 3.98505000e-04, 9.99476850e-01],\n",
       "       [7.45771300e-01, 2.54228200e-01, 4.55851200e-07],\n",
       "       [8.35038100e-04, 1.22713270e-03, 9.97937860e-01],\n",
       "       [8.40986100e-02, 9.15899900e-01, 1.52843320e-06],\n",
       "       [9.87893900e-01, 8.93236600e-03, 3.17384630e-03],\n",
       "       [9.99995950e-01, 4.00524280e-06, 4.27655020e-17],\n",
       "       [9.96564450e-01, 3.43560200e-03, 1.94680540e-09],\n",
       "       [4.44202300e-01, 5.55768500e-01, 2.92166930e-05],\n",
       "       [1.24710800e-04, 3.98505000e-04, 9.99476850e-01],\n",
       "       [5.50656100e-01, 4.49321840e-01, 2.20512810e-05],\n",
       "       [8.35038100e-04, 1.22713270e-03, 9.97937860e-01],\n",
       "       [9.99999500e-01, 5.27982800e-07, 1.53330660e-08],\n",
       "       [1.24710800e-04, 3.98505000e-04, 9.99476850e-01],\n",
       "       [6.03414070e-02, 9.39656600e-01, 1.89271910e-06],\n",
       "       [8.35038100e-04, 1.22713270e-03, 9.97937860e-01],\n",
       "       [3.14852860e-01, 6.22859000e-01, 6.22880700e-02],\n",
       "       [1.24710800e-04, 3.98505000e-04, 9.99476850e-01],\n",
       "       [5.97635570e-01, 4.01430930e-01, 9.33517900e-04]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob2 = df_proba2[df_proba2['phage']=='p0017SpresabsSTCC_qual'].iloc[:,-3:]\n",
    "y_prob2 = y_prob2.to_numpy()\n",
    "y_prob2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9839447731755424"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo2 = rocauc_ovo(y_test_over, y_prob2, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9839447731755424"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr2 = rocauc_ovr(y_test_over, y_prob2, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=345,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat3 = pd.DataFrame(X_test_over[:,0])\n",
    "dat3['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS249</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS172</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS108</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>NRS110</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>NRS255</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>NRS175</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>NRS241</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0  test\n",
       "0    NRS249     1\n",
       "1    NRS172     1\n",
       "2    NRS209     2\n",
       "3    NRS108     1\n",
       "4    NRS209     2\n",
       "..      ...   ...\n",
       "190  NRS209     2\n",
       "191  NRS110     2\n",
       "192  NRS255     1\n",
       "193  NRS175     1\n",
       "194  NRS241     1\n",
       "\n",
       "[195 rows x 2 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over3 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],)),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over3.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 453 samples, validate on 195 samples\n",
      "Epoch 1/100\n",
      "453/453 [==============================] - 0s 328us/step - loss: 4.5625 - accuracy: 0.4790 - val_loss: 6.0899 - val_accuracy: 0.4923\n",
      "Epoch 2/100\n",
      "453/453 [==============================] - 0s 83us/step - loss: 1.5184 - accuracy: 0.6203 - val_loss: 1.2294 - val_accuracy: 0.6513\n",
      "Epoch 3/100\n",
      "453/453 [==============================] - 0s 86us/step - loss: 1.1417 - accuracy: 0.5673 - val_loss: 1.3343 - val_accuracy: 0.6821\n",
      "Epoch 4/100\n",
      "453/453 [==============================] - 0s 90us/step - loss: 0.9137 - accuracy: 0.7042 - val_loss: 0.5758 - val_accuracy: 0.7385\n",
      "Epoch 5/100\n",
      "453/453 [==============================] - 0s 86us/step - loss: 0.6168 - accuracy: 0.7285 - val_loss: 0.4928 - val_accuracy: 0.7282\n",
      "Epoch 6/100\n",
      "453/453 [==============================] - 0s 87us/step - loss: 0.5193 - accuracy: 0.7638 - val_loss: 0.6887 - val_accuracy: 0.7692\n",
      "Epoch 7/100\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.4888 - accuracy: 0.7638 - val_loss: 0.4510 - val_accuracy: 0.7538\n",
      "Epoch 8/100\n",
      "453/453 [==============================] - 0s 91us/step - loss: 0.4463 - accuracy: 0.7815 - val_loss: 0.3898 - val_accuracy: 0.7897\n",
      "Epoch 9/100\n",
      "453/453 [==============================] - 0s 84us/step - loss: 0.4461 - accuracy: 0.7881 - val_loss: 0.4036 - val_accuracy: 0.7949\n",
      "Epoch 10/100\n",
      "453/453 [==============================] - 0s 81us/step - loss: 0.4396 - accuracy: 0.8124 - val_loss: 0.3527 - val_accuracy: 0.8410\n",
      "Epoch 11/100\n",
      "453/453 [==============================] - 0s 80us/step - loss: 0.4459 - accuracy: 0.8212 - val_loss: 1.5705 - val_accuracy: 0.7949\n",
      "Epoch 12/100\n",
      "453/453 [==============================] - 0s 90us/step - loss: 0.5821 - accuracy: 0.7660 - val_loss: 0.5211 - val_accuracy: 0.8051\n",
      "Epoch 13/100\n",
      "453/453 [==============================] - 0s 93us/step - loss: 0.4936 - accuracy: 0.8190 - val_loss: 0.3247 - val_accuracy: 0.8615\n",
      "Epoch 14/100\n",
      "453/453 [==============================] - 0s 86us/step - loss: 0.3659 - accuracy: 0.8366 - val_loss: 0.3160 - val_accuracy: 0.8615\n",
      "Epoch 15/100\n",
      "453/453 [==============================] - 0s 97us/step - loss: 0.3445 - accuracy: 0.8344 - val_loss: 0.3046 - val_accuracy: 0.8513\n",
      "Epoch 16/100\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.3383 - accuracy: 0.8079 - val_loss: 0.4422 - val_accuracy: 0.8154\n",
      "Epoch 17/100\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.3260 - accuracy: 0.8808 - val_loss: 0.2867 - val_accuracy: 0.8667\n",
      "Epoch 18/100\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.3194 - accuracy: 0.8389 - val_loss: 0.3532 - val_accuracy: 0.8462\n",
      "Epoch 19/100\n",
      "453/453 [==============================] - 0s 144us/step - loss: 0.3310 - accuracy: 0.8455 - val_loss: 0.7468 - val_accuracy: 0.8513\n",
      "Epoch 20/100\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.3860 - accuracy: 0.8477 - val_loss: 0.3686 - val_accuracy: 0.8769\n",
      "Epoch 21/100\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.3652 - accuracy: 0.8609 - val_loss: 0.2579 - val_accuracy: 0.9179\n",
      "Epoch 22/100\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2893 - accuracy: 0.8653 - val_loss: 0.2830 - val_accuracy: 0.9026\n",
      "Epoch 23/100\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2859 - accuracy: 0.8830 - val_loss: 0.2741 - val_accuracy: 0.8923\n",
      "Epoch 24/100\n",
      "453/453 [==============================] - 0s 77us/step - loss: 0.2764 - accuracy: 0.8940 - val_loss: 0.2411 - val_accuracy: 0.9333\n",
      "Epoch 25/100\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2835 - accuracy: 0.8918 - val_loss: 0.2833 - val_accuracy: 0.9333\n",
      "Epoch 26/100\n",
      "453/453 [==============================] - 0s 80us/step - loss: 0.3637 - accuracy: 0.8653 - val_loss: 0.2789 - val_accuracy: 0.8974\n",
      "Epoch 27/100\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.3074 - accuracy: 0.9029 - val_loss: 0.8799 - val_accuracy: 0.8462\n",
      "Epoch 28/100\n",
      "453/453 [==============================] - 0s 94us/step - loss: 0.4455 - accuracy: 0.8322 - val_loss: 0.2391 - val_accuracy: 0.9231\n",
      "Epoch 29/100\n",
      "453/453 [==============================] - 0s 84us/step - loss: 0.2906 - accuracy: 0.8918 - val_loss: 0.3012 - val_accuracy: 0.9179\n",
      "Epoch 30/100\n",
      "453/453 [==============================] - 0s 96us/step - loss: 0.2996 - accuracy: 0.9073 - val_loss: 0.5074 - val_accuracy: 0.8923\n",
      "Epoch 31/100\n",
      "453/453 [==============================] - 0s 85us/step - loss: 0.2528 - accuracy: 0.9073 - val_loss: 0.2209 - val_accuracy: 0.9282\n",
      "Epoch 32/100\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.2438 - accuracy: 0.9095 - val_loss: 0.2688 - val_accuracy: 0.9436\n",
      "Epoch 33/100\n",
      "453/453 [==============================] - 0s 83us/step - loss: 0.2701 - accuracy: 0.9227 - val_loss: 0.2199 - val_accuracy: 0.9282\n",
      "Epoch 34/100\n",
      "453/453 [==============================] - 0s 93us/step - loss: 0.2326 - accuracy: 0.9205 - val_loss: 0.3033 - val_accuracy: 0.8974\n",
      "Epoch 35/100\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.3242 - accuracy: 0.8786 - val_loss: 0.7469 - val_accuracy: 0.8923\n",
      "Epoch 36/100\n",
      "453/453 [==============================] - 0s 182us/step - loss: 0.2705 - accuracy: 0.8742 - val_loss: 0.3133 - val_accuracy: 0.8974\n",
      "Epoch 37/100\n",
      "453/453 [==============================] - 0s 138us/step - loss: 0.4537 - accuracy: 0.8874 - val_loss: 0.3411 - val_accuracy: 0.9077\n",
      "Epoch 38/100\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.6909 - accuracy: 0.8874 - val_loss: 1.4101 - val_accuracy: 0.8769\n",
      "Epoch 39/100\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2897 - accuracy: 0.8764 - val_loss: 0.2171 - val_accuracy: 0.9179\n",
      "Epoch 40/100\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2451 - accuracy: 0.9029 - val_loss: 0.1905 - val_accuracy: 0.9436\n",
      "Epoch 41/100\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2348 - accuracy: 0.9183 - val_loss: 0.3772 - val_accuracy: 0.8974\n",
      "Epoch 42/100\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2142 - accuracy: 0.9139 - val_loss: 0.1846 - val_accuracy: 0.9590\n",
      "Epoch 43/100\n",
      "453/453 [==============================] - 0s 133us/step - loss: 0.1977 - accuracy: 0.9272 - val_loss: 0.2240 - val_accuracy: 0.9128\n",
      "Epoch 44/100\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.1977 - accuracy: 0.9316 - val_loss: 0.1700 - val_accuracy: 0.9538\n",
      "Epoch 45/100\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.1911 - accuracy: 0.9294 - val_loss: 0.1915 - val_accuracy: 0.9282\n",
      "Epoch 46/100\n",
      "453/453 [==============================] - 0s 179us/step - loss: 0.1898 - accuracy: 0.9272 - val_loss: 0.1874 - val_accuracy: 0.9333\n",
      "Epoch 47/100\n",
      "453/453 [==============================] - 0s 179us/step - loss: 0.1869 - accuracy: 0.9249 - val_loss: 0.1712 - val_accuracy: 0.9590\n",
      "Epoch 48/100\n",
      "453/453 [==============================] - 0s 96us/step - loss: 0.1866 - accuracy: 0.9205 - val_loss: 0.1640 - val_accuracy: 0.9641\n",
      "Epoch 49/100\n",
      "453/453 [==============================] - 0s 92us/step - loss: 0.1941 - accuracy: 0.9316 - val_loss: 0.2438 - val_accuracy: 0.9231\n",
      "Epoch 50/100\n",
      "453/453 [==============================] - 0s 91us/step - loss: 0.2427 - accuracy: 0.9095 - val_loss: 0.7159 - val_accuracy: 0.8872\n",
      "Epoch 51/100\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2560 - accuracy: 0.9294 - val_loss: 0.1943 - val_accuracy: 0.9487\n",
      "Epoch 52/100\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.1865 - accuracy: 0.9227 - val_loss: 0.1611 - val_accuracy: 0.9641\n",
      "Epoch 53/100\n",
      "453/453 [==============================] - 0s 173us/step - loss: 0.1778 - accuracy: 0.9470 - val_loss: 0.1626 - val_accuracy: 0.9538\n",
      "Epoch 54/100\n",
      "453/453 [==============================] - 0s 85us/step - loss: 0.1755 - accuracy: 0.9294 - val_loss: 0.1631 - val_accuracy: 0.9590\n",
      "Epoch 55/100\n",
      "453/453 [==============================] - 0s 69us/step - loss: 0.1674 - accuracy: 0.9382 - val_loss: 0.1538 - val_accuracy: 0.9641\n",
      "Epoch 56/100\n",
      "453/453 [==============================] - 0s 76us/step - loss: 0.1680 - accuracy: 0.9338 - val_loss: 0.1808 - val_accuracy: 0.9179\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 84us/step - loss: 0.1633 - accuracy: 0.9294 - val_loss: 0.1534 - val_accuracy: 0.9590\n",
      "Epoch 58/100\n",
      "453/453 [==============================] - 0s 93us/step - loss: 0.1634 - accuracy: 0.9426 - val_loss: 0.1518 - val_accuracy: 0.9641\n",
      "Epoch 59/100\n",
      "453/453 [==============================] - 0s 84us/step - loss: 0.1709 - accuracy: 0.9448 - val_loss: 0.1777 - val_accuracy: 0.9385\n",
      "Epoch 60/100\n",
      "453/453 [==============================] - 0s 141us/step - loss: 0.1953 - accuracy: 0.9360 - val_loss: 0.1571 - val_accuracy: 0.9436\n",
      "Epoch 61/100\n",
      "453/453 [==============================] - 0s 148us/step - loss: 0.1618 - accuracy: 0.9360 - val_loss: 0.1519 - val_accuracy: 0.9538\n",
      "Epoch 62/100\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.1540 - accuracy: 0.9360 - val_loss: 0.1566 - val_accuracy: 0.9385\n",
      "Epoch 63/100\n",
      "453/453 [==============================] - 0s 87us/step - loss: 0.1544 - accuracy: 0.9404 - val_loss: 0.1472 - val_accuracy: 0.9641\n",
      "Epoch 64/100\n",
      "453/453 [==============================] - 0s 62us/step - loss: 0.1537 - accuracy: 0.9426 - val_loss: 0.2067 - val_accuracy: 0.9282\n",
      "Epoch 65/100\n",
      "453/453 [==============================] - 0s 64us/step - loss: 0.1503 - accuracy: 0.9536 - val_loss: 0.1517 - val_accuracy: 0.9487\n",
      "Epoch 66/100\n",
      "453/453 [==============================] - 0s 60us/step - loss: 0.1460 - accuracy: 0.9404 - val_loss: 0.1419 - val_accuracy: 0.9641\n",
      "Epoch 67/100\n",
      "453/453 [==============================] - 0s 60us/step - loss: 0.1427 - accuracy: 0.9470 - val_loss: 0.1955 - val_accuracy: 0.9231\n",
      "Epoch 68/100\n",
      "453/453 [==============================] - 0s 74us/step - loss: 0.1439 - accuracy: 0.9426 - val_loss: 0.1405 - val_accuracy: 0.9692\n",
      "Epoch 69/100\n",
      "453/453 [==============================] - 0s 85us/step - loss: 0.1462 - accuracy: 0.9581 - val_loss: 0.2196 - val_accuracy: 0.8923\n",
      "Epoch 70/100\n",
      "453/453 [==============================] - 0s 94us/step - loss: 0.1593 - accuracy: 0.9316 - val_loss: 0.2894 - val_accuracy: 0.9179\n",
      "Epoch 71/100\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.1730 - accuracy: 0.9514 - val_loss: 0.1435 - val_accuracy: 0.9641\n",
      "Epoch 72/100\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2095 - accuracy: 0.9272 - val_loss: 0.1991 - val_accuracy: 0.9487\n",
      "Epoch 73/100\n",
      "453/453 [==============================] - 0s 66us/step - loss: 0.1612 - accuracy: 0.9470 - val_loss: 0.2409 - val_accuracy: 0.9385\n",
      "Epoch 74/100\n",
      "453/453 [==============================] - 0s 76us/step - loss: 1.4371 - accuracy: 0.8698 - val_loss: 1.0529 - val_accuracy: 0.8667\n",
      "Epoch 75/100\n",
      "453/453 [==============================] - 0s 60us/step - loss: 0.7642 - accuracy: 0.8720 - val_loss: 0.2158 - val_accuracy: 0.8974\n",
      "Epoch 76/100\n",
      "453/453 [==============================] - 0s 67us/step - loss: 0.2445 - accuracy: 0.9249 - val_loss: 0.1970 - val_accuracy: 0.9231\n",
      "Epoch 77/100\n",
      "453/453 [==============================] - 0s 67us/step - loss: 0.1858 - accuracy: 0.9316 - val_loss: 0.2223 - val_accuracy: 0.9128\n",
      "Epoch 78/100\n",
      "453/453 [==============================] - 0s 65us/step - loss: 0.1483 - accuracy: 0.9514 - val_loss: 0.1358 - val_accuracy: 0.9641\n",
      "Epoch 79/100\n",
      "453/453 [==============================] - 0s 278us/step - loss: 0.1503 - accuracy: 0.9294 - val_loss: 0.1387 - val_accuracy: 0.9590\n",
      "Epoch 80/100\n",
      "453/453 [==============================] - 0s 214us/step - loss: 0.1436 - accuracy: 0.9536 - val_loss: 0.1386 - val_accuracy: 0.9590\n",
      "Epoch 81/100\n",
      "453/453 [==============================] - 0s 196us/step - loss: 0.1305 - accuracy: 0.9426 - val_loss: 0.1380 - val_accuracy: 0.9641\n",
      "Epoch 82/100\n",
      "453/453 [==============================] - 0s 157us/step - loss: 0.1409 - accuracy: 0.9470 - val_loss: 0.1276 - val_accuracy: 0.9692\n",
      "Epoch 83/100\n",
      "453/453 [==============================] - 0s 174us/step - loss: 0.1251 - accuracy: 0.9536 - val_loss: 0.1295 - val_accuracy: 0.9641\n",
      "Epoch 84/100\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.1329 - accuracy: 0.9448 - val_loss: 0.2218 - val_accuracy: 0.9282\n",
      "Epoch 85/100\n",
      "453/453 [==============================] - 0s 75us/step - loss: 0.1375 - accuracy: 0.9536 - val_loss: 0.1583 - val_accuracy: 0.9436\n",
      "Epoch 86/100\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.1396 - accuracy: 0.9536 - val_loss: 0.2114 - val_accuracy: 0.9282\n",
      "Epoch 87/100\n",
      "453/453 [==============================] - 0s 184us/step - loss: 0.1301 - accuracy: 0.9404 - val_loss: 0.2476 - val_accuracy: 0.9231\n",
      "Epoch 88/100\n",
      "453/453 [==============================] - 0s 181us/step - loss: 0.1257 - accuracy: 0.9581 - val_loss: 0.1208 - val_accuracy: 0.9641\n",
      "Epoch 89/100\n",
      "453/453 [==============================] - 0s 185us/step - loss: 0.1230 - accuracy: 0.9492 - val_loss: 0.1287 - val_accuracy: 0.9436\n",
      "Epoch 90/100\n",
      "453/453 [==============================] - 0s 175us/step - loss: 0.1209 - accuracy: 0.9603 - val_loss: 0.1255 - val_accuracy: 0.9590\n",
      "Epoch 91/100\n",
      "453/453 [==============================] - 0s 169us/step - loss: 0.1155 - accuracy: 0.9581 - val_loss: 0.1471 - val_accuracy: 0.9436\n",
      "Epoch 92/100\n",
      "453/453 [==============================] - 0s 75us/step - loss: 0.1157 - accuracy: 0.9558 - val_loss: 0.1211 - val_accuracy: 0.9590\n",
      "Epoch 93/100\n",
      "453/453 [==============================] - 0s 86us/step - loss: 0.1205 - accuracy: 0.9514 - val_loss: 0.1263 - val_accuracy: 0.9590\n",
      "Epoch 94/100\n",
      "453/453 [==============================] - 0s 198us/step - loss: 0.1144 - accuracy: 0.9581 - val_loss: 0.1307 - val_accuracy: 0.9487\n",
      "Epoch 95/100\n",
      "453/453 [==============================] - 0s 198us/step - loss: 0.1174 - accuracy: 0.9603 - val_loss: 0.1353 - val_accuracy: 0.9436\n",
      "Epoch 96/100\n",
      "453/453 [==============================] - 0s 170us/step - loss: 0.1352 - accuracy: 0.9360 - val_loss: 0.1374 - val_accuracy: 0.9487\n",
      "Epoch 97/100\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.1571 - accuracy: 0.9404 - val_loss: 0.1240 - val_accuracy: 0.9590\n",
      "Epoch 98/100\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.1174 - accuracy: 0.9558 - val_loss: 0.1355 - val_accuracy: 0.9385\n",
      "Epoch 99/100\n",
      "453/453 [==============================] - 0s 84us/step - loss: 0.1130 - accuracy: 0.9558 - val_loss: 0.1195 - val_accuracy: 0.9590\n",
      "Epoch 100/100\n",
      "453/453 [==============================] - 0s 64us/step - loss: 0.1081 - accuracy: 0.9581 - val_loss: 0.1382 - val_accuracy: 0.9385\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a34d5c898>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over3.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195/195 [==============================] - 0s 77us/step\n",
      "over-sampling test accuracy: 95.90%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over3 = model1_over3.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over3*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 2, 1, 2, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 2, 0, 2, 0, 0, 1, 2,\n",
       "       1, 0, 2, 0, 1, 0, 0, 0, 0, 0, 2, 1, 1, 1, 2, 2, 1, 0, 2, 1, 1, 0,\n",
       "       2, 2, 2, 2, 2, 1, 2, 2, 1, 0, 2, 2, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1,\n",
       "       0, 2, 2, 0, 0, 0, 1, 0, 2, 0, 1, 0, 0, 2, 1, 0, 2, 0, 2, 1, 1, 2,\n",
       "       1, 2, 0, 0, 2, 0, 1, 2, 1, 1, 2, 2, 2, 2, 2, 1, 0, 2, 1, 2, 0, 1,\n",
       "       2, 0, 1, 0, 1, 1, 2, 2, 1, 1, 1, 0, 2, 1, 1, 0, 1, 0, 2, 2, 0, 1,\n",
       "       2, 2, 1, 2, 2, 2, 0, 1, 1, 0, 2, 1, 1, 1, 2, 0, 2, 2, 0, 2, 1, 0,\n",
       "       1, 2, 0, 1, 1, 0, 0, 2, 0, 0, 0, 0, 2, 2, 1, 1, 1, 2, 1, 1, 2, 2,\n",
       "       0, 2, 1, 1, 2, 0, 2, 1, 1, 0, 1, 1, 1, 2, 2, 2, 1, 1, 1])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred3 = model1_over3.predict_classes(X_test_over)\n",
    "pred3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS249</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS172</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS108</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>NRS110</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>NRS255</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>NRS175</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>NRS241</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0  test  pred\n",
       "0    NRS249     1     1\n",
       "1    NRS172     1     1\n",
       "2    NRS209     2     2\n",
       "3    NRS108     1     1\n",
       "4    NRS209     2     2\n",
       "..      ...   ...   ...\n",
       "190  NRS209     2     2\n",
       "191  NRS110     2     2\n",
       "192  NRS255     1     1\n",
       "193  NRS175     1     1\n",
       "194  NRS241     1     1\n",
       "\n",
       "[195 rows x 3 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat3['pred'] = pred3\n",
    "dat3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba3 = model1_over3.predict_proba(X_test_over)\n",
    "dat_proba3 = pd.DataFrame(proba3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.026318</td>\n",
       "      <td>0.973601</td>\n",
       "      <td>0.000081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.999952</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000974</td>\n",
       "      <td>0.002337</td>\n",
       "      <td>0.996689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.999980</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000974</td>\n",
       "      <td>0.002337</td>\n",
       "      <td>0.996689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>0.000974</td>\n",
       "      <td>0.002337</td>\n",
       "      <td>0.996689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>0.001073</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>0.998772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>0.000557</td>\n",
       "      <td>0.994291</td>\n",
       "      <td>0.005152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>0.268605</td>\n",
       "      <td>0.731393</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>0.067980</td>\n",
       "      <td>0.931878</td>\n",
       "      <td>0.000142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2\n",
       "0    0.026318  0.973601  0.000081\n",
       "1    0.000043  0.999952  0.000005\n",
       "2    0.000974  0.002337  0.996689\n",
       "3    0.000006  0.999980  0.000014\n",
       "4    0.000974  0.002337  0.996689\n",
       "..        ...       ...       ...\n",
       "190  0.000974  0.002337  0.996689\n",
       "191  0.001073  0.000155  0.998772\n",
       "192  0.000557  0.994291  0.005152\n",
       "193  0.268605  0.731393  0.000002\n",
       "194  0.067980  0.931878  0.000142\n",
       "\n",
       "[195 rows x 3 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba3.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba3.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat3.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/3p17spST.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 453 samples, validate on 195 samples\n",
      "Epoch 1/100\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.1009 - accuracy: 0.9647 - val_loss: 0.1287 - val_accuracy: 0.9487\n",
      "Epoch 2/100\n",
      "453/453 [==============================] - 0s 134us/step - loss: 0.1051 - accuracy: 0.9581 - val_loss: 0.1121 - val_accuracy: 0.9487\n",
      "Epoch 3/100\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.1027 - accuracy: 0.9603 - val_loss: 0.1124 - val_accuracy: 0.9538\n",
      "Epoch 4/100\n",
      "453/453 [==============================] - 0s 94us/step - loss: 0.1064 - accuracy: 0.9625 - val_loss: 0.1268 - val_accuracy: 0.9487\n",
      "Epoch 5/100\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.0999 - accuracy: 0.9691 - val_loss: 0.1226 - val_accuracy: 0.9436\n",
      "Epoch 6/100\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.0962 - accuracy: 0.9581 - val_loss: 0.1155 - val_accuracy: 0.9590\n",
      "Epoch 7/100\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.0977 - accuracy: 0.9603 - val_loss: 0.1264 - val_accuracy: 0.9487\n",
      "Epoch 8/100\n",
      "453/453 [==============================] - 0s 96us/step - loss: 0.0938 - accuracy: 0.9669 - val_loss: 0.1142 - val_accuracy: 0.9590\n",
      "Epoch 9/100\n",
      "453/453 [==============================] - 0s 93us/step - loss: 0.0958 - accuracy: 0.9691 - val_loss: 0.1240 - val_accuracy: 0.9487\n",
      "Epoch 10/100\n",
      "453/453 [==============================] - 0s 96us/step - loss: 0.0932 - accuracy: 0.9669 - val_loss: 0.1119 - val_accuracy: 0.9590\n",
      "Epoch 11/100\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.0914 - accuracy: 0.9669 - val_loss: 0.1273 - val_accuracy: 0.9487\n",
      "Epoch 12/100\n",
      "453/453 [==============================] - 0s 176us/step - loss: 0.0923 - accuracy: 0.9625 - val_loss: 0.1120 - val_accuracy: 0.9590\n",
      "Epoch 13/100\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.0964 - accuracy: 0.9691 - val_loss: 0.1357 - val_accuracy: 0.9436\n",
      "Epoch 14/100\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.0951 - accuracy: 0.9625 - val_loss: 0.1106 - val_accuracy: 0.9487\n",
      "Epoch 15/100\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.0949 - accuracy: 0.9625 - val_loss: 0.1177 - val_accuracy: 0.9590\n",
      "Epoch 16/100\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.0924 - accuracy: 0.9691 - val_loss: 0.1094 - val_accuracy: 0.9487\n",
      "Epoch 17/100\n",
      "453/453 [==============================] - 0s 83us/step - loss: 0.0977 - accuracy: 0.9779 - val_loss: 0.2780 - val_accuracy: 0.9231\n",
      "Epoch 18/100\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2192 - accuracy: 0.9316 - val_loss: 0.6342 - val_accuracy: 0.8923\n",
      "Epoch 19/100\n",
      "453/453 [==============================] - 0s 85us/step - loss: 0.1835 - accuracy: 0.9558 - val_loss: 0.9692 - val_accuracy: 0.8821\n",
      "Epoch 20/100\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.2034 - accuracy: 0.9404 - val_loss: 0.1388 - val_accuracy: 0.9487\n",
      "Epoch 21/100\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.1300 - accuracy: 0.9382 - val_loss: 0.1109 - val_accuracy: 0.9590\n",
      "Epoch 22/100\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.1138 - accuracy: 0.9536 - val_loss: 0.1829 - val_accuracy: 0.9026\n",
      "Epoch 23/100\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.0879 - accuracy: 0.9625 - val_loss: 0.1134 - val_accuracy: 0.9590\n",
      "Epoch 24/100\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.0866 - accuracy: 0.9647 - val_loss: 0.1104 - val_accuracy: 0.9487\n",
      "Epoch 25/100\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.0853 - accuracy: 0.9647 - val_loss: 0.1075 - val_accuracy: 0.9487\n",
      "Epoch 26/100\n",
      "453/453 [==============================] - 0s 282us/step - loss: 0.0821 - accuracy: 0.9669 - val_loss: 0.1133 - val_accuracy: 0.9641\n",
      "Epoch 27/100\n",
      "453/453 [==============================] - 0s 345us/step - loss: 0.0807 - accuracy: 0.9691 - val_loss: 0.1069 - val_accuracy: 0.9487\n",
      "Epoch 28/100\n",
      "453/453 [==============================] - 0s 265us/step - loss: 0.0797 - accuracy: 0.9669 - val_loss: 0.1112 - val_accuracy: 0.9487\n",
      "Epoch 29/100\n",
      "453/453 [==============================] - 0s 182us/step - loss: 0.0797 - accuracy: 0.9669 - val_loss: 0.1116 - val_accuracy: 0.9487\n",
      "Epoch 30/100\n",
      "453/453 [==============================] - 0s 186us/step - loss: 0.0783 - accuracy: 0.9691 - val_loss: 0.1046 - val_accuracy: 0.9487\n",
      "Epoch 31/100\n",
      "453/453 [==============================] - 0s 486us/step - loss: 0.0792 - accuracy: 0.9647 - val_loss: 0.1069 - val_accuracy: 0.9487\n",
      "Epoch 32/100\n",
      "453/453 [==============================] - 0s 144us/step - loss: 0.0773 - accuracy: 0.9625 - val_loss: 0.1036 - val_accuracy: 0.9590\n",
      "Epoch 33/100\n",
      "453/453 [==============================] - 0s 223us/step - loss: 0.0802 - accuracy: 0.9691 - val_loss: 0.1172 - val_accuracy: 0.9641\n",
      "Epoch 34/100\n",
      "453/453 [==============================] - ETA: 0s - loss: 0.1178 - accuracy: 0.93 - 0s 144us/step - loss: 0.0788 - accuracy: 0.9647 - val_loss: 0.1139 - val_accuracy: 0.9641\n",
      "Epoch 35/100\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.0757 - accuracy: 0.9779 - val_loss: 0.1090 - val_accuracy: 0.9538\n",
      "Epoch 36/100\n",
      "453/453 [==============================] - 0s 134us/step - loss: 0.0742 - accuracy: 0.9669 - val_loss: 0.1101 - val_accuracy: 0.9590\n",
      "Epoch 37/100\n",
      "453/453 [==============================] - 0s 197us/step - loss: 0.0746 - accuracy: 0.9735 - val_loss: 0.0979 - val_accuracy: 0.9590\n",
      "Epoch 38/100\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.0751 - accuracy: 0.9735 - val_loss: 0.1137 - val_accuracy: 0.9641\n",
      "Epoch 39/100\n",
      "453/453 [==============================] - 0s 87us/step - loss: 0.0731 - accuracy: 0.9713 - val_loss: 0.1014 - val_accuracy: 0.9487\n",
      "Epoch 40/100\n",
      "453/453 [==============================] - 0s 96us/step - loss: 0.0736 - accuracy: 0.9757 - val_loss: 0.1243 - val_accuracy: 0.9538\n",
      "Epoch 41/100\n",
      "453/453 [==============================] - 0s 96us/step - loss: 0.0777 - accuracy: 0.9669 - val_loss: 0.0990 - val_accuracy: 0.9590\n",
      "Epoch 42/100\n",
      "453/453 [==============================] - 0s 87us/step - loss: 0.0778 - accuracy: 0.9691 - val_loss: 0.1122 - val_accuracy: 0.9641\n",
      "Epoch 43/100\n",
      "453/453 [==============================] - 0s 86us/step - loss: 0.0708 - accuracy: 0.9735 - val_loss: 0.0973 - val_accuracy: 0.9641\n",
      "Epoch 44/100\n",
      "453/453 [==============================] - 0s 84us/step - loss: 0.0716 - accuracy: 0.9779 - val_loss: 0.1041 - val_accuracy: 0.9538\n",
      "Epoch 45/100\n",
      "453/453 [==============================] - 0s 79us/step - loss: 0.0739 - accuracy: 0.9779 - val_loss: 0.1145 - val_accuracy: 0.9590\n",
      "Epoch 46/100\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.0695 - accuracy: 0.9735 - val_loss: 0.1047 - val_accuracy: 0.9590\n",
      "Epoch 47/100\n",
      "453/453 [==============================] - 0s 82us/step - loss: 0.0678 - accuracy: 0.9713 - val_loss: 0.1123 - val_accuracy: 0.9641\n",
      "Epoch 48/100\n",
      "453/453 [==============================] - 0s 73us/step - loss: 0.0701 - accuracy: 0.9713 - val_loss: 0.1007 - val_accuracy: 0.9590\n",
      "Epoch 49/100\n",
      "453/453 [==============================] - 0s 76us/step - loss: 0.0758 - accuracy: 0.9757 - val_loss: 0.2063 - val_accuracy: 0.9282\n",
      "Epoch 50/100\n",
      "453/453 [==============================] - 0s 73us/step - loss: 0.0817 - accuracy: 0.9625 - val_loss: 0.1253 - val_accuracy: 0.9590\n",
      "Epoch 51/100\n",
      "453/453 [==============================] - 0s 78us/step - loss: 0.0718 - accuracy: 0.9625 - val_loss: 0.0957 - val_accuracy: 0.9590\n",
      "Epoch 52/100\n",
      "453/453 [==============================] - 0s 83us/step - loss: 0.0683 - accuracy: 0.9713 - val_loss: 0.0986 - val_accuracy: 0.9590\n",
      "Epoch 53/100\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.0779 - accuracy: 0.9735 - val_loss: 0.1459 - val_accuracy: 0.9385\n",
      "Epoch 54/100\n",
      "453/453 [==============================] - 0s 204us/step - loss: 0.0676 - accuracy: 0.9779 - val_loss: 0.0956 - val_accuracy: 0.9487\n",
      "Epoch 55/100\n",
      "453/453 [==============================] - 0s 91us/step - loss: 0.0670 - accuracy: 0.9713 - val_loss: 0.1127 - val_accuracy: 0.9487\n",
      "Epoch 56/100\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.0649 - accuracy: 0.9757 - val_loss: 0.1097 - val_accuracy: 0.9641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "453/453 [==============================] - 0s 178us/step - loss: 0.0657 - accuracy: 0.9647 - val_loss: 0.1025 - val_accuracy: 0.9641\n",
      "Epoch 58/100\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.0632 - accuracy: 0.9757 - val_loss: 0.1026 - val_accuracy: 0.9641\n",
      "Epoch 59/100\n",
      "453/453 [==============================] - 0s 401us/step - loss: 0.0662 - accuracy: 0.9603 - val_loss: 0.1048 - val_accuracy: 0.9641\n",
      "Epoch 60/100\n",
      "453/453 [==============================] - 0s 176us/step - loss: 0.0635 - accuracy: 0.9801 - val_loss: 0.0985 - val_accuracy: 0.9538\n",
      "Epoch 61/100\n",
      " 32/453 [=>............................] - ETA: 0s - loss: 0.0707 - accuracy: 0.9375"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/keras/callbacks/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.100914). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 128us/step - loss: 0.0636 - accuracy: 0.9823 - val_loss: 0.1213 - val_accuracy: 0.9590\n",
      "Epoch 62/100\n",
      "453/453 [==============================] - 0s 92us/step - loss: 0.0786 - accuracy: 0.9647 - val_loss: 0.0952 - val_accuracy: 0.9590\n",
      "Epoch 63/100\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.0655 - accuracy: 0.9735 - val_loss: 0.1003 - val_accuracy: 0.9487\n",
      "Epoch 64/100\n",
      "453/453 [==============================] - 0s 133us/step - loss: 0.0636 - accuracy: 0.9757 - val_loss: 0.1051 - val_accuracy: 0.9641\n",
      "Epoch 65/100\n",
      "453/453 [==============================] - 0s 138us/step - loss: 0.0670 - accuracy: 0.9713 - val_loss: 0.1601 - val_accuracy: 0.9385\n",
      "Epoch 66/100\n",
      "453/453 [==============================] - 0s 181us/step - loss: 0.0621 - accuracy: 0.9735 - val_loss: 0.0968 - val_accuracy: 0.9487\n",
      "Epoch 67/100\n",
      "453/453 [==============================] - 0s 192us/step - loss: 0.0637 - accuracy: 0.9801 - val_loss: 0.1054 - val_accuracy: 0.9590\n",
      "Epoch 68/100\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.0638 - accuracy: 0.9735 - val_loss: 0.1537 - val_accuracy: 0.9333\n",
      "Epoch 69/100\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.0684 - accuracy: 0.9713 - val_loss: 0.1110 - val_accuracy: 0.9641\n",
      "Epoch 70/100\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.0609 - accuracy: 0.9801 - val_loss: 0.1423 - val_accuracy: 0.9282\n",
      "Epoch 71/100\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.0696 - accuracy: 0.9801 - val_loss: 0.0979 - val_accuracy: 0.9487\n",
      "Epoch 72/100\n",
      "453/453 [==============================] - 0s 182us/step - loss: 0.0906 - accuracy: 0.9691 - val_loss: 0.1306 - val_accuracy: 0.9641\n",
      "Epoch 73/100\n",
      "453/453 [==============================] - 0s 152us/step - loss: 0.0771 - accuracy: 0.9691 - val_loss: 0.2599 - val_accuracy: 0.9128\n",
      "Epoch 74/100\n",
      "453/453 [==============================] - 0s 217us/step - loss: 0.0746 - accuracy: 0.9669 - val_loss: 0.3017 - val_accuracy: 0.9231\n",
      "Epoch 75/100\n",
      "453/453 [==============================] - 0s 486us/step - loss: 0.0703 - accuracy: 0.9713 - val_loss: 0.0937 - val_accuracy: 0.9590\n",
      "Epoch 76/100\n",
      "453/453 [==============================] - 0s 254us/step - loss: 0.0615 - accuracy: 0.9735 - val_loss: 0.0972 - val_accuracy: 0.9538\n",
      "Epoch 77/100\n",
      "453/453 [==============================] - 0s 203us/step - loss: 0.0564 - accuracy: 0.9779 - val_loss: 0.1061 - val_accuracy: 0.9641\n",
      "Epoch 78/100\n",
      "453/453 [==============================] - 0s 202us/step - loss: 0.0562 - accuracy: 0.9757 - val_loss: 0.1015 - val_accuracy: 0.9641\n",
      "Epoch 79/100\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.0565 - accuracy: 0.9823 - val_loss: 0.0910 - val_accuracy: 0.9641\n",
      "Epoch 80/100\n",
      "453/453 [==============================] - 0s 172us/step - loss: 0.0570 - accuracy: 0.9801 - val_loss: 0.0956 - val_accuracy: 0.9538\n",
      "Epoch 81/100\n",
      "453/453 [==============================] - 0s 158us/step - loss: 0.0568 - accuracy: 0.9757 - val_loss: 0.1043 - val_accuracy: 0.9641\n",
      "Epoch 82/100\n",
      "453/453 [==============================] - 0s 97us/step - loss: 0.0547 - accuracy: 0.9801 - val_loss: 0.0954 - val_accuracy: 0.9538\n",
      "Epoch 83/100\n",
      "453/453 [==============================] - 0s 80us/step - loss: 0.0545 - accuracy: 0.9801 - val_loss: 0.1067 - val_accuracy: 0.9744\n",
      "Epoch 84/100\n",
      "453/453 [==============================] - 0s 162us/step - loss: 0.0694 - accuracy: 0.9713 - val_loss: 0.0884 - val_accuracy: 0.9590\n",
      "Epoch 85/100\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.0598 - accuracy: 0.9779 - val_loss: 0.1111 - val_accuracy: 0.9641\n",
      "Epoch 86/100\n",
      "453/453 [==============================] - 0s 157us/step - loss: 0.0554 - accuracy: 0.9779 - val_loss: 0.0959 - val_accuracy: 0.9538\n",
      "Epoch 87/100\n",
      "453/453 [==============================] - 0s 183us/step - loss: 0.0531 - accuracy: 0.9845 - val_loss: 0.1351 - val_accuracy: 0.9333\n",
      "Epoch 88/100\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.0530 - accuracy: 0.9801 - val_loss: 0.0907 - val_accuracy: 0.9641\n",
      "Epoch 89/100\n",
      "453/453 [==============================] - 0s 157us/step - loss: 0.0548 - accuracy: 0.9801 - val_loss: 0.1178 - val_accuracy: 0.9436\n",
      "Epoch 90/100\n",
      "453/453 [==============================] - 0s 155us/step - loss: 0.0628 - accuracy: 0.9801 - val_loss: 0.1005 - val_accuracy: 0.9641\n",
      "Epoch 91/100\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.0592 - accuracy: 0.9845 - val_loss: 0.1317 - val_accuracy: 0.9487\n",
      "Epoch 92/100\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.0551 - accuracy: 0.9823 - val_loss: 0.0926 - val_accuracy: 0.9538\n",
      "Epoch 93/100\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.0544 - accuracy: 0.9845 - val_loss: 0.1112 - val_accuracy: 0.9641\n",
      "Epoch 94/100\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.0519 - accuracy: 0.9779 - val_loss: 0.0998 - val_accuracy: 0.9538\n",
      "Epoch 95/100\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.0522 - accuracy: 0.9823 - val_loss: 0.0939 - val_accuracy: 0.9641\n",
      "Epoch 96/100\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.0508 - accuracy: 0.9823 - val_loss: 0.0916 - val_accuracy: 0.9641\n",
      "Epoch 97/100\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.0522 - accuracy: 0.9801 - val_loss: 0.0976 - val_accuracy: 0.9538\n",
      "Epoch 98/100\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.0664 - accuracy: 0.9801 - val_loss: 0.1113 - val_accuracy: 0.9641\n",
      "Epoch 99/100\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.0567 - accuracy: 0.9779 - val_loss: 0.0987 - val_accuracy: 0.9538\n",
      "Epoch 100/100\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.0554 - accuracy: 0.9823 - val_loss: 0.0962 - val_accuracy: 0.9538\n"
     ]
    }
   ],
   "source": [
    "hist1_over3 = model1_over3.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 97.08%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over3.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba3 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_2.xlsx\",\n",
    "                        sheet_name=2,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>0.013518</td>\n",
       "      <td>9.820048e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>0.013518</td>\n",
       "      <td>9.820048e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS222</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.851725</td>\n",
       "      <td>0.148269</td>\n",
       "      <td>5.980786e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>0.013518</td>\n",
       "      <td>9.820048e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>GA50245</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.812055</td>\n",
       "      <td>0.187945</td>\n",
       "      <td>1.161034e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4279</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>0.000928</td>\n",
       "      <td>9.984396e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4280</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>0.000928</td>\n",
       "      <td>9.984396e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4281</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS266</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.025932</td>\n",
       "      <td>0.974061</td>\n",
       "      <td>7.323514e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4282</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000597</td>\n",
       "      <td>0.999403</td>\n",
       "      <td>3.675362e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4283</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS112</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>0.999452</td>\n",
       "      <td>1.168620e-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4284 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    phage   strain  phenotype  prediction         0         1  \\\n",
       "0      p002ykpresabs_qual   NRS109          2           2  0.004477  0.013518   \n",
       "1      p002ykpresabs_qual   NRS109          2           2  0.004477  0.013518   \n",
       "2      p002ykpresabs_qual   NRS222          0           0  0.851725  0.148269   \n",
       "3      p002ykpresabs_qual   NRS109          2           2  0.004477  0.013518   \n",
       "4      p002ykpresabs_qual  GA50245          0           0  0.812055  0.187945   \n",
       "...                   ...      ...        ...         ...       ...       ...   \n",
       "4279  pyopresabsSTCC_qual   NRS255          2           2  0.000633  0.000928   \n",
       "4280  pyopresabsSTCC_qual   NRS255          2           2  0.000633  0.000928   \n",
       "4281  pyopresabsSTCC_qual   NRS266          1           1  0.025932  0.974061   \n",
       "4282  pyopresabsSTCC_qual   NRS001          1           1  0.000597  0.999403   \n",
       "4283  pyopresabsSTCC_qual   NRS112          1           1  0.000537  0.999452   \n",
       "\n",
       "                 2  \n",
       "0     9.820048e-01  \n",
       "1     9.820048e-01  \n",
       "2     5.980786e-06  \n",
       "3     9.820048e-01  \n",
       "4     1.161034e-07  \n",
       "...            ...  \n",
       "4279  9.984396e-01  \n",
       "4280  9.984396e-01  \n",
       "4281  7.323514e-06  \n",
       "4282  3.675362e-10  \n",
       "4283  1.168620e-05  \n",
       "\n",
       "[4284 rows x 7 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.63180710e-02, 9.73601160e-01, 8.07495450e-05],\n",
       "       [4.29265560e-05, 9.99952200e-01, 4.87588930e-06],\n",
       "       [9.73985530e-04, 2.33714930e-03, 9.96688900e-01],\n",
       "       [5.92387050e-06, 9.99980450e-01, 1.36290280e-05],\n",
       "       [9.73985530e-04, 2.33714930e-03, 9.96688900e-01],\n",
       "       [4.94338750e-01, 5.05638960e-01, 2.23278100e-05],\n",
       "       [9.90479050e-01, 9.51550200e-03, 5.48244400e-06],\n",
       "       [2.63180710e-02, 9.73601160e-01, 8.07495450e-05],\n",
       "       [9.29314430e-01, 7.06854700e-02, 1.28846000e-07],\n",
       "       [4.29265560e-05, 9.99952200e-01, 4.87588930e-06],\n",
       "       [5.02546200e-01, 4.97434650e-01, 1.90863280e-05],\n",
       "       [9.99141700e-01, 8.58285350e-04, 2.29634800e-10],\n",
       "       [4.29265560e-05, 9.99952200e-01, 4.87588930e-06],\n",
       "       [5.57202800e-04, 9.94291070e-01, 5.15168700e-03],\n",
       "       [4.59480020e-01, 5.40519100e-01, 8.91815600e-07],\n",
       "       [1.07313940e-03, 1.55146950e-04, 9.98771700e-01],\n",
       "       [5.59421500e-01, 4.39948800e-01, 6.29719000e-04],\n",
       "       [1.07313940e-03, 1.55146950e-04, 9.98771700e-01],\n",
       "       [9.99892000e-01, 4.87038450e-05, 5.92380170e-05],\n",
       "       [5.40065900e-01, 4.59331840e-01, 6.02208100e-04],\n",
       "       [9.09399500e-02, 9.08491300e-01, 5.68782270e-04],\n",
       "       [1.07313940e-03, 1.55146950e-04, 9.98771700e-01],\n",
       "       [9.15406600e-03, 9.90845600e-01, 3.23553820e-07],\n",
       "       [9.89253460e-01, 1.06112870e-02, 1.35273320e-04],\n",
       "       [9.73985530e-04, 2.33714930e-03, 9.96688900e-01],\n",
       "       [9.39332100e-01, 5.96803950e-02, 9.87408900e-04],\n",
       "       [1.03404530e-01, 8.96288500e-01, 3.06930950e-04],\n",
       "       [9.99555500e-01, 4.44506000e-04, 1.72878370e-08],\n",
       "       [9.99141700e-01, 8.58285350e-04, 2.29634800e-10],\n",
       "       [9.96621400e-01, 3.37866720e-03, 6.34853700e-14],\n",
       "       [8.82211700e-01, 1.17786050e-01, 2.16184620e-06],\n",
       "       [9.43450000e-01, 5.65326960e-02, 1.73230750e-05],\n",
       "       [1.07313940e-03, 1.55146950e-04, 9.98771700e-01],\n",
       "       [3.45732800e-05, 9.99954200e-01, 1.12594860e-05],\n",
       "       [3.03334780e-02, 9.69664040e-01, 2.50182530e-06],\n",
       "       [1.02249876e-01, 8.95878600e-01, 1.87150240e-03],\n",
       "       [9.73985530e-04, 2.33714930e-03, 9.96688900e-01],\n",
       "       [9.73985530e-04, 2.33714930e-03, 9.96688900e-01],\n",
       "       [9.09399500e-02, 9.08491300e-01, 5.68782270e-04],\n",
       "       [8.68033650e-01, 1.31962930e-01, 3.39619120e-06],\n",
       "       [9.73985530e-04, 2.33714930e-03, 9.96688900e-01],\n",
       "       [2.63180710e-02, 9.73601160e-01, 8.07495450e-05],\n",
       "       [1.41686700e-01, 8.58120260e-01, 1.93028260e-04],\n",
       "       [9.74662360e-01, 2.51534950e-02, 1.84157900e-04],\n",
       "       [9.73985530e-04, 2.33714930e-03, 9.96688900e-01],\n",
       "       [9.73985530e-04, 2.33714930e-03, 9.96688900e-01],\n",
       "       [1.07313940e-03, 1.55146950e-04, 9.98771700e-01],\n",
       "       [9.73985530e-04, 2.33714930e-03, 9.96688900e-01],\n",
       "       [1.07313940e-03, 1.55146950e-04, 9.98771700e-01],\n",
       "       [9.09399500e-02, 9.08491300e-01, 5.68782270e-04],\n",
       "       [1.07313940e-03, 1.55146950e-04, 9.98771700e-01],\n",
       "       [1.07313940e-03, 1.55146950e-04, 9.98771700e-01],\n",
       "       [1.16854270e-01, 8.83129900e-01, 1.57839680e-05],\n",
       "       [8.82567100e-01, 1.17432885e-01, 8.34856200e-14],\n",
       "       [1.07313940e-03, 1.55146950e-04, 9.98771700e-01],\n",
       "       [9.73985530e-04, 2.33714930e-03, 9.96688900e-01],\n",
       "       [5.80166280e-02, 9.41982450e-01, 8.82246870e-07],\n",
       "       [2.09540000e-01, 7.90437500e-01, 2.24985230e-05],\n",
       "       [4.94489550e-01, 4.93153130e-01, 1.23573360e-02],\n",
       "       [9.09399500e-02, 9.08491300e-01, 5.68782270e-04],\n",
       "       [1.33617110e-02, 9.86619200e-01, 1.91637300e-05],\n",
       "       [9.99983430e-01, 1.65251000e-05, 2.10914560e-08],\n",
       "       [9.90728600e-01, 9.27127900e-03, 1.66208850e-07],\n",
       "       [5.57202800e-04, 9.94291070e-01, 5.15168700e-03],\n",
       "       [9.99996300e-01, 3.22011280e-06, 4.61045000e-07],\n",
       "       [5.80166280e-02, 9.41982450e-01, 8.82246870e-07],\n",
       "       [8.25195900e-01, 1.74697970e-01, 1.06156090e-04],\n",
       "       [9.73985530e-04, 2.33714930e-03, 9.96688900e-01],\n",
       "       [9.73985530e-04, 2.33714930e-03, 9.96688900e-01],\n",
       "       [9.99999760e-01, 6.26730000e-08, 1.08985050e-07],\n",
       "       [9.77381000e-01, 2.26189550e-02, 1.72364750e-08],\n",
       "       [9.98553450e-01, 1.44169010e-03, 4.89470800e-06],\n",
       "       [4.94316970e-01, 5.05671500e-01, 1.15641490e-05],\n",
       "       [9.82352800e-01, 1.76453310e-02, 1.82637510e-06],\n",
       "       [1.07313940e-03, 1.55146950e-04, 9.98771700e-01],\n",
       "       [9.84551130e-01, 1.54489030e-02, 4.55995950e-14],\n",
       "       [3.47889900e-02, 9.62370800e-01, 2.84025980e-03],\n",
       "       [9.99710260e-01, 2.82413300e-04, 7.25346040e-06],\n",
       "       [5.70862700e-01, 4.29136800e-01, 5.18653300e-07],\n",
       "       [9.73985530e-04, 2.33714930e-03, 9.96688900e-01],\n",
       "       [1.75155580e-01, 8.23495700e-01, 1.34868830e-03],\n",
       "       [9.99995100e-01, 4.18865800e-06, 7.07560400e-07],\n",
       "       [1.07313940e-03, 1.55146950e-04, 9.98771700e-01],\n",
       "       [9.98553450e-01, 1.44169010e-03, 4.89470800e-06],\n",
       "       [1.07313940e-03, 1.55146950e-04, 9.98771700e-01],\n",
       "       [1.41686700e-01, 8.58120260e-01, 1.93028260e-04],\n",
       "       [7.20318500e-02, 9.27809400e-01, 1.58698950e-04],\n",
       "       [9.73985530e-04, 2.33714930e-03, 9.96688900e-01],\n",
       "       [7.25824270e-04, 9.99274200e-01, 5.57883600e-10],\n",
       "       [9.73985530e-04, 2.33714930e-03, 9.96688900e-01],\n",
       "       [9.74647760e-01, 2.53522710e-02, 1.09039230e-08],\n",
       "       [5.96259000e-01, 4.03697820e-01, 4.32244780e-05],\n",
       "       [1.07313940e-03, 1.55146950e-04, 9.98771700e-01],\n",
       "       [9.98810900e-01, 1.18909080e-03, 8.38182600e-09],\n",
       "       [9.17936800e-06, 9.99984400e-01, 6.41175940e-06],\n",
       "       [1.07313940e-03, 1.55146950e-04, 9.98771700e-01],\n",
       "       [9.17936800e-06, 9.99984400e-01, 6.41175940e-06],\n",
       "       [1.78346620e-01, 8.21647200e-01, 6.17325900e-06],\n",
       "       [9.73985530e-04, 2.33714930e-03, 9.96688900e-01],\n",
       "       [9.73985530e-04, 2.33714930e-03, 9.96688900e-01],\n",
       "       [1.07313940e-03, 1.55146950e-04, 9.98771700e-01],\n",
       "       [9.73985530e-04, 2.33714930e-03, 9.96688900e-01],\n",
       "       [9.73985530e-04, 2.33714930e-03, 9.96688900e-01],\n",
       "       [1.59232870e-01, 8.40714340e-01, 5.27669730e-05],\n",
       "       [7.19509540e-01, 2.80407200e-01, 8.32199900e-05],\n",
       "       [9.73985530e-04, 2.33714930e-03, 9.96688900e-01],\n",
       "       [4.80663450e-01, 5.15755240e-01, 3.58136860e-03],\n",
       "       [1.07313940e-03, 1.55146950e-04, 9.98771700e-01],\n",
       "       [9.96040460e-01, 3.92606060e-03, 3.34340730e-05],\n",
       "       [2.68605260e-01, 7.31392800e-01, 1.94279140e-06],\n",
       "       [1.07313940e-03, 1.55146950e-04, 9.98771700e-01],\n",
       "       [5.40065900e-01, 4.59331840e-01, 6.02208100e-04],\n",
       "       [5.57202800e-04, 9.94291070e-01, 5.15168700e-03],\n",
       "       [9.59923800e-01, 4.00745800e-02, 1.59828890e-06],\n",
       "       [3.47889900e-02, 9.62370800e-01, 2.84025980e-03],\n",
       "       [5.80166280e-02, 9.41982450e-01, 8.82246870e-07],\n",
       "       [1.07313940e-03, 1.55146950e-04, 9.98771700e-01],\n",
       "       [9.73985530e-04, 2.33714930e-03, 9.96688900e-01],\n",
       "       [2.68605260e-01, 7.31392800e-01, 1.94279140e-06],\n",
       "       [9.09399500e-02, 9.08491300e-01, 5.68782270e-04],\n",
       "       [1.41686700e-01, 8.58120260e-01, 1.93028260e-04],\n",
       "       [9.70864200e-01, 2.91356480e-02, 2.60950120e-07],\n",
       "       [1.07313940e-03, 1.55146950e-04, 9.98771700e-01],\n",
       "       [7.25171640e-02, 8.99022000e-01, 2.84608140e-02],\n",
       "       [4.29265560e-05, 9.99952200e-01, 4.87588930e-06],\n",
       "       [8.51814600e-01, 1.47981260e-01, 2.04152690e-04],\n",
       "       [5.57202800e-04, 9.94291070e-01, 5.15168700e-03],\n",
       "       [9.99919060e-01, 7.87184100e-05, 2.26856600e-06],\n",
       "       [1.07313940e-03, 1.55146950e-04, 9.98771700e-01],\n",
       "       [9.73985530e-04, 2.33714930e-03, 9.96688900e-01],\n",
       "       [9.25213750e-01, 7.47416400e-02, 4.46068880e-05],\n",
       "       [6.79797500e-02, 9.31878000e-01, 1.42251960e-04],\n",
       "       [1.07313940e-03, 1.55146950e-04, 9.98771700e-01],\n",
       "       [9.73985530e-04, 2.33714930e-03, 9.96688900e-01],\n",
       "       [1.33617110e-02, 9.86619200e-01, 1.91637300e-05],\n",
       "       [9.73985530e-04, 2.33714930e-03, 9.96688900e-01],\n",
       "       [1.07313940e-03, 1.55146950e-04, 9.98771700e-01],\n",
       "       [9.73985530e-04, 2.33714930e-03, 9.96688900e-01],\n",
       "       [9.99064500e-01, 9.35512400e-04, 2.31773370e-08],\n",
       "       [1.41686700e-01, 8.58120260e-01, 1.93028260e-04],\n",
       "       [4.96408050e-01, 5.03574670e-01, 1.72414780e-05],\n",
       "       [7.34491770e-01, 2.65173600e-01, 3.34562330e-04],\n",
       "       [1.07313940e-03, 1.55146950e-04, 9.98771700e-01],\n",
       "       [9.15406600e-03, 9.90845600e-01, 3.23553820e-07],\n",
       "       [9.17936800e-06, 9.99984400e-01, 6.41175940e-06],\n",
       "       [1.78346620e-01, 8.21647200e-01, 6.17325900e-06],\n",
       "       [9.73985530e-04, 2.33714930e-03, 9.96688900e-01],\n",
       "       [9.99988440e-01, 8.55547000e-06, 2.98931950e-06],\n",
       "       [1.07313940e-03, 1.55146950e-04, 9.98771700e-01],\n",
       "       [1.07313940e-03, 1.55146950e-04, 9.98771700e-01],\n",
       "       [9.49933350e-01, 5.00662030e-02, 4.28080230e-07],\n",
       "       [1.07313940e-03, 1.55146950e-04, 9.98771700e-01],\n",
       "       [5.80166280e-02, 9.41982450e-01, 8.82246870e-07],\n",
       "       [9.99657030e-01, 3.42909100e-04, 2.39502360e-10],\n",
       "       [9.09399500e-02, 9.08491300e-01, 5.68782270e-04],\n",
       "       [1.07313940e-03, 1.55146950e-04, 9.98771700e-01],\n",
       "       [9.97990130e-01, 2.00990300e-03, 1.23613310e-09],\n",
       "       [1.42893890e-03, 9.98545900e-01, 2.52530900e-05],\n",
       "       [1.16854270e-01, 8.83129900e-01, 1.57839680e-05],\n",
       "       [5.59421500e-01, 4.39948800e-01, 6.29719000e-04],\n",
       "       [7.23026100e-01, 2.76713430e-01, 2.60433760e-04],\n",
       "       [9.73985530e-04, 2.33714930e-03, 9.96688900e-01],\n",
       "       [9.99996300e-01, 3.22011280e-06, 4.61045000e-07],\n",
       "       [9.99998900e-01, 5.74788430e-07, 4.94908760e-07],\n",
       "       [9.99949200e-01, 4.94586500e-05, 1.27538180e-06],\n",
       "       [8.10464300e-01, 1.89495560e-01, 4.00996200e-05],\n",
       "       [1.07313940e-03, 1.55146950e-04, 9.98771700e-01],\n",
       "       [1.07313940e-03, 1.55146950e-04, 9.98771700e-01],\n",
       "       [3.71540430e-01, 6.28367840e-01, 9.17524200e-05],\n",
       "       [7.20318500e-02, 9.27809400e-01, 1.58698950e-04],\n",
       "       [2.53448910e-03, 9.97465500e-01, 2.35725290e-08],\n",
       "       [1.07313940e-03, 1.55146950e-04, 9.98771700e-01],\n",
       "       [3.08991040e-01, 6.91008700e-01, 2.35074450e-07],\n",
       "       [5.92387050e-06, 9.99980450e-01, 1.36290280e-05],\n",
       "       [9.73985530e-04, 2.33714930e-03, 9.96688900e-01],\n",
       "       [1.07313940e-03, 1.55146950e-04, 9.98771700e-01],\n",
       "       [9.99886400e-01, 1.11554735e-04, 1.96995870e-06],\n",
       "       [9.73985530e-04, 2.33714930e-03, 9.96688900e-01],\n",
       "       [1.41686700e-01, 8.58120260e-01, 1.93028260e-04],\n",
       "       [1.31101980e-01, 8.68818800e-01, 7.91894200e-05],\n",
       "       [1.07313940e-03, 1.55146950e-04, 9.98771700e-01],\n",
       "       [9.99866600e-01, 1.24395650e-04, 8.93209000e-06],\n",
       "       [9.73985530e-04, 2.33714930e-03, 9.96688900e-01],\n",
       "       [5.55031260e-02, 9.43575200e-01, 9.21651300e-04],\n",
       "       [5.57202800e-04, 9.94291070e-01, 5.15168700e-03],\n",
       "       [9.98366300e-01, 1.62250700e-03, 1.11850580e-05],\n",
       "       [7.25171640e-02, 8.99022000e-01, 2.84608140e-02],\n",
       "       [1.33617110e-02, 9.86619200e-01, 1.91637300e-05],\n",
       "       [5.97406700e-02, 9.40078100e-01, 1.81360020e-04],\n",
       "       [1.07313940e-03, 1.55146950e-04, 9.98771700e-01],\n",
       "       [9.73985530e-04, 2.33714930e-03, 9.96688900e-01],\n",
       "       [1.07313940e-03, 1.55146950e-04, 9.98771700e-01],\n",
       "       [5.57202800e-04, 9.94291070e-01, 5.15168700e-03],\n",
       "       [2.68605260e-01, 7.31392800e-01, 1.94279140e-06],\n",
       "       [6.79797500e-02, 9.31878000e-01, 1.42251960e-04]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob3 = df_proba3[df_proba3['phage']=='p0017SpresabsSTCC_qual'].iloc[:,-3:]\n",
    "y_prob3 = y_prob3.to_numpy()\n",
    "y_prob3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9927021696252466"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo3 = rocauc_ovo(y_test_over, y_prob3, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9927021696252466"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr3 = rocauc_ovr(y_test_over, y_prob3, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=456,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat4 = pd.DataFrame(X_test_over[:,0])\n",
    "dat4['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS241</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BCH-SA-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS219</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>GA15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>NRS246</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>312</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>CFBREBSa112</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test\n",
       "0         NRS241     1\n",
       "1      BCH-SA-01     1\n",
       "2         NRS219     1\n",
       "3         NRS209     2\n",
       "4         NRS001     1\n",
       "..           ...   ...\n",
       "190         GA15     1\n",
       "191       NRS246     1\n",
       "192          115     1\n",
       "193          312     1\n",
       "194  CFBREBSa112     0\n",
       "\n",
       "[195 rows x 2 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over4 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],)),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over4.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 453 samples, validate on 195 samples\n",
      "Epoch 1/100\n",
      "453/453 [==============================] - 0s 290us/step - loss: 16.2410 - accuracy: 0.2980 - val_loss: 9.9294 - val_accuracy: 0.3385\n",
      "Epoch 2/100\n",
      "453/453 [==============================] - 0s 54us/step - loss: 11.1890 - accuracy: 0.3974 - val_loss: 6.6034 - val_accuracy: 0.4513\n",
      "Epoch 3/100\n",
      "453/453 [==============================] - 0s 82us/step - loss: 7.0869 - accuracy: 0.4547 - val_loss: 3.6466 - val_accuracy: 0.5077\n",
      "Epoch 4/100\n",
      "453/453 [==============================] - 0s 79us/step - loss: 2.7689 - accuracy: 0.4636 - val_loss: 2.5197 - val_accuracy: 0.3897\n",
      "Epoch 5/100\n",
      "453/453 [==============================] - 0s 82us/step - loss: 1.8465 - accuracy: 0.3907 - val_loss: 1.0527 - val_accuracy: 0.4205\n",
      "Epoch 6/100\n",
      "453/453 [==============================] - 0s 95us/step - loss: 1.0844 - accuracy: 0.4636 - val_loss: 0.7405 - val_accuracy: 0.7026\n",
      "Epoch 7/100\n",
      "453/453 [==============================] - 0s 141us/step - loss: 0.8849 - accuracy: 0.7351 - val_loss: 0.9284 - val_accuracy: 0.7897\n",
      "Epoch 8/100\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.8026 - accuracy: 0.7682 - val_loss: 0.7000 - val_accuracy: 0.7949\n",
      "Epoch 9/100\n",
      "453/453 [==============================] - 0s 144us/step - loss: 0.7258 - accuracy: 0.6755 - val_loss: 0.6238 - val_accuracy: 0.6769\n",
      "Epoch 10/100\n",
      "453/453 [==============================] - 0s 87us/step - loss: 0.6306 - accuracy: 0.7638 - val_loss: 0.5968 - val_accuracy: 0.7897\n",
      "Epoch 11/100\n",
      "453/453 [==============================] - 0s 179us/step - loss: 0.6257 - accuracy: 0.7947 - val_loss: 0.5594 - val_accuracy: 0.8308\n",
      "Epoch 12/100\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.6208 - accuracy: 0.6777 - val_loss: 0.5555 - val_accuracy: 0.8564\n",
      "Epoch 13/100\n",
      "453/453 [==============================] - 0s 144us/step - loss: 0.6121 - accuracy: 0.8256 - val_loss: 0.6157 - val_accuracy: 0.8103\n",
      "Epoch 14/100\n",
      "453/453 [==============================] - 0s 73us/step - loss: 0.5508 - accuracy: 0.8146 - val_loss: 0.4662 - val_accuracy: 0.8256\n",
      "Epoch 15/100\n",
      "453/453 [==============================] - 0s 138us/step - loss: 0.4820 - accuracy: 0.8300 - val_loss: 0.4605 - val_accuracy: 0.8256\n",
      "Epoch 16/100\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.4406 - accuracy: 0.8322 - val_loss: 0.4263 - val_accuracy: 0.8308\n",
      "Epoch 17/100\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.4177 - accuracy: 0.8433 - val_loss: 0.4093 - val_accuracy: 0.8410\n",
      "Epoch 18/100\n",
      "453/453 [==============================] - 0s 71us/step - loss: 0.4054 - accuracy: 0.8389 - val_loss: 0.3845 - val_accuracy: 0.8513\n",
      "Epoch 19/100\n",
      "453/453 [==============================] - 0s 63us/step - loss: 0.3847 - accuracy: 0.8521 - val_loss: 0.3960 - val_accuracy: 0.8410\n",
      "Epoch 20/100\n",
      "453/453 [==============================] - 0s 85us/step - loss: 0.3851 - accuracy: 0.8521 - val_loss: 0.3679 - val_accuracy: 0.8513\n",
      "Epoch 21/100\n",
      "453/453 [==============================] - 0s 73us/step - loss: 0.4104 - accuracy: 0.8477 - val_loss: 0.4404 - val_accuracy: 0.8513\n",
      "Epoch 22/100\n",
      "453/453 [==============================] - 0s 92us/step - loss: 0.3762 - accuracy: 0.8455 - val_loss: 0.3775 - val_accuracy: 0.8564\n",
      "Epoch 23/100\n",
      "453/453 [==============================] - 0s 61us/step - loss: 0.3660 - accuracy: 0.8675 - val_loss: 0.4061 - val_accuracy: 0.8667\n",
      "Epoch 24/100\n",
      "453/453 [==============================] - 0s 60us/step - loss: 0.3702 - accuracy: 0.8499 - val_loss: 0.3665 - val_accuracy: 0.8667\n",
      "Epoch 25/100\n",
      "453/453 [==============================] - 0s 83us/step - loss: 0.4015 - accuracy: 0.8631 - val_loss: 0.4360 - val_accuracy: 0.8564\n",
      "Epoch 26/100\n",
      "453/453 [==============================] - 0s 60us/step - loss: 0.3687 - accuracy: 0.8653 - val_loss: 0.3279 - val_accuracy: 0.8718\n",
      "Epoch 27/100\n",
      "453/453 [==============================] - 0s 85us/step - loss: 0.3232 - accuracy: 0.8786 - val_loss: 0.3623 - val_accuracy: 0.8769\n",
      "Epoch 28/100\n",
      "453/453 [==============================] - 0s 63us/step - loss: 0.3406 - accuracy: 0.8720 - val_loss: 0.3065 - val_accuracy: 0.8667\n",
      "Epoch 29/100\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.3030 - accuracy: 0.8808 - val_loss: 0.3190 - val_accuracy: 0.8513\n",
      "Epoch 30/100\n",
      "453/453 [==============================] - 0s 59us/step - loss: 0.3118 - accuracy: 0.8499 - val_loss: 0.3075 - val_accuracy: 0.8462\n",
      "Epoch 31/100\n",
      "453/453 [==============================] - 0s 63us/step - loss: 0.3021 - accuracy: 0.8786 - val_loss: 0.3532 - val_accuracy: 0.8821\n",
      "Epoch 32/100\n",
      "453/453 [==============================] - 0s 80us/step - loss: 0.3067 - accuracy: 0.8808 - val_loss: 0.2992 - val_accuracy: 0.8769\n",
      "Epoch 33/100\n",
      "453/453 [==============================] - 0s 60us/step - loss: 0.3071 - accuracy: 0.8698 - val_loss: 0.3709 - val_accuracy: 0.8462\n",
      "Epoch 34/100\n",
      "453/453 [==============================] - 0s 68us/step - loss: 0.3208 - accuracy: 0.8698 - val_loss: 0.2874 - val_accuracy: 0.9128\n",
      "Epoch 35/100\n",
      "453/453 [==============================] - 0s 52us/step - loss: 0.3023 - accuracy: 0.9117 - val_loss: 0.2763 - val_accuracy: 0.9077\n",
      "Epoch 36/100\n",
      "453/453 [==============================] - 0s 59us/step - loss: 0.2712 - accuracy: 0.9095 - val_loss: 0.2760 - val_accuracy: 0.9026\n",
      "Epoch 37/100\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.2663 - accuracy: 0.9095 - val_loss: 0.2660 - val_accuracy: 0.8974\n",
      "Epoch 38/100\n",
      "453/453 [==============================] - 0s 65us/step - loss: 0.2606 - accuracy: 0.9139 - val_loss: 0.2759 - val_accuracy: 0.8667\n",
      "Epoch 39/100\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2638 - accuracy: 0.9029 - val_loss: 0.2750 - val_accuracy: 0.8974\n",
      "Epoch 40/100\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.3310 - accuracy: 0.8918 - val_loss: 0.4010 - val_accuracy: 0.8667\n",
      "Epoch 41/100\n",
      "453/453 [==============================] - 0s 56us/step - loss: 0.3229 - accuracy: 0.8985 - val_loss: 0.2590 - val_accuracy: 0.9077\n",
      "Epoch 42/100\n",
      "453/453 [==============================] - 0s 48us/step - loss: 0.2566 - accuracy: 0.9029 - val_loss: 0.2880 - val_accuracy: 0.9026\n",
      "Epoch 43/100\n",
      "453/453 [==============================] - 0s 61us/step - loss: 0.2654 - accuracy: 0.9051 - val_loss: 0.2827 - val_accuracy: 0.9026\n",
      "Epoch 44/100\n",
      "453/453 [==============================] - 0s 51us/step - loss: 0.3495 - accuracy: 0.8896 - val_loss: 0.2748 - val_accuracy: 0.8974\n",
      "Epoch 45/100\n",
      "453/453 [==============================] - 0s 77us/step - loss: 0.8185 - accuracy: 0.8565 - val_loss: 0.3178 - val_accuracy: 0.8667\n",
      "Epoch 46/100\n",
      "453/453 [==============================] - 0s 54us/step - loss: 0.5008 - accuracy: 0.8190 - val_loss: 0.7067 - val_accuracy: 0.7897\n",
      "Epoch 47/100\n",
      "453/453 [==============================] - 0s 45us/step - loss: 0.4740 - accuracy: 0.8499 - val_loss: 0.2519 - val_accuracy: 0.9077\n",
      "Epoch 48/100\n",
      "453/453 [==============================] - 0s 50us/step - loss: 0.2879 - accuracy: 0.8830 - val_loss: 0.3375 - val_accuracy: 0.9077\n",
      "Epoch 49/100\n",
      "453/453 [==============================] - 0s 57us/step - loss: 0.2851 - accuracy: 0.8985 - val_loss: 0.2536 - val_accuracy: 0.8667\n",
      "Epoch 50/100\n",
      "453/453 [==============================] - 0s 54us/step - loss: 0.2410 - accuracy: 0.8962 - val_loss: 0.2536 - val_accuracy: 0.8923\n",
      "Epoch 51/100\n",
      "453/453 [==============================] - 0s 81us/step - loss: 0.2401 - accuracy: 0.9029 - val_loss: 0.2496 - val_accuracy: 0.9077\n",
      "Epoch 52/100\n",
      "453/453 [==============================] - 0s 68us/step - loss: 0.2391 - accuracy: 0.8962 - val_loss: 0.2618 - val_accuracy: 0.8564\n",
      "Epoch 53/100\n",
      "453/453 [==============================] - 0s 94us/step - loss: 0.2255 - accuracy: 0.9051 - val_loss: 0.2301 - val_accuracy: 0.9231\n",
      "Epoch 54/100\n",
      "453/453 [==============================] - 0s 72us/step - loss: 0.2206 - accuracy: 0.9272 - val_loss: 0.2268 - val_accuracy: 0.9231\n",
      "Epoch 55/100\n",
      "453/453 [==============================] - 0s 50us/step - loss: 0.2225 - accuracy: 0.9249 - val_loss: 0.2330 - val_accuracy: 0.8718\n",
      "Epoch 56/100\n",
      "453/453 [==============================] - 0s 52us/step - loss: 0.2188 - accuracy: 0.9161 - val_loss: 0.2244 - val_accuracy: 0.9179\n",
      "Epoch 57/100\n",
      "453/453 [==============================] - 0s 48us/step - loss: 0.2115 - accuracy: 0.9360 - val_loss: 0.2192 - val_accuracy: 0.9333\n",
      "Epoch 58/100\n",
      "453/453 [==============================] - 0s 46us/step - loss: 0.2079 - accuracy: 0.9338 - val_loss: 0.2164 - val_accuracy: 0.9179\n",
      "Epoch 59/100\n",
      "453/453 [==============================] - 0s 45us/step - loss: 0.2050 - accuracy: 0.9316 - val_loss: 0.2122 - val_accuracy: 0.9179\n",
      "Epoch 60/100\n",
      "453/453 [==============================] - 0s 66us/step - loss: 0.2033 - accuracy: 0.9316 - val_loss: 0.2145 - val_accuracy: 0.9179\n",
      "Epoch 61/100\n",
      "453/453 [==============================] - 0s 47us/step - loss: 0.2295 - accuracy: 0.9205 - val_loss: 0.2668 - val_accuracy: 0.9077\n",
      "Epoch 62/100\n",
      "453/453 [==============================] - 0s 53us/step - loss: 0.2341 - accuracy: 0.9161 - val_loss: 0.2384 - val_accuracy: 0.9231\n",
      "Epoch 63/100\n",
      "453/453 [==============================] - 0s 87us/step - loss: 0.2265 - accuracy: 0.9205 - val_loss: 0.2794 - val_accuracy: 0.9179\n",
      "Epoch 64/100\n",
      "453/453 [==============================] - 0s 211us/step - loss: 0.2244 - accuracy: 0.9205 - val_loss: 0.2299 - val_accuracy: 0.9179\n",
      "Epoch 65/100\n",
      "453/453 [==============================] - 0s 141us/step - loss: 0.2184 - accuracy: 0.9294 - val_loss: 0.3087 - val_accuracy: 0.9077\n",
      "Epoch 66/100\n",
      "453/453 [==============================] - 0s 83us/step - loss: 0.2848 - accuracy: 0.9161 - val_loss: 0.2063 - val_accuracy: 0.9282\n",
      "Epoch 67/100\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2207 - accuracy: 0.9117 - val_loss: 0.2765 - val_accuracy: 0.9128\n",
      "Epoch 68/100\n",
      "453/453 [==============================] - 0s 76us/step - loss: 0.2534 - accuracy: 0.9249 - val_loss: 0.2117 - val_accuracy: 0.9282\n",
      "Epoch 69/100\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.1993 - accuracy: 0.9227 - val_loss: 0.2027 - val_accuracy: 0.9333\n",
      "Epoch 70/100\n",
      "453/453 [==============================] - 0s 75us/step - loss: 0.1875 - accuracy: 0.9360 - val_loss: 0.2013 - val_accuracy: 0.9333\n",
      "Epoch 71/100\n",
      "453/453 [==============================] - 0s 50us/step - loss: 0.1835 - accuracy: 0.9316 - val_loss: 0.2004 - val_accuracy: 0.9333\n",
      "Epoch 72/100\n",
      "453/453 [==============================] - 0s 88us/step - loss: 0.1818 - accuracy: 0.9382 - val_loss: 0.1976 - val_accuracy: 0.9333\n",
      "Epoch 73/100\n",
      "453/453 [==============================] - 0s 78us/step - loss: 0.1815 - accuracy: 0.9404 - val_loss: 0.1966 - val_accuracy: 0.9333\n",
      "Epoch 74/100\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.1816 - accuracy: 0.9382 - val_loss: 0.1965 - val_accuracy: 0.9333\n",
      "Epoch 75/100\n",
      "453/453 [==============================] - 0s 92us/step - loss: 0.1871 - accuracy: 0.9227 - val_loss: 0.1914 - val_accuracy: 0.9333\n",
      "Epoch 76/100\n",
      "453/453 [==============================] - 0s 146us/step - loss: 0.1858 - accuracy: 0.9316 - val_loss: 0.1967 - val_accuracy: 0.9333\n",
      "Epoch 77/100\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.1805 - accuracy: 0.9338 - val_loss: 0.1895 - val_accuracy: 0.9282\n",
      "Epoch 78/100\n",
      "453/453 [==============================] - 0s 81us/step - loss: 0.1783 - accuracy: 0.9404 - val_loss: 0.1900 - val_accuracy: 0.9436\n",
      "Epoch 79/100\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.1807 - accuracy: 0.9338 - val_loss: 0.1919 - val_accuracy: 0.9179\n",
      "Epoch 80/100\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.1771 - accuracy: 0.9360 - val_loss: 0.1870 - val_accuracy: 0.9231\n",
      "Epoch 81/100\n",
      "453/453 [==============================] - 0s 69us/step - loss: 0.1729 - accuracy: 0.9382 - val_loss: 0.1859 - val_accuracy: 0.9231\n",
      "Epoch 82/100\n",
      "453/453 [==============================] - 0s 62us/step - loss: 0.1777 - accuracy: 0.9338 - val_loss: 0.1954 - val_accuracy: 0.8974\n",
      "Epoch 83/100\n",
      "453/453 [==============================] - 0s 73us/step - loss: 0.1729 - accuracy: 0.9470 - val_loss: 0.1873 - val_accuracy: 0.9333\n",
      "Epoch 84/100\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.1727 - accuracy: 0.9360 - val_loss: 0.1923 - val_accuracy: 0.9077\n",
      "Epoch 85/100\n",
      "453/453 [==============================] - 0s 82us/step - loss: 0.1653 - accuracy: 0.9514 - val_loss: 0.1853 - val_accuracy: 0.9385\n",
      "Epoch 86/100\n",
      "453/453 [==============================] - 0s 180us/step - loss: 0.1668 - accuracy: 0.9470 - val_loss: 0.1877 - val_accuracy: 0.9385\n",
      "Epoch 87/100\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.1647 - accuracy: 0.9514 - val_loss: 0.1835 - val_accuracy: 0.9333\n",
      "Epoch 88/100\n",
      "453/453 [==============================] - 0s 87us/step - loss: 0.1638 - accuracy: 0.9426 - val_loss: 0.1825 - val_accuracy: 0.9385\n",
      "Epoch 89/100\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.1610 - accuracy: 0.9492 - val_loss: 0.1803 - val_accuracy: 0.9333\n",
      "Epoch 90/100\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.1594 - accuracy: 0.9470 - val_loss: 0.1788 - val_accuracy: 0.9333\n",
      "Epoch 91/100\n",
      "453/453 [==============================] - 0s 97us/step - loss: 0.1590 - accuracy: 0.9426 - val_loss: 0.1786 - val_accuracy: 0.9385\n",
      "Epoch 92/100\n",
      "453/453 [==============================] - 0s 83us/step - loss: 0.1601 - accuracy: 0.9448 - val_loss: 0.1782 - val_accuracy: 0.9282\n",
      "Epoch 93/100\n",
      "453/453 [==============================] - 0s 69us/step - loss: 0.1599 - accuracy: 0.9536 - val_loss: 0.1908 - val_accuracy: 0.9128\n",
      "Epoch 94/100\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.1671 - accuracy: 0.9426 - val_loss: 0.1790 - val_accuracy: 0.9385\n",
      "Epoch 95/100\n",
      "453/453 [==============================] - 0s 153us/step - loss: 0.1610 - accuracy: 0.9492 - val_loss: 0.1781 - val_accuracy: 0.9436\n",
      "Epoch 96/100\n",
      "453/453 [==============================] - 0s 142us/step - loss: 0.1609 - accuracy: 0.9492 - val_loss: 0.1811 - val_accuracy: 0.9333\n",
      "Epoch 97/100\n",
      "453/453 [==============================] - 0s 78us/step - loss: 0.1543 - accuracy: 0.9536 - val_loss: 0.1746 - val_accuracy: 0.9436\n",
      "Epoch 98/100\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.1560 - accuracy: 0.9448 - val_loss: 0.1732 - val_accuracy: 0.9436\n",
      "Epoch 99/100\n",
      "453/453 [==============================] - 0s 77us/step - loss: 0.1498 - accuracy: 0.9514 - val_loss: 0.1748 - val_accuracy: 0.9436\n",
      "Epoch 100/100\n",
      "453/453 [==============================] - 0s 67us/step - loss: 0.1511 - accuracy: 0.9558 - val_loss: 0.1727 - val_accuracy: 0.9436\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a3540ef98>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over4.fit(X_train_over, y_train_over,\n",
    "          batch_size=64, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195/195 [==============================] - 0s 118us/step\n",
      "over-sampling test accuracy: 93.85%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over4 = model1_over4.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over4*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 2, 1, 2, 1, 1, 2, 2, 2, 0, 0, 0, 1, 2, 2, 2, 2, 0, 0, 1,\n",
       "       1, 2, 1, 0, 0, 0, 2, 1, 2, 1, 2, 2, 2, 0, 0, 2, 0, 2, 1, 2, 1, 0,\n",
       "       0, 0, 2, 2, 1, 1, 2, 0, 1, 2, 1, 2, 1, 0, 0, 1, 1, 1, 0, 1, 2, 0,\n",
       "       1, 0, 0, 2, 1, 1, 2, 1, 1, 0, 2, 1, 0, 2, 1, 0, 2, 2, 2, 1, 2, 2,\n",
       "       2, 2, 1, 0, 1, 0, 1, 1, 1, 2, 2, 2, 0, 0, 0, 1, 1, 2, 0, 2, 1, 0,\n",
       "       2, 2, 0, 2, 2, 1, 2, 2, 2, 1, 0, 0, 2, 2, 2, 1, 0, 1, 2, 0, 1, 1,\n",
       "       1, 0, 1, 1, 2, 1, 1, 2, 2, 2, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 2, 1,\n",
       "       0, 0, 0, 0, 1, 1, 2, 0, 2, 1, 2, 0, 0, 2, 0, 2, 1, 0, 0, 2, 0, 0,\n",
       "       1, 2, 1, 0, 1, 2, 0, 2, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred4 = model1_over4.predict_classes(X_test_over)\n",
    "pred4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS241</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BCH-SA-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS219</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>GA15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>NRS246</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>312</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>CFBREBSa112</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test  pred\n",
       "0         NRS241     1     1\n",
       "1      BCH-SA-01     1     1\n",
       "2         NRS219     1     0\n",
       "3         NRS209     2     2\n",
       "4         NRS001     1     1\n",
       "..           ...   ...   ...\n",
       "190         GA15     1     1\n",
       "191       NRS246     1     1\n",
       "192          115     1     1\n",
       "193          312     1     1\n",
       "194  CFBREBSa112     0     0\n",
       "\n",
       "[195 rows x 3 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat4['pred'] = pred4\n",
    "dat4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba4 = model1_over4.predict_proba(X_test_over)\n",
    "dat_proba4 = pd.DataFrame(proba4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.072540</td>\n",
       "      <td>0.924324</td>\n",
       "      <td>3.135318e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.145944</td>\n",
       "      <td>0.853712</td>\n",
       "      <td>3.438867e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.772667</td>\n",
       "      <td>0.222506</td>\n",
       "      <td>4.826286e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.008321</td>\n",
       "      <td>0.012965</td>\n",
       "      <td>9.787133e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.373947</td>\n",
       "      <td>0.624066</td>\n",
       "      <td>1.986789e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>0.387804</td>\n",
       "      <td>0.610818</td>\n",
       "      <td>1.377677e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>0.441195</td>\n",
       "      <td>0.546824</td>\n",
       "      <td>1.198106e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>0.031148</td>\n",
       "      <td>0.968094</td>\n",
       "      <td>7.574646e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>0.224255</td>\n",
       "      <td>0.775738</td>\n",
       "      <td>6.864440e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>0.999919</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>7.674232e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1             2\n",
       "0    0.072540  0.924324  3.135318e-03\n",
       "1    0.145944  0.853712  3.438867e-04\n",
       "2    0.772667  0.222506  4.826286e-03\n",
       "3    0.008321  0.012965  9.787133e-01\n",
       "4    0.373947  0.624066  1.986789e-03\n",
       "..        ...       ...           ...\n",
       "190  0.387804  0.610818  1.377677e-03\n",
       "191  0.441195  0.546824  1.198106e-02\n",
       "192  0.031148  0.968094  7.574646e-04\n",
       "193  0.224255  0.775738  6.864440e-06\n",
       "194  0.999919  0.000080  7.674232e-07\n",
       "\n",
       "[195 rows x 3 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba4.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba4.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat4.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/4p17spST.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 453 samples, validate on 195 samples\n",
      "Epoch 1/100\n",
      "453/453 [==============================] - 0s 86us/step - loss: 0.1752 - accuracy: 0.9404 - val_loss: 0.1970 - val_accuracy: 0.9333\n",
      "Epoch 2/100\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.1796 - accuracy: 0.9316 - val_loss: 0.2019 - val_accuracy: 0.9333\n",
      "Epoch 3/100\n",
      "453/453 [==============================] - 0s 82us/step - loss: 0.1797 - accuracy: 0.9338 - val_loss: 0.1931 - val_accuracy: 0.9282\n",
      "Epoch 4/100\n",
      "453/453 [==============================] - 0s 91us/step - loss: 0.1779 - accuracy: 0.9272 - val_loss: 0.1912 - val_accuracy: 0.9282\n",
      "Epoch 5/100\n",
      "453/453 [==============================] - 0s 73us/step - loss: 0.1767 - accuracy: 0.9294 - val_loss: 0.1865 - val_accuracy: 0.9436\n",
      "Epoch 6/100\n",
      "453/453 [==============================] - 0s 90us/step - loss: 0.1737 - accuracy: 0.9470 - val_loss: 0.1901 - val_accuracy: 0.9436\n",
      "Epoch 7/100\n",
      "453/453 [==============================] - 0s 82us/step - loss: 0.1694 - accuracy: 0.9426 - val_loss: 0.1827 - val_accuracy: 0.9385\n",
      "Epoch 8/100\n",
      "453/453 [==============================] - 0s 73us/step - loss: 0.1658 - accuracy: 0.9316 - val_loss: 0.1833 - val_accuracy: 0.9385\n",
      "Epoch 9/100\n",
      "453/453 [==============================] - 0s 92us/step - loss: 0.1689 - accuracy: 0.9426 - val_loss: 0.1866 - val_accuracy: 0.9333\n",
      "Epoch 10/100\n",
      "453/453 [==============================] - 0s 92us/step - loss: 0.1675 - accuracy: 0.9338 - val_loss: 0.1929 - val_accuracy: 0.9282\n",
      "Epoch 11/100\n",
      "453/453 [==============================] - 0s 72us/step - loss: 0.1818 - accuracy: 0.9316 - val_loss: 0.1888 - val_accuracy: 0.9333\n",
      "Epoch 12/100\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.1678 - accuracy: 0.9470 - val_loss: 0.1892 - val_accuracy: 0.9179\n",
      "Epoch 13/100\n",
      "453/453 [==============================] - 0s 87us/step - loss: 0.1615 - accuracy: 0.9558 - val_loss: 0.1842 - val_accuracy: 0.9487\n",
      "Epoch 14/100\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.1635 - accuracy: 0.9603 - val_loss: 0.1853 - val_accuracy: 0.9487\n",
      "Epoch 15/100\n",
      "453/453 [==============================] - 0s 99us/step - loss: 0.1578 - accuracy: 0.9581 - val_loss: 0.1806 - val_accuracy: 0.9436\n",
      "Epoch 16/100\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.1575 - accuracy: 0.9470 - val_loss: 0.1813 - val_accuracy: 0.9487\n",
      "Epoch 17/100\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.1587 - accuracy: 0.9625 - val_loss: 0.1863 - val_accuracy: 0.9487\n",
      "Epoch 18/100\n",
      "453/453 [==============================] - 0s 142us/step - loss: 0.1611 - accuracy: 0.9514 - val_loss: 0.1807 - val_accuracy: 0.9436\n",
      "Epoch 19/100\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.1592 - accuracy: 0.9514 - val_loss: 0.1785 - val_accuracy: 0.9385\n",
      "Epoch 20/100\n",
      "453/453 [==============================] - 0s 85us/step - loss: 0.1559 - accuracy: 0.9558 - val_loss: 0.1776 - val_accuracy: 0.9487\n",
      "Epoch 21/100\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.1551 - accuracy: 0.9558 - val_loss: 0.1811 - val_accuracy: 0.9333\n",
      "Epoch 22/100\n",
      "453/453 [==============================] - 0s 207us/step - loss: 0.1533 - accuracy: 0.9514 - val_loss: 0.2060 - val_accuracy: 0.9128\n",
      "Epoch 23/100\n",
      "453/453 [==============================] - 0s 276us/step - loss: 0.1923 - accuracy: 0.9382 - val_loss: 0.1746 - val_accuracy: 0.9436\n",
      "Epoch 24/100\n",
      "453/453 [==============================] - 0s 148us/step - loss: 0.1596 - accuracy: 0.9426 - val_loss: 0.1822 - val_accuracy: 0.9179\n",
      "Epoch 25/100\n",
      "453/453 [==============================] - 0s 142us/step - loss: 0.1481 - accuracy: 0.9558 - val_loss: 0.1740 - val_accuracy: 0.9436\n",
      "Epoch 26/100\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.1483 - accuracy: 0.9470 - val_loss: 0.1771 - val_accuracy: 0.9179\n",
      "Epoch 27/100\n",
      "453/453 [==============================] - 0s 202us/step - loss: 0.1519 - accuracy: 0.9536 - val_loss: 0.1788 - val_accuracy: 0.9333\n",
      "Epoch 28/100\n",
      "453/453 [==============================] - 0s 171us/step - loss: 0.1476 - accuracy: 0.9514 - val_loss: 0.1872 - val_accuracy: 0.9179\n",
      "Epoch 29/100\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.1499 - accuracy: 0.9603 - val_loss: 0.1849 - val_accuracy: 0.9333\n",
      "Epoch 30/100\n",
      "453/453 [==============================] - 0s 99us/step - loss: 0.1883 - accuracy: 0.9492 - val_loss: 0.2621 - val_accuracy: 0.9077\n",
      "Epoch 31/100\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.1678 - accuracy: 0.9360 - val_loss: 0.1842 - val_accuracy: 0.9282\n",
      "Epoch 32/100\n",
      "453/453 [==============================] - 0s 96us/step - loss: 0.1664 - accuracy: 0.9404 - val_loss: 0.1925 - val_accuracy: 0.9385\n",
      "Epoch 33/100\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.1527 - accuracy: 0.9360 - val_loss: 0.1675 - val_accuracy: 0.9385\n",
      "Epoch 34/100\n",
      "453/453 [==============================] - 0s 145us/step - loss: 0.1467 - accuracy: 0.9536 - val_loss: 0.1674 - val_accuracy: 0.9487\n",
      "Epoch 35/100\n",
      "453/453 [==============================] - 0s 87us/step - loss: 0.1412 - accuracy: 0.9603 - val_loss: 0.1685 - val_accuracy: 0.9487\n",
      "Epoch 36/100\n",
      "453/453 [==============================] - 0s 193us/step - loss: 0.1373 - accuracy: 0.9647 - val_loss: 0.1723 - val_accuracy: 0.9436\n",
      "Epoch 37/100\n",
      "453/453 [==============================] - 0s 235us/step - loss: 0.1379 - accuracy: 0.9625 - val_loss: 0.1655 - val_accuracy: 0.9385\n",
      "Epoch 38/100\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.1357 - accuracy: 0.9492 - val_loss: 0.1660 - val_accuracy: 0.9436\n",
      "Epoch 39/100\n",
      "453/453 [==============================] - 0s 168us/step - loss: 0.1360 - accuracy: 0.9713 - val_loss: 0.1757 - val_accuracy: 0.9385\n",
      "Epoch 40/100\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.1369 - accuracy: 0.9536 - val_loss: 0.1690 - val_accuracy: 0.9385\n",
      "Epoch 41/100\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.1367 - accuracy: 0.9536 - val_loss: 0.1631 - val_accuracy: 0.9333\n",
      "Epoch 42/100\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.1317 - accuracy: 0.9581 - val_loss: 0.1728 - val_accuracy: 0.9333\n",
      "Epoch 43/100\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.1487 - accuracy: 0.9492 - val_loss: 0.1630 - val_accuracy: 0.9487\n",
      "Epoch 44/100\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.1825 - accuracy: 0.9404 - val_loss: 0.1618 - val_accuracy: 0.9333\n",
      "Epoch 45/100\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.1502 - accuracy: 0.9470 - val_loss: 0.1869 - val_accuracy: 0.9333\n",
      "Epoch 46/100\n",
      "453/453 [==============================] - 0s 185us/step - loss: 0.1371 - accuracy: 0.9492 - val_loss: 0.1768 - val_accuracy: 0.9282\n",
      "Epoch 47/100\n",
      "453/453 [==============================] - 0s 241us/step - loss: 0.1443 - accuracy: 0.9404 - val_loss: 0.2087 - val_accuracy: 0.9179\n",
      "Epoch 48/100\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.1400 - accuracy: 0.9558 - val_loss: 0.1626 - val_accuracy: 0.9385\n",
      "Epoch 49/100\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.1482 - accuracy: 0.9360 - val_loss: 0.2248 - val_accuracy: 0.9179\n",
      "Epoch 50/100\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.1514 - accuracy: 0.9514 - val_loss: 0.1838 - val_accuracy: 0.9282\n",
      "Epoch 51/100\n",
      "453/453 [==============================] - 0s 167us/step - loss: 0.1474 - accuracy: 0.9470 - val_loss: 0.2308 - val_accuracy: 0.9179\n",
      "Epoch 52/100\n",
      "453/453 [==============================] - 0s 170us/step - loss: 0.1508 - accuracy: 0.9514 - val_loss: 0.1646 - val_accuracy: 0.9385\n",
      "Epoch 53/100\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.1313 - accuracy: 0.9536 - val_loss: 0.1877 - val_accuracy: 0.9179\n",
      "Epoch 54/100\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.1570 - accuracy: 0.9514 - val_loss: 0.1688 - val_accuracy: 0.9385\n",
      "Epoch 55/100\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2314 - accuracy: 0.9161 - val_loss: 0.6047 - val_accuracy: 0.8974\n",
      "Epoch 56/100\n",
      "453/453 [==============================] - 0s 85us/step - loss: 0.5157 - accuracy: 0.9117 - val_loss: 0.3725 - val_accuracy: 0.9026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "453/453 [==============================] - 0s 68us/step - loss: 0.2638 - accuracy: 0.9227 - val_loss: 0.1778 - val_accuracy: 0.9385\n",
      "Epoch 58/100\n",
      "453/453 [==============================] - 0s 81us/step - loss: 0.1378 - accuracy: 0.9536 - val_loss: 0.1843 - val_accuracy: 0.9385\n",
      "Epoch 59/100\n",
      "453/453 [==============================] - 0s 77us/step - loss: 0.1279 - accuracy: 0.9536 - val_loss: 0.1624 - val_accuracy: 0.9436\n",
      "Epoch 60/100\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.1223 - accuracy: 0.9603 - val_loss: 0.1620 - val_accuracy: 0.9333\n",
      "Epoch 61/100\n",
      "453/453 [==============================] - 0s 82us/step - loss: 0.1213 - accuracy: 0.9647 - val_loss: 0.1530 - val_accuracy: 0.9487\n",
      "Epoch 62/100\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.1166 - accuracy: 0.9669 - val_loss: 0.1529 - val_accuracy: 0.9487\n",
      "Epoch 63/100\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.1177 - accuracy: 0.9647 - val_loss: 0.1521 - val_accuracy: 0.9487\n",
      "Epoch 64/100\n",
      "453/453 [==============================] - 0s 86us/step - loss: 0.1167 - accuracy: 0.9603 - val_loss: 0.1528 - val_accuracy: 0.9487\n",
      "Epoch 65/100\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.1156 - accuracy: 0.9691 - val_loss: 0.1592 - val_accuracy: 0.9436\n",
      "Epoch 66/100\n",
      "453/453 [==============================] - 0s 73us/step - loss: 0.1214 - accuracy: 0.9603 - val_loss: 0.1696 - val_accuracy: 0.9333\n",
      "Epoch 67/100\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.1301 - accuracy: 0.9536 - val_loss: 0.1624 - val_accuracy: 0.9333\n",
      "Epoch 68/100\n",
      "453/453 [==============================] - 0s 88us/step - loss: 0.1182 - accuracy: 0.9536 - val_loss: 0.1592 - val_accuracy: 0.9538\n",
      "Epoch 69/100\n",
      "453/453 [==============================] - 0s 80us/step - loss: 0.1182 - accuracy: 0.9735 - val_loss: 0.1782 - val_accuracy: 0.9128\n",
      "Epoch 70/100\n",
      "453/453 [==============================] - 0s 66us/step - loss: 0.1222 - accuracy: 0.9669 - val_loss: 0.1897 - val_accuracy: 0.9333\n",
      "Epoch 71/100\n",
      "453/453 [==============================] - 0s 61us/step - loss: 0.2213 - accuracy: 0.9294 - val_loss: 0.2880 - val_accuracy: 0.9026\n",
      "Epoch 72/100\n",
      "453/453 [==============================] - 0s 94us/step - loss: 0.1940 - accuracy: 0.9272 - val_loss: 0.2336 - val_accuracy: 0.9026\n",
      "Epoch 73/100\n",
      "453/453 [==============================] - 0s 84us/step - loss: 0.1842 - accuracy: 0.9470 - val_loss: 0.1689 - val_accuracy: 0.9231\n",
      "Epoch 74/100\n",
      "453/453 [==============================] - 0s 82us/step - loss: 0.1735 - accuracy: 0.9272 - val_loss: 0.4178 - val_accuracy: 0.9026\n",
      "Epoch 75/100\n",
      "453/453 [==============================] - 0s 67us/step - loss: 0.3064 - accuracy: 0.9360 - val_loss: 0.2239 - val_accuracy: 0.9333\n",
      "Epoch 76/100\n",
      "453/453 [==============================] - 0s 86us/step - loss: 0.1296 - accuracy: 0.9536 - val_loss: 0.1971 - val_accuracy: 0.9231\n",
      "Epoch 77/100\n",
      "453/453 [==============================] - 0s 99us/step - loss: 0.1272 - accuracy: 0.9625 - val_loss: 0.1855 - val_accuracy: 0.9231\n",
      "Epoch 78/100\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.1144 - accuracy: 0.9558 - val_loss: 0.1622 - val_accuracy: 0.9333\n",
      "Epoch 79/100\n",
      "453/453 [==============================] - 0s 79us/step - loss: 0.1069 - accuracy: 0.9603 - val_loss: 0.1520 - val_accuracy: 0.9487\n",
      "Epoch 80/100\n",
      "453/453 [==============================] - 0s 156us/step - loss: 0.1091 - accuracy: 0.9647 - val_loss: 0.1513 - val_accuracy: 0.9487\n",
      "Epoch 81/100\n",
      "453/453 [==============================] - 0s 160us/step - loss: 0.1056 - accuracy: 0.9713 - val_loss: 0.1495 - val_accuracy: 0.9436\n",
      "Epoch 82/100\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.1041 - accuracy: 0.9647 - val_loss: 0.1448 - val_accuracy: 0.9538\n",
      "Epoch 83/100\n",
      "453/453 [==============================] - 0s 87us/step - loss: 0.1046 - accuracy: 0.9625 - val_loss: 0.1437 - val_accuracy: 0.9538\n",
      "Epoch 84/100\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.1005 - accuracy: 0.9669 - val_loss: 0.1467 - val_accuracy: 0.9590\n",
      "Epoch 85/100\n",
      "453/453 [==============================] - 0s 97us/step - loss: 0.1023 - accuracy: 0.9823 - val_loss: 0.1583 - val_accuracy: 0.9487\n",
      "Epoch 86/100\n",
      "453/453 [==============================] - 0s 88us/step - loss: 0.1030 - accuracy: 0.9691 - val_loss: 0.1452 - val_accuracy: 0.9538\n",
      "Epoch 87/100\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.1004 - accuracy: 0.9647 - val_loss: 0.1417 - val_accuracy: 0.9538\n",
      "Epoch 88/100\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.0988 - accuracy: 0.9713 - val_loss: 0.1413 - val_accuracy: 0.9590\n",
      "Epoch 89/100\n",
      "453/453 [==============================] - 0s 92us/step - loss: 0.0989 - accuracy: 0.9779 - val_loss: 0.1436 - val_accuracy: 0.9590\n",
      "Epoch 90/100\n",
      "453/453 [==============================] - 0s 82us/step - loss: 0.0970 - accuracy: 0.9735 - val_loss: 0.1403 - val_accuracy: 0.9538\n",
      "Epoch 91/100\n",
      "453/453 [==============================] - 0s 258us/step - loss: 0.1007 - accuracy: 0.9625 - val_loss: 0.1420 - val_accuracy: 0.9538\n",
      "Epoch 92/100\n",
      "453/453 [==============================] - 0s 67us/step - loss: 0.0990 - accuracy: 0.9691 - val_loss: 0.1412 - val_accuracy: 0.9590\n",
      "Epoch 93/100\n",
      "453/453 [==============================] - 0s 68us/step - loss: 0.0944 - accuracy: 0.9713 - val_loss: 0.1405 - val_accuracy: 0.9538\n",
      "Epoch 94/100\n",
      "453/453 [==============================] - 0s 57us/step - loss: 0.0945 - accuracy: 0.9713 - val_loss: 0.1422 - val_accuracy: 0.9590\n",
      "Epoch 95/100\n",
      "453/453 [==============================] - 0s 73us/step - loss: 0.0947 - accuracy: 0.9757 - val_loss: 0.1416 - val_accuracy: 0.9385\n",
      "Epoch 96/100\n",
      "453/453 [==============================] - 0s 99us/step - loss: 0.0941 - accuracy: 0.9735 - val_loss: 0.1392 - val_accuracy: 0.9590\n",
      "Epoch 97/100\n",
      "453/453 [==============================] - 0s 89us/step - loss: 0.0927 - accuracy: 0.9735 - val_loss: 0.1393 - val_accuracy: 0.9590\n",
      "Epoch 98/100\n",
      "453/453 [==============================] - 0s 75us/step - loss: 0.0933 - accuracy: 0.9757 - val_loss: 0.1434 - val_accuracy: 0.9385\n",
      "Epoch 99/100\n",
      "453/453 [==============================] - 0s 68us/step - loss: 0.0920 - accuracy: 0.9713 - val_loss: 0.1416 - val_accuracy: 0.9538\n",
      "Epoch 100/100\n",
      "453/453 [==============================] - 0s 69us/step - loss: 0.0901 - accuracy: 0.9757 - val_loss: 0.1407 - val_accuracy: 0.9590\n"
     ]
    }
   ],
   "source": [
    "hist1_over4 = model1_over4.fit(X_train_over, y_train_over,\n",
    "          batch_size=64, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 95.34%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over4.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba4 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_2.xlsx\",\n",
    "                        sheet_name=3,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS110</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>5.870196e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS216</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.039254</td>\n",
       "      <td>0.960745</td>\n",
       "      <td>9.078969e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS386</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.326752</td>\n",
       "      <td>0.673248</td>\n",
       "      <td>1.061032e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>CFBRSa25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.611084</td>\n",
       "      <td>0.388916</td>\n",
       "      <td>7.664974e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>BCH-SA-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.611084</td>\n",
       "      <td>0.388916</td>\n",
       "      <td>7.664974e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4279</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS236</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.999768</td>\n",
       "      <td>1.803156e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4280</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS029</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.322350</td>\n",
       "      <td>0.677496</td>\n",
       "      <td>1.533154e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4281</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>9.999682e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4282</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>CFBRSa28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999288</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>5.361527e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4283</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS205</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>9.999868e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4284 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    phage     strain  phenotype  prediction         0  \\\n",
       "0      p002ykpresabs_qual     NRS110          1           1  0.000003   \n",
       "1      p002ykpresabs_qual     NRS216          1           1  0.039254   \n",
       "2      p002ykpresabs_qual     NRS386          1           1  0.326752   \n",
       "3      p002ykpresabs_qual   CFBRSa25          0           0  0.611084   \n",
       "4      p002ykpresabs_qual  BCH-SA-03          1           0  0.611084   \n",
       "...                   ...        ...        ...         ...       ...   \n",
       "4279  pyopresabsSTCC_qual     NRS236          1           1  0.000052   \n",
       "4280  pyopresabsSTCC_qual     NRS029          0           1  0.322350   \n",
       "4281  pyopresabsSTCC_qual     NRS148          2           2  0.000006   \n",
       "4282  pyopresabsSTCC_qual   CFBRSa28          0           0  0.999288   \n",
       "4283  pyopresabsSTCC_qual     NRS205          2           2  0.000007   \n",
       "\n",
       "             1             2  \n",
       "0     0.999997  5.870196e-13  \n",
       "1     0.960745  9.078969e-07  \n",
       "2     0.673248  1.061032e-07  \n",
       "3     0.388916  7.664974e-07  \n",
       "4     0.388916  7.664974e-07  \n",
       "...        ...           ...  \n",
       "4279  0.999768  1.803156e-04  \n",
       "4280  0.677496  1.533154e-04  \n",
       "4281  0.000026  9.999682e-01  \n",
       "4282  0.000176  5.361527e-04  \n",
       "4283  0.000007  9.999868e-01  \n",
       "\n",
       "[4284 rows x 7 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.25404840e-02, 9.24324150e-01, 3.13531820e-03],\n",
       "       [1.45943580e-01, 8.53712500e-01, 3.43886700e-04],\n",
       "       [7.72667400e-01, 2.22506400e-01, 4.82628630e-03],\n",
       "       [8.32148300e-03, 1.29651830e-02, 9.78713330e-01],\n",
       "       [3.73947470e-01, 6.24065760e-01, 1.98678930e-03],\n",
       "       [8.32148300e-03, 1.29651830e-02, 9.78713330e-01],\n",
       "       [1.41199080e-02, 9.85877040e-01, 3.00245780e-06],\n",
       "       [2.47453380e-01, 7.43928550e-01, 8.61808000e-03],\n",
       "       [2.02928800e-03, 3.38499970e-03, 9.94585700e-01],\n",
       "       [8.32148300e-03, 1.29651830e-02, 9.78713330e-01],\n",
       "       [2.02928800e-03, 3.38499970e-03, 9.94585700e-01],\n",
       "       [9.70933500e-01, 2.89793950e-02, 8.71625740e-05],\n",
       "       [9.59613800e-01, 3.77857760e-02, 2.60037100e-03],\n",
       "       [6.21423660e-01, 3.73048660e-01, 5.52768870e-03],\n",
       "       [1.03151050e-01, 8.91719040e-01, 5.12992000e-03],\n",
       "       [2.02928800e-03, 3.38499970e-03, 9.94585700e-01],\n",
       "       [2.02928800e-03, 3.38499970e-03, 9.94585700e-01],\n",
       "       [8.32148300e-03, 1.29651830e-02, 9.78713330e-01],\n",
       "       [2.02928800e-03, 3.38499970e-03, 9.94585700e-01],\n",
       "       [9.11186400e-01, 8.88134900e-02, 1.43870890e-07],\n",
       "       [9.59644440e-01, 3.83003000e-02, 2.05526170e-03],\n",
       "       [3.11481820e-02, 9.68094400e-01, 7.57464560e-04],\n",
       "       [1.33942590e-01, 8.63593760e-01, 2.46364880e-03],\n",
       "       [2.02928800e-03, 3.38499970e-03, 9.94585700e-01],\n",
       "       [2.57728580e-01, 7.40880850e-01, 1.39055720e-03],\n",
       "       [8.32495800e-01, 1.67035500e-01, 4.68760120e-04],\n",
       "       [9.97519000e-01, 2.28668960e-03, 1.94348220e-04],\n",
       "       [9.99485600e-01, 1.40612250e-04, 3.73809710e-04],\n",
       "       [8.32148300e-03, 1.29651830e-02, 9.78713330e-01],\n",
       "       [6.85024860e-02, 9.30344160e-01, 1.15337230e-03],\n",
       "       [8.32148300e-03, 1.29651830e-02, 9.78713330e-01],\n",
       "       [5.31219000e-05, 9.95822100e-01, 4.12483100e-03],\n",
       "       [8.32148300e-03, 1.29651830e-02, 9.78713330e-01],\n",
       "       [8.32148300e-03, 1.29651830e-02, 9.78713330e-01],\n",
       "       [8.32148300e-03, 1.29651830e-02, 9.78713330e-01],\n",
       "       [9.98966000e-01, 9.89856200e-04, 4.41790180e-05],\n",
       "       [7.72667400e-01, 2.22506400e-01, 4.82628630e-03],\n",
       "       [8.32148300e-03, 1.29651830e-02, 9.78713330e-01],\n",
       "       [6.59629000e-01, 3.28435400e-01, 1.19355700e-02],\n",
       "       [8.32148300e-03, 1.29651830e-02, 9.78713330e-01],\n",
       "       [1.13236405e-01, 8.81082830e-01, 5.68084230e-03],\n",
       "       [2.02928800e-03, 3.38499970e-03, 9.94585700e-01],\n",
       "       [6.85024860e-02, 9.30344160e-01, 1.15337230e-03],\n",
       "       [9.69667400e-01, 2.94231800e-02, 9.09508800e-04],\n",
       "       [8.82527800e-01, 1.17463540e-01, 8.64683800e-06],\n",
       "       [9.63379440e-01, 3.64312270e-02, 1.89321190e-04],\n",
       "       [2.02928800e-03, 3.38499970e-03, 9.94585700e-01],\n",
       "       [8.32148300e-03, 1.29651830e-02, 9.78713330e-01],\n",
       "       [6.85024860e-02, 9.30344160e-01, 1.15337230e-03],\n",
       "       [3.29819380e-01, 6.62961900e-01, 7.21868130e-03],\n",
       "       [2.02928800e-03, 3.38499970e-03, 9.94585700e-01],\n",
       "       [9.79466560e-01, 2.05261330e-02, 7.32177070e-06],\n",
       "       [7.25404840e-02, 9.24324150e-01, 3.13531820e-03],\n",
       "       [2.02928800e-03, 3.38499970e-03, 9.94585700e-01],\n",
       "       [2.57185880e-01, 7.41571070e-01, 1.24311400e-03],\n",
       "       [2.02928800e-03, 3.38499970e-03, 9.94585700e-01],\n",
       "       [1.27442840e-01, 8.69684930e-01, 2.87216160e-03],\n",
       "       [8.27692300e-01, 1.71131430e-01, 1.17636930e-03],\n",
       "       [7.72667400e-01, 2.22506400e-01, 4.82628630e-03],\n",
       "       [2.09663020e-01, 7.89431100e-01, 9.05875100e-04],\n",
       "       [2.47453380e-01, 7.43928550e-01, 8.61808000e-03],\n",
       "       [1.13236405e-01, 8.81082830e-01, 5.68084230e-03],\n",
       "       [9.99919400e-01, 7.98774340e-05, 7.67423200e-07],\n",
       "       [2.57185880e-01, 7.41571070e-01, 1.24311400e-03],\n",
       "       [2.02928800e-03, 3.38499970e-03, 9.94585700e-01],\n",
       "       [9.69017500e-01, 2.93501450e-02, 1.63239670e-03],\n",
       "       [4.54325640e-04, 9.98300000e-01, 1.24568310e-03],\n",
       "       [9.24615440e-01, 7.53187000e-02, 6.57574100e-05],\n",
       "       [7.31988430e-01, 2.66461400e-01, 1.55021060e-03],\n",
       "       [8.32148300e-03, 1.29651830e-02, 9.78713330e-01],\n",
       "       [4.54325640e-04, 9.98300000e-01, 1.24568310e-03],\n",
       "       [2.06152320e-01, 7.93820740e-01, 2.69232130e-05],\n",
       "       [2.02928800e-03, 3.38499970e-03, 9.94585700e-01],\n",
       "       [2.47453380e-01, 7.43928550e-01, 8.61808000e-03],\n",
       "       [6.85024860e-02, 9.30344160e-01, 1.15337230e-03],\n",
       "       [9.95897800e-01, 3.81393640e-03, 2.88198930e-04],\n",
       "       [2.02928800e-03, 3.38499970e-03, 9.94585700e-01],\n",
       "       [4.62783780e-01, 5.30999200e-01, 6.21698200e-03],\n",
       "       [9.98361650e-01, 1.63698490e-03, 1.29731940e-06],\n",
       "       [8.32148300e-03, 1.29651830e-02, 9.78713330e-01],\n",
       "       [2.09663020e-01, 7.89431100e-01, 9.05875100e-04],\n",
       "       [9.63379440e-01, 3.64312270e-02, 1.89321190e-04],\n",
       "       [8.32148300e-03, 1.29651830e-02, 9.78713330e-01],\n",
       "       [8.32148300e-03, 1.29651830e-02, 9.78713330e-01],\n",
       "       [8.32148300e-03, 1.29651830e-02, 9.78713330e-01],\n",
       "       [6.71360300e-02, 9.28782170e-01, 4.08176700e-03],\n",
       "       [8.32148300e-03, 1.29651830e-02, 9.78713330e-01],\n",
       "       [2.02928800e-03, 3.38499970e-03, 9.94585700e-01],\n",
       "       [8.32148300e-03, 1.29651830e-02, 9.78713330e-01],\n",
       "       [8.32148300e-03, 1.29651830e-02, 9.78713330e-01],\n",
       "       [2.73576620e-01, 7.26400550e-01, 2.28558550e-05],\n",
       "       [8.88514460e-01, 1.11485340e-01, 1.99728290e-07],\n",
       "       [4.54325640e-04, 9.98300000e-01, 1.24568310e-03],\n",
       "       [9.96272200e-01, 3.72511800e-03, 2.78062610e-06],\n",
       "       [4.20077270e-04, 9.97245100e-01, 2.33487250e-03],\n",
       "       [3.87804240e-01, 6.10818100e-01, 1.37767710e-03],\n",
       "       [3.45569960e-02, 9.65397900e-01, 4.50755200e-05],\n",
       "       [8.32148300e-03, 1.29651830e-02, 9.78713330e-01],\n",
       "       [2.02928800e-03, 3.38499970e-03, 9.94585700e-01],\n",
       "       [2.02928800e-03, 3.38499970e-03, 9.94585700e-01],\n",
       "       [9.99030350e-01, 9.64785100e-04, 4.83948130e-06],\n",
       "       [9.99772970e-01, 2.11111260e-04, 1.60024970e-05],\n",
       "       [9.83020800e-01, 1.63824130e-02, 5.96866240e-04],\n",
       "       [1.34141900e-01, 8.24489800e-01, 4.13683540e-02],\n",
       "       [4.58060000e-01, 5.41906300e-01, 3.37182940e-05],\n",
       "       [8.32148300e-03, 1.29651830e-02, 9.78713330e-01],\n",
       "       [9.27667440e-01, 7.10828750e-02, 1.24972800e-03],\n",
       "       [8.32148300e-03, 1.29651830e-02, 9.78713330e-01],\n",
       "       [3.87804240e-01, 6.10818100e-01, 1.37767710e-03],\n",
       "       [6.92516270e-01, 3.02461650e-01, 5.02208060e-03],\n",
       "       [2.02928800e-03, 3.38499970e-03, 9.94585700e-01],\n",
       "       [2.02928800e-03, 3.38499970e-03, 9.94585700e-01],\n",
       "       [9.66527800e-01, 3.34676650e-02, 4.49962360e-06],\n",
       "       [2.02928800e-03, 3.38499970e-03, 9.94585700e-01],\n",
       "       [8.32148300e-03, 1.29651830e-02, 9.78713330e-01],\n",
       "       [6.38561700e-02, 7.89839300e-01, 1.46304490e-01],\n",
       "       [2.02928800e-03, 3.38499970e-03, 9.94585700e-01],\n",
       "       [2.02928800e-03, 3.38499970e-03, 9.94585700e-01],\n",
       "       [2.02928800e-03, 3.38499970e-03, 9.94585700e-01],\n",
       "       [7.25404840e-02, 9.24324150e-01, 3.13531820e-03],\n",
       "       [9.87427350e-01, 1.21316950e-02, 4.40988020e-04],\n",
       "       [9.72571850e-01, 2.73626110e-02, 6.56143500e-05],\n",
       "       [2.02928800e-03, 3.38499970e-03, 9.94585700e-01],\n",
       "       [2.02928800e-03, 3.38499970e-03, 9.94585700e-01],\n",
       "       [2.02928800e-03, 3.38499970e-03, 9.94585700e-01],\n",
       "       [3.87804240e-01, 6.10818100e-01, 1.37767710e-03],\n",
       "       [4.33475700e-01, 2.88477420e-01, 2.78046880e-01],\n",
       "       [3.98236800e-01, 6.01567570e-01, 1.95575210e-04],\n",
       "       [8.32148300e-03, 1.29651830e-02, 9.78713330e-01],\n",
       "       [9.99772970e-01, 2.11111260e-04, 1.60024970e-05],\n",
       "       [1.59804170e-01, 8.31928730e-01, 8.26711100e-03],\n",
       "       [6.71360300e-02, 9.28782170e-01, 4.08176700e-03],\n",
       "       [1.77005510e-01, 8.19922150e-01, 3.07234540e-03],\n",
       "       [7.84833600e-01, 2.13807330e-01, 1.35906000e-03],\n",
       "       [3.35321870e-01, 6.63527970e-01, 1.15015850e-03],\n",
       "       [1.45943580e-01, 8.53712500e-01, 3.43886700e-04],\n",
       "       [8.32148300e-03, 1.29651830e-02, 9.78713330e-01],\n",
       "       [3.73947470e-01, 6.24065760e-01, 1.98678930e-03],\n",
       "       [4.54325640e-04, 9.98300000e-01, 1.24568310e-03],\n",
       "       [2.02928800e-03, 3.38499970e-03, 9.94585700e-01],\n",
       "       [2.02928800e-03, 3.38499970e-03, 9.94585700e-01],\n",
       "       [2.02928800e-03, 3.38499970e-03, 9.94585700e-01],\n",
       "       [9.50385400e-01, 4.86329120e-02, 9.81642900e-04],\n",
       "       [2.24255000e-01, 7.75738100e-01, 6.86444000e-06],\n",
       "       [3.11481820e-02, 9.68094400e-01, 7.57464560e-04],\n",
       "       [9.75790700e-01, 2.26505360e-02, 1.55868960e-03],\n",
       "       [1.13236405e-01, 8.81082830e-01, 5.68084230e-03],\n",
       "       [9.95261800e-01, 4.54076570e-03, 1.97389090e-04],\n",
       "       [4.41194560e-01, 5.46824300e-01, 1.19810620e-02],\n",
       "       [3.73947470e-01, 6.24065760e-01, 1.98678930e-03],\n",
       "       [8.39139000e-01, 1.57980550e-01, 2.88044990e-03],\n",
       "       [4.54325640e-04, 9.98300000e-01, 1.24568310e-03],\n",
       "       [8.32148300e-03, 1.29651830e-02, 9.78713330e-01],\n",
       "       [4.41024840e-01, 5.57022000e-01, 1.95323600e-03],\n",
       "       [8.52983300e-01, 1.43327520e-01, 3.68914570e-03],\n",
       "       [9.97995600e-01, 1.84359290e-03, 1.60797030e-04],\n",
       "       [9.99068800e-01, 9.20642870e-04, 1.05501290e-05],\n",
       "       [9.35126500e-01, 6.43878600e-02, 4.85685970e-04],\n",
       "       [1.34141900e-01, 8.24489800e-01, 4.13683540e-02],\n",
       "       [1.41199080e-02, 9.85877040e-01, 3.00245780e-06],\n",
       "       [2.02928800e-03, 3.38499970e-03, 9.94585700e-01],\n",
       "       [9.99772970e-01, 2.11111260e-04, 1.60024970e-05],\n",
       "       [2.02928800e-03, 3.38499970e-03, 9.94585700e-01],\n",
       "       [3.94775400e-01, 6.03193100e-01, 2.03147880e-03],\n",
       "       [8.32148300e-03, 1.29651830e-02, 9.78713330e-01],\n",
       "       [9.55747800e-01, 4.35180600e-02, 7.34199000e-04],\n",
       "       [8.82042770e-01, 1.16009556e-01, 1.94769030e-03],\n",
       "       [2.02928800e-03, 3.38499970e-03, 9.94585700e-01],\n",
       "       [9.11026600e-01, 8.82204550e-02, 7.52950700e-04],\n",
       "       [8.32148300e-03, 1.29651830e-02, 9.78713330e-01],\n",
       "       [1.12653615e-04, 9.98918530e-01, 9.68794100e-04],\n",
       "       [8.97091150e-01, 1.02908180e-01, 6.39597100e-07],\n",
       "       [9.29670630e-01, 7.01668040e-02, 1.62556990e-04],\n",
       "       [2.02928800e-03, 3.38499970e-03, 9.94585700e-01],\n",
       "       [9.94027140e-01, 5.86257040e-03, 1.10377260e-04],\n",
       "       [8.86482500e-01, 1.12644450e-01, 8.73155500e-04],\n",
       "       [6.71360300e-02, 9.28782170e-01, 4.08176700e-03],\n",
       "       [2.02928800e-03, 3.38499970e-03, 9.94585700e-01],\n",
       "       [2.47453380e-01, 7.43928550e-01, 8.61808000e-03],\n",
       "       [8.20207400e-01, 1.76994900e-01, 2.79766580e-03],\n",
       "       [3.45569960e-02, 9.65397900e-01, 4.50755200e-05],\n",
       "       [2.02928800e-03, 3.38499970e-03, 9.94585700e-01],\n",
       "       [9.98372730e-01, 1.61789900e-03, 9.40678550e-06],\n",
       "       [8.32148300e-03, 1.29651830e-02, 9.78713330e-01],\n",
       "       [3.73947470e-01, 6.24065760e-01, 1.98678930e-03],\n",
       "       [3.18489500e-01, 6.81223900e-01, 2.86577900e-04],\n",
       "       [9.84931230e-01, 1.50648905e-02, 3.84897840e-06],\n",
       "       [2.24255000e-01, 7.75738100e-01, 6.86444000e-06],\n",
       "       [1.12653615e-04, 9.98918530e-01, 9.68794100e-04],\n",
       "       [6.38561700e-02, 7.89839300e-01, 1.46304490e-01],\n",
       "       [3.87804240e-01, 6.10818100e-01, 1.37767710e-03],\n",
       "       [4.41194560e-01, 5.46824300e-01, 1.19810620e-02],\n",
       "       [3.11481820e-02, 9.68094400e-01, 7.57464560e-04],\n",
       "       [2.24255000e-01, 7.75738100e-01, 6.86444000e-06],\n",
       "       [9.99919400e-01, 7.98774340e-05, 7.67423200e-07]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob4 = df_proba4[df_proba4['phage']=='p0017SpresabsSTCC_qual'].iloc[:,-3:]\n",
    "y_prob4 = y_prob4.to_numpy()\n",
    "y_prob4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9877712031558185"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo4 = rocauc_ovo(y_test_over, y_prob4, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9877712031558185"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr4 = rocauc_ovr(y_test_over, y_prob4, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9844773175542406"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovos = [ovo1, ovo2, ovo3, ovo4]\n",
    "np.mean(ovos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.007061832633107952"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(ovos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9844773175542406"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovrs = [ovr1, ovr2, ovr3, ovr4]\n",
    "np.mean(ovrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.007061832633107952"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(ovrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs = [acc_test_over, acc_test_over2, acc_test_over3, acc_test_over4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling test accuracy mean: 93.85%\n"
     ]
    }
   ],
   "source": [
    "mean = np.mean(accs)\n",
    "print('over-sampling test accuracy mean: %.2f%%' % (mean*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling test accuracy standard deviation: 0.012561485111703652\n"
     ]
    }
   ],
   "source": [
    "std = np.std(accs)\n",
    "print('over-sampling test accuracy standard deviation:', std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs_train = [np.mean(hist1_over.history['accuracy']), np.mean(hist1_over2.history['accuracy']), np.mean(hist1_over3.history['accuracy']),\n",
    "             np.mean(hist1_over4.history['accuracy'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy mean: 96.70%\n"
     ]
    }
   ],
   "source": [
    "mean_train = np.mean(accs_train)\n",
    "print('over-sampling train accuracy mean: %.2f%%' % (mean_train*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy standard deviation: 0.0079398835\n"
     ]
    }
   ],
   "source": [
    "std_train = np.std(accs_train)\n",
    "print('over-sampling train accuracy standard deviation:', std_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=567,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat5 = pd.DataFrame(X_test_over[:,0])\n",
    "dat5['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>312</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BCH-SA-12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CFBRSa29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>CA541</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>SR4152</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>NRS110</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>CFBRSa70</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>NRS021</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0  test\n",
       "0          312     1\n",
       "1    BCH-SA-12     0\n",
       "2       NRS209     2\n",
       "3     CFBRSa29     0\n",
       "4       NRS209     2\n",
       "..         ...   ...\n",
       "190      CA541     1\n",
       "191     SR4152     1\n",
       "192     NRS110     2\n",
       "193   CFBRSa70     0\n",
       "194     NRS021     0\n",
       "\n",
       "[195 rows x 2 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### add regularizer and dropout\n",
    "model1_over5 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],), activity_regularizer=l1(0.001)),\n",
    "    Dense(3, activation='softmax'),\n",
    "    Dropout(0.2, ),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over5.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 453 samples, validate on 195 samples\n",
      "Epoch 1/100\n",
      "453/453 [==============================] - 0s 467us/step - loss: 8.4312 - accuracy: 0.4702 - val_loss: 5.8295 - val_accuracy: 0.5333\n",
      "Epoch 2/100\n",
      "453/453 [==============================] - 0s 111us/step - loss: 7.9428 - accuracy: 0.4724 - val_loss: 5.4704 - val_accuracy: 0.5436\n",
      "Epoch 3/100\n",
      "453/453 [==============================] - 0s 125us/step - loss: 7.2336 - accuracy: 0.5188 - val_loss: 5.2938 - val_accuracy: 0.5692\n",
      "Epoch 4/100\n",
      "453/453 [==============================] - 0s 136us/step - loss: 7.1452 - accuracy: 0.5099 - val_loss: 4.9137 - val_accuracy: 0.5692\n",
      "Epoch 5/100\n",
      "453/453 [==============================] - 0s 138us/step - loss: 6.4976 - accuracy: 0.5210 - val_loss: 2.8596 - val_accuracy: 0.6000\n",
      "Epoch 6/100\n",
      "453/453 [==============================] - 0s 118us/step - loss: 4.1453 - accuracy: 0.6291 - val_loss: 1.8736 - val_accuracy: 0.6872\n",
      "Epoch 7/100\n",
      "453/453 [==============================] - 0s 103us/step - loss: 4.1718 - accuracy: 0.6424 - val_loss: 1.5788 - val_accuracy: 0.7077\n",
      "Epoch 8/100\n",
      "453/453 [==============================] - 0s 115us/step - loss: 4.4966 - accuracy: 0.6291 - val_loss: 1.4373 - val_accuracy: 0.7179\n",
      "Epoch 9/100\n",
      "453/453 [==============================] - 0s 90us/step - loss: 3.6600 - accuracy: 0.6865 - val_loss: 1.3630 - val_accuracy: 0.7231\n",
      "Epoch 10/100\n",
      "453/453 [==============================] - 0s 148us/step - loss: 3.7939 - accuracy: 0.6777 - val_loss: 1.3467 - val_accuracy: 0.7231\n",
      "Epoch 11/100\n",
      "453/453 [==============================] - 0s 168us/step - loss: 3.4669 - accuracy: 0.6733 - val_loss: 1.2664 - val_accuracy: 0.7590\n",
      "Epoch 12/100\n",
      "453/453 [==============================] - 0s 87us/step - loss: 3.4768 - accuracy: 0.6843 - val_loss: 1.2304 - val_accuracy: 0.7487\n",
      "Epoch 13/100\n",
      "453/453 [==============================] - 0s 81us/step - loss: 3.4435 - accuracy: 0.6843 - val_loss: 1.1224 - val_accuracy: 0.7487\n",
      "Epoch 14/100\n",
      "453/453 [==============================] - 0s 85us/step - loss: 3.2979 - accuracy: 0.7174 - val_loss: 1.1420 - val_accuracy: 0.7436\n",
      "Epoch 15/100\n",
      "453/453 [==============================] - 0s 109us/step - loss: 3.2010 - accuracy: 0.7064 - val_loss: 1.1156 - val_accuracy: 0.7538\n",
      "Epoch 16/100\n",
      "453/453 [==============================] - 0s 110us/step - loss: 3.1838 - accuracy: 0.6998 - val_loss: 1.1873 - val_accuracy: 0.7436\n",
      "Epoch 17/100\n",
      "453/453 [==============================] - 0s 146us/step - loss: 2.8261 - accuracy: 0.6998 - val_loss: 1.1052 - val_accuracy: 0.7590\n",
      "Epoch 18/100\n",
      "453/453 [==============================] - 0s 120us/step - loss: 3.0176 - accuracy: 0.7020 - val_loss: 1.0992 - val_accuracy: 0.7641\n",
      "Epoch 19/100\n",
      "453/453 [==============================] - 0s 82us/step - loss: 3.0187 - accuracy: 0.6667 - val_loss: 1.1510 - val_accuracy: 0.7897\n",
      "Epoch 20/100\n",
      "453/453 [==============================] - 0s 95us/step - loss: 2.9602 - accuracy: 0.6821 - val_loss: 1.1344 - val_accuracy: 0.7744\n",
      "Epoch 21/100\n",
      "453/453 [==============================] - 0s 96us/step - loss: 2.4866 - accuracy: 0.7417 - val_loss: 1.0773 - val_accuracy: 0.8051\n",
      "Epoch 22/100\n",
      "453/453 [==============================] - 0s 76us/step - loss: 2.8601 - accuracy: 0.6954 - val_loss: 1.0728 - val_accuracy: 0.7897\n",
      "Epoch 23/100\n",
      "453/453 [==============================] - 0s 74us/step - loss: 2.6835 - accuracy: 0.7130 - val_loss: 1.0268 - val_accuracy: 0.8000\n",
      "Epoch 24/100\n",
      "453/453 [==============================] - 0s 76us/step - loss: 2.5998 - accuracy: 0.7263 - val_loss: 1.0588 - val_accuracy: 0.7897\n",
      "Epoch 25/100\n",
      "453/453 [==============================] - 0s 76us/step - loss: 2.6242 - accuracy: 0.7219 - val_loss: 0.9637 - val_accuracy: 0.8000\n",
      "Epoch 26/100\n",
      "453/453 [==============================] - 0s 71us/step - loss: 2.6527 - accuracy: 0.7086 - val_loss: 0.9851 - val_accuracy: 0.8000\n",
      "Epoch 27/100\n",
      "453/453 [==============================] - 0s 71us/step - loss: 2.7909 - accuracy: 0.7174 - val_loss: 0.9356 - val_accuracy: 0.8410\n",
      "Epoch 28/100\n",
      "453/453 [==============================] - 0s 69us/step - loss: 2.5815 - accuracy: 0.7241 - val_loss: 1.0136 - val_accuracy: 0.8256\n",
      "Epoch 29/100\n",
      "453/453 [==============================] - 0s 73us/step - loss: 2.6795 - accuracy: 0.7219 - val_loss: 1.0930 - val_accuracy: 0.7846\n",
      "Epoch 30/100\n",
      "453/453 [==============================] - 0s 92us/step - loss: 3.1812 - accuracy: 0.6799 - val_loss: 1.1321 - val_accuracy: 0.8000\n",
      "Epoch 31/100\n",
      "453/453 [==============================] - 0s 177us/step - loss: 2.5483 - accuracy: 0.7108 - val_loss: 1.0626 - val_accuracy: 0.7949\n",
      "Epoch 32/100\n",
      "453/453 [==============================] - 0s 179us/step - loss: 2.4793 - accuracy: 0.7351 - val_loss: 0.9710 - val_accuracy: 0.7897\n",
      "Epoch 33/100\n",
      "453/453 [==============================] - 0s 178us/step - loss: 2.9087 - accuracy: 0.6909 - val_loss: 1.2142 - val_accuracy: 0.7846\n",
      "Epoch 34/100\n",
      "453/453 [==============================] - 0s 151us/step - loss: 2.4124 - accuracy: 0.7594 - val_loss: 0.9704 - val_accuracy: 0.8308\n",
      "Epoch 35/100\n",
      "453/453 [==============================] - 0s 148us/step - loss: 3.1850 - accuracy: 0.6799 - val_loss: 0.9492 - val_accuracy: 0.8462\n",
      "Epoch 36/100\n",
      "453/453 [==============================] - 0s 121us/step - loss: 2.5305 - accuracy: 0.7395 - val_loss: 1.0240 - val_accuracy: 0.8256\n",
      "Epoch 37/100\n",
      "453/453 [==============================] - 0s 88us/step - loss: 2.7063 - accuracy: 0.7042 - val_loss: 1.0269 - val_accuracy: 0.8256\n",
      "Epoch 38/100\n",
      "453/453 [==============================] - 0s 120us/step - loss: 2.4531 - accuracy: 0.7263 - val_loss: 0.9551 - val_accuracy: 0.8615\n",
      "Epoch 39/100\n",
      "453/453 [==============================] - 0s 157us/step - loss: 2.2437 - accuracy: 0.7594 - val_loss: 0.9356 - val_accuracy: 0.8359\n",
      "Epoch 40/100\n",
      "453/453 [==============================] - 0s 163us/step - loss: 2.6720 - accuracy: 0.7174 - val_loss: 1.0051 - val_accuracy: 0.7795\n",
      "Epoch 41/100\n",
      "453/453 [==============================] - 0s 160us/step - loss: 2.3458 - accuracy: 0.7307 - val_loss: 0.9879 - val_accuracy: 0.7897\n",
      "Epoch 42/100\n",
      "453/453 [==============================] - 0s 230us/step - loss: 2.3390 - accuracy: 0.7108 - val_loss: 0.9257 - val_accuracy: 0.8308\n",
      "Epoch 43/100\n",
      "453/453 [==============================] - 0s 80us/step - loss: 2.4474 - accuracy: 0.7307 - val_loss: 0.8798 - val_accuracy: 0.8359\n",
      "Epoch 44/100\n",
      "453/453 [==============================] - 0s 72us/step - loss: 2.3532 - accuracy: 0.7395 - val_loss: 0.8825 - val_accuracy: 0.8615\n",
      "Epoch 45/100\n",
      "453/453 [==============================] - 0s 73us/step - loss: 2.4833 - accuracy: 0.7219 - val_loss: 0.9763 - val_accuracy: 0.8000\n",
      "Epoch 46/100\n",
      "453/453 [==============================] - 0s 75us/step - loss: 2.6348 - accuracy: 0.7086 - val_loss: 0.9377 - val_accuracy: 0.8462\n",
      "Epoch 47/100\n",
      "453/453 [==============================] - 0s 76us/step - loss: 2.4925 - accuracy: 0.6976 - val_loss: 1.0955 - val_accuracy: 0.8154\n",
      "Epoch 48/100\n",
      "453/453 [==============================] - 0s 108us/step - loss: 2.1533 - accuracy: 0.7329 - val_loss: 1.0054 - val_accuracy: 0.8410\n",
      "Epoch 49/100\n",
      "453/453 [==============================] - 0s 153us/step - loss: 2.4319 - accuracy: 0.7616 - val_loss: 0.9687 - val_accuracy: 0.8462\n",
      "Epoch 50/100\n",
      "453/453 [==============================] - 0s 136us/step - loss: 2.5725 - accuracy: 0.7395 - val_loss: 0.8895 - val_accuracy: 0.8462\n",
      "Epoch 51/100\n",
      "453/453 [==============================] - 0s 118us/step - loss: 2.2397 - accuracy: 0.7351 - val_loss: 0.8735 - val_accuracy: 0.8513\n",
      "Epoch 52/100\n",
      "453/453 [==============================] - 0s 149us/step - loss: 2.3438 - accuracy: 0.7417 - val_loss: 0.9040 - val_accuracy: 0.8513\n",
      "Epoch 53/100\n",
      "453/453 [==============================] - 0s 153us/step - loss: 2.2526 - accuracy: 0.7483 - val_loss: 1.0345 - val_accuracy: 0.8410\n",
      "Epoch 54/100\n",
      "453/453 [==============================] - 0s 147us/step - loss: 2.8059 - accuracy: 0.6932 - val_loss: 0.9252 - val_accuracy: 0.8513\n",
      "Epoch 55/100\n",
      "453/453 [==============================] - 0s 124us/step - loss: 2.1077 - accuracy: 0.7770 - val_loss: 0.9566 - val_accuracy: 0.8615\n",
      "Epoch 56/100\n",
      "453/453 [==============================] - 0s 82us/step - loss: 2.4595 - accuracy: 0.7108 - val_loss: 0.9586 - val_accuracy: 0.8615\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 98us/step - loss: 2.3843 - accuracy: 0.7616 - val_loss: 0.9301 - val_accuracy: 0.8667\n",
      "Epoch 58/100\n",
      "453/453 [==============================] - 0s 178us/step - loss: 2.5630 - accuracy: 0.7395 - val_loss: 0.9181 - val_accuracy: 0.8615\n",
      "Epoch 59/100\n",
      "453/453 [==============================] - 0s 164us/step - loss: 2.0944 - accuracy: 0.7682 - val_loss: 0.9390 - val_accuracy: 0.8513\n",
      "Epoch 60/100\n",
      "453/453 [==============================] - 0s 197us/step - loss: 2.1779 - accuracy: 0.7285 - val_loss: 0.9153 - val_accuracy: 0.8564\n",
      "Epoch 61/100\n",
      "453/453 [==============================] - 0s 147us/step - loss: 2.2257 - accuracy: 0.7572 - val_loss: 0.9119 - val_accuracy: 0.8564\n",
      "Epoch 62/100\n",
      "453/453 [==============================] - 0s 161us/step - loss: 2.0256 - accuracy: 0.7483 - val_loss: 0.9589 - val_accuracy: 0.8205\n",
      "Epoch 63/100\n",
      "453/453 [==============================] - 0s 131us/step - loss: 2.1729 - accuracy: 0.7174 - val_loss: 0.9244 - val_accuracy: 0.8462\n",
      "Epoch 64/100\n",
      "453/453 [==============================] - 0s 104us/step - loss: 2.2436 - accuracy: 0.7373 - val_loss: 0.9393 - val_accuracy: 0.8513\n",
      "Epoch 65/100\n",
      "453/453 [==============================] - 0s 124us/step - loss: 2.0143 - accuracy: 0.7395 - val_loss: 0.9943 - val_accuracy: 0.8410\n",
      "Epoch 66/100\n",
      "453/453 [==============================] - 0s 196us/step - loss: 2.3834 - accuracy: 0.7020 - val_loss: 1.0259 - val_accuracy: 0.8615\n",
      "Epoch 67/100\n",
      "453/453 [==============================] - 0s 137us/step - loss: 2.0057 - accuracy: 0.7417 - val_loss: 1.0731 - val_accuracy: 0.8000\n",
      "Epoch 68/100\n",
      "453/453 [==============================] - 0s 162us/step - loss: 1.8315 - accuracy: 0.7373 - val_loss: 0.9784 - val_accuracy: 0.8718\n",
      "Epoch 69/100\n",
      "453/453 [==============================] - 0s 150us/step - loss: 2.3361 - accuracy: 0.6998 - val_loss: 1.0617 - val_accuracy: 0.8103\n",
      "Epoch 70/100\n",
      "453/453 [==============================] - 0s 148us/step - loss: 2.2612 - accuracy: 0.7064 - val_loss: 1.1245 - val_accuracy: 0.8103\n",
      "Epoch 71/100\n",
      "453/453 [==============================] - 0s 138us/step - loss: 1.8808 - accuracy: 0.7550 - val_loss: 0.9925 - val_accuracy: 0.8462\n",
      "Epoch 72/100\n",
      "453/453 [==============================] - 0s 134us/step - loss: 2.2552 - accuracy: 0.7042 - val_loss: 0.9554 - val_accuracy: 0.8821\n",
      "Epoch 73/100\n",
      "453/453 [==============================] - 0s 118us/step - loss: 2.1203 - accuracy: 0.7263 - val_loss: 0.9192 - val_accuracy: 0.8718\n",
      "Epoch 74/100\n",
      "453/453 [==============================] - 0s 107us/step - loss: 2.1359 - accuracy: 0.7351 - val_loss: 0.9771 - val_accuracy: 0.8410\n",
      "Epoch 75/100\n",
      "453/453 [==============================] - 0s 84us/step - loss: 2.1993 - accuracy: 0.7373 - val_loss: 0.8923 - val_accuracy: 0.8718\n",
      "Epoch 76/100\n",
      "453/453 [==============================] - 0s 106us/step - loss: 2.1305 - accuracy: 0.7263 - val_loss: 0.9080 - val_accuracy: 0.8667\n",
      "Epoch 77/100\n",
      "453/453 [==============================] - 0s 115us/step - loss: 1.9460 - accuracy: 0.7351 - val_loss: 0.9599 - val_accuracy: 0.8769\n",
      "Epoch 78/100\n",
      "453/453 [==============================] - 0s 121us/step - loss: 1.9115 - accuracy: 0.7594 - val_loss: 0.8885 - val_accuracy: 0.8821\n",
      "Epoch 79/100\n",
      "453/453 [==============================] - 0s 88us/step - loss: 1.7821 - accuracy: 0.7528 - val_loss: 0.8465 - val_accuracy: 0.8821\n",
      "Epoch 80/100\n",
      "453/453 [==============================] - 0s 72us/step - loss: 2.1348 - accuracy: 0.7263 - val_loss: 0.8575 - val_accuracy: 0.8821\n",
      "Epoch 81/100\n",
      "453/453 [==============================] - 0s 70us/step - loss: 1.9590 - accuracy: 0.7461 - val_loss: 0.9937 - val_accuracy: 0.8256\n",
      "Epoch 82/100\n",
      "453/453 [==============================] - 0s 68us/step - loss: 1.9027 - accuracy: 0.7174 - val_loss: 1.1978 - val_accuracy: 0.8667\n",
      "Epoch 83/100\n",
      "453/453 [==============================] - 0s 76us/step - loss: 1.9663 - accuracy: 0.7483 - val_loss: 1.1827 - val_accuracy: 0.8513\n",
      "Epoch 84/100\n",
      "453/453 [==============================] - 0s 79us/step - loss: 1.8900 - accuracy: 0.7285 - val_loss: 1.0511 - val_accuracy: 0.8513\n",
      "Epoch 85/100\n",
      "453/453 [==============================] - 0s 129us/step - loss: 1.6598 - accuracy: 0.7837 - val_loss: 1.1938 - val_accuracy: 0.8564\n",
      "Epoch 86/100\n",
      "453/453 [==============================] - 0s 196us/step - loss: 1.6781 - accuracy: 0.7704 - val_loss: 0.9954 - val_accuracy: 0.8718\n",
      "Epoch 87/100\n",
      "453/453 [==============================] - 0s 202us/step - loss: 1.9556 - accuracy: 0.7461 - val_loss: 0.9421 - val_accuracy: 0.8872\n",
      "Epoch 88/100\n",
      "453/453 [==============================] - 0s 154us/step - loss: 1.8528 - accuracy: 0.7660 - val_loss: 0.9431 - val_accuracy: 0.8667\n",
      "Epoch 89/100\n",
      "453/453 [==============================] - 0s 121us/step - loss: 1.9627 - accuracy: 0.7351 - val_loss: 0.8853 - val_accuracy: 0.8769\n",
      "Epoch 90/100\n",
      "453/453 [==============================] - 0s 80us/step - loss: 1.7679 - accuracy: 0.7572 - val_loss: 0.8758 - val_accuracy: 0.8974\n",
      "Epoch 91/100\n",
      "453/453 [==============================] - 0s 71us/step - loss: 1.9536 - accuracy: 0.7439 - val_loss: 0.8902 - val_accuracy: 0.8821\n",
      "Epoch 92/100\n",
      "453/453 [==============================] - 0s 69us/step - loss: 2.1636 - accuracy: 0.7130 - val_loss: 0.9177 - val_accuracy: 0.8872\n",
      "Epoch 93/100\n",
      "453/453 [==============================] - 0s 69us/step - loss: 1.8415 - accuracy: 0.7395 - val_loss: 0.9026 - val_accuracy: 0.8718\n",
      "Epoch 94/100\n",
      "453/453 [==============================] - 0s 68us/step - loss: 1.7948 - accuracy: 0.7130 - val_loss: 0.8981 - val_accuracy: 0.8718\n",
      "Epoch 95/100\n",
      "453/453 [==============================] - 0s 71us/step - loss: 1.8816 - accuracy: 0.7483 - val_loss: 0.8398 - val_accuracy: 0.8667\n",
      "Epoch 96/100\n",
      "453/453 [==============================] - 0s 79us/step - loss: 1.6025 - accuracy: 0.7660 - val_loss: 0.8503 - val_accuracy: 0.8718\n",
      "Epoch 97/100\n",
      "453/453 [==============================] - 0s 107us/step - loss: 2.0201 - accuracy: 0.7417 - val_loss: 1.0440 - val_accuracy: 0.8564\n",
      "Epoch 98/100\n",
      "453/453 [==============================] - 0s 114us/step - loss: 1.8829 - accuracy: 0.7373 - val_loss: 0.8550 - val_accuracy: 0.8872\n",
      "Epoch 99/100\n",
      "453/453 [==============================] - 0s 99us/step - loss: 1.8704 - accuracy: 0.7550 - val_loss: 0.9708 - val_accuracy: 0.8667\n",
      "Epoch 100/100\n",
      "453/453 [==============================] - 0s 96us/step - loss: 1.9404 - accuracy: 0.7439 - val_loss: 0.8198 - val_accuracy: 0.9026\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a35a72c18>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over5.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195/195 [==============================] - 0s 63us/step\n",
      "over-sampling test accuracy: 90.77%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over5 = model1_over5.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over5*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 0, 2, 0, 0, 2, 0, 2, 2, 2, 2, 2, 1, 2, 2, 0, 0, 2, 2, 2,\n",
       "       1, 2, 2, 1, 0, 1, 2, 0, 1, 0, 2, 2, 1, 1, 2, 2, 2, 0, 1, 1, 2, 1,\n",
       "       1, 1, 1, 1, 2, 2, 0, 2, 1, 0, 2, 0, 0, 0, 2, 1, 1, 0, 2, 0, 0, 0,\n",
       "       2, 2, 1, 1, 0, 0, 1, 1, 2, 2, 2, 2, 0, 2, 0, 2, 0, 0, 2, 0, 2, 1,\n",
       "       1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 2, 2, 2, 0, 0, 0, 0,\n",
       "       2, 1, 2, 1, 1, 0, 0, 1, 1, 1, 1, 2, 0, 1, 0, 2, 2, 0, 0, 0, 2, 1,\n",
       "       2, 0, 1, 0, 2, 1, 1, 2, 2, 0, 2, 1, 0, 0, 0, 2, 2, 2, 1, 1, 2, 2,\n",
       "       0, 0, 1, 0, 2, 1, 0, 1, 2, 2, 0, 0, 2, 2, 2, 2, 1, 1, 0, 1, 0, 1,\n",
       "       2, 0, 0, 2, 1, 0, 1, 0, 0, 0, 0, 1, 2, 0, 0, 1, 2, 0, 1])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred5 = model1_over5.predict_classes(X_test_over)\n",
    "pred5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>312</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BCH-SA-12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CFBRSa29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>CA541</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>SR4152</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>NRS110</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>CFBRSa70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>NRS021</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0  test  pred\n",
       "0          312     1     1\n",
       "1    BCH-SA-12     0     0\n",
       "2       NRS209     2     2\n",
       "3     CFBRSa29     0     0\n",
       "4       NRS209     2     2\n",
       "..         ...   ...   ...\n",
       "190      CA541     1     0\n",
       "191     SR4152     1     1\n",
       "192     NRS110     2     2\n",
       "193   CFBRSa70     0     0\n",
       "194     NRS021     0     1\n",
       "\n",
       "[195 rows x 3 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat5['pred'] = pred5\n",
    "dat5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba5 = model1_over5.predict_proba(X_test_over)\n",
    "dat_proba5 = pd.DataFrame(proba5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.310851e-01</td>\n",
       "      <td>5.689149e-01</td>\n",
       "      <td>7.807134e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>8.498781e-08</td>\n",
       "      <td>1.082131e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.343175e-08</td>\n",
       "      <td>9.256006e-08</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>8.183677e-09</td>\n",
       "      <td>1.139258e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.343175e-08</td>\n",
       "      <td>9.256006e-08</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>7.755124e-01</td>\n",
       "      <td>2.244875e-01</td>\n",
       "      <td>1.170079e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>3.495487e-02</td>\n",
       "      <td>9.650442e-01</td>\n",
       "      <td>8.668809e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>4.195798e-08</td>\n",
       "      <td>3.755047e-08</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>8.460521e-01</td>\n",
       "      <td>1.539446e-01</td>\n",
       "      <td>3.216454e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>4.415057e-05</td>\n",
       "      <td>9.999559e-01</td>\n",
       "      <td>3.813908e-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0             1             2\n",
       "0    4.310851e-01  5.689149e-01  7.807134e-08\n",
       "1    9.999999e-01  8.498781e-08  1.082131e-10\n",
       "2    1.343175e-08  9.256006e-08  9.999999e-01\n",
       "3    1.000000e+00  8.183677e-09  1.139258e-10\n",
       "4    1.343175e-08  9.256006e-08  9.999999e-01\n",
       "..            ...           ...           ...\n",
       "190  7.755124e-01  2.244875e-01  1.170079e-07\n",
       "191  3.495487e-02  9.650442e-01  8.668809e-07\n",
       "192  4.195798e-08  3.755047e-08  9.999999e-01\n",
       "193  8.460521e-01  1.539446e-01  3.216454e-06\n",
       "194  4.415057e-05  9.999559e-01  3.813908e-09\n",
       "\n",
       "[195 rows x 3 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba5.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba5.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat5.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/5p17spST.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 453 samples, validate on 195 samples\n",
      "Epoch 1/100\n",
      "453/453 [==============================] - 0s 142us/step - loss: 1.7036 - accuracy: 0.7616 - val_loss: 0.7411 - val_accuracy: 0.9231\n",
      "Epoch 2/100\n",
      "453/453 [==============================] - 0s 166us/step - loss: 1.8317 - accuracy: 0.6932 - val_loss: 0.7692 - val_accuracy: 0.9128\n",
      "Epoch 3/100\n",
      "453/453 [==============================] - 0s 143us/step - loss: 1.8548 - accuracy: 0.7086 - val_loss: 0.9420 - val_accuracy: 0.8974\n",
      "Epoch 4/100\n",
      "453/453 [==============================] - 0s 136us/step - loss: 1.9690 - accuracy: 0.7373 - val_loss: 0.8254 - val_accuracy: 0.8564\n",
      "Epoch 5/100\n",
      "453/453 [==============================] - 0s 128us/step - loss: 1.5297 - accuracy: 0.7748 - val_loss: 0.8122 - val_accuracy: 0.8564\n",
      "Epoch 6/100\n",
      "453/453 [==============================] - 0s 133us/step - loss: 1.6204 - accuracy: 0.7351 - val_loss: 0.8708 - val_accuracy: 0.8615\n",
      "Epoch 7/100\n",
      "453/453 [==============================] - 0s 142us/step - loss: 1.5643 - accuracy: 0.7638 - val_loss: 0.7889 - val_accuracy: 0.8564\n",
      "Epoch 8/100\n",
      "453/453 [==============================] - 0s 145us/step - loss: 1.4857 - accuracy: 0.7506 - val_loss: 0.7321 - val_accuracy: 0.9179\n",
      "Epoch 9/100\n",
      "453/453 [==============================] - 0s 151us/step - loss: 1.5671 - accuracy: 0.7638 - val_loss: 0.7489 - val_accuracy: 0.9231\n",
      "Epoch 10/100\n",
      "453/453 [==============================] - 0s 149us/step - loss: 1.7123 - accuracy: 0.7682 - val_loss: 0.7153 - val_accuracy: 0.9231\n",
      "Epoch 11/100\n",
      "453/453 [==============================] - 0s 145us/step - loss: 1.5831 - accuracy: 0.7792 - val_loss: 0.7602 - val_accuracy: 0.8974\n",
      "Epoch 12/100\n",
      "453/453 [==============================] - 0s 162us/step - loss: 1.7077 - accuracy: 0.7506 - val_loss: 0.7375 - val_accuracy: 0.9128\n",
      "Epoch 13/100\n",
      "453/453 [==============================] - 0s 130us/step - loss: 1.6916 - accuracy: 0.7417 - val_loss: 0.7655 - val_accuracy: 0.9128\n",
      "Epoch 14/100\n",
      "453/453 [==============================] - 0s 133us/step - loss: 1.5834 - accuracy: 0.7770 - val_loss: 0.7430 - val_accuracy: 0.9077\n",
      "Epoch 15/100\n",
      "453/453 [==============================] - 0s 119us/step - loss: 1.5856 - accuracy: 0.7859 - val_loss: 0.8648 - val_accuracy: 0.9282\n",
      "Epoch 16/100\n",
      "453/453 [==============================] - 0s 121us/step - loss: 1.8540 - accuracy: 0.7152 - val_loss: 0.7066 - val_accuracy: 0.9179\n",
      "Epoch 17/100\n",
      "453/453 [==============================] - 0s 138us/step - loss: 1.4954 - accuracy: 0.7373 - val_loss: 0.8376 - val_accuracy: 0.8923\n",
      "Epoch 18/100\n",
      "453/453 [==============================] - 0s 112us/step - loss: 1.9105 - accuracy: 0.7108 - val_loss: 0.6966 - val_accuracy: 0.9179\n",
      "Epoch 19/100\n",
      "453/453 [==============================] - 0s 109us/step - loss: 1.6815 - accuracy: 0.7616 - val_loss: 0.6934 - val_accuracy: 0.9179\n",
      "Epoch 20/100\n",
      "453/453 [==============================] - 0s 115us/step - loss: 1.5201 - accuracy: 0.7395 - val_loss: 0.7089 - val_accuracy: 0.9077\n",
      "Epoch 21/100\n",
      "453/453 [==============================] - 0s 229us/step - loss: 1.6729 - accuracy: 0.7461 - val_loss: 0.6915 - val_accuracy: 0.9179\n",
      "Epoch 22/100\n",
      "453/453 [==============================] - 0s 337us/step - loss: 1.4444 - accuracy: 0.7506 - val_loss: 0.7076 - val_accuracy: 0.9282\n",
      "Epoch 23/100\n",
      "453/453 [==============================] - 0s 207us/step - loss: 1.6519 - accuracy: 0.7726 - val_loss: 0.7316 - val_accuracy: 0.8974\n",
      "Epoch 24/100\n",
      "453/453 [==============================] - 0s 239us/step - loss: 1.8693 - accuracy: 0.7373 - val_loss: 0.7359 - val_accuracy: 0.9179\n",
      "Epoch 25/100\n",
      "453/453 [==============================] - 0s 154us/step - loss: 1.4056 - accuracy: 0.7528 - val_loss: 0.7242 - val_accuracy: 0.9231\n",
      "Epoch 26/100\n",
      "453/453 [==============================] - 0s 179us/step - loss: 1.4620 - accuracy: 0.7594 - val_loss: 0.6923 - val_accuracy: 0.9385\n",
      "Epoch 27/100\n",
      "453/453 [==============================] - 0s 385us/step - loss: 1.6895 - accuracy: 0.7682 - val_loss: 0.6822 - val_accuracy: 0.9333\n",
      "Epoch 28/100\n",
      "453/453 [==============================] - 0s 152us/step - loss: 1.5777 - accuracy: 0.7528 - val_loss: 0.7148 - val_accuracy: 0.9128\n",
      "Epoch 29/100\n",
      "453/453 [==============================] - 0s 131us/step - loss: 1.7385 - accuracy: 0.7506 - val_loss: 0.7208 - val_accuracy: 0.9077\n",
      "Epoch 30/100\n",
      "453/453 [==============================] - 0s 126us/step - loss: 1.6039 - accuracy: 0.7506 - val_loss: 0.7140 - val_accuracy: 0.9231\n",
      "Epoch 31/100\n",
      "453/453 [==============================] - 0s 126us/step - loss: 1.4453 - accuracy: 0.7506 - val_loss: 0.7210 - val_accuracy: 0.9231\n",
      "Epoch 32/100\n",
      "453/453 [==============================] - 0s 192us/step - loss: 1.7204 - accuracy: 0.7461 - val_loss: 0.6926 - val_accuracy: 0.9128\n",
      "Epoch 33/100\n",
      "453/453 [==============================] - 0s 249us/step - loss: 1.7517 - accuracy: 0.7329 - val_loss: 0.6844 - val_accuracy: 0.9231\n",
      "Epoch 34/100\n",
      "453/453 [==============================] - 0s 182us/step - loss: 1.5537 - accuracy: 0.7572 - val_loss: 0.6829 - val_accuracy: 0.9333\n",
      "Epoch 35/100\n",
      "453/453 [==============================] - 0s 150us/step - loss: 1.7011 - accuracy: 0.7417 - val_loss: 0.7076 - val_accuracy: 0.9333\n",
      "Epoch 36/100\n",
      "453/453 [==============================] - 0s 118us/step - loss: 1.2330 - accuracy: 0.7572 - val_loss: 0.6969 - val_accuracy: 0.9385\n",
      "Epoch 37/100\n",
      "453/453 [==============================] - 0s 107us/step - loss: 1.5068 - accuracy: 0.7461 - val_loss: 0.6813 - val_accuracy: 0.9436\n",
      "Epoch 38/100\n",
      "453/453 [==============================] - 0s 111us/step - loss: 1.5455 - accuracy: 0.7594 - val_loss: 0.6905 - val_accuracy: 0.9436\n",
      "Epoch 39/100\n",
      "453/453 [==============================] - 0s 98us/step - loss: 1.6284 - accuracy: 0.7263 - val_loss: 0.7240 - val_accuracy: 0.8974\n",
      "Epoch 40/100\n",
      "453/453 [==============================] - 0s 105us/step - loss: 1.7093 - accuracy: 0.7572 - val_loss: 0.8705 - val_accuracy: 0.9179\n",
      "Epoch 41/100\n",
      "453/453 [==============================] - 0s 103us/step - loss: 1.7612 - accuracy: 0.7307 - val_loss: 0.6873 - val_accuracy: 0.9436\n",
      "Epoch 42/100\n",
      "453/453 [==============================] - 0s 117us/step - loss: 1.3827 - accuracy: 0.7638 - val_loss: 0.7350 - val_accuracy: 0.8872\n",
      "Epoch 43/100\n",
      "453/453 [==============================] - 0s 117us/step - loss: 1.5418 - accuracy: 0.7329 - val_loss: 0.7075 - val_accuracy: 0.9385\n",
      "Epoch 44/100\n",
      "453/453 [==============================] - 0s 113us/step - loss: 1.3191 - accuracy: 0.7903 - val_loss: 0.6847 - val_accuracy: 0.9333\n",
      "Epoch 45/100\n",
      "453/453 [==============================] - 0s 112us/step - loss: 1.8060 - accuracy: 0.6909 - val_loss: 0.7753 - val_accuracy: 0.8821\n",
      "Epoch 46/100\n",
      "453/453 [==============================] - 0s 114us/step - loss: 1.4941 - accuracy: 0.7417 - val_loss: 0.6821 - val_accuracy: 0.9179\n",
      "Epoch 47/100\n",
      "453/453 [==============================] - 0s 121us/step - loss: 1.7883 - accuracy: 0.7174 - val_loss: 0.6705 - val_accuracy: 0.9231\n",
      "Epoch 48/100\n",
      "453/453 [==============================] - 0s 144us/step - loss: 1.4809 - accuracy: 0.7483 - val_loss: 0.6990 - val_accuracy: 0.9231\n",
      "Epoch 49/100\n",
      "453/453 [==============================] - 0s 131us/step - loss: 1.6972 - accuracy: 0.7285 - val_loss: 0.7073 - val_accuracy: 0.9282\n",
      "Epoch 50/100\n",
      "453/453 [==============================] - 0s 175us/step - loss: 1.7391 - accuracy: 0.7241 - val_loss: 0.7267 - val_accuracy: 0.9333\n",
      "Epoch 51/100\n",
      "453/453 [==============================] - 0s 411us/step - loss: 1.5954 - accuracy: 0.7550 - val_loss: 0.7066 - val_accuracy: 0.9436\n",
      "Epoch 52/100\n",
      "453/453 [==============================] - 0s 594us/step - loss: 1.5366 - accuracy: 0.7329 - val_loss: 0.7818 - val_accuracy: 0.9282\n",
      "Epoch 53/100\n",
      "453/453 [==============================] - 0s 151us/step - loss: 1.7419 - accuracy: 0.7417 - val_loss: 0.6878 - val_accuracy: 0.9282\n",
      "Epoch 54/100\n",
      "453/453 [==============================] - 0s 276us/step - loss: 1.6479 - accuracy: 0.7439 - val_loss: 0.7262 - val_accuracy: 0.9026\n",
      "Epoch 55/100\n",
      "453/453 [==============================] - 0s 142us/step - loss: 1.2295 - accuracy: 0.7726 - val_loss: 0.8313 - val_accuracy: 0.8923\n",
      "Epoch 56/100\n",
      "453/453 [==============================] - 0s 343us/step - loss: 1.5036 - accuracy: 0.7616 - val_loss: 0.6633 - val_accuracy: 0.9436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "453/453 [==============================] - 0s 155us/step - loss: 1.6184 - accuracy: 0.7550 - val_loss: 0.6611 - val_accuracy: 0.9282\n",
      "Epoch 58/100\n",
      "453/453 [==============================] - 0s 114us/step - loss: 1.6447 - accuracy: 0.7439 - val_loss: 0.7121 - val_accuracy: 0.9282\n",
      "Epoch 59/100\n",
      "453/453 [==============================] - 0s 143us/step - loss: 1.3576 - accuracy: 0.7594 - val_loss: 0.6996 - val_accuracy: 0.8923\n",
      "Epoch 60/100\n",
      "453/453 [==============================] - 0s 152us/step - loss: 1.6312 - accuracy: 0.7572 - val_loss: 0.6569 - val_accuracy: 0.9282\n",
      "Epoch 61/100\n",
      "453/453 [==============================] - 0s 105us/step - loss: 1.3088 - accuracy: 0.7770 - val_loss: 0.7766 - val_accuracy: 0.9128\n",
      "Epoch 62/100\n",
      "453/453 [==============================] - 0s 111us/step - loss: 1.5837 - accuracy: 0.7351 - val_loss: 0.6797 - val_accuracy: 0.9282\n",
      "Epoch 63/100\n",
      "453/453 [==============================] - 0s 243us/step - loss: 1.6278 - accuracy: 0.6954 - val_loss: 0.6495 - val_accuracy: 0.9333\n",
      "Epoch 64/100\n",
      "453/453 [==============================] - 0s 267us/step - loss: 1.5477 - accuracy: 0.7417 - val_loss: 0.6711 - val_accuracy: 0.9385\n",
      "Epoch 65/100\n",
      "453/453 [==============================] - 0s 130us/step - loss: 1.4368 - accuracy: 0.7461 - val_loss: 0.6190 - val_accuracy: 0.9385\n",
      "Epoch 66/100\n",
      "453/453 [==============================] - 0s 118us/step - loss: 1.4147 - accuracy: 0.7483 - val_loss: 0.6340 - val_accuracy: 0.9282\n",
      "Epoch 67/100\n",
      "453/453 [==============================] - 0s 126us/step - loss: 1.5103 - accuracy: 0.7748 - val_loss: 0.7049 - val_accuracy: 0.9231\n",
      "Epoch 68/100\n",
      "453/453 [==============================] - 0s 126us/step - loss: 1.8080 - accuracy: 0.7174 - val_loss: 1.0281 - val_accuracy: 0.8872\n",
      "Epoch 69/100\n",
      "453/453 [==============================] - 0s 155us/step - loss: 1.8765 - accuracy: 0.7241 - val_loss: 0.9542 - val_accuracy: 0.9026\n",
      "Epoch 70/100\n",
      "453/453 [==============================] - 0s 143us/step - loss: 1.4964 - accuracy: 0.7682 - val_loss: 0.8450 - val_accuracy: 0.9128\n",
      "Epoch 71/100\n",
      "453/453 [==============================] - 0s 265us/step - loss: 1.7094 - accuracy: 0.7329 - val_loss: 0.6878 - val_accuracy: 0.9231\n",
      "Epoch 72/100\n",
      "453/453 [==============================] - 0s 203us/step - loss: 1.5495 - accuracy: 0.7395 - val_loss: 0.6381 - val_accuracy: 0.9231\n",
      "Epoch 73/100\n",
      "453/453 [==============================] - 0s 132us/step - loss: 1.7301 - accuracy: 0.7174 - val_loss: 0.6418 - val_accuracy: 0.9231\n",
      "Epoch 74/100\n",
      "453/453 [==============================] - 0s 126us/step - loss: 1.5193 - accuracy: 0.7528 - val_loss: 0.6574 - val_accuracy: 0.9179\n",
      "Epoch 75/100\n",
      "453/453 [==============================] - 0s 143us/step - loss: 1.5872 - accuracy: 0.7550 - val_loss: 0.6797 - val_accuracy: 0.9128\n",
      "Epoch 76/100\n",
      "453/453 [==============================] - 0s 183us/step - loss: 1.5037 - accuracy: 0.7329 - val_loss: 0.6740 - val_accuracy: 0.9231\n",
      "Epoch 77/100\n",
      "453/453 [==============================] - 0s 134us/step - loss: 1.4438 - accuracy: 0.7638 - val_loss: 0.6760 - val_accuracy: 0.9077\n",
      "Epoch 78/100\n",
      "453/453 [==============================] - 0s 149us/step - loss: 1.7212 - accuracy: 0.7307 - val_loss: 0.7388 - val_accuracy: 0.9231\n",
      "Epoch 79/100\n",
      "453/453 [==============================] - 0s 144us/step - loss: 1.4577 - accuracy: 0.7395 - val_loss: 0.7432 - val_accuracy: 0.9231\n",
      "Epoch 80/100\n",
      "453/453 [==============================] - 0s 122us/step - loss: 1.5345 - accuracy: 0.7417 - val_loss: 0.7303 - val_accuracy: 0.9128\n",
      "Epoch 81/100\n",
      "453/453 [==============================] - 0s 145us/step - loss: 1.4370 - accuracy: 0.7439 - val_loss: 0.6710 - val_accuracy: 0.9282\n",
      "Epoch 82/100\n",
      "453/453 [==============================] - 0s 184us/step - loss: 1.5725 - accuracy: 0.7439 - val_loss: 0.6886 - val_accuracy: 0.9231\n",
      "Epoch 83/100\n",
      "453/453 [==============================] - 0s 242us/step - loss: 1.1426 - accuracy: 0.7572 - val_loss: 0.7216 - val_accuracy: 0.9282\n",
      "Epoch 84/100\n",
      "453/453 [==============================] - 0s 159us/step - loss: 1.4505 - accuracy: 0.7528 - val_loss: 0.7152 - val_accuracy: 0.9282\n",
      "Epoch 85/100\n",
      "453/453 [==============================] - 0s 194us/step - loss: 1.6068 - accuracy: 0.7307 - val_loss: 0.7056 - val_accuracy: 0.9231\n",
      "Epoch 86/100\n",
      "453/453 [==============================] - 0s 241us/step - loss: 1.4943 - accuracy: 0.7351 - val_loss: 0.6968 - val_accuracy: 0.9333\n",
      "Epoch 87/100\n",
      "453/453 [==============================] - 0s 230us/step - loss: 1.3378 - accuracy: 0.7373 - val_loss: 0.6796 - val_accuracy: 0.9282\n",
      "Epoch 88/100\n",
      "453/453 [==============================] - 0s 183us/step - loss: 1.0890 - accuracy: 0.8013 - val_loss: 0.6823 - val_accuracy: 0.9282\n",
      "Epoch 89/100\n",
      "453/453 [==============================] - 0s 533us/step - loss: 1.4790 - accuracy: 0.7373 - val_loss: 0.6751 - val_accuracy: 0.9385\n",
      "Epoch 90/100\n",
      "453/453 [==============================] - 0s 269us/step - loss: 1.3906 - accuracy: 0.7594 - val_loss: 0.6987 - val_accuracy: 0.9231\n",
      "Epoch 91/100\n",
      "453/453 [==============================] - 0s 201us/step - loss: 1.4753 - accuracy: 0.7483 - val_loss: 0.7011 - val_accuracy: 0.9333\n",
      "Epoch 92/100\n",
      "453/453 [==============================] - 0s 152us/step - loss: 1.3008 - accuracy: 0.7704 - val_loss: 0.7309 - val_accuracy: 0.9077\n",
      "Epoch 93/100\n",
      "453/453 [==============================] - 0s 204us/step - loss: 1.2388 - accuracy: 0.7815 - val_loss: 0.6482 - val_accuracy: 0.9333\n",
      "Epoch 94/100\n",
      "453/453 [==============================] - 0s 197us/step - loss: 1.6096 - accuracy: 0.7550 - val_loss: 0.6936 - val_accuracy: 0.9333\n",
      "Epoch 95/100\n",
      "453/453 [==============================] - 0s 176us/step - loss: 1.2522 - accuracy: 0.8035 - val_loss: 0.6630 - val_accuracy: 0.9436\n",
      "Epoch 96/100\n",
      "453/453 [==============================] - 0s 156us/step - loss: 1.2776 - accuracy: 0.7726 - val_loss: 0.6508 - val_accuracy: 0.9333\n",
      "Epoch 97/100\n",
      "453/453 [==============================] - 0s 179us/step - loss: 1.1849 - accuracy: 0.7859 - val_loss: 0.6300 - val_accuracy: 0.9385\n",
      "Epoch 98/100\n",
      "453/453 [==============================] - 0s 127us/step - loss: 1.3008 - accuracy: 0.7925 - val_loss: 0.6445 - val_accuracy: 0.9282\n",
      "Epoch 99/100\n",
      "453/453 [==============================] - 0s 229us/step - loss: 1.4429 - accuracy: 0.7506 - val_loss: 0.6890 - val_accuracy: 0.8872\n",
      "Epoch 100/100\n",
      "453/453 [==============================] - 0s 270us/step - loss: 1.4010 - accuracy: 0.7395 - val_loss: 0.6342 - val_accuracy: 0.9385\n"
     ]
    }
   ],
   "source": [
    "hist1_over5 = model1_over5.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 74.90%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over5.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba5 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_regularizor_dropout_2.xlsx\",\n",
    "                        sheet_name=0,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS241</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.342914e-03</td>\n",
       "      <td>9.986569e-01</td>\n",
       "      <td>2.348628e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5.170289e-08</td>\n",
       "      <td>1.017893e-07</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS255</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.780311e-07</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>2.544841e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS214</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.203547e-10</td>\n",
       "      <td>5.688883e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5.170289e-08</td>\n",
       "      <td>1.017893e-07</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>BCH-SA-12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.152503e-09</td>\n",
       "      <td>1.898730e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS049</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.401357e-11</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.209735e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS022</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.755084e-10</td>\n",
       "      <td>1.974275e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS236</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.357345e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.293117e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4.074704e-08</td>\n",
       "      <td>2.329201e-08</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1982 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       phage     strain  phenotype  prediction             0  \\\n",
       "0     p002ykpresabsSTCC_qual     NRS241          1           1  1.342914e-03   \n",
       "1     p002ykpresabsSTCC_qual     NRS148          2           2  5.170289e-08   \n",
       "2     p002ykpresabsSTCC_qual     NRS255          1           1  1.780311e-07   \n",
       "3     p002ykpresabsSTCC_qual     NRS214          0           0  1.000000e+00   \n",
       "4     p002ykpresabsSTCC_qual     NRS148          2           2  5.170289e-08   \n",
       "...                      ...        ...        ...         ...           ...   \n",
       "1977     pyopresabsSTCC_qual  BCH-SA-12          0           0  1.000000e+00   \n",
       "1978     pyopresabsSTCC_qual     NRS049          0           1  8.401357e-11   \n",
       "1979     pyopresabsSTCC_qual     NRS022          0           0  1.000000e+00   \n",
       "1980     pyopresabsSTCC_qual     NRS236          1           1  1.357345e-08   \n",
       "1981     pyopresabsSTCC_qual     NRS148          2           2  4.074704e-08   \n",
       "\n",
       "                 1             2  \n",
       "0     9.986569e-01  2.348628e-07  \n",
       "1     1.017893e-07  9.999999e-01  \n",
       "2     9.999999e-01  2.544841e-12  \n",
       "3     2.203547e-10  5.688883e-15  \n",
       "4     1.017893e-07  9.999999e-01  \n",
       "...            ...           ...  \n",
       "1977  1.152503e-09  1.898730e-09  \n",
       "1978  1.000000e+00  3.209735e-13  \n",
       "1979  4.755084e-10  1.974275e-10  \n",
       "1980  1.000000e+00  1.293117e-10  \n",
       "1981  2.329201e-08  9.999999e-01  \n",
       "\n",
       "[1982 rows x 7 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.31085050e-01, 5.68914950e-01, 7.80713400e-08],\n",
       "       [9.99999900e-01, 8.49878100e-08, 1.08213105e-10],\n",
       "       [1.34317460e-08, 9.25600650e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 8.18367700e-09, 1.13925834e-10],\n",
       "       [1.34317460e-08, 9.25600650e-08, 9.99999900e-01],\n",
       "       [9.99975700e-01, 2.43147060e-05, 1.01738140e-10],\n",
       "       [1.00000000e+00, 3.56445800e-10, 1.96984100e-13],\n",
       "       [4.19579820e-08, 3.75504680e-08, 9.99999900e-01],\n",
       "       [9.99899600e-01, 1.00377370e-04, 1.12083946e-10],\n",
       "       [1.34317460e-08, 9.25600650e-08, 9.99999900e-01],\n",
       "       [4.19579820e-08, 3.75504680e-08, 9.99999900e-01],\n",
       "       [4.19579820e-08, 3.75504680e-08, 9.99999900e-01],\n",
       "       [4.19579820e-08, 3.75504680e-08, 9.99999900e-01],\n",
       "       [4.19579820e-08, 3.75504680e-08, 9.99999900e-01],\n",
       "       [1.74528570e-02, 9.82547000e-01, 6.79716200e-08],\n",
       "       [4.19579820e-08, 3.75504680e-08, 9.99999900e-01],\n",
       "       [1.34317460e-08, 9.25600650e-08, 9.99999900e-01],\n",
       "       [8.60922300e-01, 1.38499480e-01, 5.78214100e-04],\n",
       "       [9.99995600e-01, 4.41720930e-06, 6.18760350e-14],\n",
       "       [1.34317460e-08, 9.25600650e-08, 9.99999900e-01],\n",
       "       [1.34317460e-08, 9.25600650e-08, 9.99999900e-01],\n",
       "       [4.19579820e-08, 3.75504680e-08, 9.99999900e-01],\n",
       "       [2.34668930e-02, 9.76530400e-01, 2.69581570e-06],\n",
       "       [4.19579820e-08, 3.75504680e-08, 9.99999900e-01],\n",
       "       [1.34317460e-08, 9.25600650e-08, 9.99999900e-01],\n",
       "       [2.40523030e-02, 9.75947700e-01, 2.13810700e-08],\n",
       "       [9.99990700e-01, 9.32207100e-06, 5.08357660e-11],\n",
       "       [2.22219460e-03, 9.97777640e-01, 1.63691200e-07],\n",
       "       [4.19579820e-08, 3.75504680e-08, 9.99999900e-01],\n",
       "       [6.62451400e-01, 3.37548580e-01, 6.54348040e-08],\n",
       "       [1.17052690e-01, 8.82947270e-01, 8.07961900e-08],\n",
       "       [4.64323460e-01, 4.19223250e-01, 1.16453280e-01],\n",
       "       [4.19579820e-08, 3.75504680e-08, 9.99999900e-01],\n",
       "       [1.91669780e-02, 3.88394400e-01, 5.92438640e-01],\n",
       "       [3.49548700e-02, 9.65044200e-01, 8.66880900e-07],\n",
       "       [3.49548700e-02, 9.65044200e-01, 8.66880900e-07],\n",
       "       [4.19579820e-08, 3.75504680e-08, 9.99999900e-01],\n",
       "       [1.34317460e-08, 9.25600650e-08, 9.99999900e-01],\n",
       "       [1.34317460e-08, 9.25600650e-08, 9.99999900e-01],\n",
       "       [9.95621600e-01, 4.37827270e-03, 9.84803560e-08],\n",
       "       [2.25932400e-05, 9.56011060e-01, 4.39663160e-02],\n",
       "       [2.70124580e-01, 7.29854170e-01, 2.12271260e-05],\n",
       "       [4.19579820e-08, 3.75504680e-08, 9.99999900e-01],\n",
       "       [2.10768900e-02, 9.78922370e-01, 7.10900570e-07],\n",
       "       [3.53780900e-08, 1.00000000e+00, 1.92625260e-08],\n",
       "       [1.36777600e-01, 8.63063160e-01, 1.59289800e-04],\n",
       "       [5.78044900e-04, 9.99421950e-01, 2.44056720e-08],\n",
       "       [1.16045530e-04, 9.99883900e-01, 5.06243000e-09],\n",
       "       [4.19579820e-08, 3.75504680e-08, 9.99999900e-01],\n",
       "       [4.19579820e-08, 3.75504680e-08, 9.99999900e-01],\n",
       "       [9.94287550e-01, 5.71203300e-03, 4.32820100e-07],\n",
       "       [4.19579820e-08, 3.75504680e-08, 9.99999900e-01],\n",
       "       [1.16045530e-04, 9.99883900e-01, 5.06243000e-09],\n",
       "       [9.99995600e-01, 4.41720930e-06, 6.18760350e-14],\n",
       "       [1.34317460e-08, 9.25600650e-08, 9.99999900e-01],\n",
       "       [9.99999760e-01, 2.85908300e-07, 1.80599910e-11],\n",
       "       [1.00000000e+00, 2.68240810e-12, 2.70325540e-16],\n",
       "       [9.72962900e-01, 2.68892400e-02, 1.47881380e-04],\n",
       "       [4.19579820e-08, 3.75504680e-08, 9.99999900e-01],\n",
       "       [1.17195260e-04, 9.82910100e-01, 1.69727500e-02],\n",
       "       [1.16045530e-04, 9.99883900e-01, 5.06243000e-09],\n",
       "       [9.99999640e-01, 3.04899710e-07, 3.97113870e-11],\n",
       "       [1.34317460e-08, 9.25600650e-08, 9.99999900e-01],\n",
       "       [9.79885400e-01, 2.00610760e-02, 5.35428950e-05],\n",
       "       [9.99999300e-01, 7.56746100e-07, 2.55717900e-27],\n",
       "       [9.99761900e-01, 2.38172650e-04, 5.39531870e-08],\n",
       "       [4.19579820e-08, 3.75504680e-08, 9.99999900e-01],\n",
       "       [4.19579820e-08, 3.75504680e-08, 9.99999900e-01],\n",
       "       [7.32813200e-05, 9.99926700e-01, 2.79613790e-08],\n",
       "       [4.31085050e-01, 5.68914950e-01, 7.80713400e-08],\n",
       "       [9.99997850e-01, 2.16426340e-06, 3.81732670e-10],\n",
       "       [1.00000000e+00, 5.02408700e-09, 7.12918750e-11],\n",
       "       [3.94192460e-01, 6.05802900e-01, 4.66685900e-06],\n",
       "       [4.31085050e-01, 5.68914950e-01, 7.80713400e-08],\n",
       "       [4.19579820e-08, 3.75504680e-08, 9.99999900e-01],\n",
       "       [4.19579820e-08, 3.75504680e-08, 9.99999900e-01],\n",
       "       [4.19579820e-08, 3.75504680e-08, 9.99999900e-01],\n",
       "       [4.19579820e-08, 3.75504680e-08, 9.99999900e-01],\n",
       "       [9.09885470e-01, 9.00984600e-02, 1.60468500e-05],\n",
       "       [1.91669780e-02, 3.88394400e-01, 5.92438640e-01],\n",
       "       [8.35801600e-01, 1.64198370e-01, 6.01073500e-09],\n",
       "       [4.19579820e-08, 3.75504680e-08, 9.99999900e-01],\n",
       "       [7.75512400e-01, 2.24487510e-01, 1.17007930e-07],\n",
       "       [9.98030000e-01, 1.96970400e-03, 2.25589050e-07],\n",
       "       [1.34317460e-08, 9.25600650e-08, 9.99999900e-01],\n",
       "       [9.99955530e-01, 4.44802000e-05, 1.71578680e-09],\n",
       "       [4.19579820e-08, 3.75504680e-08, 9.99999900e-01],\n",
       "       [8.22394640e-02, 9.17754230e-01, 6.28239600e-06],\n",
       "       [2.40523030e-02, 9.75947700e-01, 2.13810700e-08],\n",
       "       [2.10768900e-02, 9.78922370e-01, 7.10900570e-07],\n",
       "       [2.12760990e-05, 9.99978800e-01, 7.39800350e-09],\n",
       "       [8.70676500e-01, 1.27595950e-01, 1.72752800e-03],\n",
       "       [9.99840600e-01, 1.56324500e-04, 3.02747690e-06],\n",
       "       [9.99997140e-01, 2.89111300e-06, 4.75469600e-11],\n",
       "       [6.21205050e-02, 9.24130600e-01, 1.37489300e-02],\n",
       "       [4.44599030e-06, 9.99995600e-01, 4.49753980e-10],\n",
       "       [9.99999300e-01, 7.21302060e-07, 2.95925470e-11],\n",
       "       [2.40523030e-02, 9.75947700e-01, 2.13810700e-08],\n",
       "       [2.40523030e-02, 9.75947700e-01, 2.13810700e-08],\n",
       "       [5.80489200e-03, 9.94194100e-01, 1.04092200e-06],\n",
       "       [1.74528570e-02, 9.82547000e-01, 6.79716200e-08],\n",
       "       [9.77027800e-01, 2.29719370e-02, 3.77279900e-07],\n",
       "       [3.49548700e-02, 9.65044200e-01, 8.66880900e-07],\n",
       "       [1.34317460e-08, 9.25600650e-08, 9.99999900e-01],\n",
       "       [1.34317460e-08, 9.25600650e-08, 9.99999900e-01],\n",
       "       [1.34317460e-08, 9.25600650e-08, 9.99999900e-01],\n",
       "       [9.92723300e-01, 7.27105400e-03, 5.65113850e-06],\n",
       "       [9.99985460e-01, 1.43097580e-05, 2.87607380e-07],\n",
       "       [9.87489040e-01, 1.25107460e-02, 2.22523950e-07],\n",
       "       [7.30425660e-01, 2.69529880e-01, 4.45365100e-05],\n",
       "       [1.34317460e-08, 9.25600650e-08, 9.99999900e-01],\n",
       "       [2.25932400e-05, 9.56011060e-01, 4.39663160e-02],\n",
       "       [4.19579820e-08, 3.75504680e-08, 9.99999900e-01],\n",
       "       [3.47645420e-09, 1.00000000e+00, 2.32457240e-08],\n",
       "       [2.77032600e-01, 7.21442400e-01, 1.52498730e-03],\n",
       "       [8.60922300e-01, 1.38499480e-01, 5.78214100e-04],\n",
       "       [9.99110300e-01, 8.89686500e-04, 3.09951320e-08],\n",
       "       [4.31085050e-01, 5.68914950e-01, 7.80713400e-08],\n",
       "       [3.49548700e-02, 9.65044200e-01, 8.66880900e-07],\n",
       "       [2.25932400e-05, 9.56011060e-01, 4.39663160e-02],\n",
       "       [9.15667000e-07, 9.99999050e-01, 3.18105500e-10],\n",
       "       [1.34317460e-08, 9.25600650e-08, 9.99999900e-01],\n",
       "       [9.99721940e-01, 2.77998330e-04, 1.83972280e-09],\n",
       "       [1.13157600e-01, 8.85788200e-01, 1.05426310e-03],\n",
       "       [1.00000000e+00, 3.62289400e-08, 3.01104000e-11],\n",
       "       [4.19579820e-08, 3.75504680e-08, 9.99999900e-01],\n",
       "       [4.19579820e-08, 3.75504680e-08, 9.99999900e-01],\n",
       "       [8.01165100e-01, 1.98829230e-01, 5.67310550e-06],\n",
       "       [7.62622950e-01, 2.37278760e-01, 9.82600500e-05],\n",
       "       [9.99990460e-01, 9.30251200e-06, 2.62313220e-07],\n",
       "       [1.91669780e-02, 3.88394400e-01, 5.92438640e-01],\n",
       "       [1.13157600e-01, 8.85788200e-01, 1.05426310e-03],\n",
       "       [1.34317460e-08, 9.25600650e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 4.45376480e-11, 2.04800470e-14],\n",
       "       [2.25932400e-05, 9.56011060e-01, 4.39663160e-02],\n",
       "       [9.99927760e-01, 7.22492500e-05, 1.52918510e-10],\n",
       "       [1.34317460e-08, 9.25600650e-08, 9.99999900e-01],\n",
       "       [2.25932400e-05, 9.56011060e-01, 4.39663160e-02],\n",
       "       [4.31085050e-01, 5.68914950e-01, 7.80713400e-08],\n",
       "       [4.19579820e-08, 3.75504680e-08, 9.99999900e-01],\n",
       "       [1.34317460e-08, 9.25600650e-08, 9.99999900e-01],\n",
       "       [5.80759470e-01, 4.19041930e-01, 1.98534210e-04],\n",
       "       [4.19579820e-08, 3.75504680e-08, 9.99999900e-01],\n",
       "       [1.17818590e-06, 9.99681830e-01, 3.17017520e-04],\n",
       "       [9.99995000e-01, 4.94936830e-06, 5.93815840e-12],\n",
       "       [9.47459200e-01, 5.25346700e-02, 6.14796900e-06],\n",
       "       [8.45218900e-01, 1.54761930e-01, 1.92223090e-05],\n",
       "       [1.34317460e-08, 9.25600650e-08, 9.99999900e-01],\n",
       "       [1.34317460e-08, 9.25600650e-08, 9.99999900e-01],\n",
       "       [1.34317460e-08, 9.25600650e-08, 9.99999900e-01],\n",
       "       [4.31085050e-01, 5.68914950e-01, 7.80713400e-08],\n",
       "       [9.99672340e-02, 9.00031450e-01, 1.25466010e-06],\n",
       "       [4.19579820e-08, 3.75504680e-08, 9.99999900e-01],\n",
       "       [1.34317460e-08, 9.25600650e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 3.82277460e-08, 3.59687600e-11],\n",
       "       [9.99999640e-01, 3.04899710e-07, 3.97113870e-11],\n",
       "       [9.15667000e-07, 9.99999050e-01, 3.18105500e-10],\n",
       "       [9.99721940e-01, 2.77998330e-04, 1.83972280e-09],\n",
       "       [1.34317460e-08, 9.25600650e-08, 9.99999900e-01],\n",
       "       [2.10768900e-02, 9.78922370e-01, 7.10900570e-07],\n",
       "       [8.48180950e-01, 1.51791700e-01, 2.72697620e-05],\n",
       "       [2.40523030e-02, 9.75947700e-01, 2.13810700e-08],\n",
       "       [1.34317460e-08, 9.25600650e-08, 9.99999900e-01],\n",
       "       [4.19579820e-08, 3.75504680e-08, 9.99999900e-01],\n",
       "       [9.99091860e-01, 9.07739600e-04, 3.88431460e-07],\n",
       "       [1.00000000e+00, 7.90445700e-11, 3.35692170e-13],\n",
       "       [4.19579820e-08, 3.75504680e-08, 9.99999900e-01],\n",
       "       [1.34317460e-08, 9.25600650e-08, 9.99999900e-01],\n",
       "       [1.34317460e-08, 9.25600650e-08, 9.99999900e-01],\n",
       "       [4.19579820e-08, 3.75504680e-08, 9.99999900e-01],\n",
       "       [4.31085050e-01, 5.68914950e-01, 7.80713400e-08],\n",
       "       [2.34668930e-02, 9.76530400e-01, 2.69581570e-06],\n",
       "       [9.99760450e-01, 2.39611940e-04, 4.86553960e-10],\n",
       "       [7.32813200e-05, 9.99926700e-01, 2.79613790e-08],\n",
       "       [9.99999900e-01, 1.37871770e-07, 1.15433190e-27],\n",
       "       [2.59620220e-01, 7.39984330e-01, 3.95425480e-04],\n",
       "       [1.34317460e-08, 9.25600650e-08, 9.99999900e-01],\n",
       "       [5.98700100e-01, 4.01299600e-01, 3.37197460e-07],\n",
       "       [1.00000000e+00, 2.55771020e-10, 1.10930440e-11],\n",
       "       [4.19579820e-08, 3.75504680e-08, 9.99999900e-01],\n",
       "       [1.36777600e-01, 8.63063160e-01, 1.59289800e-04],\n",
       "       [9.02773260e-01, 9.72249400e-02, 1.85742060e-06],\n",
       "       [4.78770550e-01, 5.18707500e-01, 2.52201130e-03],\n",
       "       [5.98700100e-01, 4.01299600e-01, 3.37197460e-07],\n",
       "       [9.94656200e-01, 5.34382100e-03, 1.28503890e-08],\n",
       "       [9.15567500e-01, 2.33367500e-04, 8.41991750e-02],\n",
       "       [1.00000000e+00, 7.90445700e-11, 3.35692170e-13],\n",
       "       [2.77032600e-01, 7.21442400e-01, 1.52498730e-03],\n",
       "       [1.34317460e-08, 9.25600650e-08, 9.99999900e-01],\n",
       "       [9.99999500e-01, 4.64501230e-07, 4.06292780e-09],\n",
       "       [7.75512400e-01, 2.24487510e-01, 1.17007930e-07],\n",
       "       [3.49548700e-02, 9.65044200e-01, 8.66880900e-07],\n",
       "       [4.19579820e-08, 3.75504680e-08, 9.99999900e-01],\n",
       "       [8.46052050e-01, 1.53944640e-01, 3.21645370e-06],\n",
       "       [4.41505700e-05, 9.99955900e-01, 3.81390830e-09]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob5 = df_proba5[df_proba5['phage']=='p0017SpresabsSTCC_qual'].iloc[:,-3:]\n",
    "y_prob5 = y_prob5.to_numpy()\n",
    "y_prob5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9714792899408283"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo5 = rocauc_ovo(y_test_over, y_prob5, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9714792899408283"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr5 = rocauc_ovr(y_test_over, y_prob5, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=678,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat6 = pd.DataFrame(X_test_over[:,0])\n",
    "dat6['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CFBREBSa119</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS074</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GA231</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>NRS252</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>SR2852</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>NRS108</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>NRS202</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>NRS110</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test\n",
       "0    CFBREBSa119     0\n",
       "1         NRS001     1\n",
       "2         NRS074     0\n",
       "3         NRS209     2\n",
       "4          GA231     0\n",
       "..           ...   ...\n",
       "190       NRS252     0\n",
       "191       SR2852     1\n",
       "192       NRS108     1\n",
       "193       NRS202     0\n",
       "194       NRS110     2\n",
       "\n",
       "[195 rows x 2 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over6 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],), activity_regularizer=l1(0.001)),\n",
    "    Dense(3, activation='softmax'),\n",
    "    Dropout(0.2, ),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over6.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 453 samples, validate on 195 samples\n",
      "Epoch 1/100\n",
      "453/453 [==============================] - 0s 581us/step - loss: 9.6541 - accuracy: 0.3907 - val_loss: 6.0553 - val_accuracy: 0.3949\n",
      "Epoch 2/100\n",
      "453/453 [==============================] - 0s 139us/step - loss: 8.0938 - accuracy: 0.4283 - val_loss: 4.5736 - val_accuracy: 0.4256\n",
      "Epoch 3/100\n",
      "453/453 [==============================] - 0s 140us/step - loss: 7.2743 - accuracy: 0.5386 - val_loss: 3.2626 - val_accuracy: 0.6923\n",
      "Epoch 4/100\n",
      "453/453 [==============================] - 0s 140us/step - loss: 6.1172 - accuracy: 0.5188 - val_loss: 2.7606 - val_accuracy: 0.6000\n",
      "Epoch 5/100\n",
      "453/453 [==============================] - 0s 111us/step - loss: 5.6745 - accuracy: 0.5673 - val_loss: 2.3318 - val_accuracy: 0.6513\n",
      "Epoch 6/100\n",
      "453/453 [==============================] - 0s 130us/step - loss: 5.3711 - accuracy: 0.5762 - val_loss: 1.9673 - val_accuracy: 0.7846\n",
      "Epoch 7/100\n",
      "453/453 [==============================] - 0s 159us/step - loss: 4.7168 - accuracy: 0.6711 - val_loss: 1.7196 - val_accuracy: 0.7949\n",
      "Epoch 8/100\n",
      "453/453 [==============================] - 0s 139us/step - loss: 5.0331 - accuracy: 0.5960 - val_loss: 1.5390 - val_accuracy: 0.7795\n",
      "Epoch 9/100\n",
      "453/453 [==============================] - 0s 118us/step - loss: 4.4620 - accuracy: 0.6534 - val_loss: 1.3592 - val_accuracy: 0.7897\n",
      "Epoch 10/100\n",
      "453/453 [==============================] - 0s 98us/step - loss: 4.1507 - accuracy: 0.6600 - val_loss: 1.2717 - val_accuracy: 0.7949\n",
      "Epoch 11/100\n",
      "453/453 [==============================] - 0s 119us/step - loss: 4.0057 - accuracy: 0.6490 - val_loss: 1.0721 - val_accuracy: 0.7692\n",
      "Epoch 12/100\n",
      "453/453 [==============================] - 0s 86us/step - loss: 3.3754 - accuracy: 0.6887 - val_loss: 0.9616 - val_accuracy: 0.8000\n",
      "Epoch 13/100\n",
      "453/453 [==============================] - 0s 120us/step - loss: 3.3474 - accuracy: 0.6468 - val_loss: 0.8485 - val_accuracy: 0.8051\n",
      "Epoch 14/100\n",
      "453/453 [==============================] - 0s 91us/step - loss: 3.5759 - accuracy: 0.6623 - val_loss: 0.7812 - val_accuracy: 0.7692\n",
      "Epoch 15/100\n",
      "453/453 [==============================] - 0s 91us/step - loss: 3.5706 - accuracy: 0.6225 - val_loss: 0.7391 - val_accuracy: 0.7641\n",
      "Epoch 16/100\n",
      "453/453 [==============================] - 0s 97us/step - loss: 3.6777 - accuracy: 0.5938 - val_loss: 0.7205 - val_accuracy: 0.7641\n",
      "Epoch 17/100\n",
      "453/453 [==============================] - 0s 129us/step - loss: 2.9316 - accuracy: 0.6512 - val_loss: 0.7013 - val_accuracy: 0.7641\n",
      "Epoch 18/100\n",
      "453/453 [==============================] - 0s 142us/step - loss: 3.1502 - accuracy: 0.6512 - val_loss: 0.6947 - val_accuracy: 0.7538\n",
      "Epoch 19/100\n",
      "453/453 [==============================] - 0s 139us/step - loss: 3.4740 - accuracy: 0.6159 - val_loss: 0.7520 - val_accuracy: 0.7795\n",
      "Epoch 20/100\n",
      "453/453 [==============================] - 0s 91us/step - loss: 2.9449 - accuracy: 0.6446 - val_loss: 0.6820 - val_accuracy: 0.7436\n",
      "Epoch 21/100\n",
      "453/453 [==============================] - 0s 105us/step - loss: 2.8560 - accuracy: 0.6645 - val_loss: 0.6710 - val_accuracy: 0.7436\n",
      "Epoch 22/100\n",
      "453/453 [==============================] - 0s 107us/step - loss: 3.2708 - accuracy: 0.6336 - val_loss: 0.6884 - val_accuracy: 0.7795\n",
      "Epoch 23/100\n",
      "453/453 [==============================] - 0s 128us/step - loss: 3.3623 - accuracy: 0.6269 - val_loss: 0.7203 - val_accuracy: 0.7897\n",
      "Epoch 24/100\n",
      "453/453 [==============================] - 0s 204us/step - loss: 2.9806 - accuracy: 0.6291 - val_loss: 0.6985 - val_accuracy: 0.8000\n",
      "Epoch 25/100\n",
      "453/453 [==============================] - 0s 92us/step - loss: 2.7308 - accuracy: 0.6645 - val_loss: 0.6940 - val_accuracy: 0.8103\n",
      "Epoch 26/100\n",
      "453/453 [==============================] - 0s 84us/step - loss: 2.5503 - accuracy: 0.6976 - val_loss: 0.6834 - val_accuracy: 0.7897\n",
      "Epoch 27/100\n",
      "453/453 [==============================] - 0s 101us/step - loss: 2.6832 - accuracy: 0.6556 - val_loss: 0.7096 - val_accuracy: 0.8000\n",
      "Epoch 28/100\n",
      "453/453 [==============================] - 0s 112us/step - loss: 2.7476 - accuracy: 0.6402 - val_loss: 0.7017 - val_accuracy: 0.7897\n",
      "Epoch 29/100\n",
      "453/453 [==============================] - 0s 100us/step - loss: 2.4346 - accuracy: 0.6777 - val_loss: 0.6924 - val_accuracy: 0.8205\n",
      "Epoch 30/100\n",
      "453/453 [==============================] - 0s 155us/step - loss: 2.8070 - accuracy: 0.6623 - val_loss: 0.6915 - val_accuracy: 0.8051\n",
      "Epoch 31/100\n",
      "453/453 [==============================] - 0s 109us/step - loss: 3.0003 - accuracy: 0.6512 - val_loss: 0.6917 - val_accuracy: 0.8051\n",
      "Epoch 32/100\n",
      "453/453 [==============================] - 0s 75us/step - loss: 2.2492 - accuracy: 0.7064 - val_loss: 0.6871 - val_accuracy: 0.8256\n",
      "Epoch 33/100\n",
      "453/453 [==============================] - 0s 104us/step - loss: 2.7524 - accuracy: 0.6909 - val_loss: 0.7164 - val_accuracy: 0.8154\n",
      "Epoch 34/100\n",
      "453/453 [==============================] - 0s 84us/step - loss: 2.4329 - accuracy: 0.6799 - val_loss: 0.7674 - val_accuracy: 0.8000\n",
      "Epoch 35/100\n",
      "453/453 [==============================] - 0s 79us/step - loss: 2.5251 - accuracy: 0.7042 - val_loss: 0.7291 - val_accuracy: 0.8615\n",
      "Epoch 36/100\n",
      "453/453 [==============================] - 0s 83us/step - loss: 2.5693 - accuracy: 0.7174 - val_loss: 0.9443 - val_accuracy: 0.8718\n",
      "Epoch 37/100\n",
      "453/453 [==============================] - 0s 123us/step - loss: 2.5391 - accuracy: 0.7307 - val_loss: 0.7083 - val_accuracy: 0.8410\n",
      "Epoch 38/100\n",
      "453/453 [==============================] - 0s 106us/step - loss: 2.6054 - accuracy: 0.7042 - val_loss: 0.7065 - val_accuracy: 0.8615\n",
      "Epoch 39/100\n",
      "453/453 [==============================] - 0s 107us/step - loss: 2.5054 - accuracy: 0.7196 - val_loss: 0.7139 - val_accuracy: 0.8667\n",
      "Epoch 40/100\n",
      "453/453 [==============================] - 0s 83us/step - loss: 2.4836 - accuracy: 0.7174 - val_loss: 0.7048 - val_accuracy: 0.8513\n",
      "Epoch 41/100\n",
      "453/453 [==============================] - 0s 77us/step - loss: 2.4400 - accuracy: 0.7174 - val_loss: 0.7614 - val_accuracy: 0.8564\n",
      "Epoch 42/100\n",
      "453/453 [==============================] - 0s 71us/step - loss: 2.2868 - accuracy: 0.7285 - val_loss: 0.7135 - val_accuracy: 0.8769\n",
      "Epoch 43/100\n",
      "453/453 [==============================] - 0s 83us/step - loss: 2.6356 - accuracy: 0.7241 - val_loss: 0.7718 - val_accuracy: 0.8410\n",
      "Epoch 44/100\n",
      "453/453 [==============================] - 0s 70us/step - loss: 2.0410 - accuracy: 0.7506 - val_loss: 0.7057 - val_accuracy: 0.8615\n",
      "Epoch 45/100\n",
      "453/453 [==============================] - 0s 104us/step - loss: 2.2507 - accuracy: 0.7461 - val_loss: 0.7018 - val_accuracy: 0.8872\n",
      "Epoch 46/100\n",
      "453/453 [==============================] - 0s 234us/step - loss: 1.8697 - accuracy: 0.7638 - val_loss: 0.7060 - val_accuracy: 0.8718\n",
      "Epoch 47/100\n",
      "453/453 [==============================] - 0s 213us/step - loss: 2.2404 - accuracy: 0.7219 - val_loss: 0.7756 - val_accuracy: 0.8615\n",
      "Epoch 48/100\n",
      "453/453 [==============================] - 0s 182us/step - loss: 2.0570 - accuracy: 0.7660 - val_loss: 0.6664 - val_accuracy: 0.8718\n",
      "Epoch 49/100\n",
      "453/453 [==============================] - 0s 122us/step - loss: 2.5702 - accuracy: 0.7373 - val_loss: 0.7132 - val_accuracy: 0.8872\n",
      "Epoch 50/100\n",
      "453/453 [==============================] - 0s 132us/step - loss: 2.2235 - accuracy: 0.7461 - val_loss: 0.7380 - val_accuracy: 0.8718\n",
      "Epoch 51/100\n",
      "453/453 [==============================] - 0s 147us/step - loss: 2.1856 - accuracy: 0.7108 - val_loss: 0.7852 - val_accuracy: 0.8667\n",
      "Epoch 52/100\n",
      "453/453 [==============================] - 0s 181us/step - loss: 2.2044 - accuracy: 0.6976 - val_loss: 0.7686 - val_accuracy: 0.8615\n",
      "Epoch 53/100\n",
      "453/453 [==============================] - 0s 147us/step - loss: 2.1999 - accuracy: 0.7307 - val_loss: 0.7419 - val_accuracy: 0.8667\n",
      "Epoch 54/100\n",
      "453/453 [==============================] - 0s 139us/step - loss: 2.2714 - accuracy: 0.7108 - val_loss: 0.7843 - val_accuracy: 0.8769\n",
      "Epoch 55/100\n",
      "453/453 [==============================] - 0s 173us/step - loss: 2.0841 - accuracy: 0.7307 - val_loss: 0.7880 - val_accuracy: 0.8769\n",
      "Epoch 56/100\n",
      "453/453 [==============================] - 0s 214us/step - loss: 2.2672 - accuracy: 0.7174 - val_loss: 0.7892 - val_accuracy: 0.8615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "453/453 [==============================] - 0s 102us/step - loss: 2.0916 - accuracy: 0.7152 - val_loss: 0.8274 - val_accuracy: 0.8667\n",
      "Epoch 58/100\n",
      "453/453 [==============================] - 0s 93us/step - loss: 2.0693 - accuracy: 0.7616 - val_loss: 0.7692 - val_accuracy: 0.8667\n",
      "Epoch 59/100\n",
      "453/453 [==============================] - 0s 153us/step - loss: 2.0332 - accuracy: 0.7351 - val_loss: 0.7520 - val_accuracy: 0.8564\n",
      "Epoch 60/100\n",
      "453/453 [==============================] - 0s 130us/step - loss: 1.9196 - accuracy: 0.7174 - val_loss: 0.7642 - val_accuracy: 0.8667\n",
      "Epoch 61/100\n",
      "453/453 [==============================] - 0s 138us/step - loss: 1.8954 - accuracy: 0.7770 - val_loss: 0.7262 - val_accuracy: 0.8769\n",
      "Epoch 62/100\n",
      "453/453 [==============================] - 0s 148us/step - loss: 2.0452 - accuracy: 0.7351 - val_loss: 0.7382 - val_accuracy: 0.8564\n",
      "Epoch 63/100\n",
      "453/453 [==============================] - 0s 138us/step - loss: 2.0040 - accuracy: 0.7572 - val_loss: 0.7201 - val_accuracy: 0.9077\n",
      "Epoch 64/100\n",
      "453/453 [==============================] - 0s 171us/step - loss: 2.1315 - accuracy: 0.7263 - val_loss: 0.7153 - val_accuracy: 0.8821\n",
      "Epoch 65/100\n",
      "453/453 [==============================] - 0s 190us/step - loss: 2.0467 - accuracy: 0.7351 - val_loss: 0.7361 - val_accuracy: 0.8821\n",
      "Epoch 66/100\n",
      "453/453 [==============================] - 0s 126us/step - loss: 1.9433 - accuracy: 0.7174 - val_loss: 0.7593 - val_accuracy: 0.8718\n",
      "Epoch 67/100\n",
      "453/453 [==============================] - 0s 132us/step - loss: 1.9457 - accuracy: 0.7461 - val_loss: 0.7727 - val_accuracy: 0.8769\n",
      "Epoch 68/100\n",
      "453/453 [==============================] - 0s 99us/step - loss: 1.9858 - accuracy: 0.7241 - val_loss: 0.7819 - val_accuracy: 0.8718\n",
      "Epoch 69/100\n",
      "453/453 [==============================] - 0s 128us/step - loss: 2.0398 - accuracy: 0.7285 - val_loss: 0.7687 - val_accuracy: 0.8718\n",
      "Epoch 70/100\n",
      "453/453 [==============================] - 0s 217us/step - loss: 2.2239 - accuracy: 0.7152 - val_loss: 0.7557 - val_accuracy: 0.8615\n",
      "Epoch 71/100\n",
      "453/453 [==============================] - 0s 110us/step - loss: 1.8458 - accuracy: 0.7660 - val_loss: 0.7862 - val_accuracy: 0.8513\n",
      "Epoch 72/100\n",
      "453/453 [==============================] - 0s 76us/step - loss: 1.7421 - accuracy: 0.7704 - val_loss: 0.8221 - val_accuracy: 0.8923\n",
      "Epoch 73/100\n",
      "453/453 [==============================] - 0s 77us/step - loss: 1.7656 - accuracy: 0.7373 - val_loss: 0.7655 - val_accuracy: 0.8821\n",
      "Epoch 74/100\n",
      "453/453 [==============================] - 0s 72us/step - loss: 1.7822 - accuracy: 0.7395 - val_loss: 0.7280 - val_accuracy: 0.8769\n",
      "Epoch 75/100\n",
      "453/453 [==============================] - 0s 72us/step - loss: 1.8570 - accuracy: 0.7439 - val_loss: 0.7171 - val_accuracy: 0.8718\n",
      "Epoch 76/100\n",
      "453/453 [==============================] - 0s 87us/step - loss: 2.1604 - accuracy: 0.6954 - val_loss: 0.7659 - val_accuracy: 0.8769\n",
      "Epoch 77/100\n",
      "453/453 [==============================] - 0s 75us/step - loss: 1.9674 - accuracy: 0.7373 - val_loss: 0.7475 - val_accuracy: 0.8769\n",
      "Epoch 78/100\n",
      "453/453 [==============================] - 0s 187us/step - loss: 2.1164 - accuracy: 0.7152 - val_loss: 0.7825 - val_accuracy: 0.8667\n",
      "Epoch 79/100\n",
      "453/453 [==============================] - 0s 209us/step - loss: 2.0325 - accuracy: 0.7196 - val_loss: 0.7976 - val_accuracy: 0.8615\n",
      "Epoch 80/100\n",
      "453/453 [==============================] - 0s 215us/step - loss: 1.6868 - accuracy: 0.7439 - val_loss: 0.7604 - val_accuracy: 0.8615\n",
      "Epoch 81/100\n",
      "453/453 [==============================] - 0s 212us/step - loss: 1.8281 - accuracy: 0.7307 - val_loss: 0.7459 - val_accuracy: 0.8718\n",
      "Epoch 82/100\n",
      "453/453 [==============================] - 0s 126us/step - loss: 1.9640 - accuracy: 0.7439 - val_loss: 0.7421 - val_accuracy: 0.8923\n",
      "Epoch 83/100\n",
      "453/453 [==============================] - 0s 138us/step - loss: 2.0820 - accuracy: 0.7219 - val_loss: 0.7296 - val_accuracy: 0.8872\n",
      "Epoch 84/100\n",
      "453/453 [==============================] - 0s 120us/step - loss: 1.9353 - accuracy: 0.7439 - val_loss: 0.7400 - val_accuracy: 0.8923\n",
      "Epoch 85/100\n",
      "453/453 [==============================] - 0s 103us/step - loss: 1.5954 - accuracy: 0.7483 - val_loss: 0.7125 - val_accuracy: 0.8974\n",
      "Epoch 86/100\n",
      "453/453 [==============================] - 0s 98us/step - loss: 1.8848 - accuracy: 0.7417 - val_loss: 0.7348 - val_accuracy: 0.8974\n",
      "Epoch 87/100\n",
      "453/453 [==============================] - 0s 74us/step - loss: 1.9326 - accuracy: 0.7506 - val_loss: 0.7496 - val_accuracy: 0.8769\n",
      "Epoch 88/100\n",
      "453/453 [==============================] - 0s 74us/step - loss: 1.8089 - accuracy: 0.7572 - val_loss: 0.7250 - val_accuracy: 0.8974\n",
      "Epoch 89/100\n",
      "453/453 [==============================] - 0s 71us/step - loss: 2.1051 - accuracy: 0.7152 - val_loss: 0.7455 - val_accuracy: 0.8667\n",
      "Epoch 90/100\n",
      "453/453 [==============================] - 0s 73us/step - loss: 1.5064 - accuracy: 0.7704 - val_loss: 0.7134 - val_accuracy: 0.8923\n",
      "Epoch 91/100\n",
      "453/453 [==============================] - 0s 82us/step - loss: 1.6147 - accuracy: 0.7506 - val_loss: 0.7225 - val_accuracy: 0.8718\n",
      "Epoch 92/100\n",
      "453/453 [==============================] - 0s 68us/step - loss: 1.8796 - accuracy: 0.7263 - val_loss: 0.7206 - val_accuracy: 0.8872\n",
      "Epoch 93/100\n",
      "453/453 [==============================] - 0s 77us/step - loss: 1.7925 - accuracy: 0.7550 - val_loss: 0.7314 - val_accuracy: 0.8821\n",
      "Epoch 94/100\n",
      "453/453 [==============================] - 0s 72us/step - loss: 1.7441 - accuracy: 0.7550 - val_loss: 0.7257 - val_accuracy: 0.8923\n",
      "Epoch 95/100\n",
      "453/453 [==============================] - 0s 131us/step - loss: 1.8507 - accuracy: 0.7461 - val_loss: 0.7446 - val_accuracy: 0.9026\n",
      "Epoch 96/100\n",
      "453/453 [==============================] - 0s 93us/step - loss: 1.9799 - accuracy: 0.7506 - val_loss: 0.7630 - val_accuracy: 0.8769\n",
      "Epoch 97/100\n",
      "453/453 [==============================] - 0s 106us/step - loss: 1.6272 - accuracy: 0.7770 - val_loss: 0.7452 - val_accuracy: 0.8872\n",
      "Epoch 98/100\n",
      "453/453 [==============================] - 0s 92us/step - loss: 1.8054 - accuracy: 0.7660 - val_loss: 0.7919 - val_accuracy: 0.9026\n",
      "Epoch 99/100\n",
      "453/453 [==============================] - 0s 83us/step - loss: 1.5134 - accuracy: 0.7594 - val_loss: 0.7435 - val_accuracy: 0.8718\n",
      "Epoch 100/100\n",
      "453/453 [==============================] - 0s 78us/step - loss: 1.6188 - accuracy: 0.7726 - val_loss: 0.7289 - val_accuracy: 0.9026\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a36432dd8>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over6.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195/195 [==============================] - 0s 70us/step\n",
      "over-sampling test accuracy: 90.26%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over6 = model1_over6.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over6*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 2, 0, 2, 0, 0, 1, 1, 2, 1, 2, 0, 0, 0, 2, 2, 2, 0, 2, 1,\n",
       "       0, 1, 1, 0, 0, 1, 2, 1, 2, 0, 2, 2, 1, 2, 2, 2, 0, 2, 1, 0, 1, 1,\n",
       "       2, 2, 2, 1, 1, 0, 1, 2, 0, 1, 1, 0, 1, 1, 2, 0, 2, 1, 1, 0, 0, 1,\n",
       "       1, 2, 2, 1, 0, 2, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 2, 0, 0, 0, 1, 0,\n",
       "       1, 2, 1, 1, 2, 2, 1, 1, 0, 2, 0, 2, 1, 1, 2, 2, 1, 0, 1, 1, 0, 2,\n",
       "       2, 1, 0, 1, 2, 0, 0, 0, 2, 1, 2, 1, 1, 2, 2, 0, 0, 2, 2, 0, 1, 0,\n",
       "       1, 1, 1, 2, 1, 2, 1, 0, 2, 0, 2, 0, 2, 1, 2, 1, 0, 2, 0, 2, 2, 2,\n",
       "       2, 2, 1, 0, 2, 1, 0, 0, 0, 1, 2, 1, 0, 0, 1, 0, 1, 2, 0, 0, 1, 1,\n",
       "       0, 2, 2, 2, 1, 0, 2, 1, 1, 2, 2, 1, 2, 1, 0, 1, 1, 0, 2])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred6 = model1_over6.predict_classes(X_test_over)\n",
    "pred6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CFBREBSa119</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS074</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GA231</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>NRS252</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>SR2852</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>NRS108</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>NRS202</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>NRS110</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test  pred\n",
       "0    CFBREBSa119     0     0\n",
       "1         NRS001     1     1\n",
       "2         NRS074     0     0\n",
       "3         NRS209     2     2\n",
       "4          GA231     0     0\n",
       "..           ...   ...   ...\n",
       "190       NRS252     0     0\n",
       "191       SR2852     1     1\n",
       "192       NRS108     1     1\n",
       "193       NRS202     0     0\n",
       "194       NRS110     2     2\n",
       "\n",
       "[195 rows x 3 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat6['pred'] = pred6\n",
    "dat6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba6 = model1_over6.predict_proba(X_test_over)\n",
    "dat_proba6 = pd.DataFrame(proba6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.547507e-01</td>\n",
       "      <td>4.449964e-01</td>\n",
       "      <td>2.528183e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.769752e-01</td>\n",
       "      <td>8.229654e-01</td>\n",
       "      <td>5.931539e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.297128e-08</td>\n",
       "      <td>2.716962e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.973688e-08</td>\n",
       "      <td>5.079579e-08</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.744864e-01</td>\n",
       "      <td>4.255115e-01</td>\n",
       "      <td>2.071251e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>7.873229e-01</td>\n",
       "      <td>2.126577e-01</td>\n",
       "      <td>1.932460e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>1.636022e-04</td>\n",
       "      <td>9.998363e-01</td>\n",
       "      <td>1.226338e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>2.683811e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.172592e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>7.581264e-01</td>\n",
       "      <td>2.402929e-01</td>\n",
       "      <td>1.580697e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>7.674407e-08</td>\n",
       "      <td>7.789480e-08</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0             1             2\n",
       "0    5.547507e-01  4.449964e-01  2.528183e-04\n",
       "1    1.769752e-01  8.229654e-01  5.931539e-05\n",
       "2    1.000000e+00  1.297128e-08  2.716962e-10\n",
       "3    5.973688e-08  5.079579e-08  9.999999e-01\n",
       "4    5.744864e-01  4.255115e-01  2.071251e-06\n",
       "..            ...           ...           ...\n",
       "190  7.873229e-01  2.126577e-01  1.932460e-05\n",
       "191  1.636022e-04  9.998363e-01  1.226338e-09\n",
       "192  2.683811e-08  1.000000e+00  4.172592e-11\n",
       "193  7.581264e-01  2.402929e-01  1.580697e-03\n",
       "194  7.674407e-08  7.789480e-08  9.999999e-01\n",
       "\n",
       "[195 rows x 3 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba6.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba6.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat6.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/6p17spST.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 453 samples, validate on 195 samples\n",
      "Epoch 1/100\n",
      "453/453 [==============================] - 0s 221us/step - loss: 1.9247 - accuracy: 0.7241 - val_loss: 0.7858 - val_accuracy: 0.8667\n",
      "Epoch 2/100\n",
      "453/453 [==============================] - 0s 142us/step - loss: 1.8978 - accuracy: 0.7528 - val_loss: 0.7794 - val_accuracy: 0.8667\n",
      "Epoch 3/100\n",
      "453/453 [==============================] - 0s 121us/step - loss: 1.6541 - accuracy: 0.7572 - val_loss: 0.7422 - val_accuracy: 0.8769\n",
      "Epoch 4/100\n",
      "453/453 [==============================] - 0s 136us/step - loss: 1.7294 - accuracy: 0.7550 - val_loss: 0.7210 - val_accuracy: 0.8769\n",
      "Epoch 5/100\n",
      "453/453 [==============================] - 0s 160us/step - loss: 1.8397 - accuracy: 0.7770 - val_loss: 0.7604 - val_accuracy: 0.8718\n",
      "Epoch 6/100\n",
      "453/453 [==============================] - 0s 128us/step - loss: 1.8789 - accuracy: 0.6976 - val_loss: 0.7550 - val_accuracy: 0.8821\n",
      "Epoch 7/100\n",
      "453/453 [==============================] - 0s 144us/step - loss: 1.5993 - accuracy: 0.7881 - val_loss: 0.7676 - val_accuracy: 0.8821\n",
      "Epoch 8/100\n",
      "453/453 [==============================] - 0s 168us/step - loss: 1.6748 - accuracy: 0.7506 - val_loss: 0.6981 - val_accuracy: 0.8923\n",
      "Epoch 9/100\n",
      "453/453 [==============================] - 0s 168us/step - loss: 1.5593 - accuracy: 0.7439 - val_loss: 0.6848 - val_accuracy: 0.8923\n",
      "Epoch 10/100\n",
      "453/453 [==============================] - 0s 183us/step - loss: 1.6129 - accuracy: 0.7528 - val_loss: 0.7245 - val_accuracy: 0.8923\n",
      "Epoch 11/100\n",
      "453/453 [==============================] - 0s 191us/step - loss: 1.6558 - accuracy: 0.7815 - val_loss: 0.6927 - val_accuracy: 0.8718\n",
      "Epoch 12/100\n",
      "453/453 [==============================] - 0s 168us/step - loss: 1.6730 - accuracy: 0.7461 - val_loss: 0.7224 - val_accuracy: 0.8615\n",
      "Epoch 13/100\n",
      "453/453 [==============================] - 0s 182us/step - loss: 1.7318 - accuracy: 0.7307 - val_loss: 0.9950 - val_accuracy: 0.8718\n",
      "Epoch 14/100\n",
      "453/453 [==============================] - 0s 210us/step - loss: 2.0164 - accuracy: 0.7461 - val_loss: 0.7465 - val_accuracy: 0.8615\n",
      "Epoch 15/100\n",
      "453/453 [==============================] - 0s 130us/step - loss: 1.6896 - accuracy: 0.7373 - val_loss: 0.7335 - val_accuracy: 0.8564\n",
      "Epoch 16/100\n",
      "453/453 [==============================] - 0s 133us/step - loss: 1.5158 - accuracy: 0.7660 - val_loss: 0.7098 - val_accuracy: 0.8718\n",
      "Epoch 17/100\n",
      "453/453 [==============================] - 0s 261us/step - loss: 1.7860 - accuracy: 0.7196 - val_loss: 0.7204 - val_accuracy: 0.8821\n",
      "Epoch 18/100\n",
      "453/453 [==============================] - 0s 278us/step - loss: 1.5778 - accuracy: 0.7439 - val_loss: 0.6980 - val_accuracy: 0.8872\n",
      "Epoch 19/100\n",
      "453/453 [==============================] - 0s 166us/step - loss: 1.7326 - accuracy: 0.7506 - val_loss: 0.7036 - val_accuracy: 0.8974\n",
      "Epoch 20/100\n",
      "453/453 [==============================] - 0s 278us/step - loss: 1.6862 - accuracy: 0.7704 - val_loss: 0.7364 - val_accuracy: 0.8923\n",
      "Epoch 21/100\n",
      "453/453 [==============================] - 0s 202us/step - loss: 1.9303 - accuracy: 0.7373 - val_loss: 0.8693 - val_accuracy: 0.8564\n",
      "Epoch 22/100\n",
      "453/453 [==============================] - 0s 540us/step - loss: 1.8767 - accuracy: 0.7439 - val_loss: 0.8643 - val_accuracy: 0.8821\n",
      "Epoch 23/100\n",
      "453/453 [==============================] - 0s 190us/step - loss: 1.8216 - accuracy: 0.7550 - val_loss: 0.7253 - val_accuracy: 0.8872\n",
      "Epoch 24/100\n",
      "453/453 [==============================] - 0s 277us/step - loss: 1.7044 - accuracy: 0.7307 - val_loss: 0.8208 - val_accuracy: 0.8667\n",
      "Epoch 25/100\n",
      "453/453 [==============================] - 0s 222us/step - loss: 1.7489 - accuracy: 0.7528 - val_loss: 0.9357 - val_accuracy: 0.8564\n",
      "Epoch 26/100\n",
      "453/453 [==============================] - 0s 182us/step - loss: 1.3528 - accuracy: 0.7660 - val_loss: 0.6669 - val_accuracy: 0.8872\n",
      "Epoch 27/100\n",
      "453/453 [==============================] - 0s 506us/step - loss: 1.7819 - accuracy: 0.7417 - val_loss: 0.6782 - val_accuracy: 0.8923\n",
      "Epoch 28/100\n",
      "453/453 [==============================] - 0s 345us/step - loss: 1.7025 - accuracy: 0.7726 - val_loss: 0.6951 - val_accuracy: 0.8769\n",
      "Epoch 29/100\n",
      "453/453 [==============================] - 0s 228us/step - loss: 1.6798 - accuracy: 0.7329 - val_loss: 0.6653 - val_accuracy: 0.8821\n",
      "Epoch 30/100\n",
      "453/453 [==============================] - 0s 152us/step - loss: 1.5162 - accuracy: 0.7528 - val_loss: 0.6708 - val_accuracy: 0.8923\n",
      "Epoch 31/100\n",
      "453/453 [==============================] - 0s 170us/step - loss: 1.6800 - accuracy: 0.7461 - val_loss: 0.6795 - val_accuracy: 0.9077\n",
      "Epoch 32/100\n",
      "453/453 [==============================] - 0s 122us/step - loss: 1.4394 - accuracy: 0.7660 - val_loss: 0.7001 - val_accuracy: 0.9026\n",
      "Epoch 33/100\n",
      "453/453 [==============================] - 0s 127us/step - loss: 1.4674 - accuracy: 0.8057 - val_loss: 0.6792 - val_accuracy: 0.8923\n",
      "Epoch 34/100\n",
      "453/453 [==============================] - 0s 140us/step - loss: 1.6115 - accuracy: 0.7638 - val_loss: 0.6759 - val_accuracy: 0.8769\n",
      "Epoch 35/100\n",
      "453/453 [==============================] - 0s 144us/step - loss: 1.4384 - accuracy: 0.7837 - val_loss: 0.6979 - val_accuracy: 0.8667\n",
      "Epoch 36/100\n",
      "453/453 [==============================] - 0s 453us/step - loss: 1.4481 - accuracy: 0.7859 - val_loss: 0.6822 - val_accuracy: 0.8872\n",
      "Epoch 37/100\n",
      "453/453 [==============================] - 0s 464us/step - loss: 1.5248 - accuracy: 0.7792 - val_loss: 0.7693 - val_accuracy: 0.8872\n",
      "Epoch 38/100\n",
      "453/453 [==============================] - 0s 487us/step - loss: 1.5583 - accuracy: 0.7594 - val_loss: 0.6128 - val_accuracy: 0.9026\n",
      "Epoch 39/100\n",
      "453/453 [==============================] - 0s 159us/step - loss: 1.8078 - accuracy: 0.7594 - val_loss: 0.5893 - val_accuracy: 0.8821\n",
      "Epoch 40/100\n",
      "453/453 [==============================] - 0s 217us/step - loss: 1.3468 - accuracy: 0.7748 - val_loss: 0.6033 - val_accuracy: 0.8923\n",
      "Epoch 41/100\n",
      "453/453 [==============================] - 0s 222us/step - loss: 1.6510 - accuracy: 0.7616 - val_loss: 0.7025 - val_accuracy: 0.9026\n",
      "Epoch 42/100\n",
      "453/453 [==============================] - 0s 185us/step - loss: 1.5563 - accuracy: 0.7307 - val_loss: 0.7458 - val_accuracy: 0.8667\n",
      "Epoch 43/100\n",
      "453/453 [==============================] - 0s 131us/step - loss: 1.4605 - accuracy: 0.7660 - val_loss: 0.7203 - val_accuracy: 0.8923\n",
      "Epoch 44/100\n",
      "453/453 [==============================] - 0s 163us/step - loss: 1.3701 - accuracy: 0.7881 - val_loss: 0.6612 - val_accuracy: 0.8923\n",
      "Epoch 45/100\n",
      "453/453 [==============================] - 0s 126us/step - loss: 1.7084 - accuracy: 0.7616 - val_loss: 0.6645 - val_accuracy: 0.8872\n",
      "Epoch 46/100\n",
      "453/453 [==============================] - 0s 218us/step - loss: 1.5909 - accuracy: 0.7417 - val_loss: 0.8229 - val_accuracy: 0.8821\n",
      "Epoch 47/100\n",
      "453/453 [==============================] - 0s 218us/step - loss: 1.6842 - accuracy: 0.7528 - val_loss: 1.0223 - val_accuracy: 0.8667\n",
      "Epoch 48/100\n",
      "453/453 [==============================] - 0s 151us/step - loss: 1.5158 - accuracy: 0.7528 - val_loss: 0.8196 - val_accuracy: 0.8821\n",
      "Epoch 49/100\n",
      "453/453 [==============================] - 0s 122us/step - loss: 1.6187 - accuracy: 0.7726 - val_loss: 0.9409 - val_accuracy: 0.8718\n",
      "Epoch 50/100\n",
      "453/453 [==============================] - 0s 161us/step - loss: 1.7519 - accuracy: 0.7219 - val_loss: 0.8789 - val_accuracy: 0.8872\n",
      "Epoch 51/100\n",
      "453/453 [==============================] - 0s 140us/step - loss: 1.5706 - accuracy: 0.7528 - val_loss: 0.8374 - val_accuracy: 0.8872\n",
      "Epoch 52/100\n",
      "453/453 [==============================] - 0s 149us/step - loss: 1.6999 - accuracy: 0.7506 - val_loss: 1.0124 - val_accuracy: 0.8462\n",
      "Epoch 53/100\n",
      "453/453 [==============================] - 0s 122us/step - loss: 1.6433 - accuracy: 0.7417 - val_loss: 0.9504 - val_accuracy: 0.8667\n",
      "Epoch 54/100\n",
      "453/453 [==============================] - 0s 179us/step - loss: 1.4948 - accuracy: 0.7859 - val_loss: 0.7522 - val_accuracy: 0.8769\n",
      "Epoch 55/100\n",
      "453/453 [==============================] - 0s 248us/step - loss: 1.4496 - accuracy: 0.7417 - val_loss: 0.7729 - val_accuracy: 0.8923\n",
      "Epoch 56/100\n",
      "453/453 [==============================] - 0s 169us/step - loss: 1.6757 - accuracy: 0.7417 - val_loss: 0.8736 - val_accuracy: 0.8769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "453/453 [==============================] - 0s 163us/step - loss: 1.3797 - accuracy: 0.7815 - val_loss: 0.8279 - val_accuracy: 0.8872\n",
      "Epoch 58/100\n",
      "453/453 [==============================] - 0s 173us/step - loss: 1.7186 - accuracy: 0.7726 - val_loss: 0.7775 - val_accuracy: 0.8974\n",
      "Epoch 59/100\n",
      "453/453 [==============================] - 0s 143us/step - loss: 1.6284 - accuracy: 0.7373 - val_loss: 0.7934 - val_accuracy: 0.8821\n",
      "Epoch 60/100\n",
      "453/453 [==============================] - 0s 140us/step - loss: 1.5067 - accuracy: 0.7660 - val_loss: 0.8021 - val_accuracy: 0.8974\n",
      "Epoch 61/100\n",
      "453/453 [==============================] - 0s 149us/step - loss: 1.4870 - accuracy: 0.7726 - val_loss: 0.8677 - val_accuracy: 0.9077\n",
      "Epoch 62/100\n",
      "453/453 [==============================] - 0s 158us/step - loss: 1.3330 - accuracy: 0.7859 - val_loss: 0.8025 - val_accuracy: 0.8923\n",
      "Epoch 63/100\n",
      "453/453 [==============================] - 0s 128us/step - loss: 1.4671 - accuracy: 0.7770 - val_loss: 0.8261 - val_accuracy: 0.8821\n",
      "Epoch 64/100\n",
      "453/453 [==============================] - 0s 141us/step - loss: 1.3865 - accuracy: 0.7461 - val_loss: 0.7561 - val_accuracy: 0.8923\n",
      "Epoch 65/100\n",
      "453/453 [==============================] - 0s 243us/step - loss: 1.5130 - accuracy: 0.7748 - val_loss: 0.7298 - val_accuracy: 0.8974\n",
      "Epoch 66/100\n",
      "453/453 [==============================] - 0s 137us/step - loss: 1.1697 - accuracy: 0.7991 - val_loss: 0.6928 - val_accuracy: 0.8974\n",
      "Epoch 67/100\n",
      "453/453 [==============================] - 0s 165us/step - loss: 1.4873 - accuracy: 0.7528 - val_loss: 0.6979 - val_accuracy: 0.8769\n",
      "Epoch 68/100\n",
      "453/453 [==============================] - 0s 126us/step - loss: 1.6884 - accuracy: 0.7307 - val_loss: 0.7547 - val_accuracy: 0.8872\n",
      "Epoch 69/100\n",
      "453/453 [==============================] - 0s 156us/step - loss: 1.5076 - accuracy: 0.7682 - val_loss: 0.6636 - val_accuracy: 0.8821\n",
      "Epoch 70/100\n",
      "453/453 [==============================] - 0s 159us/step - loss: 1.4839 - accuracy: 0.7329 - val_loss: 0.6868 - val_accuracy: 0.8872\n",
      "Epoch 71/100\n",
      "453/453 [==============================] - 0s 122us/step - loss: 1.5037 - accuracy: 0.7815 - val_loss: 0.7511 - val_accuracy: 0.8872\n",
      "Epoch 72/100\n",
      "453/453 [==============================] - 0s 286us/step - loss: 1.5263 - accuracy: 0.7329 - val_loss: 0.8302 - val_accuracy: 0.8821\n",
      "Epoch 73/100\n",
      "453/453 [==============================] - 0s 250us/step - loss: 1.4985 - accuracy: 0.7792 - val_loss: 0.7918 - val_accuracy: 0.8769\n",
      "Epoch 74/100\n",
      "453/453 [==============================] - 0s 294us/step - loss: 1.4508 - accuracy: 0.7616 - val_loss: 0.7178 - val_accuracy: 0.9026\n",
      "Epoch 75/100\n",
      "453/453 [==============================] - 0s 136us/step - loss: 1.3035 - accuracy: 0.7770 - val_loss: 0.8161 - val_accuracy: 0.8769\n",
      "Epoch 76/100\n",
      "453/453 [==============================] - 0s 121us/step - loss: 1.3479 - accuracy: 0.7726 - val_loss: 0.6799 - val_accuracy: 0.9077\n",
      "Epoch 77/100\n",
      "453/453 [==============================] - 0s 161us/step - loss: 1.4355 - accuracy: 0.7616 - val_loss: 0.7405 - val_accuracy: 0.8974\n",
      "Epoch 78/100\n",
      "453/453 [==============================] - 0s 129us/step - loss: 1.2812 - accuracy: 0.7726 - val_loss: 0.7785 - val_accuracy: 0.8718\n",
      "Epoch 79/100\n",
      "453/453 [==============================] - 0s 206us/step - loss: 1.3589 - accuracy: 0.7682 - val_loss: 0.7013 - val_accuracy: 0.8769\n",
      "Epoch 80/100\n",
      "453/453 [==============================] - 0s 145us/step - loss: 1.4314 - accuracy: 0.7704 - val_loss: 0.6869 - val_accuracy: 0.8923\n",
      "Epoch 81/100\n",
      "453/453 [==============================] - 0s 183us/step - loss: 1.3065 - accuracy: 0.7881 - val_loss: 0.7757 - val_accuracy: 0.8718\n",
      "Epoch 82/100\n",
      "453/453 [==============================] - 0s 116us/step - loss: 1.2959 - accuracy: 0.7704 - val_loss: 0.7145 - val_accuracy: 0.8821\n",
      "Epoch 83/100\n",
      "453/453 [==============================] - 0s 111us/step - loss: 1.2836 - accuracy: 0.7660 - val_loss: 0.6911 - val_accuracy: 0.9231\n",
      "Epoch 84/100\n",
      "453/453 [==============================] - 0s 161us/step - loss: 1.3368 - accuracy: 0.7439 - val_loss: 0.7690 - val_accuracy: 0.8821\n",
      "Epoch 85/100\n",
      "453/453 [==============================] - 0s 190us/step - loss: 1.2121 - accuracy: 0.7616 - val_loss: 0.6561 - val_accuracy: 0.9128\n",
      "Epoch 86/100\n",
      "453/453 [==============================] - 0s 154us/step - loss: 1.2841 - accuracy: 0.7726 - val_loss: 0.6612 - val_accuracy: 0.9026\n",
      "Epoch 87/100\n",
      "453/453 [==============================] - 0s 146us/step - loss: 1.3351 - accuracy: 0.7572 - val_loss: 0.6591 - val_accuracy: 0.9026\n",
      "Epoch 88/100\n",
      "453/453 [==============================] - 0s 179us/step - loss: 1.0346 - accuracy: 0.8013 - val_loss: 0.6237 - val_accuracy: 0.9026\n",
      "Epoch 89/100\n",
      "453/453 [==============================] - 0s 134us/step - loss: 1.0345 - accuracy: 0.7947 - val_loss: 0.6401 - val_accuracy: 0.9026\n",
      "Epoch 90/100\n",
      "453/453 [==============================] - 0s 121us/step - loss: 1.2690 - accuracy: 0.7660 - val_loss: 0.6079 - val_accuracy: 0.9179\n",
      "Epoch 91/100\n",
      "453/453 [==============================] - 0s 141us/step - loss: 1.3253 - accuracy: 0.7506 - val_loss: 0.5917 - val_accuracy: 0.9077\n",
      "Epoch 92/100\n",
      "453/453 [==============================] - 0s 221us/step - loss: 1.4184 - accuracy: 0.7770 - val_loss: 0.6261 - val_accuracy: 0.8923\n",
      "Epoch 93/100\n",
      "453/453 [==============================] - 0s 275us/step - loss: 1.3900 - accuracy: 0.7439 - val_loss: 0.6701 - val_accuracy: 0.8923\n",
      "Epoch 94/100\n",
      "453/453 [==============================] - 0s 426us/step - loss: 1.2119 - accuracy: 0.7881 - val_loss: 0.7732 - val_accuracy: 0.9026\n",
      "Epoch 95/100\n",
      "453/453 [==============================] - 0s 272us/step - loss: 1.2664 - accuracy: 0.7837 - val_loss: 0.7209 - val_accuracy: 0.9179\n",
      "Epoch 96/100\n",
      "453/453 [==============================] - 0s 238us/step - loss: 1.0309 - accuracy: 0.7815 - val_loss: 0.6563 - val_accuracy: 0.9026\n",
      "Epoch 97/100\n",
      "453/453 [==============================] - 0s 163us/step - loss: 1.3039 - accuracy: 0.7682 - val_loss: 0.6348 - val_accuracy: 0.9077\n",
      "Epoch 98/100\n",
      "453/453 [==============================] - 0s 628us/step - loss: 1.2854 - accuracy: 0.7837 - val_loss: 0.6065 - val_accuracy: 0.9179\n",
      "Epoch 99/100\n",
      "453/453 [==============================] - 0s 727us/step - loss: 1.2917 - accuracy: 0.7748 - val_loss: 0.5902 - val_accuracy: 0.9231\n",
      "Epoch 100/100\n",
      "453/453 [==============================] - 0s 228us/step - loss: 1.0755 - accuracy: 0.7925 - val_loss: 0.5967 - val_accuracy: 0.9077\n"
     ]
    }
   ],
   "source": [
    "hist1_over6 = model1_over6.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 76.11%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over6.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba6 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_regularizor_dropout_2.xlsx\",\n",
    "                        sheet_name=1,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.790400e-08</td>\n",
       "      <td>4.141849e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS386</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.739934e-04</td>\n",
       "      <td>9.994259e-01</td>\n",
       "      <td>6.773014e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5.286934e-09</td>\n",
       "      <td>1.269109e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS178</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.494936e-12</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.537080e-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS237</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.701098e-02</td>\n",
       "      <td>9.399204e-01</td>\n",
       "      <td>3.068583e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.999607e-01</td>\n",
       "      <td>3.367024e-05</td>\n",
       "      <td>5.776848e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS112</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.275442e-08</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>3.739556e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS064</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.168245e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.603962e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>BCH-SA-04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.026408e-15</td>\n",
       "      <td>1.630406e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.120633e-08</td>\n",
       "      <td>1.998346e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1982 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       phage     strain  phenotype  prediction             0  \\\n",
       "0     p002ykpresabsSTCC_qual     NRS209          2           2  1.790400e-08   \n",
       "1     p002ykpresabsSTCC_qual     NRS386          1           1  5.739934e-04   \n",
       "2     p002ykpresabsSTCC_qual     NRS148          2           2  5.286934e-09   \n",
       "3     p002ykpresabsSTCC_qual     NRS178          0           1  6.494936e-12   \n",
       "4     p002ykpresabsSTCC_qual     NRS237          0           1  5.701098e-02   \n",
       "...                      ...        ...        ...         ...           ...   \n",
       "1977     pyopresabsSTCC_qual     NRS272          0           0  9.999607e-01   \n",
       "1978     pyopresabsSTCC_qual     NRS112          1           1  8.275442e-08   \n",
       "1979     pyopresabsSTCC_qual     NRS064          1           1  2.168245e-08   \n",
       "1980     pyopresabsSTCC_qual  BCH-SA-04          0           0  1.000000e+00   \n",
       "1981     pyopresabsSTCC_qual     NRS148          2           2  2.120633e-08   \n",
       "\n",
       "                 1             2  \n",
       "0     4.141849e-08  1.000000e+00  \n",
       "1     9.994259e-01  6.773014e-08  \n",
       "2     1.269109e-08  1.000000e+00  \n",
       "3     1.000000e+00  2.537080e-25  \n",
       "4     9.399204e-01  3.068583e-03  \n",
       "...            ...           ...  \n",
       "1977  3.367024e-05  5.776848e-06  \n",
       "1978  9.999999e-01  3.739556e-09  \n",
       "1979  1.000000e+00  9.603962e-09  \n",
       "1980  1.026408e-15  1.630406e-14  \n",
       "1981  1.998346e-08  1.000000e+00  \n",
       "\n",
       "[1982 rows x 7 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.54750740e-01, 4.44996420e-01, 2.52818300e-04],\n",
       "       [1.76975160e-01, 8.22965440e-01, 5.93153850e-05],\n",
       "       [1.00000000e+00, 1.29712800e-08, 2.71696170e-10],\n",
       "       [5.97368840e-08, 5.07957940e-08, 9.99999900e-01],\n",
       "       [5.74486430e-01, 4.25511540e-01, 2.07125070e-06],\n",
       "       [7.67440700e-08, 7.78947960e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 8.52028300e-09, 1.62860990e-10],\n",
       "       [9.51851100e-01, 4.75664330e-02, 5.82489500e-04],\n",
       "       [9.97858940e-02, 8.97806760e-01, 2.40733520e-03],\n",
       "       [1.49431210e-01, 8.50565850e-01, 2.95004000e-06],\n",
       "       [5.97368840e-08, 5.07957940e-08, 9.99999900e-01],\n",
       "       [3.12902630e-02, 9.68696650e-01, 1.30889200e-05],\n",
       "       [7.67440700e-08, 7.78947960e-08, 9.99999900e-01],\n",
       "       [9.98425960e-01, 1.57388200e-03, 2.47838840e-07],\n",
       "       [9.97186360e-01, 2.81309150e-03, 5.03539070e-07],\n",
       "       [9.86041700e-01, 1.39416065e-02, 1.66439910e-05],\n",
       "       [7.67440700e-08, 7.78947960e-08, 9.99999900e-01],\n",
       "       [5.97368840e-08, 5.07957940e-08, 9.99999900e-01],\n",
       "       [5.97368840e-08, 5.07957940e-08, 9.99999900e-01],\n",
       "       [5.56346200e-01, 4.43652630e-01, 1.23233280e-06],\n",
       "       [7.67440700e-08, 7.78947960e-08, 9.99999900e-01],\n",
       "       [4.21933030e-01, 5.74572300e-01, 3.49455700e-03],\n",
       "       [1.00000000e+00, 5.87893600e-11, 4.88193800e-12],\n",
       "       [9.16696640e-02, 9.08271130e-01, 5.92523300e-05],\n",
       "       [3.87989660e-02, 9.61086150e-01, 1.14876970e-04],\n",
       "       [9.99999760e-01, 2.03406900e-07, 2.76355260e-12],\n",
       "       [1.00000000e+00, 1.92572360e-08, 1.41334320e-09],\n",
       "       [2.21752690e-01, 7.77802770e-01, 4.44642360e-04],\n",
       "       [7.67440700e-08, 7.78947960e-08, 9.99999900e-01],\n",
       "       [1.62244430e-03, 9.98237700e-01, 1.39783170e-04],\n",
       "       [7.67440700e-08, 7.78947960e-08, 9.99999900e-01],\n",
       "       [9.87854400e-01, 1.21445720e-02, 9.16533170e-07],\n",
       "       [5.97368840e-08, 5.07957940e-08, 9.99999900e-01],\n",
       "       [5.97368840e-08, 5.07957940e-08, 9.99999900e-01],\n",
       "       [2.43784830e-05, 9.99975560e-01, 4.44689700e-12],\n",
       "       [5.97368840e-08, 5.07957940e-08, 9.99999900e-01],\n",
       "       [7.67440700e-08, 7.78947960e-08, 9.99999900e-01],\n",
       "       [7.67440700e-08, 7.78947960e-08, 9.99999900e-01],\n",
       "       [9.99984260e-01, 1.57487340e-05, 1.84941840e-08],\n",
       "       [7.67440700e-08, 7.78947960e-08, 9.99999900e-01],\n",
       "       [1.31543140e-02, 9.86845600e-01, 9.11874100e-08],\n",
       "       [9.73123700e-01, 2.67066360e-02, 1.69560300e-04],\n",
       "       [2.68381070e-08, 1.00000000e+00, 4.17259200e-11],\n",
       "       [3.15040160e-02, 9.68295040e-01, 2.00980650e-04],\n",
       "       [5.97368840e-08, 5.07957940e-08, 9.99999900e-01],\n",
       "       [5.97368840e-08, 5.07957940e-08, 9.99999900e-01],\n",
       "       [5.97368840e-08, 5.07957940e-08, 9.99999900e-01],\n",
       "       [4.40512750e-01, 5.59437500e-01, 4.97729600e-05],\n",
       "       [1.31500900e-01, 8.68497970e-01, 1.17206790e-06],\n",
       "       [9.99999900e-01, 1.23867340e-07, 1.25555810e-09],\n",
       "       [8.24829900e-02, 9.17515750e-01, 1.20398180e-06],\n",
       "       [5.97368840e-08, 5.07957940e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 5.26062040e-09, 2.19006520e-12],\n",
       "       [1.14392560e-01, 8.85410100e-01, 1.97407720e-04],\n",
       "       [1.31543140e-02, 9.86845600e-01, 9.11874100e-08],\n",
       "       [9.99998200e-01, 1.81401540e-06, 5.16688400e-10],\n",
       "       [1.13285190e-01, 8.72974460e-01, 1.37403200e-02],\n",
       "       [2.73944640e-02, 9.72570000e-01, 3.54215500e-05],\n",
       "       [7.67440700e-08, 7.78947960e-08, 9.99999900e-01],\n",
       "       [8.55356100e-01, 1.44298210e-01, 3.45625570e-04],\n",
       "       [7.67440700e-08, 7.78947960e-08, 9.99999900e-01],\n",
       "       [9.16696640e-02, 9.08271130e-01, 5.92523300e-05],\n",
       "       [3.96135800e-01, 6.03371140e-01, 4.93037200e-04],\n",
       "       [9.99931450e-01, 6.85097700e-05, 1.81149620e-10],\n",
       "       [1.00000000e+00, 1.34373210e-10, 2.51245170e-11],\n",
       "       [1.14599214e-04, 9.99879240e-01, 6.23283500e-06],\n",
       "       [3.96135800e-01, 6.03371140e-01, 4.93037200e-04],\n",
       "       [7.67440700e-08, 7.78947960e-08, 9.99999900e-01],\n",
       "       [5.97368840e-08, 5.07957940e-08, 9.99999900e-01],\n",
       "       [8.24829900e-02, 9.17515750e-01, 1.20398180e-06],\n",
       "       [9.97870300e-01, 2.11359050e-03, 1.60352160e-05],\n",
       "       [7.67440700e-08, 7.78947960e-08, 9.99999900e-01],\n",
       "       [9.24435600e-01, 7.54324300e-02, 1.31927050e-04],\n",
       "       [2.43784830e-05, 9.99975560e-01, 4.44689700e-12],\n",
       "       [5.62797500e-01, 4.37072300e-01, 1.30134880e-04],\n",
       "       [1.00000000e+00, 8.56698600e-09, 1.56270370e-10],\n",
       "       [9.99984260e-01, 1.57487340e-05, 1.84941840e-08],\n",
       "       [8.24829900e-02, 9.17515750e-01, 1.20398180e-06],\n",
       "       [5.79362000e-04, 9.99420050e-01, 5.92810750e-07],\n",
       "       [1.00000000e+00, 1.95201190e-09, 3.75505560e-11],\n",
       "       [1.49431210e-01, 8.50565850e-01, 2.95004000e-06],\n",
       "       [9.99999900e-01, 7.96295500e-08, 2.26436470e-09],\n",
       "       [5.97368840e-08, 5.07957940e-08, 9.99999900e-01],\n",
       "       [9.50071930e-01, 4.95368950e-02, 3.91236770e-04],\n",
       "       [9.99891300e-01, 1.08667760e-04, 9.94407840e-09],\n",
       "       [9.99999900e-01, 9.17956300e-08, 1.95674490e-10],\n",
       "       [1.31543140e-02, 9.86845600e-01, 9.11874100e-08],\n",
       "       [6.35781000e-01, 3.64213940e-01, 5.08295700e-06],\n",
       "       [9.97858940e-02, 8.97806760e-01, 2.40733520e-03],\n",
       "       [7.67440700e-08, 7.78947960e-08, 9.99999900e-01],\n",
       "       [4.48832300e-02, 9.53425100e-01, 1.69171490e-03],\n",
       "       [7.22548440e-02, 9.27733200e-01, 1.18962580e-05],\n",
       "       [7.67440700e-08, 7.78947960e-08, 9.99999900e-01],\n",
       "       [5.97368840e-08, 5.07957940e-08, 9.99999900e-01],\n",
       "       [9.97858940e-02, 8.97806760e-01, 2.40733520e-03],\n",
       "       [1.67207930e-01, 8.32679800e-01, 1.12291700e-04],\n",
       "       [9.92276000e-01, 7.38787050e-03, 3.36191500e-04],\n",
       "       [5.97368840e-08, 5.07957940e-08, 9.99999900e-01],\n",
       "       [9.95321600e-01, 4.67687800e-03, 1.54384370e-06],\n",
       "       [7.67440700e-08, 7.78947960e-08, 9.99999900e-01],\n",
       "       [7.22548440e-02, 9.27733200e-01, 1.18962580e-05],\n",
       "       [2.01057220e-08, 1.00000000e+00, 7.96886500e-12],\n",
       "       [7.67440700e-08, 7.78947960e-08, 9.99999900e-01],\n",
       "       [7.67440700e-08, 7.78947960e-08, 9.99999900e-01],\n",
       "       [1.76975160e-01, 8.22965440e-01, 5.93153850e-05],\n",
       "       [9.87854400e-01, 1.21445720e-02, 9.16533170e-07],\n",
       "       [9.16696640e-02, 9.08271130e-01, 5.92523300e-05],\n",
       "       [2.13099850e-03, 9.97868300e-01, 7.63455700e-07],\n",
       "       [1.00000000e+00, 6.40617800e-09, 8.64074300e-11],\n",
       "       [7.67440700e-08, 7.78947960e-08, 9.99999900e-01],\n",
       "       [5.97368840e-08, 5.07957940e-08, 9.99999900e-01],\n",
       "       [5.74009100e-03, 9.94223200e-01, 3.66968000e-05],\n",
       "       [9.99999760e-01, 1.86756900e-07, 7.61348500e-10],\n",
       "       [1.62244430e-03, 9.98237700e-01, 1.39783170e-04],\n",
       "       [7.67440700e-08, 7.78947960e-08, 9.99999900e-01],\n",
       "       [9.99981640e-01, 1.83972720e-05, 3.41792270e-08],\n",
       "       [9.99999760e-01, 2.19065510e-07, 1.62017520e-11],\n",
       "       [9.72908100e-01, 2.70891200e-02, 2.80259340e-06],\n",
       "       [7.67440700e-08, 7.78947960e-08, 9.99999900e-01],\n",
       "       [5.74009100e-03, 9.94223200e-01, 3.66968000e-05],\n",
       "       [7.67440700e-08, 7.78947960e-08, 9.99999900e-01],\n",
       "       [4.81326940e-08, 1.00000000e+00, 2.69982020e-11],\n",
       "       [4.83060960e-02, 9.51512900e-01, 1.81072030e-04],\n",
       "       [7.67440700e-08, 7.78947960e-08, 9.99999900e-01],\n",
       "       [5.97368840e-08, 5.07957940e-08, 9.99999900e-01],\n",
       "       [9.20814160e-01, 7.91142900e-02, 7.15924600e-05],\n",
       "       [9.99999400e-01, 5.98107650e-07, 8.45506900e-09],\n",
       "       [7.67440700e-08, 7.78947960e-08, 9.99999900e-01],\n",
       "       [7.67440700e-08, 7.78947960e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 2.29094600e-10, 4.33861700e-12],\n",
       "       [2.13099850e-03, 9.97868300e-01, 7.63455700e-07],\n",
       "       [9.99935150e-01, 6.34322700e-05, 1.43873260e-06],\n",
       "       [4.83060960e-02, 9.51512900e-01, 1.81072030e-04],\n",
       "       [1.62244430e-03, 9.98237700e-01, 1.39783170e-04],\n",
       "       [2.11740360e-01, 7.87733100e-01, 5.26562740e-04],\n",
       "       [7.67440700e-08, 7.78947960e-08, 9.99999900e-01],\n",
       "       [1.38339130e-01, 8.61136100e-01, 5.24755040e-04],\n",
       "       [5.97368840e-08, 5.07957940e-08, 9.99999900e-01],\n",
       "       [2.80234460e-01, 7.19669400e-01, 9.61570260e-05],\n",
       "       [9.99999760e-01, 2.22934160e-07, 3.72952200e-15],\n",
       "       [5.97368840e-08, 5.07957940e-08, 9.99999900e-01],\n",
       "       [7.72471850e-01, 2.27526710e-01, 1.41557900e-06],\n",
       "       [5.97368840e-08, 5.07957940e-08, 9.99999900e-01],\n",
       "       [9.87854400e-01, 1.21445720e-02, 9.16533170e-07],\n",
       "       [5.97368840e-08, 5.07957940e-08, 9.99999900e-01],\n",
       "       [1.74486040e-01, 8.25477400e-01, 3.65252300e-05],\n",
       "       [5.97368840e-08, 5.07957940e-08, 9.99999900e-01],\n",
       "       [2.80234460e-01, 7.19669400e-01, 9.61570260e-05],\n",
       "       [1.00000000e+00, 1.39959340e-11, 6.31952600e-13],\n",
       "       [5.97368840e-08, 5.07957940e-08, 9.99999900e-01],\n",
       "       [5.31141400e-01, 4.68858630e-01, 1.94651730e-08],\n",
       "       [5.97368840e-08, 5.07957940e-08, 9.99999900e-01],\n",
       "       [7.67440700e-08, 7.78947960e-08, 9.99999900e-01],\n",
       "       [5.97368840e-08, 5.07957940e-08, 9.99999900e-01],\n",
       "       [7.67440700e-08, 7.78947960e-08, 9.99999900e-01],\n",
       "       [5.97368840e-08, 5.07957940e-08, 9.99999900e-01],\n",
       "       [1.03627230e-02, 9.89571700e-01, 6.55435600e-05],\n",
       "       [9.99999050e-01, 9.03160070e-07, 4.38990400e-09],\n",
       "       [5.97368840e-08, 5.07957940e-08, 9.99999900e-01],\n",
       "       [3.15040160e-02, 9.68295040e-01, 2.00980650e-04],\n",
       "       [1.00000000e+00, 4.27618080e-11, 1.10525940e-12],\n",
       "       [1.00000000e+00, 8.89043700e-12, 1.36984070e-13],\n",
       "       [1.00000000e+00, 9.42218400e-11, 2.68001330e-13],\n",
       "       [9.29850500e-06, 9.99990600e-01, 8.15887000e-08],\n",
       "       [5.97368840e-08, 5.07957940e-08, 9.99999900e-01],\n",
       "       [7.72238400e-02, 9.22501900e-01, 2.74316640e-04],\n",
       "       [9.99997600e-01, 2.42965440e-06, 1.00353220e-08],\n",
       "       [9.87854400e-01, 1.21445720e-02, 9.16533170e-07],\n",
       "       [9.16696640e-02, 9.08271130e-01, 5.92523300e-05],\n",
       "       [9.76902840e-01, 2.28593090e-02, 2.37799860e-04],\n",
       "       [4.87816240e-01, 5.09680800e-01, 2.50293570e-03],\n",
       "       [7.67440700e-08, 7.78947960e-08, 9.99999900e-01],\n",
       "       [9.99703100e-01, 2.95974050e-04, 8.77955000e-07],\n",
       "       [9.77113600e-01, 2.26251700e-02, 2.61227160e-04],\n",
       "       [4.83060960e-02, 9.51512900e-01, 1.81072030e-04],\n",
       "       [4.81326940e-08, 1.00000000e+00, 2.69982020e-11],\n",
       "       [9.99703100e-01, 2.95974050e-04, 8.77955000e-07],\n",
       "       [7.67440700e-08, 7.78947960e-08, 9.99999900e-01],\n",
       "       [7.67440700e-08, 7.78947960e-08, 9.99999900e-01],\n",
       "       [7.67440700e-08, 7.78947960e-08, 9.99999900e-01],\n",
       "       [5.79362000e-04, 9.99420050e-01, 5.92810750e-07],\n",
       "       [9.77520500e-01, 2.24678800e-02, 1.16098745e-05],\n",
       "       [5.97368840e-08, 5.07957940e-08, 9.99999900e-01],\n",
       "       [4.48832300e-02, 9.53425100e-01, 1.69171490e-03],\n",
       "       [1.76975160e-01, 8.22965440e-01, 5.93153850e-05],\n",
       "       [7.67440700e-08, 7.78947960e-08, 9.99999900e-01],\n",
       "       [5.97368840e-08, 5.07957940e-08, 9.99999900e-01],\n",
       "       [2.21752690e-01, 7.77802770e-01, 4.44642360e-04],\n",
       "       [5.97368840e-08, 5.07957940e-08, 9.99999900e-01],\n",
       "       [1.63602240e-04, 9.99836300e-01, 1.22633800e-09],\n",
       "       [7.87322940e-01, 2.12657700e-01, 1.93245980e-05],\n",
       "       [1.63602240e-04, 9.99836300e-01, 1.22633800e-09],\n",
       "       [2.68381070e-08, 1.00000000e+00, 4.17259200e-11],\n",
       "       [7.58126400e-01, 2.40292940e-01, 1.58069700e-03],\n",
       "       [7.67440700e-08, 7.78947960e-08, 9.99999900e-01]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob6 = df_proba6[df_proba6['phage']=='p0017SpresabsSTCC_qual'].iloc[:,-3:]\n",
    "y_prob6 = y_prob6.to_numpy()\n",
    "y_prob6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9694280078895464"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo6 = rocauc_ovo(y_test_over, y_prob6, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9694280078895464"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr6 = rocauc_ovr(y_test_over, y_prob6, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=789,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat7 = pd.DataFrame(X_test_over[:,0])\n",
    "dat7['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS218</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS260</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS162</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS177</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>NRS383</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>NRS218</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>SR2852</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>NRS248</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0  test\n",
       "0    NRS218     1\n",
       "1    NRS260     1\n",
       "2    NRS162     0\n",
       "3    NRS177     0\n",
       "4    NRS209     2\n",
       "..      ...   ...\n",
       "190  NRS383     1\n",
       "191  NRS218     1\n",
       "192  NRS209     2\n",
       "193  SR2852     1\n",
       "194  NRS248     0\n",
       "\n",
       "[195 rows x 2 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over7 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],), activity_regularizer=l1(0.001)),\n",
    "    Dense(3, activation='softmax'),\n",
    "    Dropout(0.2, ),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over7.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 453 samples, validate on 195 samples\n",
      "Epoch 1/100\n",
      "453/453 [==============================] - 0s 590us/step - loss: 11.7977 - accuracy: 0.3974 - val_loss: 10.8170 - val_accuracy: 0.4410\n",
      "Epoch 2/100\n",
      "453/453 [==============================] - 0s 133us/step - loss: 10.1523 - accuracy: 0.5055 - val_loss: 9.6470 - val_accuracy: 0.4923\n",
      "Epoch 3/100\n",
      "453/453 [==============================] - 0s 91us/step - loss: 9.6769 - accuracy: 0.4879 - val_loss: 8.6653 - val_accuracy: 0.4923\n",
      "Epoch 4/100\n",
      "453/453 [==============================] - 0s 106us/step - loss: 8.1876 - accuracy: 0.5342 - val_loss: 7.8644 - val_accuracy: 0.5333\n",
      "Epoch 5/100\n",
      "453/453 [==============================] - 0s 94us/step - loss: 7.6728 - accuracy: 0.5232 - val_loss: 7.1779 - val_accuracy: 0.5385\n",
      "Epoch 6/100\n",
      "453/453 [==============================] - 0s 153us/step - loss: 7.6673 - accuracy: 0.4923 - val_loss: 6.5479 - val_accuracy: 0.5128\n",
      "Epoch 7/100\n",
      "453/453 [==============================] - 0s 197us/step - loss: 6.7987 - accuracy: 0.5210 - val_loss: 5.9255 - val_accuracy: 0.5282\n",
      "Epoch 8/100\n",
      "453/453 [==============================] - 0s 96us/step - loss: 6.0336 - accuracy: 0.5254 - val_loss: 3.4982 - val_accuracy: 0.5538\n",
      "Epoch 9/100\n",
      "453/453 [==============================] - 0s 121us/step - loss: 4.8069 - accuracy: 0.5673 - val_loss: 2.0813 - val_accuracy: 0.7231\n",
      "Epoch 10/100\n",
      "453/453 [==============================] - 0s 130us/step - loss: 4.4801 - accuracy: 0.6115 - val_loss: 1.5854 - val_accuracy: 0.7385\n",
      "Epoch 11/100\n",
      "453/453 [==============================] - 0s 129us/step - loss: 3.6195 - accuracy: 0.6291 - val_loss: 1.3722 - val_accuracy: 0.6462\n",
      "Epoch 12/100\n",
      "453/453 [==============================] - 0s 87us/step - loss: 3.8850 - accuracy: 0.6291 - val_loss: 1.0394 - val_accuracy: 0.6410\n",
      "Epoch 13/100\n",
      "453/453 [==============================] - 0s 79us/step - loss: 3.6347 - accuracy: 0.6402 - val_loss: 0.9764 - val_accuracy: 0.8205\n",
      "Epoch 14/100\n",
      "453/453 [==============================] - 0s 81us/step - loss: 3.3734 - accuracy: 0.6777 - val_loss: 0.8713 - val_accuracy: 0.6513\n",
      "Epoch 15/100\n",
      "453/453 [==============================] - 0s 76us/step - loss: 3.3231 - accuracy: 0.6115 - val_loss: 0.8871 - val_accuracy: 0.8205\n",
      "Epoch 16/100\n",
      "453/453 [==============================] - 0s 116us/step - loss: 3.6703 - accuracy: 0.6667 - val_loss: 0.8411 - val_accuracy: 0.8154\n",
      "Epoch 17/100\n",
      "453/453 [==============================] - 0s 97us/step - loss: 3.3689 - accuracy: 0.6887 - val_loss: 0.8286 - val_accuracy: 0.8308\n",
      "Epoch 18/100\n",
      "453/453 [==============================] - 0s 124us/step - loss: 3.2188 - accuracy: 0.6865 - val_loss: 0.8382 - val_accuracy: 0.8205\n",
      "Epoch 19/100\n",
      "453/453 [==============================] - 0s 140us/step - loss: 3.4249 - accuracy: 0.6733 - val_loss: 0.8648 - val_accuracy: 0.8308\n",
      "Epoch 20/100\n",
      "453/453 [==============================] - 0s 151us/step - loss: 3.1269 - accuracy: 0.6865 - val_loss: 0.8834 - val_accuracy: 0.8103\n",
      "Epoch 21/100\n",
      "453/453 [==============================] - 0s 110us/step - loss: 3.0548 - accuracy: 0.6976 - val_loss: 0.8439 - val_accuracy: 0.8308\n",
      "Epoch 22/100\n",
      "453/453 [==============================] - 0s 88us/step - loss: 2.7948 - accuracy: 0.7263 - val_loss: 0.8056 - val_accuracy: 0.8256\n",
      "Epoch 23/100\n",
      "453/453 [==============================] - 0s 72us/step - loss: 2.7130 - accuracy: 0.7064 - val_loss: 0.8667 - val_accuracy: 0.8205\n",
      "Epoch 24/100\n",
      "453/453 [==============================] - 0s 91us/step - loss: 2.7628 - accuracy: 0.6887 - val_loss: 0.8766 - val_accuracy: 0.7795\n",
      "Epoch 25/100\n",
      "453/453 [==============================] - 0s 78us/step - loss: 2.9475 - accuracy: 0.6623 - val_loss: 0.8271 - val_accuracy: 0.8154\n",
      "Epoch 26/100\n",
      "453/453 [==============================] - 0s 88us/step - loss: 3.1029 - accuracy: 0.6932 - val_loss: 0.8426 - val_accuracy: 0.8000\n",
      "Epoch 27/100\n",
      "453/453 [==============================] - 0s 293us/step - loss: 2.7994 - accuracy: 0.6446 - val_loss: 0.9636 - val_accuracy: 0.7692\n",
      "Epoch 28/100\n",
      "453/453 [==============================] - 0s 164us/step - loss: 2.6808 - accuracy: 0.6932 - val_loss: 0.8107 - val_accuracy: 0.8308\n",
      "Epoch 29/100\n",
      "453/453 [==============================] - 0s 160us/step - loss: 2.8104 - accuracy: 0.7042 - val_loss: 0.8281 - val_accuracy: 0.8308\n",
      "Epoch 30/100\n",
      "453/453 [==============================] - 0s 175us/step - loss: 2.3161 - accuracy: 0.6954 - val_loss: 0.8293 - val_accuracy: 0.8462\n",
      "Epoch 31/100\n",
      "453/453 [==============================] - 0s 151us/step - loss: 2.4287 - accuracy: 0.7483 - val_loss: 0.7544 - val_accuracy: 0.8410\n",
      "Epoch 32/100\n",
      "453/453 [==============================] - 0s 94us/step - loss: 2.9868 - accuracy: 0.6645 - val_loss: 0.9299 - val_accuracy: 0.7846\n",
      "Epoch 33/100\n",
      "453/453 [==============================] - 0s 86us/step - loss: 2.5818 - accuracy: 0.6887 - val_loss: 0.8206 - val_accuracy: 0.8103\n",
      "Epoch 34/100\n",
      "453/453 [==============================] - 0s 194us/step - loss: 2.2690 - accuracy: 0.7550 - val_loss: 0.8061 - val_accuracy: 0.8359\n",
      "Epoch 35/100\n",
      "453/453 [==============================] - 0s 288us/step - loss: 2.5433 - accuracy: 0.7439 - val_loss: 0.7660 - val_accuracy: 0.8564\n",
      "Epoch 36/100\n",
      "453/453 [==============================] - 0s 188us/step - loss: 2.5990 - accuracy: 0.7373 - val_loss: 0.7355 - val_accuracy: 0.8564\n",
      "Epoch 37/100\n",
      "453/453 [==============================] - 0s 195us/step - loss: 2.8662 - accuracy: 0.7263 - val_loss: 0.7290 - val_accuracy: 0.8513\n",
      "Epoch 38/100\n",
      "453/453 [==============================] - 0s 136us/step - loss: 2.7089 - accuracy: 0.7219 - val_loss: 0.7957 - val_accuracy: 0.8718\n",
      "Epoch 39/100\n",
      "453/453 [==============================] - 0s 96us/step - loss: 2.7131 - accuracy: 0.7020 - val_loss: 0.8672 - val_accuracy: 0.8308\n",
      "Epoch 40/100\n",
      "453/453 [==============================] - 0s 118us/step - loss: 2.5713 - accuracy: 0.6733 - val_loss: 0.7762 - val_accuracy: 0.8308\n",
      "Epoch 41/100\n",
      "453/453 [==============================] - 0s 250us/step - loss: 2.1842 - accuracy: 0.7042 - val_loss: 0.8366 - val_accuracy: 0.8308\n",
      "Epoch 42/100\n",
      "453/453 [==============================] - 0s 185us/step - loss: 2.3563 - accuracy: 0.7196 - val_loss: 0.9030 - val_accuracy: 0.8462\n",
      "Epoch 43/100\n",
      "453/453 [==============================] - 0s 170us/step - loss: 2.6575 - accuracy: 0.6909 - val_loss: 0.7355 - val_accuracy: 0.8564\n",
      "Epoch 44/100\n",
      "453/453 [==============================] - 0s 216us/step - loss: 2.1905 - accuracy: 0.7373 - val_loss: 0.7950 - val_accuracy: 0.8718\n",
      "Epoch 45/100\n",
      "453/453 [==============================] - 0s 200us/step - loss: 2.5092 - accuracy: 0.7130 - val_loss: 0.9644 - val_accuracy: 0.8615\n",
      "Epoch 46/100\n",
      "453/453 [==============================] - 0s 130us/step - loss: 2.1247 - accuracy: 0.7439 - val_loss: 0.7269 - val_accuracy: 0.8462\n",
      "Epoch 47/100\n",
      "453/453 [==============================] - 0s 201us/step - loss: 2.4340 - accuracy: 0.7020 - val_loss: 0.7316 - val_accuracy: 0.8410\n",
      "Epoch 48/100\n",
      "453/453 [==============================] - 0s 248us/step - loss: 2.3497 - accuracy: 0.7417 - val_loss: 0.7393 - val_accuracy: 0.8410\n",
      "Epoch 49/100\n",
      "453/453 [==============================] - 0s 139us/step - loss: 2.1965 - accuracy: 0.7196 - val_loss: 0.7172 - val_accuracy: 0.8308\n",
      "Epoch 50/100\n",
      "453/453 [==============================] - 0s 91us/step - loss: 2.6557 - accuracy: 0.6887 - val_loss: 0.7194 - val_accuracy: 0.8615\n",
      "Epoch 51/100\n",
      "453/453 [==============================] - 0s 72us/step - loss: 1.9252 - accuracy: 0.7373 - val_loss: 0.7441 - val_accuracy: 0.8564\n",
      "Epoch 52/100\n",
      "453/453 [==============================] - 0s 71us/step - loss: 2.3072 - accuracy: 0.7417 - val_loss: 0.7310 - val_accuracy: 0.8667\n",
      "Epoch 53/100\n",
      "453/453 [==============================] - 0s 70us/step - loss: 2.1818 - accuracy: 0.7572 - val_loss: 0.7018 - val_accuracy: 0.8821\n",
      "Epoch 54/100\n",
      "453/453 [==============================] - 0s 70us/step - loss: 2.4352 - accuracy: 0.7152 - val_loss: 0.7427 - val_accuracy: 0.8615\n",
      "Epoch 55/100\n",
      "453/453 [==============================] - 0s 89us/step - loss: 2.1923 - accuracy: 0.7439 - val_loss: 0.6776 - val_accuracy: 0.8821\n",
      "Epoch 56/100\n",
      "453/453 [==============================] - 0s 84us/step - loss: 1.9658 - accuracy: 0.7726 - val_loss: 0.7171 - val_accuracy: 0.8769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "453/453 [==============================] - 0s 124us/step - loss: 2.2738 - accuracy: 0.7373 - val_loss: 0.7796 - val_accuracy: 0.8667\n",
      "Epoch 58/100\n",
      "453/453 [==============================] - 0s 128us/step - loss: 2.1465 - accuracy: 0.7417 - val_loss: 0.7009 - val_accuracy: 0.8615\n",
      "Epoch 59/100\n",
      "453/453 [==============================] - 0s 94us/step - loss: 1.9698 - accuracy: 0.7616 - val_loss: 0.7442 - val_accuracy: 0.8615\n",
      "Epoch 60/100\n",
      "453/453 [==============================] - 0s 115us/step - loss: 2.4382 - accuracy: 0.7241 - val_loss: 0.8284 - val_accuracy: 0.8615\n",
      "Epoch 61/100\n",
      "453/453 [==============================] - 0s 119us/step - loss: 1.9757 - accuracy: 0.7528 - val_loss: 0.9702 - val_accuracy: 0.8564\n",
      "Epoch 62/100\n",
      "453/453 [==============================] - 0s 118us/step - loss: 2.2523 - accuracy: 0.7285 - val_loss: 1.0378 - val_accuracy: 0.8718\n",
      "Epoch 63/100\n",
      "453/453 [==============================] - 0s 119us/step - loss: 2.5103 - accuracy: 0.7064 - val_loss: 0.8574 - val_accuracy: 0.8718\n",
      "Epoch 64/100\n",
      "453/453 [==============================] - 0s 92us/step - loss: 2.3438 - accuracy: 0.7042 - val_loss: 0.7885 - val_accuracy: 0.8615\n",
      "Epoch 65/100\n",
      "453/453 [==============================] - 0s 94us/step - loss: 1.9430 - accuracy: 0.7351 - val_loss: 0.7660 - val_accuracy: 0.8769\n",
      "Epoch 66/100\n",
      "453/453 [==============================] - 0s 89us/step - loss: 2.2716 - accuracy: 0.7064 - val_loss: 0.7902 - val_accuracy: 0.9077\n",
      "Epoch 67/100\n",
      "453/453 [==============================] - 0s 82us/step - loss: 2.0841 - accuracy: 0.7285 - val_loss: 0.7465 - val_accuracy: 0.8615\n",
      "Epoch 68/100\n",
      "453/453 [==============================] - 0s 173us/step - loss: 2.1579 - accuracy: 0.7439 - val_loss: 0.7816 - val_accuracy: 0.8513\n",
      "Epoch 69/100\n",
      "453/453 [==============================] - 0s 230us/step - loss: 2.1993 - accuracy: 0.7152 - val_loss: 0.7713 - val_accuracy: 0.8769\n",
      "Epoch 70/100\n",
      "453/453 [==============================] - 0s 158us/step - loss: 1.9632 - accuracy: 0.7174 - val_loss: 0.8158 - val_accuracy: 0.8821\n",
      "Epoch 71/100\n",
      "453/453 [==============================] - 0s 99us/step - loss: 1.9069 - accuracy: 0.7285 - val_loss: 0.9006 - val_accuracy: 0.8615\n",
      "Epoch 72/100\n",
      "453/453 [==============================] - 0s 75us/step - loss: 1.7710 - accuracy: 0.7572 - val_loss: 0.7738 - val_accuracy: 0.8769\n",
      "Epoch 73/100\n",
      "453/453 [==============================] - 0s 78us/step - loss: 1.6786 - accuracy: 0.7196 - val_loss: 0.7675 - val_accuracy: 0.8564\n",
      "Epoch 74/100\n",
      "453/453 [==============================] - 0s 73us/step - loss: 1.8323 - accuracy: 0.7373 - val_loss: 0.8008 - val_accuracy: 0.8564\n",
      "Epoch 75/100\n",
      "453/453 [==============================] - 0s 80us/step - loss: 2.1114 - accuracy: 0.7373 - val_loss: 0.7540 - val_accuracy: 0.8974\n",
      "Epoch 76/100\n",
      "453/453 [==============================] - 0s 95us/step - loss: 1.8281 - accuracy: 0.7461 - val_loss: 0.8092 - val_accuracy: 0.8821\n",
      "Epoch 77/100\n",
      "453/453 [==============================] - 0s 114us/step - loss: 1.8429 - accuracy: 0.7395 - val_loss: 0.7863 - val_accuracy: 0.8769\n",
      "Epoch 78/100\n",
      "453/453 [==============================] - 0s 117us/step - loss: 1.9649 - accuracy: 0.7351 - val_loss: 0.7903 - val_accuracy: 0.8615\n",
      "Epoch 79/100\n",
      "453/453 [==============================] - 0s 117us/step - loss: 1.8502 - accuracy: 0.7174 - val_loss: 0.8068 - val_accuracy: 0.8718\n",
      "Epoch 80/100\n",
      "453/453 [==============================] - 0s 93us/step - loss: 1.9216 - accuracy: 0.7417 - val_loss: 0.8836 - val_accuracy: 0.8718\n",
      "Epoch 81/100\n",
      "453/453 [==============================] - 0s 72us/step - loss: 1.7218 - accuracy: 0.7086 - val_loss: 0.7848 - val_accuracy: 0.8615\n",
      "Epoch 82/100\n",
      "453/453 [==============================] - 0s 68us/step - loss: 1.8564 - accuracy: 0.7064 - val_loss: 0.7218 - val_accuracy: 0.8872\n",
      "Epoch 83/100\n",
      "453/453 [==============================] - 0s 98us/step - loss: 2.0854 - accuracy: 0.7174 - val_loss: 0.7114 - val_accuracy: 0.9179\n",
      "Epoch 84/100\n",
      "453/453 [==============================] - 0s 96us/step - loss: 1.9361 - accuracy: 0.7307 - val_loss: 0.7567 - val_accuracy: 0.8718\n",
      "Epoch 85/100\n",
      "453/453 [==============================] - 0s 123us/step - loss: 1.9796 - accuracy: 0.7351 - val_loss: 0.7801 - val_accuracy: 0.8821\n",
      "Epoch 86/100\n",
      "453/453 [==============================] - 0s 118us/step - loss: 1.8453 - accuracy: 0.7241 - val_loss: 0.7740 - val_accuracy: 0.8974\n",
      "Epoch 87/100\n",
      "453/453 [==============================] - 0s 90us/step - loss: 1.7383 - accuracy: 0.7439 - val_loss: 0.7926 - val_accuracy: 0.8821\n",
      "Epoch 88/100\n",
      "453/453 [==============================] - 0s 106us/step - loss: 1.4890 - accuracy: 0.7682 - val_loss: 0.7709 - val_accuracy: 0.8769\n",
      "Epoch 89/100\n",
      "453/453 [==============================] - 0s 72us/step - loss: 2.0777 - accuracy: 0.7329 - val_loss: 0.8080 - val_accuracy: 0.8974\n",
      "Epoch 90/100\n",
      "453/453 [==============================] - 0s 89us/step - loss: 1.6141 - accuracy: 0.7307 - val_loss: 0.7200 - val_accuracy: 0.8974\n",
      "Epoch 91/100\n",
      "453/453 [==============================] - 0s 71us/step - loss: 1.6071 - accuracy: 0.7506 - val_loss: 0.7158 - val_accuracy: 0.8923\n",
      "Epoch 92/100\n",
      "453/453 [==============================] - 0s 78us/step - loss: 1.8126 - accuracy: 0.7417 - val_loss: 0.6903 - val_accuracy: 0.8923\n",
      "Epoch 93/100\n",
      "453/453 [==============================] - 0s 69us/step - loss: 2.0375 - accuracy: 0.7263 - val_loss: 0.7076 - val_accuracy: 0.8872\n",
      "Epoch 94/100\n",
      "453/453 [==============================] - 0s 70us/step - loss: 1.6126 - accuracy: 0.7594 - val_loss: 0.6620 - val_accuracy: 0.8974\n",
      "Epoch 95/100\n",
      "453/453 [==============================] - 0s 72us/step - loss: 1.6624 - accuracy: 0.7307 - val_loss: 0.7536 - val_accuracy: 0.8872\n",
      "Epoch 96/100\n",
      "453/453 [==============================] - 0s 68us/step - loss: 1.9199 - accuracy: 0.7461 - val_loss: 0.7340 - val_accuracy: 0.8821\n",
      "Epoch 97/100\n",
      "453/453 [==============================] - 0s 111us/step - loss: 1.7884 - accuracy: 0.7329 - val_loss: 0.7200 - val_accuracy: 0.8923\n",
      "Epoch 98/100\n",
      "453/453 [==============================] - 0s 117us/step - loss: 1.3551 - accuracy: 0.7439 - val_loss: 0.7060 - val_accuracy: 0.8769\n",
      "Epoch 99/100\n",
      "453/453 [==============================] - 0s 81us/step - loss: 1.8250 - accuracy: 0.7461 - val_loss: 0.6988 - val_accuracy: 0.8872\n",
      "Epoch 100/100\n",
      "453/453 [==============================] - 0s 77us/step - loss: 1.7346 - accuracy: 0.7638 - val_loss: 0.6990 - val_accuracy: 0.8769\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a36b42240>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over7.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195/195 [==============================] - 0s 94us/step\n",
      "over-sampling test accuracy: 89.74%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over7 = model1_over7.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over7*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 2, 0, 1, 0, 2, 2, 1, 2, 0, 1, 0, 1, 0, 0, 1, 1, 2, 2,\n",
       "       2, 2, 1, 1, 1, 1, 1, 0, 1, 0, 0, 2, 2, 1, 1, 0, 2, 0, 2, 0, 2, 0,\n",
       "       0, 0, 1, 2, 1, 2, 2, 0, 0, 0, 0, 2, 2, 1, 1, 1, 1, 0, 2, 2, 0, 1,\n",
       "       2, 1, 0, 2, 2, 0, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 1, 2, 2, 1, 0,\n",
       "       0, 2, 1, 2, 2, 1, 2, 1, 0, 1, 0, 2, 2, 2, 0, 0, 1, 0, 2, 0, 0, 1,\n",
       "       0, 1, 2, 0, 2, 1, 0, 1, 0, 1, 0, 1, 2, 0, 1, 2, 0, 0, 0, 2, 1, 1,\n",
       "       2, 1, 1, 1, 1, 0, 1, 0, 0, 2, 2, 1, 0, 2, 1, 0, 1, 2, 2, 2, 0, 0,\n",
       "       2, 1, 2, 2, 1, 2, 2, 0, 0, 0, 2, 0, 0, 2, 1, 1, 1, 0, 0, 0, 2, 1,\n",
       "       1, 0, 0, 1, 2, 1, 1, 0, 2, 0, 2, 1, 0, 2, 0, 1, 2, 1, 0])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred7 = model1_over7.predict_classes(X_test_over)\n",
    "pred7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS218</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS260</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS162</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS177</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>NRS383</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>NRS218</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>SR2852</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>NRS248</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0  test  pred\n",
       "0    NRS218     1     1\n",
       "1    NRS260     1     1\n",
       "2    NRS162     0     0\n",
       "3    NRS177     0     0\n",
       "4    NRS209     2     2\n",
       "..      ...   ...   ...\n",
       "190  NRS383     1     0\n",
       "191  NRS218     1     1\n",
       "192  NRS209     2     2\n",
       "193  SR2852     1     1\n",
       "194  NRS248     0     0\n",
       "\n",
       "[195 rows x 3 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat7['pred'] = pred7\n",
    "dat7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba7 = model1_over7.predict_proba(X_test_over)\n",
    "dat_proba7 = pd.DataFrame(proba7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.540596e-02</td>\n",
       "      <td>9.518660e-01</td>\n",
       "      <td>1.272812e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.710814e-03</td>\n",
       "      <td>9.939436e-01</td>\n",
       "      <td>3.454555e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.999807e-01</td>\n",
       "      <td>1.819183e-05</td>\n",
       "      <td>1.128070e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.999942e-01</td>\n",
       "      <td>5.873688e-06</td>\n",
       "      <td>1.826433e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.429018e-08</td>\n",
       "      <td>6.771530e-08</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>8.690237e-01</td>\n",
       "      <td>1.309742e-01</td>\n",
       "      <td>2.209219e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>3.540596e-02</td>\n",
       "      <td>9.518660e-01</td>\n",
       "      <td>1.272812e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>7.429018e-08</td>\n",
       "      <td>6.771530e-08</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>3.114946e-03</td>\n",
       "      <td>9.968849e-01</td>\n",
       "      <td>6.330789e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>9.864523e-01</td>\n",
       "      <td>4.975368e-05</td>\n",
       "      <td>1.349799e-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0             1             2\n",
       "0    3.540596e-02  9.518660e-01  1.272812e-02\n",
       "1    5.710814e-03  9.939436e-01  3.454555e-04\n",
       "2    9.999807e-01  1.819183e-05  1.128070e-06\n",
       "3    9.999942e-01  5.873688e-06  1.826433e-08\n",
       "4    7.429018e-08  6.771530e-08  9.999999e-01\n",
       "..            ...           ...           ...\n",
       "190  8.690237e-01  1.309742e-01  2.209219e-06\n",
       "191  3.540596e-02  9.518660e-01  1.272812e-02\n",
       "192  7.429018e-08  6.771530e-08  9.999999e-01\n",
       "193  3.114946e-03  9.968849e-01  6.330789e-08\n",
       "194  9.864523e-01  4.975368e-05  1.349799e-02\n",
       "\n",
       "[195 rows x 3 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba7.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba7.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat7.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/7p17spST.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 453 samples, validate on 195 samples\n",
      "Epoch 1/100\n",
      "453/453 [==============================] - 0s 129us/step - loss: 1.9407 - accuracy: 0.7373 - val_loss: 0.7832 - val_accuracy: 0.9077\n",
      "Epoch 2/100\n",
      "453/453 [==============================] - 0s 127us/step - loss: 1.6920 - accuracy: 0.7285 - val_loss: 0.8520 - val_accuracy: 0.8923\n",
      "Epoch 3/100\n",
      "453/453 [==============================] - 0s 157us/step - loss: 1.7241 - accuracy: 0.7351 - val_loss: 0.8375 - val_accuracy: 0.9026\n",
      "Epoch 4/100\n",
      "453/453 [==============================] - 0s 118us/step - loss: 1.9081 - accuracy: 0.7528 - val_loss: 0.8226 - val_accuracy: 0.9128\n",
      "Epoch 5/100\n",
      "453/453 [==============================] - 0s 106us/step - loss: 1.8447 - accuracy: 0.7219 - val_loss: 0.9478 - val_accuracy: 0.8667\n",
      "Epoch 6/100\n",
      "453/453 [==============================] - 0s 107us/step - loss: 1.7675 - accuracy: 0.7196 - val_loss: 0.8372 - val_accuracy: 0.8718\n",
      "Epoch 7/100\n",
      "453/453 [==============================] - 0s 118us/step - loss: 1.6275 - accuracy: 0.7373 - val_loss: 0.8013 - val_accuracy: 0.8923\n",
      "Epoch 8/100\n",
      "453/453 [==============================] - 0s 113us/step - loss: 1.8704 - accuracy: 0.7439 - val_loss: 0.8701 - val_accuracy: 0.8821\n",
      "Epoch 9/100\n",
      "453/453 [==============================] - 0s 114us/step - loss: 1.8641 - accuracy: 0.7174 - val_loss: 0.7546 - val_accuracy: 0.9026\n",
      "Epoch 10/100\n",
      "453/453 [==============================] - 0s 130us/step - loss: 1.5538 - accuracy: 0.7550 - val_loss: 0.8025 - val_accuracy: 0.8974\n",
      "Epoch 11/100\n",
      "453/453 [==============================] - 0s 156us/step - loss: 1.5459 - accuracy: 0.7859 - val_loss: 0.7832 - val_accuracy: 0.9026\n",
      "Epoch 12/100\n",
      "453/453 [==============================] - 0s 139us/step - loss: 1.6982 - accuracy: 0.7528 - val_loss: 0.9513 - val_accuracy: 0.8718\n",
      "Epoch 13/100\n",
      "453/453 [==============================] - 0s 113us/step - loss: 1.8383 - accuracy: 0.7483 - val_loss: 0.8447 - val_accuracy: 0.8667\n",
      "Epoch 14/100\n",
      "453/453 [==============================] - 0s 102us/step - loss: 1.9178 - accuracy: 0.7219 - val_loss: 0.8215 - val_accuracy: 0.8872\n",
      "Epoch 15/100\n",
      "453/453 [==============================] - 0s 95us/step - loss: 1.7455 - accuracy: 0.7572 - val_loss: 0.8064 - val_accuracy: 0.8974\n",
      "Epoch 16/100\n",
      "453/453 [==============================] - 0s 108us/step - loss: 1.6415 - accuracy: 0.7351 - val_loss: 0.8065 - val_accuracy: 0.9077\n",
      "Epoch 17/100\n",
      "453/453 [==============================] - 0s 111us/step - loss: 2.0407 - accuracy: 0.7152 - val_loss: 1.1497 - val_accuracy: 0.8564\n",
      "Epoch 18/100\n",
      "453/453 [==============================] - 0s 103us/step - loss: 1.7115 - accuracy: 0.7263 - val_loss: 0.9978 - val_accuracy: 0.8462\n",
      "Epoch 19/100\n",
      "453/453 [==============================] - 0s 136us/step - loss: 1.6892 - accuracy: 0.7682 - val_loss: 0.8425 - val_accuracy: 0.8821\n",
      "Epoch 20/100\n",
      "453/453 [==============================] - 0s 143us/step - loss: 1.7969 - accuracy: 0.7594 - val_loss: 0.8535 - val_accuracy: 0.8923\n",
      "Epoch 21/100\n",
      "453/453 [==============================] - 0s 286us/step - loss: 1.7091 - accuracy: 0.7351 - val_loss: 0.7855 - val_accuracy: 0.8923\n",
      "Epoch 22/100\n",
      "453/453 [==============================] - ETA: 0s - loss: 1.6124 - accuracy: 0.75 - 0s 439us/step - loss: 1.5384 - accuracy: 0.7594 - val_loss: 0.7473 - val_accuracy: 0.8821\n",
      "Epoch 23/100\n",
      "453/453 [==============================] - 0s 381us/step - loss: 1.5911 - accuracy: 0.7792 - val_loss: 0.7880 - val_accuracy: 0.8872\n",
      "Epoch 24/100\n",
      "453/453 [==============================] - 0s 247us/step - loss: 1.8332 - accuracy: 0.7373 - val_loss: 0.8912 - val_accuracy: 0.8769\n",
      "Epoch 25/100\n",
      "453/453 [==============================] - 0s 369us/step - loss: 1.5826 - accuracy: 0.7417 - val_loss: 1.0617 - val_accuracy: 0.8564\n",
      "Epoch 26/100\n",
      "453/453 [==============================] - 0s 194us/step - loss: 1.8399 - accuracy: 0.7704 - val_loss: 1.1488 - val_accuracy: 0.8410\n",
      "Epoch 27/100\n",
      "453/453 [==============================] - 0s 129us/step - loss: 1.7526 - accuracy: 0.7550 - val_loss: 1.0934 - val_accuracy: 0.8615\n",
      "Epoch 28/100\n",
      "453/453 [==============================] - 0s 550us/step - loss: 1.6309 - accuracy: 0.7792 - val_loss: 0.9392 - val_accuracy: 0.8564\n",
      "Epoch 29/100\n",
      "453/453 [==============================] - 0s 177us/step - loss: 1.6638 - accuracy: 0.7572 - val_loss: 0.8554 - val_accuracy: 0.8667\n",
      "Epoch 30/100\n",
      "453/453 [==============================] - 0s 191us/step - loss: 1.5435 - accuracy: 0.7616 - val_loss: 0.8029 - val_accuracy: 0.8872\n",
      "Epoch 31/100\n",
      "453/453 [==============================] - 0s 176us/step - loss: 1.6124 - accuracy: 0.7660 - val_loss: 0.7910 - val_accuracy: 0.8821\n",
      "Epoch 32/100\n",
      "453/453 [==============================] - 0s 224us/step - loss: 1.7404 - accuracy: 0.7020 - val_loss: 0.8760 - val_accuracy: 0.8923\n",
      "Epoch 33/100\n",
      "453/453 [==============================] - 0s 150us/step - loss: 1.4660 - accuracy: 0.7837 - val_loss: 0.9168 - val_accuracy: 0.8410\n",
      "Epoch 34/100\n",
      "453/453 [==============================] - 0s 139us/step - loss: 1.6218 - accuracy: 0.7550 - val_loss: 0.8960 - val_accuracy: 0.8564\n",
      "Epoch 35/100\n",
      "453/453 [==============================] - 0s 132us/step - loss: 1.7594 - accuracy: 0.7506 - val_loss: 0.9036 - val_accuracy: 0.8769\n",
      "Epoch 36/100\n",
      "453/453 [==============================] - 0s 110us/step - loss: 1.4156 - accuracy: 0.7660 - val_loss: 0.8580 - val_accuracy: 0.8821\n",
      "Epoch 37/100\n",
      "453/453 [==============================] - 0s 119us/step - loss: 1.5132 - accuracy: 0.7461 - val_loss: 0.9382 - val_accuracy: 0.8718\n",
      "Epoch 38/100\n",
      "453/453 [==============================] - 0s 118us/step - loss: 1.5870 - accuracy: 0.7395 - val_loss: 0.8990 - val_accuracy: 0.8769\n",
      "Epoch 39/100\n",
      "453/453 [==============================] - 0s 350us/step - loss: 1.5172 - accuracy: 0.7351 - val_loss: 0.8453 - val_accuracy: 0.8769\n",
      "Epoch 40/100\n",
      "453/453 [==============================] - 0s 231us/step - loss: 1.7885 - accuracy: 0.6998 - val_loss: 0.8099 - val_accuracy: 0.8974\n",
      "Epoch 41/100\n",
      "453/453 [==============================] - 0s 220us/step - loss: 1.4993 - accuracy: 0.7616 - val_loss: 0.9380 - val_accuracy: 0.8821\n",
      "Epoch 42/100\n",
      "453/453 [==============================] - 0s 466us/step - loss: 1.6275 - accuracy: 0.7395 - val_loss: 0.8333 - val_accuracy: 0.8667\n",
      "Epoch 43/100\n",
      "453/453 [==============================] - 0s 235us/step - loss: 1.5109 - accuracy: 0.7461 - val_loss: 0.8421 - val_accuracy: 0.8410\n",
      "Epoch 44/100\n",
      "453/453 [==============================] - 0s 215us/step - loss: 1.3506 - accuracy: 0.7307 - val_loss: 0.9641 - val_accuracy: 0.8769\n",
      "Epoch 45/100\n",
      "453/453 [==============================] - 0s 134us/step - loss: 1.3251 - accuracy: 0.7550 - val_loss: 1.1175 - val_accuracy: 0.8513\n",
      "Epoch 46/100\n",
      "453/453 [==============================] - 0s 221us/step - loss: 1.5051 - accuracy: 0.7704 - val_loss: 0.8370 - val_accuracy: 0.8769\n",
      "Epoch 47/100\n",
      "453/453 [==============================] - 0s 226us/step - loss: 1.2281 - accuracy: 0.7859 - val_loss: 0.7779 - val_accuracy: 0.9128\n",
      "Epoch 48/100\n",
      "453/453 [==============================] - 0s 134us/step - loss: 1.7934 - accuracy: 0.7152 - val_loss: 1.0038 - val_accuracy: 0.8564\n",
      "Epoch 49/100\n",
      "453/453 [==============================] - 0s 211us/step - loss: 1.3132 - accuracy: 0.7770 - val_loss: 0.8420 - val_accuracy: 0.8615\n",
      "Epoch 50/100\n",
      "453/453 [==============================] - 0s 274us/step - loss: 1.4341 - accuracy: 0.7660 - val_loss: 0.8628 - val_accuracy: 0.8769\n",
      "Epoch 51/100\n",
      "453/453 [==============================] - 0s 215us/step - loss: 1.5474 - accuracy: 0.7550 - val_loss: 0.8305 - val_accuracy: 0.8769\n",
      "Epoch 52/100\n",
      "453/453 [==============================] - 0s 237us/step - loss: 1.3313 - accuracy: 0.7439 - val_loss: 0.7749 - val_accuracy: 0.8769\n",
      "Epoch 53/100\n",
      "453/453 [==============================] - 0s 208us/step - loss: 1.4661 - accuracy: 0.7329 - val_loss: 0.7246 - val_accuracy: 0.8923\n",
      "Epoch 54/100\n",
      "453/453 [==============================] - 0s 219us/step - loss: 1.3140 - accuracy: 0.7638 - val_loss: 0.7345 - val_accuracy: 0.8872\n",
      "Epoch 55/100\n",
      "453/453 [==============================] - 0s 170us/step - loss: 1.4422 - accuracy: 0.7748 - val_loss: 0.7684 - val_accuracy: 0.8718\n",
      "Epoch 56/100\n",
      "453/453 [==============================] - 0s 138us/step - loss: 1.3978 - accuracy: 0.7638 - val_loss: 0.7718 - val_accuracy: 0.8769\n",
      "Epoch 57/100\n",
      "453/453 [==============================] - 0s 204us/step - loss: 1.6542 - accuracy: 0.7572 - val_loss: 0.7232 - val_accuracy: 0.9179\n",
      "Epoch 58/100\n",
      "453/453 [==============================] - 0s 266us/step - loss: 1.4628 - accuracy: 0.7351 - val_loss: 0.7222 - val_accuracy: 0.9231\n",
      "Epoch 59/100\n",
      "453/453 [==============================] - 0s 285us/step - loss: 1.4833 - accuracy: 0.7506 - val_loss: 0.7481 - val_accuracy: 0.8923\n",
      "Epoch 60/100\n",
      "453/453 [==============================] - 0s 151us/step - loss: 1.5107 - accuracy: 0.7682 - val_loss: 0.7979 - val_accuracy: 0.8872\n",
      "Epoch 61/100\n",
      "453/453 [==============================] - 0s 130us/step - loss: 1.6929 - accuracy: 0.7130 - val_loss: 0.9209 - val_accuracy: 0.8564\n",
      "Epoch 62/100\n",
      "453/453 [==============================] - 0s 142us/step - loss: 1.2595 - accuracy: 0.7748 - val_loss: 0.8696 - val_accuracy: 0.8667\n",
      "Epoch 63/100\n",
      "453/453 [==============================] - 0s 284us/step - loss: 1.3983 - accuracy: 0.7748 - val_loss: 0.8283 - val_accuracy: 0.8872\n",
      "Epoch 64/100\n",
      "453/453 [==============================] - 0s 274us/step - loss: 1.4841 - accuracy: 0.7506 - val_loss: 0.9265 - val_accuracy: 0.8821\n",
      "Epoch 65/100\n",
      "453/453 [==============================] - 0s 156us/step - loss: 1.4154 - accuracy: 0.7792 - val_loss: 0.8353 - val_accuracy: 0.8769\n",
      "Epoch 66/100\n",
      "453/453 [==============================] - 0s 124us/step - loss: 1.5001 - accuracy: 0.7594 - val_loss: 0.8495 - val_accuracy: 0.8718\n",
      "Epoch 67/100\n",
      "453/453 [==============================] - 0s 127us/step - loss: 1.3097 - accuracy: 0.7859 - val_loss: 0.8619 - val_accuracy: 0.8667\n",
      "Epoch 68/100\n",
      "453/453 [==============================] - 0s 124us/step - loss: 1.3431 - accuracy: 0.7660 - val_loss: 1.0590 - val_accuracy: 0.8667\n",
      "Epoch 69/100\n",
      "453/453 [==============================] - 0s 122us/step - loss: 1.4617 - accuracy: 0.7616 - val_loss: 0.8557 - val_accuracy: 0.8718\n",
      "Epoch 70/100\n",
      "453/453 [==============================] - 0s 146us/step - loss: 1.2966 - accuracy: 0.7969 - val_loss: 0.8118 - val_accuracy: 0.8718\n",
      "Epoch 71/100\n",
      "453/453 [==============================] - 0s 257us/step - loss: 1.3008 - accuracy: 0.7638 - val_loss: 0.8757 - val_accuracy: 0.8667\n",
      "Epoch 72/100\n",
      "453/453 [==============================] - 0s 202us/step - loss: 1.3326 - accuracy: 0.7638 - val_loss: 0.8679 - val_accuracy: 0.8718\n",
      "Epoch 73/100\n",
      "453/453 [==============================] - 0s 123us/step - loss: 1.3380 - accuracy: 0.7792 - val_loss: 0.9315 - val_accuracy: 0.8718\n",
      "Epoch 74/100\n",
      "453/453 [==============================] - 0s 129us/step - loss: 1.4872 - accuracy: 0.7307 - val_loss: 0.9567 - val_accuracy: 0.8564\n",
      "Epoch 75/100\n",
      "453/453 [==============================] - 0s 120us/step - loss: 1.4138 - accuracy: 0.7550 - val_loss: 0.8862 - val_accuracy: 0.8821\n",
      "Epoch 76/100\n",
      "453/453 [==============================] - 0s 117us/step - loss: 1.3553 - accuracy: 0.7660 - val_loss: 0.7992 - val_accuracy: 0.8872\n",
      "Epoch 77/100\n",
      "453/453 [==============================] - 0s 136us/step - loss: 1.3791 - accuracy: 0.7792 - val_loss: 0.8151 - val_accuracy: 0.8872\n",
      "Epoch 78/100\n",
      "453/453 [==============================] - 0s 129us/step - loss: 1.4858 - accuracy: 0.7616 - val_loss: 0.8699 - val_accuracy: 0.8821\n",
      "Epoch 79/100\n",
      "453/453 [==============================] - 0s 131us/step - loss: 1.3771 - accuracy: 0.7704 - val_loss: 0.8985 - val_accuracy: 0.8718\n",
      "Epoch 80/100\n",
      "453/453 [==============================] - 0s 189us/step - loss: 1.6329 - accuracy: 0.7152 - val_loss: 0.9162 - val_accuracy: 0.8667\n",
      "Epoch 81/100\n",
      "453/453 [==============================] - 0s 140us/step - loss: 1.4150 - accuracy: 0.7373 - val_loss: 0.8503 - val_accuracy: 0.8615\n",
      "Epoch 82/100\n",
      "453/453 [==============================] - 0s 236us/step - loss: 1.1609 - accuracy: 0.7925 - val_loss: 0.8087 - val_accuracy: 0.8872\n",
      "Epoch 83/100\n",
      "453/453 [==============================] - 0s 255us/step - loss: 1.4220 - accuracy: 0.7506 - val_loss: 0.8459 - val_accuracy: 0.8769\n",
      "Epoch 84/100\n",
      "453/453 [==============================] - 0s 137us/step - loss: 1.3426 - accuracy: 0.7792 - val_loss: 0.9205 - val_accuracy: 0.8872\n",
      "Epoch 85/100\n",
      "453/453 [==============================] - 0s 139us/step - loss: 1.2469 - accuracy: 0.7859 - val_loss: 0.8680 - val_accuracy: 0.8667\n",
      "Epoch 86/100\n",
      "453/453 [==============================] - 0s 119us/step - loss: 1.4694 - accuracy: 0.7285 - val_loss: 0.8700 - val_accuracy: 0.8564\n",
      "Epoch 87/100\n",
      "453/453 [==============================] - 0s 123us/step - loss: 1.2588 - accuracy: 0.7726 - val_loss: 0.7696 - val_accuracy: 0.9026\n",
      "Epoch 88/100\n",
      "453/453 [==============================] - 0s 117us/step - loss: 1.3547 - accuracy: 0.7550 - val_loss: 0.9074 - val_accuracy: 0.8974\n",
      "Epoch 89/100\n",
      "453/453 [==============================] - 0s 132us/step - loss: 1.3165 - accuracy: 0.7682 - val_loss: 0.9169 - val_accuracy: 0.8410\n",
      "Epoch 90/100\n",
      "453/453 [==============================] - 0s 140us/step - loss: 1.3115 - accuracy: 0.7594 - val_loss: 0.9005 - val_accuracy: 0.8923\n",
      "Epoch 91/100\n",
      "453/453 [==============================] - 0s 137us/step - loss: 1.3156 - accuracy: 0.7638 - val_loss: 0.9340 - val_accuracy: 0.8564\n",
      "Epoch 92/100\n",
      "453/453 [==============================] - 0s 137us/step - loss: 1.3172 - accuracy: 0.7792 - val_loss: 1.2209 - val_accuracy: 0.8718\n",
      "Epoch 93/100\n",
      "453/453 [==============================] - 0s 131us/step - loss: 1.2951 - accuracy: 0.7815 - val_loss: 0.9133 - val_accuracy: 0.8974\n",
      "Epoch 94/100\n",
      "453/453 [==============================] - 0s 184us/step - loss: 1.2826 - accuracy: 0.7572 - val_loss: 0.8054 - val_accuracy: 0.9077\n",
      "Epoch 95/100\n",
      "453/453 [==============================] - 0s 127us/step - loss: 1.3985 - accuracy: 0.8013 - val_loss: 0.9730 - val_accuracy: 0.8769\n",
      "Epoch 96/100\n",
      "453/453 [==============================] - 0s 139us/step - loss: 1.3409 - accuracy: 0.7395 - val_loss: 0.9233 - val_accuracy: 0.9026\n",
      "Epoch 97/100\n",
      "453/453 [==============================] - 0s 417us/step - loss: 1.2603 - accuracy: 0.7903 - val_loss: 0.9256 - val_accuracy: 0.8615\n",
      "Epoch 98/100\n",
      "453/453 [==============================] - 0s 288us/step - loss: 1.0838 - accuracy: 0.7815 - val_loss: 0.8716 - val_accuracy: 0.8769\n",
      "Epoch 99/100\n",
      "453/453 [==============================] - 0s 118us/step - loss: 1.4007 - accuracy: 0.7638 - val_loss: 0.9453 - val_accuracy: 0.9026\n",
      "Epoch 100/100\n",
      "453/453 [==============================] - 0s 153us/step - loss: 1.2475 - accuracy: 0.7881 - val_loss: 0.9397 - val_accuracy: 0.8718\n"
     ]
    }
   ],
   "source": [
    "hist1_over7 = model1_over7.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 75.55%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over7.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba7 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_regularizor_dropout_2.xlsx\",\n",
    "                        sheet_name=2,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8.300497e-12</td>\n",
       "      <td>1.036520e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>BCH-SA-09</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.137139e-06</td>\n",
       "      <td>9.999988e-01</td>\n",
       "      <td>2.067601e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS224</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.093110e-31</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8.300497e-12</td>\n",
       "      <td>1.036520e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS235</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.243513e-02</td>\n",
       "      <td>9.774035e-01</td>\n",
       "      <td>1.615106e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS035</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.354528e-01</td>\n",
       "      <td>6.414209e-02</td>\n",
       "      <td>4.051121e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS260</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.808470e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>7.364639e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>CA9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.361323e-08</td>\n",
       "      <td>2.871247e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS183</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.755864e-07</td>\n",
       "      <td>9.999998e-01</td>\n",
       "      <td>5.310879e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.386494e-08</td>\n",
       "      <td>2.366233e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1982 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       phage     strain  phenotype  prediction             0  \\\n",
       "0     p002ykpresabsSTCC_qual     NRS209          2           2  8.300497e-12   \n",
       "1     p002ykpresabsSTCC_qual  BCH-SA-09          1           1  1.137139e-06   \n",
       "2     p002ykpresabsSTCC_qual     NRS224          0           0  1.000000e+00   \n",
       "3     p002ykpresabsSTCC_qual     NRS209          2           2  8.300497e-12   \n",
       "4     p002ykpresabsSTCC_qual     NRS235          1           1  2.243513e-02   \n",
       "...                      ...        ...        ...         ...           ...   \n",
       "1977     pyopresabsSTCC_qual     NRS035          0           0  9.354528e-01   \n",
       "1978     pyopresabsSTCC_qual     NRS260          1           1  4.808470e-08   \n",
       "1979     pyopresabsSTCC_qual        CA9          0           0  1.000000e+00   \n",
       "1980     pyopresabsSTCC_qual     NRS183          1           1  2.755864e-07   \n",
       "1981     pyopresabsSTCC_qual     NRS148          2           2  2.386494e-08   \n",
       "\n",
       "                 1             2  \n",
       "0     1.036520e-09  1.000000e+00  \n",
       "1     9.999988e-01  2.067601e-09  \n",
       "2     2.093110e-31  0.000000e+00  \n",
       "3     1.036520e-09  1.000000e+00  \n",
       "4     9.774035e-01  1.615106e-04  \n",
       "...            ...           ...  \n",
       "1977  6.414209e-02  4.051121e-04  \n",
       "1978  1.000000e+00  7.364639e-09  \n",
       "1979  2.361323e-08  2.871247e-08  \n",
       "1980  9.999998e-01  5.310879e-08  \n",
       "1981  2.366233e-08  1.000000e+00  \n",
       "\n",
       "[1982 rows x 7 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.54059560e-02, 9.51866000e-01, 1.27281210e-02],\n",
       "       [5.71081400e-03, 9.93943630e-01, 3.45455480e-04],\n",
       "       [9.99980700e-01, 1.81918350e-05, 1.12807050e-06],\n",
       "       [9.99994160e-01, 5.87368800e-06, 1.82643340e-08],\n",
       "       [7.42901800e-08, 6.77153000e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 3.11236180e-11, 5.54551200e-13],\n",
       "       [5.09788400e-02, 9.49020560e-01, 5.65980100e-07],\n",
       "       [8.75602000e-01, 1.24389924e-01, 8.00534050e-06],\n",
       "       [7.42901800e-08, 6.77153000e-08, 9.99999900e-01],\n",
       "       [7.42901800e-08, 6.77153000e-08, 9.99999900e-01],\n",
       "       [6.68401300e-02, 9.33159900e-01, 2.40770050e-08],\n",
       "       [7.89520200e-08, 7.79008900e-08, 9.99999900e-01],\n",
       "       [8.12116440e-01, 1.87881800e-01, 1.78686130e-06],\n",
       "       [8.33406740e-05, 9.99916550e-01, 7.52781200e-08],\n",
       "       [8.93029450e-01, 1.06964940e-01, 5.61495060e-06],\n",
       "       [1.27348400e-05, 9.99982600e-01, 4.63852170e-06],\n",
       "       [9.80462970e-01, 1.95370610e-02, 7.84910800e-10],\n",
       "       [1.00000000e+00, 3.28920650e-09, 3.83464100e-12],\n",
       "       [3.70448680e-02, 9.62953600e-01, 1.53086330e-06],\n",
       "       [3.57193750e-10, 1.00000000e+00, 3.82954300e-10],\n",
       "       [7.89520200e-08, 7.79008900e-08, 9.99999900e-01],\n",
       "       [7.42901800e-08, 6.77153000e-08, 9.99999900e-01],\n",
       "       [7.89520200e-08, 7.79008900e-08, 9.99999900e-01],\n",
       "       [7.42901800e-08, 6.77153000e-08, 9.99999900e-01],\n",
       "       [1.28644860e-03, 9.98712900e-01, 7.08996900e-07],\n",
       "       [8.05826040e-02, 9.18978330e-01, 4.39101630e-04],\n",
       "       [2.57944430e-01, 7.42055600e-01, 3.83279500e-12],\n",
       "       [1.35006860e-01, 8.64992000e-01, 1.18251230e-06],\n",
       "       [3.57193750e-10, 1.00000000e+00, 3.82954300e-10],\n",
       "       [9.89829360e-01, 1.01696380e-02, 9.68994300e-07],\n",
       "       [4.79114320e-01, 5.16427500e-01, 4.45815600e-03],\n",
       "       [7.36126240e-01, 2.63842760e-01, 3.10530900e-05],\n",
       "       [8.75179500e-01, 1.24812365e-01, 8.17479900e-06],\n",
       "       [7.89520200e-08, 7.79008900e-08, 9.99999900e-01],\n",
       "       [7.89520200e-08, 7.79008900e-08, 9.99999900e-01],\n",
       "       [4.90296500e-03, 9.95096150e-01, 8.18570900e-07],\n",
       "       [3.34115450e-01, 5.97200040e-01, 6.86844800e-02],\n",
       "       [9.95431070e-01, 4.56791050e-03, 1.01444850e-06],\n",
       "       [7.42901800e-08, 6.77153000e-08, 9.99999900e-01],\n",
       "       [9.99910700e-01, 8.91487300e-05, 1.00422670e-07],\n",
       "       [7.89520200e-08, 7.79008900e-08, 9.99999900e-01],\n",
       "       [6.79781800e-01, 3.15546630e-01, 4.67161700e-03],\n",
       "       [7.42901800e-08, 6.77153000e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 3.49532360e-09, 2.83800260e-11],\n",
       "       [9.99998700e-01, 1.31742380e-06, 1.29388620e-09],\n",
       "       [1.00000000e+00, 4.93163450e-08, 3.89338260e-10],\n",
       "       [1.20991410e-03, 9.98788300e-01, 1.77980390e-06],\n",
       "       [7.42901800e-08, 6.77153000e-08, 9.99999900e-01],\n",
       "       [6.96943600e-02, 9.30302560e-01, 3.10131850e-06],\n",
       "       [7.89520200e-08, 7.79008900e-08, 9.99999900e-01],\n",
       "       [7.89520200e-08, 7.79008900e-08, 9.99999900e-01],\n",
       "       [9.78934800e-01, 2.10651570e-02, 8.52691600e-12],\n",
       "       [1.00000000e+00, 7.39592000e-12, 2.48746360e-13],\n",
       "       [9.99971600e-01, 2.83536880e-05, 1.00648450e-09],\n",
       "       [9.93099200e-01, 6.90076200e-03, 3.02783350e-09],\n",
       "       [7.42901800e-08, 6.77153000e-08, 9.99999900e-01],\n",
       "       [7.42901800e-08, 6.77153000e-08, 9.99999900e-01],\n",
       "       [1.27348400e-05, 9.99982600e-01, 4.63852170e-06],\n",
       "       [5.33827320e-02, 9.46516340e-01, 1.00984595e-04],\n",
       "       [2.04288990e-01, 7.95711000e-01, 2.22844450e-08],\n",
       "       [4.11144300e-01, 5.88854850e-01, 9.21732240e-07],\n",
       "       [9.99971600e-01, 2.83536880e-05, 1.00648450e-09],\n",
       "       [7.42901800e-08, 6.77153000e-08, 9.99999900e-01],\n",
       "       [7.89520200e-08, 7.79008900e-08, 9.99999900e-01],\n",
       "       [9.16748170e-01, 8.32428200e-02, 8.98597800e-06],\n",
       "       [4.90296500e-03, 9.95096150e-01, 8.18570900e-07],\n",
       "       [7.42901800e-08, 6.77153000e-08, 9.99999900e-01],\n",
       "       [3.70448680e-02, 9.62953600e-01, 1.53086330e-06],\n",
       "       [5.23879200e-01, 4.76067220e-01, 5.35863900e-05],\n",
       "       [7.42901800e-08, 6.77153000e-08, 9.99999900e-01],\n",
       "       [7.89520200e-08, 7.79008900e-08, 9.99999900e-01],\n",
       "       [5.10250150e-01, 4.89745900e-01, 3.97114000e-06],\n",
       "       [7.42901800e-08, 6.77153000e-08, 9.99999900e-01],\n",
       "       [7.42901800e-08, 6.77153000e-08, 9.99999900e-01],\n",
       "       [6.96943600e-02, 9.30302560e-01, 3.10131850e-06],\n",
       "       [6.68401300e-02, 9.33159900e-01, 2.40770050e-08],\n",
       "       [5.71081400e-03, 9.93943630e-01, 3.45455480e-04],\n",
       "       [4.90296500e-03, 9.95096150e-01, 8.18570900e-07],\n",
       "       [7.89520200e-08, 7.79008900e-08, 9.99999900e-01],\n",
       "       [7.42901800e-08, 6.77153000e-08, 9.99999900e-01],\n",
       "       [7.42901800e-08, 6.77153000e-08, 9.99999900e-01],\n",
       "       [7.42901800e-08, 6.77153000e-08, 9.99999900e-01],\n",
       "       [7.89520200e-08, 7.79008900e-08, 9.99999900e-01],\n",
       "       [1.76373620e-01, 8.22217460e-01, 1.40885260e-03],\n",
       "       [7.89520200e-08, 7.79008900e-08, 9.99999900e-01],\n",
       "       [7.89520200e-08, 7.79008900e-08, 9.99999900e-01],\n",
       "       [7.37716300e-02, 9.26214200e-01, 1.41051960e-05],\n",
       "       [6.80422370e-01, 3.19210140e-01, 3.67549800e-04],\n",
       "       [9.99996400e-01, 3.41148960e-06, 1.69060570e-07],\n",
       "       [7.89520200e-08, 7.79008900e-08, 9.99999900e-01],\n",
       "       [4.03900620e-01, 5.96099400e-01, 9.24676000e-11],\n",
       "       [7.89520200e-08, 7.79008900e-08, 9.99999900e-01],\n",
       "       [7.42901800e-08, 6.77153000e-08, 9.99999900e-01],\n",
       "       [2.94337270e-01, 7.05662550e-01, 1.32387630e-07],\n",
       "       [7.42901800e-08, 6.77153000e-08, 9.99999900e-01],\n",
       "       [3.70448680e-02, 9.62953600e-01, 1.53086330e-06],\n",
       "       [1.00000000e+00, 1.11080620e-10, 6.31283100e-12],\n",
       "       [8.05826040e-02, 9.18978330e-01, 4.39101630e-04],\n",
       "       [9.97413600e-01, 2.58335470e-03, 3.04611510e-06],\n",
       "       [7.42901800e-08, 6.77153000e-08, 9.99999900e-01],\n",
       "       [7.42901800e-08, 6.77153000e-08, 9.99999900e-01],\n",
       "       [7.42901800e-08, 6.77153000e-08, 9.99999900e-01],\n",
       "       [9.99999900e-01, 8.75925040e-08, 1.65928420e-10],\n",
       "       [1.00000000e+00, 7.46118900e-10, 1.76562360e-12],\n",
       "       [2.94337270e-01, 7.05662550e-01, 1.32387630e-07],\n",
       "       [1.00000000e+00, 1.94682870e-09, 4.91545100e-09],\n",
       "       [7.42901800e-08, 6.77153000e-08, 9.99999900e-01],\n",
       "       [8.90222430e-01, 1.09776355e-01, 1.16060600e-06],\n",
       "       [1.00000000e+00, 3.11236180e-11, 5.54551200e-13],\n",
       "       [5.71081400e-03, 9.93943630e-01, 3.45455480e-04],\n",
       "       [1.00000000e+00, 8.72081300e-11, 1.64962970e-12],\n",
       "       [4.08597960e-09, 1.00000000e+00, 5.30798600e-11],\n",
       "       [7.89520200e-08, 7.79008900e-08, 9.99999900e-01],\n",
       "       [9.16748170e-01, 8.32428200e-02, 8.98597800e-06],\n",
       "       [7.89520200e-08, 7.79008900e-08, 9.99999900e-01],\n",
       "       [7.40222900e-08, 9.99999900e-01, 5.13873070e-08],\n",
       "       [8.67311000e-01, 1.32679980e-01, 8.97926100e-06],\n",
       "       [2.71829000e-01, 7.28164260e-01, 6.78472200e-06],\n",
       "       [9.99999900e-01, 8.10569700e-08, 1.25824240e-10],\n",
       "       [4.67523900e-02, 9.53229800e-01, 1.77950330e-05],\n",
       "       [9.98727500e-01, 1.27249720e-03, 1.17512050e-14],\n",
       "       [5.71081400e-03, 9.93943630e-01, 3.45455480e-04],\n",
       "       [7.89520200e-08, 7.79008900e-08, 9.99999900e-01],\n",
       "       [8.00483000e-01, 1.99488940e-01, 2.80402700e-05],\n",
       "       [1.00085534e-01, 8.99912500e-01, 1.98005750e-06],\n",
       "       [7.42901800e-08, 6.77153000e-08, 9.99999900e-01],\n",
       "       [9.99999900e-01, 1.36862250e-07, 1.23281960e-09],\n",
       "       [1.00000000e+00, 4.93163450e-08, 3.89338260e-10],\n",
       "       [1.00000000e+00, 1.04416680e-10, 2.17756210e-11],\n",
       "       [7.89520200e-08, 7.79008900e-08, 9.99999900e-01],\n",
       "       [8.33406740e-05, 9.99916550e-01, 7.52781200e-08],\n",
       "       [5.09788400e-02, 9.49020560e-01, 5.65980100e-07],\n",
       "       [7.89520200e-08, 7.79008900e-08, 9.99999900e-01],\n",
       "       [6.68401300e-02, 9.33159900e-01, 2.40770050e-08],\n",
       "       [4.11144300e-01, 5.88854850e-01, 9.21732240e-07],\n",
       "       [1.35006860e-01, 8.64992000e-01, 1.18251230e-06],\n",
       "       [5.33827320e-02, 9.46516340e-01, 1.00984595e-04],\n",
       "       [9.96140300e-01, 3.85922050e-03, 4.69096050e-07],\n",
       "       [2.19207020e-01, 7.80768630e-01, 2.44166860e-05],\n",
       "       [9.97576800e-01, 2.42309670e-03, 6.29556500e-08],\n",
       "       [8.64600500e-01, 1.35381820e-01, 1.77604650e-05],\n",
       "       [7.89520200e-08, 7.79008900e-08, 9.99999900e-01],\n",
       "       [7.42901800e-08, 6.77153000e-08, 9.99999900e-01],\n",
       "       [1.64134030e-09, 1.00000000e+00, 1.19706610e-09],\n",
       "       [1.00000000e+00, 7.44566850e-09, 3.48764840e-11],\n",
       "       [7.89520200e-08, 7.79008900e-08, 9.99999900e-01],\n",
       "       [2.98594540e-03, 9.97013330e-01, 6.88324630e-07],\n",
       "       [9.97002800e-01, 2.99692570e-03, 2.46536930e-07],\n",
       "       [1.79765520e-02, 9.82016860e-01, 6.50265160e-06],\n",
       "       [7.89520200e-08, 7.79008900e-08, 9.99999900e-01],\n",
       "       [7.89520200e-08, 7.79008900e-08, 9.99999900e-01],\n",
       "       [7.42901800e-08, 6.77153000e-08, 9.99999900e-01],\n",
       "       [9.99558600e-01, 4.40888600e-04, 4.69151560e-07],\n",
       "       [5.10250150e-01, 4.89745900e-01, 3.97114000e-06],\n",
       "       [7.42901800e-08, 6.77153000e-08, 9.99999900e-01],\n",
       "       [1.27348400e-05, 9.99982600e-01, 4.63852170e-06],\n",
       "       [7.89520200e-08, 7.79008900e-08, 9.99999900e-01],\n",
       "       [7.89520200e-08, 7.79008900e-08, 9.99999900e-01],\n",
       "       [3.54059560e-02, 9.51866000e-01, 1.27281210e-02],\n",
       "       [7.42901800e-08, 6.77153000e-08, 9.99999900e-01],\n",
       "       [7.42901800e-08, 6.77153000e-08, 9.99999900e-01],\n",
       "       [7.85957500e-01, 2.13978710e-01, 6.36844100e-05],\n",
       "       [9.91623800e-01, 8.37358300e-03, 2.54658970e-06],\n",
       "       [9.90346700e-01, 9.65323000e-03, 8.28740500e-08],\n",
       "       [7.42901800e-08, 6.77153000e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 1.44572170e-11, 1.34050700e-13],\n",
       "       [9.98969300e-01, 1.03038700e-03, 3.17947580e-07],\n",
       "       [7.89520200e-08, 7.79008900e-08, 9.99999900e-01],\n",
       "       [7.40222900e-08, 9.99999900e-01, 5.13873070e-08],\n",
       "       [5.71081400e-03, 9.93943630e-01, 3.45455480e-04],\n",
       "       [2.71829000e-01, 7.28164260e-01, 6.78472200e-06],\n",
       "       [9.44512370e-01, 5.54876550e-02, 5.18920200e-08],\n",
       "       [9.99999900e-01, 8.10569700e-08, 1.25824240e-10],\n",
       "       [6.80477860e-01, 3.19491800e-01, 3.03344190e-05],\n",
       "       [7.42901800e-08, 6.77153000e-08, 9.99999900e-01],\n",
       "       [1.76112700e-02, 9.82385600e-01, 3.15351500e-06],\n",
       "       [4.08597960e-09, 1.00000000e+00, 5.30798600e-11],\n",
       "       [9.99619840e-01, 3.80185080e-04, 1.88310520e-08],\n",
       "       [9.97002800e-01, 2.99692570e-03, 2.46536930e-07],\n",
       "       [4.08597960e-09, 1.00000000e+00, 5.30798600e-11],\n",
       "       [7.42901800e-08, 6.77153000e-08, 9.99999900e-01],\n",
       "       [4.11144300e-01, 5.88854850e-01, 9.21732240e-07],\n",
       "       [8.05826040e-02, 9.18978330e-01, 4.39101630e-04],\n",
       "       [1.00000000e+00, 4.70912060e-08, 1.38394020e-10],\n",
       "       [7.42901800e-08, 6.77153000e-08, 9.99999900e-01],\n",
       "       [9.16748170e-01, 8.32428200e-02, 8.98597800e-06],\n",
       "       [7.89520200e-08, 7.79008900e-08, 9.99999900e-01],\n",
       "       [4.08597960e-09, 1.00000000e+00, 5.30798600e-11],\n",
       "       [5.10250150e-01, 4.89745900e-01, 3.97114000e-06],\n",
       "       [7.89520200e-08, 7.79008900e-08, 9.99999900e-01],\n",
       "       [8.69023700e-01, 1.30974170e-01, 2.20921950e-06],\n",
       "       [3.54059560e-02, 9.51866000e-01, 1.27281210e-02],\n",
       "       [7.42901800e-08, 6.77153000e-08, 9.99999900e-01],\n",
       "       [3.11494570e-03, 9.96884900e-01, 6.33078900e-08],\n",
       "       [9.86452340e-01, 4.97536800e-05, 1.34979920e-02]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob7 = df_proba7[df_proba7['phage']=='p0017SpresabsSTCC_qual'].iloc[:,-3:]\n",
    "y_prob7 = y_prob7.to_numpy()\n",
    "y_prob7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.968836291913215"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo7 = rocauc_ovo(y_test_over, y_prob7, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.968836291913215"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr7 = rocauc_ovr(y_test_over, y_prob7, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=890,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat8 = pd.DataFrame(X_test_over[:,0])\n",
    "dat8['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS255</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS119</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS071</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS002</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>CFBRSa30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>NRS383</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>NRS110</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>NY439</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0  test\n",
       "0      NRS209     2\n",
       "1      NRS255     1\n",
       "2      NRS119     0\n",
       "3      NRS071     0\n",
       "4      NRS002     0\n",
       "..        ...   ...\n",
       "190  CFBRSa30     0\n",
       "191    NRS383     1\n",
       "192    NRS110     2\n",
       "193    NRS209     2\n",
       "194     NY439     0\n",
       "\n",
       "[195 rows x 2 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over8 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],), activity_regularizer=l1(0.001)),\n",
    "    Dense(3, activation='softmax'),\n",
    "    Dropout(0.2, ),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over8.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 453 samples, validate on 195 samples\n",
      "Epoch 1/100\n",
      "453/453 [==============================] - 0s 634us/step - loss: 9.3642 - accuracy: 0.3709 - val_loss: 8.2229 - val_accuracy: 0.5077\n",
      "Epoch 2/100\n",
      "453/453 [==============================] - 0s 106us/step - loss: 7.8240 - accuracy: 0.4746 - val_loss: 6.6678 - val_accuracy: 0.5385\n",
      "Epoch 3/100\n",
      "453/453 [==============================] - 0s 155us/step - loss: 6.8921 - accuracy: 0.5033 - val_loss: 5.5176 - val_accuracy: 0.5692\n",
      "Epoch 4/100\n",
      "453/453 [==============================] - 0s 158us/step - loss: 5.9287 - accuracy: 0.5563 - val_loss: 4.2639 - val_accuracy: 0.6359\n",
      "Epoch 5/100\n",
      "453/453 [==============================] - 0s 182us/step - loss: 5.4087 - accuracy: 0.6137 - val_loss: 2.8019 - val_accuracy: 0.7487\n",
      "Epoch 6/100\n",
      "453/453 [==============================] - 0s 252us/step - loss: 4.8944 - accuracy: 0.6247 - val_loss: 2.0542 - val_accuracy: 0.6872\n",
      "Epoch 7/100\n",
      "453/453 [==============================] - 0s 177us/step - loss: 4.2195 - accuracy: 0.6534 - val_loss: 1.5445 - val_accuracy: 0.7846\n",
      "Epoch 8/100\n",
      "453/453 [==============================] - 0s 118us/step - loss: 3.7770 - accuracy: 0.6512 - val_loss: 1.3765 - val_accuracy: 0.7333\n",
      "Epoch 9/100\n",
      "453/453 [==============================] - 0s 143us/step - loss: 3.5652 - accuracy: 0.6799 - val_loss: 1.2051 - val_accuracy: 0.6718\n",
      "Epoch 10/100\n",
      "453/453 [==============================] - 0s 199us/step - loss: 3.3172 - accuracy: 0.5960 - val_loss: 1.0981 - val_accuracy: 0.7949\n",
      "Epoch 11/100\n",
      "453/453 [==============================] - 0s 97us/step - loss: 3.5541 - accuracy: 0.6689 - val_loss: 0.9950 - val_accuracy: 0.7949\n",
      "Epoch 12/100\n",
      "453/453 [==============================] - 0s 85us/step - loss: 3.4386 - accuracy: 0.6689 - val_loss: 0.9783 - val_accuracy: 0.7846\n",
      "Epoch 13/100\n",
      "453/453 [==============================] - 0s 81us/step - loss: 3.8696 - accuracy: 0.6468 - val_loss: 0.9365 - val_accuracy: 0.8667\n",
      "Epoch 14/100\n",
      "453/453 [==============================] - 0s 85us/step - loss: 3.1135 - accuracy: 0.7196 - val_loss: 0.8571 - val_accuracy: 0.8564\n",
      "Epoch 15/100\n",
      "453/453 [==============================] - 0s 75us/step - loss: 3.1047 - accuracy: 0.7174 - val_loss: 0.7866 - val_accuracy: 0.8872\n",
      "Epoch 16/100\n",
      "453/453 [==============================] - 0s 92us/step - loss: 3.5622 - accuracy: 0.6667 - val_loss: 0.7835 - val_accuracy: 0.8205\n",
      "Epoch 17/100\n",
      "453/453 [==============================] - 0s 78us/step - loss: 2.9102 - accuracy: 0.6645 - val_loss: 0.8055 - val_accuracy: 0.8103\n",
      "Epoch 18/100\n",
      "453/453 [==============================] - 0s 93us/step - loss: 3.8436 - accuracy: 0.6313 - val_loss: 0.8115 - val_accuracy: 0.8256\n",
      "Epoch 19/100\n",
      "453/453 [==============================] - 0s 77us/step - loss: 2.9493 - accuracy: 0.6932 - val_loss: 0.7877 - val_accuracy: 0.8308\n",
      "Epoch 20/100\n",
      "453/453 [==============================] - 0s 116us/step - loss: 3.0387 - accuracy: 0.6865 - val_loss: 0.7877 - val_accuracy: 0.8103\n",
      "Epoch 21/100\n",
      "453/453 [==============================] - 0s 136us/step - loss: 3.1507 - accuracy: 0.6667 - val_loss: 0.7553 - val_accuracy: 0.8564\n",
      "Epoch 22/100\n",
      "453/453 [==============================] - 0s 121us/step - loss: 2.6866 - accuracy: 0.7064 - val_loss: 0.7333 - val_accuracy: 0.8308\n",
      "Epoch 23/100\n",
      "453/453 [==============================] - 0s 105us/step - loss: 3.2341 - accuracy: 0.6777 - val_loss: 0.7411 - val_accuracy: 0.8769\n",
      "Epoch 24/100\n",
      "453/453 [==============================] - 0s 103us/step - loss: 2.9861 - accuracy: 0.7064 - val_loss: 0.7267 - val_accuracy: 0.9179\n",
      "Epoch 25/100\n",
      "453/453 [==============================] - 0s 97us/step - loss: 2.8993 - accuracy: 0.7130 - val_loss: 0.7410 - val_accuracy: 0.8923\n",
      "Epoch 26/100\n",
      "453/453 [==============================] - 0s 113us/step - loss: 2.6969 - accuracy: 0.7263 - val_loss: 0.7069 - val_accuracy: 0.9128\n",
      "Epoch 27/100\n",
      "453/453 [==============================] - 0s 78us/step - loss: 2.8734 - accuracy: 0.7329 - val_loss: 0.7083 - val_accuracy: 0.8718\n",
      "Epoch 28/100\n",
      "453/453 [==============================] - 0s 79us/step - loss: 2.8579 - accuracy: 0.7263 - val_loss: 0.7284 - val_accuracy: 0.8923\n",
      "Epoch 29/100\n",
      "453/453 [==============================] - 0s 69us/step - loss: 2.5814 - accuracy: 0.7174 - val_loss: 0.8185 - val_accuracy: 0.8462\n",
      "Epoch 30/100\n",
      "453/453 [==============================] - 0s 71us/step - loss: 2.3519 - accuracy: 0.7373 - val_loss: 0.7064 - val_accuracy: 0.8923\n",
      "Epoch 31/100\n",
      "453/453 [==============================] - 0s 70us/step - loss: 3.0348 - accuracy: 0.7219 - val_loss: 0.7068 - val_accuracy: 0.8923\n",
      "Epoch 32/100\n",
      "453/453 [==============================] - 0s 77us/step - loss: 2.3159 - accuracy: 0.7616 - val_loss: 0.7146 - val_accuracy: 0.8718\n",
      "Epoch 33/100\n",
      "453/453 [==============================] - 0s 97us/step - loss: 2.6986 - accuracy: 0.7064 - val_loss: 0.6775 - val_accuracy: 0.8718\n",
      "Epoch 34/100\n",
      "453/453 [==============================] - 0s 107us/step - loss: 3.0400 - accuracy: 0.6976 - val_loss: 0.6777 - val_accuracy: 0.8821\n",
      "Epoch 35/100\n",
      "453/453 [==============================] - 0s 105us/step - loss: 2.3062 - accuracy: 0.7483 - val_loss: 0.6683 - val_accuracy: 0.8821\n",
      "Epoch 36/100\n",
      "453/453 [==============================] - 0s 125us/step - loss: 2.9314 - accuracy: 0.6711 - val_loss: 0.7042 - val_accuracy: 0.8667\n",
      "Epoch 37/100\n",
      "453/453 [==============================] - 0s 111us/step - loss: 2.6648 - accuracy: 0.7108 - val_loss: 0.6929 - val_accuracy: 0.8769\n",
      "Epoch 38/100\n",
      "453/453 [==============================] - 0s 106us/step - loss: 2.7693 - accuracy: 0.7174 - val_loss: 0.6711 - val_accuracy: 0.8667\n",
      "Epoch 39/100\n",
      "453/453 [==============================] - 0s 123us/step - loss: 2.7478 - accuracy: 0.7130 - val_loss: 0.6902 - val_accuracy: 0.8718\n",
      "Epoch 40/100\n",
      "453/453 [==============================] - 0s 109us/step - loss: 2.5797 - accuracy: 0.7263 - val_loss: 0.6865 - val_accuracy: 0.8974\n",
      "Epoch 41/100\n",
      "453/453 [==============================] - 0s 139us/step - loss: 2.5437 - accuracy: 0.7219 - val_loss: 0.6578 - val_accuracy: 0.9128\n",
      "Epoch 42/100\n",
      "453/453 [==============================] - 0s 145us/step - loss: 2.7691 - accuracy: 0.7241 - val_loss: 0.6517 - val_accuracy: 0.8974\n",
      "Epoch 43/100\n",
      "453/453 [==============================] - 0s 98us/step - loss: 2.9175 - accuracy: 0.6755 - val_loss: 0.7071 - val_accuracy: 0.8667\n",
      "Epoch 44/100\n",
      "453/453 [==============================] - 0s 72us/step - loss: 2.8937 - accuracy: 0.7042 - val_loss: 0.6928 - val_accuracy: 0.8769\n",
      "Epoch 45/100\n",
      "453/453 [==============================] - 0s 73us/step - loss: 2.3209 - accuracy: 0.7461 - val_loss: 0.6341 - val_accuracy: 0.9231\n",
      "Epoch 46/100\n",
      "453/453 [==============================] - 0s 70us/step - loss: 2.5449 - accuracy: 0.7307 - val_loss: 0.7032 - val_accuracy: 0.9026\n",
      "Epoch 47/100\n",
      "453/453 [==============================] - 0s 73us/step - loss: 2.3550 - accuracy: 0.7263 - val_loss: 0.6272 - val_accuracy: 0.9231\n",
      "Epoch 48/100\n",
      "453/453 [==============================] - 0s 98us/step - loss: 2.4403 - accuracy: 0.7064 - val_loss: 0.6584 - val_accuracy: 0.8974\n",
      "Epoch 49/100\n",
      "453/453 [==============================] - 0s 205us/step - loss: 2.8470 - accuracy: 0.6865 - val_loss: 0.7213 - val_accuracy: 0.8718\n",
      "Epoch 50/100\n",
      "453/453 [==============================] - 0s 338us/step - loss: 2.6169 - accuracy: 0.7152 - val_loss: 0.6754 - val_accuracy: 0.9385\n",
      "Epoch 51/100\n",
      "453/453 [==============================] - 0s 197us/step - loss: 2.4584 - accuracy: 0.7152 - val_loss: 0.6145 - val_accuracy: 0.9282\n",
      "Epoch 52/100\n",
      "453/453 [==============================] - 0s 168us/step - loss: 2.5601 - accuracy: 0.7174 - val_loss: 0.6827 - val_accuracy: 0.8974\n",
      "Epoch 53/100\n",
      "453/453 [==============================] - 0s 95us/step - loss: 2.4238 - accuracy: 0.7682 - val_loss: 0.6338 - val_accuracy: 0.8923\n",
      "Epoch 54/100\n",
      "453/453 [==============================] - 0s 176us/step - loss: 2.5144 - accuracy: 0.7064 - val_loss: 0.6134 - val_accuracy: 0.9077\n",
      "Epoch 55/100\n",
      "453/453 [==============================] - 0s 214us/step - loss: 2.3759 - accuracy: 0.6954 - val_loss: 0.7181 - val_accuracy: 0.8667\n",
      "Epoch 56/100\n",
      "453/453 [==============================] - 0s 170us/step - loss: 2.4843 - accuracy: 0.7130 - val_loss: 0.6388 - val_accuracy: 0.8923\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 186us/step - loss: 2.7676 - accuracy: 0.6843 - val_loss: 0.6913 - val_accuracy: 0.8769\n",
      "Epoch 58/100\n",
      "453/453 [==============================] - 0s 150us/step - loss: 2.4750 - accuracy: 0.7241 - val_loss: 0.6360 - val_accuracy: 0.8974\n",
      "Epoch 59/100\n",
      "453/453 [==============================] - 0s 97us/step - loss: 2.0600 - accuracy: 0.7660 - val_loss: 0.6150 - val_accuracy: 0.8974\n",
      "Epoch 60/100\n",
      "453/453 [==============================] - 0s 122us/step - loss: 2.4241 - accuracy: 0.7395 - val_loss: 0.5947 - val_accuracy: 0.9231\n",
      "Epoch 61/100\n",
      "453/453 [==============================] - 0s 200us/step - loss: 2.1549 - accuracy: 0.7373 - val_loss: 0.5797 - val_accuracy: 0.9385\n",
      "Epoch 62/100\n",
      "453/453 [==============================] - 0s 209us/step - loss: 2.2881 - accuracy: 0.7572 - val_loss: 0.6496 - val_accuracy: 0.8923\n",
      "Epoch 63/100\n",
      "453/453 [==============================] - 0s 159us/step - loss: 2.2814 - accuracy: 0.7285 - val_loss: 0.6258 - val_accuracy: 0.8821\n",
      "Epoch 64/100\n",
      "453/453 [==============================] - 0s 210us/step - loss: 2.3840 - accuracy: 0.7329 - val_loss: 0.5744 - val_accuracy: 0.9231\n",
      "Epoch 65/100\n",
      "453/453 [==============================] - 0s 132us/step - loss: 2.5779 - accuracy: 0.7152 - val_loss: 0.6600 - val_accuracy: 0.8923\n",
      "Epoch 66/100\n",
      "453/453 [==============================] - 0s 88us/step - loss: 2.2558 - accuracy: 0.7351 - val_loss: 0.8942 - val_accuracy: 0.8718\n",
      "Epoch 67/100\n",
      "453/453 [==============================] - 0s 77us/step - loss: 2.4196 - accuracy: 0.7196 - val_loss: 0.7226 - val_accuracy: 0.8718\n",
      "Epoch 68/100\n",
      "453/453 [==============================] - 0s 188us/step - loss: 2.5687 - accuracy: 0.6909 - val_loss: 0.6240 - val_accuracy: 0.8821\n",
      "Epoch 69/100\n",
      "453/453 [==============================] - 0s 214us/step - loss: 2.0497 - accuracy: 0.7461 - val_loss: 0.5765 - val_accuracy: 0.9333\n",
      "Epoch 70/100\n",
      "453/453 [==============================] - 0s 158us/step - loss: 1.7916 - accuracy: 0.7792 - val_loss: 0.5516 - val_accuracy: 0.9231\n",
      "Epoch 71/100\n",
      "453/453 [==============================] - 0s 142us/step - loss: 2.1155 - accuracy: 0.7550 - val_loss: 0.5366 - val_accuracy: 0.9333\n",
      "Epoch 72/100\n",
      "453/453 [==============================] - 0s 82us/step - loss: 2.4601 - accuracy: 0.7108 - val_loss: 0.5540 - val_accuracy: 0.9538\n",
      "Epoch 73/100\n",
      "453/453 [==============================] - 0s 74us/step - loss: 2.0140 - accuracy: 0.7550 - val_loss: 0.5540 - val_accuracy: 0.9538\n",
      "Epoch 74/100\n",
      "453/453 [==============================] - 0s 71us/step - loss: 2.0189 - accuracy: 0.7572 - val_loss: 0.5945 - val_accuracy: 0.9385\n",
      "Epoch 75/100\n",
      "453/453 [==============================] - 0s 78us/step - loss: 2.1497 - accuracy: 0.7395 - val_loss: 0.5865 - val_accuracy: 0.9385\n",
      "Epoch 76/100\n",
      "453/453 [==============================] - 0s 74us/step - loss: 1.8202 - accuracy: 0.7881 - val_loss: 0.5537 - val_accuracy: 0.9385\n",
      "Epoch 77/100\n",
      "453/453 [==============================] - 0s 95us/step - loss: 1.9538 - accuracy: 0.7373 - val_loss: 0.5921 - val_accuracy: 0.9282\n",
      "Epoch 78/100\n",
      "453/453 [==============================] - 0s 178us/step - loss: 2.3753 - accuracy: 0.6998 - val_loss: 0.6745 - val_accuracy: 0.8667\n",
      "Epoch 79/100\n",
      "453/453 [==============================] - 0s 195us/step - loss: 1.7637 - accuracy: 0.7837 - val_loss: 0.5780 - val_accuracy: 0.9282\n",
      "Epoch 80/100\n",
      "453/453 [==============================] - 0s 125us/step - loss: 2.5331 - accuracy: 0.7329 - val_loss: 0.5977 - val_accuracy: 0.9385\n",
      "Epoch 81/100\n",
      "453/453 [==============================] - 0s 110us/step - loss: 2.1656 - accuracy: 0.7329 - val_loss: 0.6018 - val_accuracy: 0.9385\n",
      "Epoch 82/100\n",
      "453/453 [==============================] - 0s 117us/step - loss: 1.7918 - accuracy: 0.7550 - val_loss: 0.5947 - val_accuracy: 0.9179\n",
      "Epoch 83/100\n",
      "453/453 [==============================] - 0s 78us/step - loss: 2.0465 - accuracy: 0.7417 - val_loss: 0.5886 - val_accuracy: 0.9282\n",
      "Epoch 84/100\n",
      "453/453 [==============================] - 0s 83us/step - loss: 2.1102 - accuracy: 0.7461 - val_loss: 0.6763 - val_accuracy: 0.9282\n",
      "Epoch 85/100\n",
      "453/453 [==============================] - 0s 69us/step - loss: 2.0065 - accuracy: 0.7196 - val_loss: 0.6167 - val_accuracy: 0.9436\n",
      "Epoch 86/100\n",
      "453/453 [==============================] - 0s 81us/step - loss: 1.9257 - accuracy: 0.7395 - val_loss: 0.6270 - val_accuracy: 0.9385\n",
      "Epoch 87/100\n",
      "453/453 [==============================] - 0s 75us/step - loss: 1.8136 - accuracy: 0.7506 - val_loss: 0.6232 - val_accuracy: 0.9333\n",
      "Epoch 88/100\n",
      "453/453 [==============================] - 0s 76us/step - loss: 1.8605 - accuracy: 0.7660 - val_loss: 0.6192 - val_accuracy: 0.9026\n",
      "Epoch 89/100\n",
      "453/453 [==============================] - 0s 71us/step - loss: 2.1211 - accuracy: 0.7329 - val_loss: 0.5716 - val_accuracy: 0.9436\n",
      "Epoch 90/100\n",
      "453/453 [==============================] - 0s 83us/step - loss: 1.9157 - accuracy: 0.7572 - val_loss: 0.5811 - val_accuracy: 0.9436\n",
      "Epoch 91/100\n",
      "453/453 [==============================] - 0s 176us/step - loss: 1.4704 - accuracy: 0.7815 - val_loss: 0.6299 - val_accuracy: 0.9333\n",
      "Epoch 92/100\n",
      "453/453 [==============================] - 0s 282us/step - loss: 1.9413 - accuracy: 0.7461 - val_loss: 0.6060 - val_accuracy: 0.9385\n",
      "Epoch 93/100\n",
      "453/453 [==============================] - 0s 121us/step - loss: 1.8862 - accuracy: 0.7881 - val_loss: 0.5880 - val_accuracy: 0.9487\n",
      "Epoch 94/100\n",
      "453/453 [==============================] - 0s 107us/step - loss: 2.0275 - accuracy: 0.7550 - val_loss: 0.5756 - val_accuracy: 0.9231\n",
      "Epoch 95/100\n",
      "453/453 [==============================] - 0s 77us/step - loss: 2.0963 - accuracy: 0.7174 - val_loss: 0.7766 - val_accuracy: 0.8615\n",
      "Epoch 96/100\n",
      "453/453 [==============================] - 0s 79us/step - loss: 1.9163 - accuracy: 0.7329 - val_loss: 0.6404 - val_accuracy: 0.8872\n",
      "Epoch 97/100\n",
      "453/453 [==============================] - 0s 70us/step - loss: 1.7348 - accuracy: 0.7351 - val_loss: 0.6672 - val_accuracy: 0.9077\n",
      "Epoch 98/100\n",
      "453/453 [==============================] - 0s 108us/step - loss: 1.5003 - accuracy: 0.7638 - val_loss: 0.5964 - val_accuracy: 0.9333\n",
      "Epoch 99/100\n",
      "453/453 [==============================] - 0s 145us/step - loss: 1.9775 - accuracy: 0.7108 - val_loss: 0.6300 - val_accuracy: 0.9436\n",
      "Epoch 100/100\n",
      "453/453 [==============================] - 0s 95us/step - loss: 2.0922 - accuracy: 0.7461 - val_loss: 0.5900 - val_accuracy: 0.9538\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a37240828>"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over8.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195/195 [==============================] - 0s 51us/step\n",
      "over-sampling test accuracy: 91.79%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over8 = model1_over8.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over8*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 2, 1, 0, 0, 2, 2, 1, 0, 1, 2,\n",
       "       1, 0, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 0, 2, 1, 1, 2, 0,\n",
       "       2, 2, 0, 0, 2, 0, 0, 0, 0, 2, 0, 1, 2, 2, 1, 0, 0, 2, 1, 1, 2, 1,\n",
       "       0, 0, 1, 2, 0, 1, 2, 0, 1, 1, 0, 1, 2, 0, 1, 2, 2, 2, 1, 0, 1, 2,\n",
       "       2, 2, 2, 2, 2, 1, 1, 1, 2, 1, 2, 0, 0, 1, 1, 0, 1, 2, 2, 2, 1, 0,\n",
       "       0, 2, 1, 0, 0, 2, 1, 0, 2, 1, 0, 1, 2, 0, 1, 2, 1, 1, 0, 0, 0, 2,\n",
       "       2, 2, 2, 1, 1, 1, 1, 1, 0, 0, 2, 2, 0, 1, 2, 0, 1, 2, 2, 0, 2, 1,\n",
       "       0, 0, 1, 2, 1, 1, 0, 2, 2, 1, 1, 2, 2, 2, 1, 1, 0, 0, 2, 0, 2, 2,\n",
       "       1, 2, 1, 1, 0, 2, 1, 2, 1, 0, 0, 2, 1, 1, 0, 1, 2, 2, 0])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred8 = model1_over8.predict_classes(X_test_over)\n",
    "pred8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS255</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS119</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS071</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS002</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>CFBRSa30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>NRS383</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>NRS110</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>NY439</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0  test  pred\n",
       "0      NRS209     2     2\n",
       "1      NRS255     1     1\n",
       "2      NRS119     0     0\n",
       "3      NRS071     0     0\n",
       "4      NRS002     0     1\n",
       "..        ...   ...   ...\n",
       "190  CFBRSa30     0     0\n",
       "191    NRS383     1     1\n",
       "192    NRS110     2     2\n",
       "193    NRS209     2     2\n",
       "194     NY439     0     0\n",
       "\n",
       "[195 rows x 3 columns]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat8['pred'] = pred8\n",
    "dat8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba8 = model1_over8.predict_proba(X_test_over)\n",
    "dat_proba8 = pd.DataFrame(proba8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.839877e-06</td>\n",
       "      <td>4.253379e-07</td>\n",
       "      <td>9.999977e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.268283e-07</td>\n",
       "      <td>9.999995e-01</td>\n",
       "      <td>3.068627e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.579664e-01</td>\n",
       "      <td>4.170085e-02</td>\n",
       "      <td>3.327874e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.974597e-01</td>\n",
       "      <td>2.538614e-03</td>\n",
       "      <td>1.713039e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.087385e-02</td>\n",
       "      <td>9.791145e-01</td>\n",
       "      <td>1.152091e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>9.999975e-01</td>\n",
       "      <td>2.553651e-06</td>\n",
       "      <td>1.778455e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>6.077641e-02</td>\n",
       "      <td>9.384032e-01</td>\n",
       "      <td>8.203266e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>7.736103e-08</td>\n",
       "      <td>4.280218e-08</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>1.839877e-06</td>\n",
       "      <td>4.253379e-07</td>\n",
       "      <td>9.999977e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>9.995539e-01</td>\n",
       "      <td>4.461201e-04</td>\n",
       "      <td>3.227750e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0             1             2\n",
       "0    1.839877e-06  4.253379e-07  9.999977e-01\n",
       "1    4.268283e-07  9.999995e-01  3.068627e-08\n",
       "2    9.579664e-01  4.170085e-02  3.327874e-04\n",
       "3    9.974597e-01  2.538614e-03  1.713039e-06\n",
       "4    2.087385e-02  9.791145e-01  1.152091e-05\n",
       "..            ...           ...           ...\n",
       "190  9.999975e-01  2.553651e-06  1.778455e-09\n",
       "191  6.077641e-02  9.384032e-01  8.203266e-04\n",
       "192  7.736103e-08  4.280218e-08  9.999999e-01\n",
       "193  1.839877e-06  4.253379e-07  9.999977e-01\n",
       "194  9.995539e-01  4.461201e-04  3.227750e-08\n",
       "\n",
       "[195 rows x 3 columns]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba8.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba8.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat8.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/8p17spST.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 453 samples, validate on 195 samples\n",
      "Epoch 1/100\n",
      "453/453 [==============================] - 0s 129us/step - loss: 1.7257 - accuracy: 0.7594 - val_loss: 0.8542 - val_accuracy: 0.8872\n",
      "Epoch 2/100\n",
      "453/453 [==============================] - 0s 121us/step - loss: 1.9077 - accuracy: 0.7660 - val_loss: 0.8119 - val_accuracy: 0.8821\n",
      "Epoch 3/100\n",
      "453/453 [==============================] - 0s 114us/step - loss: 1.9186 - accuracy: 0.7196 - val_loss: 0.7299 - val_accuracy: 0.8821\n",
      "Epoch 4/100\n",
      "453/453 [==============================] - 0s 104us/step - loss: 1.8625 - accuracy: 0.7064 - val_loss: 0.6569 - val_accuracy: 0.9128\n",
      "Epoch 5/100\n",
      "453/453 [==============================] - 0s 104us/step - loss: 1.7785 - accuracy: 0.7616 - val_loss: 0.7111 - val_accuracy: 0.9128\n",
      "Epoch 6/100\n",
      "453/453 [==============================] - 0s 123us/step - loss: 1.8470 - accuracy: 0.7726 - val_loss: 0.7371 - val_accuracy: 0.9179\n",
      "Epoch 7/100\n",
      "453/453 [==============================] - 0s 107us/step - loss: 1.5629 - accuracy: 0.7660 - val_loss: 0.6720 - val_accuracy: 0.9231\n",
      "Epoch 8/100\n",
      "453/453 [==============================] - 0s 117us/step - loss: 1.8449 - accuracy: 0.7307 - val_loss: 0.7361 - val_accuracy: 0.9282\n",
      "Epoch 9/100\n",
      "453/453 [==============================] - 0s 107us/step - loss: 1.4287 - accuracy: 0.7550 - val_loss: 0.7202 - val_accuracy: 0.9282\n",
      "Epoch 10/100\n",
      "453/453 [==============================] - 0s 101us/step - loss: 1.8430 - accuracy: 0.7395 - val_loss: 0.6633 - val_accuracy: 0.9282\n",
      "Epoch 11/100\n",
      "453/453 [==============================] - 0s 124us/step - loss: 1.8435 - accuracy: 0.7042 - val_loss: 0.6745 - val_accuracy: 0.8974\n",
      "Epoch 12/100\n",
      "453/453 [==============================] - 0s 129us/step - loss: 1.6422 - accuracy: 0.7196 - val_loss: 0.7992 - val_accuracy: 0.9179\n",
      "Epoch 13/100\n",
      "453/453 [==============================] - 0s 125us/step - loss: 1.6989 - accuracy: 0.7307 - val_loss: 0.7720 - val_accuracy: 0.9128\n",
      "Epoch 14/100\n",
      "453/453 [==============================] - 0s 113us/step - loss: 1.6554 - accuracy: 0.7770 - val_loss: 0.7383 - val_accuracy: 0.9026\n",
      "Epoch 15/100\n",
      "453/453 [==============================] - 0s 107us/step - loss: 1.5780 - accuracy: 0.7351 - val_loss: 0.6928 - val_accuracy: 0.9128\n",
      "Epoch 16/100\n",
      "453/453 [==============================] - 0s 116us/step - loss: 1.4273 - accuracy: 0.7748 - val_loss: 0.6999 - val_accuracy: 0.9128\n",
      "Epoch 17/100\n",
      "453/453 [==============================] - 0s 133us/step - loss: 1.6694 - accuracy: 0.7528 - val_loss: 0.6641 - val_accuracy: 0.9077\n",
      "Epoch 18/100\n",
      "453/453 [==============================] - 0s 133us/step - loss: 1.6376 - accuracy: 0.7461 - val_loss: 0.6603 - val_accuracy: 0.9282\n",
      "Epoch 19/100\n",
      "453/453 [==============================] - 0s 125us/step - loss: 1.6438 - accuracy: 0.7528 - val_loss: 0.6893 - val_accuracy: 0.9128\n",
      "Epoch 20/100\n",
      "453/453 [==============================] - 0s 126us/step - loss: 1.6026 - accuracy: 0.7859 - val_loss: 0.6973 - val_accuracy: 0.9128\n",
      "Epoch 21/100\n",
      "453/453 [==============================] - 0s 108us/step - loss: 1.5715 - accuracy: 0.7483 - val_loss: 0.6713 - val_accuracy: 0.8974\n",
      "Epoch 22/100\n",
      "453/453 [==============================] - 0s 117us/step - loss: 1.4905 - accuracy: 0.7528 - val_loss: 0.6696 - val_accuracy: 0.8872\n",
      "Epoch 23/100\n",
      "453/453 [==============================] - 0s 108us/step - loss: 1.6045 - accuracy: 0.7660 - val_loss: 0.6345 - val_accuracy: 0.9179\n",
      "Epoch 24/100\n",
      "453/453 [==============================] - 0s 117us/step - loss: 1.4371 - accuracy: 0.7550 - val_loss: 0.6543 - val_accuracy: 0.9128\n",
      "Epoch 25/100\n",
      "453/453 [==============================] - 0s 115us/step - loss: 2.0051 - accuracy: 0.7241 - val_loss: 0.9885 - val_accuracy: 0.9385\n",
      "Epoch 26/100\n",
      "453/453 [==============================] - 0s 125us/step - loss: 1.9424 - accuracy: 0.7550 - val_loss: 0.9885 - val_accuracy: 0.9282\n",
      "Epoch 27/100\n",
      "453/453 [==============================] - 0s 122us/step - loss: 1.6600 - accuracy: 0.7594 - val_loss: 0.8566 - val_accuracy: 0.9231\n",
      "Epoch 28/100\n",
      "453/453 [==============================] - 0s 110us/step - loss: 1.6865 - accuracy: 0.7660 - val_loss: 0.6897 - val_accuracy: 0.9128\n",
      "Epoch 29/100\n",
      "453/453 [==============================] - 0s 113us/step - loss: 1.7975 - accuracy: 0.7417 - val_loss: 0.8187 - val_accuracy: 0.9282\n",
      "Epoch 30/100\n",
      "453/453 [==============================] - 0s 117us/step - loss: 1.5419 - accuracy: 0.7792 - val_loss: 0.7683 - val_accuracy: 0.8974\n",
      "Epoch 31/100\n",
      "453/453 [==============================] - 0s 105us/step - loss: 1.5652 - accuracy: 0.7439 - val_loss: 0.6350 - val_accuracy: 0.8974\n",
      "Epoch 32/100\n",
      "453/453 [==============================] - 0s 120us/step - loss: 1.6138 - accuracy: 0.7417 - val_loss: 0.6857 - val_accuracy: 0.9077\n",
      "Epoch 33/100\n",
      "453/453 [==============================] - 0s 112us/step - loss: 1.6144 - accuracy: 0.7550 - val_loss: 0.6580 - val_accuracy: 0.9179\n",
      "Epoch 34/100\n",
      "453/453 [==============================] - 0s 138us/step - loss: 1.6235 - accuracy: 0.7572 - val_loss: 0.6382 - val_accuracy: 0.9077\n",
      "Epoch 35/100\n",
      "453/453 [==============================] - 0s 99us/step - loss: 1.5023 - accuracy: 0.7285 - val_loss: 0.6690 - val_accuracy: 0.9179\n",
      "Epoch 36/100\n",
      "453/453 [==============================] - 0s 93us/step - loss: 1.6125 - accuracy: 0.7417 - val_loss: 0.6663 - val_accuracy: 0.9128\n",
      "Epoch 37/100\n",
      "453/453 [==============================] - 0s 100us/step - loss: 1.5416 - accuracy: 0.7152 - val_loss: 0.6860 - val_accuracy: 0.9128\n",
      "Epoch 38/100\n",
      "453/453 [==============================] - 0s 87us/step - loss: 1.5375 - accuracy: 0.7395 - val_loss: 0.6868 - val_accuracy: 0.9026\n",
      "Epoch 39/100\n",
      "453/453 [==============================] - 0s 87us/step - loss: 1.4913 - accuracy: 0.7461 - val_loss: 0.6436 - val_accuracy: 0.9231\n",
      "Epoch 40/100\n",
      "453/453 [==============================] - 0s 86us/step - loss: 1.4755 - accuracy: 0.7726 - val_loss: 0.6829 - val_accuracy: 0.9128\n",
      "Epoch 41/100\n",
      "453/453 [==============================] - 0s 82us/step - loss: 1.4621 - accuracy: 0.7439 - val_loss: 0.5927 - val_accuracy: 0.9077\n",
      "Epoch 42/100\n",
      "453/453 [==============================] - 0s 103us/step - loss: 1.3628 - accuracy: 0.7925 - val_loss: 0.6315 - val_accuracy: 0.9231\n",
      "Epoch 43/100\n",
      "453/453 [==============================] - 0s 115us/step - loss: 1.6587 - accuracy: 0.7020 - val_loss: 0.7224 - val_accuracy: 0.9077\n",
      "Epoch 44/100\n",
      "453/453 [==============================] - 0s 103us/step - loss: 1.6771 - accuracy: 0.7528 - val_loss: 0.8831 - val_accuracy: 0.9128\n",
      "Epoch 45/100\n",
      "453/453 [==============================] - 0s 93us/step - loss: 1.5107 - accuracy: 0.7616 - val_loss: 0.8539 - val_accuracy: 0.9179\n",
      "Epoch 46/100\n",
      "453/453 [==============================] - 0s 92us/step - loss: 1.5718 - accuracy: 0.7726 - val_loss: 0.6220 - val_accuracy: 0.9231\n",
      "Epoch 47/100\n",
      "453/453 [==============================] - 0s 88us/step - loss: 1.3139 - accuracy: 0.7770 - val_loss: 0.6840 - val_accuracy: 0.9282\n",
      "Epoch 48/100\n",
      "453/453 [==============================] - 0s 97us/step - loss: 1.1638 - accuracy: 0.7748 - val_loss: 0.5907 - val_accuracy: 0.8974\n",
      "Epoch 49/100\n",
      "453/453 [==============================] - 0s 106us/step - loss: 1.2986 - accuracy: 0.7815 - val_loss: 0.6044 - val_accuracy: 0.9128\n",
      "Epoch 50/100\n",
      "453/453 [==============================] - 0s 103us/step - loss: 1.6378 - accuracy: 0.7439 - val_loss: 0.6501 - val_accuracy: 0.9231\n",
      "Epoch 51/100\n",
      "453/453 [==============================] - 0s 109us/step - loss: 1.6622 - accuracy: 0.7351 - val_loss: 0.6407 - val_accuracy: 0.9026\n",
      "Epoch 52/100\n",
      "453/453 [==============================] - 0s 118us/step - loss: 1.2835 - accuracy: 0.7925 - val_loss: 0.6068 - val_accuracy: 0.8923\n",
      "Epoch 53/100\n",
      "453/453 [==============================] - 0s 112us/step - loss: 1.5732 - accuracy: 0.7550 - val_loss: 0.6367 - val_accuracy: 0.9128\n",
      "Epoch 54/100\n",
      "453/453 [==============================] - 0s 100us/step - loss: 1.5450 - accuracy: 0.7506 - val_loss: 0.6839 - val_accuracy: 0.8974\n",
      "Epoch 55/100\n",
      "453/453 [==============================] - 0s 87us/step - loss: 1.7111 - accuracy: 0.7219 - val_loss: 0.6427 - val_accuracy: 0.9128\n",
      "Epoch 56/100\n",
      "453/453 [==============================] - 0s 106us/step - loss: 1.5748 - accuracy: 0.7263 - val_loss: 0.6233 - val_accuracy: 0.9282\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "453/453 [==============================] - 0s 105us/step - loss: 1.2419 - accuracy: 0.7572 - val_loss: 0.5781 - val_accuracy: 0.9128\n",
      "Epoch 58/100\n",
      "453/453 [==============================] - 0s 99us/step - loss: 1.3725 - accuracy: 0.7572 - val_loss: 0.5665 - val_accuracy: 0.9026\n",
      "Epoch 59/100\n",
      "453/453 [==============================] - 0s 108us/step - loss: 1.5217 - accuracy: 0.7483 - val_loss: 0.5750 - val_accuracy: 0.9128\n",
      "Epoch 60/100\n",
      "453/453 [==============================] - 0s 121us/step - loss: 1.2561 - accuracy: 0.7660 - val_loss: 0.5933 - val_accuracy: 0.9333\n",
      "Epoch 61/100\n",
      "453/453 [==============================] - 0s 110us/step - loss: 1.6316 - accuracy: 0.7395 - val_loss: 0.6002 - val_accuracy: 0.9179\n",
      "Epoch 62/100\n",
      "453/453 [==============================] - 0s 87us/step - loss: 1.6017 - accuracy: 0.7373 - val_loss: 0.5768 - val_accuracy: 0.9026\n",
      "Epoch 63/100\n",
      "453/453 [==============================] - 0s 93us/step - loss: 1.4606 - accuracy: 0.7528 - val_loss: 0.6490 - val_accuracy: 0.9179\n",
      "Epoch 64/100\n",
      "453/453 [==============================] - 0s 98us/step - loss: 1.4776 - accuracy: 0.7550 - val_loss: 0.6658 - val_accuracy: 0.9179\n",
      "Epoch 65/100\n",
      "453/453 [==============================] - 0s 87us/step - loss: 1.5570 - accuracy: 0.7506 - val_loss: 0.6288 - val_accuracy: 0.9128\n",
      "Epoch 66/100\n",
      "453/453 [==============================] - 0s 104us/step - loss: 1.3398 - accuracy: 0.7550 - val_loss: 0.5701 - val_accuracy: 0.9231\n",
      "Epoch 67/100\n",
      "453/453 [==============================] - 0s 85us/step - loss: 1.5590 - accuracy: 0.7704 - val_loss: 0.7354 - val_accuracy: 0.9333\n",
      "Epoch 68/100\n",
      "453/453 [==============================] - 0s 84us/step - loss: 1.4674 - accuracy: 0.7594 - val_loss: 0.6258 - val_accuracy: 0.9128\n",
      "Epoch 69/100\n",
      "453/453 [==============================] - 0s 87us/step - loss: 1.5652 - accuracy: 0.7572 - val_loss: 0.6570 - val_accuracy: 0.9128\n",
      "Epoch 70/100\n",
      "453/453 [==============================] - 0s 93us/step - loss: 1.4105 - accuracy: 0.7439 - val_loss: 0.6259 - val_accuracy: 0.9128\n",
      "Epoch 71/100\n",
      "453/453 [==============================] - 0s 104us/step - loss: 1.4229 - accuracy: 0.7638 - val_loss: 0.5681 - val_accuracy: 0.9231\n",
      "Epoch 72/100\n",
      "453/453 [==============================] - 0s 152us/step - loss: 1.5637 - accuracy: 0.7373 - val_loss: 0.6810 - val_accuracy: 0.8718\n",
      "Epoch 73/100\n",
      "453/453 [==============================] - 0s 326us/step - loss: 1.5183 - accuracy: 0.7329 - val_loss: 0.6019 - val_accuracy: 0.9128\n",
      "Epoch 74/100\n",
      "453/453 [==============================] - 0s 189us/step - loss: 1.6716 - accuracy: 0.7439 - val_loss: 0.7575 - val_accuracy: 0.9179\n",
      "Epoch 75/100\n",
      "453/453 [==============================] - 0s 116us/step - loss: 1.6425 - accuracy: 0.7483 - val_loss: 0.6791 - val_accuracy: 0.9077\n",
      "Epoch 76/100\n",
      "453/453 [==============================] - 0s 130us/step - loss: 1.4064 - accuracy: 0.7307 - val_loss: 0.6235 - val_accuracy: 0.9179\n",
      "Epoch 77/100\n",
      "453/453 [==============================] - 0s 119us/step - loss: 1.6667 - accuracy: 0.7329 - val_loss: 0.6896 - val_accuracy: 0.9333\n",
      "Epoch 78/100\n",
      "453/453 [==============================] - 0s 121us/step - loss: 1.3890 - accuracy: 0.7748 - val_loss: 0.6746 - val_accuracy: 0.9179\n",
      "Epoch 79/100\n",
      "453/453 [==============================] - 0s 134us/step - loss: 1.5835 - accuracy: 0.7086 - val_loss: 0.6269 - val_accuracy: 0.9179\n",
      "Epoch 80/100\n",
      "453/453 [==============================] - 0s 137us/step - loss: 1.5687 - accuracy: 0.7329 - val_loss: 0.5951 - val_accuracy: 0.9282\n",
      "Epoch 81/100\n",
      "453/453 [==============================] - 0s 457us/step - loss: 1.5379 - accuracy: 0.7196 - val_loss: 0.5734 - val_accuracy: 0.9231\n",
      "Epoch 82/100\n",
      "453/453 [==============================] - 0s 141us/step - loss: 1.2334 - accuracy: 0.7682 - val_loss: 0.7732 - val_accuracy: 0.9333\n",
      "Epoch 83/100\n",
      "453/453 [==============================] - 0s 184us/step - loss: 1.7336 - accuracy: 0.7704 - val_loss: 0.7509 - val_accuracy: 0.9333\n",
      "Epoch 84/100\n",
      "453/453 [==============================] - 0s 404us/step - loss: 1.2623 - accuracy: 0.7770 - val_loss: 0.8830 - val_accuracy: 0.9077\n",
      "Epoch 85/100\n",
      "453/453 [==============================] - 0s 224us/step - loss: 1.4088 - accuracy: 0.7417 - val_loss: 0.5486 - val_accuracy: 0.9077\n",
      "Epoch 86/100\n",
      "453/453 [==============================] - 0s 135us/step - loss: 1.5144 - accuracy: 0.7506 - val_loss: 0.7207 - val_accuracy: 0.9282\n",
      "Epoch 87/100\n",
      "453/453 [==============================] - 0s 109us/step - loss: 1.4739 - accuracy: 0.7550 - val_loss: 0.8160 - val_accuracy: 0.9282\n",
      "Epoch 88/100\n",
      "453/453 [==============================] - 0s 112us/step - loss: 1.3088 - accuracy: 0.7792 - val_loss: 0.6026 - val_accuracy: 0.9231\n",
      "Epoch 89/100\n",
      "453/453 [==============================] - 0s 100us/step - loss: 1.4969 - accuracy: 0.7506 - val_loss: 0.8139 - val_accuracy: 0.9282\n",
      "Epoch 90/100\n",
      "453/453 [==============================] - 0s 105us/step - loss: 1.6177 - accuracy: 0.7351 - val_loss: 0.7636 - val_accuracy: 0.9128\n",
      "Epoch 91/100\n",
      "453/453 [==============================] - 0s 106us/step - loss: 1.1643 - accuracy: 0.7638 - val_loss: 0.6834 - val_accuracy: 0.9282\n",
      "Epoch 92/100\n",
      "453/453 [==============================] - 0s 112us/step - loss: 1.3347 - accuracy: 0.7528 - val_loss: 0.6229 - val_accuracy: 0.9231\n",
      "Epoch 93/100\n",
      "453/453 [==============================] - 0s 108us/step - loss: 1.1750 - accuracy: 0.7859 - val_loss: 0.6180 - val_accuracy: 0.9231\n",
      "Epoch 94/100\n",
      "453/453 [==============================] - 0s 112us/step - loss: 1.1024 - accuracy: 0.7991 - val_loss: 0.5216 - val_accuracy: 0.9333\n",
      "Epoch 95/100\n",
      "453/453 [==============================] - 0s 110us/step - loss: 1.1696 - accuracy: 0.7792 - val_loss: 0.6102 - val_accuracy: 0.9282\n",
      "Epoch 96/100\n",
      "453/453 [==============================] - 0s 96us/step - loss: 1.4381 - accuracy: 0.7815 - val_loss: 0.5703 - val_accuracy: 0.9231\n",
      "Epoch 97/100\n",
      "453/453 [==============================] - 0s 96us/step - loss: 1.3904 - accuracy: 0.7638 - val_loss: 0.5120 - val_accuracy: 0.9282\n",
      "Epoch 98/100\n",
      "453/453 [==============================] - 0s 104us/step - loss: 1.1930 - accuracy: 0.7881 - val_loss: 0.5495 - val_accuracy: 0.9231\n",
      "Epoch 99/100\n",
      "453/453 [==============================] - 0s 208us/step - loss: 1.3076 - accuracy: 0.7682 - val_loss: 0.5921 - val_accuracy: 0.9487\n",
      "Epoch 100/100\n",
      "453/453 [==============================] - 0s 214us/step - loss: 1.1296 - accuracy: 0.8035 - val_loss: 0.6872 - val_accuracy: 0.9333\n"
     ]
    }
   ],
   "source": [
    "hist1_over8 = model1_over8.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 75.32%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over8.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba8 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_regularizor_dropout_2.xlsx\",\n",
    "                        sheet_name=3,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>CFBREBSa116</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.676203e-01</td>\n",
       "      <td>3.237956e-02</td>\n",
       "      <td>1.480166e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS214</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>6.534852e-11</td>\n",
       "      <td>2.250731e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.948571e-11</td>\n",
       "      <td>2.839096e-07</td>\n",
       "      <td>9.999998e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.948571e-11</td>\n",
       "      <td>2.839096e-07</td>\n",
       "      <td>9.999998e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.948571e-11</td>\n",
       "      <td>2.839096e-07</td>\n",
       "      <td>9.999998e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS205</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.691095e-08</td>\n",
       "      <td>3.571927e-08</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>CFBREBSa122</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.261665e-02</td>\n",
       "      <td>9.073822e-01</td>\n",
       "      <td>1.162373e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.174278e-07</td>\n",
       "      <td>9.999995e-01</td>\n",
       "      <td>3.254024e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.234670e-08</td>\n",
       "      <td>3.121212e-08</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS265</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.250178e-08</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>6.719974e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1982 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       phage       strain  phenotype  prediction  \\\n",
       "0     p002ykpresabsSTCC_qual  CFBREBSa116          0           0   \n",
       "1     p002ykpresabsSTCC_qual       NRS214          0           0   \n",
       "2     p002ykpresabsSTCC_qual       NRS148          2           2   \n",
       "3     p002ykpresabsSTCC_qual       NRS148          2           2   \n",
       "4     p002ykpresabsSTCC_qual       NRS148          2           2   \n",
       "...                      ...          ...        ...         ...   \n",
       "1977     pyopresabsSTCC_qual       NRS205          2           2   \n",
       "1978     pyopresabsSTCC_qual  CFBREBSa122          0           1   \n",
       "1979     pyopresabsSTCC_qual       NRS001          1           1   \n",
       "1980     pyopresabsSTCC_qual       NRS148          2           2   \n",
       "1981     pyopresabsSTCC_qual       NRS265          1           1   \n",
       "\n",
       "                 0             1             2  \n",
       "0     9.676203e-01  3.237956e-02  1.480166e-07  \n",
       "1     1.000000e+00  6.534852e-11  2.250731e-18  \n",
       "2     3.948571e-11  2.839096e-07  9.999998e-01  \n",
       "3     3.948571e-11  2.839096e-07  9.999998e-01  \n",
       "4     3.948571e-11  2.839096e-07  9.999998e-01  \n",
       "...            ...           ...           ...  \n",
       "1977  3.691095e-08  3.571927e-08  9.999999e-01  \n",
       "1978  9.261665e-02  9.073822e-01  1.162373e-06  \n",
       "1979  4.174278e-07  9.999995e-01  3.254024e-09  \n",
       "1980  3.234670e-08  3.121212e-08  9.999999e-01  \n",
       "1981  5.250178e-08  9.999999e-01  6.719974e-08  \n",
       "\n",
       "[1982 rows x 7 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.83987700e-06, 4.25337900e-07, 9.99997740e-01],\n",
       "       [4.26828340e-07, 9.99999500e-01, 3.06862730e-08],\n",
       "       [9.57966400e-01, 4.17008500e-02, 3.32787430e-04],\n",
       "       [9.97459700e-01, 2.53861350e-03, 1.71303860e-06],\n",
       "       [2.08738500e-02, 9.79114530e-01, 1.15209150e-05],\n",
       "       [1.00000000e+00, 1.30497710e-08, 3.26204880e-12],\n",
       "       [1.00000000e+00, 2.24513270e-09, 7.68191900e-12],\n",
       "       [9.99999640e-01, 3.26373030e-07, 3.59689880e-09],\n",
       "       [9.81602900e-03, 9.90170660e-01, 1.33881870e-05],\n",
       "       [9.99949700e-01, 5.03017200e-05, 3.76725000e-10],\n",
       "       [7.35023200e-02, 9.26497460e-01, 2.03305620e-07],\n",
       "       [1.00000000e+00, 2.80718800e-10, 4.45458640e-12],\n",
       "       [1.83987700e-06, 4.25337900e-07, 9.99997740e-01],\n",
       "       [5.18638700e-09, 1.00000000e+00, 1.88011250e-09],\n",
       "       [9.99990460e-01, 9.44454600e-06, 6.42722000e-08],\n",
       "       [1.00000000e+00, 4.27983480e-08, 2.55972920e-11],\n",
       "       [7.73610300e-08, 4.28021800e-08, 9.99999900e-01],\n",
       "       [7.73610300e-08, 4.28021800e-08, 9.99999900e-01],\n",
       "       [4.23601980e-01, 5.76397500e-01, 4.96263340e-07],\n",
       "       [9.99998900e-01, 1.04168620e-06, 3.76421780e-10],\n",
       "       [6.33099500e-02, 9.36674540e-01, 1.54822210e-05],\n",
       "       [7.73610300e-08, 4.28021800e-08, 9.99999900e-01],\n",
       "       [7.28930970e-10, 1.00000000e+00, 1.13397885e-11],\n",
       "       [1.00000000e+00, 4.08176750e-08, 2.18739870e-11],\n",
       "       [7.94810500e-02, 9.20511540e-01, 7.34896800e-06],\n",
       "       [4.23601980e-01, 5.76397500e-01, 4.96263340e-07],\n",
       "       [7.73610300e-08, 4.28021800e-08, 9.99999900e-01],\n",
       "       [1.63381910e-09, 1.00000000e+00, 1.72418120e-11],\n",
       "       [7.73610300e-08, 4.28021800e-08, 9.99999900e-01],\n",
       "       [1.90557670e-01, 8.09442340e-01, 4.20075850e-08],\n",
       "       [2.71228620e-10, 1.00000000e+00, 1.13969240e-11],\n",
       "       [4.31116160e-01, 5.68883700e-01, 1.46856700e-07],\n",
       "       [7.54182800e-02, 9.24580630e-01, 1.06639020e-06],\n",
       "       [4.23601980e-01, 5.76397500e-01, 4.96263340e-07],\n",
       "       [3.83083340e-01, 6.16897900e-01, 1.87396650e-05],\n",
       "       [9.81602900e-03, 9.90170660e-01, 1.33881870e-05],\n",
       "       [1.83987700e-06, 4.25337900e-07, 9.99997740e-01],\n",
       "       [6.33099500e-02, 9.36674540e-01, 1.54822210e-05],\n",
       "       [9.99949700e-01, 5.03017200e-05, 3.76725000e-10],\n",
       "       [1.83987700e-06, 4.25337900e-07, 9.99997740e-01],\n",
       "       [9.71101200e-05, 9.99901900e-01, 9.99403000e-07],\n",
       "       [1.99124570e-01, 8.00852600e-01, 2.28262300e-05],\n",
       "       [7.73610300e-08, 4.28021800e-08, 9.99999900e-01],\n",
       "       [9.21472400e-01, 7.85264300e-02, 1.16746680e-06],\n",
       "       [1.83987700e-06, 4.25337900e-07, 9.99997740e-01],\n",
       "       [1.83987700e-06, 4.25337900e-07, 9.99997740e-01],\n",
       "       [1.00000000e+00, 2.59013860e-08, 2.27743900e-11],\n",
       "       [7.11388100e-01, 2.88601700e-01, 1.02852530e-05],\n",
       "       [7.73610300e-08, 4.28021800e-08, 9.99999900e-01],\n",
       "       [9.99994160e-01, 5.86715500e-06, 7.87296800e-10],\n",
       "       [8.68724400e-01, 1.31252420e-01, 2.31844460e-05],\n",
       "       [8.25014600e-01, 1.74552990e-01, 4.32429660e-04],\n",
       "       [9.99004300e-01, 9.95564000e-04, 6.25738500e-08],\n",
       "       [1.83987700e-06, 4.25337900e-07, 9.99997740e-01],\n",
       "       [9.28555550e-01, 7.14439300e-02, 5.64337650e-07],\n",
       "       [1.75673590e-01, 8.24313100e-01, 1.34122750e-05],\n",
       "       [1.83987700e-06, 4.25337900e-07, 9.99997740e-01],\n",
       "       [1.83987700e-06, 4.25337900e-07, 9.99997740e-01],\n",
       "       [1.77840380e-01, 8.22159500e-01, 7.21599400e-08],\n",
       "       [1.00000000e+00, 9.86631100e-10, 7.87384650e-12],\n",
       "       [7.19270650e-01, 2.79509930e-01, 1.21947410e-03],\n",
       "       [7.73610300e-08, 4.28021800e-08, 9.99999900e-01],\n",
       "       [6.07764120e-02, 9.38403250e-01, 8.20326560e-04],\n",
       "       [1.99124570e-01, 8.00852600e-01, 2.28262300e-05],\n",
       "       [1.83987700e-06, 4.25337900e-07, 9.99997740e-01],\n",
       "       [7.41332900e-02, 9.25866700e-01, 1.56989450e-09],\n",
       "       [9.85427700e-01, 1.45661830e-02, 6.12653280e-06],\n",
       "       [1.00000000e+00, 3.84534160e-12, 4.17467170e-14],\n",
       "       [2.47957380e-01, 7.52034960e-01, 7.63677700e-06],\n",
       "       [7.73610300e-08, 4.28021800e-08, 9.99999900e-01],\n",
       "       [6.65785300e-01, 3.34193260e-01, 2.14402520e-05],\n",
       "       [1.99461740e-01, 8.00530200e-01, 7.97413300e-06],\n",
       "       [1.83987700e-06, 4.25337900e-07, 9.99997740e-01],\n",
       "       [8.68583600e-01, 1.29513870e-01, 1.90248950e-03],\n",
       "       [4.31116160e-01, 5.68883700e-01, 1.46856700e-07],\n",
       "       [4.31116160e-01, 5.68883700e-01, 1.46856700e-07],\n",
       "       [9.98136500e-01, 1.86000260e-03, 3.43734450e-06],\n",
       "       [6.07764120e-02, 9.38403250e-01, 8.20326560e-04],\n",
       "       [7.73610300e-08, 4.28021800e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 1.26510270e-11, 7.70927200e-14],\n",
       "       [1.21476920e-02, 8.73762600e-01, 1.14089640e-01],\n",
       "       [7.73610300e-08, 4.28021800e-08, 9.99999900e-01],\n",
       "       [1.83987700e-06, 4.25337900e-07, 9.99997740e-01],\n",
       "       [1.83987700e-06, 4.25337900e-07, 9.99997740e-01],\n",
       "       [6.62159440e-05, 9.99929200e-01, 4.65310270e-06],\n",
       "       [9.99990940e-01, 9.10492000e-06, 1.83265190e-09],\n",
       "       [4.26828340e-07, 9.99999500e-01, 3.06862730e-08],\n",
       "       [7.73610300e-08, 4.28021800e-08, 9.99999900e-01],\n",
       "       [1.83987700e-06, 4.25337900e-07, 9.99997740e-01],\n",
       "       [1.83987700e-06, 4.25337900e-07, 9.99997740e-01],\n",
       "       [7.73610300e-08, 4.28021800e-08, 9.99999900e-01],\n",
       "       [1.83987700e-06, 4.25337900e-07, 9.99997740e-01],\n",
       "       [7.73610300e-08, 4.28021800e-08, 9.99999900e-01],\n",
       "       [7.94810500e-02, 9.20511540e-01, 7.34896800e-06],\n",
       "       [6.33099500e-02, 9.36674540e-01, 1.54822210e-05],\n",
       "       [4.26828340e-07, 9.99999500e-01, 3.06862730e-08],\n",
       "       [1.83987700e-06, 4.25337900e-07, 9.99997740e-01],\n",
       "       [3.06594980e-07, 9.99999640e-01, 6.56721880e-09],\n",
       "       [7.73610300e-08, 4.28021800e-08, 9.99999900e-01],\n",
       "       [9.99999900e-01, 7.06848500e-08, 4.29661430e-17],\n",
       "       [9.48701140e-01, 5.12988100e-02, 1.49362170e-07],\n",
       "       [1.29508590e-02, 9.86967150e-01, 8.19580900e-05],\n",
       "       [2.48529140e-01, 7.51461100e-01, 9.84607800e-06],\n",
       "       [9.79012850e-01, 2.09871440e-02, 8.52081250e-09],\n",
       "       [3.83083340e-01, 6.16897900e-01, 1.87396650e-05],\n",
       "       [7.73610300e-08, 4.28021800e-08, 9.99999900e-01],\n",
       "       [1.83987700e-06, 4.25337900e-07, 9.99997740e-01],\n",
       "       [1.83987700e-06, 4.25337900e-07, 9.99997740e-01],\n",
       "       [2.48529140e-01, 7.51461100e-01, 9.84607800e-06],\n",
       "       [9.99913700e-01, 8.62527000e-05, 8.31379600e-10],\n",
       "       [9.99547900e-01, 4.52038700e-04, 4.14933400e-09],\n",
       "       [7.73610300e-08, 4.28021800e-08, 9.99999900e-01],\n",
       "       [1.21476920e-02, 8.73762600e-01, 1.14089640e-01],\n",
       "       [9.99975300e-01, 2.46993170e-05, 6.96232700e-11],\n",
       "       [1.00000000e+00, 2.06249340e-14, 2.90219200e-18],\n",
       "       [1.83987700e-06, 4.25337900e-07, 9.99997740e-01],\n",
       "       [1.77840380e-01, 8.22159500e-01, 7.21599400e-08],\n",
       "       [1.00000000e+00, 2.92153100e-14, 7.98453500e-16],\n",
       "       [7.73610300e-08, 4.28021800e-08, 9.99999900e-01],\n",
       "       [1.75673590e-01, 8.24313100e-01, 1.34122750e-05],\n",
       "       [8.54023400e-01, 1.45971310e-01, 5.25101540e-06],\n",
       "       [5.18638700e-09, 1.00000000e+00, 1.88011250e-09],\n",
       "       [7.73610300e-08, 4.28021800e-08, 9.99999900e-01],\n",
       "       [9.99839540e-01, 1.60399980e-04, 2.98449880e-10],\n",
       "       [7.41332900e-02, 9.25866700e-01, 1.56989450e-09],\n",
       "       [1.83987700e-06, 4.25337900e-07, 9.99997740e-01],\n",
       "       [1.63381910e-09, 1.00000000e+00, 1.72418120e-11],\n",
       "       [3.83083340e-01, 6.16897900e-01, 1.87396650e-05],\n",
       "       [9.99999640e-01, 3.22278540e-07, 3.93333640e-10],\n",
       "       [5.91293500e-01, 4.08697070e-01, 9.45249600e-06],\n",
       "       [8.04885150e-01, 1.93917410e-01, 1.19747990e-03],\n",
       "       [1.83987700e-06, 4.25337900e-07, 9.99997740e-01],\n",
       "       [7.73610300e-08, 4.28021800e-08, 9.99999900e-01],\n",
       "       [7.73610300e-08, 4.28021800e-08, 9.99999900e-01],\n",
       "       [1.83987700e-06, 4.25337900e-07, 9.99997740e-01],\n",
       "       [2.48529140e-01, 7.51461100e-01, 9.84607800e-06],\n",
       "       [5.18638700e-09, 1.00000000e+00, 1.88011250e-09],\n",
       "       [1.77840380e-01, 8.22159500e-01, 7.21599400e-08],\n",
       "       [1.77840380e-01, 8.22159500e-01, 7.21599400e-08],\n",
       "       [2.84203350e-01, 7.15775800e-01, 2.08961200e-05],\n",
       "       [1.00000000e+00, 1.00348950e-10, 6.49282700e-13],\n",
       "       [1.00000000e+00, 3.84534160e-12, 4.17467170e-14],\n",
       "       [7.73610300e-08, 4.28021800e-08, 9.99999900e-01],\n",
       "       [1.83987700e-06, 4.25337900e-07, 9.99997740e-01],\n",
       "       [9.99840500e-01, 1.59417120e-04, 3.67635700e-08],\n",
       "       [7.35023200e-02, 9.26497460e-01, 2.03305620e-07],\n",
       "       [7.73610300e-08, 4.28021800e-08, 9.99999900e-01],\n",
       "       [9.75484430e-01, 2.45138240e-02, 1.72167030e-06],\n",
       "       [7.54182800e-02, 9.24580630e-01, 1.06639020e-06],\n",
       "       [7.73610300e-08, 4.28021800e-08, 9.99999900e-01],\n",
       "       [7.73610300e-08, 4.28021800e-08, 9.99999900e-01],\n",
       "       [9.99867200e-01, 1.32839500e-04, 8.48992100e-09],\n",
       "       [1.83987700e-06, 4.25337900e-07, 9.99997740e-01],\n",
       "       [1.29508590e-02, 9.86967150e-01, 8.19580900e-05],\n",
       "       [9.99998570e-01, 1.42049960e-06, 2.99375440e-10],\n",
       "       [9.99999170e-01, 8.87926700e-07, 9.02763530e-10],\n",
       "       [4.23601980e-01, 5.76397500e-01, 4.96263340e-07],\n",
       "       [1.83987700e-06, 4.25337900e-07, 9.99997740e-01],\n",
       "       [4.00158950e-02, 9.59967850e-01, 1.62845550e-05],\n",
       "       [1.48788870e-01, 8.51185740e-01, 2.54512290e-05],\n",
       "       [9.99989150e-01, 1.08031980e-05, 1.26088490e-08],\n",
       "       [1.83987700e-06, 4.25337900e-07, 9.99997740e-01],\n",
       "       [7.73610300e-08, 4.28021800e-08, 9.99999900e-01],\n",
       "       [4.58043630e-01, 5.41601000e-01, 3.55422700e-04],\n",
       "       [1.75673590e-01, 8.24313100e-01, 1.34122750e-05],\n",
       "       [1.83987700e-06, 4.25337900e-07, 9.99997740e-01],\n",
       "       [7.73610300e-08, 4.28021800e-08, 9.99999900e-01],\n",
       "       [7.73610300e-08, 4.28021800e-08, 9.99999900e-01],\n",
       "       [5.18638700e-09, 1.00000000e+00, 1.88011250e-09],\n",
       "       [4.93246060e-02, 9.50606400e-01, 6.89793740e-05],\n",
       "       [9.99998700e-01, 1.26062290e-06, 1.83572380e-09],\n",
       "       [7.20617950e-01, 2.79343900e-01, 3.81186660e-05],\n",
       "       [1.83987700e-06, 4.25337900e-07, 9.99997740e-01],\n",
       "       [9.87355300e-01, 1.26437640e-02, 8.97158200e-07],\n",
       "       [7.73610300e-08, 4.28021800e-08, 9.99999900e-01],\n",
       "       [7.73610300e-08, 4.28021800e-08, 9.99999900e-01],\n",
       "       [4.93246060e-02, 9.50606400e-01, 6.89793740e-05],\n",
       "       [1.83987700e-06, 4.25337900e-07, 9.99997740e-01],\n",
       "       [1.77840380e-01, 8.22159500e-01, 7.21599400e-08],\n",
       "       [2.48529140e-01, 7.51461100e-01, 9.84607800e-06],\n",
       "       [1.00000000e+00, 1.26817290e-08, 1.71118780e-11],\n",
       "       [1.83987700e-06, 4.25337900e-07, 9.99997740e-01],\n",
       "       [4.26828340e-07, 9.99999500e-01, 3.06862730e-08],\n",
       "       [1.83987700e-06, 4.25337900e-07, 9.99997740e-01],\n",
       "       [4.93246060e-02, 9.50606400e-01, 6.89793740e-05],\n",
       "       [9.99542700e-01, 4.57301530e-04, 3.76968070e-08],\n",
       "       [1.00000000e+00, 1.40138260e-08, 3.17544300e-11],\n",
       "       [7.73610300e-08, 4.28021800e-08, 9.99999900e-01],\n",
       "       [4.00158950e-02, 9.59967850e-01, 1.62845550e-05],\n",
       "       [3.02173000e-01, 6.97807000e-01, 2.00484830e-05],\n",
       "       [9.99997500e-01, 2.55365080e-06, 1.77845530e-09],\n",
       "       [6.07764120e-02, 9.38403250e-01, 8.20326560e-04],\n",
       "       [7.73610300e-08, 4.28021800e-08, 9.99999900e-01],\n",
       "       [1.83987700e-06, 4.25337900e-07, 9.99997740e-01],\n",
       "       [9.99553860e-01, 4.46120100e-04, 3.22774980e-08]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob8 = df_proba8[df_proba8['phage']=='p0017SpresabsSTCC_qual'].iloc[:,-3:]\n",
    "y_prob8 = y_prob8.to_numpy()\n",
    "y_prob8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9882445759368835"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo8 = rocauc_ovo(y_test_over, y_prob8, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9882445759368835"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr8 = rocauc_ovr(y_test_over, y_prob8, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9744970414201183"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovos2 = [ovo5, ovo6, ovo7, ovo8]\n",
    "np.mean(ovos2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.007997510787651003"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(ovos2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9744970414201183"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovrs2 = [ovr5, ovr6, ovr7, ovr8]\n",
    "np.mean(ovrs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.007997510787651003"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(ovrs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs_reg = [acc_test_over5, acc_test_over6, acc_test_over7, acc_test_over8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling test accuracy regularization mean: 90.64%\n"
     ]
    }
   ],
   "source": [
    "mean_reg = np.mean(accs_reg)\n",
    "print('over-sampling test accuracy regularization mean: %.2f%%' % (mean_reg*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling test accuracy regularization standard deviation: 0.007584717218556131\n"
     ]
    }
   ],
   "source": [
    "std_reg = np.std(accs_reg)\n",
    "print('over-sampling test accuracy regularization standard deviation:', std_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "accs_train_reg = [np.mean(hist1_over5.history['accuracy']), np.mean(hist1_over6.history['accuracy']), np.mean(hist1_over7.history['accuracy']),\n",
    "             np.mean(hist1_over8.history['accuracy'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy regularization mean: 75.47%\n"
     ]
    }
   ],
   "source": [
    "mean_train_reg = np.mean(accs_train_reg)\n",
    "print('over-sampling train accuracy regularization mean: %.2f%%' % (mean_train_reg*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy regularization standard deviation: 0.004369892\n"
     ]
    }
   ],
   "source": [
    "std_train_reg = np.std(accs_train_reg)\n",
    "print('over-sampling train accuracy regularization standard deviation:', std_train_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
