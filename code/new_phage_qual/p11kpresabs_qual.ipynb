{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This file implements neural networks before and after lasso selection for p11kpresabs_qual with four replicates.\n",
    "## We compute the mean and standarad deviation of training and test accuracies.\n",
    "## We also compute the mean and standard deviation of AUC ROC values for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "import numpy as np\n",
    "seed(100)\n",
    "import tensorflow\n",
    "tensorflow.random.set_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(253, 822)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/p11kpresabs_qual.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'Unnamed: 0':'id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      2\n",
       "1      1\n",
       "2      2\n",
       "3      2\n",
       "4      2\n",
       "      ..\n",
       "248    2\n",
       "249    1\n",
       "250    2\n",
       "251    2\n",
       "252    2\n",
       "Name: pheno, Length: 253, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pheno']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>TTTTTTGTAATTTT</th>\n",
       "      <th>TTTTTTGTAATTTTT</th>\n",
       "      <th>TTTTTTATTTTGGAT</th>\n",
       "      <th>TTTTTTATTTTGGATAA</th>\n",
       "      <th>TTTTTTATTTTGGATAAAAGGAG</th>\n",
       "      <th>TTTTTTAGTCGTTTTT</th>\n",
       "      <th>TTTTTATCGTTTACT</th>\n",
       "      <th>TTTTTAGTCGTTTTT</th>\n",
       "      <th>TTTTTAGTCGTTTTTT</th>\n",
       "      <th>...</th>\n",
       "      <th>ACAAGTCGCTGAAATATT</th>\n",
       "      <th>ACAAACTTTCTAGGTT</th>\n",
       "      <th>AATCACCCCTT</th>\n",
       "      <th>AAGGGGTGATTT</th>\n",
       "      <th>AAGGGGTGATTTT</th>\n",
       "      <th>AAGATGATTTATCCAACTTT</th>\n",
       "      <th>AACTTTCTAGGTT</th>\n",
       "      <th>AACCTAGAAAGTTT</th>\n",
       "      <th>AACATCTTTTATTT</th>\n",
       "      <th>pheno</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>109</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>120335</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120337</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 822 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  TTTTTTGTAATTTT  TTTTTTGTAATTTTT  TTTTTTATTTTGGAT  \\\n",
       "0     107               0                0                0   \n",
       "1     109               1                1                1   \n",
       "2     115               1                1                1   \n",
       "3  120335               1                1                1   \n",
       "4  120337               1                1                1   \n",
       "\n",
       "   TTTTTTATTTTGGATAA  TTTTTTATTTTGGATAAAAGGAG  TTTTTTAGTCGTTTTT  \\\n",
       "0                  0                        0                 0   \n",
       "1                  1                        1                 1   \n",
       "2                  1                        1                 1   \n",
       "3                  1                        1                 1   \n",
       "4                  1                        1                 1   \n",
       "\n",
       "   TTTTTATCGTTTACT  TTTTTAGTCGTTTTT  TTTTTAGTCGTTTTTT  ...  \\\n",
       "0                0                0                 0  ...   \n",
       "1                1                1                 1  ...   \n",
       "2                1                1                 1  ...   \n",
       "3                1                1                 1  ...   \n",
       "4                1                1                 1  ...   \n",
       "\n",
       "   ACAAGTCGCTGAAATATT  ACAAACTTTCTAGGTT  AATCACCCCTT  AAGGGGTGATTT  \\\n",
       "0                   0                 0            0             0   \n",
       "1                   1                 1            1             1   \n",
       "2                   1                 1            1             1   \n",
       "3                   1                 1            1             1   \n",
       "4                   1                 1            1             1   \n",
       "\n",
       "   AAGGGGTGATTTT  AAGATGATTTATCCAACTTT  AACTTTCTAGGTT  AACCTAGAAAGTTT  \\\n",
       "0              0                     0              0               0   \n",
       "1              1                     1              1               1   \n",
       "2              1                     1              1               1   \n",
       "3              1                     1              1               1   \n",
       "4              1                     1              1               1   \n",
       "\n",
       "   AACATCTTTTATTT  pheno  \n",
       "0               0      2  \n",
       "1               1      1  \n",
       "2               1      2  \n",
       "3               1      2  \n",
       "4               1      2  \n",
       "\n",
       "[5 rows x 822 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    181\n",
       "1     47\n",
       "0     25\n",
       "Name: pheno, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pheno'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.drop(columns=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(253, 821)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TTTTTTGTAATTTT</th>\n",
       "      <th>TTTTTTGTAATTTTT</th>\n",
       "      <th>TTTTTTATTTTGGAT</th>\n",
       "      <th>TTTTTTATTTTGGATAA</th>\n",
       "      <th>TTTTTTATTTTGGATAAAAGGAG</th>\n",
       "      <th>TTTTTTAGTCGTTTTT</th>\n",
       "      <th>TTTTTATCGTTTACT</th>\n",
       "      <th>TTTTTAGTCGTTTTT</th>\n",
       "      <th>TTTTTAGTCGTTTTTT</th>\n",
       "      <th>TTTTTAGGTAAGG</th>\n",
       "      <th>...</th>\n",
       "      <th>ACAAGTCGCTGAAATATT</th>\n",
       "      <th>ACAAACTTTCTAGGTT</th>\n",
       "      <th>AATCACCCCTT</th>\n",
       "      <th>AAGGGGTGATTT</th>\n",
       "      <th>AAGGGGTGATTTT</th>\n",
       "      <th>AAGATGATTTATCCAACTTT</th>\n",
       "      <th>AACTTTCTAGGTT</th>\n",
       "      <th>AACCTAGAAAGTTT</th>\n",
       "      <th>AACATCTTTTATTT</th>\n",
       "      <th>pheno</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 821 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TTTTTTGTAATTTT  TTTTTTGTAATTTTT  TTTTTTATTTTGGAT  TTTTTTATTTTGGATAA  \\\n",
       "0               0                0                0                  0   \n",
       "1               1                1                1                  1   \n",
       "2               1                1                1                  1   \n",
       "3               1                1                1                  1   \n",
       "4               1                1                1                  1   \n",
       "\n",
       "   TTTTTTATTTTGGATAAAAGGAG  TTTTTTAGTCGTTTTT  TTTTTATCGTTTACT  \\\n",
       "0                        0                 0                0   \n",
       "1                        1                 1                1   \n",
       "2                        1                 1                1   \n",
       "3                        1                 1                1   \n",
       "4                        1                 1                1   \n",
       "\n",
       "   TTTTTAGTCGTTTTT  TTTTTAGTCGTTTTTT  TTTTTAGGTAAGG  ...  ACAAGTCGCTGAAATATT  \\\n",
       "0                0                 0              0  ...                   0   \n",
       "1                1                 1              1  ...                   1   \n",
       "2                1                 1              1  ...                   1   \n",
       "3                1                 1              1  ...                   1   \n",
       "4                1                 1              1  ...                   1   \n",
       "\n",
       "   ACAAACTTTCTAGGTT  AATCACCCCTT  AAGGGGTGATTT  AAGGGGTGATTTT  \\\n",
       "0                 0            0             0              0   \n",
       "1                 1            1             1              1   \n",
       "2                 1            1             1              1   \n",
       "3                 1            1             1              1   \n",
       "4                 1            1             1              1   \n",
       "\n",
       "   AAGATGATTTATCCAACTTT  AACTTTCTAGGTT  AACCTAGAAAGTTT  AACATCTTTTATTT  pheno  \n",
       "0                     0              0               0               0      2  \n",
       "1                     1              1               1               1      1  \n",
       "2                     1              1               1               1      2  \n",
       "3                     1              1               1               1      2  \n",
       "4                     1              1               1               1      2  \n",
       "\n",
       "[5 rows x 821 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(253, 821) (253,)\n"
     ]
    }
   ],
   "source": [
    "X = df.loc[:, df.columns != 'pheno']\n",
    "y = df['pheno']\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.ensemble.bagging module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.ensemble.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.ensemble.forest module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 181), (1, 181), (2, 181)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.utils.testing module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.utils. Anything that cannot be imported from sklearn.utils is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.metrics.classification module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# over-sampling\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "overS = RandomOverSampler(random_state=100)\n",
    "X_over, y_over = overS.fit_resample(X, y)\n",
    "print(sorted(Counter(y_over).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# Fully-Connected Neural Network ################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.regularizers import l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=123,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = pd.DataFrame(X_test_over[:,0])\n",
    "dat['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SR1129</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS185</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS243</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BCH-SA-04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>504</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>CFBREBSa131</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>CFBREBSa133</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>NRS256</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>GA48963</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>BCH-SA-07</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test\n",
       "0         SR1129     2\n",
       "1         NRS185     2\n",
       "2         NRS243     1\n",
       "3      BCH-SA-04     0\n",
       "4            504     1\n",
       "..           ...   ...\n",
       "158  CFBREBSa131     2\n",
       "159  CFBREBSa133     1\n",
       "160       NRS256     2\n",
       "161      GA48963     1\n",
       "162    BCH-SA-07     1\n",
       "\n",
       "[163 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### neural network on over-sampling data\n",
    "model1_over = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],)),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 380 samples, validate on 163 samples\n",
      "Epoch 1/100\n",
      "380/380 [==============================] - 0s 370us/step - loss: 1.2958 - accuracy: 0.3842 - val_loss: 1.1623 - val_accuracy: 0.3497\n",
      "Epoch 2/100\n",
      "380/380 [==============================] - 0s 500us/step - loss: 1.0366 - accuracy: 0.4711 - val_loss: 1.0661 - val_accuracy: 0.4479\n",
      "Epoch 3/100\n",
      "380/380 [==============================] - 0s 310us/step - loss: 0.9914 - accuracy: 0.5263 - val_loss: 0.9755 - val_accuracy: 0.5706\n",
      "Epoch 4/100\n",
      "380/380 [==============================] - 0s 648us/step - loss: 0.8832 - accuracy: 0.6158 - val_loss: 0.9160 - val_accuracy: 0.5276\n",
      "Epoch 5/100\n",
      "380/380 [==============================] - 0s 654us/step - loss: 0.8389 - accuracy: 0.6079 - val_loss: 0.8976 - val_accuracy: 0.6135\n",
      "Epoch 6/100\n",
      "380/380 [==============================] - 0s 279us/step - loss: 0.8161 - accuracy: 0.6184 - val_loss: 0.9170 - val_accuracy: 0.6074\n",
      "Epoch 7/100\n",
      "380/380 [==============================] - 0s 275us/step - loss: 0.7946 - accuracy: 0.6342 - val_loss: 0.8560 - val_accuracy: 0.6503\n",
      "Epoch 8/100\n",
      "380/380 [==============================] - 0s 193us/step - loss: 0.7518 - accuracy: 0.7000 - val_loss: 0.8274 - val_accuracy: 0.6687\n",
      "Epoch 9/100\n",
      "380/380 [==============================] - 0s 158us/step - loss: 0.7385 - accuracy: 0.6921 - val_loss: 0.8497 - val_accuracy: 0.6074\n",
      "Epoch 10/100\n",
      "380/380 [==============================] - 0s 160us/step - loss: 0.6910 - accuracy: 0.7237 - val_loss: 0.8245 - val_accuracy: 0.6196\n",
      "Epoch 11/100\n",
      "380/380 [==============================] - 0s 454us/step - loss: 0.6934 - accuracy: 0.7237 - val_loss: 0.7606 - val_accuracy: 0.6871\n",
      "Epoch 12/100\n",
      "380/380 [==============================] - 0s 184us/step - loss: 0.6682 - accuracy: 0.7184 - val_loss: 0.7535 - val_accuracy: 0.6380\n",
      "Epoch 13/100\n",
      "380/380 [==============================] - 0s 255us/step - loss: 0.6442 - accuracy: 0.7342 - val_loss: 0.8061 - val_accuracy: 0.6074\n",
      "Epoch 14/100\n",
      "380/380 [==============================] - 0s 275us/step - loss: 0.6430 - accuracy: 0.7447 - val_loss: 0.8037 - val_accuracy: 0.6258\n",
      "Epoch 15/100\n",
      "380/380 [==============================] - 0s 567us/step - loss: 0.6238 - accuracy: 0.7526 - val_loss: 0.7005 - val_accuracy: 0.7239\n",
      "Epoch 16/100\n",
      "380/380 [==============================] - 0s 150us/step - loss: 0.5754 - accuracy: 0.7789 - val_loss: 0.7072 - val_accuracy: 0.7055\n",
      "Epoch 17/100\n",
      "380/380 [==============================] - 0s 129us/step - loss: 0.5432 - accuracy: 0.7974 - val_loss: 0.7499 - val_accuracy: 0.6564\n",
      "Epoch 18/100\n",
      "380/380 [==============================] - 0s 195us/step - loss: 0.5535 - accuracy: 0.7658 - val_loss: 0.6777 - val_accuracy: 0.6933\n",
      "Epoch 19/100\n",
      "380/380 [==============================] - 0s 155us/step - loss: 0.5351 - accuracy: 0.7816 - val_loss: 0.6640 - val_accuracy: 0.6933\n",
      "Epoch 20/100\n",
      "380/380 [==============================] - 0s 146us/step - loss: 0.5365 - accuracy: 0.7974 - val_loss: 0.6584 - val_accuracy: 0.7117\n",
      "Epoch 21/100\n",
      "380/380 [==============================] - 0s 164us/step - loss: 0.4982 - accuracy: 0.8158 - val_loss: 0.7143 - val_accuracy: 0.6687\n",
      "Epoch 22/100\n",
      "380/380 [==============================] - 0s 378us/step - loss: 0.5129 - accuracy: 0.7895 - val_loss: 0.7093 - val_accuracy: 0.6687\n",
      "Epoch 23/100\n",
      "380/380 [==============================] - 0s 209us/step - loss: 0.4954 - accuracy: 0.7895 - val_loss: 0.6718 - val_accuracy: 0.6810\n",
      "Epoch 24/100\n",
      "380/380 [==============================] - 0s 362us/step - loss: 0.4678 - accuracy: 0.8316 - val_loss: 0.6510 - val_accuracy: 0.6933\n",
      "Epoch 25/100\n",
      "380/380 [==============================] - 0s 194us/step - loss: 0.4671 - accuracy: 0.7974 - val_loss: 0.6532 - val_accuracy: 0.6933\n",
      "Epoch 26/100\n",
      "380/380 [==============================] - 0s 305us/step - loss: 0.4472 - accuracy: 0.8474 - val_loss: 0.6302 - val_accuracy: 0.6994\n",
      "Epoch 27/100\n",
      "380/380 [==============================] - 0s 166us/step - loss: 0.4445 - accuracy: 0.8237 - val_loss: 0.6332 - val_accuracy: 0.7362\n",
      "Epoch 28/100\n",
      "380/380 [==============================] - 0s 171us/step - loss: 0.4577 - accuracy: 0.8184 - val_loss: 0.7093 - val_accuracy: 0.6933\n",
      "Epoch 29/100\n",
      "380/380 [==============================] - 0s 210us/step - loss: 0.4704 - accuracy: 0.8026 - val_loss: 0.6858 - val_accuracy: 0.6810\n",
      "Epoch 30/100\n",
      "380/380 [==============================] - 0s 376us/step - loss: 0.4657 - accuracy: 0.7974 - val_loss: 0.6326 - val_accuracy: 0.7362\n",
      "Epoch 31/100\n",
      "380/380 [==============================] - 0s 478us/step - loss: 0.4441 - accuracy: 0.8132 - val_loss: 0.6610 - val_accuracy: 0.7423\n",
      "Epoch 32/100\n",
      "380/380 [==============================] - 0s 558us/step - loss: 0.4274 - accuracy: 0.8132 - val_loss: 0.6522 - val_accuracy: 0.7607\n",
      "Epoch 33/100\n",
      "380/380 [==============================] - 0s 350us/step - loss: 0.4089 - accuracy: 0.8316 - val_loss: 0.6486 - val_accuracy: 0.7117\n",
      "Epoch 34/100\n",
      "380/380 [==============================] - 0s 317us/step - loss: 0.4049 - accuracy: 0.8289 - val_loss: 0.6835 - val_accuracy: 0.7055\n",
      "Epoch 35/100\n",
      "380/380 [==============================] - 0s 536us/step - loss: 0.4165 - accuracy: 0.8184 - val_loss: 0.6698 - val_accuracy: 0.6933\n",
      "Epoch 36/100\n",
      "380/380 [==============================] - 0s 425us/step - loss: 0.3941 - accuracy: 0.8395 - val_loss: 0.7294 - val_accuracy: 0.6871\n",
      "Epoch 37/100\n",
      "380/380 [==============================] - 0s 248us/step - loss: 0.4213 - accuracy: 0.8105 - val_loss: 0.6635 - val_accuracy: 0.7117\n",
      "Epoch 38/100\n",
      "380/380 [==============================] - 0s 529us/step - loss: 0.3862 - accuracy: 0.8553 - val_loss: 0.7388 - val_accuracy: 0.6871\n",
      "Epoch 39/100\n",
      "380/380 [==============================] - 0s 160us/step - loss: 0.4140 - accuracy: 0.8526 - val_loss: 0.6768 - val_accuracy: 0.7117\n",
      "Epoch 40/100\n",
      "380/380 [==============================] - 0s 253us/step - loss: 0.3903 - accuracy: 0.8474 - val_loss: 0.6676 - val_accuracy: 0.7117\n",
      "Epoch 41/100\n",
      "380/380 [==============================] - 0s 463us/step - loss: 0.4110 - accuracy: 0.8263 - val_loss: 0.6834 - val_accuracy: 0.7117\n",
      "Epoch 42/100\n",
      "380/380 [==============================] - 0s 170us/step - loss: 0.3474 - accuracy: 0.8737 - val_loss: 0.6389 - val_accuracy: 0.7178\n",
      "Epoch 43/100\n",
      "380/380 [==============================] - 0s 496us/step - loss: 0.3979 - accuracy: 0.8368 - val_loss: 0.5984 - val_accuracy: 0.7546\n",
      "Epoch 44/100\n",
      "380/380 [==============================] - 0s 175us/step - loss: 0.3893 - accuracy: 0.8289 - val_loss: 0.6063 - val_accuracy: 0.7301\n",
      "Epoch 45/100\n",
      "380/380 [==============================] - 0s 812us/step - loss: 0.3692 - accuracy: 0.8447 - val_loss: 0.6024 - val_accuracy: 0.7178\n",
      "Epoch 46/100\n",
      "380/380 [==============================] - 0s 286us/step - loss: 0.3581 - accuracy: 0.8289 - val_loss: 0.6108 - val_accuracy: 0.7485\n",
      "Epoch 47/100\n",
      "380/380 [==============================] - 0s 510us/step - loss: 0.3630 - accuracy: 0.8658 - val_loss: 0.6008 - val_accuracy: 0.7301\n",
      "Epoch 48/100\n",
      "380/380 [==============================] - 0s 217us/step - loss: 0.3819 - accuracy: 0.8316 - val_loss: 0.6458 - val_accuracy: 0.6994\n",
      "Epoch 49/100\n",
      "380/380 [==============================] - 0s 287us/step - loss: 0.3288 - accuracy: 0.8658 - val_loss: 0.6180 - val_accuracy: 0.7178\n",
      "Epoch 50/100\n",
      "380/380 [==============================] - 0s 484us/step - loss: 0.3342 - accuracy: 0.8605 - val_loss: 0.6214 - val_accuracy: 0.7485\n",
      "Epoch 51/100\n",
      "380/380 [==============================] - 0s 193us/step - loss: 0.3259 - accuracy: 0.8711 - val_loss: 0.5791 - val_accuracy: 0.7485\n",
      "Epoch 52/100\n",
      "380/380 [==============================] - 0s 189us/step - loss: 0.3280 - accuracy: 0.8500 - val_loss: 0.6368 - val_accuracy: 0.7178\n",
      "Epoch 53/100\n",
      "380/380 [==============================] - 0s 164us/step - loss: 0.3292 - accuracy: 0.8632 - val_loss: 0.6452 - val_accuracy: 0.7301\n",
      "Epoch 54/100\n",
      "380/380 [==============================] - 0s 313us/step - loss: 0.4032 - accuracy: 0.8263 - val_loss: 0.6586 - val_accuracy: 0.7362\n",
      "Epoch 55/100\n",
      "380/380 [==============================] - 0s 303us/step - loss: 0.3945 - accuracy: 0.8447 - val_loss: 0.5783 - val_accuracy: 0.7607\n",
      "Epoch 56/100\n",
      "380/380 [==============================] - 0s 607us/step - loss: 0.3468 - accuracy: 0.8605 - val_loss: 0.5971 - val_accuracy: 0.7546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "380/380 [==============================] - 0s 688us/step - loss: 0.3541 - accuracy: 0.8526 - val_loss: 0.6356 - val_accuracy: 0.7546\n",
      "Epoch 58/100\n",
      "380/380 [==============================] - 0s 491us/step - loss: 0.2998 - accuracy: 0.8816 - val_loss: 0.5790 - val_accuracy: 0.7607\n",
      "Epoch 59/100\n",
      "380/380 [==============================] - 0s 499us/step - loss: 0.3098 - accuracy: 0.8816 - val_loss: 0.5920 - val_accuracy: 0.7546\n",
      "Epoch 60/100\n",
      "380/380 [==============================] - 0s 477us/step - loss: 0.3332 - accuracy: 0.8605 - val_loss: 0.6100 - val_accuracy: 0.7239\n",
      "Epoch 61/100\n",
      "380/380 [==============================] - 0s 481us/step - loss: 0.3297 - accuracy: 0.8474 - val_loss: 0.6261 - val_accuracy: 0.7239\n",
      "Epoch 62/100\n",
      "380/380 [==============================] - 0s 305us/step - loss: 0.3217 - accuracy: 0.8737 - val_loss: 0.6523 - val_accuracy: 0.7117\n",
      "Epoch 63/100\n",
      "380/380 [==============================] - 0s 686us/step - loss: 0.3312 - accuracy: 0.8605 - val_loss: 0.6784 - val_accuracy: 0.7117\n",
      "Epoch 64/100\n",
      "380/380 [==============================] - 0s 490us/step - loss: 0.3083 - accuracy: 0.8842 - val_loss: 0.8247 - val_accuracy: 0.6748\n",
      "Epoch 65/100\n",
      "380/380 [==============================] - 0s 201us/step - loss: 0.3315 - accuracy: 0.8605 - val_loss: 0.6368 - val_accuracy: 0.7301\n",
      "Epoch 66/100\n",
      "380/380 [==============================] - 0s 229us/step - loss: 0.3088 - accuracy: 0.8763 - val_loss: 0.6257 - val_accuracy: 0.7239\n",
      "Epoch 67/100\n",
      "380/380 [==============================] - 0s 195us/step - loss: 0.3087 - accuracy: 0.8632 - val_loss: 0.6332 - val_accuracy: 0.7423\n",
      "Epoch 68/100\n",
      "380/380 [==============================] - 0s 427us/step - loss: 0.3041 - accuracy: 0.8737 - val_loss: 0.6428 - val_accuracy: 0.7791\n",
      "Epoch 69/100\n",
      "380/380 [==============================] - 0s 225us/step - loss: 0.2918 - accuracy: 0.8921 - val_loss: 0.5973 - val_accuracy: 0.7791\n",
      "Epoch 70/100\n",
      "380/380 [==============================] - 0s 318us/step - loss: 0.2872 - accuracy: 0.8895 - val_loss: 0.5915 - val_accuracy: 0.7485\n",
      "Epoch 71/100\n",
      "380/380 [==============================] - 0s 619us/step - loss: 0.2905 - accuracy: 0.8842 - val_loss: 0.5977 - val_accuracy: 0.7730\n",
      "Epoch 72/100\n",
      "380/380 [==============================] - 0s 181us/step - loss: 0.2852 - accuracy: 0.8868 - val_loss: 0.7446 - val_accuracy: 0.6933\n",
      "Epoch 73/100\n",
      "380/380 [==============================] - 0s 676us/step - loss: 0.3233 - accuracy: 0.8684 - val_loss: 0.6540 - val_accuracy: 0.7730\n",
      "Epoch 74/100\n",
      "380/380 [==============================] - 0s 228us/step - loss: 0.3300 - accuracy: 0.8737 - val_loss: 0.6095 - val_accuracy: 0.7669\n",
      "Epoch 75/100\n",
      "380/380 [==============================] - 0s 229us/step - loss: 0.2899 - accuracy: 0.8921 - val_loss: 0.5637 - val_accuracy: 0.7669\n",
      "Epoch 76/100\n",
      "380/380 [==============================] - 0s 284us/step - loss: 0.3039 - accuracy: 0.8789 - val_loss: 0.6606 - val_accuracy: 0.7178\n",
      "Epoch 77/100\n",
      "380/380 [==============================] - 0s 302us/step - loss: 0.3118 - accuracy: 0.8816 - val_loss: 0.6735 - val_accuracy: 0.7178\n",
      "Epoch 78/100\n",
      "380/380 [==============================] - 0s 317us/step - loss: 0.3227 - accuracy: 0.8526 - val_loss: 0.7549 - val_accuracy: 0.7117\n",
      "Epoch 79/100\n",
      "380/380 [==============================] - 0s 265us/step - loss: 0.3154 - accuracy: 0.8579 - val_loss: 0.7566 - val_accuracy: 0.7117\n",
      "Epoch 80/100\n",
      "380/380 [==============================] - 0s 173us/step - loss: 0.3219 - accuracy: 0.8500 - val_loss: 0.8535 - val_accuracy: 0.6748\n",
      "Epoch 81/100\n",
      "380/380 [==============================] - 0s 566us/step - loss: 0.3526 - accuracy: 0.8526 - val_loss: 0.8144 - val_accuracy: 0.7055\n",
      "Epoch 82/100\n",
      "380/380 [==============================] - 0s 436us/step - loss: 0.3434 - accuracy: 0.8474 - val_loss: 0.7056 - val_accuracy: 0.7117\n",
      "Epoch 83/100\n",
      "380/380 [==============================] - 0s 207us/step - loss: 0.2583 - accuracy: 0.8921 - val_loss: 0.5837 - val_accuracy: 0.7669\n",
      "Epoch 84/100\n",
      "380/380 [==============================] - 0s 349us/step - loss: 0.2764 - accuracy: 0.8842 - val_loss: 0.5963 - val_accuracy: 0.7730\n",
      "Epoch 85/100\n",
      "380/380 [==============================] - 0s 279us/step - loss: 0.2988 - accuracy: 0.8789 - val_loss: 0.6655 - val_accuracy: 0.7669\n",
      "Epoch 86/100\n",
      "380/380 [==============================] - 0s 260us/step - loss: 0.2800 - accuracy: 0.8868 - val_loss: 0.6075 - val_accuracy: 0.8037\n",
      "Epoch 87/100\n",
      "380/380 [==============================] - 0s 270us/step - loss: 0.2518 - accuracy: 0.8895 - val_loss: 0.5767 - val_accuracy: 0.7423\n",
      "Epoch 88/100\n",
      "380/380 [==============================] - 0s 196us/step - loss: 0.2569 - accuracy: 0.8842 - val_loss: 0.5709 - val_accuracy: 0.7485\n",
      "Epoch 89/100\n",
      "380/380 [==============================] - 0s 315us/step - loss: 0.2471 - accuracy: 0.9026 - val_loss: 0.5967 - val_accuracy: 0.7791\n",
      "Epoch 90/100\n",
      "380/380 [==============================] - 0s 171us/step - loss: 0.2652 - accuracy: 0.8868 - val_loss: 0.5745 - val_accuracy: 0.7730\n",
      "Epoch 91/100\n",
      "380/380 [==============================] - 0s 517us/step - loss: 0.2594 - accuracy: 0.9026 - val_loss: 0.6131 - val_accuracy: 0.8037\n",
      "Epoch 92/100\n",
      "380/380 [==============================] - 0s 203us/step - loss: 0.2519 - accuracy: 0.8921 - val_loss: 0.6736 - val_accuracy: 0.7178\n",
      "Epoch 93/100\n",
      "380/380 [==============================] - 0s 628us/step - loss: 0.3184 - accuracy: 0.8500 - val_loss: 0.6773 - val_accuracy: 0.7117\n",
      "Epoch 94/100\n",
      "380/380 [==============================] - 0s 717us/step - loss: 0.2807 - accuracy: 0.8816 - val_loss: 0.6875 - val_accuracy: 0.7362\n",
      "Epoch 95/100\n",
      "380/380 [==============================] - 0s 209us/step - loss: 0.2652 - accuracy: 0.9026 - val_loss: 0.6149 - val_accuracy: 0.7362\n",
      "Epoch 96/100\n",
      "380/380 [==============================] - 0s 280us/step - loss: 0.2579 - accuracy: 0.8895 - val_loss: 0.6285 - val_accuracy: 0.7485\n",
      "Epoch 97/100\n",
      "380/380 [==============================] - 0s 384us/step - loss: 0.2703 - accuracy: 0.8868 - val_loss: 0.5889 - val_accuracy: 0.7914\n",
      "Epoch 98/100\n",
      "380/380 [==============================] - 0s 289us/step - loss: 0.2848 - accuracy: 0.8737 - val_loss: 0.5647 - val_accuracy: 0.7669\n",
      "Epoch 99/100\n",
      "380/380 [==============================] - 0s 202us/step - loss: 0.2512 - accuracy: 0.8974 - val_loss: 0.5643 - val_accuracy: 0.7791\n",
      "Epoch 100/100\n",
      "380/380 [==============================] - 0s 175us/step - loss: 0.2585 - accuracy: 0.8842 - val_loss: 0.6155 - val_accuracy: 0.7914\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a410e0048>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163/163 [==============================] - 0s 85us/step\n",
      "over-sampling test accuracy: 78.53%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over = model1_over.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 1, 0, 1, 0, 0, 0, 1, 1, 2, 0, 0, 2, 0, 0, 2, 0, 0, 0, 1, 0,\n",
       "       0, 2, 0, 0, 0, 1, 0, 0, 2, 2, 1, 0, 1, 0, 1, 1, 1, 1, 0, 2, 0, 2,\n",
       "       1, 1, 2, 1, 0, 0, 0, 0, 1, 1, 1, 2, 1, 2, 0, 0, 0, 1, 0, 0, 1, 2,\n",
       "       0, 0, 1, 0, 0, 1, 0, 1, 2, 1, 1, 0, 0, 0, 1, 1, 2, 1, 1, 0, 0, 1,\n",
       "       1, 2, 0, 0, 1, 0, 1, 2, 2, 0, 2, 0, 0, 0, 0, 1, 2, 0, 1, 0, 0, 0,\n",
       "       2, 1, 0, 1, 2, 0, 0, 1, 1, 0, 0, 2, 1, 2, 0, 2, 2, 0, 2, 0, 0, 1,\n",
       "       2, 1, 1, 2, 0, 0, 2, 0, 0, 2, 0, 2, 2, 2, 0, 1, 0, 2, 0, 0, 0, 0,\n",
       "       2, 0, 0, 2, 0, 1, 2, 1, 0])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model1_over.predict_classes(X_test_over)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SR1129</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS185</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS243</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BCH-SA-04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>504</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>CFBREBSa131</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>CFBREBSa133</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>NRS256</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>GA48963</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>BCH-SA-07</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test  pred\n",
       "0         SR1129     2     0\n",
       "1         NRS185     2     2\n",
       "2         NRS243     1     1\n",
       "3      BCH-SA-04     0     0\n",
       "4            504     1     1\n",
       "..           ...   ...   ...\n",
       "158  CFBREBSa131     2     0\n",
       "159  CFBREBSa133     1     1\n",
       "160       NRS256     2     2\n",
       "161      GA48963     1     1\n",
       "162    BCH-SA-07     1     0\n",
       "\n",
       "[163 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat['pred'] = pred\n",
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba1 = model1_over.predict_proba(X_test_over)\n",
    "dat_proba1 = pd.DataFrame(proba1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.991729</td>\n",
       "      <td>0.001580</td>\n",
       "      <td>0.006691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.011410</td>\n",
       "      <td>0.104540</td>\n",
       "      <td>0.884050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000098</td>\n",
       "      <td>0.985774</td>\n",
       "      <td>0.014128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.995715</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.004272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.113516</td>\n",
       "      <td>0.788538</td>\n",
       "      <td>0.097947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>0.883826</td>\n",
       "      <td>0.000551</td>\n",
       "      <td>0.115623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>0.000303</td>\n",
       "      <td>0.661321</td>\n",
       "      <td>0.338375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.007202</td>\n",
       "      <td>0.992771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>0.000209</td>\n",
       "      <td>0.844463</td>\n",
       "      <td>0.155327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>0.439803</td>\n",
       "      <td>0.407325</td>\n",
       "      <td>0.152872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2\n",
       "0    0.991729  0.001580  0.006691\n",
       "1    0.011410  0.104540  0.884050\n",
       "2    0.000098  0.985774  0.014128\n",
       "3    0.995715  0.000013  0.004272\n",
       "4    0.113516  0.788538  0.097947\n",
       "..        ...       ...       ...\n",
       "158  0.883826  0.000551  0.115623\n",
       "159  0.000303  0.661321  0.338375\n",
       "160  0.000027  0.007202  0.992771\n",
       "161  0.000209  0.844463  0.155327\n",
       "162  0.439803  0.407325  0.152872\n",
       "\n",
       "[163 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba1.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba1.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/1p11.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 380 samples, validate on 163 samples\n",
      "Epoch 1/100\n",
      "380/380 [==============================] - 0s 183us/step - loss: 0.2487 - accuracy: 0.9026 - val_loss: 0.5889 - val_accuracy: 0.7791\n",
      "Epoch 2/100\n",
      "380/380 [==============================] - 0s 160us/step - loss: 0.2469 - accuracy: 0.8816 - val_loss: 0.6103 - val_accuracy: 0.7362\n",
      "Epoch 3/100\n",
      "380/380 [==============================] - 0s 180us/step - loss: 0.2691 - accuracy: 0.8816 - val_loss: 0.6027 - val_accuracy: 0.7853\n",
      "Epoch 4/100\n",
      "380/380 [==============================] - 0s 165us/step - loss: 0.2568 - accuracy: 0.8921 - val_loss: 0.5829 - val_accuracy: 0.7853\n",
      "Epoch 5/100\n",
      "380/380 [==============================] - 0s 158us/step - loss: 0.2419 - accuracy: 0.9000 - val_loss: 0.6354 - val_accuracy: 0.7853\n",
      "Epoch 6/100\n",
      "380/380 [==============================] - 0s 149us/step - loss: 0.2641 - accuracy: 0.8868 - val_loss: 0.6748 - val_accuracy: 0.7362\n",
      "Epoch 7/100\n",
      "380/380 [==============================] - 0s 134us/step - loss: 0.2567 - accuracy: 0.8921 - val_loss: 0.6147 - val_accuracy: 0.7853\n",
      "Epoch 8/100\n",
      "380/380 [==============================] - 0s 114us/step - loss: 0.2548 - accuracy: 0.8974 - val_loss: 0.5857 - val_accuracy: 0.7914\n",
      "Epoch 9/100\n",
      "380/380 [==============================] - 0s 109us/step - loss: 0.2441 - accuracy: 0.9079 - val_loss: 0.6178 - val_accuracy: 0.7791\n",
      "Epoch 10/100\n",
      "380/380 [==============================] - 0s 125us/step - loss: 0.2774 - accuracy: 0.8789 - val_loss: 0.5906 - val_accuracy: 0.7914\n",
      "Epoch 11/100\n",
      "380/380 [==============================] - 0s 112us/step - loss: 0.2296 - accuracy: 0.9053 - val_loss: 0.6960 - val_accuracy: 0.7239\n",
      "Epoch 12/100\n",
      "380/380 [==============================] - 0s 113us/step - loss: 0.2537 - accuracy: 0.8921 - val_loss: 0.6842 - val_accuracy: 0.7546\n",
      "Epoch 13/100\n",
      "380/380 [==============================] - 0s 111us/step - loss: 0.2533 - accuracy: 0.8842 - val_loss: 0.7794 - val_accuracy: 0.7117\n",
      "Epoch 14/100\n",
      "380/380 [==============================] - 0s 106us/step - loss: 0.2760 - accuracy: 0.8684 - val_loss: 0.6701 - val_accuracy: 0.7362\n",
      "Epoch 15/100\n",
      "380/380 [==============================] - 0s 120us/step - loss: 0.2385 - accuracy: 0.9026 - val_loss: 0.6553 - val_accuracy: 0.7423\n",
      "Epoch 16/100\n",
      "380/380 [==============================] - 0s 110us/step - loss: 0.2324 - accuracy: 0.9053 - val_loss: 0.6376 - val_accuracy: 0.7730\n",
      "Epoch 17/100\n",
      "380/380 [==============================] - 0s 106us/step - loss: 0.2427 - accuracy: 0.8895 - val_loss: 0.7285 - val_accuracy: 0.7485\n",
      "Epoch 18/100\n",
      "380/380 [==============================] - 0s 112us/step - loss: 0.2558 - accuracy: 0.8895 - val_loss: 0.6330 - val_accuracy: 0.7914\n",
      "Epoch 19/100\n",
      "380/380 [==============================] - 0s 118us/step - loss: 0.2272 - accuracy: 0.9079 - val_loss: 0.6479 - val_accuracy: 0.7914\n",
      "Epoch 20/100\n",
      "380/380 [==============================] - 0s 116us/step - loss: 0.2334 - accuracy: 0.9053 - val_loss: 0.5940 - val_accuracy: 0.7853\n",
      "Epoch 21/100\n",
      "380/380 [==============================] - 0s 118us/step - loss: 0.2356 - accuracy: 0.9158 - val_loss: 0.6586 - val_accuracy: 0.7730\n",
      "Epoch 22/100\n",
      "380/380 [==============================] - 0s 148us/step - loss: 0.2955 - accuracy: 0.8737 - val_loss: 0.6249 - val_accuracy: 0.7730\n",
      "Epoch 23/100\n",
      "380/380 [==============================] - 0s 151us/step - loss: 0.2732 - accuracy: 0.8711 - val_loss: 0.5800 - val_accuracy: 0.7975\n",
      "Epoch 24/100\n",
      "380/380 [==============================] - 0s 165us/step - loss: 0.2414 - accuracy: 0.9000 - val_loss: 0.6419 - val_accuracy: 0.7362\n",
      "Epoch 25/100\n",
      "380/380 [==============================] - 0s 141us/step - loss: 0.2628 - accuracy: 0.8895 - val_loss: 0.6365 - val_accuracy: 0.8037\n",
      "Epoch 26/100\n",
      "380/380 [==============================] - 0s 114us/step - loss: 0.2570 - accuracy: 0.8974 - val_loss: 0.5915 - val_accuracy: 0.7914\n",
      "Epoch 27/100\n",
      "380/380 [==============================] - 0s 136us/step - loss: 0.2351 - accuracy: 0.9053 - val_loss: 0.6588 - val_accuracy: 0.7669\n",
      "Epoch 28/100\n",
      "380/380 [==============================] - 0s 123us/step - loss: 0.2384 - accuracy: 0.9079 - val_loss: 0.5976 - val_accuracy: 0.7914\n",
      "Epoch 29/100\n",
      "380/380 [==============================] - 0s 124us/step - loss: 0.2324 - accuracy: 0.8974 - val_loss: 0.6139 - val_accuracy: 0.7853\n",
      "Epoch 30/100\n",
      "380/380 [==============================] - 0s 130us/step - loss: 0.2381 - accuracy: 0.9000 - val_loss: 0.6276 - val_accuracy: 0.7853\n",
      "Epoch 31/100\n",
      "380/380 [==============================] - 0s 129us/step - loss: 0.2530 - accuracy: 0.8947 - val_loss: 0.5941 - val_accuracy: 0.7853\n",
      "Epoch 32/100\n",
      "380/380 [==============================] - 0s 131us/step - loss: 0.2416 - accuracy: 0.8921 - val_loss: 0.6363 - val_accuracy: 0.7546\n",
      "Epoch 33/100\n",
      "380/380 [==============================] - 0s 110us/step - loss: 0.2491 - accuracy: 0.8895 - val_loss: 0.6049 - val_accuracy: 0.7853\n",
      "Epoch 34/100\n",
      "380/380 [==============================] - 0s 231us/step - loss: 0.2328 - accuracy: 0.9026 - val_loss: 0.6139 - val_accuracy: 0.7914\n",
      "Epoch 35/100\n",
      "380/380 [==============================] - 0s 181us/step - loss: 0.2226 - accuracy: 0.9000 - val_loss: 0.6158 - val_accuracy: 0.7853\n",
      "Epoch 36/100\n",
      "380/380 [==============================] - 0s 153us/step - loss: 0.2226 - accuracy: 0.9053 - val_loss: 0.6237 - val_accuracy: 0.8098\n",
      "Epoch 37/100\n",
      "380/380 [==============================] - 0s 134us/step - loss: 0.2276 - accuracy: 0.9132 - val_loss: 0.6380 - val_accuracy: 0.8098\n",
      "Epoch 38/100\n",
      "380/380 [==============================] - 0s 133us/step - loss: 0.2367 - accuracy: 0.9053 - val_loss: 0.6936 - val_accuracy: 0.7362\n",
      "Epoch 39/100\n",
      "380/380 [==============================] - 0s 189us/step - loss: 0.2330 - accuracy: 0.9079 - val_loss: 0.6531 - val_accuracy: 0.7853\n",
      "Epoch 40/100\n",
      "380/380 [==============================] - 0s 193us/step - loss: 0.2166 - accuracy: 0.9105 - val_loss: 0.7055 - val_accuracy: 0.7791\n",
      "Epoch 41/100\n",
      "380/380 [==============================] - 0s 134us/step - loss: 0.2297 - accuracy: 0.9053 - val_loss: 0.6186 - val_accuracy: 0.7853\n",
      "Epoch 42/100\n",
      "380/380 [==============================] - 0s 135us/step - loss: 0.2303 - accuracy: 0.9026 - val_loss: 0.6258 - val_accuracy: 0.7914\n",
      "Epoch 43/100\n",
      "380/380 [==============================] - 0s 135us/step - loss: 0.2136 - accuracy: 0.9263 - val_loss: 0.5964 - val_accuracy: 0.7914\n",
      "Epoch 44/100\n",
      "380/380 [==============================] - 0s 142us/step - loss: 0.2416 - accuracy: 0.9000 - val_loss: 0.6875 - val_accuracy: 0.7669\n",
      "Epoch 45/100\n",
      "380/380 [==============================] - 0s 145us/step - loss: 0.2484 - accuracy: 0.9000 - val_loss: 0.7330 - val_accuracy: 0.7607\n",
      "Epoch 46/100\n",
      "380/380 [==============================] - 0s 152us/step - loss: 0.2327 - accuracy: 0.8921 - val_loss: 0.6575 - val_accuracy: 0.7730\n",
      "Epoch 47/100\n",
      "380/380 [==============================] - 0s 146us/step - loss: 0.2435 - accuracy: 0.8842 - val_loss: 0.7135 - val_accuracy: 0.7485\n",
      "Epoch 48/100\n",
      "380/380 [==============================] - 0s 574us/step - loss: 0.2376 - accuracy: 0.8974 - val_loss: 0.6436 - val_accuracy: 0.7975\n",
      "Epoch 49/100\n",
      "380/380 [==============================] - 0s 160us/step - loss: 0.2142 - accuracy: 0.9105 - val_loss: 0.6159 - val_accuracy: 0.7853\n",
      "Epoch 50/100\n",
      "380/380 [==============================] - 0s 124us/step - loss: 0.2085 - accuracy: 0.9211 - val_loss: 0.6070 - val_accuracy: 0.7607\n",
      "Epoch 51/100\n",
      "380/380 [==============================] - 0s 128us/step - loss: 0.2327 - accuracy: 0.8974 - val_loss: 0.6656 - val_accuracy: 0.7975\n",
      "Epoch 52/100\n",
      "380/380 [==============================] - 0s 174us/step - loss: 0.2100 - accuracy: 0.9132 - val_loss: 0.7282 - val_accuracy: 0.7178\n",
      "Epoch 53/100\n",
      "380/380 [==============================] - 0s 197us/step - loss: 0.2134 - accuracy: 0.9079 - val_loss: 0.6331 - val_accuracy: 0.8037\n",
      "Epoch 54/100\n",
      "380/380 [==============================] - 0s 128us/step - loss: 0.2116 - accuracy: 0.9184 - val_loss: 0.6016 - val_accuracy: 0.7914\n",
      "Epoch 55/100\n",
      "380/380 [==============================] - 0s 143us/step - loss: 0.2390 - accuracy: 0.9053 - val_loss: 0.6658 - val_accuracy: 0.7423\n",
      "Epoch 56/100\n",
      "380/380 [==============================] - 0s 127us/step - loss: 0.2643 - accuracy: 0.8895 - val_loss: 0.5929 - val_accuracy: 0.7914\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "380/380 [==============================] - 0s 110us/step - loss: 0.2208 - accuracy: 0.9026 - val_loss: 0.6264 - val_accuracy: 0.7853\n",
      "Epoch 58/100\n",
      "380/380 [==============================] - 0s 111us/step - loss: 0.2047 - accuracy: 0.9211 - val_loss: 0.6408 - val_accuracy: 0.7730\n",
      "Epoch 59/100\n",
      "380/380 [==============================] - 0s 359us/step - loss: 0.2110 - accuracy: 0.9053 - val_loss: 0.6313 - val_accuracy: 0.8098\n",
      "Epoch 60/100\n",
      "380/380 [==============================] - 0s 165us/step - loss: 0.2153 - accuracy: 0.9079 - val_loss: 0.6313 - val_accuracy: 0.8098\n",
      "Epoch 61/100\n",
      "380/380 [==============================] - 0s 132us/step - loss: 0.2150 - accuracy: 0.9105 - val_loss: 0.5999 - val_accuracy: 0.7914\n",
      "Epoch 62/100\n",
      "380/380 [==============================] - 0s 134us/step - loss: 0.2003 - accuracy: 0.9105 - val_loss: 0.5945 - val_accuracy: 0.7914\n",
      "Epoch 63/100\n",
      "380/380 [==============================] - 0s 124us/step - loss: 0.2108 - accuracy: 0.9132 - val_loss: 0.7039 - val_accuracy: 0.7362\n",
      "Epoch 64/100\n",
      "380/380 [==============================] - 0s 124us/step - loss: 0.2073 - accuracy: 0.8974 - val_loss: 0.6484 - val_accuracy: 0.7791\n",
      "Epoch 65/100\n",
      "380/380 [==============================] - 0s 123us/step - loss: 0.2436 - accuracy: 0.9105 - val_loss: 0.6697 - val_accuracy: 0.7730\n",
      "Epoch 66/100\n",
      "380/380 [==============================] - 0s 143us/step - loss: 0.2197 - accuracy: 0.9105 - val_loss: 0.6512 - val_accuracy: 0.7914\n",
      "Epoch 67/100\n",
      "380/380 [==============================] - 0s 113us/step - loss: 0.2471 - accuracy: 0.9026 - val_loss: 0.7141 - val_accuracy: 0.7423\n",
      "Epoch 68/100\n",
      "380/380 [==============================] - 0s 111us/step - loss: 0.2174 - accuracy: 0.9105 - val_loss: 0.7284 - val_accuracy: 0.7485\n",
      "Epoch 69/100\n",
      "380/380 [==============================] - 0s 104us/step - loss: 0.2498 - accuracy: 0.8974 - val_loss: 0.7437 - val_accuracy: 0.7853\n",
      "Epoch 70/100\n",
      "380/380 [==============================] - 0s 109us/step - loss: 0.2440 - accuracy: 0.9053 - val_loss: 0.5990 - val_accuracy: 0.7853\n",
      "Epoch 71/100\n",
      "380/380 [==============================] - 0s 107us/step - loss: 0.2380 - accuracy: 0.9026 - val_loss: 0.5913 - val_accuracy: 0.8098\n",
      "Epoch 72/100\n",
      "380/380 [==============================] - 0s 110us/step - loss: 0.2259 - accuracy: 0.9079 - val_loss: 0.6033 - val_accuracy: 0.7546\n",
      "Epoch 73/100\n",
      "380/380 [==============================] - 0s 101us/step - loss: 0.2675 - accuracy: 0.8789 - val_loss: 0.6040 - val_accuracy: 0.7730\n",
      "Epoch 74/100\n",
      "380/380 [==============================] - 0s 104us/step - loss: 0.2134 - accuracy: 0.9079 - val_loss: 0.6251 - val_accuracy: 0.7853\n",
      "Epoch 75/100\n",
      "380/380 [==============================] - 0s 130us/step - loss: 0.2057 - accuracy: 0.9211 - val_loss: 0.6808 - val_accuracy: 0.7669\n",
      "Epoch 76/100\n",
      "380/380 [==============================] - 0s 230us/step - loss: 0.2050 - accuracy: 0.9105 - val_loss: 0.6609 - val_accuracy: 0.7975\n",
      "Epoch 77/100\n",
      "380/380 [==============================] - 0s 142us/step - loss: 0.2071 - accuracy: 0.9105 - val_loss: 0.6231 - val_accuracy: 0.7791\n",
      "Epoch 78/100\n",
      "380/380 [==============================] - 0s 333us/step - loss: 0.2033 - accuracy: 0.9079 - val_loss: 0.5989 - val_accuracy: 0.7914\n",
      "Epoch 79/100\n",
      "380/380 [==============================] - 0s 186us/step - loss: 0.2236 - accuracy: 0.9079 - val_loss: 0.6075 - val_accuracy: 0.7853\n",
      "Epoch 80/100\n",
      "380/380 [==============================] - 0s 611us/step - loss: 0.2187 - accuracy: 0.9105 - val_loss: 0.6148 - val_accuracy: 0.7914\n",
      "Epoch 81/100\n",
      "380/380 [==============================] - 0s 607us/step - loss: 0.2227 - accuracy: 0.9105 - val_loss: 0.6228 - val_accuracy: 0.7730\n",
      "Epoch 82/100\n",
      "380/380 [==============================] - 0s 427us/step - loss: 0.2652 - accuracy: 0.8737 - val_loss: 0.7084 - val_accuracy: 0.7117\n",
      "Epoch 83/100\n",
      "380/380 [==============================] - 0s 328us/step - loss: 0.2403 - accuracy: 0.8947 - val_loss: 0.6376 - val_accuracy: 0.8037\n",
      "Epoch 84/100\n",
      "380/380 [==============================] - 0s 276us/step - loss: 0.2101 - accuracy: 0.9132 - val_loss: 0.7063 - val_accuracy: 0.7853\n",
      "Epoch 85/100\n",
      "380/380 [==============================] - 0s 313us/step - loss: 0.2119 - accuracy: 0.9211 - val_loss: 0.6499 - val_accuracy: 0.8037\n",
      "Epoch 86/100\n",
      "380/380 [==============================] - 0s 191us/step - loss: 0.1994 - accuracy: 0.9158 - val_loss: 0.6373 - val_accuracy: 0.8037\n",
      "Epoch 87/100\n",
      "380/380 [==============================] - 0s 210us/step - loss: 0.2309 - accuracy: 0.8895 - val_loss: 0.6260 - val_accuracy: 0.8098\n",
      "Epoch 88/100\n",
      "380/380 [==============================] - 0s 172us/step - loss: 0.2001 - accuracy: 0.9158 - val_loss: 0.6359 - val_accuracy: 0.8037\n",
      "Epoch 89/100\n",
      "380/380 [==============================] - 0s 178us/step - loss: 0.1978 - accuracy: 0.9053 - val_loss: 0.6464 - val_accuracy: 0.8037\n",
      "Epoch 90/100\n",
      "380/380 [==============================] - 0s 165us/step - loss: 0.1962 - accuracy: 0.9132 - val_loss: 0.6464 - val_accuracy: 0.8037\n",
      "Epoch 91/100\n",
      "380/380 [==============================] - 0s 196us/step - loss: 0.2083 - accuracy: 0.9105 - val_loss: 0.6538 - val_accuracy: 0.8037\n",
      "Epoch 92/100\n",
      "380/380 [==============================] - 0s 173us/step - loss: 0.1992 - accuracy: 0.9158 - val_loss: 0.6383 - val_accuracy: 0.8098\n",
      "Epoch 93/100\n",
      "380/380 [==============================] - 0s 146us/step - loss: 0.1973 - accuracy: 0.9158 - val_loss: 0.6210 - val_accuracy: 0.8098\n",
      "Epoch 94/100\n",
      "380/380 [==============================] - 0s 165us/step - loss: 0.1952 - accuracy: 0.9184 - val_loss: 0.6207 - val_accuracy: 0.7853\n",
      "Epoch 95/100\n",
      "380/380 [==============================] - 0s 150us/step - loss: 0.1937 - accuracy: 0.9158 - val_loss: 0.6184 - val_accuracy: 0.8160\n",
      "Epoch 96/100\n",
      "380/380 [==============================] - 0s 157us/step - loss: 0.2129 - accuracy: 0.9105 - val_loss: 0.6382 - val_accuracy: 0.7730\n",
      "Epoch 97/100\n",
      "380/380 [==============================] - 0s 139us/step - loss: 0.2514 - accuracy: 0.9053 - val_loss: 0.6764 - val_accuracy: 0.7853\n",
      "Epoch 98/100\n",
      "380/380 [==============================] - 0s 174us/step - loss: 0.2352 - accuracy: 0.8895 - val_loss: 0.7220 - val_accuracy: 0.7423\n",
      "Epoch 99/100\n",
      "380/380 [==============================] - 0s 180us/step - loss: 0.2139 - accuracy: 0.9026 - val_loss: 0.6219 - val_accuracy: 0.8098\n",
      "Epoch 100/100\n",
      "380/380 [==============================] - 0s 174us/step - loss: 0.2220 - accuracy: 0.9132 - val_loss: 0.6586 - val_accuracy: 0.8037\n"
     ]
    }
   ],
   "source": [
    "hist1_over = model1_over.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 90.24%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_2.xlsx\",\n",
    "                        sheet_name=0,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>CFBRSa26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.758914</td>\n",
       "      <td>0.241086</td>\n",
       "      <td>4.638713e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.005361</td>\n",
       "      <td>0.016236</td>\n",
       "      <td>9.784034e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS112</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.726623</td>\n",
       "      <td>0.273376</td>\n",
       "      <td>1.520979e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS216</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.138322</td>\n",
       "      <td>0.861665</td>\n",
       "      <td>1.334123e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS021</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.882176</td>\n",
       "      <td>0.117824</td>\n",
       "      <td>1.414530e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4279</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>9.998934e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4280</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.002048</td>\n",
       "      <td>9.976944e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4281</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS205</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>9.999435e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4282</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.002048</td>\n",
       "      <td>9.976944e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4283</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.000929</td>\n",
       "      <td>9.989737e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4284 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    phage    strain  phenotype  prediction         0  \\\n",
       "0      p002ykpresabs_qual  CFBRSa26          0           0  0.758914   \n",
       "1      p002ykpresabs_qual    NRS109          2           2  0.005361   \n",
       "2      p002ykpresabs_qual    NRS112          0           0  0.726623   \n",
       "3      p002ykpresabs_qual    NRS216          1           1  0.138322   \n",
       "4      p002ykpresabs_qual    NRS021          0           0  0.882176   \n",
       "...                   ...       ...        ...         ...       ...   \n",
       "4279  pyopresabsSTCC_qual    NRS148          2           2  0.000007   \n",
       "4280  pyopresabsSTCC_qual    NRS255          2           2  0.000257   \n",
       "4281  pyopresabsSTCC_qual    NRS205          2           2  0.000011   \n",
       "4282  pyopresabsSTCC_qual    NRS255          2           2  0.000257   \n",
       "4283  pyopresabsSTCC_qual    NRS109          2           2  0.000097   \n",
       "\n",
       "             1             2  \n",
       "0     0.241086  4.638713e-07  \n",
       "1     0.016236  9.784034e-01  \n",
       "2     0.273376  1.520979e-06  \n",
       "3     0.861665  1.334123e-05  \n",
       "4     0.117824  1.414530e-10  \n",
       "...        ...           ...  \n",
       "4279  0.000099  9.998934e-01  \n",
       "4280  0.002048  9.976944e-01  \n",
       "4281  0.000045  9.999435e-01  \n",
       "4282  0.002048  9.976944e-01  \n",
       "4283  0.000929  9.989737e-01  \n",
       "\n",
       "[4284 rows x 7 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.91729100e-01, 1.57970380e-03, 6.69116500e-03],\n",
       "       [1.14097060e-02, 1.04540370e-01, 8.84049900e-01],\n",
       "       [9.78376850e-05, 9.85774040e-01, 1.41280090e-02],\n",
       "       [9.95715100e-01, 1.27100590e-05, 4.27222950e-03],\n",
       "       [1.13515510e-01, 7.88537500e-01, 9.79469700e-02],\n",
       "       [4.39802830e-01, 4.07325300e-01, 1.52871890e-01],\n",
       "       [9.97045930e-01, 2.13479500e-03, 8.19317700e-04],\n",
       "       [9.72656700e-01, 4.84011600e-04, 2.68592800e-02],\n",
       "       [3.43547600e-02, 9.57373400e-01, 8.27184300e-03],\n",
       "       [4.14786630e-04, 9.92141370e-01, 7.44387800e-03],\n",
       "       [4.84715070e-02, 1.54534520e-01, 7.96994000e-01],\n",
       "       [9.88449160e-01, 9.83262600e-03, 1.71824530e-03],\n",
       "       [4.95854350e-01, 1.48356170e-01, 3.55789540e-01],\n",
       "       [3.06200950e-01, 3.41136840e-01, 3.52662270e-01],\n",
       "       [9.88449160e-01, 9.83262600e-03, 1.71824530e-03],\n",
       "       [9.96626260e-01, 1.57607890e-03, 1.79763920e-03],\n",
       "       [1.51535050e-01, 1.46507320e-01, 7.01957640e-01],\n",
       "       [4.47552920e-01, 1.16874285e-01, 4.35572740e-01],\n",
       "       [3.87072400e-01, 3.67497530e-01, 2.45430020e-01],\n",
       "       [4.39802830e-01, 4.07325300e-01, 1.52871890e-01],\n",
       "       [5.53067700e-03, 9.81277400e-01, 1.31919430e-02],\n",
       "       [9.97595500e-01, 1.04990720e-03, 1.35469260e-03],\n",
       "       [9.90821840e-01, 3.77076940e-04, 8.80115400e-03],\n",
       "       [4.29776670e-04, 1.27040580e-01, 8.72529600e-01],\n",
       "       [9.98124200e-01, 1.53980530e-03, 3.36043540e-04],\n",
       "       [9.66109500e-01, 3.63069270e-04, 3.35275460e-02],\n",
       "       [4.39802830e-01, 4.07325300e-01, 1.52871890e-01],\n",
       "       [1.13515510e-01, 7.88537500e-01, 9.79469700e-02],\n",
       "       [9.95571730e-01, 2.80790850e-03, 1.62041140e-03],\n",
       "       [9.98124200e-01, 1.53980530e-03, 3.36043540e-04],\n",
       "       [2.60943710e-02, 4.04607240e-01, 5.69298400e-01],\n",
       "       [2.84940100e-01, 1.66757760e-01, 5.48302200e-01],\n",
       "       [3.81645300e-02, 9.51415660e-01, 1.04197610e-02],\n",
       "       [3.87072400e-01, 3.67497530e-01, 2.45430020e-01],\n",
       "       [3.81645300e-02, 9.51415660e-01, 1.04197610e-02],\n",
       "       [9.90292250e-01, 3.14184740e-03, 6.56593820e-03],\n",
       "       [6.00730400e-02, 9.03803300e-01, 3.61236860e-02],\n",
       "       [1.28098390e-04, 9.98509000e-01, 1.36293330e-03],\n",
       "       [2.09254750e-04, 8.44463300e-01, 1.55327380e-01],\n",
       "       [3.12244560e-01, 4.95638000e-01, 1.92117480e-01],\n",
       "       [9.97355000e-01, 7.91225860e-08, 2.64493500e-03],\n",
       "       [1.91803500e-01, 1.80667650e-01, 6.27528900e-01],\n",
       "       [9.75941200e-01, 1.99411200e-04, 2.38594040e-02],\n",
       "       [1.92186190e-01, 1.79676550e-01, 6.28137300e-01],\n",
       "       [2.09254750e-04, 8.44463300e-01, 1.55327380e-01],\n",
       "       [2.07424370e-01, 4.01308200e-01, 3.91267480e-01],\n",
       "       [1.91803500e-01, 1.80667650e-01, 6.27528900e-01],\n",
       "       [2.49621720e-04, 9.75565850e-01, 2.41845470e-02],\n",
       "       [9.98077300e-01, 5.43888900e-04, 1.37882040e-03],\n",
       "       [3.87072400e-01, 3.67497530e-01, 2.45430020e-01],\n",
       "       [9.97158400e-01, 2.71921540e-03, 1.22415570e-04],\n",
       "       [3.87072400e-01, 3.67497530e-01, 2.45430020e-01],\n",
       "       [2.97356860e-04, 9.96192800e-01, 3.50979180e-03],\n",
       "       [6.08873130e-03, 8.32504000e-01, 1.61407300e-01],\n",
       "       [8.97469000e-03, 9.82669700e-01, 8.35554800e-03],\n",
       "       [2.00353500e-01, 1.73549430e-04, 7.99472900e-01],\n",
       "       [1.35271650e-01, 6.47507250e-01, 2.17221110e-01],\n",
       "       [1.06892890e-03, 5.49971700e-03, 9.93431400e-01],\n",
       "       [9.75941200e-01, 1.99411200e-04, 2.38594040e-02],\n",
       "       [7.76234750e-01, 1.76269780e-02, 2.06138310e-01],\n",
       "       [8.27264800e-01, 1.17210420e-03, 1.71563120e-01],\n",
       "       [3.48167870e-04, 9.93218100e-01, 6.43364760e-03],\n",
       "       [9.66109500e-01, 3.63069270e-04, 3.35275460e-02],\n",
       "       [3.87072400e-01, 3.67497530e-01, 2.45430020e-01],\n",
       "       [6.00730400e-02, 9.03803300e-01, 3.61236860e-02],\n",
       "       [4.22910330e-01, 6.40617330e-04, 5.76449000e-01],\n",
       "       [9.95715100e-01, 1.27100590e-05, 4.27222950e-03],\n",
       "       [9.90821840e-01, 3.77076940e-04, 8.80115400e-03],\n",
       "       [3.03473470e-04, 6.61321200e-01, 3.38375300e-01],\n",
       "       [3.87072400e-01, 3.67497530e-01, 2.45430020e-01],\n",
       "       [4.95854350e-01, 1.48356170e-01, 3.55789540e-01],\n",
       "       [6.00730400e-02, 9.03803300e-01, 3.61236860e-02],\n",
       "       [9.66109500e-01, 3.63069270e-04, 3.35275460e-02],\n",
       "       [4.49917430e-02, 9.40849660e-01, 1.41586400e-02],\n",
       "       [3.95624400e-02, 7.09254600e-02, 8.89512100e-01],\n",
       "       [2.84553660e-05, 9.21850200e-01, 7.81214000e-02],\n",
       "       [6.00730400e-02, 9.03803300e-01, 3.61236860e-02],\n",
       "       [6.58089460e-01, 1.79170560e-02, 3.23993470e-01],\n",
       "       [9.97045930e-01, 2.13479500e-03, 8.19317700e-04],\n",
       "       [4.48493400e-01, 3.91095500e-01, 1.60411040e-01],\n",
       "       [3.03473470e-04, 6.61321200e-01, 3.38375300e-01],\n",
       "       [2.30996560e-05, 9.93781150e-01, 6.19572080e-03],\n",
       "       [4.22910330e-01, 6.40617330e-04, 5.76449000e-01],\n",
       "       [3.15853870e-05, 9.26653300e-01, 7.33150800e-02],\n",
       "       [2.09254750e-04, 8.44463300e-01, 1.55327380e-01],\n",
       "       [9.98077300e-01, 5.43888900e-04, 1.37882040e-03],\n",
       "       [9.97045930e-01, 2.13479500e-03, 8.19317700e-04],\n",
       "       [9.78376850e-05, 9.85774040e-01, 1.41280090e-02],\n",
       "       [3.38285840e-04, 9.99220850e-01, 4.40816720e-04],\n",
       "       [6.65449200e-03, 3.43123600e-02, 9.59033130e-01],\n",
       "       [9.95715100e-01, 1.27100590e-05, 4.27222950e-03],\n",
       "       [4.39802830e-01, 4.07325300e-01, 1.52871890e-01],\n",
       "       [3.40289770e-01, 6.18917350e-01, 4.07928640e-02],\n",
       "       [9.95715100e-01, 1.27100590e-05, 4.27222950e-03],\n",
       "       [1.30110330e-04, 9.99302740e-01, 5.67199500e-04],\n",
       "       [8.20366140e-02, 7.28630930e-03, 9.10677100e-01],\n",
       "       [3.79138220e-05, 5.72281600e-03, 9.94239330e-01],\n",
       "       [9.90821840e-01, 3.77076940e-04, 8.80115400e-03],\n",
       "       [6.23981930e-03, 2.29672040e-02, 9.70793000e-01],\n",
       "       [4.95854350e-01, 1.48356170e-01, 3.55789540e-01],\n",
       "       [9.95861700e-01, 3.38498010e-03, 7.53380800e-04],\n",
       "       [9.95861700e-01, 3.38498010e-03, 7.53380800e-04],\n",
       "       [9.95715100e-01, 1.27100590e-05, 4.27222950e-03],\n",
       "       [3.12244560e-01, 4.95638000e-01, 1.92117480e-01],\n",
       "       [4.70416530e-03, 4.67784200e-02, 9.48517400e-01],\n",
       "       [4.39802830e-01, 4.07325300e-01, 1.52871890e-01],\n",
       "       [9.89228600e-04, 9.85349100e-01, 1.36615740e-02],\n",
       "       [9.50966950e-01, 4.99278200e-03, 4.40402070e-02],\n",
       "       [4.95854350e-01, 1.48356170e-01, 3.55789540e-01],\n",
       "       [8.42057500e-01, 4.16056540e-04, 1.57526420e-01],\n",
       "       [3.91226350e-03, 4.54901860e-03, 9.91538700e-01],\n",
       "       [3.81645300e-02, 9.51415660e-01, 1.04197610e-02],\n",
       "       [3.87072400e-01, 3.67497530e-01, 2.45430020e-01],\n",
       "       [3.48167870e-04, 9.93218100e-01, 6.43364760e-03],\n",
       "       [3.23674620e-01, 1.63317100e-03, 6.74692300e-01],\n",
       "       [9.95861700e-01, 3.38498010e-03, 7.53380800e-04],\n",
       "       [8.83825900e-01, 5.51052570e-04, 1.15623070e-01],\n",
       "       [3.12244560e-01, 4.95638000e-01, 1.92117480e-01],\n",
       "       [1.23071530e-02, 9.61877500e-01, 2.58152350e-02],\n",
       "       [9.91628400e-01, 3.95662800e-03, 4.41493100e-03],\n",
       "       [9.95715100e-01, 1.27100590e-05, 4.27222950e-03],\n",
       "       [3.52598070e-01, 1.17672620e-01, 5.29729300e-01],\n",
       "       [5.07674500e-03, 9.02711100e-01, 9.22121600e-02],\n",
       "       [3.81883930e-04, 1.64207720e-02, 9.83197330e-01],\n",
       "       [9.98124200e-01, 1.53980530e-03, 3.36043540e-04],\n",
       "       [3.99136800e-03, 2.32859180e-01, 7.63149440e-01],\n",
       "       [5.01691900e-02, 2.27139170e-01, 7.22691600e-01],\n",
       "       [9.95861700e-01, 3.38498010e-03, 7.53380800e-04],\n",
       "       [4.58183120e-04, 6.37756800e-02, 9.35766100e-01],\n",
       "       [9.90821840e-01, 3.77076940e-04, 8.80115400e-03],\n",
       "       [9.97158400e-01, 2.71921540e-03, 1.22415570e-04],\n",
       "       [3.48167870e-04, 9.93218100e-01, 6.43364760e-03],\n",
       "       [1.05321930e-02, 3.74105950e-02, 9.52057200e-01],\n",
       "       [1.28098390e-04, 9.98509000e-01, 1.36293330e-03],\n",
       "       [1.14252480e-02, 8.32751800e-01, 1.55822920e-01],\n",
       "       [3.47087600e-01, 1.77749740e-01, 4.75162660e-01],\n",
       "       [7.76234750e-01, 1.76269780e-02, 2.06138310e-01],\n",
       "       [9.97158400e-01, 2.71921540e-03, 1.22415570e-04],\n",
       "       [2.08035670e-02, 7.59782100e-02, 9.03218150e-01],\n",
       "       [9.97253700e-01, 2.51195950e-03, 2.34374380e-04],\n",
       "       [4.88145860e-01, 3.15352920e-01, 1.96501240e-01],\n",
       "       [4.54686030e-04, 3.61883270e-02, 9.63357000e-01],\n",
       "       [9.98124200e-01, 1.53980530e-03, 3.36043540e-04],\n",
       "       [7.10966950e-03, 1.81021690e-02, 9.74788200e-01],\n",
       "       [3.22360800e-02, 1.65606450e-01, 8.02157460e-01],\n",
       "       [2.47343610e-01, 2.16698080e-01, 5.35958300e-01],\n",
       "       [3.87072400e-01, 3.67497530e-01, 2.45430020e-01],\n",
       "       [2.97356860e-04, 9.96192800e-01, 3.50979180e-03],\n",
       "       [9.96626260e-01, 1.57607890e-03, 1.79763920e-03],\n",
       "       [1.91803500e-01, 1.80667650e-01, 6.27528900e-01],\n",
       "       [9.95715100e-01, 1.27100590e-05, 4.27222950e-03],\n",
       "       [9.95861700e-01, 3.38498010e-03, 7.53380800e-04],\n",
       "       [3.87072400e-01, 3.67497530e-01, 2.45430020e-01],\n",
       "       [9.75941200e-01, 1.99411200e-04, 2.38594040e-02],\n",
       "       [1.55646220e-01, 2.03955530e-01, 6.40398200e-01],\n",
       "       [5.41608200e-01, 2.80787830e-01, 1.77604000e-01],\n",
       "       [9.97595500e-01, 1.04990720e-03, 1.35469260e-03],\n",
       "       [7.25756960e-02, 1.22731210e-01, 8.04693100e-01],\n",
       "       [8.83825900e-01, 5.51052570e-04, 1.15623070e-01],\n",
       "       [3.03473470e-04, 6.61321200e-01, 3.38375300e-01],\n",
       "       [2.66840050e-05, 7.20237750e-03, 9.92770970e-01],\n",
       "       [2.09254750e-04, 8.44463300e-01, 1.55327380e-01],\n",
       "       [4.39802830e-01, 4.07325300e-01, 1.52871890e-01]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob = df_proba[df_proba['phage']=='p11kpresabs_qual'].iloc[:,-3:]\n",
    "y_prob = y_prob.to_numpy()\n",
    "y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Retrieved from https://github.com/scikit-learn/scikit-learn/issues/3298\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "def rocauc_ovo(truth, pred, average=\"macro\", multi_class=\"ovo\"):\n",
    "\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(truth)\n",
    "\n",
    "    truth = lb.transform(truth)   \n",
    "    \n",
    "    return roc_auc_score(truth, pred, average=average, multi_class=multi_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9317172746836354"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo1 = rocauc_ovo(y_test_over, y_prob, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rocauc_ovr(truth, pred, average=\"macro\", multi_class=\"ovr\"):\n",
    "\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(truth)\n",
    "\n",
    "    truth = lb.transform(truth)   \n",
    "\n",
    "    return roc_auc_score(truth, pred, average=average, multi_class=multi_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9317172746836354"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr1 = rocauc_ovr(y_test_over, y_prob, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=234,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat2 = pd.DataFrame(X_test_over[:,0])\n",
    "dat2['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS027</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CFBRSa07</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CFBRSa27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>504</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CFBREBSa129</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>SR3569</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>NRS243</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>GA48963</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>504</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>CFBREBSa123</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test\n",
       "0         NRS027     0\n",
       "1       CFBRSa07     0\n",
       "2       CFBRSa27     1\n",
       "3            504     1\n",
       "4    CFBREBSa129     0\n",
       "..           ...   ...\n",
       "158       SR3569     2\n",
       "159       NRS243     1\n",
       "160      GA48963     1\n",
       "161          504     1\n",
       "162  CFBREBSa123     0\n",
       "\n",
       "[163 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over2 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over2.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 380 samples, validate on 163 samples\n",
      "Epoch 1/100\n",
      "380/380 [==============================] - 0s 660us/step - loss: 1.0803 - accuracy: 0.4132 - val_loss: 1.0392 - val_accuracy: 0.4540\n",
      "Epoch 2/100\n",
      "380/380 [==============================] - 0s 319us/step - loss: 1.0433 - accuracy: 0.4711 - val_loss: 1.0081 - val_accuracy: 0.4417\n",
      "Epoch 3/100\n",
      "380/380 [==============================] - 0s 244us/step - loss: 0.9865 - accuracy: 0.5342 - val_loss: 0.9426 - val_accuracy: 0.5951\n",
      "Epoch 4/100\n",
      "380/380 [==============================] - 0s 301us/step - loss: 0.9300 - accuracy: 0.6079 - val_loss: 0.8803 - val_accuracy: 0.6196\n",
      "Epoch 5/100\n",
      "380/380 [==============================] - 0s 283us/step - loss: 0.8783 - accuracy: 0.5921 - val_loss: 0.8754 - val_accuracy: 0.6258\n",
      "Epoch 6/100\n",
      "380/380 [==============================] - 0s 157us/step - loss: 0.8566 - accuracy: 0.6474 - val_loss: 0.8344 - val_accuracy: 0.6442\n",
      "Epoch 7/100\n",
      "380/380 [==============================] - 0s 184us/step - loss: 0.7801 - accuracy: 0.6921 - val_loss: 0.8075 - val_accuracy: 0.6748\n",
      "Epoch 8/100\n",
      "380/380 [==============================] - 0s 1ms/step - loss: 0.7422 - accuracy: 0.6763 - val_loss: 0.7779 - val_accuracy: 0.6748\n",
      "Epoch 9/100\n",
      "380/380 [==============================] - 0s 221us/step - loss: 0.7119 - accuracy: 0.7079 - val_loss: 0.7477 - val_accuracy: 0.6933\n",
      "Epoch 10/100\n",
      "380/380 [==============================] - 0s 438us/step - loss: 0.6775 - accuracy: 0.7105 - val_loss: 0.7362 - val_accuracy: 0.6687\n",
      "Epoch 11/100\n",
      "380/380 [==============================] - 0s 219us/step - loss: 0.6697 - accuracy: 0.7053 - val_loss: 0.7176 - val_accuracy: 0.6748\n",
      "Epoch 12/100\n",
      "380/380 [==============================] - 0s 504us/step - loss: 0.6284 - accuracy: 0.7211 - val_loss: 0.7014 - val_accuracy: 0.7239\n",
      "Epoch 13/100\n",
      "380/380 [==============================] - 0s 655us/step - loss: 0.6007 - accuracy: 0.7395 - val_loss: 0.6798 - val_accuracy: 0.7117\n",
      "Epoch 14/100\n",
      "380/380 [==============================] - 0s 461us/step - loss: 0.6048 - accuracy: 0.7342 - val_loss: 0.6609 - val_accuracy: 0.7178\n",
      "Epoch 15/100\n",
      "380/380 [==============================] - 0s 218us/step - loss: 0.5995 - accuracy: 0.7421 - val_loss: 0.7303 - val_accuracy: 0.6564\n",
      "Epoch 16/100\n",
      "380/380 [==============================] - 0s 205us/step - loss: 0.5585 - accuracy: 0.7737 - val_loss: 0.6588 - val_accuracy: 0.7239\n",
      "Epoch 17/100\n",
      "380/380 [==============================] - 0s 218us/step - loss: 0.5296 - accuracy: 0.7789 - val_loss: 0.6233 - val_accuracy: 0.7546\n",
      "Epoch 18/100\n",
      "380/380 [==============================] - 0s 236us/step - loss: 0.5116 - accuracy: 0.7737 - val_loss: 0.6227 - val_accuracy: 0.7546\n",
      "Epoch 19/100\n",
      "380/380 [==============================] - 0s 266us/step - loss: 0.5040 - accuracy: 0.7632 - val_loss: 0.6037 - val_accuracy: 0.7178\n",
      "Epoch 20/100\n",
      "380/380 [==============================] - 0s 243us/step - loss: 0.5198 - accuracy: 0.7579 - val_loss: 0.5996 - val_accuracy: 0.7362\n",
      "Epoch 21/100\n",
      "380/380 [==============================] - 0s 177us/step - loss: 0.4721 - accuracy: 0.7816 - val_loss: 0.6022 - val_accuracy: 0.7485\n",
      "Epoch 22/100\n",
      "380/380 [==============================] - 0s 392us/step - loss: 0.4928 - accuracy: 0.7605 - val_loss: 0.6187 - val_accuracy: 0.6994\n",
      "Epoch 23/100\n",
      "380/380 [==============================] - 0s 202us/step - loss: 0.4877 - accuracy: 0.7816 - val_loss: 0.6023 - val_accuracy: 0.7178\n",
      "Epoch 24/100\n",
      "380/380 [==============================] - 0s 225us/step - loss: 0.4573 - accuracy: 0.7789 - val_loss: 0.5886 - val_accuracy: 0.7178\n",
      "Epoch 25/100\n",
      "380/380 [==============================] - 0s 257us/step - loss: 0.4343 - accuracy: 0.8079 - val_loss: 0.5928 - val_accuracy: 0.7117\n",
      "Epoch 26/100\n",
      "380/380 [==============================] - 0s 214us/step - loss: 0.4745 - accuracy: 0.7895 - val_loss: 0.6144 - val_accuracy: 0.7117\n",
      "Epoch 27/100\n",
      "380/380 [==============================] - 0s 206us/step - loss: 0.4648 - accuracy: 0.7947 - val_loss: 0.6176 - val_accuracy: 0.7178\n",
      "Epoch 28/100\n",
      "380/380 [==============================] - 0s 238us/step - loss: 0.4222 - accuracy: 0.8105 - val_loss: 0.5233 - val_accuracy: 0.7853\n",
      "Epoch 29/100\n",
      "380/380 [==============================] - 0s 406us/step - loss: 0.4027 - accuracy: 0.8105 - val_loss: 0.5347 - val_accuracy: 0.7669\n",
      "Epoch 30/100\n",
      "380/380 [==============================] - 0s 184us/step - loss: 0.3929 - accuracy: 0.8263 - val_loss: 0.5175 - val_accuracy: 0.8282\n",
      "Epoch 31/100\n",
      "380/380 [==============================] - 0s 493us/step - loss: 0.3904 - accuracy: 0.8026 - val_loss: 0.5145 - val_accuracy: 0.8221\n",
      "Epoch 32/100\n",
      "380/380 [==============================] - 0s 262us/step - loss: 0.3844 - accuracy: 0.8342 - val_loss: 0.5205 - val_accuracy: 0.7914\n",
      "Epoch 33/100\n",
      "380/380 [==============================] - 0s 287us/step - loss: 0.3910 - accuracy: 0.8237 - val_loss: 0.5838 - val_accuracy: 0.7423\n",
      "Epoch 34/100\n",
      "380/380 [==============================] - 0s 237us/step - loss: 0.3715 - accuracy: 0.8342 - val_loss: 0.5291 - val_accuracy: 0.8037\n",
      "Epoch 35/100\n",
      "380/380 [==============================] - 0s 226us/step - loss: 0.3600 - accuracy: 0.8658 - val_loss: 0.5039 - val_accuracy: 0.8221\n",
      "Epoch 36/100\n",
      "380/380 [==============================] - 0s 211us/step - loss: 0.3731 - accuracy: 0.8237 - val_loss: 0.4903 - val_accuracy: 0.7791\n",
      "Epoch 37/100\n",
      "380/380 [==============================] - 0s 257us/step - loss: 0.3430 - accuracy: 0.8632 - val_loss: 0.5151 - val_accuracy: 0.7669\n",
      "Epoch 38/100\n",
      "380/380 [==============================] - 0s 288us/step - loss: 0.3576 - accuracy: 0.8500 - val_loss: 0.4801 - val_accuracy: 0.8221\n",
      "Epoch 39/100\n",
      "380/380 [==============================] - 0s 296us/step - loss: 0.3433 - accuracy: 0.8447 - val_loss: 0.5054 - val_accuracy: 0.8037\n",
      "Epoch 40/100\n",
      "380/380 [==============================] - 0s 200us/step - loss: 0.3666 - accuracy: 0.8289 - val_loss: 0.5237 - val_accuracy: 0.7791\n",
      "Epoch 41/100\n",
      "380/380 [==============================] - 0s 785us/step - loss: 0.3793 - accuracy: 0.8342 - val_loss: 0.5471 - val_accuracy: 0.7607\n",
      "Epoch 42/100\n",
      "380/380 [==============================] - 0s 435us/step - loss: 0.3328 - accuracy: 0.8474 - val_loss: 0.4774 - val_accuracy: 0.8282\n",
      "Epoch 43/100\n",
      "380/380 [==============================] - 0s 313us/step - loss: 0.3378 - accuracy: 0.8474 - val_loss: 0.4804 - val_accuracy: 0.7853\n",
      "Epoch 44/100\n",
      "380/380 [==============================] - 0s 227us/step - loss: 0.3613 - accuracy: 0.8342 - val_loss: 0.6120 - val_accuracy: 0.7117\n",
      "Epoch 45/100\n",
      "380/380 [==============================] - ETA: 0s - loss: 0.4089 - accuracy: 0.81 - 0s 251us/step - loss: 0.3521 - accuracy: 0.8289 - val_loss: 0.5076 - val_accuracy: 0.8282\n",
      "Epoch 46/100\n",
      "380/380 [==============================] - 0s 401us/step - loss: 0.3093 - accuracy: 0.8526 - val_loss: 0.5320 - val_accuracy: 0.7669\n",
      "Epoch 47/100\n",
      "380/380 [==============================] - 0s 454us/step - loss: 0.3228 - accuracy: 0.8474 - val_loss: 0.5964 - val_accuracy: 0.7362\n",
      "Epoch 48/100\n",
      "380/380 [==============================] - 0s 317us/step - loss: 0.3487 - accuracy: 0.8395 - val_loss: 0.4962 - val_accuracy: 0.7914\n",
      "Epoch 49/100\n",
      "380/380 [==============================] - 0s 194us/step - loss: 0.3864 - accuracy: 0.8474 - val_loss: 0.5709 - val_accuracy: 0.7485\n",
      "Epoch 50/100\n",
      "380/380 [==============================] - 0s 180us/step - loss: 0.3792 - accuracy: 0.8158 - val_loss: 0.5066 - val_accuracy: 0.7853\n",
      "Epoch 51/100\n",
      "380/380 [==============================] - 0s 166us/step - loss: 0.3473 - accuracy: 0.8342 - val_loss: 0.5033 - val_accuracy: 0.7730\n",
      "Epoch 52/100\n",
      "380/380 [==============================] - 0s 193us/step - loss: 0.3204 - accuracy: 0.8395 - val_loss: 0.5461 - val_accuracy: 0.7669\n",
      "Epoch 53/100\n",
      "380/380 [==============================] - 0s 166us/step - loss: 0.3095 - accuracy: 0.8632 - val_loss: 0.4711 - val_accuracy: 0.8037\n",
      "Epoch 54/100\n",
      "380/380 [==============================] - 0s 133us/step - loss: 0.2945 - accuracy: 0.8632 - val_loss: 0.4650 - val_accuracy: 0.8221\n",
      "Epoch 55/100\n",
      "380/380 [==============================] - 0s 157us/step - loss: 0.2715 - accuracy: 0.8842 - val_loss: 0.5029 - val_accuracy: 0.8282\n",
      "Epoch 56/100\n",
      "380/380 [==============================] - 0s 570us/step - loss: 0.2910 - accuracy: 0.8632 - val_loss: 0.5447 - val_accuracy: 0.7975\n",
      "Epoch 57/100\n",
      "380/380 [==============================] - 0s 199us/step - loss: 0.3006 - accuracy: 0.8684 - val_loss: 0.5069 - val_accuracy: 0.8160\n",
      "Epoch 58/100\n",
      "380/380 [==============================] - 0s 179us/step - loss: 0.2913 - accuracy: 0.8553 - val_loss: 0.4942 - val_accuracy: 0.7791\n",
      "Epoch 59/100\n",
      "380/380 [==============================] - 0s 173us/step - loss: 0.3032 - accuracy: 0.8500 - val_loss: 0.4840 - val_accuracy: 0.8160\n",
      "Epoch 60/100\n",
      "380/380 [==============================] - 0s 138us/step - loss: 0.2990 - accuracy: 0.8763 - val_loss: 0.5006 - val_accuracy: 0.8344\n",
      "Epoch 61/100\n",
      "380/380 [==============================] - 0s 132us/step - loss: 0.3097 - accuracy: 0.8658 - val_loss: 0.5245 - val_accuracy: 0.8098\n",
      "Epoch 62/100\n",
      "380/380 [==============================] - 0s 125us/step - loss: 0.2876 - accuracy: 0.8816 - val_loss: 0.6175 - val_accuracy: 0.7301\n",
      "Epoch 63/100\n",
      "380/380 [==============================] - 0s 124us/step - loss: 0.3337 - accuracy: 0.8474 - val_loss: 0.4938 - val_accuracy: 0.8344\n",
      "Epoch 64/100\n",
      "380/380 [==============================] - 0s 142us/step - loss: 0.3162 - accuracy: 0.8526 - val_loss: 0.5478 - val_accuracy: 0.8160\n",
      "Epoch 65/100\n",
      "380/380 [==============================] - 0s 154us/step - loss: 0.2896 - accuracy: 0.8711 - val_loss: 0.4754 - val_accuracy: 0.8037\n",
      "Epoch 66/100\n",
      "380/380 [==============================] - 0s 134us/step - loss: 0.2685 - accuracy: 0.8895 - val_loss: 0.4663 - val_accuracy: 0.8098\n",
      "Epoch 67/100\n",
      "380/380 [==============================] - 0s 117us/step - loss: 0.2660 - accuracy: 0.8868 - val_loss: 0.4926 - val_accuracy: 0.8344\n",
      "Epoch 68/100\n",
      "380/380 [==============================] - 0s 147us/step - loss: 0.2686 - accuracy: 0.8737 - val_loss: 0.5387 - val_accuracy: 0.7914\n",
      "Epoch 69/100\n",
      "380/380 [==============================] - 0s 125us/step - loss: 0.2767 - accuracy: 0.8842 - val_loss: 0.6266 - val_accuracy: 0.7178\n",
      "Epoch 70/100\n",
      "380/380 [==============================] - 0s 117us/step - loss: 0.2828 - accuracy: 0.8737 - val_loss: 0.4768 - val_accuracy: 0.7914\n",
      "Epoch 71/100\n",
      "380/380 [==============================] - 0s 143us/step - loss: 0.2870 - accuracy: 0.8763 - val_loss: 0.5360 - val_accuracy: 0.7730\n",
      "Epoch 72/100\n",
      "380/380 [==============================] - 0s 119us/step - loss: 0.2757 - accuracy: 0.8737 - val_loss: 0.5609 - val_accuracy: 0.7791\n",
      "Epoch 73/100\n",
      "380/380 [==============================] - 0s 171us/step - loss: 0.2585 - accuracy: 0.8895 - val_loss: 0.5140 - val_accuracy: 0.8160\n",
      "Epoch 74/100\n",
      "380/380 [==============================] - 0s 183us/step - loss: 0.2792 - accuracy: 0.8711 - val_loss: 0.5002 - val_accuracy: 0.8160\n",
      "Epoch 75/100\n",
      "380/380 [==============================] - 0s 129us/step - loss: 0.2649 - accuracy: 0.8816 - val_loss: 0.4737 - val_accuracy: 0.8221\n",
      "Epoch 76/100\n",
      "380/380 [==============================] - 0s 118us/step - loss: 0.2551 - accuracy: 0.8895 - val_loss: 0.4779 - val_accuracy: 0.8160\n",
      "Epoch 77/100\n",
      "380/380 [==============================] - 0s 135us/step - loss: 0.2667 - accuracy: 0.8868 - val_loss: 0.4755 - val_accuracy: 0.8589\n",
      "Epoch 78/100\n",
      "380/380 [==============================] - 0s 144us/step - loss: 0.2597 - accuracy: 0.8842 - val_loss: 0.4821 - val_accuracy: 0.8282\n",
      "Epoch 79/100\n",
      "380/380 [==============================] - 0s 156us/step - loss: 0.2605 - accuracy: 0.8868 - val_loss: 0.4423 - val_accuracy: 0.8160\n",
      "Epoch 80/100\n",
      "380/380 [==============================] - 0s 171us/step - loss: 0.2835 - accuracy: 0.8711 - val_loss: 0.4848 - val_accuracy: 0.7914\n",
      "Epoch 81/100\n",
      "380/380 [==============================] - 0s 125us/step - loss: 0.2944 - accuracy: 0.8605 - val_loss: 0.5769 - val_accuracy: 0.8098\n",
      "Epoch 82/100\n",
      "380/380 [==============================] - 0s 130us/step - loss: 0.3486 - accuracy: 0.8447 - val_loss: 0.4617 - val_accuracy: 0.8221\n",
      "Epoch 83/100\n",
      "380/380 [==============================] - 0s 166us/step - loss: 0.2712 - accuracy: 0.8789 - val_loss: 0.4431 - val_accuracy: 0.8405\n",
      "Epoch 84/100\n",
      "380/380 [==============================] - 0s 210us/step - loss: 0.2499 - accuracy: 0.8895 - val_loss: 0.4235 - val_accuracy: 0.8773\n",
      "Epoch 85/100\n",
      "380/380 [==============================] - 0s 176us/step - loss: 0.2800 - accuracy: 0.8737 - val_loss: 0.5226 - val_accuracy: 0.8405\n",
      "Epoch 86/100\n",
      "380/380 [==============================] - 0s 138us/step - loss: 0.2551 - accuracy: 0.8868 - val_loss: 0.5090 - val_accuracy: 0.8282\n",
      "Epoch 87/100\n",
      "380/380 [==============================] - 0s 123us/step - loss: 0.2485 - accuracy: 0.8816 - val_loss: 0.4689 - val_accuracy: 0.8344\n",
      "Epoch 88/100\n",
      "380/380 [==============================] - 0s 139us/step - loss: 0.2380 - accuracy: 0.9026 - val_loss: 0.4762 - val_accuracy: 0.8221\n",
      "Epoch 89/100\n",
      "380/380 [==============================] - 0s 126us/step - loss: 0.2467 - accuracy: 0.8921 - val_loss: 0.5538 - val_accuracy: 0.7975\n",
      "Epoch 90/100\n",
      "380/380 [==============================] - 0s 154us/step - loss: 0.2587 - accuracy: 0.8921 - val_loss: 0.4822 - val_accuracy: 0.8405\n",
      "Epoch 91/100\n",
      "380/380 [==============================] - 0s 140us/step - loss: 0.2465 - accuracy: 0.9000 - val_loss: 0.5719 - val_accuracy: 0.7607\n",
      "Epoch 92/100\n",
      "380/380 [==============================] - 0s 116us/step - loss: 0.2735 - accuracy: 0.8763 - val_loss: 0.5443 - val_accuracy: 0.7791\n",
      "Epoch 93/100\n",
      "380/380 [==============================] - 0s 126us/step - loss: 0.2563 - accuracy: 0.8868 - val_loss: 0.4450 - val_accuracy: 0.8405\n",
      "Epoch 94/100\n",
      "380/380 [==============================] - 0s 117us/step - loss: 0.2291 - accuracy: 0.9000 - val_loss: 0.4772 - val_accuracy: 0.7975\n",
      "Epoch 95/100\n",
      "380/380 [==============================] - 0s 104us/step - loss: 0.2573 - accuracy: 0.8895 - val_loss: 0.4831 - val_accuracy: 0.8098\n",
      "Epoch 96/100\n",
      "380/380 [==============================] - 0s 128us/step - loss: 0.2699 - accuracy: 0.8921 - val_loss: 0.4904 - val_accuracy: 0.8282\n",
      "Epoch 97/100\n",
      "380/380 [==============================] - 0s 106us/step - loss: 0.2896 - accuracy: 0.8789 - val_loss: 0.5427 - val_accuracy: 0.7853\n",
      "Epoch 98/100\n",
      "380/380 [==============================] - 0s 129us/step - loss: 0.2640 - accuracy: 0.8711 - val_loss: 0.6069 - val_accuracy: 0.7669\n",
      "Epoch 99/100\n",
      "380/380 [==============================] - 0s 103us/step - loss: 0.2696 - accuracy: 0.8816 - val_loss: 0.4401 - val_accuracy: 0.8589\n",
      "Epoch 100/100\n",
      "380/380 [==============================] - 0s 146us/step - loss: 0.2864 - accuracy: 0.8711 - val_loss: 0.5077 - val_accuracy: 0.8037\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a418ad208>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over2.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163/163 [==============================] - 0s 98us/step\n",
      "over-sampling test accuracy: 84.05%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over2 = model1_over2.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over2*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 2, 1, 0, 2, 0, 1, 2, 1, 0, 0, 1, 2, 1, 2, 1, 1, 2, 2, 1, 0,\n",
       "       1, 0, 2, 0, 1, 0, 1, 0, 0, 0, 0, 2, 1, 0, 2, 1, 0, 0, 0, 0, 2, 1,\n",
       "       1, 0, 0, 1, 1, 0, 2, 2, 0, 1, 0, 0, 2, 0, 0, 0, 2, 1, 2, 0, 2, 1,\n",
       "       0, 2, 1, 2, 2, 0, 1, 2, 1, 1, 0, 0, 0, 0, 1, 2, 1, 0, 1, 1, 2, 2,\n",
       "       0, 0, 2, 0, 1, 0, 0, 1, 0, 2, 2, 0, 0, 0, 1, 0, 1, 2, 0, 2, 1, 0,\n",
       "       1, 1, 0, 0, 2, 0, 2, 1, 1, 0, 2, 1, 2, 2, 1, 0, 1, 0, 0, 2, 0, 1,\n",
       "       2, 0, 1, 2, 1, 2, 2, 0, 1, 2, 2, 2, 0, 2, 0, 0, 2, 2, 1, 0, 0, 2,\n",
       "       1, 1, 2, 2, 2, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred2 = model1_over2.predict_classes(X_test_over)\n",
    "pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS027</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CFBRSa07</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CFBRSa27</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>504</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CFBREBSa129</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>SR3569</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>NRS243</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>GA48963</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>504</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>CFBREBSa123</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test  pred\n",
       "0         NRS027     0     0\n",
       "1       CFBRSa07     0     0\n",
       "2       CFBRSa27     1     2\n",
       "3            504     1     1\n",
       "4    CFBREBSa129     0     0\n",
       "..           ...   ...   ...\n",
       "158       SR3569     2     2\n",
       "159       NRS243     1     1\n",
       "160      GA48963     1     1\n",
       "161          504     1     1\n",
       "162  CFBREBSa123     0     0\n",
       "\n",
       "[163 rows x 3 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat2['pred'] = pred2\n",
    "dat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba2 = model1_over2.predict_proba(X_test_over)\n",
    "dat_proba2 = pd.DataFrame(proba2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.988309e-01</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>0.000907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.803634e-01</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.019541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.662070e-01</td>\n",
       "      <td>0.187860</td>\n",
       "      <td>0.645933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.041796e-01</td>\n",
       "      <td>0.556848</td>\n",
       "      <td>0.338973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.980018e-01</td>\n",
       "      <td>0.000789</td>\n",
       "      <td>0.001210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>2.914282e-02</td>\n",
       "      <td>0.151264</td>\n",
       "      <td>0.819593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>8.927739e-09</td>\n",
       "      <td>0.998998</td>\n",
       "      <td>0.001002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>2.442053e-04</td>\n",
       "      <td>0.959986</td>\n",
       "      <td>0.039770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>1.041796e-01</td>\n",
       "      <td>0.556848</td>\n",
       "      <td>0.338973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>9.980172e-01</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.001726</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0         1         2\n",
       "0    9.988309e-01  0.000262  0.000907\n",
       "1    9.803634e-01  0.000096  0.019541\n",
       "2    1.662070e-01  0.187860  0.645933\n",
       "3    1.041796e-01  0.556848  0.338973\n",
       "4    9.980018e-01  0.000789  0.001210\n",
       "..            ...       ...       ...\n",
       "158  2.914282e-02  0.151264  0.819593\n",
       "159  8.927739e-09  0.998998  0.001002\n",
       "160  2.442053e-04  0.959986  0.039770\n",
       "161  1.041796e-01  0.556848  0.338973\n",
       "162  9.980172e-01  0.000257  0.001726\n",
       "\n",
       "[163 rows x 3 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba2.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba2.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat2.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/2p11.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 380 samples, validate on 163 samples\n",
      "Epoch 1/100\n",
      "380/380 [==============================] - 0s 167us/step - loss: 0.2394 - accuracy: 0.8868 - val_loss: 0.4799 - val_accuracy: 0.7914\n",
      "Epoch 2/100\n",
      "380/380 [==============================] - 0s 156us/step - loss: 0.2582 - accuracy: 0.8895 - val_loss: 0.3973 - val_accuracy: 0.8282\n",
      "Epoch 3/100\n",
      "380/380 [==============================] - 0s 163us/step - loss: 0.2531 - accuracy: 0.8763 - val_loss: 0.4499 - val_accuracy: 0.8160\n",
      "Epoch 4/100\n",
      "380/380 [==============================] - 0s 146us/step - loss: 0.2202 - accuracy: 0.9079 - val_loss: 0.4652 - val_accuracy: 0.8528\n",
      "Epoch 5/100\n",
      "380/380 [==============================] - 0s 129us/step - loss: 0.2367 - accuracy: 0.8947 - val_loss: 0.5372 - val_accuracy: 0.7853\n",
      "Epoch 6/100\n",
      "380/380 [==============================] - 0s 124us/step - loss: 0.2371 - accuracy: 0.8947 - val_loss: 0.4480 - val_accuracy: 0.8466\n",
      "Epoch 7/100\n",
      "380/380 [==============================] - 0s 132us/step - loss: 0.2126 - accuracy: 0.9158 - val_loss: 0.5062 - val_accuracy: 0.8037\n",
      "Epoch 8/100\n",
      "380/380 [==============================] - 0s 118us/step - loss: 0.2251 - accuracy: 0.8947 - val_loss: 0.5272 - val_accuracy: 0.8282\n",
      "Epoch 9/100\n",
      "380/380 [==============================] - 0s 123us/step - loss: 0.2204 - accuracy: 0.9000 - val_loss: 0.4475 - val_accuracy: 0.8466\n",
      "Epoch 10/100\n",
      "380/380 [==============================] - 0s 123us/step - loss: 0.2559 - accuracy: 0.8868 - val_loss: 0.4470 - val_accuracy: 0.8405\n",
      "Epoch 11/100\n",
      "380/380 [==============================] - 0s 125us/step - loss: 0.2141 - accuracy: 0.9132 - val_loss: 0.5035 - val_accuracy: 0.8037\n",
      "Epoch 12/100\n",
      "380/380 [==============================] - 0s 132us/step - loss: 0.2371 - accuracy: 0.9000 - val_loss: 0.5288 - val_accuracy: 0.8282\n",
      "Epoch 13/100\n",
      "380/380 [==============================] - 0s 137us/step - loss: 0.2643 - accuracy: 0.8842 - val_loss: 0.4861 - val_accuracy: 0.8282\n",
      "Epoch 14/100\n",
      "380/380 [==============================] - 0s 123us/step - loss: 0.2396 - accuracy: 0.9026 - val_loss: 0.4837 - val_accuracy: 0.8344\n",
      "Epoch 15/100\n",
      "380/380 [==============================] - 0s 119us/step - loss: 0.2176 - accuracy: 0.9053 - val_loss: 0.4710 - val_accuracy: 0.8650\n",
      "Epoch 16/100\n",
      "380/380 [==============================] - 0s 133us/step - loss: 0.2100 - accuracy: 0.9026 - val_loss: 0.4825 - val_accuracy: 0.8282\n",
      "Epoch 17/100\n",
      "380/380 [==============================] - 0s 116us/step - loss: 0.2284 - accuracy: 0.9053 - val_loss: 0.4821 - val_accuracy: 0.7975\n",
      "Epoch 18/100\n",
      "380/380 [==============================] - 0s 113us/step - loss: 0.2221 - accuracy: 0.9000 - val_loss: 0.4779 - val_accuracy: 0.8282\n",
      "Epoch 19/100\n",
      "380/380 [==============================] - 0s 114us/step - loss: 0.2350 - accuracy: 0.9000 - val_loss: 0.4246 - val_accuracy: 0.8528\n",
      "Epoch 20/100\n",
      "380/380 [==============================] - 0s 125us/step - loss: 0.2825 - accuracy: 0.8737 - val_loss: 0.4453 - val_accuracy: 0.8466\n",
      "Epoch 21/100\n",
      "380/380 [==============================] - 0s 180us/step - loss: 0.2250 - accuracy: 0.8974 - val_loss: 0.4092 - val_accuracy: 0.8405\n",
      "Epoch 22/100\n",
      "380/380 [==============================] - 0s 155us/step - loss: 0.2404 - accuracy: 0.8974 - val_loss: 0.5049 - val_accuracy: 0.8037\n",
      "Epoch 23/100\n",
      "380/380 [==============================] - 0s 148us/step - loss: 0.2909 - accuracy: 0.8553 - val_loss: 0.4647 - val_accuracy: 0.8405\n",
      "Epoch 24/100\n",
      "380/380 [==============================] - 0s 121us/step - loss: 0.2352 - accuracy: 0.9053 - val_loss: 0.6026 - val_accuracy: 0.7730\n",
      "Epoch 25/100\n",
      "380/380 [==============================] - 0s 115us/step - loss: 0.2299 - accuracy: 0.9000 - val_loss: 0.7141 - val_accuracy: 0.7669\n",
      "Epoch 26/100\n",
      "380/380 [==============================] - 0s 113us/step - loss: 0.2498 - accuracy: 0.8868 - val_loss: 0.4992 - val_accuracy: 0.8282\n",
      "Epoch 27/100\n",
      "380/380 [==============================] - 0s 115us/step - loss: 0.2249 - accuracy: 0.8868 - val_loss: 0.4144 - val_accuracy: 0.8650\n",
      "Epoch 28/100\n",
      "380/380 [==============================] - 0s 117us/step - loss: 0.2324 - accuracy: 0.8947 - val_loss: 0.4446 - val_accuracy: 0.8528\n",
      "Epoch 29/100\n",
      "380/380 [==============================] - 0s 115us/step - loss: 0.2474 - accuracy: 0.8789 - val_loss: 0.4056 - val_accuracy: 0.8712\n",
      "Epoch 30/100\n",
      "380/380 [==============================] - 0s 123us/step - loss: 0.2454 - accuracy: 0.8974 - val_loss: 0.4291 - val_accuracy: 0.8160\n",
      "Epoch 31/100\n",
      "380/380 [==============================] - 0s 141us/step - loss: 0.2195 - accuracy: 0.9132 - val_loss: 0.4473 - val_accuracy: 0.8466\n",
      "Epoch 32/100\n",
      "380/380 [==============================] - 0s 129us/step - loss: 0.2125 - accuracy: 0.9132 - val_loss: 0.4533 - val_accuracy: 0.8344\n",
      "Epoch 33/100\n",
      "380/380 [==============================] - 0s 155us/step - loss: 0.2125 - accuracy: 0.8947 - val_loss: 0.4723 - val_accuracy: 0.8221\n",
      "Epoch 34/100\n",
      "380/380 [==============================] - 0s 198us/step - loss: 0.2386 - accuracy: 0.8921 - val_loss: 0.6155 - val_accuracy: 0.7853\n",
      "Epoch 35/100\n",
      "380/380 [==============================] - 0s 149us/step - loss: 0.2473 - accuracy: 0.8868 - val_loss: 0.5822 - val_accuracy: 0.7791\n",
      "Epoch 36/100\n",
      "380/380 [==============================] - 0s 130us/step - loss: 0.2683 - accuracy: 0.8711 - val_loss: 0.5608 - val_accuracy: 0.7975\n",
      "Epoch 37/100\n",
      "380/380 [==============================] - 0s 119us/step - loss: 0.2752 - accuracy: 0.8632 - val_loss: 0.5886 - val_accuracy: 0.7853\n",
      "Epoch 38/100\n",
      "380/380 [==============================] - 0s 111us/step - loss: 0.2869 - accuracy: 0.8737 - val_loss: 0.4855 - val_accuracy: 0.8344\n",
      "Epoch 39/100\n",
      "380/380 [==============================] - 0s 110us/step - loss: 0.2945 - accuracy: 0.8842 - val_loss: 0.4390 - val_accuracy: 0.8528\n",
      "Epoch 40/100\n",
      "380/380 [==============================] - 0s 105us/step - loss: 0.2710 - accuracy: 0.8947 - val_loss: 0.4109 - val_accuracy: 0.8834\n",
      "Epoch 41/100\n",
      "380/380 [==============================] - 0s 118us/step - loss: 0.2137 - accuracy: 0.9079 - val_loss: 0.4644 - val_accuracy: 0.8344\n",
      "Epoch 42/100\n",
      "380/380 [==============================] - 0s 113us/step - loss: 0.2179 - accuracy: 0.9026 - val_loss: 0.4276 - val_accuracy: 0.8528\n",
      "Epoch 43/100\n",
      "380/380 [==============================] - 0s 116us/step - loss: 0.2214 - accuracy: 0.9026 - val_loss: 0.4771 - val_accuracy: 0.8344\n",
      "Epoch 44/100\n",
      "380/380 [==============================] - 0s 112us/step - loss: 0.2084 - accuracy: 0.9053 - val_loss: 0.4300 - val_accuracy: 0.8405\n",
      "Epoch 45/100\n",
      "380/380 [==============================] - 0s 128us/step - loss: 0.2051 - accuracy: 0.9079 - val_loss: 0.4231 - val_accuracy: 0.8282\n",
      "Epoch 46/100\n",
      "380/380 [==============================] - 0s 175us/step - loss: 0.2435 - accuracy: 0.8868 - val_loss: 0.4568 - val_accuracy: 0.8466\n",
      "Epoch 47/100\n",
      "380/380 [==============================] - 0s 181us/step - loss: 0.2382 - accuracy: 0.9000 - val_loss: 0.4415 - val_accuracy: 0.8466\n",
      "Epoch 48/100\n",
      "380/380 [==============================] - 0s 166us/step - loss: 0.2381 - accuracy: 0.8789 - val_loss: 0.5237 - val_accuracy: 0.7975\n",
      "Epoch 49/100\n",
      "380/380 [==============================] - 0s 281us/step - loss: 0.2696 - accuracy: 0.8921 - val_loss: 0.4773 - val_accuracy: 0.8405\n",
      "Epoch 50/100\n",
      "380/380 [==============================] - 0s 169us/step - loss: 0.2538 - accuracy: 0.8737 - val_loss: 0.5924 - val_accuracy: 0.7853\n",
      "Epoch 51/100\n",
      "380/380 [==============================] - 0s 155us/step - loss: 0.2424 - accuracy: 0.8789 - val_loss: 0.4321 - val_accuracy: 0.8466\n",
      "Epoch 52/100\n",
      "380/380 [==============================] - 0s 159us/step - loss: 0.2358 - accuracy: 0.8947 - val_loss: 0.5938 - val_accuracy: 0.8098\n",
      "Epoch 53/100\n",
      "380/380 [==============================] - 0s 183us/step - loss: 0.2163 - accuracy: 0.8974 - val_loss: 0.5168 - val_accuracy: 0.8466\n",
      "Epoch 54/100\n",
      "380/380 [==============================] - 0s 149us/step - loss: 0.2655 - accuracy: 0.8816 - val_loss: 0.5386 - val_accuracy: 0.7975\n",
      "Epoch 55/100\n",
      "380/380 [==============================] - 0s 184us/step - loss: 0.2399 - accuracy: 0.8868 - val_loss: 0.4637 - val_accuracy: 0.8344\n",
      "Epoch 56/100\n",
      "380/380 [==============================] - 0s 764us/step - loss: 0.2121 - accuracy: 0.9237 - val_loss: 0.4380 - val_accuracy: 0.8466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "380/380 [==============================] - 0s 209us/step - loss: 0.2115 - accuracy: 0.9053 - val_loss: 0.4603 - val_accuracy: 0.8589\n",
      "Epoch 58/100\n",
      "380/380 [==============================] - 0s 145us/step - loss: 0.2130 - accuracy: 0.9026 - val_loss: 0.6357 - val_accuracy: 0.7853\n",
      "Epoch 59/100\n",
      "380/380 [==============================] - 0s 158us/step - loss: 0.2138 - accuracy: 0.8974 - val_loss: 0.6300 - val_accuracy: 0.7853\n",
      "Epoch 60/100\n",
      "380/380 [==============================] - 0s 140us/step - loss: 0.2422 - accuracy: 0.8947 - val_loss: 0.5397 - val_accuracy: 0.8160\n",
      "Epoch 61/100\n",
      "380/380 [==============================] - 0s 125us/step - loss: 0.2665 - accuracy: 0.8737 - val_loss: 0.5049 - val_accuracy: 0.8405\n",
      "Epoch 62/100\n",
      "380/380 [==============================] - 0s 119us/step - loss: 0.2467 - accuracy: 0.8842 - val_loss: 0.4940 - val_accuracy: 0.8405\n",
      "Epoch 63/100\n",
      "380/380 [==============================] - 0s 114us/step - loss: 0.2294 - accuracy: 0.9053 - val_loss: 0.5363 - val_accuracy: 0.8221\n",
      "Epoch 64/100\n",
      "380/380 [==============================] - 0s 116us/step - loss: 0.2222 - accuracy: 0.8895 - val_loss: 0.5756 - val_accuracy: 0.8221\n",
      "Epoch 65/100\n",
      "380/380 [==============================] - 0s 391us/step - loss: 0.2484 - accuracy: 0.8816 - val_loss: 0.7215 - val_accuracy: 0.7669\n",
      "Epoch 66/100\n",
      "380/380 [==============================] - 0s 181us/step - loss: 0.2379 - accuracy: 0.8974 - val_loss: 0.5441 - val_accuracy: 0.8098\n",
      "Epoch 67/100\n",
      "380/380 [==============================] - 0s 151us/step - loss: 0.2063 - accuracy: 0.9158 - val_loss: 0.4314 - val_accuracy: 0.8712\n",
      "Epoch 68/100\n",
      "380/380 [==============================] - 0s 132us/step - loss: 0.2031 - accuracy: 0.9132 - val_loss: 0.4624 - val_accuracy: 0.8466\n",
      "Epoch 69/100\n",
      "380/380 [==============================] - 0s 148us/step - loss: 0.2147 - accuracy: 0.8974 - val_loss: 0.4274 - val_accuracy: 0.8589\n",
      "Epoch 70/100\n",
      "380/380 [==============================] - 0s 149us/step - loss: 0.2062 - accuracy: 0.9079 - val_loss: 0.4146 - val_accuracy: 0.8712\n",
      "Epoch 71/100\n",
      "380/380 [==============================] - 0s 125us/step - loss: 0.1952 - accuracy: 0.9079 - val_loss: 0.5920 - val_accuracy: 0.7914\n",
      "Epoch 72/100\n",
      "380/380 [==============================] - 0s 125us/step - loss: 0.2440 - accuracy: 0.8921 - val_loss: 0.6160 - val_accuracy: 0.7914\n",
      "Epoch 73/100\n",
      "380/380 [==============================] - 0s 120us/step - loss: 0.2385 - accuracy: 0.8921 - val_loss: 0.4402 - val_accuracy: 0.8160\n",
      "Epoch 74/100\n",
      "380/380 [==============================] - 0s 119us/step - loss: 0.2388 - accuracy: 0.8842 - val_loss: 0.4414 - val_accuracy: 0.8466\n",
      "Epoch 75/100\n",
      "380/380 [==============================] - 0s 120us/step - loss: 0.2039 - accuracy: 0.9132 - val_loss: 0.5513 - val_accuracy: 0.7914\n",
      "Epoch 76/100\n",
      "380/380 [==============================] - 0s 126us/step - loss: 0.2005 - accuracy: 0.9000 - val_loss: 0.4799 - val_accuracy: 0.8405\n",
      "Epoch 77/100\n",
      "380/380 [==============================] - 0s 125us/step - loss: 0.2009 - accuracy: 0.9132 - val_loss: 0.4492 - val_accuracy: 0.8466\n",
      "Epoch 78/100\n",
      "380/380 [==============================] - 0s 116us/step - loss: 0.2055 - accuracy: 0.9079 - val_loss: 0.4507 - val_accuracy: 0.8589\n",
      "Epoch 79/100\n",
      "380/380 [==============================] - 0s 121us/step - loss: 0.2025 - accuracy: 0.9184 - val_loss: 0.4816 - val_accuracy: 0.8589\n",
      "Epoch 80/100\n",
      "380/380 [==============================] - 0s 114us/step - loss: 0.2093 - accuracy: 0.8974 - val_loss: 0.5673 - val_accuracy: 0.8098\n",
      "Epoch 81/100\n",
      "380/380 [==============================] - 0s 110us/step - loss: 0.2455 - accuracy: 0.8816 - val_loss: 0.5233 - val_accuracy: 0.7975\n",
      "Epoch 82/100\n",
      "380/380 [==============================] - 0s 117us/step - loss: 0.1983 - accuracy: 0.9132 - val_loss: 0.5303 - val_accuracy: 0.8221\n",
      "Epoch 83/100\n",
      "380/380 [==============================] - 0s 183us/step - loss: 0.2407 - accuracy: 0.8921 - val_loss: 0.5450 - val_accuracy: 0.8160\n",
      "Epoch 84/100\n",
      "380/380 [==============================] - 0s 255us/step - loss: 0.2210 - accuracy: 0.9079 - val_loss: 0.6142 - val_accuracy: 0.7914\n",
      "Epoch 85/100\n",
      "380/380 [==============================] - 0s 246us/step - loss: 0.2262 - accuracy: 0.9026 - val_loss: 0.6459 - val_accuracy: 0.7975\n",
      "Epoch 86/100\n",
      "380/380 [==============================] - 0s 636us/step - loss: 0.2151 - accuracy: 0.8895 - val_loss: 0.5582 - val_accuracy: 0.8160\n",
      "Epoch 87/100\n",
      "380/380 [==============================] - 0s 261us/step - loss: 0.2262 - accuracy: 0.8921 - val_loss: 0.4754 - val_accuracy: 0.8405\n",
      "Epoch 88/100\n",
      "380/380 [==============================] - 0s 244us/step - loss: 0.2049 - accuracy: 0.9105 - val_loss: 0.5323 - val_accuracy: 0.8528\n",
      "Epoch 89/100\n",
      "380/380 [==============================] - 0s 258us/step - loss: 0.2180 - accuracy: 0.8974 - val_loss: 0.6748 - val_accuracy: 0.7853\n",
      "Epoch 90/100\n",
      "380/380 [==============================] - 0s 208us/step - loss: 0.2200 - accuracy: 0.8974 - val_loss: 0.5498 - val_accuracy: 0.8282\n",
      "Epoch 91/100\n",
      "380/380 [==============================] - 0s 186us/step - loss: 0.2109 - accuracy: 0.9105 - val_loss: 0.5921 - val_accuracy: 0.7975\n",
      "Epoch 92/100\n",
      "380/380 [==============================] - 0s 200us/step - loss: 0.2159 - accuracy: 0.9026 - val_loss: 0.4979 - val_accuracy: 0.8160\n",
      "Epoch 93/100\n",
      "380/380 [==============================] - 0s 160us/step - loss: 0.2173 - accuracy: 0.9053 - val_loss: 0.5624 - val_accuracy: 0.8160\n",
      "Epoch 94/100\n",
      "380/380 [==============================] - 0s 143us/step - loss: 0.2334 - accuracy: 0.9000 - val_loss: 0.4613 - val_accuracy: 0.8344\n",
      "Epoch 95/100\n",
      "380/380 [==============================] - 0s 301us/step - loss: 0.2000 - accuracy: 0.9184 - val_loss: 0.4505 - val_accuracy: 0.8160\n",
      "Epoch 96/100\n",
      "380/380 [==============================] - 0s 265us/step - loss: 0.2370 - accuracy: 0.9026 - val_loss: 0.4200 - val_accuracy: 0.8712\n",
      "Epoch 97/100\n",
      "380/380 [==============================] - 0s 161us/step - loss: 0.2232 - accuracy: 0.9026 - val_loss: 0.4207 - val_accuracy: 0.8712\n",
      "Epoch 98/100\n",
      "380/380 [==============================] - 0s 167us/step - loss: 0.2149 - accuracy: 0.8974 - val_loss: 0.5488 - val_accuracy: 0.7791\n",
      "Epoch 99/100\n",
      "380/380 [==============================] - 0s 177us/step - loss: 0.2240 - accuracy: 0.9026 - val_loss: 0.4381 - val_accuracy: 0.8712\n",
      "Epoch 100/100\n",
      "380/380 [==============================] - 0s 198us/step - loss: 0.2355 - accuracy: 0.8974 - val_loss: 0.4457 - val_accuracy: 0.8528\n"
     ]
    }
   ],
   "source": [
    "hist1_over2 = model1_over2.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 89.66%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over2.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba2 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_2.xlsx\",\n",
    "                        sheet_name=1,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>1.748042e-03</td>\n",
       "      <td>9.981960e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>BCH-SA-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.712007</td>\n",
       "      <td>2.879924e-01</td>\n",
       "      <td>9.646217e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS218</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.006222</td>\n",
       "      <td>9.937732e-01</td>\n",
       "      <td>4.482882e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS036</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.882617</td>\n",
       "      <td>1.173831e-01</td>\n",
       "      <td>2.310933e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS386</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.571179</td>\n",
       "      <td>4.288184e-01</td>\n",
       "      <td>2.444667e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4279</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS112</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001860</td>\n",
       "      <td>9.979747e-01</td>\n",
       "      <td>1.653396e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4280</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>SR1065</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.982940</td>\n",
       "      <td>1.705227e-02</td>\n",
       "      <td>7.349168e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4281</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS203</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.997093</td>\n",
       "      <td>1.962516e-03</td>\n",
       "      <td>9.441347e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4282</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>CFBREBSa129</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.031141e-13</td>\n",
       "      <td>3.208205e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4283</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>CFBRSa25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999833</td>\n",
       "      <td>1.669456e-04</td>\n",
       "      <td>4.411099e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4284 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    phage       strain  phenotype  prediction         0  \\\n",
       "0      p002ykpresabs_qual       NRS148          2           2  0.000056   \n",
       "1      p002ykpresabs_qual    BCH-SA-03          1           0  0.712007   \n",
       "2      p002ykpresabs_qual       NRS218          1           1  0.006222   \n",
       "3      p002ykpresabs_qual       NRS036          0           0  0.882617   \n",
       "4      p002ykpresabs_qual       NRS386          1           0  0.571179   \n",
       "...                   ...          ...        ...         ...       ...   \n",
       "4279  pyopresabsSTCC_qual       NRS112          1           1  0.001860   \n",
       "4280  pyopresabsSTCC_qual       SR1065          0           0  0.982940   \n",
       "4281  pyopresabsSTCC_qual       NRS203          0           0  0.997093   \n",
       "4282  pyopresabsSTCC_qual  CFBREBSa129          0           0  1.000000   \n",
       "4283  pyopresabsSTCC_qual     CFBRSa25          0           0  0.999833   \n",
       "\n",
       "                 1             2  \n",
       "0     1.748042e-03  9.981960e-01  \n",
       "1     2.879924e-01  9.646217e-07  \n",
       "2     9.937732e-01  4.482882e-06  \n",
       "3     1.173831e-01  2.310933e-10  \n",
       "4     4.288184e-01  2.444667e-06  \n",
       "...            ...           ...  \n",
       "4279  9.979747e-01  1.653396e-04  \n",
       "4280  1.705227e-02  7.349168e-06  \n",
       "4281  1.962516e-03  9.441347e-04  \n",
       "4282  3.031141e-13  3.208205e-09  \n",
       "4283  1.669456e-04  4.411099e-08  \n",
       "\n",
       "[4284 rows x 7 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.98830850e-01, 2.62073150e-04, 9.07041700e-04],\n",
       "       [9.80363400e-01, 9.58994000e-05, 1.95406820e-02],\n",
       "       [1.66207020e-01, 1.87859740e-01, 6.45933300e-01],\n",
       "       [1.04179610e-01, 5.56847600e-01, 3.38972750e-01],\n",
       "       [9.98001750e-01, 7.88705100e-04, 1.20958580e-03],\n",
       "       [4.54445150e-01, 4.22900280e-04, 5.45132000e-01],\n",
       "       [9.98001750e-01, 7.88705100e-04, 1.20958580e-03],\n",
       "       [2.70596900e-03, 9.84363260e-01, 1.29307850e-02],\n",
       "       [1.66207020e-01, 1.87859740e-01, 6.45933300e-01],\n",
       "       [2.03490440e-05, 9.97040570e-01, 2.93912880e-03],\n",
       "       [5.37244700e-01, 6.89718700e-03, 4.55858100e-01],\n",
       "       [9.98131100e-01, 1.85813630e-03, 1.07736480e-05],\n",
       "       [3.17332680e-04, 9.09443140e-01, 9.02395700e-02],\n",
       "       [1.18529715e-01, 3.15663730e-01, 5.65806600e-01],\n",
       "       [1.13068445e-05, 9.97145100e-01, 2.84360500e-03],\n",
       "       [1.62177330e-04, 4.50017250e-04, 9.99387740e-01],\n",
       "       [8.73137200e-12, 9.96745100e-01, 3.25487440e-03],\n",
       "       [6.01116900e-05, 8.42397500e-01, 1.57542290e-01],\n",
       "       [6.84489500e-02, 8.73421360e-02, 8.44208960e-01],\n",
       "       [6.84489500e-02, 8.73421360e-02, 8.44208960e-01],\n",
       "       [2.44205260e-04, 9.59986000e-01, 3.97697760e-02],\n",
       "       [9.99025700e-01, 7.74160500e-07, 9.73502200e-04],\n",
       "       [8.71605100e-10, 9.99848100e-01, 1.51887570e-04],\n",
       "       [9.99025700e-01, 7.74160500e-07, 9.73502200e-04],\n",
       "       [2.11348250e-02, 3.47904200e-01, 6.30960940e-01],\n",
       "       [9.60426300e-01, 6.15303500e-04, 3.89584700e-02],\n",
       "       [2.03490440e-05, 9.97040570e-01, 2.93912880e-03],\n",
       "       [9.99025700e-01, 7.74160500e-07, 9.73502200e-04],\n",
       "       [1.34931240e-04, 9.58805300e-01, 4.10596500e-02],\n",
       "       [7.87458000e-01, 7.14695500e-05, 2.12470590e-01],\n",
       "       [9.96444500e-01, 1.24083330e-03, 2.31467820e-03],\n",
       "       [9.58449960e-01, 1.16417460e-04, 4.14336550e-02],\n",
       "       [9.98830850e-01, 2.62073150e-04, 9.07041700e-04],\n",
       "       [1.17807240e-06, 5.85506460e-05, 9.99940300e-01],\n",
       "       [4.60872100e-07, 9.99945400e-01, 5.41252670e-05],\n",
       "       [9.98830850e-01, 2.62073150e-04, 9.07041700e-04],\n",
       "       [1.31896830e-03, 5.53216640e-02, 9.43359400e-01],\n",
       "       [7.65258500e-09, 9.99533400e-01, 4.66646100e-04],\n",
       "       [9.58449960e-01, 1.16417460e-04, 4.14336550e-02],\n",
       "       [9.98240350e-01, 1.07768830e-03, 6.81932000e-04],\n",
       "       [9.58449960e-01, 1.16417460e-04, 4.14336550e-02],\n",
       "       [9.91184200e-01, 1.38719300e-03, 7.42860460e-03],\n",
       "       [1.11667580e-03, 1.93277790e-03, 9.96950500e-01],\n",
       "       [3.93532670e-07, 9.98304370e-01, 1.69524150e-03],\n",
       "       [5.29372540e-04, 9.99228100e-01, 2.42536190e-04],\n",
       "       [9.97613200e-01, 5.85867500e-04, 1.80102970e-03],\n",
       "       [4.83869250e-01, 6.02594300e-02, 4.55871340e-01],\n",
       "       [1.04179610e-01, 5.56847600e-01, 3.38972750e-01],\n",
       "       [6.31169000e-05, 9.85080300e-01, 1.48566310e-02],\n",
       "       [9.96935960e-01, 2.05313650e-03, 1.01083820e-03],\n",
       "       [1.66207020e-01, 1.87859740e-01, 6.45933300e-01],\n",
       "       [1.66207020e-01, 1.87859740e-01, 6.45933300e-01],\n",
       "       [9.98240350e-01, 1.07768830e-03, 6.81932000e-04],\n",
       "       [6.01116900e-05, 8.42397500e-01, 1.57542290e-01],\n",
       "       [9.97613200e-01, 5.85867500e-04, 1.80102970e-03],\n",
       "       [6.07210600e-01, 7.54638100e-02, 3.17325600e-01],\n",
       "       [1.44003420e-01, 9.82490800e-02, 7.57747600e-01],\n",
       "       [4.83869250e-01, 6.02594300e-02, 4.55871340e-01],\n",
       "       [9.96444500e-01, 1.24083330e-03, 2.31467820e-03],\n",
       "       [9.96444500e-01, 1.24083330e-03, 2.31467820e-03],\n",
       "       [1.47682340e-01, 3.97330300e-02, 8.12584640e-01],\n",
       "       [1.34931240e-04, 9.58805300e-01, 4.10596500e-02],\n",
       "       [1.24168460e-02, 1.97520220e-03, 9.85608000e-01],\n",
       "       [9.99933240e-01, 3.29131070e-08, 6.67631100e-05],\n",
       "       [1.87139290e-02, 1.18644240e-02, 9.69421600e-01],\n",
       "       [9.87651850e-03, 9.87832250e-01, 2.29117700e-03],\n",
       "       [9.67165470e-01, 3.05452270e-04, 3.25291200e-02],\n",
       "       [1.66207020e-01, 1.87859740e-01, 6.45933300e-01],\n",
       "       [1.99936250e-08, 9.99986200e-01, 1.37988650e-05],\n",
       "       [1.89619700e-06, 3.12276840e-01, 6.87721250e-01],\n",
       "       [1.65576030e-04, 1.00158080e-02, 9.89818630e-01],\n",
       "       [9.98001750e-01, 7.88705100e-04, 1.20958580e-03],\n",
       "       [3.93532670e-07, 9.98304370e-01, 1.69524150e-03],\n",
       "       [9.83514400e-04, 1.49993280e-03, 9.97516500e-01],\n",
       "       [4.22131180e-01, 4.74063840e-01, 1.03805020e-01],\n",
       "       [1.04179610e-01, 5.56847600e-01, 3.38972750e-01],\n",
       "       [9.42664560e-01, 3.58954360e-04, 5.69765460e-02],\n",
       "       [9.86639900e-01, 7.07885200e-04, 1.26521530e-02],\n",
       "       [6.42146800e-01, 2.60484240e-02, 3.31804750e-01],\n",
       "       [6.31309800e-01, 2.45152400e-01, 1.23537810e-01],\n",
       "       [4.22131180e-01, 4.74063840e-01, 1.03805020e-01],\n",
       "       [6.77330930e-03, 1.53581270e-02, 9.77868500e-01],\n",
       "       [8.73137200e-12, 9.96745100e-01, 3.25487440e-03],\n",
       "       [6.42146800e-01, 2.60484240e-02, 3.31804750e-01],\n",
       "       [1.04179610e-01, 5.56847600e-01, 3.38972750e-01],\n",
       "       [8.73137200e-12, 9.96745100e-01, 3.25487440e-03],\n",
       "       [1.26837070e-03, 1.41945540e-01, 8.56786130e-01],\n",
       "       [3.09639160e-01, 1.23723110e-01, 5.66637800e-01],\n",
       "       [6.42146800e-01, 2.60484240e-02, 3.31804750e-01],\n",
       "       [9.26623800e-01, 1.06127310e-02, 6.27634100e-02],\n",
       "       [6.38748800e-03, 1.04548800e-02, 9.83157700e-01],\n",
       "       [9.98001750e-01, 7.88705100e-04, 1.20958580e-03],\n",
       "       [1.72307700e-03, 9.97131700e-01, 1.14511620e-03],\n",
       "       [9.80410300e-01, 6.16867750e-03, 1.34210500e-02],\n",
       "       [9.99933240e-01, 3.29131070e-08, 6.67631100e-05],\n",
       "       [5.74862770e-03, 9.80174660e-01, 1.40767800e-02],\n",
       "       [9.98115900e-01, 3.17456260e-04, 1.56662550e-03],\n",
       "       [5.86368670e-02, 7.43963340e-03, 9.33923500e-01],\n",
       "       [1.04413430e-04, 9.47269500e-02, 9.05168650e-01],\n",
       "       [9.80410300e-01, 6.16867750e-03, 1.34210500e-02],\n",
       "       [9.96935960e-01, 2.05313650e-03, 1.01083820e-03],\n",
       "       [9.98830850e-01, 2.62073150e-04, 9.07041700e-04],\n",
       "       [8.71605100e-10, 9.99848100e-01, 1.51887570e-04],\n",
       "       [9.98830850e-01, 2.62073150e-04, 9.07041700e-04],\n",
       "       [8.71605100e-10, 9.99848100e-01, 1.51887570e-04],\n",
       "       [1.01994730e-02, 9.33576500e-02, 8.96442900e-01],\n",
       "       [4.52634100e-01, 4.21413900e-01, 1.25952060e-01],\n",
       "       [2.34992460e-04, 3.89957200e-02, 9.60769240e-01],\n",
       "       [1.34931240e-04, 9.58805300e-01, 4.10596500e-02],\n",
       "       [9.98115900e-01, 3.17456260e-04, 1.56662550e-03],\n",
       "       [1.04327526e-04, 9.99852300e-01, 4.33646100e-05],\n",
       "       [4.22131180e-01, 4.74063840e-01, 1.03805020e-01],\n",
       "       [9.80363400e-01, 9.58994000e-05, 1.95406820e-02],\n",
       "       [9.96935960e-01, 2.05313650e-03, 1.01083820e-03],\n",
       "       [1.31597430e-02, 1.13902100e-02, 9.75450040e-01],\n",
       "       [8.27796800e-01, 4.69263530e-04, 1.71733930e-01],\n",
       "       [5.36063950e-02, 9.63309200e-04, 9.45430300e-01],\n",
       "       [4.22131180e-01, 4.74063840e-01, 1.03805020e-01],\n",
       "       [6.59835640e-05, 9.95733300e-01, 4.20065970e-03],\n",
       "       [9.99025700e-01, 7.74160500e-07, 9.73502200e-04],\n",
       "       [4.63696640e-02, 9.10691300e-02, 8.62561200e-01],\n",
       "       [5.29372540e-04, 9.99228100e-01, 2.42536190e-04],\n",
       "       [6.10941800e-02, 4.37896200e-02, 8.95116150e-01],\n",
       "       [1.34771140e-02, 9.17032600e-02, 8.94819600e-01],\n",
       "       [2.44205260e-04, 9.59986000e-01, 3.97697760e-02],\n",
       "       [9.98830850e-01, 2.62073150e-04, 9.07041700e-04],\n",
       "       [1.30088750e-04, 7.58737400e-01, 2.41132600e-01],\n",
       "       [9.88104500e-01, 2.05640140e-04, 1.16898790e-02],\n",
       "       [9.58449960e-01, 1.16417460e-04, 4.14336550e-02],\n",
       "       [1.80730480e-02, 5.21887950e-02, 9.29738160e-01],\n",
       "       [9.91184200e-01, 1.38719300e-03, 7.42860460e-03],\n",
       "       [4.22131180e-01, 4.74063840e-01, 1.03805020e-01],\n",
       "       [2.75772950e-05, 3.07482800e-02, 9.69224150e-01],\n",
       "       [9.98240350e-01, 1.07768830e-03, 6.81932000e-04],\n",
       "       [7.86014800e-05, 9.52267050e-01, 4.76544050e-02],\n",
       "       [7.35091340e-02, 8.35171700e-02, 8.42973650e-01],\n",
       "       [1.31009340e-08, 9.99205900e-01, 7.94165700e-04],\n",
       "       [1.66207020e-01, 1.87859740e-01, 6.45933300e-01],\n",
       "       [1.66207020e-01, 1.87859740e-01, 6.45933300e-01],\n",
       "       [6.42146800e-01, 2.60484240e-02, 3.31804750e-01],\n",
       "       [1.31009340e-08, 9.99205900e-01, 7.94165700e-04],\n",
       "       [6.96443070e-03, 2.02022640e-02, 9.72833300e-01],\n",
       "       [1.66207020e-01, 1.87859740e-01, 6.45933300e-01],\n",
       "       [1.93570520e-05, 3.63850670e-05, 9.99944200e-01],\n",
       "       [9.91184200e-01, 1.38719300e-03, 7.42860460e-03],\n",
       "       [1.14656910e-01, 2.02216970e-01, 6.83126150e-01],\n",
       "       [9.80410300e-01, 6.16867750e-03, 1.34210500e-02],\n",
       "       [6.42146800e-01, 2.60484240e-02, 3.31804750e-01],\n",
       "       [9.73443600e-02, 7.26074700e-02, 8.30048200e-01],\n",
       "       [6.70234700e-02, 7.55506600e-02, 8.57425870e-01],\n",
       "       [1.34931240e-04, 9.58805300e-01, 4.10596500e-02],\n",
       "       [6.51511500e-01, 8.24398600e-04, 3.47664060e-01],\n",
       "       [9.97613200e-01, 5.85867500e-04, 1.80102970e-03],\n",
       "       [6.71453870e-03, 1.28850860e-02, 9.80400440e-01],\n",
       "       [4.16983200e-04, 9.87748800e-01, 1.18341900e-02],\n",
       "       [3.55407200e-06, 9.97977550e-01, 2.01893370e-03],\n",
       "       [1.66207020e-01, 1.87859740e-01, 6.45933300e-01],\n",
       "       [7.07391000e-02, 8.32599600e-02, 8.46000970e-01],\n",
       "       [2.91428230e-02, 1.51263980e-01, 8.19593250e-01],\n",
       "       [8.92773900e-09, 9.98998000e-01, 1.00198680e-03],\n",
       "       [2.44205260e-04, 9.59986000e-01, 3.97697760e-02],\n",
       "       [1.04179610e-01, 5.56847600e-01, 3.38972750e-01],\n",
       "       [9.98017200e-01, 2.56792150e-04, 1.72609380e-03]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob2 = df_proba2[df_proba2['phage']=='p11kpresabs_qual'].iloc[:,-3:]\n",
    "y_prob2 = y_prob2.to_numpy()\n",
    "y_prob2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9459127462185566"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo2 = rocauc_ovo(y_test_over, y_prob2, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9459127462185566"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr2 = rocauc_ovr(y_test_over, y_prob2, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=345,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat3 = pd.DataFrame(X_test_over[:,0])\n",
    "dat3['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS149</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EUH13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS106</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS214</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CFBREBSa129</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>NRS027</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>CFBRSa70</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>CFBREBSa130</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>NRS214</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>NRS073</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test\n",
       "0         NRS149     0\n",
       "1          EUH13     0\n",
       "2         NRS106     2\n",
       "3         NRS214     1\n",
       "4    CFBREBSa129     0\n",
       "..           ...   ...\n",
       "158       NRS027     0\n",
       "159     CFBRSa70     2\n",
       "160  CFBREBSa130     0\n",
       "161       NRS214     1\n",
       "162       NRS073     1\n",
       "\n",
       "[163 rows x 2 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over3 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over3.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 380 samples, validate on 163 samples\n",
      "Epoch 1/100\n",
      "380/380 [==============================] - 0s 541us/step - loss: 1.1313 - accuracy: 0.3605 - val_loss: 1.0493 - val_accuracy: 0.4663\n",
      "Epoch 2/100\n",
      "380/380 [==============================] - 0s 158us/step - loss: 1.0639 - accuracy: 0.4737 - val_loss: 1.0293 - val_accuracy: 0.4969\n",
      "Epoch 3/100\n",
      "380/380 [==============================] - 0s 199us/step - loss: 0.9962 - accuracy: 0.5105 - val_loss: 0.9547 - val_accuracy: 0.5828\n",
      "Epoch 4/100\n",
      "380/380 [==============================] - 0s 162us/step - loss: 0.9509 - accuracy: 0.5789 - val_loss: 0.9205 - val_accuracy: 0.5767\n",
      "Epoch 5/100\n",
      "380/380 [==============================] - 0s 151us/step - loss: 0.9030 - accuracy: 0.5974 - val_loss: 0.8759 - val_accuracy: 0.6196\n",
      "Epoch 6/100\n",
      "380/380 [==============================] - 0s 188us/step - loss: 0.8588 - accuracy: 0.6053 - val_loss: 0.8588 - val_accuracy: 0.6564\n",
      "Epoch 7/100\n",
      "380/380 [==============================] - 0s 168us/step - loss: 0.8288 - accuracy: 0.6421 - val_loss: 0.8532 - val_accuracy: 0.6380\n",
      "Epoch 8/100\n",
      "380/380 [==============================] - 0s 182us/step - loss: 0.7850 - accuracy: 0.6500 - val_loss: 0.7938 - val_accuracy: 0.7117\n",
      "Epoch 9/100\n",
      "380/380 [==============================] - 0s 170us/step - loss: 0.7513 - accuracy: 0.7105 - val_loss: 0.8170 - val_accuracy: 0.6196\n",
      "Epoch 10/100\n",
      "380/380 [==============================] - 0s 143us/step - loss: 0.7330 - accuracy: 0.7053 - val_loss: 0.7362 - val_accuracy: 0.7055\n",
      "Epoch 11/100\n",
      "380/380 [==============================] - 0s 123us/step - loss: 0.6954 - accuracy: 0.7053 - val_loss: 0.7254 - val_accuracy: 0.7055\n",
      "Epoch 12/100\n",
      "380/380 [==============================] - 0s 148us/step - loss: 0.6710 - accuracy: 0.7184 - val_loss: 0.7269 - val_accuracy: 0.6994\n",
      "Epoch 13/100\n",
      "380/380 [==============================] - 0s 193us/step - loss: 0.6675 - accuracy: 0.7000 - val_loss: 0.6851 - val_accuracy: 0.7178\n",
      "Epoch 14/100\n",
      "380/380 [==============================] - 0s 178us/step - loss: 0.6342 - accuracy: 0.7474 - val_loss: 0.6970 - val_accuracy: 0.7362\n",
      "Epoch 15/100\n",
      "380/380 [==============================] - 0s 95us/step - loss: 0.6194 - accuracy: 0.7395 - val_loss: 0.6648 - val_accuracy: 0.7362\n",
      "Epoch 16/100\n",
      "380/380 [==============================] - 0s 110us/step - loss: 0.5900 - accuracy: 0.7579 - val_loss: 0.6763 - val_accuracy: 0.7301\n",
      "Epoch 17/100\n",
      "380/380 [==============================] - 0s 101us/step - loss: 0.5980 - accuracy: 0.7474 - val_loss: 0.6357 - val_accuracy: 0.7546\n",
      "Epoch 18/100\n",
      "380/380 [==============================] - 0s 108us/step - loss: 0.6038 - accuracy: 0.7395 - val_loss: 0.6938 - val_accuracy: 0.6871\n",
      "Epoch 19/100\n",
      "380/380 [==============================] - 0s 118us/step - loss: 0.5675 - accuracy: 0.7789 - val_loss: 0.6344 - val_accuracy: 0.7362\n",
      "Epoch 20/100\n",
      "380/380 [==============================] - 0s 152us/step - loss: 0.5673 - accuracy: 0.7684 - val_loss: 0.6619 - val_accuracy: 0.6933\n",
      "Epoch 21/100\n",
      "380/380 [==============================] - 0s 207us/step - loss: 0.5241 - accuracy: 0.8026 - val_loss: 0.6126 - val_accuracy: 0.7669\n",
      "Epoch 22/100\n",
      "380/380 [==============================] - 0s 176us/step - loss: 0.5161 - accuracy: 0.8026 - val_loss: 0.5969 - val_accuracy: 0.7485\n",
      "Epoch 23/100\n",
      "380/380 [==============================] - 0s 134us/step - loss: 0.5005 - accuracy: 0.7974 - val_loss: 0.6403 - val_accuracy: 0.7117\n",
      "Epoch 24/100\n",
      "380/380 [==============================] - 0s 133us/step - loss: 0.4977 - accuracy: 0.8026 - val_loss: 0.6063 - val_accuracy: 0.7607\n",
      "Epoch 25/100\n",
      "380/380 [==============================] - 0s 146us/step - loss: 0.4766 - accuracy: 0.7947 - val_loss: 0.6080 - val_accuracy: 0.7423\n",
      "Epoch 26/100\n",
      "380/380 [==============================] - 0s 148us/step - loss: 0.5103 - accuracy: 0.7842 - val_loss: 0.5872 - val_accuracy: 0.7914\n",
      "Epoch 27/100\n",
      "380/380 [==============================] - 0s 108us/step - loss: 0.4816 - accuracy: 0.8053 - val_loss: 0.6306 - val_accuracy: 0.7301\n",
      "Epoch 28/100\n",
      "380/380 [==============================] - 0s 93us/step - loss: 0.4636 - accuracy: 0.8053 - val_loss: 0.5981 - val_accuracy: 0.7791\n",
      "Epoch 29/100\n",
      "380/380 [==============================] - 0s 93us/step - loss: 0.4340 - accuracy: 0.8526 - val_loss: 0.5860 - val_accuracy: 0.7669\n",
      "Epoch 30/100\n",
      "380/380 [==============================] - 0s 89us/step - loss: 0.4439 - accuracy: 0.8158 - val_loss: 0.5577 - val_accuracy: 0.7730\n",
      "Epoch 31/100\n",
      "380/380 [==============================] - 0s 102us/step - loss: 0.4256 - accuracy: 0.8158 - val_loss: 0.5665 - val_accuracy: 0.8098\n",
      "Epoch 32/100\n",
      "380/380 [==============================] - ETA: 0s - loss: 0.4068 - accuracy: 0.90 - 0s 233us/step - loss: 0.4113 - accuracy: 0.8421 - val_loss: 0.5616 - val_accuracy: 0.7914\n",
      "Epoch 33/100\n",
      "380/380 [==============================] - 0s 314us/step - loss: 0.4085 - accuracy: 0.8184 - val_loss: 0.6016 - val_accuracy: 0.7485\n",
      "Epoch 34/100\n",
      "380/380 [==============================] - 0s 170us/step - loss: 0.4118 - accuracy: 0.8132 - val_loss: 0.5685 - val_accuracy: 0.7914\n",
      "Epoch 35/100\n",
      "380/380 [==============================] - 0s 152us/step - loss: 0.3910 - accuracy: 0.8579 - val_loss: 0.5983 - val_accuracy: 0.7853\n",
      "Epoch 36/100\n",
      "380/380 [==============================] - 0s 312us/step - loss: 0.3938 - accuracy: 0.8500 - val_loss: 0.5816 - val_accuracy: 0.7791\n",
      "Epoch 37/100\n",
      "380/380 [==============================] - 0s 495us/step - loss: 0.3951 - accuracy: 0.8579 - val_loss: 0.5429 - val_accuracy: 0.7975\n",
      "Epoch 38/100\n",
      "380/380 [==============================] - 0s 357us/step - loss: 0.3887 - accuracy: 0.8421 - val_loss: 0.5416 - val_accuracy: 0.7975\n",
      "Epoch 39/100\n",
      "380/380 [==============================] - 0s 174us/step - loss: 0.3859 - accuracy: 0.8526 - val_loss: 0.6718 - val_accuracy: 0.7301\n",
      "Epoch 40/100\n",
      "380/380 [==============================] - 0s 394us/step - loss: 0.3781 - accuracy: 0.8526 - val_loss: 0.5434 - val_accuracy: 0.8098\n",
      "Epoch 41/100\n",
      "380/380 [==============================] - 0s 307us/step - loss: 0.3873 - accuracy: 0.8316 - val_loss: 0.6014 - val_accuracy: 0.7546\n",
      "Epoch 42/100\n",
      "380/380 [==============================] - 0s 230us/step - loss: 0.3658 - accuracy: 0.8342 - val_loss: 0.5439 - val_accuracy: 0.7853\n",
      "Epoch 43/100\n",
      "380/380 [==============================] - 0s 156us/step - loss: 0.3630 - accuracy: 0.8526 - val_loss: 0.5504 - val_accuracy: 0.7975\n",
      "Epoch 44/100\n",
      "380/380 [==============================] - 0s 233us/step - loss: 0.3643 - accuracy: 0.8447 - val_loss: 0.5714 - val_accuracy: 0.7975\n",
      "Epoch 45/100\n",
      "380/380 [==============================] - 0s 270us/step - loss: 0.3625 - accuracy: 0.8447 - val_loss: 0.5814 - val_accuracy: 0.7791\n",
      "Epoch 46/100\n",
      "380/380 [==============================] - 0s 128us/step - loss: 0.3431 - accuracy: 0.8658 - val_loss: 0.5296 - val_accuracy: 0.8037\n",
      "Epoch 47/100\n",
      "380/380 [==============================] - 0s 243us/step - loss: 0.3485 - accuracy: 0.8684 - val_loss: 0.5535 - val_accuracy: 0.7975\n",
      "Epoch 48/100\n",
      "380/380 [==============================] - 0s 232us/step - loss: 0.3410 - accuracy: 0.8500 - val_loss: 0.7104 - val_accuracy: 0.7117\n",
      "Epoch 49/100\n",
      "380/380 [==============================] - 0s 122us/step - loss: 0.3475 - accuracy: 0.8500 - val_loss: 0.5862 - val_accuracy: 0.7791\n",
      "Epoch 50/100\n",
      "380/380 [==============================] - 0s 120us/step - loss: 0.3801 - accuracy: 0.8526 - val_loss: 0.6522 - val_accuracy: 0.7669\n",
      "Epoch 51/100\n",
      "380/380 [==============================] - 0s 108us/step - loss: 0.3279 - accuracy: 0.8895 - val_loss: 0.5083 - val_accuracy: 0.8098\n",
      "Epoch 52/100\n",
      "380/380 [==============================] - 0s 120us/step - loss: 0.3277 - accuracy: 0.8632 - val_loss: 0.5366 - val_accuracy: 0.8098\n",
      "Epoch 53/100\n",
      "380/380 [==============================] - 0s 171us/step - loss: 0.3210 - accuracy: 0.8842 - val_loss: 0.5631 - val_accuracy: 0.7975\n",
      "Epoch 54/100\n",
      "380/380 [==============================] - 0s 186us/step - loss: 0.3042 - accuracy: 0.8895 - val_loss: 0.5300 - val_accuracy: 0.8098\n",
      "Epoch 55/100\n",
      "380/380 [==============================] - 0s 119us/step - loss: 0.3292 - accuracy: 0.8579 - val_loss: 0.5573 - val_accuracy: 0.8098\n",
      "Epoch 56/100\n",
      "380/380 [==============================] - 0s 135us/step - loss: 0.3262 - accuracy: 0.8684 - val_loss: 0.5580 - val_accuracy: 0.7975\n",
      "Epoch 57/100\n",
      "380/380 [==============================] - 0s 129us/step - loss: 0.3061 - accuracy: 0.8737 - val_loss: 0.5404 - val_accuracy: 0.8037\n",
      "Epoch 58/100\n",
      "380/380 [==============================] - 0s 273us/step - loss: 0.3122 - accuracy: 0.8868 - val_loss: 0.5539 - val_accuracy: 0.8037\n",
      "Epoch 59/100\n",
      "380/380 [==============================] - 0s 210us/step - loss: 0.3010 - accuracy: 0.8684 - val_loss: 0.5353 - val_accuracy: 0.8098\n",
      "Epoch 60/100\n",
      "380/380 [==============================] - 0s 311us/step - loss: 0.2869 - accuracy: 0.8816 - val_loss: 0.5777 - val_accuracy: 0.8221\n",
      "Epoch 61/100\n",
      "380/380 [==============================] - 0s 145us/step - loss: 0.2840 - accuracy: 0.8842 - val_loss: 0.5342 - val_accuracy: 0.7975\n",
      "Epoch 62/100\n",
      "380/380 [==============================] - 0s 88us/step - loss: 0.2925 - accuracy: 0.8605 - val_loss: 0.5564 - val_accuracy: 0.8037\n",
      "Epoch 63/100\n",
      "380/380 [==============================] - 0s 104us/step - loss: 0.2807 - accuracy: 0.8763 - val_loss: 0.5862 - val_accuracy: 0.7669\n",
      "Epoch 64/100\n",
      "380/380 [==============================] - 0s 83us/step - loss: 0.3013 - accuracy: 0.8632 - val_loss: 0.6186 - val_accuracy: 0.8098\n",
      "Epoch 65/100\n",
      "380/380 [==============================] - 0s 100us/step - loss: 0.2930 - accuracy: 0.8789 - val_loss: 0.5181 - val_accuracy: 0.8098\n",
      "Epoch 66/100\n",
      "380/380 [==============================] - 0s 118us/step - loss: 0.2763 - accuracy: 0.9026 - val_loss: 0.5518 - val_accuracy: 0.8282\n",
      "Epoch 67/100\n",
      "380/380 [==============================] - 0s 170us/step - loss: 0.2784 - accuracy: 0.8921 - val_loss: 0.5515 - val_accuracy: 0.8160\n",
      "Epoch 68/100\n",
      "380/380 [==============================] - 0s 158us/step - loss: 0.2819 - accuracy: 0.8737 - val_loss: 0.5494 - val_accuracy: 0.8098\n",
      "Epoch 69/100\n",
      "380/380 [==============================] - 0s 102us/step - loss: 0.2848 - accuracy: 0.8974 - val_loss: 0.5999 - val_accuracy: 0.8221\n",
      "Epoch 70/100\n",
      "380/380 [==============================] - 0s 95us/step - loss: 0.2858 - accuracy: 0.8711 - val_loss: 0.5360 - val_accuracy: 0.8098\n",
      "Epoch 71/100\n",
      "380/380 [==============================] - 0s 85us/step - loss: 0.3194 - accuracy: 0.8605 - val_loss: 0.6102 - val_accuracy: 0.7975\n",
      "Epoch 72/100\n",
      "380/380 [==============================] - 0s 119us/step - loss: 0.2636 - accuracy: 0.8974 - val_loss: 0.5395 - val_accuracy: 0.8037\n",
      "Epoch 73/100\n",
      "380/380 [==============================] - 0s 107us/step - loss: 0.2681 - accuracy: 0.8868 - val_loss: 0.5728 - val_accuracy: 0.8098\n",
      "Epoch 74/100\n",
      "380/380 [==============================] - 0s 132us/step - loss: 0.2648 - accuracy: 0.8895 - val_loss: 0.5454 - val_accuracy: 0.8221\n",
      "Epoch 75/100\n",
      "380/380 [==============================] - 0s 150us/step - loss: 0.2674 - accuracy: 0.8842 - val_loss: 0.5498 - val_accuracy: 0.8037\n",
      "Epoch 76/100\n",
      "380/380 [==============================] - 0s 114us/step - loss: 0.2876 - accuracy: 0.8553 - val_loss: 0.6656 - val_accuracy: 0.7791\n",
      "Epoch 77/100\n",
      "380/380 [==============================] - 0s 122us/step - loss: 0.2608 - accuracy: 0.8921 - val_loss: 0.5468 - val_accuracy: 0.8221\n",
      "Epoch 78/100\n",
      "380/380 [==============================] - 0s 88us/step - loss: 0.2837 - accuracy: 0.8737 - val_loss: 0.5358 - val_accuracy: 0.7853\n",
      "Epoch 79/100\n",
      "380/380 [==============================] - 0s 94us/step - loss: 0.3338 - accuracy: 0.8316 - val_loss: 0.7610 - val_accuracy: 0.7546\n",
      "Epoch 80/100\n",
      "380/380 [==============================] - 0s 84us/step - loss: 0.3221 - accuracy: 0.8553 - val_loss: 0.6144 - val_accuracy: 0.7975\n",
      "Epoch 81/100\n",
      "380/380 [==============================] - 0s 95us/step - loss: 0.2889 - accuracy: 0.8816 - val_loss: 0.5277 - val_accuracy: 0.8098\n",
      "Epoch 82/100\n",
      "380/380 [==============================] - 0s 87us/step - loss: 0.2788 - accuracy: 0.8737 - val_loss: 0.5809 - val_accuracy: 0.8037\n",
      "Epoch 83/100\n",
      "380/380 [==============================] - 0s 90us/step - loss: 0.2509 - accuracy: 0.9079 - val_loss: 0.5449 - val_accuracy: 0.8282\n",
      "Epoch 84/100\n",
      "380/380 [==============================] - 0s 94us/step - loss: 0.2483 - accuracy: 0.9132 - val_loss: 0.5611 - val_accuracy: 0.8160\n",
      "Epoch 85/100\n",
      "380/380 [==============================] - 0s 85us/step - loss: 0.2520 - accuracy: 0.9000 - val_loss: 0.5889 - val_accuracy: 0.8098\n",
      "Epoch 86/100\n",
      "380/380 [==============================] - 0s 95us/step - loss: 0.2528 - accuracy: 0.8974 - val_loss: 0.5235 - val_accuracy: 0.8221\n",
      "Epoch 87/100\n",
      "380/380 [==============================] - 0s 83us/step - loss: 0.2522 - accuracy: 0.8947 - val_loss: 0.5385 - val_accuracy: 0.8282\n",
      "Epoch 88/100\n",
      "380/380 [==============================] - 0s 87us/step - loss: 0.2524 - accuracy: 0.9000 - val_loss: 0.6807 - val_accuracy: 0.7975\n",
      "Epoch 89/100\n",
      "380/380 [==============================] - 0s 113us/step - loss: 0.2548 - accuracy: 0.8974 - val_loss: 0.5395 - val_accuracy: 0.8221\n",
      "Epoch 90/100\n",
      "380/380 [==============================] - 0s 130us/step - loss: 0.2510 - accuracy: 0.9000 - val_loss: 0.5246 - val_accuracy: 0.8344\n",
      "Epoch 91/100\n",
      "380/380 [==============================] - 0s 88us/step - loss: 0.2418 - accuracy: 0.9184 - val_loss: 0.5964 - val_accuracy: 0.8098\n",
      "Epoch 92/100\n",
      "380/380 [==============================] - 0s 92us/step - loss: 0.2318 - accuracy: 0.9184 - val_loss: 0.5388 - val_accuracy: 0.8282\n",
      "Epoch 93/100\n",
      "380/380 [==============================] - 0s 85us/step - loss: 0.2340 - accuracy: 0.9211 - val_loss: 0.6168 - val_accuracy: 0.8037\n",
      "Epoch 94/100\n",
      "380/380 [==============================] - 0s 94us/step - loss: 0.2507 - accuracy: 0.8684 - val_loss: 0.6523 - val_accuracy: 0.7669\n",
      "Epoch 95/100\n",
      "380/380 [==============================] - 0s 123us/step - loss: 0.2831 - accuracy: 0.8789 - val_loss: 0.5463 - val_accuracy: 0.8221\n",
      "Epoch 96/100\n",
      "380/380 [==============================] - 0s 163us/step - loss: 0.2658 - accuracy: 0.8921 - val_loss: 0.5790 - val_accuracy: 0.8221\n",
      "Epoch 97/100\n",
      "380/380 [==============================] - 0s 92us/step - loss: 0.2545 - accuracy: 0.9053 - val_loss: 0.6190 - val_accuracy: 0.7975\n",
      "Epoch 98/100\n",
      "380/380 [==============================] - 0s 101us/step - loss: 0.2542 - accuracy: 0.8816 - val_loss: 0.5668 - val_accuracy: 0.8160\n",
      "Epoch 99/100\n",
      "380/380 [==============================] - 0s 85us/step - loss: 0.2658 - accuracy: 0.8895 - val_loss: 0.7654 - val_accuracy: 0.7669\n",
      "Epoch 100/100\n",
      "380/380 [==============================] - 0s 85us/step - loss: 0.2621 - accuracy: 0.8868 - val_loss: 0.5348 - val_accuracy: 0.8282\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a41fec358>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over3.fit(X_train_over, y_train_over,\n",
    "          batch_size=64, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163/163 [==============================] - 0s 102us/step\n",
      "over-sampling test accuracy: 79.75%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over3 = model1_over3.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over3*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 2, 1, 0, 1, 0, 1, 0, 0, 1, 2, 1, 0, 0, 1, 2, 1, 0, 2, 2, 2,\n",
       "       0, 2, 2, 1, 2, 2, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 2, 0, 1, 1, 1,\n",
       "       1, 2, 2, 1, 0, 1, 2, 0, 0, 0, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 2, 0, 0, 1, 0, 2, 0, 0, 0, 2, 2, 2, 2, 0, 0, 1,\n",
       "       2, 0, 2, 0, 0, 0, 1, 2, 1, 1, 0, 1, 2, 0, 1, 1, 2, 0, 2, 1, 1, 1,\n",
       "       1, 2, 1, 2, 2, 2, 1, 1, 2, 2, 2, 2, 0, 1, 1, 1, 2, 1, 1, 1, 1, 0,\n",
       "       1, 2, 0, 2, 0, 0, 0, 2, 1, 0, 1, 0, 1, 1, 0, 0, 0, 2, 0, 2, 1, 0,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 1])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred3 = model1_over3.predict_classes(X_test_over)\n",
    "pred3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS149</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EUH13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS106</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS214</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CFBREBSa129</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>NRS027</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>CFBRSa70</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>CFBREBSa130</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>NRS214</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>NRS073</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test  pred\n",
       "0         NRS149     0     0\n",
       "1          EUH13     0     0\n",
       "2         NRS106     2     2\n",
       "3         NRS214     1     1\n",
       "4    CFBREBSa129     0     0\n",
       "..           ...   ...   ...\n",
       "158       NRS027     0     0\n",
       "159     CFBRSa70     2     1\n",
       "160  CFBREBSa130     0     0\n",
       "161       NRS214     1     1\n",
       "162       NRS073     1     1\n",
       "\n",
       "[163 rows x 3 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat3['pred'] = pred3\n",
    "dat3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba3 = model1_over3.predict_proba(X_test_over)\n",
    "dat_proba3 = pd.DataFrame(proba3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.981236</td>\n",
       "      <td>0.001220</td>\n",
       "      <td>0.017544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.026475</td>\n",
       "      <td>0.010562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.081841</td>\n",
       "      <td>0.181278</td>\n",
       "      <td>0.736881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002954</td>\n",
       "      <td>0.968637</td>\n",
       "      <td>0.028409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.993843</td>\n",
       "      <td>0.001009</td>\n",
       "      <td>0.005148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>0.994845</td>\n",
       "      <td>0.001055</td>\n",
       "      <td>0.004101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>0.049889</td>\n",
       "      <td>0.561527</td>\n",
       "      <td>0.388585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>0.604731</td>\n",
       "      <td>0.000340</td>\n",
       "      <td>0.394930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>0.002954</td>\n",
       "      <td>0.968637</td>\n",
       "      <td>0.028409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.999988</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2\n",
       "0    0.981236  0.001220  0.017544\n",
       "1    0.962963  0.026475  0.010562\n",
       "2    0.081841  0.181278  0.736881\n",
       "3    0.002954  0.968637  0.028409\n",
       "4    0.993843  0.001009  0.005148\n",
       "..        ...       ...       ...\n",
       "158  0.994845  0.001055  0.004101\n",
       "159  0.049889  0.561527  0.388585\n",
       "160  0.604731  0.000340  0.394930\n",
       "161  0.002954  0.968637  0.028409\n",
       "162  0.000001  0.999988  0.000011\n",
       "\n",
       "[163 rows x 3 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba3.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba3.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat3.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/3p11.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 380 samples, validate on 163 samples\n",
      "Epoch 1/100\n",
      "380/380 [==============================] - 0s 141us/step - loss: 0.2428 - accuracy: 0.9026 - val_loss: 0.5395 - val_accuracy: 0.7730\n",
      "Epoch 2/100\n",
      "380/380 [==============================] - 0s 145us/step - loss: 0.2454 - accuracy: 0.9079 - val_loss: 0.5404 - val_accuracy: 0.8037\n",
      "Epoch 3/100\n",
      "380/380 [==============================] - 0s 125us/step - loss: 0.2870 - accuracy: 0.8711 - val_loss: 0.4782 - val_accuracy: 0.8282\n",
      "Epoch 4/100\n",
      "380/380 [==============================] - 0s 115us/step - loss: 0.2745 - accuracy: 0.9000 - val_loss: 0.7275 - val_accuracy: 0.7607\n",
      "Epoch 5/100\n",
      "380/380 [==============================] - 0s 100us/step - loss: 0.2437 - accuracy: 0.9079 - val_loss: 0.4881 - val_accuracy: 0.8160\n",
      "Epoch 6/100\n",
      "380/380 [==============================] - 0s 128us/step - loss: 0.2688 - accuracy: 0.8895 - val_loss: 0.5512 - val_accuracy: 0.8221\n",
      "Epoch 7/100\n",
      "380/380 [==============================] - 0s 118us/step - loss: 0.2500 - accuracy: 0.9053 - val_loss: 0.5419 - val_accuracy: 0.7669\n",
      "Epoch 8/100\n",
      "380/380 [==============================] - 0s 109us/step - loss: 0.2231 - accuracy: 0.9158 - val_loss: 0.5158 - val_accuracy: 0.8098\n",
      "Epoch 9/100\n",
      "380/380 [==============================] - 0s 110us/step - loss: 0.2531 - accuracy: 0.8868 - val_loss: 0.5416 - val_accuracy: 0.8160\n",
      "Epoch 10/100\n",
      "380/380 [==============================] - 0s 116us/step - loss: 0.2702 - accuracy: 0.9026 - val_loss: 0.6455 - val_accuracy: 0.7669\n",
      "Epoch 11/100\n",
      "380/380 [==============================] - 0s 97us/step - loss: 0.2759 - accuracy: 0.8763 - val_loss: 0.5981 - val_accuracy: 0.7914\n",
      "Epoch 12/100\n",
      "380/380 [==============================] - 0s 116us/step - loss: 0.2513 - accuracy: 0.8842 - val_loss: 0.4784 - val_accuracy: 0.8160\n",
      "Epoch 13/100\n",
      "380/380 [==============================] - 0s 98us/step - loss: 0.2470 - accuracy: 0.9079 - val_loss: 0.5195 - val_accuracy: 0.8221\n",
      "Epoch 14/100\n",
      "380/380 [==============================] - 0s 111us/step - loss: 0.2310 - accuracy: 0.9132 - val_loss: 0.5279 - val_accuracy: 0.8221\n",
      "Epoch 15/100\n",
      "380/380 [==============================] - 0s 108us/step - loss: 0.2220 - accuracy: 0.9105 - val_loss: 0.6010 - val_accuracy: 0.7914\n",
      "Epoch 16/100\n",
      "380/380 [==============================] - 0s 108us/step - loss: 0.2487 - accuracy: 0.8842 - val_loss: 0.5191 - val_accuracy: 0.8405\n",
      "Epoch 17/100\n",
      "380/380 [==============================] - 0s 103us/step - loss: 0.2300 - accuracy: 0.9000 - val_loss: 0.5088 - val_accuracy: 0.8160\n",
      "Epoch 18/100\n",
      "380/380 [==============================] - 0s 100us/step - loss: 0.2380 - accuracy: 0.9079 - val_loss: 0.5686 - val_accuracy: 0.8221\n",
      "Epoch 19/100\n",
      "380/380 [==============================] - 0s 96us/step - loss: 0.2459 - accuracy: 0.9079 - val_loss: 0.6021 - val_accuracy: 0.7853\n",
      "Epoch 20/100\n",
      "380/380 [==============================] - 0s 110us/step - loss: 0.2107 - accuracy: 0.9079 - val_loss: 0.5490 - val_accuracy: 0.8344\n",
      "Epoch 21/100\n",
      "380/380 [==============================] - 0s 97us/step - loss: 0.2081 - accuracy: 0.9263 - val_loss: 0.6084 - val_accuracy: 0.7975\n",
      "Epoch 22/100\n",
      "380/380 [==============================] - 0s 131us/step - loss: 0.2092 - accuracy: 0.9105 - val_loss: 0.5017 - val_accuracy: 0.8221\n",
      "Epoch 23/100\n",
      "380/380 [==============================] - 0s 134us/step - loss: 0.2053 - accuracy: 0.9263 - val_loss: 0.5248 - val_accuracy: 0.8282\n",
      "Epoch 24/100\n",
      "380/380 [==============================] - 0s 137us/step - loss: 0.2186 - accuracy: 0.9237 - val_loss: 0.5249 - val_accuracy: 0.7975\n",
      "Epoch 25/100\n",
      "380/380 [==============================] - 0s 152us/step - loss: 0.2300 - accuracy: 0.8947 - val_loss: 0.5776 - val_accuracy: 0.7853\n",
      "Epoch 26/100\n",
      "380/380 [==============================] - 0s 133us/step - loss: 0.2062 - accuracy: 0.9158 - val_loss: 0.5597 - val_accuracy: 0.8282\n",
      "Epoch 27/100\n",
      "380/380 [==============================] - 0s 144us/step - loss: 0.2026 - accuracy: 0.9289 - val_loss: 0.4880 - val_accuracy: 0.8344\n",
      "Epoch 28/100\n",
      "380/380 [==============================] - 0s 109us/step - loss: 0.2120 - accuracy: 0.9053 - val_loss: 0.5644 - val_accuracy: 0.8098\n",
      "Epoch 29/100\n",
      "380/380 [==============================] - 0s 107us/step - loss: 0.2055 - accuracy: 0.9158 - val_loss: 0.5058 - val_accuracy: 0.8221\n",
      "Epoch 30/100\n",
      "380/380 [==============================] - 0s 106us/step - loss: 0.2261 - accuracy: 0.9184 - val_loss: 0.5722 - val_accuracy: 0.8221\n",
      "Epoch 31/100\n",
      "380/380 [==============================] - 0s 117us/step - loss: 0.2274 - accuracy: 0.9211 - val_loss: 0.4874 - val_accuracy: 0.8221\n",
      "Epoch 32/100\n",
      "380/380 [==============================] - 0s 118us/step - loss: 0.2146 - accuracy: 0.9105 - val_loss: 0.5142 - val_accuracy: 0.8344\n",
      "Epoch 33/100\n",
      "380/380 [==============================] - 0s 106us/step - loss: 0.2205 - accuracy: 0.9000 - val_loss: 0.5023 - val_accuracy: 0.8098\n",
      "Epoch 34/100\n",
      "380/380 [==============================] - 0s 115us/step - loss: 0.2430 - accuracy: 0.8895 - val_loss: 0.5126 - val_accuracy: 0.8344\n",
      "Epoch 35/100\n",
      "380/380 [==============================] - 0s 122us/step - loss: 0.2049 - accuracy: 0.9132 - val_loss: 0.6640 - val_accuracy: 0.7730\n",
      "Epoch 36/100\n",
      "380/380 [==============================] - 0s 143us/step - loss: 0.2071 - accuracy: 0.9237 - val_loss: 0.4985 - val_accuracy: 0.8098\n",
      "Epoch 37/100\n",
      "380/380 [==============================] - 0s 144us/step - loss: 0.2443 - accuracy: 0.8895 - val_loss: 0.5267 - val_accuracy: 0.8282\n",
      "Epoch 38/100\n",
      "380/380 [==============================] - 0s 157us/step - loss: 0.2483 - accuracy: 0.8921 - val_loss: 0.7171 - val_accuracy: 0.7607\n",
      "Epoch 39/100\n",
      "380/380 [==============================] - 0s 115us/step - loss: 0.2231 - accuracy: 0.8974 - val_loss: 0.5436 - val_accuracy: 0.8282\n",
      "Epoch 40/100\n",
      "380/380 [==============================] - 0s 108us/step - loss: 0.2079 - accuracy: 0.9211 - val_loss: 0.4848 - val_accuracy: 0.8221\n",
      "Epoch 41/100\n",
      "380/380 [==============================] - 0s 129us/step - loss: 0.2703 - accuracy: 0.8947 - val_loss: 0.7570 - val_accuracy: 0.7853\n",
      "Epoch 42/100\n",
      "380/380 [==============================] - 0s 129us/step - loss: 0.2400 - accuracy: 0.8816 - val_loss: 0.6771 - val_accuracy: 0.7791\n",
      "Epoch 43/100\n",
      "380/380 [==============================] - 0s 138us/step - loss: 0.2182 - accuracy: 0.8974 - val_loss: 0.6133 - val_accuracy: 0.7853\n",
      "Epoch 44/100\n",
      "380/380 [==============================] - 0s 136us/step - loss: 0.2357 - accuracy: 0.8789 - val_loss: 0.4910 - val_accuracy: 0.8160\n",
      "Epoch 45/100\n",
      "380/380 [==============================] - 0s 138us/step - loss: 0.2494 - accuracy: 0.8895 - val_loss: 0.6722 - val_accuracy: 0.7791\n",
      "Epoch 46/100\n",
      "380/380 [==============================] - 0s 129us/step - loss: 0.2379 - accuracy: 0.8974 - val_loss: 0.6154 - val_accuracy: 0.7914\n",
      "Epoch 47/100\n",
      "380/380 [==============================] - 0s 111us/step - loss: 0.2428 - accuracy: 0.8921 - val_loss: 0.5264 - val_accuracy: 0.8160\n",
      "Epoch 48/100\n",
      "380/380 [==============================] - 0s 112us/step - loss: 0.2136 - accuracy: 0.9158 - val_loss: 0.5697 - val_accuracy: 0.7730\n",
      "Epoch 49/100\n",
      "380/380 [==============================] - 0s 111us/step - loss: 0.2169 - accuracy: 0.9132 - val_loss: 0.5732 - val_accuracy: 0.8221\n",
      "Epoch 50/100\n",
      "380/380 [==============================] - 0s 100us/step - loss: 0.2214 - accuracy: 0.9105 - val_loss: 0.4955 - val_accuracy: 0.8160\n",
      "Epoch 51/100\n",
      "380/380 [==============================] - 0s 108us/step - loss: 0.2138 - accuracy: 0.9132 - val_loss: 0.5213 - val_accuracy: 0.8098\n",
      "Epoch 52/100\n",
      "380/380 [==============================] - 0s 96us/step - loss: 0.2058 - accuracy: 0.9211 - val_loss: 0.5678 - val_accuracy: 0.8037\n",
      "Epoch 53/100\n",
      "380/380 [==============================] - 0s 96us/step - loss: 0.2238 - accuracy: 0.9079 - val_loss: 0.5252 - val_accuracy: 0.8405\n",
      "Epoch 54/100\n",
      "380/380 [==============================] - 0s 105us/step - loss: 0.2102 - accuracy: 0.9158 - val_loss: 0.5087 - val_accuracy: 0.8405\n",
      "Epoch 55/100\n",
      "380/380 [==============================] - 0s 110us/step - loss: 0.1970 - accuracy: 0.9237 - val_loss: 0.5683 - val_accuracy: 0.8098\n",
      "Epoch 56/100\n",
      "380/380 [==============================] - 0s 100us/step - loss: 0.1995 - accuracy: 0.9158 - val_loss: 0.6309 - val_accuracy: 0.7914\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "380/380 [==============================] - 0s 113us/step - loss: 0.2014 - accuracy: 0.9237 - val_loss: 0.5644 - val_accuracy: 0.8160\n",
      "Epoch 58/100\n",
      "380/380 [==============================] - 0s 107us/step - loss: 0.1995 - accuracy: 0.9158 - val_loss: 0.4985 - val_accuracy: 0.8405\n",
      "Epoch 59/100\n",
      "380/380 [==============================] - 0s 208us/step - loss: 0.2088 - accuracy: 0.9158 - val_loss: 0.5300 - val_accuracy: 0.8160\n",
      "Epoch 60/100\n",
      "380/380 [==============================] - 0s 277us/step - loss: 0.1820 - accuracy: 0.9289 - val_loss: 0.5319 - val_accuracy: 0.8221\n",
      "Epoch 61/100\n",
      "380/380 [==============================] - 0s 174us/step - loss: 0.1868 - accuracy: 0.9184 - val_loss: 0.5584 - val_accuracy: 0.8160\n",
      "Epoch 62/100\n",
      "380/380 [==============================] - 0s 140us/step - loss: 0.1852 - accuracy: 0.9263 - val_loss: 0.6746 - val_accuracy: 0.7914\n",
      "Epoch 63/100\n",
      "380/380 [==============================] - 0s 134us/step - loss: 0.2174 - accuracy: 0.9053 - val_loss: 0.4792 - val_accuracy: 0.8282\n",
      "Epoch 64/100\n",
      "380/380 [==============================] - 0s 130us/step - loss: 0.2071 - accuracy: 0.9053 - val_loss: 0.5569 - val_accuracy: 0.8037\n",
      "Epoch 65/100\n",
      "380/380 [==============================] - 0s 158us/step - loss: 0.1946 - accuracy: 0.9158 - val_loss: 0.5606 - val_accuracy: 0.7853\n",
      "Epoch 66/100\n",
      "380/380 [==============================] - 0s 151us/step - loss: 0.1947 - accuracy: 0.9158 - val_loss: 0.6499 - val_accuracy: 0.7914\n",
      "Epoch 67/100\n",
      "380/380 [==============================] - 0s 144us/step - loss: 0.1949 - accuracy: 0.9184 - val_loss: 0.5342 - val_accuracy: 0.8282\n",
      "Epoch 68/100\n",
      "380/380 [==============================] - 0s 138us/step - loss: 0.1776 - accuracy: 0.9316 - val_loss: 0.5690 - val_accuracy: 0.7975\n",
      "Epoch 69/100\n",
      "380/380 [==============================] - 0s 561us/step - loss: 0.1807 - accuracy: 0.9289 - val_loss: 0.6458 - val_accuracy: 0.7914\n",
      "Epoch 70/100\n",
      "380/380 [==============================] - 0s 177us/step - loss: 0.1949 - accuracy: 0.9184 - val_loss: 0.5242 - val_accuracy: 0.8344\n",
      "Epoch 71/100\n",
      "380/380 [==============================] - 0s 163us/step - loss: 0.1796 - accuracy: 0.9184 - val_loss: 0.5394 - val_accuracy: 0.7975\n",
      "Epoch 72/100\n",
      "380/380 [==============================] - 0s 214us/step - loss: 0.1788 - accuracy: 0.9237 - val_loss: 0.5904 - val_accuracy: 0.8037\n",
      "Epoch 73/100\n",
      "380/380 [==============================] - 0s 123us/step - loss: 0.1784 - accuracy: 0.9237 - val_loss: 0.5616 - val_accuracy: 0.7975\n",
      "Epoch 74/100\n",
      "380/380 [==============================] - 0s 147us/step - loss: 0.1760 - accuracy: 0.9263 - val_loss: 0.6139 - val_accuracy: 0.8037\n",
      "Epoch 75/100\n",
      "380/380 [==============================] - 0s 452us/step - loss: 0.1746 - accuracy: 0.9263 - val_loss: 0.5084 - val_accuracy: 0.8405\n",
      "Epoch 76/100\n",
      "380/380 [==============================] - 0s 151us/step - loss: 0.1783 - accuracy: 0.9237 - val_loss: 0.5957 - val_accuracy: 0.8098\n",
      "Epoch 77/100\n",
      "380/380 [==============================] - 0s 221us/step - loss: 0.1822 - accuracy: 0.9184 - val_loss: 0.6698 - val_accuracy: 0.7914\n",
      "Epoch 78/100\n",
      "380/380 [==============================] - 0s 183us/step - loss: 0.1825 - accuracy: 0.9289 - val_loss: 0.5864 - val_accuracy: 0.7975\n",
      "Epoch 79/100\n",
      "380/380 [==============================] - 0s 125us/step - loss: 0.1985 - accuracy: 0.9158 - val_loss: 0.5377 - val_accuracy: 0.8098\n",
      "Epoch 80/100\n",
      "380/380 [==============================] - 0s 147us/step - loss: 0.1877 - accuracy: 0.9237 - val_loss: 0.5877 - val_accuracy: 0.8037\n",
      "Epoch 81/100\n",
      "380/380 [==============================] - 0s 113us/step - loss: 0.1834 - accuracy: 0.9263 - val_loss: 0.5292 - val_accuracy: 0.8221\n",
      "Epoch 82/100\n",
      "380/380 [==============================] - 0s 120us/step - loss: 0.2290 - accuracy: 0.9000 - val_loss: 0.5385 - val_accuracy: 0.8037\n",
      "Epoch 83/100\n",
      "380/380 [==============================] - 0s 113us/step - loss: 0.1847 - accuracy: 0.9158 - val_loss: 0.5340 - val_accuracy: 0.8282\n",
      "Epoch 84/100\n",
      "380/380 [==============================] - 0s 120us/step - loss: 0.1724 - accuracy: 0.9263 - val_loss: 0.5625 - val_accuracy: 0.8098\n",
      "Epoch 85/100\n",
      "380/380 [==============================] - 0s 118us/step - loss: 0.1736 - accuracy: 0.9237 - val_loss: 0.5761 - val_accuracy: 0.7914\n",
      "Epoch 86/100\n",
      "380/380 [==============================] - 0s 113us/step - loss: 0.1723 - accuracy: 0.9237 - val_loss: 0.5464 - val_accuracy: 0.8282\n",
      "Epoch 87/100\n",
      "380/380 [==============================] - 0s 119us/step - loss: 0.1837 - accuracy: 0.9263 - val_loss: 0.5642 - val_accuracy: 0.8098\n",
      "Epoch 88/100\n",
      "380/380 [==============================] - 0s 126us/step - loss: 0.1701 - accuracy: 0.9211 - val_loss: 0.5450 - val_accuracy: 0.8221\n",
      "Epoch 89/100\n",
      "380/380 [==============================] - 0s 117us/step - loss: 0.1778 - accuracy: 0.9184 - val_loss: 0.5646 - val_accuracy: 0.8160\n",
      "Epoch 90/100\n",
      "380/380 [==============================] - 0s 101us/step - loss: 0.1775 - accuracy: 0.9237 - val_loss: 0.5472 - val_accuracy: 0.7975\n",
      "Epoch 91/100\n",
      "380/380 [==============================] - 0s 100us/step - loss: 0.2248 - accuracy: 0.9105 - val_loss: 0.6617 - val_accuracy: 0.7730\n",
      "Epoch 92/100\n",
      "380/380 [==============================] - 0s 102us/step - loss: 0.2236 - accuracy: 0.9000 - val_loss: 0.7008 - val_accuracy: 0.7791\n",
      "Epoch 93/100\n",
      "380/380 [==============================] - 0s 122us/step - loss: 0.2463 - accuracy: 0.8947 - val_loss: 0.8642 - val_accuracy: 0.7669\n",
      "Epoch 94/100\n",
      "380/380 [==============================] - 0s 281us/step - loss: 0.2584 - accuracy: 0.8895 - val_loss: 0.5563 - val_accuracy: 0.8282\n",
      "Epoch 95/100\n",
      "380/380 [==============================] - 0s 155us/step - loss: 0.2678 - accuracy: 0.8921 - val_loss: 0.7550 - val_accuracy: 0.7791\n",
      "Epoch 96/100\n",
      "380/380 [==============================] - 0s 228us/step - loss: 0.2000 - accuracy: 0.9158 - val_loss: 0.5206 - val_accuracy: 0.8037\n",
      "Epoch 97/100\n",
      "380/380 [==============================] - 0s 178us/step - loss: 0.1975 - accuracy: 0.9158 - val_loss: 0.6069 - val_accuracy: 0.7853\n",
      "Epoch 98/100\n",
      "380/380 [==============================] - 0s 298us/step - loss: 0.2020 - accuracy: 0.9263 - val_loss: 0.6831 - val_accuracy: 0.7853\n",
      "Epoch 99/100\n",
      "380/380 [==============================] - 0s 226us/step - loss: 0.2116 - accuracy: 0.9158 - val_loss: 0.6016 - val_accuracy: 0.7730\n",
      "Epoch 100/100\n",
      "380/380 [==============================] - 0s 174us/step - loss: 0.1925 - accuracy: 0.9158 - val_loss: 0.5555 - val_accuracy: 0.8282\n"
     ]
    }
   ],
   "source": [
    "hist1_over3 = model1_over3.fit(X_train_over, y_train_over,\n",
    "          batch_size=64, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 91.06%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over3.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba3 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_2.xlsx\",\n",
    "                        sheet_name=2,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>0.013518</td>\n",
       "      <td>9.820048e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>0.013518</td>\n",
       "      <td>9.820048e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS222</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.851725</td>\n",
       "      <td>0.148269</td>\n",
       "      <td>5.980786e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>0.013518</td>\n",
       "      <td>9.820048e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>GA50245</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.812055</td>\n",
       "      <td>0.187945</td>\n",
       "      <td>1.161034e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4279</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>0.000928</td>\n",
       "      <td>9.984396e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4280</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>0.000928</td>\n",
       "      <td>9.984396e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4281</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS266</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.025932</td>\n",
       "      <td>0.974061</td>\n",
       "      <td>7.323514e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4282</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000597</td>\n",
       "      <td>0.999403</td>\n",
       "      <td>3.675362e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4283</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS112</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>0.999452</td>\n",
       "      <td>1.168620e-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4284 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    phage   strain  phenotype  prediction         0         1  \\\n",
       "0      p002ykpresabs_qual   NRS109          2           2  0.004477  0.013518   \n",
       "1      p002ykpresabs_qual   NRS109          2           2  0.004477  0.013518   \n",
       "2      p002ykpresabs_qual   NRS222          0           0  0.851725  0.148269   \n",
       "3      p002ykpresabs_qual   NRS109          2           2  0.004477  0.013518   \n",
       "4      p002ykpresabs_qual  GA50245          0           0  0.812055  0.187945   \n",
       "...                   ...      ...        ...         ...       ...       ...   \n",
       "4279  pyopresabsSTCC_qual   NRS255          2           2  0.000633  0.000928   \n",
       "4280  pyopresabsSTCC_qual   NRS255          2           2  0.000633  0.000928   \n",
       "4281  pyopresabsSTCC_qual   NRS266          1           1  0.025932  0.974061   \n",
       "4282  pyopresabsSTCC_qual   NRS001          1           1  0.000597  0.999403   \n",
       "4283  pyopresabsSTCC_qual   NRS112          1           1  0.000537  0.999452   \n",
       "\n",
       "                 2  \n",
       "0     9.820048e-01  \n",
       "1     9.820048e-01  \n",
       "2     5.980786e-06  \n",
       "3     9.820048e-01  \n",
       "4     1.161034e-07  \n",
       "...            ...  \n",
       "4279  9.984396e-01  \n",
       "4280  9.984396e-01  \n",
       "4281  7.323514e-06  \n",
       "4282  3.675362e-10  \n",
       "4283  1.168620e-05  \n",
       "\n",
       "[4284 rows x 7 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.81236200e-01, 1.22012330e-03, 1.75436550e-02],\n",
       "       [9.62963040e-01, 2.64746080e-02, 1.05623360e-02],\n",
       "       [8.18407300e-02, 1.81278270e-01, 7.36881000e-01],\n",
       "       [2.95371170e-03, 9.68637300e-01, 2.84089970e-02],\n",
       "       [9.93843440e-01, 1.00909660e-03, 5.14757540e-03],\n",
       "       [7.45568350e-02, 5.57530100e-01, 3.67913040e-01],\n",
       "       [9.94844700e-01, 1.05456050e-03, 4.10082750e-03],\n",
       "       [3.73867120e-01, 4.66225770e-01, 1.59907090e-01],\n",
       "       [9.85071540e-01, 3.30949840e-04, 1.45975140e-02],\n",
       "       [8.27075360e-01, 1.41998840e-01, 3.09256760e-02],\n",
       "       [9.76711700e-05, 9.79777400e-01, 2.01249220e-02],\n",
       "       [3.42044800e-03, 3.69428730e-02, 9.59636600e-01],\n",
       "       [8.05964600e-06, 9.47391100e-01, 5.26008460e-02],\n",
       "       [5.21736600e-01, 6.87568750e-05, 4.78194650e-01],\n",
       "       [9.97449100e-01, 2.44725570e-03, 1.03546710e-04],\n",
       "       [3.02320430e-04, 7.54676160e-01, 2.45021580e-01],\n",
       "       [2.14490390e-02, 2.85164740e-01, 6.93386200e-01],\n",
       "       [3.73867120e-01, 4.66225770e-01, 1.59907090e-01],\n",
       "       [9.87966950e-01, 1.09561726e-04, 1.19235330e-02],\n",
       "       [5.79909130e-04, 5.79829560e-03, 9.93621770e-01],\n",
       "       [2.79708340e-02, 2.79058720e-01, 6.92970450e-01],\n",
       "       [1.54716950e-04, 2.27386020e-04, 9.99617800e-01],\n",
       "       [6.04730600e-01, 3.39667870e-04, 3.94929680e-01],\n",
       "       [6.81320670e-06, 2.29672580e-03, 9.97696460e-01],\n",
       "       [6.87440950e-03, 4.04255800e-02, 9.52699960e-01],\n",
       "       [5.22418800e-04, 9.99437750e-01, 3.97507500e-05],\n",
       "       [6.14738300e-02, 2.02005680e-01, 7.36520470e-01],\n",
       "       [5.04502400e-02, 3.16939860e-01, 6.32609960e-01],\n",
       "       [9.79945540e-01, 1.70872350e-03, 1.83457320e-02],\n",
       "       [9.94844700e-01, 1.05456050e-03, 4.10082750e-03],\n",
       "       [1.59610510e-02, 8.89831500e-01, 9.42073900e-02],\n",
       "       [7.55483900e-08, 9.99994640e-01, 5.28717650e-06],\n",
       "       [2.97125520e-05, 9.99117900e-01, 8.52407300e-04],\n",
       "       [7.45568350e-02, 5.57530100e-01, 3.67913040e-01],\n",
       "       [5.24348600e-01, 2.94795660e-03, 4.72703430e-01],\n",
       "       [4.42046080e-06, 9.99941800e-01, 5.37750020e-05],\n",
       "       [9.93334400e-02, 7.89868060e-01, 1.10798430e-01],\n",
       "       [8.76194050e-03, 5.52790050e-01, 4.38447920e-01],\n",
       "       [1.59610510e-02, 8.89831500e-01, 9.42073900e-02],\n",
       "       [1.36655360e-06, 4.91495600e-04, 9.99507200e-01],\n",
       "       [9.94844700e-01, 1.05456050e-03, 4.10082750e-03],\n",
       "       [3.79382600e-09, 9.99944570e-01, 5.54100330e-05],\n",
       "       [7.55483900e-08, 9.99994640e-01, 5.28717650e-06],\n",
       "       [1.35017940e-06, 9.99987600e-01, 1.10657860e-05],\n",
       "       [7.26002200e-04, 8.30869140e-01, 1.68404770e-01],\n",
       "       [1.56641630e-01, 2.69335980e-05, 8.43331460e-01],\n",
       "       [5.70498230e-04, 3.03855040e-02, 9.69044000e-01],\n",
       "       [7.45568350e-02, 5.57530100e-01, 3.67913040e-01],\n",
       "       [9.78881360e-01, 9.31118300e-03, 1.18074670e-02],\n",
       "       [3.73867120e-01, 4.66225770e-01, 1.59907090e-01],\n",
       "       [5.75232840e-02, 2.61812300e-01, 6.80664360e-01],\n",
       "       [9.88765800e-01, 3.46275900e-03, 7.77139100e-03],\n",
       "       [9.79945540e-01, 1.70872350e-03, 1.83457320e-02],\n",
       "       [9.79945540e-01, 1.70872350e-03, 1.83457320e-02],\n",
       "       [1.79321300e-03, 2.11075340e-01, 7.87131500e-01],\n",
       "       [3.73867120e-01, 4.66225770e-01, 1.59907090e-01],\n",
       "       [2.49920560e-02, 1.54116230e-01, 8.20891740e-01],\n",
       "       [4.98889200e-02, 5.61526540e-01, 3.88584520e-01],\n",
       "       [1.34187480e-03, 2.22748610e-02, 9.76383300e-01],\n",
       "       [4.42046080e-06, 9.99941800e-01, 5.37750020e-05],\n",
       "       [5.13787600e-02, 1.39009320e-04, 9.48482200e-01],\n",
       "       [4.67339940e-02, 7.15650900e-01, 2.37615100e-01],\n",
       "       [2.21026000e-01, 2.74992440e-01, 5.03981600e-01],\n",
       "       [1.22539180e-04, 9.99789660e-01, 8.77846100e-05],\n",
       "       [7.55483900e-08, 9.99994640e-01, 5.28717650e-06],\n",
       "       [7.45882500e-01, 3.77125940e-05, 2.54079800e-01],\n",
       "       [7.45882500e-01, 3.77125940e-05, 2.54079800e-01],\n",
       "       [7.44356160e-01, 3.26998400e-02, 2.22943930e-01],\n",
       "       [9.88765800e-01, 3.46275900e-03, 7.77139100e-03],\n",
       "       [5.06057260e-01, 4.78503970e-01, 1.54386840e-02],\n",
       "       [9.92014350e-01, 2.77132500e-03, 5.21436330e-03],\n",
       "       [3.73867120e-01, 4.66225770e-01, 1.59907090e-01],\n",
       "       [5.11862750e-06, 4.42474340e-03, 9.95570100e-01],\n",
       "       [7.45882500e-01, 3.77125940e-05, 2.54079800e-01],\n",
       "       [9.99184550e-01, 2.50102540e-04, 5.65336100e-04],\n",
       "       [2.25533200e-04, 9.99751150e-01, 2.33866270e-05],\n",
       "       [9.77160450e-01, 7.45015630e-06, 2.28321240e-02],\n",
       "       [3.63013920e-01, 1.19216435e-01, 5.17769700e-01],\n",
       "       [9.87966950e-01, 1.09561726e-04, 1.19235330e-02],\n",
       "       [9.88765800e-01, 3.46275900e-03, 7.77139100e-03],\n",
       "       [9.43072100e-01, 6.50033350e-03, 5.04276700e-02],\n",
       "       [1.86284180e-02, 4.81564200e-01, 4.99807300e-01],\n",
       "       [4.25905050e-05, 2.45567560e-04, 9.99711800e-01],\n",
       "       [8.91754100e-05, 1.47147440e-04, 9.99763670e-01],\n",
       "       [1.10295900e-03, 2.26502180e-02, 9.76246830e-01],\n",
       "       [8.27075360e-01, 1.41998840e-01, 3.09256760e-02],\n",
       "       [8.27075360e-01, 1.41998840e-01, 3.09256760e-02],\n",
       "       [1.69027670e-04, 9.88974330e-01, 1.08565740e-02],\n",
       "       [1.93968990e-05, 4.99546100e-04, 9.99481140e-01],\n",
       "       [9.99184550e-01, 2.50102540e-04, 5.65336100e-04],\n",
       "       [2.21026000e-01, 2.74992440e-01, 5.03981600e-01],\n",
       "       [9.81236200e-01, 1.22012330e-03, 1.75436550e-02],\n",
       "       [9.98023870e-01, 3.71173460e-04, 1.60494330e-03],\n",
       "       [9.79945540e-01, 1.70872350e-03, 1.83457320e-02],\n",
       "       [3.73867120e-01, 4.66225770e-01, 1.59907090e-01],\n",
       "       [3.65426600e-02, 2.90819050e-01, 6.72638300e-01],\n",
       "       [1.06690780e-02, 9.86122600e-01, 3.20832080e-03],\n",
       "       [7.55444000e-02, 5.53449150e-01, 3.71006430e-01],\n",
       "       [8.90378200e-01, 1.15939790e-03, 1.08462475e-01],\n",
       "       [7.45568350e-02, 5.57530100e-01, 3.67913040e-01],\n",
       "       [5.01059660e-05, 6.69475370e-03, 9.93255140e-01],\n",
       "       [9.94844700e-01, 1.05456050e-03, 4.10082750e-03],\n",
       "       [9.76711700e-05, 9.79777400e-01, 2.01249220e-02],\n",
       "       [9.16402000e-04, 6.33841600e-01, 3.65242060e-01],\n",
       "       [1.41367690e-02, 1.40899870e-01, 8.44963400e-01],\n",
       "       [9.94844700e-01, 1.05456050e-03, 4.10082750e-03],\n",
       "       [5.47951960e-04, 6.50308650e-02, 9.34421200e-01],\n",
       "       [5.22418800e-04, 9.99437750e-01, 3.97507500e-05],\n",
       "       [2.25533200e-04, 9.99751150e-01, 2.33866270e-05],\n",
       "       [8.71316900e-05, 9.91592900e-01, 8.32001800e-03],\n",
       "       [7.45568350e-02, 5.57530100e-01, 3.67913040e-01],\n",
       "       [9.01310000e-03, 2.05381350e-01, 7.85605550e-01],\n",
       "       [7.45568350e-02, 5.57530100e-01, 3.67913040e-01],\n",
       "       [3.63013920e-01, 1.19216435e-01, 5.17769700e-01],\n",
       "       [3.65633400e-07, 5.70126100e-04, 9.99429500e-01],\n",
       "       [5.81633470e-05, 1.15177936e-04, 9.99826700e-01],\n",
       "       [7.45568350e-02, 5.57530100e-01, 3.67913040e-01],\n",
       "       [5.02582900e-05, 9.83248000e-01, 1.67017000e-02],\n",
       "       [3.65426600e-02, 2.90819050e-01, 6.72638300e-01],\n",
       "       [1.30276130e-01, 2.66853540e-01, 6.02870350e-01],\n",
       "       [1.07645760e-06, 3.42535800e-04, 9.99656440e-01],\n",
       "       [1.47590500e-04, 1.97800700e-01, 8.02051660e-01],\n",
       "       [9.97449100e-01, 2.44725570e-03, 1.03546710e-04],\n",
       "       [1.16763210e-01, 8.80879160e-01, 2.35754460e-03],\n",
       "       [1.59610510e-02, 8.89831500e-01, 9.42073900e-02],\n",
       "       [1.35017940e-06, 9.99987600e-01, 1.10657860e-05],\n",
       "       [9.69751330e-04, 5.59727250e-04, 9.98470500e-01],\n",
       "       [7.45568350e-02, 5.57530100e-01, 3.67913040e-01],\n",
       "       [2.97125520e-05, 9.99117900e-01, 8.52407300e-04],\n",
       "       [4.42046080e-06, 9.99941800e-01, 5.37750020e-05],\n",
       "       [3.79382600e-09, 9.99944570e-01, 5.54100330e-05],\n",
       "       [8.27075360e-01, 1.41998840e-01, 3.09256760e-02],\n",
       "       [1.69027670e-04, 9.88974330e-01, 1.08565740e-02],\n",
       "       [4.31642800e-02, 3.05622160e-01, 6.51213500e-01],\n",
       "       [9.62963040e-01, 2.64746080e-02, 1.05623360e-02],\n",
       "       [3.40219960e-03, 7.22367200e-02, 9.24361050e-01],\n",
       "       [9.62963040e-01, 2.64746080e-02, 1.05623360e-02],\n",
       "       [9.81236200e-01, 1.22012330e-03, 1.75436550e-02],\n",
       "       [9.55751200e-01, 6.81941240e-05, 4.41805240e-02],\n",
       "       [5.83016200e-08, 1.46095860e-04, 9.99853850e-01],\n",
       "       [1.06690780e-02, 9.86122600e-01, 3.20832080e-03],\n",
       "       [9.55751200e-01, 6.81941240e-05, 4.41805240e-02],\n",
       "       [4.98889200e-02, 5.61526540e-01, 3.88584520e-01],\n",
       "       [9.97449100e-01, 2.44725570e-03, 1.03546710e-04],\n",
       "       [3.73867120e-01, 4.66225770e-01, 1.59907090e-01],\n",
       "       [4.42046080e-06, 9.99941800e-01, 5.37750020e-05],\n",
       "       [9.99184550e-01, 2.50102540e-04, 5.65336100e-04],\n",
       "       [9.88765800e-01, 3.46275900e-03, 7.77139100e-03],\n",
       "       [9.97697200e-01, 4.88592160e-05, 2.25396360e-03],\n",
       "       [1.28499960e-02, 1.46083860e-01, 8.41066200e-01],\n",
       "       [9.81236200e-01, 1.22012330e-03, 1.75436550e-02],\n",
       "       [3.63013920e-01, 1.19216435e-01, 5.17769700e-01],\n",
       "       [1.39683800e-05, 9.90862370e-01, 9.12367800e-03],\n",
       "       [9.92014350e-01, 2.77132500e-03, 5.21436330e-03],\n",
       "       [9.76711700e-05, 9.79777400e-01, 2.01249220e-02],\n",
       "       [9.87966950e-01, 1.09561726e-04, 1.19235330e-02],\n",
       "       [2.95371170e-03, 9.68637300e-01, 2.84089970e-02],\n",
       "       [2.99938060e-02, 9.28063400e-01, 4.19428600e-02],\n",
       "       [9.94844700e-01, 1.05456050e-03, 4.10082750e-03],\n",
       "       [4.98889200e-02, 5.61526540e-01, 3.88584520e-01],\n",
       "       [6.04730600e-01, 3.39667870e-04, 3.94929680e-01],\n",
       "       [2.95371170e-03, 9.68637300e-01, 2.84089970e-02],\n",
       "       [1.35017940e-06, 9.99987600e-01, 1.10657860e-05]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob3 = df_proba3[df_proba3['phage']=='p11kpresabs_qual'].iloc[:,-3:]\n",
    "y_prob3 = y_prob3.to_numpy()\n",
    "y_prob3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9394065527857577"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo3 = rocauc_ovo(y_test_over, y_prob3, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9394065527857577"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr3 = rocauc_ovr(y_test_over, y_prob3, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=456,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat4 = pd.DataFrame(X_test_over[:,0])\n",
    "dat4['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SR2852</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CFBREBSa138</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BCH-SA-12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EUH13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EUH13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>NRS036</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>CA105</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>CFBRSa51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>NRS102</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>NRS189</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test\n",
       "0         SR2852     2\n",
       "1    CFBREBSa138     0\n",
       "2      BCH-SA-12     0\n",
       "3          EUH13     0\n",
       "4          EUH13     0\n",
       "..           ...   ...\n",
       "158       NRS036     1\n",
       "159        CA105     1\n",
       "160     CFBRSa51     1\n",
       "161       NRS102     1\n",
       "162       NRS189     2\n",
       "\n",
       "[163 rows x 2 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over4 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over4.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 380 samples, validate on 163 samples\n",
      "Epoch 1/100\n",
      "380/380 [==============================] - 0s 744us/step - loss: 1.1390 - accuracy: 0.3684 - val_loss: 1.0621 - val_accuracy: 0.4847\n",
      "Epoch 2/100\n",
      "380/380 [==============================] - 0s 184us/step - loss: 1.0336 - accuracy: 0.4658 - val_loss: 1.0125 - val_accuracy: 0.5644\n",
      "Epoch 3/100\n",
      "380/380 [==============================] - 0s 157us/step - loss: 0.9844 - accuracy: 0.5711 - val_loss: 0.9786 - val_accuracy: 0.5828\n",
      "Epoch 4/100\n",
      "380/380 [==============================] - 0s 186us/step - loss: 0.9369 - accuracy: 0.6158 - val_loss: 0.9575 - val_accuracy: 0.5890\n",
      "Epoch 5/100\n",
      "380/380 [==============================] - 0s 200us/step - loss: 0.8896 - accuracy: 0.6158 - val_loss: 0.9384 - val_accuracy: 0.5583\n",
      "Epoch 6/100\n",
      "380/380 [==============================] - 0s 220us/step - loss: 0.8499 - accuracy: 0.6763 - val_loss: 0.8763 - val_accuracy: 0.6135\n",
      "Epoch 7/100\n",
      "380/380 [==============================] - 0s 213us/step - loss: 0.8050 - accuracy: 0.6974 - val_loss: 0.9141 - val_accuracy: 0.5644\n",
      "Epoch 8/100\n",
      "380/380 [==============================] - 0s 241us/step - loss: 0.8496 - accuracy: 0.6368 - val_loss: 0.9375 - val_accuracy: 0.5706\n",
      "Epoch 9/100\n",
      "380/380 [==============================] - 0s 204us/step - loss: 0.7652 - accuracy: 0.6868 - val_loss: 0.8422 - val_accuracy: 0.6503\n",
      "Epoch 10/100\n",
      "380/380 [==============================] - 0s 151us/step - loss: 0.7905 - accuracy: 0.6737 - val_loss: 0.8260 - val_accuracy: 0.6196\n",
      "Epoch 11/100\n",
      "380/380 [==============================] - 0s 128us/step - loss: 0.7078 - accuracy: 0.7211 - val_loss: 0.7615 - val_accuracy: 0.6503\n",
      "Epoch 12/100\n",
      "380/380 [==============================] - 0s 131us/step - loss: 0.6846 - accuracy: 0.7421 - val_loss: 0.7659 - val_accuracy: 0.6380\n",
      "Epoch 13/100\n",
      "380/380 [==============================] - 0s 296us/step - loss: 0.6556 - accuracy: 0.7263 - val_loss: 0.7212 - val_accuracy: 0.6810\n",
      "Epoch 14/100\n",
      "380/380 [==============================] - 0s 225us/step - loss: 0.6275 - accuracy: 0.7474 - val_loss: 0.7238 - val_accuracy: 0.6748\n",
      "Epoch 15/100\n",
      "380/380 [==============================] - 0s 155us/step - loss: 0.6430 - accuracy: 0.7421 - val_loss: 0.7364 - val_accuracy: 0.6626\n",
      "Epoch 16/100\n",
      "380/380 [==============================] - 0s 315us/step - loss: 0.6555 - accuracy: 0.7289 - val_loss: 0.7194 - val_accuracy: 0.6135\n",
      "Epoch 17/100\n",
      "380/380 [==============================] - 0s 230us/step - loss: 0.5956 - accuracy: 0.7526 - val_loss: 0.7354 - val_accuracy: 0.6319\n",
      "Epoch 18/100\n",
      "380/380 [==============================] - 0s 170us/step - loss: 0.5823 - accuracy: 0.7632 - val_loss: 0.6745 - val_accuracy: 0.7178\n",
      "Epoch 19/100\n",
      "380/380 [==============================] - 0s 264us/step - loss: 0.5429 - accuracy: 0.7684 - val_loss: 0.7419 - val_accuracy: 0.6626\n",
      "Epoch 20/100\n",
      "380/380 [==============================] - 0s 184us/step - loss: 0.5918 - accuracy: 0.7526 - val_loss: 0.7361 - val_accuracy: 0.6687\n",
      "Epoch 21/100\n",
      "380/380 [==============================] - 0s 118us/step - loss: 0.5832 - accuracy: 0.7632 - val_loss: 0.7018 - val_accuracy: 0.6626\n",
      "Epoch 22/100\n",
      "380/380 [==============================] - 0s 107us/step - loss: 0.5149 - accuracy: 0.7711 - val_loss: 0.6779 - val_accuracy: 0.6564\n",
      "Epoch 23/100\n",
      "380/380 [==============================] - 0s 106us/step - loss: 0.4852 - accuracy: 0.7895 - val_loss: 0.6015 - val_accuracy: 0.7362\n",
      "Epoch 24/100\n",
      "380/380 [==============================] - 0s 107us/step - loss: 0.4841 - accuracy: 0.7737 - val_loss: 0.5856 - val_accuracy: 0.7055\n",
      "Epoch 25/100\n",
      "380/380 [==============================] - 0s 135us/step - loss: 0.4644 - accuracy: 0.8079 - val_loss: 0.6014 - val_accuracy: 0.6994\n",
      "Epoch 26/100\n",
      "380/380 [==============================] - 0s 476us/step - loss: 0.4861 - accuracy: 0.7711 - val_loss: 0.7035 - val_accuracy: 0.6442\n",
      "Epoch 27/100\n",
      "380/380 [==============================] - 0s 252us/step - loss: 0.4544 - accuracy: 0.8263 - val_loss: 0.5691 - val_accuracy: 0.7423\n",
      "Epoch 28/100\n",
      "380/380 [==============================] - 0s 307us/step - loss: 0.4190 - accuracy: 0.8289 - val_loss: 0.5668 - val_accuracy: 0.7055\n",
      "Epoch 29/100\n",
      "380/380 [==============================] - 0s 223us/step - loss: 0.4335 - accuracy: 0.8105 - val_loss: 0.5919 - val_accuracy: 0.7301\n",
      "Epoch 30/100\n",
      "380/380 [==============================] - 0s 287us/step - loss: 0.4152 - accuracy: 0.8395 - val_loss: 0.5414 - val_accuracy: 0.7730\n",
      "Epoch 31/100\n",
      "380/380 [==============================] - 0s 260us/step - loss: 0.4133 - accuracy: 0.8132 - val_loss: 0.5685 - val_accuracy: 0.7546\n",
      "Epoch 32/100\n",
      "380/380 [==============================] - 0s 306us/step - loss: 0.4873 - accuracy: 0.7711 - val_loss: 0.5815 - val_accuracy: 0.7791\n",
      "Epoch 33/100\n",
      "380/380 [==============================] - 0s 271us/step - loss: 0.4431 - accuracy: 0.7974 - val_loss: 0.5391 - val_accuracy: 0.7791\n",
      "Epoch 34/100\n",
      "380/380 [==============================] - 0s 280us/step - loss: 0.4297 - accuracy: 0.8158 - val_loss: 0.6443 - val_accuracy: 0.6687\n",
      "Epoch 35/100\n",
      "380/380 [==============================] - 0s 231us/step - loss: 0.3899 - accuracy: 0.8474 - val_loss: 0.5120 - val_accuracy: 0.7975\n",
      "Epoch 36/100\n",
      "380/380 [==============================] - 0s 141us/step - loss: 0.3593 - accuracy: 0.8500 - val_loss: 0.5094 - val_accuracy: 0.7669\n",
      "Epoch 37/100\n",
      "380/380 [==============================] - 0s 125us/step - loss: 0.3516 - accuracy: 0.8605 - val_loss: 0.5109 - val_accuracy: 0.7055\n",
      "Epoch 38/100\n",
      "380/380 [==============================] - 0s 113us/step - loss: 0.3697 - accuracy: 0.8474 - val_loss: 0.5060 - val_accuracy: 0.7485\n",
      "Epoch 39/100\n",
      "380/380 [==============================] - 0s 137us/step - loss: 0.4080 - accuracy: 0.8289 - val_loss: 0.5184 - val_accuracy: 0.7669\n",
      "Epoch 40/100\n",
      "380/380 [==============================] - 0s 138us/step - loss: 0.4060 - accuracy: 0.8421 - val_loss: 0.6231 - val_accuracy: 0.7178\n",
      "Epoch 41/100\n",
      "380/380 [==============================] - 0s 214us/step - loss: 0.4292 - accuracy: 0.8132 - val_loss: 0.5366 - val_accuracy: 0.7117\n",
      "Epoch 42/100\n",
      "380/380 [==============================] - 0s 310us/step - loss: 0.3352 - accuracy: 0.8789 - val_loss: 0.4765 - val_accuracy: 0.7730\n",
      "Epoch 43/100\n",
      "380/380 [==============================] - 0s 188us/step - loss: 0.3366 - accuracy: 0.8474 - val_loss: 0.4873 - val_accuracy: 0.7485\n",
      "Epoch 44/100\n",
      "380/380 [==============================] - 0s 248us/step - loss: 0.3290 - accuracy: 0.8632 - val_loss: 0.4794 - val_accuracy: 0.7791\n",
      "Epoch 45/100\n",
      "380/380 [==============================] - 0s 316us/step - loss: 0.3216 - accuracy: 0.8789 - val_loss: 0.4957 - val_accuracy: 0.7791\n",
      "Epoch 46/100\n",
      "380/380 [==============================] - 0s 238us/step - loss: 0.3198 - accuracy: 0.8526 - val_loss: 0.5149 - val_accuracy: 0.7853\n",
      "Epoch 47/100\n",
      "380/380 [==============================] - 0s 119us/step - loss: 0.3526 - accuracy: 0.8342 - val_loss: 0.5075 - val_accuracy: 0.7791\n",
      "Epoch 48/100\n",
      "380/380 [==============================] - 0s 127us/step - loss: 0.3195 - accuracy: 0.8632 - val_loss: 0.4788 - val_accuracy: 0.7423\n",
      "Epoch 49/100\n",
      "380/380 [==============================] - 0s 105us/step - loss: 0.2999 - accuracy: 0.8974 - val_loss: 0.4775 - val_accuracy: 0.8098\n",
      "Epoch 50/100\n",
      "380/380 [==============================] - 0s 110us/step - loss: 0.3017 - accuracy: 0.8763 - val_loss: 0.5345 - val_accuracy: 0.7607\n",
      "Epoch 51/100\n",
      "380/380 [==============================] - 0s 113us/step - loss: 0.3172 - accuracy: 0.8474 - val_loss: 0.4800 - val_accuracy: 0.7791\n",
      "Epoch 52/100\n",
      "380/380 [==============================] - 0s 107us/step - loss: 0.2941 - accuracy: 0.8658 - val_loss: 0.5431 - val_accuracy: 0.7730\n",
      "Epoch 53/100\n",
      "380/380 [==============================] - 0s 109us/step - loss: 0.3183 - accuracy: 0.8816 - val_loss: 0.5407 - val_accuracy: 0.7546\n",
      "Epoch 54/100\n",
      "380/380 [==============================] - 0s 113us/step - loss: 0.3400 - accuracy: 0.8368 - val_loss: 0.4993 - val_accuracy: 0.7914\n",
      "Epoch 55/100\n",
      "380/380 [==============================] - 0s 207us/step - loss: 0.3144 - accuracy: 0.8526 - val_loss: 0.5208 - val_accuracy: 0.7546\n",
      "Epoch 56/100\n",
      "380/380 [==============================] - 0s 286us/step - loss: 0.3075 - accuracy: 0.8763 - val_loss: 0.4725 - val_accuracy: 0.7669\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "380/380 [==============================] - 0s 292us/step - loss: 0.2889 - accuracy: 0.8658 - val_loss: 0.5009 - val_accuracy: 0.7914\n",
      "Epoch 58/100\n",
      "380/380 [==============================] - 0s 118us/step - loss: 0.2783 - accuracy: 0.8868 - val_loss: 0.4951 - val_accuracy: 0.8037\n",
      "Epoch 59/100\n",
      "380/380 [==============================] - 0s 123us/step - loss: 0.2764 - accuracy: 0.9026 - val_loss: 0.4766 - val_accuracy: 0.7791\n",
      "Epoch 60/100\n",
      "380/380 [==============================] - 0s 112us/step - loss: 0.2723 - accuracy: 0.8658 - val_loss: 0.4632 - val_accuracy: 0.7791\n",
      "Epoch 61/100\n",
      "380/380 [==============================] - 0s 116us/step - loss: 0.2678 - accuracy: 0.8895 - val_loss: 0.4743 - val_accuracy: 0.8098\n",
      "Epoch 62/100\n",
      "380/380 [==============================] - 0s 171us/step - loss: 0.2639 - accuracy: 0.8868 - val_loss: 0.5162 - val_accuracy: 0.7730\n",
      "Epoch 63/100\n",
      "380/380 [==============================] - 0s 170us/step - loss: 0.2671 - accuracy: 0.8789 - val_loss: 0.5445 - val_accuracy: 0.7791\n",
      "Epoch 64/100\n",
      "380/380 [==============================] - 0s 153us/step - loss: 0.2706 - accuracy: 0.8921 - val_loss: 0.4849 - val_accuracy: 0.7914\n",
      "Epoch 65/100\n",
      "380/380 [==============================] - 0s 130us/step - loss: 0.2539 - accuracy: 0.8947 - val_loss: 0.4684 - val_accuracy: 0.8282\n",
      "Epoch 66/100\n",
      "380/380 [==============================] - 0s 116us/step - loss: 0.2723 - accuracy: 0.8816 - val_loss: 0.4850 - val_accuracy: 0.7546\n",
      "Epoch 67/100\n",
      "380/380 [==============================] - 0s 128us/step - loss: 0.2650 - accuracy: 0.8895 - val_loss: 0.4668 - val_accuracy: 0.7730\n",
      "Epoch 68/100\n",
      "380/380 [==============================] - 0s 159us/step - loss: 0.2875 - accuracy: 0.8789 - val_loss: 0.5222 - val_accuracy: 0.7607\n",
      "Epoch 69/100\n",
      "380/380 [==============================] - 0s 170us/step - loss: 0.2604 - accuracy: 0.8921 - val_loss: 0.4663 - val_accuracy: 0.7791\n",
      "Epoch 70/100\n",
      "380/380 [==============================] - 0s 162us/step - loss: 0.2689 - accuracy: 0.8737 - val_loss: 0.4467 - val_accuracy: 0.8160\n",
      "Epoch 71/100\n",
      "380/380 [==============================] - 0s 123us/step - loss: 0.2635 - accuracy: 0.8711 - val_loss: 0.4622 - val_accuracy: 0.8098\n",
      "Epoch 72/100\n",
      "380/380 [==============================] - 0s 111us/step - loss: 0.2449 - accuracy: 0.9053 - val_loss: 0.4543 - val_accuracy: 0.7975\n",
      "Epoch 73/100\n",
      "380/380 [==============================] - 0s 110us/step - loss: 0.2586 - accuracy: 0.9053 - val_loss: 0.5184 - val_accuracy: 0.7301\n",
      "Epoch 74/100\n",
      "380/380 [==============================] - 0s 116us/step - loss: 0.2680 - accuracy: 0.9026 - val_loss: 0.4525 - val_accuracy: 0.7853\n",
      "Epoch 75/100\n",
      "380/380 [==============================] - 0s 102us/step - loss: 0.2528 - accuracy: 0.8921 - val_loss: 0.4948 - val_accuracy: 0.7914\n",
      "Epoch 76/100\n",
      "380/380 [==============================] - 0s 113us/step - loss: 0.2605 - accuracy: 0.9079 - val_loss: 0.4336 - val_accuracy: 0.8098\n",
      "Epoch 77/100\n",
      "380/380 [==============================] - 0s 105us/step - loss: 0.2365 - accuracy: 0.9000 - val_loss: 0.4783 - val_accuracy: 0.8037\n",
      "Epoch 78/100\n",
      "380/380 [==============================] - 0s 124us/step - loss: 0.2375 - accuracy: 0.9105 - val_loss: 0.4377 - val_accuracy: 0.8098\n",
      "Epoch 79/100\n",
      "380/380 [==============================] - 0s 106us/step - loss: 0.2354 - accuracy: 0.9026 - val_loss: 0.4652 - val_accuracy: 0.7975\n",
      "Epoch 80/100\n",
      "380/380 [==============================] - 0s 137us/step - loss: 0.2398 - accuracy: 0.8895 - val_loss: 0.5273 - val_accuracy: 0.7791\n",
      "Epoch 81/100\n",
      "380/380 [==============================] - 0s 164us/step - loss: 0.2645 - accuracy: 0.9026 - val_loss: 0.4256 - val_accuracy: 0.8221\n",
      "Epoch 82/100\n",
      "380/380 [==============================] - 0s 111us/step - loss: 0.2391 - accuracy: 0.8947 - val_loss: 0.4724 - val_accuracy: 0.8037\n",
      "Epoch 83/100\n",
      "380/380 [==============================] - 0s 124us/step - loss: 0.2366 - accuracy: 0.8974 - val_loss: 0.4661 - val_accuracy: 0.8098\n",
      "Epoch 84/100\n",
      "380/380 [==============================] - 0s 104us/step - loss: 0.2393 - accuracy: 0.8921 - val_loss: 0.4664 - val_accuracy: 0.8098\n",
      "Epoch 85/100\n",
      "380/380 [==============================] - 0s 148us/step - loss: 0.2214 - accuracy: 0.9289 - val_loss: 0.4438 - val_accuracy: 0.8160\n",
      "Epoch 86/100\n",
      "380/380 [==============================] - 0s 161us/step - loss: 0.2208 - accuracy: 0.9105 - val_loss: 0.5304 - val_accuracy: 0.7914\n",
      "Epoch 87/100\n",
      "380/380 [==============================] - 0s 113us/step - loss: 0.2356 - accuracy: 0.8842 - val_loss: 0.4532 - val_accuracy: 0.8037\n",
      "Epoch 88/100\n",
      "380/380 [==============================] - 0s 125us/step - loss: 0.2457 - accuracy: 0.8921 - val_loss: 0.4509 - val_accuracy: 0.8160\n",
      "Epoch 89/100\n",
      "380/380 [==============================] - 0s 140us/step - loss: 0.2440 - accuracy: 0.8974 - val_loss: 0.4915 - val_accuracy: 0.8098\n",
      "Epoch 90/100\n",
      "380/380 [==============================] - 0s 116us/step - loss: 0.2410 - accuracy: 0.8947 - val_loss: 0.4871 - val_accuracy: 0.7975\n",
      "Epoch 91/100\n",
      "380/380 [==============================] - 0s 120us/step - loss: 0.2495 - accuracy: 0.9105 - val_loss: 0.4749 - val_accuracy: 0.7730\n",
      "Epoch 92/100\n",
      "380/380 [==============================] - 0s 123us/step - loss: 0.2278 - accuracy: 0.9079 - val_loss: 0.4938 - val_accuracy: 0.7975\n",
      "Epoch 93/100\n",
      "380/380 [==============================] - 0s 184us/step - loss: 0.2158 - accuracy: 0.9053 - val_loss: 0.5371 - val_accuracy: 0.7914\n",
      "Epoch 94/100\n",
      "380/380 [==============================] - 0s 143us/step - loss: 0.2648 - accuracy: 0.8737 - val_loss: 0.4787 - val_accuracy: 0.7791\n",
      "Epoch 95/100\n",
      "380/380 [==============================] - 0s 118us/step - loss: 0.2511 - accuracy: 0.8711 - val_loss: 0.4631 - val_accuracy: 0.8098\n",
      "Epoch 96/100\n",
      "380/380 [==============================] - 0s 157us/step - loss: 0.2279 - accuracy: 0.8974 - val_loss: 0.5005 - val_accuracy: 0.7914\n",
      "Epoch 97/100\n",
      "380/380 [==============================] - 0s 168us/step - loss: 0.2213 - accuracy: 0.9079 - val_loss: 0.5617 - val_accuracy: 0.7669\n",
      "Epoch 98/100\n",
      "380/380 [==============================] - 0s 151us/step - loss: 0.2291 - accuracy: 0.9105 - val_loss: 0.5515 - val_accuracy: 0.7791\n",
      "Epoch 99/100\n",
      "380/380 [==============================] - 0s 152us/step - loss: 0.2293 - accuracy: 0.9053 - val_loss: 0.4786 - val_accuracy: 0.7975\n",
      "Epoch 100/100\n",
      "380/380 [==============================] - 0s 119us/step - loss: 0.2102 - accuracy: 0.9211 - val_loss: 0.5000 - val_accuracy: 0.7853\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a427c04e0>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over4.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163/163 [==============================] - 0s 105us/step\n",
      "over-sampling test accuracy: 80.37%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over4 = model1_over4.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over4*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 0, 0, 0, 1, 2, 2, 0, 0, 1, 1, 2, 0, 1, 0, 0, 0, 1, 0, 2, 2,\n",
       "       0, 1, 1, 1, 1, 0, 2, 2, 0, 2, 1, 1, 2, 1, 0, 2, 0, 0, 0, 1, 1, 1,\n",
       "       0, 1, 2, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1,\n",
       "       1, 0, 2, 2, 0, 1, 0, 0, 1, 2, 1, 1, 1, 2, 0, 0, 2, 1, 2, 1, 1, 1,\n",
       "       0, 1, 0, 1, 2, 0, 1, 1, 0, 1, 1, 1, 0, 1, 2, 1, 2, 2, 2, 2, 1, 0,\n",
       "       2, 0, 1, 1, 0, 1, 0, 1, 2, 1, 1, 1, 2, 2, 1, 1, 2, 1, 2, 0, 1, 1,\n",
       "       1, 1, 2, 1, 0, 0, 1, 1, 0, 0, 2, 0, 2, 2, 1, 1, 1, 0, 0, 1, 2, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred4 = model1_over4.predict_classes(X_test_over)\n",
    "pred4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SR2852</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CFBREBSa138</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BCH-SA-12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EUH13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EUH13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>NRS036</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>CA105</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>CFBRSa51</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>NRS102</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>NRS189</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test  pred\n",
       "0         SR2852     2     2\n",
       "1    CFBREBSa138     0     0\n",
       "2      BCH-SA-12     0     0\n",
       "3          EUH13     0     0\n",
       "4          EUH13     0     0\n",
       "..           ...   ...   ...\n",
       "158       NRS036     1     1\n",
       "159        CA105     1     1\n",
       "160     CFBRSa51     1     1\n",
       "161       NRS102     1     1\n",
       "162       NRS189     2     0\n",
       "\n",
       "[163 rows x 3 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat4['pred'] = pred4\n",
    "dat4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba4 = model1_over4.predict_proba(X_test_over)\n",
    "dat_proba4 = pd.DataFrame(proba4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.025301</td>\n",
       "      <td>0.974663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.998706</td>\n",
       "      <td>0.000814</td>\n",
       "      <td>0.000480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.976673</td>\n",
       "      <td>0.004427</td>\n",
       "      <td>0.018900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.919572</td>\n",
       "      <td>0.067330</td>\n",
       "      <td>0.013098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.919572</td>\n",
       "      <td>0.067330</td>\n",
       "      <td>0.013098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.923615</td>\n",
       "      <td>0.075886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.999085</td>\n",
       "      <td>0.000910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>0.000258</td>\n",
       "      <td>0.999683</td>\n",
       "      <td>0.000059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.999135</td>\n",
       "      <td>0.000851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>0.731490</td>\n",
       "      <td>0.001271</td>\n",
       "      <td>0.267239</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2\n",
       "0    0.000036  0.025301  0.974663\n",
       "1    0.998706  0.000814  0.000480\n",
       "2    0.976673  0.004427  0.018900\n",
       "3    0.919572  0.067330  0.013098\n",
       "4    0.919572  0.067330  0.013098\n",
       "..        ...       ...       ...\n",
       "158  0.000499  0.923615  0.075886\n",
       "159  0.000005  0.999085  0.000910\n",
       "160  0.000258  0.999683  0.000059\n",
       "161  0.000014  0.999135  0.000851\n",
       "162  0.731490  0.001271  0.267239\n",
       "\n",
       "[163 rows x 3 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba4.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba4.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat4.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/4p11.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 380 samples, validate on 163 samples\n",
      "Epoch 1/100\n",
      "380/380 [==============================] - 0s 181us/step - loss: 0.2402 - accuracy: 0.8895 - val_loss: 0.5029 - val_accuracy: 0.8282\n",
      "Epoch 2/100\n",
      "380/380 [==============================] - 0s 154us/step - loss: 0.2139 - accuracy: 0.9158 - val_loss: 0.5459 - val_accuracy: 0.8221\n",
      "Epoch 3/100\n",
      "380/380 [==============================] - 0s 149us/step - loss: 0.2117 - accuracy: 0.9132 - val_loss: 0.5106 - val_accuracy: 0.8160\n",
      "Epoch 4/100\n",
      "380/380 [==============================] - 0s 122us/step - loss: 0.2173 - accuracy: 0.8947 - val_loss: 0.4998 - val_accuracy: 0.7914\n",
      "Epoch 5/100\n",
      "380/380 [==============================] - 0s 120us/step - loss: 0.2538 - accuracy: 0.8684 - val_loss: 0.4831 - val_accuracy: 0.8037\n",
      "Epoch 6/100\n",
      "380/380 [==============================] - 0s 123us/step - loss: 0.2280 - accuracy: 0.9184 - val_loss: 0.4708 - val_accuracy: 0.8344\n",
      "Epoch 7/100\n",
      "380/380 [==============================] - 0s 121us/step - loss: 0.3265 - accuracy: 0.8500 - val_loss: 0.6976 - val_accuracy: 0.7607\n",
      "Epoch 8/100\n",
      "380/380 [==============================] - 0s 137us/step - loss: 0.3319 - accuracy: 0.8684 - val_loss: 0.5022 - val_accuracy: 0.8098\n",
      "Epoch 9/100\n",
      "380/380 [==============================] - 0s 133us/step - loss: 0.3102 - accuracy: 0.8421 - val_loss: 0.7722 - val_accuracy: 0.7791\n",
      "Epoch 10/100\n",
      "380/380 [==============================] - 0s 127us/step - loss: 0.2765 - accuracy: 0.8947 - val_loss: 0.5383 - val_accuracy: 0.8037\n",
      "Epoch 11/100\n",
      "380/380 [==============================] - 0s 120us/step - loss: 0.2343 - accuracy: 0.8816 - val_loss: 0.5457 - val_accuracy: 0.8160\n",
      "Epoch 12/100\n",
      "380/380 [==============================] - 0s 124us/step - loss: 0.2140 - accuracy: 0.9105 - val_loss: 0.5140 - val_accuracy: 0.8528\n",
      "Epoch 13/100\n",
      "380/380 [==============================] - 0s 118us/step - loss: 0.2198 - accuracy: 0.8947 - val_loss: 0.5948 - val_accuracy: 0.7914\n",
      "Epoch 14/100\n",
      "380/380 [==============================] - 0s 114us/step - loss: 0.2305 - accuracy: 0.8921 - val_loss: 0.6129 - val_accuracy: 0.7914\n",
      "Epoch 15/100\n",
      "380/380 [==============================] - 0s 142us/step - loss: 0.2385 - accuracy: 0.8947 - val_loss: 0.5878 - val_accuracy: 0.7669\n",
      "Epoch 16/100\n",
      "380/380 [==============================] - 0s 139us/step - loss: 0.2348 - accuracy: 0.9132 - val_loss: 0.5280 - val_accuracy: 0.8282\n",
      "Epoch 17/100\n",
      "380/380 [==============================] - 0s 218us/step - loss: 0.2081 - accuracy: 0.9105 - val_loss: 0.4851 - val_accuracy: 0.8282\n",
      "Epoch 18/100\n",
      "380/380 [==============================] - 0s 241us/step - loss: 0.2217 - accuracy: 0.8974 - val_loss: 0.5202 - val_accuracy: 0.8344\n",
      "Epoch 19/100\n",
      "380/380 [==============================] - 0s 174us/step - loss: 0.2124 - accuracy: 0.9079 - val_loss: 0.5095 - val_accuracy: 0.8282\n",
      "Epoch 20/100\n",
      "380/380 [==============================] - 0s 138us/step - loss: 0.2335 - accuracy: 0.8974 - val_loss: 0.5499 - val_accuracy: 0.7975\n",
      "Epoch 21/100\n",
      "380/380 [==============================] - 0s 139us/step - loss: 0.2238 - accuracy: 0.9105 - val_loss: 0.4732 - val_accuracy: 0.8344\n",
      "Epoch 22/100\n",
      "380/380 [==============================] - 0s 144us/step - loss: 0.1943 - accuracy: 0.9184 - val_loss: 0.4979 - val_accuracy: 0.8160\n",
      "Epoch 23/100\n",
      "380/380 [==============================] - 0s 162us/step - loss: 0.1990 - accuracy: 0.9158 - val_loss: 0.5026 - val_accuracy: 0.8466\n",
      "Epoch 24/100\n",
      "380/380 [==============================] - 0s 150us/step - loss: 0.1928 - accuracy: 0.9237 - val_loss: 0.5012 - val_accuracy: 0.8098\n",
      "Epoch 25/100\n",
      "380/380 [==============================] - 0s 187us/step - loss: 0.2030 - accuracy: 0.9053 - val_loss: 0.6025 - val_accuracy: 0.7607\n",
      "Epoch 26/100\n",
      "380/380 [==============================] - 0s 181us/step - loss: 0.2085 - accuracy: 0.9053 - val_loss: 0.4707 - val_accuracy: 0.8466\n",
      "Epoch 27/100\n",
      "380/380 [==============================] - 0s 163us/step - loss: 0.2270 - accuracy: 0.8947 - val_loss: 0.5575 - val_accuracy: 0.8344\n",
      "Epoch 28/100\n",
      "380/380 [==============================] - 0s 159us/step - loss: 0.2030 - accuracy: 0.9026 - val_loss: 0.5574 - val_accuracy: 0.8098\n",
      "Epoch 29/100\n",
      "380/380 [==============================] - 0s 166us/step - loss: 0.2198 - accuracy: 0.9053 - val_loss: 0.5533 - val_accuracy: 0.7853\n",
      "Epoch 30/100\n",
      "380/380 [==============================] - 0s 154us/step - loss: 0.2241 - accuracy: 0.9053 - val_loss: 0.5459 - val_accuracy: 0.7914\n",
      "Epoch 31/100\n",
      "380/380 [==============================] - 0s 159us/step - loss: 0.2245 - accuracy: 0.8842 - val_loss: 0.6757 - val_accuracy: 0.7485\n",
      "Epoch 32/100\n",
      "380/380 [==============================] - 0s 168us/step - loss: 0.2942 - accuracy: 0.8789 - val_loss: 0.5768 - val_accuracy: 0.7669\n",
      "Epoch 33/100\n",
      "380/380 [==============================] - 0s 189us/step - loss: 0.2199 - accuracy: 0.9158 - val_loss: 0.5479 - val_accuracy: 0.7975\n",
      "Epoch 34/100\n",
      "380/380 [==============================] - 0s 182us/step - loss: 0.2418 - accuracy: 0.8947 - val_loss: 0.4877 - val_accuracy: 0.8282\n",
      "Epoch 35/100\n",
      "380/380 [==============================] - 0s 204us/step - loss: 0.2272 - accuracy: 0.8947 - val_loss: 0.5657 - val_accuracy: 0.7975\n",
      "Epoch 36/100\n",
      "380/380 [==============================] - 0s 209us/step - loss: 0.2008 - accuracy: 0.9211 - val_loss: 0.5116 - val_accuracy: 0.8405\n",
      "Epoch 37/100\n",
      "380/380 [==============================] - 0s 227us/step - loss: 0.2021 - accuracy: 0.9132 - val_loss: 0.5126 - val_accuracy: 0.8466\n",
      "Epoch 38/100\n",
      "380/380 [==============================] - 0s 181us/step - loss: 0.2114 - accuracy: 0.9053 - val_loss: 0.5297 - val_accuracy: 0.8160\n",
      "Epoch 39/100\n",
      "380/380 [==============================] - 0s 144us/step - loss: 0.1943 - accuracy: 0.9184 - val_loss: 0.4993 - val_accuracy: 0.8282\n",
      "Epoch 40/100\n",
      "380/380 [==============================] - 0s 148us/step - loss: 0.1867 - accuracy: 0.9316 - val_loss: 0.5151 - val_accuracy: 0.8466\n",
      "Epoch 41/100\n",
      "380/380 [==============================] - 0s 124us/step - loss: 0.1866 - accuracy: 0.9237 - val_loss: 0.4892 - val_accuracy: 0.8405\n",
      "Epoch 42/100\n",
      "380/380 [==============================] - 0s 142us/step - loss: 0.2071 - accuracy: 0.9000 - val_loss: 0.5287 - val_accuracy: 0.8282\n",
      "Epoch 43/100\n",
      "380/380 [==============================] - 0s 176us/step - loss: 0.1838 - accuracy: 0.9184 - val_loss: 0.5077 - val_accuracy: 0.8221\n",
      "Epoch 44/100\n",
      "380/380 [==============================] - 0s 155us/step - loss: 0.1938 - accuracy: 0.9184 - val_loss: 0.5728 - val_accuracy: 0.8221\n",
      "Epoch 45/100\n",
      "380/380 [==============================] - 0s 128us/step - loss: 0.1885 - accuracy: 0.9289 - val_loss: 0.4960 - val_accuracy: 0.8405\n",
      "Epoch 46/100\n",
      "380/380 [==============================] - 0s 148us/step - loss: 0.2209 - accuracy: 0.9000 - val_loss: 0.5361 - val_accuracy: 0.8405\n",
      "Epoch 47/100\n",
      "380/380 [==============================] - 0s 203us/step - loss: 0.2011 - accuracy: 0.9158 - val_loss: 0.4890 - val_accuracy: 0.7975\n",
      "Epoch 48/100\n",
      "380/380 [==============================] - 0s 198us/step - loss: 0.2018 - accuracy: 0.9184 - val_loss: 0.4699 - val_accuracy: 0.8344\n",
      "Epoch 49/100\n",
      "380/380 [==============================] - 0s 179us/step - loss: 0.2140 - accuracy: 0.9132 - val_loss: 0.4866 - val_accuracy: 0.7975\n",
      "Epoch 50/100\n",
      "380/380 [==============================] - 0s 213us/step - loss: 0.1953 - accuracy: 0.9132 - val_loss: 0.5370 - val_accuracy: 0.7607\n",
      "Epoch 51/100\n",
      "380/380 [==============================] - 0s 188us/step - loss: 0.2475 - accuracy: 0.8842 - val_loss: 0.5504 - val_accuracy: 0.7914\n",
      "Epoch 52/100\n",
      "380/380 [==============================] - 0s 169us/step - loss: 0.2453 - accuracy: 0.8895 - val_loss: 0.5474 - val_accuracy: 0.8160\n",
      "Epoch 53/100\n",
      "380/380 [==============================] - 0s 177us/step - loss: 0.2790 - accuracy: 0.8921 - val_loss: 0.4940 - val_accuracy: 0.8344\n",
      "Epoch 54/100\n",
      "380/380 [==============================] - 0s 179us/step - loss: 0.1954 - accuracy: 0.9263 - val_loss: 0.5052 - val_accuracy: 0.8221\n",
      "Epoch 55/100\n",
      "380/380 [==============================] - 0s 182us/step - loss: 0.1875 - accuracy: 0.9211 - val_loss: 0.5057 - val_accuracy: 0.8344\n",
      "Epoch 56/100\n",
      "380/380 [==============================] - 0s 178us/step - loss: 0.1955 - accuracy: 0.9211 - val_loss: 0.5196 - val_accuracy: 0.8098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "380/380 [==============================] - 0s 177us/step - loss: 0.2011 - accuracy: 0.9158 - val_loss: 0.5217 - val_accuracy: 0.7975\n",
      "Epoch 58/100\n",
      "380/380 [==============================] - 0s 185us/step - loss: 0.2038 - accuracy: 0.9105 - val_loss: 0.5321 - val_accuracy: 0.8037\n",
      "Epoch 59/100\n",
      "380/380 [==============================] - 0s 167us/step - loss: 0.2410 - accuracy: 0.8842 - val_loss: 0.5548 - val_accuracy: 0.8160\n",
      "Epoch 60/100\n",
      "380/380 [==============================] - 0s 189us/step - loss: 0.1935 - accuracy: 0.9237 - val_loss: 0.5489 - val_accuracy: 0.8282\n",
      "Epoch 61/100\n",
      "380/380 [==============================] - 0s 181us/step - loss: 0.1891 - accuracy: 0.9184 - val_loss: 0.5409 - val_accuracy: 0.8098\n",
      "Epoch 62/100\n",
      "380/380 [==============================] - 0s 220us/step - loss: 0.1942 - accuracy: 0.9158 - val_loss: 0.5760 - val_accuracy: 0.8098\n",
      "Epoch 63/100\n",
      "380/380 [==============================] - 0s 192us/step - loss: 0.1969 - accuracy: 0.9000 - val_loss: 0.5637 - val_accuracy: 0.8098\n",
      "Epoch 64/100\n",
      "380/380 [==============================] - 0s 178us/step - loss: 0.1990 - accuracy: 0.9000 - val_loss: 0.5707 - val_accuracy: 0.8037\n",
      "Epoch 65/100\n",
      "380/380 [==============================] - 0s 169us/step - loss: 0.1988 - accuracy: 0.9263 - val_loss: 0.5668 - val_accuracy: 0.8098\n",
      "Epoch 66/100\n",
      "380/380 [==============================] - 0s 159us/step - loss: 0.2009 - accuracy: 0.9132 - val_loss: 0.5379 - val_accuracy: 0.8221\n",
      "Epoch 67/100\n",
      "380/380 [==============================] - 0s 155us/step - loss: 0.2015 - accuracy: 0.9026 - val_loss: 0.5188 - val_accuracy: 0.8466\n",
      "Epoch 68/100\n",
      "380/380 [==============================] - 0s 181us/step - loss: 0.1910 - accuracy: 0.9132 - val_loss: 0.5172 - val_accuracy: 0.8466\n",
      "Epoch 69/100\n",
      "380/380 [==============================] - 0s 172us/step - loss: 0.2068 - accuracy: 0.8947 - val_loss: 0.6009 - val_accuracy: 0.7914\n",
      "Epoch 70/100\n",
      "380/380 [==============================] - 0s 158us/step - loss: 0.2095 - accuracy: 0.9053 - val_loss: 0.5351 - val_accuracy: 0.8160\n",
      "Epoch 71/100\n",
      "380/380 [==============================] - 0s 171us/step - loss: 0.1938 - accuracy: 0.9316 - val_loss: 0.5029 - val_accuracy: 0.8282\n",
      "Epoch 72/100\n",
      "380/380 [==============================] - 0s 175us/step - loss: 0.1760 - accuracy: 0.9289 - val_loss: 0.5583 - val_accuracy: 0.8221\n",
      "Epoch 73/100\n",
      "380/380 [==============================] - 0s 155us/step - loss: 0.1778 - accuracy: 0.9263 - val_loss: 0.5274 - val_accuracy: 0.8221\n",
      "Epoch 74/100\n",
      "380/380 [==============================] - 0s 152us/step - loss: 0.1894 - accuracy: 0.9184 - val_loss: 0.5621 - val_accuracy: 0.7914\n",
      "Epoch 75/100\n",
      "380/380 [==============================] - 0s 153us/step - loss: 0.2586 - accuracy: 0.9000 - val_loss: 0.7663 - val_accuracy: 0.7239\n",
      "Epoch 76/100\n",
      "380/380 [==============================] - 0s 145us/step - loss: 0.2604 - accuracy: 0.9053 - val_loss: 0.6008 - val_accuracy: 0.8037\n",
      "Epoch 77/100\n",
      "380/380 [==============================] - 0s 138us/step - loss: 0.2520 - accuracy: 0.9000 - val_loss: 0.5609 - val_accuracy: 0.8037\n",
      "Epoch 78/100\n",
      "380/380 [==============================] - 0s 206us/step - loss: 0.2529 - accuracy: 0.8947 - val_loss: 0.6189 - val_accuracy: 0.8282\n",
      "Epoch 79/100\n",
      "380/380 [==============================] - 0s 325us/step - loss: 0.1924 - accuracy: 0.9237 - val_loss: 0.4651 - val_accuracy: 0.8589\n",
      "Epoch 80/100\n",
      "380/380 [==============================] - 0s 164us/step - loss: 0.1978 - accuracy: 0.9158 - val_loss: 0.5422 - val_accuracy: 0.8037\n",
      "Epoch 81/100\n",
      "380/380 [==============================] - 0s 153us/step - loss: 0.1977 - accuracy: 0.9158 - val_loss: 0.5532 - val_accuracy: 0.8098\n",
      "Epoch 82/100\n",
      "380/380 [==============================] - 0s 168us/step - loss: 0.1858 - accuracy: 0.9158 - val_loss: 0.5101 - val_accuracy: 0.8405\n",
      "Epoch 83/100\n",
      "380/380 [==============================] - 0s 181us/step - loss: 0.1915 - accuracy: 0.9211 - val_loss: 0.5422 - val_accuracy: 0.8405\n",
      "Epoch 84/100\n",
      "380/380 [==============================] - 0s 219us/step - loss: 0.1808 - accuracy: 0.9263 - val_loss: 0.5154 - val_accuracy: 0.8466\n",
      "Epoch 85/100\n",
      "380/380 [==============================] - 0s 183us/step - loss: 0.1883 - accuracy: 0.9316 - val_loss: 0.4979 - val_accuracy: 0.8466\n",
      "Epoch 86/100\n",
      "380/380 [==============================] - 0s 789us/step - loss: 0.1836 - accuracy: 0.9237 - val_loss: 0.5379 - val_accuracy: 0.8405\n",
      "Epoch 87/100\n",
      "380/380 [==============================] - 0s 189us/step - loss: 0.1707 - accuracy: 0.9263 - val_loss: 0.5412 - val_accuracy: 0.8405\n",
      "Epoch 88/100\n",
      "380/380 [==============================] - 0s 274us/step - loss: 0.1892 - accuracy: 0.9158 - val_loss: 0.5816 - val_accuracy: 0.8098\n",
      "Epoch 89/100\n",
      "380/380 [==============================] - 0s 167us/step - loss: 0.1825 - accuracy: 0.9211 - val_loss: 0.5197 - val_accuracy: 0.8528\n",
      "Epoch 90/100\n",
      "380/380 [==============================] - 0s 424us/step - loss: 0.1769 - accuracy: 0.9237 - val_loss: 0.5486 - val_accuracy: 0.8405\n",
      "Epoch 91/100\n",
      "380/380 [==============================] - 0s 318us/step - loss: 0.2340 - accuracy: 0.9079 - val_loss: 0.5253 - val_accuracy: 0.8344\n",
      "Epoch 92/100\n",
      "380/380 [==============================] - 0s 159us/step - loss: 0.2152 - accuracy: 0.9158 - val_loss: 0.5591 - val_accuracy: 0.8037\n",
      "Epoch 93/100\n",
      "380/380 [==============================] - 0s 155us/step - loss: 0.2121 - accuracy: 0.9105 - val_loss: 0.5188 - val_accuracy: 0.8466\n",
      "Epoch 94/100\n",
      "380/380 [==============================] - 0s 157us/step - loss: 0.2143 - accuracy: 0.9184 - val_loss: 0.5296 - val_accuracy: 0.8466\n",
      "Epoch 95/100\n",
      "380/380 [==============================] - 0s 146us/step - loss: 0.2348 - accuracy: 0.9026 - val_loss: 0.5230 - val_accuracy: 0.8282\n",
      "Epoch 96/100\n",
      "380/380 [==============================] - 0s 146us/step - loss: 0.1873 - accuracy: 0.9184 - val_loss: 0.5282 - val_accuracy: 0.8405\n",
      "Epoch 97/100\n",
      "380/380 [==============================] - 0s 141us/step - loss: 0.1802 - accuracy: 0.9158 - val_loss: 0.5211 - val_accuracy: 0.8344\n",
      "Epoch 98/100\n",
      "380/380 [==============================] - 0s 135us/step - loss: 0.1948 - accuracy: 0.9105 - val_loss: 0.5574 - val_accuracy: 0.8221\n",
      "Epoch 99/100\n",
      "380/380 [==============================] - 0s 139us/step - loss: 0.2069 - accuracy: 0.9053 - val_loss: 0.5672 - val_accuracy: 0.8221\n",
      "Epoch 100/100\n",
      "380/380 [==============================] - 0s 143us/step - loss: 0.2102 - accuracy: 0.9000 - val_loss: 0.5174 - val_accuracy: 0.8528\n"
     ]
    }
   ],
   "source": [
    "hist1_over4 = model1_over4.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 90.78%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over4.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba4 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_2.xlsx\",\n",
    "                        sheet_name=3,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS110</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>5.870196e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS216</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.039254</td>\n",
       "      <td>0.960745</td>\n",
       "      <td>9.078969e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS386</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.326752</td>\n",
       "      <td>0.673248</td>\n",
       "      <td>1.061032e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>CFBRSa25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.611084</td>\n",
       "      <td>0.388916</td>\n",
       "      <td>7.664974e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>BCH-SA-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.611084</td>\n",
       "      <td>0.388916</td>\n",
       "      <td>7.664974e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4279</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS236</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.999768</td>\n",
       "      <td>1.803156e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4280</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS029</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.322350</td>\n",
       "      <td>0.677496</td>\n",
       "      <td>1.533154e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4281</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>9.999682e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4282</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>CFBRSa28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999288</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>5.361527e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4283</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS205</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>9.999868e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4284 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    phage     strain  phenotype  prediction         0  \\\n",
       "0      p002ykpresabs_qual     NRS110          1           1  0.000003   \n",
       "1      p002ykpresabs_qual     NRS216          1           1  0.039254   \n",
       "2      p002ykpresabs_qual     NRS386          1           1  0.326752   \n",
       "3      p002ykpresabs_qual   CFBRSa25          0           0  0.611084   \n",
       "4      p002ykpresabs_qual  BCH-SA-03          1           0  0.611084   \n",
       "...                   ...        ...        ...         ...       ...   \n",
       "4279  pyopresabsSTCC_qual     NRS236          1           1  0.000052   \n",
       "4280  pyopresabsSTCC_qual     NRS029          0           1  0.322350   \n",
       "4281  pyopresabsSTCC_qual     NRS148          2           2  0.000006   \n",
       "4282  pyopresabsSTCC_qual   CFBRSa28          0           0  0.999288   \n",
       "4283  pyopresabsSTCC_qual     NRS205          2           2  0.000007   \n",
       "\n",
       "             1             2  \n",
       "0     0.999997  5.870196e-13  \n",
       "1     0.960745  9.078969e-07  \n",
       "2     0.673248  1.061032e-07  \n",
       "3     0.388916  7.664974e-07  \n",
       "4     0.388916  7.664974e-07  \n",
       "...        ...           ...  \n",
       "4279  0.999768  1.803156e-04  \n",
       "4280  0.677496  1.533154e-04  \n",
       "4281  0.000026  9.999682e-01  \n",
       "4282  0.000176  5.361527e-04  \n",
       "4283  0.000007  9.999868e-01  \n",
       "\n",
       "[4284 rows x 7 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.5529585e-05, 2.5301340e-02, 9.7466314e-01],\n",
       "       [9.9870634e-01, 8.1354770e-04, 4.8010462e-04],\n",
       "       [9.7667330e-01, 4.4271164e-03, 1.8899648e-02],\n",
       "       [9.1957180e-01, 6.7330010e-02, 1.3098269e-02],\n",
       "       [9.1957180e-01, 6.7330010e-02, 1.3098269e-02],\n",
       "       [9.3829454e-05, 9.7523670e-01, 2.4669446e-02],\n",
       "       [2.2173378e-01, 1.8028943e-01, 5.9797674e-01],\n",
       "       [1.0273278e-05, 2.1151037e-04, 9.9977820e-01],\n",
       "       [7.4110700e-01, 2.3698530e-01, 2.1907752e-02],\n",
       "       [9.9330360e-01, 5.6237000e-03, 1.0727432e-03],\n",
       "       [7.6339087e-03, 9.1458905e-01, 7.7777030e-02],\n",
       "       [2.9734123e-01, 6.2499960e-01, 7.7659205e-02],\n",
       "       [5.3477073e-03, 8.6433790e-02, 9.0821856e-01],\n",
       "       [7.4110700e-01, 2.3698530e-01, 2.1907752e-02],\n",
       "       [1.7836774e-03, 5.4667970e-01, 4.5153670e-01],\n",
       "       [9.8375630e-01, 7.4541410e-05, 1.6169135e-02],\n",
       "       [7.4110700e-01, 2.3698530e-01, 2.1907752e-02],\n",
       "       [9.9914120e-01, 8.0202933e-04, 5.6638106e-05],\n",
       "       [4.0357750e-03, 6.1026730e-01, 3.8569700e-01],\n",
       "       [9.1957180e-01, 6.7330010e-02, 1.3098269e-02],\n",
       "       [2.8664965e-04, 2.8518908e-02, 9.7119440e-01],\n",
       "       [8.6095160e-02, 4.1675827e-01, 4.9714655e-01],\n",
       "       [9.9330360e-01, 5.6237000e-03, 1.0727432e-03],\n",
       "       [3.4296037e-05, 8.4096694e-01, 1.5899877e-01],\n",
       "       [2.3280002e-02, 8.6697480e-01, 1.0974518e-01],\n",
       "       [4.4060294e-02, 7.2424180e-01, 2.3169790e-01],\n",
       "       [2.8613592e-02, 9.7062826e-01, 7.5811456e-04],\n",
       "       [9.9330360e-01, 5.6237000e-03, 1.0727432e-03],\n",
       "       [3.1836852e-02, 1.6557788e-02, 9.5160540e-01],\n",
       "       [2.2173378e-01, 1.8028943e-01, 5.9797674e-01],\n",
       "       [9.9971825e-01, 7.8479960e-06, 2.7388398e-04],\n",
       "       [2.8285360e-04, 1.7142922e-02, 9.8257430e-01],\n",
       "       [6.7624927e-04, 6.9033235e-01, 3.0899146e-01],\n",
       "       [2.7524224e-03, 9.9714760e-01, 9.9962310e-05],\n",
       "       [5.3686860e-03, 2.4416596e-02, 9.7021466e-01],\n",
       "       [2.9734123e-01, 6.2499960e-01, 7.7659205e-02],\n",
       "       [9.9955004e-01, 3.3794495e-04, 1.1206498e-04],\n",
       "       [1.4619781e-04, 6.3886430e-03, 9.9346510e-01],\n",
       "       [9.9870634e-01, 8.1354770e-04, 4.8010462e-04],\n",
       "       [9.9446940e-01, 3.8145322e-04, 5.1491160e-03],\n",
       "       [9.8375630e-01, 7.4541410e-05, 1.6169135e-02],\n",
       "       [2.5810255e-04, 9.9968255e-01, 5.9328097e-05],\n",
       "       [1.2656836e-03, 9.9873060e-01, 3.6859494e-06],\n",
       "       [5.9898810e-04, 9.9907553e-01, 3.2546360e-04],\n",
       "       [9.8950960e-01, 3.5091832e-03, 6.9812370e-03],\n",
       "       [1.8682673e-03, 9.9530953e-01, 2.8222576e-03],\n",
       "       [3.3459590e-02, 3.9952000e-01, 5.6702040e-01],\n",
       "       [9.7667330e-01, 4.4271164e-03, 1.8899648e-02],\n",
       "       [9.9446940e-01, 3.8145322e-04, 5.1491160e-03],\n",
       "       [9.9955004e-01, 3.3794495e-04, 1.1206498e-04],\n",
       "       [1.4184709e-05, 9.9913470e-01, 8.5112115e-04],\n",
       "       [7.0935505e-07, 9.9926320e-01, 7.3602740e-04],\n",
       "       [1.8682673e-03, 9.9530953e-01, 2.8222576e-03],\n",
       "       [4.4060294e-02, 7.2424180e-01, 2.3169790e-01],\n",
       "       [5.2651465e-01, 1.8143464e-02, 4.5534194e-01],\n",
       "       [2.8517442e-02, 6.4737080e-01, 3.2411180e-01],\n",
       "       [3.8255658e-04, 8.4447920e-01, 1.5513822e-01],\n",
       "       [7.4882914e-06, 9.3594070e-01, 6.4051810e-02],\n",
       "       [6.6013390e-05, 9.9947685e-01, 4.5713235e-04],\n",
       "       [9.9330360e-01, 5.6237000e-03, 1.0727432e-03],\n",
       "       [1.9745205e-02, 7.5083613e-01, 2.2941867e-01],\n",
       "       [5.9569600e-03, 9.9225545e-01, 1.7875754e-03],\n",
       "       [9.9446940e-01, 3.8145322e-04, 5.1491160e-03],\n",
       "       [1.8906687e-06, 5.9116040e-01, 4.0883768e-01],\n",
       "       [1.0673555e-02, 5.7162710e-01, 4.1769940e-01],\n",
       "       [4.1306932e-05, 8.8951700e-01, 1.1044161e-01],\n",
       "       [1.9745205e-02, 7.5083613e-01, 2.2941867e-01],\n",
       "       [9.9914120e-01, 8.0202933e-04, 5.6638106e-05],\n",
       "       [1.9537656e-02, 2.1506330e-01, 7.6539904e-01],\n",
       "       [2.2536068e-01, 3.1304610e-01, 4.6159320e-01],\n",
       "       [9.1957180e-01, 6.7330010e-02, 1.3098269e-02],\n",
       "       [2.5810255e-04, 9.9968255e-01, 5.9328097e-05],\n",
       "       [8.0764480e-01, 3.0155700e-04, 1.9205368e-01],\n",
       "       [9.7348950e-01, 7.4047415e-04, 2.5769982e-02],\n",
       "       [1.2466652e-04, 6.2853765e-01, 3.7133770e-01],\n",
       "       [5.2204905e-03, 1.1047862e-01, 8.8430090e-01],\n",
       "       [2.9734123e-01, 6.2499960e-01, 7.7659205e-02],\n",
       "       [4.1306932e-05, 8.8951700e-01, 1.1044161e-01],\n",
       "       [2.8140292e-02, 5.0235033e-01, 4.6950933e-01],\n",
       "       [2.7880400e-08, 1.9290490e-06, 9.9999810e-01],\n",
       "       [9.7348950e-01, 7.4047415e-04, 2.5769982e-02],\n",
       "       [8.0764480e-01, 3.0155700e-04, 1.9205368e-01],\n",
       "       [6.4268380e-05, 3.3224854e-04, 9.9960345e-01],\n",
       "       [1.4184709e-05, 9.9913470e-01, 8.5112115e-04],\n",
       "       [3.1921060e-02, 6.1255520e-05, 9.6801770e-01],\n",
       "       [4.4060294e-02, 7.2424180e-01, 2.3169790e-01],\n",
       "       [2.9734123e-01, 6.2499960e-01, 7.7659205e-02],\n",
       "       [4.4060294e-02, 7.2424180e-01, 2.3169790e-01],\n",
       "       [9.9543120e-01, 4.5676300e-03, 1.1564625e-06],\n",
       "       [2.9734123e-01, 6.2499960e-01, 7.7659205e-02],\n",
       "       [9.9728394e-01, 2.2457994e-03, 4.7035248e-04],\n",
       "       [7.4882914e-06, 9.3594070e-01, 6.4051810e-02],\n",
       "       [1.4626524e-01, 3.6668047e-01, 4.8705430e-01],\n",
       "       [8.0764480e-01, 3.0155700e-04, 1.9205368e-01],\n",
       "       [7.6339087e-03, 9.1458905e-01, 7.7777030e-02],\n",
       "       [2.5810255e-04, 9.9968255e-01, 5.9328097e-05],\n",
       "       [9.9543120e-01, 4.5676300e-03, 1.1564625e-06],\n",
       "       [2.7524224e-03, 9.9714760e-01, 9.9962310e-05],\n",
       "       [2.9734123e-01, 6.2499960e-01, 7.7659205e-02],\n",
       "       [4.4060294e-02, 7.2424180e-01, 2.3169790e-01],\n",
       "       [9.3184020e-01, 1.3914547e-02, 5.4245345e-02],\n",
       "       [2.9734123e-01, 6.2499960e-01, 7.7659205e-02],\n",
       "       [1.2881686e-06, 2.6850905e-03, 9.9731356e-01],\n",
       "       [7.6339087e-03, 9.1458905e-01, 7.7777030e-02],\n",
       "       [1.4260601e-03, 8.3112806e-02, 9.1546106e-01],\n",
       "       [2.0740498e-02, 1.8838875e-05, 9.7924060e-01],\n",
       "       [1.4626524e-01, 3.6668047e-01, 4.8705430e-01],\n",
       "       [4.8177462e-06, 6.6966255e-05, 9.9992824e-01],\n",
       "       [7.6339087e-03, 9.1458905e-01, 7.7777030e-02],\n",
       "       [9.9244785e-01, 5.6997870e-03, 1.8523391e-03],\n",
       "       [8.2320970e-03, 2.5067277e-02, 9.6670070e-01],\n",
       "       [9.9330360e-01, 5.6237000e-03, 1.0727432e-03],\n",
       "       [5.9898810e-04, 9.9907553e-01, 3.2546360e-04],\n",
       "       [2.9734123e-01, 6.2499960e-01, 7.7659205e-02],\n",
       "       [9.8375630e-01, 7.4541410e-05, 1.6169135e-02],\n",
       "       [2.9734123e-01, 6.2499960e-01, 7.7659205e-02],\n",
       "       [9.9446940e-01, 3.8145322e-04, 5.1491160e-03],\n",
       "       [1.5391587e-04, 9.9334730e-01, 6.4988527e-03],\n",
       "       [3.2254476e-07, 4.2153795e-05, 9.9995756e-01],\n",
       "       [1.4989587e-05, 9.9854240e-01, 1.4426459e-03],\n",
       "       [3.0402615e-04, 9.9574950e-01, 3.9464820e-03],\n",
       "       [4.9894943e-04, 8.9277020e-01, 1.0673093e-01],\n",
       "       [7.3762412e-06, 2.9835217e-03, 9.9700910e-01],\n",
       "       [7.1278060e-07, 4.2781403e-04, 9.9957150e-01],\n",
       "       [7.6339087e-03, 9.1458905e-01, 7.7777030e-02],\n",
       "       [7.2098610e-06, 9.9819190e-01, 1.8008057e-03],\n",
       "       [2.4803590e-02, 3.5625917e-01, 6.1893725e-01],\n",
       "       [5.9898810e-04, 9.9907553e-01, 3.2546360e-04],\n",
       "       [1.5763160e-05, 7.5603235e-03, 9.9242390e-01],\n",
       "       [9.9330360e-01, 5.6237000e-03, 1.0727432e-03],\n",
       "       [4.4060294e-02, 7.2424180e-01, 2.3169790e-01],\n",
       "       [4.4060294e-02, 7.2424180e-01, 2.3169790e-01],\n",
       "       [9.6886940e-03, 9.3208146e-01, 5.8229912e-02],\n",
       "       [5.9898810e-04, 9.9907553e-01, 3.2546360e-04],\n",
       "       [2.2173378e-01, 1.8028943e-01, 5.9797674e-01],\n",
       "       [7.4882914e-06, 9.3594070e-01, 6.4051810e-02],\n",
       "       [9.3184020e-01, 1.3914547e-02, 5.4245345e-02],\n",
       "       [5.8000320e-01, 1.0344137e-05, 4.1998646e-01],\n",
       "       [1.2733167e-03, 9.8518710e-01, 1.3539574e-02],\n",
       "       [6.7546985e-06, 9.9211700e-01, 7.8762890e-03],\n",
       "       [9.9232435e-01, 7.3765963e-03, 2.9899230e-04],\n",
       "       [9.9501800e-01, 3.6402003e-04, 4.6179110e-03],\n",
       "       [8.2392400e-06, 2.0822082e-03, 9.9790950e-01],\n",
       "       [9.9244785e-01, 5.6997870e-03, 1.8523391e-03],\n",
       "       [3.3459590e-02, 3.9952000e-01, 5.6702040e-01],\n",
       "       [6.0922354e-02, 9.1597730e-05, 9.3898600e-01],\n",
       "       [1.2466652e-04, 6.2853765e-01, 3.7133770e-01],\n",
       "       [1.4257007e-05, 9.7567140e-01, 2.4314255e-02],\n",
       "       [2.9734123e-01, 6.2499960e-01, 7.7659205e-02],\n",
       "       [9.8603520e-01, 1.2089956e-02, 1.8748733e-03],\n",
       "       [9.9446940e-01, 3.8145322e-04, 5.1491160e-03],\n",
       "       [1.3016548e-04, 9.6950770e-01, 3.0362180e-02],\n",
       "       [2.2221422e-02, 3.6178170e-01, 6.1599684e-01],\n",
       "       [2.3866760e-02, 4.9554625e-01, 4.8058695e-01],\n",
       "       [6.7624927e-04, 6.9033235e-01, 3.0899146e-01],\n",
       "       [2.2374978e-07, 9.9981123e-01, 1.8849684e-04],\n",
       "       [2.9734123e-01, 6.2499960e-01, 7.7659205e-02],\n",
       "       [7.0935505e-07, 9.9926320e-01, 7.3602740e-04],\n",
       "       [4.9890470e-04, 9.2361486e-01, 7.5886264e-02],\n",
       "       [5.1381870e-06, 9.9908470e-01, 9.1019150e-04],\n",
       "       [2.5810255e-04, 9.9968255e-01, 5.9328097e-05],\n",
       "       [1.4184709e-05, 9.9913470e-01, 8.5112115e-04],\n",
       "       [7.3149043e-01, 1.2710330e-03, 2.6723853e-01]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob4 = df_proba4[df_proba4['phage']=='p11kpresabs_qual'].iloc[:,-3:]\n",
    "y_prob4 = y_prob4.to_numpy()\n",
    "y_prob4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9480261328885181"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo4 = rocauc_ovo(y_test_over, y_prob4, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9480261328885181"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr4 = rocauc_ovr(y_test_over, y_prob4, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9412656766441169"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovos = [ovo1, ovo2, ovo3, ovo4]\n",
    "np.mean(ovos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.006362533807018114"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(ovos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9412656766441169"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovrs = [ovr1, ovr2, ovr3, ovr4]\n",
    "np.mean(ovrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.006362533807018114"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(ovrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs = [acc_test_over, acc_test_over2, acc_test_over3, acc_test_over4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling test accuracy mean: 80.67%\n"
     ]
    }
   ],
   "source": [
    "mean = np.mean(accs)\n",
    "print('over-sampling test accuracy mean: %.2f%%' % (mean*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling test accuracy standard deviation: 0.020577324900535585\n"
     ]
    }
   ],
   "source": [
    "std = np.std(accs)\n",
    "print('over-sampling test accuracy standard deviation:', std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs_train = [np.mean(hist1_over.history['accuracy']), np.mean(hist1_over2.history['accuracy']), np.mean(hist1_over3.history['accuracy']),\n",
    "             np.mean(hist1_over4.history['accuracy'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy mean: 90.43%\n"
     ]
    }
   ],
   "source": [
    "mean_train = np.mean(accs_train)\n",
    "print('over-sampling train accuracy mean: %.2f%%' % (mean_train*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy standard deviation: 0.0053634555\n"
     ]
    }
   ],
   "source": [
    "std_train = np.std(accs_train)\n",
    "print('over-sampling train accuracy standard deviation:', std_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ Feature selection using lasso ##########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Retrieved from https://towardsdatascience.com/feature-selection-using-regularisation-a3678b71e499\n",
    "from sklearn.linear_model import Lasso, LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectFromModel(estimator=LogisticRegression(C=1, class_weight=None, dual=False,\n",
       "                                             fit_intercept=True,\n",
       "                                             intercept_scaling=1, l1_ratio=None,\n",
       "                                             max_iter=100, multi_class='auto',\n",
       "                                             n_jobs=None, penalty='l1',\n",
       "                                             random_state=None,\n",
       "                                             solver='liblinear', tol=0.0001,\n",
       "                                             verbose=0, warm_start=False),\n",
       "                max_features=None, norm_order=1, prefit=False, threshold=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selection = SelectFromModel(LogisticRegression(C=1, penalty='l1', solver='liblinear'))\n",
    "selection.fit(X_over[:,1:], y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = np.array(df_clean.columns).tolist()\n",
    "names.remove('pheno')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_features_over = np.vstack((names, X_over[:,1:]))\n",
    "X_train_features_over = pd.DataFrame(X_train_features_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total features: 820\n",
      "selected features: 184\n"
     ]
    }
   ],
   "source": [
    "sel_features = X_train_features_over.columns[(selection.get_support())]\n",
    "print('total features: {}'.format((X_train_features_over.shape[1])))\n",
    "print('selected features: {}'.format(len(sel_features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   1,   2,   3,   4,  12,  13,  14,  20,  21,  27,  29,  36,\n",
       "         39,  70,  74,  75,  87,  94, 100, 101, 102, 104, 116, 125, 135,\n",
       "        138, 140, 146, 156, 161, 164, 166, 168, 177, 194, 196, 198, 199,\n",
       "        200, 202, 204, 206, 208, 213, 220, 229, 231, 232, 233, 241, 242,\n",
       "        243, 250, 265, 266, 270, 277, 280, 288, 296, 303, 307, 308, 310,\n",
       "        316, 318, 319, 323, 325, 334, 338, 344, 345, 352, 357, 359, 363,\n",
       "        367, 369, 374, 380, 386, 389, 390, 395, 396, 399, 410, 417, 428,\n",
       "        433, 442, 444, 445, 447, 455, 457, 463, 466, 467, 468, 470, 471,\n",
       "        473, 476, 477, 481, 482, 488, 490, 497, 503, 506, 515, 517, 518,\n",
       "        519, 521, 534, 541, 544, 549, 553, 558, 559, 560, 561, 562, 563,\n",
       "        564, 571, 573, 581, 585, 586, 588, 589, 593, 597, 602, 603, 604,\n",
       "        605, 606, 608, 614, 617, 618, 619, 628, 634, 639, 651, 652, 670,\n",
       "        673, 677, 678, 685, 702, 703, 704, 705, 712, 713, 716, 737, 738,\n",
       "        742, 746, 750, 751, 757, 759, 766, 768, 779, 781, 784, 788, 798,\n",
       "        804, 818]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = sel_features.values\n",
    "cols.reshape((1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['TTTTTTGTAATTTT', 'TTTTTTGTAATTTTT', 'TTTTTTATTTTGGAT',\n",
       "       'TTTTTTATTTTGGATAA', 'TTTTTTATTTTGGATAAAAGGAG', 'TTTTCTTTTCGT',\n",
       "       'TTTTCTTCTAATC', 'TTTTCTATTGTC',\n",
       "       'TTTTATGGAAGGTAATTTTAAAAATGTAAAGAAGCTTAT',\n",
       "       'TTTTATGGAAGGTAATTTTAAAAATGTAAAGAAGCTTATTTACGAAG',\n",
       "       'TTTTAATAGCTAGCACTTAATTGTGTTGGCTATTTTTTATGTCCAAAACGTGCTGATGACATAAAAAGCACGCATGGAAAAACAGTCGACAGACTATAAA',\n",
       "       'TTTGCCAGTATC', 'TTTCGCAAACTA', 'TTTCAGCGACT', 'TTGTGATGTTGTTT',\n",
       "       'TTGGTTTTAAATTT', 'TTGGTTTTAAATTTTT', 'TTGATAAAGTTTA',\n",
       "       'TTCTTTACATTTTTA', 'TTCTCTTCCATC', 'TTCTCTTCCATCCCTCATC',\n",
       "       'TTCTCTTCCATCCCTCATCCTCCTC', 'TTCTATAAAAAGT', 'TTCATCGTCGA',\n",
       "       'TTCAATCTAGAT', 'TTATTAGGTTCAAC', 'TTATCATCAAATG',\n",
       "       'TTATAGTCTGTCGACTGTTTTTCCATGCGTGCTTTTTATGTCATCAGCACGTTTTGGACATAAAAAATAGCCAACACAATTAAGTGCTAGCTATTAAAAG',\n",
       "       'TTAGGCGAAGAT', 'TTACGCAATAGTTTAGATGTAGA', 'TTACCTAAAAATAAAT',\n",
       "       'TTAATTGAATAACGGGAAGTAGCTCAGCTTGGTAGAGCACTTGGTTTGGGACCAAGGGGTCGCAGGTTCGAATCCTGTCTTCCCGATTACTTCTTAAATT',\n",
       "       'TTAACGAATAC', 'TTAAATTTTGCAGT', 'TGTTTATGGAAG', 'TGTCTAAATTGTT',\n",
       "       'TGTCCTTTGTT', 'TGTCCAAAACGTG', 'TGTCCAAAACGTGCTGA',\n",
       "       'TGTATTTTTTCTT', 'TGTAGCTGGAT', 'TGTACAAAATAAAAGA',\n",
       "       'TGGTTTTAAATTTT', 'TGGCGATTGTC', 'TGGAATGGGAGCA', 'TGCTCCCATTCC',\n",
       "       'TGCAAAATCG', 'TGATTTTTATCTGC', 'TGATTTGATGAGG',\n",
       "       'TGATTTGATGAGGGCGGAGGTG', 'TGATAACAATGTGCCT', 'TGATAACAATGTGCCTA',\n",
       "       'TGATAACAATGTGCCTAT', 'TGACTTTAAG', 'TCTTTTATTTTGT',\n",
       "       'TCTTTTAATAGCTAGCACTTAATTGTGTTGGCTATTTTTTATGTCCAAAACGTGCTGATGACATAAAAAGCACGCATGGAAAAACAGTCGACAGACTATA',\n",
       "       'TCTTCCATAAAC', 'TCTGTACTAAC', 'TCTGATTTTTTTG', 'TCTACTTCTTAAT',\n",
       "       'TCGTGTCTGT', 'TCGCCGTTATG', 'TCGAAAGAGT', 'TCCTTGCCTTA',\n",
       "       'TCCTCCTCATATTTATAGAC', 'TCCAGTGCTTG', 'TCCAAAGTATTT',\n",
       "       'TCCAAAGTATTTT', 'TCATCAAACTTT', 'TCAGTCTGAT', 'TCACTATAAGTG',\n",
       "       'TCACACCGCCT', 'TCAAAAGTTAATA', 'TCAAAAAGATGAAT', 'TATTGACTCCT',\n",
       "       'TATTAAATTTAAAG', 'TATCTTCGCCTA', 'TATCCAGAATG', 'TATAGTGTTCAT',\n",
       "       'TATAGGAGCC', 'TAGTTTAGATGT', 'TAGGGATTATG', 'TAGCTAAATCC',\n",
       "       'TAGATTCAAATAT', 'TAGAGTCGTTG', 'TACTTGCCTAAAT', 'TACTAGTCATC',\n",
       "       'TACGCCAGTTT', 'TACAGCTTTCT', 'TAATCTTGTTGTT', 'TAACTAAATTCGT',\n",
       "       'TAAATTAATAGGTG', 'TAAACTATTGCG', 'TAAAAGGTATCT', 'TAAAAGATCCAG',\n",
       "       'TAAAAAAGCGAT', 'GTTTATGGAAG', 'GTTTAAAATTATTC', 'GTTCAACTCC',\n",
       "       'GTTACAAACAACAT', 'GTTAATACTGGC',\n",
       "       'GTTAAACTACAAAAACAAAAGTTAACTAAAGATAT', 'GTGTTCATCGT',\n",
       "       'GTGTATTTTAAG', 'GTGATGTTGTTTGT', 'GTGAATTCATG', 'GTCTGATTTTTT',\n",
       "       'GTCGCAAATATTTC', 'GTCACTATAAGTGATGTTTATTCAGGATC',\n",
       "       'GTATTGCAACAGATTGGCTCAAAAGTTAGT', 'GTAGCTGGATT',\n",
       "       'GTAATTTTAAAAATGTAAAGAAG', 'GTAATAGGCAT', 'GGTTTTAAATTTTT',\n",
       "       'GGTAACGGTTTAACACGTCC', 'GGTAAAAACGGT', 'GGGGTGATTTT',\n",
       "       'GGGGCTCATTTT', 'GGGCTCATTT',\n",
       "       'GGAGTTGAACCTAATAAAAGTTATCAGGTGACAATAGAAAATGTACGTAGCGGTATAATGAGG',\n",
       "       'GCTTGACTGT', 'GCTCTGTGTT', 'GCTATAGGAG', 'GCGGAGTTGC',\n",
       "       'GCCAAGTAGT', 'GCATTACACCT', 'GCAGTAGGGATT', 'GCAGTAGGGATTATG',\n",
       "       'GCACGACGTC', 'GCACGACGTCTT', 'GCAACTCCGCT', 'GATTTCCCGT',\n",
       "       'GATTCGAAATATT', 'GATACGTTAGATG', 'GAGGGGGACGTTTAAAT',\n",
       "       'GAGGGATGGAAGAG', 'GAGGAGCAGG', 'GAGCGATCAG', 'GAGAAAGCTGTAG',\n",
       "       'GACACGTTAG', 'GAAGTCACTCG', 'GAAGGATTACTAAAG', 'GAAGGATTACTAAAGT',\n",
       "       'GAACTAGTTGAT', 'GAACGCTATTT', 'GAACAAGACATG', 'GAAAAAAGAAAATGAG',\n",
       "       'CTTTGCGAAGT', 'CTTTCATTCTTT', 'CTTGCCTAAAT',\n",
       "       'CTTCAATCTAGATAACATGTAATGATT',\n",
       "       'CTCTTTTAATAGCTAGCACTTAATTGTGTTGGCTATTTTTTATGTCCAAAACGTGCTGATGACATAAAAAGCACGCATGGAAAAACAGTCGACAGACTAT',\n",
       "       'CTCCGCTATTG', 'CTAATGTGGT', 'CTAATCCTTCAAT', 'CGCCTAACATG',\n",
       "       'CGACTAATTTTTT', 'CCTTGCATAGG', 'CCTTCGTAAAT', 'CCTGAAGGATT',\n",
       "       'CCAGTGCTTG', 'CCAGACATTGTT', 'CCAATATTCTTG', 'CCAATATAAGAT',\n",
       "       'CATCTAACGTAT', 'CATCAAACTTTT', 'CAGTCTGATTT', 'ATTTATCCAACTTT',\n",
       "       'ATTGTATGACT', 'ATTAATAGGTGGT', 'ATGGCTACTGGT', 'ATGAAGATAGAGT',\n",
       "       'ATCGTCAGCACT', 'ATCATCTCCGT', 'ATCAATACAAGTT', 'ATAGGCACATT',\n",
       "       'ATAGCGGAGTT', 'AGGTGTAATGCT', 'AGGGGTGATT', 'AGGCTAACTT',\n",
       "       'AGCATCTACTTTT', 'ACTGCGTTAGT', 'ACTAAATTCGT', 'AACCTAGAAAGTTT'],\n",
       "      dtype='<U100')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names_arr = np.array(names)\n",
    "names_arr[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###### keep selected variables as a new dataframe\n",
    "df_sel = df_clean.loc[:,names_arr[cols]].copy()\n",
    "df_sel['pheno'] = df_clean['pheno']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_sel['strain'] = X.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TTTTTTGTAATTTT</th>\n",
       "      <th>TTTTTTGTAATTTTT</th>\n",
       "      <th>TTTTTTATTTTGGAT</th>\n",
       "      <th>TTTTTTATTTTGGATAA</th>\n",
       "      <th>TTTTTTATTTTGGATAAAAGGAG</th>\n",
       "      <th>TTTTCTTTTCGT</th>\n",
       "      <th>TTTTCTTCTAATC</th>\n",
       "      <th>TTTTCTATTGTC</th>\n",
       "      <th>TTTTATGGAAGGTAATTTTAAAAATGTAAAGAAGCTTAT</th>\n",
       "      <th>TTTTATGGAAGGTAATTTTAAAAATGTAAAGAAGCTTATTTACGAAG</th>\n",
       "      <th>...</th>\n",
       "      <th>ATAGCGGAGTT</th>\n",
       "      <th>AGGTGTAATGCT</th>\n",
       "      <th>AGGGGTGATT</th>\n",
       "      <th>AGGCTAACTT</th>\n",
       "      <th>AGCATCTACTTTT</th>\n",
       "      <th>ACTGCGTTAGT</th>\n",
       "      <th>ACTAAATTCGT</th>\n",
       "      <th>AACCTAGAAAGTTT</th>\n",
       "      <th>pheno</th>\n",
       "      <th>strain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>120335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>120337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>SR4152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>SR4153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>SR4155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>SR4156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>SR4187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>253 rows × 186 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     TTTTTTGTAATTTT  TTTTTTGTAATTTTT  TTTTTTATTTTGGAT  TTTTTTATTTTGGATAA  \\\n",
       "0                 0                0                0                  0   \n",
       "1                 1                1                1                  1   \n",
       "2                 1                1                1                  1   \n",
       "3                 1                1                1                  1   \n",
       "4                 1                1                1                  1   \n",
       "..              ...              ...              ...                ...   \n",
       "248               1                1                1                  1   \n",
       "249               1                1                1                  1   \n",
       "250               1                1                1                  1   \n",
       "251               1                1                1                  1   \n",
       "252               1                1                1                  1   \n",
       "\n",
       "     TTTTTTATTTTGGATAAAAGGAG  TTTTCTTTTCGT  TTTTCTTCTAATC  TTTTCTATTGTC  \\\n",
       "0                          0             0              1             0   \n",
       "1                          1             1              1             1   \n",
       "2                          1             1              1             1   \n",
       "3                          1             1              1             1   \n",
       "4                          1             1              1             1   \n",
       "..                       ...           ...            ...           ...   \n",
       "248                        1             1              1             1   \n",
       "249                        1             1              1             1   \n",
       "250                        1             1              1             1   \n",
       "251                        1             1              1             1   \n",
       "252                        1             1              1             1   \n",
       "\n",
       "     TTTTATGGAAGGTAATTTTAAAAATGTAAAGAAGCTTAT  \\\n",
       "0                                          0   \n",
       "1                                          1   \n",
       "2                                          0   \n",
       "3                                          1   \n",
       "4                                          1   \n",
       "..                                       ...   \n",
       "248                                        1   \n",
       "249                                        1   \n",
       "250                                        1   \n",
       "251                                        0   \n",
       "252                                        1   \n",
       "\n",
       "     TTTTATGGAAGGTAATTTTAAAAATGTAAAGAAGCTTATTTACGAAG  ...  ATAGCGGAGTT  \\\n",
       "0                                                  0  ...            0   \n",
       "1                                                  1  ...            1   \n",
       "2                                                  0  ...            1   \n",
       "3                                                  1  ...            1   \n",
       "4                                                  1  ...            1   \n",
       "..                                               ...  ...          ...   \n",
       "248                                                1  ...            1   \n",
       "249                                                1  ...            1   \n",
       "250                                                1  ...            1   \n",
       "251                                                0  ...            1   \n",
       "252                                                1  ...            1   \n",
       "\n",
       "     AGGTGTAATGCT  AGGGGTGATT  AGGCTAACTT  AGCATCTACTTTT  ACTGCGTTAGT  \\\n",
       "0               0           1           1              0            0   \n",
       "1               1           1           1              1            1   \n",
       "2               1           1           1              1            1   \n",
       "3               1           1           1              1            1   \n",
       "4               1           1           1              1            1   \n",
       "..            ...         ...         ...            ...          ...   \n",
       "248             1           1           1              1            1   \n",
       "249             1           1           1              1            1   \n",
       "250             1           1           1              1            1   \n",
       "251             0           1           1              1            1   \n",
       "252             1           1           1              1            1   \n",
       "\n",
       "     ACTAAATTCGT  AACCTAGAAAGTTT  pheno  strain  \n",
       "0              0               0      2     107  \n",
       "1              1               1      1     109  \n",
       "2              1               1      2     115  \n",
       "3              1               1      2  120335  \n",
       "4              1               1      2  120337  \n",
       "..           ...             ...    ...     ...  \n",
       "248            1               1      2  SR4152  \n",
       "249            1               1      1  SR4153  \n",
       "250            1               1      2  SR4155  \n",
       "251            1               1      2  SR4156  \n",
       "252            1               1      2  SR4187  \n",
       "\n",
       "[253 rows x 186 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(253, 185) (253,) (253, 186)\n"
     ]
    }
   ],
   "source": [
    "X_sel = df_sel.loc[:, df_sel.columns != 'pheno']\n",
    "y_sel = df_sel['pheno']\n",
    "print(X_sel.shape, y_sel.shape, df_sel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    181\n",
       "1     47\n",
       "0     25\n",
       "Name: pheno, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sel['pheno'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 181), (1, 181), (2, 181)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# over-sampling\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "overS = RandomOverSampler(random_state=100)\n",
    "X_sel_over, y_sel_over = overS.fit_resample(X_sel, y_sel)\n",
    "print(sorted(Counter(y_sel_over).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_sel_train_over, X_sel_test_over, y_sel_train_over, y_sel_test_over = train_test_split(X_sel_over, y_sel_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=567,\n",
    "                                                    stratify=y_sel_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat5 = pd.DataFrame(X_sel_test_over[:,-1])\n",
    "dat5['test'] = y_sel_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CFBRSa49</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS108</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MN105</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CFBRSa03</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BCH-SA-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>NRS027</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>BCH-SA-04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>SR3585</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>504</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>NRS149</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0  test\n",
       "0     CFBRSa49     1\n",
       "1       NRS108     2\n",
       "2        MN105     2\n",
       "3     CFBRSa03     2\n",
       "4    BCH-SA-01     0\n",
       "..         ...   ...\n",
       "158     NRS027     0\n",
       "159  BCH-SA-04     0\n",
       "160     SR3585     2\n",
       "161        504     1\n",
       "162     NRS149     0\n",
       "\n",
       "[163 rows x 2 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sel_train_over = X_sel_train_over[:,:-1]\n",
    "X_sel_test_over = X_sel_test_over[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### neural network on over-sampling data\n",
    "model2_over = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_sel_train_over.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2_over.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 380 samples, validate on 163 samples\n",
      "Epoch 1/100\n",
      "380/380 [==============================] - 0s 499us/step - loss: 1.1424 - accuracy: 0.3342 - val_loss: 1.0788 - val_accuracy: 0.4294\n",
      "Epoch 2/100\n",
      "380/380 [==============================] - 0s 81us/step - loss: 1.0708 - accuracy: 0.4368 - val_loss: 1.0371 - val_accuracy: 0.4724\n",
      "Epoch 3/100\n",
      "380/380 [==============================] - 0s 98us/step - loss: 1.0193 - accuracy: 0.4895 - val_loss: 1.0172 - val_accuracy: 0.4601\n",
      "Epoch 4/100\n",
      "380/380 [==============================] - 0s 101us/step - loss: 0.9796 - accuracy: 0.5158 - val_loss: 0.9844 - val_accuracy: 0.6012\n",
      "Epoch 5/100\n",
      "380/380 [==============================] - 0s 112us/step - loss: 0.9393 - accuracy: 0.5895 - val_loss: 0.9506 - val_accuracy: 0.5828\n",
      "Epoch 6/100\n",
      "380/380 [==============================] - 0s 105us/step - loss: 0.9007 - accuracy: 0.6632 - val_loss: 0.9176 - val_accuracy: 0.6442\n",
      "Epoch 7/100\n",
      "380/380 [==============================] - 0s 118us/step - loss: 0.8682 - accuracy: 0.6632 - val_loss: 0.8854 - val_accuracy: 0.6503\n",
      "Epoch 8/100\n",
      "380/380 [==============================] - 0s 96us/step - loss: 0.8346 - accuracy: 0.6868 - val_loss: 0.8604 - val_accuracy: 0.6503\n",
      "Epoch 9/100\n",
      "380/380 [==============================] - 0s 80us/step - loss: 0.8031 - accuracy: 0.6921 - val_loss: 0.8390 - val_accuracy: 0.7301\n",
      "Epoch 10/100\n",
      "380/380 [==============================] - 0s 64us/step - loss: 0.7748 - accuracy: 0.7237 - val_loss: 0.8120 - val_accuracy: 0.6810\n",
      "Epoch 11/100\n",
      "380/380 [==============================] - 0s 73us/step - loss: 0.7508 - accuracy: 0.7000 - val_loss: 0.7894 - val_accuracy: 0.7485\n",
      "Epoch 12/100\n",
      "380/380 [==============================] - 0s 86us/step - loss: 0.7210 - accuracy: 0.7395 - val_loss: 0.7640 - val_accuracy: 0.7239\n",
      "Epoch 13/100\n",
      "380/380 [==============================] - 0s 85us/step - loss: 0.7025 - accuracy: 0.7368 - val_loss: 0.7434 - val_accuracy: 0.7178\n",
      "Epoch 14/100\n",
      "380/380 [==============================] - 0s 91us/step - loss: 0.6741 - accuracy: 0.7395 - val_loss: 0.7198 - val_accuracy: 0.7178\n",
      "Epoch 15/100\n",
      "380/380 [==============================] - 0s 111us/step - loss: 0.6504 - accuracy: 0.7342 - val_loss: 0.7033 - val_accuracy: 0.7607\n",
      "Epoch 16/100\n",
      "380/380 [==============================] - 0s 77us/step - loss: 0.6312 - accuracy: 0.7763 - val_loss: 0.6821 - val_accuracy: 0.7239\n",
      "Epoch 17/100\n",
      "380/380 [==============================] - 0s 65us/step - loss: 0.6073 - accuracy: 0.7789 - val_loss: 0.6656 - val_accuracy: 0.7117\n",
      "Epoch 18/100\n",
      "380/380 [==============================] - 0s 112us/step - loss: 0.5870 - accuracy: 0.7658 - val_loss: 0.6492 - val_accuracy: 0.7362\n",
      "Epoch 19/100\n",
      "380/380 [==============================] - 0s 62us/step - loss: 0.5817 - accuracy: 0.8053 - val_loss: 0.6355 - val_accuracy: 0.7117\n",
      "Epoch 20/100\n",
      "380/380 [==============================] - 0s 53us/step - loss: 0.5677 - accuracy: 0.7684 - val_loss: 0.6280 - val_accuracy: 0.7362\n",
      "Epoch 21/100\n",
      "380/380 [==============================] - 0s 58us/step - loss: 0.5447 - accuracy: 0.8263 - val_loss: 0.6180 - val_accuracy: 0.7607\n",
      "Epoch 22/100\n",
      "380/380 [==============================] - 0s 63us/step - loss: 0.5317 - accuracy: 0.8053 - val_loss: 0.6047 - val_accuracy: 0.7546\n",
      "Epoch 23/100\n",
      "380/380 [==============================] - 0s 83us/step - loss: 0.5107 - accuracy: 0.8132 - val_loss: 0.5928 - val_accuracy: 0.7239\n",
      "Epoch 24/100\n",
      "380/380 [==============================] - 0s 78us/step - loss: 0.5003 - accuracy: 0.8158 - val_loss: 0.5815 - val_accuracy: 0.7975\n",
      "Epoch 25/100\n",
      "380/380 [==============================] - 0s 67us/step - loss: 0.4830 - accuracy: 0.8553 - val_loss: 0.5659 - val_accuracy: 0.7607\n",
      "Epoch 26/100\n",
      "380/380 [==============================] - 0s 71us/step - loss: 0.4663 - accuracy: 0.8500 - val_loss: 0.5524 - val_accuracy: 0.7975\n",
      "Epoch 27/100\n",
      "380/380 [==============================] - 0s 96us/step - loss: 0.4465 - accuracy: 0.8553 - val_loss: 0.5434 - val_accuracy: 0.7791\n",
      "Epoch 28/100\n",
      "380/380 [==============================] - 0s 89us/step - loss: 0.4365 - accuracy: 0.8605 - val_loss: 0.5372 - val_accuracy: 0.8037\n",
      "Epoch 29/100\n",
      "380/380 [==============================] - 0s 80us/step - loss: 0.4197 - accuracy: 0.8579 - val_loss: 0.5290 - val_accuracy: 0.8037\n",
      "Epoch 30/100\n",
      "380/380 [==============================] - 0s 80us/step - loss: 0.4183 - accuracy: 0.8553 - val_loss: 0.5126 - val_accuracy: 0.7791\n",
      "Epoch 31/100\n",
      "380/380 [==============================] - 0s 84us/step - loss: 0.4067 - accuracy: 0.8500 - val_loss: 0.5288 - val_accuracy: 0.7853\n",
      "Epoch 32/100\n",
      "380/380 [==============================] - 0s 127us/step - loss: 0.3967 - accuracy: 0.8526 - val_loss: 0.4976 - val_accuracy: 0.8098\n",
      "Epoch 33/100\n",
      "380/380 [==============================] - 0s 127us/step - loss: 0.3777 - accuracy: 0.8737 - val_loss: 0.5031 - val_accuracy: 0.8037\n",
      "Epoch 34/100\n",
      "380/380 [==============================] - 0s 118us/step - loss: 0.3751 - accuracy: 0.8632 - val_loss: 0.4857 - val_accuracy: 0.8098\n",
      "Epoch 35/100\n",
      "380/380 [==============================] - 0s 123us/step - loss: 0.3635 - accuracy: 0.8737 - val_loss: 0.4733 - val_accuracy: 0.8098\n",
      "Epoch 36/100\n",
      "380/380 [==============================] - 0s 99us/step - loss: 0.3548 - accuracy: 0.8737 - val_loss: 0.4697 - val_accuracy: 0.8098\n",
      "Epoch 37/100\n",
      "380/380 [==============================] - 0s 69us/step - loss: 0.3469 - accuracy: 0.8816 - val_loss: 0.4646 - val_accuracy: 0.8160\n",
      "Epoch 38/100\n",
      "380/380 [==============================] - 0s 81us/step - loss: 0.3462 - accuracy: 0.8789 - val_loss: 0.4712 - val_accuracy: 0.7975\n",
      "Epoch 39/100\n",
      "380/380 [==============================] - 0s 67us/step - loss: 0.3472 - accuracy: 0.8684 - val_loss: 0.4697 - val_accuracy: 0.8221\n",
      "Epoch 40/100\n",
      "380/380 [==============================] - 0s 67us/step - loss: 0.3330 - accuracy: 0.8737 - val_loss: 0.4540 - val_accuracy: 0.7853\n",
      "Epoch 41/100\n",
      "380/380 [==============================] - 0s 65us/step - loss: 0.3294 - accuracy: 0.8763 - val_loss: 0.4663 - val_accuracy: 0.7975\n",
      "Epoch 42/100\n",
      "380/380 [==============================] - 0s 67us/step - loss: 0.3191 - accuracy: 0.8737 - val_loss: 0.4380 - val_accuracy: 0.7914\n",
      "Epoch 43/100\n",
      "380/380 [==============================] - 0s 107us/step - loss: 0.3188 - accuracy: 0.8763 - val_loss: 0.4318 - val_accuracy: 0.8098\n",
      "Epoch 44/100\n",
      "380/380 [==============================] - 0s 104us/step - loss: 0.3098 - accuracy: 0.8921 - val_loss: 0.4422 - val_accuracy: 0.8037\n",
      "Epoch 45/100\n",
      "380/380 [==============================] - 0s 133us/step - loss: 0.3039 - accuracy: 0.8868 - val_loss: 0.4234 - val_accuracy: 0.8098\n",
      "Epoch 46/100\n",
      "380/380 [==============================] - 0s 98us/step - loss: 0.3123 - accuracy: 0.8684 - val_loss: 0.4115 - val_accuracy: 0.7975\n",
      "Epoch 47/100\n",
      "380/380 [==============================] - 0s 137us/step - loss: 0.3007 - accuracy: 0.8816 - val_loss: 0.4339 - val_accuracy: 0.8037\n",
      "Epoch 48/100\n",
      "380/380 [==============================] - 0s 141us/step - loss: 0.2981 - accuracy: 0.8947 - val_loss: 0.4023 - val_accuracy: 0.8160\n",
      "Epoch 49/100\n",
      "380/380 [==============================] - 0s 111us/step - loss: 0.2839 - accuracy: 0.9000 - val_loss: 0.3987 - val_accuracy: 0.8282\n",
      "Epoch 50/100\n",
      "380/380 [==============================] - 0s 128us/step - loss: 0.2707 - accuracy: 0.9105 - val_loss: 0.4054 - val_accuracy: 0.8221\n",
      "Epoch 51/100\n",
      "380/380 [==============================] - 0s 113us/step - loss: 0.2692 - accuracy: 0.9053 - val_loss: 0.3944 - val_accuracy: 0.8221\n",
      "Epoch 52/100\n",
      "380/380 [==============================] - 0s 127us/step - loss: 0.2670 - accuracy: 0.9079 - val_loss: 0.3959 - val_accuracy: 0.8221\n",
      "Epoch 53/100\n",
      "380/380 [==============================] - 0s 166us/step - loss: 0.2617 - accuracy: 0.9105 - val_loss: 0.3820 - val_accuracy: 0.8282\n",
      "Epoch 54/100\n",
      "380/380 [==============================] - 0s 115us/step - loss: 0.2599 - accuracy: 0.9053 - val_loss: 0.3812 - val_accuracy: 0.8221\n",
      "Epoch 55/100\n",
      "380/380 [==============================] - 0s 94us/step - loss: 0.2513 - accuracy: 0.9105 - val_loss: 0.3843 - val_accuracy: 0.8221\n",
      "Epoch 56/100\n",
      "380/380 [==============================] - 0s 105us/step - loss: 0.2505 - accuracy: 0.9105 - val_loss: 0.3656 - val_accuracy: 0.8344\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "380/380 [==============================] - 0s 119us/step - loss: 0.2486 - accuracy: 0.9132 - val_loss: 0.3731 - val_accuracy: 0.8405\n",
      "Epoch 58/100\n",
      "380/380 [==============================] - 0s 86us/step - loss: 0.2440 - accuracy: 0.9132 - val_loss: 0.3794 - val_accuracy: 0.8282\n",
      "Epoch 59/100\n",
      "380/380 [==============================] - 0s 104us/step - loss: 0.2447 - accuracy: 0.9105 - val_loss: 0.3716 - val_accuracy: 0.8528\n",
      "Epoch 60/100\n",
      "380/380 [==============================] - 0s 140us/step - loss: 0.2396 - accuracy: 0.9132 - val_loss: 0.3820 - val_accuracy: 0.8221\n",
      "Epoch 61/100\n",
      "380/380 [==============================] - 0s 114us/step - loss: 0.2337 - accuracy: 0.9158 - val_loss: 0.3524 - val_accuracy: 0.8528\n",
      "Epoch 62/100\n",
      "380/380 [==============================] - 0s 95us/step - loss: 0.2404 - accuracy: 0.9026 - val_loss: 0.3737 - val_accuracy: 0.8528\n",
      "Epoch 63/100\n",
      "380/380 [==============================] - 0s 99us/step - loss: 0.2416 - accuracy: 0.9158 - val_loss: 0.3529 - val_accuracy: 0.8589\n",
      "Epoch 64/100\n",
      "380/380 [==============================] - 0s 77us/step - loss: 0.2304 - accuracy: 0.9184 - val_loss: 0.3496 - val_accuracy: 0.8405\n",
      "Epoch 65/100\n",
      "380/380 [==============================] - 0s 157us/step - loss: 0.2236 - accuracy: 0.9158 - val_loss: 0.3654 - val_accuracy: 0.8466\n",
      "Epoch 66/100\n",
      "380/380 [==============================] - 0s 206us/step - loss: 0.2227 - accuracy: 0.9158 - val_loss: 0.3399 - val_accuracy: 0.8528\n",
      "Epoch 67/100\n",
      "380/380 [==============================] - 0s 139us/step - loss: 0.2371 - accuracy: 0.9158 - val_loss: 0.3635 - val_accuracy: 0.8528\n",
      "Epoch 68/100\n",
      "380/380 [==============================] - 0s 231us/step - loss: 0.2382 - accuracy: 0.9026 - val_loss: 0.3574 - val_accuracy: 0.8528\n",
      "Epoch 69/100\n",
      "380/380 [==============================] - 0s 186us/step - loss: 0.2314 - accuracy: 0.9026 - val_loss: 0.3393 - val_accuracy: 0.8650\n",
      "Epoch 70/100\n",
      "380/380 [==============================] - 0s 143us/step - loss: 0.2246 - accuracy: 0.9132 - val_loss: 0.3614 - val_accuracy: 0.8589\n",
      "Epoch 71/100\n",
      "380/380 [==============================] - 0s 96us/step - loss: 0.2309 - accuracy: 0.9105 - val_loss: 0.3319 - val_accuracy: 0.8528\n",
      "Epoch 72/100\n",
      "380/380 [==============================] - 0s 80us/step - loss: 0.2255 - accuracy: 0.9053 - val_loss: 0.3902 - val_accuracy: 0.8466\n",
      "Epoch 73/100\n",
      "380/380 [==============================] - 0s 77us/step - loss: 0.2446 - accuracy: 0.8974 - val_loss: 0.3635 - val_accuracy: 0.8282\n",
      "Epoch 74/100\n",
      "380/380 [==============================] - 0s 78us/step - loss: 0.2227 - accuracy: 0.9158 - val_loss: 0.3339 - val_accuracy: 0.8528\n",
      "Epoch 75/100\n",
      "380/380 [==============================] - 0s 101us/step - loss: 0.2156 - accuracy: 0.9105 - val_loss: 0.3774 - val_accuracy: 0.8282\n",
      "Epoch 76/100\n",
      "380/380 [==============================] - 0s 126us/step - loss: 0.2150 - accuracy: 0.9184 - val_loss: 0.3295 - val_accuracy: 0.8466\n",
      "Epoch 77/100\n",
      "380/380 [==============================] - 0s 139us/step - loss: 0.2067 - accuracy: 0.9237 - val_loss: 0.3631 - val_accuracy: 0.8405\n",
      "Epoch 78/100\n",
      "380/380 [==============================] - 0s 126us/step - loss: 0.2078 - accuracy: 0.9211 - val_loss: 0.3290 - val_accuracy: 0.8712\n",
      "Epoch 79/100\n",
      "380/380 [==============================] - 0s 129us/step - loss: 0.2098 - accuracy: 0.9263 - val_loss: 0.3249 - val_accuracy: 0.8650\n",
      "Epoch 80/100\n",
      "380/380 [==============================] - 0s 87us/step - loss: 0.2026 - accuracy: 0.9237 - val_loss: 0.3364 - val_accuracy: 0.8589\n",
      "Epoch 81/100\n",
      "380/380 [==============================] - 0s 84us/step - loss: 0.1994 - accuracy: 0.9263 - val_loss: 0.3265 - val_accuracy: 0.8650\n",
      "Epoch 82/100\n",
      "380/380 [==============================] - 0s 84us/step - loss: 0.2004 - accuracy: 0.9263 - val_loss: 0.3353 - val_accuracy: 0.8650\n",
      "Epoch 83/100\n",
      "380/380 [==============================] - 0s 74us/step - loss: 0.1968 - accuracy: 0.9263 - val_loss: 0.3392 - val_accuracy: 0.8528\n",
      "Epoch 84/100\n",
      "380/380 [==============================] - 0s 92us/step - loss: 0.1946 - accuracy: 0.9211 - val_loss: 0.3179 - val_accuracy: 0.8650\n",
      "Epoch 85/100\n",
      "380/380 [==============================] - 0s 107us/step - loss: 0.1924 - accuracy: 0.9289 - val_loss: 0.3318 - val_accuracy: 0.8712\n",
      "Epoch 86/100\n",
      "380/380 [==============================] - 0s 115us/step - loss: 0.1999 - accuracy: 0.9184 - val_loss: 0.3191 - val_accuracy: 0.8712\n",
      "Epoch 87/100\n",
      "380/380 [==============================] - 0s 112us/step - loss: 0.1962 - accuracy: 0.9211 - val_loss: 0.3643 - val_accuracy: 0.8405\n",
      "Epoch 88/100\n",
      "380/380 [==============================] - 0s 130us/step - loss: 0.1954 - accuracy: 0.9211 - val_loss: 0.3135 - val_accuracy: 0.8773\n",
      "Epoch 89/100\n",
      "380/380 [==============================] - 0s 134us/step - loss: 0.1965 - accuracy: 0.9211 - val_loss: 0.3225 - val_accuracy: 0.8712\n",
      "Epoch 90/100\n",
      "380/380 [==============================] - 0s 107us/step - loss: 0.2017 - accuracy: 0.9158 - val_loss: 0.3438 - val_accuracy: 0.8650\n",
      "Epoch 91/100\n",
      "380/380 [==============================] - 0s 108us/step - loss: 0.1950 - accuracy: 0.9237 - val_loss: 0.3167 - val_accuracy: 0.8650\n",
      "Epoch 92/100\n",
      "380/380 [==============================] - 0s 99us/step - loss: 0.1889 - accuracy: 0.9263 - val_loss: 0.3226 - val_accuracy: 0.8589\n",
      "Epoch 93/100\n",
      "380/380 [==============================] - 0s 112us/step - loss: 0.1924 - accuracy: 0.9263 - val_loss: 0.3433 - val_accuracy: 0.8466\n",
      "Epoch 94/100\n",
      "380/380 [==============================] - 0s 95us/step - loss: 0.2094 - accuracy: 0.9237 - val_loss: 0.3350 - val_accuracy: 0.8589\n",
      "Epoch 95/100\n",
      "380/380 [==============================] - 0s 89us/step - loss: 0.2004 - accuracy: 0.9158 - val_loss: 0.3214 - val_accuracy: 0.8589\n",
      "Epoch 96/100\n",
      "380/380 [==============================] - 0s 93us/step - loss: 0.1990 - accuracy: 0.9263 - val_loss: 0.3030 - val_accuracy: 0.8712\n",
      "Epoch 97/100\n",
      "380/380 [==============================] - 0s 92us/step - loss: 0.1829 - accuracy: 0.9289 - val_loss: 0.3215 - val_accuracy: 0.8712\n",
      "Epoch 98/100\n",
      "380/380 [==============================] - 0s 124us/step - loss: 0.1903 - accuracy: 0.9237 - val_loss: 0.3086 - val_accuracy: 0.8712\n",
      "Epoch 99/100\n",
      "380/380 [==============================] - 0s 99us/step - loss: 0.2031 - accuracy: 0.9263 - val_loss: 0.3087 - val_accuracy: 0.8773\n",
      "Epoch 100/100\n",
      "380/380 [==============================] - 0s 117us/step - loss: 0.2090 - accuracy: 0.9105 - val_loss: 0.3601 - val_accuracy: 0.8466\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a43c73630>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2_over.fit(X_sel_train_over, y_sel_train_over,\n",
    "          batch_size=64, epochs=100,\n",
    "          validation_data=(X_sel_test_over, y_sel_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163/163 [==============================] - 0s 104us/step\n",
      "over-sampling test accuracy: 84.05%\n"
     ]
    }
   ],
   "source": [
    "acc_test2_over = model2_over.evaluate(X_sel_test_over, y_sel_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test2_over*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 1, 2, 0, 1, 1, 2, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 2, 2, 1, 1,\n",
       "       0, 2, 0, 1, 2, 1, 0, 2, 2, 0, 1, 0, 1, 1, 1, 0, 1, 2, 2, 2, 2, 1,\n",
       "       0, 1, 1, 0, 1, 2, 1, 2, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 2, 2, 1, 2,\n",
       "       1, 0, 2, 1, 2, 0, 2, 0, 0, 1, 2, 0, 0, 0, 0, 0, 2, 1, 1, 0, 1, 0,\n",
       "       0, 1, 2, 1, 1, 1, 2, 2, 0, 1, 0, 0, 1, 1, 1, 0, 2, 1, 2, 1, 1, 2,\n",
       "       1, 0, 2, 1, 1, 0, 0, 1, 1, 2, 1, 0, 1, 0, 0, 1, 2, 0, 2, 1, 1, 2,\n",
       "       1, 0, 0, 2, 1, 0, 0, 0, 0, 1, 2, 2, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1,\n",
       "       0, 1, 0, 1, 0, 0, 1, 1, 0])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred5 = model2_over.predict_classes(X_sel_test_over)\n",
    "pred5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CFBRSa49</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS108</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MN105</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CFBRSa03</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BCH-SA-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>NRS027</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>BCH-SA-04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>SR3585</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>504</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>NRS149</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0  test  pred\n",
       "0     CFBRSa49     1     1\n",
       "1       NRS108     2     2\n",
       "2        MN105     2     1\n",
       "3     CFBRSa03     2     2\n",
       "4    BCH-SA-01     0     0\n",
       "..         ...   ...   ...\n",
       "158     NRS027     0     0\n",
       "159  BCH-SA-04     0     0\n",
       "160     SR3585     2     1\n",
       "161        504     1     1\n",
       "162     NRS149     0     0\n",
       "\n",
       "[163 rows x 3 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat5['pred'] = pred5\n",
    "dat5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba5 = model2_over.predict_proba(X_sel_test_over)\n",
    "dat_proba5 = pd.DataFrame(proba5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.411915</td>\n",
       "      <td>0.469525</td>\n",
       "      <td>0.118560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.009521</td>\n",
       "      <td>0.990294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.863504</td>\n",
       "      <td>0.136460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>0.999799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.973129</td>\n",
       "      <td>0.000358</td>\n",
       "      <td>0.026513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>0.996810</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>0.003042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>0.992484</td>\n",
       "      <td>0.004105</td>\n",
       "      <td>0.003411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>0.262175</td>\n",
       "      <td>0.461844</td>\n",
       "      <td>0.275981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>0.006449</td>\n",
       "      <td>0.981863</td>\n",
       "      <td>0.011687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>0.997835</td>\n",
       "      <td>0.000292</td>\n",
       "      <td>0.001874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2\n",
       "0    0.411915  0.469525  0.118560\n",
       "1    0.000185  0.009521  0.990294\n",
       "2    0.000036  0.863504  0.136460\n",
       "3    0.000045  0.000156  0.999799\n",
       "4    0.973129  0.000358  0.026513\n",
       "..        ...       ...       ...\n",
       "158  0.996810  0.000148  0.003042\n",
       "159  0.992484  0.004105  0.003411\n",
       "160  0.262175  0.461844  0.275981\n",
       "161  0.006449  0.981863  0.011687\n",
       "162  0.997835  0.000292  0.001874\n",
       "\n",
       "[163 rows x 3 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba5.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba5.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat5.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/5p11.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 380 samples, validate on 163 samples\n",
      "Epoch 1/100\n",
      "380/380 [==============================] - 0s 91us/step - loss: 0.2082 - accuracy: 0.9237 - val_loss: 0.3912 - val_accuracy: 0.8221\n",
      "Epoch 2/100\n",
      "380/380 [==============================] - 0s 106us/step - loss: 0.2081 - accuracy: 0.9158 - val_loss: 0.3695 - val_accuracy: 0.8405\n",
      "Epoch 3/100\n",
      "380/380 [==============================] - 0s 102us/step - loss: 0.2050 - accuracy: 0.9184 - val_loss: 0.3856 - val_accuracy: 0.8282\n",
      "Epoch 4/100\n",
      "380/380 [==============================] - 0s 72us/step - loss: 0.2001 - accuracy: 0.9263 - val_loss: 0.3812 - val_accuracy: 0.8221\n",
      "Epoch 5/100\n",
      "380/380 [==============================] - 0s 70us/step - loss: 0.1888 - accuracy: 0.9211 - val_loss: 0.3737 - val_accuracy: 0.8282\n",
      "Epoch 6/100\n",
      "380/380 [==============================] - 0s 75us/step - loss: 0.1957 - accuracy: 0.9263 - val_loss: 0.3579 - val_accuracy: 0.8282\n",
      "Epoch 7/100\n",
      "380/380 [==============================] - 0s 68us/step - loss: 0.2014 - accuracy: 0.9184 - val_loss: 0.3362 - val_accuracy: 0.8528\n",
      "Epoch 8/100\n",
      "380/380 [==============================] - 0s 76us/step - loss: 0.2012 - accuracy: 0.9237 - val_loss: 0.4328 - val_accuracy: 0.8221\n",
      "Epoch 9/100\n",
      "380/380 [==============================] - 0s 68us/step - loss: 0.1852 - accuracy: 0.9263 - val_loss: 0.3578 - val_accuracy: 0.8344\n",
      "Epoch 10/100\n",
      "380/380 [==============================] - 0s 65us/step - loss: 0.1855 - accuracy: 0.9289 - val_loss: 0.3862 - val_accuracy: 0.8160\n",
      "Epoch 11/100\n",
      "380/380 [==============================] - 0s 73us/step - loss: 0.1886 - accuracy: 0.9263 - val_loss: 0.3664 - val_accuracy: 0.8221\n",
      "Epoch 12/100\n",
      "380/380 [==============================] - 0s 66us/step - loss: 0.1888 - accuracy: 0.9263 - val_loss: 0.4399 - val_accuracy: 0.8160\n",
      "Epoch 13/100\n",
      "380/380 [==============================] - ETA: 0s - loss: 0.1796 - accuracy: 0.92 - 0s 70us/step - loss: 0.2018 - accuracy: 0.9263 - val_loss: 0.3616 - val_accuracy: 0.8405\n",
      "Epoch 14/100\n",
      "380/380 [==============================] - 0s 69us/step - loss: 0.1902 - accuracy: 0.9237 - val_loss: 0.4008 - val_accuracy: 0.8221\n",
      "Epoch 15/100\n",
      "380/380 [==============================] - 0s 71us/step - loss: 0.1883 - accuracy: 0.9237 - val_loss: 0.3582 - val_accuracy: 0.8405\n",
      "Epoch 16/100\n",
      "380/380 [==============================] - 0s 88us/step - loss: 0.1824 - accuracy: 0.9263 - val_loss: 0.3493 - val_accuracy: 0.8466\n",
      "Epoch 17/100\n",
      "380/380 [==============================] - 0s 69us/step - loss: 0.1850 - accuracy: 0.9263 - val_loss: 0.4270 - val_accuracy: 0.8221\n",
      "Epoch 18/100\n",
      "380/380 [==============================] - 0s 70us/step - loss: 0.1967 - accuracy: 0.9211 - val_loss: 0.3365 - val_accuracy: 0.8466\n",
      "Epoch 19/100\n",
      "380/380 [==============================] - 0s 71us/step - loss: 0.1994 - accuracy: 0.9184 - val_loss: 0.4388 - val_accuracy: 0.8160\n",
      "Epoch 20/100\n",
      "380/380 [==============================] - 0s 70us/step - loss: 0.1857 - accuracy: 0.9237 - val_loss: 0.3281 - val_accuracy: 0.8589\n",
      "Epoch 21/100\n",
      "380/380 [==============================] - 0s 71us/step - loss: 0.2032 - accuracy: 0.9158 - val_loss: 0.5143 - val_accuracy: 0.7914\n",
      "Epoch 22/100\n",
      "380/380 [==============================] - 0s 70us/step - loss: 0.1852 - accuracy: 0.9053 - val_loss: 0.3500 - val_accuracy: 0.8344\n",
      "Epoch 23/100\n",
      "380/380 [==============================] - 0s 73us/step - loss: 0.2125 - accuracy: 0.9132 - val_loss: 0.5561 - val_accuracy: 0.7730\n",
      "Epoch 24/100\n",
      "380/380 [==============================] - 0s 63us/step - loss: 0.2029 - accuracy: 0.9053 - val_loss: 0.3333 - val_accuracy: 0.8589\n",
      "Epoch 25/100\n",
      "380/380 [==============================] - 0s 64us/step - loss: 0.2124 - accuracy: 0.9158 - val_loss: 0.4295 - val_accuracy: 0.8098\n",
      "Epoch 26/100\n",
      "380/380 [==============================] - 0s 74us/step - loss: 0.2091 - accuracy: 0.9184 - val_loss: 0.3719 - val_accuracy: 0.8344\n",
      "Epoch 27/100\n",
      "380/380 [==============================] - 0s 75us/step - loss: 0.1944 - accuracy: 0.9289 - val_loss: 0.3821 - val_accuracy: 0.8282\n",
      "Epoch 28/100\n",
      "380/380 [==============================] - 0s 72us/step - loss: 0.1837 - accuracy: 0.9289 - val_loss: 0.3437 - val_accuracy: 0.8405\n",
      "Epoch 29/100\n",
      "380/380 [==============================] - 0s 81us/step - loss: 0.1835 - accuracy: 0.9289 - val_loss: 0.3491 - val_accuracy: 0.8282\n",
      "Epoch 30/100\n",
      "380/380 [==============================] - 0s 79us/step - loss: 0.1901 - accuracy: 0.9132 - val_loss: 0.3694 - val_accuracy: 0.8344\n",
      "Epoch 31/100\n",
      "380/380 [==============================] - 0s 87us/step - loss: 0.1905 - accuracy: 0.9184 - val_loss: 0.3684 - val_accuracy: 0.8344\n",
      "Epoch 32/100\n",
      "380/380 [==============================] - 0s 72us/step - loss: 0.1850 - accuracy: 0.9263 - val_loss: 0.4353 - val_accuracy: 0.8221\n",
      "Epoch 33/100\n",
      "380/380 [==============================] - 0s 102us/step - loss: 0.2018 - accuracy: 0.9105 - val_loss: 0.3519 - val_accuracy: 0.8405\n",
      "Epoch 34/100\n",
      "380/380 [==============================] - 0s 67us/step - loss: 0.1858 - accuracy: 0.9211 - val_loss: 0.5045 - val_accuracy: 0.7914\n",
      "Epoch 35/100\n",
      "380/380 [==============================] - 0s 67us/step - loss: 0.1789 - accuracy: 0.9237 - val_loss: 0.3411 - val_accuracy: 0.8589\n",
      "Epoch 36/100\n",
      "380/380 [==============================] - 0s 84us/step - loss: 0.2086 - accuracy: 0.9158 - val_loss: 0.4538 - val_accuracy: 0.8098\n",
      "Epoch 37/100\n",
      "380/380 [==============================] - 0s 64us/step - loss: 0.1824 - accuracy: 0.9237 - val_loss: 0.3488 - val_accuracy: 0.8344\n",
      "Epoch 38/100\n",
      "380/380 [==============================] - 0s 75us/step - loss: 0.1854 - accuracy: 0.9158 - val_loss: 0.4032 - val_accuracy: 0.8221\n",
      "Epoch 39/100\n",
      "380/380 [==============================] - 0s 71us/step - loss: 0.1782 - accuracy: 0.9211 - val_loss: 0.3595 - val_accuracy: 0.8344\n",
      "Epoch 40/100\n",
      "380/380 [==============================] - 0s 56us/step - loss: 0.1712 - accuracy: 0.9289 - val_loss: 0.4154 - val_accuracy: 0.8221\n",
      "Epoch 41/100\n",
      "380/380 [==============================] - 0s 62us/step - loss: 0.1842 - accuracy: 0.9237 - val_loss: 0.3441 - val_accuracy: 0.8344\n",
      "Epoch 42/100\n",
      "380/380 [==============================] - 0s 59us/step - loss: 0.1744 - accuracy: 0.9289 - val_loss: 0.3950 - val_accuracy: 0.8221\n",
      "Epoch 43/100\n",
      "380/380 [==============================] - 0s 61us/step - loss: 0.1892 - accuracy: 0.9211 - val_loss: 0.4365 - val_accuracy: 0.8160\n",
      "Epoch 44/100\n",
      "380/380 [==============================] - 0s 58us/step - loss: 0.1856 - accuracy: 0.9211 - val_loss: 0.3626 - val_accuracy: 0.8344\n",
      "Epoch 45/100\n",
      "380/380 [==============================] - 0s 59us/step - loss: 0.1987 - accuracy: 0.9211 - val_loss: 0.4641 - val_accuracy: 0.7975\n",
      "Epoch 46/100\n",
      "380/380 [==============================] - 0s 59us/step - loss: 0.1951 - accuracy: 0.9158 - val_loss: 0.3268 - val_accuracy: 0.8589\n",
      "Epoch 47/100\n",
      "380/380 [==============================] - 0s 58us/step - loss: 0.1994 - accuracy: 0.9158 - val_loss: 0.5006 - val_accuracy: 0.7975\n",
      "Epoch 48/100\n",
      "380/380 [==============================] - 0s 59us/step - loss: 0.2035 - accuracy: 0.9184 - val_loss: 0.3737 - val_accuracy: 0.8344\n",
      "Epoch 49/100\n",
      "380/380 [==============================] - 0s 57us/step - loss: 0.1739 - accuracy: 0.9289 - val_loss: 0.4592 - val_accuracy: 0.8160\n",
      "Epoch 50/100\n",
      "380/380 [==============================] - 0s 62us/step - loss: 0.1795 - accuracy: 0.9263 - val_loss: 0.3432 - val_accuracy: 0.8344\n",
      "Epoch 51/100\n",
      "380/380 [==============================] - 0s 67us/step - loss: 0.1798 - accuracy: 0.9263 - val_loss: 0.3483 - val_accuracy: 0.8344\n",
      "Epoch 52/100\n",
      "380/380 [==============================] - 0s 68us/step - loss: 0.1687 - accuracy: 0.9289 - val_loss: 0.3474 - val_accuracy: 0.8405\n",
      "Epoch 53/100\n",
      "380/380 [==============================] - 0s 63us/step - loss: 0.1779 - accuracy: 0.9289 - val_loss: 0.3678 - val_accuracy: 0.8344\n",
      "Epoch 54/100\n",
      "380/380 [==============================] - 0s 83us/step - loss: 0.1750 - accuracy: 0.9184 - val_loss: 0.3343 - val_accuracy: 0.8466\n",
      "Epoch 55/100\n",
      "380/380 [==============================] - 0s 189us/step - loss: 0.1789 - accuracy: 0.9211 - val_loss: 0.4017 - val_accuracy: 0.8282\n",
      "Epoch 56/100\n",
      "380/380 [==============================] - 0s 147us/step - loss: 0.1704 - accuracy: 0.9289 - val_loss: 0.3656 - val_accuracy: 0.8344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "380/380 [==============================] - 0s 125us/step - loss: 0.1653 - accuracy: 0.9289 - val_loss: 0.3880 - val_accuracy: 0.8282\n",
      "Epoch 58/100\n",
      "380/380 [==============================] - 0s 114us/step - loss: 0.1674 - accuracy: 0.9289 - val_loss: 0.3485 - val_accuracy: 0.8344\n",
      "Epoch 59/100\n",
      "380/380 [==============================] - 0s 87us/step - loss: 0.1740 - accuracy: 0.9289 - val_loss: 0.3870 - val_accuracy: 0.8282\n",
      "Epoch 60/100\n",
      "380/380 [==============================] - 0s 117us/step - loss: 0.1797 - accuracy: 0.9263 - val_loss: 0.3708 - val_accuracy: 0.8344\n",
      "Epoch 61/100\n",
      "380/380 [==============================] - 0s 89us/step - loss: 0.1767 - accuracy: 0.9263 - val_loss: 0.3672 - val_accuracy: 0.8344\n",
      "Epoch 62/100\n",
      "380/380 [==============================] - 0s 112us/step - loss: 0.1800 - accuracy: 0.9211 - val_loss: 0.3672 - val_accuracy: 0.8282\n",
      "Epoch 63/100\n",
      "380/380 [==============================] - 0s 96us/step - loss: 0.1688 - accuracy: 0.9263 - val_loss: 0.3678 - val_accuracy: 0.8344\n",
      "Epoch 64/100\n",
      "380/380 [==============================] - 0s 85us/step - loss: 0.1628 - accuracy: 0.9289 - val_loss: 0.3311 - val_accuracy: 0.8528\n",
      "Epoch 65/100\n",
      "380/380 [==============================] - 0s 92us/step - loss: 0.1651 - accuracy: 0.9211 - val_loss: 0.4011 - val_accuracy: 0.8221\n",
      "Epoch 66/100\n",
      "380/380 [==============================] - 0s 105us/step - loss: 0.1663 - accuracy: 0.9184 - val_loss: 0.3247 - val_accuracy: 0.8466\n",
      "Epoch 67/100\n",
      "380/380 [==============================] - 0s 184us/step - loss: 0.1740 - accuracy: 0.9237 - val_loss: 0.4150 - val_accuracy: 0.8282\n",
      "Epoch 68/100\n",
      "380/380 [==============================] - 0s 398us/step - loss: 0.1743 - accuracy: 0.9237 - val_loss: 0.4013 - val_accuracy: 0.8344\n",
      "Epoch 69/100\n",
      "380/380 [==============================] - 0s 107us/step - loss: 0.1758 - accuracy: 0.9237 - val_loss: 0.3321 - val_accuracy: 0.8466\n",
      "Epoch 70/100\n",
      "380/380 [==============================] - 0s 165us/step - loss: 0.1857 - accuracy: 0.9158 - val_loss: 0.4285 - val_accuracy: 0.8344\n",
      "Epoch 71/100\n",
      "380/380 [==============================] - 0s 140us/step - loss: 0.1800 - accuracy: 0.9158 - val_loss: 0.3533 - val_accuracy: 0.8405\n",
      "Epoch 72/100\n",
      "380/380 [==============================] - 0s 86us/step - loss: 0.1721 - accuracy: 0.9237 - val_loss: 0.3655 - val_accuracy: 0.8344\n",
      "Epoch 73/100\n",
      "380/380 [==============================] - 0s 79us/step - loss: 0.1655 - accuracy: 0.9289 - val_loss: 0.3758 - val_accuracy: 0.8344\n",
      "Epoch 74/100\n",
      "380/380 [==============================] - 0s 72us/step - loss: 0.1738 - accuracy: 0.9211 - val_loss: 0.3479 - val_accuracy: 0.8405\n",
      "Epoch 75/100\n",
      "380/380 [==============================] - 0s 64us/step - loss: 0.1792 - accuracy: 0.9184 - val_loss: 0.3899 - val_accuracy: 0.8282\n",
      "Epoch 76/100\n",
      "380/380 [==============================] - 0s 74us/step - loss: 0.1650 - accuracy: 0.9263 - val_loss: 0.3738 - val_accuracy: 0.8405\n",
      "Epoch 77/100\n",
      "380/380 [==============================] - 0s 63us/step - loss: 0.1724 - accuracy: 0.9316 - val_loss: 0.3281 - val_accuracy: 0.8589\n",
      "Epoch 78/100\n",
      "380/380 [==============================] - 0s 71us/step - loss: 0.1789 - accuracy: 0.9184 - val_loss: 0.4307 - val_accuracy: 0.8221\n",
      "Epoch 79/100\n",
      "380/380 [==============================] - 0s 327us/step - loss: 0.1639 - accuracy: 0.9316 - val_loss: 0.3556 - val_accuracy: 0.8344\n",
      "Epoch 80/100\n",
      "380/380 [==============================] - 0s 134us/step - loss: 0.1638 - accuracy: 0.9316 - val_loss: 0.4455 - val_accuracy: 0.8160\n",
      "Epoch 81/100\n",
      "380/380 [==============================] - 0s 93us/step - loss: 0.1772 - accuracy: 0.9237 - val_loss: 0.3527 - val_accuracy: 0.8344\n",
      "Epoch 82/100\n",
      "380/380 [==============================] - 0s 122us/step - loss: 0.1830 - accuracy: 0.9211 - val_loss: 0.3392 - val_accuracy: 0.8466\n",
      "Epoch 83/100\n",
      "380/380 [==============================] - 0s 200us/step - loss: 0.2063 - accuracy: 0.9184 - val_loss: 0.4741 - val_accuracy: 0.7914\n",
      "Epoch 84/100\n",
      "380/380 [==============================] - 0s 84us/step - loss: 0.1999 - accuracy: 0.9105 - val_loss: 0.3398 - val_accuracy: 0.8405\n",
      "Epoch 85/100\n",
      "380/380 [==============================] - 0s 88us/step - loss: 0.1724 - accuracy: 0.9316 - val_loss: 0.4430 - val_accuracy: 0.8221\n",
      "Epoch 86/100\n",
      "380/380 [==============================] - 0s 89us/step - loss: 0.1669 - accuracy: 0.9316 - val_loss: 0.3555 - val_accuracy: 0.8344\n",
      "Epoch 87/100\n",
      "380/380 [==============================] - 0s 80us/step - loss: 0.1653 - accuracy: 0.9289 - val_loss: 0.3845 - val_accuracy: 0.8344\n",
      "Epoch 88/100\n",
      "380/380 [==============================] - 0s 64us/step - loss: 0.1685 - accuracy: 0.9316 - val_loss: 0.4049 - val_accuracy: 0.8344\n",
      "Epoch 89/100\n",
      "380/380 [==============================] - 0s 72us/step - loss: 0.1719 - accuracy: 0.9289 - val_loss: 0.3526 - val_accuracy: 0.8405\n",
      "Epoch 90/100\n",
      "380/380 [==============================] - 0s 68us/step - loss: 0.1742 - accuracy: 0.9316 - val_loss: 0.3973 - val_accuracy: 0.8282\n",
      "Epoch 91/100\n",
      "380/380 [==============================] - 0s 68us/step - loss: 0.1798 - accuracy: 0.9289 - val_loss: 0.3917 - val_accuracy: 0.8344\n",
      "Epoch 92/100\n",
      "380/380 [==============================] - 0s 72us/step - loss: 0.1989 - accuracy: 0.9079 - val_loss: 0.3527 - val_accuracy: 0.8405\n",
      "Epoch 93/100\n",
      "380/380 [==============================] - 0s 65us/step - loss: 0.1890 - accuracy: 0.9158 - val_loss: 0.5376 - val_accuracy: 0.7853\n",
      "Epoch 94/100\n",
      "380/380 [==============================] - 0s 61us/step - loss: 0.2048 - accuracy: 0.9132 - val_loss: 0.3605 - val_accuracy: 0.8344\n",
      "Epoch 95/100\n",
      "380/380 [==============================] - 0s 75us/step - loss: 0.1911 - accuracy: 0.9289 - val_loss: 0.4544 - val_accuracy: 0.7914\n",
      "Epoch 96/100\n",
      "380/380 [==============================] - 0s 64us/step - loss: 0.1798 - accuracy: 0.9237 - val_loss: 0.3436 - val_accuracy: 0.8405\n",
      "Epoch 97/100\n",
      "380/380 [==============================] - 0s 65us/step - loss: 0.1697 - accuracy: 0.9316 - val_loss: 0.3714 - val_accuracy: 0.8405\n",
      "Epoch 98/100\n",
      "380/380 [==============================] - 0s 78us/step - loss: 0.1723 - accuracy: 0.9263 - val_loss: 0.3682 - val_accuracy: 0.8405\n",
      "Epoch 99/100\n",
      "380/380 [==============================] - 0s 71us/step - loss: 0.1723 - accuracy: 0.9289 - val_loss: 0.3312 - val_accuracy: 0.8466\n",
      "Epoch 100/100\n",
      "380/380 [==============================] - 0s 157us/step - loss: 0.1824 - accuracy: 0.9184 - val_loss: 0.3835 - val_accuracy: 0.8466\n"
     ]
    }
   ],
   "source": [
    "hist2_over = model2_over.fit(X_sel_train_over, y_sel_train_over,\n",
    "          batch_size=64, epochs=100,\n",
    "          validation_data=(X_sel_test_over, y_sel_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 92.29%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist2_over.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba5 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_lasso_2.xlsx\",\n",
    "                        sheet_name=0,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>NRS245</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.345807e-02</td>\n",
       "      <td>2.164788e-01</td>\n",
       "      <td>7.700630e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>NY439</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.674153e-02</td>\n",
       "      <td>9.294230e-04</td>\n",
       "      <td>9.723290e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>CA544</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.147484e-01</td>\n",
       "      <td>3.626331e-01</td>\n",
       "      <td>2.226184e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>CA541</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4.147484e-01</td>\n",
       "      <td>3.626331e-01</td>\n",
       "      <td>2.226184e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>EUH15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.147484e-01</td>\n",
       "      <td>3.626331e-01</td>\n",
       "      <td>2.226184e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>CA541</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.723218e-01</td>\n",
       "      <td>6.276781e-01</td>\n",
       "      <td>1.945911e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>SR4152</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.372800e-01</td>\n",
       "      <td>2.627200e-01</td>\n",
       "      <td>4.197748e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>NRS110</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4.194510e-08</td>\n",
       "      <td>7.508231e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>CFBRSa70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.372800e-01</td>\n",
       "      <td>2.627200e-01</td>\n",
       "      <td>4.197748e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>NRS021</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.943684e-01</td>\n",
       "      <td>6.056316e-01</td>\n",
       "      <td>2.843107e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>989 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   phage    strain  phenotype  prediction             0  \\\n",
       "0     p0006kpresabs_qual    NRS245          1           2  1.345807e-02   \n",
       "1     p0006kpresabs_qual     NY439          2           2  2.674153e-02   \n",
       "2     p0006kpresabs_qual     CA544          1           0  4.147484e-01   \n",
       "3     p0006kpresabs_qual     CA541          2           0  4.147484e-01   \n",
       "4     p0006kpresabs_qual     EUH15          1           0  4.147484e-01   \n",
       "..                   ...       ...        ...         ...           ...   \n",
       "984  p0017Skpresabs_qual     CA541          1           1  3.723218e-01   \n",
       "985  p0017Skpresabs_qual    SR4152          1           0  7.372800e-01   \n",
       "986  p0017Skpresabs_qual    NRS110          2           2  4.194510e-08   \n",
       "987  p0017Skpresabs_qual  CFBRSa70          0           0  7.372800e-01   \n",
       "988  p0017Skpresabs_qual    NRS021          0           1  3.943684e-01   \n",
       "\n",
       "                1             2  \n",
       "0    2.164788e-01  7.700630e-01  \n",
       "1    9.294230e-04  9.723290e-01  \n",
       "2    3.626331e-01  2.226184e-01  \n",
       "3    3.626331e-01  2.226184e-01  \n",
       "4    3.626331e-01  2.226184e-01  \n",
       "..            ...           ...  \n",
       "984  6.276781e-01  1.945911e-08  \n",
       "985  2.627200e-01  4.197748e-08  \n",
       "986  7.508231e-09  1.000000e+00  \n",
       "987  2.627200e-01  4.197748e-08  \n",
       "988  6.056316e-01  2.843107e-08  \n",
       "\n",
       "[989 rows x 7 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.11915480e-01, 4.69524650e-01, 1.18559930e-01],\n",
       "       [1.85266310e-04, 9.52110300e-03, 9.90293600e-01],\n",
       "       [3.60156920e-05, 8.63503800e-01, 1.36460160e-01],\n",
       "       [4.47145980e-05, 1.55991150e-04, 9.99799300e-01],\n",
       "       [9.73128600e-01, 3.57974520e-04, 2.65133900e-02],\n",
       "       [2.07474390e-06, 9.99939440e-01, 5.85182750e-05],\n",
       "       [4.47925930e-03, 6.53110300e-01, 3.42410360e-01],\n",
       "       [8.66245200e-06, 7.00983870e-03, 9.92981430e-01],\n",
       "       [9.93974600e-01, 4.42929500e-03, 1.59612850e-03],\n",
       "       [8.00493540e-01, 5.56601730e-02, 1.43846350e-01],\n",
       "       [8.58791900e-06, 9.76473100e-01, 2.35182720e-02],\n",
       "       [4.17082200e-05, 9.99937800e-01, 2.04926220e-05],\n",
       "       [4.11915480e-01, 4.69524650e-01, 1.18559930e-01],\n",
       "       [1.82089920e-01, 7.36610100e-01, 8.12999400e-02],\n",
       "       [9.97834600e-01, 2.91613160e-04, 1.87375400e-03],\n",
       "       [6.53518140e-01, 2.28519260e-01, 1.17962636e-01],\n",
       "       [4.75453040e-04, 9.98560850e-01, 9.63785100e-04],\n",
       "       [6.61089600e-01, 2.46374680e-05, 3.38885750e-01],\n",
       "       [1.33086130e-04, 4.60417980e-02, 9.53825200e-01],\n",
       "       [1.24341674e-01, 1.29851930e-02, 8.62673160e-01],\n",
       "       [4.11915480e-01, 4.69524650e-01, 1.18559930e-01],\n",
       "       [1.82089920e-01, 7.36610100e-01, 8.12999400e-02],\n",
       "       [9.98167630e-01, 1.26418690e-04, 1.70594600e-03],\n",
       "       [2.04154770e-04, 1.03302070e-02, 9.89465700e-01],\n",
       "       [9.92799900e-01, 4.71943840e-04, 6.72818530e-03],\n",
       "       [4.11915480e-01, 4.69524650e-01, 1.18559930e-01],\n",
       "       [5.23369350e-02, 2.03425900e-01, 7.44237100e-01],\n",
       "       [4.92544600e-06, 9.99678000e-01, 3.17123340e-04],\n",
       "       [9.96627500e-01, 2.05366220e-03, 1.31879920e-03],\n",
       "       [3.96703540e-01, 1.37103470e-01, 4.66193020e-01],\n",
       "       [1.13238010e-05, 1.57707430e-02, 9.84218000e-01],\n",
       "       [9.91213860e-01, 1.72375970e-03, 7.06244170e-03],\n",
       "       [4.62726900e-07, 9.94612340e-01, 5.38722470e-03],\n",
       "       [9.94024100e-01, 3.54569310e-03, 2.43030350e-03],\n",
       "       [4.38607860e-03, 9.52158330e-01, 4.34555820e-02],\n",
       "       [9.58761960e-08, 9.94728270e-01, 5.27157730e-03],\n",
       "       [1.06337060e-01, 8.62169740e-01, 3.14932470e-02],\n",
       "       [9.92799900e-01, 4.71943840e-04, 6.72818530e-03],\n",
       "       [4.62726900e-07, 9.94612340e-01, 5.38722470e-03],\n",
       "       [7.40007600e-02, 3.66592260e-01, 5.59407000e-01],\n",
       "       [5.16189400e-02, 1.22737800e-02, 9.36107300e-01],\n",
       "       [5.30633800e-02, 2.44684760e-01, 7.02251900e-01],\n",
       "       [2.18934060e-01, 1.44985590e-01, 6.36080400e-01],\n",
       "       [4.46096700e-06, 9.98684470e-01, 1.31106940e-03],\n",
       "       [9.99499560e-01, 1.96956000e-05, 4.80824200e-04],\n",
       "       [4.33929800e-04, 5.85037050e-01, 4.14528970e-01],\n",
       "       [2.07474390e-06, 9.99939440e-01, 5.85182750e-05],\n",
       "       [9.90256000e-01, 5.19146780e-05, 9.69209600e-03],\n",
       "       [3.33818700e-04, 9.98820840e-01, 8.45275640e-04],\n",
       "       [5.62325900e-05, 7.82184400e-04, 9.99161600e-01],\n",
       "       [4.17082200e-05, 9.99937800e-01, 2.04926220e-05],\n",
       "       [2.85019000e-04, 5.86594760e-05, 9.99656300e-01],\n",
       "       [9.73128600e-01, 3.57974520e-04, 2.65133900e-02],\n",
       "       [1.11095320e-01, 6.80095900e-01, 2.08808660e-01],\n",
       "       [6.44946050e-03, 9.81863200e-01, 1.16874340e-02],\n",
       "       [6.35854200e-05, 9.09309900e-01, 9.06264200e-02],\n",
       "       [6.53518140e-01, 2.28519260e-01, 1.17962636e-01],\n",
       "       [9.91296300e-01, 7.64013870e-03, 1.06353760e-03],\n",
       "       [9.96810000e-01, 1.48356060e-04, 3.04170530e-03],\n",
       "       [9.96810000e-01, 1.48356060e-04, 3.04170530e-03],\n",
       "       [4.11915480e-01, 4.69524650e-01, 1.18559930e-01],\n",
       "       [1.18625320e-03, 9.80931000e-01, 1.78827460e-02],\n",
       "       [7.40007600e-02, 3.66592260e-01, 5.59407000e-01],\n",
       "       [2.52141120e-04, 4.06154730e-02, 9.59132400e-01],\n",
       "       [2.40906480e-08, 9.89823760e-01, 1.01762740e-02],\n",
       "       [4.86448050e-01, 4.93778060e-03, 5.08614200e-01],\n",
       "       [1.82089920e-01, 7.36610100e-01, 8.12999400e-02],\n",
       "       [6.53518140e-01, 2.28519260e-01, 1.17962636e-01],\n",
       "       [2.23106120e-01, 4.44082300e-03, 7.72453070e-01],\n",
       "       [1.27732180e-05, 9.98655200e-01, 1.33199480e-03],\n",
       "       [5.08572800e-03, 8.77935100e-03, 9.86134950e-01],\n",
       "       [9.27785100e-01, 5.22571400e-03, 6.69891700e-02],\n",
       "       [9.74991500e-04, 6.94126700e-05, 9.98955600e-01],\n",
       "       [9.74449900e-01, 5.53677050e-05, 2.54947710e-02],\n",
       "       [9.91213860e-01, 1.72375970e-03, 7.06244170e-03],\n",
       "       [5.71483200e-06, 9.60859300e-01, 3.91349570e-02],\n",
       "       [7.40007600e-02, 3.66592260e-01, 5.59407000e-01],\n",
       "       [9.44679860e-01, 1.37802360e-04, 5.51822370e-02],\n",
       "       [9.98167630e-01, 1.26418690e-04, 1.70594600e-03],\n",
       "       [9.91296300e-01, 7.64013870e-03, 1.06353760e-03],\n",
       "       [9.74449900e-01, 5.53677050e-05, 2.54947710e-02],\n",
       "       [9.73128600e-01, 3.57974520e-04, 2.65133900e-02],\n",
       "       [5.44792670e-02, 7.79227700e-02, 8.67597900e-01],\n",
       "       [6.44946050e-03, 9.81863200e-01, 1.16874340e-02],\n",
       "       [3.78602050e-05, 9.97492200e-01, 2.46999530e-03],\n",
       "       [8.00493540e-01, 5.56601730e-02, 1.43846350e-01],\n",
       "       [8.58791900e-06, 9.76473100e-01, 2.35182720e-02],\n",
       "       [9.91213860e-01, 1.72375970e-03, 7.06244170e-03],\n",
       "       [9.92483900e-01, 4.10462960e-03, 3.41147800e-03],\n",
       "       [1.13791850e-04, 9.93017800e-01, 6.86845930e-03],\n",
       "       [1.09370210e-02, 2.75677900e-03, 9.86306200e-01],\n",
       "       [8.96784100e-03, 9.69298840e-01, 2.17333140e-02],\n",
       "       [1.18625320e-03, 9.80931000e-01, 1.78827460e-02],\n",
       "       [1.82089920e-01, 7.36610100e-01, 8.12999400e-02],\n",
       "       [7.40007600e-02, 3.66592260e-01, 5.59407000e-01],\n",
       "       [6.49847960e-04, 9.50358460e-04, 9.98399800e-01],\n",
       "       [9.44679860e-01, 1.37802360e-04, 5.51822370e-02],\n",
       "       [4.38607860e-03, 9.52158330e-01, 4.34555820e-02],\n",
       "       [9.90256000e-01, 5.19146780e-05, 9.69209600e-03],\n",
       "       [9.90256000e-01, 5.19146780e-05, 9.69209600e-03],\n",
       "       [1.82089920e-01, 7.36610100e-01, 8.12999400e-02],\n",
       "       [1.82089920e-01, 7.36610100e-01, 8.12999400e-02],\n",
       "       [1.82089920e-01, 7.36610100e-01, 8.12999400e-02],\n",
       "       [9.97834600e-01, 2.91613160e-04, 1.87375400e-03],\n",
       "       [2.97377530e-04, 2.93969480e-03, 9.96762900e-01],\n",
       "       [1.82089920e-01, 7.36610100e-01, 8.12999400e-02],\n",
       "       [5.64195030e-02, 1.16285720e-01, 8.27294700e-01],\n",
       "       [1.32457770e-07, 9.99731840e-01, 2.68042380e-04],\n",
       "       [9.58761960e-08, 9.94728270e-01, 5.27157730e-03],\n",
       "       [2.57602500e-05, 8.06679900e-02, 9.19306300e-01],\n",
       "       [4.38607860e-03, 9.52158330e-01, 4.34555820e-02],\n",
       "       [9.94024100e-01, 3.54569310e-03, 2.43030350e-03],\n",
       "       [3.50314050e-03, 2.04084870e-02, 9.76088400e-01],\n",
       "       [1.82089920e-01, 7.36610100e-01, 8.12999400e-02],\n",
       "       [5.59920800e-03, 6.27563240e-01, 3.66837530e-01],\n",
       "       [9.90256000e-01, 5.19146780e-05, 9.69209600e-03],\n",
       "       [9.96810000e-01, 1.48356060e-04, 3.04170530e-03],\n",
       "       [2.40906480e-08, 9.89823760e-01, 1.01762740e-02],\n",
       "       [2.87426740e-01, 6.12189900e-01, 1.00383360e-01],\n",
       "       [1.86270730e-03, 2.35625240e-02, 9.74574700e-01],\n",
       "       [1.01589390e-04, 9.81643500e-01, 1.82549230e-02],\n",
       "       [9.92483900e-01, 4.10462960e-03, 3.41147800e-03],\n",
       "       [3.43351550e-02, 5.58847840e-01, 4.06817020e-01],\n",
       "       [9.92799900e-01, 4.71943840e-04, 6.72818530e-03],\n",
       "       [9.97834600e-01, 2.91613160e-04, 1.87375400e-03],\n",
       "       [4.11915480e-01, 4.69524650e-01, 1.18559930e-01],\n",
       "       [2.47812670e-01, 5.73912150e-02, 6.94796140e-01],\n",
       "       [9.80985700e-01, 9.65844000e-05, 1.89176970e-02],\n",
       "       [9.10562700e-02, 1.08521690e-01, 8.00422100e-01],\n",
       "       [1.06337060e-01, 8.62169740e-01, 3.14932470e-02],\n",
       "       [1.82089920e-01, 7.36610100e-01, 8.12999400e-02],\n",
       "       [2.24624500e-01, 7.69743200e-02, 6.98401150e-01],\n",
       "       [4.22144660e-05, 9.29428500e-01, 7.05293000e-02],\n",
       "       [9.93974600e-01, 4.42929500e-03, 1.59612850e-03],\n",
       "       [3.96759570e-01, 3.56748370e-01, 2.46492070e-01],\n",
       "       [4.43596100e-04, 3.12937420e-03, 9.96427000e-01],\n",
       "       [3.33818700e-04, 9.98820840e-01, 8.45275640e-04],\n",
       "       [9.98167630e-01, 1.26418690e-04, 1.70594600e-03],\n",
       "       [9.97834600e-01, 2.91613160e-04, 1.87375400e-03],\n",
       "       [9.92483900e-01, 4.10462960e-03, 3.41147800e-03],\n",
       "       [9.96627500e-01, 2.05366220e-03, 1.31879920e-03],\n",
       "       [2.07474390e-06, 9.99939440e-01, 5.85182750e-05],\n",
       "       [3.85772370e-03, 5.27156050e-03, 9.90870650e-01],\n",
       "       [4.15290770e-01, 1.47991250e-01, 4.36717960e-01],\n",
       "       [4.11915480e-01, 4.69524650e-01, 1.18559930e-01],\n",
       "       [9.96223100e-01, 2.19248900e-03, 1.58436640e-03],\n",
       "       [6.47466000e-01, 8.53203100e-02, 2.67213670e-01],\n",
       "       [9.94024100e-01, 3.54569310e-03, 2.43030350e-03],\n",
       "       [1.13791850e-04, 9.93017800e-01, 6.86845930e-03],\n",
       "       [9.92799900e-01, 4.71943840e-04, 6.72818530e-03],\n",
       "       [8.00493540e-01, 5.56601730e-02, 1.43846350e-01],\n",
       "       [4.11915480e-01, 4.69524650e-01, 1.18559930e-01],\n",
       "       [1.13791850e-04, 9.93017800e-01, 6.86845930e-03],\n",
       "       [4.38607860e-03, 9.52158330e-01, 4.34555820e-02],\n",
       "       [9.16837300e-01, 3.78063900e-04, 8.27847050e-02],\n",
       "       [4.62726900e-07, 9.94612340e-01, 5.38722470e-03],\n",
       "       [9.90256000e-01, 5.19146780e-05, 9.69209600e-03],\n",
       "       [4.75453040e-04, 9.98560850e-01, 9.63785100e-04],\n",
       "       [9.96810000e-01, 1.48356060e-04, 3.04170530e-03],\n",
       "       [9.92483900e-01, 4.10462960e-03, 3.41147800e-03],\n",
       "       [2.62174870e-01, 4.61843800e-01, 2.75981300e-01],\n",
       "       [6.44946050e-03, 9.81863200e-01, 1.16874340e-02],\n",
       "       [9.97834600e-01, 2.91613160e-04, 1.87375400e-03]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob5 = df_proba5[df_proba5['phage']=='p11kpresabs_qual'].iloc[:,-3:]\n",
    "y_prob5 = y_prob5.to_numpy()\n",
    "y_prob5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9762062521236835"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo5 = rocauc_ovo(y_sel_test_over, y_prob5, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9762062521236835"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr5 = rocauc_ovr(y_sel_test_over, y_prob5, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_sel_train_over, X_sel_test_over, y_sel_train_over, y_sel_test_over = train_test_split(X_sel_over, y_sel_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=678,\n",
    "                                                    stratify=y_sel_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat6 = pd.DataFrame(X_sel_test_over[:,-1])\n",
    "dat6['test'] = y_sel_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GA48963</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SR4187</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS182</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CFBREBSa125</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS188</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>BCH-SA-05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>NRS027</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>CFBREBSa123</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>NRS199</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>Grady1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test\n",
       "0        GA48963     1\n",
       "1         SR4187     2\n",
       "2         NRS182     2\n",
       "3    CFBREBSa125     2\n",
       "4         NRS188     1\n",
       "..           ...   ...\n",
       "158    BCH-SA-05     0\n",
       "159       NRS027     0\n",
       "160  CFBREBSa123     0\n",
       "161       NRS199     2\n",
       "162       Grady1     2\n",
       "\n",
       "[163 rows x 2 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sel_train_over = X_sel_train_over[:,:-1]\n",
    "X_sel_test_over = X_sel_test_over[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2_over2 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_sel_train_over.shape[1],)),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2_over2.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 380 samples, validate on 163 samples\n",
      "Epoch 1/100\n",
      "380/380 [==============================] - 0s 315us/step - loss: 1.1623 - accuracy: 0.3737 - val_loss: 1.1773 - val_accuracy: 0.3313\n",
      "Epoch 2/100\n",
      "380/380 [==============================] - 0s 95us/step - loss: 1.0969 - accuracy: 0.4184 - val_loss: 1.0819 - val_accuracy: 0.4049\n",
      "Epoch 3/100\n",
      "380/380 [==============================] - 0s 61us/step - loss: 1.0238 - accuracy: 0.5000 - val_loss: 1.0314 - val_accuracy: 0.5276\n",
      "Epoch 4/100\n",
      "380/380 [==============================] - 0s 76us/step - loss: 0.9774 - accuracy: 0.5579 - val_loss: 1.0038 - val_accuracy: 0.4663\n",
      "Epoch 5/100\n",
      "380/380 [==============================] - 0s 100us/step - loss: 0.9556 - accuracy: 0.6184 - val_loss: 0.9948 - val_accuracy: 0.4908\n",
      "Epoch 6/100\n",
      "380/380 [==============================] - 0s 111us/step - loss: 0.9206 - accuracy: 0.6211 - val_loss: 0.9570 - val_accuracy: 0.5583\n",
      "Epoch 7/100\n",
      "380/380 [==============================] - 0s 95us/step - loss: 0.8817 - accuracy: 0.6421 - val_loss: 0.9526 - val_accuracy: 0.5399\n",
      "Epoch 8/100\n",
      "380/380 [==============================] - 0s 78us/step - loss: 0.8686 - accuracy: 0.6974 - val_loss: 0.9431 - val_accuracy: 0.5215\n",
      "Epoch 9/100\n",
      "380/380 [==============================] - 0s 84us/step - loss: 0.8389 - accuracy: 0.6763 - val_loss: 0.9035 - val_accuracy: 0.6074\n",
      "Epoch 10/100\n",
      "380/380 [==============================] - 0s 68us/step - loss: 0.8187 - accuracy: 0.7105 - val_loss: 0.9005 - val_accuracy: 0.5583\n",
      "Epoch 11/100\n",
      "380/380 [==============================] - 0s 64us/step - loss: 0.7920 - accuracy: 0.7132 - val_loss: 0.8794 - val_accuracy: 0.5951\n",
      "Epoch 12/100\n",
      "380/380 [==============================] - 0s 72us/step - loss: 0.7687 - accuracy: 0.7263 - val_loss: 0.8607 - val_accuracy: 0.5890\n",
      "Epoch 13/100\n",
      "380/380 [==============================] - 0s 58us/step - loss: 0.7508 - accuracy: 0.7237 - val_loss: 0.8461 - val_accuracy: 0.5890\n",
      "Epoch 14/100\n",
      "380/380 [==============================] - 0s 106us/step - loss: 0.7359 - accuracy: 0.7395 - val_loss: 0.8333 - val_accuracy: 0.6012\n",
      "Epoch 15/100\n",
      "380/380 [==============================] - 0s 63us/step - loss: 0.7137 - accuracy: 0.7447 - val_loss: 0.8152 - val_accuracy: 0.6503\n",
      "Epoch 16/100\n",
      "380/380 [==============================] - 0s 69us/step - loss: 0.6977 - accuracy: 0.7579 - val_loss: 0.8062 - val_accuracy: 0.6319\n",
      "Epoch 17/100\n",
      "380/380 [==============================] - 0s 100us/step - loss: 0.6868 - accuracy: 0.7553 - val_loss: 0.8007 - val_accuracy: 0.6258\n",
      "Epoch 18/100\n",
      "380/380 [==============================] - 0s 55us/step - loss: 0.6707 - accuracy: 0.7868 - val_loss: 0.7775 - val_accuracy: 0.6687\n",
      "Epoch 19/100\n",
      "380/380 [==============================] - 0s 64us/step - loss: 0.6506 - accuracy: 0.7816 - val_loss: 0.7753 - val_accuracy: 0.6503\n",
      "Epoch 20/100\n",
      "380/380 [==============================] - 0s 103us/step - loss: 0.6400 - accuracy: 0.7711 - val_loss: 0.7554 - val_accuracy: 0.6626\n",
      "Epoch 21/100\n",
      "380/380 [==============================] - 0s 94us/step - loss: 0.6243 - accuracy: 0.7737 - val_loss: 0.7455 - val_accuracy: 0.6687\n",
      "Epoch 22/100\n",
      "380/380 [==============================] - 0s 147us/step - loss: 0.6197 - accuracy: 0.7842 - val_loss: 0.7390 - val_accuracy: 0.6871\n",
      "Epoch 23/100\n",
      "380/380 [==============================] - 0s 134us/step - loss: 0.6098 - accuracy: 0.7605 - val_loss: 0.7219 - val_accuracy: 0.6810\n",
      "Epoch 24/100\n",
      "380/380 [==============================] - 0s 86us/step - loss: 0.5903 - accuracy: 0.7921 - val_loss: 0.7457 - val_accuracy: 0.6442\n",
      "Epoch 25/100\n",
      "380/380 [==============================] - 0s 91us/step - loss: 0.5840 - accuracy: 0.7816 - val_loss: 0.7044 - val_accuracy: 0.6994\n",
      "Epoch 26/100\n",
      "380/380 [==============================] - 0s 74us/step - loss: 0.5797 - accuracy: 0.7763 - val_loss: 0.6973 - val_accuracy: 0.6871\n",
      "Epoch 27/100\n",
      "380/380 [==============================] - 0s 81us/step - loss: 0.5567 - accuracy: 0.8026 - val_loss: 0.7065 - val_accuracy: 0.6933\n",
      "Epoch 28/100\n",
      "380/380 [==============================] - 0s 157us/step - loss: 0.5483 - accuracy: 0.8026 - val_loss: 0.6772 - val_accuracy: 0.7239\n",
      "Epoch 29/100\n",
      "380/380 [==============================] - 0s 150us/step - loss: 0.5380 - accuracy: 0.8289 - val_loss: 0.6822 - val_accuracy: 0.6933\n",
      "Epoch 30/100\n",
      "380/380 [==============================] - 0s 63us/step - loss: 0.5293 - accuracy: 0.8079 - val_loss: 0.6625 - val_accuracy: 0.7055\n",
      "Epoch 31/100\n",
      "380/380 [==============================] - 0s 95us/step - loss: 0.5180 - accuracy: 0.7947 - val_loss: 0.6647 - val_accuracy: 0.6994\n",
      "Epoch 32/100\n",
      "380/380 [==============================] - 0s 107us/step - loss: 0.5141 - accuracy: 0.8079 - val_loss: 0.6489 - val_accuracy: 0.7423\n",
      "Epoch 33/100\n",
      "380/380 [==============================] - 0s 255us/step - loss: 0.4968 - accuracy: 0.8316 - val_loss: 0.6436 - val_accuracy: 0.6933\n",
      "Epoch 34/100\n",
      "380/380 [==============================] - 0s 165us/step - loss: 0.4943 - accuracy: 0.7921 - val_loss: 0.6417 - val_accuracy: 0.7117\n",
      "Epoch 35/100\n",
      "380/380 [==============================] - 0s 179us/step - loss: 0.4838 - accuracy: 0.8289 - val_loss: 0.6282 - val_accuracy: 0.7301\n",
      "Epoch 36/100\n",
      "380/380 [==============================] - 0s 144us/step - loss: 0.4757 - accuracy: 0.8184 - val_loss: 0.6268 - val_accuracy: 0.7178\n",
      "Epoch 37/100\n",
      "380/380 [==============================] - 0s 161us/step - loss: 0.4680 - accuracy: 0.8211 - val_loss: 0.6172 - val_accuracy: 0.7423\n",
      "Epoch 38/100\n",
      "380/380 [==============================] - 0s 182us/step - loss: 0.4619 - accuracy: 0.8316 - val_loss: 0.6137 - val_accuracy: 0.7117\n",
      "Epoch 39/100\n",
      "380/380 [==============================] - 0s 106us/step - loss: 0.4525 - accuracy: 0.8237 - val_loss: 0.6042 - val_accuracy: 0.7669\n",
      "Epoch 40/100\n",
      "380/380 [==============================] - 0s 119us/step - loss: 0.4469 - accuracy: 0.8395 - val_loss: 0.6009 - val_accuracy: 0.7607\n",
      "Epoch 41/100\n",
      "380/380 [==============================] - 0s 70us/step - loss: 0.4407 - accuracy: 0.8342 - val_loss: 0.5917 - val_accuracy: 0.7485\n",
      "Epoch 42/100\n",
      "380/380 [==============================] - 0s 77us/step - loss: 0.4416 - accuracy: 0.8342 - val_loss: 0.6025 - val_accuracy: 0.7301\n",
      "Epoch 43/100\n",
      "380/380 [==============================] - 0s 91us/step - loss: 0.4384 - accuracy: 0.8368 - val_loss: 0.5847 - val_accuracy: 0.7546\n",
      "Epoch 44/100\n",
      "380/380 [==============================] - 0s 179us/step - loss: 0.4301 - accuracy: 0.8474 - val_loss: 0.5816 - val_accuracy: 0.7423\n",
      "Epoch 45/100\n",
      "380/380 [==============================] - 0s 62us/step - loss: 0.4244 - accuracy: 0.8474 - val_loss: 0.5801 - val_accuracy: 0.7730\n",
      "Epoch 46/100\n",
      "380/380 [==============================] - 0s 108us/step - loss: 0.4164 - accuracy: 0.8474 - val_loss: 0.5747 - val_accuracy: 0.7546\n",
      "Epoch 47/100\n",
      "380/380 [==============================] - 0s 77us/step - loss: 0.4098 - accuracy: 0.8605 - val_loss: 0.5629 - val_accuracy: 0.7669\n",
      "Epoch 48/100\n",
      "380/380 [==============================] - 0s 96us/step - loss: 0.4028 - accuracy: 0.8421 - val_loss: 0.5613 - val_accuracy: 0.7730\n",
      "Epoch 49/100\n",
      "380/380 [==============================] - 0s 97us/step - loss: 0.4000 - accuracy: 0.8526 - val_loss: 0.5584 - val_accuracy: 0.7730\n",
      "Epoch 50/100\n",
      "380/380 [==============================] - 0s 158us/step - loss: 0.3965 - accuracy: 0.8579 - val_loss: 0.5534 - val_accuracy: 0.7485\n",
      "Epoch 51/100\n",
      "380/380 [==============================] - 0s 119us/step - loss: 0.3861 - accuracy: 0.8474 - val_loss: 0.5489 - val_accuracy: 0.7730\n",
      "Epoch 52/100\n",
      "380/380 [==============================] - 0s 117us/step - loss: 0.3895 - accuracy: 0.8553 - val_loss: 0.5446 - val_accuracy: 0.7485\n",
      "Epoch 53/100\n",
      "380/380 [==============================] - 0s 117us/step - loss: 0.3804 - accuracy: 0.8474 - val_loss: 0.5374 - val_accuracy: 0.7975\n",
      "Epoch 54/100\n",
      "380/380 [==============================] - 0s 102us/step - loss: 0.3795 - accuracy: 0.8579 - val_loss: 0.5335 - val_accuracy: 0.7853\n",
      "Epoch 55/100\n",
      "380/380 [==============================] - 0s 74us/step - loss: 0.3761 - accuracy: 0.8605 - val_loss: 0.5304 - val_accuracy: 0.7853\n",
      "Epoch 56/100\n",
      "380/380 [==============================] - 0s 76us/step - loss: 0.3769 - accuracy: 0.8632 - val_loss: 0.5295 - val_accuracy: 0.7791\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "380/380 [==============================] - 0s 138us/step - loss: 0.3607 - accuracy: 0.8684 - val_loss: 0.5243 - val_accuracy: 0.7791\n",
      "Epoch 58/100\n",
      "380/380 [==============================] - 0s 121us/step - loss: 0.3602 - accuracy: 0.8579 - val_loss: 0.5192 - val_accuracy: 0.7975\n",
      "Epoch 59/100\n",
      "380/380 [==============================] - 0s 130us/step - loss: 0.3513 - accuracy: 0.8842 - val_loss: 0.5273 - val_accuracy: 0.7607\n",
      "Epoch 60/100\n",
      "380/380 [==============================] - 0s 120us/step - loss: 0.3525 - accuracy: 0.8789 - val_loss: 0.5182 - val_accuracy: 0.7730\n",
      "Epoch 61/100\n",
      "380/380 [==============================] - 0s 96us/step - loss: 0.3491 - accuracy: 0.8842 - val_loss: 0.5152 - val_accuracy: 0.7546\n",
      "Epoch 62/100\n",
      "380/380 [==============================] - 0s 80us/step - loss: 0.3462 - accuracy: 0.8684 - val_loss: 0.5048 - val_accuracy: 0.7914\n",
      "Epoch 63/100\n",
      "380/380 [==============================] - 0s 63us/step - loss: 0.3461 - accuracy: 0.8711 - val_loss: 0.5033 - val_accuracy: 0.7975\n",
      "Epoch 64/100\n",
      "380/380 [==============================] - 0s 89us/step - loss: 0.3433 - accuracy: 0.8737 - val_loss: 0.5010 - val_accuracy: 0.8221\n",
      "Epoch 65/100\n",
      "380/380 [==============================] - 0s 70us/step - loss: 0.3402 - accuracy: 0.8763 - val_loss: 0.5014 - val_accuracy: 0.7853\n",
      "Epoch 66/100\n",
      "380/380 [==============================] - 0s 60us/step - loss: 0.3562 - accuracy: 0.8579 - val_loss: 0.4946 - val_accuracy: 0.8282\n",
      "Epoch 67/100\n",
      "380/380 [==============================] - 0s 66us/step - loss: 0.3413 - accuracy: 0.8632 - val_loss: 0.4966 - val_accuracy: 0.8344\n",
      "Epoch 68/100\n",
      "380/380 [==============================] - 0s 119us/step - loss: 0.3245 - accuracy: 0.8974 - val_loss: 0.4897 - val_accuracy: 0.8160\n",
      "Epoch 69/100\n",
      "380/380 [==============================] - 0s 129us/step - loss: 0.3184 - accuracy: 0.9000 - val_loss: 0.4902 - val_accuracy: 0.7975\n",
      "Epoch 70/100\n",
      "380/380 [==============================] - 0s 233us/step - loss: 0.3185 - accuracy: 0.8868 - val_loss: 0.4859 - val_accuracy: 0.8160\n",
      "Epoch 71/100\n",
      "380/380 [==============================] - 0s 160us/step - loss: 0.3114 - accuracy: 0.8921 - val_loss: 0.4900 - val_accuracy: 0.7975\n",
      "Epoch 72/100\n",
      "380/380 [==============================] - 0s 209us/step - loss: 0.3170 - accuracy: 0.8789 - val_loss: 0.4841 - val_accuracy: 0.8282\n",
      "Epoch 73/100\n",
      "380/380 [==============================] - 0s 112us/step - loss: 0.3099 - accuracy: 0.9026 - val_loss: 0.4833 - val_accuracy: 0.7975\n",
      "Epoch 74/100\n",
      "380/380 [==============================] - 0s 167us/step - loss: 0.3124 - accuracy: 0.8895 - val_loss: 0.4822 - val_accuracy: 0.8282\n",
      "Epoch 75/100\n",
      "380/380 [==============================] - 0s 125us/step - loss: 0.3082 - accuracy: 0.8947 - val_loss: 0.4745 - val_accuracy: 0.8221\n",
      "Epoch 76/100\n",
      "380/380 [==============================] - 0s 93us/step - loss: 0.3000 - accuracy: 0.9000 - val_loss: 0.4711 - val_accuracy: 0.8344\n",
      "Epoch 77/100\n",
      "380/380 [==============================] - 0s 93us/step - loss: 0.2995 - accuracy: 0.8947 - val_loss: 0.4727 - val_accuracy: 0.8282\n",
      "Epoch 78/100\n",
      "380/380 [==============================] - 0s 68us/step - loss: 0.2995 - accuracy: 0.8974 - val_loss: 0.4670 - val_accuracy: 0.8160\n",
      "Epoch 79/100\n",
      "380/380 [==============================] - 0s 121us/step - loss: 0.2930 - accuracy: 0.8974 - val_loss: 0.4694 - val_accuracy: 0.8466\n",
      "Epoch 80/100\n",
      "380/380 [==============================] - 0s 144us/step - loss: 0.2929 - accuracy: 0.8974 - val_loss: 0.4633 - val_accuracy: 0.8282\n",
      "Epoch 81/100\n",
      "380/380 [==============================] - 0s 104us/step - loss: 0.2954 - accuracy: 0.8895 - val_loss: 0.4623 - val_accuracy: 0.8344\n",
      "Epoch 82/100\n",
      "380/380 [==============================] - 0s 151us/step - loss: 0.2924 - accuracy: 0.8974 - val_loss: 0.4594 - val_accuracy: 0.8466\n",
      "Epoch 83/100\n",
      "380/380 [==============================] - 0s 85us/step - loss: 0.2947 - accuracy: 0.8842 - val_loss: 0.4680 - val_accuracy: 0.8282\n",
      "Epoch 84/100\n",
      "380/380 [==============================] - 0s 90us/step - loss: 0.3130 - accuracy: 0.8684 - val_loss: 0.4546 - val_accuracy: 0.8466\n",
      "Epoch 85/100\n",
      "380/380 [==============================] - 0s 141us/step - loss: 0.3033 - accuracy: 0.8789 - val_loss: 0.4618 - val_accuracy: 0.8528\n",
      "Epoch 86/100\n",
      "380/380 [==============================] - 0s 87us/step - loss: 0.2951 - accuracy: 0.8921 - val_loss: 0.4581 - val_accuracy: 0.8405\n",
      "Epoch 87/100\n",
      "380/380 [==============================] - 0s 138us/step - loss: 0.2769 - accuracy: 0.9000 - val_loss: 0.4558 - val_accuracy: 0.8405\n",
      "Epoch 88/100\n",
      "380/380 [==============================] - 0s 162us/step - loss: 0.2802 - accuracy: 0.9000 - val_loss: 0.4474 - val_accuracy: 0.8405\n",
      "Epoch 89/100\n",
      "380/380 [==============================] - 0s 94us/step - loss: 0.2801 - accuracy: 0.9053 - val_loss: 0.4459 - val_accuracy: 0.8466\n",
      "Epoch 90/100\n",
      "380/380 [==============================] - 0s 116us/step - loss: 0.2815 - accuracy: 0.8947 - val_loss: 0.4466 - val_accuracy: 0.8282\n",
      "Epoch 91/100\n",
      "380/380 [==============================] - 0s 89us/step - loss: 0.2716 - accuracy: 0.9026 - val_loss: 0.4468 - val_accuracy: 0.8405\n",
      "Epoch 92/100\n",
      "380/380 [==============================] - 0s 164us/step - loss: 0.2749 - accuracy: 0.8974 - val_loss: 0.4414 - val_accuracy: 0.8405\n",
      "Epoch 93/100\n",
      "380/380 [==============================] - 0s 103us/step - loss: 0.2665 - accuracy: 0.9000 - val_loss: 0.4414 - val_accuracy: 0.8405\n",
      "Epoch 94/100\n",
      "380/380 [==============================] - 0s 111us/step - loss: 0.2666 - accuracy: 0.9000 - val_loss: 0.4390 - val_accuracy: 0.8405\n",
      "Epoch 95/100\n",
      "380/380 [==============================] - 0s 133us/step - loss: 0.2709 - accuracy: 0.9000 - val_loss: 0.4406 - val_accuracy: 0.8589\n",
      "Epoch 96/100\n",
      "380/380 [==============================] - 0s 59us/step - loss: 0.2659 - accuracy: 0.9105 - val_loss: 0.4423 - val_accuracy: 0.8405\n",
      "Epoch 97/100\n",
      "380/380 [==============================] - 0s 103us/step - loss: 0.2691 - accuracy: 0.9026 - val_loss: 0.4384 - val_accuracy: 0.8650\n",
      "Epoch 98/100\n",
      "380/380 [==============================] - 0s 65us/step - loss: 0.2634 - accuracy: 0.9132 - val_loss: 0.4314 - val_accuracy: 0.8528\n",
      "Epoch 99/100\n",
      "380/380 [==============================] - 0s 85us/step - loss: 0.2589 - accuracy: 0.9079 - val_loss: 0.4326 - val_accuracy: 0.8650\n",
      "Epoch 100/100\n",
      "380/380 [==============================] - 0s 75us/step - loss: 0.2574 - accuracy: 0.9105 - val_loss: 0.4303 - val_accuracy: 0.8528\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a44254080>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2_over2.fit(X_sel_train_over, y_sel_train_over,\n",
    "          batch_size=64, epochs=100,\n",
    "          validation_data=(X_sel_test_over, y_sel_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected dense_69_input to have shape (183,) but got array with shape (184,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-210-c3852a9d3cf5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0macc_test2_over2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel2_over2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_sel_test_over\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_sel_test_over\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'over-sampling test accuracy: %.2f%%'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0macc_test2_over2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1347\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1348\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1349\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1350\u001b[0m         \u001b[0;31m# Prepare inputs, delegate logic to `test_loop`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1351\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_uses_dynamic_learning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    143\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    146\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected dense_69_input to have shape (183,) but got array with shape (184,)"
     ]
    }
   ],
   "source": [
    "acc_test2_over2 = model2_over2.evaluate(X_sel_test_over, y_sel_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test2_over2*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 2, 1, 1, 0, 1, 2, 2, 1, 2, 1, 0, 0, 1, 0, 2, 1, 2, 1, 2, 1,\n",
       "       0, 1, 1, 2, 0, 2, 0, 2, 0, 0, 0, 1, 1, 1, 1, 2, 1, 0, 1, 1, 1, 0,\n",
       "       1, 2, 2, 2, 0, 1, 2, 1, 2, 2, 0, 0, 1, 2, 0, 0, 1, 1, 2, 1, 0, 1,\n",
       "       2, 2, 0, 2, 2, 1, 1, 1, 1, 2, 2, 1, 0, 1, 2, 1, 2, 1, 1, 2, 1, 1,\n",
       "       2, 1, 1, 2, 1, 0, 2, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1,\n",
       "       2, 2, 2, 2, 0, 2, 1, 0, 1, 0, 1, 0, 2, 0, 2, 0, 0, 1, 2, 1, 0, 1,\n",
       "       1, 1, 2, 2, 2, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 2, 1, 0, 0, 2, 0, 1,\n",
       "       2, 1, 0, 0, 0, 0, 0, 2, 0])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred6 = model2_over2.predict_classes(X_sel_test_over)\n",
    "pred6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GA48963</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SR4187</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS182</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CFBREBSa125</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS188</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>BCH-SA-05</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>NRS027</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>CFBREBSa123</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>NRS199</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>Grady1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test  pred\n",
       "0        GA48963     1     1\n",
       "1         SR4187     2     2\n",
       "2         NRS182     2     2\n",
       "3    CFBREBSa125     2     1\n",
       "4         NRS188     1     1\n",
       "..           ...   ...   ...\n",
       "158    BCH-SA-05     0     0\n",
       "159       NRS027     0     0\n",
       "160  CFBREBSa123     0     0\n",
       "161       NRS199     2     2\n",
       "162       Grady1     2     0\n",
       "\n",
       "[163 rows x 3 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat6['pred'] = pred6\n",
    "dat6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba6 = model2_over2.predict_proba(X_sel_test_over)\n",
    "dat_proba6 = pd.DataFrame(proba6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002574</td>\n",
       "      <td>0.885729</td>\n",
       "      <td>0.111697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.118700</td>\n",
       "      <td>0.210628</td>\n",
       "      <td>0.670673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.043093</td>\n",
       "      <td>0.105198</td>\n",
       "      <td>0.851708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.245581</td>\n",
       "      <td>0.651203</td>\n",
       "      <td>0.103216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000436</td>\n",
       "      <td>0.977856</td>\n",
       "      <td>0.021708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>0.962178</td>\n",
       "      <td>0.013605</td>\n",
       "      <td>0.024217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>0.983021</td>\n",
       "      <td>0.005792</td>\n",
       "      <td>0.011186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>0.655458</td>\n",
       "      <td>0.002887</td>\n",
       "      <td>0.341655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>0.013677</td>\n",
       "      <td>0.003953</td>\n",
       "      <td>0.982369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>0.491432</td>\n",
       "      <td>0.055427</td>\n",
       "      <td>0.453142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2\n",
       "0    0.002574  0.885729  0.111697\n",
       "1    0.118700  0.210628  0.670673\n",
       "2    0.043093  0.105198  0.851708\n",
       "3    0.245581  0.651203  0.103216\n",
       "4    0.000436  0.977856  0.021708\n",
       "..        ...       ...       ...\n",
       "158  0.962178  0.013605  0.024217\n",
       "159  0.983021  0.005792  0.011186\n",
       "160  0.655458  0.002887  0.341655\n",
       "161  0.013677  0.003953  0.982369\n",
       "162  0.491432  0.055427  0.453142\n",
       "\n",
       "[163 rows x 3 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba6.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba6.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat6.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/6p11.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 380 samples, validate on 163 samples\n",
      "Epoch 1/100\n",
      "380/380 [==============================] - 0s 82us/step - loss: 0.2749 - accuracy: 0.9105 - val_loss: 0.4064 - val_accuracy: 0.8650\n",
      "Epoch 2/100\n",
      "380/380 [==============================] - 0s 97us/step - loss: 0.2704 - accuracy: 0.9079 - val_loss: 0.4095 - val_accuracy: 0.8650\n",
      "Epoch 3/100\n",
      "380/380 [==============================] - 0s 100us/step - loss: 0.2688 - accuracy: 0.9079 - val_loss: 0.4106 - val_accuracy: 0.8528\n",
      "Epoch 4/100\n",
      "380/380 [==============================] - 0s 85us/step - loss: 0.2752 - accuracy: 0.9079 - val_loss: 0.4065 - val_accuracy: 0.8650\n",
      "Epoch 5/100\n",
      "380/380 [==============================] - 0s 72us/step - loss: 0.2729 - accuracy: 0.9053 - val_loss: 0.3993 - val_accuracy: 0.8650\n",
      "Epoch 6/100\n",
      "380/380 [==============================] - 0s 68us/step - loss: 0.2643 - accuracy: 0.9079 - val_loss: 0.4035 - val_accuracy: 0.8650\n",
      "Epoch 7/100\n",
      "380/380 [==============================] - 0s 71us/step - loss: 0.2675 - accuracy: 0.9079 - val_loss: 0.4072 - val_accuracy: 0.8528\n",
      "Epoch 8/100\n",
      "380/380 [==============================] - 0s 77us/step - loss: 0.2626 - accuracy: 0.9132 - val_loss: 0.4078 - val_accuracy: 0.8650\n",
      "Epoch 9/100\n",
      "380/380 [==============================] - 0s 83us/step - loss: 0.2670 - accuracy: 0.9000 - val_loss: 0.4004 - val_accuracy: 0.8528\n",
      "Epoch 10/100\n",
      "380/380 [==============================] - 0s 84us/step - loss: 0.2614 - accuracy: 0.9158 - val_loss: 0.4002 - val_accuracy: 0.8528\n",
      "Epoch 11/100\n",
      "380/380 [==============================] - 0s 68us/step - loss: 0.2651 - accuracy: 0.9026 - val_loss: 0.4037 - val_accuracy: 0.8650\n",
      "Epoch 12/100\n",
      "380/380 [==============================] - 0s 68us/step - loss: 0.2553 - accuracy: 0.9158 - val_loss: 0.3989 - val_accuracy: 0.8528\n",
      "Epoch 13/100\n",
      "380/380 [==============================] - 0s 70us/step - loss: 0.2558 - accuracy: 0.9132 - val_loss: 0.4066 - val_accuracy: 0.8528\n",
      "Epoch 14/100\n",
      "380/380 [==============================] - 0s 81us/step - loss: 0.2537 - accuracy: 0.9053 - val_loss: 0.3994 - val_accuracy: 0.8528\n",
      "Epoch 15/100\n",
      "380/380 [==============================] - 0s 81us/step - loss: 0.2571 - accuracy: 0.9158 - val_loss: 0.4008 - val_accuracy: 0.8650\n",
      "Epoch 16/100\n",
      "380/380 [==============================] - 0s 80us/step - loss: 0.2510 - accuracy: 0.9105 - val_loss: 0.3944 - val_accuracy: 0.8528\n",
      "Epoch 17/100\n",
      "380/380 [==============================] - 0s 79us/step - loss: 0.2516 - accuracy: 0.9184 - val_loss: 0.3957 - val_accuracy: 0.8650\n",
      "Epoch 18/100\n",
      "380/380 [==============================] - 0s 76us/step - loss: 0.2487 - accuracy: 0.9105 - val_loss: 0.3960 - val_accuracy: 0.8528\n",
      "Epoch 19/100\n",
      "380/380 [==============================] - 0s 68us/step - loss: 0.2549 - accuracy: 0.9132 - val_loss: 0.3945 - val_accuracy: 0.8528\n",
      "Epoch 20/100\n",
      "380/380 [==============================] - 0s 79us/step - loss: 0.2530 - accuracy: 0.9079 - val_loss: 0.3860 - val_accuracy: 0.8650\n",
      "Epoch 21/100\n",
      "380/380 [==============================] - 0s 93us/step - loss: 0.2625 - accuracy: 0.9053 - val_loss: 0.3917 - val_accuracy: 0.8528\n",
      "Epoch 22/100\n",
      "380/380 [==============================] - 0s 73us/step - loss: 0.2484 - accuracy: 0.9184 - val_loss: 0.4048 - val_accuracy: 0.8466\n",
      "Epoch 23/100\n",
      "380/380 [==============================] - 0s 75us/step - loss: 0.2472 - accuracy: 0.9132 - val_loss: 0.4050 - val_accuracy: 0.8528\n",
      "Epoch 24/100\n",
      "380/380 [==============================] - 0s 73us/step - loss: 0.2425 - accuracy: 0.9158 - val_loss: 0.4087 - val_accuracy: 0.8344\n",
      "Epoch 25/100\n",
      "380/380 [==============================] - 0s 66us/step - loss: 0.2471 - accuracy: 0.9105 - val_loss: 0.3978 - val_accuracy: 0.8528\n",
      "Epoch 26/100\n",
      "380/380 [==============================] - 0s 73us/step - loss: 0.2520 - accuracy: 0.8947 - val_loss: 0.3974 - val_accuracy: 0.8650\n",
      "Epoch 27/100\n",
      "380/380 [==============================] - 0s 80us/step - loss: 0.2401 - accuracy: 0.9132 - val_loss: 0.3919 - val_accuracy: 0.8650\n",
      "Epoch 28/100\n",
      "380/380 [==============================] - 0s 74us/step - loss: 0.2387 - accuracy: 0.9184 - val_loss: 0.3865 - val_accuracy: 0.8528\n",
      "Epoch 29/100\n",
      "380/380 [==============================] - 0s 68us/step - loss: 0.2433 - accuracy: 0.9079 - val_loss: 0.3971 - val_accuracy: 0.8589\n",
      "Epoch 30/100\n",
      "380/380 [==============================] - 0s 73us/step - loss: 0.2492 - accuracy: 0.9132 - val_loss: 0.3880 - val_accuracy: 0.8528\n",
      "Epoch 31/100\n",
      "380/380 [==============================] - 0s 71us/step - loss: 0.2441 - accuracy: 0.9105 - val_loss: 0.3979 - val_accuracy: 0.8589\n",
      "Epoch 32/100\n",
      "380/380 [==============================] - 0s 91us/step - loss: 0.2396 - accuracy: 0.9158 - val_loss: 0.3901 - val_accuracy: 0.8528\n",
      "Epoch 33/100\n",
      "380/380 [==============================] - 0s 105us/step - loss: 0.2420 - accuracy: 0.9211 - val_loss: 0.3911 - val_accuracy: 0.8650\n",
      "Epoch 34/100\n",
      "380/380 [==============================] - 0s 81us/step - loss: 0.2370 - accuracy: 0.9053 - val_loss: 0.3856 - val_accuracy: 0.8528\n",
      "Epoch 35/100\n",
      "380/380 [==============================] - 0s 72us/step - loss: 0.2396 - accuracy: 0.9184 - val_loss: 0.3855 - val_accuracy: 0.8466\n",
      "Epoch 36/100\n",
      "380/380 [==============================] - 0s 70us/step - loss: 0.2375 - accuracy: 0.9263 - val_loss: 0.3946 - val_accuracy: 0.8650\n",
      "Epoch 37/100\n",
      "380/380 [==============================] - 0s 83us/step - loss: 0.2279 - accuracy: 0.9158 - val_loss: 0.3935 - val_accuracy: 0.8466\n",
      "Epoch 38/100\n",
      "380/380 [==============================] - 0s 70us/step - loss: 0.2316 - accuracy: 0.9158 - val_loss: 0.3875 - val_accuracy: 0.8650\n",
      "Epoch 39/100\n",
      "380/380 [==============================] - 0s 60us/step - loss: 0.2271 - accuracy: 0.9211 - val_loss: 0.3853 - val_accuracy: 0.8650\n",
      "Epoch 40/100\n",
      "380/380 [==============================] - 0s 64us/step - loss: 0.2304 - accuracy: 0.9105 - val_loss: 0.3891 - val_accuracy: 0.8466\n",
      "Epoch 41/100\n",
      "380/380 [==============================] - 0s 64us/step - loss: 0.2379 - accuracy: 0.9211 - val_loss: 0.3845 - val_accuracy: 0.8466\n",
      "Epoch 42/100\n",
      "380/380 [==============================] - 0s 103us/step - loss: 0.2343 - accuracy: 0.9105 - val_loss: 0.3874 - val_accuracy: 0.8589\n",
      "Epoch 43/100\n",
      "380/380 [==============================] - 0s 238us/step - loss: 0.2424 - accuracy: 0.9158 - val_loss: 0.3841 - val_accuracy: 0.8466\n",
      "Epoch 44/100\n",
      "380/380 [==============================] - 0s 91us/step - loss: 0.2283 - accuracy: 0.9158 - val_loss: 0.3967 - val_accuracy: 0.8528\n",
      "Epoch 45/100\n",
      "380/380 [==============================] - 0s 83us/step - loss: 0.2276 - accuracy: 0.9158 - val_loss: 0.3815 - val_accuracy: 0.8589\n",
      "Epoch 46/100\n",
      "380/380 [==============================] - 0s 112us/step - loss: 0.2268 - accuracy: 0.9132 - val_loss: 0.4002 - val_accuracy: 0.8466\n",
      "Epoch 47/100\n",
      "380/380 [==============================] - 0s 85us/step - loss: 0.2258 - accuracy: 0.9053 - val_loss: 0.3797 - val_accuracy: 0.8528\n",
      "Epoch 48/100\n",
      "380/380 [==============================] - 0s 93us/step - loss: 0.2297 - accuracy: 0.9158 - val_loss: 0.3859 - val_accuracy: 0.8589\n",
      "Epoch 49/100\n",
      "380/380 [==============================] - 0s 94us/step - loss: 0.2196 - accuracy: 0.9132 - val_loss: 0.3852 - val_accuracy: 0.8589\n",
      "Epoch 50/100\n",
      "380/380 [==============================] - 0s 89us/step - loss: 0.2242 - accuracy: 0.9211 - val_loss: 0.4019 - val_accuracy: 0.8528\n",
      "Epoch 51/100\n",
      "380/380 [==============================] - 0s 102us/step - loss: 0.2314 - accuracy: 0.9184 - val_loss: 0.3835 - val_accuracy: 0.8650\n",
      "Epoch 52/100\n",
      "380/380 [==============================] - 0s 99us/step - loss: 0.2186 - accuracy: 0.9211 - val_loss: 0.3930 - val_accuracy: 0.8528\n",
      "Epoch 53/100\n",
      "380/380 [==============================] - 0s 99us/step - loss: 0.2185 - accuracy: 0.9158 - val_loss: 0.3867 - val_accuracy: 0.8528\n",
      "Epoch 54/100\n",
      "380/380 [==============================] - 0s 142us/step - loss: 0.2222 - accuracy: 0.9211 - val_loss: 0.3885 - val_accuracy: 0.8466\n",
      "Epoch 55/100\n",
      "380/380 [==============================] - 0s 306us/step - loss: 0.2163 - accuracy: 0.9158 - val_loss: 0.3816 - val_accuracy: 0.8528\n",
      "Epoch 56/100\n",
      "380/380 [==============================] - 0s 145us/step - loss: 0.2141 - accuracy: 0.9211 - val_loss: 0.3835 - val_accuracy: 0.8712\n",
      "Epoch 57/100\n",
      "380/380 [==============================] - 0s 83us/step - loss: 0.2129 - accuracy: 0.9211 - val_loss: 0.3868 - val_accuracy: 0.8650\n",
      "Epoch 58/100\n",
      "380/380 [==============================] - 0s 84us/step - loss: 0.2132 - accuracy: 0.9211 - val_loss: 0.3764 - val_accuracy: 0.8589\n",
      "Epoch 59/100\n",
      "380/380 [==============================] - 0s 53us/step - loss: 0.2156 - accuracy: 0.9184 - val_loss: 0.3850 - val_accuracy: 0.8650\n",
      "Epoch 60/100\n",
      "380/380 [==============================] - 0s 80us/step - loss: 0.2156 - accuracy: 0.9211 - val_loss: 0.3870 - val_accuracy: 0.8528\n",
      "Epoch 61/100\n",
      "380/380 [==============================] - 0s 80us/step - loss: 0.2171 - accuracy: 0.9211 - val_loss: 0.3922 - val_accuracy: 0.8589\n",
      "Epoch 62/100\n",
      "380/380 [==============================] - 0s 106us/step - loss: 0.2169 - accuracy: 0.9211 - val_loss: 0.3845 - val_accuracy: 0.8589\n",
      "Epoch 63/100\n",
      "380/380 [==============================] - 0s 131us/step - loss: 0.2129 - accuracy: 0.9237 - val_loss: 0.3892 - val_accuracy: 0.8589\n",
      "Epoch 64/100\n",
      "380/380 [==============================] - 0s 139us/step - loss: 0.2256 - accuracy: 0.9053 - val_loss: 0.3753 - val_accuracy: 0.8773\n",
      "Epoch 65/100\n",
      "380/380 [==============================] - 0s 75us/step - loss: 0.2339 - accuracy: 0.9105 - val_loss: 0.3842 - val_accuracy: 0.8650\n",
      "Epoch 66/100\n",
      "380/380 [==============================] - 0s 75us/step - loss: 0.2195 - accuracy: 0.9158 - val_loss: 0.3946 - val_accuracy: 0.8528\n",
      "Epoch 67/100\n",
      "380/380 [==============================] - 0s 61us/step - loss: 0.2122 - accuracy: 0.9237 - val_loss: 0.3888 - val_accuracy: 0.8528\n",
      "Epoch 68/100\n",
      "380/380 [==============================] - 0s 62us/step - loss: 0.2169 - accuracy: 0.9132 - val_loss: 0.3862 - val_accuracy: 0.8650\n",
      "Epoch 69/100\n",
      "380/380 [==============================] - 0s 56us/step - loss: 0.2121 - accuracy: 0.9184 - val_loss: 0.3778 - val_accuracy: 0.8528\n",
      "Epoch 70/100\n",
      "380/380 [==============================] - 0s 74us/step - loss: 0.2228 - accuracy: 0.9158 - val_loss: 0.3889 - val_accuracy: 0.8650\n",
      "Epoch 71/100\n",
      "380/380 [==============================] - 0s 56us/step - loss: 0.2187 - accuracy: 0.9158 - val_loss: 0.3870 - val_accuracy: 0.8589\n",
      "Epoch 72/100\n",
      "380/380 [==============================] - 0s 440us/step - loss: 0.2339 - accuracy: 0.8974 - val_loss: 0.3834 - val_accuracy: 0.8712\n",
      "Epoch 73/100\n",
      "380/380 [==============================] - 0s 128us/step - loss: 0.2185 - accuracy: 0.9158 - val_loss: 0.3737 - val_accuracy: 0.8712\n",
      "Epoch 74/100\n",
      "380/380 [==============================] - 0s 87us/step - loss: 0.2128 - accuracy: 0.9184 - val_loss: 0.3853 - val_accuracy: 0.8528\n",
      "Epoch 75/100\n",
      "380/380 [==============================] - 0s 77us/step - loss: 0.2125 - accuracy: 0.9237 - val_loss: 0.3844 - val_accuracy: 0.8589\n",
      "Epoch 76/100\n",
      "380/380 [==============================] - 0s 80us/step - loss: 0.2075 - accuracy: 0.9158 - val_loss: 0.3915 - val_accuracy: 0.8589\n",
      "Epoch 77/100\n",
      "380/380 [==============================] - 0s 78us/step - loss: 0.2041 - accuracy: 0.9237 - val_loss: 0.3790 - val_accuracy: 0.8528\n",
      "Epoch 78/100\n",
      "380/380 [==============================] - 0s 76us/step - loss: 0.2048 - accuracy: 0.9237 - val_loss: 0.3866 - val_accuracy: 0.8589\n",
      "Epoch 79/100\n",
      "380/380 [==============================] - 0s 76us/step - loss: 0.2042 - accuracy: 0.9184 - val_loss: 0.3784 - val_accuracy: 0.8712\n",
      "Epoch 80/100\n",
      "380/380 [==============================] - 0s 78us/step - loss: 0.2150 - accuracy: 0.9237 - val_loss: 0.3787 - val_accuracy: 0.8650\n",
      "Epoch 81/100\n",
      "380/380 [==============================] - 0s 76us/step - loss: 0.2009 - accuracy: 0.9237 - val_loss: 0.3746 - val_accuracy: 0.8528\n",
      "Epoch 82/100\n",
      "380/380 [==============================] - 0s 71us/step - loss: 0.2042 - accuracy: 0.9211 - val_loss: 0.3760 - val_accuracy: 0.8650\n",
      "Epoch 83/100\n",
      "380/380 [==============================] - 0s 116us/step - loss: 0.2006 - accuracy: 0.9263 - val_loss: 0.3795 - val_accuracy: 0.8466\n",
      "Epoch 84/100\n",
      "380/380 [==============================] - 0s 98us/step - loss: 0.2051 - accuracy: 0.9184 - val_loss: 0.3766 - val_accuracy: 0.8589\n",
      "Epoch 85/100\n",
      "380/380 [==============================] - 0s 64us/step - loss: 0.2014 - accuracy: 0.9237 - val_loss: 0.3801 - val_accuracy: 0.8528\n",
      "Epoch 86/100\n",
      "380/380 [==============================] - 0s 60us/step - loss: 0.1981 - accuracy: 0.9263 - val_loss: 0.3810 - val_accuracy: 0.8712\n",
      "Epoch 87/100\n",
      "380/380 [==============================] - 0s 64us/step - loss: 0.2027 - accuracy: 0.9211 - val_loss: 0.3779 - val_accuracy: 0.8528\n",
      "Epoch 88/100\n",
      "380/380 [==============================] - 0s 63us/step - loss: 0.1998 - accuracy: 0.9158 - val_loss: 0.3829 - val_accuracy: 0.8650\n",
      "Epoch 89/100\n",
      "380/380 [==============================] - 0s 60us/step - loss: 0.1989 - accuracy: 0.9263 - val_loss: 0.3793 - val_accuracy: 0.8528\n",
      "Epoch 90/100\n",
      "380/380 [==============================] - 0s 68us/step - loss: 0.2044 - accuracy: 0.9158 - val_loss: 0.3938 - val_accuracy: 0.8589\n",
      "Epoch 91/100\n",
      "380/380 [==============================] - 0s 77us/step - loss: 0.1965 - accuracy: 0.9237 - val_loss: 0.3829 - val_accuracy: 0.8589\n",
      "Epoch 92/100\n",
      "380/380 [==============================] - 0s 209us/step - loss: 0.2042 - accuracy: 0.9184 - val_loss: 0.4034 - val_accuracy: 0.8466\n",
      "Epoch 93/100\n",
      "380/380 [==============================] - 0s 163us/step - loss: 0.1996 - accuracy: 0.9184 - val_loss: 0.3728 - val_accuracy: 0.8528\n",
      "Epoch 94/100\n",
      "380/380 [==============================] - 0s 95us/step - loss: 0.2043 - accuracy: 0.9211 - val_loss: 0.4027 - val_accuracy: 0.8466\n",
      "Epoch 95/100\n",
      "380/380 [==============================] - 0s 88us/step - loss: 0.2019 - accuracy: 0.9158 - val_loss: 0.3728 - val_accuracy: 0.8528\n",
      "Epoch 96/100\n",
      "380/380 [==============================] - ETA: 0s - loss: 0.1181 - accuracy: 0.95 - 0s 157us/step - loss: 0.1987 - accuracy: 0.9237 - val_loss: 0.3898 - val_accuracy: 0.8650\n",
      "Epoch 97/100\n",
      "380/380 [==============================] - 0s 118us/step - loss: 0.1959 - accuracy: 0.9211 - val_loss: 0.3748 - val_accuracy: 0.8528\n",
      "Epoch 98/100\n",
      "380/380 [==============================] - 0s 460us/step - loss: 0.1994 - accuracy: 0.9211 - val_loss: 0.3777 - val_accuracy: 0.8528\n",
      "Epoch 99/100\n",
      "380/380 [==============================] - 0s 191us/step - loss: 0.2063 - accuracy: 0.9158 - val_loss: 0.3737 - val_accuracy: 0.8528\n",
      "Epoch 100/100\n",
      "380/380 [==============================] - 0s 122us/step - loss: 0.2023 - accuracy: 0.9158 - val_loss: 0.3736 - val_accuracy: 0.8589\n"
     ]
    }
   ],
   "source": [
    "hist2_over2 = model2_over2.fit(X_sel_train_over, y_sel_train_over,\n",
    "          batch_size=64, epochs=100,\n",
    "          validation_data=(X_sel_test_over, y_sel_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 91.57%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist2_over2.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba6 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_lasso_2.xlsx\",\n",
    "                        sheet_name=1,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>NRS249</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.888869e-01</td>\n",
       "      <td>5.108038e-01</td>\n",
       "      <td>3.003094e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>NRS188</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.888869e-01</td>\n",
       "      <td>5.108038e-01</td>\n",
       "      <td>3.003094e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>NRS232</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4.222906e-01</td>\n",
       "      <td>7.029924e-02</td>\n",
       "      <td>5.074101e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>NY439</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.558408e-04</td>\n",
       "      <td>2.976018e-04</td>\n",
       "      <td>9.993465e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>GA27</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.940971e-01</td>\n",
       "      <td>4.184215e-01</td>\n",
       "      <td>1.874814e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>NRS252</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.239556e-01</td>\n",
       "      <td>2.760444e-01</td>\n",
       "      <td>1.176030e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>SR2852</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.052276e-07</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>1.101559e-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>NRS108</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.540350e-17</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.011977e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>NRS202</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.888959e-01</td>\n",
       "      <td>3.111042e-01</td>\n",
       "      <td>2.228958e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>NRS110</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.097719e-09</td>\n",
       "      <td>4.404655e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>989 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   phage  strain  phenotype  prediction             0  \\\n",
       "0     p0006kpresabs_qual  NRS249          2           1  1.888869e-01   \n",
       "1     p0006kpresabs_qual  NRS188          1           1  1.888869e-01   \n",
       "2     p0006kpresabs_qual  NRS232          2           2  4.222906e-01   \n",
       "3     p0006kpresabs_qual   NY439          2           2  3.558408e-04   \n",
       "4     p0006kpresabs_qual    GA27          2           1  3.940971e-01   \n",
       "..                   ...     ...        ...         ...           ...   \n",
       "984  p0017Skpresabs_qual  NRS252          0           0  7.239556e-01   \n",
       "985  p0017Skpresabs_qual  SR2852          1           1  1.052276e-07   \n",
       "986  p0017Skpresabs_qual  NRS108          1           1  1.540350e-17   \n",
       "987  p0017Skpresabs_qual  NRS202          0           0  6.888959e-01   \n",
       "988  p0017Skpresabs_qual  NRS110          2           2  1.097719e-09   \n",
       "\n",
       "                1             2  \n",
       "0    5.108038e-01  3.003094e-01  \n",
       "1    5.108038e-01  3.003094e-01  \n",
       "2    7.029924e-02  5.074101e-01  \n",
       "3    2.976018e-04  9.993465e-01  \n",
       "4    4.184215e-01  1.874814e-01  \n",
       "..            ...           ...  \n",
       "984  2.760444e-01  1.176030e-09  \n",
       "985  9.999999e-01  1.101559e-28  \n",
       "986  1.000000e+00  9.011977e-16  \n",
       "987  3.111042e-01  2.228958e-09  \n",
       "988  4.404655e-08  1.000000e+00  \n",
       "\n",
       "[989 rows x 7 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.57378890e-03, 8.85729100e-01, 1.11697110e-01],\n",
       "       [1.18699506e-01, 2.10627940e-01, 6.70672540e-01],\n",
       "       [4.30934470e-02, 1.05198040e-01, 8.51708500e-01],\n",
       "       [2.45580930e-01, 6.51203200e-01, 1.03215870e-01],\n",
       "       [4.35716620e-04, 9.77855860e-01, 2.17083600e-02],\n",
       "       [9.78418700e-01, 5.73518870e-03, 1.58461430e-02],\n",
       "       [7.86796000e-03, 9.69179600e-01, 2.29524260e-02],\n",
       "       [3.83677870e-01, 1.22634664e-01, 4.93687500e-01],\n",
       "       [2.77630700e-03, 5.93725100e-02, 9.37851200e-01],\n",
       "       [2.20101040e-01, 5.52219100e-01, 2.27679920e-01],\n",
       "       [3.53825270e-01, 1.98377700e-01, 4.47797030e-01],\n",
       "       [6.19283280e-02, 5.99709000e-01, 3.38362660e-01],\n",
       "       [5.54868900e-01, 2.27175970e-01, 2.17955100e-01],\n",
       "       [8.17905070e-01, 7.51824160e-02, 1.06912486e-01],\n",
       "       [2.45580930e-01, 6.51203200e-01, 1.03215870e-01],\n",
       "       [8.56446150e-01, 2.02935190e-04, 1.43350880e-01],\n",
       "       [2.70295090e-02, 1.55329500e-02, 9.57437500e-01],\n",
       "       [5.89528900e-04, 9.39687200e-01, 5.97232580e-02],\n",
       "       [2.79141460e-01, 1.34825680e-01, 5.86032870e-01],\n",
       "       [2.65483420e-03, 9.62582470e-01, 3.47626300e-02],\n",
       "       [2.94742800e-01, 3.04688900e-01, 4.00568300e-01],\n",
       "       [1.58799980e-02, 9.66621460e-01, 1.74985790e-02],\n",
       "       [8.56446150e-01, 2.02935190e-04, 1.43350880e-01],\n",
       "       [7.35140900e-03, 9.69836100e-01, 2.28125040e-02],\n",
       "       [2.20101040e-01, 5.52219100e-01, 2.27679920e-01],\n",
       "       [3.43493070e-03, 2.26457580e-02, 9.73919330e-01],\n",
       "       [8.43924600e-01, 1.18354104e-01, 3.77212840e-02],\n",
       "       [1.27277970e-03, 7.68596300e-02, 9.21867600e-01],\n",
       "       [9.77325300e-01, 5.12343900e-03, 1.75512430e-02],\n",
       "       [4.02551700e-02, 3.88255750e-01, 5.71489100e-01],\n",
       "       [9.82042850e-01, 7.67912340e-03, 1.02780230e-02],\n",
       "       [8.81917400e-01, 2.09818930e-02, 9.71007400e-02],\n",
       "       [8.03327100e-01, 2.08010080e-03, 1.94592850e-01],\n",
       "       [2.45580930e-01, 6.51203200e-01, 1.03215870e-01],\n",
       "       [2.57378890e-03, 8.85729100e-01, 1.11697110e-01],\n",
       "       [2.31946870e-03, 5.36798100e-01, 4.60882340e-01],\n",
       "       [2.20101040e-01, 5.52219100e-01, 2.27679920e-01],\n",
       "       [8.05117500e-02, 2.77067960e-01, 6.42420230e-01],\n",
       "       [1.71092410e-02, 9.72787000e-01, 1.01037510e-02],\n",
       "       [8.43924600e-01, 1.18354104e-01, 3.77212840e-02],\n",
       "       [6.45334270e-03, 8.01379500e-01, 1.92167150e-01],\n",
       "       [2.20101040e-01, 5.52219100e-01, 2.27679920e-01],\n",
       "       [1.83428400e-03, 9.78495300e-01, 1.96703880e-02],\n",
       "       [9.62177930e-01, 1.36050545e-02, 2.42169630e-02],\n",
       "       [1.19506390e-03, 5.95498560e-01, 4.03306400e-01],\n",
       "       [1.13370220e-02, 4.12953500e-01, 5.75709500e-01],\n",
       "       [8.98698250e-03, 6.83597100e-02, 9.22653300e-01],\n",
       "       [2.48284150e-01, 1.20115630e-01, 6.31600200e-01],\n",
       "       [9.26808700e-01, 1.19870830e-02, 6.12042140e-02],\n",
       "       [2.31946870e-03, 5.36798100e-01, 4.60882340e-01],\n",
       "       [8.43461600e-03, 8.37353200e-03, 9.83191900e-01],\n",
       "       [2.20101040e-01, 5.52219100e-01, 2.27679920e-01],\n",
       "       [6.49825100e-02, 8.27672300e-02, 8.52250200e-01],\n",
       "       [4.75069230e-03, 1.27739580e-01, 8.67509800e-01],\n",
       "       [8.43924600e-01, 1.18354104e-01, 3.77212840e-02],\n",
       "       [7.75903900e-01, 5.42156050e-04, 2.23554000e-01],\n",
       "       [1.81152470e-04, 9.77973500e-01, 2.18452500e-02],\n",
       "       [2.44021120e-02, 3.60226840e-01, 6.15371050e-01],\n",
       "       [9.58786250e-01, 7.77235500e-03, 3.34414000e-02],\n",
       "       [7.75903900e-01, 5.42156050e-04, 2.23554000e-01],\n",
       "       [2.20101040e-01, 5.52219100e-01, 2.27679920e-01],\n",
       "       [5.79200800e-02, 8.90684300e-01, 5.13956470e-02],\n",
       "       [8.05117500e-02, 2.77067960e-01, 6.42420230e-01],\n",
       "       [3.45814340e-03, 9.75882700e-01, 2.06590800e-02],\n",
       "       [8.03327100e-01, 2.08010080e-03, 1.94592850e-01],\n",
       "       [1.71092410e-02, 9.72787000e-01, 1.01037510e-02],\n",
       "       [4.50861270e-02, 2.99154500e-01, 6.55759400e-01],\n",
       "       [1.34695570e-01, 2.08398860e-01, 6.56905600e-01],\n",
       "       [8.03327100e-01, 2.08010080e-03, 1.94592850e-01],\n",
       "       [2.22878800e-01, 2.90279200e-01, 4.86842000e-01],\n",
       "       [8.05117500e-02, 2.77067960e-01, 6.42420230e-01],\n",
       "       [2.57378890e-03, 8.85729100e-01, 1.11697110e-01],\n",
       "       [2.57378890e-03, 8.85729100e-01, 1.11697110e-01],\n",
       "       [1.39188820e-05, 9.82140900e-01, 1.78451200e-02],\n",
       "       [2.24272330e-04, 9.74426500e-01, 2.53491270e-02],\n",
       "       [1.60118620e-02, 1.90524710e-01, 7.93463400e-01],\n",
       "       [3.83321800e-02, 1.91677850e-02, 9.42500000e-01],\n",
       "       [2.00429590e-01, 5.18103900e-01, 2.81466450e-01],\n",
       "       [9.72304200e-01, 2.47931400e-03, 2.52165600e-02],\n",
       "       [9.30421000e-04, 9.86842450e-01, 1.22271260e-02],\n",
       "       [2.47377850e-02, 3.36190200e-01, 6.39072060e-01],\n",
       "       [1.12776436e-01, 7.64412900e-01, 1.22810684e-01],\n",
       "       [3.14344750e-03, 1.91414160e-03, 9.94942370e-01],\n",
       "       [1.17538925e-02, 9.63657860e-01, 2.45882460e-02],\n",
       "       [2.90172970e-03, 9.93793250e-01, 3.30501840e-03],\n",
       "       [1.24080560e-03, 1.20209660e-01, 8.78549500e-01],\n",
       "       [5.79200800e-02, 8.90684300e-01, 5.13956470e-02],\n",
       "       [3.51816020e-03, 8.58964100e-01, 1.37517780e-01],\n",
       "       [1.96046960e-02, 4.66061380e-01, 5.14333960e-01],\n",
       "       [2.24272330e-04, 9.74426500e-01, 2.53491270e-02],\n",
       "       [5.79200800e-02, 8.90684300e-01, 5.13956470e-02],\n",
       "       [3.83677870e-01, 1.22634664e-01, 4.93687500e-01],\n",
       "       [1.07452630e-01, 7.95877300e-01, 9.66700500e-02],\n",
       "       [4.16052340e-01, 2.81863300e-01, 3.02084360e-01],\n",
       "       [8.05117500e-02, 2.77067960e-01, 6.42420230e-01],\n",
       "       [9.45760700e-01, 1.73429570e-02, 3.68962800e-02],\n",
       "       [9.62177930e-01, 1.36050545e-02, 2.42169630e-02],\n",
       "       [3.45814340e-03, 9.75882700e-01, 2.06590800e-02],\n",
       "       [1.64263170e-03, 9.60854530e-01, 3.75027620e-02],\n",
       "       [8.17905070e-01, 7.51824160e-02, 1.06912486e-01],\n",
       "       [9.77325300e-01, 5.12343900e-03, 1.75512430e-02],\n",
       "       [7.35140900e-03, 9.69836100e-01, 2.28125040e-02],\n",
       "       [1.58799980e-02, 9.66621460e-01, 1.74985790e-02],\n",
       "       [8.03327100e-01, 2.08010080e-03, 1.94592850e-01],\n",
       "       [1.81152470e-04, 9.77973500e-01, 2.18452500e-02],\n",
       "       [4.65890540e-04, 9.54750540e-01, 4.47835850e-02],\n",
       "       [9.44840130e-01, 1.33947340e-04, 5.50259840e-02],\n",
       "       [2.45580930e-01, 6.51203200e-01, 1.03215870e-01],\n",
       "       [3.13138200e-02, 9.00383830e-01, 6.83022700e-02],\n",
       "       [2.20101040e-01, 5.52219100e-01, 2.27679920e-01],\n",
       "       [2.32595480e-02, 1.12872906e-01, 8.63867500e-01],\n",
       "       [3.83677870e-01, 1.22634664e-01, 4.93687500e-01],\n",
       "       [4.18334340e-02, 2.28873860e-01, 7.29292750e-01],\n",
       "       [1.30656730e-01, 3.13872070e-01, 5.55471240e-01],\n",
       "       [9.88705200e-01, 2.04335600e-03, 9.25142700e-03],\n",
       "       [1.16520330e-03, 2.07504030e-02, 9.78084400e-01],\n",
       "       [2.45580930e-01, 6.51203200e-01, 1.03215870e-01],\n",
       "       [9.48196300e-01, 2.05026470e-02, 3.13011500e-02],\n",
       "       [9.30421000e-04, 9.86842450e-01, 1.22271260e-02],\n",
       "       [9.26808700e-01, 1.19870830e-02, 6.12042140e-02],\n",
       "       [2.20101040e-01, 5.52219100e-01, 2.27679920e-01],\n",
       "       [8.03327100e-01, 2.08010080e-03, 1.94592850e-01],\n",
       "       [5.92928500e-03, 2.97538770e-03, 9.91095300e-01],\n",
       "       [9.83021400e-01, 5.79233900e-03, 1.11862190e-02],\n",
       "       [8.14797600e-03, 9.93184400e-03, 9.81920200e-01],\n",
       "       [9.78418700e-01, 5.73518870e-03, 1.58461430e-02],\n",
       "       [6.55458450e-01, 2.88670400e-03, 3.41654900e-01],\n",
       "       [3.51816020e-03, 8.58964100e-01, 1.37517780e-01],\n",
       "       [1.53309300e-04, 4.87638000e-01, 5.12208640e-01],\n",
       "       [2.57378890e-03, 8.85729100e-01, 1.11697110e-01],\n",
       "       [6.55458450e-01, 2.88670400e-03, 3.41654900e-01],\n",
       "       [1.57288970e-03, 7.05135170e-01, 2.93292000e-01],\n",
       "       [2.45580930e-01, 6.51203200e-01, 1.03215870e-01],\n",
       "       [9.30421000e-04, 9.86842450e-01, 1.22271260e-02],\n",
       "       [3.35994800e-02, 1.35258450e-01, 8.31142070e-01],\n",
       "       [2.36646500e-01, 2.79162060e-03, 7.60561900e-01],\n",
       "       [9.13355600e-03, 1.26818600e-01, 8.64047900e-01],\n",
       "       [8.43924600e-01, 1.18354104e-01, 3.77212840e-02],\n",
       "       [2.20101040e-01, 5.52219100e-01, 2.27679920e-01],\n",
       "       [8.43924600e-01, 1.18354104e-01, 3.77212840e-02],\n",
       "       [9.78418700e-01, 5.73518870e-03, 1.58461430e-02],\n",
       "       [9.60277500e-01, 7.29501850e-03, 3.24274670e-02],\n",
       "       [9.48196300e-01, 2.05026470e-02, 3.13011500e-02],\n",
       "       [2.00429590e-01, 5.18103900e-01, 2.81466450e-01],\n",
       "       [2.45580930e-01, 6.51203200e-01, 1.03215870e-01],\n",
       "       [2.20101040e-01, 5.52219100e-01, 2.27679920e-01],\n",
       "       [4.20259100e-02, 7.87853800e-01, 1.70120300e-01],\n",
       "       [3.83677870e-01, 1.22634664e-01, 4.93687500e-01],\n",
       "       [2.20101040e-01, 5.52219100e-01, 2.27679920e-01],\n",
       "       [9.62177930e-01, 1.36050545e-02, 2.42169630e-02],\n",
       "       [6.55458450e-01, 2.88670400e-03, 3.41654900e-01],\n",
       "       [2.12208330e-01, 9.08607900e-03, 7.78705540e-01],\n",
       "       [8.43924600e-01, 1.18354104e-01, 3.77212840e-02],\n",
       "       [2.20101040e-01, 5.52219100e-01, 2.27679920e-01],\n",
       "       [1.82565060e-01, 3.76190850e-03, 8.13673100e-01],\n",
       "       [1.64263170e-03, 9.60854530e-01, 3.75027620e-02],\n",
       "       [7.75903900e-01, 5.42156050e-04, 2.23554000e-01],\n",
       "       [9.89855500e-01, 2.39740430e-03, 7.74707200e-03],\n",
       "       [9.62177930e-01, 1.36050545e-02, 2.42169630e-02],\n",
       "       [9.83021400e-01, 5.79233900e-03, 1.11862190e-02],\n",
       "       [6.55458450e-01, 2.88670400e-03, 3.41654900e-01],\n",
       "       [1.36771430e-02, 3.95338400e-03, 9.82369500e-01],\n",
       "       [4.91431860e-01, 5.54265600e-02, 4.53141600e-01]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob6 = df_proba6[df_proba6['phage']=='p11kpresabs_qual'].iloc[:,-3:]\n",
    "y_prob6 = y_prob6.to_numpy()\n",
    "y_prob6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9506739155057198"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo6 = rocauc_ovo(y_sel_test_over, y_prob6, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9506739155057198"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr6 = rocauc_ovr(y_sel_test_over, y_prob6, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_sel_train_over, X_sel_test_over, y_sel_train_over, y_sel_test_over = train_test_split(X_sel_over, y_sel_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=789,\n",
    "                                                    stratify=y_sel_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat7 = pd.DataFrame(X_sel_test_over[:,-1])\n",
    "dat7['test'] = y_sel_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CFBREBSa127</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS145</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CFBRSa66B</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS204</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BCH-SA-13</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>NRS233</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>NRS204</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>CFBRSa07</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>CFBREBSa117</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>CFBREBSa126</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test\n",
       "0    CFBREBSa127     1\n",
       "1         NRS145     0\n",
       "2      CFBRSa66B     1\n",
       "3         NRS204     1\n",
       "4      BCH-SA-13     2\n",
       "..           ...   ...\n",
       "158       NRS233     2\n",
       "159       NRS204     1\n",
       "160     CFBRSa07     0\n",
       "161  CFBREBSa117     1\n",
       "162  CFBREBSa126     0\n",
       "\n",
       "[163 rows x 2 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sel_train_over = X_sel_train_over[:,:-1]\n",
    "X_sel_test_over = X_sel_test_over[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2_over3 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_sel_train_over.shape[1],)),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2_over3.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 380 samples, validate on 163 samples\n",
      "Epoch 1/100\n",
      "380/380 [==============================] - 0s 396us/step - loss: 1.1924 - accuracy: 0.3421 - val_loss: 1.1260 - val_accuracy: 0.3742\n",
      "Epoch 2/100\n",
      "380/380 [==============================] - 0s 88us/step - loss: 1.0327 - accuracy: 0.4237 - val_loss: 1.0526 - val_accuracy: 0.4356\n",
      "Epoch 3/100\n",
      "380/380 [==============================] - 0s 132us/step - loss: 0.9660 - accuracy: 0.5500 - val_loss: 0.9896 - val_accuracy: 0.4847\n",
      "Epoch 4/100\n",
      "380/380 [==============================] - 0s 124us/step - loss: 0.9188 - accuracy: 0.5684 - val_loss: 0.9463 - val_accuracy: 0.5215\n",
      "Epoch 5/100\n",
      "380/380 [==============================] - 0s 155us/step - loss: 0.8724 - accuracy: 0.6211 - val_loss: 0.9104 - val_accuracy: 0.5521\n",
      "Epoch 6/100\n",
      "380/380 [==============================] - 0s 149us/step - loss: 0.8275 - accuracy: 0.6579 - val_loss: 0.8671 - val_accuracy: 0.6135\n",
      "Epoch 7/100\n",
      "380/380 [==============================] - 0s 111us/step - loss: 0.7933 - accuracy: 0.6474 - val_loss: 0.8390 - val_accuracy: 0.6319\n",
      "Epoch 8/100\n",
      "380/380 [==============================] - 0s 143us/step - loss: 0.7656 - accuracy: 0.6895 - val_loss: 0.8234 - val_accuracy: 0.6380\n",
      "Epoch 9/100\n",
      "380/380 [==============================] - 0s 151us/step - loss: 0.7305 - accuracy: 0.6974 - val_loss: 0.7980 - val_accuracy: 0.6319\n",
      "Epoch 10/100\n",
      "380/380 [==============================] - 0s 108us/step - loss: 0.7100 - accuracy: 0.6947 - val_loss: 0.7764 - val_accuracy: 0.6933\n",
      "Epoch 11/100\n",
      "380/380 [==============================] - 0s 147us/step - loss: 0.6843 - accuracy: 0.7237 - val_loss: 0.7592 - val_accuracy: 0.7117\n",
      "Epoch 12/100\n",
      "380/380 [==============================] - 0s 158us/step - loss: 0.6525 - accuracy: 0.7474 - val_loss: 0.7353 - val_accuracy: 0.7239\n",
      "Epoch 13/100\n",
      "380/380 [==============================] - 0s 161us/step - loss: 0.6475 - accuracy: 0.7474 - val_loss: 0.7494 - val_accuracy: 0.6871\n",
      "Epoch 14/100\n",
      "380/380 [==============================] - 0s 109us/step - loss: 0.6142 - accuracy: 0.7684 - val_loss: 0.7548 - val_accuracy: 0.6626\n",
      "Epoch 15/100\n",
      "380/380 [==============================] - 0s 121us/step - loss: 0.6158 - accuracy: 0.7553 - val_loss: 0.6879 - val_accuracy: 0.7055\n",
      "Epoch 16/100\n",
      "380/380 [==============================] - 0s 106us/step - loss: 0.5887 - accuracy: 0.7737 - val_loss: 0.6812 - val_accuracy: 0.6933\n",
      "Epoch 17/100\n",
      "380/380 [==============================] - 0s 104us/step - loss: 0.5646 - accuracy: 0.7974 - val_loss: 0.6898 - val_accuracy: 0.6933\n",
      "Epoch 18/100\n",
      "380/380 [==============================] - 0s 91us/step - loss: 0.5675 - accuracy: 0.7605 - val_loss: 0.6764 - val_accuracy: 0.6871\n",
      "Epoch 19/100\n",
      "380/380 [==============================] - 0s 107us/step - loss: 0.5498 - accuracy: 0.7921 - val_loss: 0.6317 - val_accuracy: 0.7791\n",
      "Epoch 20/100\n",
      "380/380 [==============================] - 0s 152us/step - loss: 0.5255 - accuracy: 0.8263 - val_loss: 0.6303 - val_accuracy: 0.7669\n",
      "Epoch 21/100\n",
      "380/380 [==============================] - 0s 221us/step - loss: 0.5059 - accuracy: 0.8158 - val_loss: 0.6103 - val_accuracy: 0.7669\n",
      "Epoch 22/100\n",
      "380/380 [==============================] - 0s 101us/step - loss: 0.4953 - accuracy: 0.8053 - val_loss: 0.6535 - val_accuracy: 0.7117\n",
      "Epoch 23/100\n",
      "380/380 [==============================] - 0s 83us/step - loss: 0.5194 - accuracy: 0.7947 - val_loss: 0.5993 - val_accuracy: 0.7546\n",
      "Epoch 24/100\n",
      "380/380 [==============================] - 0s 117us/step - loss: 0.4705 - accuracy: 0.8395 - val_loss: 0.5807 - val_accuracy: 0.7853\n",
      "Epoch 25/100\n",
      "380/380 [==============================] - 0s 116us/step - loss: 0.4642 - accuracy: 0.8395 - val_loss: 0.5721 - val_accuracy: 0.7853\n",
      "Epoch 26/100\n",
      "380/380 [==============================] - 0s 158us/step - loss: 0.4500 - accuracy: 0.8447 - val_loss: 0.5626 - val_accuracy: 0.8282\n",
      "Epoch 27/100\n",
      "380/380 [==============================] - 0s 132us/step - loss: 0.4517 - accuracy: 0.8316 - val_loss: 0.6063 - val_accuracy: 0.6933\n",
      "Epoch 28/100\n",
      "380/380 [==============================] - 0s 134us/step - loss: 0.4833 - accuracy: 0.8053 - val_loss: 0.5615 - val_accuracy: 0.7546\n",
      "Epoch 29/100\n",
      "380/380 [==============================] - 0s 118us/step - loss: 0.4550 - accuracy: 0.8263 - val_loss: 0.5378 - val_accuracy: 0.8466\n",
      "Epoch 30/100\n",
      "380/380 [==============================] - 0s 139us/step - loss: 0.4202 - accuracy: 0.8658 - val_loss: 0.5359 - val_accuracy: 0.8221\n",
      "Epoch 31/100\n",
      "380/380 [==============================] - 0s 134us/step - loss: 0.4084 - accuracy: 0.8632 - val_loss: 0.5344 - val_accuracy: 0.7914\n",
      "Epoch 32/100\n",
      "380/380 [==============================] - 0s 302us/step - loss: 0.4006 - accuracy: 0.8605 - val_loss: 0.5322 - val_accuracy: 0.8037\n",
      "Epoch 33/100\n",
      "380/380 [==============================] - 0s 68us/step - loss: 0.3840 - accuracy: 0.8763 - val_loss: 0.5152 - val_accuracy: 0.8282\n",
      "Epoch 34/100\n",
      "380/380 [==============================] - 0s 68us/step - loss: 0.3831 - accuracy: 0.8737 - val_loss: 0.5093 - val_accuracy: 0.8282\n",
      "Epoch 35/100\n",
      "380/380 [==============================] - 0s 77us/step - loss: 0.3736 - accuracy: 0.8737 - val_loss: 0.5093 - val_accuracy: 0.8344\n",
      "Epoch 36/100\n",
      "380/380 [==============================] - 0s 81us/step - loss: 0.3725 - accuracy: 0.8684 - val_loss: 0.5077 - val_accuracy: 0.8037\n",
      "Epoch 37/100\n",
      "380/380 [==============================] - 0s 78us/step - loss: 0.3604 - accuracy: 0.8842 - val_loss: 0.5083 - val_accuracy: 0.8037\n",
      "Epoch 38/100\n",
      "380/380 [==============================] - 0s 74us/step - loss: 0.3510 - accuracy: 0.8868 - val_loss: 0.5011 - val_accuracy: 0.8098\n",
      "Epoch 39/100\n",
      "380/380 [==============================] - 0s 72us/step - loss: 0.3520 - accuracy: 0.8895 - val_loss: 0.4942 - val_accuracy: 0.8405\n",
      "Epoch 40/100\n",
      "380/380 [==============================] - 0s 100us/step - loss: 0.3639 - accuracy: 0.8763 - val_loss: 0.5161 - val_accuracy: 0.8098\n",
      "Epoch 41/100\n",
      "380/380 [==============================] - 0s 101us/step - loss: 0.3481 - accuracy: 0.8842 - val_loss: 0.5363 - val_accuracy: 0.7607\n",
      "Epoch 42/100\n",
      "380/380 [==============================] - 0s 294us/step - loss: 0.3586 - accuracy: 0.8632 - val_loss: 0.4988 - val_accuracy: 0.8160\n",
      "Epoch 43/100\n",
      "380/380 [==============================] - 0s 179us/step - loss: 0.3295 - accuracy: 0.8842 - val_loss: 0.4858 - val_accuracy: 0.8282\n",
      "Epoch 44/100\n",
      "380/380 [==============================] - 0s 263us/step - loss: 0.3297 - accuracy: 0.8763 - val_loss: 0.4837 - val_accuracy: 0.8098\n",
      "Epoch 45/100\n",
      "380/380 [==============================] - 0s 191us/step - loss: 0.3181 - accuracy: 0.8895 - val_loss: 0.4761 - val_accuracy: 0.8221\n",
      "Epoch 46/100\n",
      "380/380 [==============================] - 0s 161us/step - loss: 0.3133 - accuracy: 0.8868 - val_loss: 0.4602 - val_accuracy: 0.8282\n",
      "Epoch 47/100\n",
      "380/380 [==============================] - 0s 142us/step - loss: 0.3192 - accuracy: 0.8816 - val_loss: 0.4682 - val_accuracy: 0.8282\n",
      "Epoch 48/100\n",
      "380/380 [==============================] - 0s 201us/step - loss: 0.3100 - accuracy: 0.8895 - val_loss: 0.4772 - val_accuracy: 0.8037\n",
      "Epoch 49/100\n",
      "380/380 [==============================] - 0s 187us/step - loss: 0.3079 - accuracy: 0.8789 - val_loss: 0.4887 - val_accuracy: 0.8466\n",
      "Epoch 50/100\n",
      "380/380 [==============================] - 0s 161us/step - loss: 0.3056 - accuracy: 0.8868 - val_loss: 0.4697 - val_accuracy: 0.8221\n",
      "Epoch 51/100\n",
      "380/380 [==============================] - 0s 125us/step - loss: 0.2956 - accuracy: 0.8921 - val_loss: 0.4611 - val_accuracy: 0.8221\n",
      "Epoch 52/100\n",
      "380/380 [==============================] - 0s 113us/step - loss: 0.2932 - accuracy: 0.8921 - val_loss: 0.4537 - val_accuracy: 0.8282\n",
      "Epoch 53/100\n",
      "380/380 [==============================] - 0s 178us/step - loss: 0.2885 - accuracy: 0.8947 - val_loss: 0.4747 - val_accuracy: 0.8466\n",
      "Epoch 54/100\n",
      "380/380 [==============================] - 0s 199us/step - loss: 0.2852 - accuracy: 0.9053 - val_loss: 0.4484 - val_accuracy: 0.8282\n",
      "Epoch 55/100\n",
      "380/380 [==============================] - 0s 162us/step - loss: 0.2886 - accuracy: 0.8974 - val_loss: 0.4547 - val_accuracy: 0.8282\n",
      "Epoch 56/100\n",
      "380/380 [==============================] - 0s 94us/step - loss: 0.2809 - accuracy: 0.8921 - val_loss: 0.4452 - val_accuracy: 0.8282\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "380/380 [==============================] - 0s 209us/step - loss: 0.2818 - accuracy: 0.8947 - val_loss: 0.4449 - val_accuracy: 0.8282\n",
      "Epoch 58/100\n",
      "380/380 [==============================] - 0s 213us/step - loss: 0.2861 - accuracy: 0.8947 - val_loss: 0.4383 - val_accuracy: 0.8282\n",
      "Epoch 59/100\n",
      "380/380 [==============================] - 0s 217us/step - loss: 0.2787 - accuracy: 0.8947 - val_loss: 0.4691 - val_accuracy: 0.8037\n",
      "Epoch 60/100\n",
      "380/380 [==============================] - 0s 171us/step - loss: 0.2934 - accuracy: 0.8842 - val_loss: 0.4483 - val_accuracy: 0.8344\n",
      "Epoch 61/100\n",
      "380/380 [==============================] - 0s 217us/step - loss: 0.2807 - accuracy: 0.9053 - val_loss: 0.4612 - val_accuracy: 0.8528\n",
      "Epoch 62/100\n",
      "380/380 [==============================] - 0s 186us/step - loss: 0.2700 - accuracy: 0.8921 - val_loss: 0.4488 - val_accuracy: 0.8528\n",
      "Epoch 63/100\n",
      "380/380 [==============================] - 0s 126us/step - loss: 0.2764 - accuracy: 0.8974 - val_loss: 0.4456 - val_accuracy: 0.8344\n",
      "Epoch 64/100\n",
      "380/380 [==============================] - 0s 96us/step - loss: 0.2654 - accuracy: 0.9053 - val_loss: 0.4487 - val_accuracy: 0.8528\n",
      "Epoch 65/100\n",
      "380/380 [==============================] - 0s 73us/step - loss: 0.2600 - accuracy: 0.9079 - val_loss: 0.4252 - val_accuracy: 0.8282\n",
      "Epoch 66/100\n",
      "380/380 [==============================] - 0s 67us/step - loss: 0.2605 - accuracy: 0.9079 - val_loss: 0.4389 - val_accuracy: 0.8282\n",
      "Epoch 67/100\n",
      "380/380 [==============================] - 0s 87us/step - loss: 0.2660 - accuracy: 0.9000 - val_loss: 0.4661 - val_accuracy: 0.8466\n",
      "Epoch 68/100\n",
      "380/380 [==============================] - 0s 74us/step - loss: 0.2634 - accuracy: 0.9184 - val_loss: 0.4419 - val_accuracy: 0.8712\n",
      "Epoch 69/100\n",
      "380/380 [==============================] - 0s 81us/step - loss: 0.2477 - accuracy: 0.9079 - val_loss: 0.4313 - val_accuracy: 0.8282\n",
      "Epoch 70/100\n",
      "380/380 [==============================] - 0s 82us/step - loss: 0.2551 - accuracy: 0.9105 - val_loss: 0.5203 - val_accuracy: 0.7975\n",
      "Epoch 71/100\n",
      "380/380 [==============================] - 0s 190us/step - loss: 0.2809 - accuracy: 0.8895 - val_loss: 0.4561 - val_accuracy: 0.8650\n",
      "Epoch 72/100\n",
      "380/380 [==============================] - 0s 218us/step - loss: 0.2767 - accuracy: 0.9000 - val_loss: 0.4659 - val_accuracy: 0.8037\n",
      "Epoch 73/100\n",
      "380/380 [==============================] - 0s 202us/step - loss: 0.2786 - accuracy: 0.9053 - val_loss: 0.4260 - val_accuracy: 0.8344\n",
      "Epoch 74/100\n",
      "380/380 [==============================] - 0s 211us/step - loss: 0.2415 - accuracy: 0.9184 - val_loss: 0.4475 - val_accuracy: 0.8650\n",
      "Epoch 75/100\n",
      "380/380 [==============================] - 0s 184us/step - loss: 0.2470 - accuracy: 0.9132 - val_loss: 0.4352 - val_accuracy: 0.8528\n",
      "Epoch 76/100\n",
      "380/380 [==============================] - 0s 188us/step - loss: 0.2409 - accuracy: 0.9158 - val_loss: 0.4400 - val_accuracy: 0.8712\n",
      "Epoch 77/100\n",
      "380/380 [==============================] - 0s 139us/step - loss: 0.2379 - accuracy: 0.9184 - val_loss: 0.4290 - val_accuracy: 0.8344\n",
      "Epoch 78/100\n",
      "380/380 [==============================] - 0s 178us/step - loss: 0.2419 - accuracy: 0.9105 - val_loss: 0.4384 - val_accuracy: 0.8344\n",
      "Epoch 79/100\n",
      "380/380 [==============================] - 0s 102us/step - loss: 0.2374 - accuracy: 0.9132 - val_loss: 0.4231 - val_accuracy: 0.8405\n",
      "Epoch 80/100\n",
      "380/380 [==============================] - 0s 74us/step - loss: 0.2403 - accuracy: 0.9184 - val_loss: 0.4198 - val_accuracy: 0.8466\n",
      "Epoch 81/100\n",
      "380/380 [==============================] - 0s 95us/step - loss: 0.2381 - accuracy: 0.9105 - val_loss: 0.4224 - val_accuracy: 0.8650\n",
      "Epoch 82/100\n",
      "380/380 [==============================] - 0s 68us/step - loss: 0.2350 - accuracy: 0.9211 - val_loss: 0.4378 - val_accuracy: 0.8650\n",
      "Epoch 83/100\n",
      "380/380 [==============================] - 0s 75us/step - loss: 0.2345 - accuracy: 0.9132 - val_loss: 0.4174 - val_accuracy: 0.8589\n",
      "Epoch 84/100\n",
      "380/380 [==============================] - 0s 80us/step - loss: 0.2286 - accuracy: 0.9132 - val_loss: 0.4145 - val_accuracy: 0.8405\n",
      "Epoch 85/100\n",
      "380/380 [==============================] - 0s 91us/step - loss: 0.2377 - accuracy: 0.9026 - val_loss: 0.4140 - val_accuracy: 0.8589\n",
      "Epoch 86/100\n",
      "380/380 [==============================] - 0s 140us/step - loss: 0.2298 - accuracy: 0.9237 - val_loss: 0.4223 - val_accuracy: 0.8712\n",
      "Epoch 87/100\n",
      "380/380 [==============================] - 0s 120us/step - loss: 0.2321 - accuracy: 0.9158 - val_loss: 0.4420 - val_accuracy: 0.8650\n",
      "Epoch 88/100\n",
      "380/380 [==============================] - 0s 101us/step - loss: 0.2300 - accuracy: 0.9132 - val_loss: 0.4303 - val_accuracy: 0.8650\n",
      "Epoch 89/100\n",
      "380/380 [==============================] - 0s 110us/step - loss: 0.2239 - accuracy: 0.9184 - val_loss: 0.4362 - val_accuracy: 0.8712\n",
      "Epoch 90/100\n",
      "380/380 [==============================] - 0s 79us/step - loss: 0.2211 - accuracy: 0.9132 - val_loss: 0.4194 - val_accuracy: 0.8589\n",
      "Epoch 91/100\n",
      "380/380 [==============================] - 0s 69us/step - loss: 0.2188 - accuracy: 0.9211 - val_loss: 0.4170 - val_accuracy: 0.8712\n",
      "Epoch 92/100\n",
      "380/380 [==============================] - 0s 82us/step - loss: 0.2170 - accuracy: 0.9289 - val_loss: 0.4033 - val_accuracy: 0.8466\n",
      "Epoch 93/100\n",
      "380/380 [==============================] - 0s 69us/step - loss: 0.2332 - accuracy: 0.9079 - val_loss: 0.4165 - val_accuracy: 0.8528\n",
      "Epoch 94/100\n",
      "380/380 [==============================] - 0s 114us/step - loss: 0.2234 - accuracy: 0.9079 - val_loss: 0.4846 - val_accuracy: 0.7975\n",
      "Epoch 95/100\n",
      "380/380 [==============================] - 0s 94us/step - loss: 0.2206 - accuracy: 0.9132 - val_loss: 0.4025 - val_accuracy: 0.8466\n",
      "Epoch 96/100\n",
      "380/380 [==============================] - 0s 120us/step - loss: 0.2147 - accuracy: 0.9211 - val_loss: 0.4103 - val_accuracy: 0.8712\n",
      "Epoch 97/100\n",
      "380/380 [==============================] - 0s 99us/step - loss: 0.2148 - accuracy: 0.9211 - val_loss: 0.4102 - val_accuracy: 0.8712\n",
      "Epoch 98/100\n",
      "380/380 [==============================] - 0s 99us/step - loss: 0.2172 - accuracy: 0.9079 - val_loss: 0.4366 - val_accuracy: 0.8712\n",
      "Epoch 99/100\n",
      "380/380 [==============================] - 0s 83us/step - loss: 0.2146 - accuracy: 0.9289 - val_loss: 0.4098 - val_accuracy: 0.8712\n",
      "Epoch 100/100\n",
      "380/380 [==============================] - 0s 76us/step - loss: 0.2113 - accuracy: 0.9263 - val_loss: 0.4353 - val_accuracy: 0.8650\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a44715a20>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2_over3.fit(X_sel_train_over, y_sel_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_sel_test_over, y_sel_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163/163 [==============================] - 0s 83us/step\n",
      "over-sampling test accuracy: 83.44%\n"
     ]
    }
   ],
   "source": [
    "acc_test2_over3 = model2_over3.evaluate(X_sel_test_over, y_sel_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test2_over3*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 1, 0, 0, 0, 2, 1, 1, 1, 2, 2, 0, 2, 0, 1, 2, 1, 1, 1,\n",
       "       0, 1, 0, 1, 0, 0, 2, 1, 2, 2, 0, 1, 2, 2, 1, 0, 1, 2, 0, 2, 1, 1,\n",
       "       0, 1, 0, 1, 1, 0, 1, 1, 1, 2, 0, 1, 0, 1, 1, 0, 2, 0, 0, 0, 0, 0,\n",
       "       1, 2, 1, 1, 1, 2, 1, 1, 0, 1, 1, 2, 0, 0, 1, 2, 2, 0, 2, 0, 2, 0,\n",
       "       0, 0, 1, 1, 2, 2, 2, 2, 1, 0, 2, 0, 2, 2, 1, 2, 1, 2, 1, 1, 1, 2,\n",
       "       0, 0, 0, 1, 2, 0, 0, 1, 0, 2, 2, 2, 0, 1, 1, 1, 1, 2, 0, 2, 1, 0,\n",
       "       2, 1, 1, 0, 0, 0, 1, 1, 1, 2, 0, 1, 2, 2, 0, 1, 1, 2, 1, 1, 0, 1,\n",
       "       0, 0, 0, 2, 2, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred7 = model2_over3.predict_classes(X_sel_test_over)\n",
    "pred7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CFBREBSa127</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS145</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CFBRSa66B</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS204</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BCH-SA-13</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>NRS233</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>NRS204</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>CFBRSa07</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>CFBREBSa117</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>CFBREBSa126</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test  pred\n",
       "0    CFBREBSa127     1     1\n",
       "1         NRS145     0     0\n",
       "2      CFBRSa66B     1     1\n",
       "3         NRS204     1     1\n",
       "4      BCH-SA-13     2     1\n",
       "..           ...   ...   ...\n",
       "158       NRS233     2     2\n",
       "159       NRS204     1     1\n",
       "160     CFBRSa07     0     0\n",
       "161  CFBREBSa117     1     1\n",
       "162  CFBREBSa126     0     0\n",
       "\n",
       "[163 rows x 3 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat7['pred'] = pred7\n",
    "dat7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba7 = model2_over3.predict_proba(X_sel_test_over)\n",
    "dat_proba7 = pd.DataFrame(proba7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.041830</td>\n",
       "      <td>0.945889</td>\n",
       "      <td>0.012282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.979797</td>\n",
       "      <td>0.015503</td>\n",
       "      <td>0.004700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.203042</td>\n",
       "      <td>0.520154</td>\n",
       "      <td>0.276803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001634</td>\n",
       "      <td>0.984215</td>\n",
       "      <td>0.014151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.314982</td>\n",
       "      <td>0.621410</td>\n",
       "      <td>0.063608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>0.999834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>0.001634</td>\n",
       "      <td>0.984215</td>\n",
       "      <td>0.014151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.000749</td>\n",
       "      <td>0.044706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>0.228832</td>\n",
       "      <td>0.663252</td>\n",
       "      <td>0.107916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>0.992449</td>\n",
       "      <td>0.003225</td>\n",
       "      <td>0.004326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2\n",
       "0    0.041830  0.945889  0.012282\n",
       "1    0.979797  0.015503  0.004700\n",
       "2    0.203042  0.520154  0.276803\n",
       "3    0.001634  0.984215  0.014151\n",
       "4    0.314982  0.621410  0.063608\n",
       "..        ...       ...       ...\n",
       "158  0.000005  0.000161  0.999834\n",
       "159  0.001634  0.984215  0.014151\n",
       "160  0.954545  0.000749  0.044706\n",
       "161  0.228832  0.663252  0.107916\n",
       "162  0.992449  0.003225  0.004326\n",
       "\n",
       "[163 rows x 3 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba7.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba7.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat7.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/7p11.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 380 samples, validate on 163 samples\n",
      "Epoch 1/100\n",
      "380/380 [==============================] - 0s 105us/step - loss: 0.2186 - accuracy: 0.9132 - val_loss: 0.4422 - val_accuracy: 0.8466\n",
      "Epoch 2/100\n",
      "380/380 [==============================] - 0s 121us/step - loss: 0.2107 - accuracy: 0.9263 - val_loss: 0.4208 - val_accuracy: 0.8466\n",
      "Epoch 3/100\n",
      "380/380 [==============================] - 0s 89us/step - loss: 0.2118 - accuracy: 0.9132 - val_loss: 0.4142 - val_accuracy: 0.8466\n",
      "Epoch 4/100\n",
      "380/380 [==============================] - 0s 87us/step - loss: 0.2111 - accuracy: 0.9237 - val_loss: 0.4230 - val_accuracy: 0.8466\n",
      "Epoch 5/100\n",
      "380/380 [==============================] - 0s 87us/step - loss: 0.2079 - accuracy: 0.9211 - val_loss: 0.4145 - val_accuracy: 0.8466\n",
      "Epoch 6/100\n",
      "380/380 [==============================] - 0s 83us/step - loss: 0.2124 - accuracy: 0.9237 - val_loss: 0.4484 - val_accuracy: 0.8466\n",
      "Epoch 7/100\n",
      "380/380 [==============================] - 0s 88us/step - loss: 0.2164 - accuracy: 0.9158 - val_loss: 0.4105 - val_accuracy: 0.8344\n",
      "Epoch 8/100\n",
      "380/380 [==============================] - 0s 80us/step - loss: 0.2244 - accuracy: 0.9132 - val_loss: 0.4484 - val_accuracy: 0.8466\n",
      "Epoch 9/100\n",
      "380/380 [==============================] - 0s 83us/step - loss: 0.2112 - accuracy: 0.9263 - val_loss: 0.4178 - val_accuracy: 0.8466\n",
      "Epoch 10/100\n",
      "380/380 [==============================] - 0s 105us/step - loss: 0.2067 - accuracy: 0.9263 - val_loss: 0.4308 - val_accuracy: 0.8466\n",
      "Epoch 11/100\n",
      "380/380 [==============================] - 0s 89us/step - loss: 0.2066 - accuracy: 0.9211 - val_loss: 0.4415 - val_accuracy: 0.8466\n",
      "Epoch 12/100\n",
      "380/380 [==============================] - 0s 88us/step - loss: 0.2067 - accuracy: 0.9184 - val_loss: 0.4654 - val_accuracy: 0.7975\n",
      "Epoch 13/100\n",
      "380/380 [==============================] - 0s 88us/step - loss: 0.2161 - accuracy: 0.9211 - val_loss: 0.4374 - val_accuracy: 0.8466\n",
      "Epoch 14/100\n",
      "380/380 [==============================] - 0s 89us/step - loss: 0.1988 - accuracy: 0.9211 - val_loss: 0.4024 - val_accuracy: 0.8344\n",
      "Epoch 15/100\n",
      "380/380 [==============================] - 0s 86us/step - loss: 0.2044 - accuracy: 0.9132 - val_loss: 0.4548 - val_accuracy: 0.8405\n",
      "Epoch 16/100\n",
      "380/380 [==============================] - 0s 86us/step - loss: 0.2031 - accuracy: 0.9053 - val_loss: 0.4138 - val_accuracy: 0.8405\n",
      "Epoch 17/100\n",
      "380/380 [==============================] - 0s 84us/step - loss: 0.2207 - accuracy: 0.9132 - val_loss: 0.4392 - val_accuracy: 0.8466\n",
      "Epoch 18/100\n",
      "380/380 [==============================] - 0s 85us/step - loss: 0.2086 - accuracy: 0.9079 - val_loss: 0.4638 - val_accuracy: 0.8466\n",
      "Epoch 19/100\n",
      "380/380 [==============================] - 0s 94us/step - loss: 0.2026 - accuracy: 0.9211 - val_loss: 0.4212 - val_accuracy: 0.8466\n",
      "Epoch 20/100\n",
      "380/380 [==============================] - 0s 92us/step - loss: 0.2056 - accuracy: 0.9158 - val_loss: 0.4366 - val_accuracy: 0.8405\n",
      "Epoch 21/100\n",
      "380/380 [==============================] - 0s 86us/step - loss: 0.2012 - accuracy: 0.9184 - val_loss: 0.4327 - val_accuracy: 0.8466\n",
      "Epoch 22/100\n",
      "380/380 [==============================] - 0s 87us/step - loss: 0.2026 - accuracy: 0.9184 - val_loss: 0.4494 - val_accuracy: 0.8466\n",
      "Epoch 23/100\n",
      "380/380 [==============================] - 0s 87us/step - loss: 0.2013 - accuracy: 0.9158 - val_loss: 0.4075 - val_accuracy: 0.8344\n",
      "Epoch 24/100\n",
      "380/380 [==============================] - 0s 103us/step - loss: 0.2251 - accuracy: 0.9132 - val_loss: 0.4509 - val_accuracy: 0.8466\n",
      "Epoch 25/100\n",
      "380/380 [==============================] - 0s 83us/step - loss: 0.2082 - accuracy: 0.9132 - val_loss: 0.4144 - val_accuracy: 0.8466\n",
      "Epoch 26/100\n",
      "380/380 [==============================] - 0s 86us/step - loss: 0.2070 - accuracy: 0.9237 - val_loss: 0.5097 - val_accuracy: 0.7791\n",
      "Epoch 27/100\n",
      "380/380 [==============================] - 0s 87us/step - loss: 0.2046 - accuracy: 0.9184 - val_loss: 0.4102 - val_accuracy: 0.8466\n",
      "Epoch 28/100\n",
      "380/380 [==============================] - 0s 89us/step - loss: 0.2009 - accuracy: 0.9184 - val_loss: 0.4639 - val_accuracy: 0.8405\n",
      "Epoch 29/100\n",
      "380/380 [==============================] - 0s 87us/step - loss: 0.1941 - accuracy: 0.9184 - val_loss: 0.4262 - val_accuracy: 0.8405\n",
      "Epoch 30/100\n",
      "380/380 [==============================] - 0s 100us/step - loss: 0.1923 - accuracy: 0.9263 - val_loss: 0.4142 - val_accuracy: 0.8466\n",
      "Epoch 31/100\n",
      "380/380 [==============================] - 0s 95us/step - loss: 0.1919 - accuracy: 0.9237 - val_loss: 0.4522 - val_accuracy: 0.8405\n",
      "Epoch 32/100\n",
      "380/380 [==============================] - 0s 105us/step - loss: 0.1937 - accuracy: 0.9237 - val_loss: 0.4169 - val_accuracy: 0.8466\n",
      "Epoch 33/100\n",
      "380/380 [==============================] - 0s 95us/step - loss: 0.1908 - accuracy: 0.9105 - val_loss: 0.4545 - val_accuracy: 0.8405\n",
      "Epoch 34/100\n",
      "380/380 [==============================] - 0s 82us/step - loss: 0.1940 - accuracy: 0.9263 - val_loss: 0.4268 - val_accuracy: 0.8466\n",
      "Epoch 35/100\n",
      "380/380 [==============================] - 0s 72us/step - loss: 0.1886 - accuracy: 0.9263 - val_loss: 0.4504 - val_accuracy: 0.8405\n",
      "Epoch 36/100\n",
      "380/380 [==============================] - 0s 98us/step - loss: 0.1909 - accuracy: 0.9263 - val_loss: 0.4434 - val_accuracy: 0.8405\n",
      "Epoch 37/100\n",
      "380/380 [==============================] - 0s 121us/step - loss: 0.1929 - accuracy: 0.9289 - val_loss: 0.4436 - val_accuracy: 0.8221\n",
      "Epoch 38/100\n",
      "380/380 [==============================] - 0s 101us/step - loss: 0.2447 - accuracy: 0.8947 - val_loss: 0.5150 - val_accuracy: 0.7914\n",
      "Epoch 39/100\n",
      "380/380 [==============================] - 0s 103us/step - loss: 0.1949 - accuracy: 0.9289 - val_loss: 0.4273 - val_accuracy: 0.8466\n",
      "Epoch 40/100\n",
      "380/380 [==============================] - 0s 82us/step - loss: 0.1913 - accuracy: 0.9263 - val_loss: 0.4509 - val_accuracy: 0.8405\n",
      "Epoch 41/100\n",
      "380/380 [==============================] - 0s 80us/step - loss: 0.1982 - accuracy: 0.9184 - val_loss: 0.4196 - val_accuracy: 0.8405\n",
      "Epoch 42/100\n",
      "380/380 [==============================] - 0s 93us/step - loss: 0.2063 - accuracy: 0.9184 - val_loss: 0.4596 - val_accuracy: 0.8098\n",
      "Epoch 43/100\n",
      "380/380 [==============================] - 0s 85us/step - loss: 0.2106 - accuracy: 0.9079 - val_loss: 0.4680 - val_accuracy: 0.8344\n",
      "Epoch 44/100\n",
      "380/380 [==============================] - 0s 91us/step - loss: 0.1933 - accuracy: 0.9289 - val_loss: 0.4229 - val_accuracy: 0.8466\n",
      "Epoch 45/100\n",
      "380/380 [==============================] - 0s 80us/step - loss: 0.1878 - accuracy: 0.9289 - val_loss: 0.4307 - val_accuracy: 0.8405\n",
      "Epoch 46/100\n",
      "380/380 [==============================] - 0s 75us/step - loss: 0.1879 - accuracy: 0.9184 - val_loss: 0.4762 - val_accuracy: 0.8405\n",
      "Epoch 47/100\n",
      "380/380 [==============================] - 0s 79us/step - loss: 0.1991 - accuracy: 0.9184 - val_loss: 0.4179 - val_accuracy: 0.8528\n",
      "Epoch 48/100\n",
      "380/380 [==============================] - 0s 78us/step - loss: 0.1829 - accuracy: 0.9289 - val_loss: 0.4544 - val_accuracy: 0.8405\n",
      "Epoch 49/100\n",
      "380/380 [==============================] - 0s 90us/step - loss: 0.1871 - accuracy: 0.9289 - val_loss: 0.4213 - val_accuracy: 0.8466\n",
      "Epoch 50/100\n",
      "380/380 [==============================] - 0s 155us/step - loss: 0.1868 - accuracy: 0.9289 - val_loss: 0.4502 - val_accuracy: 0.8466\n",
      "Epoch 51/100\n",
      "380/380 [==============================] - 0s 407us/step - loss: 0.1900 - accuracy: 0.9316 - val_loss: 0.4134 - val_accuracy: 0.8589\n",
      "Epoch 52/100\n",
      "380/380 [==============================] - 0s 148us/step - loss: 0.1971 - accuracy: 0.9079 - val_loss: 0.4307 - val_accuracy: 0.8528\n",
      "Epoch 53/100\n",
      "380/380 [==============================] - 0s 135us/step - loss: 0.1929 - accuracy: 0.9237 - val_loss: 0.4204 - val_accuracy: 0.8466\n",
      "Epoch 54/100\n",
      "380/380 [==============================] - 0s 123us/step - loss: 0.1868 - accuracy: 0.9263 - val_loss: 0.4488 - val_accuracy: 0.8405\n",
      "Epoch 55/100\n",
      "380/380 [==============================] - 0s 125us/step - loss: 0.1958 - accuracy: 0.9184 - val_loss: 0.4422 - val_accuracy: 0.8528\n",
      "Epoch 56/100\n",
      "380/380 [==============================] - 0s 132us/step - loss: 0.1932 - accuracy: 0.9237 - val_loss: 0.4476 - val_accuracy: 0.8405\n",
      "Epoch 57/100\n",
      "380/380 [==============================] - 0s 166us/step - loss: 0.1985 - accuracy: 0.9237 - val_loss: 0.4385 - val_accuracy: 0.8466\n",
      "Epoch 58/100\n",
      "380/380 [==============================] - 0s 581us/step - loss: 0.1978 - accuracy: 0.9105 - val_loss: 0.4165 - val_accuracy: 0.8466\n",
      "Epoch 59/100\n",
      "380/380 [==============================] - 0s 266us/step - loss: 0.1884 - accuracy: 0.9237 - val_loss: 0.4562 - val_accuracy: 0.8466\n",
      "Epoch 60/100\n",
      "380/380 [==============================] - 0s 160us/step - loss: 0.1915 - accuracy: 0.9263 - val_loss: 0.4264 - val_accuracy: 0.8405\n",
      "Epoch 61/100\n",
      "380/380 [==============================] - 0s 164us/step - loss: 0.1912 - accuracy: 0.9263 - val_loss: 0.4365 - val_accuracy: 0.8466\n",
      "Epoch 62/100\n",
      "380/380 [==============================] - 0s 154us/step - loss: 0.1898 - accuracy: 0.9237 - val_loss: 0.4594 - val_accuracy: 0.8405\n",
      "Epoch 63/100\n",
      "380/380 [==============================] - 0s 112us/step - loss: 0.1934 - accuracy: 0.9158 - val_loss: 0.4187 - val_accuracy: 0.8405\n",
      "Epoch 64/100\n",
      "380/380 [==============================] - 0s 89us/step - loss: 0.1996 - accuracy: 0.9132 - val_loss: 0.4664 - val_accuracy: 0.8466\n",
      "Epoch 65/100\n",
      "380/380 [==============================] - 0s 152us/step - loss: 0.2122 - accuracy: 0.9237 - val_loss: 0.5260 - val_accuracy: 0.8037\n",
      "Epoch 66/100\n",
      "380/380 [==============================] - 0s 150us/step - loss: 0.1830 - accuracy: 0.9211 - val_loss: 0.4280 - val_accuracy: 0.8528\n",
      "Epoch 67/100\n",
      "380/380 [==============================] - 0s 162us/step - loss: 0.1968 - accuracy: 0.9105 - val_loss: 0.4388 - val_accuracy: 0.8466\n",
      "Epoch 68/100\n",
      "380/380 [==============================] - 0s 108us/step - loss: 0.1902 - accuracy: 0.9237 - val_loss: 0.4810 - val_accuracy: 0.8160\n",
      "Epoch 69/100\n",
      "380/380 [==============================] - 0s 101us/step - loss: 0.1969 - accuracy: 0.9158 - val_loss: 0.4136 - val_accuracy: 0.8528\n",
      "Epoch 70/100\n",
      "380/380 [==============================] - 0s 158us/step - loss: 0.1979 - accuracy: 0.9105 - val_loss: 0.5447 - val_accuracy: 0.7791\n",
      "Epoch 71/100\n",
      "380/380 [==============================] - 0s 103us/step - loss: 0.2023 - accuracy: 0.9184 - val_loss: 0.4379 - val_accuracy: 0.8405\n",
      "Epoch 72/100\n",
      "380/380 [==============================] - 0s 108us/step - loss: 0.1935 - accuracy: 0.9184 - val_loss: 0.4045 - val_accuracy: 0.8528\n",
      "Epoch 73/100\n",
      "380/380 [==============================] - 0s 101us/step - loss: 0.1878 - accuracy: 0.9132 - val_loss: 0.4598 - val_accuracy: 0.8405\n",
      "Epoch 74/100\n",
      "380/380 [==============================] - 0s 100us/step - loss: 0.1882 - accuracy: 0.9289 - val_loss: 0.4215 - val_accuracy: 0.8466\n",
      "Epoch 75/100\n",
      "380/380 [==============================] - 0s 87us/step - loss: 0.1750 - accuracy: 0.9237 - val_loss: 0.4441 - val_accuracy: 0.8528\n",
      "Epoch 76/100\n",
      "380/380 [==============================] - 0s 89us/step - loss: 0.1875 - accuracy: 0.9211 - val_loss: 0.4336 - val_accuracy: 0.8466\n",
      "Epoch 77/100\n",
      "380/380 [==============================] - 0s 91us/step - loss: 0.1791 - accuracy: 0.9263 - val_loss: 0.4419 - val_accuracy: 0.8466\n",
      "Epoch 78/100\n",
      "380/380 [==============================] - 0s 89us/step - loss: 0.1871 - accuracy: 0.9158 - val_loss: 0.4632 - val_accuracy: 0.8405\n",
      "Epoch 79/100\n",
      "380/380 [==============================] - 0s 86us/step - loss: 0.1777 - accuracy: 0.9263 - val_loss: 0.4174 - val_accuracy: 0.8466\n",
      "Epoch 80/100\n",
      "380/380 [==============================] - 0s 399us/step - loss: 0.1886 - accuracy: 0.9184 - val_loss: 0.4895 - val_accuracy: 0.8037\n",
      "Epoch 81/100\n",
      "380/380 [==============================] - 0s 119us/step - loss: 0.1907 - accuracy: 0.9289 - val_loss: 0.4790 - val_accuracy: 0.8466\n",
      "Epoch 82/100\n",
      "380/380 [==============================] - 0s 125us/step - loss: 0.1743 - accuracy: 0.9289 - val_loss: 0.4211 - val_accuracy: 0.8528\n",
      "Epoch 83/100\n",
      "380/380 [==============================] - 0s 123us/step - loss: 0.1846 - accuracy: 0.9184 - val_loss: 0.4908 - val_accuracy: 0.8405\n",
      "Epoch 84/100\n",
      "380/380 [==============================] - 0s 112us/step - loss: 0.1842 - accuracy: 0.9184 - val_loss: 0.4297 - val_accuracy: 0.8405\n",
      "Epoch 85/100\n",
      "380/380 [==============================] - 0s 98us/step - loss: 0.1887 - accuracy: 0.9132 - val_loss: 0.4444 - val_accuracy: 0.8466\n",
      "Epoch 86/100\n",
      "380/380 [==============================] - 0s 104us/step - loss: 0.1812 - accuracy: 0.9289 - val_loss: 0.4370 - val_accuracy: 0.8466\n",
      "Epoch 87/100\n",
      "380/380 [==============================] - 0s 100us/step - loss: 0.1896 - accuracy: 0.9026 - val_loss: 0.4445 - val_accuracy: 0.8160\n",
      "Epoch 88/100\n",
      "380/380 [==============================] - 0s 98us/step - loss: 0.1775 - accuracy: 0.9211 - val_loss: 0.4451 - val_accuracy: 0.8466\n",
      "Epoch 89/100\n",
      "380/380 [==============================] - 0s 100us/step - loss: 0.1918 - accuracy: 0.9132 - val_loss: 0.4262 - val_accuracy: 0.8528\n",
      "Epoch 90/100\n",
      "380/380 [==============================] - 0s 98us/step - loss: 0.1961 - accuracy: 0.9158 - val_loss: 0.4490 - val_accuracy: 0.8466\n",
      "Epoch 91/100\n",
      "380/380 [==============================] - 0s 92us/step - loss: 0.1858 - accuracy: 0.9289 - val_loss: 0.4945 - val_accuracy: 0.8344\n",
      "Epoch 92/100\n",
      "380/380 [==============================] - 0s 92us/step - loss: 0.1800 - accuracy: 0.9237 - val_loss: 0.4425 - val_accuracy: 0.8466\n",
      "Epoch 93/100\n",
      "380/380 [==============================] - 0s 93us/step - loss: 0.1853 - accuracy: 0.9211 - val_loss: 0.4389 - val_accuracy: 0.8466\n",
      "Epoch 94/100\n",
      "380/380 [==============================] - 0s 104us/step - loss: 0.1946 - accuracy: 0.9132 - val_loss: 0.4622 - val_accuracy: 0.8160\n",
      "Epoch 95/100\n",
      "380/380 [==============================] - 0s 88us/step - loss: 0.1849 - accuracy: 0.9184 - val_loss: 0.4881 - val_accuracy: 0.8037\n",
      "Epoch 96/100\n",
      "380/380 [==============================] - 0s 92us/step - loss: 0.1742 - accuracy: 0.9263 - val_loss: 0.4096 - val_accuracy: 0.8528\n",
      "Epoch 97/100\n",
      "380/380 [==============================] - 0s 89us/step - loss: 0.1805 - accuracy: 0.9263 - val_loss: 0.4532 - val_accuracy: 0.8466\n",
      "Epoch 98/100\n",
      "380/380 [==============================] - 0s 88us/step - loss: 0.1755 - accuracy: 0.9263 - val_loss: 0.4498 - val_accuracy: 0.8160\n",
      "Epoch 99/100\n",
      "380/380 [==============================] - 0s 86us/step - loss: 0.1853 - accuracy: 0.9158 - val_loss: 0.4316 - val_accuracy: 0.8528\n",
      "Epoch 100/100\n",
      "380/380 [==============================] - 0s 84us/step - loss: 0.1740 - accuracy: 0.9316 - val_loss: 0.4568 - val_accuracy: 0.8466\n"
     ]
    }
   ],
   "source": [
    "hist2_over3 = model2_over3.fit(X_sel_train_over, y_sel_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_sel_test_over, y_sel_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 92.02%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist2_over3.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba7 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_lasso_2.xlsx\",\n",
    "                        sheet_name=2,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>NRS210</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.132076e-01</td>\n",
       "      <td>2.812180e-01</td>\n",
       "      <td>1.055744e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>NRS205</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.993202e-04</td>\n",
       "      <td>6.834937e-07</td>\n",
       "      <td>9.998000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>312</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.589463e-01</td>\n",
       "      <td>3.982787e-01</td>\n",
       "      <td>2.427750e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>GA15</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.589463e-01</td>\n",
       "      <td>3.982787e-01</td>\n",
       "      <td>2.427750e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>SR4035</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.589463e-01</td>\n",
       "      <td>3.982787e-01</td>\n",
       "      <td>2.427750e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>NRS383</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.477194e-01</td>\n",
       "      <td>4.522807e-01</td>\n",
       "      <td>1.761374e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>NRS218</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6.953657e-05</td>\n",
       "      <td>9.999305e-01</td>\n",
       "      <td>3.132419e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.713214e-09</td>\n",
       "      <td>6.656316e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>SR2852</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9.956684e-12</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>7.441288e-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>NRS248</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.999998e-01</td>\n",
       "      <td>1.958189e-07</td>\n",
       "      <td>1.001001e-12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>989 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   phage  strain  phenotype  prediction             0  \\\n",
       "0     p0006kpresabs_qual  NRS210          0           0  6.132076e-01   \n",
       "1     p0006kpresabs_qual  NRS205          2           2  1.993202e-04   \n",
       "2     p0006kpresabs_qual     312          2           1  3.589463e-01   \n",
       "3     p0006kpresabs_qual    GA15          2           1  3.589463e-01   \n",
       "4     p0006kpresabs_qual  SR4035          0           1  3.589463e-01   \n",
       "..                   ...     ...        ...         ...           ...   \n",
       "984  p0017Skpresabs_qual  NRS383          1           0  5.477194e-01   \n",
       "985  p0017Skpresabs_qual  NRS218          1           1  6.953657e-05   \n",
       "986  p0017Skpresabs_qual  NRS209          2           2  2.713214e-09   \n",
       "987  p0017Skpresabs_qual  SR2852          1           1  9.956684e-12   \n",
       "988  p0017Skpresabs_qual  NRS248          0           0  9.999998e-01   \n",
       "\n",
       "                1             2  \n",
       "0    2.812180e-01  1.055744e-01  \n",
       "1    6.834937e-07  9.998000e-01  \n",
       "2    3.982787e-01  2.427750e-01  \n",
       "3    3.982787e-01  2.427750e-01  \n",
       "4    3.982787e-01  2.427750e-01  \n",
       "..            ...           ...  \n",
       "984  4.522807e-01  1.761374e-08  \n",
       "985  9.999305e-01  3.132419e-10  \n",
       "986  6.656316e-09  1.000000e+00  \n",
       "987  1.000000e+00  7.441288e-26  \n",
       "988  1.958189e-07  1.001001e-12  \n",
       "\n",
       "[989 rows x 7 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.18298060e-02, 9.45888700e-01, 1.22816170e-02],\n",
       "       [9.79796950e-01, 1.55026970e-02, 4.70028770e-03],\n",
       "       [2.03042490e-01, 5.20154400e-01, 2.76803140e-01],\n",
       "       [1.63378920e-03, 9.84215440e-01, 1.41508020e-02],\n",
       "       [3.14981760e-01, 6.21409800e-01, 6.36084750e-02],\n",
       "       [9.92449300e-01, 3.22524180e-03, 4.32556080e-03],\n",
       "       [9.92570600e-01, 2.82636380e-03, 4.60304550e-03],\n",
       "       [9.98242000e-01, 1.65318630e-03, 1.04834170e-04],\n",
       "       [3.31534670e-02, 4.17398780e-01, 5.49447800e-01],\n",
       "       [2.28831710e-01, 6.63252230e-01, 1.07916080e-01],\n",
       "       [4.34379730e-02, 9.50388600e-01, 6.17349800e-03],\n",
       "       [4.18298060e-02, 9.45888700e-01, 1.22816170e-02],\n",
       "       [2.45814490e-01, 1.75794840e-01, 5.78390700e-01],\n",
       "       [2.69555630e-04, 2.42486040e-03, 9.97305630e-01],\n",
       "       [6.24578830e-01, 2.10758240e-01, 1.64662930e-01],\n",
       "       [1.10714085e-01, 4.16145800e-01, 4.73140120e-01],\n",
       "       [9.51160700e-01, 4.37449600e-02, 5.09426560e-03],\n",
       "       [4.51731350e-04, 9.97174600e-01, 2.37367330e-03],\n",
       "       [6.13205830e-04, 2.23257200e-02, 9.77061100e-01],\n",
       "       [3.14981760e-01, 6.21409800e-01, 6.36084750e-02],\n",
       "       [1.73404190e-04, 9.95373100e-01, 4.45358550e-03],\n",
       "       [7.17145200e-03, 9.80000800e-01, 1.28277550e-02],\n",
       "       [9.47204530e-01, 2.46690850e-02, 2.81263140e-02],\n",
       "       [3.14981760e-01, 6.21409800e-01, 6.36084750e-02],\n",
       "       [9.65961100e-01, 3.32089850e-02, 8.29858400e-04],\n",
       "       [3.14981760e-01, 6.21409800e-01, 6.36084750e-02],\n",
       "       [9.91672800e-01, 4.70391360e-04, 7.85676800e-03],\n",
       "       [9.91672800e-01, 4.70391360e-04, 7.85676800e-03],\n",
       "       [1.24735970e-03, 4.34944670e-02, 9.55258130e-01],\n",
       "       [4.34379730e-02, 9.50388600e-01, 6.17349800e-03],\n",
       "       [1.10714085e-01, 4.16145800e-01, 4.73140120e-01],\n",
       "       [7.64969900e-02, 3.75772950e-01, 5.47730000e-01],\n",
       "       [9.40801560e-01, 5.66193100e-02, 2.57916200e-03],\n",
       "       [1.50592400e-03, 9.87696350e-01, 1.07976830e-02],\n",
       "       [5.43923200e-03, 2.93111350e-01, 7.01449400e-01],\n",
       "       [8.57441700e-02, 2.16114210e-01, 6.98141600e-01],\n",
       "       [3.14981760e-01, 6.21409800e-01, 6.36084750e-02],\n",
       "       [9.87223500e-01, 6.86818180e-03, 5.90836440e-03],\n",
       "       [3.14981760e-01, 6.21409800e-01, 6.36084750e-02],\n",
       "       [6.48761700e-03, 5.40465530e-02, 9.39465800e-01],\n",
       "       [7.16839130e-01, 6.76758400e-02, 2.15485070e-01],\n",
       "       [1.85715690e-01, 7.67747400e-03, 8.06606800e-01],\n",
       "       [2.28831710e-01, 6.63252230e-01, 1.07916080e-01],\n",
       "       [8.51495400e-02, 8.81100240e-01, 3.37502730e-02],\n",
       "       [6.24578830e-01, 2.10758240e-01, 1.64662930e-01],\n",
       "       [2.24970460e-04, 9.97655150e-01, 2.11984400e-03],\n",
       "       [9.99101300e-01, 4.83895960e-05, 8.50356800e-04],\n",
       "       [4.51731350e-04, 9.97174600e-01, 2.37367330e-03],\n",
       "       [2.03042490e-01, 5.20154400e-01, 2.76803140e-01],\n",
       "       [6.71168500e-01, 2.23473150e-01, 1.05358380e-01],\n",
       "       [1.81610650e-06, 9.94926200e-01, 5.07203770e-03],\n",
       "       [4.95792540e-04, 9.96628340e-01, 2.87585680e-03],\n",
       "       [2.28831710e-01, 6.63252230e-01, 1.07916080e-01],\n",
       "       [7.67852650e-03, 2.07547920e-02, 9.71566740e-01],\n",
       "       [9.70080500e-01, 2.26202550e-02, 7.29925000e-03],\n",
       "       [2.93625830e-01, 6.33110000e-01, 7.32642000e-02],\n",
       "       [9.98663900e-01, 4.73220750e-04, 8.62916300e-04],\n",
       "       [2.09738670e-02, 5.05334300e-01, 4.73691760e-01],\n",
       "       [2.46415850e-04, 9.98230300e-01, 1.52334850e-03],\n",
       "       [9.98242000e-01, 1.65318630e-03, 1.04834170e-04],\n",
       "       [1.10914030e-01, 1.86908110e-02, 8.70395100e-01],\n",
       "       [9.91672800e-01, 4.70391360e-04, 7.85676800e-03],\n",
       "       [9.92570600e-01, 2.82636380e-03, 4.60304550e-03],\n",
       "       [9.92570600e-01, 2.82636380e-03, 4.60304550e-03],\n",
       "       [9.98663900e-01, 4.73220750e-04, 8.62916300e-04],\n",
       "       [9.49820500e-01, 6.15272400e-04, 4.95641230e-02],\n",
       "       [4.18298060e-02, 9.45888700e-01, 1.22816170e-02],\n",
       "       [9.07171700e-02, 4.29278000e-01, 4.80004850e-01],\n",
       "       [3.14981760e-01, 6.21409800e-01, 6.36084750e-02],\n",
       "       [3.14981760e-01, 6.21409800e-01, 6.36084750e-02],\n",
       "       [8.51495400e-02, 8.81100240e-01, 3.37502730e-02],\n",
       "       [1.01369770e-03, 1.71088430e-01, 8.27897850e-01],\n",
       "       [2.03042490e-01, 5.20154400e-01, 2.76803140e-01],\n",
       "       [2.28831710e-01, 6.63252230e-01, 1.07916080e-01],\n",
       "       [9.54544960e-01, 7.48857600e-04, 4.47062180e-02],\n",
       "       [4.95792540e-04, 9.96628340e-01, 2.87585680e-03],\n",
       "       [2.77233160e-04, 9.89148560e-01, 1.05742410e-02],\n",
       "       [2.82902350e-05, 2.99318050e-01, 7.00653700e-01],\n",
       "       [8.75756140e-01, 1.67647000e-02, 1.07479155e-01],\n",
       "       [9.98663900e-01, 4.73220750e-04, 8.62916300e-04],\n",
       "       [2.28831710e-01, 6.63252230e-01, 1.07916080e-01],\n",
       "       [2.45851260e-03, 3.81549660e-01, 6.15991900e-01],\n",
       "       [1.10714085e-01, 4.16145800e-01, 4.73140120e-01],\n",
       "       [6.95662860e-01, 1.39371060e-03, 3.02943470e-01],\n",
       "       [1.10714085e-01, 4.16145800e-01, 4.73140120e-01],\n",
       "       [9.49820500e-01, 6.15272400e-04, 4.95641230e-02],\n",
       "       [3.48689380e-03, 3.21058740e-02, 9.64407270e-01],\n",
       "       [9.70080500e-01, 2.26202550e-02, 7.29925000e-03],\n",
       "       [9.99101300e-01, 4.83895960e-05, 8.50356800e-04],\n",
       "       [9.51160700e-01, 4.37449600e-02, 5.09426560e-03],\n",
       "       [1.63378920e-03, 9.84215440e-01, 1.41508020e-02],\n",
       "       [9.83759600e-03, 7.52131940e-01, 2.38030450e-01],\n",
       "       [1.10714085e-01, 4.16145800e-01, 4.73140120e-01],\n",
       "       [1.99312580e-01, 3.14455840e-01, 4.86231630e-01],\n",
       "       [2.41851280e-05, 3.44177100e-02, 9.65558200e-01],\n",
       "       [1.10714085e-01, 4.16145800e-01, 4.73140120e-01],\n",
       "       [3.14981760e-01, 6.21409800e-01, 6.36084750e-02],\n",
       "       [9.70891100e-01, 1.31841110e-02, 1.59247900e-02],\n",
       "       [1.96454860e-03, 1.49007470e-02, 9.83134750e-01],\n",
       "       [9.78085300e-01, 4.90652160e-03, 1.70082000e-02],\n",
       "       [4.80820950e-01, 4.40087460e-04, 5.18739000e-01],\n",
       "       [1.34901390e-03, 1.01598460e-01, 8.97052500e-01],\n",
       "       [2.54877790e-02, 8.86657300e-01, 8.78549500e-02],\n",
       "       [2.45851260e-03, 3.81549660e-01, 6.15991900e-01],\n",
       "       [2.03042490e-01, 5.20154400e-01, 2.76803140e-01],\n",
       "       [1.10714085e-01, 4.16145800e-01, 4.73140120e-01],\n",
       "       [7.42726000e-04, 9.97354870e-01, 1.90241790e-03],\n",
       "       [1.97799220e-03, 9.89136340e-01, 8.88571700e-03],\n",
       "       [1.97799220e-03, 9.89136340e-01, 8.88571700e-03],\n",
       "       [2.74961530e-02, 3.15847400e-04, 9.72188060e-01],\n",
       "       [9.98242000e-01, 1.65318630e-03, 1.04834170e-04],\n",
       "       [8.75756140e-01, 1.67647000e-02, 1.07479155e-01],\n",
       "       [9.70891100e-01, 1.31841110e-02, 1.59247900e-02],\n",
       "       [1.16222920e-03, 9.18101000e-01, 8.07367800e-02],\n",
       "       [1.10714085e-01, 4.16145800e-01, 4.73140120e-01],\n",
       "       [9.98242000e-01, 1.65318630e-03, 1.04834170e-04],\n",
       "       [9.92570600e-01, 2.82636380e-03, 4.60304550e-03],\n",
       "       [8.23438400e-05, 9.73153770e-01, 2.67638280e-02],\n",
       "       [9.70891100e-01, 1.31841110e-02, 1.59247900e-02],\n",
       "       [6.80525100e-03, 1.49874660e-02, 9.78207300e-01],\n",
       "       [9.11497200e-05, 7.79885100e-03, 9.92110100e-01],\n",
       "       [1.10714085e-01, 4.16145800e-01, 4.73140120e-01],\n",
       "       [9.78085300e-01, 4.90652160e-03, 1.70082000e-02],\n",
       "       [1.24693390e-03, 9.96994140e-01, 1.75889470e-03],\n",
       "       [2.28831710e-01, 6.63252230e-01, 1.07916080e-01],\n",
       "       [8.51495400e-02, 8.81100240e-01, 3.37502730e-02],\n",
       "       [6.84452650e-02, 7.01274340e-01, 2.30280340e-01],\n",
       "       [7.82104150e-04, 1.04672170e-02, 9.88750640e-01],\n",
       "       [9.98054740e-01, 1.25930140e-03, 6.85977400e-04],\n",
       "       [1.26216140e-01, 1.46282170e-01, 7.27501700e-01],\n",
       "       [4.51731350e-04, 9.97174600e-01, 2.37367330e-03],\n",
       "       [9.47204530e-01, 2.46690850e-02, 2.81263140e-02],\n",
       "       [1.24735970e-03, 4.34944670e-02, 9.55258130e-01],\n",
       "       [1.81610650e-06, 9.94926200e-01, 5.07203770e-03],\n",
       "       [1.15282170e-01, 7.26788400e-01, 1.57929470e-01],\n",
       "       [9.49820500e-01, 6.15272400e-04, 4.95641230e-02],\n",
       "       [9.79796950e-01, 1.55026970e-02, 4.70028770e-03],\n",
       "       [6.24578830e-01, 2.10758240e-01, 1.64662930e-01],\n",
       "       [4.63442970e-03, 9.90846100e-01, 4.51947050e-03],\n",
       "       [4.12921450e-04, 9.56318200e-01, 4.32689300e-02],\n",
       "       [8.51495400e-02, 8.81100240e-01, 3.37502730e-02],\n",
       "       [1.10714085e-01, 4.16145800e-01, 4.73140120e-01],\n",
       "       [6.95662860e-01, 1.39371060e-03, 3.02943470e-01],\n",
       "       [1.72317430e-01, 7.34835270e-01, 9.28473100e-02],\n",
       "       [1.10714085e-01, 4.16145800e-01, 4.73140120e-01],\n",
       "       [3.02182660e-02, 3.69339800e-05, 9.69744860e-01],\n",
       "       [9.87223500e-01, 6.86818180e-03, 5.90836440e-03],\n",
       "       [1.24693390e-03, 9.96994140e-01, 1.75889470e-03],\n",
       "       [3.14981760e-01, 6.21409800e-01, 6.36084750e-02],\n",
       "       [1.10714085e-01, 4.16145800e-01, 4.73140120e-01],\n",
       "       [4.34379730e-02, 9.50388600e-01, 6.17349800e-03],\n",
       "       [1.24693390e-03, 9.96994140e-01, 1.75889470e-03],\n",
       "       [9.79796950e-01, 1.55026970e-02, 4.70028770e-03],\n",
       "       [1.73404190e-04, 9.95373100e-01, 4.45358550e-03],\n",
       "       [3.97190750e-01, 2.83378800e-01, 3.19430470e-01],\n",
       "       [9.49820500e-01, 6.15272400e-04, 4.95641230e-02],\n",
       "       [9.78085300e-01, 4.90652160e-03, 1.70082000e-02],\n",
       "       [8.63702100e-04, 2.52137560e-02, 9.73922550e-01],\n",
       "       [5.01888370e-06, 1.60845940e-04, 9.99834060e-01],\n",
       "       [1.63378920e-03, 9.84215440e-01, 1.41508020e-02],\n",
       "       [9.54544960e-01, 7.48857600e-04, 4.47062180e-02],\n",
       "       [2.28831710e-01, 6.63252230e-01, 1.07916080e-01],\n",
       "       [9.92449300e-01, 3.22524180e-03, 4.32556080e-03]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob7 = df_proba7[df_proba7['phage']=='p11kpresabs_qual'].iloc[:,-3:]\n",
    "y_prob7 = y_prob7.to_numpy()\n",
    "y_prob7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9639063931877389"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo7 = rocauc_ovo(y_sel_test_over, y_prob7, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9639063931877389"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr7 = rocauc_ovr(y_sel_test_over, y_prob7, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_sel_train_over, X_sel_test_over, y_sel_train_over, y_sel_test_over = train_test_split(X_sel_over, y_sel_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=890,\n",
    "                                                    stratify=y_sel_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat8 = pd.DataFrame(X_sel_test_over[:,-1])\n",
    "dat8['test'] = y_sel_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SR2852</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS054</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS157</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NY224</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS070</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>NY417</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>NRS051</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>NRS226</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>EUH13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>NRS110</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0  test\n",
       "0    SR2852     2\n",
       "1    NRS054     1\n",
       "2    NRS157     2\n",
       "3     NY224     1\n",
       "4    NRS070     1\n",
       "..      ...   ...\n",
       "158   NY417     2\n",
       "159  NRS051     1\n",
       "160  NRS226     1\n",
       "161   EUH13     0\n",
       "162  NRS110     2\n",
       "\n",
       "[163 rows x 2 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sel_train_over = X_sel_train_over[:,:-1]\n",
    "X_sel_test_over = X_sel_test_over[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2_over4 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_sel_train_over.shape[1],)),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2_over4.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 380 samples, validate on 163 samples\n",
      "Epoch 1/100\n",
      "380/380 [==============================] - 0s 394us/step - loss: 1.1455 - accuracy: 0.3579 - val_loss: 1.1096 - val_accuracy: 0.3742\n",
      "Epoch 2/100\n",
      "380/380 [==============================] - 0s 158us/step - loss: 1.0360 - accuracy: 0.4737 - val_loss: 1.0614 - val_accuracy: 0.4356\n",
      "Epoch 3/100\n",
      "380/380 [==============================] - 0s 76us/step - loss: 0.9965 - accuracy: 0.5737 - val_loss: 1.0365 - val_accuracy: 0.4356\n",
      "Epoch 4/100\n",
      "380/380 [==============================] - 0s 128us/step - loss: 0.9747 - accuracy: 0.5737 - val_loss: 1.0264 - val_accuracy: 0.4479\n",
      "Epoch 5/100\n",
      "380/380 [==============================] - 0s 95us/step - loss: 0.9371 - accuracy: 0.5605 - val_loss: 0.9960 - val_accuracy: 0.5031\n",
      "Epoch 6/100\n",
      "380/380 [==============================] - 0s 111us/step - loss: 0.9115 - accuracy: 0.6237 - val_loss: 0.9766 - val_accuracy: 0.4785\n",
      "Epoch 7/100\n",
      "380/380 [==============================] - 0s 65us/step - loss: 0.8882 - accuracy: 0.5842 - val_loss: 0.9581 - val_accuracy: 0.4969\n",
      "Epoch 8/100\n",
      "380/380 [==============================] - 0s 92us/step - loss: 0.8562 - accuracy: 0.6263 - val_loss: 0.9405 - val_accuracy: 0.5153\n",
      "Epoch 9/100\n",
      "380/380 [==============================] - 0s 70us/step - loss: 0.8389 - accuracy: 0.6553 - val_loss: 0.9218 - val_accuracy: 0.5951\n",
      "Epoch 10/100\n",
      "380/380 [==============================] - 0s 142us/step - loss: 0.8130 - accuracy: 0.6553 - val_loss: 0.9109 - val_accuracy: 0.5276\n",
      "Epoch 11/100\n",
      "380/380 [==============================] - 0s 89us/step - loss: 0.7941 - accuracy: 0.6684 - val_loss: 0.8875 - val_accuracy: 0.6012\n",
      "Epoch 12/100\n",
      "380/380 [==============================] - 0s 140us/step - loss: 0.7688 - accuracy: 0.7211 - val_loss: 0.8744 - val_accuracy: 0.5951\n",
      "Epoch 13/100\n",
      "380/380 [==============================] - 0s 89us/step - loss: 0.7545 - accuracy: 0.7053 - val_loss: 0.8690 - val_accuracy: 0.5828\n",
      "Epoch 14/100\n",
      "380/380 [==============================] - 0s 116us/step - loss: 0.7268 - accuracy: 0.7342 - val_loss: 0.8474 - val_accuracy: 0.6564\n",
      "Epoch 15/100\n",
      "380/380 [==============================] - 0s 106us/step - loss: 0.7126 - accuracy: 0.7553 - val_loss: 0.8361 - val_accuracy: 0.6196\n",
      "Epoch 16/100\n",
      "380/380 [==============================] - 0s 105us/step - loss: 0.6919 - accuracy: 0.7684 - val_loss: 0.8183 - val_accuracy: 0.6626\n",
      "Epoch 17/100\n",
      "380/380 [==============================] - 0s 101us/step - loss: 0.6745 - accuracy: 0.7605 - val_loss: 0.8042 - val_accuracy: 0.6319\n",
      "Epoch 18/100\n",
      "380/380 [==============================] - 0s 71us/step - loss: 0.6625 - accuracy: 0.7737 - val_loss: 0.7981 - val_accuracy: 0.6564\n",
      "Epoch 19/100\n",
      "380/380 [==============================] - 0s 70us/step - loss: 0.6601 - accuracy: 0.7711 - val_loss: 0.7921 - val_accuracy: 0.6810\n",
      "Epoch 20/100\n",
      "380/380 [==============================] - 0s 93us/step - loss: 0.6295 - accuracy: 0.7921 - val_loss: 0.7803 - val_accuracy: 0.6810\n",
      "Epoch 21/100\n",
      "380/380 [==============================] - 0s 68us/step - loss: 0.6213 - accuracy: 0.8079 - val_loss: 0.7592 - val_accuracy: 0.6933\n",
      "Epoch 22/100\n",
      "380/380 [==============================] - 0s 110us/step - loss: 0.6013 - accuracy: 0.8105 - val_loss: 0.7447 - val_accuracy: 0.6748\n",
      "Epoch 23/100\n",
      "380/380 [==============================] - 0s 90us/step - loss: 0.5802 - accuracy: 0.8289 - val_loss: 0.7353 - val_accuracy: 0.7055\n",
      "Epoch 24/100\n",
      "380/380 [==============================] - 0s 55us/step - loss: 0.5696 - accuracy: 0.8184 - val_loss: 0.7231 - val_accuracy: 0.6748\n",
      "Epoch 25/100\n",
      "380/380 [==============================] - 0s 90us/step - loss: 0.5544 - accuracy: 0.8211 - val_loss: 0.7117 - val_accuracy: 0.6933\n",
      "Epoch 26/100\n",
      "380/380 [==============================] - 0s 175us/step - loss: 0.5459 - accuracy: 0.7974 - val_loss: 0.7031 - val_accuracy: 0.6871\n",
      "Epoch 27/100\n",
      "380/380 [==============================] - 0s 99us/step - loss: 0.5484 - accuracy: 0.8184 - val_loss: 0.6977 - val_accuracy: 0.7301\n",
      "Epoch 28/100\n",
      "380/380 [==============================] - 0s 97us/step - loss: 0.5241 - accuracy: 0.8316 - val_loss: 0.6934 - val_accuracy: 0.7117\n",
      "Epoch 29/100\n",
      "380/380 [==============================] - 0s 99us/step - loss: 0.5101 - accuracy: 0.8395 - val_loss: 0.6807 - val_accuracy: 0.7362\n",
      "Epoch 30/100\n",
      "380/380 [==============================] - 0s 124us/step - loss: 0.4968 - accuracy: 0.8474 - val_loss: 0.6682 - val_accuracy: 0.7239\n",
      "Epoch 31/100\n",
      "380/380 [==============================] - 0s 97us/step - loss: 0.4882 - accuracy: 0.8289 - val_loss: 0.6619 - val_accuracy: 0.7178\n",
      "Epoch 32/100\n",
      "380/380 [==============================] - 0s 112us/step - loss: 0.4770 - accuracy: 0.8342 - val_loss: 0.6557 - val_accuracy: 0.7301\n",
      "Epoch 33/100\n",
      "380/380 [==============================] - 0s 132us/step - loss: 0.4653 - accuracy: 0.8474 - val_loss: 0.6496 - val_accuracy: 0.7178\n",
      "Epoch 34/100\n",
      "380/380 [==============================] - 0s 209us/step - loss: 0.4566 - accuracy: 0.8421 - val_loss: 0.6402 - val_accuracy: 0.7485\n",
      "Epoch 35/100\n",
      "380/380 [==============================] - 0s 154us/step - loss: 0.4478 - accuracy: 0.8632 - val_loss: 0.6320 - val_accuracy: 0.7423\n",
      "Epoch 36/100\n",
      "380/380 [==============================] - 0s 143us/step - loss: 0.4432 - accuracy: 0.8632 - val_loss: 0.6283 - val_accuracy: 0.7423\n",
      "Epoch 37/100\n",
      "380/380 [==============================] - 0s 112us/step - loss: 0.4305 - accuracy: 0.8474 - val_loss: 0.6216 - val_accuracy: 0.7423\n",
      "Epoch 38/100\n",
      "380/380 [==============================] - 0s 91us/step - loss: 0.4224 - accuracy: 0.8763 - val_loss: 0.6167 - val_accuracy: 0.7362\n",
      "Epoch 39/100\n",
      "380/380 [==============================] - 0s 128us/step - loss: 0.4189 - accuracy: 0.8500 - val_loss: 0.6094 - val_accuracy: 0.7546\n",
      "Epoch 40/100\n",
      "380/380 [==============================] - 0s 94us/step - loss: 0.4211 - accuracy: 0.8658 - val_loss: 0.6078 - val_accuracy: 0.7423\n",
      "Epoch 41/100\n",
      "380/380 [==============================] - 0s 84us/step - loss: 0.4049 - accuracy: 0.8789 - val_loss: 0.6030 - val_accuracy: 0.7423\n",
      "Epoch 42/100\n",
      "380/380 [==============================] - 0s 75us/step - loss: 0.3930 - accuracy: 0.8816 - val_loss: 0.6055 - val_accuracy: 0.7607\n",
      "Epoch 43/100\n",
      "380/380 [==============================] - 0s 73us/step - loss: 0.3996 - accuracy: 0.8763 - val_loss: 0.6001 - val_accuracy: 0.7423\n",
      "Epoch 44/100\n",
      "380/380 [==============================] - 0s 81us/step - loss: 0.3862 - accuracy: 0.8763 - val_loss: 0.5865 - val_accuracy: 0.7546\n",
      "Epoch 45/100\n",
      "380/380 [==============================] - 0s 77us/step - loss: 0.3834 - accuracy: 0.8737 - val_loss: 0.5860 - val_accuracy: 0.7423\n",
      "Epoch 46/100\n",
      "380/380 [==============================] - 0s 118us/step - loss: 0.3742 - accuracy: 0.8816 - val_loss: 0.5777 - val_accuracy: 0.7607\n",
      "Epoch 47/100\n",
      "380/380 [==============================] - 0s 85us/step - loss: 0.3686 - accuracy: 0.8895 - val_loss: 0.5750 - val_accuracy: 0.7485\n",
      "Epoch 48/100\n",
      "380/380 [==============================] - 0s 147us/step - loss: 0.3623 - accuracy: 0.8895 - val_loss: 0.5703 - val_accuracy: 0.7546\n",
      "Epoch 49/100\n",
      "380/380 [==============================] - 0s 195us/step - loss: 0.3557 - accuracy: 0.8868 - val_loss: 0.5768 - val_accuracy: 0.7485\n",
      "Epoch 50/100\n",
      "380/380 [==============================] - 0s 139us/step - loss: 0.3525 - accuracy: 0.8895 - val_loss: 0.5612 - val_accuracy: 0.7669\n",
      "Epoch 51/100\n",
      "380/380 [==============================] - 0s 76us/step - loss: 0.3491 - accuracy: 0.8895 - val_loss: 0.5647 - val_accuracy: 0.7607\n",
      "Epoch 52/100\n",
      "380/380 [==============================] - 0s 178us/step - loss: 0.3416 - accuracy: 0.9000 - val_loss: 0.5530 - val_accuracy: 0.7546\n",
      "Epoch 53/100\n",
      "380/380 [==============================] - 0s 83us/step - loss: 0.3376 - accuracy: 0.8921 - val_loss: 0.5498 - val_accuracy: 0.7669\n",
      "Epoch 54/100\n",
      "380/380 [==============================] - 0s 77us/step - loss: 0.3358 - accuracy: 0.8947 - val_loss: 0.5586 - val_accuracy: 0.7607\n",
      "Epoch 55/100\n",
      "380/380 [==============================] - 0s 80us/step - loss: 0.3308 - accuracy: 0.8921 - val_loss: 0.5486 - val_accuracy: 0.7607\n",
      "Epoch 56/100\n",
      "380/380 [==============================] - 0s 109us/step - loss: 0.3321 - accuracy: 0.8921 - val_loss: 0.5507 - val_accuracy: 0.7607\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "380/380 [==============================] - 0s 221us/step - loss: 0.3285 - accuracy: 0.8921 - val_loss: 0.5479 - val_accuracy: 0.7607\n",
      "Epoch 58/100\n",
      "380/380 [==============================] - 0s 270us/step - loss: 0.3305 - accuracy: 0.8816 - val_loss: 0.5413 - val_accuracy: 0.7730\n",
      "Epoch 59/100\n",
      "380/380 [==============================] - 0s 309us/step - loss: 0.3220 - accuracy: 0.8921 - val_loss: 0.5453 - val_accuracy: 0.7607\n",
      "Epoch 60/100\n",
      "380/380 [==============================] - 0s 112us/step - loss: 0.3136 - accuracy: 0.9105 - val_loss: 0.5353 - val_accuracy: 0.7607\n",
      "Epoch 61/100\n",
      "380/380 [==============================] - 0s 78us/step - loss: 0.3102 - accuracy: 0.8974 - val_loss: 0.5453 - val_accuracy: 0.7730\n",
      "Epoch 62/100\n",
      "380/380 [==============================] - 0s 64us/step - loss: 0.3090 - accuracy: 0.8947 - val_loss: 0.5368 - val_accuracy: 0.7730\n",
      "Epoch 63/100\n",
      "380/380 [==============================] - 0s 62us/step - loss: 0.2996 - accuracy: 0.9158 - val_loss: 0.5304 - val_accuracy: 0.7791\n",
      "Epoch 64/100\n",
      "380/380 [==============================] - 0s 94us/step - loss: 0.2984 - accuracy: 0.9132 - val_loss: 0.5255 - val_accuracy: 0.7730\n",
      "Epoch 65/100\n",
      "380/380 [==============================] - 0s 68us/step - loss: 0.3022 - accuracy: 0.9158 - val_loss: 0.5288 - val_accuracy: 0.7607\n",
      "Epoch 66/100\n",
      "380/380 [==============================] - 0s 103us/step - loss: 0.2964 - accuracy: 0.9000 - val_loss: 0.5190 - val_accuracy: 0.7853\n",
      "Epoch 67/100\n",
      "380/380 [==============================] - 0s 123us/step - loss: 0.2887 - accuracy: 0.9132 - val_loss: 0.5450 - val_accuracy: 0.7730\n",
      "Epoch 68/100\n",
      "380/380 [==============================] - 0s 314us/step - loss: 0.2945 - accuracy: 0.9105 - val_loss: 0.5200 - val_accuracy: 0.7914\n",
      "Epoch 69/100\n",
      "380/380 [==============================] - 0s 134us/step - loss: 0.2851 - accuracy: 0.9132 - val_loss: 0.5330 - val_accuracy: 0.7730\n",
      "Epoch 70/100\n",
      "380/380 [==============================] - 0s 207us/step - loss: 0.2887 - accuracy: 0.9105 - val_loss: 0.5217 - val_accuracy: 0.7791\n",
      "Epoch 71/100\n",
      "380/380 [==============================] - 0s 115us/step - loss: 0.2810 - accuracy: 0.9079 - val_loss: 0.5139 - val_accuracy: 0.7853\n",
      "Epoch 72/100\n",
      "380/380 [==============================] - 0s 103us/step - loss: 0.2866 - accuracy: 0.8895 - val_loss: 0.5333 - val_accuracy: 0.7853\n",
      "Epoch 73/100\n",
      "380/380 [==============================] - 0s 74us/step - loss: 0.2850 - accuracy: 0.8974 - val_loss: 0.5143 - val_accuracy: 0.7853\n",
      "Epoch 74/100\n",
      "380/380 [==============================] - 0s 86us/step - loss: 0.2768 - accuracy: 0.9053 - val_loss: 0.5105 - val_accuracy: 0.7975\n",
      "Epoch 75/100\n",
      "380/380 [==============================] - 0s 75us/step - loss: 0.2713 - accuracy: 0.9184 - val_loss: 0.5177 - val_accuracy: 0.7791\n",
      "Epoch 76/100\n",
      "380/380 [==============================] - 0s 136us/step - loss: 0.2661 - accuracy: 0.9158 - val_loss: 0.5047 - val_accuracy: 0.7914\n",
      "Epoch 77/100\n",
      "380/380 [==============================] - 0s 118us/step - loss: 0.2775 - accuracy: 0.8974 - val_loss: 0.5149 - val_accuracy: 0.7730\n",
      "Epoch 78/100\n",
      "380/380 [==============================] - 0s 143us/step - loss: 0.2722 - accuracy: 0.8947 - val_loss: 0.5118 - val_accuracy: 0.7730\n",
      "Epoch 79/100\n",
      "380/380 [==============================] - 0s 74us/step - loss: 0.2727 - accuracy: 0.9053 - val_loss: 0.5120 - val_accuracy: 0.7853\n",
      "Epoch 80/100\n",
      "380/380 [==============================] - 0s 113us/step - loss: 0.2627 - accuracy: 0.9158 - val_loss: 0.5024 - val_accuracy: 0.7853\n",
      "Epoch 81/100\n",
      "380/380 [==============================] - 0s 97us/step - loss: 0.2692 - accuracy: 0.9132 - val_loss: 0.5046 - val_accuracy: 0.7914\n",
      "Epoch 82/100\n",
      "380/380 [==============================] - 0s 95us/step - loss: 0.2625 - accuracy: 0.9158 - val_loss: 0.4995 - val_accuracy: 0.7914\n",
      "Epoch 83/100\n",
      "380/380 [==============================] - 0s 121us/step - loss: 0.2608 - accuracy: 0.9079 - val_loss: 0.5202 - val_accuracy: 0.7853\n",
      "Epoch 84/100\n",
      "380/380 [==============================] - 0s 84us/step - loss: 0.2525 - accuracy: 0.9184 - val_loss: 0.5137 - val_accuracy: 0.7914\n",
      "Epoch 85/100\n",
      "380/380 [==============================] - 0s 135us/step - loss: 0.2591 - accuracy: 0.9132 - val_loss: 0.5092 - val_accuracy: 0.7853\n",
      "Epoch 86/100\n",
      "380/380 [==============================] - 0s 95us/step - loss: 0.2487 - accuracy: 0.9211 - val_loss: 0.4957 - val_accuracy: 0.7914\n",
      "Epoch 87/100\n",
      "380/380 [==============================] - 0s 121us/step - loss: 0.2522 - accuracy: 0.9105 - val_loss: 0.5201 - val_accuracy: 0.7730\n",
      "Epoch 88/100\n",
      "380/380 [==============================] - 0s 84us/step - loss: 0.2589 - accuracy: 0.9184 - val_loss: 0.4906 - val_accuracy: 0.7975\n",
      "Epoch 89/100\n",
      "380/380 [==============================] - 0s 111us/step - loss: 0.2474 - accuracy: 0.9184 - val_loss: 0.4935 - val_accuracy: 0.7975\n",
      "Epoch 90/100\n",
      "380/380 [==============================] - 0s 86us/step - loss: 0.2549 - accuracy: 0.9211 - val_loss: 0.5191 - val_accuracy: 0.7730\n",
      "Epoch 91/100\n",
      "380/380 [==============================] - 0s 113us/step - loss: 0.2583 - accuracy: 0.9158 - val_loss: 0.4937 - val_accuracy: 0.7975\n",
      "Epoch 92/100\n",
      "380/380 [==============================] - 0s 58us/step - loss: 0.2407 - accuracy: 0.9158 - val_loss: 0.4970 - val_accuracy: 0.7791\n",
      "Epoch 93/100\n",
      "380/380 [==============================] - 0s 54us/step - loss: 0.2382 - accuracy: 0.9237 - val_loss: 0.4913 - val_accuracy: 0.7975\n",
      "Epoch 94/100\n",
      "380/380 [==============================] - 0s 74us/step - loss: 0.2378 - accuracy: 0.9211 - val_loss: 0.4875 - val_accuracy: 0.8037\n",
      "Epoch 95/100\n",
      "380/380 [==============================] - 0s 47us/step - loss: 0.2402 - accuracy: 0.9237 - val_loss: 0.4977 - val_accuracy: 0.7853\n",
      "Epoch 96/100\n",
      "380/380 [==============================] - 0s 48us/step - loss: 0.2363 - accuracy: 0.9132 - val_loss: 0.4904 - val_accuracy: 0.8037\n",
      "Epoch 97/100\n",
      "380/380 [==============================] - 0s 64us/step - loss: 0.2376 - accuracy: 0.9184 - val_loss: 0.4950 - val_accuracy: 0.7853\n",
      "Epoch 98/100\n",
      "380/380 [==============================] - 0s 49us/step - loss: 0.2324 - accuracy: 0.9184 - val_loss: 0.4918 - val_accuracy: 0.7975\n",
      "Epoch 99/100\n",
      "380/380 [==============================] - 0s 46us/step - loss: 0.2338 - accuracy: 0.9158 - val_loss: 0.5067 - val_accuracy: 0.7853\n",
      "Epoch 100/100\n",
      "380/380 [==============================] - 0s 47us/step - loss: 0.2326 - accuracy: 0.9237 - val_loss: 0.4919 - val_accuracy: 0.7914\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a44c0f550>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2_over4.fit(X_sel_train_over, y_sel_train_over,\n",
    "          batch_size=64, epochs=100,\n",
    "          validation_data=(X_sel_test_over, y_sel_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163/163 [==============================] - 0s 99us/step\n",
      "over-sampling test accuracy: 80.37%\n"
     ]
    }
   ],
   "source": [
    "acc_test2_over4 = model2_over4.evaluate(X_sel_test_over, y_sel_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test2_over4*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 2, 2, 1, 1, 2, 2, 1, 0, 2, 2, 2, 1, 1, 0, 0, 1, 1, 1, 0, 1,\n",
       "       2, 2, 0, 2, 2, 2, 2, 1, 0, 1, 2, 2, 1, 1, 0, 2, 1, 0, 2, 1, 1, 0,\n",
       "       0, 2, 0, 0, 1, 2, 1, 0, 0, 1, 1, 1, 1, 1, 2, 1, 0, 2, 1, 0, 0, 0,\n",
       "       0, 1, 1, 0, 2, 0, 1, 1, 1, 1, 1, 2, 1, 0, 0, 1, 2, 2, 2, 1, 2, 2,\n",
       "       0, 2, 0, 0, 0, 2, 2, 1, 1, 0, 1, 1, 1, 2, 0, 2, 1, 2, 2, 0, 0, 2,\n",
       "       1, 1, 1, 0, 0, 2, 1, 1, 1, 2, 1, 2, 2, 0, 2, 2, 0, 0, 1, 1, 2, 0,\n",
       "       0, 1, 1, 1, 1, 1, 2, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 2, 0, 0,\n",
       "       2, 2, 2, 2, 2, 1, 1, 0, 1])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred8 = model2_over4.predict_classes(X_sel_test_over)\n",
    "pred8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SR2852</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS054</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS157</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NY224</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS070</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>NY417</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>NRS051</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>NRS226</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>EUH13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>NRS110</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0  test  pred\n",
       "0    SR2852     2     2\n",
       "1    NRS054     1     1\n",
       "2    NRS157     2     2\n",
       "3     NY224     1     2\n",
       "4    NRS070     1     1\n",
       "..      ...   ...   ...\n",
       "158   NY417     2     2\n",
       "159  NRS051     1     1\n",
       "160  NRS226     1     1\n",
       "161   EUH13     0     0\n",
       "162  NRS110     2     1\n",
       "\n",
       "[163 rows x 3 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat8['pred'] = pred8\n",
    "dat8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba8 = model2_over4.predict_proba(X_sel_test_over)\n",
    "dat_proba8 = pd.DataFrame(proba8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002746</td>\n",
       "      <td>0.288469</td>\n",
       "      <td>0.708786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.004718</td>\n",
       "      <td>0.975754</td>\n",
       "      <td>0.019529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000192</td>\n",
       "      <td>0.007352</td>\n",
       "      <td>0.992455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.058554</td>\n",
       "      <td>0.185173</td>\n",
       "      <td>0.756274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000289</td>\n",
       "      <td>0.963804</td>\n",
       "      <td>0.035907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>0.058554</td>\n",
       "      <td>0.185173</td>\n",
       "      <td>0.756274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>0.007984</td>\n",
       "      <td>0.972268</td>\n",
       "      <td>0.019748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>0.003023</td>\n",
       "      <td>0.756889</td>\n",
       "      <td>0.240087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>0.989564</td>\n",
       "      <td>0.002574</td>\n",
       "      <td>0.007862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>0.070066</td>\n",
       "      <td>0.664020</td>\n",
       "      <td>0.265914</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2\n",
       "0    0.002746  0.288469  0.708786\n",
       "1    0.004718  0.975754  0.019529\n",
       "2    0.000192  0.007352  0.992455\n",
       "3    0.058554  0.185173  0.756274\n",
       "4    0.000289  0.963804  0.035907\n",
       "..        ...       ...       ...\n",
       "158  0.058554  0.185173  0.756274\n",
       "159  0.007984  0.972268  0.019748\n",
       "160  0.003023  0.756889  0.240087\n",
       "161  0.989564  0.002574  0.007862\n",
       "162  0.070066  0.664020  0.265914\n",
       "\n",
       "[163 rows x 3 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba8.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba8.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat8.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/8p11.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 380 samples, validate on 163 samples\n",
      "Epoch 1/100\n",
      "380/380 [==============================] - 0s 146us/step - loss: 0.2564 - accuracy: 0.9053 - val_loss: 0.5488 - val_accuracy: 0.8037\n",
      "Epoch 2/100\n",
      "380/380 [==============================] - 0s 145us/step - loss: 0.2737 - accuracy: 0.8711 - val_loss: 0.6301 - val_accuracy: 0.7485\n",
      "Epoch 3/100\n",
      "380/380 [==============================] - 0s 127us/step - loss: 0.2742 - accuracy: 0.8895 - val_loss: 0.5938 - val_accuracy: 0.7914\n",
      "Epoch 4/100\n",
      "380/380 [==============================] - 0s 130us/step - loss: 0.2369 - accuracy: 0.9132 - val_loss: 0.5442 - val_accuracy: 0.7853\n",
      "Epoch 5/100\n",
      "380/380 [==============================] - 0s 118us/step - loss: 0.2305 - accuracy: 0.9184 - val_loss: 0.5575 - val_accuracy: 0.8282\n",
      "Epoch 6/100\n",
      "380/380 [==============================] - 0s 138us/step - loss: 0.2543 - accuracy: 0.8763 - val_loss: 0.5614 - val_accuracy: 0.7669\n",
      "Epoch 7/100\n",
      "380/380 [==============================] - 0s 110us/step - loss: 0.2188 - accuracy: 0.9184 - val_loss: 0.5592 - val_accuracy: 0.8344\n",
      "Epoch 8/100\n",
      "380/380 [==============================] - 0s 101us/step - loss: 0.2272 - accuracy: 0.9184 - val_loss: 0.5724 - val_accuracy: 0.7914\n",
      "Epoch 9/100\n",
      "380/380 [==============================] - 0s 87us/step - loss: 0.2336 - accuracy: 0.9184 - val_loss: 0.5817 - val_accuracy: 0.7853\n",
      "Epoch 10/100\n",
      "380/380 [==============================] - 0s 105us/step - loss: 0.2410 - accuracy: 0.9132 - val_loss: 0.5688 - val_accuracy: 0.7853\n",
      "Epoch 11/100\n",
      "380/380 [==============================] - 0s 92us/step - loss: 0.2284 - accuracy: 0.9000 - val_loss: 0.5180 - val_accuracy: 0.7791\n",
      "Epoch 12/100\n",
      "380/380 [==============================] - 0s 99us/step - loss: 0.2499 - accuracy: 0.8947 - val_loss: 0.5556 - val_accuracy: 0.7730\n",
      "Epoch 13/100\n",
      "380/380 [==============================] - 0s 96us/step - loss: 0.2463 - accuracy: 0.9000 - val_loss: 0.5463 - val_accuracy: 0.7607\n",
      "Epoch 14/100\n",
      "380/380 [==============================] - 0s 130us/step - loss: 0.2280 - accuracy: 0.9026 - val_loss: 0.5409 - val_accuracy: 0.7853\n",
      "Epoch 15/100\n",
      "380/380 [==============================] - 0s 89us/step - loss: 0.2156 - accuracy: 0.9211 - val_loss: 0.5578 - val_accuracy: 0.8282\n",
      "Epoch 16/100\n",
      "380/380 [==============================] - 0s 128us/step - loss: 0.2236 - accuracy: 0.9079 - val_loss: 0.5514 - val_accuracy: 0.7730\n",
      "Epoch 17/100\n",
      "380/380 [==============================] - 0s 107us/step - loss: 0.2319 - accuracy: 0.8868 - val_loss: 0.6307 - val_accuracy: 0.7485\n",
      "Epoch 18/100\n",
      "380/380 [==============================] - 0s 97us/step - loss: 0.2461 - accuracy: 0.8842 - val_loss: 0.5841 - val_accuracy: 0.7669\n",
      "Epoch 19/100\n",
      "380/380 [==============================] - 0s 105us/step - loss: 0.2403 - accuracy: 0.8947 - val_loss: 0.5538 - val_accuracy: 0.7791\n",
      "Epoch 20/100\n",
      "380/380 [==============================] - 0s 96us/step - loss: 0.2244 - accuracy: 0.9053 - val_loss: 0.5409 - val_accuracy: 0.7791\n",
      "Epoch 21/100\n",
      "380/380 [==============================] - 0s 95us/step - loss: 0.2106 - accuracy: 0.9211 - val_loss: 0.5698 - val_accuracy: 0.7791\n",
      "Epoch 22/100\n",
      "380/380 [==============================] - 0s 91us/step - loss: 0.2079 - accuracy: 0.9263 - val_loss: 0.5705 - val_accuracy: 0.7791\n",
      "Epoch 23/100\n",
      "380/380 [==============================] - 0s 87us/step - loss: 0.2076 - accuracy: 0.9184 - val_loss: 0.5349 - val_accuracy: 0.7730\n",
      "Epoch 24/100\n",
      "380/380 [==============================] - 0s 101us/step - loss: 0.2005 - accuracy: 0.9184 - val_loss: 0.5300 - val_accuracy: 0.7730\n",
      "Epoch 25/100\n",
      "380/380 [==============================] - 0s 122us/step - loss: 0.2061 - accuracy: 0.9237 - val_loss: 0.5618 - val_accuracy: 0.8160\n",
      "Epoch 26/100\n",
      "380/380 [==============================] - 0s 105us/step - loss: 0.2084 - accuracy: 0.9211 - val_loss: 0.5899 - val_accuracy: 0.7730\n",
      "Epoch 27/100\n",
      "380/380 [==============================] - 0s 97us/step - loss: 0.2091 - accuracy: 0.9237 - val_loss: 0.6025 - val_accuracy: 0.7853\n",
      "Epoch 28/100\n",
      "380/380 [==============================] - 0s 124us/step - loss: 0.2087 - accuracy: 0.9026 - val_loss: 0.5704 - val_accuracy: 0.7853\n",
      "Epoch 29/100\n",
      "380/380 [==============================] - 0s 103us/step - loss: 0.2029 - accuracy: 0.9237 - val_loss: 0.5611 - val_accuracy: 0.7853\n",
      "Epoch 30/100\n",
      "380/380 [==============================] - 0s 135us/step - loss: 0.2229 - accuracy: 0.9211 - val_loss: 0.5930 - val_accuracy: 0.7975\n",
      "Epoch 31/100\n",
      "380/380 [==============================] - 0s 129us/step - loss: 0.2090 - accuracy: 0.9105 - val_loss: 0.5867 - val_accuracy: 0.7791\n",
      "Epoch 32/100\n",
      "380/380 [==============================] - 0s 140us/step - loss: 0.1997 - accuracy: 0.9184 - val_loss: 0.5539 - val_accuracy: 0.8160\n",
      "Epoch 33/100\n",
      "380/380 [==============================] - 0s 132us/step - loss: 0.2083 - accuracy: 0.9158 - val_loss: 0.5522 - val_accuracy: 0.7791\n",
      "Epoch 34/100\n",
      "380/380 [==============================] - 0s 130us/step - loss: 0.1855 - accuracy: 0.9289 - val_loss: 0.5661 - val_accuracy: 0.8037\n",
      "Epoch 35/100\n",
      "380/380 [==============================] - 0s 133us/step - loss: 0.1902 - accuracy: 0.9237 - val_loss: 0.5324 - val_accuracy: 0.7853\n",
      "Epoch 36/100\n",
      "380/380 [==============================] - 0s 131us/step - loss: 0.1990 - accuracy: 0.9184 - val_loss: 0.6570 - val_accuracy: 0.7362\n",
      "Epoch 37/100\n",
      "380/380 [==============================] - 0s 166us/step - loss: 0.1982 - accuracy: 0.9184 - val_loss: 0.5301 - val_accuracy: 0.8037\n",
      "Epoch 38/100\n",
      "380/380 [==============================] - 0s 100us/step - loss: 0.2017 - accuracy: 0.9053 - val_loss: 0.5308 - val_accuracy: 0.7791\n",
      "Epoch 39/100\n",
      "380/380 [==============================] - 0s 86us/step - loss: 0.1950 - accuracy: 0.9211 - val_loss: 0.5476 - val_accuracy: 0.7730\n",
      "Epoch 40/100\n",
      "380/380 [==============================] - 0s 79us/step - loss: 0.1867 - accuracy: 0.9211 - val_loss: 0.5397 - val_accuracy: 0.7730\n",
      "Epoch 41/100\n",
      "380/380 [==============================] - 0s 78us/step - loss: 0.1958 - accuracy: 0.9158 - val_loss: 0.5796 - val_accuracy: 0.7853\n",
      "Epoch 42/100\n",
      "380/380 [==============================] - 0s 85us/step - loss: 0.1934 - accuracy: 0.9289 - val_loss: 0.5835 - val_accuracy: 0.8160\n",
      "Epoch 43/100\n",
      "380/380 [==============================] - 0s 81us/step - loss: 0.1933 - accuracy: 0.9237 - val_loss: 0.5725 - val_accuracy: 0.8160\n",
      "Epoch 44/100\n",
      "380/380 [==============================] - 0s 82us/step - loss: 0.1899 - accuracy: 0.9211 - val_loss: 0.5428 - val_accuracy: 0.8221\n",
      "Epoch 45/100\n",
      "380/380 [==============================] - 0s 92us/step - loss: 0.1901 - accuracy: 0.9289 - val_loss: 0.5346 - val_accuracy: 0.7730\n",
      "Epoch 46/100\n",
      "380/380 [==============================] - 0s 91us/step - loss: 0.1888 - accuracy: 0.9289 - val_loss: 0.5542 - val_accuracy: 0.8160\n",
      "Epoch 47/100\n",
      "380/380 [==============================] - 0s 84us/step - loss: 0.2048 - accuracy: 0.9211 - val_loss: 0.6408 - val_accuracy: 0.7669\n",
      "Epoch 48/100\n",
      "380/380 [==============================] - 0s 101us/step - loss: 0.1836 - accuracy: 0.9211 - val_loss: 0.5399 - val_accuracy: 0.8221\n",
      "Epoch 49/100\n",
      "380/380 [==============================] - 0s 98us/step - loss: 0.1810 - accuracy: 0.9263 - val_loss: 0.5670 - val_accuracy: 0.7730\n",
      "Epoch 50/100\n",
      "380/380 [==============================] - 0s 116us/step - loss: 0.1830 - accuracy: 0.9289 - val_loss: 0.5550 - val_accuracy: 0.8160\n",
      "Epoch 51/100\n",
      "380/380 [==============================] - ETA: 0s - loss: 0.1837 - accuracy: 0.90 - 0s 98us/step - loss: 0.1770 - accuracy: 0.9289 - val_loss: 0.5890 - val_accuracy: 0.7853\n",
      "Epoch 52/100\n",
      "380/380 [==============================] - 0s 91us/step - loss: 0.1783 - accuracy: 0.9237 - val_loss: 0.5299 - val_accuracy: 0.8221\n",
      "Epoch 53/100\n",
      "380/380 [==============================] - 0s 106us/step - loss: 0.1875 - accuracy: 0.9211 - val_loss: 0.5807 - val_accuracy: 0.7730\n",
      "Epoch 54/100\n",
      "380/380 [==============================] - 0s 82us/step - loss: 0.1821 - accuracy: 0.9316 - val_loss: 0.5667 - val_accuracy: 0.8160\n",
      "Epoch 55/100\n",
      "380/380 [==============================] - 0s 89us/step - loss: 0.1922 - accuracy: 0.9132 - val_loss: 0.5411 - val_accuracy: 0.7791\n",
      "Epoch 56/100\n",
      "380/380 [==============================] - 0s 93us/step - loss: 0.1889 - accuracy: 0.9158 - val_loss: 0.5604 - val_accuracy: 0.8160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "380/380 [==============================] - 0s 83us/step - loss: 0.2006 - accuracy: 0.9184 - val_loss: 0.5456 - val_accuracy: 0.7791\n",
      "Epoch 58/100\n",
      "380/380 [==============================] - 0s 98us/step - loss: 0.1853 - accuracy: 0.9316 - val_loss: 0.5438 - val_accuracy: 0.7730\n",
      "Epoch 59/100\n",
      "380/380 [==============================] - 0s 85us/step - loss: 0.1803 - accuracy: 0.9316 - val_loss: 0.6363 - val_accuracy: 0.8037\n",
      "Epoch 60/100\n",
      "380/380 [==============================] - 0s 103us/step - loss: 0.1863 - accuracy: 0.9079 - val_loss: 0.5529 - val_accuracy: 0.8344\n",
      "Epoch 61/100\n",
      "380/380 [==============================] - 0s 101us/step - loss: 0.1848 - accuracy: 0.9289 - val_loss: 0.5541 - val_accuracy: 0.7853\n",
      "Epoch 62/100\n",
      "380/380 [==============================] - 0s 87us/step - loss: 0.1986 - accuracy: 0.9211 - val_loss: 0.5683 - val_accuracy: 0.8160\n",
      "Epoch 63/100\n",
      "380/380 [==============================] - 0s 95us/step - loss: 0.1724 - accuracy: 0.9316 - val_loss: 0.5503 - val_accuracy: 0.7730\n",
      "Epoch 64/100\n",
      "380/380 [==============================] - 0s 89us/step - loss: 0.1758 - accuracy: 0.9289 - val_loss: 0.6021 - val_accuracy: 0.8160\n",
      "Epoch 65/100\n",
      "380/380 [==============================] - 0s 111us/step - loss: 0.1795 - accuracy: 0.9211 - val_loss: 0.5555 - val_accuracy: 0.8037\n",
      "Epoch 66/100\n",
      "380/380 [==============================] - 0s 110us/step - loss: 0.1935 - accuracy: 0.9211 - val_loss: 0.5489 - val_accuracy: 0.7914\n",
      "Epoch 67/100\n",
      "380/380 [==============================] - 0s 109us/step - loss: 0.1819 - accuracy: 0.9237 - val_loss: 0.5826 - val_accuracy: 0.8037\n",
      "Epoch 68/100\n",
      "380/380 [==============================] - 0s 81us/step - loss: 0.1695 - accuracy: 0.9342 - val_loss: 0.5543 - val_accuracy: 0.8344\n",
      "Epoch 69/100\n",
      "380/380 [==============================] - 0s 98us/step - loss: 0.1839 - accuracy: 0.9342 - val_loss: 0.5387 - val_accuracy: 0.7791\n",
      "Epoch 70/100\n",
      "380/380 [==============================] - 0s 85us/step - loss: 0.1730 - accuracy: 0.9316 - val_loss: 0.6530 - val_accuracy: 0.7791\n",
      "Epoch 71/100\n",
      "380/380 [==============================] - 0s 124us/step - loss: 0.1844 - accuracy: 0.9184 - val_loss: 0.5725 - val_accuracy: 0.8160\n",
      "Epoch 72/100\n",
      "380/380 [==============================] - 0s 91us/step - loss: 0.1760 - accuracy: 0.9263 - val_loss: 0.5598 - val_accuracy: 0.8037\n",
      "Epoch 73/100\n",
      "380/380 [==============================] - 0s 97us/step - loss: 0.1797 - accuracy: 0.9237 - val_loss: 0.6062 - val_accuracy: 0.7730\n",
      "Epoch 74/100\n",
      "380/380 [==============================] - 0s 126us/step - loss: 0.1985 - accuracy: 0.9105 - val_loss: 0.5627 - val_accuracy: 0.8037\n",
      "Epoch 75/100\n",
      "380/380 [==============================] - 0s 80us/step - loss: 0.1854 - accuracy: 0.9211 - val_loss: 0.6285 - val_accuracy: 0.8037\n",
      "Epoch 76/100\n",
      "380/380 [==============================] - 0s 83us/step - loss: 0.1894 - accuracy: 0.9211 - val_loss: 0.6003 - val_accuracy: 0.8037\n",
      "Epoch 77/100\n",
      "380/380 [==============================] - 0s 87us/step - loss: 0.1703 - accuracy: 0.9237 - val_loss: 0.5444 - val_accuracy: 0.8160\n",
      "Epoch 78/100\n",
      "380/380 [==============================] - 0s 87us/step - loss: 0.1766 - accuracy: 0.9184 - val_loss: 0.6432 - val_accuracy: 0.8221\n",
      "Epoch 79/100\n",
      "380/380 [==============================] - 0s 93us/step - loss: 0.1763 - accuracy: 0.9289 - val_loss: 0.5415 - val_accuracy: 0.7791\n",
      "Epoch 80/100\n",
      "380/380 [==============================] - 0s 97us/step - loss: 0.1762 - accuracy: 0.9263 - val_loss: 0.5561 - val_accuracy: 0.8037\n",
      "Epoch 81/100\n",
      "380/380 [==============================] - 0s 104us/step - loss: 0.1724 - accuracy: 0.9316 - val_loss: 0.5595 - val_accuracy: 0.8160\n",
      "Epoch 82/100\n",
      "380/380 [==============================] - 0s 107us/step - loss: 0.1714 - accuracy: 0.9289 - val_loss: 0.5835 - val_accuracy: 0.8160\n",
      "Epoch 83/100\n",
      "380/380 [==============================] - 0s 85us/step - loss: 0.1758 - accuracy: 0.9184 - val_loss: 0.5483 - val_accuracy: 0.7791\n",
      "Epoch 84/100\n",
      "380/380 [==============================] - 0s 86us/step - loss: 0.1818 - accuracy: 0.9263 - val_loss: 0.6042 - val_accuracy: 0.8037\n",
      "Epoch 85/100\n",
      "380/380 [==============================] - 0s 88us/step - loss: 0.1793 - accuracy: 0.9211 - val_loss: 0.5649 - val_accuracy: 0.8160\n",
      "Epoch 86/100\n",
      "380/380 [==============================] - 0s 93us/step - loss: 0.1718 - accuracy: 0.9263 - val_loss: 0.5478 - val_accuracy: 0.8037\n",
      "Epoch 87/100\n",
      "380/380 [==============================] - 0s 101us/step - loss: 0.1719 - accuracy: 0.9237 - val_loss: 0.5579 - val_accuracy: 0.8221\n",
      "Epoch 88/100\n",
      "380/380 [==============================] - 0s 86us/step - loss: 0.1677 - accuracy: 0.9289 - val_loss: 0.6422 - val_accuracy: 0.7975\n",
      "Epoch 89/100\n",
      "380/380 [==============================] - 0s 84us/step - loss: 0.1773 - accuracy: 0.9158 - val_loss: 0.5502 - val_accuracy: 0.8098\n",
      "Epoch 90/100\n",
      "380/380 [==============================] - 0s 81us/step - loss: 0.1652 - accuracy: 0.9316 - val_loss: 0.5915 - val_accuracy: 0.8098\n",
      "Epoch 91/100\n",
      "380/380 [==============================] - 0s 81us/step - loss: 0.1755 - accuracy: 0.9263 - val_loss: 0.5719 - val_accuracy: 0.7791\n",
      "Epoch 92/100\n",
      "380/380 [==============================] - 0s 80us/step - loss: 0.1887 - accuracy: 0.9211 - val_loss: 0.5648 - val_accuracy: 0.7853\n",
      "Epoch 93/100\n",
      "380/380 [==============================] - 0s 87us/step - loss: 0.1679 - accuracy: 0.9289 - val_loss: 0.6240 - val_accuracy: 0.8037\n",
      "Epoch 94/100\n",
      "380/380 [==============================] - 0s 121us/step - loss: 0.1714 - accuracy: 0.9211 - val_loss: 0.5336 - val_accuracy: 0.8160\n",
      "Epoch 95/100\n",
      "380/380 [==============================] - 0s 310us/step - loss: 0.1908 - accuracy: 0.9211 - val_loss: 0.5560 - val_accuracy: 0.7853\n",
      "Epoch 96/100\n",
      "380/380 [==============================] - 0s 237us/step - loss: 0.1839 - accuracy: 0.9237 - val_loss: 0.6237 - val_accuracy: 0.8037\n",
      "Epoch 97/100\n",
      "380/380 [==============================] - 0s 194us/step - loss: 0.1857 - accuracy: 0.9184 - val_loss: 0.5835 - val_accuracy: 0.8037\n",
      "Epoch 98/100\n",
      "380/380 [==============================] - 0s 129us/step - loss: 0.1739 - accuracy: 0.9105 - val_loss: 0.5479 - val_accuracy: 0.8344\n",
      "Epoch 99/100\n",
      "380/380 [==============================] - 0s 130us/step - loss: 0.1656 - accuracy: 0.9237 - val_loss: 0.5824 - val_accuracy: 0.8160\n",
      "Epoch 100/100\n",
      "380/380 [==============================] - 0s 148us/step - loss: 0.1715 - accuracy: 0.9316 - val_loss: 0.5466 - val_accuracy: 0.8098\n"
     ]
    }
   ],
   "source": [
    "hist2_over4 = model2_over4.fit(X_sel_train_over, y_sel_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_sel_test_over, y_sel_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 91.86%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist2_over4.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba8 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_lasso_2.xlsx\",\n",
    "                        sheet_name=3,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>NRS236</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.321970e-02</td>\n",
       "      <td>2.446264e-01</td>\n",
       "      <td>7.421539e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>NRS113</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.478230e-02</td>\n",
       "      <td>2.806685e-01</td>\n",
       "      <td>6.845492e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>CFBRSa23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.090251e-01</td>\n",
       "      <td>3.405008e-01</td>\n",
       "      <td>2.504741e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>NRS249</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.987907e-01</td>\n",
       "      <td>5.331044e-01</td>\n",
       "      <td>2.681049e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>107</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.090251e-01</td>\n",
       "      <td>3.405008e-01</td>\n",
       "      <td>2.504741e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>CFBRSa30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.207667e-01</td>\n",
       "      <td>2.792331e-01</td>\n",
       "      <td>2.571588e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>NRS383</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6.129044e-01</td>\n",
       "      <td>3.870795e-01</td>\n",
       "      <td>1.601290e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>NRS110</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.260306e-07</td>\n",
       "      <td>7.910664e-07</td>\n",
       "      <td>9.999989e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.604249e-12</td>\n",
       "      <td>2.698129e-07</td>\n",
       "      <td>9.999998e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>NY439</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.207667e-01</td>\n",
       "      <td>2.792331e-01</td>\n",
       "      <td>2.571588e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>989 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   phage    strain  phenotype  prediction             0  \\\n",
       "0     p0006kpresabs_qual    NRS236          1           2  1.321970e-02   \n",
       "1     p0006kpresabs_qual    NRS113          2           2  3.478230e-02   \n",
       "2     p0006kpresabs_qual  CFBRSa23          0           0  4.090251e-01   \n",
       "3     p0006kpresabs_qual    NRS249          2           1  1.987907e-01   \n",
       "4     p0006kpresabs_qual       107          1           0  4.090251e-01   \n",
       "..                   ...       ...        ...         ...           ...   \n",
       "984  p0017Skpresabs_qual  CFBRSa30          0           0  7.207667e-01   \n",
       "985  p0017Skpresabs_qual    NRS383          1           0  6.129044e-01   \n",
       "986  p0017Skpresabs_qual    NRS110          2           2  3.260306e-07   \n",
       "987  p0017Skpresabs_qual    NRS209          2           2  3.604249e-12   \n",
       "988  p0017Skpresabs_qual     NY439          0           0  7.207667e-01   \n",
       "\n",
       "                1             2  \n",
       "0    2.446264e-01  7.421539e-01  \n",
       "1    2.806685e-01  6.845492e-01  \n",
       "2    3.405008e-01  2.504741e-01  \n",
       "3    5.331044e-01  2.681049e-01  \n",
       "4    3.405008e-01  2.504741e-01  \n",
       "..            ...           ...  \n",
       "984  2.792331e-01  2.571588e-07  \n",
       "985  3.870795e-01  1.601290e-05  \n",
       "986  7.910664e-07  9.999989e-01  \n",
       "987  2.698129e-07  9.999998e-01  \n",
       "988  2.792331e-01  2.571588e-07  \n",
       "\n",
       "[989 rows x 7 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.74581700e-03, 2.88468540e-01, 7.08785600e-01],\n",
       "       [4.71758560e-03, 9.75753660e-01, 1.95287750e-02],\n",
       "       [1.92255250e-04, 7.35249100e-03, 9.92455240e-01],\n",
       "       [5.85535060e-02, 1.85172830e-01, 7.56273700e-01],\n",
       "       [2.88878950e-04, 9.63804100e-01, 3.59069700e-02],\n",
       "       [2.23829400e-06, 9.92302660e-01, 7.69512730e-03],\n",
       "       [1.25340930e-03, 3.29659900e-02, 9.65780600e-01],\n",
       "       [3.12293350e-01, 5.72142100e-02, 6.30492400e-01],\n",
       "       [6.43630160e-04, 9.81170500e-01, 1.81859140e-02],\n",
       "       [9.37851700e-01, 4.23572140e-02, 1.97910460e-02],\n",
       "       [3.11034360e-02, 2.67407200e-01, 7.01489300e-01],\n",
       "       [7.15927700e-03, 8.03341300e-03, 9.84807250e-01],\n",
       "       [1.73330750e-01, 2.99731760e-01, 5.26937500e-01],\n",
       "       [4.71758560e-03, 9.75753660e-01, 1.95287750e-02],\n",
       "       [1.47159160e-01, 5.85265000e-01, 2.67575830e-01],\n",
       "       [9.03133870e-01, 5.17746880e-02, 4.50914540e-02],\n",
       "       [9.88825000e-01, 7.81643200e-05, 1.10968060e-02],\n",
       "       [9.98544200e-04, 9.04473800e-01, 9.45277400e-02],\n",
       "       [6.53156820e-03, 7.55080940e-01, 2.38387480e-01],\n",
       "       [2.73665520e-01, 5.30940600e-01, 1.95393890e-01],\n",
       "       [9.82885840e-01, 1.03948950e-02, 6.71929070e-03],\n",
       "       [8.22161400e-02, 8.38162300e-01, 7.96215400e-02],\n",
       "       [1.85913400e-02, 6.44396000e-02, 9.16969060e-01],\n",
       "       [5.85535060e-02, 1.85172830e-01, 7.56273700e-01],\n",
       "       [9.85801500e-01, 1.24119960e-03, 1.29572940e-02],\n",
       "       [5.85535060e-02, 1.85172830e-01, 7.56273700e-01],\n",
       "       [2.16182790e-04, 3.29451640e-02, 9.66838600e-01],\n",
       "       [4.89789240e-04, 4.20597670e-04, 9.99089600e-01],\n",
       "       [1.90282750e-01, 7.09122100e-02, 7.38805060e-01],\n",
       "       [1.47159160e-01, 5.85265000e-01, 2.67575830e-01],\n",
       "       [5.63474500e-01, 9.44594800e-03, 4.27079530e-01],\n",
       "       [2.73665520e-01, 5.30940600e-01, 1.95393890e-01],\n",
       "       [7.81508600e-02, 1.04467310e-03, 9.20804500e-01],\n",
       "       [1.28297580e-01, 1.52391700e-01, 7.19310640e-01],\n",
       "       [9.98544200e-04, 9.04473800e-01, 9.45277400e-02],\n",
       "       [2.73665520e-01, 5.30940600e-01, 1.95393890e-01],\n",
       "       [9.66194900e-01, 3.53103040e-03, 3.02740370e-02],\n",
       "       [3.68386100e-02, 1.89164950e-01, 7.73996500e-01],\n",
       "       [2.66897630e-03, 6.60801050e-01, 3.36529940e-01],\n",
       "       [9.66194900e-01, 3.53103040e-03, 3.02740370e-02],\n",
       "       [2.04066810e-01, 1.02355750e-02, 7.85697600e-01],\n",
       "       [1.48468580e-03, 9.94087340e-01, 4.42795130e-03],\n",
       "       [1.47159160e-01, 5.85265000e-01, 2.67575830e-01],\n",
       "       [8.97351000e-01, 1.34841160e-05, 1.02635480e-01],\n",
       "       [9.41169500e-01, 2.45169350e-02, 3.43136040e-02],\n",
       "       [1.73330750e-01, 2.99731760e-01, 5.26937500e-01],\n",
       "       [9.89563900e-01, 2.57412270e-03, 7.86200100e-03],\n",
       "       [5.63474500e-01, 9.44594800e-03, 4.27079530e-01],\n",
       "       [7.43875700e-02, 9.02459860e-01, 2.31525530e-02],\n",
       "       [1.73330750e-01, 2.99731760e-01, 5.26937500e-01],\n",
       "       [2.50214760e-03, 9.58823740e-01, 3.86740800e-02],\n",
       "       [7.78845000e-01, 2.37328230e-03, 2.18781620e-01],\n",
       "       [8.05304100e-01, 1.61422030e-02, 1.78553770e-01],\n",
       "       [1.47159160e-01, 5.85265000e-01, 2.67575830e-01],\n",
       "       [3.02337880e-03, 7.56889200e-01, 2.40087350e-01],\n",
       "       [2.94642110e-02, 6.98645230e-01, 2.71890550e-01],\n",
       "       [1.47159160e-01, 5.85265000e-01, 2.67575830e-01],\n",
       "       [2.75474900e-05, 8.97681200e-01, 1.02291346e-01],\n",
       "       [2.95523930e-02, 4.72326220e-01, 4.98121440e-01],\n",
       "       [2.94642110e-02, 6.98645230e-01, 2.71890550e-01],\n",
       "       [8.67480700e-01, 2.54278900e-05, 1.32493840e-01],\n",
       "       [1.73330750e-01, 2.99731760e-01, 5.26937500e-01],\n",
       "       [1.47159160e-01, 5.85265000e-01, 2.67575830e-01],\n",
       "       [9.85186640e-01, 1.00675534e-04, 1.47127400e-02],\n",
       "       [9.03133870e-01, 5.17746880e-02, 4.50914540e-02],\n",
       "       [9.90096200e-01, 8.18772100e-04, 9.08501350e-03],\n",
       "       [9.66194900e-01, 3.53103040e-03, 3.02740370e-02],\n",
       "       [2.50214760e-03, 9.58823740e-01, 3.86740800e-02],\n",
       "       [8.22161400e-02, 8.38162300e-01, 7.96215400e-02],\n",
       "       [8.12832060e-01, 4.33954400e-03, 1.82828440e-01],\n",
       "       [1.68001980e-01, 9.15818850e-03, 8.22839860e-01],\n",
       "       [9.03133870e-01, 5.17746880e-02, 4.50914540e-02],\n",
       "       [2.96875230e-03, 9.39301000e-01, 5.77302870e-02],\n",
       "       [1.47159160e-01, 5.85265000e-01, 2.67575830e-01],\n",
       "       [1.03376250e-04, 9.69634650e-01, 3.02619880e-02],\n",
       "       [2.50214760e-03, 9.58823740e-01, 3.86740800e-02],\n",
       "       [5.80157450e-02, 9.04391770e-01, 3.75924450e-02],\n",
       "       [5.01690400e-03, 4.21960920e-01, 5.73022200e-01],\n",
       "       [2.97581300e-02, 9.21277900e-01, 4.89640350e-02],\n",
       "       [9.03133870e-01, 5.17746880e-02, 4.50914540e-02],\n",
       "       [9.72271400e-01, 8.28812300e-03, 1.94404570e-02],\n",
       "       [2.73665520e-01, 5.30940600e-01, 1.95393890e-01],\n",
       "       [1.69442200e-05, 1.03388810e-02, 9.89644170e-01],\n",
       "       [3.73667570e-01, 5.66045750e-02, 5.69727960e-01],\n",
       "       [6.74903600e-02, 2.05903000e-01, 7.26606600e-01],\n",
       "       [4.83928800e-03, 9.28491830e-01, 6.66689300e-02],\n",
       "       [3.73667570e-01, 5.66045750e-02, 5.69727960e-01],\n",
       "       [1.94091540e-02, 1.01271590e-04, 9.80489550e-01],\n",
       "       [9.63274400e-01, 1.00766900e-02, 2.66489180e-02],\n",
       "       [4.46662600e-03, 1.11740805e-01, 8.83792500e-01],\n",
       "       [8.97351000e-01, 1.34841160e-05, 1.02635480e-01],\n",
       "       [9.88825000e-01, 7.81643200e-05, 1.10968060e-02],\n",
       "       [8.12832060e-01, 4.33954400e-03, 1.82828440e-01],\n",
       "       [5.85535060e-02, 1.85172830e-01, 7.56273700e-01],\n",
       "       [2.14771660e-05, 4.86140460e-04, 9.99492400e-01],\n",
       "       [8.62989350e-02, 6.81622700e-01, 2.32078390e-01],\n",
       "       [1.27253360e-03, 6.00164650e-01, 3.98562900e-01],\n",
       "       [9.72271400e-01, 8.28812300e-03, 1.94404570e-02],\n",
       "       [6.43630160e-04, 9.81170500e-01, 1.81859140e-02],\n",
       "       [1.51392490e-05, 9.86533050e-01, 1.34518170e-02],\n",
       "       [2.50214760e-03, 9.58823740e-01, 3.86740800e-02],\n",
       "       [1.07245630e-01, 3.01893230e-01, 5.90861200e-01],\n",
       "       [9.72271400e-01, 8.28812300e-03, 1.94404570e-02],\n",
       "       [1.66357960e-01, 1.30638900e-01, 7.03003100e-01],\n",
       "       [1.08249530e-02, 9.80207150e-01, 8.96784500e-03],\n",
       "       [5.13990640e-04, 5.85365780e-02, 9.40949500e-01],\n",
       "       [5.85535060e-02, 1.85172830e-01, 7.56273700e-01],\n",
       "       [8.67480700e-01, 2.54278900e-05, 1.32493840e-01],\n",
       "       [9.88825000e-01, 7.81643200e-05, 1.10968060e-02],\n",
       "       [3.92205600e-02, 2.44154050e-01, 7.16625400e-01],\n",
       "       [2.75474900e-05, 8.97681200e-01, 1.02291346e-01],\n",
       "       [1.47159160e-01, 5.85265000e-01, 2.67575830e-01],\n",
       "       [2.51126380e-03, 6.78946500e-01, 3.18542330e-01],\n",
       "       [9.42534100e-01, 1.76052280e-02, 3.98606600e-02],\n",
       "       [8.97351000e-01, 1.34841160e-05, 1.02635480e-01],\n",
       "       [3.40771230e-03, 8.26599700e-02, 9.13932300e-01],\n",
       "       [1.47159160e-01, 5.85265000e-01, 2.67575830e-01],\n",
       "       [3.44732700e-02, 8.77932130e-01, 8.75946300e-02],\n",
       "       [6.05271150e-03, 9.84376550e-01, 9.57068500e-03],\n",
       "       [1.73330750e-01, 2.99731760e-01, 5.26937500e-01],\n",
       "       [4.83928800e-03, 9.28491830e-01, 6.66689300e-02],\n",
       "       [1.40919090e-03, 4.51507870e-01, 5.47082900e-01],\n",
       "       [6.36566900e-02, 1.53007400e-01, 7.83335900e-01],\n",
       "       [9.88825000e-01, 7.81643200e-05, 1.10968060e-02],\n",
       "       [1.68672950e-01, 2.18931750e-02, 8.09433800e-01],\n",
       "       [5.85535060e-02, 1.85172830e-01, 7.56273700e-01],\n",
       "       [5.63474500e-01, 9.44594800e-03, 4.27079530e-01],\n",
       "       [8.23850100e-01, 3.08099070e-02, 1.45340000e-01],\n",
       "       [2.73665520e-01, 5.30940600e-01, 1.95393890e-01],\n",
       "       [2.73665520e-01, 5.30940600e-01, 1.95393890e-01],\n",
       "       [7.01692400e-04, 9.37319300e-04, 9.98360930e-01],\n",
       "       [9.63274400e-01, 1.00766900e-02, 2.66489180e-02],\n",
       "       [7.04740700e-01, 4.04639830e-05, 2.95218800e-01],\n",
       "       [1.47159160e-01, 5.85265000e-01, 2.67575830e-01],\n",
       "       [2.96875230e-03, 9.39301000e-01, 5.77302870e-02],\n",
       "       [4.83928800e-03, 9.28491830e-01, 6.66689300e-02],\n",
       "       [2.73665520e-01, 5.30940600e-01, 1.95393890e-01],\n",
       "       [5.80157450e-02, 9.04391770e-01, 3.75924450e-02],\n",
       "       [4.69490950e-01, 5.31771970e-03, 5.25191370e-01],\n",
       "       [2.97088870e-02, 6.75862300e-01, 2.94428770e-01],\n",
       "       [2.73665520e-01, 5.30940600e-01, 1.95393890e-01],\n",
       "       [1.47159160e-01, 5.85265000e-01, 2.67575830e-01],\n",
       "       [9.88825000e-01, 7.81643200e-05, 1.10968060e-02],\n",
       "       [1.47159160e-01, 5.85265000e-01, 2.67575830e-01],\n",
       "       [6.05271150e-03, 9.84376550e-01, 9.57068500e-03],\n",
       "       [1.77801240e-01, 7.13833800e-01, 1.08364960e-01],\n",
       "       [9.88825000e-01, 7.81643200e-05, 1.10968060e-02],\n",
       "       [9.85801500e-01, 1.24119960e-03, 1.29572940e-02],\n",
       "       [9.37851700e-01, 4.23572140e-02, 1.97910460e-02],\n",
       "       [5.80157450e-02, 9.04391770e-01, 3.75924450e-02],\n",
       "       [4.71758560e-03, 9.75753660e-01, 1.95287750e-02],\n",
       "       [5.85535060e-02, 1.85172830e-01, 7.56273700e-01],\n",
       "       [9.63274400e-01, 1.00766900e-02, 2.66489180e-02],\n",
       "       [9.63274400e-01, 1.00766900e-02, 2.66489180e-02],\n",
       "       [1.63023450e-04, 7.96402200e-02, 9.20196700e-01],\n",
       "       [6.74038830e-04, 2.04650390e-02, 9.78860900e-01],\n",
       "       [1.07430620e-03, 7.33335600e-04, 9.98192370e-01],\n",
       "       [1.07245630e-01, 3.01893230e-01, 5.90861200e-01],\n",
       "       [5.85535060e-02, 1.85172830e-01, 7.56273700e-01],\n",
       "       [7.98386900e-03, 9.72267700e-01, 1.97484080e-02],\n",
       "       [3.02337880e-03, 7.56889200e-01, 2.40087350e-01],\n",
       "       [9.89563900e-01, 2.57412270e-03, 7.86200100e-03],\n",
       "       [7.00659450e-02, 6.64020300e-01, 2.65913780e-01]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob8 = df_proba8[df_proba8['phage']=='p11kpresabs_qual'].iloc[:,-3:]\n",
    "y_prob8 = y_prob8.to_numpy()\n",
    "y_prob8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9384924680031714"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo8 = rocauc_ovo(y_sel_test_over, y_prob8, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9384924680031714"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr8 = rocauc_ovr(y_sel_test_over, y_prob8, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9573197572050784"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovos2 = [ovo5, ovo6, ovo7, ovo8]\n",
    "np.mean(ovos2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.014130795222348162"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(ovos2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9573197572050784"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovrs2 = [ovr5, ovr6, ovr7, ovr8]\n",
    "np.mean(ovrs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.014130795222348162"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(ovrs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs_l_over = [acc_test2_over, acc_test2_over2, acc_test2_over3, acc_test2_over4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling test accuracy mean after lasso: 83.44%\n"
     ]
    }
   ],
   "source": [
    "mean_l_over = np.mean(accs_l_over)\n",
    "print('over-sampling test accuracy mean after lasso: %.2f%%' % (mean_l_over*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling test accuracy standard deviation after lasso: 0.019879588183034303\n"
     ]
    }
   ],
   "source": [
    "std_l_over = np.std(accs_l_over)\n",
    "print('over-sampling test accuracy standard deviation after lasso:', std_l_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs_train_l_over = [np.mean(hist2_over.history['accuracy']), np.mean(hist2_over2.history['accuracy']), np.mean(hist2_over3.history['accuracy']),\n",
    "             np.mean(hist2_over4.history['accuracy'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy mean after lasso: 91.94%\n"
     ]
    }
   ],
   "source": [
    "mean_train_l_over = np.mean(accs_train_l_over)\n",
    "print('over-sampling train accuracy mean after lasso: %.2f%%' % (mean_train_l_over*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy standard deviation after lasso: 0.0026263413\n"
     ]
    }
   ],
   "source": [
    "std_train_l_over = np.std(accs_train_l_over)\n",
    "print('over-sampling train accuracy standard deviation after lasso:', std_train_l_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
