<!DOCTYPE html>
<html>
<head><meta charset="utf-8" />

<title>p11kpresabs_qual</title>

<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>



<style type="text/css">
    /*!
*
* Twitter Bootstrap
*
*/
/*!
 * Bootstrap v3.3.7 (http://getbootstrap.com)
 * Copyright 2011-2016 Twitter, Inc.
 * Licensed under MIT (https://github.com/twbs/bootstrap/blob/master/LICENSE)
 */
/*! normalize.css v3.0.3 | MIT License | github.com/necolas/normalize.css */
html {
  font-family: sans-serif;
  -ms-text-size-adjust: 100%;
  -webkit-text-size-adjust: 100%;
}
body {
  margin: 0;
}
article,
aside,
details,
figcaption,
figure,
footer,
header,
hgroup,
main,
menu,
nav,
section,
summary {
  display: block;
}
audio,
canvas,
progress,
video {
  display: inline-block;
  vertical-align: baseline;
}
audio:not([controls]) {
  display: none;
  height: 0;
}
[hidden],
template {
  display: none;
}
a {
  background-color: transparent;
}
a:active,
a:hover {
  outline: 0;
}
abbr[title] {
  border-bottom: 1px dotted;
}
b,
strong {
  font-weight: bold;
}
dfn {
  font-style: italic;
}
h1 {
  font-size: 2em;
  margin: 0.67em 0;
}
mark {
  background: #ff0;
  color: #000;
}
small {
  font-size: 80%;
}
sub,
sup {
  font-size: 75%;
  line-height: 0;
  position: relative;
  vertical-align: baseline;
}
sup {
  top: -0.5em;
}
sub {
  bottom: -0.25em;
}
img {
  border: 0;
}
svg:not(:root) {
  overflow: hidden;
}
figure {
  margin: 1em 40px;
}
hr {
  box-sizing: content-box;
  height: 0;
}
pre {
  overflow: auto;
}
code,
kbd,
pre,
samp {
  font-family: monospace, monospace;
  font-size: 1em;
}
button,
input,
optgroup,
select,
textarea {
  color: inherit;
  font: inherit;
  margin: 0;
}
button {
  overflow: visible;
}
button,
select {
  text-transform: none;
}
button,
html input[type="button"],
input[type="reset"],
input[type="submit"] {
  -webkit-appearance: button;
  cursor: pointer;
}
button[disabled],
html input[disabled] {
  cursor: default;
}
button::-moz-focus-inner,
input::-moz-focus-inner {
  border: 0;
  padding: 0;
}
input {
  line-height: normal;
}
input[type="checkbox"],
input[type="radio"] {
  box-sizing: border-box;
  padding: 0;
}
input[type="number"]::-webkit-inner-spin-button,
input[type="number"]::-webkit-outer-spin-button {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: textfield;
  box-sizing: content-box;
}
input[type="search"]::-webkit-search-cancel-button,
input[type="search"]::-webkit-search-decoration {
  -webkit-appearance: none;
}
fieldset {
  border: 1px solid #c0c0c0;
  margin: 0 2px;
  padding: 0.35em 0.625em 0.75em;
}
legend {
  border: 0;
  padding: 0;
}
textarea {
  overflow: auto;
}
optgroup {
  font-weight: bold;
}
table {
  border-collapse: collapse;
  border-spacing: 0;
}
td,
th {
  padding: 0;
}
/*! Source: https://github.com/h5bp/html5-boilerplate/blob/master/src/css/main.css */
@media print {
  *,
  *:before,
  *:after {
    background: transparent !important;
    box-shadow: none !important;
    text-shadow: none !important;
  }
  a,
  a:visited {
    text-decoration: underline;
  }
  a[href]:after {
    content: " (" attr(href) ")";
  }
  abbr[title]:after {
    content: " (" attr(title) ")";
  }
  a[href^="#"]:after,
  a[href^="javascript:"]:after {
    content: "";
  }
  pre,
  blockquote {
    border: 1px solid #999;
    page-break-inside: avoid;
  }
  thead {
    display: table-header-group;
  }
  tr,
  img {
    page-break-inside: avoid;
  }
  img {
    max-width: 100% !important;
  }
  p,
  h2,
  h3 {
    orphans: 3;
    widows: 3;
  }
  h2,
  h3 {
    page-break-after: avoid;
  }
  .navbar {
    display: none;
  }
  .btn > .caret,
  .dropup > .btn > .caret {
    border-top-color: #000 !important;
  }
  .label {
    border: 1px solid #000;
  }
  .table {
    border-collapse: collapse !important;
  }
  .table td,
  .table th {
    background-color: #fff !important;
  }
  .table-bordered th,
  .table-bordered td {
    border: 1px solid #ddd !important;
  }
}
@font-face {
  font-family: 'Glyphicons Halflings';
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot');
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot?#iefix') format('embedded-opentype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff2') format('woff2'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff') format('woff'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.ttf') format('truetype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.svg#glyphicons_halflingsregular') format('svg');
}
.glyphicon {
  position: relative;
  top: 1px;
  display: inline-block;
  font-family: 'Glyphicons Halflings';
  font-style: normal;
  font-weight: normal;
  line-height: 1;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
.glyphicon-asterisk:before {
  content: "\002a";
}
.glyphicon-plus:before {
  content: "\002b";
}
.glyphicon-euro:before,
.glyphicon-eur:before {
  content: "\20ac";
}
.glyphicon-minus:before {
  content: "\2212";
}
.glyphicon-cloud:before {
  content: "\2601";
}
.glyphicon-envelope:before {
  content: "\2709";
}
.glyphicon-pencil:before {
  content: "\270f";
}
.glyphicon-glass:before {
  content: "\e001";
}
.glyphicon-music:before {
  content: "\e002";
}
.glyphicon-search:before {
  content: "\e003";
}
.glyphicon-heart:before {
  content: "\e005";
}
.glyphicon-star:before {
  content: "\e006";
}
.glyphicon-star-empty:before {
  content: "\e007";
}
.glyphicon-user:before {
  content: "\e008";
}
.glyphicon-film:before {
  content: "\e009";
}
.glyphicon-th-large:before {
  content: "\e010";
}
.glyphicon-th:before {
  content: "\e011";
}
.glyphicon-th-list:before {
  content: "\e012";
}
.glyphicon-ok:before {
  content: "\e013";
}
.glyphicon-remove:before {
  content: "\e014";
}
.glyphicon-zoom-in:before {
  content: "\e015";
}
.glyphicon-zoom-out:before {
  content: "\e016";
}
.glyphicon-off:before {
  content: "\e017";
}
.glyphicon-signal:before {
  content: "\e018";
}
.glyphicon-cog:before {
  content: "\e019";
}
.glyphicon-trash:before {
  content: "\e020";
}
.glyphicon-home:before {
  content: "\e021";
}
.glyphicon-file:before {
  content: "\e022";
}
.glyphicon-time:before {
  content: "\e023";
}
.glyphicon-road:before {
  content: "\e024";
}
.glyphicon-download-alt:before {
  content: "\e025";
}
.glyphicon-download:before {
  content: "\e026";
}
.glyphicon-upload:before {
  content: "\e027";
}
.glyphicon-inbox:before {
  content: "\e028";
}
.glyphicon-play-circle:before {
  content: "\e029";
}
.glyphicon-repeat:before {
  content: "\e030";
}
.glyphicon-refresh:before {
  content: "\e031";
}
.glyphicon-list-alt:before {
  content: "\e032";
}
.glyphicon-lock:before {
  content: "\e033";
}
.glyphicon-flag:before {
  content: "\e034";
}
.glyphicon-headphones:before {
  content: "\e035";
}
.glyphicon-volume-off:before {
  content: "\e036";
}
.glyphicon-volume-down:before {
  content: "\e037";
}
.glyphicon-volume-up:before {
  content: "\e038";
}
.glyphicon-qrcode:before {
  content: "\e039";
}
.glyphicon-barcode:before {
  content: "\e040";
}
.glyphicon-tag:before {
  content: "\e041";
}
.glyphicon-tags:before {
  content: "\e042";
}
.glyphicon-book:before {
  content: "\e043";
}
.glyphicon-bookmark:before {
  content: "\e044";
}
.glyphicon-print:before {
  content: "\e045";
}
.glyphicon-camera:before {
  content: "\e046";
}
.glyphicon-font:before {
  content: "\e047";
}
.glyphicon-bold:before {
  content: "\e048";
}
.glyphicon-italic:before {
  content: "\e049";
}
.glyphicon-text-height:before {
  content: "\e050";
}
.glyphicon-text-width:before {
  content: "\e051";
}
.glyphicon-align-left:before {
  content: "\e052";
}
.glyphicon-align-center:before {
  content: "\e053";
}
.glyphicon-align-right:before {
  content: "\e054";
}
.glyphicon-align-justify:before {
  content: "\e055";
}
.glyphicon-list:before {
  content: "\e056";
}
.glyphicon-indent-left:before {
  content: "\e057";
}
.glyphicon-indent-right:before {
  content: "\e058";
}
.glyphicon-facetime-video:before {
  content: "\e059";
}
.glyphicon-picture:before {
  content: "\e060";
}
.glyphicon-map-marker:before {
  content: "\e062";
}
.glyphicon-adjust:before {
  content: "\e063";
}
.glyphicon-tint:before {
  content: "\e064";
}
.glyphicon-edit:before {
  content: "\e065";
}
.glyphicon-share:before {
  content: "\e066";
}
.glyphicon-check:before {
  content: "\e067";
}
.glyphicon-move:before {
  content: "\e068";
}
.glyphicon-step-backward:before {
  content: "\e069";
}
.glyphicon-fast-backward:before {
  content: "\e070";
}
.glyphicon-backward:before {
  content: "\e071";
}
.glyphicon-play:before {
  content: "\e072";
}
.glyphicon-pause:before {
  content: "\e073";
}
.glyphicon-stop:before {
  content: "\e074";
}
.glyphicon-forward:before {
  content: "\e075";
}
.glyphicon-fast-forward:before {
  content: "\e076";
}
.glyphicon-step-forward:before {
  content: "\e077";
}
.glyphicon-eject:before {
  content: "\e078";
}
.glyphicon-chevron-left:before {
  content: "\e079";
}
.glyphicon-chevron-right:before {
  content: "\e080";
}
.glyphicon-plus-sign:before {
  content: "\e081";
}
.glyphicon-minus-sign:before {
  content: "\e082";
}
.glyphicon-remove-sign:before {
  content: "\e083";
}
.glyphicon-ok-sign:before {
  content: "\e084";
}
.glyphicon-question-sign:before {
  content: "\e085";
}
.glyphicon-info-sign:before {
  content: "\e086";
}
.glyphicon-screenshot:before {
  content: "\e087";
}
.glyphicon-remove-circle:before {
  content: "\e088";
}
.glyphicon-ok-circle:before {
  content: "\e089";
}
.glyphicon-ban-circle:before {
  content: "\e090";
}
.glyphicon-arrow-left:before {
  content: "\e091";
}
.glyphicon-arrow-right:before {
  content: "\e092";
}
.glyphicon-arrow-up:before {
  content: "\e093";
}
.glyphicon-arrow-down:before {
  content: "\e094";
}
.glyphicon-share-alt:before {
  content: "\e095";
}
.glyphicon-resize-full:before {
  content: "\e096";
}
.glyphicon-resize-small:before {
  content: "\e097";
}
.glyphicon-exclamation-sign:before {
  content: "\e101";
}
.glyphicon-gift:before {
  content: "\e102";
}
.glyphicon-leaf:before {
  content: "\e103";
}
.glyphicon-fire:before {
  content: "\e104";
}
.glyphicon-eye-open:before {
  content: "\e105";
}
.glyphicon-eye-close:before {
  content: "\e106";
}
.glyphicon-warning-sign:before {
  content: "\e107";
}
.glyphicon-plane:before {
  content: "\e108";
}
.glyphicon-calendar:before {
  content: "\e109";
}
.glyphicon-random:before {
  content: "\e110";
}
.glyphicon-comment:before {
  content: "\e111";
}
.glyphicon-magnet:before {
  content: "\e112";
}
.glyphicon-chevron-up:before {
  content: "\e113";
}
.glyphicon-chevron-down:before {
  content: "\e114";
}
.glyphicon-retweet:before {
  content: "\e115";
}
.glyphicon-shopping-cart:before {
  content: "\e116";
}
.glyphicon-folder-close:before {
  content: "\e117";
}
.glyphicon-folder-open:before {
  content: "\e118";
}
.glyphicon-resize-vertical:before {
  content: "\e119";
}
.glyphicon-resize-horizontal:before {
  content: "\e120";
}
.glyphicon-hdd:before {
  content: "\e121";
}
.glyphicon-bullhorn:before {
  content: "\e122";
}
.glyphicon-bell:before {
  content: "\e123";
}
.glyphicon-certificate:before {
  content: "\e124";
}
.glyphicon-thumbs-up:before {
  content: "\e125";
}
.glyphicon-thumbs-down:before {
  content: "\e126";
}
.glyphicon-hand-right:before {
  content: "\e127";
}
.glyphicon-hand-left:before {
  content: "\e128";
}
.glyphicon-hand-up:before {
  content: "\e129";
}
.glyphicon-hand-down:before {
  content: "\e130";
}
.glyphicon-circle-arrow-right:before {
  content: "\e131";
}
.glyphicon-circle-arrow-left:before {
  content: "\e132";
}
.glyphicon-circle-arrow-up:before {
  content: "\e133";
}
.glyphicon-circle-arrow-down:before {
  content: "\e134";
}
.glyphicon-globe:before {
  content: "\e135";
}
.glyphicon-wrench:before {
  content: "\e136";
}
.glyphicon-tasks:before {
  content: "\e137";
}
.glyphicon-filter:before {
  content: "\e138";
}
.glyphicon-briefcase:before {
  content: "\e139";
}
.glyphicon-fullscreen:before {
  content: "\e140";
}
.glyphicon-dashboard:before {
  content: "\e141";
}
.glyphicon-paperclip:before {
  content: "\e142";
}
.glyphicon-heart-empty:before {
  content: "\e143";
}
.glyphicon-link:before {
  content: "\e144";
}
.glyphicon-phone:before {
  content: "\e145";
}
.glyphicon-pushpin:before {
  content: "\e146";
}
.glyphicon-usd:before {
  content: "\e148";
}
.glyphicon-gbp:before {
  content: "\e149";
}
.glyphicon-sort:before {
  content: "\e150";
}
.glyphicon-sort-by-alphabet:before {
  content: "\e151";
}
.glyphicon-sort-by-alphabet-alt:before {
  content: "\e152";
}
.glyphicon-sort-by-order:before {
  content: "\e153";
}
.glyphicon-sort-by-order-alt:before {
  content: "\e154";
}
.glyphicon-sort-by-attributes:before {
  content: "\e155";
}
.glyphicon-sort-by-attributes-alt:before {
  content: "\e156";
}
.glyphicon-unchecked:before {
  content: "\e157";
}
.glyphicon-expand:before {
  content: "\e158";
}
.glyphicon-collapse-down:before {
  content: "\e159";
}
.glyphicon-collapse-up:before {
  content: "\e160";
}
.glyphicon-log-in:before {
  content: "\e161";
}
.glyphicon-flash:before {
  content: "\e162";
}
.glyphicon-log-out:before {
  content: "\e163";
}
.glyphicon-new-window:before {
  content: "\e164";
}
.glyphicon-record:before {
  content: "\e165";
}
.glyphicon-save:before {
  content: "\e166";
}
.glyphicon-open:before {
  content: "\e167";
}
.glyphicon-saved:before {
  content: "\e168";
}
.glyphicon-import:before {
  content: "\e169";
}
.glyphicon-export:before {
  content: "\e170";
}
.glyphicon-send:before {
  content: "\e171";
}
.glyphicon-floppy-disk:before {
  content: "\e172";
}
.glyphicon-floppy-saved:before {
  content: "\e173";
}
.glyphicon-floppy-remove:before {
  content: "\e174";
}
.glyphicon-floppy-save:before {
  content: "\e175";
}
.glyphicon-floppy-open:before {
  content: "\e176";
}
.glyphicon-credit-card:before {
  content: "\e177";
}
.glyphicon-transfer:before {
  content: "\e178";
}
.glyphicon-cutlery:before {
  content: "\e179";
}
.glyphicon-header:before {
  content: "\e180";
}
.glyphicon-compressed:before {
  content: "\e181";
}
.glyphicon-earphone:before {
  content: "\e182";
}
.glyphicon-phone-alt:before {
  content: "\e183";
}
.glyphicon-tower:before {
  content: "\e184";
}
.glyphicon-stats:before {
  content: "\e185";
}
.glyphicon-sd-video:before {
  content: "\e186";
}
.glyphicon-hd-video:before {
  content: "\e187";
}
.glyphicon-subtitles:before {
  content: "\e188";
}
.glyphicon-sound-stereo:before {
  content: "\e189";
}
.glyphicon-sound-dolby:before {
  content: "\e190";
}
.glyphicon-sound-5-1:before {
  content: "\e191";
}
.glyphicon-sound-6-1:before {
  content: "\e192";
}
.glyphicon-sound-7-1:before {
  content: "\e193";
}
.glyphicon-copyright-mark:before {
  content: "\e194";
}
.glyphicon-registration-mark:before {
  content: "\e195";
}
.glyphicon-cloud-download:before {
  content: "\e197";
}
.glyphicon-cloud-upload:before {
  content: "\e198";
}
.glyphicon-tree-conifer:before {
  content: "\e199";
}
.glyphicon-tree-deciduous:before {
  content: "\e200";
}
.glyphicon-cd:before {
  content: "\e201";
}
.glyphicon-save-file:before {
  content: "\e202";
}
.glyphicon-open-file:before {
  content: "\e203";
}
.glyphicon-level-up:before {
  content: "\e204";
}
.glyphicon-copy:before {
  content: "\e205";
}
.glyphicon-paste:before {
  content: "\e206";
}
.glyphicon-alert:before {
  content: "\e209";
}
.glyphicon-equalizer:before {
  content: "\e210";
}
.glyphicon-king:before {
  content: "\e211";
}
.glyphicon-queen:before {
  content: "\e212";
}
.glyphicon-pawn:before {
  content: "\e213";
}
.glyphicon-bishop:before {
  content: "\e214";
}
.glyphicon-knight:before {
  content: "\e215";
}
.glyphicon-baby-formula:before {
  content: "\e216";
}
.glyphicon-tent:before {
  content: "\26fa";
}
.glyphicon-blackboard:before {
  content: "\e218";
}
.glyphicon-bed:before {
  content: "\e219";
}
.glyphicon-apple:before {
  content: "\f8ff";
}
.glyphicon-erase:before {
  content: "\e221";
}
.glyphicon-hourglass:before {
  content: "\231b";
}
.glyphicon-lamp:before {
  content: "\e223";
}
.glyphicon-duplicate:before {
  content: "\e224";
}
.glyphicon-piggy-bank:before {
  content: "\e225";
}
.glyphicon-scissors:before {
  content: "\e226";
}
.glyphicon-bitcoin:before {
  content: "\e227";
}
.glyphicon-btc:before {
  content: "\e227";
}
.glyphicon-xbt:before {
  content: "\e227";
}
.glyphicon-yen:before {
  content: "\00a5";
}
.glyphicon-jpy:before {
  content: "\00a5";
}
.glyphicon-ruble:before {
  content: "\20bd";
}
.glyphicon-rub:before {
  content: "\20bd";
}
.glyphicon-scale:before {
  content: "\e230";
}
.glyphicon-ice-lolly:before {
  content: "\e231";
}
.glyphicon-ice-lolly-tasted:before {
  content: "\e232";
}
.glyphicon-education:before {
  content: "\e233";
}
.glyphicon-option-horizontal:before {
  content: "\e234";
}
.glyphicon-option-vertical:before {
  content: "\e235";
}
.glyphicon-menu-hamburger:before {
  content: "\e236";
}
.glyphicon-modal-window:before {
  content: "\e237";
}
.glyphicon-oil:before {
  content: "\e238";
}
.glyphicon-grain:before {
  content: "\e239";
}
.glyphicon-sunglasses:before {
  content: "\e240";
}
.glyphicon-text-size:before {
  content: "\e241";
}
.glyphicon-text-color:before {
  content: "\e242";
}
.glyphicon-text-background:before {
  content: "\e243";
}
.glyphicon-object-align-top:before {
  content: "\e244";
}
.glyphicon-object-align-bottom:before {
  content: "\e245";
}
.glyphicon-object-align-horizontal:before {
  content: "\e246";
}
.glyphicon-object-align-left:before {
  content: "\e247";
}
.glyphicon-object-align-vertical:before {
  content: "\e248";
}
.glyphicon-object-align-right:before {
  content: "\e249";
}
.glyphicon-triangle-right:before {
  content: "\e250";
}
.glyphicon-triangle-left:before {
  content: "\e251";
}
.glyphicon-triangle-bottom:before {
  content: "\e252";
}
.glyphicon-triangle-top:before {
  content: "\e253";
}
.glyphicon-console:before {
  content: "\e254";
}
.glyphicon-superscript:before {
  content: "\e255";
}
.glyphicon-subscript:before {
  content: "\e256";
}
.glyphicon-menu-left:before {
  content: "\e257";
}
.glyphicon-menu-right:before {
  content: "\e258";
}
.glyphicon-menu-down:before {
  content: "\e259";
}
.glyphicon-menu-up:before {
  content: "\e260";
}
* {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
*:before,
*:after {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
html {
  font-size: 10px;
  -webkit-tap-highlight-color: rgba(0, 0, 0, 0);
}
body {
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-size: 13px;
  line-height: 1.42857143;
  color: #000;
  background-color: #fff;
}
input,
button,
select,
textarea {
  font-family: inherit;
  font-size: inherit;
  line-height: inherit;
}
a {
  color: #337ab7;
  text-decoration: none;
}
a:hover,
a:focus {
  color: #23527c;
  text-decoration: underline;
}
a:focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
figure {
  margin: 0;
}
img {
  vertical-align: middle;
}
.img-responsive,
.thumbnail > img,
.thumbnail a > img,
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  display: block;
  max-width: 100%;
  height: auto;
}
.img-rounded {
  border-radius: 3px;
}
.img-thumbnail {
  padding: 4px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: all 0.2s ease-in-out;
  -o-transition: all 0.2s ease-in-out;
  transition: all 0.2s ease-in-out;
  display: inline-block;
  max-width: 100%;
  height: auto;
}
.img-circle {
  border-radius: 50%;
}
hr {
  margin-top: 18px;
  margin-bottom: 18px;
  border: 0;
  border-top: 1px solid #eeeeee;
}
.sr-only {
  position: absolute;
  width: 1px;
  height: 1px;
  margin: -1px;
  padding: 0;
  overflow: hidden;
  clip: rect(0, 0, 0, 0);
  border: 0;
}
.sr-only-focusable:active,
.sr-only-focusable:focus {
  position: static;
  width: auto;
  height: auto;
  margin: 0;
  overflow: visible;
  clip: auto;
}
[role="button"] {
  cursor: pointer;
}
h1,
h2,
h3,
h4,
h5,
h6,
.h1,
.h2,
.h3,
.h4,
.h5,
.h6 {
  font-family: inherit;
  font-weight: 500;
  line-height: 1.1;
  color: inherit;
}
h1 small,
h2 small,
h3 small,
h4 small,
h5 small,
h6 small,
.h1 small,
.h2 small,
.h3 small,
.h4 small,
.h5 small,
.h6 small,
h1 .small,
h2 .small,
h3 .small,
h4 .small,
h5 .small,
h6 .small,
.h1 .small,
.h2 .small,
.h3 .small,
.h4 .small,
.h5 .small,
.h6 .small {
  font-weight: normal;
  line-height: 1;
  color: #777777;
}
h1,
.h1,
h2,
.h2,
h3,
.h3 {
  margin-top: 18px;
  margin-bottom: 9px;
}
h1 small,
.h1 small,
h2 small,
.h2 small,
h3 small,
.h3 small,
h1 .small,
.h1 .small,
h2 .small,
.h2 .small,
h3 .small,
.h3 .small {
  font-size: 65%;
}
h4,
.h4,
h5,
.h5,
h6,
.h6 {
  margin-top: 9px;
  margin-bottom: 9px;
}
h4 small,
.h4 small,
h5 small,
.h5 small,
h6 small,
.h6 small,
h4 .small,
.h4 .small,
h5 .small,
.h5 .small,
h6 .small,
.h6 .small {
  font-size: 75%;
}
h1,
.h1 {
  font-size: 33px;
}
h2,
.h2 {
  font-size: 27px;
}
h3,
.h3 {
  font-size: 23px;
}
h4,
.h4 {
  font-size: 17px;
}
h5,
.h5 {
  font-size: 13px;
}
h6,
.h6 {
  font-size: 12px;
}
p {
  margin: 0 0 9px;
}
.lead {
  margin-bottom: 18px;
  font-size: 14px;
  font-weight: 300;
  line-height: 1.4;
}
@media (min-width: 768px) {
  .lead {
    font-size: 19.5px;
  }
}
small,
.small {
  font-size: 92%;
}
mark,
.mark {
  background-color: #fcf8e3;
  padding: .2em;
}
.text-left {
  text-align: left;
}
.text-right {
  text-align: right;
}
.text-center {
  text-align: center;
}
.text-justify {
  text-align: justify;
}
.text-nowrap {
  white-space: nowrap;
}
.text-lowercase {
  text-transform: lowercase;
}
.text-uppercase {
  text-transform: uppercase;
}
.text-capitalize {
  text-transform: capitalize;
}
.text-muted {
  color: #777777;
}
.text-primary {
  color: #337ab7;
}
a.text-primary:hover,
a.text-primary:focus {
  color: #286090;
}
.text-success {
  color: #3c763d;
}
a.text-success:hover,
a.text-success:focus {
  color: #2b542c;
}
.text-info {
  color: #31708f;
}
a.text-info:hover,
a.text-info:focus {
  color: #245269;
}
.text-warning {
  color: #8a6d3b;
}
a.text-warning:hover,
a.text-warning:focus {
  color: #66512c;
}
.text-danger {
  color: #a94442;
}
a.text-danger:hover,
a.text-danger:focus {
  color: #843534;
}
.bg-primary {
  color: #fff;
  background-color: #337ab7;
}
a.bg-primary:hover,
a.bg-primary:focus {
  background-color: #286090;
}
.bg-success {
  background-color: #dff0d8;
}
a.bg-success:hover,
a.bg-success:focus {
  background-color: #c1e2b3;
}
.bg-info {
  background-color: #d9edf7;
}
a.bg-info:hover,
a.bg-info:focus {
  background-color: #afd9ee;
}
.bg-warning {
  background-color: #fcf8e3;
}
a.bg-warning:hover,
a.bg-warning:focus {
  background-color: #f7ecb5;
}
.bg-danger {
  background-color: #f2dede;
}
a.bg-danger:hover,
a.bg-danger:focus {
  background-color: #e4b9b9;
}
.page-header {
  padding-bottom: 8px;
  margin: 36px 0 18px;
  border-bottom: 1px solid #eeeeee;
}
ul,
ol {
  margin-top: 0;
  margin-bottom: 9px;
}
ul ul,
ol ul,
ul ol,
ol ol {
  margin-bottom: 0;
}
.list-unstyled {
  padding-left: 0;
  list-style: none;
}
.list-inline {
  padding-left: 0;
  list-style: none;
  margin-left: -5px;
}
.list-inline > li {
  display: inline-block;
  padding-left: 5px;
  padding-right: 5px;
}
dl {
  margin-top: 0;
  margin-bottom: 18px;
}
dt,
dd {
  line-height: 1.42857143;
}
dt {
  font-weight: bold;
}
dd {
  margin-left: 0;
}
@media (min-width: 541px) {
  .dl-horizontal dt {
    float: left;
    width: 160px;
    clear: left;
    text-align: right;
    overflow: hidden;
    text-overflow: ellipsis;
    white-space: nowrap;
  }
  .dl-horizontal dd {
    margin-left: 180px;
  }
}
abbr[title],
abbr[data-original-title] {
  cursor: help;
  border-bottom: 1px dotted #777777;
}
.initialism {
  font-size: 90%;
  text-transform: uppercase;
}
blockquote {
  padding: 9px 18px;
  margin: 0 0 18px;
  font-size: inherit;
  border-left: 5px solid #eeeeee;
}
blockquote p:last-child,
blockquote ul:last-child,
blockquote ol:last-child {
  margin-bottom: 0;
}
blockquote footer,
blockquote small,
blockquote .small {
  display: block;
  font-size: 80%;
  line-height: 1.42857143;
  color: #777777;
}
blockquote footer:before,
blockquote small:before,
blockquote .small:before {
  content: '\2014 \00A0';
}
.blockquote-reverse,
blockquote.pull-right {
  padding-right: 15px;
  padding-left: 0;
  border-right: 5px solid #eeeeee;
  border-left: 0;
  text-align: right;
}
.blockquote-reverse footer:before,
blockquote.pull-right footer:before,
.blockquote-reverse small:before,
blockquote.pull-right small:before,
.blockquote-reverse .small:before,
blockquote.pull-right .small:before {
  content: '';
}
.blockquote-reverse footer:after,
blockquote.pull-right footer:after,
.blockquote-reverse small:after,
blockquote.pull-right small:after,
.blockquote-reverse .small:after,
blockquote.pull-right .small:after {
  content: '\00A0 \2014';
}
address {
  margin-bottom: 18px;
  font-style: normal;
  line-height: 1.42857143;
}
code,
kbd,
pre,
samp {
  font-family: monospace;
}
code {
  padding: 2px 4px;
  font-size: 90%;
  color: #c7254e;
  background-color: #f9f2f4;
  border-radius: 2px;
}
kbd {
  padding: 2px 4px;
  font-size: 90%;
  color: #888;
  background-color: transparent;
  border-radius: 1px;
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.25);
}
kbd kbd {
  padding: 0;
  font-size: 100%;
  font-weight: bold;
  box-shadow: none;
}
pre {
  display: block;
  padding: 8.5px;
  margin: 0 0 9px;
  font-size: 12px;
  line-height: 1.42857143;
  word-break: break-all;
  word-wrap: break-word;
  color: #333333;
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 2px;
}
pre code {
  padding: 0;
  font-size: inherit;
  color: inherit;
  white-space: pre-wrap;
  background-color: transparent;
  border-radius: 0;
}
.pre-scrollable {
  max-height: 340px;
  overflow-y: scroll;
}
.container {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
@media (min-width: 768px) {
  .container {
    width: 768px;
  }
}
@media (min-width: 992px) {
  .container {
    width: 940px;
  }
}
@media (min-width: 1200px) {
  .container {
    width: 1140px;
  }
}
.container-fluid {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
.row {
  margin-left: 0px;
  margin-right: 0px;
}
.col-xs-1, .col-sm-1, .col-md-1, .col-lg-1, .col-xs-2, .col-sm-2, .col-md-2, .col-lg-2, .col-xs-3, .col-sm-3, .col-md-3, .col-lg-3, .col-xs-4, .col-sm-4, .col-md-4, .col-lg-4, .col-xs-5, .col-sm-5, .col-md-5, .col-lg-5, .col-xs-6, .col-sm-6, .col-md-6, .col-lg-6, .col-xs-7, .col-sm-7, .col-md-7, .col-lg-7, .col-xs-8, .col-sm-8, .col-md-8, .col-lg-8, .col-xs-9, .col-sm-9, .col-md-9, .col-lg-9, .col-xs-10, .col-sm-10, .col-md-10, .col-lg-10, .col-xs-11, .col-sm-11, .col-md-11, .col-lg-11, .col-xs-12, .col-sm-12, .col-md-12, .col-lg-12 {
  position: relative;
  min-height: 1px;
  padding-left: 0px;
  padding-right: 0px;
}
.col-xs-1, .col-xs-2, .col-xs-3, .col-xs-4, .col-xs-5, .col-xs-6, .col-xs-7, .col-xs-8, .col-xs-9, .col-xs-10, .col-xs-11, .col-xs-12 {
  float: left;
}
.col-xs-12 {
  width: 100%;
}
.col-xs-11 {
  width: 91.66666667%;
}
.col-xs-10 {
  width: 83.33333333%;
}
.col-xs-9 {
  width: 75%;
}
.col-xs-8 {
  width: 66.66666667%;
}
.col-xs-7 {
  width: 58.33333333%;
}
.col-xs-6 {
  width: 50%;
}
.col-xs-5 {
  width: 41.66666667%;
}
.col-xs-4 {
  width: 33.33333333%;
}
.col-xs-3 {
  width: 25%;
}
.col-xs-2 {
  width: 16.66666667%;
}
.col-xs-1 {
  width: 8.33333333%;
}
.col-xs-pull-12 {
  right: 100%;
}
.col-xs-pull-11 {
  right: 91.66666667%;
}
.col-xs-pull-10 {
  right: 83.33333333%;
}
.col-xs-pull-9 {
  right: 75%;
}
.col-xs-pull-8 {
  right: 66.66666667%;
}
.col-xs-pull-7 {
  right: 58.33333333%;
}
.col-xs-pull-6 {
  right: 50%;
}
.col-xs-pull-5 {
  right: 41.66666667%;
}
.col-xs-pull-4 {
  right: 33.33333333%;
}
.col-xs-pull-3 {
  right: 25%;
}
.col-xs-pull-2 {
  right: 16.66666667%;
}
.col-xs-pull-1 {
  right: 8.33333333%;
}
.col-xs-pull-0 {
  right: auto;
}
.col-xs-push-12 {
  left: 100%;
}
.col-xs-push-11 {
  left: 91.66666667%;
}
.col-xs-push-10 {
  left: 83.33333333%;
}
.col-xs-push-9 {
  left: 75%;
}
.col-xs-push-8 {
  left: 66.66666667%;
}
.col-xs-push-7 {
  left: 58.33333333%;
}
.col-xs-push-6 {
  left: 50%;
}
.col-xs-push-5 {
  left: 41.66666667%;
}
.col-xs-push-4 {
  left: 33.33333333%;
}
.col-xs-push-3 {
  left: 25%;
}
.col-xs-push-2 {
  left: 16.66666667%;
}
.col-xs-push-1 {
  left: 8.33333333%;
}
.col-xs-push-0 {
  left: auto;
}
.col-xs-offset-12 {
  margin-left: 100%;
}
.col-xs-offset-11 {
  margin-left: 91.66666667%;
}
.col-xs-offset-10 {
  margin-left: 83.33333333%;
}
.col-xs-offset-9 {
  margin-left: 75%;
}
.col-xs-offset-8 {
  margin-left: 66.66666667%;
}
.col-xs-offset-7 {
  margin-left: 58.33333333%;
}
.col-xs-offset-6 {
  margin-left: 50%;
}
.col-xs-offset-5 {
  margin-left: 41.66666667%;
}
.col-xs-offset-4 {
  margin-left: 33.33333333%;
}
.col-xs-offset-3 {
  margin-left: 25%;
}
.col-xs-offset-2 {
  margin-left: 16.66666667%;
}
.col-xs-offset-1 {
  margin-left: 8.33333333%;
}
.col-xs-offset-0 {
  margin-left: 0%;
}
@media (min-width: 768px) {
  .col-sm-1, .col-sm-2, .col-sm-3, .col-sm-4, .col-sm-5, .col-sm-6, .col-sm-7, .col-sm-8, .col-sm-9, .col-sm-10, .col-sm-11, .col-sm-12 {
    float: left;
  }
  .col-sm-12 {
    width: 100%;
  }
  .col-sm-11 {
    width: 91.66666667%;
  }
  .col-sm-10 {
    width: 83.33333333%;
  }
  .col-sm-9 {
    width: 75%;
  }
  .col-sm-8 {
    width: 66.66666667%;
  }
  .col-sm-7 {
    width: 58.33333333%;
  }
  .col-sm-6 {
    width: 50%;
  }
  .col-sm-5 {
    width: 41.66666667%;
  }
  .col-sm-4 {
    width: 33.33333333%;
  }
  .col-sm-3 {
    width: 25%;
  }
  .col-sm-2 {
    width: 16.66666667%;
  }
  .col-sm-1 {
    width: 8.33333333%;
  }
  .col-sm-pull-12 {
    right: 100%;
  }
  .col-sm-pull-11 {
    right: 91.66666667%;
  }
  .col-sm-pull-10 {
    right: 83.33333333%;
  }
  .col-sm-pull-9 {
    right: 75%;
  }
  .col-sm-pull-8 {
    right: 66.66666667%;
  }
  .col-sm-pull-7 {
    right: 58.33333333%;
  }
  .col-sm-pull-6 {
    right: 50%;
  }
  .col-sm-pull-5 {
    right: 41.66666667%;
  }
  .col-sm-pull-4 {
    right: 33.33333333%;
  }
  .col-sm-pull-3 {
    right: 25%;
  }
  .col-sm-pull-2 {
    right: 16.66666667%;
  }
  .col-sm-pull-1 {
    right: 8.33333333%;
  }
  .col-sm-pull-0 {
    right: auto;
  }
  .col-sm-push-12 {
    left: 100%;
  }
  .col-sm-push-11 {
    left: 91.66666667%;
  }
  .col-sm-push-10 {
    left: 83.33333333%;
  }
  .col-sm-push-9 {
    left: 75%;
  }
  .col-sm-push-8 {
    left: 66.66666667%;
  }
  .col-sm-push-7 {
    left: 58.33333333%;
  }
  .col-sm-push-6 {
    left: 50%;
  }
  .col-sm-push-5 {
    left: 41.66666667%;
  }
  .col-sm-push-4 {
    left: 33.33333333%;
  }
  .col-sm-push-3 {
    left: 25%;
  }
  .col-sm-push-2 {
    left: 16.66666667%;
  }
  .col-sm-push-1 {
    left: 8.33333333%;
  }
  .col-sm-push-0 {
    left: auto;
  }
  .col-sm-offset-12 {
    margin-left: 100%;
  }
  .col-sm-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-sm-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-sm-offset-9 {
    margin-left: 75%;
  }
  .col-sm-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-sm-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-sm-offset-6 {
    margin-left: 50%;
  }
  .col-sm-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-sm-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-sm-offset-3 {
    margin-left: 25%;
  }
  .col-sm-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-sm-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-sm-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 992px) {
  .col-md-1, .col-md-2, .col-md-3, .col-md-4, .col-md-5, .col-md-6, .col-md-7, .col-md-8, .col-md-9, .col-md-10, .col-md-11, .col-md-12 {
    float: left;
  }
  .col-md-12 {
    width: 100%;
  }
  .col-md-11 {
    width: 91.66666667%;
  }
  .col-md-10 {
    width: 83.33333333%;
  }
  .col-md-9 {
    width: 75%;
  }
  .col-md-8 {
    width: 66.66666667%;
  }
  .col-md-7 {
    width: 58.33333333%;
  }
  .col-md-6 {
    width: 50%;
  }
  .col-md-5 {
    width: 41.66666667%;
  }
  .col-md-4 {
    width: 33.33333333%;
  }
  .col-md-3 {
    width: 25%;
  }
  .col-md-2 {
    width: 16.66666667%;
  }
  .col-md-1 {
    width: 8.33333333%;
  }
  .col-md-pull-12 {
    right: 100%;
  }
  .col-md-pull-11 {
    right: 91.66666667%;
  }
  .col-md-pull-10 {
    right: 83.33333333%;
  }
  .col-md-pull-9 {
    right: 75%;
  }
  .col-md-pull-8 {
    right: 66.66666667%;
  }
  .col-md-pull-7 {
    right: 58.33333333%;
  }
  .col-md-pull-6 {
    right: 50%;
  }
  .col-md-pull-5 {
    right: 41.66666667%;
  }
  .col-md-pull-4 {
    right: 33.33333333%;
  }
  .col-md-pull-3 {
    right: 25%;
  }
  .col-md-pull-2 {
    right: 16.66666667%;
  }
  .col-md-pull-1 {
    right: 8.33333333%;
  }
  .col-md-pull-0 {
    right: auto;
  }
  .col-md-push-12 {
    left: 100%;
  }
  .col-md-push-11 {
    left: 91.66666667%;
  }
  .col-md-push-10 {
    left: 83.33333333%;
  }
  .col-md-push-9 {
    left: 75%;
  }
  .col-md-push-8 {
    left: 66.66666667%;
  }
  .col-md-push-7 {
    left: 58.33333333%;
  }
  .col-md-push-6 {
    left: 50%;
  }
  .col-md-push-5 {
    left: 41.66666667%;
  }
  .col-md-push-4 {
    left: 33.33333333%;
  }
  .col-md-push-3 {
    left: 25%;
  }
  .col-md-push-2 {
    left: 16.66666667%;
  }
  .col-md-push-1 {
    left: 8.33333333%;
  }
  .col-md-push-0 {
    left: auto;
  }
  .col-md-offset-12 {
    margin-left: 100%;
  }
  .col-md-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-md-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-md-offset-9 {
    margin-left: 75%;
  }
  .col-md-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-md-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-md-offset-6 {
    margin-left: 50%;
  }
  .col-md-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-md-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-md-offset-3 {
    margin-left: 25%;
  }
  .col-md-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-md-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-md-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 1200px) {
  .col-lg-1, .col-lg-2, .col-lg-3, .col-lg-4, .col-lg-5, .col-lg-6, .col-lg-7, .col-lg-8, .col-lg-9, .col-lg-10, .col-lg-11, .col-lg-12 {
    float: left;
  }
  .col-lg-12 {
    width: 100%;
  }
  .col-lg-11 {
    width: 91.66666667%;
  }
  .col-lg-10 {
    width: 83.33333333%;
  }
  .col-lg-9 {
    width: 75%;
  }
  .col-lg-8 {
    width: 66.66666667%;
  }
  .col-lg-7 {
    width: 58.33333333%;
  }
  .col-lg-6 {
    width: 50%;
  }
  .col-lg-5 {
    width: 41.66666667%;
  }
  .col-lg-4 {
    width: 33.33333333%;
  }
  .col-lg-3 {
    width: 25%;
  }
  .col-lg-2 {
    width: 16.66666667%;
  }
  .col-lg-1 {
    width: 8.33333333%;
  }
  .col-lg-pull-12 {
    right: 100%;
  }
  .col-lg-pull-11 {
    right: 91.66666667%;
  }
  .col-lg-pull-10 {
    right: 83.33333333%;
  }
  .col-lg-pull-9 {
    right: 75%;
  }
  .col-lg-pull-8 {
    right: 66.66666667%;
  }
  .col-lg-pull-7 {
    right: 58.33333333%;
  }
  .col-lg-pull-6 {
    right: 50%;
  }
  .col-lg-pull-5 {
    right: 41.66666667%;
  }
  .col-lg-pull-4 {
    right: 33.33333333%;
  }
  .col-lg-pull-3 {
    right: 25%;
  }
  .col-lg-pull-2 {
    right: 16.66666667%;
  }
  .col-lg-pull-1 {
    right: 8.33333333%;
  }
  .col-lg-pull-0 {
    right: auto;
  }
  .col-lg-push-12 {
    left: 100%;
  }
  .col-lg-push-11 {
    left: 91.66666667%;
  }
  .col-lg-push-10 {
    left: 83.33333333%;
  }
  .col-lg-push-9 {
    left: 75%;
  }
  .col-lg-push-8 {
    left: 66.66666667%;
  }
  .col-lg-push-7 {
    left: 58.33333333%;
  }
  .col-lg-push-6 {
    left: 50%;
  }
  .col-lg-push-5 {
    left: 41.66666667%;
  }
  .col-lg-push-4 {
    left: 33.33333333%;
  }
  .col-lg-push-3 {
    left: 25%;
  }
  .col-lg-push-2 {
    left: 16.66666667%;
  }
  .col-lg-push-1 {
    left: 8.33333333%;
  }
  .col-lg-push-0 {
    left: auto;
  }
  .col-lg-offset-12 {
    margin-left: 100%;
  }
  .col-lg-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-lg-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-lg-offset-9 {
    margin-left: 75%;
  }
  .col-lg-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-lg-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-lg-offset-6 {
    margin-left: 50%;
  }
  .col-lg-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-lg-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-lg-offset-3 {
    margin-left: 25%;
  }
  .col-lg-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-lg-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-lg-offset-0 {
    margin-left: 0%;
  }
}
table {
  background-color: transparent;
}
caption {
  padding-top: 8px;
  padding-bottom: 8px;
  color: #777777;
  text-align: left;
}
th {
  text-align: left;
}
.table {
  width: 100%;
  max-width: 100%;
  margin-bottom: 18px;
}
.table > thead > tr > th,
.table > tbody > tr > th,
.table > tfoot > tr > th,
.table > thead > tr > td,
.table > tbody > tr > td,
.table > tfoot > tr > td {
  padding: 8px;
  line-height: 1.42857143;
  vertical-align: top;
  border-top: 1px solid #ddd;
}
.table > thead > tr > th {
  vertical-align: bottom;
  border-bottom: 2px solid #ddd;
}
.table > caption + thead > tr:first-child > th,
.table > colgroup + thead > tr:first-child > th,
.table > thead:first-child > tr:first-child > th,
.table > caption + thead > tr:first-child > td,
.table > colgroup + thead > tr:first-child > td,
.table > thead:first-child > tr:first-child > td {
  border-top: 0;
}
.table > tbody + tbody {
  border-top: 2px solid #ddd;
}
.table .table {
  background-color: #fff;
}
.table-condensed > thead > tr > th,
.table-condensed > tbody > tr > th,
.table-condensed > tfoot > tr > th,
.table-condensed > thead > tr > td,
.table-condensed > tbody > tr > td,
.table-condensed > tfoot > tr > td {
  padding: 5px;
}
.table-bordered {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > tbody > tr > th,
.table-bordered > tfoot > tr > th,
.table-bordered > thead > tr > td,
.table-bordered > tbody > tr > td,
.table-bordered > tfoot > tr > td {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > thead > tr > td {
  border-bottom-width: 2px;
}
.table-striped > tbody > tr:nth-of-type(odd) {
  background-color: #f9f9f9;
}
.table-hover > tbody > tr:hover {
  background-color: #f5f5f5;
}
table col[class*="col-"] {
  position: static;
  float: none;
  display: table-column;
}
table td[class*="col-"],
table th[class*="col-"] {
  position: static;
  float: none;
  display: table-cell;
}
.table > thead > tr > td.active,
.table > tbody > tr > td.active,
.table > tfoot > tr > td.active,
.table > thead > tr > th.active,
.table > tbody > tr > th.active,
.table > tfoot > tr > th.active,
.table > thead > tr.active > td,
.table > tbody > tr.active > td,
.table > tfoot > tr.active > td,
.table > thead > tr.active > th,
.table > tbody > tr.active > th,
.table > tfoot > tr.active > th {
  background-color: #f5f5f5;
}
.table-hover > tbody > tr > td.active:hover,
.table-hover > tbody > tr > th.active:hover,
.table-hover > tbody > tr.active:hover > td,
.table-hover > tbody > tr:hover > .active,
.table-hover > tbody > tr.active:hover > th {
  background-color: #e8e8e8;
}
.table > thead > tr > td.success,
.table > tbody > tr > td.success,
.table > tfoot > tr > td.success,
.table > thead > tr > th.success,
.table > tbody > tr > th.success,
.table > tfoot > tr > th.success,
.table > thead > tr.success > td,
.table > tbody > tr.success > td,
.table > tfoot > tr.success > td,
.table > thead > tr.success > th,
.table > tbody > tr.success > th,
.table > tfoot > tr.success > th {
  background-color: #dff0d8;
}
.table-hover > tbody > tr > td.success:hover,
.table-hover > tbody > tr > th.success:hover,
.table-hover > tbody > tr.success:hover > td,
.table-hover > tbody > tr:hover > .success,
.table-hover > tbody > tr.success:hover > th {
  background-color: #d0e9c6;
}
.table > thead > tr > td.info,
.table > tbody > tr > td.info,
.table > tfoot > tr > td.info,
.table > thead > tr > th.info,
.table > tbody > tr > th.info,
.table > tfoot > tr > th.info,
.table > thead > tr.info > td,
.table > tbody > tr.info > td,
.table > tfoot > tr.info > td,
.table > thead > tr.info > th,
.table > tbody > tr.info > th,
.table > tfoot > tr.info > th {
  background-color: #d9edf7;
}
.table-hover > tbody > tr > td.info:hover,
.table-hover > tbody > tr > th.info:hover,
.table-hover > tbody > tr.info:hover > td,
.table-hover > tbody > tr:hover > .info,
.table-hover > tbody > tr.info:hover > th {
  background-color: #c4e3f3;
}
.table > thead > tr > td.warning,
.table > tbody > tr > td.warning,
.table > tfoot > tr > td.warning,
.table > thead > tr > th.warning,
.table > tbody > tr > th.warning,
.table > tfoot > tr > th.warning,
.table > thead > tr.warning > td,
.table > tbody > tr.warning > td,
.table > tfoot > tr.warning > td,
.table > thead > tr.warning > th,
.table > tbody > tr.warning > th,
.table > tfoot > tr.warning > th {
  background-color: #fcf8e3;
}
.table-hover > tbody > tr > td.warning:hover,
.table-hover > tbody > tr > th.warning:hover,
.table-hover > tbody > tr.warning:hover > td,
.table-hover > tbody > tr:hover > .warning,
.table-hover > tbody > tr.warning:hover > th {
  background-color: #faf2cc;
}
.table > thead > tr > td.danger,
.table > tbody > tr > td.danger,
.table > tfoot > tr > td.danger,
.table > thead > tr > th.danger,
.table > tbody > tr > th.danger,
.table > tfoot > tr > th.danger,
.table > thead > tr.danger > td,
.table > tbody > tr.danger > td,
.table > tfoot > tr.danger > td,
.table > thead > tr.danger > th,
.table > tbody > tr.danger > th,
.table > tfoot > tr.danger > th {
  background-color: #f2dede;
}
.table-hover > tbody > tr > td.danger:hover,
.table-hover > tbody > tr > th.danger:hover,
.table-hover > tbody > tr.danger:hover > td,
.table-hover > tbody > tr:hover > .danger,
.table-hover > tbody > tr.danger:hover > th {
  background-color: #ebcccc;
}
.table-responsive {
  overflow-x: auto;
  min-height: 0.01%;
}
@media screen and (max-width: 767px) {
  .table-responsive {
    width: 100%;
    margin-bottom: 13.5px;
    overflow-y: hidden;
    -ms-overflow-style: -ms-autohiding-scrollbar;
    border: 1px solid #ddd;
  }
  .table-responsive > .table {
    margin-bottom: 0;
  }
  .table-responsive > .table > thead > tr > th,
  .table-responsive > .table > tbody > tr > th,
  .table-responsive > .table > tfoot > tr > th,
  .table-responsive > .table > thead > tr > td,
  .table-responsive > .table > tbody > tr > td,
  .table-responsive > .table > tfoot > tr > td {
    white-space: nowrap;
  }
  .table-responsive > .table-bordered {
    border: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:first-child,
  .table-responsive > .table-bordered > tbody > tr > th:first-child,
  .table-responsive > .table-bordered > tfoot > tr > th:first-child,
  .table-responsive > .table-bordered > thead > tr > td:first-child,
  .table-responsive > .table-bordered > tbody > tr > td:first-child,
  .table-responsive > .table-bordered > tfoot > tr > td:first-child {
    border-left: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:last-child,
  .table-responsive > .table-bordered > tbody > tr > th:last-child,
  .table-responsive > .table-bordered > tfoot > tr > th:last-child,
  .table-responsive > .table-bordered > thead > tr > td:last-child,
  .table-responsive > .table-bordered > tbody > tr > td:last-child,
  .table-responsive > .table-bordered > tfoot > tr > td:last-child {
    border-right: 0;
  }
  .table-responsive > .table-bordered > tbody > tr:last-child > th,
  .table-responsive > .table-bordered > tfoot > tr:last-child > th,
  .table-responsive > .table-bordered > tbody > tr:last-child > td,
  .table-responsive > .table-bordered > tfoot > tr:last-child > td {
    border-bottom: 0;
  }
}
fieldset {
  padding: 0;
  margin: 0;
  border: 0;
  min-width: 0;
}
legend {
  display: block;
  width: 100%;
  padding: 0;
  margin-bottom: 18px;
  font-size: 19.5px;
  line-height: inherit;
  color: #333333;
  border: 0;
  border-bottom: 1px solid #e5e5e5;
}
label {
  display: inline-block;
  max-width: 100%;
  margin-bottom: 5px;
  font-weight: bold;
}
input[type="search"] {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
input[type="radio"],
input[type="checkbox"] {
  margin: 4px 0 0;
  margin-top: 1px \9;
  line-height: normal;
}
input[type="file"] {
  display: block;
}
input[type="range"] {
  display: block;
  width: 100%;
}
select[multiple],
select[size] {
  height: auto;
}
input[type="file"]:focus,
input[type="radio"]:focus,
input[type="checkbox"]:focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
output {
  display: block;
  padding-top: 7px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
}
.form-control {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
}
.form-control:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.form-control::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.form-control:-ms-input-placeholder {
  color: #999;
}
.form-control::-webkit-input-placeholder {
  color: #999;
}
.form-control::-ms-expand {
  border: 0;
  background-color: transparent;
}
.form-control[disabled],
.form-control[readonly],
fieldset[disabled] .form-control {
  background-color: #eeeeee;
  opacity: 1;
}
.form-control[disabled],
fieldset[disabled] .form-control {
  cursor: not-allowed;
}
textarea.form-control {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: none;
}
@media screen and (-webkit-min-device-pixel-ratio: 0) {
  input[type="date"].form-control,
  input[type="time"].form-control,
  input[type="datetime-local"].form-control,
  input[type="month"].form-control {
    line-height: 32px;
  }
  input[type="date"].input-sm,
  input[type="time"].input-sm,
  input[type="datetime-local"].input-sm,
  input[type="month"].input-sm,
  .input-group-sm input[type="date"],
  .input-group-sm input[type="time"],
  .input-group-sm input[type="datetime-local"],
  .input-group-sm input[type="month"] {
    line-height: 30px;
  }
  input[type="date"].input-lg,
  input[type="time"].input-lg,
  input[type="datetime-local"].input-lg,
  input[type="month"].input-lg,
  .input-group-lg input[type="date"],
  .input-group-lg input[type="time"],
  .input-group-lg input[type="datetime-local"],
  .input-group-lg input[type="month"] {
    line-height: 45px;
  }
}
.form-group {
  margin-bottom: 15px;
}
.radio,
.checkbox {
  position: relative;
  display: block;
  margin-top: 10px;
  margin-bottom: 10px;
}
.radio label,
.checkbox label {
  min-height: 18px;
  padding-left: 20px;
  margin-bottom: 0;
  font-weight: normal;
  cursor: pointer;
}
.radio input[type="radio"],
.radio-inline input[type="radio"],
.checkbox input[type="checkbox"],
.checkbox-inline input[type="checkbox"] {
  position: absolute;
  margin-left: -20px;
  margin-top: 4px \9;
}
.radio + .radio,
.checkbox + .checkbox {
  margin-top: -5px;
}
.radio-inline,
.checkbox-inline {
  position: relative;
  display: inline-block;
  padding-left: 20px;
  margin-bottom: 0;
  vertical-align: middle;
  font-weight: normal;
  cursor: pointer;
}
.radio-inline + .radio-inline,
.checkbox-inline + .checkbox-inline {
  margin-top: 0;
  margin-left: 10px;
}
input[type="radio"][disabled],
input[type="checkbox"][disabled],
input[type="radio"].disabled,
input[type="checkbox"].disabled,
fieldset[disabled] input[type="radio"],
fieldset[disabled] input[type="checkbox"] {
  cursor: not-allowed;
}
.radio-inline.disabled,
.checkbox-inline.disabled,
fieldset[disabled] .radio-inline,
fieldset[disabled] .checkbox-inline {
  cursor: not-allowed;
}
.radio.disabled label,
.checkbox.disabled label,
fieldset[disabled] .radio label,
fieldset[disabled] .checkbox label {
  cursor: not-allowed;
}
.form-control-static {
  padding-top: 7px;
  padding-bottom: 7px;
  margin-bottom: 0;
  min-height: 31px;
}
.form-control-static.input-lg,
.form-control-static.input-sm {
  padding-left: 0;
  padding-right: 0;
}
.input-sm {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-sm {
  height: 30px;
  line-height: 30px;
}
textarea.input-sm,
select[multiple].input-sm {
  height: auto;
}
.form-group-sm .form-control {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.form-group-sm select.form-control {
  height: 30px;
  line-height: 30px;
}
.form-group-sm textarea.form-control,
.form-group-sm select[multiple].form-control {
  height: auto;
}
.form-group-sm .form-control-static {
  height: 30px;
  min-height: 30px;
  padding: 6px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.input-lg {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-lg {
  height: 45px;
  line-height: 45px;
}
textarea.input-lg,
select[multiple].input-lg {
  height: auto;
}
.form-group-lg .form-control {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.form-group-lg select.form-control {
  height: 45px;
  line-height: 45px;
}
.form-group-lg textarea.form-control,
.form-group-lg select[multiple].form-control {
  height: auto;
}
.form-group-lg .form-control-static {
  height: 45px;
  min-height: 35px;
  padding: 11px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.has-feedback {
  position: relative;
}
.has-feedback .form-control {
  padding-right: 40px;
}
.form-control-feedback {
  position: absolute;
  top: 0;
  right: 0;
  z-index: 2;
  display: block;
  width: 32px;
  height: 32px;
  line-height: 32px;
  text-align: center;
  pointer-events: none;
}
.input-lg + .form-control-feedback,
.input-group-lg + .form-control-feedback,
.form-group-lg .form-control + .form-control-feedback {
  width: 45px;
  height: 45px;
  line-height: 45px;
}
.input-sm + .form-control-feedback,
.input-group-sm + .form-control-feedback,
.form-group-sm .form-control + .form-control-feedback {
  width: 30px;
  height: 30px;
  line-height: 30px;
}
.has-success .help-block,
.has-success .control-label,
.has-success .radio,
.has-success .checkbox,
.has-success .radio-inline,
.has-success .checkbox-inline,
.has-success.radio label,
.has-success.checkbox label,
.has-success.radio-inline label,
.has-success.checkbox-inline label {
  color: #3c763d;
}
.has-success .form-control {
  border-color: #3c763d;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-success .form-control:focus {
  border-color: #2b542c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
}
.has-success .input-group-addon {
  color: #3c763d;
  border-color: #3c763d;
  background-color: #dff0d8;
}
.has-success .form-control-feedback {
  color: #3c763d;
}
.has-warning .help-block,
.has-warning .control-label,
.has-warning .radio,
.has-warning .checkbox,
.has-warning .radio-inline,
.has-warning .checkbox-inline,
.has-warning.radio label,
.has-warning.checkbox label,
.has-warning.radio-inline label,
.has-warning.checkbox-inline label {
  color: #8a6d3b;
}
.has-warning .form-control {
  border-color: #8a6d3b;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-warning .form-control:focus {
  border-color: #66512c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
}
.has-warning .input-group-addon {
  color: #8a6d3b;
  border-color: #8a6d3b;
  background-color: #fcf8e3;
}
.has-warning .form-control-feedback {
  color: #8a6d3b;
}
.has-error .help-block,
.has-error .control-label,
.has-error .radio,
.has-error .checkbox,
.has-error .radio-inline,
.has-error .checkbox-inline,
.has-error.radio label,
.has-error.checkbox label,
.has-error.radio-inline label,
.has-error.checkbox-inline label {
  color: #a94442;
}
.has-error .form-control {
  border-color: #a94442;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-error .form-control:focus {
  border-color: #843534;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
}
.has-error .input-group-addon {
  color: #a94442;
  border-color: #a94442;
  background-color: #f2dede;
}
.has-error .form-control-feedback {
  color: #a94442;
}
.has-feedback label ~ .form-control-feedback {
  top: 23px;
}
.has-feedback label.sr-only ~ .form-control-feedback {
  top: 0;
}
.help-block {
  display: block;
  margin-top: 5px;
  margin-bottom: 10px;
  color: #404040;
}
@media (min-width: 768px) {
  .form-inline .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .form-inline .form-control-static {
    display: inline-block;
  }
  .form-inline .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .form-inline .input-group .input-group-addon,
  .form-inline .input-group .input-group-btn,
  .form-inline .input-group .form-control {
    width: auto;
  }
  .form-inline .input-group > .form-control {
    width: 100%;
  }
  .form-inline .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio,
  .form-inline .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio label,
  .form-inline .checkbox label {
    padding-left: 0;
  }
  .form-inline .radio input[type="radio"],
  .form-inline .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .form-inline .has-feedback .form-control-feedback {
    top: 0;
  }
}
.form-horizontal .radio,
.form-horizontal .checkbox,
.form-horizontal .radio-inline,
.form-horizontal .checkbox-inline {
  margin-top: 0;
  margin-bottom: 0;
  padding-top: 7px;
}
.form-horizontal .radio,
.form-horizontal .checkbox {
  min-height: 25px;
}
.form-horizontal .form-group {
  margin-left: 0px;
  margin-right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .control-label {
    text-align: right;
    margin-bottom: 0;
    padding-top: 7px;
  }
}
.form-horizontal .has-feedback .form-control-feedback {
  right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .form-group-lg .control-label {
    padding-top: 11px;
    font-size: 17px;
  }
}
@media (min-width: 768px) {
  .form-horizontal .form-group-sm .control-label {
    padding-top: 6px;
    font-size: 12px;
  }
}
.btn {
  display: inline-block;
  margin-bottom: 0;
  font-weight: normal;
  text-align: center;
  vertical-align: middle;
  touch-action: manipulation;
  cursor: pointer;
  background-image: none;
  border: 1px solid transparent;
  white-space: nowrap;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  border-radius: 2px;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}
.btn:focus,
.btn:active:focus,
.btn.active:focus,
.btn.focus,
.btn:active.focus,
.btn.active.focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
.btn:hover,
.btn:focus,
.btn.focus {
  color: #333;
  text-decoration: none;
}
.btn:active,
.btn.active {
  outline: 0;
  background-image: none;
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn.disabled,
.btn[disabled],
fieldset[disabled] .btn {
  cursor: not-allowed;
  opacity: 0.65;
  filter: alpha(opacity=65);
  -webkit-box-shadow: none;
  box-shadow: none;
}
a.btn.disabled,
fieldset[disabled] a.btn {
  pointer-events: none;
}
.btn-default {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.btn-default:focus,
.btn-default.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.btn-default:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active:hover,
.btn-default.active:hover,
.open > .dropdown-toggle.btn-default:hover,
.btn-default:active:focus,
.btn-default.active:focus,
.open > .dropdown-toggle.btn-default:focus,
.btn-default:active.focus,
.btn-default.active.focus,
.open > .dropdown-toggle.btn-default.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  background-image: none;
}
.btn-default.disabled:hover,
.btn-default[disabled]:hover,
fieldset[disabled] .btn-default:hover,
.btn-default.disabled:focus,
.btn-default[disabled]:focus,
fieldset[disabled] .btn-default:focus,
.btn-default.disabled.focus,
.btn-default[disabled].focus,
fieldset[disabled] .btn-default.focus {
  background-color: #fff;
  border-color: #ccc;
}
.btn-default .badge {
  color: #fff;
  background-color: #333;
}
.btn-primary {
  color: #fff;
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary:focus,
.btn-primary.focus {
  color: #fff;
  background-color: #286090;
  border-color: #122b40;
}
.btn-primary:hover {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active:hover,
.btn-primary.active:hover,
.open > .dropdown-toggle.btn-primary:hover,
.btn-primary:active:focus,
.btn-primary.active:focus,
.open > .dropdown-toggle.btn-primary:focus,
.btn-primary:active.focus,
.btn-primary.active.focus,
.open > .dropdown-toggle.btn-primary.focus {
  color: #fff;
  background-color: #204d74;
  border-color: #122b40;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  background-image: none;
}
.btn-primary.disabled:hover,
.btn-primary[disabled]:hover,
fieldset[disabled] .btn-primary:hover,
.btn-primary.disabled:focus,
.btn-primary[disabled]:focus,
fieldset[disabled] .btn-primary:focus,
.btn-primary.disabled.focus,
.btn-primary[disabled].focus,
fieldset[disabled] .btn-primary.focus {
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary .badge {
  color: #337ab7;
  background-color: #fff;
}
.btn-success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success:focus,
.btn-success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.btn-success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active:hover,
.btn-success.active:hover,
.open > .dropdown-toggle.btn-success:hover,
.btn-success:active:focus,
.btn-success.active:focus,
.open > .dropdown-toggle.btn-success:focus,
.btn-success:active.focus,
.btn-success.active.focus,
.open > .dropdown-toggle.btn-success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  background-image: none;
}
.btn-success.disabled:hover,
.btn-success[disabled]:hover,
fieldset[disabled] .btn-success:hover,
.btn-success.disabled:focus,
.btn-success[disabled]:focus,
fieldset[disabled] .btn-success:focus,
.btn-success.disabled.focus,
.btn-success[disabled].focus,
fieldset[disabled] .btn-success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.btn-info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info:focus,
.btn-info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.btn-info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active:hover,
.btn-info.active:hover,
.open > .dropdown-toggle.btn-info:hover,
.btn-info:active:focus,
.btn-info.active:focus,
.open > .dropdown-toggle.btn-info:focus,
.btn-info:active.focus,
.btn-info.active.focus,
.open > .dropdown-toggle.btn-info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  background-image: none;
}
.btn-info.disabled:hover,
.btn-info[disabled]:hover,
fieldset[disabled] .btn-info:hover,
.btn-info.disabled:focus,
.btn-info[disabled]:focus,
fieldset[disabled] .btn-info:focus,
.btn-info.disabled.focus,
.btn-info[disabled].focus,
fieldset[disabled] .btn-info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.btn-warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning:focus,
.btn-warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.btn-warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active:hover,
.btn-warning.active:hover,
.open > .dropdown-toggle.btn-warning:hover,
.btn-warning:active:focus,
.btn-warning.active:focus,
.open > .dropdown-toggle.btn-warning:focus,
.btn-warning:active.focus,
.btn-warning.active.focus,
.open > .dropdown-toggle.btn-warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  background-image: none;
}
.btn-warning.disabled:hover,
.btn-warning[disabled]:hover,
fieldset[disabled] .btn-warning:hover,
.btn-warning.disabled:focus,
.btn-warning[disabled]:focus,
fieldset[disabled] .btn-warning:focus,
.btn-warning.disabled.focus,
.btn-warning[disabled].focus,
fieldset[disabled] .btn-warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.btn-danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger:focus,
.btn-danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.btn-danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active:hover,
.btn-danger.active:hover,
.open > .dropdown-toggle.btn-danger:hover,
.btn-danger:active:focus,
.btn-danger.active:focus,
.open > .dropdown-toggle.btn-danger:focus,
.btn-danger:active.focus,
.btn-danger.active.focus,
.open > .dropdown-toggle.btn-danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  background-image: none;
}
.btn-danger.disabled:hover,
.btn-danger[disabled]:hover,
fieldset[disabled] .btn-danger:hover,
.btn-danger.disabled:focus,
.btn-danger[disabled]:focus,
fieldset[disabled] .btn-danger:focus,
.btn-danger.disabled.focus,
.btn-danger[disabled].focus,
fieldset[disabled] .btn-danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger .badge {
  color: #d9534f;
  background-color: #fff;
}
.btn-link {
  color: #337ab7;
  font-weight: normal;
  border-radius: 0;
}
.btn-link,
.btn-link:active,
.btn-link.active,
.btn-link[disabled],
fieldset[disabled] .btn-link {
  background-color: transparent;
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn-link,
.btn-link:hover,
.btn-link:focus,
.btn-link:active {
  border-color: transparent;
}
.btn-link:hover,
.btn-link:focus {
  color: #23527c;
  text-decoration: underline;
  background-color: transparent;
}
.btn-link[disabled]:hover,
fieldset[disabled] .btn-link:hover,
.btn-link[disabled]:focus,
fieldset[disabled] .btn-link:focus {
  color: #777777;
  text-decoration: none;
}
.btn-lg,
.btn-group-lg > .btn {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.btn-sm,
.btn-group-sm > .btn {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-xs,
.btn-group-xs > .btn {
  padding: 1px 5px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-block {
  display: block;
  width: 100%;
}
.btn-block + .btn-block {
  margin-top: 5px;
}
input[type="submit"].btn-block,
input[type="reset"].btn-block,
input[type="button"].btn-block {
  width: 100%;
}
.fade {
  opacity: 0;
  -webkit-transition: opacity 0.15s linear;
  -o-transition: opacity 0.15s linear;
  transition: opacity 0.15s linear;
}
.fade.in {
  opacity: 1;
}
.collapse {
  display: none;
}
.collapse.in {
  display: block;
}
tr.collapse.in {
  display: table-row;
}
tbody.collapse.in {
  display: table-row-group;
}
.collapsing {
  position: relative;
  height: 0;
  overflow: hidden;
  -webkit-transition-property: height, visibility;
  transition-property: height, visibility;
  -webkit-transition-duration: 0.35s;
  transition-duration: 0.35s;
  -webkit-transition-timing-function: ease;
  transition-timing-function: ease;
}
.caret {
  display: inline-block;
  width: 0;
  height: 0;
  margin-left: 2px;
  vertical-align: middle;
  border-top: 4px dashed;
  border-top: 4px solid \9;
  border-right: 4px solid transparent;
  border-left: 4px solid transparent;
}
.dropup,
.dropdown {
  position: relative;
}
.dropdown-toggle:focus {
  outline: 0;
}
.dropdown-menu {
  position: absolute;
  top: 100%;
  left: 0;
  z-index: 1000;
  display: none;
  float: left;
  min-width: 160px;
  padding: 5px 0;
  margin: 2px 0 0;
  list-style: none;
  font-size: 13px;
  text-align: left;
  background-color: #fff;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.15);
  border-radius: 2px;
  -webkit-box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  background-clip: padding-box;
}
.dropdown-menu.pull-right {
  right: 0;
  left: auto;
}
.dropdown-menu .divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.dropdown-menu > li > a {
  display: block;
  padding: 3px 20px;
  clear: both;
  font-weight: normal;
  line-height: 1.42857143;
  color: #333333;
  white-space: nowrap;
}
.dropdown-menu > li > a:hover,
.dropdown-menu > li > a:focus {
  text-decoration: none;
  color: #262626;
  background-color: #f5f5f5;
}
.dropdown-menu > .active > a,
.dropdown-menu > .active > a:hover,
.dropdown-menu > .active > a:focus {
  color: #fff;
  text-decoration: none;
  outline: 0;
  background-color: #337ab7;
}
.dropdown-menu > .disabled > a,
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  color: #777777;
}
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  text-decoration: none;
  background-color: transparent;
  background-image: none;
  filter: progid:DXImageTransform.Microsoft.gradient(enabled = false);
  cursor: not-allowed;
}
.open > .dropdown-menu {
  display: block;
}
.open > a {
  outline: 0;
}
.dropdown-menu-right {
  left: auto;
  right: 0;
}
.dropdown-menu-left {
  left: 0;
  right: auto;
}
.dropdown-header {
  display: block;
  padding: 3px 20px;
  font-size: 12px;
  line-height: 1.42857143;
  color: #777777;
  white-space: nowrap;
}
.dropdown-backdrop {
  position: fixed;
  left: 0;
  right: 0;
  bottom: 0;
  top: 0;
  z-index: 990;
}
.pull-right > .dropdown-menu {
  right: 0;
  left: auto;
}
.dropup .caret,
.navbar-fixed-bottom .dropdown .caret {
  border-top: 0;
  border-bottom: 4px dashed;
  border-bottom: 4px solid \9;
  content: "";
}
.dropup .dropdown-menu,
.navbar-fixed-bottom .dropdown .dropdown-menu {
  top: auto;
  bottom: 100%;
  margin-bottom: 2px;
}
@media (min-width: 541px) {
  .navbar-right .dropdown-menu {
    left: auto;
    right: 0;
  }
  .navbar-right .dropdown-menu-left {
    left: 0;
    right: auto;
  }
}
.btn-group,
.btn-group-vertical {
  position: relative;
  display: inline-block;
  vertical-align: middle;
}
.btn-group > .btn,
.btn-group-vertical > .btn {
  position: relative;
  float: left;
}
.btn-group > .btn:hover,
.btn-group-vertical > .btn:hover,
.btn-group > .btn:focus,
.btn-group-vertical > .btn:focus,
.btn-group > .btn:active,
.btn-group-vertical > .btn:active,
.btn-group > .btn.active,
.btn-group-vertical > .btn.active {
  z-index: 2;
}
.btn-group .btn + .btn,
.btn-group .btn + .btn-group,
.btn-group .btn-group + .btn,
.btn-group .btn-group + .btn-group {
  margin-left: -1px;
}
.btn-toolbar {
  margin-left: -5px;
}
.btn-toolbar .btn,
.btn-toolbar .btn-group,
.btn-toolbar .input-group {
  float: left;
}
.btn-toolbar > .btn,
.btn-toolbar > .btn-group,
.btn-toolbar > .input-group {
  margin-left: 5px;
}
.btn-group > .btn:not(:first-child):not(:last-child):not(.dropdown-toggle) {
  border-radius: 0;
}
.btn-group > .btn:first-child {
  margin-left: 0;
}
.btn-group > .btn:first-child:not(:last-child):not(.dropdown-toggle) {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn:last-child:not(:first-child),
.btn-group > .dropdown-toggle:not(:first-child) {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group > .btn-group {
  float: left;
}
.btn-group > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group .dropdown-toggle:active,
.btn-group.open .dropdown-toggle {
  outline: 0;
}
.btn-group > .btn + .dropdown-toggle {
  padding-left: 8px;
  padding-right: 8px;
}
.btn-group > .btn-lg + .dropdown-toggle {
  padding-left: 12px;
  padding-right: 12px;
}
.btn-group.open .dropdown-toggle {
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn-group.open .dropdown-toggle.btn-link {
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn .caret {
  margin-left: 0;
}
.btn-lg .caret {
  border-width: 5px 5px 0;
  border-bottom-width: 0;
}
.dropup .btn-lg .caret {
  border-width: 0 5px 5px;
}
.btn-group-vertical > .btn,
.btn-group-vertical > .btn-group,
.btn-group-vertical > .btn-group > .btn {
  display: block;
  float: none;
  width: 100%;
  max-width: 100%;
}
.btn-group-vertical > .btn-group > .btn {
  float: none;
}
.btn-group-vertical > .btn + .btn,
.btn-group-vertical > .btn + .btn-group,
.btn-group-vertical > .btn-group + .btn,
.btn-group-vertical > .btn-group + .btn-group {
  margin-top: -1px;
  margin-left: 0;
}
.btn-group-vertical > .btn:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.btn-group-vertical > .btn:first-child:not(:last-child) {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn:last-child:not(:first-child) {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
.btn-group-vertical > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.btn-group-justified {
  display: table;
  width: 100%;
  table-layout: fixed;
  border-collapse: separate;
}
.btn-group-justified > .btn,
.btn-group-justified > .btn-group {
  float: none;
  display: table-cell;
  width: 1%;
}
.btn-group-justified > .btn-group .btn {
  width: 100%;
}
.btn-group-justified > .btn-group .dropdown-menu {
  left: auto;
}
[data-toggle="buttons"] > .btn input[type="radio"],
[data-toggle="buttons"] > .btn-group > .btn input[type="radio"],
[data-toggle="buttons"] > .btn input[type="checkbox"],
[data-toggle="buttons"] > .btn-group > .btn input[type="checkbox"] {
  position: absolute;
  clip: rect(0, 0, 0, 0);
  pointer-events: none;
}
.input-group {
  position: relative;
  display: table;
  border-collapse: separate;
}
.input-group[class*="col-"] {
  float: none;
  padding-left: 0;
  padding-right: 0;
}
.input-group .form-control {
  position: relative;
  z-index: 2;
  float: left;
  width: 100%;
  margin-bottom: 0;
}
.input-group .form-control:focus {
  z-index: 3;
}
.input-group-lg > .form-control,
.input-group-lg > .input-group-addon,
.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-group-lg > .form-control,
select.input-group-lg > .input-group-addon,
select.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  line-height: 45px;
}
textarea.input-group-lg > .form-control,
textarea.input-group-lg > .input-group-addon,
textarea.input-group-lg > .input-group-btn > .btn,
select[multiple].input-group-lg > .form-control,
select[multiple].input-group-lg > .input-group-addon,
select[multiple].input-group-lg > .input-group-btn > .btn {
  height: auto;
}
.input-group-sm > .form-control,
.input-group-sm > .input-group-addon,
.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-group-sm > .form-control,
select.input-group-sm > .input-group-addon,
select.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  line-height: 30px;
}
textarea.input-group-sm > .form-control,
textarea.input-group-sm > .input-group-addon,
textarea.input-group-sm > .input-group-btn > .btn,
select[multiple].input-group-sm > .form-control,
select[multiple].input-group-sm > .input-group-addon,
select[multiple].input-group-sm > .input-group-btn > .btn {
  height: auto;
}
.input-group-addon,
.input-group-btn,
.input-group .form-control {
  display: table-cell;
}
.input-group-addon:not(:first-child):not(:last-child),
.input-group-btn:not(:first-child):not(:last-child),
.input-group .form-control:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.input-group-addon,
.input-group-btn {
  width: 1%;
  white-space: nowrap;
  vertical-align: middle;
}
.input-group-addon {
  padding: 6px 12px;
  font-size: 13px;
  font-weight: normal;
  line-height: 1;
  color: #555555;
  text-align: center;
  background-color: #eeeeee;
  border: 1px solid #ccc;
  border-radius: 2px;
}
.input-group-addon.input-sm {
  padding: 5px 10px;
  font-size: 12px;
  border-radius: 1px;
}
.input-group-addon.input-lg {
  padding: 10px 16px;
  font-size: 17px;
  border-radius: 3px;
}
.input-group-addon input[type="radio"],
.input-group-addon input[type="checkbox"] {
  margin-top: 0;
}
.input-group .form-control:first-child,
.input-group-addon:first-child,
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group > .btn,
.input-group-btn:first-child > .dropdown-toggle,
.input-group-btn:last-child > .btn:not(:last-child):not(.dropdown-toggle),
.input-group-btn:last-child > .btn-group:not(:last-child) > .btn {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.input-group-addon:first-child {
  border-right: 0;
}
.input-group .form-control:last-child,
.input-group-addon:last-child,
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group > .btn,
.input-group-btn:last-child > .dropdown-toggle,
.input-group-btn:first-child > .btn:not(:first-child),
.input-group-btn:first-child > .btn-group:not(:first-child) > .btn {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.input-group-addon:last-child {
  border-left: 0;
}
.input-group-btn {
  position: relative;
  font-size: 0;
  white-space: nowrap;
}
.input-group-btn > .btn {
  position: relative;
}
.input-group-btn > .btn + .btn {
  margin-left: -1px;
}
.input-group-btn > .btn:hover,
.input-group-btn > .btn:focus,
.input-group-btn > .btn:active {
  z-index: 2;
}
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group {
  margin-right: -1px;
}
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group {
  z-index: 2;
  margin-left: -1px;
}
.nav {
  margin-bottom: 0;
  padding-left: 0;
  list-style: none;
}
.nav > li {
  position: relative;
  display: block;
}
.nav > li > a {
  position: relative;
  display: block;
  padding: 10px 15px;
}
.nav > li > a:hover,
.nav > li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.nav > li.disabled > a {
  color: #777777;
}
.nav > li.disabled > a:hover,
.nav > li.disabled > a:focus {
  color: #777777;
  text-decoration: none;
  background-color: transparent;
  cursor: not-allowed;
}
.nav .open > a,
.nav .open > a:hover,
.nav .open > a:focus {
  background-color: #eeeeee;
  border-color: #337ab7;
}
.nav .nav-divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.nav > li > a > img {
  max-width: none;
}
.nav-tabs {
  border-bottom: 1px solid #ddd;
}
.nav-tabs > li {
  float: left;
  margin-bottom: -1px;
}
.nav-tabs > li > a {
  margin-right: 2px;
  line-height: 1.42857143;
  border: 1px solid transparent;
  border-radius: 2px 2px 0 0;
}
.nav-tabs > li > a:hover {
  border-color: #eeeeee #eeeeee #ddd;
}
.nav-tabs > li.active > a,
.nav-tabs > li.active > a:hover,
.nav-tabs > li.active > a:focus {
  color: #555555;
  background-color: #fff;
  border: 1px solid #ddd;
  border-bottom-color: transparent;
  cursor: default;
}
.nav-tabs.nav-justified {
  width: 100%;
  border-bottom: 0;
}
.nav-tabs.nav-justified > li {
  float: none;
}
.nav-tabs.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-tabs.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-tabs.nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs.nav-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs.nav-justified > .active > a,
.nav-tabs.nav-justified > .active > a:hover,
.nav-tabs.nav-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs.nav-justified > .active > a,
  .nav-tabs.nav-justified > .active > a:hover,
  .nav-tabs.nav-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.nav-pills > li {
  float: left;
}
.nav-pills > li > a {
  border-radius: 2px;
}
.nav-pills > li + li {
  margin-left: 2px;
}
.nav-pills > li.active > a,
.nav-pills > li.active > a:hover,
.nav-pills > li.active > a:focus {
  color: #fff;
  background-color: #337ab7;
}
.nav-stacked > li {
  float: none;
}
.nav-stacked > li + li {
  margin-top: 2px;
  margin-left: 0;
}
.nav-justified {
  width: 100%;
}
.nav-justified > li {
  float: none;
}
.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs-justified {
  border-bottom: 0;
}
.nav-tabs-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs-justified > .active > a,
.nav-tabs-justified > .active > a:hover,
.nav-tabs-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs-justified > .active > a,
  .nav-tabs-justified > .active > a:hover,
  .nav-tabs-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.tab-content > .tab-pane {
  display: none;
}
.tab-content > .active {
  display: block;
}
.nav-tabs .dropdown-menu {
  margin-top: -1px;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar {
  position: relative;
  min-height: 30px;
  margin-bottom: 18px;
  border: 1px solid transparent;
}
@media (min-width: 541px) {
  .navbar {
    border-radius: 2px;
  }
}
@media (min-width: 541px) {
  .navbar-header {
    float: left;
  }
}
.navbar-collapse {
  overflow-x: visible;
  padding-right: 0px;
  padding-left: 0px;
  border-top: 1px solid transparent;
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1);
  -webkit-overflow-scrolling: touch;
}
.navbar-collapse.in {
  overflow-y: auto;
}
@media (min-width: 541px) {
  .navbar-collapse {
    width: auto;
    border-top: 0;
    box-shadow: none;
  }
  .navbar-collapse.collapse {
    display: block !important;
    height: auto !important;
    padding-bottom: 0;
    overflow: visible !important;
  }
  .navbar-collapse.in {
    overflow-y: visible;
  }
  .navbar-fixed-top .navbar-collapse,
  .navbar-static-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    padding-left: 0;
    padding-right: 0;
  }
}
.navbar-fixed-top .navbar-collapse,
.navbar-fixed-bottom .navbar-collapse {
  max-height: 340px;
}
@media (max-device-width: 540px) and (orientation: landscape) {
  .navbar-fixed-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    max-height: 200px;
  }
}
.container > .navbar-header,
.container-fluid > .navbar-header,
.container > .navbar-collapse,
.container-fluid > .navbar-collapse {
  margin-right: 0px;
  margin-left: 0px;
}
@media (min-width: 541px) {
  .container > .navbar-header,
  .container-fluid > .navbar-header,
  .container > .navbar-collapse,
  .container-fluid > .navbar-collapse {
    margin-right: 0;
    margin-left: 0;
  }
}
.navbar-static-top {
  z-index: 1000;
  border-width: 0 0 1px;
}
@media (min-width: 541px) {
  .navbar-static-top {
    border-radius: 0;
  }
}
.navbar-fixed-top,
.navbar-fixed-bottom {
  position: fixed;
  right: 0;
  left: 0;
  z-index: 1030;
}
@media (min-width: 541px) {
  .navbar-fixed-top,
  .navbar-fixed-bottom {
    border-radius: 0;
  }
}
.navbar-fixed-top {
  top: 0;
  border-width: 0 0 1px;
}
.navbar-fixed-bottom {
  bottom: 0;
  margin-bottom: 0;
  border-width: 1px 0 0;
}
.navbar-brand {
  float: left;
  padding: 6px 0px;
  font-size: 17px;
  line-height: 18px;
  height: 30px;
}
.navbar-brand:hover,
.navbar-brand:focus {
  text-decoration: none;
}
.navbar-brand > img {
  display: block;
}
@media (min-width: 541px) {
  .navbar > .container .navbar-brand,
  .navbar > .container-fluid .navbar-brand {
    margin-left: 0px;
  }
}
.navbar-toggle {
  position: relative;
  float: right;
  margin-right: 0px;
  padding: 9px 10px;
  margin-top: -2px;
  margin-bottom: -2px;
  background-color: transparent;
  background-image: none;
  border: 1px solid transparent;
  border-radius: 2px;
}
.navbar-toggle:focus {
  outline: 0;
}
.navbar-toggle .icon-bar {
  display: block;
  width: 22px;
  height: 2px;
  border-radius: 1px;
}
.navbar-toggle .icon-bar + .icon-bar {
  margin-top: 4px;
}
@media (min-width: 541px) {
  .navbar-toggle {
    display: none;
  }
}
.navbar-nav {
  margin: 3px 0px;
}
.navbar-nav > li > a {
  padding-top: 10px;
  padding-bottom: 10px;
  line-height: 18px;
}
@media (max-width: 540px) {
  .navbar-nav .open .dropdown-menu {
    position: static;
    float: none;
    width: auto;
    margin-top: 0;
    background-color: transparent;
    border: 0;
    box-shadow: none;
  }
  .navbar-nav .open .dropdown-menu > li > a,
  .navbar-nav .open .dropdown-menu .dropdown-header {
    padding: 5px 15px 5px 25px;
  }
  .navbar-nav .open .dropdown-menu > li > a {
    line-height: 18px;
  }
  .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-nav .open .dropdown-menu > li > a:focus {
    background-image: none;
  }
}
@media (min-width: 541px) {
  .navbar-nav {
    float: left;
    margin: 0;
  }
  .navbar-nav > li {
    float: left;
  }
  .navbar-nav > li > a {
    padding-top: 6px;
    padding-bottom: 6px;
  }
}
.navbar-form {
  margin-left: 0px;
  margin-right: 0px;
  padding: 10px 0px;
  border-top: 1px solid transparent;
  border-bottom: 1px solid transparent;
  -webkit-box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  margin-top: -1px;
  margin-bottom: -1px;
}
@media (min-width: 768px) {
  .navbar-form .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .navbar-form .form-control-static {
    display: inline-block;
  }
  .navbar-form .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .navbar-form .input-group .input-group-addon,
  .navbar-form .input-group .input-group-btn,
  .navbar-form .input-group .form-control {
    width: auto;
  }
  .navbar-form .input-group > .form-control {
    width: 100%;
  }
  .navbar-form .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio,
  .navbar-form .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio label,
  .navbar-form .checkbox label {
    padding-left: 0;
  }
  .navbar-form .radio input[type="radio"],
  .navbar-form .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .navbar-form .has-feedback .form-control-feedback {
    top: 0;
  }
}
@media (max-width: 540px) {
  .navbar-form .form-group {
    margin-bottom: 5px;
  }
  .navbar-form .form-group:last-child {
    margin-bottom: 0;
  }
}
@media (min-width: 541px) {
  .navbar-form {
    width: auto;
    border: 0;
    margin-left: 0;
    margin-right: 0;
    padding-top: 0;
    padding-bottom: 0;
    -webkit-box-shadow: none;
    box-shadow: none;
  }
}
.navbar-nav > li > .dropdown-menu {
  margin-top: 0;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar-fixed-bottom .navbar-nav > li > .dropdown-menu {
  margin-bottom: 0;
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.navbar-btn {
  margin-top: -1px;
  margin-bottom: -1px;
}
.navbar-btn.btn-sm {
  margin-top: 0px;
  margin-bottom: 0px;
}
.navbar-btn.btn-xs {
  margin-top: 4px;
  margin-bottom: 4px;
}
.navbar-text {
  margin-top: 6px;
  margin-bottom: 6px;
}
@media (min-width: 541px) {
  .navbar-text {
    float: left;
    margin-left: 0px;
    margin-right: 0px;
  }
}
@media (min-width: 541px) {
  .navbar-left {
    float: left !important;
    float: left;
  }
  .navbar-right {
    float: right !important;
    float: right;
    margin-right: 0px;
  }
  .navbar-right ~ .navbar-right {
    margin-right: 0;
  }
}
.navbar-default {
  background-color: #f8f8f8;
  border-color: #e7e7e7;
}
.navbar-default .navbar-brand {
  color: #777;
}
.navbar-default .navbar-brand:hover,
.navbar-default .navbar-brand:focus {
  color: #5e5e5e;
  background-color: transparent;
}
.navbar-default .navbar-text {
  color: #777;
}
.navbar-default .navbar-nav > li > a {
  color: #777;
}
.navbar-default .navbar-nav > li > a:hover,
.navbar-default .navbar-nav > li > a:focus {
  color: #333;
  background-color: transparent;
}
.navbar-default .navbar-nav > .active > a,
.navbar-default .navbar-nav > .active > a:hover,
.navbar-default .navbar-nav > .active > a:focus {
  color: #555;
  background-color: #e7e7e7;
}
.navbar-default .navbar-nav > .disabled > a,
.navbar-default .navbar-nav > .disabled > a:hover,
.navbar-default .navbar-nav > .disabled > a:focus {
  color: #ccc;
  background-color: transparent;
}
.navbar-default .navbar-toggle {
  border-color: #ddd;
}
.navbar-default .navbar-toggle:hover,
.navbar-default .navbar-toggle:focus {
  background-color: #ddd;
}
.navbar-default .navbar-toggle .icon-bar {
  background-color: #888;
}
.navbar-default .navbar-collapse,
.navbar-default .navbar-form {
  border-color: #e7e7e7;
}
.navbar-default .navbar-nav > .open > a,
.navbar-default .navbar-nav > .open > a:hover,
.navbar-default .navbar-nav > .open > a:focus {
  background-color: #e7e7e7;
  color: #555;
}
@media (max-width: 540px) {
  .navbar-default .navbar-nav .open .dropdown-menu > li > a {
    color: #777;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #333;
    background-color: transparent;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #555;
    background-color: #e7e7e7;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #ccc;
    background-color: transparent;
  }
}
.navbar-default .navbar-link {
  color: #777;
}
.navbar-default .navbar-link:hover {
  color: #333;
}
.navbar-default .btn-link {
  color: #777;
}
.navbar-default .btn-link:hover,
.navbar-default .btn-link:focus {
  color: #333;
}
.navbar-default .btn-link[disabled]:hover,
fieldset[disabled] .navbar-default .btn-link:hover,
.navbar-default .btn-link[disabled]:focus,
fieldset[disabled] .navbar-default .btn-link:focus {
  color: #ccc;
}
.navbar-inverse {
  background-color: #222;
  border-color: #080808;
}
.navbar-inverse .navbar-brand {
  color: #9d9d9d;
}
.navbar-inverse .navbar-brand:hover,
.navbar-inverse .navbar-brand:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-text {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a:hover,
.navbar-inverse .navbar-nav > li > a:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-nav > .active > a,
.navbar-inverse .navbar-nav > .active > a:hover,
.navbar-inverse .navbar-nav > .active > a:focus {
  color: #fff;
  background-color: #080808;
}
.navbar-inverse .navbar-nav > .disabled > a,
.navbar-inverse .navbar-nav > .disabled > a:hover,
.navbar-inverse .navbar-nav > .disabled > a:focus {
  color: #444;
  background-color: transparent;
}
.navbar-inverse .navbar-toggle {
  border-color: #333;
}
.navbar-inverse .navbar-toggle:hover,
.navbar-inverse .navbar-toggle:focus {
  background-color: #333;
}
.navbar-inverse .navbar-toggle .icon-bar {
  background-color: #fff;
}
.navbar-inverse .navbar-collapse,
.navbar-inverse .navbar-form {
  border-color: #101010;
}
.navbar-inverse .navbar-nav > .open > a,
.navbar-inverse .navbar-nav > .open > a:hover,
.navbar-inverse .navbar-nav > .open > a:focus {
  background-color: #080808;
  color: #fff;
}
@media (max-width: 540px) {
  .navbar-inverse .navbar-nav .open .dropdown-menu > .dropdown-header {
    border-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu .divider {
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a {
    color: #9d9d9d;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #fff;
    background-color: transparent;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #fff;
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #444;
    background-color: transparent;
  }
}
.navbar-inverse .navbar-link {
  color: #9d9d9d;
}
.navbar-inverse .navbar-link:hover {
  color: #fff;
}
.navbar-inverse .btn-link {
  color: #9d9d9d;
}
.navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link:focus {
  color: #fff;
}
.navbar-inverse .btn-link[disabled]:hover,
fieldset[disabled] .navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link[disabled]:focus,
fieldset[disabled] .navbar-inverse .btn-link:focus {
  color: #444;
}
.breadcrumb {
  padding: 8px 15px;
  margin-bottom: 18px;
  list-style: none;
  background-color: #f5f5f5;
  border-radius: 2px;
}
.breadcrumb > li {
  display: inline-block;
}
.breadcrumb > li + li:before {
  content: "/\00a0";
  padding: 0 5px;
  color: #5e5e5e;
}
.breadcrumb > .active {
  color: #777777;
}
.pagination {
  display: inline-block;
  padding-left: 0;
  margin: 18px 0;
  border-radius: 2px;
}
.pagination > li {
  display: inline;
}
.pagination > li > a,
.pagination > li > span {
  position: relative;
  float: left;
  padding: 6px 12px;
  line-height: 1.42857143;
  text-decoration: none;
  color: #337ab7;
  background-color: #fff;
  border: 1px solid #ddd;
  margin-left: -1px;
}
.pagination > li:first-child > a,
.pagination > li:first-child > span {
  margin-left: 0;
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.pagination > li:last-child > a,
.pagination > li:last-child > span {
  border-bottom-right-radius: 2px;
  border-top-right-radius: 2px;
}
.pagination > li > a:hover,
.pagination > li > span:hover,
.pagination > li > a:focus,
.pagination > li > span:focus {
  z-index: 2;
  color: #23527c;
  background-color: #eeeeee;
  border-color: #ddd;
}
.pagination > .active > a,
.pagination > .active > span,
.pagination > .active > a:hover,
.pagination > .active > span:hover,
.pagination > .active > a:focus,
.pagination > .active > span:focus {
  z-index: 3;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
  cursor: default;
}
.pagination > .disabled > span,
.pagination > .disabled > span:hover,
.pagination > .disabled > span:focus,
.pagination > .disabled > a,
.pagination > .disabled > a:hover,
.pagination > .disabled > a:focus {
  color: #777777;
  background-color: #fff;
  border-color: #ddd;
  cursor: not-allowed;
}
.pagination-lg > li > a,
.pagination-lg > li > span {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.pagination-lg > li:first-child > a,
.pagination-lg > li:first-child > span {
  border-bottom-left-radius: 3px;
  border-top-left-radius: 3px;
}
.pagination-lg > li:last-child > a,
.pagination-lg > li:last-child > span {
  border-bottom-right-radius: 3px;
  border-top-right-radius: 3px;
}
.pagination-sm > li > a,
.pagination-sm > li > span {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.pagination-sm > li:first-child > a,
.pagination-sm > li:first-child > span {
  border-bottom-left-radius: 1px;
  border-top-left-radius: 1px;
}
.pagination-sm > li:last-child > a,
.pagination-sm > li:last-child > span {
  border-bottom-right-radius: 1px;
  border-top-right-radius: 1px;
}
.pager {
  padding-left: 0;
  margin: 18px 0;
  list-style: none;
  text-align: center;
}
.pager li {
  display: inline;
}
.pager li > a,
.pager li > span {
  display: inline-block;
  padding: 5px 14px;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 15px;
}
.pager li > a:hover,
.pager li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.pager .next > a,
.pager .next > span {
  float: right;
}
.pager .previous > a,
.pager .previous > span {
  float: left;
}
.pager .disabled > a,
.pager .disabled > a:hover,
.pager .disabled > a:focus,
.pager .disabled > span {
  color: #777777;
  background-color: #fff;
  cursor: not-allowed;
}
.label {
  display: inline;
  padding: .2em .6em .3em;
  font-size: 75%;
  font-weight: bold;
  line-height: 1;
  color: #fff;
  text-align: center;
  white-space: nowrap;
  vertical-align: baseline;
  border-radius: .25em;
}
a.label:hover,
a.label:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.label:empty {
  display: none;
}
.btn .label {
  position: relative;
  top: -1px;
}
.label-default {
  background-color: #777777;
}
.label-default[href]:hover,
.label-default[href]:focus {
  background-color: #5e5e5e;
}
.label-primary {
  background-color: #337ab7;
}
.label-primary[href]:hover,
.label-primary[href]:focus {
  background-color: #286090;
}
.label-success {
  background-color: #5cb85c;
}
.label-success[href]:hover,
.label-success[href]:focus {
  background-color: #449d44;
}
.label-info {
  background-color: #5bc0de;
}
.label-info[href]:hover,
.label-info[href]:focus {
  background-color: #31b0d5;
}
.label-warning {
  background-color: #f0ad4e;
}
.label-warning[href]:hover,
.label-warning[href]:focus {
  background-color: #ec971f;
}
.label-danger {
  background-color: #d9534f;
}
.label-danger[href]:hover,
.label-danger[href]:focus {
  background-color: #c9302c;
}
.badge {
  display: inline-block;
  min-width: 10px;
  padding: 3px 7px;
  font-size: 12px;
  font-weight: bold;
  color: #fff;
  line-height: 1;
  vertical-align: middle;
  white-space: nowrap;
  text-align: center;
  background-color: #777777;
  border-radius: 10px;
}
.badge:empty {
  display: none;
}
.btn .badge {
  position: relative;
  top: -1px;
}
.btn-xs .badge,
.btn-group-xs > .btn .badge {
  top: 0;
  padding: 1px 5px;
}
a.badge:hover,
a.badge:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.list-group-item.active > .badge,
.nav-pills > .active > a > .badge {
  color: #337ab7;
  background-color: #fff;
}
.list-group-item > .badge {
  float: right;
}
.list-group-item > .badge + .badge {
  margin-right: 5px;
}
.nav-pills > li > a > .badge {
  margin-left: 3px;
}
.jumbotron {
  padding-top: 30px;
  padding-bottom: 30px;
  margin-bottom: 30px;
  color: inherit;
  background-color: #eeeeee;
}
.jumbotron h1,
.jumbotron .h1 {
  color: inherit;
}
.jumbotron p {
  margin-bottom: 15px;
  font-size: 20px;
  font-weight: 200;
}
.jumbotron > hr {
  border-top-color: #d5d5d5;
}
.container .jumbotron,
.container-fluid .jumbotron {
  border-radius: 3px;
  padding-left: 0px;
  padding-right: 0px;
}
.jumbotron .container {
  max-width: 100%;
}
@media screen and (min-width: 768px) {
  .jumbotron {
    padding-top: 48px;
    padding-bottom: 48px;
  }
  .container .jumbotron,
  .container-fluid .jumbotron {
    padding-left: 60px;
    padding-right: 60px;
  }
  .jumbotron h1,
  .jumbotron .h1 {
    font-size: 59px;
  }
}
.thumbnail {
  display: block;
  padding: 4px;
  margin-bottom: 18px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: border 0.2s ease-in-out;
  -o-transition: border 0.2s ease-in-out;
  transition: border 0.2s ease-in-out;
}
.thumbnail > img,
.thumbnail a > img {
  margin-left: auto;
  margin-right: auto;
}
a.thumbnail:hover,
a.thumbnail:focus,
a.thumbnail.active {
  border-color: #337ab7;
}
.thumbnail .caption {
  padding: 9px;
  color: #000;
}
.alert {
  padding: 15px;
  margin-bottom: 18px;
  border: 1px solid transparent;
  border-radius: 2px;
}
.alert h4 {
  margin-top: 0;
  color: inherit;
}
.alert .alert-link {
  font-weight: bold;
}
.alert > p,
.alert > ul {
  margin-bottom: 0;
}
.alert > p + p {
  margin-top: 5px;
}
.alert-dismissable,
.alert-dismissible {
  padding-right: 35px;
}
.alert-dismissable .close,
.alert-dismissible .close {
  position: relative;
  top: -2px;
  right: -21px;
  color: inherit;
}
.alert-success {
  background-color: #dff0d8;
  border-color: #d6e9c6;
  color: #3c763d;
}
.alert-success hr {
  border-top-color: #c9e2b3;
}
.alert-success .alert-link {
  color: #2b542c;
}
.alert-info {
  background-color: #d9edf7;
  border-color: #bce8f1;
  color: #31708f;
}
.alert-info hr {
  border-top-color: #a6e1ec;
}
.alert-info .alert-link {
  color: #245269;
}
.alert-warning {
  background-color: #fcf8e3;
  border-color: #faebcc;
  color: #8a6d3b;
}
.alert-warning hr {
  border-top-color: #f7e1b5;
}
.alert-warning .alert-link {
  color: #66512c;
}
.alert-danger {
  background-color: #f2dede;
  border-color: #ebccd1;
  color: #a94442;
}
.alert-danger hr {
  border-top-color: #e4b9c0;
}
.alert-danger .alert-link {
  color: #843534;
}
@-webkit-keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
@keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
.progress {
  overflow: hidden;
  height: 18px;
  margin-bottom: 18px;
  background-color: #f5f5f5;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
  box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
}
.progress-bar {
  float: left;
  width: 0%;
  height: 100%;
  font-size: 12px;
  line-height: 18px;
  color: #fff;
  text-align: center;
  background-color: #337ab7;
  -webkit-box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  -webkit-transition: width 0.6s ease;
  -o-transition: width 0.6s ease;
  transition: width 0.6s ease;
}
.progress-striped .progress-bar,
.progress-bar-striped {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-size: 40px 40px;
}
.progress.active .progress-bar,
.progress-bar.active {
  -webkit-animation: progress-bar-stripes 2s linear infinite;
  -o-animation: progress-bar-stripes 2s linear infinite;
  animation: progress-bar-stripes 2s linear infinite;
}
.progress-bar-success {
  background-color: #5cb85c;
}
.progress-striped .progress-bar-success {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-info {
  background-color: #5bc0de;
}
.progress-striped .progress-bar-info {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-warning {
  background-color: #f0ad4e;
}
.progress-striped .progress-bar-warning {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-danger {
  background-color: #d9534f;
}
.progress-striped .progress-bar-danger {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.media {
  margin-top: 15px;
}
.media:first-child {
  margin-top: 0;
}
.media,
.media-body {
  zoom: 1;
  overflow: hidden;
}
.media-body {
  width: 10000px;
}
.media-object {
  display: block;
}
.media-object.img-thumbnail {
  max-width: none;
}
.media-right,
.media > .pull-right {
  padding-left: 10px;
}
.media-left,
.media > .pull-left {
  padding-right: 10px;
}
.media-left,
.media-right,
.media-body {
  display: table-cell;
  vertical-align: top;
}
.media-middle {
  vertical-align: middle;
}
.media-bottom {
  vertical-align: bottom;
}
.media-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.media-list {
  padding-left: 0;
  list-style: none;
}
.list-group {
  margin-bottom: 20px;
  padding-left: 0;
}
.list-group-item {
  position: relative;
  display: block;
  padding: 10px 15px;
  margin-bottom: -1px;
  background-color: #fff;
  border: 1px solid #ddd;
}
.list-group-item:first-child {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
}
.list-group-item:last-child {
  margin-bottom: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
a.list-group-item,
button.list-group-item {
  color: #555;
}
a.list-group-item .list-group-item-heading,
button.list-group-item .list-group-item-heading {
  color: #333;
}
a.list-group-item:hover,
button.list-group-item:hover,
a.list-group-item:focus,
button.list-group-item:focus {
  text-decoration: none;
  color: #555;
  background-color: #f5f5f5;
}
button.list-group-item {
  width: 100%;
  text-align: left;
}
.list-group-item.disabled,
.list-group-item.disabled:hover,
.list-group-item.disabled:focus {
  background-color: #eeeeee;
  color: #777777;
  cursor: not-allowed;
}
.list-group-item.disabled .list-group-item-heading,
.list-group-item.disabled:hover .list-group-item-heading,
.list-group-item.disabled:focus .list-group-item-heading {
  color: inherit;
}
.list-group-item.disabled .list-group-item-text,
.list-group-item.disabled:hover .list-group-item-text,
.list-group-item.disabled:focus .list-group-item-text {
  color: #777777;
}
.list-group-item.active,
.list-group-item.active:hover,
.list-group-item.active:focus {
  z-index: 2;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.list-group-item.active .list-group-item-heading,
.list-group-item.active:hover .list-group-item-heading,
.list-group-item.active:focus .list-group-item-heading,
.list-group-item.active .list-group-item-heading > small,
.list-group-item.active:hover .list-group-item-heading > small,
.list-group-item.active:focus .list-group-item-heading > small,
.list-group-item.active .list-group-item-heading > .small,
.list-group-item.active:hover .list-group-item-heading > .small,
.list-group-item.active:focus .list-group-item-heading > .small {
  color: inherit;
}
.list-group-item.active .list-group-item-text,
.list-group-item.active:hover .list-group-item-text,
.list-group-item.active:focus .list-group-item-text {
  color: #c7ddef;
}
.list-group-item-success {
  color: #3c763d;
  background-color: #dff0d8;
}
a.list-group-item-success,
button.list-group-item-success {
  color: #3c763d;
}
a.list-group-item-success .list-group-item-heading,
button.list-group-item-success .list-group-item-heading {
  color: inherit;
}
a.list-group-item-success:hover,
button.list-group-item-success:hover,
a.list-group-item-success:focus,
button.list-group-item-success:focus {
  color: #3c763d;
  background-color: #d0e9c6;
}
a.list-group-item-success.active,
button.list-group-item-success.active,
a.list-group-item-success.active:hover,
button.list-group-item-success.active:hover,
a.list-group-item-success.active:focus,
button.list-group-item-success.active:focus {
  color: #fff;
  background-color: #3c763d;
  border-color: #3c763d;
}
.list-group-item-info {
  color: #31708f;
  background-color: #d9edf7;
}
a.list-group-item-info,
button.list-group-item-info {
  color: #31708f;
}
a.list-group-item-info .list-group-item-heading,
button.list-group-item-info .list-group-item-heading {
  color: inherit;
}
a.list-group-item-info:hover,
button.list-group-item-info:hover,
a.list-group-item-info:focus,
button.list-group-item-info:focus {
  color: #31708f;
  background-color: #c4e3f3;
}
a.list-group-item-info.active,
button.list-group-item-info.active,
a.list-group-item-info.active:hover,
button.list-group-item-info.active:hover,
a.list-group-item-info.active:focus,
button.list-group-item-info.active:focus {
  color: #fff;
  background-color: #31708f;
  border-color: #31708f;
}
.list-group-item-warning {
  color: #8a6d3b;
  background-color: #fcf8e3;
}
a.list-group-item-warning,
button.list-group-item-warning {
  color: #8a6d3b;
}
a.list-group-item-warning .list-group-item-heading,
button.list-group-item-warning .list-group-item-heading {
  color: inherit;
}
a.list-group-item-warning:hover,
button.list-group-item-warning:hover,
a.list-group-item-warning:focus,
button.list-group-item-warning:focus {
  color: #8a6d3b;
  background-color: #faf2cc;
}
a.list-group-item-warning.active,
button.list-group-item-warning.active,
a.list-group-item-warning.active:hover,
button.list-group-item-warning.active:hover,
a.list-group-item-warning.active:focus,
button.list-group-item-warning.active:focus {
  color: #fff;
  background-color: #8a6d3b;
  border-color: #8a6d3b;
}
.list-group-item-danger {
  color: #a94442;
  background-color: #f2dede;
}
a.list-group-item-danger,
button.list-group-item-danger {
  color: #a94442;
}
a.list-group-item-danger .list-group-item-heading,
button.list-group-item-danger .list-group-item-heading {
  color: inherit;
}
a.list-group-item-danger:hover,
button.list-group-item-danger:hover,
a.list-group-item-danger:focus,
button.list-group-item-danger:focus {
  color: #a94442;
  background-color: #ebcccc;
}
a.list-group-item-danger.active,
button.list-group-item-danger.active,
a.list-group-item-danger.active:hover,
button.list-group-item-danger.active:hover,
a.list-group-item-danger.active:focus,
button.list-group-item-danger.active:focus {
  color: #fff;
  background-color: #a94442;
  border-color: #a94442;
}
.list-group-item-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.list-group-item-text {
  margin-bottom: 0;
  line-height: 1.3;
}
.panel {
  margin-bottom: 18px;
  background-color: #fff;
  border: 1px solid transparent;
  border-radius: 2px;
  -webkit-box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
}
.panel-body {
  padding: 15px;
}
.panel-heading {
  padding: 10px 15px;
  border-bottom: 1px solid transparent;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel-heading > .dropdown .dropdown-toggle {
  color: inherit;
}
.panel-title {
  margin-top: 0;
  margin-bottom: 0;
  font-size: 15px;
  color: inherit;
}
.panel-title > a,
.panel-title > small,
.panel-title > .small,
.panel-title > small > a,
.panel-title > .small > a {
  color: inherit;
}
.panel-footer {
  padding: 10px 15px;
  background-color: #f5f5f5;
  border-top: 1px solid #ddd;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .list-group,
.panel > .panel-collapse > .list-group {
  margin-bottom: 0;
}
.panel > .list-group .list-group-item,
.panel > .panel-collapse > .list-group .list-group-item {
  border-width: 1px 0;
  border-radius: 0;
}
.panel > .list-group:first-child .list-group-item:first-child,
.panel > .panel-collapse > .list-group:first-child .list-group-item:first-child {
  border-top: 0;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .list-group:last-child .list-group-item:last-child,
.panel > .panel-collapse > .list-group:last-child .list-group-item:last-child {
  border-bottom: 0;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .panel-heading + .panel-collapse > .list-group .list-group-item:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.panel-heading + .list-group .list-group-item:first-child {
  border-top-width: 0;
}
.list-group + .panel-footer {
  border-top-width: 0;
}
.panel > .table,
.panel > .table-responsive > .table,
.panel > .panel-collapse > .table {
  margin-bottom: 0;
}
.panel > .table caption,
.panel > .table-responsive > .table caption,
.panel > .panel-collapse > .table caption {
  padding-left: 15px;
  padding-right: 15px;
}
.panel > .table:first-child,
.panel > .table-responsive:first-child > .table:first-child {
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child {
  border-top-left-radius: 1px;
  border-top-right-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:first-child {
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:last-child {
  border-top-right-radius: 1px;
}
.panel > .table:last-child,
.panel > .table-responsive:last-child > .table:last-child {
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child {
  border-bottom-left-radius: 1px;
  border-bottom-right-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:first-child {
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:last-child {
  border-bottom-right-radius: 1px;
}
.panel > .panel-body + .table,
.panel > .panel-body + .table-responsive,
.panel > .table + .panel-body,
.panel > .table-responsive + .panel-body {
  border-top: 1px solid #ddd;
}
.panel > .table > tbody:first-child > tr:first-child th,
.panel > .table > tbody:first-child > tr:first-child td {
  border-top: 0;
}
.panel > .table-bordered,
.panel > .table-responsive > .table-bordered {
  border: 0;
}
.panel > .table-bordered > thead > tr > th:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:first-child,
.panel > .table-bordered > tbody > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:first-child,
.panel > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-bordered > thead > tr > td:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:first-child,
.panel > .table-bordered > tbody > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:first-child,
.panel > .table-bordered > tfoot > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:first-child {
  border-left: 0;
}
.panel > .table-bordered > thead > tr > th:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:last-child,
.panel > .table-bordered > tbody > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:last-child,
.panel > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-bordered > thead > tr > td:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:last-child,
.panel > .table-bordered > tbody > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:last-child,
.panel > .table-bordered > tfoot > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:last-child {
  border-right: 0;
}
.panel > .table-bordered > thead > tr:first-child > td,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > td,
.panel > .table-bordered > tbody > tr:first-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > td,
.panel > .table-bordered > thead > tr:first-child > th,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > th,
.panel > .table-bordered > tbody > tr:first-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > th {
  border-bottom: 0;
}
.panel > .table-bordered > tbody > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > td,
.panel > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-bordered > tbody > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > th,
.panel > .table-bordered > tfoot > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > th {
  border-bottom: 0;
}
.panel > .table-responsive {
  border: 0;
  margin-bottom: 0;
}
.panel-group {
  margin-bottom: 18px;
}
.panel-group .panel {
  margin-bottom: 0;
  border-radius: 2px;
}
.panel-group .panel + .panel {
  margin-top: 5px;
}
.panel-group .panel-heading {
  border-bottom: 0;
}
.panel-group .panel-heading + .panel-collapse > .panel-body,
.panel-group .panel-heading + .panel-collapse > .list-group {
  border-top: 1px solid #ddd;
}
.panel-group .panel-footer {
  border-top: 0;
}
.panel-group .panel-footer + .panel-collapse .panel-body {
  border-bottom: 1px solid #ddd;
}
.panel-default {
  border-color: #ddd;
}
.panel-default > .panel-heading {
  color: #333333;
  background-color: #f5f5f5;
  border-color: #ddd;
}
.panel-default > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ddd;
}
.panel-default > .panel-heading .badge {
  color: #f5f5f5;
  background-color: #333333;
}
.panel-default > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ddd;
}
.panel-primary {
  border-color: #337ab7;
}
.panel-primary > .panel-heading {
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.panel-primary > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #337ab7;
}
.panel-primary > .panel-heading .badge {
  color: #337ab7;
  background-color: #fff;
}
.panel-primary > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #337ab7;
}
.panel-success {
  border-color: #d6e9c6;
}
.panel-success > .panel-heading {
  color: #3c763d;
  background-color: #dff0d8;
  border-color: #d6e9c6;
}
.panel-success > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #d6e9c6;
}
.panel-success > .panel-heading .badge {
  color: #dff0d8;
  background-color: #3c763d;
}
.panel-success > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #d6e9c6;
}
.panel-info {
  border-color: #bce8f1;
}
.panel-info > .panel-heading {
  color: #31708f;
  background-color: #d9edf7;
  border-color: #bce8f1;
}
.panel-info > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #bce8f1;
}
.panel-info > .panel-heading .badge {
  color: #d9edf7;
  background-color: #31708f;
}
.panel-info > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #bce8f1;
}
.panel-warning {
  border-color: #faebcc;
}
.panel-warning > .panel-heading {
  color: #8a6d3b;
  background-color: #fcf8e3;
  border-color: #faebcc;
}
.panel-warning > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #faebcc;
}
.panel-warning > .panel-heading .badge {
  color: #fcf8e3;
  background-color: #8a6d3b;
}
.panel-warning > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #faebcc;
}
.panel-danger {
  border-color: #ebccd1;
}
.panel-danger > .panel-heading {
  color: #a94442;
  background-color: #f2dede;
  border-color: #ebccd1;
}
.panel-danger > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ebccd1;
}
.panel-danger > .panel-heading .badge {
  color: #f2dede;
  background-color: #a94442;
}
.panel-danger > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ebccd1;
}
.embed-responsive {
  position: relative;
  display: block;
  height: 0;
  padding: 0;
  overflow: hidden;
}
.embed-responsive .embed-responsive-item,
.embed-responsive iframe,
.embed-responsive embed,
.embed-responsive object,
.embed-responsive video {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  height: 100%;
  width: 100%;
  border: 0;
}
.embed-responsive-16by9 {
  padding-bottom: 56.25%;
}
.embed-responsive-4by3 {
  padding-bottom: 75%;
}
.well {
  min-height: 20px;
  padding: 19px;
  margin-bottom: 20px;
  background-color: #f5f5f5;
  border: 1px solid #e3e3e3;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
}
.well blockquote {
  border-color: #ddd;
  border-color: rgba(0, 0, 0, 0.15);
}
.well-lg {
  padding: 24px;
  border-radius: 3px;
}
.well-sm {
  padding: 9px;
  border-radius: 1px;
}
.close {
  float: right;
  font-size: 19.5px;
  font-weight: bold;
  line-height: 1;
  color: #000;
  text-shadow: 0 1px 0 #fff;
  opacity: 0.2;
  filter: alpha(opacity=20);
}
.close:hover,
.close:focus {
  color: #000;
  text-decoration: none;
  cursor: pointer;
  opacity: 0.5;
  filter: alpha(opacity=50);
}
button.close {
  padding: 0;
  cursor: pointer;
  background: transparent;
  border: 0;
  -webkit-appearance: none;
}
.modal-open {
  overflow: hidden;
}
.modal {
  display: none;
  overflow: hidden;
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1050;
  -webkit-overflow-scrolling: touch;
  outline: 0;
}
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, -25%);
  -ms-transform: translate(0, -25%);
  -o-transform: translate(0, -25%);
  transform: translate(0, -25%);
  -webkit-transition: -webkit-transform 0.3s ease-out;
  -moz-transition: -moz-transform 0.3s ease-out;
  -o-transition: -o-transform 0.3s ease-out;
  transition: transform 0.3s ease-out;
}
.modal.in .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
.modal-open .modal {
  overflow-x: hidden;
  overflow-y: auto;
}
.modal-dialog {
  position: relative;
  width: auto;
  margin: 10px;
}
.modal-content {
  position: relative;
  background-color: #fff;
  border: 1px solid #999;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  background-clip: padding-box;
  outline: 0;
}
.modal-backdrop {
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1040;
  background-color: #000;
}
.modal-backdrop.fade {
  opacity: 0;
  filter: alpha(opacity=0);
}
.modal-backdrop.in {
  opacity: 0.5;
  filter: alpha(opacity=50);
}
.modal-header {
  padding: 15px;
  border-bottom: 1px solid #e5e5e5;
}
.modal-header .close {
  margin-top: -2px;
}
.modal-title {
  margin: 0;
  line-height: 1.42857143;
}
.modal-body {
  position: relative;
  padding: 15px;
}
.modal-footer {
  padding: 15px;
  text-align: right;
  border-top: 1px solid #e5e5e5;
}
.modal-footer .btn + .btn {
  margin-left: 5px;
  margin-bottom: 0;
}
.modal-footer .btn-group .btn + .btn {
  margin-left: -1px;
}
.modal-footer .btn-block + .btn-block {
  margin-left: 0;
}
.modal-scrollbar-measure {
  position: absolute;
  top: -9999px;
  width: 50px;
  height: 50px;
  overflow: scroll;
}
@media (min-width: 768px) {
  .modal-dialog {
    width: 600px;
    margin: 30px auto;
  }
  .modal-content {
    -webkit-box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
    box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
  }
  .modal-sm {
    width: 300px;
  }
}
@media (min-width: 992px) {
  .modal-lg {
    width: 900px;
  }
}
.tooltip {
  position: absolute;
  z-index: 1070;
  display: block;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 12px;
  opacity: 0;
  filter: alpha(opacity=0);
}
.tooltip.in {
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.tooltip.top {
  margin-top: -3px;
  padding: 5px 0;
}
.tooltip.right {
  margin-left: 3px;
  padding: 0 5px;
}
.tooltip.bottom {
  margin-top: 3px;
  padding: 5px 0;
}
.tooltip.left {
  margin-left: -3px;
  padding: 0 5px;
}
.tooltip-inner {
  max-width: 200px;
  padding: 3px 8px;
  color: #fff;
  text-align: center;
  background-color: #000;
  border-radius: 2px;
}
.tooltip-arrow {
  position: absolute;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.tooltip.top .tooltip-arrow {
  bottom: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-left .tooltip-arrow {
  bottom: 0;
  right: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-right .tooltip-arrow {
  bottom: 0;
  left: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.right .tooltip-arrow {
  top: 50%;
  left: 0;
  margin-top: -5px;
  border-width: 5px 5px 5px 0;
  border-right-color: #000;
}
.tooltip.left .tooltip-arrow {
  top: 50%;
  right: 0;
  margin-top: -5px;
  border-width: 5px 0 5px 5px;
  border-left-color: #000;
}
.tooltip.bottom .tooltip-arrow {
  top: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-left .tooltip-arrow {
  top: 0;
  right: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-right .tooltip-arrow {
  top: 0;
  left: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.popover {
  position: absolute;
  top: 0;
  left: 0;
  z-index: 1060;
  display: none;
  max-width: 276px;
  padding: 1px;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 13px;
  background-color: #fff;
  background-clip: padding-box;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
  box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
}
.popover.top {
  margin-top: -10px;
}
.popover.right {
  margin-left: 10px;
}
.popover.bottom {
  margin-top: 10px;
}
.popover.left {
  margin-left: -10px;
}
.popover-title {
  margin: 0;
  padding: 8px 14px;
  font-size: 13px;
  background-color: #f7f7f7;
  border-bottom: 1px solid #ebebeb;
  border-radius: 2px 2px 0 0;
}
.popover-content {
  padding: 9px 14px;
}
.popover > .arrow,
.popover > .arrow:after {
  position: absolute;
  display: block;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.popover > .arrow {
  border-width: 11px;
}
.popover > .arrow:after {
  border-width: 10px;
  content: "";
}
.popover.top > .arrow {
  left: 50%;
  margin-left: -11px;
  border-bottom-width: 0;
  border-top-color: #999999;
  border-top-color: rgba(0, 0, 0, 0.25);
  bottom: -11px;
}
.popover.top > .arrow:after {
  content: " ";
  bottom: 1px;
  margin-left: -10px;
  border-bottom-width: 0;
  border-top-color: #fff;
}
.popover.right > .arrow {
  top: 50%;
  left: -11px;
  margin-top: -11px;
  border-left-width: 0;
  border-right-color: #999999;
  border-right-color: rgba(0, 0, 0, 0.25);
}
.popover.right > .arrow:after {
  content: " ";
  left: 1px;
  bottom: -10px;
  border-left-width: 0;
  border-right-color: #fff;
}
.popover.bottom > .arrow {
  left: 50%;
  margin-left: -11px;
  border-top-width: 0;
  border-bottom-color: #999999;
  border-bottom-color: rgba(0, 0, 0, 0.25);
  top: -11px;
}
.popover.bottom > .arrow:after {
  content: " ";
  top: 1px;
  margin-left: -10px;
  border-top-width: 0;
  border-bottom-color: #fff;
}
.popover.left > .arrow {
  top: 50%;
  right: -11px;
  margin-top: -11px;
  border-right-width: 0;
  border-left-color: #999999;
  border-left-color: rgba(0, 0, 0, 0.25);
}
.popover.left > .arrow:after {
  content: " ";
  right: 1px;
  border-right-width: 0;
  border-left-color: #fff;
  bottom: -10px;
}
.carousel {
  position: relative;
}
.carousel-inner {
  position: relative;
  overflow: hidden;
  width: 100%;
}
.carousel-inner > .item {
  display: none;
  position: relative;
  -webkit-transition: 0.6s ease-in-out left;
  -o-transition: 0.6s ease-in-out left;
  transition: 0.6s ease-in-out left;
}
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  line-height: 1;
}
@media all and (transform-3d), (-webkit-transform-3d) {
  .carousel-inner > .item {
    -webkit-transition: -webkit-transform 0.6s ease-in-out;
    -moz-transition: -moz-transform 0.6s ease-in-out;
    -o-transition: -o-transform 0.6s ease-in-out;
    transition: transform 0.6s ease-in-out;
    -webkit-backface-visibility: hidden;
    -moz-backface-visibility: hidden;
    backface-visibility: hidden;
    -webkit-perspective: 1000px;
    -moz-perspective: 1000px;
    perspective: 1000px;
  }
  .carousel-inner > .item.next,
  .carousel-inner > .item.active.right {
    -webkit-transform: translate3d(100%, 0, 0);
    transform: translate3d(100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.prev,
  .carousel-inner > .item.active.left {
    -webkit-transform: translate3d(-100%, 0, 0);
    transform: translate3d(-100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.next.left,
  .carousel-inner > .item.prev.right,
  .carousel-inner > .item.active {
    -webkit-transform: translate3d(0, 0, 0);
    transform: translate3d(0, 0, 0);
    left: 0;
  }
}
.carousel-inner > .active,
.carousel-inner > .next,
.carousel-inner > .prev {
  display: block;
}
.carousel-inner > .active {
  left: 0;
}
.carousel-inner > .next,
.carousel-inner > .prev {
  position: absolute;
  top: 0;
  width: 100%;
}
.carousel-inner > .next {
  left: 100%;
}
.carousel-inner > .prev {
  left: -100%;
}
.carousel-inner > .next.left,
.carousel-inner > .prev.right {
  left: 0;
}
.carousel-inner > .active.left {
  left: -100%;
}
.carousel-inner > .active.right {
  left: 100%;
}
.carousel-control {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  width: 15%;
  opacity: 0.5;
  filter: alpha(opacity=50);
  font-size: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
  background-color: rgba(0, 0, 0, 0);
}
.carousel-control.left {
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#80000000', endColorstr='#00000000', GradientType=1);
}
.carousel-control.right {
  left: auto;
  right: 0;
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#00000000', endColorstr='#80000000', GradientType=1);
}
.carousel-control:hover,
.carousel-control:focus {
  outline: 0;
  color: #fff;
  text-decoration: none;
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.carousel-control .icon-prev,
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-left,
.carousel-control .glyphicon-chevron-right {
  position: absolute;
  top: 50%;
  margin-top: -10px;
  z-index: 5;
  display: inline-block;
}
.carousel-control .icon-prev,
.carousel-control .glyphicon-chevron-left {
  left: 50%;
  margin-left: -10px;
}
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-right {
  right: 50%;
  margin-right: -10px;
}
.carousel-control .icon-prev,
.carousel-control .icon-next {
  width: 20px;
  height: 20px;
  line-height: 1;
  font-family: serif;
}
.carousel-control .icon-prev:before {
  content: '\2039';
}
.carousel-control .icon-next:before {
  content: '\203a';
}
.carousel-indicators {
  position: absolute;
  bottom: 10px;
  left: 50%;
  z-index: 15;
  width: 60%;
  margin-left: -30%;
  padding-left: 0;
  list-style: none;
  text-align: center;
}
.carousel-indicators li {
  display: inline-block;
  width: 10px;
  height: 10px;
  margin: 1px;
  text-indent: -999px;
  border: 1px solid #fff;
  border-radius: 10px;
  cursor: pointer;
  background-color: #000 \9;
  background-color: rgba(0, 0, 0, 0);
}
.carousel-indicators .active {
  margin: 0;
  width: 12px;
  height: 12px;
  background-color: #fff;
}
.carousel-caption {
  position: absolute;
  left: 15%;
  right: 15%;
  bottom: 20px;
  z-index: 10;
  padding-top: 20px;
  padding-bottom: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
}
.carousel-caption .btn {
  text-shadow: none;
}
@media screen and (min-width: 768px) {
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-prev,
  .carousel-control .icon-next {
    width: 30px;
    height: 30px;
    margin-top: -10px;
    font-size: 30px;
  }
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .icon-prev {
    margin-left: -10px;
  }
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-next {
    margin-right: -10px;
  }
  .carousel-caption {
    left: 20%;
    right: 20%;
    padding-bottom: 30px;
  }
  .carousel-indicators {
    bottom: 20px;
  }
}
.clearfix:before,
.clearfix:after,
.dl-horizontal dd:before,
.dl-horizontal dd:after,
.container:before,
.container:after,
.container-fluid:before,
.container-fluid:after,
.row:before,
.row:after,
.form-horizontal .form-group:before,
.form-horizontal .form-group:after,
.btn-toolbar:before,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:before,
.btn-group-vertical > .btn-group:after,
.nav:before,
.nav:after,
.navbar:before,
.navbar:after,
.navbar-header:before,
.navbar-header:after,
.navbar-collapse:before,
.navbar-collapse:after,
.pager:before,
.pager:after,
.panel-body:before,
.panel-body:after,
.modal-header:before,
.modal-header:after,
.modal-footer:before,
.modal-footer:after,
.item_buttons:before,
.item_buttons:after {
  content: " ";
  display: table;
}
.clearfix:after,
.dl-horizontal dd:after,
.container:after,
.container-fluid:after,
.row:after,
.form-horizontal .form-group:after,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:after,
.nav:after,
.navbar:after,
.navbar-header:after,
.navbar-collapse:after,
.pager:after,
.panel-body:after,
.modal-header:after,
.modal-footer:after,
.item_buttons:after {
  clear: both;
}
.center-block {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.pull-right {
  float: right !important;
}
.pull-left {
  float: left !important;
}
.hide {
  display: none !important;
}
.show {
  display: block !important;
}
.invisible {
  visibility: hidden;
}
.text-hide {
  font: 0/0 a;
  color: transparent;
  text-shadow: none;
  background-color: transparent;
  border: 0;
}
.hidden {
  display: none !important;
}
.affix {
  position: fixed;
}
@-ms-viewport {
  width: device-width;
}
.visible-xs,
.visible-sm,
.visible-md,
.visible-lg {
  display: none !important;
}
.visible-xs-block,
.visible-xs-inline,
.visible-xs-inline-block,
.visible-sm-block,
.visible-sm-inline,
.visible-sm-inline-block,
.visible-md-block,
.visible-md-inline,
.visible-md-inline-block,
.visible-lg-block,
.visible-lg-inline,
.visible-lg-inline-block {
  display: none !important;
}
@media (max-width: 767px) {
  .visible-xs {
    display: block !important;
  }
  table.visible-xs {
    display: table !important;
  }
  tr.visible-xs {
    display: table-row !important;
  }
  th.visible-xs,
  td.visible-xs {
    display: table-cell !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-block {
    display: block !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline {
    display: inline !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm {
    display: block !important;
  }
  table.visible-sm {
    display: table !important;
  }
  tr.visible-sm {
    display: table-row !important;
  }
  th.visible-sm,
  td.visible-sm {
    display: table-cell !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-block {
    display: block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline {
    display: inline !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md {
    display: block !important;
  }
  table.visible-md {
    display: table !important;
  }
  tr.visible-md {
    display: table-row !important;
  }
  th.visible-md,
  td.visible-md {
    display: table-cell !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-block {
    display: block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline {
    display: inline !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg {
    display: block !important;
  }
  table.visible-lg {
    display: table !important;
  }
  tr.visible-lg {
    display: table-row !important;
  }
  th.visible-lg,
  td.visible-lg {
    display: table-cell !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-block {
    display: block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline {
    display: inline !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline-block {
    display: inline-block !important;
  }
}
@media (max-width: 767px) {
  .hidden-xs {
    display: none !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .hidden-sm {
    display: none !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .hidden-md {
    display: none !important;
  }
}
@media (min-width: 1200px) {
  .hidden-lg {
    display: none !important;
  }
}
.visible-print {
  display: none !important;
}
@media print {
  .visible-print {
    display: block !important;
  }
  table.visible-print {
    display: table !important;
  }
  tr.visible-print {
    display: table-row !important;
  }
  th.visible-print,
  td.visible-print {
    display: table-cell !important;
  }
}
.visible-print-block {
  display: none !important;
}
@media print {
  .visible-print-block {
    display: block !important;
  }
}
.visible-print-inline {
  display: none !important;
}
@media print {
  .visible-print-inline {
    display: inline !important;
  }
}
.visible-print-inline-block {
  display: none !important;
}
@media print {
  .visible-print-inline-block {
    display: inline-block !important;
  }
}
@media print {
  .hidden-print {
    display: none !important;
  }
}
/*!
*
* Font Awesome
*
*/
/*!
 *  Font Awesome 4.7.0 by @davegandy - http://fontawesome.io - @fontawesome
 *  License - http://fontawesome.io/license (Font: SIL OFL 1.1, CSS: MIT License)
 */
/* FONT PATH
 * -------------------------- */
@font-face {
  font-family: 'FontAwesome';
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?v=4.7.0');
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?#iefix&v=4.7.0') format('embedded-opentype'), url('../components/font-awesome/fonts/fontawesome-webfont.woff2?v=4.7.0') format('woff2'), url('../components/font-awesome/fonts/fontawesome-webfont.woff?v=4.7.0') format('woff'), url('../components/font-awesome/fonts/fontawesome-webfont.ttf?v=4.7.0') format('truetype'), url('../components/font-awesome/fonts/fontawesome-webfont.svg?v=4.7.0#fontawesomeregular') format('svg');
  font-weight: normal;
  font-style: normal;
}
.fa {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
/* makes the font 33% larger relative to the icon container */
.fa-lg {
  font-size: 1.33333333em;
  line-height: 0.75em;
  vertical-align: -15%;
}
.fa-2x {
  font-size: 2em;
}
.fa-3x {
  font-size: 3em;
}
.fa-4x {
  font-size: 4em;
}
.fa-5x {
  font-size: 5em;
}
.fa-fw {
  width: 1.28571429em;
  text-align: center;
}
.fa-ul {
  padding-left: 0;
  margin-left: 2.14285714em;
  list-style-type: none;
}
.fa-ul > li {
  position: relative;
}
.fa-li {
  position: absolute;
  left: -2.14285714em;
  width: 2.14285714em;
  top: 0.14285714em;
  text-align: center;
}
.fa-li.fa-lg {
  left: -1.85714286em;
}
.fa-border {
  padding: .2em .25em .15em;
  border: solid 0.08em #eee;
  border-radius: .1em;
}
.fa-pull-left {
  float: left;
}
.fa-pull-right {
  float: right;
}
.fa.fa-pull-left {
  margin-right: .3em;
}
.fa.fa-pull-right {
  margin-left: .3em;
}
/* Deprecated as of 4.4.0 */
.pull-right {
  float: right;
}
.pull-left {
  float: left;
}
.fa.pull-left {
  margin-right: .3em;
}
.fa.pull-right {
  margin-left: .3em;
}
.fa-spin {
  -webkit-animation: fa-spin 2s infinite linear;
  animation: fa-spin 2s infinite linear;
}
.fa-pulse {
  -webkit-animation: fa-spin 1s infinite steps(8);
  animation: fa-spin 1s infinite steps(8);
}
@-webkit-keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
@keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
.fa-rotate-90 {
  -ms-filter: "progid:DXImageTransform.Microsoft.BasicImage(rotation=1)";
  -webkit-transform: rotate(90deg);
  -ms-transform: rotate(90deg);
  transform: rotate(90deg);
}
.fa-rotate-180 {
  -ms-filter: "progid:DXImageTransform.Microsoft.BasicImage(rotation=2)";
  -webkit-transform: rotate(180deg);
  -ms-transform: rotate(180deg);
  transform: rotate(180deg);
}
.fa-rotate-270 {
  -ms-filter: "progid:DXImageTransform.Microsoft.BasicImage(rotation=3)";
  -webkit-transform: rotate(270deg);
  -ms-transform: rotate(270deg);
  transform: rotate(270deg);
}
.fa-flip-horizontal {
  -ms-filter: "progid:DXImageTransform.Microsoft.BasicImage(rotation=0, mirror=1)";
  -webkit-transform: scale(-1, 1);
  -ms-transform: scale(-1, 1);
  transform: scale(-1, 1);
}
.fa-flip-vertical {
  -ms-filter: "progid:DXImageTransform.Microsoft.BasicImage(rotation=2, mirror=1)";
  -webkit-transform: scale(1, -1);
  -ms-transform: scale(1, -1);
  transform: scale(1, -1);
}
:root .fa-rotate-90,
:root .fa-rotate-180,
:root .fa-rotate-270,
:root .fa-flip-horizontal,
:root .fa-flip-vertical {
  filter: none;
}
.fa-stack {
  position: relative;
  display: inline-block;
  width: 2em;
  height: 2em;
  line-height: 2em;
  vertical-align: middle;
}
.fa-stack-1x,
.fa-stack-2x {
  position: absolute;
  left: 0;
  width: 100%;
  text-align: center;
}
.fa-stack-1x {
  line-height: inherit;
}
.fa-stack-2x {
  font-size: 2em;
}
.fa-inverse {
  color: #fff;
}
/* Font Awesome uses the Unicode Private Use Area (PUA) to ensure screen
   readers do not read off random characters that represent icons */
.fa-glass:before {
  content: "\f000";
}
.fa-music:before {
  content: "\f001";
}
.fa-search:before {
  content: "\f002";
}
.fa-envelope-o:before {
  content: "\f003";
}
.fa-heart:before {
  content: "\f004";
}
.fa-star:before {
  content: "\f005";
}
.fa-star-o:before {
  content: "\f006";
}
.fa-user:before {
  content: "\f007";
}
.fa-film:before {
  content: "\f008";
}
.fa-th-large:before {
  content: "\f009";
}
.fa-th:before {
  content: "\f00a";
}
.fa-th-list:before {
  content: "\f00b";
}
.fa-check:before {
  content: "\f00c";
}
.fa-remove:before,
.fa-close:before,
.fa-times:before {
  content: "\f00d";
}
.fa-search-plus:before {
  content: "\f00e";
}
.fa-search-minus:before {
  content: "\f010";
}
.fa-power-off:before {
  content: "\f011";
}
.fa-signal:before {
  content: "\f012";
}
.fa-gear:before,
.fa-cog:before {
  content: "\f013";
}
.fa-trash-o:before {
  content: "\f014";
}
.fa-home:before {
  content: "\f015";
}
.fa-file-o:before {
  content: "\f016";
}
.fa-clock-o:before {
  content: "\f017";
}
.fa-road:before {
  content: "\f018";
}
.fa-download:before {
  content: "\f019";
}
.fa-arrow-circle-o-down:before {
  content: "\f01a";
}
.fa-arrow-circle-o-up:before {
  content: "\f01b";
}
.fa-inbox:before {
  content: "\f01c";
}
.fa-play-circle-o:before {
  content: "\f01d";
}
.fa-rotate-right:before,
.fa-repeat:before {
  content: "\f01e";
}
.fa-refresh:before {
  content: "\f021";
}
.fa-list-alt:before {
  content: "\f022";
}
.fa-lock:before {
  content: "\f023";
}
.fa-flag:before {
  content: "\f024";
}
.fa-headphones:before {
  content: "\f025";
}
.fa-volume-off:before {
  content: "\f026";
}
.fa-volume-down:before {
  content: "\f027";
}
.fa-volume-up:before {
  content: "\f028";
}
.fa-qrcode:before {
  content: "\f029";
}
.fa-barcode:before {
  content: "\f02a";
}
.fa-tag:before {
  content: "\f02b";
}
.fa-tags:before {
  content: "\f02c";
}
.fa-book:before {
  content: "\f02d";
}
.fa-bookmark:before {
  content: "\f02e";
}
.fa-print:before {
  content: "\f02f";
}
.fa-camera:before {
  content: "\f030";
}
.fa-font:before {
  content: "\f031";
}
.fa-bold:before {
  content: "\f032";
}
.fa-italic:before {
  content: "\f033";
}
.fa-text-height:before {
  content: "\f034";
}
.fa-text-width:before {
  content: "\f035";
}
.fa-align-left:before {
  content: "\f036";
}
.fa-align-center:before {
  content: "\f037";
}
.fa-align-right:before {
  content: "\f038";
}
.fa-align-justify:before {
  content: "\f039";
}
.fa-list:before {
  content: "\f03a";
}
.fa-dedent:before,
.fa-outdent:before {
  content: "\f03b";
}
.fa-indent:before {
  content: "\f03c";
}
.fa-video-camera:before {
  content: "\f03d";
}
.fa-photo:before,
.fa-image:before,
.fa-picture-o:before {
  content: "\f03e";
}
.fa-pencil:before {
  content: "\f040";
}
.fa-map-marker:before {
  content: "\f041";
}
.fa-adjust:before {
  content: "\f042";
}
.fa-tint:before {
  content: "\f043";
}
.fa-edit:before,
.fa-pencil-square-o:before {
  content: "\f044";
}
.fa-share-square-o:before {
  content: "\f045";
}
.fa-check-square-o:before {
  content: "\f046";
}
.fa-arrows:before {
  content: "\f047";
}
.fa-step-backward:before {
  content: "\f048";
}
.fa-fast-backward:before {
  content: "\f049";
}
.fa-backward:before {
  content: "\f04a";
}
.fa-play:before {
  content: "\f04b";
}
.fa-pause:before {
  content: "\f04c";
}
.fa-stop:before {
  content: "\f04d";
}
.fa-forward:before {
  content: "\f04e";
}
.fa-fast-forward:before {
  content: "\f050";
}
.fa-step-forward:before {
  content: "\f051";
}
.fa-eject:before {
  content: "\f052";
}
.fa-chevron-left:before {
  content: "\f053";
}
.fa-chevron-right:before {
  content: "\f054";
}
.fa-plus-circle:before {
  content: "\f055";
}
.fa-minus-circle:before {
  content: "\f056";
}
.fa-times-circle:before {
  content: "\f057";
}
.fa-check-circle:before {
  content: "\f058";
}
.fa-question-circle:before {
  content: "\f059";
}
.fa-info-circle:before {
  content: "\f05a";
}
.fa-crosshairs:before {
  content: "\f05b";
}
.fa-times-circle-o:before {
  content: "\f05c";
}
.fa-check-circle-o:before {
  content: "\f05d";
}
.fa-ban:before {
  content: "\f05e";
}
.fa-arrow-left:before {
  content: "\f060";
}
.fa-arrow-right:before {
  content: "\f061";
}
.fa-arrow-up:before {
  content: "\f062";
}
.fa-arrow-down:before {
  content: "\f063";
}
.fa-mail-forward:before,
.fa-share:before {
  content: "\f064";
}
.fa-expand:before {
  content: "\f065";
}
.fa-compress:before {
  content: "\f066";
}
.fa-plus:before {
  content: "\f067";
}
.fa-minus:before {
  content: "\f068";
}
.fa-asterisk:before {
  content: "\f069";
}
.fa-exclamation-circle:before {
  content: "\f06a";
}
.fa-gift:before {
  content: "\f06b";
}
.fa-leaf:before {
  content: "\f06c";
}
.fa-fire:before {
  content: "\f06d";
}
.fa-eye:before {
  content: "\f06e";
}
.fa-eye-slash:before {
  content: "\f070";
}
.fa-warning:before,
.fa-exclamation-triangle:before {
  content: "\f071";
}
.fa-plane:before {
  content: "\f072";
}
.fa-calendar:before {
  content: "\f073";
}
.fa-random:before {
  content: "\f074";
}
.fa-comment:before {
  content: "\f075";
}
.fa-magnet:before {
  content: "\f076";
}
.fa-chevron-up:before {
  content: "\f077";
}
.fa-chevron-down:before {
  content: "\f078";
}
.fa-retweet:before {
  content: "\f079";
}
.fa-shopping-cart:before {
  content: "\f07a";
}
.fa-folder:before {
  content: "\f07b";
}
.fa-folder-open:before {
  content: "\f07c";
}
.fa-arrows-v:before {
  content: "\f07d";
}
.fa-arrows-h:before {
  content: "\f07e";
}
.fa-bar-chart-o:before,
.fa-bar-chart:before {
  content: "\f080";
}
.fa-twitter-square:before {
  content: "\f081";
}
.fa-facebook-square:before {
  content: "\f082";
}
.fa-camera-retro:before {
  content: "\f083";
}
.fa-key:before {
  content: "\f084";
}
.fa-gears:before,
.fa-cogs:before {
  content: "\f085";
}
.fa-comments:before {
  content: "\f086";
}
.fa-thumbs-o-up:before {
  content: "\f087";
}
.fa-thumbs-o-down:before {
  content: "\f088";
}
.fa-star-half:before {
  content: "\f089";
}
.fa-heart-o:before {
  content: "\f08a";
}
.fa-sign-out:before {
  content: "\f08b";
}
.fa-linkedin-square:before {
  content: "\f08c";
}
.fa-thumb-tack:before {
  content: "\f08d";
}
.fa-external-link:before {
  content: "\f08e";
}
.fa-sign-in:before {
  content: "\f090";
}
.fa-trophy:before {
  content: "\f091";
}
.fa-github-square:before {
  content: "\f092";
}
.fa-upload:before {
  content: "\f093";
}
.fa-lemon-o:before {
  content: "\f094";
}
.fa-phone:before {
  content: "\f095";
}
.fa-square-o:before {
  content: "\f096";
}
.fa-bookmark-o:before {
  content: "\f097";
}
.fa-phone-square:before {
  content: "\f098";
}
.fa-twitter:before {
  content: "\f099";
}
.fa-facebook-f:before,
.fa-facebook:before {
  content: "\f09a";
}
.fa-github:before {
  content: "\f09b";
}
.fa-unlock:before {
  content: "\f09c";
}
.fa-credit-card:before {
  content: "\f09d";
}
.fa-feed:before,
.fa-rss:before {
  content: "\f09e";
}
.fa-hdd-o:before {
  content: "\f0a0";
}
.fa-bullhorn:before {
  content: "\f0a1";
}
.fa-bell:before {
  content: "\f0f3";
}
.fa-certificate:before {
  content: "\f0a3";
}
.fa-hand-o-right:before {
  content: "\f0a4";
}
.fa-hand-o-left:before {
  content: "\f0a5";
}
.fa-hand-o-up:before {
  content: "\f0a6";
}
.fa-hand-o-down:before {
  content: "\f0a7";
}
.fa-arrow-circle-left:before {
  content: "\f0a8";
}
.fa-arrow-circle-right:before {
  content: "\f0a9";
}
.fa-arrow-circle-up:before {
  content: "\f0aa";
}
.fa-arrow-circle-down:before {
  content: "\f0ab";
}
.fa-globe:before {
  content: "\f0ac";
}
.fa-wrench:before {
  content: "\f0ad";
}
.fa-tasks:before {
  content: "\f0ae";
}
.fa-filter:before {
  content: "\f0b0";
}
.fa-briefcase:before {
  content: "\f0b1";
}
.fa-arrows-alt:before {
  content: "\f0b2";
}
.fa-group:before,
.fa-users:before {
  content: "\f0c0";
}
.fa-chain:before,
.fa-link:before {
  content: "\f0c1";
}
.fa-cloud:before {
  content: "\f0c2";
}
.fa-flask:before {
  content: "\f0c3";
}
.fa-cut:before,
.fa-scissors:before {
  content: "\f0c4";
}
.fa-copy:before,
.fa-files-o:before {
  content: "\f0c5";
}
.fa-paperclip:before {
  content: "\f0c6";
}
.fa-save:before,
.fa-floppy-o:before {
  content: "\f0c7";
}
.fa-square:before {
  content: "\f0c8";
}
.fa-navicon:before,
.fa-reorder:before,
.fa-bars:before {
  content: "\f0c9";
}
.fa-list-ul:before {
  content: "\f0ca";
}
.fa-list-ol:before {
  content: "\f0cb";
}
.fa-strikethrough:before {
  content: "\f0cc";
}
.fa-underline:before {
  content: "\f0cd";
}
.fa-table:before {
  content: "\f0ce";
}
.fa-magic:before {
  content: "\f0d0";
}
.fa-truck:before {
  content: "\f0d1";
}
.fa-pinterest:before {
  content: "\f0d2";
}
.fa-pinterest-square:before {
  content: "\f0d3";
}
.fa-google-plus-square:before {
  content: "\f0d4";
}
.fa-google-plus:before {
  content: "\f0d5";
}
.fa-money:before {
  content: "\f0d6";
}
.fa-caret-down:before {
  content: "\f0d7";
}
.fa-caret-up:before {
  content: "\f0d8";
}
.fa-caret-left:before {
  content: "\f0d9";
}
.fa-caret-right:before {
  content: "\f0da";
}
.fa-columns:before {
  content: "\f0db";
}
.fa-unsorted:before,
.fa-sort:before {
  content: "\f0dc";
}
.fa-sort-down:before,
.fa-sort-desc:before {
  content: "\f0dd";
}
.fa-sort-up:before,
.fa-sort-asc:before {
  content: "\f0de";
}
.fa-envelope:before {
  content: "\f0e0";
}
.fa-linkedin:before {
  content: "\f0e1";
}
.fa-rotate-left:before,
.fa-undo:before {
  content: "\f0e2";
}
.fa-legal:before,
.fa-gavel:before {
  content: "\f0e3";
}
.fa-dashboard:before,
.fa-tachometer:before {
  content: "\f0e4";
}
.fa-comment-o:before {
  content: "\f0e5";
}
.fa-comments-o:before {
  content: "\f0e6";
}
.fa-flash:before,
.fa-bolt:before {
  content: "\f0e7";
}
.fa-sitemap:before {
  content: "\f0e8";
}
.fa-umbrella:before {
  content: "\f0e9";
}
.fa-paste:before,
.fa-clipboard:before {
  content: "\f0ea";
}
.fa-lightbulb-o:before {
  content: "\f0eb";
}
.fa-exchange:before {
  content: "\f0ec";
}
.fa-cloud-download:before {
  content: "\f0ed";
}
.fa-cloud-upload:before {
  content: "\f0ee";
}
.fa-user-md:before {
  content: "\f0f0";
}
.fa-stethoscope:before {
  content: "\f0f1";
}
.fa-suitcase:before {
  content: "\f0f2";
}
.fa-bell-o:before {
  content: "\f0a2";
}
.fa-coffee:before {
  content: "\f0f4";
}
.fa-cutlery:before {
  content: "\f0f5";
}
.fa-file-text-o:before {
  content: "\f0f6";
}
.fa-building-o:before {
  content: "\f0f7";
}
.fa-hospital-o:before {
  content: "\f0f8";
}
.fa-ambulance:before {
  content: "\f0f9";
}
.fa-medkit:before {
  content: "\f0fa";
}
.fa-fighter-jet:before {
  content: "\f0fb";
}
.fa-beer:before {
  content: "\f0fc";
}
.fa-h-square:before {
  content: "\f0fd";
}
.fa-plus-square:before {
  content: "\f0fe";
}
.fa-angle-double-left:before {
  content: "\f100";
}
.fa-angle-double-right:before {
  content: "\f101";
}
.fa-angle-double-up:before {
  content: "\f102";
}
.fa-angle-double-down:before {
  content: "\f103";
}
.fa-angle-left:before {
  content: "\f104";
}
.fa-angle-right:before {
  content: "\f105";
}
.fa-angle-up:before {
  content: "\f106";
}
.fa-angle-down:before {
  content: "\f107";
}
.fa-desktop:before {
  content: "\f108";
}
.fa-laptop:before {
  content: "\f109";
}
.fa-tablet:before {
  content: "\f10a";
}
.fa-mobile-phone:before,
.fa-mobile:before {
  content: "\f10b";
}
.fa-circle-o:before {
  content: "\f10c";
}
.fa-quote-left:before {
  content: "\f10d";
}
.fa-quote-right:before {
  content: "\f10e";
}
.fa-spinner:before {
  content: "\f110";
}
.fa-circle:before {
  content: "\f111";
}
.fa-mail-reply:before,
.fa-reply:before {
  content: "\f112";
}
.fa-github-alt:before {
  content: "\f113";
}
.fa-folder-o:before {
  content: "\f114";
}
.fa-folder-open-o:before {
  content: "\f115";
}
.fa-smile-o:before {
  content: "\f118";
}
.fa-frown-o:before {
  content: "\f119";
}
.fa-meh-o:before {
  content: "\f11a";
}
.fa-gamepad:before {
  content: "\f11b";
}
.fa-keyboard-o:before {
  content: "\f11c";
}
.fa-flag-o:before {
  content: "\f11d";
}
.fa-flag-checkered:before {
  content: "\f11e";
}
.fa-terminal:before {
  content: "\f120";
}
.fa-code:before {
  content: "\f121";
}
.fa-mail-reply-all:before,
.fa-reply-all:before {
  content: "\f122";
}
.fa-star-half-empty:before,
.fa-star-half-full:before,
.fa-star-half-o:before {
  content: "\f123";
}
.fa-location-arrow:before {
  content: "\f124";
}
.fa-crop:before {
  content: "\f125";
}
.fa-code-fork:before {
  content: "\f126";
}
.fa-unlink:before,
.fa-chain-broken:before {
  content: "\f127";
}
.fa-question:before {
  content: "\f128";
}
.fa-info:before {
  content: "\f129";
}
.fa-exclamation:before {
  content: "\f12a";
}
.fa-superscript:before {
  content: "\f12b";
}
.fa-subscript:before {
  content: "\f12c";
}
.fa-eraser:before {
  content: "\f12d";
}
.fa-puzzle-piece:before {
  content: "\f12e";
}
.fa-microphone:before {
  content: "\f130";
}
.fa-microphone-slash:before {
  content: "\f131";
}
.fa-shield:before {
  content: "\f132";
}
.fa-calendar-o:before {
  content: "\f133";
}
.fa-fire-extinguisher:before {
  content: "\f134";
}
.fa-rocket:before {
  content: "\f135";
}
.fa-maxcdn:before {
  content: "\f136";
}
.fa-chevron-circle-left:before {
  content: "\f137";
}
.fa-chevron-circle-right:before {
  content: "\f138";
}
.fa-chevron-circle-up:before {
  content: "\f139";
}
.fa-chevron-circle-down:before {
  content: "\f13a";
}
.fa-html5:before {
  content: "\f13b";
}
.fa-css3:before {
  content: "\f13c";
}
.fa-anchor:before {
  content: "\f13d";
}
.fa-unlock-alt:before {
  content: "\f13e";
}
.fa-bullseye:before {
  content: "\f140";
}
.fa-ellipsis-h:before {
  content: "\f141";
}
.fa-ellipsis-v:before {
  content: "\f142";
}
.fa-rss-square:before {
  content: "\f143";
}
.fa-play-circle:before {
  content: "\f144";
}
.fa-ticket:before {
  content: "\f145";
}
.fa-minus-square:before {
  content: "\f146";
}
.fa-minus-square-o:before {
  content: "\f147";
}
.fa-level-up:before {
  content: "\f148";
}
.fa-level-down:before {
  content: "\f149";
}
.fa-check-square:before {
  content: "\f14a";
}
.fa-pencil-square:before {
  content: "\f14b";
}
.fa-external-link-square:before {
  content: "\f14c";
}
.fa-share-square:before {
  content: "\f14d";
}
.fa-compass:before {
  content: "\f14e";
}
.fa-toggle-down:before,
.fa-caret-square-o-down:before {
  content: "\f150";
}
.fa-toggle-up:before,
.fa-caret-square-o-up:before {
  content: "\f151";
}
.fa-toggle-right:before,
.fa-caret-square-o-right:before {
  content: "\f152";
}
.fa-euro:before,
.fa-eur:before {
  content: "\f153";
}
.fa-gbp:before {
  content: "\f154";
}
.fa-dollar:before,
.fa-usd:before {
  content: "\f155";
}
.fa-rupee:before,
.fa-inr:before {
  content: "\f156";
}
.fa-cny:before,
.fa-rmb:before,
.fa-yen:before,
.fa-jpy:before {
  content: "\f157";
}
.fa-ruble:before,
.fa-rouble:before,
.fa-rub:before {
  content: "\f158";
}
.fa-won:before,
.fa-krw:before {
  content: "\f159";
}
.fa-bitcoin:before,
.fa-btc:before {
  content: "\f15a";
}
.fa-file:before {
  content: "\f15b";
}
.fa-file-text:before {
  content: "\f15c";
}
.fa-sort-alpha-asc:before {
  content: "\f15d";
}
.fa-sort-alpha-desc:before {
  content: "\f15e";
}
.fa-sort-amount-asc:before {
  content: "\f160";
}
.fa-sort-amount-desc:before {
  content: "\f161";
}
.fa-sort-numeric-asc:before {
  content: "\f162";
}
.fa-sort-numeric-desc:before {
  content: "\f163";
}
.fa-thumbs-up:before {
  content: "\f164";
}
.fa-thumbs-down:before {
  content: "\f165";
}
.fa-youtube-square:before {
  content: "\f166";
}
.fa-youtube:before {
  content: "\f167";
}
.fa-xing:before {
  content: "\f168";
}
.fa-xing-square:before {
  content: "\f169";
}
.fa-youtube-play:before {
  content: "\f16a";
}
.fa-dropbox:before {
  content: "\f16b";
}
.fa-stack-overflow:before {
  content: "\f16c";
}
.fa-instagram:before {
  content: "\f16d";
}
.fa-flickr:before {
  content: "\f16e";
}
.fa-adn:before {
  content: "\f170";
}
.fa-bitbucket:before {
  content: "\f171";
}
.fa-bitbucket-square:before {
  content: "\f172";
}
.fa-tumblr:before {
  content: "\f173";
}
.fa-tumblr-square:before {
  content: "\f174";
}
.fa-long-arrow-down:before {
  content: "\f175";
}
.fa-long-arrow-up:before {
  content: "\f176";
}
.fa-long-arrow-left:before {
  content: "\f177";
}
.fa-long-arrow-right:before {
  content: "\f178";
}
.fa-apple:before {
  content: "\f179";
}
.fa-windows:before {
  content: "\f17a";
}
.fa-android:before {
  content: "\f17b";
}
.fa-linux:before {
  content: "\f17c";
}
.fa-dribbble:before {
  content: "\f17d";
}
.fa-skype:before {
  content: "\f17e";
}
.fa-foursquare:before {
  content: "\f180";
}
.fa-trello:before {
  content: "\f181";
}
.fa-female:before {
  content: "\f182";
}
.fa-male:before {
  content: "\f183";
}
.fa-gittip:before,
.fa-gratipay:before {
  content: "\f184";
}
.fa-sun-o:before {
  content: "\f185";
}
.fa-moon-o:before {
  content: "\f186";
}
.fa-archive:before {
  content: "\f187";
}
.fa-bug:before {
  content: "\f188";
}
.fa-vk:before {
  content: "\f189";
}
.fa-weibo:before {
  content: "\f18a";
}
.fa-renren:before {
  content: "\f18b";
}
.fa-pagelines:before {
  content: "\f18c";
}
.fa-stack-exchange:before {
  content: "\f18d";
}
.fa-arrow-circle-o-right:before {
  content: "\f18e";
}
.fa-arrow-circle-o-left:before {
  content: "\f190";
}
.fa-toggle-left:before,
.fa-caret-square-o-left:before {
  content: "\f191";
}
.fa-dot-circle-o:before {
  content: "\f192";
}
.fa-wheelchair:before {
  content: "\f193";
}
.fa-vimeo-square:before {
  content: "\f194";
}
.fa-turkish-lira:before,
.fa-try:before {
  content: "\f195";
}
.fa-plus-square-o:before {
  content: "\f196";
}
.fa-space-shuttle:before {
  content: "\f197";
}
.fa-slack:before {
  content: "\f198";
}
.fa-envelope-square:before {
  content: "\f199";
}
.fa-wordpress:before {
  content: "\f19a";
}
.fa-openid:before {
  content: "\f19b";
}
.fa-institution:before,
.fa-bank:before,
.fa-university:before {
  content: "\f19c";
}
.fa-mortar-board:before,
.fa-graduation-cap:before {
  content: "\f19d";
}
.fa-yahoo:before {
  content: "\f19e";
}
.fa-google:before {
  content: "\f1a0";
}
.fa-reddit:before {
  content: "\f1a1";
}
.fa-reddit-square:before {
  content: "\f1a2";
}
.fa-stumbleupon-circle:before {
  content: "\f1a3";
}
.fa-stumbleupon:before {
  content: "\f1a4";
}
.fa-delicious:before {
  content: "\f1a5";
}
.fa-digg:before {
  content: "\f1a6";
}
.fa-pied-piper-pp:before {
  content: "\f1a7";
}
.fa-pied-piper-alt:before {
  content: "\f1a8";
}
.fa-drupal:before {
  content: "\f1a9";
}
.fa-joomla:before {
  content: "\f1aa";
}
.fa-language:before {
  content: "\f1ab";
}
.fa-fax:before {
  content: "\f1ac";
}
.fa-building:before {
  content: "\f1ad";
}
.fa-child:before {
  content: "\f1ae";
}
.fa-paw:before {
  content: "\f1b0";
}
.fa-spoon:before {
  content: "\f1b1";
}
.fa-cube:before {
  content: "\f1b2";
}
.fa-cubes:before {
  content: "\f1b3";
}
.fa-behance:before {
  content: "\f1b4";
}
.fa-behance-square:before {
  content: "\f1b5";
}
.fa-steam:before {
  content: "\f1b6";
}
.fa-steam-square:before {
  content: "\f1b7";
}
.fa-recycle:before {
  content: "\f1b8";
}
.fa-automobile:before,
.fa-car:before {
  content: "\f1b9";
}
.fa-cab:before,
.fa-taxi:before {
  content: "\f1ba";
}
.fa-tree:before {
  content: "\f1bb";
}
.fa-spotify:before {
  content: "\f1bc";
}
.fa-deviantart:before {
  content: "\f1bd";
}
.fa-soundcloud:before {
  content: "\f1be";
}
.fa-database:before {
  content: "\f1c0";
}
.fa-file-pdf-o:before {
  content: "\f1c1";
}
.fa-file-word-o:before {
  content: "\f1c2";
}
.fa-file-excel-o:before {
  content: "\f1c3";
}
.fa-file-powerpoint-o:before {
  content: "\f1c4";
}
.fa-file-photo-o:before,
.fa-file-picture-o:before,
.fa-file-image-o:before {
  content: "\f1c5";
}
.fa-file-zip-o:before,
.fa-file-archive-o:before {
  content: "\f1c6";
}
.fa-file-sound-o:before,
.fa-file-audio-o:before {
  content: "\f1c7";
}
.fa-file-movie-o:before,
.fa-file-video-o:before {
  content: "\f1c8";
}
.fa-file-code-o:before {
  content: "\f1c9";
}
.fa-vine:before {
  content: "\f1ca";
}
.fa-codepen:before {
  content: "\f1cb";
}
.fa-jsfiddle:before {
  content: "\f1cc";
}
.fa-life-bouy:before,
.fa-life-buoy:before,
.fa-life-saver:before,
.fa-support:before,
.fa-life-ring:before {
  content: "\f1cd";
}
.fa-circle-o-notch:before {
  content: "\f1ce";
}
.fa-ra:before,
.fa-resistance:before,
.fa-rebel:before {
  content: "\f1d0";
}
.fa-ge:before,
.fa-empire:before {
  content: "\f1d1";
}
.fa-git-square:before {
  content: "\f1d2";
}
.fa-git:before {
  content: "\f1d3";
}
.fa-y-combinator-square:before,
.fa-yc-square:before,
.fa-hacker-news:before {
  content: "\f1d4";
}
.fa-tencent-weibo:before {
  content: "\f1d5";
}
.fa-qq:before {
  content: "\f1d6";
}
.fa-wechat:before,
.fa-weixin:before {
  content: "\f1d7";
}
.fa-send:before,
.fa-paper-plane:before {
  content: "\f1d8";
}
.fa-send-o:before,
.fa-paper-plane-o:before {
  content: "\f1d9";
}
.fa-history:before {
  content: "\f1da";
}
.fa-circle-thin:before {
  content: "\f1db";
}
.fa-header:before {
  content: "\f1dc";
}
.fa-paragraph:before {
  content: "\f1dd";
}
.fa-sliders:before {
  content: "\f1de";
}
.fa-share-alt:before {
  content: "\f1e0";
}
.fa-share-alt-square:before {
  content: "\f1e1";
}
.fa-bomb:before {
  content: "\f1e2";
}
.fa-soccer-ball-o:before,
.fa-futbol-o:before {
  content: "\f1e3";
}
.fa-tty:before {
  content: "\f1e4";
}
.fa-binoculars:before {
  content: "\f1e5";
}
.fa-plug:before {
  content: "\f1e6";
}
.fa-slideshare:before {
  content: "\f1e7";
}
.fa-twitch:before {
  content: "\f1e8";
}
.fa-yelp:before {
  content: "\f1e9";
}
.fa-newspaper-o:before {
  content: "\f1ea";
}
.fa-wifi:before {
  content: "\f1eb";
}
.fa-calculator:before {
  content: "\f1ec";
}
.fa-paypal:before {
  content: "\f1ed";
}
.fa-google-wallet:before {
  content: "\f1ee";
}
.fa-cc-visa:before {
  content: "\f1f0";
}
.fa-cc-mastercard:before {
  content: "\f1f1";
}
.fa-cc-discover:before {
  content: "\f1f2";
}
.fa-cc-amex:before {
  content: "\f1f3";
}
.fa-cc-paypal:before {
  content: "\f1f4";
}
.fa-cc-stripe:before {
  content: "\f1f5";
}
.fa-bell-slash:before {
  content: "\f1f6";
}
.fa-bell-slash-o:before {
  content: "\f1f7";
}
.fa-trash:before {
  content: "\f1f8";
}
.fa-copyright:before {
  content: "\f1f9";
}
.fa-at:before {
  content: "\f1fa";
}
.fa-eyedropper:before {
  content: "\f1fb";
}
.fa-paint-brush:before {
  content: "\f1fc";
}
.fa-birthday-cake:before {
  content: "\f1fd";
}
.fa-area-chart:before {
  content: "\f1fe";
}
.fa-pie-chart:before {
  content: "\f200";
}
.fa-line-chart:before {
  content: "\f201";
}
.fa-lastfm:before {
  content: "\f202";
}
.fa-lastfm-square:before {
  content: "\f203";
}
.fa-toggle-off:before {
  content: "\f204";
}
.fa-toggle-on:before {
  content: "\f205";
}
.fa-bicycle:before {
  content: "\f206";
}
.fa-bus:before {
  content: "\f207";
}
.fa-ioxhost:before {
  content: "\f208";
}
.fa-angellist:before {
  content: "\f209";
}
.fa-cc:before {
  content: "\f20a";
}
.fa-shekel:before,
.fa-sheqel:before,
.fa-ils:before {
  content: "\f20b";
}
.fa-meanpath:before {
  content: "\f20c";
}
.fa-buysellads:before {
  content: "\f20d";
}
.fa-connectdevelop:before {
  content: "\f20e";
}
.fa-dashcube:before {
  content: "\f210";
}
.fa-forumbee:before {
  content: "\f211";
}
.fa-leanpub:before {
  content: "\f212";
}
.fa-sellsy:before {
  content: "\f213";
}
.fa-shirtsinbulk:before {
  content: "\f214";
}
.fa-simplybuilt:before {
  content: "\f215";
}
.fa-skyatlas:before {
  content: "\f216";
}
.fa-cart-plus:before {
  content: "\f217";
}
.fa-cart-arrow-down:before {
  content: "\f218";
}
.fa-diamond:before {
  content: "\f219";
}
.fa-ship:before {
  content: "\f21a";
}
.fa-user-secret:before {
  content: "\f21b";
}
.fa-motorcycle:before {
  content: "\f21c";
}
.fa-street-view:before {
  content: "\f21d";
}
.fa-heartbeat:before {
  content: "\f21e";
}
.fa-venus:before {
  content: "\f221";
}
.fa-mars:before {
  content: "\f222";
}
.fa-mercury:before {
  content: "\f223";
}
.fa-intersex:before,
.fa-transgender:before {
  content: "\f224";
}
.fa-transgender-alt:before {
  content: "\f225";
}
.fa-venus-double:before {
  content: "\f226";
}
.fa-mars-double:before {
  content: "\f227";
}
.fa-venus-mars:before {
  content: "\f228";
}
.fa-mars-stroke:before {
  content: "\f229";
}
.fa-mars-stroke-v:before {
  content: "\f22a";
}
.fa-mars-stroke-h:before {
  content: "\f22b";
}
.fa-neuter:before {
  content: "\f22c";
}
.fa-genderless:before {
  content: "\f22d";
}
.fa-facebook-official:before {
  content: "\f230";
}
.fa-pinterest-p:before {
  content: "\f231";
}
.fa-whatsapp:before {
  content: "\f232";
}
.fa-server:before {
  content: "\f233";
}
.fa-user-plus:before {
  content: "\f234";
}
.fa-user-times:before {
  content: "\f235";
}
.fa-hotel:before,
.fa-bed:before {
  content: "\f236";
}
.fa-viacoin:before {
  content: "\f237";
}
.fa-train:before {
  content: "\f238";
}
.fa-subway:before {
  content: "\f239";
}
.fa-medium:before {
  content: "\f23a";
}
.fa-yc:before,
.fa-y-combinator:before {
  content: "\f23b";
}
.fa-optin-monster:before {
  content: "\f23c";
}
.fa-opencart:before {
  content: "\f23d";
}
.fa-expeditedssl:before {
  content: "\f23e";
}
.fa-battery-4:before,
.fa-battery:before,
.fa-battery-full:before {
  content: "\f240";
}
.fa-battery-3:before,
.fa-battery-three-quarters:before {
  content: "\f241";
}
.fa-battery-2:before,
.fa-battery-half:before {
  content: "\f242";
}
.fa-battery-1:before,
.fa-battery-quarter:before {
  content: "\f243";
}
.fa-battery-0:before,
.fa-battery-empty:before {
  content: "\f244";
}
.fa-mouse-pointer:before {
  content: "\f245";
}
.fa-i-cursor:before {
  content: "\f246";
}
.fa-object-group:before {
  content: "\f247";
}
.fa-object-ungroup:before {
  content: "\f248";
}
.fa-sticky-note:before {
  content: "\f249";
}
.fa-sticky-note-o:before {
  content: "\f24a";
}
.fa-cc-jcb:before {
  content: "\f24b";
}
.fa-cc-diners-club:before {
  content: "\f24c";
}
.fa-clone:before {
  content: "\f24d";
}
.fa-balance-scale:before {
  content: "\f24e";
}
.fa-hourglass-o:before {
  content: "\f250";
}
.fa-hourglass-1:before,
.fa-hourglass-start:before {
  content: "\f251";
}
.fa-hourglass-2:before,
.fa-hourglass-half:before {
  content: "\f252";
}
.fa-hourglass-3:before,
.fa-hourglass-end:before {
  content: "\f253";
}
.fa-hourglass:before {
  content: "\f254";
}
.fa-hand-grab-o:before,
.fa-hand-rock-o:before {
  content: "\f255";
}
.fa-hand-stop-o:before,
.fa-hand-paper-o:before {
  content: "\f256";
}
.fa-hand-scissors-o:before {
  content: "\f257";
}
.fa-hand-lizard-o:before {
  content: "\f258";
}
.fa-hand-spock-o:before {
  content: "\f259";
}
.fa-hand-pointer-o:before {
  content: "\f25a";
}
.fa-hand-peace-o:before {
  content: "\f25b";
}
.fa-trademark:before {
  content: "\f25c";
}
.fa-registered:before {
  content: "\f25d";
}
.fa-creative-commons:before {
  content: "\f25e";
}
.fa-gg:before {
  content: "\f260";
}
.fa-gg-circle:before {
  content: "\f261";
}
.fa-tripadvisor:before {
  content: "\f262";
}
.fa-odnoklassniki:before {
  content: "\f263";
}
.fa-odnoklassniki-square:before {
  content: "\f264";
}
.fa-get-pocket:before {
  content: "\f265";
}
.fa-wikipedia-w:before {
  content: "\f266";
}
.fa-safari:before {
  content: "\f267";
}
.fa-chrome:before {
  content: "\f268";
}
.fa-firefox:before {
  content: "\f269";
}
.fa-opera:before {
  content: "\f26a";
}
.fa-internet-explorer:before {
  content: "\f26b";
}
.fa-tv:before,
.fa-television:before {
  content: "\f26c";
}
.fa-contao:before {
  content: "\f26d";
}
.fa-500px:before {
  content: "\f26e";
}
.fa-amazon:before {
  content: "\f270";
}
.fa-calendar-plus-o:before {
  content: "\f271";
}
.fa-calendar-minus-o:before {
  content: "\f272";
}
.fa-calendar-times-o:before {
  content: "\f273";
}
.fa-calendar-check-o:before {
  content: "\f274";
}
.fa-industry:before {
  content: "\f275";
}
.fa-map-pin:before {
  content: "\f276";
}
.fa-map-signs:before {
  content: "\f277";
}
.fa-map-o:before {
  content: "\f278";
}
.fa-map:before {
  content: "\f279";
}
.fa-commenting:before {
  content: "\f27a";
}
.fa-commenting-o:before {
  content: "\f27b";
}
.fa-houzz:before {
  content: "\f27c";
}
.fa-vimeo:before {
  content: "\f27d";
}
.fa-black-tie:before {
  content: "\f27e";
}
.fa-fonticons:before {
  content: "\f280";
}
.fa-reddit-alien:before {
  content: "\f281";
}
.fa-edge:before {
  content: "\f282";
}
.fa-credit-card-alt:before {
  content: "\f283";
}
.fa-codiepie:before {
  content: "\f284";
}
.fa-modx:before {
  content: "\f285";
}
.fa-fort-awesome:before {
  content: "\f286";
}
.fa-usb:before {
  content: "\f287";
}
.fa-product-hunt:before {
  content: "\f288";
}
.fa-mixcloud:before {
  content: "\f289";
}
.fa-scribd:before {
  content: "\f28a";
}
.fa-pause-circle:before {
  content: "\f28b";
}
.fa-pause-circle-o:before {
  content: "\f28c";
}
.fa-stop-circle:before {
  content: "\f28d";
}
.fa-stop-circle-o:before {
  content: "\f28e";
}
.fa-shopping-bag:before {
  content: "\f290";
}
.fa-shopping-basket:before {
  content: "\f291";
}
.fa-hashtag:before {
  content: "\f292";
}
.fa-bluetooth:before {
  content: "\f293";
}
.fa-bluetooth-b:before {
  content: "\f294";
}
.fa-percent:before {
  content: "\f295";
}
.fa-gitlab:before {
  content: "\f296";
}
.fa-wpbeginner:before {
  content: "\f297";
}
.fa-wpforms:before {
  content: "\f298";
}
.fa-envira:before {
  content: "\f299";
}
.fa-universal-access:before {
  content: "\f29a";
}
.fa-wheelchair-alt:before {
  content: "\f29b";
}
.fa-question-circle-o:before {
  content: "\f29c";
}
.fa-blind:before {
  content: "\f29d";
}
.fa-audio-description:before {
  content: "\f29e";
}
.fa-volume-control-phone:before {
  content: "\f2a0";
}
.fa-braille:before {
  content: "\f2a1";
}
.fa-assistive-listening-systems:before {
  content: "\f2a2";
}
.fa-asl-interpreting:before,
.fa-american-sign-language-interpreting:before {
  content: "\f2a3";
}
.fa-deafness:before,
.fa-hard-of-hearing:before,
.fa-deaf:before {
  content: "\f2a4";
}
.fa-glide:before {
  content: "\f2a5";
}
.fa-glide-g:before {
  content: "\f2a6";
}
.fa-signing:before,
.fa-sign-language:before {
  content: "\f2a7";
}
.fa-low-vision:before {
  content: "\f2a8";
}
.fa-viadeo:before {
  content: "\f2a9";
}
.fa-viadeo-square:before {
  content: "\f2aa";
}
.fa-snapchat:before {
  content: "\f2ab";
}
.fa-snapchat-ghost:before {
  content: "\f2ac";
}
.fa-snapchat-square:before {
  content: "\f2ad";
}
.fa-pied-piper:before {
  content: "\f2ae";
}
.fa-first-order:before {
  content: "\f2b0";
}
.fa-yoast:before {
  content: "\f2b1";
}
.fa-themeisle:before {
  content: "\f2b2";
}
.fa-google-plus-circle:before,
.fa-google-plus-official:before {
  content: "\f2b3";
}
.fa-fa:before,
.fa-font-awesome:before {
  content: "\f2b4";
}
.fa-handshake-o:before {
  content: "\f2b5";
}
.fa-envelope-open:before {
  content: "\f2b6";
}
.fa-envelope-open-o:before {
  content: "\f2b7";
}
.fa-linode:before {
  content: "\f2b8";
}
.fa-address-book:before {
  content: "\f2b9";
}
.fa-address-book-o:before {
  content: "\f2ba";
}
.fa-vcard:before,
.fa-address-card:before {
  content: "\f2bb";
}
.fa-vcard-o:before,
.fa-address-card-o:before {
  content: "\f2bc";
}
.fa-user-circle:before {
  content: "\f2bd";
}
.fa-user-circle-o:before {
  content: "\f2be";
}
.fa-user-o:before {
  content: "\f2c0";
}
.fa-id-badge:before {
  content: "\f2c1";
}
.fa-drivers-license:before,
.fa-id-card:before {
  content: "\f2c2";
}
.fa-drivers-license-o:before,
.fa-id-card-o:before {
  content: "\f2c3";
}
.fa-quora:before {
  content: "\f2c4";
}
.fa-free-code-camp:before {
  content: "\f2c5";
}
.fa-telegram:before {
  content: "\f2c6";
}
.fa-thermometer-4:before,
.fa-thermometer:before,
.fa-thermometer-full:before {
  content: "\f2c7";
}
.fa-thermometer-3:before,
.fa-thermometer-three-quarters:before {
  content: "\f2c8";
}
.fa-thermometer-2:before,
.fa-thermometer-half:before {
  content: "\f2c9";
}
.fa-thermometer-1:before,
.fa-thermometer-quarter:before {
  content: "\f2ca";
}
.fa-thermometer-0:before,
.fa-thermometer-empty:before {
  content: "\f2cb";
}
.fa-shower:before {
  content: "\f2cc";
}
.fa-bathtub:before,
.fa-s15:before,
.fa-bath:before {
  content: "\f2cd";
}
.fa-podcast:before {
  content: "\f2ce";
}
.fa-window-maximize:before {
  content: "\f2d0";
}
.fa-window-minimize:before {
  content: "\f2d1";
}
.fa-window-restore:before {
  content: "\f2d2";
}
.fa-times-rectangle:before,
.fa-window-close:before {
  content: "\f2d3";
}
.fa-times-rectangle-o:before,
.fa-window-close-o:before {
  content: "\f2d4";
}
.fa-bandcamp:before {
  content: "\f2d5";
}
.fa-grav:before {
  content: "\f2d6";
}
.fa-etsy:before {
  content: "\f2d7";
}
.fa-imdb:before {
  content: "\f2d8";
}
.fa-ravelry:before {
  content: "\f2d9";
}
.fa-eercast:before {
  content: "\f2da";
}
.fa-microchip:before {
  content: "\f2db";
}
.fa-snowflake-o:before {
  content: "\f2dc";
}
.fa-superpowers:before {
  content: "\f2dd";
}
.fa-wpexplorer:before {
  content: "\f2de";
}
.fa-meetup:before {
  content: "\f2e0";
}
.sr-only {
  position: absolute;
  width: 1px;
  height: 1px;
  padding: 0;
  margin: -1px;
  overflow: hidden;
  clip: rect(0, 0, 0, 0);
  border: 0;
}
.sr-only-focusable:active,
.sr-only-focusable:focus {
  position: static;
  width: auto;
  height: auto;
  margin: 0;
  overflow: visible;
  clip: auto;
}
.sr-only-focusable:active,
.sr-only-focusable:focus {
  position: static;
  width: auto;
  height: auto;
  margin: 0;
  overflow: visible;
  clip: auto;
}
/*!
*
* IPython base
*
*/
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
code {
  color: #000;
}
pre {
  font-size: inherit;
  line-height: inherit;
}
label {
  font-weight: normal;
}
/* Make the page background atleast 100% the height of the view port */
/* Make the page itself atleast 70% the height of the view port */
.border-box-sizing {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.corner-all {
  border-radius: 2px;
}
.no-padding {
  padding: 0px;
}
/* Flexible box model classes */
/* Taken from Alex Russell http://infrequently.org/2009/08/css-3-progress/ */
/* This file is a compatability layer.  It allows the usage of flexible box 
model layouts accross multiple browsers, including older browsers.  The newest,
universal implementation of the flexible box model is used when available (see
`Modern browsers` comments below).  Browsers that are known to implement this 
new spec completely include:

    Firefox 28.0+
    Chrome 29.0+
    Internet Explorer 11+ 
    Opera 17.0+

Browsers not listed, including Safari, are supported via the styling under the
`Old browsers` comments below.
*/
.hbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
.hbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.vbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
.vbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.hbox.reverse,
.vbox.reverse,
.reverse {
  /* Old browsers */
  -webkit-box-direction: reverse;
  -moz-box-direction: reverse;
  box-direction: reverse;
  /* Modern browsers */
  flex-direction: row-reverse;
}
.hbox.box-flex0,
.vbox.box-flex0,
.box-flex0 {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
  width: auto;
}
.hbox.box-flex1,
.vbox.box-flex1,
.box-flex1 {
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex,
.vbox.box-flex,
.box-flex {
  /* Old browsers */
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex2,
.vbox.box-flex2,
.box-flex2 {
  /* Old browsers */
  -webkit-box-flex: 2;
  -moz-box-flex: 2;
  box-flex: 2;
  /* Modern browsers */
  flex: 2;
}
.box-group1 {
  /*  Deprecated */
  -webkit-box-flex-group: 1;
  -moz-box-flex-group: 1;
  box-flex-group: 1;
}
.box-group2 {
  /* Deprecated */
  -webkit-box-flex-group: 2;
  -moz-box-flex-group: 2;
  box-flex-group: 2;
}
.hbox.start,
.vbox.start,
.start {
  /* Old browsers */
  -webkit-box-pack: start;
  -moz-box-pack: start;
  box-pack: start;
  /* Modern browsers */
  justify-content: flex-start;
}
.hbox.end,
.vbox.end,
.end {
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
}
.hbox.center,
.vbox.center,
.center {
  /* Old browsers */
  -webkit-box-pack: center;
  -moz-box-pack: center;
  box-pack: center;
  /* Modern browsers */
  justify-content: center;
}
.hbox.baseline,
.vbox.baseline,
.baseline {
  /* Old browsers */
  -webkit-box-pack: baseline;
  -moz-box-pack: baseline;
  box-pack: baseline;
  /* Modern browsers */
  justify-content: baseline;
}
.hbox.stretch,
.vbox.stretch,
.stretch {
  /* Old browsers */
  -webkit-box-pack: stretch;
  -moz-box-pack: stretch;
  box-pack: stretch;
  /* Modern browsers */
  justify-content: stretch;
}
.hbox.align-start,
.vbox.align-start,
.align-start {
  /* Old browsers */
  -webkit-box-align: start;
  -moz-box-align: start;
  box-align: start;
  /* Modern browsers */
  align-items: flex-start;
}
.hbox.align-end,
.vbox.align-end,
.align-end {
  /* Old browsers */
  -webkit-box-align: end;
  -moz-box-align: end;
  box-align: end;
  /* Modern browsers */
  align-items: flex-end;
}
.hbox.align-center,
.vbox.align-center,
.align-center {
  /* Old browsers */
  -webkit-box-align: center;
  -moz-box-align: center;
  box-align: center;
  /* Modern browsers */
  align-items: center;
}
.hbox.align-baseline,
.vbox.align-baseline,
.align-baseline {
  /* Old browsers */
  -webkit-box-align: baseline;
  -moz-box-align: baseline;
  box-align: baseline;
  /* Modern browsers */
  align-items: baseline;
}
.hbox.align-stretch,
.vbox.align-stretch,
.align-stretch {
  /* Old browsers */
  -webkit-box-align: stretch;
  -moz-box-align: stretch;
  box-align: stretch;
  /* Modern browsers */
  align-items: stretch;
}
div.error {
  margin: 2em;
  text-align: center;
}
div.error > h1 {
  font-size: 500%;
  line-height: normal;
}
div.error > p {
  font-size: 200%;
  line-height: normal;
}
div.traceback-wrapper {
  text-align: left;
  max-width: 800px;
  margin: auto;
}
div.traceback-wrapper pre.traceback {
  max-height: 600px;
  overflow: auto;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
body {
  background-color: #fff;
  /* This makes sure that the body covers the entire window and needs to
       be in a different element than the display: box in wrapper below */
  position: absolute;
  left: 0px;
  right: 0px;
  top: 0px;
  bottom: 0px;
  overflow: visible;
}
body > #header {
  /* Initially hidden to prevent FLOUC */
  display: none;
  background-color: #fff;
  /* Display over codemirror */
  position: relative;
  z-index: 100;
}
body > #header #header-container {
  display: flex;
  flex-direction: row;
  justify-content: space-between;
  padding: 5px;
  padding-bottom: 5px;
  padding-top: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
body > #header .header-bar {
  width: 100%;
  height: 1px;
  background: #e7e7e7;
  margin-bottom: -1px;
}
@media print {
  body > #header {
    display: none !important;
  }
}
#header-spacer {
  width: 100%;
  visibility: hidden;
}
@media print {
  #header-spacer {
    display: none;
  }
}
#ipython_notebook {
  padding-left: 0px;
  padding-top: 1px;
  padding-bottom: 1px;
}
[dir="rtl"] #ipython_notebook {
  margin-right: 10px;
  margin-left: 0;
}
[dir="rtl"] #ipython_notebook.pull-left {
  float: right !important;
  float: right;
}
.flex-spacer {
  flex: 1;
}
#noscript {
  width: auto;
  padding-top: 16px;
  padding-bottom: 16px;
  text-align: center;
  font-size: 22px;
  color: red;
  font-weight: bold;
}
#ipython_notebook img {
  height: 28px;
}
#site {
  width: 100%;
  display: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  overflow: auto;
}
@media print {
  #site {
    height: auto !important;
  }
}
/* Smaller buttons */
.ui-button .ui-button-text {
  padding: 0.2em 0.8em;
  font-size: 77%;
}
input.ui-button {
  padding: 0.3em 0.9em;
}
span#kernel_logo_widget {
  margin: 0 10px;
}
span#login_widget {
  float: right;
}
[dir="rtl"] span#login_widget {
  float: left;
}
span#login_widget > .button,
#logout {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button:focus,
#logout:focus,
span#login_widget > .button.focus,
#logout.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
span#login_widget > .button:hover,
#logout:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active:hover,
#logout:active:hover,
span#login_widget > .button.active:hover,
#logout.active:hover,
.open > .dropdown-togglespan#login_widget > .button:hover,
.open > .dropdown-toggle#logout:hover,
span#login_widget > .button:active:focus,
#logout:active:focus,
span#login_widget > .button.active:focus,
#logout.active:focus,
.open > .dropdown-togglespan#login_widget > .button:focus,
.open > .dropdown-toggle#logout:focus,
span#login_widget > .button:active.focus,
#logout:active.focus,
span#login_widget > .button.active.focus,
#logout.active.focus,
.open > .dropdown-togglespan#login_widget > .button.focus,
.open > .dropdown-toggle#logout.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  background-image: none;
}
span#login_widget > .button.disabled:hover,
#logout.disabled:hover,
span#login_widget > .button[disabled]:hover,
#logout[disabled]:hover,
fieldset[disabled] span#login_widget > .button:hover,
fieldset[disabled] #logout:hover,
span#login_widget > .button.disabled:focus,
#logout.disabled:focus,
span#login_widget > .button[disabled]:focus,
#logout[disabled]:focus,
fieldset[disabled] span#login_widget > .button:focus,
fieldset[disabled] #logout:focus,
span#login_widget > .button.disabled.focus,
#logout.disabled.focus,
span#login_widget > .button[disabled].focus,
#logout[disabled].focus,
fieldset[disabled] span#login_widget > .button.focus,
fieldset[disabled] #logout.focus {
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button .badge,
#logout .badge {
  color: #fff;
  background-color: #333;
}
.nav-header {
  text-transform: none;
}
#header > span {
  margin-top: 10px;
}
.modal_stretch .modal-dialog {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  min-height: 80vh;
}
.modal_stretch .modal-dialog .modal-body {
  max-height: calc(100vh - 200px);
  overflow: auto;
  flex: 1;
}
.modal-header {
  cursor: move;
}
@media (min-width: 768px) {
  .modal .modal-dialog {
    width: 700px;
  }
}
@media (min-width: 768px) {
  select.form-control {
    margin-left: 12px;
    margin-right: 12px;
  }
}
/*!
*
* IPython auth
*
*/
.center-nav {
  display: inline-block;
  margin-bottom: -4px;
}
[dir="rtl"] .center-nav form.pull-left {
  float: right !important;
  float: right;
}
[dir="rtl"] .center-nav .navbar-text {
  float: right;
}
[dir="rtl"] .navbar-inner {
  text-align: right;
}
[dir="rtl"] div.text-left {
  text-align: right;
}
/*!
*
* IPython tree view
*
*/
/* We need an invisible input field on top of the sentense*/
/* "Drag file onto the list ..." */
.alternate_upload {
  background-color: none;
  display: inline;
}
.alternate_upload.form {
  padding: 0;
  margin: 0;
}
.alternate_upload input.fileinput {
  position: absolute;
  display: block;
  width: 100%;
  height: 100%;
  overflow: hidden;
  cursor: pointer;
  opacity: 0;
  z-index: 2;
}
.alternate_upload .btn-xs > input.fileinput {
  margin: -1px -5px;
}
.alternate_upload .btn-upload {
  position: relative;
  height: 22px;
}
::-webkit-file-upload-button {
  cursor: pointer;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
ul#tabs {
  margin-bottom: 4px;
}
ul#tabs a {
  padding-top: 6px;
  padding-bottom: 4px;
}
[dir="rtl"] ul#tabs.nav-tabs > li {
  float: right;
}
[dir="rtl"] ul#tabs.nav.nav-tabs {
  padding-right: 0;
}
ul.breadcrumb a:focus,
ul.breadcrumb a:hover {
  text-decoration: none;
}
ul.breadcrumb i.icon-home {
  font-size: 16px;
  margin-right: 4px;
}
ul.breadcrumb span {
  color: #5e5e5e;
}
.list_toolbar {
  padding: 4px 0 4px 0;
  vertical-align: middle;
}
.list_toolbar .tree-buttons {
  padding-top: 1px;
}
[dir="rtl"] .list_toolbar .tree-buttons .pull-right {
  float: left !important;
  float: left;
}
[dir="rtl"] .list_toolbar .col-sm-4,
[dir="rtl"] .list_toolbar .col-sm-8 {
  float: right;
}
.dynamic-buttons {
  padding-top: 3px;
  display: inline-block;
}
.list_toolbar [class*="span"] {
  min-height: 24px;
}
.list_header {
  font-weight: bold;
  background-color: #EEE;
}
.list_placeholder {
  font-weight: bold;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
}
.list_container {
  margin-top: 4px;
  margin-bottom: 20px;
  border: 1px solid #ddd;
  border-radius: 2px;
}
.list_container > div {
  border-bottom: 1px solid #ddd;
}
.list_container > div:hover .list-item {
  background-color: red;
}
.list_container > div:last-child {
  border: none;
}
.list_item:hover .list_item {
  background-color: #ddd;
}
.list_item a {
  text-decoration: none;
}
.list_item:hover {
  background-color: #fafafa;
}
.list_header > div,
.list_item > div {
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
.list_header > div input,
.list_item > div input {
  margin-right: 7px;
  margin-left: 14px;
  vertical-align: text-bottom;
  line-height: 22px;
  position: relative;
  top: -1px;
}
.list_header > div .item_link,
.list_item > div .item_link {
  margin-left: -1px;
  vertical-align: baseline;
  line-height: 22px;
}
[dir="rtl"] .list_item > div input {
  margin-right: 0;
}
.new-file input[type=checkbox] {
  visibility: hidden;
}
.item_name {
  line-height: 22px;
  height: 24px;
}
.item_icon {
  font-size: 14px;
  color: #5e5e5e;
  margin-right: 7px;
  margin-left: 7px;
  line-height: 22px;
  vertical-align: baseline;
}
.item_modified {
  margin-right: 7px;
  margin-left: 7px;
}
[dir="rtl"] .item_modified.pull-right {
  float: left !important;
  float: left;
}
.item_buttons {
  line-height: 1em;
  margin-left: -5px;
}
.item_buttons .btn,
.item_buttons .btn-group,
.item_buttons .input-group {
  float: left;
}
.item_buttons > .btn,
.item_buttons > .btn-group,
.item_buttons > .input-group {
  margin-left: 5px;
}
.item_buttons .btn {
  min-width: 13ex;
}
.item_buttons .running-indicator {
  padding-top: 4px;
  color: #5cb85c;
}
.item_buttons .kernel-name {
  padding-top: 4px;
  color: #5bc0de;
  margin-right: 7px;
  float: left;
}
[dir="rtl"] .item_buttons.pull-right {
  float: left !important;
  float: left;
}
[dir="rtl"] .item_buttons .kernel-name {
  margin-left: 7px;
  float: right;
}
.toolbar_info {
  height: 24px;
  line-height: 24px;
}
.list_item input:not([type=checkbox]) {
  padding-top: 3px;
  padding-bottom: 3px;
  height: 22px;
  line-height: 14px;
  margin: 0px;
}
.highlight_text {
  color: blue;
}
#project_name {
  display: inline-block;
  padding-left: 7px;
  margin-left: -2px;
}
#project_name > .breadcrumb {
  padding: 0px;
  margin-bottom: 0px;
  background-color: transparent;
  font-weight: bold;
}
.sort_button {
  display: inline-block;
  padding-left: 7px;
}
[dir="rtl"] .sort_button.pull-right {
  float: left !important;
  float: left;
}
#tree-selector {
  padding-right: 0px;
}
#button-select-all {
  min-width: 50px;
}
[dir="rtl"] #button-select-all.btn {
  float: right ;
}
#select-all {
  margin-left: 7px;
  margin-right: 2px;
  margin-top: 2px;
  height: 16px;
}
[dir="rtl"] #select-all.pull-left {
  float: right !important;
  float: right;
}
.menu_icon {
  margin-right: 2px;
}
.tab-content .row {
  margin-left: 0px;
  margin-right: 0px;
}
.folder_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f114";
}
.folder_icon:before.fa-pull-left {
  margin-right: .3em;
}
.folder_icon:before.fa-pull-right {
  margin-left: .3em;
}
.folder_icon:before.pull-left {
  margin-right: .3em;
}
.folder_icon:before.pull-right {
  margin-left: .3em;
}
.notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
}
.notebook_icon:before.fa-pull-left {
  margin-right: .3em;
}
.notebook_icon:before.fa-pull-right {
  margin-left: .3em;
}
.notebook_icon:before.pull-left {
  margin-right: .3em;
}
.notebook_icon:before.pull-right {
  margin-left: .3em;
}
.running_notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
  color: #5cb85c;
}
.running_notebook_icon:before.fa-pull-left {
  margin-right: .3em;
}
.running_notebook_icon:before.fa-pull-right {
  margin-left: .3em;
}
.running_notebook_icon:before.pull-left {
  margin-right: .3em;
}
.running_notebook_icon:before.pull-right {
  margin-left: .3em;
}
.file_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f016";
  position: relative;
  top: -2px;
}
.file_icon:before.fa-pull-left {
  margin-right: .3em;
}
.file_icon:before.fa-pull-right {
  margin-left: .3em;
}
.file_icon:before.pull-left {
  margin-right: .3em;
}
.file_icon:before.pull-right {
  margin-left: .3em;
}
#notebook_toolbar .pull-right {
  padding-top: 0px;
  margin-right: -1px;
}
ul#new-menu {
  left: auto;
  right: 0;
}
#new-menu .dropdown-header {
  font-size: 10px;
  border-bottom: 1px solid #e5e5e5;
  padding: 0 0 3px;
  margin: -3px 20px 0;
}
.kernel-menu-icon {
  padding-right: 12px;
  width: 24px;
  content: "\f096";
}
.kernel-menu-icon:before {
  content: "\f096";
}
.kernel-menu-icon-current:before {
  content: "\f00c";
}
#tab_content {
  padding-top: 20px;
}
#running .panel-group .panel {
  margin-top: 3px;
  margin-bottom: 1em;
}
#running .panel-group .panel .panel-heading {
  background-color: #EEE;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
#running .panel-group .panel .panel-heading a:focus,
#running .panel-group .panel .panel-heading a:hover {
  text-decoration: none;
}
#running .panel-group .panel .panel-body {
  padding: 0px;
}
#running .panel-group .panel .panel-body .list_container {
  margin-top: 0px;
  margin-bottom: 0px;
  border: 0px;
  border-radius: 0px;
}
#running .panel-group .panel .panel-body .list_container .list_item {
  border-bottom: 1px solid #ddd;
}
#running .panel-group .panel .panel-body .list_container .list_item:last-child {
  border-bottom: 0px;
}
.delete-button {
  display: none;
}
.duplicate-button {
  display: none;
}
.rename-button {
  display: none;
}
.move-button {
  display: none;
}
.download-button {
  display: none;
}
.shutdown-button {
  display: none;
}
.dynamic-instructions {
  display: inline-block;
  padding-top: 4px;
}
/*!
*
* IPython text editor webapp
*
*/
.selected-keymap i.fa {
  padding: 0px 5px;
}
.selected-keymap i.fa:before {
  content: "\f00c";
}
#mode-menu {
  overflow: auto;
  max-height: 20em;
}
.edit_app #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.edit_app #menubar .navbar {
  /* Use a negative 1 bottom margin, so the border overlaps the border of the
    header */
  margin-bottom: -1px;
}
.dirty-indicator {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator.fa-pull-left {
  margin-right: .3em;
}
.dirty-indicator.fa-pull-right {
  margin-left: .3em;
}
.dirty-indicator.pull-left {
  margin-right: .3em;
}
.dirty-indicator.pull-right {
  margin-left: .3em;
}
.dirty-indicator-dirty {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-dirty.fa-pull-left {
  margin-right: .3em;
}
.dirty-indicator-dirty.fa-pull-right {
  margin-left: .3em;
}
.dirty-indicator-dirty.pull-left {
  margin-right: .3em;
}
.dirty-indicator-dirty.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-clean.fa-pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean.fa-pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f00c";
}
.dirty-indicator-clean:before.fa-pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean:before.fa-pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean:before.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean:before.pull-right {
  margin-left: .3em;
}
#filename {
  font-size: 16pt;
  display: table;
  padding: 0px 5px;
}
#current-mode {
  padding-left: 5px;
  padding-right: 5px;
}
#texteditor-backdrop {
  padding-top: 20px;
  padding-bottom: 20px;
}
@media not print {
  #texteditor-backdrop {
    background-color: #EEE;
  }
}
@media print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container {
    padding: 0px;
    background-color: #fff;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
.CodeMirror-dialog {
  background-color: #fff;
}
/*!
*
* IPython notebook
*
*/
/* CSS font colors for translated ANSI escape sequences */
/* The color values are a mix of
   http://www.xcolors.net/dl/baskerville-ivorylight and
   http://www.xcolors.net/dl/euphrasia */
.ansi-black-fg {
  color: #3E424D;
}
.ansi-black-bg {
  background-color: #3E424D;
}
.ansi-black-intense-fg {
  color: #282C36;
}
.ansi-black-intense-bg {
  background-color: #282C36;
}
.ansi-red-fg {
  color: #E75C58;
}
.ansi-red-bg {
  background-color: #E75C58;
}
.ansi-red-intense-fg {
  color: #B22B31;
}
.ansi-red-intense-bg {
  background-color: #B22B31;
}
.ansi-green-fg {
  color: #00A250;
}
.ansi-green-bg {
  background-color: #00A250;
}
.ansi-green-intense-fg {
  color: #007427;
}
.ansi-green-intense-bg {
  background-color: #007427;
}
.ansi-yellow-fg {
  color: #DDB62B;
}
.ansi-yellow-bg {
  background-color: #DDB62B;
}
.ansi-yellow-intense-fg {
  color: #B27D12;
}
.ansi-yellow-intense-bg {
  background-color: #B27D12;
}
.ansi-blue-fg {
  color: #208FFB;
}
.ansi-blue-bg {
  background-color: #208FFB;
}
.ansi-blue-intense-fg {
  color: #0065CA;
}
.ansi-blue-intense-bg {
  background-color: #0065CA;
}
.ansi-magenta-fg {
  color: #D160C4;
}
.ansi-magenta-bg {
  background-color: #D160C4;
}
.ansi-magenta-intense-fg {
  color: #A03196;
}
.ansi-magenta-intense-bg {
  background-color: #A03196;
}
.ansi-cyan-fg {
  color: #60C6C8;
}
.ansi-cyan-bg {
  background-color: #60C6C8;
}
.ansi-cyan-intense-fg {
  color: #258F8F;
}
.ansi-cyan-intense-bg {
  background-color: #258F8F;
}
.ansi-white-fg {
  color: #C5C1B4;
}
.ansi-white-bg {
  background-color: #C5C1B4;
}
.ansi-white-intense-fg {
  color: #A1A6B2;
}
.ansi-white-intense-bg {
  background-color: #A1A6B2;
}
.ansi-default-inverse-fg {
  color: #FFFFFF;
}
.ansi-default-inverse-bg {
  background-color: #000000;
}
.ansi-bold {
  font-weight: bold;
}
.ansi-underline {
  text-decoration: underline;
}
/* The following styles are deprecated an will be removed in a future version */
.ansibold {
  font-weight: bold;
}
.ansi-inverse {
  outline: 0.5px dotted;
}
/* use dark versions for foreground, to improve visibility */
.ansiblack {
  color: black;
}
.ansired {
  color: darkred;
}
.ansigreen {
  color: darkgreen;
}
.ansiyellow {
  color: #c4a000;
}
.ansiblue {
  color: darkblue;
}
.ansipurple {
  color: darkviolet;
}
.ansicyan {
  color: steelblue;
}
.ansigray {
  color: gray;
}
/* and light for background, for the same reason */
.ansibgblack {
  background-color: black;
}
.ansibgred {
  background-color: red;
}
.ansibggreen {
  background-color: green;
}
.ansibgyellow {
  background-color: yellow;
}
.ansibgblue {
  background-color: blue;
}
.ansibgpurple {
  background-color: magenta;
}
.ansibgcyan {
  background-color: cyan;
}
.ansibggray {
  background-color: gray;
}
div.cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  border-radius: 2px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  border-width: 1px;
  border-style: solid;
  border-color: transparent;
  width: 100%;
  padding: 5px;
  /* This acts as a spacer between cells, that is outside the border */
  margin: 0px;
  outline: none;
  position: relative;
  overflow: visible;
}
div.cell:before {
  position: absolute;
  display: block;
  top: -1px;
  left: -1px;
  width: 5px;
  height: calc(100% +  2px);
  content: '';
  background: transparent;
}
div.cell.jupyter-soft-selected {
  border-left-color: #E3F2FD;
  border-left-width: 1px;
  padding-left: 5px;
  border-right-color: #E3F2FD;
  border-right-width: 1px;
  background: #E3F2FD;
}
@media print {
  div.cell.jupyter-soft-selected {
    border-color: transparent;
  }
}
div.cell.selected,
div.cell.selected.jupyter-soft-selected {
  border-color: #ababab;
}
div.cell.selected:before,
div.cell.selected.jupyter-soft-selected:before {
  position: absolute;
  display: block;
  top: -1px;
  left: -1px;
  width: 5px;
  height: calc(100% +  2px);
  content: '';
  background: #42A5F5;
}
@media print {
  div.cell.selected,
  div.cell.selected.jupyter-soft-selected {
    border-color: transparent;
  }
}
.edit_mode div.cell.selected {
  border-color: #66BB6A;
}
.edit_mode div.cell.selected:before {
  position: absolute;
  display: block;
  top: -1px;
  left: -1px;
  width: 5px;
  height: calc(100% +  2px);
  content: '';
  background: #66BB6A;
}
@media print {
  .edit_mode div.cell.selected {
    border-color: transparent;
  }
}
.prompt {
  /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */
  min-width: 14ex;
  /* This padding is tuned to match the padding on the CodeMirror editor. */
  padding: 0.4em;
  margin: 0px;
  font-family: monospace;
  text-align: right;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
  /* Don't highlight prompt number selection */
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
  /* Use default cursor */
  cursor: default;
}
@media (max-width: 540px) {
  .prompt {
    text-align: left;
  }
}
div.inner_cell {
  min-width: 0;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_area {
  border: 1px solid #cfcfcf;
  border-radius: 2px;
  background: #f7f7f7;
  line-height: 1.21429em;
}
/* This is needed so that empty prompt areas can collapse to zero height when there
   is no content in the output_subarea and the prompt. The main purpose of this is
   to make sure that empty JavaScript output_subareas have no height. */
div.prompt:empty {
  padding-top: 0;
  padding-bottom: 0;
}
div.unrecognized_cell {
  padding: 5px 5px 5px 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.unrecognized_cell .inner_cell {
  border-radius: 2px;
  padding: 5px;
  font-weight: bold;
  color: red;
  border: 1px solid #cfcfcf;
  background: #eaeaea;
}
div.unrecognized_cell .inner_cell a {
  color: inherit;
  text-decoration: none;
}
div.unrecognized_cell .inner_cell a:hover {
  color: inherit;
  text-decoration: none;
}
@media (max-width: 540px) {
  div.unrecognized_cell > div.prompt {
    display: none;
  }
}
div.code_cell {
  /* avoid page breaking on code cells when printing */
}
@media print {
  div.code_cell {
    page-break-inside: avoid;
  }
}
/* any special styling for code cells that are currently running goes here */
div.input {
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.input {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_prompt {
  color: #303F9F;
  border-top: 1px solid transparent;
}
div.input_area > div.highlight {
  margin: 0.4em;
  border: none;
  padding: 0px;
  background-color: transparent;
}
div.input_area > div.highlight > pre {
  margin: 0px;
  border: none;
  padding: 0px;
  background-color: transparent;
}
/* The following gets added to the <head> if it is detected that the user has a
 * monospace font with inconsistent normal/bold/italic height.  See
 * notebookmain.js.  Such fonts will have keywords vertically offset with
 * respect to the rest of the text.  The user should select a better font.
 * See: https://github.com/ipython/ipython/issues/1503
 *
 * .CodeMirror span {
 *      vertical-align: bottom;
 * }
 */
.CodeMirror {
  line-height: 1.21429em;
  /* Changed from 1em to our global default */
  font-size: 14px;
  height: auto;
  /* Changed to auto to autogrow */
  background: none;
  /* Changed from white to allow our bg to show through */
}
.CodeMirror-scroll {
  /*  The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/
  /*  We have found that if it is visible, vertical scrollbars appear with font size changes.*/
  overflow-y: hidden;
  overflow-x: auto;
}
.CodeMirror-lines {
  /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */
  /* we have set a different line-height and want this to scale with that. */
  /* Note that this should set vertical padding only, since CodeMirror assumes
       that horizontal padding will be set on CodeMirror pre */
  padding: 0.4em 0;
}
.CodeMirror-linenumber {
  padding: 0 8px 0 4px;
}
.CodeMirror-gutters {
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.CodeMirror pre {
  /* In CM3 this went to 4px from 0 in CM2. This sets horizontal padding only,
    use .CodeMirror-lines for vertical */
  padding: 0 0.4em;
  border: 0;
  border-radius: 0;
}
.CodeMirror-cursor {
  border-left: 1.4px solid black;
}
@media screen and (min-width: 2138px) and (max-width: 4319px) {
  .CodeMirror-cursor {
    border-left: 2px solid black;
  }
}
@media screen and (min-width: 4320px) {
  .CodeMirror-cursor {
    border-left: 4px solid black;
  }
}
/*

Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org>
Adapted from GitHub theme

*/
.highlight-base {
  color: #000;
}
.highlight-variable {
  color: #000;
}
.highlight-variable-2 {
  color: #1a1a1a;
}
.highlight-variable-3 {
  color: #333333;
}
.highlight-string {
  color: #BA2121;
}
.highlight-comment {
  color: #408080;
  font-style: italic;
}
.highlight-number {
  color: #080;
}
.highlight-atom {
  color: #88F;
}
.highlight-keyword {
  color: #008000;
  font-weight: bold;
}
.highlight-builtin {
  color: #008000;
}
.highlight-error {
  color: #f00;
}
.highlight-operator {
  color: #AA22FF;
  font-weight: bold;
}
.highlight-meta {
  color: #AA22FF;
}
/* previously not defined, copying from default codemirror */
.highlight-def {
  color: #00f;
}
.highlight-string-2 {
  color: #f50;
}
.highlight-qualifier {
  color: #555;
}
.highlight-bracket {
  color: #997;
}
.highlight-tag {
  color: #170;
}
.highlight-attribute {
  color: #00c;
}
.highlight-header {
  color: blue;
}
.highlight-quote {
  color: #090;
}
.highlight-link {
  color: #00c;
}
/* apply the same style to codemirror */
.cm-s-ipython span.cm-keyword {
  color: #008000;
  font-weight: bold;
}
.cm-s-ipython span.cm-atom {
  color: #88F;
}
.cm-s-ipython span.cm-number {
  color: #080;
}
.cm-s-ipython span.cm-def {
  color: #00f;
}
.cm-s-ipython span.cm-variable {
  color: #000;
}
.cm-s-ipython span.cm-operator {
  color: #AA22FF;
  font-weight: bold;
}
.cm-s-ipython span.cm-variable-2 {
  color: #1a1a1a;
}
.cm-s-ipython span.cm-variable-3 {
  color: #333333;
}
.cm-s-ipython span.cm-comment {
  color: #408080;
  font-style: italic;
}
.cm-s-ipython span.cm-string {
  color: #BA2121;
}
.cm-s-ipython span.cm-string-2 {
  color: #f50;
}
.cm-s-ipython span.cm-meta {
  color: #AA22FF;
}
.cm-s-ipython span.cm-qualifier {
  color: #555;
}
.cm-s-ipython span.cm-builtin {
  color: #008000;
}
.cm-s-ipython span.cm-bracket {
  color: #997;
}
.cm-s-ipython span.cm-tag {
  color: #170;
}
.cm-s-ipython span.cm-attribute {
  color: #00c;
}
.cm-s-ipython span.cm-header {
  color: blue;
}
.cm-s-ipython span.cm-quote {
  color: #090;
}
.cm-s-ipython span.cm-link {
  color: #00c;
}
.cm-s-ipython span.cm-error {
  color: #f00;
}
.cm-s-ipython span.cm-tab {
  background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=);
  background-position: right;
  background-repeat: no-repeat;
}
div.output_wrapper {
  /* this position must be relative to enable descendents to be absolute within it */
  position: relative;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  z-index: 1;
}
/* class for the output area when it should be height-limited */
div.output_scroll {
  /* ideally, this would be max-height, but FF barfs all over that */
  height: 24em;
  /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */
  width: 100%;
  overflow: auto;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  display: block;
}
/* output div while it is collapsed */
div.output_collapsed {
  margin: 0px;
  padding: 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
div.out_prompt_overlay {
  height: 100%;
  padding: 0px 0.4em;
  position: absolute;
  border-radius: 2px;
}
div.out_prompt_overlay:hover {
  /* use inner shadow to get border that is computed the same on WebKit/FF */
  -webkit-box-shadow: inset 0 0 1px #000;
  box-shadow: inset 0 0 1px #000;
  background: rgba(240, 240, 240, 0.5);
}
div.output_prompt {
  color: #D84315;
}
/* This class is the outer container of all output sections. */
div.output_area {
  padding: 0px;
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.output_area .MathJax_Display {
  text-align: left !important;
}
div.output_area .rendered_html table {
  margin-left: 0;
  margin-right: 0;
}
div.output_area .rendered_html img {
  margin-left: 0;
  margin-right: 0;
}
div.output_area img,
div.output_area svg {
  max-width: 100%;
  height: auto;
}
div.output_area img.unconfined,
div.output_area svg.unconfined {
  max-width: none;
}
div.output_area .mglyph > img {
  max-width: none;
}
/* This is needed to protect the pre formating from global settings such
   as that of bootstrap */
.output {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.output_area {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
div.output_area pre {
  margin: 0;
  padding: 1px 0 1px 0;
  border: 0;
  vertical-align: baseline;
  color: black;
  background-color: transparent;
  border-radius: 0;
}
/* This class is for the output subarea inside the output_area and after
   the prompt div. */
div.output_subarea {
  overflow-x: auto;
  padding: 0.4em;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
  max-width: calc(100% - 14ex);
}
div.output_scroll div.output_subarea {
  overflow-x: visible;
}
/* The rest of the output_* classes are for special styling of the different
   output types */
/* all text output has this class: */
div.output_text {
  text-align: left;
  color: #000;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
}
/* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */
div.output_stderr {
  background: #fdd;
  /* very light red background for stderr */
}
div.output_latex {
  text-align: left;
}
/* Empty output_javascript divs should have no height */
div.output_javascript:empty {
  padding: 0;
}
.js-error {
  color: darkred;
}
/* raw_input styles */
div.raw_input_container {
  line-height: 1.21429em;
  padding-top: 5px;
}
pre.raw_input_prompt {
  /* nothing needed here. */
}
input.raw_input {
  font-family: monospace;
  font-size: inherit;
  color: inherit;
  width: auto;
  /* make sure input baseline aligns with prompt */
  vertical-align: baseline;
  /* padding + margin = 0.5em between prompt and cursor */
  padding: 0em 0.25em;
  margin: 0em 0.25em;
}
input.raw_input:focus {
  box-shadow: none;
}
p.p-space {
  margin-bottom: 10px;
}
div.output_unrecognized {
  padding: 5px;
  font-weight: bold;
  color: red;
}
div.output_unrecognized a {
  color: inherit;
  text-decoration: none;
}
div.output_unrecognized a:hover {
  color: inherit;
  text-decoration: none;
}
.rendered_html {
  color: #000;
  /* any extras will just be numbers: */
}
.rendered_html em {
  font-style: italic;
}
.rendered_html strong {
  font-weight: bold;
}
.rendered_html u {
  text-decoration: underline;
}
.rendered_html :link {
  text-decoration: underline;
}
.rendered_html :visited {
  text-decoration: underline;
}
.rendered_html h1 {
  font-size: 185.7%;
  margin: 1.08em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h2 {
  font-size: 157.1%;
  margin: 1.27em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h3 {
  font-size: 128.6%;
  margin: 1.55em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h4 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h5 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h6 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h1:first-child {
  margin-top: 0.538em;
}
.rendered_html h2:first-child {
  margin-top: 0.636em;
}
.rendered_html h3:first-child {
  margin-top: 0.777em;
}
.rendered_html h4:first-child {
  margin-top: 1em;
}
.rendered_html h5:first-child {
  margin-top: 1em;
}
.rendered_html h6:first-child {
  margin-top: 1em;
}
.rendered_html ul:not(.list-inline),
.rendered_html ol:not(.list-inline) {
  padding-left: 2em;
}
.rendered_html ul {
  list-style: disc;
}
.rendered_html ul ul {
  list-style: square;
  margin-top: 0;
}
.rendered_html ul ul ul {
  list-style: circle;
}
.rendered_html ol {
  list-style: decimal;
}
.rendered_html ol ol {
  list-style: upper-alpha;
  margin-top: 0;
}
.rendered_html ol ol ol {
  list-style: lower-alpha;
}
.rendered_html ol ol ol ol {
  list-style: lower-roman;
}
.rendered_html ol ol ol ol ol {
  list-style: decimal;
}
.rendered_html * + ul {
  margin-top: 1em;
}
.rendered_html * + ol {
  margin-top: 1em;
}
.rendered_html hr {
  color: black;
  background-color: black;
}
.rendered_html pre {
  margin: 1em 2em;
  padding: 0px;
  background-color: #fff;
}
.rendered_html code {
  background-color: #eff0f1;
}
.rendered_html p code {
  padding: 1px 5px;
}
.rendered_html pre code {
  background-color: #fff;
}
.rendered_html pre,
.rendered_html code {
  border: 0;
  color: #000;
  font-size: 100%;
}
.rendered_html blockquote {
  margin: 1em 2em;
}
.rendered_html table {
  margin-left: auto;
  margin-right: auto;
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
.rendered_html tr,
.rendered_html th,
.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
.rendered_html th {
  font-weight: bold;
}
.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}
.rendered_html * + table {
  margin-top: 1em;
}
.rendered_html p {
  text-align: left;
}
.rendered_html * + p {
  margin-top: 1em;
}
.rendered_html img {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.rendered_html * + img {
  margin-top: 1em;
}
.rendered_html img,
.rendered_html svg {
  max-width: 100%;
  height: auto;
}
.rendered_html img.unconfined,
.rendered_html svg.unconfined {
  max-width: none;
}
.rendered_html .alert {
  margin-bottom: initial;
}
.rendered_html * + .alert {
  margin-top: 1em;
}
[dir="rtl"] .rendered_html p {
  text-align: right;
}
div.text_cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.text_cell > div.prompt {
    display: none;
  }
}
div.text_cell_render {
  /*font-family: "Helvetica Neue", Arial, Helvetica, Geneva, sans-serif;*/
  outline: none;
  resize: none;
  width: inherit;
  border-style: none;
  padding: 0.5em 0.5em 0.5em 0.4em;
  color: #000;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
a.anchor-link:link {
  text-decoration: none;
  padding: 0px 20px;
  visibility: hidden;
}
h1:hover .anchor-link,
h2:hover .anchor-link,
h3:hover .anchor-link,
h4:hover .anchor-link,
h5:hover .anchor-link,
h6:hover .anchor-link {
  visibility: visible;
}
.text_cell.rendered .input_area {
  display: none;
}
.text_cell.rendered .rendered_html {
  overflow-x: auto;
  overflow-y: hidden;
}
.text_cell.rendered .rendered_html tr,
.text_cell.rendered .rendered_html th,
.text_cell.rendered .rendered_html td {
  max-width: none;
}
.text_cell.unrendered .text_cell_render {
  display: none;
}
.text_cell .dropzone .input_area {
  border: 2px dashed #bababa;
  margin: -1px;
}
.cm-header-1,
.cm-header-2,
.cm-header-3,
.cm-header-4,
.cm-header-5,
.cm-header-6 {
  font-weight: bold;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
}
.cm-header-1 {
  font-size: 185.7%;
}
.cm-header-2 {
  font-size: 157.1%;
}
.cm-header-3 {
  font-size: 128.6%;
}
.cm-header-4 {
  font-size: 110%;
}
.cm-header-5 {
  font-size: 100%;
  font-style: italic;
}
.cm-header-6 {
  font-size: 100%;
  font-style: italic;
}
/*!
*
* IPython notebook webapp
*
*/
@media (max-width: 767px) {
  .notebook_app {
    padding-left: 0px;
    padding-right: 0px;
  }
}
#ipython-main-app {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook_panel {
  margin: 0px;
  padding: 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook {
  font-size: 14px;
  line-height: 20px;
  overflow-y: hidden;
  overflow-x: auto;
  width: 100%;
  /* This spaces the page away from the edge of the notebook area */
  padding-top: 20px;
  margin: 0px;
  outline: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  min-height: 100%;
}
@media not print {
  #notebook-container {
    padding: 15px;
    background-color: #fff;
    min-height: 0;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
@media print {
  #notebook-container {
    width: 100%;
  }
}
div.ui-widget-content {
  border: 1px solid #ababab;
  outline: none;
}
pre.dialog {
  background-color: #f7f7f7;
  border: 1px solid #ddd;
  border-radius: 2px;
  padding: 0.4em;
  padding-left: 2em;
}
p.dialog {
  padding: 0.2em;
}
/* Word-wrap output correctly.  This is the CSS3 spelling, though Firefox seems
   to not honor it correctly.  Webkit browsers (Chrome, rekonq, Safari) do.
 */
pre,
code,
kbd,
samp {
  white-space: pre-wrap;
}
#fonttest {
  font-family: monospace;
}
p {
  margin-bottom: 0;
}
.end_space {
  min-height: 100px;
  transition: height .2s ease;
}
.notebook_app > #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
@media not print {
  .notebook_app {
    background-color: #EEE;
  }
}
kbd {
  border-style: solid;
  border-width: 1px;
  box-shadow: none;
  margin: 2px;
  padding-left: 2px;
  padding-right: 2px;
  padding-top: 1px;
  padding-bottom: 1px;
}
.jupyter-keybindings {
  padding: 1px;
  line-height: 24px;
  border-bottom: 1px solid gray;
}
.jupyter-keybindings input {
  margin: 0;
  padding: 0;
  border: none;
}
.jupyter-keybindings i {
  padding: 6px;
}
.well code {
  background-color: #ffffff;
  border-color: #ababab;
  border-width: 1px;
  border-style: solid;
  padding: 2px;
  padding-top: 1px;
  padding-bottom: 1px;
}
/* CSS for the cell toolbar */
.celltoolbar {
  border: thin solid #CFCFCF;
  border-bottom: none;
  background: #EEE;
  border-radius: 2px 2px 0px 0px;
  width: 100%;
  height: 29px;
  padding-right: 4px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
  display: -webkit-flex;
}
@media print {
  .celltoolbar {
    display: none;
  }
}
.ctb_hideshow {
  display: none;
  vertical-align: bottom;
}
/* ctb_show is added to the ctb_hideshow div to show the cell toolbar.
   Cell toolbars are only shown when the ctb_global_show class is also set.
*/
.ctb_global_show .ctb_show.ctb_hideshow {
  display: block;
}
.ctb_global_show .ctb_show + .input_area,
.ctb_global_show .ctb_show + div.text_cell_input,
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border-top-right-radius: 0px;
  border-top-left-radius: 0px;
}
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border: 1px solid #cfcfcf;
}
.celltoolbar {
  font-size: 87%;
  padding-top: 3px;
}
.celltoolbar select {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
  width: inherit;
  font-size: inherit;
  height: 22px;
  padding: 0px;
  display: inline-block;
}
.celltoolbar select:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.celltoolbar select::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.celltoolbar select:-ms-input-placeholder {
  color: #999;
}
.celltoolbar select::-webkit-input-placeholder {
  color: #999;
}
.celltoolbar select::-ms-expand {
  border: 0;
  background-color: transparent;
}
.celltoolbar select[disabled],
.celltoolbar select[readonly],
fieldset[disabled] .celltoolbar select {
  background-color: #eeeeee;
  opacity: 1;
}
.celltoolbar select[disabled],
fieldset[disabled] .celltoolbar select {
  cursor: not-allowed;
}
textarea.celltoolbar select {
  height: auto;
}
select.celltoolbar select {
  height: 30px;
  line-height: 30px;
}
textarea.celltoolbar select,
select[multiple].celltoolbar select {
  height: auto;
}
.celltoolbar label {
  margin-left: 5px;
  margin-right: 5px;
}
.tags_button_container {
  width: 100%;
  display: flex;
}
.tag-container {
  display: flex;
  flex-direction: row;
  flex-grow: 1;
  overflow: hidden;
  position: relative;
}
.tag-container > * {
  margin: 0 4px;
}
.remove-tag-btn {
  margin-left: 4px;
}
.tags-input {
  display: flex;
}
.cell-tag:last-child:after {
  content: "";
  position: absolute;
  right: 0;
  width: 40px;
  height: 100%;
  /* Fade to background color of cell toolbar */
  background: linear-gradient(to right, rgba(0, 0, 0, 0), #EEE);
}
.tags-input > * {
  margin-left: 4px;
}
.cell-tag,
.tags-input input,
.tags-input button {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
  box-shadow: none;
  width: inherit;
  font-size: inherit;
  height: 22px;
  line-height: 22px;
  padding: 0px 4px;
  display: inline-block;
}
.cell-tag:focus,
.tags-input input:focus,
.tags-input button:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.cell-tag::-moz-placeholder,
.tags-input input::-moz-placeholder,
.tags-input button::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.cell-tag:-ms-input-placeholder,
.tags-input input:-ms-input-placeholder,
.tags-input button:-ms-input-placeholder {
  color: #999;
}
.cell-tag::-webkit-input-placeholder,
.tags-input input::-webkit-input-placeholder,
.tags-input button::-webkit-input-placeholder {
  color: #999;
}
.cell-tag::-ms-expand,
.tags-input input::-ms-expand,
.tags-input button::-ms-expand {
  border: 0;
  background-color: transparent;
}
.cell-tag[disabled],
.tags-input input[disabled],
.tags-input button[disabled],
.cell-tag[readonly],
.tags-input input[readonly],
.tags-input button[readonly],
fieldset[disabled] .cell-tag,
fieldset[disabled] .tags-input input,
fieldset[disabled] .tags-input button {
  background-color: #eeeeee;
  opacity: 1;
}
.cell-tag[disabled],
.tags-input input[disabled],
.tags-input button[disabled],
fieldset[disabled] .cell-tag,
fieldset[disabled] .tags-input input,
fieldset[disabled] .tags-input button {
  cursor: not-allowed;
}
textarea.cell-tag,
textarea.tags-input input,
textarea.tags-input button {
  height: auto;
}
select.cell-tag,
select.tags-input input,
select.tags-input button {
  height: 30px;
  line-height: 30px;
}
textarea.cell-tag,
textarea.tags-input input,
textarea.tags-input button,
select[multiple].cell-tag,
select[multiple].tags-input input,
select[multiple].tags-input button {
  height: auto;
}
.cell-tag,
.tags-input button {
  padding: 0px 4px;
}
.cell-tag {
  background-color: #fff;
  white-space: nowrap;
}
.tags-input input[type=text]:focus {
  outline: none;
  box-shadow: none;
  border-color: #ccc;
}
.completions {
  position: absolute;
  z-index: 110;
  overflow: hidden;
  border: 1px solid #ababab;
  border-radius: 2px;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  line-height: 1;
}
.completions select {
  background: white;
  outline: none;
  border: none;
  padding: 0px;
  margin: 0px;
  overflow: auto;
  font-family: monospace;
  font-size: 110%;
  color: #000;
  width: auto;
}
.completions select option.context {
  color: #286090;
}
#kernel_logo_widget .current_kernel_logo {
  display: none;
  margin-top: -1px;
  margin-bottom: -1px;
  width: 32px;
  height: 32px;
}
[dir="rtl"] #kernel_logo_widget {
  float: left !important;
  float: left;
}
.modal .modal-body .move-path {
  display: flex;
  flex-direction: row;
  justify-content: space;
  align-items: center;
}
.modal .modal-body .move-path .server-root {
  padding-right: 20px;
}
.modal .modal-body .move-path .path-input {
  flex: 1;
}
#menubar {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  margin-top: 1px;
}
#menubar .navbar {
  border-top: 1px;
  border-radius: 0px 0px 2px 2px;
  margin-bottom: 0px;
}
#menubar .navbar-toggle {
  float: left;
  padding-top: 7px;
  padding-bottom: 7px;
  border: none;
}
#menubar .navbar-collapse {
  clear: left;
}
[dir="rtl"] #menubar .navbar-toggle {
  float: right;
}
[dir="rtl"] #menubar .navbar-collapse {
  clear: right;
}
[dir="rtl"] #menubar .navbar-nav {
  float: right;
}
[dir="rtl"] #menubar .nav {
  padding-right: 0px;
}
[dir="rtl"] #menubar .navbar-nav > li {
  float: right;
}
[dir="rtl"] #menubar .navbar-right {
  float: left !important;
}
[dir="rtl"] ul.dropdown-menu {
  text-align: right;
  left: auto;
}
[dir="rtl"] ul#new-menu.dropdown-menu {
  right: auto;
  left: 0;
}
.nav-wrapper {
  border-bottom: 1px solid #e7e7e7;
}
i.menu-icon {
  padding-top: 4px;
}
[dir="rtl"] i.menu-icon.pull-right {
  float: left !important;
  float: left;
}
ul#help_menu li a {
  overflow: hidden;
  padding-right: 2.2em;
}
ul#help_menu li a i {
  margin-right: -1.2em;
}
[dir="rtl"] ul#help_menu li a {
  padding-left: 2.2em;
}
[dir="rtl"] ul#help_menu li a i {
  margin-right: 0;
  margin-left: -1.2em;
}
[dir="rtl"] ul#help_menu li a i.pull-right {
  float: left !important;
  float: left;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu > .dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
}
[dir="rtl"] .dropdown-submenu > .dropdown-menu {
  right: 100%;
  margin-right: -1px;
}
.dropdown-submenu:hover > .dropdown-menu {
  display: block;
}
.dropdown-submenu > a:after {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  display: block;
  content: "\f0da";
  float: right;
  color: #333333;
  margin-top: 2px;
  margin-right: -10px;
}
.dropdown-submenu > a:after.fa-pull-left {
  margin-right: .3em;
}
.dropdown-submenu > a:after.fa-pull-right {
  margin-left: .3em;
}
.dropdown-submenu > a:after.pull-left {
  margin-right: .3em;
}
.dropdown-submenu > a:after.pull-right {
  margin-left: .3em;
}
[dir="rtl"] .dropdown-submenu > a:after {
  float: left;
  content: "\f0d9";
  margin-right: 0;
  margin-left: -10px;
}
.dropdown-submenu:hover > a:after {
  color: #262626;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left > .dropdown-menu {
  left: -100%;
  margin-left: 10px;
}
#notification_area {
  float: right !important;
  float: right;
  z-index: 10;
}
[dir="rtl"] #notification_area {
  float: left !important;
  float: left;
}
.indicator_area {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
[dir="rtl"] .indicator_area {
  float: left !important;
  float: left;
}
#kernel_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  border-left: 1px solid;
}
#kernel_indicator .kernel_indicator_name {
  padding-left: 5px;
  padding-right: 5px;
}
[dir="rtl"] #kernel_indicator {
  float: left !important;
  float: left;
  border-left: 0;
  border-right: 1px solid;
}
#modal_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
[dir="rtl"] #modal_indicator {
  float: left !important;
  float: left;
}
#readonly-indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  margin-top: 2px;
  margin-bottom: 0px;
  margin-left: 0px;
  margin-right: 0px;
  display: none;
}
.modal_indicator:before {
  width: 1.28571429em;
  text-align: center;
}
.edit_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f040";
}
.edit_mode .modal_indicator:before.fa-pull-left {
  margin-right: .3em;
}
.edit_mode .modal_indicator:before.fa-pull-right {
  margin-left: .3em;
}
.edit_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.edit_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.command_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: ' ';
}
.command_mode .modal_indicator:before.fa-pull-left {
  margin-right: .3em;
}
.command_mode .modal_indicator:before.fa-pull-right {
  margin-left: .3em;
}
.command_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.command_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.kernel_idle_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f10c";
}
.kernel_idle_icon:before.fa-pull-left {
  margin-right: .3em;
}
.kernel_idle_icon:before.fa-pull-right {
  margin-left: .3em;
}
.kernel_idle_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_idle_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_busy_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f111";
}
.kernel_busy_icon:before.fa-pull-left {
  margin-right: .3em;
}
.kernel_busy_icon:before.fa-pull-right {
  margin-left: .3em;
}
.kernel_busy_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_busy_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_dead_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f1e2";
}
.kernel_dead_icon:before.fa-pull-left {
  margin-right: .3em;
}
.kernel_dead_icon:before.fa-pull-right {
  margin-left: .3em;
}
.kernel_dead_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_dead_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_disconnected_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f127";
}
.kernel_disconnected_icon:before.fa-pull-left {
  margin-right: .3em;
}
.kernel_disconnected_icon:before.fa-pull-right {
  margin-left: .3em;
}
.kernel_disconnected_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_disconnected_icon:before.pull-right {
  margin-left: .3em;
}
.notification_widget {
  color: #777;
  z-index: 10;
  background: rgba(240, 240, 240, 0.5);
  margin-right: 4px;
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget:focus,
.notification_widget.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.notification_widget:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active:hover,
.notification_widget.active:hover,
.open > .dropdown-toggle.notification_widget:hover,
.notification_widget:active:focus,
.notification_widget.active:focus,
.open > .dropdown-toggle.notification_widget:focus,
.notification_widget:active.focus,
.notification_widget.active.focus,
.open > .dropdown-toggle.notification_widget.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  background-image: none;
}
.notification_widget.disabled:hover,
.notification_widget[disabled]:hover,
fieldset[disabled] .notification_widget:hover,
.notification_widget.disabled:focus,
.notification_widget[disabled]:focus,
fieldset[disabled] .notification_widget:focus,
.notification_widget.disabled.focus,
.notification_widget[disabled].focus,
fieldset[disabled] .notification_widget.focus {
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget .badge {
  color: #fff;
  background-color: #333;
}
.notification_widget.warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning:focus,
.notification_widget.warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.notification_widget.warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active:hover,
.notification_widget.warning.active:hover,
.open > .dropdown-toggle.notification_widget.warning:hover,
.notification_widget.warning:active:focus,
.notification_widget.warning.active:focus,
.open > .dropdown-toggle.notification_widget.warning:focus,
.notification_widget.warning:active.focus,
.notification_widget.warning.active.focus,
.open > .dropdown-toggle.notification_widget.warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  background-image: none;
}
.notification_widget.warning.disabled:hover,
.notification_widget.warning[disabled]:hover,
fieldset[disabled] .notification_widget.warning:hover,
.notification_widget.warning.disabled:focus,
.notification_widget.warning[disabled]:focus,
fieldset[disabled] .notification_widget.warning:focus,
.notification_widget.warning.disabled.focus,
.notification_widget.warning[disabled].focus,
fieldset[disabled] .notification_widget.warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.notification_widget.success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success:focus,
.notification_widget.success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.notification_widget.success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active:hover,
.notification_widget.success.active:hover,
.open > .dropdown-toggle.notification_widget.success:hover,
.notification_widget.success:active:focus,
.notification_widget.success.active:focus,
.open > .dropdown-toggle.notification_widget.success:focus,
.notification_widget.success:active.focus,
.notification_widget.success.active.focus,
.open > .dropdown-toggle.notification_widget.success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  background-image: none;
}
.notification_widget.success.disabled:hover,
.notification_widget.success[disabled]:hover,
fieldset[disabled] .notification_widget.success:hover,
.notification_widget.success.disabled:focus,
.notification_widget.success[disabled]:focus,
fieldset[disabled] .notification_widget.success:focus,
.notification_widget.success.disabled.focus,
.notification_widget.success[disabled].focus,
fieldset[disabled] .notification_widget.success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.notification_widget.info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info:focus,
.notification_widget.info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.notification_widget.info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active:hover,
.notification_widget.info.active:hover,
.open > .dropdown-toggle.notification_widget.info:hover,
.notification_widget.info:active:focus,
.notification_widget.info.active:focus,
.open > .dropdown-toggle.notification_widget.info:focus,
.notification_widget.info:active.focus,
.notification_widget.info.active.focus,
.open > .dropdown-toggle.notification_widget.info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  background-image: none;
}
.notification_widget.info.disabled:hover,
.notification_widget.info[disabled]:hover,
fieldset[disabled] .notification_widget.info:hover,
.notification_widget.info.disabled:focus,
.notification_widget.info[disabled]:focus,
fieldset[disabled] .notification_widget.info:focus,
.notification_widget.info.disabled.focus,
.notification_widget.info[disabled].focus,
fieldset[disabled] .notification_widget.info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.notification_widget.danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger:focus,
.notification_widget.danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.notification_widget.danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active:hover,
.notification_widget.danger.active:hover,
.open > .dropdown-toggle.notification_widget.danger:hover,
.notification_widget.danger:active:focus,
.notification_widget.danger.active:focus,
.open > .dropdown-toggle.notification_widget.danger:focus,
.notification_widget.danger:active.focus,
.notification_widget.danger.active.focus,
.open > .dropdown-toggle.notification_widget.danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  background-image: none;
}
.notification_widget.danger.disabled:hover,
.notification_widget.danger[disabled]:hover,
fieldset[disabled] .notification_widget.danger:hover,
.notification_widget.danger.disabled:focus,
.notification_widget.danger[disabled]:focus,
fieldset[disabled] .notification_widget.danger:focus,
.notification_widget.danger.disabled.focus,
.notification_widget.danger[disabled].focus,
fieldset[disabled] .notification_widget.danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger .badge {
  color: #d9534f;
  background-color: #fff;
}
div#pager {
  background-color: #fff;
  font-size: 14px;
  line-height: 20px;
  overflow: hidden;
  display: none;
  position: fixed;
  bottom: 0px;
  width: 100%;
  max-height: 50%;
  padding-top: 8px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  /* Display over codemirror */
  z-index: 100;
  /* Hack which prevents jquery ui resizable from changing top. */
  top: auto !important;
}
div#pager pre {
  line-height: 1.21429em;
  color: #000;
  background-color: #f7f7f7;
  padding: 0.4em;
}
div#pager #pager-button-area {
  position: absolute;
  top: 8px;
  right: 20px;
}
div#pager #pager-contents {
  position: relative;
  overflow: auto;
  width: 100%;
  height: 100%;
}
div#pager #pager-contents #pager-container {
  position: relative;
  padding: 15px 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
div#pager .ui-resizable-handle {
  top: 0px;
  height: 8px;
  background: #f7f7f7;
  border-top: 1px solid #cfcfcf;
  border-bottom: 1px solid #cfcfcf;
  /* This injects handle bars (a short, wide = symbol) for 
        the resize handle. */
}
div#pager .ui-resizable-handle::after {
  content: '';
  top: 2px;
  left: 50%;
  height: 3px;
  width: 30px;
  margin-left: -15px;
  position: absolute;
  border-top: 1px solid #cfcfcf;
}
.quickhelp {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  line-height: 1.8em;
}
.shortcut_key {
  display: inline-block;
  width: 21ex;
  text-align: right;
  font-family: monospace;
}
.shortcut_descr {
  display: inline-block;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
span.save_widget {
  height: 30px;
  margin-top: 4px;
  display: flex;
  justify-content: flex-start;
  align-items: baseline;
  width: 50%;
  flex: 1;
}
span.save_widget span.filename {
  height: 100%;
  line-height: 1em;
  margin-left: 16px;
  border: none;
  font-size: 146.5%;
  text-overflow: ellipsis;
  overflow: hidden;
  white-space: nowrap;
  border-radius: 2px;
}
span.save_widget span.filename:hover {
  background-color: #e6e6e6;
}
[dir="rtl"] span.save_widget.pull-left {
  float: right !important;
  float: right;
}
[dir="rtl"] span.save_widget span.filename {
  margin-left: 0;
  margin-right: 16px;
}
span.checkpoint_status,
span.autosave_status {
  font-size: small;
  white-space: nowrap;
  padding: 0 5px;
}
@media (max-width: 767px) {
  span.save_widget {
    font-size: small;
    padding: 0 0 0 5px;
  }
  span.checkpoint_status,
  span.autosave_status {
    display: none;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  span.checkpoint_status {
    display: none;
  }
  span.autosave_status {
    font-size: x-small;
  }
}
.toolbar {
  padding: 0px;
  margin-left: -5px;
  margin-top: 2px;
  margin-bottom: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.toolbar select,
.toolbar label {
  width: auto;
  vertical-align: middle;
  margin-right: 2px;
  margin-bottom: 0px;
  display: inline;
  font-size: 92%;
  margin-left: 0.3em;
  margin-right: 0.3em;
  padding: 0px;
  padding-top: 3px;
}
.toolbar .btn {
  padding: 2px 8px;
}
.toolbar .btn-group {
  margin-top: 0px;
  margin-left: 5px;
}
.toolbar-btn-label {
  margin-left: 6px;
}
#maintoolbar {
  margin-bottom: -3px;
  margin-top: -8px;
  border: 0px;
  min-height: 27px;
  margin-left: 0px;
  padding-top: 11px;
  padding-bottom: 3px;
}
#maintoolbar .navbar-text {
  float: none;
  vertical-align: middle;
  text-align: right;
  margin-left: 5px;
  margin-right: 0px;
  margin-top: 0px;
}
.select-xs {
  height: 24px;
}
[dir="rtl"] .btn-group > .btn,
.btn-group-vertical > .btn {
  float: right;
}
.pulse,
.dropdown-menu > li > a.pulse,
li.pulse > a.dropdown-toggle,
li.pulse.open > a.dropdown-toggle {
  background-color: #F37626;
  color: white;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
/** WARNING IF YOU ARE EDITTING THIS FILE, if this is a .css file, It has a lot
 * of chance of beeing generated from the ../less/[samename].less file, you can
 * try to get back the less file by reverting somme commit in history
 **/
/*
 * We'll try to get something pretty, so we
 * have some strange css to have the scroll bar on
 * the left with fix button on the top right of the tooltip
 */
@-moz-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-webkit-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-moz-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
@-webkit-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
/*properties of tooltip after "expand"*/
.bigtooltip {
  overflow: auto;
  height: 200px;
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
}
/*properties of tooltip before "expand"*/
.smalltooltip {
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
  text-overflow: ellipsis;
  overflow: hidden;
  height: 80px;
}
.tooltipbuttons {
  position: absolute;
  padding-right: 15px;
  top: 0px;
  right: 0px;
}
.tooltiptext {
  /*avoid the button to overlap on some docstring*/
  padding-right: 30px;
}
.ipython_tooltip {
  max-width: 700px;
  /*fade-in animation when inserted*/
  -webkit-animation: fadeOut 400ms;
  -moz-animation: fadeOut 400ms;
  animation: fadeOut 400ms;
  -webkit-animation: fadeIn 400ms;
  -moz-animation: fadeIn 400ms;
  animation: fadeIn 400ms;
  vertical-align: middle;
  background-color: #f7f7f7;
  overflow: visible;
  border: #ababab 1px solid;
  outline: none;
  padding: 3px;
  margin: 0px;
  padding-left: 7px;
  font-family: monospace;
  min-height: 50px;
  -moz-box-shadow: 0px 6px 10px -1px #adadad;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  border-radius: 2px;
  position: absolute;
  z-index: 1000;
}
.ipython_tooltip a {
  float: right;
}
.ipython_tooltip .tooltiptext pre {
  border: 0;
  border-radius: 0;
  font-size: 100%;
  background-color: #f7f7f7;
}
.pretooltiparrow {
  left: 0px;
  margin: 0px;
  top: -16px;
  width: 40px;
  height: 16px;
  overflow: hidden;
  position: absolute;
}
.pretooltiparrow:before {
  background-color: #f7f7f7;
  border: 1px #ababab solid;
  z-index: 11;
  content: "";
  position: absolute;
  left: 15px;
  top: 10px;
  width: 25px;
  height: 25px;
  -webkit-transform: rotate(45deg);
  -moz-transform: rotate(45deg);
  -ms-transform: rotate(45deg);
  -o-transform: rotate(45deg);
}
ul.typeahead-list i {
  margin-left: -10px;
  width: 18px;
}
[dir="rtl"] ul.typeahead-list i {
  margin-left: 0;
  margin-right: -10px;
}
ul.typeahead-list {
  max-height: 80vh;
  overflow: auto;
}
ul.typeahead-list > li > a {
  /** Firefox bug **/
  /* see https://github.com/jupyter/notebook/issues/559 */
  white-space: normal;
}
ul.typeahead-list  > li > a.pull-right {
  float: left !important;
  float: left;
}
[dir="rtl"] .typeahead-list {
  text-align: right;
}
.cmd-palette .modal-body {
  padding: 7px;
}
.cmd-palette form {
  background: white;
}
.cmd-palette input {
  outline: none;
}
.no-shortcut {
  min-width: 20px;
  color: transparent;
}
[dir="rtl"] .no-shortcut.pull-right {
  float: left !important;
  float: left;
}
[dir="rtl"] .command-shortcut.pull-right {
  float: left !important;
  float: left;
}
.command-shortcut:before {
  content: "(command mode)";
  padding-right: 3px;
  color: #777777;
}
.edit-shortcut:before {
  content: "(edit)";
  padding-right: 3px;
  color: #777777;
}
[dir="rtl"] .edit-shortcut.pull-right {
  float: left !important;
  float: left;
}
#find-and-replace #replace-preview .match,
#find-and-replace #replace-preview .insert {
  background-color: #BBDEFB;
  border-color: #90CAF9;
  border-style: solid;
  border-width: 1px;
  border-radius: 0px;
}
[dir="ltr"] #find-and-replace .input-group-btn + .form-control {
  border-left: none;
}
[dir="rtl"] #find-and-replace .input-group-btn + .form-control {
  border-right: none;
}
#find-and-replace #replace-preview .replace .match {
  background-color: #FFCDD2;
  border-color: #EF9A9A;
  border-radius: 0px;
}
#find-and-replace #replace-preview .replace .insert {
  background-color: #C8E6C9;
  border-color: #A5D6A7;
  border-radius: 0px;
}
#find-and-replace #replace-preview {
  max-height: 60vh;
  overflow: auto;
}
#find-and-replace #replace-preview pre {
  padding: 5px 10px;
}
.terminal-app {
  background: #EEE;
}
.terminal-app #header {
  background: #fff;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.terminal-app .terminal {
  width: 100%;
  float: left;
  font-family: monospace;
  color: white;
  background: black;
  padding: 0.4em;
  border-radius: 2px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
}
.terminal-app .terminal,
.terminal-app .terminal dummy-screen {
  line-height: 1em;
  font-size: 14px;
}
.terminal-app .terminal .xterm-rows {
  padding: 10px;
}
.terminal-app .terminal-cursor {
  color: black;
  background: white;
}
.terminal-app #terminado-container {
  margin-top: 20px;
}
/*# sourceMappingURL=style.min.css.map */
    </style>
<style type="text/css">
    .highlight .hll { background-color: #ffffcc }
.highlight  { background: #f8f8f8; }
.highlight .c { color: #408080; font-style: italic } /* Comment */
.highlight .err { border: 1px solid #FF0000 } /* Error */
.highlight .k { color: #008000; font-weight: bold } /* Keyword */
.highlight .o { color: #666666 } /* Operator */
.highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */
.highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */
.highlight .cp { color: #BC7A00 } /* Comment.Preproc */
.highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */
.highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */
.highlight .cs { color: #408080; font-style: italic } /* Comment.Special */
.highlight .gd { color: #A00000 } /* Generic.Deleted */
.highlight .ge { font-style: italic } /* Generic.Emph */
.highlight .gr { color: #FF0000 } /* Generic.Error */
.highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */
.highlight .gi { color: #00A000 } /* Generic.Inserted */
.highlight .go { color: #888888 } /* Generic.Output */
.highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */
.highlight .gs { font-weight: bold } /* Generic.Strong */
.highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */
.highlight .gt { color: #0044DD } /* Generic.Traceback */
.highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: #008000 } /* Keyword.Pseudo */
.highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: #B00040 } /* Keyword.Type */
.highlight .m { color: #666666 } /* Literal.Number */
.highlight .s { color: #BA2121 } /* Literal.String */
.highlight .na { color: #7D9029 } /* Name.Attribute */
.highlight .nb { color: #008000 } /* Name.Builtin */
.highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */
.highlight .no { color: #880000 } /* Name.Constant */
.highlight .nd { color: #AA22FF } /* Name.Decorator */
.highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */
.highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */
.highlight .nf { color: #0000FF } /* Name.Function */
.highlight .nl { color: #A0A000 } /* Name.Label */
.highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */
.highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */
.highlight .nv { color: #19177C } /* Name.Variable */
.highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */
.highlight .w { color: #bbbbbb } /* Text.Whitespace */
.highlight .mb { color: #666666 } /* Literal.Number.Bin */
.highlight .mf { color: #666666 } /* Literal.Number.Float */
.highlight .mh { color: #666666 } /* Literal.Number.Hex */
.highlight .mi { color: #666666 } /* Literal.Number.Integer */
.highlight .mo { color: #666666 } /* Literal.Number.Oct */
.highlight .sa { color: #BA2121 } /* Literal.String.Affix */
.highlight .sb { color: #BA2121 } /* Literal.String.Backtick */
.highlight .sc { color: #BA2121 } /* Literal.String.Char */
.highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */
.highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */
.highlight .s2 { color: #BA2121 } /* Literal.String.Double */
.highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */
.highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */
.highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */
.highlight .sx { color: #008000 } /* Literal.String.Other */
.highlight .sr { color: #BB6688 } /* Literal.String.Regex */
.highlight .s1 { color: #BA2121 } /* Literal.String.Single */
.highlight .ss { color: #19177C } /* Literal.String.Symbol */
.highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */
.highlight .fm { color: #0000FF } /* Name.Function.Magic */
.highlight .vc { color: #19177C } /* Name.Variable.Class */
.highlight .vg { color: #19177C } /* Name.Variable.Global */
.highlight .vi { color: #19177C } /* Name.Variable.Instance */
.highlight .vm { color: #19177C } /* Name.Variable.Magic */
.highlight .il { color: #666666 } /* Literal.Number.Integer.Long */
    </style>


<style type="text/css">
/* Overrides of notebook CSS for static HTML export */
body {
  overflow: visible;
  padding: 8px;
}

div#notebook {
  overflow: visible;
  border-top: none;
}@media print {
  div.cell {
    display: block;
    page-break-inside: avoid;
  } 
  div.output_wrapper { 
    display: block;
    page-break-inside: avoid; 
  }
  div.output { 
    display: block;
    page-break-inside: avoid; 
  }
}
</style>

<!-- Custom stylesheet, it must be in the same directory as the html file -->
<link rel="stylesheet" href="custom.css">

<!-- Loading mathjax macro -->
<!-- Load mathjax -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS_HTML"></script>
    <!-- MathJax configuration -->
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
            processEscapes: true,
            processEnvironments: true
        },
        // Center justify equations in code and markdown cells. Elsewhere
        // we use CSS to left justify single line equations in code cells.
        displayAlign: 'center',
        "HTML-CSS": {
            styles: {'.MathJax_Display': {"margin": 0}},
            linebreaks: { automatic: true }
        }
    });
    </script>
    <!-- End of mathjax configuration --></head>
<body>
  <div tabindex="-1" id="notebook" class="border-box-sizing">
    <div class="container" id="notebook-container">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">## This file implements neural networks before and after lasso selection for p11kpresabs_qual with four replicates.</span>
<span class="c1">## We compute the mean and standarad deviation of training and test accuracies.</span>
<span class="c1">## We also compute the mean and standard deviation of AUC ROC values for each model.</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[1]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">numpy.random</span> <span class="kn">import</span> <span class="n">seed</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="n">seed</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
<span class="kn">import</span> <span class="nn">tensorflow</span>
<span class="n">tensorflow</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">123</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[2]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/p11kpresabs_qual.csv&#39;</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[2]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>(253, 822)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[3]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;Unnamed: 0&#39;</span><span class="p">:</span><span class="s1">&#39;id&#39;</span><span class="p">},</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[4]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;pheno&#39;</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[4]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>0      2
1      1
2      2
3      2
4      2
      ..
248    2
249    1
250    2
251    2
252    2
Name: pheno, Length: 253, dtype: int64</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[5]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[5]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>TTTTTTGTAATTTT</th>
      <th>TTTTTTGTAATTTTT</th>
      <th>TTTTTTATTTTGGAT</th>
      <th>TTTTTTATTTTGGATAA</th>
      <th>TTTTTTATTTTGGATAAAAGGAG</th>
      <th>TTTTTTAGTCGTTTTT</th>
      <th>TTTTTATCGTTTACT</th>
      <th>TTTTTAGTCGTTTTT</th>
      <th>TTTTTAGTCGTTTTTT</th>
      <th>...</th>
      <th>ACAAGTCGCTGAAATATT</th>
      <th>ACAAACTTTCTAGGTT</th>
      <th>AATCACCCCTT</th>
      <th>AAGGGGTGATTT</th>
      <th>AAGGGGTGATTTT</th>
      <th>AAGATGATTTATCCAACTTT</th>
      <th>AACTTTCTAGGTT</th>
      <th>AACCTAGAAAGTTT</th>
      <th>AACATCTTTTATTT</th>
      <th>pheno</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>107</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>2</td>
    </tr>
    <tr>
      <th>1</th>
      <td>109</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>...</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>115</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>...</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>120335</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>...</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>2</td>
    </tr>
    <tr>
      <th>4</th>
      <td>120337</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>...</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>2</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 822 columns</p>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[6]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;pheno&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[6]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>2    181
1     47
0     25
Name: pheno, dtype: int64</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[7]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df_clean</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;id&#39;</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[8]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df_clean</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[8]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>(253, 821)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[9]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df_clean</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[9]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>TTTTTTGTAATTTT</th>
      <th>TTTTTTGTAATTTTT</th>
      <th>TTTTTTATTTTGGAT</th>
      <th>TTTTTTATTTTGGATAA</th>
      <th>TTTTTTATTTTGGATAAAAGGAG</th>
      <th>TTTTTTAGTCGTTTTT</th>
      <th>TTTTTATCGTTTACT</th>
      <th>TTTTTAGTCGTTTTT</th>
      <th>TTTTTAGTCGTTTTTT</th>
      <th>TTTTTAGGTAAGG</th>
      <th>...</th>
      <th>ACAAGTCGCTGAAATATT</th>
      <th>ACAAACTTTCTAGGTT</th>
      <th>AATCACCCCTT</th>
      <th>AAGGGGTGATTT</th>
      <th>AAGGGGTGATTTT</th>
      <th>AAGATGATTTATCCAACTTT</th>
      <th>AACTTTCTAGGTT</th>
      <th>AACCTAGAAAGTTT</th>
      <th>AACATCTTTTATTT</th>
      <th>pheno</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>2</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>...</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>...</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>...</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>2</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>...</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>2</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 821 columns</p>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[10]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span> <span class="o">!=</span> <span class="s1">&#39;pheno&#39;</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;pheno&#39;</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>(253, 821) (253,)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[11]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># over-sampling</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Counter</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_classification</span>
<span class="kn">from</span> <span class="nn">imblearn.over_sampling</span> <span class="kn">import</span> <span class="n">RandomOverSampler</span>
<span class="n">overS</span> <span class="o">=</span> <span class="n">RandomOverSampler</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">X_over</span><span class="p">,</span> <span class="n">y_over</span> <span class="o">=</span> <span class="n">overS</span><span class="o">.</span><span class="n">fit_resample</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">sorted</span><span class="p">(</span><span class="n">Counter</span><span class="p">(</span><span class="n">y_over</span><span class="p">)</span><span class="o">.</span><span class="n">items</span><span class="p">()))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.
  warnings.warn(message, FutureWarning)
/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.ensemble.bagging module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.
  warnings.warn(message, FutureWarning)
/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.ensemble.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.
  warnings.warn(message, FutureWarning)
/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.ensemble.forest module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.
  warnings.warn(message, FutureWarning)
Using TensorFlow backend.
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[(0, 181), (1, 181), (2, 181)]
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.utils.testing module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.utils. Anything that cannot be imported from sklearn.utils is now part of the private API.
  warnings.warn(message, FutureWarning)
/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.metrics.classification module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.
  warnings.warn(message, FutureWarning)
/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.
  warnings.warn(msg, category=FutureWarning)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[12]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">############# Fully-Connected Neural Network ################</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[13]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">Dropout</span>
<span class="kn">from</span> <span class="nn">keras.regularizers</span> <span class="kn">import</span> <span class="n">l1</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[14]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># split into train, test data (over)</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="n">X_train_over</span><span class="p">,</span> <span class="n">X_test_over</span><span class="p">,</span> <span class="n">y_train_over</span><span class="p">,</span> <span class="n">y_test_over</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X_over</span><span class="p">,</span> <span class="n">y_over</span><span class="p">,</span>
                                                    <span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.3</span><span class="p">,</span>
                                                    <span class="n">random_state</span><span class="o">=</span><span class="mi">123</span><span class="p">,</span>
                                                    <span class="n">stratify</span><span class="o">=</span><span class="n">y_over</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[15]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dat</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X_test_over</span><span class="p">[:,</span><span class="mi">0</span><span class="p">])</span>
<span class="n">dat</span><span class="p">[</span><span class="s1">&#39;test&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">y_test_over</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[16]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dat</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[16]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>test</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>SR1129</td>
      <td>2</td>
    </tr>
    <tr>
      <th>1</th>
      <td>NRS185</td>
      <td>2</td>
    </tr>
    <tr>
      <th>2</th>
      <td>NRS243</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>BCH-SA-04</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>504</td>
      <td>1</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>158</th>
      <td>CFBREBSa131</td>
      <td>2</td>
    </tr>
    <tr>
      <th>159</th>
      <td>CFBREBSa133</td>
      <td>1</td>
    </tr>
    <tr>
      <th>160</th>
      <td>NRS256</td>
      <td>2</td>
    </tr>
    <tr>
      <th>161</th>
      <td>GA48963</td>
      <td>1</td>
    </tr>
    <tr>
      <th>162</th>
      <td>BCH-SA-07</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
<p>163 rows × 2 columns</p>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[17]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">X_train_over</span> <span class="o">=</span> <span class="n">X_train_over</span><span class="p">[:,</span><span class="mi">1</span><span class="p">:]</span>
<span class="n">X_test_over</span> <span class="o">=</span> <span class="n">X_test_over</span><span class="p">[:,</span><span class="mi">1</span><span class="p">:]</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[18]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#### neural network on over-sampling data</span>
<span class="n">model1_over</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">([</span>
    <span class="n">Dense</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="n">X_train_over</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],)),</span>
    <span class="n">Dense</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">),</span>
<span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[19]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model1_over</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span>
              <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;sparse_categorical_crossentropy&#39;</span><span class="p">,</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[20]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model1_over</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_over</span><span class="p">,</span> <span class="n">y_train_over</span><span class="p">,</span>
          <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
          <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">X_test_over</span><span class="p">,</span> <span class="n">y_test_over</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Train on 380 samples, validate on 163 samples
Epoch 1/100
380/380 [==============================] - 0s 370us/step - loss: 1.2958 - accuracy: 0.3842 - val_loss: 1.1623 - val_accuracy: 0.3497
Epoch 2/100
380/380 [==============================] - 0s 500us/step - loss: 1.0366 - accuracy: 0.4711 - val_loss: 1.0661 - val_accuracy: 0.4479
Epoch 3/100
380/380 [==============================] - 0s 310us/step - loss: 0.9914 - accuracy: 0.5263 - val_loss: 0.9755 - val_accuracy: 0.5706
Epoch 4/100
380/380 [==============================] - 0s 648us/step - loss: 0.8832 - accuracy: 0.6158 - val_loss: 0.9160 - val_accuracy: 0.5276
Epoch 5/100
380/380 [==============================] - 0s 654us/step - loss: 0.8389 - accuracy: 0.6079 - val_loss: 0.8976 - val_accuracy: 0.6135
Epoch 6/100
380/380 [==============================] - 0s 279us/step - loss: 0.8161 - accuracy: 0.6184 - val_loss: 0.9170 - val_accuracy: 0.6074
Epoch 7/100
380/380 [==============================] - 0s 275us/step - loss: 0.7946 - accuracy: 0.6342 - val_loss: 0.8560 - val_accuracy: 0.6503
Epoch 8/100
380/380 [==============================] - 0s 193us/step - loss: 0.7518 - accuracy: 0.7000 - val_loss: 0.8274 - val_accuracy: 0.6687
Epoch 9/100
380/380 [==============================] - 0s 158us/step - loss: 0.7385 - accuracy: 0.6921 - val_loss: 0.8497 - val_accuracy: 0.6074
Epoch 10/100
380/380 [==============================] - 0s 160us/step - loss: 0.6910 - accuracy: 0.7237 - val_loss: 0.8245 - val_accuracy: 0.6196
Epoch 11/100
380/380 [==============================] - 0s 454us/step - loss: 0.6934 - accuracy: 0.7237 - val_loss: 0.7606 - val_accuracy: 0.6871
Epoch 12/100
380/380 [==============================] - 0s 184us/step - loss: 0.6682 - accuracy: 0.7184 - val_loss: 0.7535 - val_accuracy: 0.6380
Epoch 13/100
380/380 [==============================] - 0s 255us/step - loss: 0.6442 - accuracy: 0.7342 - val_loss: 0.8061 - val_accuracy: 0.6074
Epoch 14/100
380/380 [==============================] - 0s 275us/step - loss: 0.6430 - accuracy: 0.7447 - val_loss: 0.8037 - val_accuracy: 0.6258
Epoch 15/100
380/380 [==============================] - 0s 567us/step - loss: 0.6238 - accuracy: 0.7526 - val_loss: 0.7005 - val_accuracy: 0.7239
Epoch 16/100
380/380 [==============================] - 0s 150us/step - loss: 0.5754 - accuracy: 0.7789 - val_loss: 0.7072 - val_accuracy: 0.7055
Epoch 17/100
380/380 [==============================] - 0s 129us/step - loss: 0.5432 - accuracy: 0.7974 - val_loss: 0.7499 - val_accuracy: 0.6564
Epoch 18/100
380/380 [==============================] - 0s 195us/step - loss: 0.5535 - accuracy: 0.7658 - val_loss: 0.6777 - val_accuracy: 0.6933
Epoch 19/100
380/380 [==============================] - 0s 155us/step - loss: 0.5351 - accuracy: 0.7816 - val_loss: 0.6640 - val_accuracy: 0.6933
Epoch 20/100
380/380 [==============================] - 0s 146us/step - loss: 0.5365 - accuracy: 0.7974 - val_loss: 0.6584 - val_accuracy: 0.7117
Epoch 21/100
380/380 [==============================] - 0s 164us/step - loss: 0.4982 - accuracy: 0.8158 - val_loss: 0.7143 - val_accuracy: 0.6687
Epoch 22/100
380/380 [==============================] - 0s 378us/step - loss: 0.5129 - accuracy: 0.7895 - val_loss: 0.7093 - val_accuracy: 0.6687
Epoch 23/100
380/380 [==============================] - 0s 209us/step - loss: 0.4954 - accuracy: 0.7895 - val_loss: 0.6718 - val_accuracy: 0.6810
Epoch 24/100
380/380 [==============================] - 0s 362us/step - loss: 0.4678 - accuracy: 0.8316 - val_loss: 0.6510 - val_accuracy: 0.6933
Epoch 25/100
380/380 [==============================] - 0s 194us/step - loss: 0.4671 - accuracy: 0.7974 - val_loss: 0.6532 - val_accuracy: 0.6933
Epoch 26/100
380/380 [==============================] - 0s 305us/step - loss: 0.4472 - accuracy: 0.8474 - val_loss: 0.6302 - val_accuracy: 0.6994
Epoch 27/100
380/380 [==============================] - 0s 166us/step - loss: 0.4445 - accuracy: 0.8237 - val_loss: 0.6332 - val_accuracy: 0.7362
Epoch 28/100
380/380 [==============================] - 0s 171us/step - loss: 0.4577 - accuracy: 0.8184 - val_loss: 0.7093 - val_accuracy: 0.6933
Epoch 29/100
380/380 [==============================] - 0s 210us/step - loss: 0.4704 - accuracy: 0.8026 - val_loss: 0.6858 - val_accuracy: 0.6810
Epoch 30/100
380/380 [==============================] - 0s 376us/step - loss: 0.4657 - accuracy: 0.7974 - val_loss: 0.6326 - val_accuracy: 0.7362
Epoch 31/100
380/380 [==============================] - 0s 478us/step - loss: 0.4441 - accuracy: 0.8132 - val_loss: 0.6610 - val_accuracy: 0.7423
Epoch 32/100
380/380 [==============================] - 0s 558us/step - loss: 0.4274 - accuracy: 0.8132 - val_loss: 0.6522 - val_accuracy: 0.7607
Epoch 33/100
380/380 [==============================] - 0s 350us/step - loss: 0.4089 - accuracy: 0.8316 - val_loss: 0.6486 - val_accuracy: 0.7117
Epoch 34/100
380/380 [==============================] - 0s 317us/step - loss: 0.4049 - accuracy: 0.8289 - val_loss: 0.6835 - val_accuracy: 0.7055
Epoch 35/100
380/380 [==============================] - 0s 536us/step - loss: 0.4165 - accuracy: 0.8184 - val_loss: 0.6698 - val_accuracy: 0.6933
Epoch 36/100
380/380 [==============================] - 0s 425us/step - loss: 0.3941 - accuracy: 0.8395 - val_loss: 0.7294 - val_accuracy: 0.6871
Epoch 37/100
380/380 [==============================] - 0s 248us/step - loss: 0.4213 - accuracy: 0.8105 - val_loss: 0.6635 - val_accuracy: 0.7117
Epoch 38/100
380/380 [==============================] - 0s 529us/step - loss: 0.3862 - accuracy: 0.8553 - val_loss: 0.7388 - val_accuracy: 0.6871
Epoch 39/100
380/380 [==============================] - 0s 160us/step - loss: 0.4140 - accuracy: 0.8526 - val_loss: 0.6768 - val_accuracy: 0.7117
Epoch 40/100
380/380 [==============================] - 0s 253us/step - loss: 0.3903 - accuracy: 0.8474 - val_loss: 0.6676 - val_accuracy: 0.7117
Epoch 41/100
380/380 [==============================] - 0s 463us/step - loss: 0.4110 - accuracy: 0.8263 - val_loss: 0.6834 - val_accuracy: 0.7117
Epoch 42/100
380/380 [==============================] - 0s 170us/step - loss: 0.3474 - accuracy: 0.8737 - val_loss: 0.6389 - val_accuracy: 0.7178
Epoch 43/100
380/380 [==============================] - 0s 496us/step - loss: 0.3979 - accuracy: 0.8368 - val_loss: 0.5984 - val_accuracy: 0.7546
Epoch 44/100
380/380 [==============================] - 0s 175us/step - loss: 0.3893 - accuracy: 0.8289 - val_loss: 0.6063 - val_accuracy: 0.7301
Epoch 45/100
380/380 [==============================] - 0s 812us/step - loss: 0.3692 - accuracy: 0.8447 - val_loss: 0.6024 - val_accuracy: 0.7178
Epoch 46/100
380/380 [==============================] - 0s 286us/step - loss: 0.3581 - accuracy: 0.8289 - val_loss: 0.6108 - val_accuracy: 0.7485
Epoch 47/100
380/380 [==============================] - 0s 510us/step - loss: 0.3630 - accuracy: 0.8658 - val_loss: 0.6008 - val_accuracy: 0.7301
Epoch 48/100
380/380 [==============================] - 0s 217us/step - loss: 0.3819 - accuracy: 0.8316 - val_loss: 0.6458 - val_accuracy: 0.6994
Epoch 49/100
380/380 [==============================] - 0s 287us/step - loss: 0.3288 - accuracy: 0.8658 - val_loss: 0.6180 - val_accuracy: 0.7178
Epoch 50/100
380/380 [==============================] - 0s 484us/step - loss: 0.3342 - accuracy: 0.8605 - val_loss: 0.6214 - val_accuracy: 0.7485
Epoch 51/100
380/380 [==============================] - 0s 193us/step - loss: 0.3259 - accuracy: 0.8711 - val_loss: 0.5791 - val_accuracy: 0.7485
Epoch 52/100
380/380 [==============================] - 0s 189us/step - loss: 0.3280 - accuracy: 0.8500 - val_loss: 0.6368 - val_accuracy: 0.7178
Epoch 53/100
380/380 [==============================] - 0s 164us/step - loss: 0.3292 - accuracy: 0.8632 - val_loss: 0.6452 - val_accuracy: 0.7301
Epoch 54/100
380/380 [==============================] - 0s 313us/step - loss: 0.4032 - accuracy: 0.8263 - val_loss: 0.6586 - val_accuracy: 0.7362
Epoch 55/100
380/380 [==============================] - 0s 303us/step - loss: 0.3945 - accuracy: 0.8447 - val_loss: 0.5783 - val_accuracy: 0.7607
Epoch 56/100
380/380 [==============================] - 0s 607us/step - loss: 0.3468 - accuracy: 0.8605 - val_loss: 0.5971 - val_accuracy: 0.7546
Epoch 57/100
380/380 [==============================] - 0s 688us/step - loss: 0.3541 - accuracy: 0.8526 - val_loss: 0.6356 - val_accuracy: 0.7546
Epoch 58/100
380/380 [==============================] - 0s 491us/step - loss: 0.2998 - accuracy: 0.8816 - val_loss: 0.5790 - val_accuracy: 0.7607
Epoch 59/100
380/380 [==============================] - 0s 499us/step - loss: 0.3098 - accuracy: 0.8816 - val_loss: 0.5920 - val_accuracy: 0.7546
Epoch 60/100
380/380 [==============================] - 0s 477us/step - loss: 0.3332 - accuracy: 0.8605 - val_loss: 0.6100 - val_accuracy: 0.7239
Epoch 61/100
380/380 [==============================] - 0s 481us/step - loss: 0.3297 - accuracy: 0.8474 - val_loss: 0.6261 - val_accuracy: 0.7239
Epoch 62/100
380/380 [==============================] - 0s 305us/step - loss: 0.3217 - accuracy: 0.8737 - val_loss: 0.6523 - val_accuracy: 0.7117
Epoch 63/100
380/380 [==============================] - 0s 686us/step - loss: 0.3312 - accuracy: 0.8605 - val_loss: 0.6784 - val_accuracy: 0.7117
Epoch 64/100
380/380 [==============================] - 0s 490us/step - loss: 0.3083 - accuracy: 0.8842 - val_loss: 0.8247 - val_accuracy: 0.6748
Epoch 65/100
380/380 [==============================] - 0s 201us/step - loss: 0.3315 - accuracy: 0.8605 - val_loss: 0.6368 - val_accuracy: 0.7301
Epoch 66/100
380/380 [==============================] - 0s 229us/step - loss: 0.3088 - accuracy: 0.8763 - val_loss: 0.6257 - val_accuracy: 0.7239
Epoch 67/100
380/380 [==============================] - 0s 195us/step - loss: 0.3087 - accuracy: 0.8632 - val_loss: 0.6332 - val_accuracy: 0.7423
Epoch 68/100
380/380 [==============================] - 0s 427us/step - loss: 0.3041 - accuracy: 0.8737 - val_loss: 0.6428 - val_accuracy: 0.7791
Epoch 69/100
380/380 [==============================] - 0s 225us/step - loss: 0.2918 - accuracy: 0.8921 - val_loss: 0.5973 - val_accuracy: 0.7791
Epoch 70/100
380/380 [==============================] - 0s 318us/step - loss: 0.2872 - accuracy: 0.8895 - val_loss: 0.5915 - val_accuracy: 0.7485
Epoch 71/100
380/380 [==============================] - 0s 619us/step - loss: 0.2905 - accuracy: 0.8842 - val_loss: 0.5977 - val_accuracy: 0.7730
Epoch 72/100
380/380 [==============================] - 0s 181us/step - loss: 0.2852 - accuracy: 0.8868 - val_loss: 0.7446 - val_accuracy: 0.6933
Epoch 73/100
380/380 [==============================] - 0s 676us/step - loss: 0.3233 - accuracy: 0.8684 - val_loss: 0.6540 - val_accuracy: 0.7730
Epoch 74/100
380/380 [==============================] - 0s 228us/step - loss: 0.3300 - accuracy: 0.8737 - val_loss: 0.6095 - val_accuracy: 0.7669
Epoch 75/100
380/380 [==============================] - 0s 229us/step - loss: 0.2899 - accuracy: 0.8921 - val_loss: 0.5637 - val_accuracy: 0.7669
Epoch 76/100
380/380 [==============================] - 0s 284us/step - loss: 0.3039 - accuracy: 0.8789 - val_loss: 0.6606 - val_accuracy: 0.7178
Epoch 77/100
380/380 [==============================] - 0s 302us/step - loss: 0.3118 - accuracy: 0.8816 - val_loss: 0.6735 - val_accuracy: 0.7178
Epoch 78/100
380/380 [==============================] - 0s 317us/step - loss: 0.3227 - accuracy: 0.8526 - val_loss: 0.7549 - val_accuracy: 0.7117
Epoch 79/100
380/380 [==============================] - 0s 265us/step - loss: 0.3154 - accuracy: 0.8579 - val_loss: 0.7566 - val_accuracy: 0.7117
Epoch 80/100
380/380 [==============================] - 0s 173us/step - loss: 0.3219 - accuracy: 0.8500 - val_loss: 0.8535 - val_accuracy: 0.6748
Epoch 81/100
380/380 [==============================] - 0s 566us/step - loss: 0.3526 - accuracy: 0.8526 - val_loss: 0.8144 - val_accuracy: 0.7055
Epoch 82/100
380/380 [==============================] - 0s 436us/step - loss: 0.3434 - accuracy: 0.8474 - val_loss: 0.7056 - val_accuracy: 0.7117
Epoch 83/100
380/380 [==============================] - 0s 207us/step - loss: 0.2583 - accuracy: 0.8921 - val_loss: 0.5837 - val_accuracy: 0.7669
Epoch 84/100
380/380 [==============================] - 0s 349us/step - loss: 0.2764 - accuracy: 0.8842 - val_loss: 0.5963 - val_accuracy: 0.7730
Epoch 85/100
380/380 [==============================] - 0s 279us/step - loss: 0.2988 - accuracy: 0.8789 - val_loss: 0.6655 - val_accuracy: 0.7669
Epoch 86/100
380/380 [==============================] - 0s 260us/step - loss: 0.2800 - accuracy: 0.8868 - val_loss: 0.6075 - val_accuracy: 0.8037
Epoch 87/100
380/380 [==============================] - 0s 270us/step - loss: 0.2518 - accuracy: 0.8895 - val_loss: 0.5767 - val_accuracy: 0.7423
Epoch 88/100
380/380 [==============================] - 0s 196us/step - loss: 0.2569 - accuracy: 0.8842 - val_loss: 0.5709 - val_accuracy: 0.7485
Epoch 89/100
380/380 [==============================] - 0s 315us/step - loss: 0.2471 - accuracy: 0.9026 - val_loss: 0.5967 - val_accuracy: 0.7791
Epoch 90/100
380/380 [==============================] - 0s 171us/step - loss: 0.2652 - accuracy: 0.8868 - val_loss: 0.5745 - val_accuracy: 0.7730
Epoch 91/100
380/380 [==============================] - 0s 517us/step - loss: 0.2594 - accuracy: 0.9026 - val_loss: 0.6131 - val_accuracy: 0.8037
Epoch 92/100
380/380 [==============================] - 0s 203us/step - loss: 0.2519 - accuracy: 0.8921 - val_loss: 0.6736 - val_accuracy: 0.7178
Epoch 93/100
380/380 [==============================] - 0s 628us/step - loss: 0.3184 - accuracy: 0.8500 - val_loss: 0.6773 - val_accuracy: 0.7117
Epoch 94/100
380/380 [==============================] - 0s 717us/step - loss: 0.2807 - accuracy: 0.8816 - val_loss: 0.6875 - val_accuracy: 0.7362
Epoch 95/100
380/380 [==============================] - 0s 209us/step - loss: 0.2652 - accuracy: 0.9026 - val_loss: 0.6149 - val_accuracy: 0.7362
Epoch 96/100
380/380 [==============================] - 0s 280us/step - loss: 0.2579 - accuracy: 0.8895 - val_loss: 0.6285 - val_accuracy: 0.7485
Epoch 97/100
380/380 [==============================] - 0s 384us/step - loss: 0.2703 - accuracy: 0.8868 - val_loss: 0.5889 - val_accuracy: 0.7914
Epoch 98/100
380/380 [==============================] - 0s 289us/step - loss: 0.2848 - accuracy: 0.8737 - val_loss: 0.5647 - val_accuracy: 0.7669
Epoch 99/100
380/380 [==============================] - 0s 202us/step - loss: 0.2512 - accuracy: 0.8974 - val_loss: 0.5643 - val_accuracy: 0.7791
Epoch 100/100
380/380 [==============================] - 0s 175us/step - loss: 0.2585 - accuracy: 0.8842 - val_loss: 0.6155 - val_accuracy: 0.7914
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[20]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&lt;keras.callbacks.callbacks.History at 0x1a410e0048&gt;</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[37]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">acc_test_over</span> <span class="o">=</span> <span class="n">model1_over</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_test_over</span><span class="p">,</span> <span class="n">y_test_over</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;over-sampling test accuracy: </span><span class="si">%.2f%%</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">acc_test_over</span><span class="o">*</span><span class="mi">100</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>163/163 [==============================] - 0s 85us/step
over-sampling test accuracy: 78.53%
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[21]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">pred</span> <span class="o">=</span> <span class="n">model1_over</span><span class="o">.</span><span class="n">predict_classes</span><span class="p">(</span><span class="n">X_test_over</span><span class="p">)</span>
<span class="n">pred</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[21]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>array([0, 2, 1, 0, 1, 0, 0, 0, 1, 1, 2, 0, 0, 2, 0, 0, 2, 0, 0, 0, 1, 0,
       0, 2, 0, 0, 0, 1, 0, 0, 2, 2, 1, 0, 1, 0, 1, 1, 1, 1, 0, 2, 0, 2,
       1, 1, 2, 1, 0, 0, 0, 0, 1, 1, 1, 2, 1, 2, 0, 0, 0, 1, 0, 0, 1, 2,
       0, 0, 1, 0, 0, 1, 0, 1, 2, 1, 1, 0, 0, 0, 1, 1, 2, 1, 1, 0, 0, 1,
       1, 2, 0, 0, 1, 0, 1, 2, 2, 0, 2, 0, 0, 0, 0, 1, 2, 0, 1, 0, 0, 0,
       2, 1, 0, 1, 2, 0, 0, 1, 1, 0, 0, 2, 1, 2, 0, 2, 2, 0, 2, 0, 0, 1,
       2, 1, 1, 2, 0, 0, 2, 0, 0, 2, 0, 2, 2, 2, 0, 1, 0, 2, 0, 0, 0, 0,
       2, 0, 0, 2, 0, 1, 2, 1, 0])</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[22]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dat</span><span class="p">[</span><span class="s1">&#39;pred&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pred</span>
<span class="n">dat</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[22]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>test</th>
      <th>pred</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>SR1129</td>
      <td>2</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>NRS185</td>
      <td>2</td>
      <td>2</td>
    </tr>
    <tr>
      <th>2</th>
      <td>NRS243</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>BCH-SA-04</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>504</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>158</th>
      <td>CFBREBSa131</td>
      <td>2</td>
      <td>0</td>
    </tr>
    <tr>
      <th>159</th>
      <td>CFBREBSa133</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>160</th>
      <td>NRS256</td>
      <td>2</td>
      <td>2</td>
    </tr>
    <tr>
      <th>161</th>
      <td>GA48963</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>162</th>
      <td>BCH-SA-07</td>
      <td>1</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>163 rows × 3 columns</p>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[23]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">proba1</span> <span class="o">=</span> <span class="n">model1_over</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test_over</span><span class="p">)</span>
<span class="n">dat_proba1</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">proba1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[24]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dat_proba1</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[24]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.991729</td>
      <td>0.001580</td>
      <td>0.006691</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.011410</td>
      <td>0.104540</td>
      <td>0.884050</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.000098</td>
      <td>0.985774</td>
      <td>0.014128</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.995715</td>
      <td>0.000013</td>
      <td>0.004272</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.113516</td>
      <td>0.788538</td>
      <td>0.097947</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>158</th>
      <td>0.883826</td>
      <td>0.000551</td>
      <td>0.115623</td>
    </tr>
    <tr>
      <th>159</th>
      <td>0.000303</td>
      <td>0.661321</td>
      <td>0.338375</td>
    </tr>
    <tr>
      <th>160</th>
      <td>0.000027</td>
      <td>0.007202</td>
      <td>0.992771</td>
    </tr>
    <tr>
      <th>161</th>
      <td>0.000209</td>
      <td>0.844463</td>
      <td>0.155327</td>
    </tr>
    <tr>
      <th>162</th>
      <td>0.439803</td>
      <td>0.407325</td>
      <td>0.152872</td>
    </tr>
  </tbody>
</table>
<p>163 rows × 3 columns</p>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[25]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dat_proba1</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s2">&quot;/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba1.csv&quot;</span><span class="p">,</span> <span class="n">index</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
         <span class="n">header</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[26]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dat</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s2">&quot;/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/1p11.csv&quot;</span><span class="p">,</span> <span class="n">index</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
         <span class="n">header</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[41]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">hist1_over</span> <span class="o">=</span> <span class="n">model1_over</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_over</span><span class="p">,</span> <span class="n">y_train_over</span><span class="p">,</span>
          <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
          <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">X_test_over</span><span class="p">,</span> <span class="n">y_test_over</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Train on 380 samples, validate on 163 samples
Epoch 1/100
380/380 [==============================] - 0s 183us/step - loss: 0.2487 - accuracy: 0.9026 - val_loss: 0.5889 - val_accuracy: 0.7791
Epoch 2/100
380/380 [==============================] - 0s 160us/step - loss: 0.2469 - accuracy: 0.8816 - val_loss: 0.6103 - val_accuracy: 0.7362
Epoch 3/100
380/380 [==============================] - 0s 180us/step - loss: 0.2691 - accuracy: 0.8816 - val_loss: 0.6027 - val_accuracy: 0.7853
Epoch 4/100
380/380 [==============================] - 0s 165us/step - loss: 0.2568 - accuracy: 0.8921 - val_loss: 0.5829 - val_accuracy: 0.7853
Epoch 5/100
380/380 [==============================] - 0s 158us/step - loss: 0.2419 - accuracy: 0.9000 - val_loss: 0.6354 - val_accuracy: 0.7853
Epoch 6/100
380/380 [==============================] - 0s 149us/step - loss: 0.2641 - accuracy: 0.8868 - val_loss: 0.6748 - val_accuracy: 0.7362
Epoch 7/100
380/380 [==============================] - 0s 134us/step - loss: 0.2567 - accuracy: 0.8921 - val_loss: 0.6147 - val_accuracy: 0.7853
Epoch 8/100
380/380 [==============================] - 0s 114us/step - loss: 0.2548 - accuracy: 0.8974 - val_loss: 0.5857 - val_accuracy: 0.7914
Epoch 9/100
380/380 [==============================] - 0s 109us/step - loss: 0.2441 - accuracy: 0.9079 - val_loss: 0.6178 - val_accuracy: 0.7791
Epoch 10/100
380/380 [==============================] - 0s 125us/step - loss: 0.2774 - accuracy: 0.8789 - val_loss: 0.5906 - val_accuracy: 0.7914
Epoch 11/100
380/380 [==============================] - 0s 112us/step - loss: 0.2296 - accuracy: 0.9053 - val_loss: 0.6960 - val_accuracy: 0.7239
Epoch 12/100
380/380 [==============================] - 0s 113us/step - loss: 0.2537 - accuracy: 0.8921 - val_loss: 0.6842 - val_accuracy: 0.7546
Epoch 13/100
380/380 [==============================] - 0s 111us/step - loss: 0.2533 - accuracy: 0.8842 - val_loss: 0.7794 - val_accuracy: 0.7117
Epoch 14/100
380/380 [==============================] - 0s 106us/step - loss: 0.2760 - accuracy: 0.8684 - val_loss: 0.6701 - val_accuracy: 0.7362
Epoch 15/100
380/380 [==============================] - 0s 120us/step - loss: 0.2385 - accuracy: 0.9026 - val_loss: 0.6553 - val_accuracy: 0.7423
Epoch 16/100
380/380 [==============================] - 0s 110us/step - loss: 0.2324 - accuracy: 0.9053 - val_loss: 0.6376 - val_accuracy: 0.7730
Epoch 17/100
380/380 [==============================] - 0s 106us/step - loss: 0.2427 - accuracy: 0.8895 - val_loss: 0.7285 - val_accuracy: 0.7485
Epoch 18/100
380/380 [==============================] - 0s 112us/step - loss: 0.2558 - accuracy: 0.8895 - val_loss: 0.6330 - val_accuracy: 0.7914
Epoch 19/100
380/380 [==============================] - 0s 118us/step - loss: 0.2272 - accuracy: 0.9079 - val_loss: 0.6479 - val_accuracy: 0.7914
Epoch 20/100
380/380 [==============================] - 0s 116us/step - loss: 0.2334 - accuracy: 0.9053 - val_loss: 0.5940 - val_accuracy: 0.7853
Epoch 21/100
380/380 [==============================] - 0s 118us/step - loss: 0.2356 - accuracy: 0.9158 - val_loss: 0.6586 - val_accuracy: 0.7730
Epoch 22/100
380/380 [==============================] - 0s 148us/step - loss: 0.2955 - accuracy: 0.8737 - val_loss: 0.6249 - val_accuracy: 0.7730
Epoch 23/100
380/380 [==============================] - 0s 151us/step - loss: 0.2732 - accuracy: 0.8711 - val_loss: 0.5800 - val_accuracy: 0.7975
Epoch 24/100
380/380 [==============================] - 0s 165us/step - loss: 0.2414 - accuracy: 0.9000 - val_loss: 0.6419 - val_accuracy: 0.7362
Epoch 25/100
380/380 [==============================] - 0s 141us/step - loss: 0.2628 - accuracy: 0.8895 - val_loss: 0.6365 - val_accuracy: 0.8037
Epoch 26/100
380/380 [==============================] - 0s 114us/step - loss: 0.2570 - accuracy: 0.8974 - val_loss: 0.5915 - val_accuracy: 0.7914
Epoch 27/100
380/380 [==============================] - 0s 136us/step - loss: 0.2351 - accuracy: 0.9053 - val_loss: 0.6588 - val_accuracy: 0.7669
Epoch 28/100
380/380 [==============================] - 0s 123us/step - loss: 0.2384 - accuracy: 0.9079 - val_loss: 0.5976 - val_accuracy: 0.7914
Epoch 29/100
380/380 [==============================] - 0s 124us/step - loss: 0.2324 - accuracy: 0.8974 - val_loss: 0.6139 - val_accuracy: 0.7853
Epoch 30/100
380/380 [==============================] - 0s 130us/step - loss: 0.2381 - accuracy: 0.9000 - val_loss: 0.6276 - val_accuracy: 0.7853
Epoch 31/100
380/380 [==============================] - 0s 129us/step - loss: 0.2530 - accuracy: 0.8947 - val_loss: 0.5941 - val_accuracy: 0.7853
Epoch 32/100
380/380 [==============================] - 0s 131us/step - loss: 0.2416 - accuracy: 0.8921 - val_loss: 0.6363 - val_accuracy: 0.7546
Epoch 33/100
380/380 [==============================] - 0s 110us/step - loss: 0.2491 - accuracy: 0.8895 - val_loss: 0.6049 - val_accuracy: 0.7853
Epoch 34/100
380/380 [==============================] - 0s 231us/step - loss: 0.2328 - accuracy: 0.9026 - val_loss: 0.6139 - val_accuracy: 0.7914
Epoch 35/100
380/380 [==============================] - 0s 181us/step - loss: 0.2226 - accuracy: 0.9000 - val_loss: 0.6158 - val_accuracy: 0.7853
Epoch 36/100
380/380 [==============================] - 0s 153us/step - loss: 0.2226 - accuracy: 0.9053 - val_loss: 0.6237 - val_accuracy: 0.8098
Epoch 37/100
380/380 [==============================] - 0s 134us/step - loss: 0.2276 - accuracy: 0.9132 - val_loss: 0.6380 - val_accuracy: 0.8098
Epoch 38/100
380/380 [==============================] - 0s 133us/step - loss: 0.2367 - accuracy: 0.9053 - val_loss: 0.6936 - val_accuracy: 0.7362
Epoch 39/100
380/380 [==============================] - 0s 189us/step - loss: 0.2330 - accuracy: 0.9079 - val_loss: 0.6531 - val_accuracy: 0.7853
Epoch 40/100
380/380 [==============================] - 0s 193us/step - loss: 0.2166 - accuracy: 0.9105 - val_loss: 0.7055 - val_accuracy: 0.7791
Epoch 41/100
380/380 [==============================] - 0s 134us/step - loss: 0.2297 - accuracy: 0.9053 - val_loss: 0.6186 - val_accuracy: 0.7853
Epoch 42/100
380/380 [==============================] - 0s 135us/step - loss: 0.2303 - accuracy: 0.9026 - val_loss: 0.6258 - val_accuracy: 0.7914
Epoch 43/100
380/380 [==============================] - 0s 135us/step - loss: 0.2136 - accuracy: 0.9263 - val_loss: 0.5964 - val_accuracy: 0.7914
Epoch 44/100
380/380 [==============================] - 0s 142us/step - loss: 0.2416 - accuracy: 0.9000 - val_loss: 0.6875 - val_accuracy: 0.7669
Epoch 45/100
380/380 [==============================] - 0s 145us/step - loss: 0.2484 - accuracy: 0.9000 - val_loss: 0.7330 - val_accuracy: 0.7607
Epoch 46/100
380/380 [==============================] - 0s 152us/step - loss: 0.2327 - accuracy: 0.8921 - val_loss: 0.6575 - val_accuracy: 0.7730
Epoch 47/100
380/380 [==============================] - 0s 146us/step - loss: 0.2435 - accuracy: 0.8842 - val_loss: 0.7135 - val_accuracy: 0.7485
Epoch 48/100
380/380 [==============================] - 0s 574us/step - loss: 0.2376 - accuracy: 0.8974 - val_loss: 0.6436 - val_accuracy: 0.7975
Epoch 49/100
380/380 [==============================] - 0s 160us/step - loss: 0.2142 - accuracy: 0.9105 - val_loss: 0.6159 - val_accuracy: 0.7853
Epoch 50/100
380/380 [==============================] - 0s 124us/step - loss: 0.2085 - accuracy: 0.9211 - val_loss: 0.6070 - val_accuracy: 0.7607
Epoch 51/100
380/380 [==============================] - 0s 128us/step - loss: 0.2327 - accuracy: 0.8974 - val_loss: 0.6656 - val_accuracy: 0.7975
Epoch 52/100
380/380 [==============================] - 0s 174us/step - loss: 0.2100 - accuracy: 0.9132 - val_loss: 0.7282 - val_accuracy: 0.7178
Epoch 53/100
380/380 [==============================] - 0s 197us/step - loss: 0.2134 - accuracy: 0.9079 - val_loss: 0.6331 - val_accuracy: 0.8037
Epoch 54/100
380/380 [==============================] - 0s 128us/step - loss: 0.2116 - accuracy: 0.9184 - val_loss: 0.6016 - val_accuracy: 0.7914
Epoch 55/100
380/380 [==============================] - 0s 143us/step - loss: 0.2390 - accuracy: 0.9053 - val_loss: 0.6658 - val_accuracy: 0.7423
Epoch 56/100
380/380 [==============================] - 0s 127us/step - loss: 0.2643 - accuracy: 0.8895 - val_loss: 0.5929 - val_accuracy: 0.7914
Epoch 57/100
380/380 [==============================] - 0s 110us/step - loss: 0.2208 - accuracy: 0.9026 - val_loss: 0.6264 - val_accuracy: 0.7853
Epoch 58/100
380/380 [==============================] - 0s 111us/step - loss: 0.2047 - accuracy: 0.9211 - val_loss: 0.6408 - val_accuracy: 0.7730
Epoch 59/100
380/380 [==============================] - 0s 359us/step - loss: 0.2110 - accuracy: 0.9053 - val_loss: 0.6313 - val_accuracy: 0.8098
Epoch 60/100
380/380 [==============================] - 0s 165us/step - loss: 0.2153 - accuracy: 0.9079 - val_loss: 0.6313 - val_accuracy: 0.8098
Epoch 61/100
380/380 [==============================] - 0s 132us/step - loss: 0.2150 - accuracy: 0.9105 - val_loss: 0.5999 - val_accuracy: 0.7914
Epoch 62/100
380/380 [==============================] - 0s 134us/step - loss: 0.2003 - accuracy: 0.9105 - val_loss: 0.5945 - val_accuracy: 0.7914
Epoch 63/100
380/380 [==============================] - 0s 124us/step - loss: 0.2108 - accuracy: 0.9132 - val_loss: 0.7039 - val_accuracy: 0.7362
Epoch 64/100
380/380 [==============================] - 0s 124us/step - loss: 0.2073 - accuracy: 0.8974 - val_loss: 0.6484 - val_accuracy: 0.7791
Epoch 65/100
380/380 [==============================] - 0s 123us/step - loss: 0.2436 - accuracy: 0.9105 - val_loss: 0.6697 - val_accuracy: 0.7730
Epoch 66/100
380/380 [==============================] - 0s 143us/step - loss: 0.2197 - accuracy: 0.9105 - val_loss: 0.6512 - val_accuracy: 0.7914
Epoch 67/100
380/380 [==============================] - 0s 113us/step - loss: 0.2471 - accuracy: 0.9026 - val_loss: 0.7141 - val_accuracy: 0.7423
Epoch 68/100
380/380 [==============================] - 0s 111us/step - loss: 0.2174 - accuracy: 0.9105 - val_loss: 0.7284 - val_accuracy: 0.7485
Epoch 69/100
380/380 [==============================] - 0s 104us/step - loss: 0.2498 - accuracy: 0.8974 - val_loss: 0.7437 - val_accuracy: 0.7853
Epoch 70/100
380/380 [==============================] - 0s 109us/step - loss: 0.2440 - accuracy: 0.9053 - val_loss: 0.5990 - val_accuracy: 0.7853
Epoch 71/100
380/380 [==============================] - 0s 107us/step - loss: 0.2380 - accuracy: 0.9026 - val_loss: 0.5913 - val_accuracy: 0.8098
Epoch 72/100
380/380 [==============================] - 0s 110us/step - loss: 0.2259 - accuracy: 0.9079 - val_loss: 0.6033 - val_accuracy: 0.7546
Epoch 73/100
380/380 [==============================] - 0s 101us/step - loss: 0.2675 - accuracy: 0.8789 - val_loss: 0.6040 - val_accuracy: 0.7730
Epoch 74/100
380/380 [==============================] - 0s 104us/step - loss: 0.2134 - accuracy: 0.9079 - val_loss: 0.6251 - val_accuracy: 0.7853
Epoch 75/100
380/380 [==============================] - 0s 130us/step - loss: 0.2057 - accuracy: 0.9211 - val_loss: 0.6808 - val_accuracy: 0.7669
Epoch 76/100
380/380 [==============================] - 0s 230us/step - loss: 0.2050 - accuracy: 0.9105 - val_loss: 0.6609 - val_accuracy: 0.7975
Epoch 77/100
380/380 [==============================] - 0s 142us/step - loss: 0.2071 - accuracy: 0.9105 - val_loss: 0.6231 - val_accuracy: 0.7791
Epoch 78/100
380/380 [==============================] - 0s 333us/step - loss: 0.2033 - accuracy: 0.9079 - val_loss: 0.5989 - val_accuracy: 0.7914
Epoch 79/100
380/380 [==============================] - 0s 186us/step - loss: 0.2236 - accuracy: 0.9079 - val_loss: 0.6075 - val_accuracy: 0.7853
Epoch 80/100
380/380 [==============================] - 0s 611us/step - loss: 0.2187 - accuracy: 0.9105 - val_loss: 0.6148 - val_accuracy: 0.7914
Epoch 81/100
380/380 [==============================] - 0s 607us/step - loss: 0.2227 - accuracy: 0.9105 - val_loss: 0.6228 - val_accuracy: 0.7730
Epoch 82/100
380/380 [==============================] - 0s 427us/step - loss: 0.2652 - accuracy: 0.8737 - val_loss: 0.7084 - val_accuracy: 0.7117
Epoch 83/100
380/380 [==============================] - 0s 328us/step - loss: 0.2403 - accuracy: 0.8947 - val_loss: 0.6376 - val_accuracy: 0.8037
Epoch 84/100
380/380 [==============================] - 0s 276us/step - loss: 0.2101 - accuracy: 0.9132 - val_loss: 0.7063 - val_accuracy: 0.7853
Epoch 85/100
380/380 [==============================] - 0s 313us/step - loss: 0.2119 - accuracy: 0.9211 - val_loss: 0.6499 - val_accuracy: 0.8037
Epoch 86/100
380/380 [==============================] - 0s 191us/step - loss: 0.1994 - accuracy: 0.9158 - val_loss: 0.6373 - val_accuracy: 0.8037
Epoch 87/100
380/380 [==============================] - 0s 210us/step - loss: 0.2309 - accuracy: 0.8895 - val_loss: 0.6260 - val_accuracy: 0.8098
Epoch 88/100
380/380 [==============================] - 0s 172us/step - loss: 0.2001 - accuracy: 0.9158 - val_loss: 0.6359 - val_accuracy: 0.8037
Epoch 89/100
380/380 [==============================] - 0s 178us/step - loss: 0.1978 - accuracy: 0.9053 - val_loss: 0.6464 - val_accuracy: 0.8037
Epoch 90/100
380/380 [==============================] - 0s 165us/step - loss: 0.1962 - accuracy: 0.9132 - val_loss: 0.6464 - val_accuracy: 0.8037
Epoch 91/100
380/380 [==============================] - 0s 196us/step - loss: 0.2083 - accuracy: 0.9105 - val_loss: 0.6538 - val_accuracy: 0.8037
Epoch 92/100
380/380 [==============================] - 0s 173us/step - loss: 0.1992 - accuracy: 0.9158 - val_loss: 0.6383 - val_accuracy: 0.8098
Epoch 93/100
380/380 [==============================] - 0s 146us/step - loss: 0.1973 - accuracy: 0.9158 - val_loss: 0.6210 - val_accuracy: 0.8098
Epoch 94/100
380/380 [==============================] - 0s 165us/step - loss: 0.1952 - accuracy: 0.9184 - val_loss: 0.6207 - val_accuracy: 0.7853
Epoch 95/100
380/380 [==============================] - 0s 150us/step - loss: 0.1937 - accuracy: 0.9158 - val_loss: 0.6184 - val_accuracy: 0.8160
Epoch 96/100
380/380 [==============================] - 0s 157us/step - loss: 0.2129 - accuracy: 0.9105 - val_loss: 0.6382 - val_accuracy: 0.7730
Epoch 97/100
380/380 [==============================] - 0s 139us/step - loss: 0.2514 - accuracy: 0.9053 - val_loss: 0.6764 - val_accuracy: 0.7853
Epoch 98/100
380/380 [==============================] - 0s 174us/step - loss: 0.2352 - accuracy: 0.8895 - val_loss: 0.7220 - val_accuracy: 0.7423
Epoch 99/100
380/380 [==============================] - 0s 180us/step - loss: 0.2139 - accuracy: 0.9026 - val_loss: 0.6219 - val_accuracy: 0.8098
Epoch 100/100
380/380 [==============================] - 0s 174us/step - loss: 0.2220 - accuracy: 0.9132 - val_loss: 0.6586 - val_accuracy: 0.8037
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[42]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;over-sampling train accuracy: </span><span class="si">%.2f%%</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">hist1_over</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span><span class="o">*</span><span class="mi">100</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>over-sampling train accuracy: 90.24%
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[18]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df_proba</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_excel</span><span class="p">(</span><span class="s2">&quot;/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_2.xlsx&quot;</span><span class="p">,</span>
                        <span class="n">sheet_name</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                        <span class="n">index_col</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[19]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df_proba</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[19]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>phage</th>
      <th>strain</th>
      <th>phenotype</th>
      <th>prediction</th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>p002ykpresabs_qual</td>
      <td>CFBRSa26</td>
      <td>0</td>
      <td>0</td>
      <td>0.758914</td>
      <td>0.241086</td>
      <td>4.638713e-07</td>
    </tr>
    <tr>
      <th>1</th>
      <td>p002ykpresabs_qual</td>
      <td>NRS109</td>
      <td>2</td>
      <td>2</td>
      <td>0.005361</td>
      <td>0.016236</td>
      <td>9.784034e-01</td>
    </tr>
    <tr>
      <th>2</th>
      <td>p002ykpresabs_qual</td>
      <td>NRS112</td>
      <td>0</td>
      <td>0</td>
      <td>0.726623</td>
      <td>0.273376</td>
      <td>1.520979e-06</td>
    </tr>
    <tr>
      <th>3</th>
      <td>p002ykpresabs_qual</td>
      <td>NRS216</td>
      <td>1</td>
      <td>1</td>
      <td>0.138322</td>
      <td>0.861665</td>
      <td>1.334123e-05</td>
    </tr>
    <tr>
      <th>4</th>
      <td>p002ykpresabs_qual</td>
      <td>NRS021</td>
      <td>0</td>
      <td>0</td>
      <td>0.882176</td>
      <td>0.117824</td>
      <td>1.414530e-10</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>4279</th>
      <td>pyopresabsSTCC_qual</td>
      <td>NRS148</td>
      <td>2</td>
      <td>2</td>
      <td>0.000007</td>
      <td>0.000099</td>
      <td>9.998934e-01</td>
    </tr>
    <tr>
      <th>4280</th>
      <td>pyopresabsSTCC_qual</td>
      <td>NRS255</td>
      <td>2</td>
      <td>2</td>
      <td>0.000257</td>
      <td>0.002048</td>
      <td>9.976944e-01</td>
    </tr>
    <tr>
      <th>4281</th>
      <td>pyopresabsSTCC_qual</td>
      <td>NRS205</td>
      <td>2</td>
      <td>2</td>
      <td>0.000011</td>
      <td>0.000045</td>
      <td>9.999435e-01</td>
    </tr>
    <tr>
      <th>4282</th>
      <td>pyopresabsSTCC_qual</td>
      <td>NRS255</td>
      <td>2</td>
      <td>2</td>
      <td>0.000257</td>
      <td>0.002048</td>
      <td>9.976944e-01</td>
    </tr>
    <tr>
      <th>4283</th>
      <td>pyopresabsSTCC_qual</td>
      <td>NRS109</td>
      <td>2</td>
      <td>2</td>
      <td>0.000097</td>
      <td>0.000929</td>
      <td>9.989737e-01</td>
    </tr>
  </tbody>
</table>
<p>4284 rows × 7 columns</p>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[20]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">y_prob</span> <span class="o">=</span> <span class="n">df_proba</span><span class="p">[</span><span class="n">df_proba</span><span class="p">[</span><span class="s1">&#39;phage&#39;</span><span class="p">]</span><span class="o">==</span><span class="s1">&#39;p11kpresabs_qual&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="o">-</span><span class="mi">3</span><span class="p">:]</span>
<span class="n">y_prob</span> <span class="o">=</span> <span class="n">y_prob</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
<span class="n">y_prob</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[20]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>array([[9.91729100e-01, 1.57970380e-03, 6.69116500e-03],
       [1.14097060e-02, 1.04540370e-01, 8.84049900e-01],
       [9.78376850e-05, 9.85774040e-01, 1.41280090e-02],
       [9.95715100e-01, 1.27100590e-05, 4.27222950e-03],
       [1.13515510e-01, 7.88537500e-01, 9.79469700e-02],
       [4.39802830e-01, 4.07325300e-01, 1.52871890e-01],
       [9.97045930e-01, 2.13479500e-03, 8.19317700e-04],
       [9.72656700e-01, 4.84011600e-04, 2.68592800e-02],
       [3.43547600e-02, 9.57373400e-01, 8.27184300e-03],
       [4.14786630e-04, 9.92141370e-01, 7.44387800e-03],
       [4.84715070e-02, 1.54534520e-01, 7.96994000e-01],
       [9.88449160e-01, 9.83262600e-03, 1.71824530e-03],
       [4.95854350e-01, 1.48356170e-01, 3.55789540e-01],
       [3.06200950e-01, 3.41136840e-01, 3.52662270e-01],
       [9.88449160e-01, 9.83262600e-03, 1.71824530e-03],
       [9.96626260e-01, 1.57607890e-03, 1.79763920e-03],
       [1.51535050e-01, 1.46507320e-01, 7.01957640e-01],
       [4.47552920e-01, 1.16874285e-01, 4.35572740e-01],
       [3.87072400e-01, 3.67497530e-01, 2.45430020e-01],
       [4.39802830e-01, 4.07325300e-01, 1.52871890e-01],
       [5.53067700e-03, 9.81277400e-01, 1.31919430e-02],
       [9.97595500e-01, 1.04990720e-03, 1.35469260e-03],
       [9.90821840e-01, 3.77076940e-04, 8.80115400e-03],
       [4.29776670e-04, 1.27040580e-01, 8.72529600e-01],
       [9.98124200e-01, 1.53980530e-03, 3.36043540e-04],
       [9.66109500e-01, 3.63069270e-04, 3.35275460e-02],
       [4.39802830e-01, 4.07325300e-01, 1.52871890e-01],
       [1.13515510e-01, 7.88537500e-01, 9.79469700e-02],
       [9.95571730e-01, 2.80790850e-03, 1.62041140e-03],
       [9.98124200e-01, 1.53980530e-03, 3.36043540e-04],
       [2.60943710e-02, 4.04607240e-01, 5.69298400e-01],
       [2.84940100e-01, 1.66757760e-01, 5.48302200e-01],
       [3.81645300e-02, 9.51415660e-01, 1.04197610e-02],
       [3.87072400e-01, 3.67497530e-01, 2.45430020e-01],
       [3.81645300e-02, 9.51415660e-01, 1.04197610e-02],
       [9.90292250e-01, 3.14184740e-03, 6.56593820e-03],
       [6.00730400e-02, 9.03803300e-01, 3.61236860e-02],
       [1.28098390e-04, 9.98509000e-01, 1.36293330e-03],
       [2.09254750e-04, 8.44463300e-01, 1.55327380e-01],
       [3.12244560e-01, 4.95638000e-01, 1.92117480e-01],
       [9.97355000e-01, 7.91225860e-08, 2.64493500e-03],
       [1.91803500e-01, 1.80667650e-01, 6.27528900e-01],
       [9.75941200e-01, 1.99411200e-04, 2.38594040e-02],
       [1.92186190e-01, 1.79676550e-01, 6.28137300e-01],
       [2.09254750e-04, 8.44463300e-01, 1.55327380e-01],
       [2.07424370e-01, 4.01308200e-01, 3.91267480e-01],
       [1.91803500e-01, 1.80667650e-01, 6.27528900e-01],
       [2.49621720e-04, 9.75565850e-01, 2.41845470e-02],
       [9.98077300e-01, 5.43888900e-04, 1.37882040e-03],
       [3.87072400e-01, 3.67497530e-01, 2.45430020e-01],
       [9.97158400e-01, 2.71921540e-03, 1.22415570e-04],
       [3.87072400e-01, 3.67497530e-01, 2.45430020e-01],
       [2.97356860e-04, 9.96192800e-01, 3.50979180e-03],
       [6.08873130e-03, 8.32504000e-01, 1.61407300e-01],
       [8.97469000e-03, 9.82669700e-01, 8.35554800e-03],
       [2.00353500e-01, 1.73549430e-04, 7.99472900e-01],
       [1.35271650e-01, 6.47507250e-01, 2.17221110e-01],
       [1.06892890e-03, 5.49971700e-03, 9.93431400e-01],
       [9.75941200e-01, 1.99411200e-04, 2.38594040e-02],
       [7.76234750e-01, 1.76269780e-02, 2.06138310e-01],
       [8.27264800e-01, 1.17210420e-03, 1.71563120e-01],
       [3.48167870e-04, 9.93218100e-01, 6.43364760e-03],
       [9.66109500e-01, 3.63069270e-04, 3.35275460e-02],
       [3.87072400e-01, 3.67497530e-01, 2.45430020e-01],
       [6.00730400e-02, 9.03803300e-01, 3.61236860e-02],
       [4.22910330e-01, 6.40617330e-04, 5.76449000e-01],
       [9.95715100e-01, 1.27100590e-05, 4.27222950e-03],
       [9.90821840e-01, 3.77076940e-04, 8.80115400e-03],
       [3.03473470e-04, 6.61321200e-01, 3.38375300e-01],
       [3.87072400e-01, 3.67497530e-01, 2.45430020e-01],
       [4.95854350e-01, 1.48356170e-01, 3.55789540e-01],
       [6.00730400e-02, 9.03803300e-01, 3.61236860e-02],
       [9.66109500e-01, 3.63069270e-04, 3.35275460e-02],
       [4.49917430e-02, 9.40849660e-01, 1.41586400e-02],
       [3.95624400e-02, 7.09254600e-02, 8.89512100e-01],
       [2.84553660e-05, 9.21850200e-01, 7.81214000e-02],
       [6.00730400e-02, 9.03803300e-01, 3.61236860e-02],
       [6.58089460e-01, 1.79170560e-02, 3.23993470e-01],
       [9.97045930e-01, 2.13479500e-03, 8.19317700e-04],
       [4.48493400e-01, 3.91095500e-01, 1.60411040e-01],
       [3.03473470e-04, 6.61321200e-01, 3.38375300e-01],
       [2.30996560e-05, 9.93781150e-01, 6.19572080e-03],
       [4.22910330e-01, 6.40617330e-04, 5.76449000e-01],
       [3.15853870e-05, 9.26653300e-01, 7.33150800e-02],
       [2.09254750e-04, 8.44463300e-01, 1.55327380e-01],
       [9.98077300e-01, 5.43888900e-04, 1.37882040e-03],
       [9.97045930e-01, 2.13479500e-03, 8.19317700e-04],
       [9.78376850e-05, 9.85774040e-01, 1.41280090e-02],
       [3.38285840e-04, 9.99220850e-01, 4.40816720e-04],
       [6.65449200e-03, 3.43123600e-02, 9.59033130e-01],
       [9.95715100e-01, 1.27100590e-05, 4.27222950e-03],
       [4.39802830e-01, 4.07325300e-01, 1.52871890e-01],
       [3.40289770e-01, 6.18917350e-01, 4.07928640e-02],
       [9.95715100e-01, 1.27100590e-05, 4.27222950e-03],
       [1.30110330e-04, 9.99302740e-01, 5.67199500e-04],
       [8.20366140e-02, 7.28630930e-03, 9.10677100e-01],
       [3.79138220e-05, 5.72281600e-03, 9.94239330e-01],
       [9.90821840e-01, 3.77076940e-04, 8.80115400e-03],
       [6.23981930e-03, 2.29672040e-02, 9.70793000e-01],
       [4.95854350e-01, 1.48356170e-01, 3.55789540e-01],
       [9.95861700e-01, 3.38498010e-03, 7.53380800e-04],
       [9.95861700e-01, 3.38498010e-03, 7.53380800e-04],
       [9.95715100e-01, 1.27100590e-05, 4.27222950e-03],
       [3.12244560e-01, 4.95638000e-01, 1.92117480e-01],
       [4.70416530e-03, 4.67784200e-02, 9.48517400e-01],
       [4.39802830e-01, 4.07325300e-01, 1.52871890e-01],
       [9.89228600e-04, 9.85349100e-01, 1.36615740e-02],
       [9.50966950e-01, 4.99278200e-03, 4.40402070e-02],
       [4.95854350e-01, 1.48356170e-01, 3.55789540e-01],
       [8.42057500e-01, 4.16056540e-04, 1.57526420e-01],
       [3.91226350e-03, 4.54901860e-03, 9.91538700e-01],
       [3.81645300e-02, 9.51415660e-01, 1.04197610e-02],
       [3.87072400e-01, 3.67497530e-01, 2.45430020e-01],
       [3.48167870e-04, 9.93218100e-01, 6.43364760e-03],
       [3.23674620e-01, 1.63317100e-03, 6.74692300e-01],
       [9.95861700e-01, 3.38498010e-03, 7.53380800e-04],
       [8.83825900e-01, 5.51052570e-04, 1.15623070e-01],
       [3.12244560e-01, 4.95638000e-01, 1.92117480e-01],
       [1.23071530e-02, 9.61877500e-01, 2.58152350e-02],
       [9.91628400e-01, 3.95662800e-03, 4.41493100e-03],
       [9.95715100e-01, 1.27100590e-05, 4.27222950e-03],
       [3.52598070e-01, 1.17672620e-01, 5.29729300e-01],
       [5.07674500e-03, 9.02711100e-01, 9.22121600e-02],
       [3.81883930e-04, 1.64207720e-02, 9.83197330e-01],
       [9.98124200e-01, 1.53980530e-03, 3.36043540e-04],
       [3.99136800e-03, 2.32859180e-01, 7.63149440e-01],
       [5.01691900e-02, 2.27139170e-01, 7.22691600e-01],
       [9.95861700e-01, 3.38498010e-03, 7.53380800e-04],
       [4.58183120e-04, 6.37756800e-02, 9.35766100e-01],
       [9.90821840e-01, 3.77076940e-04, 8.80115400e-03],
       [9.97158400e-01, 2.71921540e-03, 1.22415570e-04],
       [3.48167870e-04, 9.93218100e-01, 6.43364760e-03],
       [1.05321930e-02, 3.74105950e-02, 9.52057200e-01],
       [1.28098390e-04, 9.98509000e-01, 1.36293330e-03],
       [1.14252480e-02, 8.32751800e-01, 1.55822920e-01],
       [3.47087600e-01, 1.77749740e-01, 4.75162660e-01],
       [7.76234750e-01, 1.76269780e-02, 2.06138310e-01],
       [9.97158400e-01, 2.71921540e-03, 1.22415570e-04],
       [2.08035670e-02, 7.59782100e-02, 9.03218150e-01],
       [9.97253700e-01, 2.51195950e-03, 2.34374380e-04],
       [4.88145860e-01, 3.15352920e-01, 1.96501240e-01],
       [4.54686030e-04, 3.61883270e-02, 9.63357000e-01],
       [9.98124200e-01, 1.53980530e-03, 3.36043540e-04],
       [7.10966950e-03, 1.81021690e-02, 9.74788200e-01],
       [3.22360800e-02, 1.65606450e-01, 8.02157460e-01],
       [2.47343610e-01, 2.16698080e-01, 5.35958300e-01],
       [3.87072400e-01, 3.67497530e-01, 2.45430020e-01],
       [2.97356860e-04, 9.96192800e-01, 3.50979180e-03],
       [9.96626260e-01, 1.57607890e-03, 1.79763920e-03],
       [1.91803500e-01, 1.80667650e-01, 6.27528900e-01],
       [9.95715100e-01, 1.27100590e-05, 4.27222950e-03],
       [9.95861700e-01, 3.38498010e-03, 7.53380800e-04],
       [3.87072400e-01, 3.67497530e-01, 2.45430020e-01],
       [9.75941200e-01, 1.99411200e-04, 2.38594040e-02],
       [1.55646220e-01, 2.03955530e-01, 6.40398200e-01],
       [5.41608200e-01, 2.80787830e-01, 1.77604000e-01],
       [9.97595500e-01, 1.04990720e-03, 1.35469260e-03],
       [7.25756960e-02, 1.22731210e-01, 8.04693100e-01],
       [8.83825900e-01, 5.51052570e-04, 1.15623070e-01],
       [3.03473470e-04, 6.61321200e-01, 3.38375300e-01],
       [2.66840050e-05, 7.20237750e-03, 9.92770970e-01],
       [2.09254750e-04, 8.44463300e-01, 1.55327380e-01],
       [4.39802830e-01, 4.07325300e-01, 1.52871890e-01]])</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[15]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">## Retrieved from https://github.com/scikit-learn/scikit-learn/issues/3298</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">roc_auc_score</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">LabelBinarizer</span>

<span class="k">def</span> <span class="nf">rocauc_ovo</span><span class="p">(</span><span class="n">truth</span><span class="p">,</span> <span class="n">pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s2">&quot;macro&quot;</span><span class="p">,</span> <span class="n">multi_class</span><span class="o">=</span><span class="s2">&quot;ovo&quot;</span><span class="p">):</span>

    <span class="n">lb</span> <span class="o">=</span> <span class="n">LabelBinarizer</span><span class="p">()</span>
    <span class="n">lb</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">truth</span><span class="p">)</span>

    <span class="n">truth</span> <span class="o">=</span> <span class="n">lb</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">truth</span><span class="p">)</span>   
    
    <span class="k">return</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">truth</span><span class="p">,</span> <span class="n">pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="n">average</span><span class="p">,</span> <span class="n">multi_class</span><span class="o">=</span><span class="n">multi_class</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[22]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">ovo1</span> <span class="o">=</span> <span class="n">rocauc_ovo</span><span class="p">(</span><span class="n">y_test_over</span><span class="p">,</span> <span class="n">y_prob</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s2">&quot;macro&quot;</span><span class="p">,</span> <span class="n">multi_class</span><span class="o">=</span><span class="s2">&quot;ovo&quot;</span><span class="p">)</span>
<span class="n">ovo1</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[22]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>0.9317172746836354</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[16]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">rocauc_ovr</span><span class="p">(</span><span class="n">truth</span><span class="p">,</span> <span class="n">pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s2">&quot;macro&quot;</span><span class="p">,</span> <span class="n">multi_class</span><span class="o">=</span><span class="s2">&quot;ovr&quot;</span><span class="p">):</span>

    <span class="n">lb</span> <span class="o">=</span> <span class="n">LabelBinarizer</span><span class="p">()</span>
    <span class="n">lb</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">truth</span><span class="p">)</span>

    <span class="n">truth</span> <span class="o">=</span> <span class="n">lb</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">truth</span><span class="p">)</span>   

    <span class="k">return</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">truth</span><span class="p">,</span> <span class="n">pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="n">average</span><span class="p">,</span> <span class="n">multi_class</span><span class="o">=</span><span class="n">multi_class</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[24]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">ovr1</span> <span class="o">=</span> <span class="n">rocauc_ovr</span><span class="p">(</span><span class="n">y_test_over</span><span class="p">,</span> <span class="n">y_prob</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s2">&quot;macro&quot;</span><span class="p">,</span> <span class="n">multi_class</span><span class="o">=</span><span class="s2">&quot;ovr&quot;</span><span class="p">)</span>
<span class="n">ovr1</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[24]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>0.9317172746836354</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[25]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># split into train, test data (over)</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="n">X_train_over</span><span class="p">,</span> <span class="n">X_test_over</span><span class="p">,</span> <span class="n">y_train_over</span><span class="p">,</span> <span class="n">y_test_over</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X_over</span><span class="p">,</span> <span class="n">y_over</span><span class="p">,</span>
                                                    <span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.3</span><span class="p">,</span>
                                                    <span class="n">random_state</span><span class="o">=</span><span class="mi">234</span><span class="p">,</span>
                                                    <span class="n">stratify</span><span class="o">=</span><span class="n">y_over</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[26]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dat2</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X_test_over</span><span class="p">[:,</span><span class="mi">0</span><span class="p">])</span>
<span class="n">dat2</span><span class="p">[</span><span class="s1">&#39;test&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">y_test_over</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[27]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dat2</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[27]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>test</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>NRS027</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>CFBRSa07</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>CFBRSa27</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>504</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>CFBREBSa129</td>
      <td>0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>158</th>
      <td>SR3569</td>
      <td>2</td>
    </tr>
    <tr>
      <th>159</th>
      <td>NRS243</td>
      <td>1</td>
    </tr>
    <tr>
      <th>160</th>
      <td>GA48963</td>
      <td>1</td>
    </tr>
    <tr>
      <th>161</th>
      <td>504</td>
      <td>1</td>
    </tr>
    <tr>
      <th>162</th>
      <td>CFBREBSa123</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>163 rows × 2 columns</p>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[28]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">X_train_over</span> <span class="o">=</span> <span class="n">X_train_over</span><span class="p">[:,</span><span class="mi">1</span><span class="p">:]</span>
<span class="n">X_test_over</span> <span class="o">=</span> <span class="n">X_test_over</span><span class="p">[:,</span><span class="mi">1</span><span class="p">:]</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[31]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model1_over2</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">([</span>
    <span class="n">Dense</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="n">X_train_over</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],)),</span>
    <span class="n">Dense</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">),</span>
    <span class="n">Dense</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">),</span>
<span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[32]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model1_over2</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span>
              <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;sparse_categorical_crossentropy&#39;</span><span class="p">,</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[33]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model1_over2</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_over</span><span class="p">,</span> <span class="n">y_train_over</span><span class="p">,</span>
          <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
          <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">X_test_over</span><span class="p">,</span> <span class="n">y_test_over</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Train on 380 samples, validate on 163 samples
Epoch 1/100
380/380 [==============================] - 0s 660us/step - loss: 1.0803 - accuracy: 0.4132 - val_loss: 1.0392 - val_accuracy: 0.4540
Epoch 2/100
380/380 [==============================] - 0s 319us/step - loss: 1.0433 - accuracy: 0.4711 - val_loss: 1.0081 - val_accuracy: 0.4417
Epoch 3/100
380/380 [==============================] - 0s 244us/step - loss: 0.9865 - accuracy: 0.5342 - val_loss: 0.9426 - val_accuracy: 0.5951
Epoch 4/100
380/380 [==============================] - 0s 301us/step - loss: 0.9300 - accuracy: 0.6079 - val_loss: 0.8803 - val_accuracy: 0.6196
Epoch 5/100
380/380 [==============================] - 0s 283us/step - loss: 0.8783 - accuracy: 0.5921 - val_loss: 0.8754 - val_accuracy: 0.6258
Epoch 6/100
380/380 [==============================] - 0s 157us/step - loss: 0.8566 - accuracy: 0.6474 - val_loss: 0.8344 - val_accuracy: 0.6442
Epoch 7/100
380/380 [==============================] - 0s 184us/step - loss: 0.7801 - accuracy: 0.6921 - val_loss: 0.8075 - val_accuracy: 0.6748
Epoch 8/100
380/380 [==============================] - 0s 1ms/step - loss: 0.7422 - accuracy: 0.6763 - val_loss: 0.7779 - val_accuracy: 0.6748
Epoch 9/100
380/380 [==============================] - 0s 221us/step - loss: 0.7119 - accuracy: 0.7079 - val_loss: 0.7477 - val_accuracy: 0.6933
Epoch 10/100
380/380 [==============================] - 0s 438us/step - loss: 0.6775 - accuracy: 0.7105 - val_loss: 0.7362 - val_accuracy: 0.6687
Epoch 11/100
380/380 [==============================] - 0s 219us/step - loss: 0.6697 - accuracy: 0.7053 - val_loss: 0.7176 - val_accuracy: 0.6748
Epoch 12/100
380/380 [==============================] - 0s 504us/step - loss: 0.6284 - accuracy: 0.7211 - val_loss: 0.7014 - val_accuracy: 0.7239
Epoch 13/100
380/380 [==============================] - 0s 655us/step - loss: 0.6007 - accuracy: 0.7395 - val_loss: 0.6798 - val_accuracy: 0.7117
Epoch 14/100
380/380 [==============================] - 0s 461us/step - loss: 0.6048 - accuracy: 0.7342 - val_loss: 0.6609 - val_accuracy: 0.7178
Epoch 15/100
380/380 [==============================] - 0s 218us/step - loss: 0.5995 - accuracy: 0.7421 - val_loss: 0.7303 - val_accuracy: 0.6564
Epoch 16/100
380/380 [==============================] - 0s 205us/step - loss: 0.5585 - accuracy: 0.7737 - val_loss: 0.6588 - val_accuracy: 0.7239
Epoch 17/100
380/380 [==============================] - 0s 218us/step - loss: 0.5296 - accuracy: 0.7789 - val_loss: 0.6233 - val_accuracy: 0.7546
Epoch 18/100
380/380 [==============================] - 0s 236us/step - loss: 0.5116 - accuracy: 0.7737 - val_loss: 0.6227 - val_accuracy: 0.7546
Epoch 19/100
380/380 [==============================] - 0s 266us/step - loss: 0.5040 - accuracy: 0.7632 - val_loss: 0.6037 - val_accuracy: 0.7178
Epoch 20/100
380/380 [==============================] - 0s 243us/step - loss: 0.5198 - accuracy: 0.7579 - val_loss: 0.5996 - val_accuracy: 0.7362
Epoch 21/100
380/380 [==============================] - 0s 177us/step - loss: 0.4721 - accuracy: 0.7816 - val_loss: 0.6022 - val_accuracy: 0.7485
Epoch 22/100
380/380 [==============================] - 0s 392us/step - loss: 0.4928 - accuracy: 0.7605 - val_loss: 0.6187 - val_accuracy: 0.6994
Epoch 23/100
380/380 [==============================] - 0s 202us/step - loss: 0.4877 - accuracy: 0.7816 - val_loss: 0.6023 - val_accuracy: 0.7178
Epoch 24/100
380/380 [==============================] - 0s 225us/step - loss: 0.4573 - accuracy: 0.7789 - val_loss: 0.5886 - val_accuracy: 0.7178
Epoch 25/100
380/380 [==============================] - 0s 257us/step - loss: 0.4343 - accuracy: 0.8079 - val_loss: 0.5928 - val_accuracy: 0.7117
Epoch 26/100
380/380 [==============================] - 0s 214us/step - loss: 0.4745 - accuracy: 0.7895 - val_loss: 0.6144 - val_accuracy: 0.7117
Epoch 27/100
380/380 [==============================] - 0s 206us/step - loss: 0.4648 - accuracy: 0.7947 - val_loss: 0.6176 - val_accuracy: 0.7178
Epoch 28/100
380/380 [==============================] - 0s 238us/step - loss: 0.4222 - accuracy: 0.8105 - val_loss: 0.5233 - val_accuracy: 0.7853
Epoch 29/100
380/380 [==============================] - 0s 406us/step - loss: 0.4027 - accuracy: 0.8105 - val_loss: 0.5347 - val_accuracy: 0.7669
Epoch 30/100
380/380 [==============================] - 0s 184us/step - loss: 0.3929 - accuracy: 0.8263 - val_loss: 0.5175 - val_accuracy: 0.8282
Epoch 31/100
380/380 [==============================] - 0s 493us/step - loss: 0.3904 - accuracy: 0.8026 - val_loss: 0.5145 - val_accuracy: 0.8221
Epoch 32/100
380/380 [==============================] - 0s 262us/step - loss: 0.3844 - accuracy: 0.8342 - val_loss: 0.5205 - val_accuracy: 0.7914
Epoch 33/100
380/380 [==============================] - 0s 287us/step - loss: 0.3910 - accuracy: 0.8237 - val_loss: 0.5838 - val_accuracy: 0.7423
Epoch 34/100
380/380 [==============================] - 0s 237us/step - loss: 0.3715 - accuracy: 0.8342 - val_loss: 0.5291 - val_accuracy: 0.8037
Epoch 35/100
380/380 [==============================] - 0s 226us/step - loss: 0.3600 - accuracy: 0.8658 - val_loss: 0.5039 - val_accuracy: 0.8221
Epoch 36/100
380/380 [==============================] - 0s 211us/step - loss: 0.3731 - accuracy: 0.8237 - val_loss: 0.4903 - val_accuracy: 0.7791
Epoch 37/100
380/380 [==============================] - 0s 257us/step - loss: 0.3430 - accuracy: 0.8632 - val_loss: 0.5151 - val_accuracy: 0.7669
Epoch 38/100
380/380 [==============================] - 0s 288us/step - loss: 0.3576 - accuracy: 0.8500 - val_loss: 0.4801 - val_accuracy: 0.8221
Epoch 39/100
380/380 [==============================] - 0s 296us/step - loss: 0.3433 - accuracy: 0.8447 - val_loss: 0.5054 - val_accuracy: 0.8037
Epoch 40/100
380/380 [==============================] - 0s 200us/step - loss: 0.3666 - accuracy: 0.8289 - val_loss: 0.5237 - val_accuracy: 0.7791
Epoch 41/100
380/380 [==============================] - 0s 785us/step - loss: 0.3793 - accuracy: 0.8342 - val_loss: 0.5471 - val_accuracy: 0.7607
Epoch 42/100
380/380 [==============================] - 0s 435us/step - loss: 0.3328 - accuracy: 0.8474 - val_loss: 0.4774 - val_accuracy: 0.8282
Epoch 43/100
380/380 [==============================] - 0s 313us/step - loss: 0.3378 - accuracy: 0.8474 - val_loss: 0.4804 - val_accuracy: 0.7853
Epoch 44/100
380/380 [==============================] - 0s 227us/step - loss: 0.3613 - accuracy: 0.8342 - val_loss: 0.6120 - val_accuracy: 0.7117
Epoch 45/100
380/380 [==============================] - ETA: 0s - loss: 0.4089 - accuracy: 0.81 - 0s 251us/step - loss: 0.3521 - accuracy: 0.8289 - val_loss: 0.5076 - val_accuracy: 0.8282
Epoch 46/100
380/380 [==============================] - 0s 401us/step - loss: 0.3093 - accuracy: 0.8526 - val_loss: 0.5320 - val_accuracy: 0.7669
Epoch 47/100
380/380 [==============================] - 0s 454us/step - loss: 0.3228 - accuracy: 0.8474 - val_loss: 0.5964 - val_accuracy: 0.7362
Epoch 48/100
380/380 [==============================] - 0s 317us/step - loss: 0.3487 - accuracy: 0.8395 - val_loss: 0.4962 - val_accuracy: 0.7914
Epoch 49/100
380/380 [==============================] - 0s 194us/step - loss: 0.3864 - accuracy: 0.8474 - val_loss: 0.5709 - val_accuracy: 0.7485
Epoch 50/100
380/380 [==============================] - 0s 180us/step - loss: 0.3792 - accuracy: 0.8158 - val_loss: 0.5066 - val_accuracy: 0.7853
Epoch 51/100
380/380 [==============================] - 0s 166us/step - loss: 0.3473 - accuracy: 0.8342 - val_loss: 0.5033 - val_accuracy: 0.7730
Epoch 52/100
380/380 [==============================] - 0s 193us/step - loss: 0.3204 - accuracy: 0.8395 - val_loss: 0.5461 - val_accuracy: 0.7669
Epoch 53/100
380/380 [==============================] - 0s 166us/step - loss: 0.3095 - accuracy: 0.8632 - val_loss: 0.4711 - val_accuracy: 0.8037
Epoch 54/100
380/380 [==============================] - 0s 133us/step - loss: 0.2945 - accuracy: 0.8632 - val_loss: 0.4650 - val_accuracy: 0.8221
Epoch 55/100
380/380 [==============================] - 0s 157us/step - loss: 0.2715 - accuracy: 0.8842 - val_loss: 0.5029 - val_accuracy: 0.8282
Epoch 56/100
380/380 [==============================] - 0s 570us/step - loss: 0.2910 - accuracy: 0.8632 - val_loss: 0.5447 - val_accuracy: 0.7975
Epoch 57/100
380/380 [==============================] - 0s 199us/step - loss: 0.3006 - accuracy: 0.8684 - val_loss: 0.5069 - val_accuracy: 0.8160
Epoch 58/100
380/380 [==============================] - 0s 179us/step - loss: 0.2913 - accuracy: 0.8553 - val_loss: 0.4942 - val_accuracy: 0.7791
Epoch 59/100
380/380 [==============================] - 0s 173us/step - loss: 0.3032 - accuracy: 0.8500 - val_loss: 0.4840 - val_accuracy: 0.8160
Epoch 60/100
380/380 [==============================] - 0s 138us/step - loss: 0.2990 - accuracy: 0.8763 - val_loss: 0.5006 - val_accuracy: 0.8344
Epoch 61/100
380/380 [==============================] - 0s 132us/step - loss: 0.3097 - accuracy: 0.8658 - val_loss: 0.5245 - val_accuracy: 0.8098
Epoch 62/100
380/380 [==============================] - 0s 125us/step - loss: 0.2876 - accuracy: 0.8816 - val_loss: 0.6175 - val_accuracy: 0.7301
Epoch 63/100
380/380 [==============================] - 0s 124us/step - loss: 0.3337 - accuracy: 0.8474 - val_loss: 0.4938 - val_accuracy: 0.8344
Epoch 64/100
380/380 [==============================] - 0s 142us/step - loss: 0.3162 - accuracy: 0.8526 - val_loss: 0.5478 - val_accuracy: 0.8160
Epoch 65/100
380/380 [==============================] - 0s 154us/step - loss: 0.2896 - accuracy: 0.8711 - val_loss: 0.4754 - val_accuracy: 0.8037
Epoch 66/100
380/380 [==============================] - 0s 134us/step - loss: 0.2685 - accuracy: 0.8895 - val_loss: 0.4663 - val_accuracy: 0.8098
Epoch 67/100
380/380 [==============================] - 0s 117us/step - loss: 0.2660 - accuracy: 0.8868 - val_loss: 0.4926 - val_accuracy: 0.8344
Epoch 68/100
380/380 [==============================] - 0s 147us/step - loss: 0.2686 - accuracy: 0.8737 - val_loss: 0.5387 - val_accuracy: 0.7914
Epoch 69/100
380/380 [==============================] - 0s 125us/step - loss: 0.2767 - accuracy: 0.8842 - val_loss: 0.6266 - val_accuracy: 0.7178
Epoch 70/100
380/380 [==============================] - 0s 117us/step - loss: 0.2828 - accuracy: 0.8737 - val_loss: 0.4768 - val_accuracy: 0.7914
Epoch 71/100
380/380 [==============================] - 0s 143us/step - loss: 0.2870 - accuracy: 0.8763 - val_loss: 0.5360 - val_accuracy: 0.7730
Epoch 72/100
380/380 [==============================] - 0s 119us/step - loss: 0.2757 - accuracy: 0.8737 - val_loss: 0.5609 - val_accuracy: 0.7791
Epoch 73/100
380/380 [==============================] - 0s 171us/step - loss: 0.2585 - accuracy: 0.8895 - val_loss: 0.5140 - val_accuracy: 0.8160
Epoch 74/100
380/380 [==============================] - 0s 183us/step - loss: 0.2792 - accuracy: 0.8711 - val_loss: 0.5002 - val_accuracy: 0.8160
Epoch 75/100
380/380 [==============================] - 0s 129us/step - loss: 0.2649 - accuracy: 0.8816 - val_loss: 0.4737 - val_accuracy: 0.8221
Epoch 76/100
380/380 [==============================] - 0s 118us/step - loss: 0.2551 - accuracy: 0.8895 - val_loss: 0.4779 - val_accuracy: 0.8160
Epoch 77/100
380/380 [==============================] - 0s 135us/step - loss: 0.2667 - accuracy: 0.8868 - val_loss: 0.4755 - val_accuracy: 0.8589
Epoch 78/100
380/380 [==============================] - 0s 144us/step - loss: 0.2597 - accuracy: 0.8842 - val_loss: 0.4821 - val_accuracy: 0.8282
Epoch 79/100
380/380 [==============================] - 0s 156us/step - loss: 0.2605 - accuracy: 0.8868 - val_loss: 0.4423 - val_accuracy: 0.8160
Epoch 80/100
380/380 [==============================] - 0s 171us/step - loss: 0.2835 - accuracy: 0.8711 - val_loss: 0.4848 - val_accuracy: 0.7914
Epoch 81/100
380/380 [==============================] - 0s 125us/step - loss: 0.2944 - accuracy: 0.8605 - val_loss: 0.5769 - val_accuracy: 0.8098
Epoch 82/100
380/380 [==============================] - 0s 130us/step - loss: 0.3486 - accuracy: 0.8447 - val_loss: 0.4617 - val_accuracy: 0.8221
Epoch 83/100
380/380 [==============================] - 0s 166us/step - loss: 0.2712 - accuracy: 0.8789 - val_loss: 0.4431 - val_accuracy: 0.8405
Epoch 84/100
380/380 [==============================] - 0s 210us/step - loss: 0.2499 - accuracy: 0.8895 - val_loss: 0.4235 - val_accuracy: 0.8773
Epoch 85/100
380/380 [==============================] - 0s 176us/step - loss: 0.2800 - accuracy: 0.8737 - val_loss: 0.5226 - val_accuracy: 0.8405
Epoch 86/100
380/380 [==============================] - 0s 138us/step - loss: 0.2551 - accuracy: 0.8868 - val_loss: 0.5090 - val_accuracy: 0.8282
Epoch 87/100
380/380 [==============================] - 0s 123us/step - loss: 0.2485 - accuracy: 0.8816 - val_loss: 0.4689 - val_accuracy: 0.8344
Epoch 88/100
380/380 [==============================] - 0s 139us/step - loss: 0.2380 - accuracy: 0.9026 - val_loss: 0.4762 - val_accuracy: 0.8221
Epoch 89/100
380/380 [==============================] - 0s 126us/step - loss: 0.2467 - accuracy: 0.8921 - val_loss: 0.5538 - val_accuracy: 0.7975
Epoch 90/100
380/380 [==============================] - 0s 154us/step - loss: 0.2587 - accuracy: 0.8921 - val_loss: 0.4822 - val_accuracy: 0.8405
Epoch 91/100
380/380 [==============================] - 0s 140us/step - loss: 0.2465 - accuracy: 0.9000 - val_loss: 0.5719 - val_accuracy: 0.7607
Epoch 92/100
380/380 [==============================] - 0s 116us/step - loss: 0.2735 - accuracy: 0.8763 - val_loss: 0.5443 - val_accuracy: 0.7791
Epoch 93/100
380/380 [==============================] - 0s 126us/step - loss: 0.2563 - accuracy: 0.8868 - val_loss: 0.4450 - val_accuracy: 0.8405
Epoch 94/100
380/380 [==============================] - 0s 117us/step - loss: 0.2291 - accuracy: 0.9000 - val_loss: 0.4772 - val_accuracy: 0.7975
Epoch 95/100
380/380 [==============================] - 0s 104us/step - loss: 0.2573 - accuracy: 0.8895 - val_loss: 0.4831 - val_accuracy: 0.8098
Epoch 96/100
380/380 [==============================] - 0s 128us/step - loss: 0.2699 - accuracy: 0.8921 - val_loss: 0.4904 - val_accuracy: 0.8282
Epoch 97/100
380/380 [==============================] - 0s 106us/step - loss: 0.2896 - accuracy: 0.8789 - val_loss: 0.5427 - val_accuracy: 0.7853
Epoch 98/100
380/380 [==============================] - 0s 129us/step - loss: 0.2640 - accuracy: 0.8711 - val_loss: 0.6069 - val_accuracy: 0.7669
Epoch 99/100
380/380 [==============================] - 0s 103us/step - loss: 0.2696 - accuracy: 0.8816 - val_loss: 0.4401 - val_accuracy: 0.8589
Epoch 100/100
380/380 [==============================] - 0s 146us/step - loss: 0.2864 - accuracy: 0.8711 - val_loss: 0.5077 - val_accuracy: 0.8037
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[33]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&lt;keras.callbacks.callbacks.History at 0x1a418ad208&gt;</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[62]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">acc_test_over2</span> <span class="o">=</span> <span class="n">model1_over2</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_test_over</span><span class="p">,</span> <span class="n">y_test_over</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;over-sampling test accuracy: </span><span class="si">%.2f%%</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">acc_test_over2</span><span class="o">*</span><span class="mi">100</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>163/163 [==============================] - 0s 98us/step
over-sampling test accuracy: 84.05%
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[34]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">pred2</span> <span class="o">=</span> <span class="n">model1_over2</span><span class="o">.</span><span class="n">predict_classes</span><span class="p">(</span><span class="n">X_test_over</span><span class="p">)</span>
<span class="n">pred2</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[34]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>array([0, 0, 2, 1, 0, 2, 0, 1, 2, 1, 0, 0, 1, 2, 1, 2, 1, 1, 2, 2, 1, 0,
       1, 0, 2, 0, 1, 0, 1, 0, 0, 0, 0, 2, 1, 0, 2, 1, 0, 0, 0, 0, 2, 1,
       1, 0, 0, 1, 1, 0, 2, 2, 0, 1, 0, 0, 2, 0, 0, 0, 2, 1, 2, 0, 2, 1,
       0, 2, 1, 2, 2, 0, 1, 2, 1, 1, 0, 0, 0, 0, 1, 2, 1, 0, 1, 1, 2, 2,
       0, 0, 2, 0, 1, 0, 0, 1, 0, 2, 2, 0, 0, 0, 1, 0, 1, 2, 0, 2, 1, 0,
       1, 1, 0, 0, 2, 0, 2, 1, 1, 0, 2, 1, 2, 2, 1, 0, 1, 0, 0, 2, 0, 1,
       2, 0, 1, 2, 1, 2, 2, 0, 1, 2, 2, 2, 0, 2, 0, 0, 2, 2, 1, 0, 0, 2,
       1, 1, 2, 2, 2, 1, 1, 1, 0])</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[35]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dat2</span><span class="p">[</span><span class="s1">&#39;pred&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pred2</span>
<span class="n">dat2</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[35]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>test</th>
      <th>pred</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>NRS027</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>CFBRSa07</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>CFBRSa27</td>
      <td>1</td>
      <td>2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>504</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>CFBREBSa129</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>158</th>
      <td>SR3569</td>
      <td>2</td>
      <td>2</td>
    </tr>
    <tr>
      <th>159</th>
      <td>NRS243</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>160</th>
      <td>GA48963</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>161</th>
      <td>504</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>162</th>
      <td>CFBREBSa123</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>163 rows × 3 columns</p>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[36]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">proba2</span> <span class="o">=</span> <span class="n">model1_over2</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test_over</span><span class="p">)</span>
<span class="n">dat_proba2</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">proba2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[37]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dat_proba2</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[37]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>9.988309e-01</td>
      <td>0.000262</td>
      <td>0.000907</td>
    </tr>
    <tr>
      <th>1</th>
      <td>9.803634e-01</td>
      <td>0.000096</td>
      <td>0.019541</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1.662070e-01</td>
      <td>0.187860</td>
      <td>0.645933</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1.041796e-01</td>
      <td>0.556848</td>
      <td>0.338973</td>
    </tr>
    <tr>
      <th>4</th>
      <td>9.980018e-01</td>
      <td>0.000789</td>
      <td>0.001210</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>158</th>
      <td>2.914282e-02</td>
      <td>0.151264</td>
      <td>0.819593</td>
    </tr>
    <tr>
      <th>159</th>
      <td>8.927739e-09</td>
      <td>0.998998</td>
      <td>0.001002</td>
    </tr>
    <tr>
      <th>160</th>
      <td>2.442053e-04</td>
      <td>0.959986</td>
      <td>0.039770</td>
    </tr>
    <tr>
      <th>161</th>
      <td>1.041796e-01</td>
      <td>0.556848</td>
      <td>0.338973</td>
    </tr>
    <tr>
      <th>162</th>
      <td>9.980172e-01</td>
      <td>0.000257</td>
      <td>0.001726</td>
    </tr>
  </tbody>
</table>
<p>163 rows × 3 columns</p>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[38]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dat_proba2</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s2">&quot;/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba2.csv&quot;</span><span class="p">,</span> <span class="n">index</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
         <span class="n">header</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[39]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dat2</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s2">&quot;/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/2p11.csv&quot;</span><span class="p">,</span> <span class="n">index</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
         <span class="n">header</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[66]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">hist1_over2</span> <span class="o">=</span> <span class="n">model1_over2</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_over</span><span class="p">,</span> <span class="n">y_train_over</span><span class="p">,</span>
          <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
          <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">X_test_over</span><span class="p">,</span> <span class="n">y_test_over</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Train on 380 samples, validate on 163 samples
Epoch 1/100
380/380 [==============================] - 0s 167us/step - loss: 0.2394 - accuracy: 0.8868 - val_loss: 0.4799 - val_accuracy: 0.7914
Epoch 2/100
380/380 [==============================] - 0s 156us/step - loss: 0.2582 - accuracy: 0.8895 - val_loss: 0.3973 - val_accuracy: 0.8282
Epoch 3/100
380/380 [==============================] - 0s 163us/step - loss: 0.2531 - accuracy: 0.8763 - val_loss: 0.4499 - val_accuracy: 0.8160
Epoch 4/100
380/380 [==============================] - 0s 146us/step - loss: 0.2202 - accuracy: 0.9079 - val_loss: 0.4652 - val_accuracy: 0.8528
Epoch 5/100
380/380 [==============================] - 0s 129us/step - loss: 0.2367 - accuracy: 0.8947 - val_loss: 0.5372 - val_accuracy: 0.7853
Epoch 6/100
380/380 [==============================] - 0s 124us/step - loss: 0.2371 - accuracy: 0.8947 - val_loss: 0.4480 - val_accuracy: 0.8466
Epoch 7/100
380/380 [==============================] - 0s 132us/step - loss: 0.2126 - accuracy: 0.9158 - val_loss: 0.5062 - val_accuracy: 0.8037
Epoch 8/100
380/380 [==============================] - 0s 118us/step - loss: 0.2251 - accuracy: 0.8947 - val_loss: 0.5272 - val_accuracy: 0.8282
Epoch 9/100
380/380 [==============================] - 0s 123us/step - loss: 0.2204 - accuracy: 0.9000 - val_loss: 0.4475 - val_accuracy: 0.8466
Epoch 10/100
380/380 [==============================] - 0s 123us/step - loss: 0.2559 - accuracy: 0.8868 - val_loss: 0.4470 - val_accuracy: 0.8405
Epoch 11/100
380/380 [==============================] - 0s 125us/step - loss: 0.2141 - accuracy: 0.9132 - val_loss: 0.5035 - val_accuracy: 0.8037
Epoch 12/100
380/380 [==============================] - 0s 132us/step - loss: 0.2371 - accuracy: 0.9000 - val_loss: 0.5288 - val_accuracy: 0.8282
Epoch 13/100
380/380 [==============================] - 0s 137us/step - loss: 0.2643 - accuracy: 0.8842 - val_loss: 0.4861 - val_accuracy: 0.8282
Epoch 14/100
380/380 [==============================] - 0s 123us/step - loss: 0.2396 - accuracy: 0.9026 - val_loss: 0.4837 - val_accuracy: 0.8344
Epoch 15/100
380/380 [==============================] - 0s 119us/step - loss: 0.2176 - accuracy: 0.9053 - val_loss: 0.4710 - val_accuracy: 0.8650
Epoch 16/100
380/380 [==============================] - 0s 133us/step - loss: 0.2100 - accuracy: 0.9026 - val_loss: 0.4825 - val_accuracy: 0.8282
Epoch 17/100
380/380 [==============================] - 0s 116us/step - loss: 0.2284 - accuracy: 0.9053 - val_loss: 0.4821 - val_accuracy: 0.7975
Epoch 18/100
380/380 [==============================] - 0s 113us/step - loss: 0.2221 - accuracy: 0.9000 - val_loss: 0.4779 - val_accuracy: 0.8282
Epoch 19/100
380/380 [==============================] - 0s 114us/step - loss: 0.2350 - accuracy: 0.9000 - val_loss: 0.4246 - val_accuracy: 0.8528
Epoch 20/100
380/380 [==============================] - 0s 125us/step - loss: 0.2825 - accuracy: 0.8737 - val_loss: 0.4453 - val_accuracy: 0.8466
Epoch 21/100
380/380 [==============================] - 0s 180us/step - loss: 0.2250 - accuracy: 0.8974 - val_loss: 0.4092 - val_accuracy: 0.8405
Epoch 22/100
380/380 [==============================] - 0s 155us/step - loss: 0.2404 - accuracy: 0.8974 - val_loss: 0.5049 - val_accuracy: 0.8037
Epoch 23/100
380/380 [==============================] - 0s 148us/step - loss: 0.2909 - accuracy: 0.8553 - val_loss: 0.4647 - val_accuracy: 0.8405
Epoch 24/100
380/380 [==============================] - 0s 121us/step - loss: 0.2352 - accuracy: 0.9053 - val_loss: 0.6026 - val_accuracy: 0.7730
Epoch 25/100
380/380 [==============================] - 0s 115us/step - loss: 0.2299 - accuracy: 0.9000 - val_loss: 0.7141 - val_accuracy: 0.7669
Epoch 26/100
380/380 [==============================] - 0s 113us/step - loss: 0.2498 - accuracy: 0.8868 - val_loss: 0.4992 - val_accuracy: 0.8282
Epoch 27/100
380/380 [==============================] - 0s 115us/step - loss: 0.2249 - accuracy: 0.8868 - val_loss: 0.4144 - val_accuracy: 0.8650
Epoch 28/100
380/380 [==============================] - 0s 117us/step - loss: 0.2324 - accuracy: 0.8947 - val_loss: 0.4446 - val_accuracy: 0.8528
Epoch 29/100
380/380 [==============================] - 0s 115us/step - loss: 0.2474 - accuracy: 0.8789 - val_loss: 0.4056 - val_accuracy: 0.8712
Epoch 30/100
380/380 [==============================] - 0s 123us/step - loss: 0.2454 - accuracy: 0.8974 - val_loss: 0.4291 - val_accuracy: 0.8160
Epoch 31/100
380/380 [==============================] - 0s 141us/step - loss: 0.2195 - accuracy: 0.9132 - val_loss: 0.4473 - val_accuracy: 0.8466
Epoch 32/100
380/380 [==============================] - 0s 129us/step - loss: 0.2125 - accuracy: 0.9132 - val_loss: 0.4533 - val_accuracy: 0.8344
Epoch 33/100
380/380 [==============================] - 0s 155us/step - loss: 0.2125 - accuracy: 0.8947 - val_loss: 0.4723 - val_accuracy: 0.8221
Epoch 34/100
380/380 [==============================] - 0s 198us/step - loss: 0.2386 - accuracy: 0.8921 - val_loss: 0.6155 - val_accuracy: 0.7853
Epoch 35/100
380/380 [==============================] - 0s 149us/step - loss: 0.2473 - accuracy: 0.8868 - val_loss: 0.5822 - val_accuracy: 0.7791
Epoch 36/100
380/380 [==============================] - 0s 130us/step - loss: 0.2683 - accuracy: 0.8711 - val_loss: 0.5608 - val_accuracy: 0.7975
Epoch 37/100
380/380 [==============================] - 0s 119us/step - loss: 0.2752 - accuracy: 0.8632 - val_loss: 0.5886 - val_accuracy: 0.7853
Epoch 38/100
380/380 [==============================] - 0s 111us/step - loss: 0.2869 - accuracy: 0.8737 - val_loss: 0.4855 - val_accuracy: 0.8344
Epoch 39/100
380/380 [==============================] - 0s 110us/step - loss: 0.2945 - accuracy: 0.8842 - val_loss: 0.4390 - val_accuracy: 0.8528
Epoch 40/100
380/380 [==============================] - 0s 105us/step - loss: 0.2710 - accuracy: 0.8947 - val_loss: 0.4109 - val_accuracy: 0.8834
Epoch 41/100
380/380 [==============================] - 0s 118us/step - loss: 0.2137 - accuracy: 0.9079 - val_loss: 0.4644 - val_accuracy: 0.8344
Epoch 42/100
380/380 [==============================] - 0s 113us/step - loss: 0.2179 - accuracy: 0.9026 - val_loss: 0.4276 - val_accuracy: 0.8528
Epoch 43/100
380/380 [==============================] - 0s 116us/step - loss: 0.2214 - accuracy: 0.9026 - val_loss: 0.4771 - val_accuracy: 0.8344
Epoch 44/100
380/380 [==============================] - 0s 112us/step - loss: 0.2084 - accuracy: 0.9053 - val_loss: 0.4300 - val_accuracy: 0.8405
Epoch 45/100
380/380 [==============================] - 0s 128us/step - loss: 0.2051 - accuracy: 0.9079 - val_loss: 0.4231 - val_accuracy: 0.8282
Epoch 46/100
380/380 [==============================] - 0s 175us/step - loss: 0.2435 - accuracy: 0.8868 - val_loss: 0.4568 - val_accuracy: 0.8466
Epoch 47/100
380/380 [==============================] - 0s 181us/step - loss: 0.2382 - accuracy: 0.9000 - val_loss: 0.4415 - val_accuracy: 0.8466
Epoch 48/100
380/380 [==============================] - 0s 166us/step - loss: 0.2381 - accuracy: 0.8789 - val_loss: 0.5237 - val_accuracy: 0.7975
Epoch 49/100
380/380 [==============================] - 0s 281us/step - loss: 0.2696 - accuracy: 0.8921 - val_loss: 0.4773 - val_accuracy: 0.8405
Epoch 50/100
380/380 [==============================] - 0s 169us/step - loss: 0.2538 - accuracy: 0.8737 - val_loss: 0.5924 - val_accuracy: 0.7853
Epoch 51/100
380/380 [==============================] - 0s 155us/step - loss: 0.2424 - accuracy: 0.8789 - val_loss: 0.4321 - val_accuracy: 0.8466
Epoch 52/100
380/380 [==============================] - 0s 159us/step - loss: 0.2358 - accuracy: 0.8947 - val_loss: 0.5938 - val_accuracy: 0.8098
Epoch 53/100
380/380 [==============================] - 0s 183us/step - loss: 0.2163 - accuracy: 0.8974 - val_loss: 0.5168 - val_accuracy: 0.8466
Epoch 54/100
380/380 [==============================] - 0s 149us/step - loss: 0.2655 - accuracy: 0.8816 - val_loss: 0.5386 - val_accuracy: 0.7975
Epoch 55/100
380/380 [==============================] - 0s 184us/step - loss: 0.2399 - accuracy: 0.8868 - val_loss: 0.4637 - val_accuracy: 0.8344
Epoch 56/100
380/380 [==============================] - 0s 764us/step - loss: 0.2121 - accuracy: 0.9237 - val_loss: 0.4380 - val_accuracy: 0.8466
Epoch 57/100
380/380 [==============================] - 0s 209us/step - loss: 0.2115 - accuracy: 0.9053 - val_loss: 0.4603 - val_accuracy: 0.8589
Epoch 58/100
380/380 [==============================] - 0s 145us/step - loss: 0.2130 - accuracy: 0.9026 - val_loss: 0.6357 - val_accuracy: 0.7853
Epoch 59/100
380/380 [==============================] - 0s 158us/step - loss: 0.2138 - accuracy: 0.8974 - val_loss: 0.6300 - val_accuracy: 0.7853
Epoch 60/100
380/380 [==============================] - 0s 140us/step - loss: 0.2422 - accuracy: 0.8947 - val_loss: 0.5397 - val_accuracy: 0.8160
Epoch 61/100
380/380 [==============================] - 0s 125us/step - loss: 0.2665 - accuracy: 0.8737 - val_loss: 0.5049 - val_accuracy: 0.8405
Epoch 62/100
380/380 [==============================] - 0s 119us/step - loss: 0.2467 - accuracy: 0.8842 - val_loss: 0.4940 - val_accuracy: 0.8405
Epoch 63/100
380/380 [==============================] - 0s 114us/step - loss: 0.2294 - accuracy: 0.9053 - val_loss: 0.5363 - val_accuracy: 0.8221
Epoch 64/100
380/380 [==============================] - 0s 116us/step - loss: 0.2222 - accuracy: 0.8895 - val_loss: 0.5756 - val_accuracy: 0.8221
Epoch 65/100
380/380 [==============================] - 0s 391us/step - loss: 0.2484 - accuracy: 0.8816 - val_loss: 0.7215 - val_accuracy: 0.7669
Epoch 66/100
380/380 [==============================] - 0s 181us/step - loss: 0.2379 - accuracy: 0.8974 - val_loss: 0.5441 - val_accuracy: 0.8098
Epoch 67/100
380/380 [==============================] - 0s 151us/step - loss: 0.2063 - accuracy: 0.9158 - val_loss: 0.4314 - val_accuracy: 0.8712
Epoch 68/100
380/380 [==============================] - 0s 132us/step - loss: 0.2031 - accuracy: 0.9132 - val_loss: 0.4624 - val_accuracy: 0.8466
Epoch 69/100
380/380 [==============================] - 0s 148us/step - loss: 0.2147 - accuracy: 0.8974 - val_loss: 0.4274 - val_accuracy: 0.8589
Epoch 70/100
380/380 [==============================] - 0s 149us/step - loss: 0.2062 - accuracy: 0.9079 - val_loss: 0.4146 - val_accuracy: 0.8712
Epoch 71/100
380/380 [==============================] - 0s 125us/step - loss: 0.1952 - accuracy: 0.9079 - val_loss: 0.5920 - val_accuracy: 0.7914
Epoch 72/100
380/380 [==============================] - 0s 125us/step - loss: 0.2440 - accuracy: 0.8921 - val_loss: 0.6160 - val_accuracy: 0.7914
Epoch 73/100
380/380 [==============================] - 0s 120us/step - loss: 0.2385 - accuracy: 0.8921 - val_loss: 0.4402 - val_accuracy: 0.8160
Epoch 74/100
380/380 [==============================] - 0s 119us/step - loss: 0.2388 - accuracy: 0.8842 - val_loss: 0.4414 - val_accuracy: 0.8466
Epoch 75/100
380/380 [==============================] - 0s 120us/step - loss: 0.2039 - accuracy: 0.9132 - val_loss: 0.5513 - val_accuracy: 0.7914
Epoch 76/100
380/380 [==============================] - 0s 126us/step - loss: 0.2005 - accuracy: 0.9000 - val_loss: 0.4799 - val_accuracy: 0.8405
Epoch 77/100
380/380 [==============================] - 0s 125us/step - loss: 0.2009 - accuracy: 0.9132 - val_loss: 0.4492 - val_accuracy: 0.8466
Epoch 78/100
380/380 [==============================] - 0s 116us/step - loss: 0.2055 - accuracy: 0.9079 - val_loss: 0.4507 - val_accuracy: 0.8589
Epoch 79/100
380/380 [==============================] - 0s 121us/step - loss: 0.2025 - accuracy: 0.9184 - val_loss: 0.4816 - val_accuracy: 0.8589
Epoch 80/100
380/380 [==============================] - 0s 114us/step - loss: 0.2093 - accuracy: 0.8974 - val_loss: 0.5673 - val_accuracy: 0.8098
Epoch 81/100
380/380 [==============================] - 0s 110us/step - loss: 0.2455 - accuracy: 0.8816 - val_loss: 0.5233 - val_accuracy: 0.7975
Epoch 82/100
380/380 [==============================] - 0s 117us/step - loss: 0.1983 - accuracy: 0.9132 - val_loss: 0.5303 - val_accuracy: 0.8221
Epoch 83/100
380/380 [==============================] - 0s 183us/step - loss: 0.2407 - accuracy: 0.8921 - val_loss: 0.5450 - val_accuracy: 0.8160
Epoch 84/100
380/380 [==============================] - 0s 255us/step - loss: 0.2210 - accuracy: 0.9079 - val_loss: 0.6142 - val_accuracy: 0.7914
Epoch 85/100
380/380 [==============================] - 0s 246us/step - loss: 0.2262 - accuracy: 0.9026 - val_loss: 0.6459 - val_accuracy: 0.7975
Epoch 86/100
380/380 [==============================] - 0s 636us/step - loss: 0.2151 - accuracy: 0.8895 - val_loss: 0.5582 - val_accuracy: 0.8160
Epoch 87/100
380/380 [==============================] - 0s 261us/step - loss: 0.2262 - accuracy: 0.8921 - val_loss: 0.4754 - val_accuracy: 0.8405
Epoch 88/100
380/380 [==============================] - 0s 244us/step - loss: 0.2049 - accuracy: 0.9105 - val_loss: 0.5323 - val_accuracy: 0.8528
Epoch 89/100
380/380 [==============================] - 0s 258us/step - loss: 0.2180 - accuracy: 0.8974 - val_loss: 0.6748 - val_accuracy: 0.7853
Epoch 90/100
380/380 [==============================] - 0s 208us/step - loss: 0.2200 - accuracy: 0.8974 - val_loss: 0.5498 - val_accuracy: 0.8282
Epoch 91/100
380/380 [==============================] - 0s 186us/step - loss: 0.2109 - accuracy: 0.9105 - val_loss: 0.5921 - val_accuracy: 0.7975
Epoch 92/100
380/380 [==============================] - 0s 200us/step - loss: 0.2159 - accuracy: 0.9026 - val_loss: 0.4979 - val_accuracy: 0.8160
Epoch 93/100
380/380 [==============================] - 0s 160us/step - loss: 0.2173 - accuracy: 0.9053 - val_loss: 0.5624 - val_accuracy: 0.8160
Epoch 94/100
380/380 [==============================] - 0s 143us/step - loss: 0.2334 - accuracy: 0.9000 - val_loss: 0.4613 - val_accuracy: 0.8344
Epoch 95/100
380/380 [==============================] - 0s 301us/step - loss: 0.2000 - accuracy: 0.9184 - val_loss: 0.4505 - val_accuracy: 0.8160
Epoch 96/100
380/380 [==============================] - 0s 265us/step - loss: 0.2370 - accuracy: 0.9026 - val_loss: 0.4200 - val_accuracy: 0.8712
Epoch 97/100
380/380 [==============================] - 0s 161us/step - loss: 0.2232 - accuracy: 0.9026 - val_loss: 0.4207 - val_accuracy: 0.8712
Epoch 98/100
380/380 [==============================] - 0s 167us/step - loss: 0.2149 - accuracy: 0.8974 - val_loss: 0.5488 - val_accuracy: 0.7791
Epoch 99/100
380/380 [==============================] - 0s 177us/step - loss: 0.2240 - accuracy: 0.9026 - val_loss: 0.4381 - val_accuracy: 0.8712
Epoch 100/100
380/380 [==============================] - 0s 198us/step - loss: 0.2355 - accuracy: 0.8974 - val_loss: 0.4457 - val_accuracy: 0.8528
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[67]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;over-sampling train accuracy: </span><span class="si">%.2f%%</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">hist1_over2</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span><span class="o">*</span><span class="mi">100</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>over-sampling train accuracy: 89.66%
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[29]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df_proba2</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_excel</span><span class="p">(</span><span class="s2">&quot;/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_2.xlsx&quot;</span><span class="p">,</span>
                        <span class="n">sheet_name</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                        <span class="n">index_col</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[30]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df_proba2</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[30]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>phage</th>
      <th>strain</th>
      <th>phenotype</th>
      <th>prediction</th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>p002ykpresabs_qual</td>
      <td>NRS148</td>
      <td>2</td>
      <td>2</td>
      <td>0.000056</td>
      <td>1.748042e-03</td>
      <td>9.981960e-01</td>
    </tr>
    <tr>
      <th>1</th>
      <td>p002ykpresabs_qual</td>
      <td>BCH-SA-03</td>
      <td>1</td>
      <td>0</td>
      <td>0.712007</td>
      <td>2.879924e-01</td>
      <td>9.646217e-07</td>
    </tr>
    <tr>
      <th>2</th>
      <td>p002ykpresabs_qual</td>
      <td>NRS218</td>
      <td>1</td>
      <td>1</td>
      <td>0.006222</td>
      <td>9.937732e-01</td>
      <td>4.482882e-06</td>
    </tr>
    <tr>
      <th>3</th>
      <td>p002ykpresabs_qual</td>
      <td>NRS036</td>
      <td>0</td>
      <td>0</td>
      <td>0.882617</td>
      <td>1.173831e-01</td>
      <td>2.310933e-10</td>
    </tr>
    <tr>
      <th>4</th>
      <td>p002ykpresabs_qual</td>
      <td>NRS386</td>
      <td>1</td>
      <td>0</td>
      <td>0.571179</td>
      <td>4.288184e-01</td>
      <td>2.444667e-06</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>4279</th>
      <td>pyopresabsSTCC_qual</td>
      <td>NRS112</td>
      <td>1</td>
      <td>1</td>
      <td>0.001860</td>
      <td>9.979747e-01</td>
      <td>1.653396e-04</td>
    </tr>
    <tr>
      <th>4280</th>
      <td>pyopresabsSTCC_qual</td>
      <td>SR1065</td>
      <td>0</td>
      <td>0</td>
      <td>0.982940</td>
      <td>1.705227e-02</td>
      <td>7.349168e-06</td>
    </tr>
    <tr>
      <th>4281</th>
      <td>pyopresabsSTCC_qual</td>
      <td>NRS203</td>
      <td>0</td>
      <td>0</td>
      <td>0.997093</td>
      <td>1.962516e-03</td>
      <td>9.441347e-04</td>
    </tr>
    <tr>
      <th>4282</th>
      <td>pyopresabsSTCC_qual</td>
      <td>CFBREBSa129</td>
      <td>0</td>
      <td>0</td>
      <td>1.000000</td>
      <td>3.031141e-13</td>
      <td>3.208205e-09</td>
    </tr>
    <tr>
      <th>4283</th>
      <td>pyopresabsSTCC_qual</td>
      <td>CFBRSa25</td>
      <td>0</td>
      <td>0</td>
      <td>0.999833</td>
      <td>1.669456e-04</td>
      <td>4.411099e-08</td>
    </tr>
  </tbody>
</table>
<p>4284 rows × 7 columns</p>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[31]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">y_prob2</span> <span class="o">=</span> <span class="n">df_proba2</span><span class="p">[</span><span class="n">df_proba2</span><span class="p">[</span><span class="s1">&#39;phage&#39;</span><span class="p">]</span><span class="o">==</span><span class="s1">&#39;p11kpresabs_qual&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="o">-</span><span class="mi">3</span><span class="p">:]</span>
<span class="n">y_prob2</span> <span class="o">=</span> <span class="n">y_prob2</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
<span class="n">y_prob2</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[31]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>array([[9.98830850e-01, 2.62073150e-04, 9.07041700e-04],
       [9.80363400e-01, 9.58994000e-05, 1.95406820e-02],
       [1.66207020e-01, 1.87859740e-01, 6.45933300e-01],
       [1.04179610e-01, 5.56847600e-01, 3.38972750e-01],
       [9.98001750e-01, 7.88705100e-04, 1.20958580e-03],
       [4.54445150e-01, 4.22900280e-04, 5.45132000e-01],
       [9.98001750e-01, 7.88705100e-04, 1.20958580e-03],
       [2.70596900e-03, 9.84363260e-01, 1.29307850e-02],
       [1.66207020e-01, 1.87859740e-01, 6.45933300e-01],
       [2.03490440e-05, 9.97040570e-01, 2.93912880e-03],
       [5.37244700e-01, 6.89718700e-03, 4.55858100e-01],
       [9.98131100e-01, 1.85813630e-03, 1.07736480e-05],
       [3.17332680e-04, 9.09443140e-01, 9.02395700e-02],
       [1.18529715e-01, 3.15663730e-01, 5.65806600e-01],
       [1.13068445e-05, 9.97145100e-01, 2.84360500e-03],
       [1.62177330e-04, 4.50017250e-04, 9.99387740e-01],
       [8.73137200e-12, 9.96745100e-01, 3.25487440e-03],
       [6.01116900e-05, 8.42397500e-01, 1.57542290e-01],
       [6.84489500e-02, 8.73421360e-02, 8.44208960e-01],
       [6.84489500e-02, 8.73421360e-02, 8.44208960e-01],
       [2.44205260e-04, 9.59986000e-01, 3.97697760e-02],
       [9.99025700e-01, 7.74160500e-07, 9.73502200e-04],
       [8.71605100e-10, 9.99848100e-01, 1.51887570e-04],
       [9.99025700e-01, 7.74160500e-07, 9.73502200e-04],
       [2.11348250e-02, 3.47904200e-01, 6.30960940e-01],
       [9.60426300e-01, 6.15303500e-04, 3.89584700e-02],
       [2.03490440e-05, 9.97040570e-01, 2.93912880e-03],
       [9.99025700e-01, 7.74160500e-07, 9.73502200e-04],
       [1.34931240e-04, 9.58805300e-01, 4.10596500e-02],
       [7.87458000e-01, 7.14695500e-05, 2.12470590e-01],
       [9.96444500e-01, 1.24083330e-03, 2.31467820e-03],
       [9.58449960e-01, 1.16417460e-04, 4.14336550e-02],
       [9.98830850e-01, 2.62073150e-04, 9.07041700e-04],
       [1.17807240e-06, 5.85506460e-05, 9.99940300e-01],
       [4.60872100e-07, 9.99945400e-01, 5.41252670e-05],
       [9.98830850e-01, 2.62073150e-04, 9.07041700e-04],
       [1.31896830e-03, 5.53216640e-02, 9.43359400e-01],
       [7.65258500e-09, 9.99533400e-01, 4.66646100e-04],
       [9.58449960e-01, 1.16417460e-04, 4.14336550e-02],
       [9.98240350e-01, 1.07768830e-03, 6.81932000e-04],
       [9.58449960e-01, 1.16417460e-04, 4.14336550e-02],
       [9.91184200e-01, 1.38719300e-03, 7.42860460e-03],
       [1.11667580e-03, 1.93277790e-03, 9.96950500e-01],
       [3.93532670e-07, 9.98304370e-01, 1.69524150e-03],
       [5.29372540e-04, 9.99228100e-01, 2.42536190e-04],
       [9.97613200e-01, 5.85867500e-04, 1.80102970e-03],
       [4.83869250e-01, 6.02594300e-02, 4.55871340e-01],
       [1.04179610e-01, 5.56847600e-01, 3.38972750e-01],
       [6.31169000e-05, 9.85080300e-01, 1.48566310e-02],
       [9.96935960e-01, 2.05313650e-03, 1.01083820e-03],
       [1.66207020e-01, 1.87859740e-01, 6.45933300e-01],
       [1.66207020e-01, 1.87859740e-01, 6.45933300e-01],
       [9.98240350e-01, 1.07768830e-03, 6.81932000e-04],
       [6.01116900e-05, 8.42397500e-01, 1.57542290e-01],
       [9.97613200e-01, 5.85867500e-04, 1.80102970e-03],
       [6.07210600e-01, 7.54638100e-02, 3.17325600e-01],
       [1.44003420e-01, 9.82490800e-02, 7.57747600e-01],
       [4.83869250e-01, 6.02594300e-02, 4.55871340e-01],
       [9.96444500e-01, 1.24083330e-03, 2.31467820e-03],
       [9.96444500e-01, 1.24083330e-03, 2.31467820e-03],
       [1.47682340e-01, 3.97330300e-02, 8.12584640e-01],
       [1.34931240e-04, 9.58805300e-01, 4.10596500e-02],
       [1.24168460e-02, 1.97520220e-03, 9.85608000e-01],
       [9.99933240e-01, 3.29131070e-08, 6.67631100e-05],
       [1.87139290e-02, 1.18644240e-02, 9.69421600e-01],
       [9.87651850e-03, 9.87832250e-01, 2.29117700e-03],
       [9.67165470e-01, 3.05452270e-04, 3.25291200e-02],
       [1.66207020e-01, 1.87859740e-01, 6.45933300e-01],
       [1.99936250e-08, 9.99986200e-01, 1.37988650e-05],
       [1.89619700e-06, 3.12276840e-01, 6.87721250e-01],
       [1.65576030e-04, 1.00158080e-02, 9.89818630e-01],
       [9.98001750e-01, 7.88705100e-04, 1.20958580e-03],
       [3.93532670e-07, 9.98304370e-01, 1.69524150e-03],
       [9.83514400e-04, 1.49993280e-03, 9.97516500e-01],
       [4.22131180e-01, 4.74063840e-01, 1.03805020e-01],
       [1.04179610e-01, 5.56847600e-01, 3.38972750e-01],
       [9.42664560e-01, 3.58954360e-04, 5.69765460e-02],
       [9.86639900e-01, 7.07885200e-04, 1.26521530e-02],
       [6.42146800e-01, 2.60484240e-02, 3.31804750e-01],
       [6.31309800e-01, 2.45152400e-01, 1.23537810e-01],
       [4.22131180e-01, 4.74063840e-01, 1.03805020e-01],
       [6.77330930e-03, 1.53581270e-02, 9.77868500e-01],
       [8.73137200e-12, 9.96745100e-01, 3.25487440e-03],
       [6.42146800e-01, 2.60484240e-02, 3.31804750e-01],
       [1.04179610e-01, 5.56847600e-01, 3.38972750e-01],
       [8.73137200e-12, 9.96745100e-01, 3.25487440e-03],
       [1.26837070e-03, 1.41945540e-01, 8.56786130e-01],
       [3.09639160e-01, 1.23723110e-01, 5.66637800e-01],
       [6.42146800e-01, 2.60484240e-02, 3.31804750e-01],
       [9.26623800e-01, 1.06127310e-02, 6.27634100e-02],
       [6.38748800e-03, 1.04548800e-02, 9.83157700e-01],
       [9.98001750e-01, 7.88705100e-04, 1.20958580e-03],
       [1.72307700e-03, 9.97131700e-01, 1.14511620e-03],
       [9.80410300e-01, 6.16867750e-03, 1.34210500e-02],
       [9.99933240e-01, 3.29131070e-08, 6.67631100e-05],
       [5.74862770e-03, 9.80174660e-01, 1.40767800e-02],
       [9.98115900e-01, 3.17456260e-04, 1.56662550e-03],
       [5.86368670e-02, 7.43963340e-03, 9.33923500e-01],
       [1.04413430e-04, 9.47269500e-02, 9.05168650e-01],
       [9.80410300e-01, 6.16867750e-03, 1.34210500e-02],
       [9.96935960e-01, 2.05313650e-03, 1.01083820e-03],
       [9.98830850e-01, 2.62073150e-04, 9.07041700e-04],
       [8.71605100e-10, 9.99848100e-01, 1.51887570e-04],
       [9.98830850e-01, 2.62073150e-04, 9.07041700e-04],
       [8.71605100e-10, 9.99848100e-01, 1.51887570e-04],
       [1.01994730e-02, 9.33576500e-02, 8.96442900e-01],
       [4.52634100e-01, 4.21413900e-01, 1.25952060e-01],
       [2.34992460e-04, 3.89957200e-02, 9.60769240e-01],
       [1.34931240e-04, 9.58805300e-01, 4.10596500e-02],
       [9.98115900e-01, 3.17456260e-04, 1.56662550e-03],
       [1.04327526e-04, 9.99852300e-01, 4.33646100e-05],
       [4.22131180e-01, 4.74063840e-01, 1.03805020e-01],
       [9.80363400e-01, 9.58994000e-05, 1.95406820e-02],
       [9.96935960e-01, 2.05313650e-03, 1.01083820e-03],
       [1.31597430e-02, 1.13902100e-02, 9.75450040e-01],
       [8.27796800e-01, 4.69263530e-04, 1.71733930e-01],
       [5.36063950e-02, 9.63309200e-04, 9.45430300e-01],
       [4.22131180e-01, 4.74063840e-01, 1.03805020e-01],
       [6.59835640e-05, 9.95733300e-01, 4.20065970e-03],
       [9.99025700e-01, 7.74160500e-07, 9.73502200e-04],
       [4.63696640e-02, 9.10691300e-02, 8.62561200e-01],
       [5.29372540e-04, 9.99228100e-01, 2.42536190e-04],
       [6.10941800e-02, 4.37896200e-02, 8.95116150e-01],
       [1.34771140e-02, 9.17032600e-02, 8.94819600e-01],
       [2.44205260e-04, 9.59986000e-01, 3.97697760e-02],
       [9.98830850e-01, 2.62073150e-04, 9.07041700e-04],
       [1.30088750e-04, 7.58737400e-01, 2.41132600e-01],
       [9.88104500e-01, 2.05640140e-04, 1.16898790e-02],
       [9.58449960e-01, 1.16417460e-04, 4.14336550e-02],
       [1.80730480e-02, 5.21887950e-02, 9.29738160e-01],
       [9.91184200e-01, 1.38719300e-03, 7.42860460e-03],
       [4.22131180e-01, 4.74063840e-01, 1.03805020e-01],
       [2.75772950e-05, 3.07482800e-02, 9.69224150e-01],
       [9.98240350e-01, 1.07768830e-03, 6.81932000e-04],
       [7.86014800e-05, 9.52267050e-01, 4.76544050e-02],
       [7.35091340e-02, 8.35171700e-02, 8.42973650e-01],
       [1.31009340e-08, 9.99205900e-01, 7.94165700e-04],
       [1.66207020e-01, 1.87859740e-01, 6.45933300e-01],
       [1.66207020e-01, 1.87859740e-01, 6.45933300e-01],
       [6.42146800e-01, 2.60484240e-02, 3.31804750e-01],
       [1.31009340e-08, 9.99205900e-01, 7.94165700e-04],
       [6.96443070e-03, 2.02022640e-02, 9.72833300e-01],
       [1.66207020e-01, 1.87859740e-01, 6.45933300e-01],
       [1.93570520e-05, 3.63850670e-05, 9.99944200e-01],
       [9.91184200e-01, 1.38719300e-03, 7.42860460e-03],
       [1.14656910e-01, 2.02216970e-01, 6.83126150e-01],
       [9.80410300e-01, 6.16867750e-03, 1.34210500e-02],
       [6.42146800e-01, 2.60484240e-02, 3.31804750e-01],
       [9.73443600e-02, 7.26074700e-02, 8.30048200e-01],
       [6.70234700e-02, 7.55506600e-02, 8.57425870e-01],
       [1.34931240e-04, 9.58805300e-01, 4.10596500e-02],
       [6.51511500e-01, 8.24398600e-04, 3.47664060e-01],
       [9.97613200e-01, 5.85867500e-04, 1.80102970e-03],
       [6.71453870e-03, 1.28850860e-02, 9.80400440e-01],
       [4.16983200e-04, 9.87748800e-01, 1.18341900e-02],
       [3.55407200e-06, 9.97977550e-01, 2.01893370e-03],
       [1.66207020e-01, 1.87859740e-01, 6.45933300e-01],
       [7.07391000e-02, 8.32599600e-02, 8.46000970e-01],
       [2.91428230e-02, 1.51263980e-01, 8.19593250e-01],
       [8.92773900e-09, 9.98998000e-01, 1.00198680e-03],
       [2.44205260e-04, 9.59986000e-01, 3.97697760e-02],
       [1.04179610e-01, 5.56847600e-01, 3.38972750e-01],
       [9.98017200e-01, 2.56792150e-04, 1.72609380e-03]])</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[32]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">ovo2</span> <span class="o">=</span> <span class="n">rocauc_ovo</span><span class="p">(</span><span class="n">y_test_over</span><span class="p">,</span> <span class="n">y_prob2</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s2">&quot;macro&quot;</span><span class="p">,</span> <span class="n">multi_class</span><span class="o">=</span><span class="s2">&quot;ovo&quot;</span><span class="p">)</span>
<span class="n">ovo2</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[32]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>0.9459127462185566</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[33]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">ovr2</span> <span class="o">=</span> <span class="n">rocauc_ovr</span><span class="p">(</span><span class="n">y_test_over</span><span class="p">,</span> <span class="n">y_prob2</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s2">&quot;macro&quot;</span><span class="p">,</span> <span class="n">multi_class</span><span class="o">=</span><span class="s2">&quot;ovr&quot;</span><span class="p">)</span>
<span class="n">ovr2</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[33]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>0.9459127462185566</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[34]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># split into train, test data (over)</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="n">X_train_over</span><span class="p">,</span> <span class="n">X_test_over</span><span class="p">,</span> <span class="n">y_train_over</span><span class="p">,</span> <span class="n">y_test_over</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X_over</span><span class="p">,</span> <span class="n">y_over</span><span class="p">,</span>
                                                    <span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.3</span><span class="p">,</span>
                                                    <span class="n">random_state</span><span class="o">=</span><span class="mi">345</span><span class="p">,</span>
                                                    <span class="n">stratify</span><span class="o">=</span><span class="n">y_over</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[35]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dat3</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X_test_over</span><span class="p">[:,</span><span class="mi">0</span><span class="p">])</span>
<span class="n">dat3</span><span class="p">[</span><span class="s1">&#39;test&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">y_test_over</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[36]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dat3</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[36]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>test</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>NRS149</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>EUH13</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>NRS106</td>
      <td>2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>NRS214</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>CFBREBSa129</td>
      <td>0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>158</th>
      <td>NRS027</td>
      <td>0</td>
    </tr>
    <tr>
      <th>159</th>
      <td>CFBRSa70</td>
      <td>2</td>
    </tr>
    <tr>
      <th>160</th>
      <td>CFBREBSa130</td>
      <td>0</td>
    </tr>
    <tr>
      <th>161</th>
      <td>NRS214</td>
      <td>1</td>
    </tr>
    <tr>
      <th>162</th>
      <td>NRS073</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
<p>163 rows × 2 columns</p>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[37]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">X_train_over</span> <span class="o">=</span> <span class="n">X_train_over</span><span class="p">[:,</span><span class="mi">1</span><span class="p">:]</span>
<span class="n">X_test_over</span> <span class="o">=</span> <span class="n">X_test_over</span><span class="p">[:,</span><span class="mi">1</span><span class="p">:]</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[44]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model1_over3</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">([</span>
    <span class="n">Dense</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="n">X_train_over</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],)),</span>
    <span class="n">Dense</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">),</span>
    <span class="n">Dense</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">),</span>
<span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[45]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model1_over3</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span>
              <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;sparse_categorical_crossentropy&#39;</span><span class="p">,</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[46]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model1_over3</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_over</span><span class="p">,</span> <span class="n">y_train_over</span><span class="p">,</span>
          <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
          <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">X_test_over</span><span class="p">,</span> <span class="n">y_test_over</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Train on 380 samples, validate on 163 samples
Epoch 1/100
380/380 [==============================] - 0s 541us/step - loss: 1.1313 - accuracy: 0.3605 - val_loss: 1.0493 - val_accuracy: 0.4663
Epoch 2/100
380/380 [==============================] - 0s 158us/step - loss: 1.0639 - accuracy: 0.4737 - val_loss: 1.0293 - val_accuracy: 0.4969
Epoch 3/100
380/380 [==============================] - 0s 199us/step - loss: 0.9962 - accuracy: 0.5105 - val_loss: 0.9547 - val_accuracy: 0.5828
Epoch 4/100
380/380 [==============================] - 0s 162us/step - loss: 0.9509 - accuracy: 0.5789 - val_loss: 0.9205 - val_accuracy: 0.5767
Epoch 5/100
380/380 [==============================] - 0s 151us/step - loss: 0.9030 - accuracy: 0.5974 - val_loss: 0.8759 - val_accuracy: 0.6196
Epoch 6/100
380/380 [==============================] - 0s 188us/step - loss: 0.8588 - accuracy: 0.6053 - val_loss: 0.8588 - val_accuracy: 0.6564
Epoch 7/100
380/380 [==============================] - 0s 168us/step - loss: 0.8288 - accuracy: 0.6421 - val_loss: 0.8532 - val_accuracy: 0.6380
Epoch 8/100
380/380 [==============================] - 0s 182us/step - loss: 0.7850 - accuracy: 0.6500 - val_loss: 0.7938 - val_accuracy: 0.7117
Epoch 9/100
380/380 [==============================] - 0s 170us/step - loss: 0.7513 - accuracy: 0.7105 - val_loss: 0.8170 - val_accuracy: 0.6196
Epoch 10/100
380/380 [==============================] - 0s 143us/step - loss: 0.7330 - accuracy: 0.7053 - val_loss: 0.7362 - val_accuracy: 0.7055
Epoch 11/100
380/380 [==============================] - 0s 123us/step - loss: 0.6954 - accuracy: 0.7053 - val_loss: 0.7254 - val_accuracy: 0.7055
Epoch 12/100
380/380 [==============================] - 0s 148us/step - loss: 0.6710 - accuracy: 0.7184 - val_loss: 0.7269 - val_accuracy: 0.6994
Epoch 13/100
380/380 [==============================] - 0s 193us/step - loss: 0.6675 - accuracy: 0.7000 - val_loss: 0.6851 - val_accuracy: 0.7178
Epoch 14/100
380/380 [==============================] - 0s 178us/step - loss: 0.6342 - accuracy: 0.7474 - val_loss: 0.6970 - val_accuracy: 0.7362
Epoch 15/100
380/380 [==============================] - 0s 95us/step - loss: 0.6194 - accuracy: 0.7395 - val_loss: 0.6648 - val_accuracy: 0.7362
Epoch 16/100
380/380 [==============================] - 0s 110us/step - loss: 0.5900 - accuracy: 0.7579 - val_loss: 0.6763 - val_accuracy: 0.7301
Epoch 17/100
380/380 [==============================] - 0s 101us/step - loss: 0.5980 - accuracy: 0.7474 - val_loss: 0.6357 - val_accuracy: 0.7546
Epoch 18/100
380/380 [==============================] - 0s 108us/step - loss: 0.6038 - accuracy: 0.7395 - val_loss: 0.6938 - val_accuracy: 0.6871
Epoch 19/100
380/380 [==============================] - 0s 118us/step - loss: 0.5675 - accuracy: 0.7789 - val_loss: 0.6344 - val_accuracy: 0.7362
Epoch 20/100
380/380 [==============================] - 0s 152us/step - loss: 0.5673 - accuracy: 0.7684 - val_loss: 0.6619 - val_accuracy: 0.6933
Epoch 21/100
380/380 [==============================] - 0s 207us/step - loss: 0.5241 - accuracy: 0.8026 - val_loss: 0.6126 - val_accuracy: 0.7669
Epoch 22/100
380/380 [==============================] - 0s 176us/step - loss: 0.5161 - accuracy: 0.8026 - val_loss: 0.5969 - val_accuracy: 0.7485
Epoch 23/100
380/380 [==============================] - 0s 134us/step - loss: 0.5005 - accuracy: 0.7974 - val_loss: 0.6403 - val_accuracy: 0.7117
Epoch 24/100
380/380 [==============================] - 0s 133us/step - loss: 0.4977 - accuracy: 0.8026 - val_loss: 0.6063 - val_accuracy: 0.7607
Epoch 25/100
380/380 [==============================] - 0s 146us/step - loss: 0.4766 - accuracy: 0.7947 - val_loss: 0.6080 - val_accuracy: 0.7423
Epoch 26/100
380/380 [==============================] - 0s 148us/step - loss: 0.5103 - accuracy: 0.7842 - val_loss: 0.5872 - val_accuracy: 0.7914
Epoch 27/100
380/380 [==============================] - 0s 108us/step - loss: 0.4816 - accuracy: 0.8053 - val_loss: 0.6306 - val_accuracy: 0.7301
Epoch 28/100
380/380 [==============================] - 0s 93us/step - loss: 0.4636 - accuracy: 0.8053 - val_loss: 0.5981 - val_accuracy: 0.7791
Epoch 29/100
380/380 [==============================] - 0s 93us/step - loss: 0.4340 - accuracy: 0.8526 - val_loss: 0.5860 - val_accuracy: 0.7669
Epoch 30/100
380/380 [==============================] - 0s 89us/step - loss: 0.4439 - accuracy: 0.8158 - val_loss: 0.5577 - val_accuracy: 0.7730
Epoch 31/100
380/380 [==============================] - 0s 102us/step - loss: 0.4256 - accuracy: 0.8158 - val_loss: 0.5665 - val_accuracy: 0.8098
Epoch 32/100
380/380 [==============================] - ETA: 0s - loss: 0.4068 - accuracy: 0.90 - 0s 233us/step - loss: 0.4113 - accuracy: 0.8421 - val_loss: 0.5616 - val_accuracy: 0.7914
Epoch 33/100
380/380 [==============================] - 0s 314us/step - loss: 0.4085 - accuracy: 0.8184 - val_loss: 0.6016 - val_accuracy: 0.7485
Epoch 34/100
380/380 [==============================] - 0s 170us/step - loss: 0.4118 - accuracy: 0.8132 - val_loss: 0.5685 - val_accuracy: 0.7914
Epoch 35/100
380/380 [==============================] - 0s 152us/step - loss: 0.3910 - accuracy: 0.8579 - val_loss: 0.5983 - val_accuracy: 0.7853
Epoch 36/100
380/380 [==============================] - 0s 312us/step - loss: 0.3938 - accuracy: 0.8500 - val_loss: 0.5816 - val_accuracy: 0.7791
Epoch 37/100
380/380 [==============================] - 0s 495us/step - loss: 0.3951 - accuracy: 0.8579 - val_loss: 0.5429 - val_accuracy: 0.7975
Epoch 38/100
380/380 [==============================] - 0s 357us/step - loss: 0.3887 - accuracy: 0.8421 - val_loss: 0.5416 - val_accuracy: 0.7975
Epoch 39/100
380/380 [==============================] - 0s 174us/step - loss: 0.3859 - accuracy: 0.8526 - val_loss: 0.6718 - val_accuracy: 0.7301
Epoch 40/100
380/380 [==============================] - 0s 394us/step - loss: 0.3781 - accuracy: 0.8526 - val_loss: 0.5434 - val_accuracy: 0.8098
Epoch 41/100
380/380 [==============================] - 0s 307us/step - loss: 0.3873 - accuracy: 0.8316 - val_loss: 0.6014 - val_accuracy: 0.7546
Epoch 42/100
380/380 [==============================] - 0s 230us/step - loss: 0.3658 - accuracy: 0.8342 - val_loss: 0.5439 - val_accuracy: 0.7853
Epoch 43/100
380/380 [==============================] - 0s 156us/step - loss: 0.3630 - accuracy: 0.8526 - val_loss: 0.5504 - val_accuracy: 0.7975
Epoch 44/100
380/380 [==============================] - 0s 233us/step - loss: 0.3643 - accuracy: 0.8447 - val_loss: 0.5714 - val_accuracy: 0.7975
Epoch 45/100
380/380 [==============================] - 0s 270us/step - loss: 0.3625 - accuracy: 0.8447 - val_loss: 0.5814 - val_accuracy: 0.7791
Epoch 46/100
380/380 [==============================] - 0s 128us/step - loss: 0.3431 - accuracy: 0.8658 - val_loss: 0.5296 - val_accuracy: 0.8037
Epoch 47/100
380/380 [==============================] - 0s 243us/step - loss: 0.3485 - accuracy: 0.8684 - val_loss: 0.5535 - val_accuracy: 0.7975
Epoch 48/100
380/380 [==============================] - 0s 232us/step - loss: 0.3410 - accuracy: 0.8500 - val_loss: 0.7104 - val_accuracy: 0.7117
Epoch 49/100
380/380 [==============================] - 0s 122us/step - loss: 0.3475 - accuracy: 0.8500 - val_loss: 0.5862 - val_accuracy: 0.7791
Epoch 50/100
380/380 [==============================] - 0s 120us/step - loss: 0.3801 - accuracy: 0.8526 - val_loss: 0.6522 - val_accuracy: 0.7669
Epoch 51/100
380/380 [==============================] - 0s 108us/step - loss: 0.3279 - accuracy: 0.8895 - val_loss: 0.5083 - val_accuracy: 0.8098
Epoch 52/100
380/380 [==============================] - 0s 120us/step - loss: 0.3277 - accuracy: 0.8632 - val_loss: 0.5366 - val_accuracy: 0.8098
Epoch 53/100
380/380 [==============================] - 0s 171us/step - loss: 0.3210 - accuracy: 0.8842 - val_loss: 0.5631 - val_accuracy: 0.7975
Epoch 54/100
380/380 [==============================] - 0s 186us/step - loss: 0.3042 - accuracy: 0.8895 - val_loss: 0.5300 - val_accuracy: 0.8098
Epoch 55/100
380/380 [==============================] - 0s 119us/step - loss: 0.3292 - accuracy: 0.8579 - val_loss: 0.5573 - val_accuracy: 0.8098
Epoch 56/100
380/380 [==============================] - 0s 135us/step - loss: 0.3262 - accuracy: 0.8684 - val_loss: 0.5580 - val_accuracy: 0.7975
Epoch 57/100
380/380 [==============================] - 0s 129us/step - loss: 0.3061 - accuracy: 0.8737 - val_loss: 0.5404 - val_accuracy: 0.8037
Epoch 58/100
380/380 [==============================] - 0s 273us/step - loss: 0.3122 - accuracy: 0.8868 - val_loss: 0.5539 - val_accuracy: 0.8037
Epoch 59/100
380/380 [==============================] - 0s 210us/step - loss: 0.3010 - accuracy: 0.8684 - val_loss: 0.5353 - val_accuracy: 0.8098
Epoch 60/100
380/380 [==============================] - 0s 311us/step - loss: 0.2869 - accuracy: 0.8816 - val_loss: 0.5777 - val_accuracy: 0.8221
Epoch 61/100
380/380 [==============================] - 0s 145us/step - loss: 0.2840 - accuracy: 0.8842 - val_loss: 0.5342 - val_accuracy: 0.7975
Epoch 62/100
380/380 [==============================] - 0s 88us/step - loss: 0.2925 - accuracy: 0.8605 - val_loss: 0.5564 - val_accuracy: 0.8037
Epoch 63/100
380/380 [==============================] - 0s 104us/step - loss: 0.2807 - accuracy: 0.8763 - val_loss: 0.5862 - val_accuracy: 0.7669
Epoch 64/100
380/380 [==============================] - 0s 83us/step - loss: 0.3013 - accuracy: 0.8632 - val_loss: 0.6186 - val_accuracy: 0.8098
Epoch 65/100
380/380 [==============================] - 0s 100us/step - loss: 0.2930 - accuracy: 0.8789 - val_loss: 0.5181 - val_accuracy: 0.8098
Epoch 66/100
380/380 [==============================] - 0s 118us/step - loss: 0.2763 - accuracy: 0.9026 - val_loss: 0.5518 - val_accuracy: 0.8282
Epoch 67/100
380/380 [==============================] - 0s 170us/step - loss: 0.2784 - accuracy: 0.8921 - val_loss: 0.5515 - val_accuracy: 0.8160
Epoch 68/100
380/380 [==============================] - 0s 158us/step - loss: 0.2819 - accuracy: 0.8737 - val_loss: 0.5494 - val_accuracy: 0.8098
Epoch 69/100
380/380 [==============================] - 0s 102us/step - loss: 0.2848 - accuracy: 0.8974 - val_loss: 0.5999 - val_accuracy: 0.8221
Epoch 70/100
380/380 [==============================] - 0s 95us/step - loss: 0.2858 - accuracy: 0.8711 - val_loss: 0.5360 - val_accuracy: 0.8098
Epoch 71/100
380/380 [==============================] - 0s 85us/step - loss: 0.3194 - accuracy: 0.8605 - val_loss: 0.6102 - val_accuracy: 0.7975
Epoch 72/100
380/380 [==============================] - 0s 119us/step - loss: 0.2636 - accuracy: 0.8974 - val_loss: 0.5395 - val_accuracy: 0.8037
Epoch 73/100
380/380 [==============================] - 0s 107us/step - loss: 0.2681 - accuracy: 0.8868 - val_loss: 0.5728 - val_accuracy: 0.8098
Epoch 74/100
380/380 [==============================] - 0s 132us/step - loss: 0.2648 - accuracy: 0.8895 - val_loss: 0.5454 - val_accuracy: 0.8221
Epoch 75/100
380/380 [==============================] - 0s 150us/step - loss: 0.2674 - accuracy: 0.8842 - val_loss: 0.5498 - val_accuracy: 0.8037
Epoch 76/100
380/380 [==============================] - 0s 114us/step - loss: 0.2876 - accuracy: 0.8553 - val_loss: 0.6656 - val_accuracy: 0.7791
Epoch 77/100
380/380 [==============================] - 0s 122us/step - loss: 0.2608 - accuracy: 0.8921 - val_loss: 0.5468 - val_accuracy: 0.8221
Epoch 78/100
380/380 [==============================] - 0s 88us/step - loss: 0.2837 - accuracy: 0.8737 - val_loss: 0.5358 - val_accuracy: 0.7853
Epoch 79/100
380/380 [==============================] - 0s 94us/step - loss: 0.3338 - accuracy: 0.8316 - val_loss: 0.7610 - val_accuracy: 0.7546
Epoch 80/100
380/380 [==============================] - 0s 84us/step - loss: 0.3221 - accuracy: 0.8553 - val_loss: 0.6144 - val_accuracy: 0.7975
Epoch 81/100
380/380 [==============================] - 0s 95us/step - loss: 0.2889 - accuracy: 0.8816 - val_loss: 0.5277 - val_accuracy: 0.8098
Epoch 82/100
380/380 [==============================] - 0s 87us/step - loss: 0.2788 - accuracy: 0.8737 - val_loss: 0.5809 - val_accuracy: 0.8037
Epoch 83/100
380/380 [==============================] - 0s 90us/step - loss: 0.2509 - accuracy: 0.9079 - val_loss: 0.5449 - val_accuracy: 0.8282
Epoch 84/100
380/380 [==============================] - 0s 94us/step - loss: 0.2483 - accuracy: 0.9132 - val_loss: 0.5611 - val_accuracy: 0.8160
Epoch 85/100
380/380 [==============================] - 0s 85us/step - loss: 0.2520 - accuracy: 0.9000 - val_loss: 0.5889 - val_accuracy: 0.8098
Epoch 86/100
380/380 [==============================] - 0s 95us/step - loss: 0.2528 - accuracy: 0.8974 - val_loss: 0.5235 - val_accuracy: 0.8221
Epoch 87/100
380/380 [==============================] - 0s 83us/step - loss: 0.2522 - accuracy: 0.8947 - val_loss: 0.5385 - val_accuracy: 0.8282
Epoch 88/100
380/380 [==============================] - 0s 87us/step - loss: 0.2524 - accuracy: 0.9000 - val_loss: 0.6807 - val_accuracy: 0.7975
Epoch 89/100
380/380 [==============================] - 0s 113us/step - loss: 0.2548 - accuracy: 0.8974 - val_loss: 0.5395 - val_accuracy: 0.8221
Epoch 90/100
380/380 [==============================] - 0s 130us/step - loss: 0.2510 - accuracy: 0.9000 - val_loss: 0.5246 - val_accuracy: 0.8344
Epoch 91/100
380/380 [==============================] - 0s 88us/step - loss: 0.2418 - accuracy: 0.9184 - val_loss: 0.5964 - val_accuracy: 0.8098
Epoch 92/100
380/380 [==============================] - 0s 92us/step - loss: 0.2318 - accuracy: 0.9184 - val_loss: 0.5388 - val_accuracy: 0.8282
Epoch 93/100
380/380 [==============================] - 0s 85us/step - loss: 0.2340 - accuracy: 0.9211 - val_loss: 0.6168 - val_accuracy: 0.8037
Epoch 94/100
380/380 [==============================] - 0s 94us/step - loss: 0.2507 - accuracy: 0.8684 - val_loss: 0.6523 - val_accuracy: 0.7669
Epoch 95/100
380/380 [==============================] - 0s 123us/step - loss: 0.2831 - accuracy: 0.8789 - val_loss: 0.5463 - val_accuracy: 0.8221
Epoch 96/100
380/380 [==============================] - 0s 163us/step - loss: 0.2658 - accuracy: 0.8921 - val_loss: 0.5790 - val_accuracy: 0.8221
Epoch 97/100
380/380 [==============================] - 0s 92us/step - loss: 0.2545 - accuracy: 0.9053 - val_loss: 0.6190 - val_accuracy: 0.7975
Epoch 98/100
380/380 [==============================] - 0s 101us/step - loss: 0.2542 - accuracy: 0.8816 - val_loss: 0.5668 - val_accuracy: 0.8160
Epoch 99/100
380/380 [==============================] - 0s 85us/step - loss: 0.2658 - accuracy: 0.8895 - val_loss: 0.7654 - val_accuracy: 0.7669
Epoch 100/100
380/380 [==============================] - 0s 85us/step - loss: 0.2621 - accuracy: 0.8868 - val_loss: 0.5348 - val_accuracy: 0.8282
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[46]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&lt;keras.callbacks.callbacks.History at 0x1a41fec358&gt;</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[91]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">acc_test_over3</span> <span class="o">=</span> <span class="n">model1_over3</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_test_over</span><span class="p">,</span> <span class="n">y_test_over</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;over-sampling test accuracy: </span><span class="si">%.2f%%</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">acc_test_over3</span><span class="o">*</span><span class="mi">100</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>163/163 [==============================] - 0s 102us/step
over-sampling test accuracy: 79.75%
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[47]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">pred3</span> <span class="o">=</span> <span class="n">model1_over3</span><span class="o">.</span><span class="n">predict_classes</span><span class="p">(</span><span class="n">X_test_over</span><span class="p">)</span>
<span class="n">pred3</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[47]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>array([0, 0, 2, 1, 0, 1, 0, 1, 0, 0, 1, 2, 1, 0, 0, 1, 2, 1, 0, 2, 2, 2,
       0, 2, 2, 1, 2, 2, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 2, 0, 1, 1, 1,
       1, 2, 2, 1, 0, 1, 2, 0, 0, 0, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 1, 0,
       0, 0, 0, 0, 0, 1, 2, 0, 0, 1, 0, 2, 0, 0, 0, 2, 2, 2, 2, 0, 0, 1,
       2, 0, 2, 0, 0, 0, 1, 2, 1, 1, 0, 1, 2, 0, 1, 1, 2, 0, 2, 1, 1, 1,
       1, 2, 1, 2, 2, 2, 1, 1, 2, 2, 2, 2, 0, 1, 1, 1, 2, 1, 1, 1, 1, 0,
       1, 2, 0, 2, 0, 0, 0, 2, 1, 0, 1, 0, 1, 1, 0, 0, 0, 2, 0, 2, 1, 0,
       1, 0, 1, 1, 0, 1, 0, 1, 1])</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[48]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dat3</span><span class="p">[</span><span class="s1">&#39;pred&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pred3</span>
<span class="n">dat3</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[48]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>test</th>
      <th>pred</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>NRS149</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>EUH13</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>NRS106</td>
      <td>2</td>
      <td>2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>NRS214</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>CFBREBSa129</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>158</th>
      <td>NRS027</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>159</th>
      <td>CFBRSa70</td>
      <td>2</td>
      <td>1</td>
    </tr>
    <tr>
      <th>160</th>
      <td>CFBREBSa130</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>161</th>
      <td>NRS214</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>162</th>
      <td>NRS073</td>
      <td>1</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
<p>163 rows × 3 columns</p>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[49]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">proba3</span> <span class="o">=</span> <span class="n">model1_over3</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test_over</span><span class="p">)</span>
<span class="n">dat_proba3</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">proba3</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[50]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dat_proba3</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[50]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.981236</td>
      <td>0.001220</td>
      <td>0.017544</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.962963</td>
      <td>0.026475</td>
      <td>0.010562</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.081841</td>
      <td>0.181278</td>
      <td>0.736881</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.002954</td>
      <td>0.968637</td>
      <td>0.028409</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.993843</td>
      <td>0.001009</td>
      <td>0.005148</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>158</th>
      <td>0.994845</td>
      <td>0.001055</td>
      <td>0.004101</td>
    </tr>
    <tr>
      <th>159</th>
      <td>0.049889</td>
      <td>0.561527</td>
      <td>0.388585</td>
    </tr>
    <tr>
      <th>160</th>
      <td>0.604731</td>
      <td>0.000340</td>
      <td>0.394930</td>
    </tr>
    <tr>
      <th>161</th>
      <td>0.002954</td>
      <td>0.968637</td>
      <td>0.028409</td>
    </tr>
    <tr>
      <th>162</th>
      <td>0.000001</td>
      <td>0.999988</td>
      <td>0.000011</td>
    </tr>
  </tbody>
</table>
<p>163 rows × 3 columns</p>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[51]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dat_proba3</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s2">&quot;/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba3.csv&quot;</span><span class="p">,</span> <span class="n">index</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
         <span class="n">header</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[52]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dat3</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s2">&quot;/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/3p11.csv&quot;</span><span class="p">,</span> <span class="n">index</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
         <span class="n">header</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[95]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">hist1_over3</span> <span class="o">=</span> <span class="n">model1_over3</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_over</span><span class="p">,</span> <span class="n">y_train_over</span><span class="p">,</span>
          <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
          <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">X_test_over</span><span class="p">,</span> <span class="n">y_test_over</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Train on 380 samples, validate on 163 samples
Epoch 1/100
380/380 [==============================] - 0s 141us/step - loss: 0.2428 - accuracy: 0.9026 - val_loss: 0.5395 - val_accuracy: 0.7730
Epoch 2/100
380/380 [==============================] - 0s 145us/step - loss: 0.2454 - accuracy: 0.9079 - val_loss: 0.5404 - val_accuracy: 0.8037
Epoch 3/100
380/380 [==============================] - 0s 125us/step - loss: 0.2870 - accuracy: 0.8711 - val_loss: 0.4782 - val_accuracy: 0.8282
Epoch 4/100
380/380 [==============================] - 0s 115us/step - loss: 0.2745 - accuracy: 0.9000 - val_loss: 0.7275 - val_accuracy: 0.7607
Epoch 5/100
380/380 [==============================] - 0s 100us/step - loss: 0.2437 - accuracy: 0.9079 - val_loss: 0.4881 - val_accuracy: 0.8160
Epoch 6/100
380/380 [==============================] - 0s 128us/step - loss: 0.2688 - accuracy: 0.8895 - val_loss: 0.5512 - val_accuracy: 0.8221
Epoch 7/100
380/380 [==============================] - 0s 118us/step - loss: 0.2500 - accuracy: 0.9053 - val_loss: 0.5419 - val_accuracy: 0.7669
Epoch 8/100
380/380 [==============================] - 0s 109us/step - loss: 0.2231 - accuracy: 0.9158 - val_loss: 0.5158 - val_accuracy: 0.8098
Epoch 9/100
380/380 [==============================] - 0s 110us/step - loss: 0.2531 - accuracy: 0.8868 - val_loss: 0.5416 - val_accuracy: 0.8160
Epoch 10/100
380/380 [==============================] - 0s 116us/step - loss: 0.2702 - accuracy: 0.9026 - val_loss: 0.6455 - val_accuracy: 0.7669
Epoch 11/100
380/380 [==============================] - 0s 97us/step - loss: 0.2759 - accuracy: 0.8763 - val_loss: 0.5981 - val_accuracy: 0.7914
Epoch 12/100
380/380 [==============================] - 0s 116us/step - loss: 0.2513 - accuracy: 0.8842 - val_loss: 0.4784 - val_accuracy: 0.8160
Epoch 13/100
380/380 [==============================] - 0s 98us/step - loss: 0.2470 - accuracy: 0.9079 - val_loss: 0.5195 - val_accuracy: 0.8221
Epoch 14/100
380/380 [==============================] - 0s 111us/step - loss: 0.2310 - accuracy: 0.9132 - val_loss: 0.5279 - val_accuracy: 0.8221
Epoch 15/100
380/380 [==============================] - 0s 108us/step - loss: 0.2220 - accuracy: 0.9105 - val_loss: 0.6010 - val_accuracy: 0.7914
Epoch 16/100
380/380 [==============================] - 0s 108us/step - loss: 0.2487 - accuracy: 0.8842 - val_loss: 0.5191 - val_accuracy: 0.8405
Epoch 17/100
380/380 [==============================] - 0s 103us/step - loss: 0.2300 - accuracy: 0.9000 - val_loss: 0.5088 - val_accuracy: 0.8160
Epoch 18/100
380/380 [==============================] - 0s 100us/step - loss: 0.2380 - accuracy: 0.9079 - val_loss: 0.5686 - val_accuracy: 0.8221
Epoch 19/100
380/380 [==============================] - 0s 96us/step - loss: 0.2459 - accuracy: 0.9079 - val_loss: 0.6021 - val_accuracy: 0.7853
Epoch 20/100
380/380 [==============================] - 0s 110us/step - loss: 0.2107 - accuracy: 0.9079 - val_loss: 0.5490 - val_accuracy: 0.8344
Epoch 21/100
380/380 [==============================] - 0s 97us/step - loss: 0.2081 - accuracy: 0.9263 - val_loss: 0.6084 - val_accuracy: 0.7975
Epoch 22/100
380/380 [==============================] - 0s 131us/step - loss: 0.2092 - accuracy: 0.9105 - val_loss: 0.5017 - val_accuracy: 0.8221
Epoch 23/100
380/380 [==============================] - 0s 134us/step - loss: 0.2053 - accuracy: 0.9263 - val_loss: 0.5248 - val_accuracy: 0.8282
Epoch 24/100
380/380 [==============================] - 0s 137us/step - loss: 0.2186 - accuracy: 0.9237 - val_loss: 0.5249 - val_accuracy: 0.7975
Epoch 25/100
380/380 [==============================] - 0s 152us/step - loss: 0.2300 - accuracy: 0.8947 - val_loss: 0.5776 - val_accuracy: 0.7853
Epoch 26/100
380/380 [==============================] - 0s 133us/step - loss: 0.2062 - accuracy: 0.9158 - val_loss: 0.5597 - val_accuracy: 0.8282
Epoch 27/100
380/380 [==============================] - 0s 144us/step - loss: 0.2026 - accuracy: 0.9289 - val_loss: 0.4880 - val_accuracy: 0.8344
Epoch 28/100
380/380 [==============================] - 0s 109us/step - loss: 0.2120 - accuracy: 0.9053 - val_loss: 0.5644 - val_accuracy: 0.8098
Epoch 29/100
380/380 [==============================] - 0s 107us/step - loss: 0.2055 - accuracy: 0.9158 - val_loss: 0.5058 - val_accuracy: 0.8221
Epoch 30/100
380/380 [==============================] - 0s 106us/step - loss: 0.2261 - accuracy: 0.9184 - val_loss: 0.5722 - val_accuracy: 0.8221
Epoch 31/100
380/380 [==============================] - 0s 117us/step - loss: 0.2274 - accuracy: 0.9211 - val_loss: 0.4874 - val_accuracy: 0.8221
Epoch 32/100
380/380 [==============================] - 0s 118us/step - loss: 0.2146 - accuracy: 0.9105 - val_loss: 0.5142 - val_accuracy: 0.8344
Epoch 33/100
380/380 [==============================] - 0s 106us/step - loss: 0.2205 - accuracy: 0.9000 - val_loss: 0.5023 - val_accuracy: 0.8098
Epoch 34/100
380/380 [==============================] - 0s 115us/step - loss: 0.2430 - accuracy: 0.8895 - val_loss: 0.5126 - val_accuracy: 0.8344
Epoch 35/100
380/380 [==============================] - 0s 122us/step - loss: 0.2049 - accuracy: 0.9132 - val_loss: 0.6640 - val_accuracy: 0.7730
Epoch 36/100
380/380 [==============================] - 0s 143us/step - loss: 0.2071 - accuracy: 0.9237 - val_loss: 0.4985 - val_accuracy: 0.8098
Epoch 37/100
380/380 [==============================] - 0s 144us/step - loss: 0.2443 - accuracy: 0.8895 - val_loss: 0.5267 - val_accuracy: 0.8282
Epoch 38/100
380/380 [==============================] - 0s 157us/step - loss: 0.2483 - accuracy: 0.8921 - val_loss: 0.7171 - val_accuracy: 0.7607
Epoch 39/100
380/380 [==============================] - 0s 115us/step - loss: 0.2231 - accuracy: 0.8974 - val_loss: 0.5436 - val_accuracy: 0.8282
Epoch 40/100
380/380 [==============================] - 0s 108us/step - loss: 0.2079 - accuracy: 0.9211 - val_loss: 0.4848 - val_accuracy: 0.8221
Epoch 41/100
380/380 [==============================] - 0s 129us/step - loss: 0.2703 - accuracy: 0.8947 - val_loss: 0.7570 - val_accuracy: 0.7853
Epoch 42/100
380/380 [==============================] - 0s 129us/step - loss: 0.2400 - accuracy: 0.8816 - val_loss: 0.6771 - val_accuracy: 0.7791
Epoch 43/100
380/380 [==============================] - 0s 138us/step - loss: 0.2182 - accuracy: 0.8974 - val_loss: 0.6133 - val_accuracy: 0.7853
Epoch 44/100
380/380 [==============================] - 0s 136us/step - loss: 0.2357 - accuracy: 0.8789 - val_loss: 0.4910 - val_accuracy: 0.8160
Epoch 45/100
380/380 [==============================] - 0s 138us/step - loss: 0.2494 - accuracy: 0.8895 - val_loss: 0.6722 - val_accuracy: 0.7791
Epoch 46/100
380/380 [==============================] - 0s 129us/step - loss: 0.2379 - accuracy: 0.8974 - val_loss: 0.6154 - val_accuracy: 0.7914
Epoch 47/100
380/380 [==============================] - 0s 111us/step - loss: 0.2428 - accuracy: 0.8921 - val_loss: 0.5264 - val_accuracy: 0.8160
Epoch 48/100
380/380 [==============================] - 0s 112us/step - loss: 0.2136 - accuracy: 0.9158 - val_loss: 0.5697 - val_accuracy: 0.7730
Epoch 49/100
380/380 [==============================] - 0s 111us/step - loss: 0.2169 - accuracy: 0.9132 - val_loss: 0.5732 - val_accuracy: 0.8221
Epoch 50/100
380/380 [==============================] - 0s 100us/step - loss: 0.2214 - accuracy: 0.9105 - val_loss: 0.4955 - val_accuracy: 0.8160
Epoch 51/100
380/380 [==============================] - 0s 108us/step - loss: 0.2138 - accuracy: 0.9132 - val_loss: 0.5213 - val_accuracy: 0.8098
Epoch 52/100
380/380 [==============================] - 0s 96us/step - loss: 0.2058 - accuracy: 0.9211 - val_loss: 0.5678 - val_accuracy: 0.8037
Epoch 53/100
380/380 [==============================] - 0s 96us/step - loss: 0.2238 - accuracy: 0.9079 - val_loss: 0.5252 - val_accuracy: 0.8405
Epoch 54/100
380/380 [==============================] - 0s 105us/step - loss: 0.2102 - accuracy: 0.9158 - val_loss: 0.5087 - val_accuracy: 0.8405
Epoch 55/100
380/380 [==============================] - 0s 110us/step - loss: 0.1970 - accuracy: 0.9237 - val_loss: 0.5683 - val_accuracy: 0.8098
Epoch 56/100
380/380 [==============================] - 0s 100us/step - loss: 0.1995 - accuracy: 0.9158 - val_loss: 0.6309 - val_accuracy: 0.7914
Epoch 57/100
380/380 [==============================] - 0s 113us/step - loss: 0.2014 - accuracy: 0.9237 - val_loss: 0.5644 - val_accuracy: 0.8160
Epoch 58/100
380/380 [==============================] - 0s 107us/step - loss: 0.1995 - accuracy: 0.9158 - val_loss: 0.4985 - val_accuracy: 0.8405
Epoch 59/100
380/380 [==============================] - 0s 208us/step - loss: 0.2088 - accuracy: 0.9158 - val_loss: 0.5300 - val_accuracy: 0.8160
Epoch 60/100
380/380 [==============================] - 0s 277us/step - loss: 0.1820 - accuracy: 0.9289 - val_loss: 0.5319 - val_accuracy: 0.8221
Epoch 61/100
380/380 [==============================] - 0s 174us/step - loss: 0.1868 - accuracy: 0.9184 - val_loss: 0.5584 - val_accuracy: 0.8160
Epoch 62/100
380/380 [==============================] - 0s 140us/step - loss: 0.1852 - accuracy: 0.9263 - val_loss: 0.6746 - val_accuracy: 0.7914
Epoch 63/100
380/380 [==============================] - 0s 134us/step - loss: 0.2174 - accuracy: 0.9053 - val_loss: 0.4792 - val_accuracy: 0.8282
Epoch 64/100
380/380 [==============================] - 0s 130us/step - loss: 0.2071 - accuracy: 0.9053 - val_loss: 0.5569 - val_accuracy: 0.8037
Epoch 65/100
380/380 [==============================] - 0s 158us/step - loss: 0.1946 - accuracy: 0.9158 - val_loss: 0.5606 - val_accuracy: 0.7853
Epoch 66/100
380/380 [==============================] - 0s 151us/step - loss: 0.1947 - accuracy: 0.9158 - val_loss: 0.6499 - val_accuracy: 0.7914
Epoch 67/100
380/380 [==============================] - 0s 144us/step - loss: 0.1949 - accuracy: 0.9184 - val_loss: 0.5342 - val_accuracy: 0.8282
Epoch 68/100
380/380 [==============================] - 0s 138us/step - loss: 0.1776 - accuracy: 0.9316 - val_loss: 0.5690 - val_accuracy: 0.7975
Epoch 69/100
380/380 [==============================] - 0s 561us/step - loss: 0.1807 - accuracy: 0.9289 - val_loss: 0.6458 - val_accuracy: 0.7914
Epoch 70/100
380/380 [==============================] - 0s 177us/step - loss: 0.1949 - accuracy: 0.9184 - val_loss: 0.5242 - val_accuracy: 0.8344
Epoch 71/100
380/380 [==============================] - 0s 163us/step - loss: 0.1796 - accuracy: 0.9184 - val_loss: 0.5394 - val_accuracy: 0.7975
Epoch 72/100
380/380 [==============================] - 0s 214us/step - loss: 0.1788 - accuracy: 0.9237 - val_loss: 0.5904 - val_accuracy: 0.8037
Epoch 73/100
380/380 [==============================] - 0s 123us/step - loss: 0.1784 - accuracy: 0.9237 - val_loss: 0.5616 - val_accuracy: 0.7975
Epoch 74/100
380/380 [==============================] - 0s 147us/step - loss: 0.1760 - accuracy: 0.9263 - val_loss: 0.6139 - val_accuracy: 0.8037
Epoch 75/100
380/380 [==============================] - 0s 452us/step - loss: 0.1746 - accuracy: 0.9263 - val_loss: 0.5084 - val_accuracy: 0.8405
Epoch 76/100
380/380 [==============================] - 0s 151us/step - loss: 0.1783 - accuracy: 0.9237 - val_loss: 0.5957 - val_accuracy: 0.8098
Epoch 77/100
380/380 [==============================] - 0s 221us/step - loss: 0.1822 - accuracy: 0.9184 - val_loss: 0.6698 - val_accuracy: 0.7914
Epoch 78/100
380/380 [==============================] - 0s 183us/step - loss: 0.1825 - accuracy: 0.9289 - val_loss: 0.5864 - val_accuracy: 0.7975
Epoch 79/100
380/380 [==============================] - 0s 125us/step - loss: 0.1985 - accuracy: 0.9158 - val_loss: 0.5377 - val_accuracy: 0.8098
Epoch 80/100
380/380 [==============================] - 0s 147us/step - loss: 0.1877 - accuracy: 0.9237 - val_loss: 0.5877 - val_accuracy: 0.8037
Epoch 81/100
380/380 [==============================] - 0s 113us/step - loss: 0.1834 - accuracy: 0.9263 - val_loss: 0.5292 - val_accuracy: 0.8221
Epoch 82/100
380/380 [==============================] - 0s 120us/step - loss: 0.2290 - accuracy: 0.9000 - val_loss: 0.5385 - val_accuracy: 0.8037
Epoch 83/100
380/380 [==============================] - 0s 113us/step - loss: 0.1847 - accuracy: 0.9158 - val_loss: 0.5340 - val_accuracy: 0.8282
Epoch 84/100
380/380 [==============================] - 0s 120us/step - loss: 0.1724 - accuracy: 0.9263 - val_loss: 0.5625 - val_accuracy: 0.8098
Epoch 85/100
380/380 [==============================] - 0s 118us/step - loss: 0.1736 - accuracy: 0.9237 - val_loss: 0.5761 - val_accuracy: 0.7914
Epoch 86/100
380/380 [==============================] - 0s 113us/step - loss: 0.1723 - accuracy: 0.9237 - val_loss: 0.5464 - val_accuracy: 0.8282
Epoch 87/100
380/380 [==============================] - 0s 119us/step - loss: 0.1837 - accuracy: 0.9263 - val_loss: 0.5642 - val_accuracy: 0.8098
Epoch 88/100
380/380 [==============================] - 0s 126us/step - loss: 0.1701 - accuracy: 0.9211 - val_loss: 0.5450 - val_accuracy: 0.8221
Epoch 89/100
380/380 [==============================] - 0s 117us/step - loss: 0.1778 - accuracy: 0.9184 - val_loss: 0.5646 - val_accuracy: 0.8160
Epoch 90/100
380/380 [==============================] - 0s 101us/step - loss: 0.1775 - accuracy: 0.9237 - val_loss: 0.5472 - val_accuracy: 0.7975
Epoch 91/100
380/380 [==============================] - 0s 100us/step - loss: 0.2248 - accuracy: 0.9105 - val_loss: 0.6617 - val_accuracy: 0.7730
Epoch 92/100
380/380 [==============================] - 0s 102us/step - loss: 0.2236 - accuracy: 0.9000 - val_loss: 0.7008 - val_accuracy: 0.7791
Epoch 93/100
380/380 [==============================] - 0s 122us/step - loss: 0.2463 - accuracy: 0.8947 - val_loss: 0.8642 - val_accuracy: 0.7669
Epoch 94/100
380/380 [==============================] - 0s 281us/step - loss: 0.2584 - accuracy: 0.8895 - val_loss: 0.5563 - val_accuracy: 0.8282
Epoch 95/100
380/380 [==============================] - 0s 155us/step - loss: 0.2678 - accuracy: 0.8921 - val_loss: 0.7550 - val_accuracy: 0.7791
Epoch 96/100
380/380 [==============================] - 0s 228us/step - loss: 0.2000 - accuracy: 0.9158 - val_loss: 0.5206 - val_accuracy: 0.8037
Epoch 97/100
380/380 [==============================] - 0s 178us/step - loss: 0.1975 - accuracy: 0.9158 - val_loss: 0.6069 - val_accuracy: 0.7853
Epoch 98/100
380/380 [==============================] - 0s 298us/step - loss: 0.2020 - accuracy: 0.9263 - val_loss: 0.6831 - val_accuracy: 0.7853
Epoch 99/100
380/380 [==============================] - 0s 226us/step - loss: 0.2116 - accuracy: 0.9158 - val_loss: 0.6016 - val_accuracy: 0.7730
Epoch 100/100
380/380 [==============================] - 0s 174us/step - loss: 0.1925 - accuracy: 0.9158 - val_loss: 0.5555 - val_accuracy: 0.8282
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[96]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;over-sampling train accuracy: </span><span class="si">%.2f%%</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">hist1_over3</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span><span class="o">*</span><span class="mi">100</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>over-sampling train accuracy: 91.06%
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[38]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df_proba3</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_excel</span><span class="p">(</span><span class="s2">&quot;/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_2.xlsx&quot;</span><span class="p">,</span>
                        <span class="n">sheet_name</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                        <span class="n">index_col</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[39]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df_proba3</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[39]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>phage</th>
      <th>strain</th>
      <th>phenotype</th>
      <th>prediction</th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>p002ykpresabs_qual</td>
      <td>NRS109</td>
      <td>2</td>
      <td>2</td>
      <td>0.004477</td>
      <td>0.013518</td>
      <td>9.820048e-01</td>
    </tr>
    <tr>
      <th>1</th>
      <td>p002ykpresabs_qual</td>
      <td>NRS109</td>
      <td>2</td>
      <td>2</td>
      <td>0.004477</td>
      <td>0.013518</td>
      <td>9.820048e-01</td>
    </tr>
    <tr>
      <th>2</th>
      <td>p002ykpresabs_qual</td>
      <td>NRS222</td>
      <td>0</td>
      <td>0</td>
      <td>0.851725</td>
      <td>0.148269</td>
      <td>5.980786e-06</td>
    </tr>
    <tr>
      <th>3</th>
      <td>p002ykpresabs_qual</td>
      <td>NRS109</td>
      <td>2</td>
      <td>2</td>
      <td>0.004477</td>
      <td>0.013518</td>
      <td>9.820048e-01</td>
    </tr>
    <tr>
      <th>4</th>
      <td>p002ykpresabs_qual</td>
      <td>GA50245</td>
      <td>0</td>
      <td>0</td>
      <td>0.812055</td>
      <td>0.187945</td>
      <td>1.161034e-07</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>4279</th>
      <td>pyopresabsSTCC_qual</td>
      <td>NRS255</td>
      <td>2</td>
      <td>2</td>
      <td>0.000633</td>
      <td>0.000928</td>
      <td>9.984396e-01</td>
    </tr>
    <tr>
      <th>4280</th>
      <td>pyopresabsSTCC_qual</td>
      <td>NRS255</td>
      <td>2</td>
      <td>2</td>
      <td>0.000633</td>
      <td>0.000928</td>
      <td>9.984396e-01</td>
    </tr>
    <tr>
      <th>4281</th>
      <td>pyopresabsSTCC_qual</td>
      <td>NRS266</td>
      <td>1</td>
      <td>1</td>
      <td>0.025932</td>
      <td>0.974061</td>
      <td>7.323514e-06</td>
    </tr>
    <tr>
      <th>4282</th>
      <td>pyopresabsSTCC_qual</td>
      <td>NRS001</td>
      <td>1</td>
      <td>1</td>
      <td>0.000597</td>
      <td>0.999403</td>
      <td>3.675362e-10</td>
    </tr>
    <tr>
      <th>4283</th>
      <td>pyopresabsSTCC_qual</td>
      <td>NRS112</td>
      <td>1</td>
      <td>1</td>
      <td>0.000537</td>
      <td>0.999452</td>
      <td>1.168620e-05</td>
    </tr>
  </tbody>
</table>
<p>4284 rows × 7 columns</p>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[40]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">y_prob3</span> <span class="o">=</span> <span class="n">df_proba3</span><span class="p">[</span><span class="n">df_proba3</span><span class="p">[</span><span class="s1">&#39;phage&#39;</span><span class="p">]</span><span class="o">==</span><span class="s1">&#39;p11kpresabs_qual&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="o">-</span><span class="mi">3</span><span class="p">:]</span>
<span class="n">y_prob3</span> <span class="o">=</span> <span class="n">y_prob3</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
<span class="n">y_prob3</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[40]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>array([[9.81236200e-01, 1.22012330e-03, 1.75436550e-02],
       [9.62963040e-01, 2.64746080e-02, 1.05623360e-02],
       [8.18407300e-02, 1.81278270e-01, 7.36881000e-01],
       [2.95371170e-03, 9.68637300e-01, 2.84089970e-02],
       [9.93843440e-01, 1.00909660e-03, 5.14757540e-03],
       [7.45568350e-02, 5.57530100e-01, 3.67913040e-01],
       [9.94844700e-01, 1.05456050e-03, 4.10082750e-03],
       [3.73867120e-01, 4.66225770e-01, 1.59907090e-01],
       [9.85071540e-01, 3.30949840e-04, 1.45975140e-02],
       [8.27075360e-01, 1.41998840e-01, 3.09256760e-02],
       [9.76711700e-05, 9.79777400e-01, 2.01249220e-02],
       [3.42044800e-03, 3.69428730e-02, 9.59636600e-01],
       [8.05964600e-06, 9.47391100e-01, 5.26008460e-02],
       [5.21736600e-01, 6.87568750e-05, 4.78194650e-01],
       [9.97449100e-01, 2.44725570e-03, 1.03546710e-04],
       [3.02320430e-04, 7.54676160e-01, 2.45021580e-01],
       [2.14490390e-02, 2.85164740e-01, 6.93386200e-01],
       [3.73867120e-01, 4.66225770e-01, 1.59907090e-01],
       [9.87966950e-01, 1.09561726e-04, 1.19235330e-02],
       [5.79909130e-04, 5.79829560e-03, 9.93621770e-01],
       [2.79708340e-02, 2.79058720e-01, 6.92970450e-01],
       [1.54716950e-04, 2.27386020e-04, 9.99617800e-01],
       [6.04730600e-01, 3.39667870e-04, 3.94929680e-01],
       [6.81320670e-06, 2.29672580e-03, 9.97696460e-01],
       [6.87440950e-03, 4.04255800e-02, 9.52699960e-01],
       [5.22418800e-04, 9.99437750e-01, 3.97507500e-05],
       [6.14738300e-02, 2.02005680e-01, 7.36520470e-01],
       [5.04502400e-02, 3.16939860e-01, 6.32609960e-01],
       [9.79945540e-01, 1.70872350e-03, 1.83457320e-02],
       [9.94844700e-01, 1.05456050e-03, 4.10082750e-03],
       [1.59610510e-02, 8.89831500e-01, 9.42073900e-02],
       [7.55483900e-08, 9.99994640e-01, 5.28717650e-06],
       [2.97125520e-05, 9.99117900e-01, 8.52407300e-04],
       [7.45568350e-02, 5.57530100e-01, 3.67913040e-01],
       [5.24348600e-01, 2.94795660e-03, 4.72703430e-01],
       [4.42046080e-06, 9.99941800e-01, 5.37750020e-05],
       [9.93334400e-02, 7.89868060e-01, 1.10798430e-01],
       [8.76194050e-03, 5.52790050e-01, 4.38447920e-01],
       [1.59610510e-02, 8.89831500e-01, 9.42073900e-02],
       [1.36655360e-06, 4.91495600e-04, 9.99507200e-01],
       [9.94844700e-01, 1.05456050e-03, 4.10082750e-03],
       [3.79382600e-09, 9.99944570e-01, 5.54100330e-05],
       [7.55483900e-08, 9.99994640e-01, 5.28717650e-06],
       [1.35017940e-06, 9.99987600e-01, 1.10657860e-05],
       [7.26002200e-04, 8.30869140e-01, 1.68404770e-01],
       [1.56641630e-01, 2.69335980e-05, 8.43331460e-01],
       [5.70498230e-04, 3.03855040e-02, 9.69044000e-01],
       [7.45568350e-02, 5.57530100e-01, 3.67913040e-01],
       [9.78881360e-01, 9.31118300e-03, 1.18074670e-02],
       [3.73867120e-01, 4.66225770e-01, 1.59907090e-01],
       [5.75232840e-02, 2.61812300e-01, 6.80664360e-01],
       [9.88765800e-01, 3.46275900e-03, 7.77139100e-03],
       [9.79945540e-01, 1.70872350e-03, 1.83457320e-02],
       [9.79945540e-01, 1.70872350e-03, 1.83457320e-02],
       [1.79321300e-03, 2.11075340e-01, 7.87131500e-01],
       [3.73867120e-01, 4.66225770e-01, 1.59907090e-01],
       [2.49920560e-02, 1.54116230e-01, 8.20891740e-01],
       [4.98889200e-02, 5.61526540e-01, 3.88584520e-01],
       [1.34187480e-03, 2.22748610e-02, 9.76383300e-01],
       [4.42046080e-06, 9.99941800e-01, 5.37750020e-05],
       [5.13787600e-02, 1.39009320e-04, 9.48482200e-01],
       [4.67339940e-02, 7.15650900e-01, 2.37615100e-01],
       [2.21026000e-01, 2.74992440e-01, 5.03981600e-01],
       [1.22539180e-04, 9.99789660e-01, 8.77846100e-05],
       [7.55483900e-08, 9.99994640e-01, 5.28717650e-06],
       [7.45882500e-01, 3.77125940e-05, 2.54079800e-01],
       [7.45882500e-01, 3.77125940e-05, 2.54079800e-01],
       [7.44356160e-01, 3.26998400e-02, 2.22943930e-01],
       [9.88765800e-01, 3.46275900e-03, 7.77139100e-03],
       [5.06057260e-01, 4.78503970e-01, 1.54386840e-02],
       [9.92014350e-01, 2.77132500e-03, 5.21436330e-03],
       [3.73867120e-01, 4.66225770e-01, 1.59907090e-01],
       [5.11862750e-06, 4.42474340e-03, 9.95570100e-01],
       [7.45882500e-01, 3.77125940e-05, 2.54079800e-01],
       [9.99184550e-01, 2.50102540e-04, 5.65336100e-04],
       [2.25533200e-04, 9.99751150e-01, 2.33866270e-05],
       [9.77160450e-01, 7.45015630e-06, 2.28321240e-02],
       [3.63013920e-01, 1.19216435e-01, 5.17769700e-01],
       [9.87966950e-01, 1.09561726e-04, 1.19235330e-02],
       [9.88765800e-01, 3.46275900e-03, 7.77139100e-03],
       [9.43072100e-01, 6.50033350e-03, 5.04276700e-02],
       [1.86284180e-02, 4.81564200e-01, 4.99807300e-01],
       [4.25905050e-05, 2.45567560e-04, 9.99711800e-01],
       [8.91754100e-05, 1.47147440e-04, 9.99763670e-01],
       [1.10295900e-03, 2.26502180e-02, 9.76246830e-01],
       [8.27075360e-01, 1.41998840e-01, 3.09256760e-02],
       [8.27075360e-01, 1.41998840e-01, 3.09256760e-02],
       [1.69027670e-04, 9.88974330e-01, 1.08565740e-02],
       [1.93968990e-05, 4.99546100e-04, 9.99481140e-01],
       [9.99184550e-01, 2.50102540e-04, 5.65336100e-04],
       [2.21026000e-01, 2.74992440e-01, 5.03981600e-01],
       [9.81236200e-01, 1.22012330e-03, 1.75436550e-02],
       [9.98023870e-01, 3.71173460e-04, 1.60494330e-03],
       [9.79945540e-01, 1.70872350e-03, 1.83457320e-02],
       [3.73867120e-01, 4.66225770e-01, 1.59907090e-01],
       [3.65426600e-02, 2.90819050e-01, 6.72638300e-01],
       [1.06690780e-02, 9.86122600e-01, 3.20832080e-03],
       [7.55444000e-02, 5.53449150e-01, 3.71006430e-01],
       [8.90378200e-01, 1.15939790e-03, 1.08462475e-01],
       [7.45568350e-02, 5.57530100e-01, 3.67913040e-01],
       [5.01059660e-05, 6.69475370e-03, 9.93255140e-01],
       [9.94844700e-01, 1.05456050e-03, 4.10082750e-03],
       [9.76711700e-05, 9.79777400e-01, 2.01249220e-02],
       [9.16402000e-04, 6.33841600e-01, 3.65242060e-01],
       [1.41367690e-02, 1.40899870e-01, 8.44963400e-01],
       [9.94844700e-01, 1.05456050e-03, 4.10082750e-03],
       [5.47951960e-04, 6.50308650e-02, 9.34421200e-01],
       [5.22418800e-04, 9.99437750e-01, 3.97507500e-05],
       [2.25533200e-04, 9.99751150e-01, 2.33866270e-05],
       [8.71316900e-05, 9.91592900e-01, 8.32001800e-03],
       [7.45568350e-02, 5.57530100e-01, 3.67913040e-01],
       [9.01310000e-03, 2.05381350e-01, 7.85605550e-01],
       [7.45568350e-02, 5.57530100e-01, 3.67913040e-01],
       [3.63013920e-01, 1.19216435e-01, 5.17769700e-01],
       [3.65633400e-07, 5.70126100e-04, 9.99429500e-01],
       [5.81633470e-05, 1.15177936e-04, 9.99826700e-01],
       [7.45568350e-02, 5.57530100e-01, 3.67913040e-01],
       [5.02582900e-05, 9.83248000e-01, 1.67017000e-02],
       [3.65426600e-02, 2.90819050e-01, 6.72638300e-01],
       [1.30276130e-01, 2.66853540e-01, 6.02870350e-01],
       [1.07645760e-06, 3.42535800e-04, 9.99656440e-01],
       [1.47590500e-04, 1.97800700e-01, 8.02051660e-01],
       [9.97449100e-01, 2.44725570e-03, 1.03546710e-04],
       [1.16763210e-01, 8.80879160e-01, 2.35754460e-03],
       [1.59610510e-02, 8.89831500e-01, 9.42073900e-02],
       [1.35017940e-06, 9.99987600e-01, 1.10657860e-05],
       [9.69751330e-04, 5.59727250e-04, 9.98470500e-01],
       [7.45568350e-02, 5.57530100e-01, 3.67913040e-01],
       [2.97125520e-05, 9.99117900e-01, 8.52407300e-04],
       [4.42046080e-06, 9.99941800e-01, 5.37750020e-05],
       [3.79382600e-09, 9.99944570e-01, 5.54100330e-05],
       [8.27075360e-01, 1.41998840e-01, 3.09256760e-02],
       [1.69027670e-04, 9.88974330e-01, 1.08565740e-02],
       [4.31642800e-02, 3.05622160e-01, 6.51213500e-01],
       [9.62963040e-01, 2.64746080e-02, 1.05623360e-02],
       [3.40219960e-03, 7.22367200e-02, 9.24361050e-01],
       [9.62963040e-01, 2.64746080e-02, 1.05623360e-02],
       [9.81236200e-01, 1.22012330e-03, 1.75436550e-02],
       [9.55751200e-01, 6.81941240e-05, 4.41805240e-02],
       [5.83016200e-08, 1.46095860e-04, 9.99853850e-01],
       [1.06690780e-02, 9.86122600e-01, 3.20832080e-03],
       [9.55751200e-01, 6.81941240e-05, 4.41805240e-02],
       [4.98889200e-02, 5.61526540e-01, 3.88584520e-01],
       [9.97449100e-01, 2.44725570e-03, 1.03546710e-04],
       [3.73867120e-01, 4.66225770e-01, 1.59907090e-01],
       [4.42046080e-06, 9.99941800e-01, 5.37750020e-05],
       [9.99184550e-01, 2.50102540e-04, 5.65336100e-04],
       [9.88765800e-01, 3.46275900e-03, 7.77139100e-03],
       [9.97697200e-01, 4.88592160e-05, 2.25396360e-03],
       [1.28499960e-02, 1.46083860e-01, 8.41066200e-01],
       [9.81236200e-01, 1.22012330e-03, 1.75436550e-02],
       [3.63013920e-01, 1.19216435e-01, 5.17769700e-01],
       [1.39683800e-05, 9.90862370e-01, 9.12367800e-03],
       [9.92014350e-01, 2.77132500e-03, 5.21436330e-03],
       [9.76711700e-05, 9.79777400e-01, 2.01249220e-02],
       [9.87966950e-01, 1.09561726e-04, 1.19235330e-02],
       [2.95371170e-03, 9.68637300e-01, 2.84089970e-02],
       [2.99938060e-02, 9.28063400e-01, 4.19428600e-02],
       [9.94844700e-01, 1.05456050e-03, 4.10082750e-03],
       [4.98889200e-02, 5.61526540e-01, 3.88584520e-01],
       [6.04730600e-01, 3.39667870e-04, 3.94929680e-01],
       [2.95371170e-03, 9.68637300e-01, 2.84089970e-02],
       [1.35017940e-06, 9.99987600e-01, 1.10657860e-05]])</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[41]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">ovo3</span> <span class="o">=</span> <span class="n">rocauc_ovo</span><span class="p">(</span><span class="n">y_test_over</span><span class="p">,</span> <span class="n">y_prob3</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s2">&quot;macro&quot;</span><span class="p">,</span> <span class="n">multi_class</span><span class="o">=</span><span class="s2">&quot;ovo&quot;</span><span class="p">)</span>
<span class="n">ovo3</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[41]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>0.9394065527857577</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[42]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">ovr3</span> <span class="o">=</span> <span class="n">rocauc_ovr</span><span class="p">(</span><span class="n">y_test_over</span><span class="p">,</span> <span class="n">y_prob3</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s2">&quot;macro&quot;</span><span class="p">,</span> <span class="n">multi_class</span><span class="o">=</span><span class="s2">&quot;ovr&quot;</span><span class="p">)</span>
<span class="n">ovr3</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[42]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>0.9394065527857577</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[43]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># split into train, test data (over)</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="n">X_train_over</span><span class="p">,</span> <span class="n">X_test_over</span><span class="p">,</span> <span class="n">y_train_over</span><span class="p">,</span> <span class="n">y_test_over</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X_over</span><span class="p">,</span> <span class="n">y_over</span><span class="p">,</span>
                                                    <span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.3</span><span class="p">,</span>
                                                    <span class="n">random_state</span><span class="o">=</span><span class="mi">456</span><span class="p">,</span>
                                                    <span class="n">stratify</span><span class="o">=</span><span class="n">y_over</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[44]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dat4</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X_test_over</span><span class="p">[:,</span><span class="mi">0</span><span class="p">])</span>
<span class="n">dat4</span><span class="p">[</span><span class="s1">&#39;test&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">y_test_over</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[45]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dat4</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[45]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>test</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>SR2852</td>
      <td>2</td>
    </tr>
    <tr>
      <th>1</th>
      <td>CFBREBSa138</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>BCH-SA-12</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>EUH13</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>EUH13</td>
      <td>0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>158</th>
      <td>NRS036</td>
      <td>1</td>
    </tr>
    <tr>
      <th>159</th>
      <td>CA105</td>
      <td>1</td>
    </tr>
    <tr>
      <th>160</th>
      <td>CFBRSa51</td>
      <td>1</td>
    </tr>
    <tr>
      <th>161</th>
      <td>NRS102</td>
      <td>1</td>
    </tr>
    <tr>
      <th>162</th>
      <td>NRS189</td>
      <td>2</td>
    </tr>
  </tbody>
</table>
<p>163 rows × 2 columns</p>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[46]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">X_train_over</span> <span class="o">=</span> <span class="n">X_train_over</span><span class="p">[:,</span><span class="mi">1</span><span class="p">:]</span>
<span class="n">X_test_over</span> <span class="o">=</span> <span class="n">X_test_over</span><span class="p">[:,</span><span class="mi">1</span><span class="p">:]</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[57]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model1_over4</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">([</span>
    <span class="n">Dense</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="n">X_train_over</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],)),</span>
    <span class="n">Dense</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">),</span>
    <span class="n">Dense</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">),</span>
<span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[58]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model1_over4</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span>
              <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;sparse_categorical_crossentropy&#39;</span><span class="p">,</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[59]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model1_over4</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_over</span><span class="p">,</span> <span class="n">y_train_over</span><span class="p">,</span>
          <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
          <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">X_test_over</span><span class="p">,</span> <span class="n">y_test_over</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Train on 380 samples, validate on 163 samples
Epoch 1/100
380/380 [==============================] - 0s 744us/step - loss: 1.1390 - accuracy: 0.3684 - val_loss: 1.0621 - val_accuracy: 0.4847
Epoch 2/100
380/380 [==============================] - 0s 184us/step - loss: 1.0336 - accuracy: 0.4658 - val_loss: 1.0125 - val_accuracy: 0.5644
Epoch 3/100
380/380 [==============================] - 0s 157us/step - loss: 0.9844 - accuracy: 0.5711 - val_loss: 0.9786 - val_accuracy: 0.5828
Epoch 4/100
380/380 [==============================] - 0s 186us/step - loss: 0.9369 - accuracy: 0.6158 - val_loss: 0.9575 - val_accuracy: 0.5890
Epoch 5/100
380/380 [==============================] - 0s 200us/step - loss: 0.8896 - accuracy: 0.6158 - val_loss: 0.9384 - val_accuracy: 0.5583
Epoch 6/100
380/380 [==============================] - 0s 220us/step - loss: 0.8499 - accuracy: 0.6763 - val_loss: 0.8763 - val_accuracy: 0.6135
Epoch 7/100
380/380 [==============================] - 0s 213us/step - loss: 0.8050 - accuracy: 0.6974 - val_loss: 0.9141 - val_accuracy: 0.5644
Epoch 8/100
380/380 [==============================] - 0s 241us/step - loss: 0.8496 - accuracy: 0.6368 - val_loss: 0.9375 - val_accuracy: 0.5706
Epoch 9/100
380/380 [==============================] - 0s 204us/step - loss: 0.7652 - accuracy: 0.6868 - val_loss: 0.8422 - val_accuracy: 0.6503
Epoch 10/100
380/380 [==============================] - 0s 151us/step - loss: 0.7905 - accuracy: 0.6737 - val_loss: 0.8260 - val_accuracy: 0.6196
Epoch 11/100
380/380 [==============================] - 0s 128us/step - loss: 0.7078 - accuracy: 0.7211 - val_loss: 0.7615 - val_accuracy: 0.6503
Epoch 12/100
380/380 [==============================] - 0s 131us/step - loss: 0.6846 - accuracy: 0.7421 - val_loss: 0.7659 - val_accuracy: 0.6380
Epoch 13/100
380/380 [==============================] - 0s 296us/step - loss: 0.6556 - accuracy: 0.7263 - val_loss: 0.7212 - val_accuracy: 0.6810
Epoch 14/100
380/380 [==============================] - 0s 225us/step - loss: 0.6275 - accuracy: 0.7474 - val_loss: 0.7238 - val_accuracy: 0.6748
Epoch 15/100
380/380 [==============================] - 0s 155us/step - loss: 0.6430 - accuracy: 0.7421 - val_loss: 0.7364 - val_accuracy: 0.6626
Epoch 16/100
380/380 [==============================] - 0s 315us/step - loss: 0.6555 - accuracy: 0.7289 - val_loss: 0.7194 - val_accuracy: 0.6135
Epoch 17/100
380/380 [==============================] - 0s 230us/step - loss: 0.5956 - accuracy: 0.7526 - val_loss: 0.7354 - val_accuracy: 0.6319
Epoch 18/100
380/380 [==============================] - 0s 170us/step - loss: 0.5823 - accuracy: 0.7632 - val_loss: 0.6745 - val_accuracy: 0.7178
Epoch 19/100
380/380 [==============================] - 0s 264us/step - loss: 0.5429 - accuracy: 0.7684 - val_loss: 0.7419 - val_accuracy: 0.6626
Epoch 20/100
380/380 [==============================] - 0s 184us/step - loss: 0.5918 - accuracy: 0.7526 - val_loss: 0.7361 - val_accuracy: 0.6687
Epoch 21/100
380/380 [==============================] - 0s 118us/step - loss: 0.5832 - accuracy: 0.7632 - val_loss: 0.7018 - val_accuracy: 0.6626
Epoch 22/100
380/380 [==============================] - 0s 107us/step - loss: 0.5149 - accuracy: 0.7711 - val_loss: 0.6779 - val_accuracy: 0.6564
Epoch 23/100
380/380 [==============================] - 0s 106us/step - loss: 0.4852 - accuracy: 0.7895 - val_loss: 0.6015 - val_accuracy: 0.7362
Epoch 24/100
380/380 [==============================] - 0s 107us/step - loss: 0.4841 - accuracy: 0.7737 - val_loss: 0.5856 - val_accuracy: 0.7055
Epoch 25/100
380/380 [==============================] - 0s 135us/step - loss: 0.4644 - accuracy: 0.8079 - val_loss: 0.6014 - val_accuracy: 0.6994
Epoch 26/100
380/380 [==============================] - 0s 476us/step - loss: 0.4861 - accuracy: 0.7711 - val_loss: 0.7035 - val_accuracy: 0.6442
Epoch 27/100
380/380 [==============================] - 0s 252us/step - loss: 0.4544 - accuracy: 0.8263 - val_loss: 0.5691 - val_accuracy: 0.7423
Epoch 28/100
380/380 [==============================] - 0s 307us/step - loss: 0.4190 - accuracy: 0.8289 - val_loss: 0.5668 - val_accuracy: 0.7055
Epoch 29/100
380/380 [==============================] - 0s 223us/step - loss: 0.4335 - accuracy: 0.8105 - val_loss: 0.5919 - val_accuracy: 0.7301
Epoch 30/100
380/380 [==============================] - 0s 287us/step - loss: 0.4152 - accuracy: 0.8395 - val_loss: 0.5414 - val_accuracy: 0.7730
Epoch 31/100
380/380 [==============================] - 0s 260us/step - loss: 0.4133 - accuracy: 0.8132 - val_loss: 0.5685 - val_accuracy: 0.7546
Epoch 32/100
380/380 [==============================] - 0s 306us/step - loss: 0.4873 - accuracy: 0.7711 - val_loss: 0.5815 - val_accuracy: 0.7791
Epoch 33/100
380/380 [==============================] - 0s 271us/step - loss: 0.4431 - accuracy: 0.7974 - val_loss: 0.5391 - val_accuracy: 0.7791
Epoch 34/100
380/380 [==============================] - 0s 280us/step - loss: 0.4297 - accuracy: 0.8158 - val_loss: 0.6443 - val_accuracy: 0.6687
Epoch 35/100
380/380 [==============================] - 0s 231us/step - loss: 0.3899 - accuracy: 0.8474 - val_loss: 0.5120 - val_accuracy: 0.7975
Epoch 36/100
380/380 [==============================] - 0s 141us/step - loss: 0.3593 - accuracy: 0.8500 - val_loss: 0.5094 - val_accuracy: 0.7669
Epoch 37/100
380/380 [==============================] - 0s 125us/step - loss: 0.3516 - accuracy: 0.8605 - val_loss: 0.5109 - val_accuracy: 0.7055
Epoch 38/100
380/380 [==============================] - 0s 113us/step - loss: 0.3697 - accuracy: 0.8474 - val_loss: 0.5060 - val_accuracy: 0.7485
Epoch 39/100
380/380 [==============================] - 0s 137us/step - loss: 0.4080 - accuracy: 0.8289 - val_loss: 0.5184 - val_accuracy: 0.7669
Epoch 40/100
380/380 [==============================] - 0s 138us/step - loss: 0.4060 - accuracy: 0.8421 - val_loss: 0.6231 - val_accuracy: 0.7178
Epoch 41/100
380/380 [==============================] - 0s 214us/step - loss: 0.4292 - accuracy: 0.8132 - val_loss: 0.5366 - val_accuracy: 0.7117
Epoch 42/100
380/380 [==============================] - 0s 310us/step - loss: 0.3352 - accuracy: 0.8789 - val_loss: 0.4765 - val_accuracy: 0.7730
Epoch 43/100
380/380 [==============================] - 0s 188us/step - loss: 0.3366 - accuracy: 0.8474 - val_loss: 0.4873 - val_accuracy: 0.7485
Epoch 44/100
380/380 [==============================] - 0s 248us/step - loss: 0.3290 - accuracy: 0.8632 - val_loss: 0.4794 - val_accuracy: 0.7791
Epoch 45/100
380/380 [==============================] - 0s 316us/step - loss: 0.3216 - accuracy: 0.8789 - val_loss: 0.4957 - val_accuracy: 0.7791
Epoch 46/100
380/380 [==============================] - 0s 238us/step - loss: 0.3198 - accuracy: 0.8526 - val_loss: 0.5149 - val_accuracy: 0.7853
Epoch 47/100
380/380 [==============================] - 0s 119us/step - loss: 0.3526 - accuracy: 0.8342 - val_loss: 0.5075 - val_accuracy: 0.7791
Epoch 48/100
380/380 [==============================] - 0s 127us/step - loss: 0.3195 - accuracy: 0.8632 - val_loss: 0.4788 - val_accuracy: 0.7423
Epoch 49/100
380/380 [==============================] - 0s 105us/step - loss: 0.2999 - accuracy: 0.8974 - val_loss: 0.4775 - val_accuracy: 0.8098
Epoch 50/100
380/380 [==============================] - 0s 110us/step - loss: 0.3017 - accuracy: 0.8763 - val_loss: 0.5345 - val_accuracy: 0.7607
Epoch 51/100
380/380 [==============================] - 0s 113us/step - loss: 0.3172 - accuracy: 0.8474 - val_loss: 0.4800 - val_accuracy: 0.7791
Epoch 52/100
380/380 [==============================] - 0s 107us/step - loss: 0.2941 - accuracy: 0.8658 - val_loss: 0.5431 - val_accuracy: 0.7730
Epoch 53/100
380/380 [==============================] - 0s 109us/step - loss: 0.3183 - accuracy: 0.8816 - val_loss: 0.5407 - val_accuracy: 0.7546
Epoch 54/100
380/380 [==============================] - 0s 113us/step - loss: 0.3400 - accuracy: 0.8368 - val_loss: 0.4993 - val_accuracy: 0.7914
Epoch 55/100
380/380 [==============================] - 0s 207us/step - loss: 0.3144 - accuracy: 0.8526 - val_loss: 0.5208 - val_accuracy: 0.7546
Epoch 56/100
380/380 [==============================] - 0s 286us/step - loss: 0.3075 - accuracy: 0.8763 - val_loss: 0.4725 - val_accuracy: 0.7669
Epoch 57/100
380/380 [==============================] - 0s 292us/step - loss: 0.2889 - accuracy: 0.8658 - val_loss: 0.5009 - val_accuracy: 0.7914
Epoch 58/100
380/380 [==============================] - 0s 118us/step - loss: 0.2783 - accuracy: 0.8868 - val_loss: 0.4951 - val_accuracy: 0.8037
Epoch 59/100
380/380 [==============================] - 0s 123us/step - loss: 0.2764 - accuracy: 0.9026 - val_loss: 0.4766 - val_accuracy: 0.7791
Epoch 60/100
380/380 [==============================] - 0s 112us/step - loss: 0.2723 - accuracy: 0.8658 - val_loss: 0.4632 - val_accuracy: 0.7791
Epoch 61/100
380/380 [==============================] - 0s 116us/step - loss: 0.2678 - accuracy: 0.8895 - val_loss: 0.4743 - val_accuracy: 0.8098
Epoch 62/100
380/380 [==============================] - 0s 171us/step - loss: 0.2639 - accuracy: 0.8868 - val_loss: 0.5162 - val_accuracy: 0.7730
Epoch 63/100
380/380 [==============================] - 0s 170us/step - loss: 0.2671 - accuracy: 0.8789 - val_loss: 0.5445 - val_accuracy: 0.7791
Epoch 64/100
380/380 [==============================] - 0s 153us/step - loss: 0.2706 - accuracy: 0.8921 - val_loss: 0.4849 - val_accuracy: 0.7914
Epoch 65/100
380/380 [==============================] - 0s 130us/step - loss: 0.2539 - accuracy: 0.8947 - val_loss: 0.4684 - val_accuracy: 0.8282
Epoch 66/100
380/380 [==============================] - 0s 116us/step - loss: 0.2723 - accuracy: 0.8816 - val_loss: 0.4850 - val_accuracy: 0.7546
Epoch 67/100
380/380 [==============================] - 0s 128us/step - loss: 0.2650 - accuracy: 0.8895 - val_loss: 0.4668 - val_accuracy: 0.7730
Epoch 68/100
380/380 [==============================] - 0s 159us/step - loss: 0.2875 - accuracy: 0.8789 - val_loss: 0.5222 - val_accuracy: 0.7607
Epoch 69/100
380/380 [==============================] - 0s 170us/step - loss: 0.2604 - accuracy: 0.8921 - val_loss: 0.4663 - val_accuracy: 0.7791
Epoch 70/100
380/380 [==============================] - 0s 162us/step - loss: 0.2689 - accuracy: 0.8737 - val_loss: 0.4467 - val_accuracy: 0.8160
Epoch 71/100
380/380 [==============================] - 0s 123us/step - loss: 0.2635 - accuracy: 0.8711 - val_loss: 0.4622 - val_accuracy: 0.8098
Epoch 72/100
380/380 [==============================] - 0s 111us/step - loss: 0.2449 - accuracy: 0.9053 - val_loss: 0.4543 - val_accuracy: 0.7975
Epoch 73/100
380/380 [==============================] - 0s 110us/step - loss: 0.2586 - accuracy: 0.9053 - val_loss: 0.5184 - val_accuracy: 0.7301
Epoch 74/100
380/380 [==============================] - 0s 116us/step - loss: 0.2680 - accuracy: 0.9026 - val_loss: 0.4525 - val_accuracy: 0.7853
Epoch 75/100
380/380 [==============================] - 0s 102us/step - loss: 0.2528 - accuracy: 0.8921 - val_loss: 0.4948 - val_accuracy: 0.7914
Epoch 76/100
380/380 [==============================] - 0s 113us/step - loss: 0.2605 - accuracy: 0.9079 - val_loss: 0.4336 - val_accuracy: 0.8098
Epoch 77/100
380/380 [==============================] - 0s 105us/step - loss: 0.2365 - accuracy: 0.9000 - val_loss: 0.4783 - val_accuracy: 0.8037
Epoch 78/100
380/380 [==============================] - 0s 124us/step - loss: 0.2375 - accuracy: 0.9105 - val_loss: 0.4377 - val_accuracy: 0.8098
Epoch 79/100
380/380 [==============================] - 0s 106us/step - loss: 0.2354 - accuracy: 0.9026 - val_loss: 0.4652 - val_accuracy: 0.7975
Epoch 80/100
380/380 [==============================] - 0s 137us/step - loss: 0.2398 - accuracy: 0.8895 - val_loss: 0.5273 - val_accuracy: 0.7791
Epoch 81/100
380/380 [==============================] - 0s 164us/step - loss: 0.2645 - accuracy: 0.9026 - val_loss: 0.4256 - val_accuracy: 0.8221
Epoch 82/100
380/380 [==============================] - 0s 111us/step - loss: 0.2391 - accuracy: 0.8947 - val_loss: 0.4724 - val_accuracy: 0.8037
Epoch 83/100
380/380 [==============================] - 0s 124us/step - loss: 0.2366 - accuracy: 0.8974 - val_loss: 0.4661 - val_accuracy: 0.8098
Epoch 84/100
380/380 [==============================] - 0s 104us/step - loss: 0.2393 - accuracy: 0.8921 - val_loss: 0.4664 - val_accuracy: 0.8098
Epoch 85/100
380/380 [==============================] - 0s 148us/step - loss: 0.2214 - accuracy: 0.9289 - val_loss: 0.4438 - val_accuracy: 0.8160
Epoch 86/100
380/380 [==============================] - 0s 161us/step - loss: 0.2208 - accuracy: 0.9105 - val_loss: 0.5304 - val_accuracy: 0.7914
Epoch 87/100
380/380 [==============================] - 0s 113us/step - loss: 0.2356 - accuracy: 0.8842 - val_loss: 0.4532 - val_accuracy: 0.8037
Epoch 88/100
380/380 [==============================] - 0s 125us/step - loss: 0.2457 - accuracy: 0.8921 - val_loss: 0.4509 - val_accuracy: 0.8160
Epoch 89/100
380/380 [==============================] - 0s 140us/step - loss: 0.2440 - accuracy: 0.8974 - val_loss: 0.4915 - val_accuracy: 0.8098
Epoch 90/100
380/380 [==============================] - 0s 116us/step - loss: 0.2410 - accuracy: 0.8947 - val_loss: 0.4871 - val_accuracy: 0.7975
Epoch 91/100
380/380 [==============================] - 0s 120us/step - loss: 0.2495 - accuracy: 0.9105 - val_loss: 0.4749 - val_accuracy: 0.7730
Epoch 92/100
380/380 [==============================] - 0s 123us/step - loss: 0.2278 - accuracy: 0.9079 - val_loss: 0.4938 - val_accuracy: 0.7975
Epoch 93/100
380/380 [==============================] - 0s 184us/step - loss: 0.2158 - accuracy: 0.9053 - val_loss: 0.5371 - val_accuracy: 0.7914
Epoch 94/100
380/380 [==============================] - 0s 143us/step - loss: 0.2648 - accuracy: 0.8737 - val_loss: 0.4787 - val_accuracy: 0.7791
Epoch 95/100
380/380 [==============================] - 0s 118us/step - loss: 0.2511 - accuracy: 0.8711 - val_loss: 0.4631 - val_accuracy: 0.8098
Epoch 96/100
380/380 [==============================] - 0s 157us/step - loss: 0.2279 - accuracy: 0.8974 - val_loss: 0.5005 - val_accuracy: 0.7914
Epoch 97/100
380/380 [==============================] - 0s 168us/step - loss: 0.2213 - accuracy: 0.9079 - val_loss: 0.5617 - val_accuracy: 0.7669
Epoch 98/100
380/380 [==============================] - 0s 151us/step - loss: 0.2291 - accuracy: 0.9105 - val_loss: 0.5515 - val_accuracy: 0.7791
Epoch 99/100
380/380 [==============================] - 0s 152us/step - loss: 0.2293 - accuracy: 0.9053 - val_loss: 0.4786 - val_accuracy: 0.7975
Epoch 100/100
380/380 [==============================] - 0s 119us/step - loss: 0.2102 - accuracy: 0.9211 - val_loss: 0.5000 - val_accuracy: 0.7853
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[59]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&lt;keras.callbacks.callbacks.History at 0x1a427c04e0&gt;</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[116]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">acc_test_over4</span> <span class="o">=</span> <span class="n">model1_over4</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_test_over</span><span class="p">,</span> <span class="n">y_test_over</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;over-sampling test accuracy: </span><span class="si">%.2f%%</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">acc_test_over4</span><span class="o">*</span><span class="mi">100</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>163/163 [==============================] - 0s 105us/step
over-sampling test accuracy: 80.37%
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[60]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">pred4</span> <span class="o">=</span> <span class="n">model1_over4</span><span class="o">.</span><span class="n">predict_classes</span><span class="p">(</span><span class="n">X_test_over</span><span class="p">)</span>
<span class="n">pred4</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[60]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>array([2, 0, 0, 0, 0, 1, 2, 2, 0, 0, 1, 1, 2, 0, 1, 0, 0, 0, 1, 0, 2, 2,
       0, 1, 1, 1, 1, 0, 2, 2, 0, 2, 1, 1, 2, 1, 0, 2, 0, 0, 0, 1, 1, 1,
       0, 1, 2, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1,
       1, 0, 2, 2, 0, 1, 0, 0, 1, 2, 1, 1, 1, 2, 0, 0, 2, 1, 2, 1, 1, 1,
       0, 1, 0, 1, 2, 0, 1, 1, 0, 1, 1, 1, 0, 1, 2, 1, 2, 2, 2, 2, 1, 0,
       2, 0, 1, 1, 0, 1, 0, 1, 2, 1, 1, 1, 2, 2, 1, 1, 2, 1, 2, 0, 1, 1,
       1, 1, 2, 1, 0, 0, 1, 1, 0, 0, 2, 0, 2, 2, 1, 1, 1, 0, 0, 1, 2, 1,
       1, 1, 1, 1, 1, 1, 1, 1, 0])</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[61]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dat4</span><span class="p">[</span><span class="s1">&#39;pred&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pred4</span>
<span class="n">dat4</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[61]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>test</th>
      <th>pred</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>SR2852</td>
      <td>2</td>
      <td>2</td>
    </tr>
    <tr>
      <th>1</th>
      <td>CFBREBSa138</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>BCH-SA-12</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>EUH13</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>EUH13</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>158</th>
      <td>NRS036</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>159</th>
      <td>CA105</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>160</th>
      <td>CFBRSa51</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>161</th>
      <td>NRS102</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>162</th>
      <td>NRS189</td>
      <td>2</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>163 rows × 3 columns</p>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[62]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">proba4</span> <span class="o">=</span> <span class="n">model1_over4</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test_over</span><span class="p">)</span>
<span class="n">dat_proba4</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">proba4</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[63]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dat_proba4</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[63]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.000036</td>
      <td>0.025301</td>
      <td>0.974663</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.998706</td>
      <td>0.000814</td>
      <td>0.000480</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.976673</td>
      <td>0.004427</td>
      <td>0.018900</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.919572</td>
      <td>0.067330</td>
      <td>0.013098</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.919572</td>
      <td>0.067330</td>
      <td>0.013098</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>158</th>
      <td>0.000499</td>
      <td>0.923615</td>
      <td>0.075886</td>
    </tr>
    <tr>
      <th>159</th>
      <td>0.000005</td>
      <td>0.999085</td>
      <td>0.000910</td>
    </tr>
    <tr>
      <th>160</th>
      <td>0.000258</td>
      <td>0.999683</td>
      <td>0.000059</td>
    </tr>
    <tr>
      <th>161</th>
      <td>0.000014</td>
      <td>0.999135</td>
      <td>0.000851</td>
    </tr>
    <tr>
      <th>162</th>
      <td>0.731490</td>
      <td>0.001271</td>
      <td>0.267239</td>
    </tr>
  </tbody>
</table>
<p>163 rows × 3 columns</p>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[64]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dat_proba4</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s2">&quot;/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba4.csv&quot;</span><span class="p">,</span> <span class="n">index</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
         <span class="n">header</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[65]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dat4</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s2">&quot;/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/4p11.csv&quot;</span><span class="p">,</span> <span class="n">index</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
         <span class="n">header</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[120]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">hist1_over4</span> <span class="o">=</span> <span class="n">model1_over4</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_over</span><span class="p">,</span> <span class="n">y_train_over</span><span class="p">,</span>
          <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
          <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">X_test_over</span><span class="p">,</span> <span class="n">y_test_over</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Train on 380 samples, validate on 163 samples
Epoch 1/100
380/380 [==============================] - 0s 181us/step - loss: 0.2402 - accuracy: 0.8895 - val_loss: 0.5029 - val_accuracy: 0.8282
Epoch 2/100
380/380 [==============================] - 0s 154us/step - loss: 0.2139 - accuracy: 0.9158 - val_loss: 0.5459 - val_accuracy: 0.8221
Epoch 3/100
380/380 [==============================] - 0s 149us/step - loss: 0.2117 - accuracy: 0.9132 - val_loss: 0.5106 - val_accuracy: 0.8160
Epoch 4/100
380/380 [==============================] - 0s 122us/step - loss: 0.2173 - accuracy: 0.8947 - val_loss: 0.4998 - val_accuracy: 0.7914
Epoch 5/100
380/380 [==============================] - 0s 120us/step - loss: 0.2538 - accuracy: 0.8684 - val_loss: 0.4831 - val_accuracy: 0.8037
Epoch 6/100
380/380 [==============================] - 0s 123us/step - loss: 0.2280 - accuracy: 0.9184 - val_loss: 0.4708 - val_accuracy: 0.8344
Epoch 7/100
380/380 [==============================] - 0s 121us/step - loss: 0.3265 - accuracy: 0.8500 - val_loss: 0.6976 - val_accuracy: 0.7607
Epoch 8/100
380/380 [==============================] - 0s 137us/step - loss: 0.3319 - accuracy: 0.8684 - val_loss: 0.5022 - val_accuracy: 0.8098
Epoch 9/100
380/380 [==============================] - 0s 133us/step - loss: 0.3102 - accuracy: 0.8421 - val_loss: 0.7722 - val_accuracy: 0.7791
Epoch 10/100
380/380 [==============================] - 0s 127us/step - loss: 0.2765 - accuracy: 0.8947 - val_loss: 0.5383 - val_accuracy: 0.8037
Epoch 11/100
380/380 [==============================] - 0s 120us/step - loss: 0.2343 - accuracy: 0.8816 - val_loss: 0.5457 - val_accuracy: 0.8160
Epoch 12/100
380/380 [==============================] - 0s 124us/step - loss: 0.2140 - accuracy: 0.9105 - val_loss: 0.5140 - val_accuracy: 0.8528
Epoch 13/100
380/380 [==============================] - 0s 118us/step - loss: 0.2198 - accuracy: 0.8947 - val_loss: 0.5948 - val_accuracy: 0.7914
Epoch 14/100
380/380 [==============================] - 0s 114us/step - loss: 0.2305 - accuracy: 0.8921 - val_loss: 0.6129 - val_accuracy: 0.7914
Epoch 15/100
380/380 [==============================] - 0s 142us/step - loss: 0.2385 - accuracy: 0.8947 - val_loss: 0.5878 - val_accuracy: 0.7669
Epoch 16/100
380/380 [==============================] - 0s 139us/step - loss: 0.2348 - accuracy: 0.9132 - val_loss: 0.5280 - val_accuracy: 0.8282
Epoch 17/100
380/380 [==============================] - 0s 218us/step - loss: 0.2081 - accuracy: 0.9105 - val_loss: 0.4851 - val_accuracy: 0.8282
Epoch 18/100
380/380 [==============================] - 0s 241us/step - loss: 0.2217 - accuracy: 0.8974 - val_loss: 0.5202 - val_accuracy: 0.8344
Epoch 19/100
380/380 [==============================] - 0s 174us/step - loss: 0.2124 - accuracy: 0.9079 - val_loss: 0.5095 - val_accuracy: 0.8282
Epoch 20/100
380/380 [==============================] - 0s 138us/step - loss: 0.2335 - accuracy: 0.8974 - val_loss: 0.5499 - val_accuracy: 0.7975
Epoch 21/100
380/380 [==============================] - 0s 139us/step - loss: 0.2238 - accuracy: 0.9105 - val_loss: 0.4732 - val_accuracy: 0.8344
Epoch 22/100
380/380 [==============================] - 0s 144us/step - loss: 0.1943 - accuracy: 0.9184 - val_loss: 0.4979 - val_accuracy: 0.8160
Epoch 23/100
380/380 [==============================] - 0s 162us/step - loss: 0.1990 - accuracy: 0.9158 - val_loss: 0.5026 - val_accuracy: 0.8466
Epoch 24/100
380/380 [==============================] - 0s 150us/step - loss: 0.1928 - accuracy: 0.9237 - val_loss: 0.5012 - val_accuracy: 0.8098
Epoch 25/100
380/380 [==============================] - 0s 187us/step - loss: 0.2030 - accuracy: 0.9053 - val_loss: 0.6025 - val_accuracy: 0.7607
Epoch 26/100
380/380 [==============================] - 0s 181us/step - loss: 0.2085 - accuracy: 0.9053 - val_loss: 0.4707 - val_accuracy: 0.8466
Epoch 27/100
380/380 [==============================] - 0s 163us/step - loss: 0.2270 - accuracy: 0.8947 - val_loss: 0.5575 - val_accuracy: 0.8344
Epoch 28/100
380/380 [==============================] - 0s 159us/step - loss: 0.2030 - accuracy: 0.9026 - val_loss: 0.5574 - val_accuracy: 0.8098
Epoch 29/100
380/380 [==============================] - 0s 166us/step - loss: 0.2198 - accuracy: 0.9053 - val_loss: 0.5533 - val_accuracy: 0.7853
Epoch 30/100
380/380 [==============================] - 0s 154us/step - loss: 0.2241 - accuracy: 0.9053 - val_loss: 0.5459 - val_accuracy: 0.7914
Epoch 31/100
380/380 [==============================] - 0s 159us/step - loss: 0.2245 - accuracy: 0.8842 - val_loss: 0.6757 - val_accuracy: 0.7485
Epoch 32/100
380/380 [==============================] - 0s 168us/step - loss: 0.2942 - accuracy: 0.8789 - val_loss: 0.5768 - val_accuracy: 0.7669
Epoch 33/100
380/380 [==============================] - 0s 189us/step - loss: 0.2199 - accuracy: 0.9158 - val_loss: 0.5479 - val_accuracy: 0.7975
Epoch 34/100
380/380 [==============================] - 0s 182us/step - loss: 0.2418 - accuracy: 0.8947 - val_loss: 0.4877 - val_accuracy: 0.8282
Epoch 35/100
380/380 [==============================] - 0s 204us/step - loss: 0.2272 - accuracy: 0.8947 - val_loss: 0.5657 - val_accuracy: 0.7975
Epoch 36/100
380/380 [==============================] - 0s 209us/step - loss: 0.2008 - accuracy: 0.9211 - val_loss: 0.5116 - val_accuracy: 0.8405
Epoch 37/100
380/380 [==============================] - 0s 227us/step - loss: 0.2021 - accuracy: 0.9132 - val_loss: 0.5126 - val_accuracy: 0.8466
Epoch 38/100
380/380 [==============================] - 0s 181us/step - loss: 0.2114 - accuracy: 0.9053 - val_loss: 0.5297 - val_accuracy: 0.8160
Epoch 39/100
380/380 [==============================] - 0s 144us/step - loss: 0.1943 - accuracy: 0.9184 - val_loss: 0.4993 - val_accuracy: 0.8282
Epoch 40/100
380/380 [==============================] - 0s 148us/step - loss: 0.1867 - accuracy: 0.9316 - val_loss: 0.5151 - val_accuracy: 0.8466
Epoch 41/100
380/380 [==============================] - 0s 124us/step - loss: 0.1866 - accuracy: 0.9237 - val_loss: 0.4892 - val_accuracy: 0.8405
Epoch 42/100
380/380 [==============================] - 0s 142us/step - loss: 0.2071 - accuracy: 0.9000 - val_loss: 0.5287 - val_accuracy: 0.8282
Epoch 43/100
380/380 [==============================] - 0s 176us/step - loss: 0.1838 - accuracy: 0.9184 - val_loss: 0.5077 - val_accuracy: 0.8221
Epoch 44/100
380/380 [==============================] - 0s 155us/step - loss: 0.1938 - accuracy: 0.9184 - val_loss: 0.5728 - val_accuracy: 0.8221
Epoch 45/100
380/380 [==============================] - 0s 128us/step - loss: 0.1885 - accuracy: 0.9289 - val_loss: 0.4960 - val_accuracy: 0.8405
Epoch 46/100
380/380 [==============================] - 0s 148us/step - loss: 0.2209 - accuracy: 0.9000 - val_loss: 0.5361 - val_accuracy: 0.8405
Epoch 47/100
380/380 [==============================] - 0s 203us/step - loss: 0.2011 - accuracy: 0.9158 - val_loss: 0.4890 - val_accuracy: 0.7975
Epoch 48/100
380/380 [==============================] - 0s 198us/step - loss: 0.2018 - accuracy: 0.9184 - val_loss: 0.4699 - val_accuracy: 0.8344
Epoch 49/100
380/380 [==============================] - 0s 179us/step - loss: 0.2140 - accuracy: 0.9132 - val_loss: 0.4866 - val_accuracy: 0.7975
Epoch 50/100
380/380 [==============================] - 0s 213us/step - loss: 0.1953 - accuracy: 0.9132 - val_loss: 0.5370 - val_accuracy: 0.7607
Epoch 51/100
380/380 [==============================] - 0s 188us/step - loss: 0.2475 - accuracy: 0.8842 - val_loss: 0.5504 - val_accuracy: 0.7914
Epoch 52/100
380/380 [==============================] - 0s 169us/step - loss: 0.2453 - accuracy: 0.8895 - val_loss: 0.5474 - val_accuracy: 0.8160
Epoch 53/100
380/380 [==============================] - 0s 177us/step - loss: 0.2790 - accuracy: 0.8921 - val_loss: 0.4940 - val_accuracy: 0.8344
Epoch 54/100
380/380 [==============================] - 0s 179us/step - loss: 0.1954 - accuracy: 0.9263 - val_loss: 0.5052 - val_accuracy: 0.8221
Epoch 55/100
380/380 [==============================] - 0s 182us/step - loss: 0.1875 - accuracy: 0.9211 - val_loss: 0.5057 - val_accuracy: 0.8344
Epoch 56/100
380/380 [==============================] - 0s 178us/step - loss: 0.1955 - accuracy: 0.9211 - val_loss: 0.5196 - val_accuracy: 0.8098
Epoch 57/100
380/380 [==============================] - 0s 177us/step - loss: 0.2011 - accuracy: 0.9158 - val_loss: 0.5217 - val_accuracy: 0.7975
Epoch 58/100
380/380 [==============================] - 0s 185us/step - loss: 0.2038 - accuracy: 0.9105 - val_loss: 0.5321 - val_accuracy: 0.8037
Epoch 59/100
380/380 [==============================] - 0s 167us/step - loss: 0.2410 - accuracy: 0.8842 - val_loss: 0.5548 - val_accuracy: 0.8160
Epoch 60/100
380/380 [==============================] - 0s 189us/step - loss: 0.1935 - accuracy: 0.9237 - val_loss: 0.5489 - val_accuracy: 0.8282
Epoch 61/100
380/380 [==============================] - 0s 181us/step - loss: 0.1891 - accuracy: 0.9184 - val_loss: 0.5409 - val_accuracy: 0.8098
Epoch 62/100
380/380 [==============================] - 0s 220us/step - loss: 0.1942 - accuracy: 0.9158 - val_loss: 0.5760 - val_accuracy: 0.8098
Epoch 63/100
380/380 [==============================] - 0s 192us/step - loss: 0.1969 - accuracy: 0.9000 - val_loss: 0.5637 - val_accuracy: 0.8098
Epoch 64/100
380/380 [==============================] - 0s 178us/step - loss: 0.1990 - accuracy: 0.9000 - val_loss: 0.5707 - val_accuracy: 0.8037
Epoch 65/100
380/380 [==============================] - 0s 169us/step - loss: 0.1988 - accuracy: 0.9263 - val_loss: 0.5668 - val_accuracy: 0.8098
Epoch 66/100
380/380 [==============================] - 0s 159us/step - loss: 0.2009 - accuracy: 0.9132 - val_loss: 0.5379 - val_accuracy: 0.8221
Epoch 67/100
380/380 [==============================] - 0s 155us/step - loss: 0.2015 - accuracy: 0.9026 - val_loss: 0.5188 - val_accuracy: 0.8466
Epoch 68/100
380/380 [==============================] - 0s 181us/step - loss: 0.1910 - accuracy: 0.9132 - val_loss: 0.5172 - val_accuracy: 0.8466
Epoch 69/100
380/380 [==============================] - 0s 172us/step - loss: 0.2068 - accuracy: 0.8947 - val_loss: 0.6009 - val_accuracy: 0.7914
Epoch 70/100
380/380 [==============================] - 0s 158us/step - loss: 0.2095 - accuracy: 0.9053 - val_loss: 0.5351 - val_accuracy: 0.8160
Epoch 71/100
380/380 [==============================] - 0s 171us/step - loss: 0.1938 - accuracy: 0.9316 - val_loss: 0.5029 - val_accuracy: 0.8282
Epoch 72/100
380/380 [==============================] - 0s 175us/step - loss: 0.1760 - accuracy: 0.9289 - val_loss: 0.5583 - val_accuracy: 0.8221
Epoch 73/100
380/380 [==============================] - 0s 155us/step - loss: 0.1778 - accuracy: 0.9263 - val_loss: 0.5274 - val_accuracy: 0.8221
Epoch 74/100
380/380 [==============================] - 0s 152us/step - loss: 0.1894 - accuracy: 0.9184 - val_loss: 0.5621 - val_accuracy: 0.7914
Epoch 75/100
380/380 [==============================] - 0s 153us/step - loss: 0.2586 - accuracy: 0.9000 - val_loss: 0.7663 - val_accuracy: 0.7239
Epoch 76/100
380/380 [==============================] - 0s 145us/step - loss: 0.2604 - accuracy: 0.9053 - val_loss: 0.6008 - val_accuracy: 0.8037
Epoch 77/100
380/380 [==============================] - 0s 138us/step - loss: 0.2520 - accuracy: 0.9000 - val_loss: 0.5609 - val_accuracy: 0.8037
Epoch 78/100
380/380 [==============================] - 0s 206us/step - loss: 0.2529 - accuracy: 0.8947 - val_loss: 0.6189 - val_accuracy: 0.8282
Epoch 79/100
380/380 [==============================] - 0s 325us/step - loss: 0.1924 - accuracy: 0.9237 - val_loss: 0.4651 - val_accuracy: 0.8589
Epoch 80/100
380/380 [==============================] - 0s 164us/step - loss: 0.1978 - accuracy: 0.9158 - val_loss: 0.5422 - val_accuracy: 0.8037
Epoch 81/100
380/380 [==============================] - 0s 153us/step - loss: 0.1977 - accuracy: 0.9158 - val_loss: 0.5532 - val_accuracy: 0.8098
Epoch 82/100
380/380 [==============================] - 0s 168us/step - loss: 0.1858 - accuracy: 0.9158 - val_loss: 0.5101 - val_accuracy: 0.8405
Epoch 83/100
380/380 [==============================] - 0s 181us/step - loss: 0.1915 - accuracy: 0.9211 - val_loss: 0.5422 - val_accuracy: 0.8405
Epoch 84/100
380/380 [==============================] - 0s 219us/step - loss: 0.1808 - accuracy: 0.9263 - val_loss: 0.5154 - val_accuracy: 0.8466
Epoch 85/100
380/380 [==============================] - 0s 183us/step - loss: 0.1883 - accuracy: 0.9316 - val_loss: 0.4979 - val_accuracy: 0.8466
Epoch 86/100
380/380 [==============================] - 0s 789us/step - loss: 0.1836 - accuracy: 0.9237 - val_loss: 0.5379 - val_accuracy: 0.8405
Epoch 87/100
380/380 [==============================] - 0s 189us/step - loss: 0.1707 - accuracy: 0.9263 - val_loss: 0.5412 - val_accuracy: 0.8405
Epoch 88/100
380/380 [==============================] - 0s 274us/step - loss: 0.1892 - accuracy: 0.9158 - val_loss: 0.5816 - val_accuracy: 0.8098
Epoch 89/100
380/380 [==============================] - 0s 167us/step - loss: 0.1825 - accuracy: 0.9211 - val_loss: 0.5197 - val_accuracy: 0.8528
Epoch 90/100
380/380 [==============================] - 0s 424us/step - loss: 0.1769 - accuracy: 0.9237 - val_loss: 0.5486 - val_accuracy: 0.8405
Epoch 91/100
380/380 [==============================] - 0s 318us/step - loss: 0.2340 - accuracy: 0.9079 - val_loss: 0.5253 - val_accuracy: 0.8344
Epoch 92/100
380/380 [==============================] - 0s 159us/step - loss: 0.2152 - accuracy: 0.9158 - val_loss: 0.5591 - val_accuracy: 0.8037
Epoch 93/100
380/380 [==============================] - 0s 155us/step - loss: 0.2121 - accuracy: 0.9105 - val_loss: 0.5188 - val_accuracy: 0.8466
Epoch 94/100
380/380 [==============================] - 0s 157us/step - loss: 0.2143 - accuracy: 0.9184 - val_loss: 0.5296 - val_accuracy: 0.8466
Epoch 95/100
380/380 [==============================] - 0s 146us/step - loss: 0.2348 - accuracy: 0.9026 - val_loss: 0.5230 - val_accuracy: 0.8282
Epoch 96/100
380/380 [==============================] - 0s 146us/step - loss: 0.1873 - accuracy: 0.9184 - val_loss: 0.5282 - val_accuracy: 0.8405
Epoch 97/100
380/380 [==============================] - 0s 141us/step - loss: 0.1802 - accuracy: 0.9158 - val_loss: 0.5211 - val_accuracy: 0.8344
Epoch 98/100
380/380 [==============================] - 0s 135us/step - loss: 0.1948 - accuracy: 0.9105 - val_loss: 0.5574 - val_accuracy: 0.8221
Epoch 99/100
380/380 [==============================] - 0s 139us/step - loss: 0.2069 - accuracy: 0.9053 - val_loss: 0.5672 - val_accuracy: 0.8221
Epoch 100/100
380/380 [==============================] - 0s 143us/step - loss: 0.2102 - accuracy: 0.9000 - val_loss: 0.5174 - val_accuracy: 0.8528
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[121]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;over-sampling train accuracy: </span><span class="si">%.2f%%</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">hist1_over4</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span><span class="o">*</span><span class="mi">100</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>over-sampling train accuracy: 90.78%
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[47]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df_proba4</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_excel</span><span class="p">(</span><span class="s2">&quot;/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_2.xlsx&quot;</span><span class="p">,</span>
                        <span class="n">sheet_name</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
                        <span class="n">index_col</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[48]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df_proba4</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[48]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>phage</th>
      <th>strain</th>
      <th>phenotype</th>
      <th>prediction</th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>p002ykpresabs_qual</td>
      <td>NRS110</td>
      <td>1</td>
      <td>1</td>
      <td>0.000003</td>
      <td>0.999997</td>
      <td>5.870196e-13</td>
    </tr>
    <tr>
      <th>1</th>
      <td>p002ykpresabs_qual</td>
      <td>NRS216</td>
      <td>1</td>
      <td>1</td>
      <td>0.039254</td>
      <td>0.960745</td>
      <td>9.078969e-07</td>
    </tr>
    <tr>
      <th>2</th>
      <td>p002ykpresabs_qual</td>
      <td>NRS386</td>
      <td>1</td>
      <td>1</td>
      <td>0.326752</td>
      <td>0.673248</td>
      <td>1.061032e-07</td>
    </tr>
    <tr>
      <th>3</th>
      <td>p002ykpresabs_qual</td>
      <td>CFBRSa25</td>
      <td>0</td>
      <td>0</td>
      <td>0.611084</td>
      <td>0.388916</td>
      <td>7.664974e-07</td>
    </tr>
    <tr>
      <th>4</th>
      <td>p002ykpresabs_qual</td>
      <td>BCH-SA-03</td>
      <td>1</td>
      <td>0</td>
      <td>0.611084</td>
      <td>0.388916</td>
      <td>7.664974e-07</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>4279</th>
      <td>pyopresabsSTCC_qual</td>
      <td>NRS236</td>
      <td>1</td>
      <td>1</td>
      <td>0.000052</td>
      <td>0.999768</td>
      <td>1.803156e-04</td>
    </tr>
    <tr>
      <th>4280</th>
      <td>pyopresabsSTCC_qual</td>
      <td>NRS029</td>
      <td>0</td>
      <td>1</td>
      <td>0.322350</td>
      <td>0.677496</td>
      <td>1.533154e-04</td>
    </tr>
    <tr>
      <th>4281</th>
      <td>pyopresabsSTCC_qual</td>
      <td>NRS148</td>
      <td>2</td>
      <td>2</td>
      <td>0.000006</td>
      <td>0.000026</td>
      <td>9.999682e-01</td>
    </tr>
    <tr>
      <th>4282</th>
      <td>pyopresabsSTCC_qual</td>
      <td>CFBRSa28</td>
      <td>0</td>
      <td>0</td>
      <td>0.999288</td>
      <td>0.000176</td>
      <td>5.361527e-04</td>
    </tr>
    <tr>
      <th>4283</th>
      <td>pyopresabsSTCC_qual</td>
      <td>NRS205</td>
      <td>2</td>
      <td>2</td>
      <td>0.000007</td>
      <td>0.000007</td>
      <td>9.999868e-01</td>
    </tr>
  </tbody>
</table>
<p>4284 rows × 7 columns</p>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[49]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">y_prob4</span> <span class="o">=</span> <span class="n">df_proba4</span><span class="p">[</span><span class="n">df_proba4</span><span class="p">[</span><span class="s1">&#39;phage&#39;</span><span class="p">]</span><span class="o">==</span><span class="s1">&#39;p11kpresabs_qual&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="o">-</span><span class="mi">3</span><span class="p">:]</span>
<span class="n">y_prob4</span> <span class="o">=</span> <span class="n">y_prob4</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
<span class="n">y_prob4</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[49]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>array([[3.5529585e-05, 2.5301340e-02, 9.7466314e-01],
       [9.9870634e-01, 8.1354770e-04, 4.8010462e-04],
       [9.7667330e-01, 4.4271164e-03, 1.8899648e-02],
       [9.1957180e-01, 6.7330010e-02, 1.3098269e-02],
       [9.1957180e-01, 6.7330010e-02, 1.3098269e-02],
       [9.3829454e-05, 9.7523670e-01, 2.4669446e-02],
       [2.2173378e-01, 1.8028943e-01, 5.9797674e-01],
       [1.0273278e-05, 2.1151037e-04, 9.9977820e-01],
       [7.4110700e-01, 2.3698530e-01, 2.1907752e-02],
       [9.9330360e-01, 5.6237000e-03, 1.0727432e-03],
       [7.6339087e-03, 9.1458905e-01, 7.7777030e-02],
       [2.9734123e-01, 6.2499960e-01, 7.7659205e-02],
       [5.3477073e-03, 8.6433790e-02, 9.0821856e-01],
       [7.4110700e-01, 2.3698530e-01, 2.1907752e-02],
       [1.7836774e-03, 5.4667970e-01, 4.5153670e-01],
       [9.8375630e-01, 7.4541410e-05, 1.6169135e-02],
       [7.4110700e-01, 2.3698530e-01, 2.1907752e-02],
       [9.9914120e-01, 8.0202933e-04, 5.6638106e-05],
       [4.0357750e-03, 6.1026730e-01, 3.8569700e-01],
       [9.1957180e-01, 6.7330010e-02, 1.3098269e-02],
       [2.8664965e-04, 2.8518908e-02, 9.7119440e-01],
       [8.6095160e-02, 4.1675827e-01, 4.9714655e-01],
       [9.9330360e-01, 5.6237000e-03, 1.0727432e-03],
       [3.4296037e-05, 8.4096694e-01, 1.5899877e-01],
       [2.3280002e-02, 8.6697480e-01, 1.0974518e-01],
       [4.4060294e-02, 7.2424180e-01, 2.3169790e-01],
       [2.8613592e-02, 9.7062826e-01, 7.5811456e-04],
       [9.9330360e-01, 5.6237000e-03, 1.0727432e-03],
       [3.1836852e-02, 1.6557788e-02, 9.5160540e-01],
       [2.2173378e-01, 1.8028943e-01, 5.9797674e-01],
       [9.9971825e-01, 7.8479960e-06, 2.7388398e-04],
       [2.8285360e-04, 1.7142922e-02, 9.8257430e-01],
       [6.7624927e-04, 6.9033235e-01, 3.0899146e-01],
       [2.7524224e-03, 9.9714760e-01, 9.9962310e-05],
       [5.3686860e-03, 2.4416596e-02, 9.7021466e-01],
       [2.9734123e-01, 6.2499960e-01, 7.7659205e-02],
       [9.9955004e-01, 3.3794495e-04, 1.1206498e-04],
       [1.4619781e-04, 6.3886430e-03, 9.9346510e-01],
       [9.9870634e-01, 8.1354770e-04, 4.8010462e-04],
       [9.9446940e-01, 3.8145322e-04, 5.1491160e-03],
       [9.8375630e-01, 7.4541410e-05, 1.6169135e-02],
       [2.5810255e-04, 9.9968255e-01, 5.9328097e-05],
       [1.2656836e-03, 9.9873060e-01, 3.6859494e-06],
       [5.9898810e-04, 9.9907553e-01, 3.2546360e-04],
       [9.8950960e-01, 3.5091832e-03, 6.9812370e-03],
       [1.8682673e-03, 9.9530953e-01, 2.8222576e-03],
       [3.3459590e-02, 3.9952000e-01, 5.6702040e-01],
       [9.7667330e-01, 4.4271164e-03, 1.8899648e-02],
       [9.9446940e-01, 3.8145322e-04, 5.1491160e-03],
       [9.9955004e-01, 3.3794495e-04, 1.1206498e-04],
       [1.4184709e-05, 9.9913470e-01, 8.5112115e-04],
       [7.0935505e-07, 9.9926320e-01, 7.3602740e-04],
       [1.8682673e-03, 9.9530953e-01, 2.8222576e-03],
       [4.4060294e-02, 7.2424180e-01, 2.3169790e-01],
       [5.2651465e-01, 1.8143464e-02, 4.5534194e-01],
       [2.8517442e-02, 6.4737080e-01, 3.2411180e-01],
       [3.8255658e-04, 8.4447920e-01, 1.5513822e-01],
       [7.4882914e-06, 9.3594070e-01, 6.4051810e-02],
       [6.6013390e-05, 9.9947685e-01, 4.5713235e-04],
       [9.9330360e-01, 5.6237000e-03, 1.0727432e-03],
       [1.9745205e-02, 7.5083613e-01, 2.2941867e-01],
       [5.9569600e-03, 9.9225545e-01, 1.7875754e-03],
       [9.9446940e-01, 3.8145322e-04, 5.1491160e-03],
       [1.8906687e-06, 5.9116040e-01, 4.0883768e-01],
       [1.0673555e-02, 5.7162710e-01, 4.1769940e-01],
       [4.1306932e-05, 8.8951700e-01, 1.1044161e-01],
       [1.9745205e-02, 7.5083613e-01, 2.2941867e-01],
       [9.9914120e-01, 8.0202933e-04, 5.6638106e-05],
       [1.9537656e-02, 2.1506330e-01, 7.6539904e-01],
       [2.2536068e-01, 3.1304610e-01, 4.6159320e-01],
       [9.1957180e-01, 6.7330010e-02, 1.3098269e-02],
       [2.5810255e-04, 9.9968255e-01, 5.9328097e-05],
       [8.0764480e-01, 3.0155700e-04, 1.9205368e-01],
       [9.7348950e-01, 7.4047415e-04, 2.5769982e-02],
       [1.2466652e-04, 6.2853765e-01, 3.7133770e-01],
       [5.2204905e-03, 1.1047862e-01, 8.8430090e-01],
       [2.9734123e-01, 6.2499960e-01, 7.7659205e-02],
       [4.1306932e-05, 8.8951700e-01, 1.1044161e-01],
       [2.8140292e-02, 5.0235033e-01, 4.6950933e-01],
       [2.7880400e-08, 1.9290490e-06, 9.9999810e-01],
       [9.7348950e-01, 7.4047415e-04, 2.5769982e-02],
       [8.0764480e-01, 3.0155700e-04, 1.9205368e-01],
       [6.4268380e-05, 3.3224854e-04, 9.9960345e-01],
       [1.4184709e-05, 9.9913470e-01, 8.5112115e-04],
       [3.1921060e-02, 6.1255520e-05, 9.6801770e-01],
       [4.4060294e-02, 7.2424180e-01, 2.3169790e-01],
       [2.9734123e-01, 6.2499960e-01, 7.7659205e-02],
       [4.4060294e-02, 7.2424180e-01, 2.3169790e-01],
       [9.9543120e-01, 4.5676300e-03, 1.1564625e-06],
       [2.9734123e-01, 6.2499960e-01, 7.7659205e-02],
       [9.9728394e-01, 2.2457994e-03, 4.7035248e-04],
       [7.4882914e-06, 9.3594070e-01, 6.4051810e-02],
       [1.4626524e-01, 3.6668047e-01, 4.8705430e-01],
       [8.0764480e-01, 3.0155700e-04, 1.9205368e-01],
       [7.6339087e-03, 9.1458905e-01, 7.7777030e-02],
       [2.5810255e-04, 9.9968255e-01, 5.9328097e-05],
       [9.9543120e-01, 4.5676300e-03, 1.1564625e-06],
       [2.7524224e-03, 9.9714760e-01, 9.9962310e-05],
       [2.9734123e-01, 6.2499960e-01, 7.7659205e-02],
       [4.4060294e-02, 7.2424180e-01, 2.3169790e-01],
       [9.3184020e-01, 1.3914547e-02, 5.4245345e-02],
       [2.9734123e-01, 6.2499960e-01, 7.7659205e-02],
       [1.2881686e-06, 2.6850905e-03, 9.9731356e-01],
       [7.6339087e-03, 9.1458905e-01, 7.7777030e-02],
       [1.4260601e-03, 8.3112806e-02, 9.1546106e-01],
       [2.0740498e-02, 1.8838875e-05, 9.7924060e-01],
       [1.4626524e-01, 3.6668047e-01, 4.8705430e-01],
       [4.8177462e-06, 6.6966255e-05, 9.9992824e-01],
       [7.6339087e-03, 9.1458905e-01, 7.7777030e-02],
       [9.9244785e-01, 5.6997870e-03, 1.8523391e-03],
       [8.2320970e-03, 2.5067277e-02, 9.6670070e-01],
       [9.9330360e-01, 5.6237000e-03, 1.0727432e-03],
       [5.9898810e-04, 9.9907553e-01, 3.2546360e-04],
       [2.9734123e-01, 6.2499960e-01, 7.7659205e-02],
       [9.8375630e-01, 7.4541410e-05, 1.6169135e-02],
       [2.9734123e-01, 6.2499960e-01, 7.7659205e-02],
       [9.9446940e-01, 3.8145322e-04, 5.1491160e-03],
       [1.5391587e-04, 9.9334730e-01, 6.4988527e-03],
       [3.2254476e-07, 4.2153795e-05, 9.9995756e-01],
       [1.4989587e-05, 9.9854240e-01, 1.4426459e-03],
       [3.0402615e-04, 9.9574950e-01, 3.9464820e-03],
       [4.9894943e-04, 8.9277020e-01, 1.0673093e-01],
       [7.3762412e-06, 2.9835217e-03, 9.9700910e-01],
       [7.1278060e-07, 4.2781403e-04, 9.9957150e-01],
       [7.6339087e-03, 9.1458905e-01, 7.7777030e-02],
       [7.2098610e-06, 9.9819190e-01, 1.8008057e-03],
       [2.4803590e-02, 3.5625917e-01, 6.1893725e-01],
       [5.9898810e-04, 9.9907553e-01, 3.2546360e-04],
       [1.5763160e-05, 7.5603235e-03, 9.9242390e-01],
       [9.9330360e-01, 5.6237000e-03, 1.0727432e-03],
       [4.4060294e-02, 7.2424180e-01, 2.3169790e-01],
       [4.4060294e-02, 7.2424180e-01, 2.3169790e-01],
       [9.6886940e-03, 9.3208146e-01, 5.8229912e-02],
       [5.9898810e-04, 9.9907553e-01, 3.2546360e-04],
       [2.2173378e-01, 1.8028943e-01, 5.9797674e-01],
       [7.4882914e-06, 9.3594070e-01, 6.4051810e-02],
       [9.3184020e-01, 1.3914547e-02, 5.4245345e-02],
       [5.8000320e-01, 1.0344137e-05, 4.1998646e-01],
       [1.2733167e-03, 9.8518710e-01, 1.3539574e-02],
       [6.7546985e-06, 9.9211700e-01, 7.8762890e-03],
       [9.9232435e-01, 7.3765963e-03, 2.9899230e-04],
       [9.9501800e-01, 3.6402003e-04, 4.6179110e-03],
       [8.2392400e-06, 2.0822082e-03, 9.9790950e-01],
       [9.9244785e-01, 5.6997870e-03, 1.8523391e-03],
       [3.3459590e-02, 3.9952000e-01, 5.6702040e-01],
       [6.0922354e-02, 9.1597730e-05, 9.3898600e-01],
       [1.2466652e-04, 6.2853765e-01, 3.7133770e-01],
       [1.4257007e-05, 9.7567140e-01, 2.4314255e-02],
       [2.9734123e-01, 6.2499960e-01, 7.7659205e-02],
       [9.8603520e-01, 1.2089956e-02, 1.8748733e-03],
       [9.9446940e-01, 3.8145322e-04, 5.1491160e-03],
       [1.3016548e-04, 9.6950770e-01, 3.0362180e-02],
       [2.2221422e-02, 3.6178170e-01, 6.1599684e-01],
       [2.3866760e-02, 4.9554625e-01, 4.8058695e-01],
       [6.7624927e-04, 6.9033235e-01, 3.0899146e-01],
       [2.2374978e-07, 9.9981123e-01, 1.8849684e-04],
       [2.9734123e-01, 6.2499960e-01, 7.7659205e-02],
       [7.0935505e-07, 9.9926320e-01, 7.3602740e-04],
       [4.9890470e-04, 9.2361486e-01, 7.5886264e-02],
       [5.1381870e-06, 9.9908470e-01, 9.1019150e-04],
       [2.5810255e-04, 9.9968255e-01, 5.9328097e-05],
       [1.4184709e-05, 9.9913470e-01, 8.5112115e-04],
       [7.3149043e-01, 1.2710330e-03, 2.6723853e-01]])</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[50]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">ovo4</span> <span class="o">=</span> <span class="n">rocauc_ovo</span><span class="p">(</span><span class="n">y_test_over</span><span class="p">,</span> <span class="n">y_prob4</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s2">&quot;macro&quot;</span><span class="p">,</span> <span class="n">multi_class</span><span class="o">=</span><span class="s2">&quot;ovo&quot;</span><span class="p">)</span>
<span class="n">ovo4</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[50]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>0.9480261328885181</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[51]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">ovr4</span> <span class="o">=</span> <span class="n">rocauc_ovr</span><span class="p">(</span><span class="n">y_test_over</span><span class="p">,</span> <span class="n">y_prob4</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s2">&quot;macro&quot;</span><span class="p">,</span> <span class="n">multi_class</span><span class="o">=</span><span class="s2">&quot;ovr&quot;</span><span class="p">)</span>
<span class="n">ovr4</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[51]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>0.9480261328885181</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[52]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">ovos</span> <span class="o">=</span> <span class="p">[</span><span class="n">ovo1</span><span class="p">,</span> <span class="n">ovo2</span><span class="p">,</span> <span class="n">ovo3</span><span class="p">,</span> <span class="n">ovo4</span><span class="p">]</span>
<span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">ovos</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[52]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>0.9412656766441169</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[53]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">ovos</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[53]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>0.006362533807018114</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[54]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">ovrs</span> <span class="o">=</span> <span class="p">[</span><span class="n">ovr1</span><span class="p">,</span> <span class="n">ovr2</span><span class="p">,</span> <span class="n">ovr3</span><span class="p">,</span> <span class="n">ovr4</span><span class="p">]</span>
<span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">ovrs</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[54]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>0.9412656766441169</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[55]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">ovrs</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[55]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>0.006362533807018114</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[122]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">accs</span> <span class="o">=</span> <span class="p">[</span><span class="n">acc_test_over</span><span class="p">,</span> <span class="n">acc_test_over2</span><span class="p">,</span> <span class="n">acc_test_over3</span><span class="p">,</span> <span class="n">acc_test_over4</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[123]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">accs</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;over-sampling test accuracy mean: </span><span class="si">%.2f%%</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">mean</span><span class="o">*</span><span class="mi">100</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>over-sampling test accuracy mean: 80.67%
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[124]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">accs</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;over-sampling test accuracy standard deviation:&#39;</span><span class="p">,</span> <span class="n">std</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>over-sampling test accuracy standard deviation: 0.020577324900535585
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[125]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">accs_train</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">hist1_over</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]),</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">hist1_over2</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]),</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">hist1_over3</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]),</span>
             <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">hist1_over4</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])]</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[126]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">mean_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">accs_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;over-sampling train accuracy mean: </span><span class="si">%.2f%%</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">mean_train</span><span class="o">*</span><span class="mi">100</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>over-sampling train accuracy mean: 90.43%
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[127]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">std_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">accs_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;over-sampling train accuracy standard deviation:&#39;</span><span class="p">,</span> <span class="n">std_train</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>over-sampling train accuracy standard deviation: 0.0053634555
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[49]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">############ Feature selection using lasso ##########</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[17]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">## Retrieved from https://towardsdatascience.com/feature-selection-using-regularisation-a3678b71e499</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">Lasso</span><span class="p">,</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="kn">import</span> <span class="n">SelectFromModel</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[18]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">selection</span> <span class="o">=</span> <span class="n">SelectFromModel</span><span class="p">(</span><span class="n">LogisticRegression</span><span class="p">(</span><span class="n">C</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">penalty</span><span class="o">=</span><span class="s1">&#39;l1&#39;</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s1">&#39;liblinear&#39;</span><span class="p">))</span>
<span class="n">selection</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_over</span><span class="p">[:,</span><span class="mi">1</span><span class="p">:],</span> <span class="n">y_over</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[18]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>SelectFromModel(estimator=LogisticRegression(C=1, class_weight=None, dual=False,
                                             fit_intercept=True,
                                             intercept_scaling=1, l1_ratio=None,
                                             max_iter=100, multi_class=&#39;auto&#39;,
                                             n_jobs=None, penalty=&#39;l1&#39;,
                                             random_state=None,
                                             solver=&#39;liblinear&#39;, tol=0.0001,
                                             verbose=0, warm_start=False),
                max_features=None, norm_order=1, prefit=False, threshold=None)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[19]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">names</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">df_clean</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
<span class="n">names</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="s1">&#39;pheno&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[20]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">X_train_features_over</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span><span class="n">names</span><span class="p">,</span> <span class="n">X_over</span><span class="p">[:,</span><span class="mi">1</span><span class="p">:]))</span>
<span class="n">X_train_features_over</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X_train_features_over</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[21]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">sel_features</span> <span class="o">=</span> <span class="n">X_train_features_over</span><span class="o">.</span><span class="n">columns</span><span class="p">[(</span><span class="n">selection</span><span class="o">.</span><span class="n">get_support</span><span class="p">())]</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;total features: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">((</span><span class="n">X_train_features_over</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;selected features: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">sel_features</span><span class="p">)))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>total features: 820
selected features: 184
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[22]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">cols</span> <span class="o">=</span> <span class="n">sel_features</span><span class="o">.</span><span class="n">values</span>
<span class="n">cols</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[22]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>array([[  0,   1,   2,   3,   4,  12,  13,  14,  20,  21,  27,  29,  36,
         39,  70,  74,  75,  87,  94, 100, 101, 102, 104, 116, 125, 135,
        138, 140, 146, 156, 161, 164, 166, 168, 177, 194, 196, 198, 199,
        200, 202, 204, 206, 208, 213, 220, 229, 231, 232, 233, 241, 242,
        243, 250, 265, 266, 270, 277, 280, 288, 296, 303, 307, 308, 310,
        316, 318, 319, 323, 325, 334, 338, 344, 345, 352, 357, 359, 363,
        367, 369, 374, 380, 386, 389, 390, 395, 396, 399, 410, 417, 428,
        433, 442, 444, 445, 447, 455, 457, 463, 466, 467, 468, 470, 471,
        473, 476, 477, 481, 482, 488, 490, 497, 503, 506, 515, 517, 518,
        519, 521, 534, 541, 544, 549, 553, 558, 559, 560, 561, 562, 563,
        564, 571, 573, 581, 585, 586, 588, 589, 593, 597, 602, 603, 604,
        605, 606, 608, 614, 617, 618, 619, 628, 634, 639, 651, 652, 670,
        673, 677, 678, 685, 702, 703, 704, 705, 712, 713, 716, 737, 738,
        742, 746, 750, 751, 757, 759, 766, 768, 779, 781, 784, 788, 798,
        804, 818]])</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[23]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">names_arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">names</span><span class="p">)</span>
<span class="n">names_arr</span><span class="p">[</span><span class="n">cols</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[23]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>array([&#39;TTTTTTGTAATTTT&#39;, &#39;TTTTTTGTAATTTTT&#39;, &#39;TTTTTTATTTTGGAT&#39;,
       &#39;TTTTTTATTTTGGATAA&#39;, &#39;TTTTTTATTTTGGATAAAAGGAG&#39;, &#39;TTTTCTTTTCGT&#39;,
       &#39;TTTTCTTCTAATC&#39;, &#39;TTTTCTATTGTC&#39;,
       &#39;TTTTATGGAAGGTAATTTTAAAAATGTAAAGAAGCTTAT&#39;,
       &#39;TTTTATGGAAGGTAATTTTAAAAATGTAAAGAAGCTTATTTACGAAG&#39;,
       &#39;TTTTAATAGCTAGCACTTAATTGTGTTGGCTATTTTTTATGTCCAAAACGTGCTGATGACATAAAAAGCACGCATGGAAAAACAGTCGACAGACTATAAA&#39;,
       &#39;TTTGCCAGTATC&#39;, &#39;TTTCGCAAACTA&#39;, &#39;TTTCAGCGACT&#39;, &#39;TTGTGATGTTGTTT&#39;,
       &#39;TTGGTTTTAAATTT&#39;, &#39;TTGGTTTTAAATTTTT&#39;, &#39;TTGATAAAGTTTA&#39;,
       &#39;TTCTTTACATTTTTA&#39;, &#39;TTCTCTTCCATC&#39;, &#39;TTCTCTTCCATCCCTCATC&#39;,
       &#39;TTCTCTTCCATCCCTCATCCTCCTC&#39;, &#39;TTCTATAAAAAGT&#39;, &#39;TTCATCGTCGA&#39;,
       &#39;TTCAATCTAGAT&#39;, &#39;TTATTAGGTTCAAC&#39;, &#39;TTATCATCAAATG&#39;,
       &#39;TTATAGTCTGTCGACTGTTTTTCCATGCGTGCTTTTTATGTCATCAGCACGTTTTGGACATAAAAAATAGCCAACACAATTAAGTGCTAGCTATTAAAAG&#39;,
       &#39;TTAGGCGAAGAT&#39;, &#39;TTACGCAATAGTTTAGATGTAGA&#39;, &#39;TTACCTAAAAATAAAT&#39;,
       &#39;TTAATTGAATAACGGGAAGTAGCTCAGCTTGGTAGAGCACTTGGTTTGGGACCAAGGGGTCGCAGGTTCGAATCCTGTCTTCCCGATTACTTCTTAAATT&#39;,
       &#39;TTAACGAATAC&#39;, &#39;TTAAATTTTGCAGT&#39;, &#39;TGTTTATGGAAG&#39;, &#39;TGTCTAAATTGTT&#39;,
       &#39;TGTCCTTTGTT&#39;, &#39;TGTCCAAAACGTG&#39;, &#39;TGTCCAAAACGTGCTGA&#39;,
       &#39;TGTATTTTTTCTT&#39;, &#39;TGTAGCTGGAT&#39;, &#39;TGTACAAAATAAAAGA&#39;,
       &#39;TGGTTTTAAATTTT&#39;, &#39;TGGCGATTGTC&#39;, &#39;TGGAATGGGAGCA&#39;, &#39;TGCTCCCATTCC&#39;,
       &#39;TGCAAAATCG&#39;, &#39;TGATTTTTATCTGC&#39;, &#39;TGATTTGATGAGG&#39;,
       &#39;TGATTTGATGAGGGCGGAGGTG&#39;, &#39;TGATAACAATGTGCCT&#39;, &#39;TGATAACAATGTGCCTA&#39;,
       &#39;TGATAACAATGTGCCTAT&#39;, &#39;TGACTTTAAG&#39;, &#39;TCTTTTATTTTGT&#39;,
       &#39;TCTTTTAATAGCTAGCACTTAATTGTGTTGGCTATTTTTTATGTCCAAAACGTGCTGATGACATAAAAAGCACGCATGGAAAAACAGTCGACAGACTATA&#39;,
       &#39;TCTTCCATAAAC&#39;, &#39;TCTGTACTAAC&#39;, &#39;TCTGATTTTTTTG&#39;, &#39;TCTACTTCTTAAT&#39;,
       &#39;TCGTGTCTGT&#39;, &#39;TCGCCGTTATG&#39;, &#39;TCGAAAGAGT&#39;, &#39;TCCTTGCCTTA&#39;,
       &#39;TCCTCCTCATATTTATAGAC&#39;, &#39;TCCAGTGCTTG&#39;, &#39;TCCAAAGTATTT&#39;,
       &#39;TCCAAAGTATTTT&#39;, &#39;TCATCAAACTTT&#39;, &#39;TCAGTCTGAT&#39;, &#39;TCACTATAAGTG&#39;,
       &#39;TCACACCGCCT&#39;, &#39;TCAAAAGTTAATA&#39;, &#39;TCAAAAAGATGAAT&#39;, &#39;TATTGACTCCT&#39;,
       &#39;TATTAAATTTAAAG&#39;, &#39;TATCTTCGCCTA&#39;, &#39;TATCCAGAATG&#39;, &#39;TATAGTGTTCAT&#39;,
       &#39;TATAGGAGCC&#39;, &#39;TAGTTTAGATGT&#39;, &#39;TAGGGATTATG&#39;, &#39;TAGCTAAATCC&#39;,
       &#39;TAGATTCAAATAT&#39;, &#39;TAGAGTCGTTG&#39;, &#39;TACTTGCCTAAAT&#39;, &#39;TACTAGTCATC&#39;,
       &#39;TACGCCAGTTT&#39;, &#39;TACAGCTTTCT&#39;, &#39;TAATCTTGTTGTT&#39;, &#39;TAACTAAATTCGT&#39;,
       &#39;TAAATTAATAGGTG&#39;, &#39;TAAACTATTGCG&#39;, &#39;TAAAAGGTATCT&#39;, &#39;TAAAAGATCCAG&#39;,
       &#39;TAAAAAAGCGAT&#39;, &#39;GTTTATGGAAG&#39;, &#39;GTTTAAAATTATTC&#39;, &#39;GTTCAACTCC&#39;,
       &#39;GTTACAAACAACAT&#39;, &#39;GTTAATACTGGC&#39;,
       &#39;GTTAAACTACAAAAACAAAAGTTAACTAAAGATAT&#39;, &#39;GTGTTCATCGT&#39;,
       &#39;GTGTATTTTAAG&#39;, &#39;GTGATGTTGTTTGT&#39;, &#39;GTGAATTCATG&#39;, &#39;GTCTGATTTTTT&#39;,
       &#39;GTCGCAAATATTTC&#39;, &#39;GTCACTATAAGTGATGTTTATTCAGGATC&#39;,
       &#39;GTATTGCAACAGATTGGCTCAAAAGTTAGT&#39;, &#39;GTAGCTGGATT&#39;,
       &#39;GTAATTTTAAAAATGTAAAGAAG&#39;, &#39;GTAATAGGCAT&#39;, &#39;GGTTTTAAATTTTT&#39;,
       &#39;GGTAACGGTTTAACACGTCC&#39;, &#39;GGTAAAAACGGT&#39;, &#39;GGGGTGATTTT&#39;,
       &#39;GGGGCTCATTTT&#39;, &#39;GGGCTCATTT&#39;,
       &#39;GGAGTTGAACCTAATAAAAGTTATCAGGTGACAATAGAAAATGTACGTAGCGGTATAATGAGG&#39;,
       &#39;GCTTGACTGT&#39;, &#39;GCTCTGTGTT&#39;, &#39;GCTATAGGAG&#39;, &#39;GCGGAGTTGC&#39;,
       &#39;GCCAAGTAGT&#39;, &#39;GCATTACACCT&#39;, &#39;GCAGTAGGGATT&#39;, &#39;GCAGTAGGGATTATG&#39;,
       &#39;GCACGACGTC&#39;, &#39;GCACGACGTCTT&#39;, &#39;GCAACTCCGCT&#39;, &#39;GATTTCCCGT&#39;,
       &#39;GATTCGAAATATT&#39;, &#39;GATACGTTAGATG&#39;, &#39;GAGGGGGACGTTTAAAT&#39;,
       &#39;GAGGGATGGAAGAG&#39;, &#39;GAGGAGCAGG&#39;, &#39;GAGCGATCAG&#39;, &#39;GAGAAAGCTGTAG&#39;,
       &#39;GACACGTTAG&#39;, &#39;GAAGTCACTCG&#39;, &#39;GAAGGATTACTAAAG&#39;, &#39;GAAGGATTACTAAAGT&#39;,
       &#39;GAACTAGTTGAT&#39;, &#39;GAACGCTATTT&#39;, &#39;GAACAAGACATG&#39;, &#39;GAAAAAAGAAAATGAG&#39;,
       &#39;CTTTGCGAAGT&#39;, &#39;CTTTCATTCTTT&#39;, &#39;CTTGCCTAAAT&#39;,
       &#39;CTTCAATCTAGATAACATGTAATGATT&#39;,
       &#39;CTCTTTTAATAGCTAGCACTTAATTGTGTTGGCTATTTTTTATGTCCAAAACGTGCTGATGACATAAAAAGCACGCATGGAAAAACAGTCGACAGACTAT&#39;,
       &#39;CTCCGCTATTG&#39;, &#39;CTAATGTGGT&#39;, &#39;CTAATCCTTCAAT&#39;, &#39;CGCCTAACATG&#39;,
       &#39;CGACTAATTTTTT&#39;, &#39;CCTTGCATAGG&#39;, &#39;CCTTCGTAAAT&#39;, &#39;CCTGAAGGATT&#39;,
       &#39;CCAGTGCTTG&#39;, &#39;CCAGACATTGTT&#39;, &#39;CCAATATTCTTG&#39;, &#39;CCAATATAAGAT&#39;,
       &#39;CATCTAACGTAT&#39;, &#39;CATCAAACTTTT&#39;, &#39;CAGTCTGATTT&#39;, &#39;ATTTATCCAACTTT&#39;,
       &#39;ATTGTATGACT&#39;, &#39;ATTAATAGGTGGT&#39;, &#39;ATGGCTACTGGT&#39;, &#39;ATGAAGATAGAGT&#39;,
       &#39;ATCGTCAGCACT&#39;, &#39;ATCATCTCCGT&#39;, &#39;ATCAATACAAGTT&#39;, &#39;ATAGGCACATT&#39;,
       &#39;ATAGCGGAGTT&#39;, &#39;AGGTGTAATGCT&#39;, &#39;AGGGGTGATT&#39;, &#39;AGGCTAACTT&#39;,
       &#39;AGCATCTACTTTT&#39;, &#39;ACTGCGTTAGT&#39;, &#39;ACTAAATTCGT&#39;, &#39;AACCTAGAAAGTTT&#39;],
      dtype=&#39;&lt;U100&#39;)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[24]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">###### keep selected variables as a new dataframe</span>
<span class="n">df_sel</span> <span class="o">=</span> <span class="n">df_clean</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span><span class="n">names_arr</span><span class="p">[</span><span class="n">cols</span><span class="p">]]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">df_sel</span><span class="p">[</span><span class="s1">&#39;pheno&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_clean</span><span class="p">[</span><span class="s1">&#39;pheno&#39;</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[25]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df_sel</span><span class="p">[</span><span class="s1">&#39;strain&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[26]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df_sel</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[26]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>TTTTTTGTAATTTT</th>
      <th>TTTTTTGTAATTTTT</th>
      <th>TTTTTTATTTTGGAT</th>
      <th>TTTTTTATTTTGGATAA</th>
      <th>TTTTTTATTTTGGATAAAAGGAG</th>
      <th>TTTTCTTTTCGT</th>
      <th>TTTTCTTCTAATC</th>
      <th>TTTTCTATTGTC</th>
      <th>TTTTATGGAAGGTAATTTTAAAAATGTAAAGAAGCTTAT</th>
      <th>TTTTATGGAAGGTAATTTTAAAAATGTAAAGAAGCTTATTTACGAAG</th>
      <th>...</th>
      <th>ATAGCGGAGTT</th>
      <th>AGGTGTAATGCT</th>
      <th>AGGGGTGATT</th>
      <th>AGGCTAACTT</th>
      <th>AGCATCTACTTTT</th>
      <th>ACTGCGTTAGT</th>
      <th>ACTAAATTCGT</th>
      <th>AACCTAGAAAGTTT</th>
      <th>pheno</th>
      <th>strain</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>2</td>
      <td>107</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>...</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>109</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>2</td>
      <td>115</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>...</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>2</td>
      <td>120335</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>...</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>2</td>
      <td>120337</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>248</th>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>...</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>2</td>
      <td>SR4152</td>
    </tr>
    <tr>
      <th>249</th>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>...</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>SR4153</td>
    </tr>
    <tr>
      <th>250</th>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>...</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>2</td>
      <td>SR4155</td>
    </tr>
    <tr>
      <th>251</th>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>2</td>
      <td>SR4156</td>
    </tr>
    <tr>
      <th>252</th>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>...</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>2</td>
      <td>SR4187</td>
    </tr>
  </tbody>
</table>
<p>253 rows × 186 columns</p>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[27]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">X_sel</span> <span class="o">=</span> <span class="n">df_sel</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">df_sel</span><span class="o">.</span><span class="n">columns</span> <span class="o">!=</span> <span class="s1">&#39;pheno&#39;</span><span class="p">]</span>
<span class="n">y_sel</span> <span class="o">=</span> <span class="n">df_sel</span><span class="p">[</span><span class="s1">&#39;pheno&#39;</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">X_sel</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y_sel</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">df_sel</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>(253, 185) (253,) (253, 186)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[28]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df_sel</span><span class="p">[</span><span class="s1">&#39;pheno&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[28]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>2    181
1     47
0     25
Name: pheno, dtype: int64</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[29]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># over-sampling</span>
<span class="kn">from</span> <span class="nn">imblearn.over_sampling</span> <span class="kn">import</span> <span class="n">RandomOverSampler</span>
<span class="n">overS</span> <span class="o">=</span> <span class="n">RandomOverSampler</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">X_sel_over</span><span class="p">,</span> <span class="n">y_sel_over</span> <span class="o">=</span> <span class="n">overS</span><span class="o">.</span><span class="n">fit_resample</span><span class="p">(</span><span class="n">X_sel</span><span class="p">,</span> <span class="n">y_sel</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">sorted</span><span class="p">(</span><span class="n">Counter</span><span class="p">(</span><span class="n">y_sel_over</span><span class="p">)</span><span class="o">.</span><span class="n">items</span><span class="p">()))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[(0, 181), (1, 181), (2, 181)]
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.
  warnings.warn(msg, category=FutureWarning)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[30]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># split into train, test data (over)</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="n">X_sel_train_over</span><span class="p">,</span> <span class="n">X_sel_test_over</span><span class="p">,</span> <span class="n">y_sel_train_over</span><span class="p">,</span> <span class="n">y_sel_test_over</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X_sel_over</span><span class="p">,</span> <span class="n">y_sel_over</span><span class="p">,</span>
                                                    <span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.3</span><span class="p">,</span>
                                                    <span class="n">random_state</span><span class="o">=</span><span class="mi">567</span><span class="p">,</span>
                                                    <span class="n">stratify</span><span class="o">=</span><span class="n">y_sel_over</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[31]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dat5</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X_sel_test_over</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
<span class="n">dat5</span><span class="p">[</span><span class="s1">&#39;test&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">y_sel_test_over</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[32]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dat5</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[32]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>test</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>CFBRSa49</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>NRS108</td>
      <td>2</td>
    </tr>
    <tr>
      <th>2</th>
      <td>MN105</td>
      <td>2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>CFBRSa03</td>
      <td>2</td>
    </tr>
    <tr>
      <th>4</th>
      <td>BCH-SA-01</td>
      <td>0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>158</th>
      <td>NRS027</td>
      <td>0</td>
    </tr>
    <tr>
      <th>159</th>
      <td>BCH-SA-04</td>
      <td>0</td>
    </tr>
    <tr>
      <th>160</th>
      <td>SR3585</td>
      <td>2</td>
    </tr>
    <tr>
      <th>161</th>
      <td>504</td>
      <td>1</td>
    </tr>
    <tr>
      <th>162</th>
      <td>NRS149</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>163 rows × 2 columns</p>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[33]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">X_sel_train_over</span> <span class="o">=</span> <span class="n">X_sel_train_over</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">X_sel_test_over</span> <span class="o">=</span> <span class="n">X_sel_test_over</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[83]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#### neural network on over-sampling data</span>
<span class="n">model2_over</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">([</span>
    <span class="n">Dense</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="n">X_sel_train_over</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],)),</span>
    <span class="n">Dense</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">),</span>
    <span class="n">Dense</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">),</span>
<span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[84]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model2_over</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span>
              <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;sparse_categorical_crossentropy&#39;</span><span class="p">,</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[85]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model2_over</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_sel_train_over</span><span class="p">,</span> <span class="n">y_sel_train_over</span><span class="p">,</span>
          <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
          <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">X_sel_test_over</span><span class="p">,</span> <span class="n">y_sel_test_over</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Train on 380 samples, validate on 163 samples
Epoch 1/100
380/380 [==============================] - 0s 499us/step - loss: 1.1424 - accuracy: 0.3342 - val_loss: 1.0788 - val_accuracy: 0.4294
Epoch 2/100
380/380 [==============================] - 0s 81us/step - loss: 1.0708 - accuracy: 0.4368 - val_loss: 1.0371 - val_accuracy: 0.4724
Epoch 3/100
380/380 [==============================] - 0s 98us/step - loss: 1.0193 - accuracy: 0.4895 - val_loss: 1.0172 - val_accuracy: 0.4601
Epoch 4/100
380/380 [==============================] - 0s 101us/step - loss: 0.9796 - accuracy: 0.5158 - val_loss: 0.9844 - val_accuracy: 0.6012
Epoch 5/100
380/380 [==============================] - 0s 112us/step - loss: 0.9393 - accuracy: 0.5895 - val_loss: 0.9506 - val_accuracy: 0.5828
Epoch 6/100
380/380 [==============================] - 0s 105us/step - loss: 0.9007 - accuracy: 0.6632 - val_loss: 0.9176 - val_accuracy: 0.6442
Epoch 7/100
380/380 [==============================] - 0s 118us/step - loss: 0.8682 - accuracy: 0.6632 - val_loss: 0.8854 - val_accuracy: 0.6503
Epoch 8/100
380/380 [==============================] - 0s 96us/step - loss: 0.8346 - accuracy: 0.6868 - val_loss: 0.8604 - val_accuracy: 0.6503
Epoch 9/100
380/380 [==============================] - 0s 80us/step - loss: 0.8031 - accuracy: 0.6921 - val_loss: 0.8390 - val_accuracy: 0.7301
Epoch 10/100
380/380 [==============================] - 0s 64us/step - loss: 0.7748 - accuracy: 0.7237 - val_loss: 0.8120 - val_accuracy: 0.6810
Epoch 11/100
380/380 [==============================] - 0s 73us/step - loss: 0.7508 - accuracy: 0.7000 - val_loss: 0.7894 - val_accuracy: 0.7485
Epoch 12/100
380/380 [==============================] - 0s 86us/step - loss: 0.7210 - accuracy: 0.7395 - val_loss: 0.7640 - val_accuracy: 0.7239
Epoch 13/100
380/380 [==============================] - 0s 85us/step - loss: 0.7025 - accuracy: 0.7368 - val_loss: 0.7434 - val_accuracy: 0.7178
Epoch 14/100
380/380 [==============================] - 0s 91us/step - loss: 0.6741 - accuracy: 0.7395 - val_loss: 0.7198 - val_accuracy: 0.7178
Epoch 15/100
380/380 [==============================] - 0s 111us/step - loss: 0.6504 - accuracy: 0.7342 - val_loss: 0.7033 - val_accuracy: 0.7607
Epoch 16/100
380/380 [==============================] - 0s 77us/step - loss: 0.6312 - accuracy: 0.7763 - val_loss: 0.6821 - val_accuracy: 0.7239
Epoch 17/100
380/380 [==============================] - 0s 65us/step - loss: 0.6073 - accuracy: 0.7789 - val_loss: 0.6656 - val_accuracy: 0.7117
Epoch 18/100
380/380 [==============================] - 0s 112us/step - loss: 0.5870 - accuracy: 0.7658 - val_loss: 0.6492 - val_accuracy: 0.7362
Epoch 19/100
380/380 [==============================] - 0s 62us/step - loss: 0.5817 - accuracy: 0.8053 - val_loss: 0.6355 - val_accuracy: 0.7117
Epoch 20/100
380/380 [==============================] - 0s 53us/step - loss: 0.5677 - accuracy: 0.7684 - val_loss: 0.6280 - val_accuracy: 0.7362
Epoch 21/100
380/380 [==============================] - 0s 58us/step - loss: 0.5447 - accuracy: 0.8263 - val_loss: 0.6180 - val_accuracy: 0.7607
Epoch 22/100
380/380 [==============================] - 0s 63us/step - loss: 0.5317 - accuracy: 0.8053 - val_loss: 0.6047 - val_accuracy: 0.7546
Epoch 23/100
380/380 [==============================] - 0s 83us/step - loss: 0.5107 - accuracy: 0.8132 - val_loss: 0.5928 - val_accuracy: 0.7239
Epoch 24/100
380/380 [==============================] - 0s 78us/step - loss: 0.5003 - accuracy: 0.8158 - val_loss: 0.5815 - val_accuracy: 0.7975
Epoch 25/100
380/380 [==============================] - 0s 67us/step - loss: 0.4830 - accuracy: 0.8553 - val_loss: 0.5659 - val_accuracy: 0.7607
Epoch 26/100
380/380 [==============================] - 0s 71us/step - loss: 0.4663 - accuracy: 0.8500 - val_loss: 0.5524 - val_accuracy: 0.7975
Epoch 27/100
380/380 [==============================] - 0s 96us/step - loss: 0.4465 - accuracy: 0.8553 - val_loss: 0.5434 - val_accuracy: 0.7791
Epoch 28/100
380/380 [==============================] - 0s 89us/step - loss: 0.4365 - accuracy: 0.8605 - val_loss: 0.5372 - val_accuracy: 0.8037
Epoch 29/100
380/380 [==============================] - 0s 80us/step - loss: 0.4197 - accuracy: 0.8579 - val_loss: 0.5290 - val_accuracy: 0.8037
Epoch 30/100
380/380 [==============================] - 0s 80us/step - loss: 0.4183 - accuracy: 0.8553 - val_loss: 0.5126 - val_accuracy: 0.7791
Epoch 31/100
380/380 [==============================] - 0s 84us/step - loss: 0.4067 - accuracy: 0.8500 - val_loss: 0.5288 - val_accuracy: 0.7853
Epoch 32/100
380/380 [==============================] - 0s 127us/step - loss: 0.3967 - accuracy: 0.8526 - val_loss: 0.4976 - val_accuracy: 0.8098
Epoch 33/100
380/380 [==============================] - 0s 127us/step - loss: 0.3777 - accuracy: 0.8737 - val_loss: 0.5031 - val_accuracy: 0.8037
Epoch 34/100
380/380 [==============================] - 0s 118us/step - loss: 0.3751 - accuracy: 0.8632 - val_loss: 0.4857 - val_accuracy: 0.8098
Epoch 35/100
380/380 [==============================] - 0s 123us/step - loss: 0.3635 - accuracy: 0.8737 - val_loss: 0.4733 - val_accuracy: 0.8098
Epoch 36/100
380/380 [==============================] - 0s 99us/step - loss: 0.3548 - accuracy: 0.8737 - val_loss: 0.4697 - val_accuracy: 0.8098
Epoch 37/100
380/380 [==============================] - 0s 69us/step - loss: 0.3469 - accuracy: 0.8816 - val_loss: 0.4646 - val_accuracy: 0.8160
Epoch 38/100
380/380 [==============================] - 0s 81us/step - loss: 0.3462 - accuracy: 0.8789 - val_loss: 0.4712 - val_accuracy: 0.7975
Epoch 39/100
380/380 [==============================] - 0s 67us/step - loss: 0.3472 - accuracy: 0.8684 - val_loss: 0.4697 - val_accuracy: 0.8221
Epoch 40/100
380/380 [==============================] - 0s 67us/step - loss: 0.3330 - accuracy: 0.8737 - val_loss: 0.4540 - val_accuracy: 0.7853
Epoch 41/100
380/380 [==============================] - 0s 65us/step - loss: 0.3294 - accuracy: 0.8763 - val_loss: 0.4663 - val_accuracy: 0.7975
Epoch 42/100
380/380 [==============================] - 0s 67us/step - loss: 0.3191 - accuracy: 0.8737 - val_loss: 0.4380 - val_accuracy: 0.7914
Epoch 43/100
380/380 [==============================] - 0s 107us/step - loss: 0.3188 - accuracy: 0.8763 - val_loss: 0.4318 - val_accuracy: 0.8098
Epoch 44/100
380/380 [==============================] - 0s 104us/step - loss: 0.3098 - accuracy: 0.8921 - val_loss: 0.4422 - val_accuracy: 0.8037
Epoch 45/100
380/380 [==============================] - 0s 133us/step - loss: 0.3039 - accuracy: 0.8868 - val_loss: 0.4234 - val_accuracy: 0.8098
Epoch 46/100
380/380 [==============================] - 0s 98us/step - loss: 0.3123 - accuracy: 0.8684 - val_loss: 0.4115 - val_accuracy: 0.7975
Epoch 47/100
380/380 [==============================] - 0s 137us/step - loss: 0.3007 - accuracy: 0.8816 - val_loss: 0.4339 - val_accuracy: 0.8037
Epoch 48/100
380/380 [==============================] - 0s 141us/step - loss: 0.2981 - accuracy: 0.8947 - val_loss: 0.4023 - val_accuracy: 0.8160
Epoch 49/100
380/380 [==============================] - 0s 111us/step - loss: 0.2839 - accuracy: 0.9000 - val_loss: 0.3987 - val_accuracy: 0.8282
Epoch 50/100
380/380 [==============================] - 0s 128us/step - loss: 0.2707 - accuracy: 0.9105 - val_loss: 0.4054 - val_accuracy: 0.8221
Epoch 51/100
380/380 [==============================] - 0s 113us/step - loss: 0.2692 - accuracy: 0.9053 - val_loss: 0.3944 - val_accuracy: 0.8221
Epoch 52/100
380/380 [==============================] - 0s 127us/step - loss: 0.2670 - accuracy: 0.9079 - val_loss: 0.3959 - val_accuracy: 0.8221
Epoch 53/100
380/380 [==============================] - 0s 166us/step - loss: 0.2617 - accuracy: 0.9105 - val_loss: 0.3820 - val_accuracy: 0.8282
Epoch 54/100
380/380 [==============================] - 0s 115us/step - loss: 0.2599 - accuracy: 0.9053 - val_loss: 0.3812 - val_accuracy: 0.8221
Epoch 55/100
380/380 [==============================] - 0s 94us/step - loss: 0.2513 - accuracy: 0.9105 - val_loss: 0.3843 - val_accuracy: 0.8221
Epoch 56/100
380/380 [==============================] - 0s 105us/step - loss: 0.2505 - accuracy: 0.9105 - val_loss: 0.3656 - val_accuracy: 0.8344
Epoch 57/100
380/380 [==============================] - 0s 119us/step - loss: 0.2486 - accuracy: 0.9132 - val_loss: 0.3731 - val_accuracy: 0.8405
Epoch 58/100
380/380 [==============================] - 0s 86us/step - loss: 0.2440 - accuracy: 0.9132 - val_loss: 0.3794 - val_accuracy: 0.8282
Epoch 59/100
380/380 [==============================] - 0s 104us/step - loss: 0.2447 - accuracy: 0.9105 - val_loss: 0.3716 - val_accuracy: 0.8528
Epoch 60/100
380/380 [==============================] - 0s 140us/step - loss: 0.2396 - accuracy: 0.9132 - val_loss: 0.3820 - val_accuracy: 0.8221
Epoch 61/100
380/380 [==============================] - 0s 114us/step - loss: 0.2337 - accuracy: 0.9158 - val_loss: 0.3524 - val_accuracy: 0.8528
Epoch 62/100
380/380 [==============================] - 0s 95us/step - loss: 0.2404 - accuracy: 0.9026 - val_loss: 0.3737 - val_accuracy: 0.8528
Epoch 63/100
380/380 [==============================] - 0s 99us/step - loss: 0.2416 - accuracy: 0.9158 - val_loss: 0.3529 - val_accuracy: 0.8589
Epoch 64/100
380/380 [==============================] - 0s 77us/step - loss: 0.2304 - accuracy: 0.9184 - val_loss: 0.3496 - val_accuracy: 0.8405
Epoch 65/100
380/380 [==============================] - 0s 157us/step - loss: 0.2236 - accuracy: 0.9158 - val_loss: 0.3654 - val_accuracy: 0.8466
Epoch 66/100
380/380 [==============================] - 0s 206us/step - loss: 0.2227 - accuracy: 0.9158 - val_loss: 0.3399 - val_accuracy: 0.8528
Epoch 67/100
380/380 [==============================] - 0s 139us/step - loss: 0.2371 - accuracy: 0.9158 - val_loss: 0.3635 - val_accuracy: 0.8528
Epoch 68/100
380/380 [==============================] - 0s 231us/step - loss: 0.2382 - accuracy: 0.9026 - val_loss: 0.3574 - val_accuracy: 0.8528
Epoch 69/100
380/380 [==============================] - 0s 186us/step - loss: 0.2314 - accuracy: 0.9026 - val_loss: 0.3393 - val_accuracy: 0.8650
Epoch 70/100
380/380 [==============================] - 0s 143us/step - loss: 0.2246 - accuracy: 0.9132 - val_loss: 0.3614 - val_accuracy: 0.8589
Epoch 71/100
380/380 [==============================] - 0s 96us/step - loss: 0.2309 - accuracy: 0.9105 - val_loss: 0.3319 - val_accuracy: 0.8528
Epoch 72/100
380/380 [==============================] - 0s 80us/step - loss: 0.2255 - accuracy: 0.9053 - val_loss: 0.3902 - val_accuracy: 0.8466
Epoch 73/100
380/380 [==============================] - 0s 77us/step - loss: 0.2446 - accuracy: 0.8974 - val_loss: 0.3635 - val_accuracy: 0.8282
Epoch 74/100
380/380 [==============================] - 0s 78us/step - loss: 0.2227 - accuracy: 0.9158 - val_loss: 0.3339 - val_accuracy: 0.8528
Epoch 75/100
380/380 [==============================] - 0s 101us/step - loss: 0.2156 - accuracy: 0.9105 - val_loss: 0.3774 - val_accuracy: 0.8282
Epoch 76/100
380/380 [==============================] - 0s 126us/step - loss: 0.2150 - accuracy: 0.9184 - val_loss: 0.3295 - val_accuracy: 0.8466
Epoch 77/100
380/380 [==============================] - 0s 139us/step - loss: 0.2067 - accuracy: 0.9237 - val_loss: 0.3631 - val_accuracy: 0.8405
Epoch 78/100
380/380 [==============================] - 0s 126us/step - loss: 0.2078 - accuracy: 0.9211 - val_loss: 0.3290 - val_accuracy: 0.8712
Epoch 79/100
380/380 [==============================] - 0s 129us/step - loss: 0.2098 - accuracy: 0.9263 - val_loss: 0.3249 - val_accuracy: 0.8650
Epoch 80/100
380/380 [==============================] - 0s 87us/step - loss: 0.2026 - accuracy: 0.9237 - val_loss: 0.3364 - val_accuracy: 0.8589
Epoch 81/100
380/380 [==============================] - 0s 84us/step - loss: 0.1994 - accuracy: 0.9263 - val_loss: 0.3265 - val_accuracy: 0.8650
Epoch 82/100
380/380 [==============================] - 0s 84us/step - loss: 0.2004 - accuracy: 0.9263 - val_loss: 0.3353 - val_accuracy: 0.8650
Epoch 83/100
380/380 [==============================] - 0s 74us/step - loss: 0.1968 - accuracy: 0.9263 - val_loss: 0.3392 - val_accuracy: 0.8528
Epoch 84/100
380/380 [==============================] - 0s 92us/step - loss: 0.1946 - accuracy: 0.9211 - val_loss: 0.3179 - val_accuracy: 0.8650
Epoch 85/100
380/380 [==============================] - 0s 107us/step - loss: 0.1924 - accuracy: 0.9289 - val_loss: 0.3318 - val_accuracy: 0.8712
Epoch 86/100
380/380 [==============================] - 0s 115us/step - loss: 0.1999 - accuracy: 0.9184 - val_loss: 0.3191 - val_accuracy: 0.8712
Epoch 87/100
380/380 [==============================] - 0s 112us/step - loss: 0.1962 - accuracy: 0.9211 - val_loss: 0.3643 - val_accuracy: 0.8405
Epoch 88/100
380/380 [==============================] - 0s 130us/step - loss: 0.1954 - accuracy: 0.9211 - val_loss: 0.3135 - val_accuracy: 0.8773
Epoch 89/100
380/380 [==============================] - 0s 134us/step - loss: 0.1965 - accuracy: 0.9211 - val_loss: 0.3225 - val_accuracy: 0.8712
Epoch 90/100
380/380 [==============================] - 0s 107us/step - loss: 0.2017 - accuracy: 0.9158 - val_loss: 0.3438 - val_accuracy: 0.8650
Epoch 91/100
380/380 [==============================] - 0s 108us/step - loss: 0.1950 - accuracy: 0.9237 - val_loss: 0.3167 - val_accuracy: 0.8650
Epoch 92/100
380/380 [==============================] - 0s 99us/step - loss: 0.1889 - accuracy: 0.9263 - val_loss: 0.3226 - val_accuracy: 0.8589
Epoch 93/100
380/380 [==============================] - 0s 112us/step - loss: 0.1924 - accuracy: 0.9263 - val_loss: 0.3433 - val_accuracy: 0.8466
Epoch 94/100
380/380 [==============================] - 0s 95us/step - loss: 0.2094 - accuracy: 0.9237 - val_loss: 0.3350 - val_accuracy: 0.8589
Epoch 95/100
380/380 [==============================] - 0s 89us/step - loss: 0.2004 - accuracy: 0.9158 - val_loss: 0.3214 - val_accuracy: 0.8589
Epoch 96/100
380/380 [==============================] - 0s 93us/step - loss: 0.1990 - accuracy: 0.9263 - val_loss: 0.3030 - val_accuracy: 0.8712
Epoch 97/100
380/380 [==============================] - 0s 92us/step - loss: 0.1829 - accuracy: 0.9289 - val_loss: 0.3215 - val_accuracy: 0.8712
Epoch 98/100
380/380 [==============================] - 0s 124us/step - loss: 0.1903 - accuracy: 0.9237 - val_loss: 0.3086 - val_accuracy: 0.8712
Epoch 99/100
380/380 [==============================] - 0s 99us/step - loss: 0.2031 - accuracy: 0.9263 - val_loss: 0.3087 - val_accuracy: 0.8773
Epoch 100/100
380/380 [==============================] - 0s 117us/step - loss: 0.2090 - accuracy: 0.9105 - val_loss: 0.3601 - val_accuracy: 0.8466
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[85]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&lt;keras.callbacks.callbacks.History at 0x1a43c73630&gt;</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[164]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">acc_test2_over</span> <span class="o">=</span> <span class="n">model2_over</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_sel_test_over</span><span class="p">,</span> <span class="n">y_sel_test_over</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;over-sampling test accuracy: </span><span class="si">%.2f%%</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">acc_test2_over</span><span class="o">*</span><span class="mi">100</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>163/163 [==============================] - 0s 104us/step
over-sampling test accuracy: 84.05%
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[86]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">pred5</span> <span class="o">=</span> <span class="n">model2_over</span><span class="o">.</span><span class="n">predict_classes</span><span class="p">(</span><span class="n">X_sel_test_over</span><span class="p">)</span>
<span class="n">pred5</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[86]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>array([1, 2, 1, 2, 0, 1, 1, 2, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 2, 2, 1, 1,
       0, 2, 0, 1, 2, 1, 0, 2, 2, 0, 1, 0, 1, 1, 1, 0, 1, 2, 2, 2, 2, 1,
       0, 1, 1, 0, 1, 2, 1, 2, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 2, 2, 1, 2,
       1, 0, 2, 1, 2, 0, 2, 0, 0, 1, 2, 0, 0, 0, 0, 0, 2, 1, 1, 0, 1, 0,
       0, 1, 2, 1, 1, 1, 2, 2, 0, 1, 0, 0, 1, 1, 1, 0, 2, 1, 2, 1, 1, 2,
       1, 0, 2, 1, 1, 0, 0, 1, 1, 2, 1, 0, 1, 0, 0, 1, 2, 0, 2, 1, 1, 2,
       1, 0, 0, 2, 1, 0, 0, 0, 0, 1, 2, 2, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1,
       0, 1, 0, 1, 0, 0, 1, 1, 0])</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[87]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dat5</span><span class="p">[</span><span class="s1">&#39;pred&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pred5</span>
<span class="n">dat5</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[87]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>test</th>
      <th>pred</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>CFBRSa49</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>NRS108</td>
      <td>2</td>
      <td>2</td>
    </tr>
    <tr>
      <th>2</th>
      <td>MN105</td>
      <td>2</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>CFBRSa03</td>
      <td>2</td>
      <td>2</td>
    </tr>
    <tr>
      <th>4</th>
      <td>BCH-SA-01</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>158</th>
      <td>NRS027</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>159</th>
      <td>BCH-SA-04</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>160</th>
      <td>SR3585</td>
      <td>2</td>
      <td>1</td>
    </tr>
    <tr>
      <th>161</th>
      <td>504</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>162</th>
      <td>NRS149</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>163 rows × 3 columns</p>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[88]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">proba5</span> <span class="o">=</span> <span class="n">model2_over</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_sel_test_over</span><span class="p">)</span>
<span class="n">dat_proba5</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">proba5</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[89]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dat_proba5</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[89]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.411915</td>
      <td>0.469525</td>
      <td>0.118560</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.000185</td>
      <td>0.009521</td>
      <td>0.990294</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.000036</td>
      <td>0.863504</td>
      <td>0.136460</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.000045</td>
      <td>0.000156</td>
      <td>0.999799</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.973129</td>
      <td>0.000358</td>
      <td>0.026513</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>158</th>
      <td>0.996810</td>
      <td>0.000148</td>
      <td>0.003042</td>
    </tr>
    <tr>
      <th>159</th>
      <td>0.992484</td>
      <td>0.004105</td>
      <td>0.003411</td>
    </tr>
    <tr>
      <th>160</th>
      <td>0.262175</td>
      <td>0.461844</td>
      <td>0.275981</td>
    </tr>
    <tr>
      <th>161</th>
      <td>0.006449</td>
      <td>0.981863</td>
      <td>0.011687</td>
    </tr>
    <tr>
      <th>162</th>
      <td>0.997835</td>
      <td>0.000292</td>
      <td>0.001874</td>
    </tr>
  </tbody>
</table>
<p>163 rows × 3 columns</p>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[90]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dat_proba5</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s2">&quot;/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba5.csv&quot;</span><span class="p">,</span> <span class="n">index</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
         <span class="n">header</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[91]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dat5</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s2">&quot;/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/5p11.csv&quot;</span><span class="p">,</span> <span class="n">index</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
         <span class="n">header</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[168]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">hist2_over</span> <span class="o">=</span> <span class="n">model2_over</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_sel_train_over</span><span class="p">,</span> <span class="n">y_sel_train_over</span><span class="p">,</span>
          <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
          <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">X_sel_test_over</span><span class="p">,</span> <span class="n">y_sel_test_over</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Train on 380 samples, validate on 163 samples
Epoch 1/100
380/380 [==============================] - 0s 91us/step - loss: 0.2082 - accuracy: 0.9237 - val_loss: 0.3912 - val_accuracy: 0.8221
Epoch 2/100
380/380 [==============================] - 0s 106us/step - loss: 0.2081 - accuracy: 0.9158 - val_loss: 0.3695 - val_accuracy: 0.8405
Epoch 3/100
380/380 [==============================] - 0s 102us/step - loss: 0.2050 - accuracy: 0.9184 - val_loss: 0.3856 - val_accuracy: 0.8282
Epoch 4/100
380/380 [==============================] - 0s 72us/step - loss: 0.2001 - accuracy: 0.9263 - val_loss: 0.3812 - val_accuracy: 0.8221
Epoch 5/100
380/380 [==============================] - 0s 70us/step - loss: 0.1888 - accuracy: 0.9211 - val_loss: 0.3737 - val_accuracy: 0.8282
Epoch 6/100
380/380 [==============================] - 0s 75us/step - loss: 0.1957 - accuracy: 0.9263 - val_loss: 0.3579 - val_accuracy: 0.8282
Epoch 7/100
380/380 [==============================] - 0s 68us/step - loss: 0.2014 - accuracy: 0.9184 - val_loss: 0.3362 - val_accuracy: 0.8528
Epoch 8/100
380/380 [==============================] - 0s 76us/step - loss: 0.2012 - accuracy: 0.9237 - val_loss: 0.4328 - val_accuracy: 0.8221
Epoch 9/100
380/380 [==============================] - 0s 68us/step - loss: 0.1852 - accuracy: 0.9263 - val_loss: 0.3578 - val_accuracy: 0.8344
Epoch 10/100
380/380 [==============================] - 0s 65us/step - loss: 0.1855 - accuracy: 0.9289 - val_loss: 0.3862 - val_accuracy: 0.8160
Epoch 11/100
380/380 [==============================] - 0s 73us/step - loss: 0.1886 - accuracy: 0.9263 - val_loss: 0.3664 - val_accuracy: 0.8221
Epoch 12/100
380/380 [==============================] - 0s 66us/step - loss: 0.1888 - accuracy: 0.9263 - val_loss: 0.4399 - val_accuracy: 0.8160
Epoch 13/100
380/380 [==============================] - ETA: 0s - loss: 0.1796 - accuracy: 0.92 - 0s 70us/step - loss: 0.2018 - accuracy: 0.9263 - val_loss: 0.3616 - val_accuracy: 0.8405
Epoch 14/100
380/380 [==============================] - 0s 69us/step - loss: 0.1902 - accuracy: 0.9237 - val_loss: 0.4008 - val_accuracy: 0.8221
Epoch 15/100
380/380 [==============================] - 0s 71us/step - loss: 0.1883 - accuracy: 0.9237 - val_loss: 0.3582 - val_accuracy: 0.8405
Epoch 16/100
380/380 [==============================] - 0s 88us/step - loss: 0.1824 - accuracy: 0.9263 - val_loss: 0.3493 - val_accuracy: 0.8466
Epoch 17/100
380/380 [==============================] - 0s 69us/step - loss: 0.1850 - accuracy: 0.9263 - val_loss: 0.4270 - val_accuracy: 0.8221
Epoch 18/100
380/380 [==============================] - 0s 70us/step - loss: 0.1967 - accuracy: 0.9211 - val_loss: 0.3365 - val_accuracy: 0.8466
Epoch 19/100
380/380 [==============================] - 0s 71us/step - loss: 0.1994 - accuracy: 0.9184 - val_loss: 0.4388 - val_accuracy: 0.8160
Epoch 20/100
380/380 [==============================] - 0s 70us/step - loss: 0.1857 - accuracy: 0.9237 - val_loss: 0.3281 - val_accuracy: 0.8589
Epoch 21/100
380/380 [==============================] - 0s 71us/step - loss: 0.2032 - accuracy: 0.9158 - val_loss: 0.5143 - val_accuracy: 0.7914
Epoch 22/100
380/380 [==============================] - 0s 70us/step - loss: 0.1852 - accuracy: 0.9053 - val_loss: 0.3500 - val_accuracy: 0.8344
Epoch 23/100
380/380 [==============================] - 0s 73us/step - loss: 0.2125 - accuracy: 0.9132 - val_loss: 0.5561 - val_accuracy: 0.7730
Epoch 24/100
380/380 [==============================] - 0s 63us/step - loss: 0.2029 - accuracy: 0.9053 - val_loss: 0.3333 - val_accuracy: 0.8589
Epoch 25/100
380/380 [==============================] - 0s 64us/step - loss: 0.2124 - accuracy: 0.9158 - val_loss: 0.4295 - val_accuracy: 0.8098
Epoch 26/100
380/380 [==============================] - 0s 74us/step - loss: 0.2091 - accuracy: 0.9184 - val_loss: 0.3719 - val_accuracy: 0.8344
Epoch 27/100
380/380 [==============================] - 0s 75us/step - loss: 0.1944 - accuracy: 0.9289 - val_loss: 0.3821 - val_accuracy: 0.8282
Epoch 28/100
380/380 [==============================] - 0s 72us/step - loss: 0.1837 - accuracy: 0.9289 - val_loss: 0.3437 - val_accuracy: 0.8405
Epoch 29/100
380/380 [==============================] - 0s 81us/step - loss: 0.1835 - accuracy: 0.9289 - val_loss: 0.3491 - val_accuracy: 0.8282
Epoch 30/100
380/380 [==============================] - 0s 79us/step - loss: 0.1901 - accuracy: 0.9132 - val_loss: 0.3694 - val_accuracy: 0.8344
Epoch 31/100
380/380 [==============================] - 0s 87us/step - loss: 0.1905 - accuracy: 0.9184 - val_loss: 0.3684 - val_accuracy: 0.8344
Epoch 32/100
380/380 [==============================] - 0s 72us/step - loss: 0.1850 - accuracy: 0.9263 - val_loss: 0.4353 - val_accuracy: 0.8221
Epoch 33/100
380/380 [==============================] - 0s 102us/step - loss: 0.2018 - accuracy: 0.9105 - val_loss: 0.3519 - val_accuracy: 0.8405
Epoch 34/100
380/380 [==============================] - 0s 67us/step - loss: 0.1858 - accuracy: 0.9211 - val_loss: 0.5045 - val_accuracy: 0.7914
Epoch 35/100
380/380 [==============================] - 0s 67us/step - loss: 0.1789 - accuracy: 0.9237 - val_loss: 0.3411 - val_accuracy: 0.8589
Epoch 36/100
380/380 [==============================] - 0s 84us/step - loss: 0.2086 - accuracy: 0.9158 - val_loss: 0.4538 - val_accuracy: 0.8098
Epoch 37/100
380/380 [==============================] - 0s 64us/step - loss: 0.1824 - accuracy: 0.9237 - val_loss: 0.3488 - val_accuracy: 0.8344
Epoch 38/100
380/380 [==============================] - 0s 75us/step - loss: 0.1854 - accuracy: 0.9158 - val_loss: 0.4032 - val_accuracy: 0.8221
Epoch 39/100
380/380 [==============================] - 0s 71us/step - loss: 0.1782 - accuracy: 0.9211 - val_loss: 0.3595 - val_accuracy: 0.8344
Epoch 40/100
380/380 [==============================] - 0s 56us/step - loss: 0.1712 - accuracy: 0.9289 - val_loss: 0.4154 - val_accuracy: 0.8221
Epoch 41/100
380/380 [==============================] - 0s 62us/step - loss: 0.1842 - accuracy: 0.9237 - val_loss: 0.3441 - val_accuracy: 0.8344
Epoch 42/100
380/380 [==============================] - 0s 59us/step - loss: 0.1744 - accuracy: 0.9289 - val_loss: 0.3950 - val_accuracy: 0.8221
Epoch 43/100
380/380 [==============================] - 0s 61us/step - loss: 0.1892 - accuracy: 0.9211 - val_loss: 0.4365 - val_accuracy: 0.8160
Epoch 44/100
380/380 [==============================] - 0s 58us/step - loss: 0.1856 - accuracy: 0.9211 - val_loss: 0.3626 - val_accuracy: 0.8344
Epoch 45/100
380/380 [==============================] - 0s 59us/step - loss: 0.1987 - accuracy: 0.9211 - val_loss: 0.4641 - val_accuracy: 0.7975
Epoch 46/100
380/380 [==============================] - 0s 59us/step - loss: 0.1951 - accuracy: 0.9158 - val_loss: 0.3268 - val_accuracy: 0.8589
Epoch 47/100
380/380 [==============================] - 0s 58us/step - loss: 0.1994 - accuracy: 0.9158 - val_loss: 0.5006 - val_accuracy: 0.7975
Epoch 48/100
380/380 [==============================] - 0s 59us/step - loss: 0.2035 - accuracy: 0.9184 - val_loss: 0.3737 - val_accuracy: 0.8344
Epoch 49/100
380/380 [==============================] - 0s 57us/step - loss: 0.1739 - accuracy: 0.9289 - val_loss: 0.4592 - val_accuracy: 0.8160
Epoch 50/100
380/380 [==============================] - 0s 62us/step - loss: 0.1795 - accuracy: 0.9263 - val_loss: 0.3432 - val_accuracy: 0.8344
Epoch 51/100
380/380 [==============================] - 0s 67us/step - loss: 0.1798 - accuracy: 0.9263 - val_loss: 0.3483 - val_accuracy: 0.8344
Epoch 52/100
380/380 [==============================] - 0s 68us/step - loss: 0.1687 - accuracy: 0.9289 - val_loss: 0.3474 - val_accuracy: 0.8405
Epoch 53/100
380/380 [==============================] - 0s 63us/step - loss: 0.1779 - accuracy: 0.9289 - val_loss: 0.3678 - val_accuracy: 0.8344
Epoch 54/100
380/380 [==============================] - 0s 83us/step - loss: 0.1750 - accuracy: 0.9184 - val_loss: 0.3343 - val_accuracy: 0.8466
Epoch 55/100
380/380 [==============================] - 0s 189us/step - loss: 0.1789 - accuracy: 0.9211 - val_loss: 0.4017 - val_accuracy: 0.8282
Epoch 56/100
380/380 [==============================] - 0s 147us/step - loss: 0.1704 - accuracy: 0.9289 - val_loss: 0.3656 - val_accuracy: 0.8344
Epoch 57/100
380/380 [==============================] - 0s 125us/step - loss: 0.1653 - accuracy: 0.9289 - val_loss: 0.3880 - val_accuracy: 0.8282
Epoch 58/100
380/380 [==============================] - 0s 114us/step - loss: 0.1674 - accuracy: 0.9289 - val_loss: 0.3485 - val_accuracy: 0.8344
Epoch 59/100
380/380 [==============================] - 0s 87us/step - loss: 0.1740 - accuracy: 0.9289 - val_loss: 0.3870 - val_accuracy: 0.8282
Epoch 60/100
380/380 [==============================] - 0s 117us/step - loss: 0.1797 - accuracy: 0.9263 - val_loss: 0.3708 - val_accuracy: 0.8344
Epoch 61/100
380/380 [==============================] - 0s 89us/step - loss: 0.1767 - accuracy: 0.9263 - val_loss: 0.3672 - val_accuracy: 0.8344
Epoch 62/100
380/380 [==============================] - 0s 112us/step - loss: 0.1800 - accuracy: 0.9211 - val_loss: 0.3672 - val_accuracy: 0.8282
Epoch 63/100
380/380 [==============================] - 0s 96us/step - loss: 0.1688 - accuracy: 0.9263 - val_loss: 0.3678 - val_accuracy: 0.8344
Epoch 64/100
380/380 [==============================] - 0s 85us/step - loss: 0.1628 - accuracy: 0.9289 - val_loss: 0.3311 - val_accuracy: 0.8528
Epoch 65/100
380/380 [==============================] - 0s 92us/step - loss: 0.1651 - accuracy: 0.9211 - val_loss: 0.4011 - val_accuracy: 0.8221
Epoch 66/100
380/380 [==============================] - 0s 105us/step - loss: 0.1663 - accuracy: 0.9184 - val_loss: 0.3247 - val_accuracy: 0.8466
Epoch 67/100
380/380 [==============================] - 0s 184us/step - loss: 0.1740 - accuracy: 0.9237 - val_loss: 0.4150 - val_accuracy: 0.8282
Epoch 68/100
380/380 [==============================] - 0s 398us/step - loss: 0.1743 - accuracy: 0.9237 - val_loss: 0.4013 - val_accuracy: 0.8344
Epoch 69/100
380/380 [==============================] - 0s 107us/step - loss: 0.1758 - accuracy: 0.9237 - val_loss: 0.3321 - val_accuracy: 0.8466
Epoch 70/100
380/380 [==============================] - 0s 165us/step - loss: 0.1857 - accuracy: 0.9158 - val_loss: 0.4285 - val_accuracy: 0.8344
Epoch 71/100
380/380 [==============================] - 0s 140us/step - loss: 0.1800 - accuracy: 0.9158 - val_loss: 0.3533 - val_accuracy: 0.8405
Epoch 72/100
380/380 [==============================] - 0s 86us/step - loss: 0.1721 - accuracy: 0.9237 - val_loss: 0.3655 - val_accuracy: 0.8344
Epoch 73/100
380/380 [==============================] - 0s 79us/step - loss: 0.1655 - accuracy: 0.9289 - val_loss: 0.3758 - val_accuracy: 0.8344
Epoch 74/100
380/380 [==============================] - 0s 72us/step - loss: 0.1738 - accuracy: 0.9211 - val_loss: 0.3479 - val_accuracy: 0.8405
Epoch 75/100
380/380 [==============================] - 0s 64us/step - loss: 0.1792 - accuracy: 0.9184 - val_loss: 0.3899 - val_accuracy: 0.8282
Epoch 76/100
380/380 [==============================] - 0s 74us/step - loss: 0.1650 - accuracy: 0.9263 - val_loss: 0.3738 - val_accuracy: 0.8405
Epoch 77/100
380/380 [==============================] - 0s 63us/step - loss: 0.1724 - accuracy: 0.9316 - val_loss: 0.3281 - val_accuracy: 0.8589
Epoch 78/100
380/380 [==============================] - 0s 71us/step - loss: 0.1789 - accuracy: 0.9184 - val_loss: 0.4307 - val_accuracy: 0.8221
Epoch 79/100
380/380 [==============================] - 0s 327us/step - loss: 0.1639 - accuracy: 0.9316 - val_loss: 0.3556 - val_accuracy: 0.8344
Epoch 80/100
380/380 [==============================] - 0s 134us/step - loss: 0.1638 - accuracy: 0.9316 - val_loss: 0.4455 - val_accuracy: 0.8160
Epoch 81/100
380/380 [==============================] - 0s 93us/step - loss: 0.1772 - accuracy: 0.9237 - val_loss: 0.3527 - val_accuracy: 0.8344
Epoch 82/100
380/380 [==============================] - 0s 122us/step - loss: 0.1830 - accuracy: 0.9211 - val_loss: 0.3392 - val_accuracy: 0.8466
Epoch 83/100
380/380 [==============================] - 0s 200us/step - loss: 0.2063 - accuracy: 0.9184 - val_loss: 0.4741 - val_accuracy: 0.7914
Epoch 84/100
380/380 [==============================] - 0s 84us/step - loss: 0.1999 - accuracy: 0.9105 - val_loss: 0.3398 - val_accuracy: 0.8405
Epoch 85/100
380/380 [==============================] - 0s 88us/step - loss: 0.1724 - accuracy: 0.9316 - val_loss: 0.4430 - val_accuracy: 0.8221
Epoch 86/100
380/380 [==============================] - 0s 89us/step - loss: 0.1669 - accuracy: 0.9316 - val_loss: 0.3555 - val_accuracy: 0.8344
Epoch 87/100
380/380 [==============================] - 0s 80us/step - loss: 0.1653 - accuracy: 0.9289 - val_loss: 0.3845 - val_accuracy: 0.8344
Epoch 88/100
380/380 [==============================] - 0s 64us/step - loss: 0.1685 - accuracy: 0.9316 - val_loss: 0.4049 - val_accuracy: 0.8344
Epoch 89/100
380/380 [==============================] - 0s 72us/step - loss: 0.1719 - accuracy: 0.9289 - val_loss: 0.3526 - val_accuracy: 0.8405
Epoch 90/100
380/380 [==============================] - 0s 68us/step - loss: 0.1742 - accuracy: 0.9316 - val_loss: 0.3973 - val_accuracy: 0.8282
Epoch 91/100
380/380 [==============================] - 0s 68us/step - loss: 0.1798 - accuracy: 0.9289 - val_loss: 0.3917 - val_accuracy: 0.8344
Epoch 92/100
380/380 [==============================] - 0s 72us/step - loss: 0.1989 - accuracy: 0.9079 - val_loss: 0.3527 - val_accuracy: 0.8405
Epoch 93/100
380/380 [==============================] - 0s 65us/step - loss: 0.1890 - accuracy: 0.9158 - val_loss: 0.5376 - val_accuracy: 0.7853
Epoch 94/100
380/380 [==============================] - 0s 61us/step - loss: 0.2048 - accuracy: 0.9132 - val_loss: 0.3605 - val_accuracy: 0.8344
Epoch 95/100
380/380 [==============================] - 0s 75us/step - loss: 0.1911 - accuracy: 0.9289 - val_loss: 0.4544 - val_accuracy: 0.7914
Epoch 96/100
380/380 [==============================] - 0s 64us/step - loss: 0.1798 - accuracy: 0.9237 - val_loss: 0.3436 - val_accuracy: 0.8405
Epoch 97/100
380/380 [==============================] - 0s 65us/step - loss: 0.1697 - accuracy: 0.9316 - val_loss: 0.3714 - val_accuracy: 0.8405
Epoch 98/100
380/380 [==============================] - 0s 78us/step - loss: 0.1723 - accuracy: 0.9263 - val_loss: 0.3682 - val_accuracy: 0.8405
Epoch 99/100
380/380 [==============================] - 0s 71us/step - loss: 0.1723 - accuracy: 0.9289 - val_loss: 0.3312 - val_accuracy: 0.8466
Epoch 100/100
380/380 [==============================] - 0s 157us/step - loss: 0.1824 - accuracy: 0.9184 - val_loss: 0.3835 - val_accuracy: 0.8466
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[169]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;over-sampling train accuracy: </span><span class="si">%.2f%%</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">hist2_over</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span><span class="o">*</span><span class="mi">100</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>over-sampling train accuracy: 92.29%
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[34]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df_proba5</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_excel</span><span class="p">(</span><span class="s2">&quot;/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_lasso_2.xlsx&quot;</span><span class="p">,</span>
                        <span class="n">sheet_name</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                        <span class="n">index_col</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[35]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df_proba5</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[35]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>phage</th>
      <th>strain</th>
      <th>phenotype</th>
      <th>prediction</th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>p0006kpresabs_qual</td>
      <td>NRS245</td>
      <td>1</td>
      <td>2</td>
      <td>1.345807e-02</td>
      <td>2.164788e-01</td>
      <td>7.700630e-01</td>
    </tr>
    <tr>
      <th>1</th>
      <td>p0006kpresabs_qual</td>
      <td>NY439</td>
      <td>2</td>
      <td>2</td>
      <td>2.674153e-02</td>
      <td>9.294230e-04</td>
      <td>9.723290e-01</td>
    </tr>
    <tr>
      <th>2</th>
      <td>p0006kpresabs_qual</td>
      <td>CA544</td>
      <td>1</td>
      <td>0</td>
      <td>4.147484e-01</td>
      <td>3.626331e-01</td>
      <td>2.226184e-01</td>
    </tr>
    <tr>
      <th>3</th>
      <td>p0006kpresabs_qual</td>
      <td>CA541</td>
      <td>2</td>
      <td>0</td>
      <td>4.147484e-01</td>
      <td>3.626331e-01</td>
      <td>2.226184e-01</td>
    </tr>
    <tr>
      <th>4</th>
      <td>p0006kpresabs_qual</td>
      <td>EUH15</td>
      <td>1</td>
      <td>0</td>
      <td>4.147484e-01</td>
      <td>3.626331e-01</td>
      <td>2.226184e-01</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>984</th>
      <td>p0017Skpresabs_qual</td>
      <td>CA541</td>
      <td>1</td>
      <td>1</td>
      <td>3.723218e-01</td>
      <td>6.276781e-01</td>
      <td>1.945911e-08</td>
    </tr>
    <tr>
      <th>985</th>
      <td>p0017Skpresabs_qual</td>
      <td>SR4152</td>
      <td>1</td>
      <td>0</td>
      <td>7.372800e-01</td>
      <td>2.627200e-01</td>
      <td>4.197748e-08</td>
    </tr>
    <tr>
      <th>986</th>
      <td>p0017Skpresabs_qual</td>
      <td>NRS110</td>
      <td>2</td>
      <td>2</td>
      <td>4.194510e-08</td>
      <td>7.508231e-09</td>
      <td>1.000000e+00</td>
    </tr>
    <tr>
      <th>987</th>
      <td>p0017Skpresabs_qual</td>
      <td>CFBRSa70</td>
      <td>0</td>
      <td>0</td>
      <td>7.372800e-01</td>
      <td>2.627200e-01</td>
      <td>4.197748e-08</td>
    </tr>
    <tr>
      <th>988</th>
      <td>p0017Skpresabs_qual</td>
      <td>NRS021</td>
      <td>0</td>
      <td>1</td>
      <td>3.943684e-01</td>
      <td>6.056316e-01</td>
      <td>2.843107e-08</td>
    </tr>
  </tbody>
</table>
<p>989 rows × 7 columns</p>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[36]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">y_prob5</span> <span class="o">=</span> <span class="n">df_proba5</span><span class="p">[</span><span class="n">df_proba5</span><span class="p">[</span><span class="s1">&#39;phage&#39;</span><span class="p">]</span><span class="o">==</span><span class="s1">&#39;p11kpresabs_qual&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="o">-</span><span class="mi">3</span><span class="p">:]</span>
<span class="n">y_prob5</span> <span class="o">=</span> <span class="n">y_prob5</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
<span class="n">y_prob5</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[36]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>array([[4.11915480e-01, 4.69524650e-01, 1.18559930e-01],
       [1.85266310e-04, 9.52110300e-03, 9.90293600e-01],
       [3.60156920e-05, 8.63503800e-01, 1.36460160e-01],
       [4.47145980e-05, 1.55991150e-04, 9.99799300e-01],
       [9.73128600e-01, 3.57974520e-04, 2.65133900e-02],
       [2.07474390e-06, 9.99939440e-01, 5.85182750e-05],
       [4.47925930e-03, 6.53110300e-01, 3.42410360e-01],
       [8.66245200e-06, 7.00983870e-03, 9.92981430e-01],
       [9.93974600e-01, 4.42929500e-03, 1.59612850e-03],
       [8.00493540e-01, 5.56601730e-02, 1.43846350e-01],
       [8.58791900e-06, 9.76473100e-01, 2.35182720e-02],
       [4.17082200e-05, 9.99937800e-01, 2.04926220e-05],
       [4.11915480e-01, 4.69524650e-01, 1.18559930e-01],
       [1.82089920e-01, 7.36610100e-01, 8.12999400e-02],
       [9.97834600e-01, 2.91613160e-04, 1.87375400e-03],
       [6.53518140e-01, 2.28519260e-01, 1.17962636e-01],
       [4.75453040e-04, 9.98560850e-01, 9.63785100e-04],
       [6.61089600e-01, 2.46374680e-05, 3.38885750e-01],
       [1.33086130e-04, 4.60417980e-02, 9.53825200e-01],
       [1.24341674e-01, 1.29851930e-02, 8.62673160e-01],
       [4.11915480e-01, 4.69524650e-01, 1.18559930e-01],
       [1.82089920e-01, 7.36610100e-01, 8.12999400e-02],
       [9.98167630e-01, 1.26418690e-04, 1.70594600e-03],
       [2.04154770e-04, 1.03302070e-02, 9.89465700e-01],
       [9.92799900e-01, 4.71943840e-04, 6.72818530e-03],
       [4.11915480e-01, 4.69524650e-01, 1.18559930e-01],
       [5.23369350e-02, 2.03425900e-01, 7.44237100e-01],
       [4.92544600e-06, 9.99678000e-01, 3.17123340e-04],
       [9.96627500e-01, 2.05366220e-03, 1.31879920e-03],
       [3.96703540e-01, 1.37103470e-01, 4.66193020e-01],
       [1.13238010e-05, 1.57707430e-02, 9.84218000e-01],
       [9.91213860e-01, 1.72375970e-03, 7.06244170e-03],
       [4.62726900e-07, 9.94612340e-01, 5.38722470e-03],
       [9.94024100e-01, 3.54569310e-03, 2.43030350e-03],
       [4.38607860e-03, 9.52158330e-01, 4.34555820e-02],
       [9.58761960e-08, 9.94728270e-01, 5.27157730e-03],
       [1.06337060e-01, 8.62169740e-01, 3.14932470e-02],
       [9.92799900e-01, 4.71943840e-04, 6.72818530e-03],
       [4.62726900e-07, 9.94612340e-01, 5.38722470e-03],
       [7.40007600e-02, 3.66592260e-01, 5.59407000e-01],
       [5.16189400e-02, 1.22737800e-02, 9.36107300e-01],
       [5.30633800e-02, 2.44684760e-01, 7.02251900e-01],
       [2.18934060e-01, 1.44985590e-01, 6.36080400e-01],
       [4.46096700e-06, 9.98684470e-01, 1.31106940e-03],
       [9.99499560e-01, 1.96956000e-05, 4.80824200e-04],
       [4.33929800e-04, 5.85037050e-01, 4.14528970e-01],
       [2.07474390e-06, 9.99939440e-01, 5.85182750e-05],
       [9.90256000e-01, 5.19146780e-05, 9.69209600e-03],
       [3.33818700e-04, 9.98820840e-01, 8.45275640e-04],
       [5.62325900e-05, 7.82184400e-04, 9.99161600e-01],
       [4.17082200e-05, 9.99937800e-01, 2.04926220e-05],
       [2.85019000e-04, 5.86594760e-05, 9.99656300e-01],
       [9.73128600e-01, 3.57974520e-04, 2.65133900e-02],
       [1.11095320e-01, 6.80095900e-01, 2.08808660e-01],
       [6.44946050e-03, 9.81863200e-01, 1.16874340e-02],
       [6.35854200e-05, 9.09309900e-01, 9.06264200e-02],
       [6.53518140e-01, 2.28519260e-01, 1.17962636e-01],
       [9.91296300e-01, 7.64013870e-03, 1.06353760e-03],
       [9.96810000e-01, 1.48356060e-04, 3.04170530e-03],
       [9.96810000e-01, 1.48356060e-04, 3.04170530e-03],
       [4.11915480e-01, 4.69524650e-01, 1.18559930e-01],
       [1.18625320e-03, 9.80931000e-01, 1.78827460e-02],
       [7.40007600e-02, 3.66592260e-01, 5.59407000e-01],
       [2.52141120e-04, 4.06154730e-02, 9.59132400e-01],
       [2.40906480e-08, 9.89823760e-01, 1.01762740e-02],
       [4.86448050e-01, 4.93778060e-03, 5.08614200e-01],
       [1.82089920e-01, 7.36610100e-01, 8.12999400e-02],
       [6.53518140e-01, 2.28519260e-01, 1.17962636e-01],
       [2.23106120e-01, 4.44082300e-03, 7.72453070e-01],
       [1.27732180e-05, 9.98655200e-01, 1.33199480e-03],
       [5.08572800e-03, 8.77935100e-03, 9.86134950e-01],
       [9.27785100e-01, 5.22571400e-03, 6.69891700e-02],
       [9.74991500e-04, 6.94126700e-05, 9.98955600e-01],
       [9.74449900e-01, 5.53677050e-05, 2.54947710e-02],
       [9.91213860e-01, 1.72375970e-03, 7.06244170e-03],
       [5.71483200e-06, 9.60859300e-01, 3.91349570e-02],
       [7.40007600e-02, 3.66592260e-01, 5.59407000e-01],
       [9.44679860e-01, 1.37802360e-04, 5.51822370e-02],
       [9.98167630e-01, 1.26418690e-04, 1.70594600e-03],
       [9.91296300e-01, 7.64013870e-03, 1.06353760e-03],
       [9.74449900e-01, 5.53677050e-05, 2.54947710e-02],
       [9.73128600e-01, 3.57974520e-04, 2.65133900e-02],
       [5.44792670e-02, 7.79227700e-02, 8.67597900e-01],
       [6.44946050e-03, 9.81863200e-01, 1.16874340e-02],
       [3.78602050e-05, 9.97492200e-01, 2.46999530e-03],
       [8.00493540e-01, 5.56601730e-02, 1.43846350e-01],
       [8.58791900e-06, 9.76473100e-01, 2.35182720e-02],
       [9.91213860e-01, 1.72375970e-03, 7.06244170e-03],
       [9.92483900e-01, 4.10462960e-03, 3.41147800e-03],
       [1.13791850e-04, 9.93017800e-01, 6.86845930e-03],
       [1.09370210e-02, 2.75677900e-03, 9.86306200e-01],
       [8.96784100e-03, 9.69298840e-01, 2.17333140e-02],
       [1.18625320e-03, 9.80931000e-01, 1.78827460e-02],
       [1.82089920e-01, 7.36610100e-01, 8.12999400e-02],
       [7.40007600e-02, 3.66592260e-01, 5.59407000e-01],
       [6.49847960e-04, 9.50358460e-04, 9.98399800e-01],
       [9.44679860e-01, 1.37802360e-04, 5.51822370e-02],
       [4.38607860e-03, 9.52158330e-01, 4.34555820e-02],
       [9.90256000e-01, 5.19146780e-05, 9.69209600e-03],
       [9.90256000e-01, 5.19146780e-05, 9.69209600e-03],
       [1.82089920e-01, 7.36610100e-01, 8.12999400e-02],
       [1.82089920e-01, 7.36610100e-01, 8.12999400e-02],
       [1.82089920e-01, 7.36610100e-01, 8.12999400e-02],
       [9.97834600e-01, 2.91613160e-04, 1.87375400e-03],
       [2.97377530e-04, 2.93969480e-03, 9.96762900e-01],
       [1.82089920e-01, 7.36610100e-01, 8.12999400e-02],
       [5.64195030e-02, 1.16285720e-01, 8.27294700e-01],
       [1.32457770e-07, 9.99731840e-01, 2.68042380e-04],
       [9.58761960e-08, 9.94728270e-01, 5.27157730e-03],
       [2.57602500e-05, 8.06679900e-02, 9.19306300e-01],
       [4.38607860e-03, 9.52158330e-01, 4.34555820e-02],
       [9.94024100e-01, 3.54569310e-03, 2.43030350e-03],
       [3.50314050e-03, 2.04084870e-02, 9.76088400e-01],
       [1.82089920e-01, 7.36610100e-01, 8.12999400e-02],
       [5.59920800e-03, 6.27563240e-01, 3.66837530e-01],
       [9.90256000e-01, 5.19146780e-05, 9.69209600e-03],
       [9.96810000e-01, 1.48356060e-04, 3.04170530e-03],
       [2.40906480e-08, 9.89823760e-01, 1.01762740e-02],
       [2.87426740e-01, 6.12189900e-01, 1.00383360e-01],
       [1.86270730e-03, 2.35625240e-02, 9.74574700e-01],
       [1.01589390e-04, 9.81643500e-01, 1.82549230e-02],
       [9.92483900e-01, 4.10462960e-03, 3.41147800e-03],
       [3.43351550e-02, 5.58847840e-01, 4.06817020e-01],
       [9.92799900e-01, 4.71943840e-04, 6.72818530e-03],
       [9.97834600e-01, 2.91613160e-04, 1.87375400e-03],
       [4.11915480e-01, 4.69524650e-01, 1.18559930e-01],
       [2.47812670e-01, 5.73912150e-02, 6.94796140e-01],
       [9.80985700e-01, 9.65844000e-05, 1.89176970e-02],
       [9.10562700e-02, 1.08521690e-01, 8.00422100e-01],
       [1.06337060e-01, 8.62169740e-01, 3.14932470e-02],
       [1.82089920e-01, 7.36610100e-01, 8.12999400e-02],
       [2.24624500e-01, 7.69743200e-02, 6.98401150e-01],
       [4.22144660e-05, 9.29428500e-01, 7.05293000e-02],
       [9.93974600e-01, 4.42929500e-03, 1.59612850e-03],
       [3.96759570e-01, 3.56748370e-01, 2.46492070e-01],
       [4.43596100e-04, 3.12937420e-03, 9.96427000e-01],
       [3.33818700e-04, 9.98820840e-01, 8.45275640e-04],
       [9.98167630e-01, 1.26418690e-04, 1.70594600e-03],
       [9.97834600e-01, 2.91613160e-04, 1.87375400e-03],
       [9.92483900e-01, 4.10462960e-03, 3.41147800e-03],
       [9.96627500e-01, 2.05366220e-03, 1.31879920e-03],
       [2.07474390e-06, 9.99939440e-01, 5.85182750e-05],
       [3.85772370e-03, 5.27156050e-03, 9.90870650e-01],
       [4.15290770e-01, 1.47991250e-01, 4.36717960e-01],
       [4.11915480e-01, 4.69524650e-01, 1.18559930e-01],
       [9.96223100e-01, 2.19248900e-03, 1.58436640e-03],
       [6.47466000e-01, 8.53203100e-02, 2.67213670e-01],
       [9.94024100e-01, 3.54569310e-03, 2.43030350e-03],
       [1.13791850e-04, 9.93017800e-01, 6.86845930e-03],
       [9.92799900e-01, 4.71943840e-04, 6.72818530e-03],
       [8.00493540e-01, 5.56601730e-02, 1.43846350e-01],
       [4.11915480e-01, 4.69524650e-01, 1.18559930e-01],
       [1.13791850e-04, 9.93017800e-01, 6.86845930e-03],
       [4.38607860e-03, 9.52158330e-01, 4.34555820e-02],
       [9.16837300e-01, 3.78063900e-04, 8.27847050e-02],
       [4.62726900e-07, 9.94612340e-01, 5.38722470e-03],
       [9.90256000e-01, 5.19146780e-05, 9.69209600e-03],
       [4.75453040e-04, 9.98560850e-01, 9.63785100e-04],
       [9.96810000e-01, 1.48356060e-04, 3.04170530e-03],
       [9.92483900e-01, 4.10462960e-03, 3.41147800e-03],
       [2.62174870e-01, 4.61843800e-01, 2.75981300e-01],
       [6.44946050e-03, 9.81863200e-01, 1.16874340e-02],
       [9.97834600e-01, 2.91613160e-04, 1.87375400e-03]])</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[37]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">ovo5</span> <span class="o">=</span> <span class="n">rocauc_ovo</span><span class="p">(</span><span class="n">y_sel_test_over</span><span class="p">,</span> <span class="n">y_prob5</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s2">&quot;macro&quot;</span><span class="p">,</span> <span class="n">multi_class</span><span class="o">=</span><span class="s2">&quot;ovo&quot;</span><span class="p">)</span>
<span class="n">ovo5</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[37]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>0.9762062521236835</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[38]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">ovr5</span> <span class="o">=</span> <span class="n">rocauc_ovr</span><span class="p">(</span><span class="n">y_sel_test_over</span><span class="p">,</span> <span class="n">y_prob5</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s2">&quot;macro&quot;</span><span class="p">,</span> <span class="n">multi_class</span><span class="o">=</span><span class="s2">&quot;ovr&quot;</span><span class="p">)</span>
<span class="n">ovr5</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[38]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>0.9762062521236835</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[39]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># split into train, test data (over)</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="n">X_sel_train_over</span><span class="p">,</span> <span class="n">X_sel_test_over</span><span class="p">,</span> <span class="n">y_sel_train_over</span><span class="p">,</span> <span class="n">y_sel_test_over</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X_sel_over</span><span class="p">,</span> <span class="n">y_sel_over</span><span class="p">,</span>
                                                    <span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.3</span><span class="p">,</span>
                                                    <span class="n">random_state</span><span class="o">=</span><span class="mi">678</span><span class="p">,</span>
                                                    <span class="n">stratify</span><span class="o">=</span><span class="n">y_sel_over</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[40]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dat6</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X_sel_test_over</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
<span class="n">dat6</span><span class="p">[</span><span class="s1">&#39;test&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">y_sel_test_over</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[41]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dat6</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[41]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>test</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>GA48963</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>SR4187</td>
      <td>2</td>
    </tr>
    <tr>
      <th>2</th>
      <td>NRS182</td>
      <td>2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>CFBREBSa125</td>
      <td>2</td>
    </tr>
    <tr>
      <th>4</th>
      <td>NRS188</td>
      <td>1</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>158</th>
      <td>BCH-SA-05</td>
      <td>0</td>
    </tr>
    <tr>
      <th>159</th>
      <td>NRS027</td>
      <td>0</td>
    </tr>
    <tr>
      <th>160</th>
      <td>CFBREBSa123</td>
      <td>0</td>
    </tr>
    <tr>
      <th>161</th>
      <td>NRS199</td>
      <td>2</td>
    </tr>
    <tr>
      <th>162</th>
      <td>Grady1</td>
      <td>2</td>
    </tr>
  </tbody>
</table>
<p>163 rows × 2 columns</p>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[42]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">X_sel_train_over</span> <span class="o">=</span> <span class="n">X_sel_train_over</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">X_sel_test_over</span> <span class="o">=</span> <span class="n">X_sel_test_over</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[96]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model2_over2</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">([</span>
    <span class="n">Dense</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="n">X_sel_train_over</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],)),</span>
    <span class="n">Dense</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">),</span>
<span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[97]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model2_over2</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span>
              <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;sparse_categorical_crossentropy&#39;</span><span class="p">,</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[98]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model2_over2</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_sel_train_over</span><span class="p">,</span> <span class="n">y_sel_train_over</span><span class="p">,</span>
          <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
          <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">X_sel_test_over</span><span class="p">,</span> <span class="n">y_sel_test_over</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Train on 380 samples, validate on 163 samples
Epoch 1/100
380/380 [==============================] - 0s 315us/step - loss: 1.1623 - accuracy: 0.3737 - val_loss: 1.1773 - val_accuracy: 0.3313
Epoch 2/100
380/380 [==============================] - 0s 95us/step - loss: 1.0969 - accuracy: 0.4184 - val_loss: 1.0819 - val_accuracy: 0.4049
Epoch 3/100
380/380 [==============================] - 0s 61us/step - loss: 1.0238 - accuracy: 0.5000 - val_loss: 1.0314 - val_accuracy: 0.5276
Epoch 4/100
380/380 [==============================] - 0s 76us/step - loss: 0.9774 - accuracy: 0.5579 - val_loss: 1.0038 - val_accuracy: 0.4663
Epoch 5/100
380/380 [==============================] - 0s 100us/step - loss: 0.9556 - accuracy: 0.6184 - val_loss: 0.9948 - val_accuracy: 0.4908
Epoch 6/100
380/380 [==============================] - 0s 111us/step - loss: 0.9206 - accuracy: 0.6211 - val_loss: 0.9570 - val_accuracy: 0.5583
Epoch 7/100
380/380 [==============================] - 0s 95us/step - loss: 0.8817 - accuracy: 0.6421 - val_loss: 0.9526 - val_accuracy: 0.5399
Epoch 8/100
380/380 [==============================] - 0s 78us/step - loss: 0.8686 - accuracy: 0.6974 - val_loss: 0.9431 - val_accuracy: 0.5215
Epoch 9/100
380/380 [==============================] - 0s 84us/step - loss: 0.8389 - accuracy: 0.6763 - val_loss: 0.9035 - val_accuracy: 0.6074
Epoch 10/100
380/380 [==============================] - 0s 68us/step - loss: 0.8187 - accuracy: 0.7105 - val_loss: 0.9005 - val_accuracy: 0.5583
Epoch 11/100
380/380 [==============================] - 0s 64us/step - loss: 0.7920 - accuracy: 0.7132 - val_loss: 0.8794 - val_accuracy: 0.5951
Epoch 12/100
380/380 [==============================] - 0s 72us/step - loss: 0.7687 - accuracy: 0.7263 - val_loss: 0.8607 - val_accuracy: 0.5890
Epoch 13/100
380/380 [==============================] - 0s 58us/step - loss: 0.7508 - accuracy: 0.7237 - val_loss: 0.8461 - val_accuracy: 0.5890
Epoch 14/100
380/380 [==============================] - 0s 106us/step - loss: 0.7359 - accuracy: 0.7395 - val_loss: 0.8333 - val_accuracy: 0.6012
Epoch 15/100
380/380 [==============================] - 0s 63us/step - loss: 0.7137 - accuracy: 0.7447 - val_loss: 0.8152 - val_accuracy: 0.6503
Epoch 16/100
380/380 [==============================] - 0s 69us/step - loss: 0.6977 - accuracy: 0.7579 - val_loss: 0.8062 - val_accuracy: 0.6319
Epoch 17/100
380/380 [==============================] - 0s 100us/step - loss: 0.6868 - accuracy: 0.7553 - val_loss: 0.8007 - val_accuracy: 0.6258
Epoch 18/100
380/380 [==============================] - 0s 55us/step - loss: 0.6707 - accuracy: 0.7868 - val_loss: 0.7775 - val_accuracy: 0.6687
Epoch 19/100
380/380 [==============================] - 0s 64us/step - loss: 0.6506 - accuracy: 0.7816 - val_loss: 0.7753 - val_accuracy: 0.6503
Epoch 20/100
380/380 [==============================] - 0s 103us/step - loss: 0.6400 - accuracy: 0.7711 - val_loss: 0.7554 - val_accuracy: 0.6626
Epoch 21/100
380/380 [==============================] - 0s 94us/step - loss: 0.6243 - accuracy: 0.7737 - val_loss: 0.7455 - val_accuracy: 0.6687
Epoch 22/100
380/380 [==============================] - 0s 147us/step - loss: 0.6197 - accuracy: 0.7842 - val_loss: 0.7390 - val_accuracy: 0.6871
Epoch 23/100
380/380 [==============================] - 0s 134us/step - loss: 0.6098 - accuracy: 0.7605 - val_loss: 0.7219 - val_accuracy: 0.6810
Epoch 24/100
380/380 [==============================] - 0s 86us/step - loss: 0.5903 - accuracy: 0.7921 - val_loss: 0.7457 - val_accuracy: 0.6442
Epoch 25/100
380/380 [==============================] - 0s 91us/step - loss: 0.5840 - accuracy: 0.7816 - val_loss: 0.7044 - val_accuracy: 0.6994
Epoch 26/100
380/380 [==============================] - 0s 74us/step - loss: 0.5797 - accuracy: 0.7763 - val_loss: 0.6973 - val_accuracy: 0.6871
Epoch 27/100
380/380 [==============================] - 0s 81us/step - loss: 0.5567 - accuracy: 0.8026 - val_loss: 0.7065 - val_accuracy: 0.6933
Epoch 28/100
380/380 [==============================] - 0s 157us/step - loss: 0.5483 - accuracy: 0.8026 - val_loss: 0.6772 - val_accuracy: 0.7239
Epoch 29/100
380/380 [==============================] - 0s 150us/step - loss: 0.5380 - accuracy: 0.8289 - val_loss: 0.6822 - val_accuracy: 0.6933
Epoch 30/100
380/380 [==============================] - 0s 63us/step - loss: 0.5293 - accuracy: 0.8079 - val_loss: 0.6625 - val_accuracy: 0.7055
Epoch 31/100
380/380 [==============================] - 0s 95us/step - loss: 0.5180 - accuracy: 0.7947 - val_loss: 0.6647 - val_accuracy: 0.6994
Epoch 32/100
380/380 [==============================] - 0s 107us/step - loss: 0.5141 - accuracy: 0.8079 - val_loss: 0.6489 - val_accuracy: 0.7423
Epoch 33/100
380/380 [==============================] - 0s 255us/step - loss: 0.4968 - accuracy: 0.8316 - val_loss: 0.6436 - val_accuracy: 0.6933
Epoch 34/100
380/380 [==============================] - 0s 165us/step - loss: 0.4943 - accuracy: 0.7921 - val_loss: 0.6417 - val_accuracy: 0.7117
Epoch 35/100
380/380 [==============================] - 0s 179us/step - loss: 0.4838 - accuracy: 0.8289 - val_loss: 0.6282 - val_accuracy: 0.7301
Epoch 36/100
380/380 [==============================] - 0s 144us/step - loss: 0.4757 - accuracy: 0.8184 - val_loss: 0.6268 - val_accuracy: 0.7178
Epoch 37/100
380/380 [==============================] - 0s 161us/step - loss: 0.4680 - accuracy: 0.8211 - val_loss: 0.6172 - val_accuracy: 0.7423
Epoch 38/100
380/380 [==============================] - 0s 182us/step - loss: 0.4619 - accuracy: 0.8316 - val_loss: 0.6137 - val_accuracy: 0.7117
Epoch 39/100
380/380 [==============================] - 0s 106us/step - loss: 0.4525 - accuracy: 0.8237 - val_loss: 0.6042 - val_accuracy: 0.7669
Epoch 40/100
380/380 [==============================] - 0s 119us/step - loss: 0.4469 - accuracy: 0.8395 - val_loss: 0.6009 - val_accuracy: 0.7607
Epoch 41/100
380/380 [==============================] - 0s 70us/step - loss: 0.4407 - accuracy: 0.8342 - val_loss: 0.5917 - val_accuracy: 0.7485
Epoch 42/100
380/380 [==============================] - 0s 77us/step - loss: 0.4416 - accuracy: 0.8342 - val_loss: 0.6025 - val_accuracy: 0.7301
Epoch 43/100
380/380 [==============================] - 0s 91us/step - loss: 0.4384 - accuracy: 0.8368 - val_loss: 0.5847 - val_accuracy: 0.7546
Epoch 44/100
380/380 [==============================] - 0s 179us/step - loss: 0.4301 - accuracy: 0.8474 - val_loss: 0.5816 - val_accuracy: 0.7423
Epoch 45/100
380/380 [==============================] - 0s 62us/step - loss: 0.4244 - accuracy: 0.8474 - val_loss: 0.5801 - val_accuracy: 0.7730
Epoch 46/100
380/380 [==============================] - 0s 108us/step - loss: 0.4164 - accuracy: 0.8474 - val_loss: 0.5747 - val_accuracy: 0.7546
Epoch 47/100
380/380 [==============================] - 0s 77us/step - loss: 0.4098 - accuracy: 0.8605 - val_loss: 0.5629 - val_accuracy: 0.7669
Epoch 48/100
380/380 [==============================] - 0s 96us/step - loss: 0.4028 - accuracy: 0.8421 - val_loss: 0.5613 - val_accuracy: 0.7730
Epoch 49/100
380/380 [==============================] - 0s 97us/step - loss: 0.4000 - accuracy: 0.8526 - val_loss: 0.5584 - val_accuracy: 0.7730
Epoch 50/100
380/380 [==============================] - 0s 158us/step - loss: 0.3965 - accuracy: 0.8579 - val_loss: 0.5534 - val_accuracy: 0.7485
Epoch 51/100
380/380 [==============================] - 0s 119us/step - loss: 0.3861 - accuracy: 0.8474 - val_loss: 0.5489 - val_accuracy: 0.7730
Epoch 52/100
380/380 [==============================] - 0s 117us/step - loss: 0.3895 - accuracy: 0.8553 - val_loss: 0.5446 - val_accuracy: 0.7485
Epoch 53/100
380/380 [==============================] - 0s 117us/step - loss: 0.3804 - accuracy: 0.8474 - val_loss: 0.5374 - val_accuracy: 0.7975
Epoch 54/100
380/380 [==============================] - 0s 102us/step - loss: 0.3795 - accuracy: 0.8579 - val_loss: 0.5335 - val_accuracy: 0.7853
Epoch 55/100
380/380 [==============================] - 0s 74us/step - loss: 0.3761 - accuracy: 0.8605 - val_loss: 0.5304 - val_accuracy: 0.7853
Epoch 56/100
380/380 [==============================] - 0s 76us/step - loss: 0.3769 - accuracy: 0.8632 - val_loss: 0.5295 - val_accuracy: 0.7791
Epoch 57/100
380/380 [==============================] - 0s 138us/step - loss: 0.3607 - accuracy: 0.8684 - val_loss: 0.5243 - val_accuracy: 0.7791
Epoch 58/100
380/380 [==============================] - 0s 121us/step - loss: 0.3602 - accuracy: 0.8579 - val_loss: 0.5192 - val_accuracy: 0.7975
Epoch 59/100
380/380 [==============================] - 0s 130us/step - loss: 0.3513 - accuracy: 0.8842 - val_loss: 0.5273 - val_accuracy: 0.7607
Epoch 60/100
380/380 [==============================] - 0s 120us/step - loss: 0.3525 - accuracy: 0.8789 - val_loss: 0.5182 - val_accuracy: 0.7730
Epoch 61/100
380/380 [==============================] - 0s 96us/step - loss: 0.3491 - accuracy: 0.8842 - val_loss: 0.5152 - val_accuracy: 0.7546
Epoch 62/100
380/380 [==============================] - 0s 80us/step - loss: 0.3462 - accuracy: 0.8684 - val_loss: 0.5048 - val_accuracy: 0.7914
Epoch 63/100
380/380 [==============================] - 0s 63us/step - loss: 0.3461 - accuracy: 0.8711 - val_loss: 0.5033 - val_accuracy: 0.7975
Epoch 64/100
380/380 [==============================] - 0s 89us/step - loss: 0.3433 - accuracy: 0.8737 - val_loss: 0.5010 - val_accuracy: 0.8221
Epoch 65/100
380/380 [==============================] - 0s 70us/step - loss: 0.3402 - accuracy: 0.8763 - val_loss: 0.5014 - val_accuracy: 0.7853
Epoch 66/100
380/380 [==============================] - 0s 60us/step - loss: 0.3562 - accuracy: 0.8579 - val_loss: 0.4946 - val_accuracy: 0.8282
Epoch 67/100
380/380 [==============================] - 0s 66us/step - loss: 0.3413 - accuracy: 0.8632 - val_loss: 0.4966 - val_accuracy: 0.8344
Epoch 68/100
380/380 [==============================] - 0s 119us/step - loss: 0.3245 - accuracy: 0.8974 - val_loss: 0.4897 - val_accuracy: 0.8160
Epoch 69/100
380/380 [==============================] - 0s 129us/step - loss: 0.3184 - accuracy: 0.9000 - val_loss: 0.4902 - val_accuracy: 0.7975
Epoch 70/100
380/380 [==============================] - 0s 233us/step - loss: 0.3185 - accuracy: 0.8868 - val_loss: 0.4859 - val_accuracy: 0.8160
Epoch 71/100
380/380 [==============================] - 0s 160us/step - loss: 0.3114 - accuracy: 0.8921 - val_loss: 0.4900 - val_accuracy: 0.7975
Epoch 72/100
380/380 [==============================] - 0s 209us/step - loss: 0.3170 - accuracy: 0.8789 - val_loss: 0.4841 - val_accuracy: 0.8282
Epoch 73/100
380/380 [==============================] - 0s 112us/step - loss: 0.3099 - accuracy: 0.9026 - val_loss: 0.4833 - val_accuracy: 0.7975
Epoch 74/100
380/380 [==============================] - 0s 167us/step - loss: 0.3124 - accuracy: 0.8895 - val_loss: 0.4822 - val_accuracy: 0.8282
Epoch 75/100
380/380 [==============================] - 0s 125us/step - loss: 0.3082 - accuracy: 0.8947 - val_loss: 0.4745 - val_accuracy: 0.8221
Epoch 76/100
380/380 [==============================] - 0s 93us/step - loss: 0.3000 - accuracy: 0.9000 - val_loss: 0.4711 - val_accuracy: 0.8344
Epoch 77/100
380/380 [==============================] - 0s 93us/step - loss: 0.2995 - accuracy: 0.8947 - val_loss: 0.4727 - val_accuracy: 0.8282
Epoch 78/100
380/380 [==============================] - 0s 68us/step - loss: 0.2995 - accuracy: 0.8974 - val_loss: 0.4670 - val_accuracy: 0.8160
Epoch 79/100
380/380 [==============================] - 0s 121us/step - loss: 0.2930 - accuracy: 0.8974 - val_loss: 0.4694 - val_accuracy: 0.8466
Epoch 80/100
380/380 [==============================] - 0s 144us/step - loss: 0.2929 - accuracy: 0.8974 - val_loss: 0.4633 - val_accuracy: 0.8282
Epoch 81/100
380/380 [==============================] - 0s 104us/step - loss: 0.2954 - accuracy: 0.8895 - val_loss: 0.4623 - val_accuracy: 0.8344
Epoch 82/100
380/380 [==============================] - 0s 151us/step - loss: 0.2924 - accuracy: 0.8974 - val_loss: 0.4594 - val_accuracy: 0.8466
Epoch 83/100
380/380 [==============================] - 0s 85us/step - loss: 0.2947 - accuracy: 0.8842 - val_loss: 0.4680 - val_accuracy: 0.8282
Epoch 84/100
380/380 [==============================] - 0s 90us/step - loss: 0.3130 - accuracy: 0.8684 - val_loss: 0.4546 - val_accuracy: 0.8466
Epoch 85/100
380/380 [==============================] - 0s 141us/step - loss: 0.3033 - accuracy: 0.8789 - val_loss: 0.4618 - val_accuracy: 0.8528
Epoch 86/100
380/380 [==============================] - 0s 87us/step - loss: 0.2951 - accuracy: 0.8921 - val_loss: 0.4581 - val_accuracy: 0.8405
Epoch 87/100
380/380 [==============================] - 0s 138us/step - loss: 0.2769 - accuracy: 0.9000 - val_loss: 0.4558 - val_accuracy: 0.8405
Epoch 88/100
380/380 [==============================] - 0s 162us/step - loss: 0.2802 - accuracy: 0.9000 - val_loss: 0.4474 - val_accuracy: 0.8405
Epoch 89/100
380/380 [==============================] - 0s 94us/step - loss: 0.2801 - accuracy: 0.9053 - val_loss: 0.4459 - val_accuracy: 0.8466
Epoch 90/100
380/380 [==============================] - 0s 116us/step - loss: 0.2815 - accuracy: 0.8947 - val_loss: 0.4466 - val_accuracy: 0.8282
Epoch 91/100
380/380 [==============================] - 0s 89us/step - loss: 0.2716 - accuracy: 0.9026 - val_loss: 0.4468 - val_accuracy: 0.8405
Epoch 92/100
380/380 [==============================] - 0s 164us/step - loss: 0.2749 - accuracy: 0.8974 - val_loss: 0.4414 - val_accuracy: 0.8405
Epoch 93/100
380/380 [==============================] - 0s 103us/step - loss: 0.2665 - accuracy: 0.9000 - val_loss: 0.4414 - val_accuracy: 0.8405
Epoch 94/100
380/380 [==============================] - 0s 111us/step - loss: 0.2666 - accuracy: 0.9000 - val_loss: 0.4390 - val_accuracy: 0.8405
Epoch 95/100
380/380 [==============================] - 0s 133us/step - loss: 0.2709 - accuracy: 0.9000 - val_loss: 0.4406 - val_accuracy: 0.8589
Epoch 96/100
380/380 [==============================] - 0s 59us/step - loss: 0.2659 - accuracy: 0.9105 - val_loss: 0.4423 - val_accuracy: 0.8405
Epoch 97/100
380/380 [==============================] - 0s 103us/step - loss: 0.2691 - accuracy: 0.9026 - val_loss: 0.4384 - val_accuracy: 0.8650
Epoch 98/100
380/380 [==============================] - 0s 65us/step - loss: 0.2634 - accuracy: 0.9132 - val_loss: 0.4314 - val_accuracy: 0.8528
Epoch 99/100
380/380 [==============================] - 0s 85us/step - loss: 0.2589 - accuracy: 0.9079 - val_loss: 0.4326 - val_accuracy: 0.8650
Epoch 100/100
380/380 [==============================] - 0s 75us/step - loss: 0.2574 - accuracy: 0.9105 - val_loss: 0.4303 - val_accuracy: 0.8528
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[98]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&lt;keras.callbacks.callbacks.History at 0x1a44254080&gt;</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[210]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">acc_test2_over2</span> <span class="o">=</span> <span class="n">model2_over2</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_sel_test_over</span><span class="p">,</span> <span class="n">y_sel_test_over</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;over-sampling test accuracy: </span><span class="si">%.2f%%</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">acc_test2_over2</span><span class="o">*</span><span class="mi">100</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_text output_error">
<pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">ValueError</span>                                Traceback (most recent call last)
<span class="ansi-green-fg">&lt;ipython-input-210-c3852a9d3cf5&gt;</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span>
<span class="ansi-green-fg">----&gt; 1</span><span class="ansi-red-fg"> </span>acc_test2_over2 <span class="ansi-blue-fg">=</span> model2_over2<span class="ansi-blue-fg">.</span>evaluate<span class="ansi-blue-fg">(</span>X_sel_test_over<span class="ansi-blue-fg">,</span> y_sel_test_over<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">[</span><span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">]</span>
<span class="ansi-green-intense-fg ansi-bold">      2</span> print<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">&#39;over-sampling test accuracy: %.2f%%&#39;</span> <span class="ansi-blue-fg">%</span> <span class="ansi-blue-fg">(</span>acc_test2_over2<span class="ansi-blue-fg">*</span><span class="ansi-cyan-fg">100</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py</span> in <span class="ansi-cyan-fg">evaluate</span><span class="ansi-blue-fg">(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing)</span>
<span class="ansi-green-intense-fg ansi-bold">   1347</span>             x<span class="ansi-blue-fg">,</span> y<span class="ansi-blue-fg">,</span>
<span class="ansi-green-intense-fg ansi-bold">   1348</span>             sample_weight<span class="ansi-blue-fg">=</span>sample_weight<span class="ansi-blue-fg">,</span>
<span class="ansi-green-fg">-&gt; 1349</span><span class="ansi-red-fg">             batch_size=batch_size)
</span><span class="ansi-green-intense-fg ansi-bold">   1350</span>         <span class="ansi-red-fg"># Prepare inputs, delegate logic to `test_loop`.</span>
<span class="ansi-green-intense-fg ansi-bold">   1351</span>         <span class="ansi-green-fg">if</span> self<span class="ansi-blue-fg">.</span>_uses_dynamic_learning_phase<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>

<span class="ansi-green-fg">~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py</span> in <span class="ansi-cyan-fg">_standardize_user_data</span><span class="ansi-blue-fg">(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)</span>
<span class="ansi-green-intense-fg ansi-bold">    577</span>             feed_input_shapes<span class="ansi-blue-fg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    578</span>             check_batch_axis<span class="ansi-blue-fg">=</span><span class="ansi-green-fg">False</span><span class="ansi-blue-fg">,</span>  <span class="ansi-red-fg"># Don&#39;t enforce the batch size.</span>
<span class="ansi-green-fg">--&gt; 579</span><span class="ansi-red-fg">             exception_prefix=&#39;input&#39;)
</span><span class="ansi-green-intense-fg ansi-bold">    580</span> 
<span class="ansi-green-intense-fg ansi-bold">    581</span>         <span class="ansi-green-fg">if</span> y <span class="ansi-green-fg">is</span> <span class="ansi-green-fg">not</span> <span class="ansi-green-fg">None</span><span class="ansi-blue-fg">:</span>

<span class="ansi-green-fg">~/anaconda3/lib/python3.7/site-packages/keras/engine/training_utils.py</span> in <span class="ansi-cyan-fg">standardize_input_data</span><span class="ansi-blue-fg">(data, names, shapes, check_batch_axis, exception_prefix)</span>
<span class="ansi-green-intense-fg ansi-bold">    143</span>                             <span class="ansi-blue-fg">&#39;: expected &#39;</span> <span class="ansi-blue-fg">+</span> names<span class="ansi-blue-fg">[</span>i<span class="ansi-blue-fg">]</span> <span class="ansi-blue-fg">+</span> <span class="ansi-blue-fg">&#39; to have shape &#39;</span> <span class="ansi-blue-fg">+</span>
<span class="ansi-green-intense-fg ansi-bold">    144</span>                             str<span class="ansi-blue-fg">(</span>shape<span class="ansi-blue-fg">)</span> <span class="ansi-blue-fg">+</span> <span class="ansi-blue-fg">&#39; but got array with shape &#39;</span> <span class="ansi-blue-fg">+</span>
<span class="ansi-green-fg">--&gt; 145</span><span class="ansi-red-fg">                             str(data_shape))
</span><span class="ansi-green-intense-fg ansi-bold">    146</span>     <span class="ansi-green-fg">return</span> data
<span class="ansi-green-intense-fg ansi-bold">    147</span> 

<span class="ansi-red-fg">ValueError</span>: Error when checking input: expected dense_69_input to have shape (183,) but got array with shape (184,)</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[99]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">pred6</span> <span class="o">=</span> <span class="n">model2_over2</span><span class="o">.</span><span class="n">predict_classes</span><span class="p">(</span><span class="n">X_sel_test_over</span><span class="p">)</span>
<span class="n">pred6</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[99]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>array([1, 2, 2, 1, 1, 0, 1, 2, 2, 1, 2, 1, 0, 0, 1, 0, 2, 1, 2, 1, 2, 1,
       0, 1, 1, 2, 0, 2, 0, 2, 0, 0, 0, 1, 1, 1, 1, 2, 1, 0, 1, 1, 1, 0,
       1, 2, 2, 2, 0, 1, 2, 1, 2, 2, 0, 0, 1, 2, 0, 0, 1, 1, 2, 1, 0, 1,
       2, 2, 0, 2, 2, 1, 1, 1, 1, 2, 2, 1, 0, 1, 2, 1, 2, 1, 1, 2, 1, 1,
       2, 1, 1, 2, 1, 0, 2, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1,
       2, 2, 2, 2, 0, 2, 1, 0, 1, 0, 1, 0, 2, 0, 2, 0, 0, 1, 2, 1, 0, 1,
       1, 1, 2, 2, 2, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 2, 1, 0, 0, 2, 0, 1,
       2, 1, 0, 0, 0, 0, 0, 2, 0])</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[100]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dat6</span><span class="p">[</span><span class="s1">&#39;pred&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pred6</span>
<span class="n">dat6</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[100]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>test</th>
      <th>pred</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>GA48963</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>SR4187</td>
      <td>2</td>
      <td>2</td>
    </tr>
    <tr>
      <th>2</th>
      <td>NRS182</td>
      <td>2</td>
      <td>2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>CFBREBSa125</td>
      <td>2</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>NRS188</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>158</th>
      <td>BCH-SA-05</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>159</th>
      <td>NRS027</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>160</th>
      <td>CFBREBSa123</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>161</th>
      <td>NRS199</td>
      <td>2</td>
      <td>2</td>
    </tr>
    <tr>
      <th>162</th>
      <td>Grady1</td>
      <td>2</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>163 rows × 3 columns</p>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[101]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">proba6</span> <span class="o">=</span> <span class="n">model2_over2</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_sel_test_over</span><span class="p">)</span>
<span class="n">dat_proba6</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">proba6</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[102]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dat_proba6</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[102]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.002574</td>
      <td>0.885729</td>
      <td>0.111697</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.118700</td>
      <td>0.210628</td>
      <td>0.670673</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.043093</td>
      <td>0.105198</td>
      <td>0.851708</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.245581</td>
      <td>0.651203</td>
      <td>0.103216</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.000436</td>
      <td>0.977856</td>
      <td>0.021708</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>158</th>
      <td>0.962178</td>
      <td>0.013605</td>
      <td>0.024217</td>
    </tr>
    <tr>
      <th>159</th>
      <td>0.983021</td>
      <td>0.005792</td>
      <td>0.011186</td>
    </tr>
    <tr>
      <th>160</th>
      <td>0.655458</td>
      <td>0.002887</td>
      <td>0.341655</td>
    </tr>
    <tr>
      <th>161</th>
      <td>0.013677</td>
      <td>0.003953</td>
      <td>0.982369</td>
    </tr>
    <tr>
      <th>162</th>
      <td>0.491432</td>
      <td>0.055427</td>
      <td>0.453142</td>
    </tr>
  </tbody>
</table>
<p>163 rows × 3 columns</p>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[103]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dat_proba6</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s2">&quot;/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba6.csv&quot;</span><span class="p">,</span> <span class="n">index</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
         <span class="n">header</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[104]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dat6</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s2">&quot;/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/6p11.csv&quot;</span><span class="p">,</span> <span class="n">index</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
         <span class="n">header</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[197]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">hist2_over2</span> <span class="o">=</span> <span class="n">model2_over2</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_sel_train_over</span><span class="p">,</span> <span class="n">y_sel_train_over</span><span class="p">,</span>
          <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
          <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">X_sel_test_over</span><span class="p">,</span> <span class="n">y_sel_test_over</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Train on 380 samples, validate on 163 samples
Epoch 1/100
380/380 [==============================] - 0s 82us/step - loss: 0.2749 - accuracy: 0.9105 - val_loss: 0.4064 - val_accuracy: 0.8650
Epoch 2/100
380/380 [==============================] - 0s 97us/step - loss: 0.2704 - accuracy: 0.9079 - val_loss: 0.4095 - val_accuracy: 0.8650
Epoch 3/100
380/380 [==============================] - 0s 100us/step - loss: 0.2688 - accuracy: 0.9079 - val_loss: 0.4106 - val_accuracy: 0.8528
Epoch 4/100
380/380 [==============================] - 0s 85us/step - loss: 0.2752 - accuracy: 0.9079 - val_loss: 0.4065 - val_accuracy: 0.8650
Epoch 5/100
380/380 [==============================] - 0s 72us/step - loss: 0.2729 - accuracy: 0.9053 - val_loss: 0.3993 - val_accuracy: 0.8650
Epoch 6/100
380/380 [==============================] - 0s 68us/step - loss: 0.2643 - accuracy: 0.9079 - val_loss: 0.4035 - val_accuracy: 0.8650
Epoch 7/100
380/380 [==============================] - 0s 71us/step - loss: 0.2675 - accuracy: 0.9079 - val_loss: 0.4072 - val_accuracy: 0.8528
Epoch 8/100
380/380 [==============================] - 0s 77us/step - loss: 0.2626 - accuracy: 0.9132 - val_loss: 0.4078 - val_accuracy: 0.8650
Epoch 9/100
380/380 [==============================] - 0s 83us/step - loss: 0.2670 - accuracy: 0.9000 - val_loss: 0.4004 - val_accuracy: 0.8528
Epoch 10/100
380/380 [==============================] - 0s 84us/step - loss: 0.2614 - accuracy: 0.9158 - val_loss: 0.4002 - val_accuracy: 0.8528
Epoch 11/100
380/380 [==============================] - 0s 68us/step - loss: 0.2651 - accuracy: 0.9026 - val_loss: 0.4037 - val_accuracy: 0.8650
Epoch 12/100
380/380 [==============================] - 0s 68us/step - loss: 0.2553 - accuracy: 0.9158 - val_loss: 0.3989 - val_accuracy: 0.8528
Epoch 13/100
380/380 [==============================] - 0s 70us/step - loss: 0.2558 - accuracy: 0.9132 - val_loss: 0.4066 - val_accuracy: 0.8528
Epoch 14/100
380/380 [==============================] - 0s 81us/step - loss: 0.2537 - accuracy: 0.9053 - val_loss: 0.3994 - val_accuracy: 0.8528
Epoch 15/100
380/380 [==============================] - 0s 81us/step - loss: 0.2571 - accuracy: 0.9158 - val_loss: 0.4008 - val_accuracy: 0.8650
Epoch 16/100
380/380 [==============================] - 0s 80us/step - loss: 0.2510 - accuracy: 0.9105 - val_loss: 0.3944 - val_accuracy: 0.8528
Epoch 17/100
380/380 [==============================] - 0s 79us/step - loss: 0.2516 - accuracy: 0.9184 - val_loss: 0.3957 - val_accuracy: 0.8650
Epoch 18/100
380/380 [==============================] - 0s 76us/step - loss: 0.2487 - accuracy: 0.9105 - val_loss: 0.3960 - val_accuracy: 0.8528
Epoch 19/100
380/380 [==============================] - 0s 68us/step - loss: 0.2549 - accuracy: 0.9132 - val_loss: 0.3945 - val_accuracy: 0.8528
Epoch 20/100
380/380 [==============================] - 0s 79us/step - loss: 0.2530 - accuracy: 0.9079 - val_loss: 0.3860 - val_accuracy: 0.8650
Epoch 21/100
380/380 [==============================] - 0s 93us/step - loss: 0.2625 - accuracy: 0.9053 - val_loss: 0.3917 - val_accuracy: 0.8528
Epoch 22/100
380/380 [==============================] - 0s 73us/step - loss: 0.2484 - accuracy: 0.9184 - val_loss: 0.4048 - val_accuracy: 0.8466
Epoch 23/100
380/380 [==============================] - 0s 75us/step - loss: 0.2472 - accuracy: 0.9132 - val_loss: 0.4050 - val_accuracy: 0.8528
Epoch 24/100
380/380 [==============================] - 0s 73us/step - loss: 0.2425 - accuracy: 0.9158 - val_loss: 0.4087 - val_accuracy: 0.8344
Epoch 25/100
380/380 [==============================] - 0s 66us/step - loss: 0.2471 - accuracy: 0.9105 - val_loss: 0.3978 - val_accuracy: 0.8528
Epoch 26/100
380/380 [==============================] - 0s 73us/step - loss: 0.2520 - accuracy: 0.8947 - val_loss: 0.3974 - val_accuracy: 0.8650
Epoch 27/100
380/380 [==============================] - 0s 80us/step - loss: 0.2401 - accuracy: 0.9132 - val_loss: 0.3919 - val_accuracy: 0.8650
Epoch 28/100
380/380 [==============================] - 0s 74us/step - loss: 0.2387 - accuracy: 0.9184 - val_loss: 0.3865 - val_accuracy: 0.8528
Epoch 29/100
380/380 [==============================] - 0s 68us/step - loss: 0.2433 - accuracy: 0.9079 - val_loss: 0.3971 - val_accuracy: 0.8589
Epoch 30/100
380/380 [==============================] - 0s 73us/step - loss: 0.2492 - accuracy: 0.9132 - val_loss: 0.3880 - val_accuracy: 0.8528
Epoch 31/100
380/380 [==============================] - 0s 71us/step - loss: 0.2441 - accuracy: 0.9105 - val_loss: 0.3979 - val_accuracy: 0.8589
Epoch 32/100
380/380 [==============================] - 0s 91us/step - loss: 0.2396 - accuracy: 0.9158 - val_loss: 0.3901 - val_accuracy: 0.8528
Epoch 33/100
380/380 [==============================] - 0s 105us/step - loss: 0.2420 - accuracy: 0.9211 - val_loss: 0.3911 - val_accuracy: 0.8650
Epoch 34/100
380/380 [==============================] - 0s 81us/step - loss: 0.2370 - accuracy: 0.9053 - val_loss: 0.3856 - val_accuracy: 0.8528
Epoch 35/100
380/380 [==============================] - 0s 72us/step - loss: 0.2396 - accuracy: 0.9184 - val_loss: 0.3855 - val_accuracy: 0.8466
Epoch 36/100
380/380 [==============================] - 0s 70us/step - loss: 0.2375 - accuracy: 0.9263 - val_loss: 0.3946 - val_accuracy: 0.8650
Epoch 37/100
380/380 [==============================] - 0s 83us/step - loss: 0.2279 - accuracy: 0.9158 - val_loss: 0.3935 - val_accuracy: 0.8466
Epoch 38/100
380/380 [==============================] - 0s 70us/step - loss: 0.2316 - accuracy: 0.9158 - val_loss: 0.3875 - val_accuracy: 0.8650
Epoch 39/100
380/380 [==============================] - 0s 60us/step - loss: 0.2271 - accuracy: 0.9211 - val_loss: 0.3853 - val_accuracy: 0.8650
Epoch 40/100
380/380 [==============================] - 0s 64us/step - loss: 0.2304 - accuracy: 0.9105 - val_loss: 0.3891 - val_accuracy: 0.8466
Epoch 41/100
380/380 [==============================] - 0s 64us/step - loss: 0.2379 - accuracy: 0.9211 - val_loss: 0.3845 - val_accuracy: 0.8466
Epoch 42/100
380/380 [==============================] - 0s 103us/step - loss: 0.2343 - accuracy: 0.9105 - val_loss: 0.3874 - val_accuracy: 0.8589
Epoch 43/100
380/380 [==============================] - 0s 238us/step - loss: 0.2424 - accuracy: 0.9158 - val_loss: 0.3841 - val_accuracy: 0.8466
Epoch 44/100
380/380 [==============================] - 0s 91us/step - loss: 0.2283 - accuracy: 0.9158 - val_loss: 0.3967 - val_accuracy: 0.8528
Epoch 45/100
380/380 [==============================] - 0s 83us/step - loss: 0.2276 - accuracy: 0.9158 - val_loss: 0.3815 - val_accuracy: 0.8589
Epoch 46/100
380/380 [==============================] - 0s 112us/step - loss: 0.2268 - accuracy: 0.9132 - val_loss: 0.4002 - val_accuracy: 0.8466
Epoch 47/100
380/380 [==============================] - 0s 85us/step - loss: 0.2258 - accuracy: 0.9053 - val_loss: 0.3797 - val_accuracy: 0.8528
Epoch 48/100
380/380 [==============================] - 0s 93us/step - loss: 0.2297 - accuracy: 0.9158 - val_loss: 0.3859 - val_accuracy: 0.8589
Epoch 49/100
380/380 [==============================] - 0s 94us/step - loss: 0.2196 - accuracy: 0.9132 - val_loss: 0.3852 - val_accuracy: 0.8589
Epoch 50/100
380/380 [==============================] - 0s 89us/step - loss: 0.2242 - accuracy: 0.9211 - val_loss: 0.4019 - val_accuracy: 0.8528
Epoch 51/100
380/380 [==============================] - 0s 102us/step - loss: 0.2314 - accuracy: 0.9184 - val_loss: 0.3835 - val_accuracy: 0.8650
Epoch 52/100
380/380 [==============================] - 0s 99us/step - loss: 0.2186 - accuracy: 0.9211 - val_loss: 0.3930 - val_accuracy: 0.8528
Epoch 53/100
380/380 [==============================] - 0s 99us/step - loss: 0.2185 - accuracy: 0.9158 - val_loss: 0.3867 - val_accuracy: 0.8528
Epoch 54/100
380/380 [==============================] - 0s 142us/step - loss: 0.2222 - accuracy: 0.9211 - val_loss: 0.3885 - val_accuracy: 0.8466
Epoch 55/100
380/380 [==============================] - 0s 306us/step - loss: 0.2163 - accuracy: 0.9158 - val_loss: 0.3816 - val_accuracy: 0.8528
Epoch 56/100
380/380 [==============================] - 0s 145us/step - loss: 0.2141 - accuracy: 0.9211 - val_loss: 0.3835 - val_accuracy: 0.8712
Epoch 57/100
380/380 [==============================] - 0s 83us/step - loss: 0.2129 - accuracy: 0.9211 - val_loss: 0.3868 - val_accuracy: 0.8650
Epoch 58/100
380/380 [==============================] - 0s 84us/step - loss: 0.2132 - accuracy: 0.9211 - val_loss: 0.3764 - val_accuracy: 0.8589
Epoch 59/100
380/380 [==============================] - 0s 53us/step - loss: 0.2156 - accuracy: 0.9184 - val_loss: 0.3850 - val_accuracy: 0.8650
Epoch 60/100
380/380 [==============================] - 0s 80us/step - loss: 0.2156 - accuracy: 0.9211 - val_loss: 0.3870 - val_accuracy: 0.8528
Epoch 61/100
380/380 [==============================] - 0s 80us/step - loss: 0.2171 - accuracy: 0.9211 - val_loss: 0.3922 - val_accuracy: 0.8589
Epoch 62/100
380/380 [==============================] - 0s 106us/step - loss: 0.2169 - accuracy: 0.9211 - val_loss: 0.3845 - val_accuracy: 0.8589
Epoch 63/100
380/380 [==============================] - 0s 131us/step - loss: 0.2129 - accuracy: 0.9237 - val_loss: 0.3892 - val_accuracy: 0.8589
Epoch 64/100
380/380 [==============================] - 0s 139us/step - loss: 0.2256 - accuracy: 0.9053 - val_loss: 0.3753 - val_accuracy: 0.8773
Epoch 65/100
380/380 [==============================] - 0s 75us/step - loss: 0.2339 - accuracy: 0.9105 - val_loss: 0.3842 - val_accuracy: 0.8650
Epoch 66/100
380/380 [==============================] - 0s 75us/step - loss: 0.2195 - accuracy: 0.9158 - val_loss: 0.3946 - val_accuracy: 0.8528
Epoch 67/100
380/380 [==============================] - 0s 61us/step - loss: 0.2122 - accuracy: 0.9237 - val_loss: 0.3888 - val_accuracy: 0.8528
Epoch 68/100
380/380 [==============================] - 0s 62us/step - loss: 0.2169 - accuracy: 0.9132 - val_loss: 0.3862 - val_accuracy: 0.8650
Epoch 69/100
380/380 [==============================] - 0s 56us/step - loss: 0.2121 - accuracy: 0.9184 - val_loss: 0.3778 - val_accuracy: 0.8528
Epoch 70/100
380/380 [==============================] - 0s 74us/step - loss: 0.2228 - accuracy: 0.9158 - val_loss: 0.3889 - val_accuracy: 0.8650
Epoch 71/100
380/380 [==============================] - 0s 56us/step - loss: 0.2187 - accuracy: 0.9158 - val_loss: 0.3870 - val_accuracy: 0.8589
Epoch 72/100
380/380 [==============================] - 0s 440us/step - loss: 0.2339 - accuracy: 0.8974 - val_loss: 0.3834 - val_accuracy: 0.8712
Epoch 73/100
380/380 [==============================] - 0s 128us/step - loss: 0.2185 - accuracy: 0.9158 - val_loss: 0.3737 - val_accuracy: 0.8712
Epoch 74/100
380/380 [==============================] - 0s 87us/step - loss: 0.2128 - accuracy: 0.9184 - val_loss: 0.3853 - val_accuracy: 0.8528
Epoch 75/100
380/380 [==============================] - 0s 77us/step - loss: 0.2125 - accuracy: 0.9237 - val_loss: 0.3844 - val_accuracy: 0.8589
Epoch 76/100
380/380 [==============================] - 0s 80us/step - loss: 0.2075 - accuracy: 0.9158 - val_loss: 0.3915 - val_accuracy: 0.8589
Epoch 77/100
380/380 [==============================] - 0s 78us/step - loss: 0.2041 - accuracy: 0.9237 - val_loss: 0.3790 - val_accuracy: 0.8528
Epoch 78/100
380/380 [==============================] - 0s 76us/step - loss: 0.2048 - accuracy: 0.9237 - val_loss: 0.3866 - val_accuracy: 0.8589
Epoch 79/100
380/380 [==============================] - 0s 76us/step - loss: 0.2042 - accuracy: 0.9184 - val_loss: 0.3784 - val_accuracy: 0.8712
Epoch 80/100
380/380 [==============================] - 0s 78us/step - loss: 0.2150 - accuracy: 0.9237 - val_loss: 0.3787 - val_accuracy: 0.8650
Epoch 81/100
380/380 [==============================] - 0s 76us/step - loss: 0.2009 - accuracy: 0.9237 - val_loss: 0.3746 - val_accuracy: 0.8528
Epoch 82/100
380/380 [==============================] - 0s 71us/step - loss: 0.2042 - accuracy: 0.9211 - val_loss: 0.3760 - val_accuracy: 0.8650
Epoch 83/100
380/380 [==============================] - 0s 116us/step - loss: 0.2006 - accuracy: 0.9263 - val_loss: 0.3795 - val_accuracy: 0.8466
Epoch 84/100
380/380 [==============================] - 0s 98us/step - loss: 0.2051 - accuracy: 0.9184 - val_loss: 0.3766 - val_accuracy: 0.8589
Epoch 85/100
380/380 [==============================] - 0s 64us/step - loss: 0.2014 - accuracy: 0.9237 - val_loss: 0.3801 - val_accuracy: 0.8528
Epoch 86/100
380/380 [==============================] - 0s 60us/step - loss: 0.1981 - accuracy: 0.9263 - val_loss: 0.3810 - val_accuracy: 0.8712
Epoch 87/100
380/380 [==============================] - 0s 64us/step - loss: 0.2027 - accuracy: 0.9211 - val_loss: 0.3779 - val_accuracy: 0.8528
Epoch 88/100
380/380 [==============================] - 0s 63us/step - loss: 0.1998 - accuracy: 0.9158 - val_loss: 0.3829 - val_accuracy: 0.8650
Epoch 89/100
380/380 [==============================] - 0s 60us/step - loss: 0.1989 - accuracy: 0.9263 - val_loss: 0.3793 - val_accuracy: 0.8528
Epoch 90/100
380/380 [==============================] - 0s 68us/step - loss: 0.2044 - accuracy: 0.9158 - val_loss: 0.3938 - val_accuracy: 0.8589
Epoch 91/100
380/380 [==============================] - 0s 77us/step - loss: 0.1965 - accuracy: 0.9237 - val_loss: 0.3829 - val_accuracy: 0.8589
Epoch 92/100
380/380 [==============================] - 0s 209us/step - loss: 0.2042 - accuracy: 0.9184 - val_loss: 0.4034 - val_accuracy: 0.8466
Epoch 93/100
380/380 [==============================] - 0s 163us/step - loss: 0.1996 - accuracy: 0.9184 - val_loss: 0.3728 - val_accuracy: 0.8528
Epoch 94/100
380/380 [==============================] - 0s 95us/step - loss: 0.2043 - accuracy: 0.9211 - val_loss: 0.4027 - val_accuracy: 0.8466
Epoch 95/100
380/380 [==============================] - 0s 88us/step - loss: 0.2019 - accuracy: 0.9158 - val_loss: 0.3728 - val_accuracy: 0.8528
Epoch 96/100
380/380 [==============================] - ETA: 0s - loss: 0.1181 - accuracy: 0.95 - 0s 157us/step - loss: 0.1987 - accuracy: 0.9237 - val_loss: 0.3898 - val_accuracy: 0.8650
Epoch 97/100
380/380 [==============================] - 0s 118us/step - loss: 0.1959 - accuracy: 0.9211 - val_loss: 0.3748 - val_accuracy: 0.8528
Epoch 98/100
380/380 [==============================] - 0s 460us/step - loss: 0.1994 - accuracy: 0.9211 - val_loss: 0.3777 - val_accuracy: 0.8528
Epoch 99/100
380/380 [==============================] - 0s 191us/step - loss: 0.2063 - accuracy: 0.9158 - val_loss: 0.3737 - val_accuracy: 0.8528
Epoch 100/100
380/380 [==============================] - 0s 122us/step - loss: 0.2023 - accuracy: 0.9158 - val_loss: 0.3736 - val_accuracy: 0.8589
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[198]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;over-sampling train accuracy: </span><span class="si">%.2f%%</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">hist2_over2</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span><span class="o">*</span><span class="mi">100</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>over-sampling train accuracy: 91.57%
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[43]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df_proba6</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_excel</span><span class="p">(</span><span class="s2">&quot;/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_lasso_2.xlsx&quot;</span><span class="p">,</span>
                        <span class="n">sheet_name</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                        <span class="n">index_col</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[44]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df_proba6</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[44]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>phage</th>
      <th>strain</th>
      <th>phenotype</th>
      <th>prediction</th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>p0006kpresabs_qual</td>
      <td>NRS249</td>
      <td>2</td>
      <td>1</td>
      <td>1.888869e-01</td>
      <td>5.108038e-01</td>
      <td>3.003094e-01</td>
    </tr>
    <tr>
      <th>1</th>
      <td>p0006kpresabs_qual</td>
      <td>NRS188</td>
      <td>1</td>
      <td>1</td>
      <td>1.888869e-01</td>
      <td>5.108038e-01</td>
      <td>3.003094e-01</td>
    </tr>
    <tr>
      <th>2</th>
      <td>p0006kpresabs_qual</td>
      <td>NRS232</td>
      <td>2</td>
      <td>2</td>
      <td>4.222906e-01</td>
      <td>7.029924e-02</td>
      <td>5.074101e-01</td>
    </tr>
    <tr>
      <th>3</th>
      <td>p0006kpresabs_qual</td>
      <td>NY439</td>
      <td>2</td>
      <td>2</td>
      <td>3.558408e-04</td>
      <td>2.976018e-04</td>
      <td>9.993465e-01</td>
    </tr>
    <tr>
      <th>4</th>
      <td>p0006kpresabs_qual</td>
      <td>GA27</td>
      <td>2</td>
      <td>1</td>
      <td>3.940971e-01</td>
      <td>4.184215e-01</td>
      <td>1.874814e-01</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>984</th>
      <td>p0017Skpresabs_qual</td>
      <td>NRS252</td>
      <td>0</td>
      <td>0</td>
      <td>7.239556e-01</td>
      <td>2.760444e-01</td>
      <td>1.176030e-09</td>
    </tr>
    <tr>
      <th>985</th>
      <td>p0017Skpresabs_qual</td>
      <td>SR2852</td>
      <td>1</td>
      <td>1</td>
      <td>1.052276e-07</td>
      <td>9.999999e-01</td>
      <td>1.101559e-28</td>
    </tr>
    <tr>
      <th>986</th>
      <td>p0017Skpresabs_qual</td>
      <td>NRS108</td>
      <td>1</td>
      <td>1</td>
      <td>1.540350e-17</td>
      <td>1.000000e+00</td>
      <td>9.011977e-16</td>
    </tr>
    <tr>
      <th>987</th>
      <td>p0017Skpresabs_qual</td>
      <td>NRS202</td>
      <td>0</td>
      <td>0</td>
      <td>6.888959e-01</td>
      <td>3.111042e-01</td>
      <td>2.228958e-09</td>
    </tr>
    <tr>
      <th>988</th>
      <td>p0017Skpresabs_qual</td>
      <td>NRS110</td>
      <td>2</td>
      <td>2</td>
      <td>1.097719e-09</td>
      <td>4.404655e-08</td>
      <td>1.000000e+00</td>
    </tr>
  </tbody>
</table>
<p>989 rows × 7 columns</p>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[45]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">y_prob6</span> <span class="o">=</span> <span class="n">df_proba6</span><span class="p">[</span><span class="n">df_proba6</span><span class="p">[</span><span class="s1">&#39;phage&#39;</span><span class="p">]</span><span class="o">==</span><span class="s1">&#39;p11kpresabs_qual&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="o">-</span><span class="mi">3</span><span class="p">:]</span>
<span class="n">y_prob6</span> <span class="o">=</span> <span class="n">y_prob6</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
<span class="n">y_prob6</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[45]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>array([[2.57378890e-03, 8.85729100e-01, 1.11697110e-01],
       [1.18699506e-01, 2.10627940e-01, 6.70672540e-01],
       [4.30934470e-02, 1.05198040e-01, 8.51708500e-01],
       [2.45580930e-01, 6.51203200e-01, 1.03215870e-01],
       [4.35716620e-04, 9.77855860e-01, 2.17083600e-02],
       [9.78418700e-01, 5.73518870e-03, 1.58461430e-02],
       [7.86796000e-03, 9.69179600e-01, 2.29524260e-02],
       [3.83677870e-01, 1.22634664e-01, 4.93687500e-01],
       [2.77630700e-03, 5.93725100e-02, 9.37851200e-01],
       [2.20101040e-01, 5.52219100e-01, 2.27679920e-01],
       [3.53825270e-01, 1.98377700e-01, 4.47797030e-01],
       [6.19283280e-02, 5.99709000e-01, 3.38362660e-01],
       [5.54868900e-01, 2.27175970e-01, 2.17955100e-01],
       [8.17905070e-01, 7.51824160e-02, 1.06912486e-01],
       [2.45580930e-01, 6.51203200e-01, 1.03215870e-01],
       [8.56446150e-01, 2.02935190e-04, 1.43350880e-01],
       [2.70295090e-02, 1.55329500e-02, 9.57437500e-01],
       [5.89528900e-04, 9.39687200e-01, 5.97232580e-02],
       [2.79141460e-01, 1.34825680e-01, 5.86032870e-01],
       [2.65483420e-03, 9.62582470e-01, 3.47626300e-02],
       [2.94742800e-01, 3.04688900e-01, 4.00568300e-01],
       [1.58799980e-02, 9.66621460e-01, 1.74985790e-02],
       [8.56446150e-01, 2.02935190e-04, 1.43350880e-01],
       [7.35140900e-03, 9.69836100e-01, 2.28125040e-02],
       [2.20101040e-01, 5.52219100e-01, 2.27679920e-01],
       [3.43493070e-03, 2.26457580e-02, 9.73919330e-01],
       [8.43924600e-01, 1.18354104e-01, 3.77212840e-02],
       [1.27277970e-03, 7.68596300e-02, 9.21867600e-01],
       [9.77325300e-01, 5.12343900e-03, 1.75512430e-02],
       [4.02551700e-02, 3.88255750e-01, 5.71489100e-01],
       [9.82042850e-01, 7.67912340e-03, 1.02780230e-02],
       [8.81917400e-01, 2.09818930e-02, 9.71007400e-02],
       [8.03327100e-01, 2.08010080e-03, 1.94592850e-01],
       [2.45580930e-01, 6.51203200e-01, 1.03215870e-01],
       [2.57378890e-03, 8.85729100e-01, 1.11697110e-01],
       [2.31946870e-03, 5.36798100e-01, 4.60882340e-01],
       [2.20101040e-01, 5.52219100e-01, 2.27679920e-01],
       [8.05117500e-02, 2.77067960e-01, 6.42420230e-01],
       [1.71092410e-02, 9.72787000e-01, 1.01037510e-02],
       [8.43924600e-01, 1.18354104e-01, 3.77212840e-02],
       [6.45334270e-03, 8.01379500e-01, 1.92167150e-01],
       [2.20101040e-01, 5.52219100e-01, 2.27679920e-01],
       [1.83428400e-03, 9.78495300e-01, 1.96703880e-02],
       [9.62177930e-01, 1.36050545e-02, 2.42169630e-02],
       [1.19506390e-03, 5.95498560e-01, 4.03306400e-01],
       [1.13370220e-02, 4.12953500e-01, 5.75709500e-01],
       [8.98698250e-03, 6.83597100e-02, 9.22653300e-01],
       [2.48284150e-01, 1.20115630e-01, 6.31600200e-01],
       [9.26808700e-01, 1.19870830e-02, 6.12042140e-02],
       [2.31946870e-03, 5.36798100e-01, 4.60882340e-01],
       [8.43461600e-03, 8.37353200e-03, 9.83191900e-01],
       [2.20101040e-01, 5.52219100e-01, 2.27679920e-01],
       [6.49825100e-02, 8.27672300e-02, 8.52250200e-01],
       [4.75069230e-03, 1.27739580e-01, 8.67509800e-01],
       [8.43924600e-01, 1.18354104e-01, 3.77212840e-02],
       [7.75903900e-01, 5.42156050e-04, 2.23554000e-01],
       [1.81152470e-04, 9.77973500e-01, 2.18452500e-02],
       [2.44021120e-02, 3.60226840e-01, 6.15371050e-01],
       [9.58786250e-01, 7.77235500e-03, 3.34414000e-02],
       [7.75903900e-01, 5.42156050e-04, 2.23554000e-01],
       [2.20101040e-01, 5.52219100e-01, 2.27679920e-01],
       [5.79200800e-02, 8.90684300e-01, 5.13956470e-02],
       [8.05117500e-02, 2.77067960e-01, 6.42420230e-01],
       [3.45814340e-03, 9.75882700e-01, 2.06590800e-02],
       [8.03327100e-01, 2.08010080e-03, 1.94592850e-01],
       [1.71092410e-02, 9.72787000e-01, 1.01037510e-02],
       [4.50861270e-02, 2.99154500e-01, 6.55759400e-01],
       [1.34695570e-01, 2.08398860e-01, 6.56905600e-01],
       [8.03327100e-01, 2.08010080e-03, 1.94592850e-01],
       [2.22878800e-01, 2.90279200e-01, 4.86842000e-01],
       [8.05117500e-02, 2.77067960e-01, 6.42420230e-01],
       [2.57378890e-03, 8.85729100e-01, 1.11697110e-01],
       [2.57378890e-03, 8.85729100e-01, 1.11697110e-01],
       [1.39188820e-05, 9.82140900e-01, 1.78451200e-02],
       [2.24272330e-04, 9.74426500e-01, 2.53491270e-02],
       [1.60118620e-02, 1.90524710e-01, 7.93463400e-01],
       [3.83321800e-02, 1.91677850e-02, 9.42500000e-01],
       [2.00429590e-01, 5.18103900e-01, 2.81466450e-01],
       [9.72304200e-01, 2.47931400e-03, 2.52165600e-02],
       [9.30421000e-04, 9.86842450e-01, 1.22271260e-02],
       [2.47377850e-02, 3.36190200e-01, 6.39072060e-01],
       [1.12776436e-01, 7.64412900e-01, 1.22810684e-01],
       [3.14344750e-03, 1.91414160e-03, 9.94942370e-01],
       [1.17538925e-02, 9.63657860e-01, 2.45882460e-02],
       [2.90172970e-03, 9.93793250e-01, 3.30501840e-03],
       [1.24080560e-03, 1.20209660e-01, 8.78549500e-01],
       [5.79200800e-02, 8.90684300e-01, 5.13956470e-02],
       [3.51816020e-03, 8.58964100e-01, 1.37517780e-01],
       [1.96046960e-02, 4.66061380e-01, 5.14333960e-01],
       [2.24272330e-04, 9.74426500e-01, 2.53491270e-02],
       [5.79200800e-02, 8.90684300e-01, 5.13956470e-02],
       [3.83677870e-01, 1.22634664e-01, 4.93687500e-01],
       [1.07452630e-01, 7.95877300e-01, 9.66700500e-02],
       [4.16052340e-01, 2.81863300e-01, 3.02084360e-01],
       [8.05117500e-02, 2.77067960e-01, 6.42420230e-01],
       [9.45760700e-01, 1.73429570e-02, 3.68962800e-02],
       [9.62177930e-01, 1.36050545e-02, 2.42169630e-02],
       [3.45814340e-03, 9.75882700e-01, 2.06590800e-02],
       [1.64263170e-03, 9.60854530e-01, 3.75027620e-02],
       [8.17905070e-01, 7.51824160e-02, 1.06912486e-01],
       [9.77325300e-01, 5.12343900e-03, 1.75512430e-02],
       [7.35140900e-03, 9.69836100e-01, 2.28125040e-02],
       [1.58799980e-02, 9.66621460e-01, 1.74985790e-02],
       [8.03327100e-01, 2.08010080e-03, 1.94592850e-01],
       [1.81152470e-04, 9.77973500e-01, 2.18452500e-02],
       [4.65890540e-04, 9.54750540e-01, 4.47835850e-02],
       [9.44840130e-01, 1.33947340e-04, 5.50259840e-02],
       [2.45580930e-01, 6.51203200e-01, 1.03215870e-01],
       [3.13138200e-02, 9.00383830e-01, 6.83022700e-02],
       [2.20101040e-01, 5.52219100e-01, 2.27679920e-01],
       [2.32595480e-02, 1.12872906e-01, 8.63867500e-01],
       [3.83677870e-01, 1.22634664e-01, 4.93687500e-01],
       [4.18334340e-02, 2.28873860e-01, 7.29292750e-01],
       [1.30656730e-01, 3.13872070e-01, 5.55471240e-01],
       [9.88705200e-01, 2.04335600e-03, 9.25142700e-03],
       [1.16520330e-03, 2.07504030e-02, 9.78084400e-01],
       [2.45580930e-01, 6.51203200e-01, 1.03215870e-01],
       [9.48196300e-01, 2.05026470e-02, 3.13011500e-02],
       [9.30421000e-04, 9.86842450e-01, 1.22271260e-02],
       [9.26808700e-01, 1.19870830e-02, 6.12042140e-02],
       [2.20101040e-01, 5.52219100e-01, 2.27679920e-01],
       [8.03327100e-01, 2.08010080e-03, 1.94592850e-01],
       [5.92928500e-03, 2.97538770e-03, 9.91095300e-01],
       [9.83021400e-01, 5.79233900e-03, 1.11862190e-02],
       [8.14797600e-03, 9.93184400e-03, 9.81920200e-01],
       [9.78418700e-01, 5.73518870e-03, 1.58461430e-02],
       [6.55458450e-01, 2.88670400e-03, 3.41654900e-01],
       [3.51816020e-03, 8.58964100e-01, 1.37517780e-01],
       [1.53309300e-04, 4.87638000e-01, 5.12208640e-01],
       [2.57378890e-03, 8.85729100e-01, 1.11697110e-01],
       [6.55458450e-01, 2.88670400e-03, 3.41654900e-01],
       [1.57288970e-03, 7.05135170e-01, 2.93292000e-01],
       [2.45580930e-01, 6.51203200e-01, 1.03215870e-01],
       [9.30421000e-04, 9.86842450e-01, 1.22271260e-02],
       [3.35994800e-02, 1.35258450e-01, 8.31142070e-01],
       [2.36646500e-01, 2.79162060e-03, 7.60561900e-01],
       [9.13355600e-03, 1.26818600e-01, 8.64047900e-01],
       [8.43924600e-01, 1.18354104e-01, 3.77212840e-02],
       [2.20101040e-01, 5.52219100e-01, 2.27679920e-01],
       [8.43924600e-01, 1.18354104e-01, 3.77212840e-02],
       [9.78418700e-01, 5.73518870e-03, 1.58461430e-02],
       [9.60277500e-01, 7.29501850e-03, 3.24274670e-02],
       [9.48196300e-01, 2.05026470e-02, 3.13011500e-02],
       [2.00429590e-01, 5.18103900e-01, 2.81466450e-01],
       [2.45580930e-01, 6.51203200e-01, 1.03215870e-01],
       [2.20101040e-01, 5.52219100e-01, 2.27679920e-01],
       [4.20259100e-02, 7.87853800e-01, 1.70120300e-01],
       [3.83677870e-01, 1.22634664e-01, 4.93687500e-01],
       [2.20101040e-01, 5.52219100e-01, 2.27679920e-01],
       [9.62177930e-01, 1.36050545e-02, 2.42169630e-02],
       [6.55458450e-01, 2.88670400e-03, 3.41654900e-01],
       [2.12208330e-01, 9.08607900e-03, 7.78705540e-01],
       [8.43924600e-01, 1.18354104e-01, 3.77212840e-02],
       [2.20101040e-01, 5.52219100e-01, 2.27679920e-01],
       [1.82565060e-01, 3.76190850e-03, 8.13673100e-01],
       [1.64263170e-03, 9.60854530e-01, 3.75027620e-02],
       [7.75903900e-01, 5.42156050e-04, 2.23554000e-01],
       [9.89855500e-01, 2.39740430e-03, 7.74707200e-03],
       [9.62177930e-01, 1.36050545e-02, 2.42169630e-02],
       [9.83021400e-01, 5.79233900e-03, 1.11862190e-02],
       [6.55458450e-01, 2.88670400e-03, 3.41654900e-01],
       [1.36771430e-02, 3.95338400e-03, 9.82369500e-01],
       [4.91431860e-01, 5.54265600e-02, 4.53141600e-01]])</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[46]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">ovo6</span> <span class="o">=</span> <span class="n">rocauc_ovo</span><span class="p">(</span><span class="n">y_sel_test_over</span><span class="p">,</span> <span class="n">y_prob6</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s2">&quot;macro&quot;</span><span class="p">,</span> <span class="n">multi_class</span><span class="o">=</span><span class="s2">&quot;ovo&quot;</span><span class="p">)</span>
<span class="n">ovo6</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[46]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>0.9506739155057198</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[47]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">ovr6</span> <span class="o">=</span> <span class="n">rocauc_ovr</span><span class="p">(</span><span class="n">y_sel_test_over</span><span class="p">,</span> <span class="n">y_prob6</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s2">&quot;macro&quot;</span><span class="p">,</span> <span class="n">multi_class</span><span class="o">=</span><span class="s2">&quot;ovr&quot;</span><span class="p">)</span>
<span class="n">ovr6</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[47]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>0.9506739155057198</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[48]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># split into train, test data (over)</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="n">X_sel_train_over</span><span class="p">,</span> <span class="n">X_sel_test_over</span><span class="p">,</span> <span class="n">y_sel_train_over</span><span class="p">,</span> <span class="n">y_sel_test_over</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X_sel_over</span><span class="p">,</span> <span class="n">y_sel_over</span><span class="p">,</span>
                                                    <span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.3</span><span class="p">,</span>
                                                    <span class="n">random_state</span><span class="o">=</span><span class="mi">789</span><span class="p">,</span>
                                                    <span class="n">stratify</span><span class="o">=</span><span class="n">y_sel_over</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[49]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dat7</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X_sel_test_over</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
<span class="n">dat7</span><span class="p">[</span><span class="s1">&#39;test&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">y_sel_test_over</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[50]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dat7</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[50]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>test</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>CFBREBSa127</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>NRS145</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>CFBRSa66B</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>NRS204</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>BCH-SA-13</td>
      <td>2</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>158</th>
      <td>NRS233</td>
      <td>2</td>
    </tr>
    <tr>
      <th>159</th>
      <td>NRS204</td>
      <td>1</td>
    </tr>
    <tr>
      <th>160</th>
      <td>CFBRSa07</td>
      <td>0</td>
    </tr>
    <tr>
      <th>161</th>
      <td>CFBREBSa117</td>
      <td>1</td>
    </tr>
    <tr>
      <th>162</th>
      <td>CFBREBSa126</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>163 rows × 2 columns</p>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[51]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">X_sel_train_over</span> <span class="o">=</span> <span class="n">X_sel_train_over</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">X_sel_test_over</span> <span class="o">=</span> <span class="n">X_sel_test_over</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[109]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model2_over3</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">([</span>
    <span class="n">Dense</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="n">X_sel_train_over</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],)),</span>
    <span class="n">Dense</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">),</span>
<span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[110]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model2_over3</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span>
              <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;sparse_categorical_crossentropy&#39;</span><span class="p">,</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[111]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model2_over3</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_sel_train_over</span><span class="p">,</span> <span class="n">y_sel_train_over</span><span class="p">,</span>
          <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
          <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">X_sel_test_over</span><span class="p">,</span> <span class="n">y_sel_test_over</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Train on 380 samples, validate on 163 samples
Epoch 1/100
380/380 [==============================] - 0s 396us/step - loss: 1.1924 - accuracy: 0.3421 - val_loss: 1.1260 - val_accuracy: 0.3742
Epoch 2/100
380/380 [==============================] - 0s 88us/step - loss: 1.0327 - accuracy: 0.4237 - val_loss: 1.0526 - val_accuracy: 0.4356
Epoch 3/100
380/380 [==============================] - 0s 132us/step - loss: 0.9660 - accuracy: 0.5500 - val_loss: 0.9896 - val_accuracy: 0.4847
Epoch 4/100
380/380 [==============================] - 0s 124us/step - loss: 0.9188 - accuracy: 0.5684 - val_loss: 0.9463 - val_accuracy: 0.5215
Epoch 5/100
380/380 [==============================] - 0s 155us/step - loss: 0.8724 - accuracy: 0.6211 - val_loss: 0.9104 - val_accuracy: 0.5521
Epoch 6/100
380/380 [==============================] - 0s 149us/step - loss: 0.8275 - accuracy: 0.6579 - val_loss: 0.8671 - val_accuracy: 0.6135
Epoch 7/100
380/380 [==============================] - 0s 111us/step - loss: 0.7933 - accuracy: 0.6474 - val_loss: 0.8390 - val_accuracy: 0.6319
Epoch 8/100
380/380 [==============================] - 0s 143us/step - loss: 0.7656 - accuracy: 0.6895 - val_loss: 0.8234 - val_accuracy: 0.6380
Epoch 9/100
380/380 [==============================] - 0s 151us/step - loss: 0.7305 - accuracy: 0.6974 - val_loss: 0.7980 - val_accuracy: 0.6319
Epoch 10/100
380/380 [==============================] - 0s 108us/step - loss: 0.7100 - accuracy: 0.6947 - val_loss: 0.7764 - val_accuracy: 0.6933
Epoch 11/100
380/380 [==============================] - 0s 147us/step - loss: 0.6843 - accuracy: 0.7237 - val_loss: 0.7592 - val_accuracy: 0.7117
Epoch 12/100
380/380 [==============================] - 0s 158us/step - loss: 0.6525 - accuracy: 0.7474 - val_loss: 0.7353 - val_accuracy: 0.7239
Epoch 13/100
380/380 [==============================] - 0s 161us/step - loss: 0.6475 - accuracy: 0.7474 - val_loss: 0.7494 - val_accuracy: 0.6871
Epoch 14/100
380/380 [==============================] - 0s 109us/step - loss: 0.6142 - accuracy: 0.7684 - val_loss: 0.7548 - val_accuracy: 0.6626
Epoch 15/100
380/380 [==============================] - 0s 121us/step - loss: 0.6158 - accuracy: 0.7553 - val_loss: 0.6879 - val_accuracy: 0.7055
Epoch 16/100
380/380 [==============================] - 0s 106us/step - loss: 0.5887 - accuracy: 0.7737 - val_loss: 0.6812 - val_accuracy: 0.6933
Epoch 17/100
380/380 [==============================] - 0s 104us/step - loss: 0.5646 - accuracy: 0.7974 - val_loss: 0.6898 - val_accuracy: 0.6933
Epoch 18/100
380/380 [==============================] - 0s 91us/step - loss: 0.5675 - accuracy: 0.7605 - val_loss: 0.6764 - val_accuracy: 0.6871
Epoch 19/100
380/380 [==============================] - 0s 107us/step - loss: 0.5498 - accuracy: 0.7921 - val_loss: 0.6317 - val_accuracy: 0.7791
Epoch 20/100
380/380 [==============================] - 0s 152us/step - loss: 0.5255 - accuracy: 0.8263 - val_loss: 0.6303 - val_accuracy: 0.7669
Epoch 21/100
380/380 [==============================] - 0s 221us/step - loss: 0.5059 - accuracy: 0.8158 - val_loss: 0.6103 - val_accuracy: 0.7669
Epoch 22/100
380/380 [==============================] - 0s 101us/step - loss: 0.4953 - accuracy: 0.8053 - val_loss: 0.6535 - val_accuracy: 0.7117
Epoch 23/100
380/380 [==============================] - 0s 83us/step - loss: 0.5194 - accuracy: 0.7947 - val_loss: 0.5993 - val_accuracy: 0.7546
Epoch 24/100
380/380 [==============================] - 0s 117us/step - loss: 0.4705 - accuracy: 0.8395 - val_loss: 0.5807 - val_accuracy: 0.7853
Epoch 25/100
380/380 [==============================] - 0s 116us/step - loss: 0.4642 - accuracy: 0.8395 - val_loss: 0.5721 - val_accuracy: 0.7853
Epoch 26/100
380/380 [==============================] - 0s 158us/step - loss: 0.4500 - accuracy: 0.8447 - val_loss: 0.5626 - val_accuracy: 0.8282
Epoch 27/100
380/380 [==============================] - 0s 132us/step - loss: 0.4517 - accuracy: 0.8316 - val_loss: 0.6063 - val_accuracy: 0.6933
Epoch 28/100
380/380 [==============================] - 0s 134us/step - loss: 0.4833 - accuracy: 0.8053 - val_loss: 0.5615 - val_accuracy: 0.7546
Epoch 29/100
380/380 [==============================] - 0s 118us/step - loss: 0.4550 - accuracy: 0.8263 - val_loss: 0.5378 - val_accuracy: 0.8466
Epoch 30/100
380/380 [==============================] - 0s 139us/step - loss: 0.4202 - accuracy: 0.8658 - val_loss: 0.5359 - val_accuracy: 0.8221
Epoch 31/100
380/380 [==============================] - 0s 134us/step - loss: 0.4084 - accuracy: 0.8632 - val_loss: 0.5344 - val_accuracy: 0.7914
Epoch 32/100
380/380 [==============================] - 0s 302us/step - loss: 0.4006 - accuracy: 0.8605 - val_loss: 0.5322 - val_accuracy: 0.8037
Epoch 33/100
380/380 [==============================] - 0s 68us/step - loss: 0.3840 - accuracy: 0.8763 - val_loss: 0.5152 - val_accuracy: 0.8282
Epoch 34/100
380/380 [==============================] - 0s 68us/step - loss: 0.3831 - accuracy: 0.8737 - val_loss: 0.5093 - val_accuracy: 0.8282
Epoch 35/100
380/380 [==============================] - 0s 77us/step - loss: 0.3736 - accuracy: 0.8737 - val_loss: 0.5093 - val_accuracy: 0.8344
Epoch 36/100
380/380 [==============================] - 0s 81us/step - loss: 0.3725 - accuracy: 0.8684 - val_loss: 0.5077 - val_accuracy: 0.8037
Epoch 37/100
380/380 [==============================] - 0s 78us/step - loss: 0.3604 - accuracy: 0.8842 - val_loss: 0.5083 - val_accuracy: 0.8037
Epoch 38/100
380/380 [==============================] - 0s 74us/step - loss: 0.3510 - accuracy: 0.8868 - val_loss: 0.5011 - val_accuracy: 0.8098
Epoch 39/100
380/380 [==============================] - 0s 72us/step - loss: 0.3520 - accuracy: 0.8895 - val_loss: 0.4942 - val_accuracy: 0.8405
Epoch 40/100
380/380 [==============================] - 0s 100us/step - loss: 0.3639 - accuracy: 0.8763 - val_loss: 0.5161 - val_accuracy: 0.8098
Epoch 41/100
380/380 [==============================] - 0s 101us/step - loss: 0.3481 - accuracy: 0.8842 - val_loss: 0.5363 - val_accuracy: 0.7607
Epoch 42/100
380/380 [==============================] - 0s 294us/step - loss: 0.3586 - accuracy: 0.8632 - val_loss: 0.4988 - val_accuracy: 0.8160
Epoch 43/100
380/380 [==============================] - 0s 179us/step - loss: 0.3295 - accuracy: 0.8842 - val_loss: 0.4858 - val_accuracy: 0.8282
Epoch 44/100
380/380 [==============================] - 0s 263us/step - loss: 0.3297 - accuracy: 0.8763 - val_loss: 0.4837 - val_accuracy: 0.8098
Epoch 45/100
380/380 [==============================] - 0s 191us/step - loss: 0.3181 - accuracy: 0.8895 - val_loss: 0.4761 - val_accuracy: 0.8221
Epoch 46/100
380/380 [==============================] - 0s 161us/step - loss: 0.3133 - accuracy: 0.8868 - val_loss: 0.4602 - val_accuracy: 0.8282
Epoch 47/100
380/380 [==============================] - 0s 142us/step - loss: 0.3192 - accuracy: 0.8816 - val_loss: 0.4682 - val_accuracy: 0.8282
Epoch 48/100
380/380 [==============================] - 0s 201us/step - loss: 0.3100 - accuracy: 0.8895 - val_loss: 0.4772 - val_accuracy: 0.8037
Epoch 49/100
380/380 [==============================] - 0s 187us/step - loss: 0.3079 - accuracy: 0.8789 - val_loss: 0.4887 - val_accuracy: 0.8466
Epoch 50/100
380/380 [==============================] - 0s 161us/step - loss: 0.3056 - accuracy: 0.8868 - val_loss: 0.4697 - val_accuracy: 0.8221
Epoch 51/100
380/380 [==============================] - 0s 125us/step - loss: 0.2956 - accuracy: 0.8921 - val_loss: 0.4611 - val_accuracy: 0.8221
Epoch 52/100
380/380 [==============================] - 0s 113us/step - loss: 0.2932 - accuracy: 0.8921 - val_loss: 0.4537 - val_accuracy: 0.8282
Epoch 53/100
380/380 [==============================] - 0s 178us/step - loss: 0.2885 - accuracy: 0.8947 - val_loss: 0.4747 - val_accuracy: 0.8466
Epoch 54/100
380/380 [==============================] - 0s 199us/step - loss: 0.2852 - accuracy: 0.9053 - val_loss: 0.4484 - val_accuracy: 0.8282
Epoch 55/100
380/380 [==============================] - 0s 162us/step - loss: 0.2886 - accuracy: 0.8974 - val_loss: 0.4547 - val_accuracy: 0.8282
Epoch 56/100
380/380 [==============================] - 0s 94us/step - loss: 0.2809 - accuracy: 0.8921 - val_loss: 0.4452 - val_accuracy: 0.8282
Epoch 57/100
380/380 [==============================] - 0s 209us/step - loss: 0.2818 - accuracy: 0.8947 - val_loss: 0.4449 - val_accuracy: 0.8282
Epoch 58/100
380/380 [==============================] - 0s 213us/step - loss: 0.2861 - accuracy: 0.8947 - val_loss: 0.4383 - val_accuracy: 0.8282
Epoch 59/100
380/380 [==============================] - 0s 217us/step - loss: 0.2787 - accuracy: 0.8947 - val_loss: 0.4691 - val_accuracy: 0.8037
Epoch 60/100
380/380 [==============================] - 0s 171us/step - loss: 0.2934 - accuracy: 0.8842 - val_loss: 0.4483 - val_accuracy: 0.8344
Epoch 61/100
380/380 [==============================] - 0s 217us/step - loss: 0.2807 - accuracy: 0.9053 - val_loss: 0.4612 - val_accuracy: 0.8528
Epoch 62/100
380/380 [==============================] - 0s 186us/step - loss: 0.2700 - accuracy: 0.8921 - val_loss: 0.4488 - val_accuracy: 0.8528
Epoch 63/100
380/380 [==============================] - 0s 126us/step - loss: 0.2764 - accuracy: 0.8974 - val_loss: 0.4456 - val_accuracy: 0.8344
Epoch 64/100
380/380 [==============================] - 0s 96us/step - loss: 0.2654 - accuracy: 0.9053 - val_loss: 0.4487 - val_accuracy: 0.8528
Epoch 65/100
380/380 [==============================] - 0s 73us/step - loss: 0.2600 - accuracy: 0.9079 - val_loss: 0.4252 - val_accuracy: 0.8282
Epoch 66/100
380/380 [==============================] - 0s 67us/step - loss: 0.2605 - accuracy: 0.9079 - val_loss: 0.4389 - val_accuracy: 0.8282
Epoch 67/100
380/380 [==============================] - 0s 87us/step - loss: 0.2660 - accuracy: 0.9000 - val_loss: 0.4661 - val_accuracy: 0.8466
Epoch 68/100
380/380 [==============================] - 0s 74us/step - loss: 0.2634 - accuracy: 0.9184 - val_loss: 0.4419 - val_accuracy: 0.8712
Epoch 69/100
380/380 [==============================] - 0s 81us/step - loss: 0.2477 - accuracy: 0.9079 - val_loss: 0.4313 - val_accuracy: 0.8282
Epoch 70/100
380/380 [==============================] - 0s 82us/step - loss: 0.2551 - accuracy: 0.9105 - val_loss: 0.5203 - val_accuracy: 0.7975
Epoch 71/100
380/380 [==============================] - 0s 190us/step - loss: 0.2809 - accuracy: 0.8895 - val_loss: 0.4561 - val_accuracy: 0.8650
Epoch 72/100
380/380 [==============================] - 0s 218us/step - loss: 0.2767 - accuracy: 0.9000 - val_loss: 0.4659 - val_accuracy: 0.8037
Epoch 73/100
380/380 [==============================] - 0s 202us/step - loss: 0.2786 - accuracy: 0.9053 - val_loss: 0.4260 - val_accuracy: 0.8344
Epoch 74/100
380/380 [==============================] - 0s 211us/step - loss: 0.2415 - accuracy: 0.9184 - val_loss: 0.4475 - val_accuracy: 0.8650
Epoch 75/100
380/380 [==============================] - 0s 184us/step - loss: 0.2470 - accuracy: 0.9132 - val_loss: 0.4352 - val_accuracy: 0.8528
Epoch 76/100
380/380 [==============================] - 0s 188us/step - loss: 0.2409 - accuracy: 0.9158 - val_loss: 0.4400 - val_accuracy: 0.8712
Epoch 77/100
380/380 [==============================] - 0s 139us/step - loss: 0.2379 - accuracy: 0.9184 - val_loss: 0.4290 - val_accuracy: 0.8344
Epoch 78/100
380/380 [==============================] - 0s 178us/step - loss: 0.2419 - accuracy: 0.9105 - val_loss: 0.4384 - val_accuracy: 0.8344
Epoch 79/100
380/380 [==============================] - 0s 102us/step - loss: 0.2374 - accuracy: 0.9132 - val_loss: 0.4231 - val_accuracy: 0.8405
Epoch 80/100
380/380 [==============================] - 0s 74us/step - loss: 0.2403 - accuracy: 0.9184 - val_loss: 0.4198 - val_accuracy: 0.8466
Epoch 81/100
380/380 [==============================] - 0s 95us/step - loss: 0.2381 - accuracy: 0.9105 - val_loss: 0.4224 - val_accuracy: 0.8650
Epoch 82/100
380/380 [==============================] - 0s 68us/step - loss: 0.2350 - accuracy: 0.9211 - val_loss: 0.4378 - val_accuracy: 0.8650
Epoch 83/100
380/380 [==============================] - 0s 75us/step - loss: 0.2345 - accuracy: 0.9132 - val_loss: 0.4174 - val_accuracy: 0.8589
Epoch 84/100
380/380 [==============================] - 0s 80us/step - loss: 0.2286 - accuracy: 0.9132 - val_loss: 0.4145 - val_accuracy: 0.8405
Epoch 85/100
380/380 [==============================] - 0s 91us/step - loss: 0.2377 - accuracy: 0.9026 - val_loss: 0.4140 - val_accuracy: 0.8589
Epoch 86/100
380/380 [==============================] - 0s 140us/step - loss: 0.2298 - accuracy: 0.9237 - val_loss: 0.4223 - val_accuracy: 0.8712
Epoch 87/100
380/380 [==============================] - 0s 120us/step - loss: 0.2321 - accuracy: 0.9158 - val_loss: 0.4420 - val_accuracy: 0.8650
Epoch 88/100
380/380 [==============================] - 0s 101us/step - loss: 0.2300 - accuracy: 0.9132 - val_loss: 0.4303 - val_accuracy: 0.8650
Epoch 89/100
380/380 [==============================] - 0s 110us/step - loss: 0.2239 - accuracy: 0.9184 - val_loss: 0.4362 - val_accuracy: 0.8712
Epoch 90/100
380/380 [==============================] - 0s 79us/step - loss: 0.2211 - accuracy: 0.9132 - val_loss: 0.4194 - val_accuracy: 0.8589
Epoch 91/100
380/380 [==============================] - 0s 69us/step - loss: 0.2188 - accuracy: 0.9211 - val_loss: 0.4170 - val_accuracy: 0.8712
Epoch 92/100
380/380 [==============================] - 0s 82us/step - loss: 0.2170 - accuracy: 0.9289 - val_loss: 0.4033 - val_accuracy: 0.8466
Epoch 93/100
380/380 [==============================] - 0s 69us/step - loss: 0.2332 - accuracy: 0.9079 - val_loss: 0.4165 - val_accuracy: 0.8528
Epoch 94/100
380/380 [==============================] - 0s 114us/step - loss: 0.2234 - accuracy: 0.9079 - val_loss: 0.4846 - val_accuracy: 0.7975
Epoch 95/100
380/380 [==============================] - 0s 94us/step - loss: 0.2206 - accuracy: 0.9132 - val_loss: 0.4025 - val_accuracy: 0.8466
Epoch 96/100
380/380 [==============================] - 0s 120us/step - loss: 0.2147 - accuracy: 0.9211 - val_loss: 0.4103 - val_accuracy: 0.8712
Epoch 97/100
380/380 [==============================] - 0s 99us/step - loss: 0.2148 - accuracy: 0.9211 - val_loss: 0.4102 - val_accuracy: 0.8712
Epoch 98/100
380/380 [==============================] - 0s 99us/step - loss: 0.2172 - accuracy: 0.9079 - val_loss: 0.4366 - val_accuracy: 0.8712
Epoch 99/100
380/380 [==============================] - 0s 83us/step - loss: 0.2146 - accuracy: 0.9289 - val_loss: 0.4098 - val_accuracy: 0.8712
Epoch 100/100
380/380 [==============================] - 0s 76us/step - loss: 0.2113 - accuracy: 0.9263 - val_loss: 0.4353 - val_accuracy: 0.8650
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[111]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&lt;keras.callbacks.callbacks.History at 0x1a44715a20&gt;</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[263]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">acc_test2_over3</span> <span class="o">=</span> <span class="n">model2_over3</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_sel_test_over</span><span class="p">,</span> <span class="n">y_sel_test_over</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;over-sampling test accuracy: </span><span class="si">%.2f%%</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">acc_test2_over3</span><span class="o">*</span><span class="mi">100</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>163/163 [==============================] - 0s 83us/step
over-sampling test accuracy: 83.44%
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[112]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">pred7</span> <span class="o">=</span> <span class="n">model2_over3</span><span class="o">.</span><span class="n">predict_classes</span><span class="p">(</span><span class="n">X_sel_test_over</span><span class="p">)</span>
<span class="n">pred7</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[112]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>array([1, 0, 1, 1, 1, 0, 0, 0, 2, 1, 1, 1, 2, 2, 0, 2, 0, 1, 2, 1, 1, 1,
       0, 1, 0, 1, 0, 0, 2, 1, 2, 2, 0, 1, 2, 2, 1, 0, 1, 2, 0, 2, 1, 1,
       0, 1, 0, 1, 1, 0, 1, 1, 1, 2, 0, 1, 0, 1, 1, 0, 2, 0, 0, 0, 0, 0,
       1, 2, 1, 1, 1, 2, 1, 1, 0, 1, 1, 2, 0, 0, 1, 2, 2, 0, 2, 0, 2, 0,
       0, 0, 1, 1, 2, 2, 2, 2, 1, 0, 2, 0, 2, 2, 1, 2, 1, 2, 1, 1, 1, 2,
       0, 0, 0, 1, 2, 0, 0, 1, 0, 2, 2, 2, 0, 1, 1, 1, 1, 2, 0, 2, 1, 0,
       2, 1, 1, 0, 0, 0, 1, 1, 1, 2, 0, 1, 2, 2, 0, 1, 1, 2, 1, 1, 0, 1,
       0, 0, 0, 2, 2, 1, 0, 1, 0])</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[113]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dat7</span><span class="p">[</span><span class="s1">&#39;pred&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pred7</span>
<span class="n">dat7</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[113]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>test</th>
      <th>pred</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>CFBREBSa127</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>NRS145</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>CFBRSa66B</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>NRS204</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>BCH-SA-13</td>
      <td>2</td>
      <td>1</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>158</th>
      <td>NRS233</td>
      <td>2</td>
      <td>2</td>
    </tr>
    <tr>
      <th>159</th>
      <td>NRS204</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>160</th>
      <td>CFBRSa07</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>161</th>
      <td>CFBREBSa117</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>162</th>
      <td>CFBREBSa126</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>163 rows × 3 columns</p>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[114]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">proba7</span> <span class="o">=</span> <span class="n">model2_over3</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_sel_test_over</span><span class="p">)</span>
<span class="n">dat_proba7</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">proba7</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[115]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dat_proba7</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[115]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.041830</td>
      <td>0.945889</td>
      <td>0.012282</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.979797</td>
      <td>0.015503</td>
      <td>0.004700</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.203042</td>
      <td>0.520154</td>
      <td>0.276803</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.001634</td>
      <td>0.984215</td>
      <td>0.014151</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.314982</td>
      <td>0.621410</td>
      <td>0.063608</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>158</th>
      <td>0.000005</td>
      <td>0.000161</td>
      <td>0.999834</td>
    </tr>
    <tr>
      <th>159</th>
      <td>0.001634</td>
      <td>0.984215</td>
      <td>0.014151</td>
    </tr>
    <tr>
      <th>160</th>
      <td>0.954545</td>
      <td>0.000749</td>
      <td>0.044706</td>
    </tr>
    <tr>
      <th>161</th>
      <td>0.228832</td>
      <td>0.663252</td>
      <td>0.107916</td>
    </tr>
    <tr>
      <th>162</th>
      <td>0.992449</td>
      <td>0.003225</td>
      <td>0.004326</td>
    </tr>
  </tbody>
</table>
<p>163 rows × 3 columns</p>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[116]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dat_proba7</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s2">&quot;/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba7.csv&quot;</span><span class="p">,</span> <span class="n">index</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
         <span class="n">header</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[117]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dat7</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s2">&quot;/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/7p11.csv&quot;</span><span class="p">,</span> <span class="n">index</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
         <span class="n">header</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[267]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">hist2_over3</span> <span class="o">=</span> <span class="n">model2_over3</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_sel_train_over</span><span class="p">,</span> <span class="n">y_sel_train_over</span><span class="p">,</span>
          <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
          <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">X_sel_test_over</span><span class="p">,</span> <span class="n">y_sel_test_over</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Train on 380 samples, validate on 163 samples
Epoch 1/100
380/380 [==============================] - 0s 105us/step - loss: 0.2186 - accuracy: 0.9132 - val_loss: 0.4422 - val_accuracy: 0.8466
Epoch 2/100
380/380 [==============================] - 0s 121us/step - loss: 0.2107 - accuracy: 0.9263 - val_loss: 0.4208 - val_accuracy: 0.8466
Epoch 3/100
380/380 [==============================] - 0s 89us/step - loss: 0.2118 - accuracy: 0.9132 - val_loss: 0.4142 - val_accuracy: 0.8466
Epoch 4/100
380/380 [==============================] - 0s 87us/step - loss: 0.2111 - accuracy: 0.9237 - val_loss: 0.4230 - val_accuracy: 0.8466
Epoch 5/100
380/380 [==============================] - 0s 87us/step - loss: 0.2079 - accuracy: 0.9211 - val_loss: 0.4145 - val_accuracy: 0.8466
Epoch 6/100
380/380 [==============================] - 0s 83us/step - loss: 0.2124 - accuracy: 0.9237 - val_loss: 0.4484 - val_accuracy: 0.8466
Epoch 7/100
380/380 [==============================] - 0s 88us/step - loss: 0.2164 - accuracy: 0.9158 - val_loss: 0.4105 - val_accuracy: 0.8344
Epoch 8/100
380/380 [==============================] - 0s 80us/step - loss: 0.2244 - accuracy: 0.9132 - val_loss: 0.4484 - val_accuracy: 0.8466
Epoch 9/100
380/380 [==============================] - 0s 83us/step - loss: 0.2112 - accuracy: 0.9263 - val_loss: 0.4178 - val_accuracy: 0.8466
Epoch 10/100
380/380 [==============================] - 0s 105us/step - loss: 0.2067 - accuracy: 0.9263 - val_loss: 0.4308 - val_accuracy: 0.8466
Epoch 11/100
380/380 [==============================] - 0s 89us/step - loss: 0.2066 - accuracy: 0.9211 - val_loss: 0.4415 - val_accuracy: 0.8466
Epoch 12/100
380/380 [==============================] - 0s 88us/step - loss: 0.2067 - accuracy: 0.9184 - val_loss: 0.4654 - val_accuracy: 0.7975
Epoch 13/100
380/380 [==============================] - 0s 88us/step - loss: 0.2161 - accuracy: 0.9211 - val_loss: 0.4374 - val_accuracy: 0.8466
Epoch 14/100
380/380 [==============================] - 0s 89us/step - loss: 0.1988 - accuracy: 0.9211 - val_loss: 0.4024 - val_accuracy: 0.8344
Epoch 15/100
380/380 [==============================] - 0s 86us/step - loss: 0.2044 - accuracy: 0.9132 - val_loss: 0.4548 - val_accuracy: 0.8405
Epoch 16/100
380/380 [==============================] - 0s 86us/step - loss: 0.2031 - accuracy: 0.9053 - val_loss: 0.4138 - val_accuracy: 0.8405
Epoch 17/100
380/380 [==============================] - 0s 84us/step - loss: 0.2207 - accuracy: 0.9132 - val_loss: 0.4392 - val_accuracy: 0.8466
Epoch 18/100
380/380 [==============================] - 0s 85us/step - loss: 0.2086 - accuracy: 0.9079 - val_loss: 0.4638 - val_accuracy: 0.8466
Epoch 19/100
380/380 [==============================] - 0s 94us/step - loss: 0.2026 - accuracy: 0.9211 - val_loss: 0.4212 - val_accuracy: 0.8466
Epoch 20/100
380/380 [==============================] - 0s 92us/step - loss: 0.2056 - accuracy: 0.9158 - val_loss: 0.4366 - val_accuracy: 0.8405
Epoch 21/100
380/380 [==============================] - 0s 86us/step - loss: 0.2012 - accuracy: 0.9184 - val_loss: 0.4327 - val_accuracy: 0.8466
Epoch 22/100
380/380 [==============================] - 0s 87us/step - loss: 0.2026 - accuracy: 0.9184 - val_loss: 0.4494 - val_accuracy: 0.8466
Epoch 23/100
380/380 [==============================] - 0s 87us/step - loss: 0.2013 - accuracy: 0.9158 - val_loss: 0.4075 - val_accuracy: 0.8344
Epoch 24/100
380/380 [==============================] - 0s 103us/step - loss: 0.2251 - accuracy: 0.9132 - val_loss: 0.4509 - val_accuracy: 0.8466
Epoch 25/100
380/380 [==============================] - 0s 83us/step - loss: 0.2082 - accuracy: 0.9132 - val_loss: 0.4144 - val_accuracy: 0.8466
Epoch 26/100
380/380 [==============================] - 0s 86us/step - loss: 0.2070 - accuracy: 0.9237 - val_loss: 0.5097 - val_accuracy: 0.7791
Epoch 27/100
380/380 [==============================] - 0s 87us/step - loss: 0.2046 - accuracy: 0.9184 - val_loss: 0.4102 - val_accuracy: 0.8466
Epoch 28/100
380/380 [==============================] - 0s 89us/step - loss: 0.2009 - accuracy: 0.9184 - val_loss: 0.4639 - val_accuracy: 0.8405
Epoch 29/100
380/380 [==============================] - 0s 87us/step - loss: 0.1941 - accuracy: 0.9184 - val_loss: 0.4262 - val_accuracy: 0.8405
Epoch 30/100
380/380 [==============================] - 0s 100us/step - loss: 0.1923 - accuracy: 0.9263 - val_loss: 0.4142 - val_accuracy: 0.8466
Epoch 31/100
380/380 [==============================] - 0s 95us/step - loss: 0.1919 - accuracy: 0.9237 - val_loss: 0.4522 - val_accuracy: 0.8405
Epoch 32/100
380/380 [==============================] - 0s 105us/step - loss: 0.1937 - accuracy: 0.9237 - val_loss: 0.4169 - val_accuracy: 0.8466
Epoch 33/100
380/380 [==============================] - 0s 95us/step - loss: 0.1908 - accuracy: 0.9105 - val_loss: 0.4545 - val_accuracy: 0.8405
Epoch 34/100
380/380 [==============================] - 0s 82us/step - loss: 0.1940 - accuracy: 0.9263 - val_loss: 0.4268 - val_accuracy: 0.8466
Epoch 35/100
380/380 [==============================] - 0s 72us/step - loss: 0.1886 - accuracy: 0.9263 - val_loss: 0.4504 - val_accuracy: 0.8405
Epoch 36/100
380/380 [==============================] - 0s 98us/step - loss: 0.1909 - accuracy: 0.9263 - val_loss: 0.4434 - val_accuracy: 0.8405
Epoch 37/100
380/380 [==============================] - 0s 121us/step - loss: 0.1929 - accuracy: 0.9289 - val_loss: 0.4436 - val_accuracy: 0.8221
Epoch 38/100
380/380 [==============================] - 0s 101us/step - loss: 0.2447 - accuracy: 0.8947 - val_loss: 0.5150 - val_accuracy: 0.7914
Epoch 39/100
380/380 [==============================] - 0s 103us/step - loss: 0.1949 - accuracy: 0.9289 - val_loss: 0.4273 - val_accuracy: 0.8466
Epoch 40/100
380/380 [==============================] - 0s 82us/step - loss: 0.1913 - accuracy: 0.9263 - val_loss: 0.4509 - val_accuracy: 0.8405
Epoch 41/100
380/380 [==============================] - 0s 80us/step - loss: 0.1982 - accuracy: 0.9184 - val_loss: 0.4196 - val_accuracy: 0.8405
Epoch 42/100
380/380 [==============================] - 0s 93us/step - loss: 0.2063 - accuracy: 0.9184 - val_loss: 0.4596 - val_accuracy: 0.8098
Epoch 43/100
380/380 [==============================] - 0s 85us/step - loss: 0.2106 - accuracy: 0.9079 - val_loss: 0.4680 - val_accuracy: 0.8344
Epoch 44/100
380/380 [==============================] - 0s 91us/step - loss: 0.1933 - accuracy: 0.9289 - val_loss: 0.4229 - val_accuracy: 0.8466
Epoch 45/100
380/380 [==============================] - 0s 80us/step - loss: 0.1878 - accuracy: 0.9289 - val_loss: 0.4307 - val_accuracy: 0.8405
Epoch 46/100
380/380 [==============================] - 0s 75us/step - loss: 0.1879 - accuracy: 0.9184 - val_loss: 0.4762 - val_accuracy: 0.8405
Epoch 47/100
380/380 [==============================] - 0s 79us/step - loss: 0.1991 - accuracy: 0.9184 - val_loss: 0.4179 - val_accuracy: 0.8528
Epoch 48/100
380/380 [==============================] - 0s 78us/step - loss: 0.1829 - accuracy: 0.9289 - val_loss: 0.4544 - val_accuracy: 0.8405
Epoch 49/100
380/380 [==============================] - 0s 90us/step - loss: 0.1871 - accuracy: 0.9289 - val_loss: 0.4213 - val_accuracy: 0.8466
Epoch 50/100
380/380 [==============================] - 0s 155us/step - loss: 0.1868 - accuracy: 0.9289 - val_loss: 0.4502 - val_accuracy: 0.8466
Epoch 51/100
380/380 [==============================] - 0s 407us/step - loss: 0.1900 - accuracy: 0.9316 - val_loss: 0.4134 - val_accuracy: 0.8589
Epoch 52/100
380/380 [==============================] - 0s 148us/step - loss: 0.1971 - accuracy: 0.9079 - val_loss: 0.4307 - val_accuracy: 0.8528
Epoch 53/100
380/380 [==============================] - 0s 135us/step - loss: 0.1929 - accuracy: 0.9237 - val_loss: 0.4204 - val_accuracy: 0.8466
Epoch 54/100
380/380 [==============================] - 0s 123us/step - loss: 0.1868 - accuracy: 0.9263 - val_loss: 0.4488 - val_accuracy: 0.8405
Epoch 55/100
380/380 [==============================] - 0s 125us/step - loss: 0.1958 - accuracy: 0.9184 - val_loss: 0.4422 - val_accuracy: 0.8528
Epoch 56/100
380/380 [==============================] - 0s 132us/step - loss: 0.1932 - accuracy: 0.9237 - val_loss: 0.4476 - val_accuracy: 0.8405
Epoch 57/100
380/380 [==============================] - 0s 166us/step - loss: 0.1985 - accuracy: 0.9237 - val_loss: 0.4385 - val_accuracy: 0.8466
Epoch 58/100
380/380 [==============================] - 0s 581us/step - loss: 0.1978 - accuracy: 0.9105 - val_loss: 0.4165 - val_accuracy: 0.8466
Epoch 59/100
380/380 [==============================] - 0s 266us/step - loss: 0.1884 - accuracy: 0.9237 - val_loss: 0.4562 - val_accuracy: 0.8466
Epoch 60/100
380/380 [==============================] - 0s 160us/step - loss: 0.1915 - accuracy: 0.9263 - val_loss: 0.4264 - val_accuracy: 0.8405
Epoch 61/100
380/380 [==============================] - 0s 164us/step - loss: 0.1912 - accuracy: 0.9263 - val_loss: 0.4365 - val_accuracy: 0.8466
Epoch 62/100
380/380 [==============================] - 0s 154us/step - loss: 0.1898 - accuracy: 0.9237 - val_loss: 0.4594 - val_accuracy: 0.8405
Epoch 63/100
380/380 [==============================] - 0s 112us/step - loss: 0.1934 - accuracy: 0.9158 - val_loss: 0.4187 - val_accuracy: 0.8405
Epoch 64/100
380/380 [==============================] - 0s 89us/step - loss: 0.1996 - accuracy: 0.9132 - val_loss: 0.4664 - val_accuracy: 0.8466
Epoch 65/100
380/380 [==============================] - 0s 152us/step - loss: 0.2122 - accuracy: 0.9237 - val_loss: 0.5260 - val_accuracy: 0.8037
Epoch 66/100
380/380 [==============================] - 0s 150us/step - loss: 0.1830 - accuracy: 0.9211 - val_loss: 0.4280 - val_accuracy: 0.8528
Epoch 67/100
380/380 [==============================] - 0s 162us/step - loss: 0.1968 - accuracy: 0.9105 - val_loss: 0.4388 - val_accuracy: 0.8466
Epoch 68/100
380/380 [==============================] - 0s 108us/step - loss: 0.1902 - accuracy: 0.9237 - val_loss: 0.4810 - val_accuracy: 0.8160
Epoch 69/100
380/380 [==============================] - 0s 101us/step - loss: 0.1969 - accuracy: 0.9158 - val_loss: 0.4136 - val_accuracy: 0.8528
Epoch 70/100
380/380 [==============================] - 0s 158us/step - loss: 0.1979 - accuracy: 0.9105 - val_loss: 0.5447 - val_accuracy: 0.7791
Epoch 71/100
380/380 [==============================] - 0s 103us/step - loss: 0.2023 - accuracy: 0.9184 - val_loss: 0.4379 - val_accuracy: 0.8405
Epoch 72/100
380/380 [==============================] - 0s 108us/step - loss: 0.1935 - accuracy: 0.9184 - val_loss: 0.4045 - val_accuracy: 0.8528
Epoch 73/100
380/380 [==============================] - 0s 101us/step - loss: 0.1878 - accuracy: 0.9132 - val_loss: 0.4598 - val_accuracy: 0.8405
Epoch 74/100
380/380 [==============================] - 0s 100us/step - loss: 0.1882 - accuracy: 0.9289 - val_loss: 0.4215 - val_accuracy: 0.8466
Epoch 75/100
380/380 [==============================] - 0s 87us/step - loss: 0.1750 - accuracy: 0.9237 - val_loss: 0.4441 - val_accuracy: 0.8528
Epoch 76/100
380/380 [==============================] - 0s 89us/step - loss: 0.1875 - accuracy: 0.9211 - val_loss: 0.4336 - val_accuracy: 0.8466
Epoch 77/100
380/380 [==============================] - 0s 91us/step - loss: 0.1791 - accuracy: 0.9263 - val_loss: 0.4419 - val_accuracy: 0.8466
Epoch 78/100
380/380 [==============================] - 0s 89us/step - loss: 0.1871 - accuracy: 0.9158 - val_loss: 0.4632 - val_accuracy: 0.8405
Epoch 79/100
380/380 [==============================] - 0s 86us/step - loss: 0.1777 - accuracy: 0.9263 - val_loss: 0.4174 - val_accuracy: 0.8466
Epoch 80/100
380/380 [==============================] - 0s 399us/step - loss: 0.1886 - accuracy: 0.9184 - val_loss: 0.4895 - val_accuracy: 0.8037
Epoch 81/100
380/380 [==============================] - 0s 119us/step - loss: 0.1907 - accuracy: 0.9289 - val_loss: 0.4790 - val_accuracy: 0.8466
Epoch 82/100
380/380 [==============================] - 0s 125us/step - loss: 0.1743 - accuracy: 0.9289 - val_loss: 0.4211 - val_accuracy: 0.8528
Epoch 83/100
380/380 [==============================] - 0s 123us/step - loss: 0.1846 - accuracy: 0.9184 - val_loss: 0.4908 - val_accuracy: 0.8405
Epoch 84/100
380/380 [==============================] - 0s 112us/step - loss: 0.1842 - accuracy: 0.9184 - val_loss: 0.4297 - val_accuracy: 0.8405
Epoch 85/100
380/380 [==============================] - 0s 98us/step - loss: 0.1887 - accuracy: 0.9132 - val_loss: 0.4444 - val_accuracy: 0.8466
Epoch 86/100
380/380 [==============================] - 0s 104us/step - loss: 0.1812 - accuracy: 0.9289 - val_loss: 0.4370 - val_accuracy: 0.8466
Epoch 87/100
380/380 [==============================] - 0s 100us/step - loss: 0.1896 - accuracy: 0.9026 - val_loss: 0.4445 - val_accuracy: 0.8160
Epoch 88/100
380/380 [==============================] - 0s 98us/step - loss: 0.1775 - accuracy: 0.9211 - val_loss: 0.4451 - val_accuracy: 0.8466
Epoch 89/100
380/380 [==============================] - 0s 100us/step - loss: 0.1918 - accuracy: 0.9132 - val_loss: 0.4262 - val_accuracy: 0.8528
Epoch 90/100
380/380 [==============================] - 0s 98us/step - loss: 0.1961 - accuracy: 0.9158 - val_loss: 0.4490 - val_accuracy: 0.8466
Epoch 91/100
380/380 [==============================] - 0s 92us/step - loss: 0.1858 - accuracy: 0.9289 - val_loss: 0.4945 - val_accuracy: 0.8344
Epoch 92/100
380/380 [==============================] - 0s 92us/step - loss: 0.1800 - accuracy: 0.9237 - val_loss: 0.4425 - val_accuracy: 0.8466
Epoch 93/100
380/380 [==============================] - 0s 93us/step - loss: 0.1853 - accuracy: 0.9211 - val_loss: 0.4389 - val_accuracy: 0.8466
Epoch 94/100
380/380 [==============================] - 0s 104us/step - loss: 0.1946 - accuracy: 0.9132 - val_loss: 0.4622 - val_accuracy: 0.8160
Epoch 95/100
380/380 [==============================] - 0s 88us/step - loss: 0.1849 - accuracy: 0.9184 - val_loss: 0.4881 - val_accuracy: 0.8037
Epoch 96/100
380/380 [==============================] - 0s 92us/step - loss: 0.1742 - accuracy: 0.9263 - val_loss: 0.4096 - val_accuracy: 0.8528
Epoch 97/100
380/380 [==============================] - 0s 89us/step - loss: 0.1805 - accuracy: 0.9263 - val_loss: 0.4532 - val_accuracy: 0.8466
Epoch 98/100
380/380 [==============================] - 0s 88us/step - loss: 0.1755 - accuracy: 0.9263 - val_loss: 0.4498 - val_accuracy: 0.8160
Epoch 99/100
380/380 [==============================] - 0s 86us/step - loss: 0.1853 - accuracy: 0.9158 - val_loss: 0.4316 - val_accuracy: 0.8528
Epoch 100/100
380/380 [==============================] - 0s 84us/step - loss: 0.1740 - accuracy: 0.9316 - val_loss: 0.4568 - val_accuracy: 0.8466
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[268]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;over-sampling train accuracy: </span><span class="si">%.2f%%</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">hist2_over3</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span><span class="o">*</span><span class="mi">100</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>over-sampling train accuracy: 92.02%
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[52]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df_proba7</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_excel</span><span class="p">(</span><span class="s2">&quot;/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_lasso_2.xlsx&quot;</span><span class="p">,</span>
                        <span class="n">sheet_name</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                        <span class="n">index_col</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[53]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df_proba7</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[53]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>phage</th>
      <th>strain</th>
      <th>phenotype</th>
      <th>prediction</th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>p0006kpresabs_qual</td>
      <td>NRS210</td>
      <td>0</td>
      <td>0</td>
      <td>6.132076e-01</td>
      <td>2.812180e-01</td>
      <td>1.055744e-01</td>
    </tr>
    <tr>
      <th>1</th>
      <td>p0006kpresabs_qual</td>
      <td>NRS205</td>
      <td>2</td>
      <td>2</td>
      <td>1.993202e-04</td>
      <td>6.834937e-07</td>
      <td>9.998000e-01</td>
    </tr>
    <tr>
      <th>2</th>
      <td>p0006kpresabs_qual</td>
      <td>312</td>
      <td>2</td>
      <td>1</td>
      <td>3.589463e-01</td>
      <td>3.982787e-01</td>
      <td>2.427750e-01</td>
    </tr>
    <tr>
      <th>3</th>
      <td>p0006kpresabs_qual</td>
      <td>GA15</td>
      <td>2</td>
      <td>1</td>
      <td>3.589463e-01</td>
      <td>3.982787e-01</td>
      <td>2.427750e-01</td>
    </tr>
    <tr>
      <th>4</th>
      <td>p0006kpresabs_qual</td>
      <td>SR4035</td>
      <td>0</td>
      <td>1</td>
      <td>3.589463e-01</td>
      <td>3.982787e-01</td>
      <td>2.427750e-01</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>984</th>
      <td>p0017Skpresabs_qual</td>
      <td>NRS383</td>
      <td>1</td>
      <td>0</td>
      <td>5.477194e-01</td>
      <td>4.522807e-01</td>
      <td>1.761374e-08</td>
    </tr>
    <tr>
      <th>985</th>
      <td>p0017Skpresabs_qual</td>
      <td>NRS218</td>
      <td>1</td>
      <td>1</td>
      <td>6.953657e-05</td>
      <td>9.999305e-01</td>
      <td>3.132419e-10</td>
    </tr>
    <tr>
      <th>986</th>
      <td>p0017Skpresabs_qual</td>
      <td>NRS209</td>
      <td>2</td>
      <td>2</td>
      <td>2.713214e-09</td>
      <td>6.656316e-09</td>
      <td>1.000000e+00</td>
    </tr>
    <tr>
      <th>987</th>
      <td>p0017Skpresabs_qual</td>
      <td>SR2852</td>
      <td>1</td>
      <td>1</td>
      <td>9.956684e-12</td>
      <td>1.000000e+00</td>
      <td>7.441288e-26</td>
    </tr>
    <tr>
      <th>988</th>
      <td>p0017Skpresabs_qual</td>
      <td>NRS248</td>
      <td>0</td>
      <td>0</td>
      <td>9.999998e-01</td>
      <td>1.958189e-07</td>
      <td>1.001001e-12</td>
    </tr>
  </tbody>
</table>
<p>989 rows × 7 columns</p>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[54]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">y_prob7</span> <span class="o">=</span> <span class="n">df_proba7</span><span class="p">[</span><span class="n">df_proba7</span><span class="p">[</span><span class="s1">&#39;phage&#39;</span><span class="p">]</span><span class="o">==</span><span class="s1">&#39;p11kpresabs_qual&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="o">-</span><span class="mi">3</span><span class="p">:]</span>
<span class="n">y_prob7</span> <span class="o">=</span> <span class="n">y_prob7</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
<span class="n">y_prob7</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[54]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>array([[4.18298060e-02, 9.45888700e-01, 1.22816170e-02],
       [9.79796950e-01, 1.55026970e-02, 4.70028770e-03],
       [2.03042490e-01, 5.20154400e-01, 2.76803140e-01],
       [1.63378920e-03, 9.84215440e-01, 1.41508020e-02],
       [3.14981760e-01, 6.21409800e-01, 6.36084750e-02],
       [9.92449300e-01, 3.22524180e-03, 4.32556080e-03],
       [9.92570600e-01, 2.82636380e-03, 4.60304550e-03],
       [9.98242000e-01, 1.65318630e-03, 1.04834170e-04],
       [3.31534670e-02, 4.17398780e-01, 5.49447800e-01],
       [2.28831710e-01, 6.63252230e-01, 1.07916080e-01],
       [4.34379730e-02, 9.50388600e-01, 6.17349800e-03],
       [4.18298060e-02, 9.45888700e-01, 1.22816170e-02],
       [2.45814490e-01, 1.75794840e-01, 5.78390700e-01],
       [2.69555630e-04, 2.42486040e-03, 9.97305630e-01],
       [6.24578830e-01, 2.10758240e-01, 1.64662930e-01],
       [1.10714085e-01, 4.16145800e-01, 4.73140120e-01],
       [9.51160700e-01, 4.37449600e-02, 5.09426560e-03],
       [4.51731350e-04, 9.97174600e-01, 2.37367330e-03],
       [6.13205830e-04, 2.23257200e-02, 9.77061100e-01],
       [3.14981760e-01, 6.21409800e-01, 6.36084750e-02],
       [1.73404190e-04, 9.95373100e-01, 4.45358550e-03],
       [7.17145200e-03, 9.80000800e-01, 1.28277550e-02],
       [9.47204530e-01, 2.46690850e-02, 2.81263140e-02],
       [3.14981760e-01, 6.21409800e-01, 6.36084750e-02],
       [9.65961100e-01, 3.32089850e-02, 8.29858400e-04],
       [3.14981760e-01, 6.21409800e-01, 6.36084750e-02],
       [9.91672800e-01, 4.70391360e-04, 7.85676800e-03],
       [9.91672800e-01, 4.70391360e-04, 7.85676800e-03],
       [1.24735970e-03, 4.34944670e-02, 9.55258130e-01],
       [4.34379730e-02, 9.50388600e-01, 6.17349800e-03],
       [1.10714085e-01, 4.16145800e-01, 4.73140120e-01],
       [7.64969900e-02, 3.75772950e-01, 5.47730000e-01],
       [9.40801560e-01, 5.66193100e-02, 2.57916200e-03],
       [1.50592400e-03, 9.87696350e-01, 1.07976830e-02],
       [5.43923200e-03, 2.93111350e-01, 7.01449400e-01],
       [8.57441700e-02, 2.16114210e-01, 6.98141600e-01],
       [3.14981760e-01, 6.21409800e-01, 6.36084750e-02],
       [9.87223500e-01, 6.86818180e-03, 5.90836440e-03],
       [3.14981760e-01, 6.21409800e-01, 6.36084750e-02],
       [6.48761700e-03, 5.40465530e-02, 9.39465800e-01],
       [7.16839130e-01, 6.76758400e-02, 2.15485070e-01],
       [1.85715690e-01, 7.67747400e-03, 8.06606800e-01],
       [2.28831710e-01, 6.63252230e-01, 1.07916080e-01],
       [8.51495400e-02, 8.81100240e-01, 3.37502730e-02],
       [6.24578830e-01, 2.10758240e-01, 1.64662930e-01],
       [2.24970460e-04, 9.97655150e-01, 2.11984400e-03],
       [9.99101300e-01, 4.83895960e-05, 8.50356800e-04],
       [4.51731350e-04, 9.97174600e-01, 2.37367330e-03],
       [2.03042490e-01, 5.20154400e-01, 2.76803140e-01],
       [6.71168500e-01, 2.23473150e-01, 1.05358380e-01],
       [1.81610650e-06, 9.94926200e-01, 5.07203770e-03],
       [4.95792540e-04, 9.96628340e-01, 2.87585680e-03],
       [2.28831710e-01, 6.63252230e-01, 1.07916080e-01],
       [7.67852650e-03, 2.07547920e-02, 9.71566740e-01],
       [9.70080500e-01, 2.26202550e-02, 7.29925000e-03],
       [2.93625830e-01, 6.33110000e-01, 7.32642000e-02],
       [9.98663900e-01, 4.73220750e-04, 8.62916300e-04],
       [2.09738670e-02, 5.05334300e-01, 4.73691760e-01],
       [2.46415850e-04, 9.98230300e-01, 1.52334850e-03],
       [9.98242000e-01, 1.65318630e-03, 1.04834170e-04],
       [1.10914030e-01, 1.86908110e-02, 8.70395100e-01],
       [9.91672800e-01, 4.70391360e-04, 7.85676800e-03],
       [9.92570600e-01, 2.82636380e-03, 4.60304550e-03],
       [9.92570600e-01, 2.82636380e-03, 4.60304550e-03],
       [9.98663900e-01, 4.73220750e-04, 8.62916300e-04],
       [9.49820500e-01, 6.15272400e-04, 4.95641230e-02],
       [4.18298060e-02, 9.45888700e-01, 1.22816170e-02],
       [9.07171700e-02, 4.29278000e-01, 4.80004850e-01],
       [3.14981760e-01, 6.21409800e-01, 6.36084750e-02],
       [3.14981760e-01, 6.21409800e-01, 6.36084750e-02],
       [8.51495400e-02, 8.81100240e-01, 3.37502730e-02],
       [1.01369770e-03, 1.71088430e-01, 8.27897850e-01],
       [2.03042490e-01, 5.20154400e-01, 2.76803140e-01],
       [2.28831710e-01, 6.63252230e-01, 1.07916080e-01],
       [9.54544960e-01, 7.48857600e-04, 4.47062180e-02],
       [4.95792540e-04, 9.96628340e-01, 2.87585680e-03],
       [2.77233160e-04, 9.89148560e-01, 1.05742410e-02],
       [2.82902350e-05, 2.99318050e-01, 7.00653700e-01],
       [8.75756140e-01, 1.67647000e-02, 1.07479155e-01],
       [9.98663900e-01, 4.73220750e-04, 8.62916300e-04],
       [2.28831710e-01, 6.63252230e-01, 1.07916080e-01],
       [2.45851260e-03, 3.81549660e-01, 6.15991900e-01],
       [1.10714085e-01, 4.16145800e-01, 4.73140120e-01],
       [6.95662860e-01, 1.39371060e-03, 3.02943470e-01],
       [1.10714085e-01, 4.16145800e-01, 4.73140120e-01],
       [9.49820500e-01, 6.15272400e-04, 4.95641230e-02],
       [3.48689380e-03, 3.21058740e-02, 9.64407270e-01],
       [9.70080500e-01, 2.26202550e-02, 7.29925000e-03],
       [9.99101300e-01, 4.83895960e-05, 8.50356800e-04],
       [9.51160700e-01, 4.37449600e-02, 5.09426560e-03],
       [1.63378920e-03, 9.84215440e-01, 1.41508020e-02],
       [9.83759600e-03, 7.52131940e-01, 2.38030450e-01],
       [1.10714085e-01, 4.16145800e-01, 4.73140120e-01],
       [1.99312580e-01, 3.14455840e-01, 4.86231630e-01],
       [2.41851280e-05, 3.44177100e-02, 9.65558200e-01],
       [1.10714085e-01, 4.16145800e-01, 4.73140120e-01],
       [3.14981760e-01, 6.21409800e-01, 6.36084750e-02],
       [9.70891100e-01, 1.31841110e-02, 1.59247900e-02],
       [1.96454860e-03, 1.49007470e-02, 9.83134750e-01],
       [9.78085300e-01, 4.90652160e-03, 1.70082000e-02],
       [4.80820950e-01, 4.40087460e-04, 5.18739000e-01],
       [1.34901390e-03, 1.01598460e-01, 8.97052500e-01],
       [2.54877790e-02, 8.86657300e-01, 8.78549500e-02],
       [2.45851260e-03, 3.81549660e-01, 6.15991900e-01],
       [2.03042490e-01, 5.20154400e-01, 2.76803140e-01],
       [1.10714085e-01, 4.16145800e-01, 4.73140120e-01],
       [7.42726000e-04, 9.97354870e-01, 1.90241790e-03],
       [1.97799220e-03, 9.89136340e-01, 8.88571700e-03],
       [1.97799220e-03, 9.89136340e-01, 8.88571700e-03],
       [2.74961530e-02, 3.15847400e-04, 9.72188060e-01],
       [9.98242000e-01, 1.65318630e-03, 1.04834170e-04],
       [8.75756140e-01, 1.67647000e-02, 1.07479155e-01],
       [9.70891100e-01, 1.31841110e-02, 1.59247900e-02],
       [1.16222920e-03, 9.18101000e-01, 8.07367800e-02],
       [1.10714085e-01, 4.16145800e-01, 4.73140120e-01],
       [9.98242000e-01, 1.65318630e-03, 1.04834170e-04],
       [9.92570600e-01, 2.82636380e-03, 4.60304550e-03],
       [8.23438400e-05, 9.73153770e-01, 2.67638280e-02],
       [9.70891100e-01, 1.31841110e-02, 1.59247900e-02],
       [6.80525100e-03, 1.49874660e-02, 9.78207300e-01],
       [9.11497200e-05, 7.79885100e-03, 9.92110100e-01],
       [1.10714085e-01, 4.16145800e-01, 4.73140120e-01],
       [9.78085300e-01, 4.90652160e-03, 1.70082000e-02],
       [1.24693390e-03, 9.96994140e-01, 1.75889470e-03],
       [2.28831710e-01, 6.63252230e-01, 1.07916080e-01],
       [8.51495400e-02, 8.81100240e-01, 3.37502730e-02],
       [6.84452650e-02, 7.01274340e-01, 2.30280340e-01],
       [7.82104150e-04, 1.04672170e-02, 9.88750640e-01],
       [9.98054740e-01, 1.25930140e-03, 6.85977400e-04],
       [1.26216140e-01, 1.46282170e-01, 7.27501700e-01],
       [4.51731350e-04, 9.97174600e-01, 2.37367330e-03],
       [9.47204530e-01, 2.46690850e-02, 2.81263140e-02],
       [1.24735970e-03, 4.34944670e-02, 9.55258130e-01],
       [1.81610650e-06, 9.94926200e-01, 5.07203770e-03],
       [1.15282170e-01, 7.26788400e-01, 1.57929470e-01],
       [9.49820500e-01, 6.15272400e-04, 4.95641230e-02],
       [9.79796950e-01, 1.55026970e-02, 4.70028770e-03],
       [6.24578830e-01, 2.10758240e-01, 1.64662930e-01],
       [4.63442970e-03, 9.90846100e-01, 4.51947050e-03],
       [4.12921450e-04, 9.56318200e-01, 4.32689300e-02],
       [8.51495400e-02, 8.81100240e-01, 3.37502730e-02],
       [1.10714085e-01, 4.16145800e-01, 4.73140120e-01],
       [6.95662860e-01, 1.39371060e-03, 3.02943470e-01],
       [1.72317430e-01, 7.34835270e-01, 9.28473100e-02],
       [1.10714085e-01, 4.16145800e-01, 4.73140120e-01],
       [3.02182660e-02, 3.69339800e-05, 9.69744860e-01],
       [9.87223500e-01, 6.86818180e-03, 5.90836440e-03],
       [1.24693390e-03, 9.96994140e-01, 1.75889470e-03],
       [3.14981760e-01, 6.21409800e-01, 6.36084750e-02],
       [1.10714085e-01, 4.16145800e-01, 4.73140120e-01],
       [4.34379730e-02, 9.50388600e-01, 6.17349800e-03],
       [1.24693390e-03, 9.96994140e-01, 1.75889470e-03],
       [9.79796950e-01, 1.55026970e-02, 4.70028770e-03],
       [1.73404190e-04, 9.95373100e-01, 4.45358550e-03],
       [3.97190750e-01, 2.83378800e-01, 3.19430470e-01],
       [9.49820500e-01, 6.15272400e-04, 4.95641230e-02],
       [9.78085300e-01, 4.90652160e-03, 1.70082000e-02],
       [8.63702100e-04, 2.52137560e-02, 9.73922550e-01],
       [5.01888370e-06, 1.60845940e-04, 9.99834060e-01],
       [1.63378920e-03, 9.84215440e-01, 1.41508020e-02],
       [9.54544960e-01, 7.48857600e-04, 4.47062180e-02],
       [2.28831710e-01, 6.63252230e-01, 1.07916080e-01],
       [9.92449300e-01, 3.22524180e-03, 4.32556080e-03]])</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[55]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">ovo7</span> <span class="o">=</span> <span class="n">rocauc_ovo</span><span class="p">(</span><span class="n">y_sel_test_over</span><span class="p">,</span> <span class="n">y_prob7</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s2">&quot;macro&quot;</span><span class="p">,</span> <span class="n">multi_class</span><span class="o">=</span><span class="s2">&quot;ovo&quot;</span><span class="p">)</span>
<span class="n">ovo7</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[55]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>0.9639063931877389</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[56]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">ovr7</span> <span class="o">=</span> <span class="n">rocauc_ovr</span><span class="p">(</span><span class="n">y_sel_test_over</span><span class="p">,</span> <span class="n">y_prob7</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s2">&quot;macro&quot;</span><span class="p">,</span> <span class="n">multi_class</span><span class="o">=</span><span class="s2">&quot;ovr&quot;</span><span class="p">)</span>
<span class="n">ovr7</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[56]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>0.9639063931877389</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[57]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># split into train, test data (over)</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="n">X_sel_train_over</span><span class="p">,</span> <span class="n">X_sel_test_over</span><span class="p">,</span> <span class="n">y_sel_train_over</span><span class="p">,</span> <span class="n">y_sel_test_over</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X_sel_over</span><span class="p">,</span> <span class="n">y_sel_over</span><span class="p">,</span>
                                                    <span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.3</span><span class="p">,</span>
                                                    <span class="n">random_state</span><span class="o">=</span><span class="mi">890</span><span class="p">,</span>
                                                    <span class="n">stratify</span><span class="o">=</span><span class="n">y_sel_over</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[58]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dat8</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X_sel_test_over</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
<span class="n">dat8</span><span class="p">[</span><span class="s1">&#39;test&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">y_sel_test_over</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[59]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dat8</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[59]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>test</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>SR2852</td>
      <td>2</td>
    </tr>
    <tr>
      <th>1</th>
      <td>NRS054</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>NRS157</td>
      <td>2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>NY224</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>NRS070</td>
      <td>1</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>158</th>
      <td>NY417</td>
      <td>2</td>
    </tr>
    <tr>
      <th>159</th>
      <td>NRS051</td>
      <td>1</td>
    </tr>
    <tr>
      <th>160</th>
      <td>NRS226</td>
      <td>1</td>
    </tr>
    <tr>
      <th>161</th>
      <td>EUH13</td>
      <td>0</td>
    </tr>
    <tr>
      <th>162</th>
      <td>NRS110</td>
      <td>2</td>
    </tr>
  </tbody>
</table>
<p>163 rows × 2 columns</p>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[60]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">X_sel_train_over</span> <span class="o">=</span> <span class="n">X_sel_train_over</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">X_sel_test_over</span> <span class="o">=</span> <span class="n">X_sel_test_over</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[100]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model2_over4</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">([</span>
    <span class="n">Dense</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="n">X_sel_train_over</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],)),</span>
    <span class="n">Dense</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">),</span>
<span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[123]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model2_over4</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span>
              <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;sparse_categorical_crossentropy&#39;</span><span class="p">,</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[124]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model2_over4</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_sel_train_over</span><span class="p">,</span> <span class="n">y_sel_train_over</span><span class="p">,</span>
          <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
          <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">X_sel_test_over</span><span class="p">,</span> <span class="n">y_sel_test_over</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Train on 380 samples, validate on 163 samples
Epoch 1/100
380/380 [==============================] - 0s 394us/step - loss: 1.1455 - accuracy: 0.3579 - val_loss: 1.1096 - val_accuracy: 0.3742
Epoch 2/100
380/380 [==============================] - 0s 158us/step - loss: 1.0360 - accuracy: 0.4737 - val_loss: 1.0614 - val_accuracy: 0.4356
Epoch 3/100
380/380 [==============================] - 0s 76us/step - loss: 0.9965 - accuracy: 0.5737 - val_loss: 1.0365 - val_accuracy: 0.4356
Epoch 4/100
380/380 [==============================] - 0s 128us/step - loss: 0.9747 - accuracy: 0.5737 - val_loss: 1.0264 - val_accuracy: 0.4479
Epoch 5/100
380/380 [==============================] - 0s 95us/step - loss: 0.9371 - accuracy: 0.5605 - val_loss: 0.9960 - val_accuracy: 0.5031
Epoch 6/100
380/380 [==============================] - 0s 111us/step - loss: 0.9115 - accuracy: 0.6237 - val_loss: 0.9766 - val_accuracy: 0.4785
Epoch 7/100
380/380 [==============================] - 0s 65us/step - loss: 0.8882 - accuracy: 0.5842 - val_loss: 0.9581 - val_accuracy: 0.4969
Epoch 8/100
380/380 [==============================] - 0s 92us/step - loss: 0.8562 - accuracy: 0.6263 - val_loss: 0.9405 - val_accuracy: 0.5153
Epoch 9/100
380/380 [==============================] - 0s 70us/step - loss: 0.8389 - accuracy: 0.6553 - val_loss: 0.9218 - val_accuracy: 0.5951
Epoch 10/100
380/380 [==============================] - 0s 142us/step - loss: 0.8130 - accuracy: 0.6553 - val_loss: 0.9109 - val_accuracy: 0.5276
Epoch 11/100
380/380 [==============================] - 0s 89us/step - loss: 0.7941 - accuracy: 0.6684 - val_loss: 0.8875 - val_accuracy: 0.6012
Epoch 12/100
380/380 [==============================] - 0s 140us/step - loss: 0.7688 - accuracy: 0.7211 - val_loss: 0.8744 - val_accuracy: 0.5951
Epoch 13/100
380/380 [==============================] - 0s 89us/step - loss: 0.7545 - accuracy: 0.7053 - val_loss: 0.8690 - val_accuracy: 0.5828
Epoch 14/100
380/380 [==============================] - 0s 116us/step - loss: 0.7268 - accuracy: 0.7342 - val_loss: 0.8474 - val_accuracy: 0.6564
Epoch 15/100
380/380 [==============================] - 0s 106us/step - loss: 0.7126 - accuracy: 0.7553 - val_loss: 0.8361 - val_accuracy: 0.6196
Epoch 16/100
380/380 [==============================] - 0s 105us/step - loss: 0.6919 - accuracy: 0.7684 - val_loss: 0.8183 - val_accuracy: 0.6626
Epoch 17/100
380/380 [==============================] - 0s 101us/step - loss: 0.6745 - accuracy: 0.7605 - val_loss: 0.8042 - val_accuracy: 0.6319
Epoch 18/100
380/380 [==============================] - 0s 71us/step - loss: 0.6625 - accuracy: 0.7737 - val_loss: 0.7981 - val_accuracy: 0.6564
Epoch 19/100
380/380 [==============================] - 0s 70us/step - loss: 0.6601 - accuracy: 0.7711 - val_loss: 0.7921 - val_accuracy: 0.6810
Epoch 20/100
380/380 [==============================] - 0s 93us/step - loss: 0.6295 - accuracy: 0.7921 - val_loss: 0.7803 - val_accuracy: 0.6810
Epoch 21/100
380/380 [==============================] - 0s 68us/step - loss: 0.6213 - accuracy: 0.8079 - val_loss: 0.7592 - val_accuracy: 0.6933
Epoch 22/100
380/380 [==============================] - 0s 110us/step - loss: 0.6013 - accuracy: 0.8105 - val_loss: 0.7447 - val_accuracy: 0.6748
Epoch 23/100
380/380 [==============================] - 0s 90us/step - loss: 0.5802 - accuracy: 0.8289 - val_loss: 0.7353 - val_accuracy: 0.7055
Epoch 24/100
380/380 [==============================] - 0s 55us/step - loss: 0.5696 - accuracy: 0.8184 - val_loss: 0.7231 - val_accuracy: 0.6748
Epoch 25/100
380/380 [==============================] - 0s 90us/step - loss: 0.5544 - accuracy: 0.8211 - val_loss: 0.7117 - val_accuracy: 0.6933
Epoch 26/100
380/380 [==============================] - 0s 175us/step - loss: 0.5459 - accuracy: 0.7974 - val_loss: 0.7031 - val_accuracy: 0.6871
Epoch 27/100
380/380 [==============================] - 0s 99us/step - loss: 0.5484 - accuracy: 0.8184 - val_loss: 0.6977 - val_accuracy: 0.7301
Epoch 28/100
380/380 [==============================] - 0s 97us/step - loss: 0.5241 - accuracy: 0.8316 - val_loss: 0.6934 - val_accuracy: 0.7117
Epoch 29/100
380/380 [==============================] - 0s 99us/step - loss: 0.5101 - accuracy: 0.8395 - val_loss: 0.6807 - val_accuracy: 0.7362
Epoch 30/100
380/380 [==============================] - 0s 124us/step - loss: 0.4968 - accuracy: 0.8474 - val_loss: 0.6682 - val_accuracy: 0.7239
Epoch 31/100
380/380 [==============================] - 0s 97us/step - loss: 0.4882 - accuracy: 0.8289 - val_loss: 0.6619 - val_accuracy: 0.7178
Epoch 32/100
380/380 [==============================] - 0s 112us/step - loss: 0.4770 - accuracy: 0.8342 - val_loss: 0.6557 - val_accuracy: 0.7301
Epoch 33/100
380/380 [==============================] - 0s 132us/step - loss: 0.4653 - accuracy: 0.8474 - val_loss: 0.6496 - val_accuracy: 0.7178
Epoch 34/100
380/380 [==============================] - 0s 209us/step - loss: 0.4566 - accuracy: 0.8421 - val_loss: 0.6402 - val_accuracy: 0.7485
Epoch 35/100
380/380 [==============================] - 0s 154us/step - loss: 0.4478 - accuracy: 0.8632 - val_loss: 0.6320 - val_accuracy: 0.7423
Epoch 36/100
380/380 [==============================] - 0s 143us/step - loss: 0.4432 - accuracy: 0.8632 - val_loss: 0.6283 - val_accuracy: 0.7423
Epoch 37/100
380/380 [==============================] - 0s 112us/step - loss: 0.4305 - accuracy: 0.8474 - val_loss: 0.6216 - val_accuracy: 0.7423
Epoch 38/100
380/380 [==============================] - 0s 91us/step - loss: 0.4224 - accuracy: 0.8763 - val_loss: 0.6167 - val_accuracy: 0.7362
Epoch 39/100
380/380 [==============================] - 0s 128us/step - loss: 0.4189 - accuracy: 0.8500 - val_loss: 0.6094 - val_accuracy: 0.7546
Epoch 40/100
380/380 [==============================] - 0s 94us/step - loss: 0.4211 - accuracy: 0.8658 - val_loss: 0.6078 - val_accuracy: 0.7423
Epoch 41/100
380/380 [==============================] - 0s 84us/step - loss: 0.4049 - accuracy: 0.8789 - val_loss: 0.6030 - val_accuracy: 0.7423
Epoch 42/100
380/380 [==============================] - 0s 75us/step - loss: 0.3930 - accuracy: 0.8816 - val_loss: 0.6055 - val_accuracy: 0.7607
Epoch 43/100
380/380 [==============================] - 0s 73us/step - loss: 0.3996 - accuracy: 0.8763 - val_loss: 0.6001 - val_accuracy: 0.7423
Epoch 44/100
380/380 [==============================] - 0s 81us/step - loss: 0.3862 - accuracy: 0.8763 - val_loss: 0.5865 - val_accuracy: 0.7546
Epoch 45/100
380/380 [==============================] - 0s 77us/step - loss: 0.3834 - accuracy: 0.8737 - val_loss: 0.5860 - val_accuracy: 0.7423
Epoch 46/100
380/380 [==============================] - 0s 118us/step - loss: 0.3742 - accuracy: 0.8816 - val_loss: 0.5777 - val_accuracy: 0.7607
Epoch 47/100
380/380 [==============================] - 0s 85us/step - loss: 0.3686 - accuracy: 0.8895 - val_loss: 0.5750 - val_accuracy: 0.7485
Epoch 48/100
380/380 [==============================] - 0s 147us/step - loss: 0.3623 - accuracy: 0.8895 - val_loss: 0.5703 - val_accuracy: 0.7546
Epoch 49/100
380/380 [==============================] - 0s 195us/step - loss: 0.3557 - accuracy: 0.8868 - val_loss: 0.5768 - val_accuracy: 0.7485
Epoch 50/100
380/380 [==============================] - 0s 139us/step - loss: 0.3525 - accuracy: 0.8895 - val_loss: 0.5612 - val_accuracy: 0.7669
Epoch 51/100
380/380 [==============================] - 0s 76us/step - loss: 0.3491 - accuracy: 0.8895 - val_loss: 0.5647 - val_accuracy: 0.7607
Epoch 52/100
380/380 [==============================] - 0s 178us/step - loss: 0.3416 - accuracy: 0.9000 - val_loss: 0.5530 - val_accuracy: 0.7546
Epoch 53/100
380/380 [==============================] - 0s 83us/step - loss: 0.3376 - accuracy: 0.8921 - val_loss: 0.5498 - val_accuracy: 0.7669
Epoch 54/100
380/380 [==============================] - 0s 77us/step - loss: 0.3358 - accuracy: 0.8947 - val_loss: 0.5586 - val_accuracy: 0.7607
Epoch 55/100
380/380 [==============================] - 0s 80us/step - loss: 0.3308 - accuracy: 0.8921 - val_loss: 0.5486 - val_accuracy: 0.7607
Epoch 56/100
380/380 [==============================] - 0s 109us/step - loss: 0.3321 - accuracy: 0.8921 - val_loss: 0.5507 - val_accuracy: 0.7607
Epoch 57/100
380/380 [==============================] - 0s 221us/step - loss: 0.3285 - accuracy: 0.8921 - val_loss: 0.5479 - val_accuracy: 0.7607
Epoch 58/100
380/380 [==============================] - 0s 270us/step - loss: 0.3305 - accuracy: 0.8816 - val_loss: 0.5413 - val_accuracy: 0.7730
Epoch 59/100
380/380 [==============================] - 0s 309us/step - loss: 0.3220 - accuracy: 0.8921 - val_loss: 0.5453 - val_accuracy: 0.7607
Epoch 60/100
380/380 [==============================] - 0s 112us/step - loss: 0.3136 - accuracy: 0.9105 - val_loss: 0.5353 - val_accuracy: 0.7607
Epoch 61/100
380/380 [==============================] - 0s 78us/step - loss: 0.3102 - accuracy: 0.8974 - val_loss: 0.5453 - val_accuracy: 0.7730
Epoch 62/100
380/380 [==============================] - 0s 64us/step - loss: 0.3090 - accuracy: 0.8947 - val_loss: 0.5368 - val_accuracy: 0.7730
Epoch 63/100
380/380 [==============================] - 0s 62us/step - loss: 0.2996 - accuracy: 0.9158 - val_loss: 0.5304 - val_accuracy: 0.7791
Epoch 64/100
380/380 [==============================] - 0s 94us/step - loss: 0.2984 - accuracy: 0.9132 - val_loss: 0.5255 - val_accuracy: 0.7730
Epoch 65/100
380/380 [==============================] - 0s 68us/step - loss: 0.3022 - accuracy: 0.9158 - val_loss: 0.5288 - val_accuracy: 0.7607
Epoch 66/100
380/380 [==============================] - 0s 103us/step - loss: 0.2964 - accuracy: 0.9000 - val_loss: 0.5190 - val_accuracy: 0.7853
Epoch 67/100
380/380 [==============================] - 0s 123us/step - loss: 0.2887 - accuracy: 0.9132 - val_loss: 0.5450 - val_accuracy: 0.7730
Epoch 68/100
380/380 [==============================] - 0s 314us/step - loss: 0.2945 - accuracy: 0.9105 - val_loss: 0.5200 - val_accuracy: 0.7914
Epoch 69/100
380/380 [==============================] - 0s 134us/step - loss: 0.2851 - accuracy: 0.9132 - val_loss: 0.5330 - val_accuracy: 0.7730
Epoch 70/100
380/380 [==============================] - 0s 207us/step - loss: 0.2887 - accuracy: 0.9105 - val_loss: 0.5217 - val_accuracy: 0.7791
Epoch 71/100
380/380 [==============================] - 0s 115us/step - loss: 0.2810 - accuracy: 0.9079 - val_loss: 0.5139 - val_accuracy: 0.7853
Epoch 72/100
380/380 [==============================] - 0s 103us/step - loss: 0.2866 - accuracy: 0.8895 - val_loss: 0.5333 - val_accuracy: 0.7853
Epoch 73/100
380/380 [==============================] - 0s 74us/step - loss: 0.2850 - accuracy: 0.8974 - val_loss: 0.5143 - val_accuracy: 0.7853
Epoch 74/100
380/380 [==============================] - 0s 86us/step - loss: 0.2768 - accuracy: 0.9053 - val_loss: 0.5105 - val_accuracy: 0.7975
Epoch 75/100
380/380 [==============================] - 0s 75us/step - loss: 0.2713 - accuracy: 0.9184 - val_loss: 0.5177 - val_accuracy: 0.7791
Epoch 76/100
380/380 [==============================] - 0s 136us/step - loss: 0.2661 - accuracy: 0.9158 - val_loss: 0.5047 - val_accuracy: 0.7914
Epoch 77/100
380/380 [==============================] - 0s 118us/step - loss: 0.2775 - accuracy: 0.8974 - val_loss: 0.5149 - val_accuracy: 0.7730
Epoch 78/100
380/380 [==============================] - 0s 143us/step - loss: 0.2722 - accuracy: 0.8947 - val_loss: 0.5118 - val_accuracy: 0.7730
Epoch 79/100
380/380 [==============================] - 0s 74us/step - loss: 0.2727 - accuracy: 0.9053 - val_loss: 0.5120 - val_accuracy: 0.7853
Epoch 80/100
380/380 [==============================] - 0s 113us/step - loss: 0.2627 - accuracy: 0.9158 - val_loss: 0.5024 - val_accuracy: 0.7853
Epoch 81/100
380/380 [==============================] - 0s 97us/step - loss: 0.2692 - accuracy: 0.9132 - val_loss: 0.5046 - val_accuracy: 0.7914
Epoch 82/100
380/380 [==============================] - 0s 95us/step - loss: 0.2625 - accuracy: 0.9158 - val_loss: 0.4995 - val_accuracy: 0.7914
Epoch 83/100
380/380 [==============================] - 0s 121us/step - loss: 0.2608 - accuracy: 0.9079 - val_loss: 0.5202 - val_accuracy: 0.7853
Epoch 84/100
380/380 [==============================] - 0s 84us/step - loss: 0.2525 - accuracy: 0.9184 - val_loss: 0.5137 - val_accuracy: 0.7914
Epoch 85/100
380/380 [==============================] - 0s 135us/step - loss: 0.2591 - accuracy: 0.9132 - val_loss: 0.5092 - val_accuracy: 0.7853
Epoch 86/100
380/380 [==============================] - 0s 95us/step - loss: 0.2487 - accuracy: 0.9211 - val_loss: 0.4957 - val_accuracy: 0.7914
Epoch 87/100
380/380 [==============================] - 0s 121us/step - loss: 0.2522 - accuracy: 0.9105 - val_loss: 0.5201 - val_accuracy: 0.7730
Epoch 88/100
380/380 [==============================] - 0s 84us/step - loss: 0.2589 - accuracy: 0.9184 - val_loss: 0.4906 - val_accuracy: 0.7975
Epoch 89/100
380/380 [==============================] - 0s 111us/step - loss: 0.2474 - accuracy: 0.9184 - val_loss: 0.4935 - val_accuracy: 0.7975
Epoch 90/100
380/380 [==============================] - 0s 86us/step - loss: 0.2549 - accuracy: 0.9211 - val_loss: 0.5191 - val_accuracy: 0.7730
Epoch 91/100
380/380 [==============================] - 0s 113us/step - loss: 0.2583 - accuracy: 0.9158 - val_loss: 0.4937 - val_accuracy: 0.7975
Epoch 92/100
380/380 [==============================] - 0s 58us/step - loss: 0.2407 - accuracy: 0.9158 - val_loss: 0.4970 - val_accuracy: 0.7791
Epoch 93/100
380/380 [==============================] - 0s 54us/step - loss: 0.2382 - accuracy: 0.9237 - val_loss: 0.4913 - val_accuracy: 0.7975
Epoch 94/100
380/380 [==============================] - 0s 74us/step - loss: 0.2378 - accuracy: 0.9211 - val_loss: 0.4875 - val_accuracy: 0.8037
Epoch 95/100
380/380 [==============================] - 0s 47us/step - loss: 0.2402 - accuracy: 0.9237 - val_loss: 0.4977 - val_accuracy: 0.7853
Epoch 96/100
380/380 [==============================] - 0s 48us/step - loss: 0.2363 - accuracy: 0.9132 - val_loss: 0.4904 - val_accuracy: 0.8037
Epoch 97/100
380/380 [==============================] - 0s 64us/step - loss: 0.2376 - accuracy: 0.9184 - val_loss: 0.4950 - val_accuracy: 0.7853
Epoch 98/100
380/380 [==============================] - 0s 49us/step - loss: 0.2324 - accuracy: 0.9184 - val_loss: 0.4918 - val_accuracy: 0.7975
Epoch 99/100
380/380 [==============================] - 0s 46us/step - loss: 0.2338 - accuracy: 0.9158 - val_loss: 0.5067 - val_accuracy: 0.7853
Epoch 100/100
380/380 [==============================] - 0s 47us/step - loss: 0.2326 - accuracy: 0.9237 - val_loss: 0.4919 - val_accuracy: 0.7914
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[124]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&lt;keras.callbacks.callbacks.History at 0x1a44c0f550&gt;</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[296]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">acc_test2_over4</span> <span class="o">=</span> <span class="n">model2_over4</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_sel_test_over</span><span class="p">,</span> <span class="n">y_sel_test_over</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;over-sampling test accuracy: </span><span class="si">%.2f%%</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">acc_test2_over4</span><span class="o">*</span><span class="mi">100</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>163/163 [==============================] - 0s 99us/step
over-sampling test accuracy: 80.37%
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[125]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">pred8</span> <span class="o">=</span> <span class="n">model2_over4</span><span class="o">.</span><span class="n">predict_classes</span><span class="p">(</span><span class="n">X_sel_test_over</span><span class="p">)</span>
<span class="n">pred8</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[125]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>array([2, 1, 2, 2, 1, 1, 2, 2, 1, 0, 2, 2, 2, 1, 1, 0, 0, 1, 1, 1, 0, 1,
       2, 2, 0, 2, 2, 2, 2, 1, 0, 1, 2, 2, 1, 1, 0, 2, 1, 0, 2, 1, 1, 0,
       0, 2, 0, 0, 1, 2, 1, 0, 0, 1, 1, 1, 1, 1, 2, 1, 0, 2, 1, 0, 0, 0,
       0, 1, 1, 0, 2, 0, 1, 1, 1, 1, 1, 2, 1, 0, 0, 1, 2, 2, 2, 1, 2, 2,
       0, 2, 0, 0, 0, 2, 2, 1, 1, 0, 1, 1, 1, 2, 0, 2, 1, 2, 2, 0, 0, 2,
       1, 1, 1, 0, 0, 2, 1, 1, 1, 2, 1, 2, 2, 0, 2, 2, 0, 0, 1, 1, 2, 0,
       0, 1, 1, 1, 1, 1, 2, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 2, 0, 0,
       2, 2, 2, 2, 2, 1, 1, 0, 1])</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[126]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dat8</span><span class="p">[</span><span class="s1">&#39;pred&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pred8</span>
<span class="n">dat8</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[126]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>test</th>
      <th>pred</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>SR2852</td>
      <td>2</td>
      <td>2</td>
    </tr>
    <tr>
      <th>1</th>
      <td>NRS054</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>NRS157</td>
      <td>2</td>
      <td>2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>NY224</td>
      <td>1</td>
      <td>2</td>
    </tr>
    <tr>
      <th>4</th>
      <td>NRS070</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>158</th>
      <td>NY417</td>
      <td>2</td>
      <td>2</td>
    </tr>
    <tr>
      <th>159</th>
      <td>NRS051</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>160</th>
      <td>NRS226</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>161</th>
      <td>EUH13</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>162</th>
      <td>NRS110</td>
      <td>2</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
<p>163 rows × 3 columns</p>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[127]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">proba8</span> <span class="o">=</span> <span class="n">model2_over4</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_sel_test_over</span><span class="p">)</span>
<span class="n">dat_proba8</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">proba8</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[128]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dat_proba8</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[128]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.002746</td>
      <td>0.288469</td>
      <td>0.708786</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.004718</td>
      <td>0.975754</td>
      <td>0.019529</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.000192</td>
      <td>0.007352</td>
      <td>0.992455</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.058554</td>
      <td>0.185173</td>
      <td>0.756274</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.000289</td>
      <td>0.963804</td>
      <td>0.035907</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>158</th>
      <td>0.058554</td>
      <td>0.185173</td>
      <td>0.756274</td>
    </tr>
    <tr>
      <th>159</th>
      <td>0.007984</td>
      <td>0.972268</td>
      <td>0.019748</td>
    </tr>
    <tr>
      <th>160</th>
      <td>0.003023</td>
      <td>0.756889</td>
      <td>0.240087</td>
    </tr>
    <tr>
      <th>161</th>
      <td>0.989564</td>
      <td>0.002574</td>
      <td>0.007862</td>
    </tr>
    <tr>
      <th>162</th>
      <td>0.070066</td>
      <td>0.664020</td>
      <td>0.265914</td>
    </tr>
  </tbody>
</table>
<p>163 rows × 3 columns</p>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[129]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dat_proba8</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s2">&quot;/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba8.csv&quot;</span><span class="p">,</span> <span class="n">index</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
         <span class="n">header</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[130]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dat8</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s2">&quot;/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/8p11.csv&quot;</span><span class="p">,</span> <span class="n">index</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
         <span class="n">header</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[300]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">hist2_over4</span> <span class="o">=</span> <span class="n">model2_over4</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_sel_train_over</span><span class="p">,</span> <span class="n">y_sel_train_over</span><span class="p">,</span>
          <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
          <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">X_sel_test_over</span><span class="p">,</span> <span class="n">y_sel_test_over</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Train on 380 samples, validate on 163 samples
Epoch 1/100
380/380 [==============================] - 0s 146us/step - loss: 0.2564 - accuracy: 0.9053 - val_loss: 0.5488 - val_accuracy: 0.8037
Epoch 2/100
380/380 [==============================] - 0s 145us/step - loss: 0.2737 - accuracy: 0.8711 - val_loss: 0.6301 - val_accuracy: 0.7485
Epoch 3/100
380/380 [==============================] - 0s 127us/step - loss: 0.2742 - accuracy: 0.8895 - val_loss: 0.5938 - val_accuracy: 0.7914
Epoch 4/100
380/380 [==============================] - 0s 130us/step - loss: 0.2369 - accuracy: 0.9132 - val_loss: 0.5442 - val_accuracy: 0.7853
Epoch 5/100
380/380 [==============================] - 0s 118us/step - loss: 0.2305 - accuracy: 0.9184 - val_loss: 0.5575 - val_accuracy: 0.8282
Epoch 6/100
380/380 [==============================] - 0s 138us/step - loss: 0.2543 - accuracy: 0.8763 - val_loss: 0.5614 - val_accuracy: 0.7669
Epoch 7/100
380/380 [==============================] - 0s 110us/step - loss: 0.2188 - accuracy: 0.9184 - val_loss: 0.5592 - val_accuracy: 0.8344
Epoch 8/100
380/380 [==============================] - 0s 101us/step - loss: 0.2272 - accuracy: 0.9184 - val_loss: 0.5724 - val_accuracy: 0.7914
Epoch 9/100
380/380 [==============================] - 0s 87us/step - loss: 0.2336 - accuracy: 0.9184 - val_loss: 0.5817 - val_accuracy: 0.7853
Epoch 10/100
380/380 [==============================] - 0s 105us/step - loss: 0.2410 - accuracy: 0.9132 - val_loss: 0.5688 - val_accuracy: 0.7853
Epoch 11/100
380/380 [==============================] - 0s 92us/step - loss: 0.2284 - accuracy: 0.9000 - val_loss: 0.5180 - val_accuracy: 0.7791
Epoch 12/100
380/380 [==============================] - 0s 99us/step - loss: 0.2499 - accuracy: 0.8947 - val_loss: 0.5556 - val_accuracy: 0.7730
Epoch 13/100
380/380 [==============================] - 0s 96us/step - loss: 0.2463 - accuracy: 0.9000 - val_loss: 0.5463 - val_accuracy: 0.7607
Epoch 14/100
380/380 [==============================] - 0s 130us/step - loss: 0.2280 - accuracy: 0.9026 - val_loss: 0.5409 - val_accuracy: 0.7853
Epoch 15/100
380/380 [==============================] - 0s 89us/step - loss: 0.2156 - accuracy: 0.9211 - val_loss: 0.5578 - val_accuracy: 0.8282
Epoch 16/100
380/380 [==============================] - 0s 128us/step - loss: 0.2236 - accuracy: 0.9079 - val_loss: 0.5514 - val_accuracy: 0.7730
Epoch 17/100
380/380 [==============================] - 0s 107us/step - loss: 0.2319 - accuracy: 0.8868 - val_loss: 0.6307 - val_accuracy: 0.7485
Epoch 18/100
380/380 [==============================] - 0s 97us/step - loss: 0.2461 - accuracy: 0.8842 - val_loss: 0.5841 - val_accuracy: 0.7669
Epoch 19/100
380/380 [==============================] - 0s 105us/step - loss: 0.2403 - accuracy: 0.8947 - val_loss: 0.5538 - val_accuracy: 0.7791
Epoch 20/100
380/380 [==============================] - 0s 96us/step - loss: 0.2244 - accuracy: 0.9053 - val_loss: 0.5409 - val_accuracy: 0.7791
Epoch 21/100
380/380 [==============================] - 0s 95us/step - loss: 0.2106 - accuracy: 0.9211 - val_loss: 0.5698 - val_accuracy: 0.7791
Epoch 22/100
380/380 [==============================] - 0s 91us/step - loss: 0.2079 - accuracy: 0.9263 - val_loss: 0.5705 - val_accuracy: 0.7791
Epoch 23/100
380/380 [==============================] - 0s 87us/step - loss: 0.2076 - accuracy: 0.9184 - val_loss: 0.5349 - val_accuracy: 0.7730
Epoch 24/100
380/380 [==============================] - 0s 101us/step - loss: 0.2005 - accuracy: 0.9184 - val_loss: 0.5300 - val_accuracy: 0.7730
Epoch 25/100
380/380 [==============================] - 0s 122us/step - loss: 0.2061 - accuracy: 0.9237 - val_loss: 0.5618 - val_accuracy: 0.8160
Epoch 26/100
380/380 [==============================] - 0s 105us/step - loss: 0.2084 - accuracy: 0.9211 - val_loss: 0.5899 - val_accuracy: 0.7730
Epoch 27/100
380/380 [==============================] - 0s 97us/step - loss: 0.2091 - accuracy: 0.9237 - val_loss: 0.6025 - val_accuracy: 0.7853
Epoch 28/100
380/380 [==============================] - 0s 124us/step - loss: 0.2087 - accuracy: 0.9026 - val_loss: 0.5704 - val_accuracy: 0.7853
Epoch 29/100
380/380 [==============================] - 0s 103us/step - loss: 0.2029 - accuracy: 0.9237 - val_loss: 0.5611 - val_accuracy: 0.7853
Epoch 30/100
380/380 [==============================] - 0s 135us/step - loss: 0.2229 - accuracy: 0.9211 - val_loss: 0.5930 - val_accuracy: 0.7975
Epoch 31/100
380/380 [==============================] - 0s 129us/step - loss: 0.2090 - accuracy: 0.9105 - val_loss: 0.5867 - val_accuracy: 0.7791
Epoch 32/100
380/380 [==============================] - 0s 140us/step - loss: 0.1997 - accuracy: 0.9184 - val_loss: 0.5539 - val_accuracy: 0.8160
Epoch 33/100
380/380 [==============================] - 0s 132us/step - loss: 0.2083 - accuracy: 0.9158 - val_loss: 0.5522 - val_accuracy: 0.7791
Epoch 34/100
380/380 [==============================] - 0s 130us/step - loss: 0.1855 - accuracy: 0.9289 - val_loss: 0.5661 - val_accuracy: 0.8037
Epoch 35/100
380/380 [==============================] - 0s 133us/step - loss: 0.1902 - accuracy: 0.9237 - val_loss: 0.5324 - val_accuracy: 0.7853
Epoch 36/100
380/380 [==============================] - 0s 131us/step - loss: 0.1990 - accuracy: 0.9184 - val_loss: 0.6570 - val_accuracy: 0.7362
Epoch 37/100
380/380 [==============================] - 0s 166us/step - loss: 0.1982 - accuracy: 0.9184 - val_loss: 0.5301 - val_accuracy: 0.8037
Epoch 38/100
380/380 [==============================] - 0s 100us/step - loss: 0.2017 - accuracy: 0.9053 - val_loss: 0.5308 - val_accuracy: 0.7791
Epoch 39/100
380/380 [==============================] - 0s 86us/step - loss: 0.1950 - accuracy: 0.9211 - val_loss: 0.5476 - val_accuracy: 0.7730
Epoch 40/100
380/380 [==============================] - 0s 79us/step - loss: 0.1867 - accuracy: 0.9211 - val_loss: 0.5397 - val_accuracy: 0.7730
Epoch 41/100
380/380 [==============================] - 0s 78us/step - loss: 0.1958 - accuracy: 0.9158 - val_loss: 0.5796 - val_accuracy: 0.7853
Epoch 42/100
380/380 [==============================] - 0s 85us/step - loss: 0.1934 - accuracy: 0.9289 - val_loss: 0.5835 - val_accuracy: 0.8160
Epoch 43/100
380/380 [==============================] - 0s 81us/step - loss: 0.1933 - accuracy: 0.9237 - val_loss: 0.5725 - val_accuracy: 0.8160
Epoch 44/100
380/380 [==============================] - 0s 82us/step - loss: 0.1899 - accuracy: 0.9211 - val_loss: 0.5428 - val_accuracy: 0.8221
Epoch 45/100
380/380 [==============================] - 0s 92us/step - loss: 0.1901 - accuracy: 0.9289 - val_loss: 0.5346 - val_accuracy: 0.7730
Epoch 46/100
380/380 [==============================] - 0s 91us/step - loss: 0.1888 - accuracy: 0.9289 - val_loss: 0.5542 - val_accuracy: 0.8160
Epoch 47/100
380/380 [==============================] - 0s 84us/step - loss: 0.2048 - accuracy: 0.9211 - val_loss: 0.6408 - val_accuracy: 0.7669
Epoch 48/100
380/380 [==============================] - 0s 101us/step - loss: 0.1836 - accuracy: 0.9211 - val_loss: 0.5399 - val_accuracy: 0.8221
Epoch 49/100
380/380 [==============================] - 0s 98us/step - loss: 0.1810 - accuracy: 0.9263 - val_loss: 0.5670 - val_accuracy: 0.7730
Epoch 50/100
380/380 [==============================] - 0s 116us/step - loss: 0.1830 - accuracy: 0.9289 - val_loss: 0.5550 - val_accuracy: 0.8160
Epoch 51/100
380/380 [==============================] - ETA: 0s - loss: 0.1837 - accuracy: 0.90 - 0s 98us/step - loss: 0.1770 - accuracy: 0.9289 - val_loss: 0.5890 - val_accuracy: 0.7853
Epoch 52/100
380/380 [==============================] - 0s 91us/step - loss: 0.1783 - accuracy: 0.9237 - val_loss: 0.5299 - val_accuracy: 0.8221
Epoch 53/100
380/380 [==============================] - 0s 106us/step - loss: 0.1875 - accuracy: 0.9211 - val_loss: 0.5807 - val_accuracy: 0.7730
Epoch 54/100
380/380 [==============================] - 0s 82us/step - loss: 0.1821 - accuracy: 0.9316 - val_loss: 0.5667 - val_accuracy: 0.8160
Epoch 55/100
380/380 [==============================] - 0s 89us/step - loss: 0.1922 - accuracy: 0.9132 - val_loss: 0.5411 - val_accuracy: 0.7791
Epoch 56/100
380/380 [==============================] - 0s 93us/step - loss: 0.1889 - accuracy: 0.9158 - val_loss: 0.5604 - val_accuracy: 0.8160
Epoch 57/100
380/380 [==============================] - 0s 83us/step - loss: 0.2006 - accuracy: 0.9184 - val_loss: 0.5456 - val_accuracy: 0.7791
Epoch 58/100
380/380 [==============================] - 0s 98us/step - loss: 0.1853 - accuracy: 0.9316 - val_loss: 0.5438 - val_accuracy: 0.7730
Epoch 59/100
380/380 [==============================] - 0s 85us/step - loss: 0.1803 - accuracy: 0.9316 - val_loss: 0.6363 - val_accuracy: 0.8037
Epoch 60/100
380/380 [==============================] - 0s 103us/step - loss: 0.1863 - accuracy: 0.9079 - val_loss: 0.5529 - val_accuracy: 0.8344
Epoch 61/100
380/380 [==============================] - 0s 101us/step - loss: 0.1848 - accuracy: 0.9289 - val_loss: 0.5541 - val_accuracy: 0.7853
Epoch 62/100
380/380 [==============================] - 0s 87us/step - loss: 0.1986 - accuracy: 0.9211 - val_loss: 0.5683 - val_accuracy: 0.8160
Epoch 63/100
380/380 [==============================] - 0s 95us/step - loss: 0.1724 - accuracy: 0.9316 - val_loss: 0.5503 - val_accuracy: 0.7730
Epoch 64/100
380/380 [==============================] - 0s 89us/step - loss: 0.1758 - accuracy: 0.9289 - val_loss: 0.6021 - val_accuracy: 0.8160
Epoch 65/100
380/380 [==============================] - 0s 111us/step - loss: 0.1795 - accuracy: 0.9211 - val_loss: 0.5555 - val_accuracy: 0.8037
Epoch 66/100
380/380 [==============================] - 0s 110us/step - loss: 0.1935 - accuracy: 0.9211 - val_loss: 0.5489 - val_accuracy: 0.7914
Epoch 67/100
380/380 [==============================] - 0s 109us/step - loss: 0.1819 - accuracy: 0.9237 - val_loss: 0.5826 - val_accuracy: 0.8037
Epoch 68/100
380/380 [==============================] - 0s 81us/step - loss: 0.1695 - accuracy: 0.9342 - val_loss: 0.5543 - val_accuracy: 0.8344
Epoch 69/100
380/380 [==============================] - 0s 98us/step - loss: 0.1839 - accuracy: 0.9342 - val_loss: 0.5387 - val_accuracy: 0.7791
Epoch 70/100
380/380 [==============================] - 0s 85us/step - loss: 0.1730 - accuracy: 0.9316 - val_loss: 0.6530 - val_accuracy: 0.7791
Epoch 71/100
380/380 [==============================] - 0s 124us/step - loss: 0.1844 - accuracy: 0.9184 - val_loss: 0.5725 - val_accuracy: 0.8160
Epoch 72/100
380/380 [==============================] - 0s 91us/step - loss: 0.1760 - accuracy: 0.9263 - val_loss: 0.5598 - val_accuracy: 0.8037
Epoch 73/100
380/380 [==============================] - 0s 97us/step - loss: 0.1797 - accuracy: 0.9237 - val_loss: 0.6062 - val_accuracy: 0.7730
Epoch 74/100
380/380 [==============================] - 0s 126us/step - loss: 0.1985 - accuracy: 0.9105 - val_loss: 0.5627 - val_accuracy: 0.8037
Epoch 75/100
380/380 [==============================] - 0s 80us/step - loss: 0.1854 - accuracy: 0.9211 - val_loss: 0.6285 - val_accuracy: 0.8037
Epoch 76/100
380/380 [==============================] - 0s 83us/step - loss: 0.1894 - accuracy: 0.9211 - val_loss: 0.6003 - val_accuracy: 0.8037
Epoch 77/100
380/380 [==============================] - 0s 87us/step - loss: 0.1703 - accuracy: 0.9237 - val_loss: 0.5444 - val_accuracy: 0.8160
Epoch 78/100
380/380 [==============================] - 0s 87us/step - loss: 0.1766 - accuracy: 0.9184 - val_loss: 0.6432 - val_accuracy: 0.8221
Epoch 79/100
380/380 [==============================] - 0s 93us/step - loss: 0.1763 - accuracy: 0.9289 - val_loss: 0.5415 - val_accuracy: 0.7791
Epoch 80/100
380/380 [==============================] - 0s 97us/step - loss: 0.1762 - accuracy: 0.9263 - val_loss: 0.5561 - val_accuracy: 0.8037
Epoch 81/100
380/380 [==============================] - 0s 104us/step - loss: 0.1724 - accuracy: 0.9316 - val_loss: 0.5595 - val_accuracy: 0.8160
Epoch 82/100
380/380 [==============================] - 0s 107us/step - loss: 0.1714 - accuracy: 0.9289 - val_loss: 0.5835 - val_accuracy: 0.8160
Epoch 83/100
380/380 [==============================] - 0s 85us/step - loss: 0.1758 - accuracy: 0.9184 - val_loss: 0.5483 - val_accuracy: 0.7791
Epoch 84/100
380/380 [==============================] - 0s 86us/step - loss: 0.1818 - accuracy: 0.9263 - val_loss: 0.6042 - val_accuracy: 0.8037
Epoch 85/100
380/380 [==============================] - 0s 88us/step - loss: 0.1793 - accuracy: 0.9211 - val_loss: 0.5649 - val_accuracy: 0.8160
Epoch 86/100
380/380 [==============================] - 0s 93us/step - loss: 0.1718 - accuracy: 0.9263 - val_loss: 0.5478 - val_accuracy: 0.8037
Epoch 87/100
380/380 [==============================] - 0s 101us/step - loss: 0.1719 - accuracy: 0.9237 - val_loss: 0.5579 - val_accuracy: 0.8221
Epoch 88/100
380/380 [==============================] - 0s 86us/step - loss: 0.1677 - accuracy: 0.9289 - val_loss: 0.6422 - val_accuracy: 0.7975
Epoch 89/100
380/380 [==============================] - 0s 84us/step - loss: 0.1773 - accuracy: 0.9158 - val_loss: 0.5502 - val_accuracy: 0.8098
Epoch 90/100
380/380 [==============================] - 0s 81us/step - loss: 0.1652 - accuracy: 0.9316 - val_loss: 0.5915 - val_accuracy: 0.8098
Epoch 91/100
380/380 [==============================] - 0s 81us/step - loss: 0.1755 - accuracy: 0.9263 - val_loss: 0.5719 - val_accuracy: 0.7791
Epoch 92/100
380/380 [==============================] - 0s 80us/step - loss: 0.1887 - accuracy: 0.9211 - val_loss: 0.5648 - val_accuracy: 0.7853
Epoch 93/100
380/380 [==============================] - 0s 87us/step - loss: 0.1679 - accuracy: 0.9289 - val_loss: 0.6240 - val_accuracy: 0.8037
Epoch 94/100
380/380 [==============================] - 0s 121us/step - loss: 0.1714 - accuracy: 0.9211 - val_loss: 0.5336 - val_accuracy: 0.8160
Epoch 95/100
380/380 [==============================] - 0s 310us/step - loss: 0.1908 - accuracy: 0.9211 - val_loss: 0.5560 - val_accuracy: 0.7853
Epoch 96/100
380/380 [==============================] - 0s 237us/step - loss: 0.1839 - accuracy: 0.9237 - val_loss: 0.6237 - val_accuracy: 0.8037
Epoch 97/100
380/380 [==============================] - 0s 194us/step - loss: 0.1857 - accuracy: 0.9184 - val_loss: 0.5835 - val_accuracy: 0.8037
Epoch 98/100
380/380 [==============================] - 0s 129us/step - loss: 0.1739 - accuracy: 0.9105 - val_loss: 0.5479 - val_accuracy: 0.8344
Epoch 99/100
380/380 [==============================] - 0s 130us/step - loss: 0.1656 - accuracy: 0.9237 - val_loss: 0.5824 - val_accuracy: 0.8160
Epoch 100/100
380/380 [==============================] - 0s 148us/step - loss: 0.1715 - accuracy: 0.9316 - val_loss: 0.5466 - val_accuracy: 0.8098
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[301]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;over-sampling train accuracy: </span><span class="si">%.2f%%</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">hist2_over4</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span><span class="o">*</span><span class="mi">100</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>over-sampling train accuracy: 91.86%
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[61]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df_proba8</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_excel</span><span class="p">(</span><span class="s2">&quot;/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_lasso_2.xlsx&quot;</span><span class="p">,</span>
                        <span class="n">sheet_name</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
                        <span class="n">index_col</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[62]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df_proba8</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[62]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>phage</th>
      <th>strain</th>
      <th>phenotype</th>
      <th>prediction</th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>p0006kpresabs_qual</td>
      <td>NRS236</td>
      <td>1</td>
      <td>2</td>
      <td>1.321970e-02</td>
      <td>2.446264e-01</td>
      <td>7.421539e-01</td>
    </tr>
    <tr>
      <th>1</th>
      <td>p0006kpresabs_qual</td>
      <td>NRS113</td>
      <td>2</td>
      <td>2</td>
      <td>3.478230e-02</td>
      <td>2.806685e-01</td>
      <td>6.845492e-01</td>
    </tr>
    <tr>
      <th>2</th>
      <td>p0006kpresabs_qual</td>
      <td>CFBRSa23</td>
      <td>0</td>
      <td>0</td>
      <td>4.090251e-01</td>
      <td>3.405008e-01</td>
      <td>2.504741e-01</td>
    </tr>
    <tr>
      <th>3</th>
      <td>p0006kpresabs_qual</td>
      <td>NRS249</td>
      <td>2</td>
      <td>1</td>
      <td>1.987907e-01</td>
      <td>5.331044e-01</td>
      <td>2.681049e-01</td>
    </tr>
    <tr>
      <th>4</th>
      <td>p0006kpresabs_qual</td>
      <td>107</td>
      <td>1</td>
      <td>0</td>
      <td>4.090251e-01</td>
      <td>3.405008e-01</td>
      <td>2.504741e-01</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>984</th>
      <td>p0017Skpresabs_qual</td>
      <td>CFBRSa30</td>
      <td>0</td>
      <td>0</td>
      <td>7.207667e-01</td>
      <td>2.792331e-01</td>
      <td>2.571588e-07</td>
    </tr>
    <tr>
      <th>985</th>
      <td>p0017Skpresabs_qual</td>
      <td>NRS383</td>
      <td>1</td>
      <td>0</td>
      <td>6.129044e-01</td>
      <td>3.870795e-01</td>
      <td>1.601290e-05</td>
    </tr>
    <tr>
      <th>986</th>
      <td>p0017Skpresabs_qual</td>
      <td>NRS110</td>
      <td>2</td>
      <td>2</td>
      <td>3.260306e-07</td>
      <td>7.910664e-07</td>
      <td>9.999989e-01</td>
    </tr>
    <tr>
      <th>987</th>
      <td>p0017Skpresabs_qual</td>
      <td>NRS209</td>
      <td>2</td>
      <td>2</td>
      <td>3.604249e-12</td>
      <td>2.698129e-07</td>
      <td>9.999998e-01</td>
    </tr>
    <tr>
      <th>988</th>
      <td>p0017Skpresabs_qual</td>
      <td>NY439</td>
      <td>0</td>
      <td>0</td>
      <td>7.207667e-01</td>
      <td>2.792331e-01</td>
      <td>2.571588e-07</td>
    </tr>
  </tbody>
</table>
<p>989 rows × 7 columns</p>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[63]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">y_prob8</span> <span class="o">=</span> <span class="n">df_proba8</span><span class="p">[</span><span class="n">df_proba8</span><span class="p">[</span><span class="s1">&#39;phage&#39;</span><span class="p">]</span><span class="o">==</span><span class="s1">&#39;p11kpresabs_qual&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="o">-</span><span class="mi">3</span><span class="p">:]</span>
<span class="n">y_prob8</span> <span class="o">=</span> <span class="n">y_prob8</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
<span class="n">y_prob8</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[63]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>array([[2.74581700e-03, 2.88468540e-01, 7.08785600e-01],
       [4.71758560e-03, 9.75753660e-01, 1.95287750e-02],
       [1.92255250e-04, 7.35249100e-03, 9.92455240e-01],
       [5.85535060e-02, 1.85172830e-01, 7.56273700e-01],
       [2.88878950e-04, 9.63804100e-01, 3.59069700e-02],
       [2.23829400e-06, 9.92302660e-01, 7.69512730e-03],
       [1.25340930e-03, 3.29659900e-02, 9.65780600e-01],
       [3.12293350e-01, 5.72142100e-02, 6.30492400e-01],
       [6.43630160e-04, 9.81170500e-01, 1.81859140e-02],
       [9.37851700e-01, 4.23572140e-02, 1.97910460e-02],
       [3.11034360e-02, 2.67407200e-01, 7.01489300e-01],
       [7.15927700e-03, 8.03341300e-03, 9.84807250e-01],
       [1.73330750e-01, 2.99731760e-01, 5.26937500e-01],
       [4.71758560e-03, 9.75753660e-01, 1.95287750e-02],
       [1.47159160e-01, 5.85265000e-01, 2.67575830e-01],
       [9.03133870e-01, 5.17746880e-02, 4.50914540e-02],
       [9.88825000e-01, 7.81643200e-05, 1.10968060e-02],
       [9.98544200e-04, 9.04473800e-01, 9.45277400e-02],
       [6.53156820e-03, 7.55080940e-01, 2.38387480e-01],
       [2.73665520e-01, 5.30940600e-01, 1.95393890e-01],
       [9.82885840e-01, 1.03948950e-02, 6.71929070e-03],
       [8.22161400e-02, 8.38162300e-01, 7.96215400e-02],
       [1.85913400e-02, 6.44396000e-02, 9.16969060e-01],
       [5.85535060e-02, 1.85172830e-01, 7.56273700e-01],
       [9.85801500e-01, 1.24119960e-03, 1.29572940e-02],
       [5.85535060e-02, 1.85172830e-01, 7.56273700e-01],
       [2.16182790e-04, 3.29451640e-02, 9.66838600e-01],
       [4.89789240e-04, 4.20597670e-04, 9.99089600e-01],
       [1.90282750e-01, 7.09122100e-02, 7.38805060e-01],
       [1.47159160e-01, 5.85265000e-01, 2.67575830e-01],
       [5.63474500e-01, 9.44594800e-03, 4.27079530e-01],
       [2.73665520e-01, 5.30940600e-01, 1.95393890e-01],
       [7.81508600e-02, 1.04467310e-03, 9.20804500e-01],
       [1.28297580e-01, 1.52391700e-01, 7.19310640e-01],
       [9.98544200e-04, 9.04473800e-01, 9.45277400e-02],
       [2.73665520e-01, 5.30940600e-01, 1.95393890e-01],
       [9.66194900e-01, 3.53103040e-03, 3.02740370e-02],
       [3.68386100e-02, 1.89164950e-01, 7.73996500e-01],
       [2.66897630e-03, 6.60801050e-01, 3.36529940e-01],
       [9.66194900e-01, 3.53103040e-03, 3.02740370e-02],
       [2.04066810e-01, 1.02355750e-02, 7.85697600e-01],
       [1.48468580e-03, 9.94087340e-01, 4.42795130e-03],
       [1.47159160e-01, 5.85265000e-01, 2.67575830e-01],
       [8.97351000e-01, 1.34841160e-05, 1.02635480e-01],
       [9.41169500e-01, 2.45169350e-02, 3.43136040e-02],
       [1.73330750e-01, 2.99731760e-01, 5.26937500e-01],
       [9.89563900e-01, 2.57412270e-03, 7.86200100e-03],
       [5.63474500e-01, 9.44594800e-03, 4.27079530e-01],
       [7.43875700e-02, 9.02459860e-01, 2.31525530e-02],
       [1.73330750e-01, 2.99731760e-01, 5.26937500e-01],
       [2.50214760e-03, 9.58823740e-01, 3.86740800e-02],
       [7.78845000e-01, 2.37328230e-03, 2.18781620e-01],
       [8.05304100e-01, 1.61422030e-02, 1.78553770e-01],
       [1.47159160e-01, 5.85265000e-01, 2.67575830e-01],
       [3.02337880e-03, 7.56889200e-01, 2.40087350e-01],
       [2.94642110e-02, 6.98645230e-01, 2.71890550e-01],
       [1.47159160e-01, 5.85265000e-01, 2.67575830e-01],
       [2.75474900e-05, 8.97681200e-01, 1.02291346e-01],
       [2.95523930e-02, 4.72326220e-01, 4.98121440e-01],
       [2.94642110e-02, 6.98645230e-01, 2.71890550e-01],
       [8.67480700e-01, 2.54278900e-05, 1.32493840e-01],
       [1.73330750e-01, 2.99731760e-01, 5.26937500e-01],
       [1.47159160e-01, 5.85265000e-01, 2.67575830e-01],
       [9.85186640e-01, 1.00675534e-04, 1.47127400e-02],
       [9.03133870e-01, 5.17746880e-02, 4.50914540e-02],
       [9.90096200e-01, 8.18772100e-04, 9.08501350e-03],
       [9.66194900e-01, 3.53103040e-03, 3.02740370e-02],
       [2.50214760e-03, 9.58823740e-01, 3.86740800e-02],
       [8.22161400e-02, 8.38162300e-01, 7.96215400e-02],
       [8.12832060e-01, 4.33954400e-03, 1.82828440e-01],
       [1.68001980e-01, 9.15818850e-03, 8.22839860e-01],
       [9.03133870e-01, 5.17746880e-02, 4.50914540e-02],
       [2.96875230e-03, 9.39301000e-01, 5.77302870e-02],
       [1.47159160e-01, 5.85265000e-01, 2.67575830e-01],
       [1.03376250e-04, 9.69634650e-01, 3.02619880e-02],
       [2.50214760e-03, 9.58823740e-01, 3.86740800e-02],
       [5.80157450e-02, 9.04391770e-01, 3.75924450e-02],
       [5.01690400e-03, 4.21960920e-01, 5.73022200e-01],
       [2.97581300e-02, 9.21277900e-01, 4.89640350e-02],
       [9.03133870e-01, 5.17746880e-02, 4.50914540e-02],
       [9.72271400e-01, 8.28812300e-03, 1.94404570e-02],
       [2.73665520e-01, 5.30940600e-01, 1.95393890e-01],
       [1.69442200e-05, 1.03388810e-02, 9.89644170e-01],
       [3.73667570e-01, 5.66045750e-02, 5.69727960e-01],
       [6.74903600e-02, 2.05903000e-01, 7.26606600e-01],
       [4.83928800e-03, 9.28491830e-01, 6.66689300e-02],
       [3.73667570e-01, 5.66045750e-02, 5.69727960e-01],
       [1.94091540e-02, 1.01271590e-04, 9.80489550e-01],
       [9.63274400e-01, 1.00766900e-02, 2.66489180e-02],
       [4.46662600e-03, 1.11740805e-01, 8.83792500e-01],
       [8.97351000e-01, 1.34841160e-05, 1.02635480e-01],
       [9.88825000e-01, 7.81643200e-05, 1.10968060e-02],
       [8.12832060e-01, 4.33954400e-03, 1.82828440e-01],
       [5.85535060e-02, 1.85172830e-01, 7.56273700e-01],
       [2.14771660e-05, 4.86140460e-04, 9.99492400e-01],
       [8.62989350e-02, 6.81622700e-01, 2.32078390e-01],
       [1.27253360e-03, 6.00164650e-01, 3.98562900e-01],
       [9.72271400e-01, 8.28812300e-03, 1.94404570e-02],
       [6.43630160e-04, 9.81170500e-01, 1.81859140e-02],
       [1.51392490e-05, 9.86533050e-01, 1.34518170e-02],
       [2.50214760e-03, 9.58823740e-01, 3.86740800e-02],
       [1.07245630e-01, 3.01893230e-01, 5.90861200e-01],
       [9.72271400e-01, 8.28812300e-03, 1.94404570e-02],
       [1.66357960e-01, 1.30638900e-01, 7.03003100e-01],
       [1.08249530e-02, 9.80207150e-01, 8.96784500e-03],
       [5.13990640e-04, 5.85365780e-02, 9.40949500e-01],
       [5.85535060e-02, 1.85172830e-01, 7.56273700e-01],
       [8.67480700e-01, 2.54278900e-05, 1.32493840e-01],
       [9.88825000e-01, 7.81643200e-05, 1.10968060e-02],
       [3.92205600e-02, 2.44154050e-01, 7.16625400e-01],
       [2.75474900e-05, 8.97681200e-01, 1.02291346e-01],
       [1.47159160e-01, 5.85265000e-01, 2.67575830e-01],
       [2.51126380e-03, 6.78946500e-01, 3.18542330e-01],
       [9.42534100e-01, 1.76052280e-02, 3.98606600e-02],
       [8.97351000e-01, 1.34841160e-05, 1.02635480e-01],
       [3.40771230e-03, 8.26599700e-02, 9.13932300e-01],
       [1.47159160e-01, 5.85265000e-01, 2.67575830e-01],
       [3.44732700e-02, 8.77932130e-01, 8.75946300e-02],
       [6.05271150e-03, 9.84376550e-01, 9.57068500e-03],
       [1.73330750e-01, 2.99731760e-01, 5.26937500e-01],
       [4.83928800e-03, 9.28491830e-01, 6.66689300e-02],
       [1.40919090e-03, 4.51507870e-01, 5.47082900e-01],
       [6.36566900e-02, 1.53007400e-01, 7.83335900e-01],
       [9.88825000e-01, 7.81643200e-05, 1.10968060e-02],
       [1.68672950e-01, 2.18931750e-02, 8.09433800e-01],
       [5.85535060e-02, 1.85172830e-01, 7.56273700e-01],
       [5.63474500e-01, 9.44594800e-03, 4.27079530e-01],
       [8.23850100e-01, 3.08099070e-02, 1.45340000e-01],
       [2.73665520e-01, 5.30940600e-01, 1.95393890e-01],
       [2.73665520e-01, 5.30940600e-01, 1.95393890e-01],
       [7.01692400e-04, 9.37319300e-04, 9.98360930e-01],
       [9.63274400e-01, 1.00766900e-02, 2.66489180e-02],
       [7.04740700e-01, 4.04639830e-05, 2.95218800e-01],
       [1.47159160e-01, 5.85265000e-01, 2.67575830e-01],
       [2.96875230e-03, 9.39301000e-01, 5.77302870e-02],
       [4.83928800e-03, 9.28491830e-01, 6.66689300e-02],
       [2.73665520e-01, 5.30940600e-01, 1.95393890e-01],
       [5.80157450e-02, 9.04391770e-01, 3.75924450e-02],
       [4.69490950e-01, 5.31771970e-03, 5.25191370e-01],
       [2.97088870e-02, 6.75862300e-01, 2.94428770e-01],
       [2.73665520e-01, 5.30940600e-01, 1.95393890e-01],
       [1.47159160e-01, 5.85265000e-01, 2.67575830e-01],
       [9.88825000e-01, 7.81643200e-05, 1.10968060e-02],
       [1.47159160e-01, 5.85265000e-01, 2.67575830e-01],
       [6.05271150e-03, 9.84376550e-01, 9.57068500e-03],
       [1.77801240e-01, 7.13833800e-01, 1.08364960e-01],
       [9.88825000e-01, 7.81643200e-05, 1.10968060e-02],
       [9.85801500e-01, 1.24119960e-03, 1.29572940e-02],
       [9.37851700e-01, 4.23572140e-02, 1.97910460e-02],
       [5.80157450e-02, 9.04391770e-01, 3.75924450e-02],
       [4.71758560e-03, 9.75753660e-01, 1.95287750e-02],
       [5.85535060e-02, 1.85172830e-01, 7.56273700e-01],
       [9.63274400e-01, 1.00766900e-02, 2.66489180e-02],
       [9.63274400e-01, 1.00766900e-02, 2.66489180e-02],
       [1.63023450e-04, 7.96402200e-02, 9.20196700e-01],
       [6.74038830e-04, 2.04650390e-02, 9.78860900e-01],
       [1.07430620e-03, 7.33335600e-04, 9.98192370e-01],
       [1.07245630e-01, 3.01893230e-01, 5.90861200e-01],
       [5.85535060e-02, 1.85172830e-01, 7.56273700e-01],
       [7.98386900e-03, 9.72267700e-01, 1.97484080e-02],
       [3.02337880e-03, 7.56889200e-01, 2.40087350e-01],
       [9.89563900e-01, 2.57412270e-03, 7.86200100e-03],
       [7.00659450e-02, 6.64020300e-01, 2.65913780e-01]])</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[64]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">ovo8</span> <span class="o">=</span> <span class="n">rocauc_ovo</span><span class="p">(</span><span class="n">y_sel_test_over</span><span class="p">,</span> <span class="n">y_prob8</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s2">&quot;macro&quot;</span><span class="p">,</span> <span class="n">multi_class</span><span class="o">=</span><span class="s2">&quot;ovo&quot;</span><span class="p">)</span>
<span class="n">ovo8</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[64]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>0.9384924680031714</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[65]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">ovr8</span> <span class="o">=</span> <span class="n">rocauc_ovr</span><span class="p">(</span><span class="n">y_sel_test_over</span><span class="p">,</span> <span class="n">y_prob8</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s2">&quot;macro&quot;</span><span class="p">,</span> <span class="n">multi_class</span><span class="o">=</span><span class="s2">&quot;ovr&quot;</span><span class="p">)</span>
<span class="n">ovr8</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[65]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>0.9384924680031714</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[66]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">ovos2</span> <span class="o">=</span> <span class="p">[</span><span class="n">ovo5</span><span class="p">,</span> <span class="n">ovo6</span><span class="p">,</span> <span class="n">ovo7</span><span class="p">,</span> <span class="n">ovo8</span><span class="p">]</span>
<span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">ovos2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[66]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>0.9573197572050784</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[67]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">ovos2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[67]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>0.014130795222348162</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[68]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">ovrs2</span> <span class="o">=</span> <span class="p">[</span><span class="n">ovr5</span><span class="p">,</span> <span class="n">ovr6</span><span class="p">,</span> <span class="n">ovr7</span><span class="p">,</span> <span class="n">ovr8</span><span class="p">]</span>
<span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">ovrs2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[68]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>0.9573197572050784</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[69]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">ovrs2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[69]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>0.014130795222348162</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[302]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">accs_l_over</span> <span class="o">=</span> <span class="p">[</span><span class="n">acc_test2_over</span><span class="p">,</span> <span class="n">acc_test2_over2</span><span class="p">,</span> <span class="n">acc_test2_over3</span><span class="p">,</span> <span class="n">acc_test2_over4</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[303]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">mean_l_over</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">accs_l_over</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;over-sampling test accuracy mean after lasso: </span><span class="si">%.2f%%</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">mean_l_over</span><span class="o">*</span><span class="mi">100</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>over-sampling test accuracy mean after lasso: 83.44%
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[304]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">std_l_over</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">accs_l_over</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;over-sampling test accuracy standard deviation after lasso:&#39;</span><span class="p">,</span> <span class="n">std_l_over</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>over-sampling test accuracy standard deviation after lasso: 0.019879588183034303
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[305]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">accs_train_l_over</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">hist2_over</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]),</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">hist2_over2</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]),</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">hist2_over3</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]),</span>
             <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">hist2_over4</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])]</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[306]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">mean_train_l_over</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">accs_train_l_over</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;over-sampling train accuracy mean after lasso: </span><span class="si">%.2f%%</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">mean_train_l_over</span><span class="o">*</span><span class="mi">100</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>over-sampling train accuracy mean after lasso: 91.94%
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[307]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">std_train_l_over</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">accs_train_l_over</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;over-sampling train accuracy standard deviation after lasso:&#39;</span><span class="p">,</span> <span class="n">std_train_l_over</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>over-sampling train accuracy standard deviation after lasso: 0.0026263413
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

</div>
    </div>
  </div>
</body>

 


</html>
