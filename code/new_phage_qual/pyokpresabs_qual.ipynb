{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This file implements neural networks for pyokpresabs_qual with four replicates.\n",
    "## We compute the mean and standarad deviation of training and test accuracies.\n",
    "## We also compute the mean and standard deviation of AUC ROC values for four replicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "import numpy as np\n",
    "seed(100)\n",
    "import tensorflow\n",
    "tensorflow.random.set_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(253, 16)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/pyokpresabs_qual.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'Unnamed: 0':'id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "      ..\n",
       "248    0\n",
       "249    0\n",
       "250    0\n",
       "251    0\n",
       "252    0\n",
       "Name: pheno, Length: 253, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pheno']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>TTTTCCCCCAT</th>\n",
       "      <th>TTCAAATTACCCTCTCTTGTAAAATCAAATTCACATGATGTCCATGGTTC</th>\n",
       "      <th>TGGGTCTGAC</th>\n",
       "      <th>TCCTGATGGACCAAAACCTAATTTAATCCAATCTATATAATCAAACGATACTTTCAAATTACCCTCTCTTGTAAAATCAAATTCACATGATGTCCATGGT</th>\n",
       "      <th>TATATAGACTG</th>\n",
       "      <th>TAGTCGCACT</th>\n",
       "      <th>TAAGAATAATATATTAAATATTTATTAACAAATTATAGATAAAATATGAATAATTAATTAATGGTATTTACATATTCATAACC</th>\n",
       "      <th>GGGCTGAGG</th>\n",
       "      <th>GAGCAACCTT</th>\n",
       "      <th>GAACCATGGACATCATGTGAATTTGATTTTACAAGAGAGGGT</th>\n",
       "      <th>GAACCATGGACATCATGTGAATTTGATTTTACAAGAGAGGGTAATTTGAAAGTATCGTTTGATTATATAGATTGGAT</th>\n",
       "      <th>GAACCATGGACATCATGTGAATTTGATTTTACAAGAGAGGGTAATTTGAAAGTATCGTTTGATTATATAGATTGGATTAAATTAGGTTTTGGTCCATCAG</th>\n",
       "      <th>CCTTGTTGCGG</th>\n",
       "      <th>CCTGATGGACCAAAACCTAATTTAATCCAATCTATATAATCAAACGATACTTTCAAATTACCCTCTCTTGTAAAATCAAATTCACATGATGTCCATGGTT</th>\n",
       "      <th>pheno</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>109</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>120335</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120337</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  TTTTCCCCCAT  TTCAAATTACCCTCTCTTGTAAAATCAAATTCACATGATGTCCATGGTTC  \\\n",
       "0     107            0                                                  1    \n",
       "1     109            0                                                  1    \n",
       "2     115            0                                                  0    \n",
       "3  120335            0                                                  1    \n",
       "4  120337            0                                                  1    \n",
       "\n",
       "   TGGGTCTGAC  \\\n",
       "0           1   \n",
       "1           0   \n",
       "2           0   \n",
       "3           0   \n",
       "4           0   \n",
       "\n",
       "   TCCTGATGGACCAAAACCTAATTTAATCCAATCTATATAATCAAACGATACTTTCAAATTACCCTCTCTTGTAAAATCAAATTCACATGATGTCCATGGT  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  1                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   TATATAGACTG  TAGTCGCACT  \\\n",
       "0            1           0   \n",
       "1            1           0   \n",
       "2            1           1   \n",
       "3            1           0   \n",
       "4            1           0   \n",
       "\n",
       "   TAAGAATAATATATTAAATATTTATTAACAAATTATAGATAAAATATGAATAATTAATTAATGGTATTTACATATTCATAACC  \\\n",
       "0                                                  1                                     \n",
       "1                                                  1                                     \n",
       "2                                                  1                                     \n",
       "3                                                  1                                     \n",
       "4                                                  1                                     \n",
       "\n",
       "   GGGCTGAGG  GAGCAACCTT  GAACCATGGACATCATGTGAATTTGATTTTACAAGAGAGGGT  \\\n",
       "0          0           0                                           1   \n",
       "1          0           0                                           1   \n",
       "2          1           1                                           0   \n",
       "3          0           0                                           1   \n",
       "4          0           0                                           1   \n",
       "\n",
       "   GAACCATGGACATCATGTGAATTTGATTTTACAAGAGAGGGTAATTTGAAAGTATCGTTTGATTATATAGATTGGAT  \\\n",
       "0                                                  1                               \n",
       "1                                                  1                               \n",
       "2                                                  0                               \n",
       "3                                                  1                               \n",
       "4                                                  1                               \n",
       "\n",
       "   GAACCATGGACATCATGTGAATTTGATTTTACAAGAGAGGGTAATTTGAAAGTATCGTTTGATTATATAGATTGGATTAAATTAGGTTTTGGTCCATCAG  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  1                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   CCTTGTTGCGG  \\\n",
       "0            0   \n",
       "1            0   \n",
       "2            1   \n",
       "3            0   \n",
       "4            0   \n",
       "\n",
       "   CCTGATGGACCAAAACCTAATTTAATCCAATCTATATAATCAAACGATACTTTCAAATTACCCTCTCTTGTAAAATCAAATTCACATGATGTCCATGGTT  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  1                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   pheno  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    217\n",
       "1     32\n",
       "2      4\n",
       "Name: pheno, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pheno'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.drop(columns=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(253, 15)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TTTTCCCCCAT</th>\n",
       "      <th>TTCAAATTACCCTCTCTTGTAAAATCAAATTCACATGATGTCCATGGTTC</th>\n",
       "      <th>TGGGTCTGAC</th>\n",
       "      <th>TCCTGATGGACCAAAACCTAATTTAATCCAATCTATATAATCAAACGATACTTTCAAATTACCCTCTCTTGTAAAATCAAATTCACATGATGTCCATGGT</th>\n",
       "      <th>TATATAGACTG</th>\n",
       "      <th>TAGTCGCACT</th>\n",
       "      <th>TAAGAATAATATATTAAATATTTATTAACAAATTATAGATAAAATATGAATAATTAATTAATGGTATTTACATATTCATAACC</th>\n",
       "      <th>GGGCTGAGG</th>\n",
       "      <th>GAGCAACCTT</th>\n",
       "      <th>GAACCATGGACATCATGTGAATTTGATTTTACAAGAGAGGGT</th>\n",
       "      <th>GAACCATGGACATCATGTGAATTTGATTTTACAAGAGAGGGTAATTTGAAAGTATCGTTTGATTATATAGATTGGAT</th>\n",
       "      <th>GAACCATGGACATCATGTGAATTTGATTTTACAAGAGAGGGTAATTTGAAAGTATCGTTTGATTATATAGATTGGATTAAATTAGGTTTTGGTCCATCAG</th>\n",
       "      <th>CCTTGTTGCGG</th>\n",
       "      <th>CCTGATGGACCAAAACCTAATTTAATCCAATCTATATAATCAAACGATACTTTCAAATTACCCTCTCTTGTAAAATCAAATTCACATGATGTCCATGGTT</th>\n",
       "      <th>pheno</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TTTTCCCCCAT  TTCAAATTACCCTCTCTTGTAAAATCAAATTCACATGATGTCCATGGTTC  \\\n",
       "0            0                                                  1    \n",
       "1            0                                                  1    \n",
       "2            0                                                  0    \n",
       "3            0                                                  1    \n",
       "4            0                                                  1    \n",
       "\n",
       "   TGGGTCTGAC  \\\n",
       "0           1   \n",
       "1           0   \n",
       "2           0   \n",
       "3           0   \n",
       "4           0   \n",
       "\n",
       "   TCCTGATGGACCAAAACCTAATTTAATCCAATCTATATAATCAAACGATACTTTCAAATTACCCTCTCTTGTAAAATCAAATTCACATGATGTCCATGGT  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  1                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   TATATAGACTG  TAGTCGCACT  \\\n",
       "0            1           0   \n",
       "1            1           0   \n",
       "2            1           1   \n",
       "3            1           0   \n",
       "4            1           0   \n",
       "\n",
       "   TAAGAATAATATATTAAATATTTATTAACAAATTATAGATAAAATATGAATAATTAATTAATGGTATTTACATATTCATAACC  \\\n",
       "0                                                  1                                     \n",
       "1                                                  1                                     \n",
       "2                                                  1                                     \n",
       "3                                                  1                                     \n",
       "4                                                  1                                     \n",
       "\n",
       "   GGGCTGAGG  GAGCAACCTT  GAACCATGGACATCATGTGAATTTGATTTTACAAGAGAGGGT  \\\n",
       "0          0           0                                           1   \n",
       "1          0           0                                           1   \n",
       "2          1           1                                           0   \n",
       "3          0           0                                           1   \n",
       "4          0           0                                           1   \n",
       "\n",
       "   GAACCATGGACATCATGTGAATTTGATTTTACAAGAGAGGGTAATTTGAAAGTATCGTTTGATTATATAGATTGGAT  \\\n",
       "0                                                  1                               \n",
       "1                                                  1                               \n",
       "2                                                  0                               \n",
       "3                                                  1                               \n",
       "4                                                  1                               \n",
       "\n",
       "   GAACCATGGACATCATGTGAATTTGATTTTACAAGAGAGGGTAATTTGAAAGTATCGTTTGATTATATAGATTGGATTAAATTAGGTTTTGGTCCATCAG  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  1                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   CCTTGTTGCGG  \\\n",
       "0            0   \n",
       "1            0   \n",
       "2            1   \n",
       "3            0   \n",
       "4            0   \n",
       "\n",
       "   CCTGATGGACCAAAACCTAATTTAATCCAATCTATATAATCAAACGATACTTTCAAATTACCCTCTCTTGTAAAATCAAATTCACATGATGTCCATGGTT  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  1                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   pheno  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(253, 15) (253,)\n"
     ]
    }
   ],
   "source": [
    "X = df.loc[:, df.columns != 'pheno']\n",
    "y = df['pheno']\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.ensemble.bagging module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.ensemble.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.ensemble.forest module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 217), (1, 217), (2, 217)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.utils.testing module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.utils. Anything that cannot be imported from sklearn.utils is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.metrics.classification module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# over-sampling\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "overS = RandomOverSampler(random_state=100)\n",
    "X_over, y_over = overS.fit_resample(X, y)\n",
    "print(sorted(Counter(y_over).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# Fully-Connected Neural Network ################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.regularizers import l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=123,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = pd.DataFrame(X_test_over[:,0])\n",
    "dat['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CFBRSa07</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CFBRSa66A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS112</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS211</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CFBRSa22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>NRS205</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>196 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0  test\n",
       "0     CFBRSa07     0\n",
       "1    CFBRSa66A     0\n",
       "2       NRS112     1\n",
       "3       NRS211     0\n",
       "4     CFBRSa22     0\n",
       "..         ...   ...\n",
       "191     NRS148     2\n",
       "192     NRS255     2\n",
       "193     NRS205     2\n",
       "194     NRS255     2\n",
       "195     NRS109     2\n",
       "\n",
       "[196 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### neural network on over-sampling data\n",
    "model1_over = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],)),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 455 samples, validate on 196 samples\n",
      "Epoch 1/100\n",
      "455/455 [==============================] - 0s 266us/step - loss: 1.0886 - accuracy: 0.4044 - val_loss: 1.0551 - val_accuracy: 0.4439\n",
      "Epoch 2/100\n",
      "455/455 [==============================] - 0s 78us/step - loss: 0.9936 - accuracy: 0.4681 - val_loss: 0.9743 - val_accuracy: 0.5459\n",
      "Epoch 3/100\n",
      "455/455 [==============================] - 0s 69us/step - loss: 0.9264 - accuracy: 0.5516 - val_loss: 0.9158 - val_accuracy: 0.5459\n",
      "Epoch 4/100\n",
      "455/455 [==============================] - 0s 70us/step - loss: 0.8773 - accuracy: 0.5736 - val_loss: 0.8719 - val_accuracy: 0.6173\n",
      "Epoch 5/100\n",
      "455/455 [==============================] - 0s 67us/step - loss: 0.8386 - accuracy: 0.6703 - val_loss: 0.8311 - val_accuracy: 0.6633\n",
      "Epoch 6/100\n",
      "455/455 [==============================] - 0s 75us/step - loss: 0.8040 - accuracy: 0.6967 - val_loss: 0.7999 - val_accuracy: 0.6786\n",
      "Epoch 7/100\n",
      "455/455 [==============================] - 0s 66us/step - loss: 0.7772 - accuracy: 0.7231 - val_loss: 0.7726 - val_accuracy: 0.7347\n",
      "Epoch 8/100\n",
      "455/455 [==============================] - 0s 67us/step - loss: 0.7527 - accuracy: 0.7385 - val_loss: 0.7477 - val_accuracy: 0.7449\n",
      "Epoch 9/100\n",
      "455/455 [==============================] - 0s 78us/step - loss: 0.7307 - accuracy: 0.7451 - val_loss: 0.7259 - val_accuracy: 0.7449\n",
      "Epoch 10/100\n",
      "455/455 [==============================] - 0s 65us/step - loss: 0.7100 - accuracy: 0.7407 - val_loss: 0.7049 - val_accuracy: 0.7398\n",
      "Epoch 11/100\n",
      "455/455 [==============================] - 0s 75us/step - loss: 0.6936 - accuracy: 0.7385 - val_loss: 0.6881 - val_accuracy: 0.7398\n",
      "Epoch 12/100\n",
      "455/455 [==============================] - 0s 68us/step - loss: 0.6784 - accuracy: 0.7385 - val_loss: 0.6716 - val_accuracy: 0.7449\n",
      "Epoch 13/100\n",
      "455/455 [==============================] - 0s 87us/step - loss: 0.6627 - accuracy: 0.7407 - val_loss: 0.6572 - val_accuracy: 0.7449\n",
      "Epoch 14/100\n",
      "455/455 [==============================] - 0s 85us/step - loss: 0.6493 - accuracy: 0.7429 - val_loss: 0.6431 - val_accuracy: 0.7449\n",
      "Epoch 15/100\n",
      "455/455 [==============================] - 0s 111us/step - loss: 0.6366 - accuracy: 0.7407 - val_loss: 0.6285 - val_accuracy: 0.7449\n",
      "Epoch 16/100\n",
      "455/455 [==============================] - 0s 90us/step - loss: 0.6235 - accuracy: 0.7451 - val_loss: 0.6152 - val_accuracy: 0.7704\n",
      "Epoch 17/100\n",
      "455/455 [==============================] - 0s 77us/step - loss: 0.6109 - accuracy: 0.7692 - val_loss: 0.6022 - val_accuracy: 0.7704\n",
      "Epoch 18/100\n",
      "455/455 [==============================] - 0s 87us/step - loss: 0.6003 - accuracy: 0.7714 - val_loss: 0.5898 - val_accuracy: 0.7704\n",
      "Epoch 19/100\n",
      "455/455 [==============================] - 0s 75us/step - loss: 0.5887 - accuracy: 0.7648 - val_loss: 0.5778 - val_accuracy: 0.7806\n",
      "Epoch 20/100\n",
      "455/455 [==============================] - 0s 75us/step - loss: 0.5787 - accuracy: 0.7692 - val_loss: 0.5675 - val_accuracy: 0.7704\n",
      "Epoch 21/100\n",
      "455/455 [==============================] - 0s 68us/step - loss: 0.5684 - accuracy: 0.7714 - val_loss: 0.5579 - val_accuracy: 0.7806\n",
      "Epoch 22/100\n",
      "455/455 [==============================] - 0s 72us/step - loss: 0.5586 - accuracy: 0.7692 - val_loss: 0.5488 - val_accuracy: 0.7704\n",
      "Epoch 23/100\n",
      "455/455 [==============================] - 0s 74us/step - loss: 0.5501 - accuracy: 0.7648 - val_loss: 0.5407 - val_accuracy: 0.7806\n",
      "Epoch 24/100\n",
      "455/455 [==============================] - 0s 82us/step - loss: 0.5414 - accuracy: 0.7692 - val_loss: 0.5313 - val_accuracy: 0.7704\n",
      "Epoch 25/100\n",
      "455/455 [==============================] - 0s 84us/step - loss: 0.5346 - accuracy: 0.7692 - val_loss: 0.5239 - val_accuracy: 0.7704\n",
      "Epoch 26/100\n",
      "455/455 [==============================] - 0s 83us/step - loss: 0.5266 - accuracy: 0.7692 - val_loss: 0.5171 - val_accuracy: 0.7704\n",
      "Epoch 27/100\n",
      "455/455 [==============================] - 0s 99us/step - loss: 0.5204 - accuracy: 0.7692 - val_loss: 0.5117 - val_accuracy: 0.7704\n",
      "Epoch 28/100\n",
      "455/455 [==============================] - 0s 86us/step - loss: 0.5135 - accuracy: 0.7648 - val_loss: 0.5039 - val_accuracy: 0.7704\n",
      "Epoch 29/100\n",
      "455/455 [==============================] - 0s 80us/step - loss: 0.5063 - accuracy: 0.7648 - val_loss: 0.4977 - val_accuracy: 0.7704\n",
      "Epoch 30/100\n",
      "455/455 [==============================] - 0s 70us/step - loss: 0.5013 - accuracy: 0.7670 - val_loss: 0.4916 - val_accuracy: 0.7704\n",
      "Epoch 31/100\n",
      "455/455 [==============================] - 0s 66us/step - loss: 0.4967 - accuracy: 0.7670 - val_loss: 0.4864 - val_accuracy: 0.7704\n",
      "Epoch 32/100\n",
      "455/455 [==============================] - 0s 69us/step - loss: 0.4907 - accuracy: 0.7714 - val_loss: 0.4807 - val_accuracy: 0.7755\n",
      "Epoch 33/100\n",
      "455/455 [==============================] - 0s 64us/step - loss: 0.4862 - accuracy: 0.7714 - val_loss: 0.4775 - val_accuracy: 0.7704\n",
      "Epoch 34/100\n",
      "455/455 [==============================] - 0s 107us/step - loss: 0.4817 - accuracy: 0.7714 - val_loss: 0.4731 - val_accuracy: 0.7755\n",
      "Epoch 35/100\n",
      "455/455 [==============================] - 0s 123us/step - loss: 0.4776 - accuracy: 0.7780 - val_loss: 0.4677 - val_accuracy: 0.7755\n",
      "Epoch 36/100\n",
      "455/455 [==============================] - 0s 66us/step - loss: 0.4733 - accuracy: 0.7824 - val_loss: 0.4635 - val_accuracy: 0.7857\n",
      "Epoch 37/100\n",
      "455/455 [==============================] - 0s 58us/step - loss: 0.4705 - accuracy: 0.7780 - val_loss: 0.4595 - val_accuracy: 0.7755\n",
      "Epoch 38/100\n",
      "455/455 [==============================] - 0s 60us/step - loss: 0.4653 - accuracy: 0.7780 - val_loss: 0.4565 - val_accuracy: 0.7755\n",
      "Epoch 39/100\n",
      "455/455 [==============================] - 0s 64us/step - loss: 0.4633 - accuracy: 0.7758 - val_loss: 0.4516 - val_accuracy: 0.7755\n",
      "Epoch 40/100\n",
      "455/455 [==============================] - 0s 75us/step - loss: 0.4591 - accuracy: 0.7780 - val_loss: 0.4497 - val_accuracy: 0.8265\n",
      "Epoch 41/100\n",
      "455/455 [==============================] - 0s 80us/step - loss: 0.4564 - accuracy: 0.7802 - val_loss: 0.4470 - val_accuracy: 0.8010\n",
      "Epoch 42/100\n",
      "455/455 [==============================] - 0s 103us/step - loss: 0.4535 - accuracy: 0.8088 - val_loss: 0.4436 - val_accuracy: 0.8214\n",
      "Epoch 43/100\n",
      "455/455 [==============================] - 0s 98us/step - loss: 0.4524 - accuracy: 0.8088 - val_loss: 0.4411 - val_accuracy: 0.8214\n",
      "Epoch 44/100\n",
      "455/455 [==============================] - 0s 97us/step - loss: 0.4485 - accuracy: 0.8110 - val_loss: 0.4381 - val_accuracy: 0.8214\n",
      "Epoch 45/100\n",
      "455/455 [==============================] - 0s 83us/step - loss: 0.4465 - accuracy: 0.8308 - val_loss: 0.4331 - val_accuracy: 0.8827\n",
      "Epoch 46/100\n",
      "455/455 [==============================] - 0s 83us/step - loss: 0.4424 - accuracy: 0.8440 - val_loss: 0.4326 - val_accuracy: 0.8724\n",
      "Epoch 47/100\n",
      "455/455 [==============================] - 0s 106us/step - loss: 0.4424 - accuracy: 0.8220 - val_loss: 0.4317 - val_accuracy: 0.8316\n",
      "Epoch 48/100\n",
      "455/455 [==============================] - 0s 74us/step - loss: 0.4380 - accuracy: 0.8264 - val_loss: 0.4287 - val_accuracy: 0.8724\n",
      "Epoch 49/100\n",
      "455/455 [==============================] - 0s 75us/step - loss: 0.4353 - accuracy: 0.8462 - val_loss: 0.4265 - val_accuracy: 0.8724\n",
      "Epoch 50/100\n",
      "455/455 [==============================] - 0s 56us/step - loss: 0.4327 - accuracy: 0.8505 - val_loss: 0.4228 - val_accuracy: 0.8724\n",
      "Epoch 51/100\n",
      "455/455 [==============================] - 0s 51us/step - loss: 0.4311 - accuracy: 0.8440 - val_loss: 0.4226 - val_accuracy: 0.8724\n",
      "Epoch 52/100\n",
      "455/455 [==============================] - 0s 51us/step - loss: 0.4288 - accuracy: 0.8505 - val_loss: 0.4205 - val_accuracy: 0.8724\n",
      "Epoch 53/100\n",
      "455/455 [==============================] - 0s 48us/step - loss: 0.4276 - accuracy: 0.8374 - val_loss: 0.4189 - val_accuracy: 0.8827\n",
      "Epoch 54/100\n",
      "455/455 [==============================] - 0s 62us/step - loss: 0.4254 - accuracy: 0.8484 - val_loss: 0.4154 - val_accuracy: 0.8827\n",
      "Epoch 55/100\n",
      "455/455 [==============================] - 0s 51us/step - loss: 0.4233 - accuracy: 0.8484 - val_loss: 0.4132 - val_accuracy: 0.8827\n",
      "Epoch 56/100\n",
      "455/455 [==============================] - 0s 57us/step - loss: 0.4213 - accuracy: 0.8484 - val_loss: 0.4125 - val_accuracy: 0.8827\n",
      "Epoch 57/100\n",
      "455/455 [==============================] - 0s 53us/step - loss: 0.4190 - accuracy: 0.8505 - val_loss: 0.4096 - val_accuracy: 0.8827\n",
      "Epoch 58/100\n",
      "455/455 [==============================] - 0s 83us/step - loss: 0.4172 - accuracy: 0.8484 - val_loss: 0.4081 - val_accuracy: 0.8724\n",
      "Epoch 59/100\n",
      "455/455 [==============================] - 0s 339us/step - loss: 0.4159 - accuracy: 0.8505 - val_loss: 0.4069 - val_accuracy: 0.8724\n",
      "Epoch 60/100\n",
      "455/455 [==============================] - 0s 129us/step - loss: 0.4135 - accuracy: 0.8484 - val_loss: 0.4051 - val_accuracy: 0.8827\n",
      "Epoch 61/100\n",
      "455/455 [==============================] - 0s 110us/step - loss: 0.4121 - accuracy: 0.8505 - val_loss: 0.4042 - val_accuracy: 0.8827\n",
      "Epoch 62/100\n",
      "455/455 [==============================] - 0s 125us/step - loss: 0.4120 - accuracy: 0.8462 - val_loss: 0.4035 - val_accuracy: 0.8827\n",
      "Epoch 63/100\n",
      "455/455 [==============================] - 0s 118us/step - loss: 0.4114 - accuracy: 0.8505 - val_loss: 0.4016 - val_accuracy: 0.8827\n",
      "Epoch 64/100\n",
      "455/455 [==============================] - 0s 139us/step - loss: 0.4079 - accuracy: 0.8505 - val_loss: 0.4009 - val_accuracy: 0.8827\n",
      "Epoch 65/100\n",
      "455/455 [==============================] - 0s 120us/step - loss: 0.4073 - accuracy: 0.8527 - val_loss: 0.3991 - val_accuracy: 0.8827\n",
      "Epoch 66/100\n",
      "455/455 [==============================] - 0s 125us/step - loss: 0.4051 - accuracy: 0.8527 - val_loss: 0.3984 - val_accuracy: 0.8827\n",
      "Epoch 67/100\n",
      "455/455 [==============================] - 0s 113us/step - loss: 0.4038 - accuracy: 0.8527 - val_loss: 0.3963 - val_accuracy: 0.8827\n",
      "Epoch 68/100\n",
      "455/455 [==============================] - 0s 140us/step - loss: 0.4035 - accuracy: 0.8549 - val_loss: 0.3961 - val_accuracy: 0.8724\n",
      "Epoch 69/100\n",
      "455/455 [==============================] - 0s 131us/step - loss: 0.4020 - accuracy: 0.8505 - val_loss: 0.3937 - val_accuracy: 0.8827\n",
      "Epoch 70/100\n",
      "455/455 [==============================] - 0s 140us/step - loss: 0.4013 - accuracy: 0.8527 - val_loss: 0.3945 - val_accuracy: 0.8827\n",
      "Epoch 71/100\n",
      "455/455 [==============================] - 0s 124us/step - loss: 0.3987 - accuracy: 0.8549 - val_loss: 0.3936 - val_accuracy: 0.8724\n",
      "Epoch 72/100\n",
      "455/455 [==============================] - 0s 127us/step - loss: 0.3983 - accuracy: 0.8505 - val_loss: 0.3918 - val_accuracy: 0.8827\n",
      "Epoch 73/100\n",
      "455/455 [==============================] - 0s 129us/step - loss: 0.3975 - accuracy: 0.8527 - val_loss: 0.3892 - val_accuracy: 0.8827\n",
      "Epoch 74/100\n",
      "455/455 [==============================] - 0s 126us/step - loss: 0.4001 - accuracy: 0.8527 - val_loss: 0.3879 - val_accuracy: 0.8827\n",
      "Epoch 75/100\n",
      "455/455 [==============================] - 0s 126us/step - loss: 0.3950 - accuracy: 0.8527 - val_loss: 0.3876 - val_accuracy: 0.8724\n",
      "Epoch 76/100\n",
      "455/455 [==============================] - 0s 118us/step - loss: 0.3951 - accuracy: 0.8527 - val_loss: 0.3884 - val_accuracy: 0.8827\n",
      "Epoch 77/100\n",
      "455/455 [==============================] - 0s 118us/step - loss: 0.3938 - accuracy: 0.8527 - val_loss: 0.3862 - val_accuracy: 0.8827\n",
      "Epoch 78/100\n",
      "455/455 [==============================] - 0s 127us/step - loss: 0.3924 - accuracy: 0.8527 - val_loss: 0.3877 - val_accuracy: 0.8827\n",
      "Epoch 79/100\n",
      "455/455 [==============================] - 0s 125us/step - loss: 0.3916 - accuracy: 0.8527 - val_loss: 0.3878 - val_accuracy: 0.8827\n",
      "Epoch 80/100\n",
      "455/455 [==============================] - 0s 70us/step - loss: 0.3919 - accuracy: 0.8549 - val_loss: 0.3850 - val_accuracy: 0.8827\n",
      "Epoch 81/100\n",
      "455/455 [==============================] - 0s 59us/step - loss: 0.3911 - accuracy: 0.8527 - val_loss: 0.3860 - val_accuracy: 0.8827\n",
      "Epoch 82/100\n",
      "455/455 [==============================] - 0s 53us/step - loss: 0.3895 - accuracy: 0.8527 - val_loss: 0.3850 - val_accuracy: 0.8827\n",
      "Epoch 83/100\n",
      "455/455 [==============================] - 0s 53us/step - loss: 0.3877 - accuracy: 0.8527 - val_loss: 0.3849 - val_accuracy: 0.8827\n",
      "Epoch 84/100\n",
      "455/455 [==============================] - 0s 50us/step - loss: 0.3888 - accuracy: 0.8527 - val_loss: 0.3829 - val_accuracy: 0.8827\n",
      "Epoch 85/100\n",
      "455/455 [==============================] - 0s 56us/step - loss: 0.3867 - accuracy: 0.8505 - val_loss: 0.3837 - val_accuracy: 0.8724\n",
      "Epoch 86/100\n",
      "455/455 [==============================] - 0s 51us/step - loss: 0.3862 - accuracy: 0.8549 - val_loss: 0.3826 - val_accuracy: 0.8827\n",
      "Epoch 87/100\n",
      "455/455 [==============================] - 0s 53us/step - loss: 0.3848 - accuracy: 0.8527 - val_loss: 0.3820 - val_accuracy: 0.8827\n",
      "Epoch 88/100\n",
      "455/455 [==============================] - 0s 58us/step - loss: 0.3844 - accuracy: 0.8527 - val_loss: 0.3814 - val_accuracy: 0.8827\n",
      "Epoch 89/100\n",
      "455/455 [==============================] - 0s 51us/step - loss: 0.3836 - accuracy: 0.8527 - val_loss: 0.3806 - val_accuracy: 0.8827\n",
      "Epoch 90/100\n",
      "455/455 [==============================] - 0s 56us/step - loss: 0.3841 - accuracy: 0.8549 - val_loss: 0.3806 - val_accuracy: 0.8827\n",
      "Epoch 91/100\n",
      "455/455 [==============================] - 0s 91us/step - loss: 0.3839 - accuracy: 0.8549 - val_loss: 0.3800 - val_accuracy: 0.8827\n",
      "Epoch 92/100\n",
      "455/455 [==============================] - 0s 161us/step - loss: 0.3815 - accuracy: 0.8527 - val_loss: 0.3789 - val_accuracy: 0.8827\n",
      "Epoch 93/100\n",
      "455/455 [==============================] - 0s 137us/step - loss: 0.3823 - accuracy: 0.8527 - val_loss: 0.3762 - val_accuracy: 0.8827\n",
      "Epoch 94/100\n",
      "455/455 [==============================] - 0s 154us/step - loss: 0.3819 - accuracy: 0.8527 - val_loss: 0.3759 - val_accuracy: 0.8827\n",
      "Epoch 95/100\n",
      "455/455 [==============================] - 0s 128us/step - loss: 0.3801 - accuracy: 0.8527 - val_loss: 0.3768 - val_accuracy: 0.8827\n",
      "Epoch 96/100\n",
      "455/455 [==============================] - 0s 96us/step - loss: 0.3792 - accuracy: 0.8527 - val_loss: 0.3752 - val_accuracy: 0.8827\n",
      "Epoch 97/100\n",
      "455/455 [==============================] - 0s 70us/step - loss: 0.3787 - accuracy: 0.8527 - val_loss: 0.3762 - val_accuracy: 0.8827\n",
      "Epoch 98/100\n",
      "455/455 [==============================] - 0s 78us/step - loss: 0.3787 - accuracy: 0.8527 - val_loss: 0.3752 - val_accuracy: 0.8827\n",
      "Epoch 99/100\n",
      "455/455 [==============================] - 0s 100us/step - loss: 0.3781 - accuracy: 0.8571 - val_loss: 0.3766 - val_accuracy: 0.8827\n",
      "Epoch 100/100\n",
      "455/455 [==============================] - 0s 146us/step - loss: 0.3767 - accuracy: 0.8571 - val_loss: 0.3741 - val_accuracy: 0.8827\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a3ded9198>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196/196 [==============================] - 0s 47us/step\n",
      "over-sampling test accuracy: 88.27%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over = model1_over.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 0, 1, 0, 0, 2, 1, 0, 0, 1, 2, 0, 0, 1, 0, 0, 1, 1, 0,\n",
       "       0, 1, 0, 2, 0, 0, 0, 2, 2, 0, 2, 0, 0, 0, 2, 2, 2, 2, 0, 0, 0, 0,\n",
       "       0, 1, 0, 1, 1, 2, 2, 2, 2, 1, 1, 0, 0, 1, 1, 1, 2, 1, 0, 2, 1, 1,\n",
       "       0, 1, 2, 1, 0, 1, 2, 2, 2, 0, 1, 2, 0, 1, 0, 0, 0, 1, 0, 1, 2, 0,\n",
       "       0, 0, 0, 1, 0, 2, 2, 2, 2, 2, 1, 1, 2, 0, 0, 0, 1, 2, 0, 0, 2, 1,\n",
       "       0, 2, 0, 2, 1, 2, 2, 1, 1, 2, 1, 2, 2, 2, 2, 1, 1, 0, 2, 1, 0, 1,\n",
       "       0, 2, 2, 0, 2, 0, 0, 0, 2, 1, 0, 2, 1, 0, 0, 2, 2, 1, 0, 2, 2, 2,\n",
       "       2, 2, 2, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 2, 0, 2, 2, 2, 2, 2,\n",
       "       2, 1, 2, 1, 0, 2, 0, 2, 2, 2, 2, 1, 2, 2, 0, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model1_over.predict_classes(X_test_over)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CFBRSa07</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CFBRSa66A</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS112</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS211</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CFBRSa22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>NRS205</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>196 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0  test  pred\n",
       "0     CFBRSa07     0     1\n",
       "1    CFBRSa66A     0     0\n",
       "2       NRS112     1     1\n",
       "3       NRS211     0     0\n",
       "4     CFBRSa22     0     0\n",
       "..         ...   ...   ...\n",
       "191     NRS148     2     2\n",
       "192     NRS255     2     2\n",
       "193     NRS205     2     2\n",
       "194     NRS255     2     2\n",
       "195     NRS109     2     2\n",
       "\n",
       "[196 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat['pred'] = pred\n",
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba1 = model1_over.predict_proba(X_test_over)\n",
    "dat_proba1 = pd.DataFrame(proba1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.265483</td>\n",
       "      <td>0.734014</td>\n",
       "      <td>0.000503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.858843</td>\n",
       "      <td>0.141141</td>\n",
       "      <td>0.000016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.003340</td>\n",
       "      <td>0.924840</td>\n",
       "      <td>0.071820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.585653</td>\n",
       "      <td>0.410576</td>\n",
       "      <td>0.003771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.858843</td>\n",
       "      <td>0.141141</td>\n",
       "      <td>0.000016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>0.002040</td>\n",
       "      <td>0.051028</td>\n",
       "      <td>0.946932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>0.020451</td>\n",
       "      <td>0.027734</td>\n",
       "      <td>0.951815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>0.002040</td>\n",
       "      <td>0.051028</td>\n",
       "      <td>0.946932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>0.020451</td>\n",
       "      <td>0.027734</td>\n",
       "      <td>0.951815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.010380</td>\n",
       "      <td>0.109148</td>\n",
       "      <td>0.880472</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>196 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2\n",
       "0    0.265483  0.734014  0.000503\n",
       "1    0.858843  0.141141  0.000016\n",
       "2    0.003340  0.924840  0.071820\n",
       "3    0.585653  0.410576  0.003771\n",
       "4    0.858843  0.141141  0.000016\n",
       "..        ...       ...       ...\n",
       "191  0.002040  0.051028  0.946932\n",
       "192  0.020451  0.027734  0.951815\n",
       "193  0.002040  0.051028  0.946932\n",
       "194  0.020451  0.027734  0.951815\n",
       "195  0.010380  0.109148  0.880472\n",
       "\n",
       "[196 rows x 3 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba1.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba1.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/1pyo.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 455 samples, validate on 196 samples\n",
      "Epoch 1/100\n",
      "455/455 [==============================] - 0s 110us/step - loss: 0.3763 - accuracy: 0.8571 - val_loss: 0.3725 - val_accuracy: 0.8827\n",
      "Epoch 2/100\n",
      "455/455 [==============================] - 0s 95us/step - loss: 0.3764 - accuracy: 0.8571 - val_loss: 0.3713 - val_accuracy: 0.8827\n",
      "Epoch 3/100\n",
      "455/455 [==============================] - 0s 103us/step - loss: 0.3761 - accuracy: 0.8352 - val_loss: 0.3725 - val_accuracy: 0.8827\n",
      "Epoch 4/100\n",
      "455/455 [==============================] - 0s 110us/step - loss: 0.3774 - accuracy: 0.8571 - val_loss: 0.3705 - val_accuracy: 0.8827\n",
      "Epoch 5/100\n",
      "455/455 [==============================] - 0s 97us/step - loss: 0.3755 - accuracy: 0.8571 - val_loss: 0.3734 - val_accuracy: 0.8827\n",
      "Epoch 6/100\n",
      "455/455 [==============================] - 0s 66us/step - loss: 0.3744 - accuracy: 0.8571 - val_loss: 0.3721 - val_accuracy: 0.8827\n",
      "Epoch 7/100\n",
      "455/455 [==============================] - 0s 64us/step - loss: 0.3739 - accuracy: 0.8571 - val_loss: 0.3708 - val_accuracy: 0.8827\n",
      "Epoch 8/100\n",
      "455/455 [==============================] - 0s 58us/step - loss: 0.3731 - accuracy: 0.8571 - val_loss: 0.3695 - val_accuracy: 0.8827\n",
      "Epoch 9/100\n",
      "455/455 [==============================] - 0s 73us/step - loss: 0.3731 - accuracy: 0.8571 - val_loss: 0.3684 - val_accuracy: 0.8827\n",
      "Epoch 10/100\n",
      "455/455 [==============================] - 0s 71us/step - loss: 0.3726 - accuracy: 0.8571 - val_loss: 0.3678 - val_accuracy: 0.8827\n",
      "Epoch 11/100\n",
      "455/455 [==============================] - 0s 65us/step - loss: 0.3735 - accuracy: 0.8571 - val_loss: 0.3661 - val_accuracy: 0.8827\n",
      "Epoch 12/100\n",
      "455/455 [==============================] - 0s 67us/step - loss: 0.3718 - accuracy: 0.8571 - val_loss: 0.3691 - val_accuracy: 0.8827\n",
      "Epoch 13/100\n",
      "455/455 [==============================] - 0s 88us/step - loss: 0.3712 - accuracy: 0.8571 - val_loss: 0.3715 - val_accuracy: 0.8827\n",
      "Epoch 14/100\n",
      "455/455 [==============================] - 0s 99us/step - loss: 0.3709 - accuracy: 0.8571 - val_loss: 0.3709 - val_accuracy: 0.8827\n",
      "Epoch 15/100\n",
      "455/455 [==============================] - 0s 79us/step - loss: 0.3716 - accuracy: 0.8527 - val_loss: 0.3688 - val_accuracy: 0.8827\n",
      "Epoch 16/100\n",
      "455/455 [==============================] - 0s 83us/step - loss: 0.3704 - accuracy: 0.8571 - val_loss: 0.3681 - val_accuracy: 0.8827\n",
      "Epoch 17/100\n",
      "455/455 [==============================] - 0s 68us/step - loss: 0.3699 - accuracy: 0.8571 - val_loss: 0.3669 - val_accuracy: 0.8827\n",
      "Epoch 18/100\n",
      "455/455 [==============================] - 0s 66us/step - loss: 0.3694 - accuracy: 0.8571 - val_loss: 0.3664 - val_accuracy: 0.8827\n",
      "Epoch 19/100\n",
      "455/455 [==============================] - 0s 67us/step - loss: 0.3691 - accuracy: 0.8571 - val_loss: 0.3666 - val_accuracy: 0.8827\n",
      "Epoch 20/100\n",
      "455/455 [==============================] - 0s 64us/step - loss: 0.3688 - accuracy: 0.8571 - val_loss: 0.3649 - val_accuracy: 0.8827\n",
      "Epoch 21/100\n",
      "455/455 [==============================] - 0s 72us/step - loss: 0.3686 - accuracy: 0.8571 - val_loss: 0.3665 - val_accuracy: 0.8827\n",
      "Epoch 22/100\n",
      "455/455 [==============================] - 0s 71us/step - loss: 0.3690 - accuracy: 0.8571 - val_loss: 0.3666 - val_accuracy: 0.8827\n",
      "Epoch 23/100\n",
      "455/455 [==============================] - 0s 67us/step - loss: 0.3673 - accuracy: 0.8571 - val_loss: 0.3674 - val_accuracy: 0.8827\n",
      "Epoch 24/100\n",
      "455/455 [==============================] - 0s 71us/step - loss: 0.3682 - accuracy: 0.8571 - val_loss: 0.3648 - val_accuracy: 0.8827\n",
      "Epoch 25/100\n",
      "455/455 [==============================] - 0s 70us/step - loss: 0.3673 - accuracy: 0.8571 - val_loss: 0.3644 - val_accuracy: 0.8827\n",
      "Epoch 26/100\n",
      "455/455 [==============================] - 0s 69us/step - loss: 0.3679 - accuracy: 0.8571 - val_loss: 0.3671 - val_accuracy: 0.8827\n",
      "Epoch 27/100\n",
      "455/455 [==============================] - 0s 65us/step - loss: 0.3665 - accuracy: 0.8571 - val_loss: 0.3661 - val_accuracy: 0.8827\n",
      "Epoch 28/100\n",
      "455/455 [==============================] - 0s 78us/step - loss: 0.3659 - accuracy: 0.8571 - val_loss: 0.3650 - val_accuracy: 0.8827\n",
      "Epoch 29/100\n",
      "455/455 [==============================] - 0s 68us/step - loss: 0.3666 - accuracy: 0.8571 - val_loss: 0.3653 - val_accuracy: 0.8827\n",
      "Epoch 30/100\n",
      "455/455 [==============================] - 0s 76us/step - loss: 0.3654 - accuracy: 0.8571 - val_loss: 0.3659 - val_accuracy: 0.8827\n",
      "Epoch 31/100\n",
      "455/455 [==============================] - 0s 118us/step - loss: 0.3676 - accuracy: 0.8527 - val_loss: 0.3639 - val_accuracy: 0.8827\n",
      "Epoch 32/100\n",
      "455/455 [==============================] - 0s 145us/step - loss: 0.3660 - accuracy: 0.8571 - val_loss: 0.3616 - val_accuracy: 0.8827\n",
      "Epoch 33/100\n",
      "455/455 [==============================] - 0s 93us/step - loss: 0.3670 - accuracy: 0.8571 - val_loss: 0.3666 - val_accuracy: 0.8827\n",
      "Epoch 34/100\n",
      "455/455 [==============================] - 0s 46us/step - loss: 0.3663 - accuracy: 0.8571 - val_loss: 0.3656 - val_accuracy: 0.8827\n",
      "Epoch 35/100\n",
      "455/455 [==============================] - 0s 118us/step - loss: 0.3650 - accuracy: 0.8571 - val_loss: 0.3641 - val_accuracy: 0.8827\n",
      "Epoch 36/100\n",
      "455/455 [==============================] - 0s 106us/step - loss: 0.3641 - accuracy: 0.8571 - val_loss: 0.3659 - val_accuracy: 0.8827\n",
      "Epoch 37/100\n",
      "455/455 [==============================] - 0s 89us/step - loss: 0.3649 - accuracy: 0.8571 - val_loss: 0.3688 - val_accuracy: 0.8827\n",
      "Epoch 38/100\n",
      "455/455 [==============================] - 0s 76us/step - loss: 0.3653 - accuracy: 0.8571 - val_loss: 0.3663 - val_accuracy: 0.8827\n",
      "Epoch 39/100\n",
      "455/455 [==============================] - 0s 88us/step - loss: 0.3642 - accuracy: 0.8571 - val_loss: 0.3646 - val_accuracy: 0.8827\n",
      "Epoch 40/100\n",
      "455/455 [==============================] - 0s 88us/step - loss: 0.3645 - accuracy: 0.8571 - val_loss: 0.3661 - val_accuracy: 0.8827\n",
      "Epoch 41/100\n",
      "455/455 [==============================] - 0s 86us/step - loss: 0.3633 - accuracy: 0.8571 - val_loss: 0.3642 - val_accuracy: 0.8827\n",
      "Epoch 42/100\n",
      "455/455 [==============================] - 0s 87us/step - loss: 0.3644 - accuracy: 0.8571 - val_loss: 0.3643 - val_accuracy: 0.8827\n",
      "Epoch 43/100\n",
      "455/455 [==============================] - 0s 85us/step - loss: 0.3623 - accuracy: 0.8571 - val_loss: 0.3634 - val_accuracy: 0.8827\n",
      "Epoch 44/100\n",
      "455/455 [==============================] - 0s 82us/step - loss: 0.3627 - accuracy: 0.8571 - val_loss: 0.3603 - val_accuracy: 0.8827\n",
      "Epoch 45/100\n",
      "455/455 [==============================] - 0s 77us/step - loss: 0.3621 - accuracy: 0.8571 - val_loss: 0.3599 - val_accuracy: 0.8827\n",
      "Epoch 46/100\n",
      "455/455 [==============================] - 0s 288us/step - loss: 0.3631 - accuracy: 0.8571 - val_loss: 0.3637 - val_accuracy: 0.8827\n",
      "Epoch 47/100\n",
      "455/455 [==============================] - 0s 107us/step - loss: 0.3618 - accuracy: 0.8571 - val_loss: 0.3619 - val_accuracy: 0.8827\n",
      "Epoch 48/100\n",
      "455/455 [==============================] - 0s 116us/step - loss: 0.3618 - accuracy: 0.8571 - val_loss: 0.3619 - val_accuracy: 0.8827\n",
      "Epoch 49/100\n",
      "455/455 [==============================] - 0s 71us/step - loss: 0.3617 - accuracy: 0.8571 - val_loss: 0.3613 - val_accuracy: 0.8827\n",
      "Epoch 50/100\n",
      "455/455 [==============================] - 0s 67us/step - loss: 0.3612 - accuracy: 0.8571 - val_loss: 0.3603 - val_accuracy: 0.8827\n",
      "Epoch 51/100\n",
      "455/455 [==============================] - 0s 60us/step - loss: 0.3619 - accuracy: 0.8571 - val_loss: 0.3628 - val_accuracy: 0.8827\n",
      "Epoch 52/100\n",
      "455/455 [==============================] - 0s 90us/step - loss: 0.3620 - accuracy: 0.8571 - val_loss: 0.3623 - val_accuracy: 0.8827\n",
      "Epoch 53/100\n",
      "455/455 [==============================] - 0s 56us/step - loss: 0.3617 - accuracy: 0.8549 - val_loss: 0.3658 - val_accuracy: 0.8827\n",
      "Epoch 54/100\n",
      "455/455 [==============================] - 0s 54us/step - loss: 0.3619 - accuracy: 0.8571 - val_loss: 0.3626 - val_accuracy: 0.8827\n",
      "Epoch 55/100\n",
      "455/455 [==============================] - 0s 54us/step - loss: 0.3608 - accuracy: 0.8571 - val_loss: 0.3625 - val_accuracy: 0.8827\n",
      "Epoch 56/100\n",
      "455/455 [==============================] - 0s 56us/step - loss: 0.3597 - accuracy: 0.8571 - val_loss: 0.3618 - val_accuracy: 0.8827\n",
      "Epoch 57/100\n",
      "455/455 [==============================] - 0s 54us/step - loss: 0.3599 - accuracy: 0.8571 - val_loss: 0.3611 - val_accuracy: 0.8827\n",
      "Epoch 58/100\n",
      "455/455 [==============================] - 0s 56us/step - loss: 0.3606 - accuracy: 0.8571 - val_loss: 0.3607 - val_accuracy: 0.8827\n",
      "Epoch 59/100\n",
      "455/455 [==============================] - 0s 58us/step - loss: 0.3594 - accuracy: 0.8571 - val_loss: 0.3615 - val_accuracy: 0.8827\n",
      "Epoch 60/100\n",
      "455/455 [==============================] - 0s 60us/step - loss: 0.3595 - accuracy: 0.8571 - val_loss: 0.3611 - val_accuracy: 0.8827\n",
      "Epoch 61/100\n",
      "455/455 [==============================] - 0s 111us/step - loss: 0.3585 - accuracy: 0.8571 - val_loss: 0.3579 - val_accuracy: 0.8827\n",
      "Epoch 62/100\n",
      "455/455 [==============================] - 0s 67us/step - loss: 0.3598 - accuracy: 0.8571 - val_loss: 0.3595 - val_accuracy: 0.8827\n",
      "Epoch 63/100\n",
      "455/455 [==============================] - 0s 62us/step - loss: 0.3586 - accuracy: 0.8571 - val_loss: 0.3607 - val_accuracy: 0.8827\n",
      "Epoch 64/100\n",
      "455/455 [==============================] - 0s 68us/step - loss: 0.3588 - accuracy: 0.8571 - val_loss: 0.3581 - val_accuracy: 0.8827\n",
      "Epoch 65/100\n",
      "455/455 [==============================] - 0s 58us/step - loss: 0.3591 - accuracy: 0.8571 - val_loss: 0.3593 - val_accuracy: 0.8827\n",
      "Epoch 66/100\n",
      "455/455 [==============================] - 0s 59us/step - loss: 0.3593 - accuracy: 0.8571 - val_loss: 0.3612 - val_accuracy: 0.8827\n",
      "Epoch 67/100\n",
      "455/455 [==============================] - 0s 56us/step - loss: 0.3599 - accuracy: 0.8571 - val_loss: 0.3645 - val_accuracy: 0.8827\n",
      "Epoch 68/100\n",
      "455/455 [==============================] - 0s 55us/step - loss: 0.3601 - accuracy: 0.8571 - val_loss: 0.3649 - val_accuracy: 0.8827\n",
      "Epoch 69/100\n",
      "455/455 [==============================] - 0s 64us/step - loss: 0.3580 - accuracy: 0.8571 - val_loss: 0.3618 - val_accuracy: 0.8827\n",
      "Epoch 70/100\n",
      "455/455 [==============================] - 0s 59us/step - loss: 0.3576 - accuracy: 0.8571 - val_loss: 0.3602 - val_accuracy: 0.8827\n",
      "Epoch 71/100\n",
      "455/455 [==============================] - 0s 56us/step - loss: 0.3580 - accuracy: 0.8571 - val_loss: 0.3593 - val_accuracy: 0.8827\n",
      "Epoch 72/100\n",
      "455/455 [==============================] - 0s 54us/step - loss: 0.3575 - accuracy: 0.8571 - val_loss: 0.3575 - val_accuracy: 0.8827\n",
      "Epoch 73/100\n",
      "455/455 [==============================] - 0s 53us/step - loss: 0.3573 - accuracy: 0.8571 - val_loss: 0.3591 - val_accuracy: 0.8827\n",
      "Epoch 74/100\n",
      "455/455 [==============================] - 0s 58us/step - loss: 0.3570 - accuracy: 0.8571 - val_loss: 0.3598 - val_accuracy: 0.8827\n",
      "Epoch 75/100\n",
      "455/455 [==============================] - 0s 57us/step - loss: 0.3564 - accuracy: 0.8571 - val_loss: 0.3594 - val_accuracy: 0.8827\n",
      "Epoch 76/100\n",
      "455/455 [==============================] - 0s 60us/step - loss: 0.3572 - accuracy: 0.8571 - val_loss: 0.3594 - val_accuracy: 0.8827\n",
      "Epoch 77/100\n",
      "455/455 [==============================] - 0s 62us/step - loss: 0.3563 - accuracy: 0.8571 - val_loss: 0.3594 - val_accuracy: 0.8827\n",
      "Epoch 78/100\n",
      "455/455 [==============================] - 0s 61us/step - loss: 0.3570 - accuracy: 0.8571 - val_loss: 0.3593 - val_accuracy: 0.8827\n",
      "Epoch 79/100\n",
      "455/455 [==============================] - 0s 70us/step - loss: 0.3567 - accuracy: 0.8571 - val_loss: 0.3597 - val_accuracy: 0.8827\n",
      "Epoch 80/100\n",
      "455/455 [==============================] - 0s 63us/step - loss: 0.3562 - accuracy: 0.8571 - val_loss: 0.3584 - val_accuracy: 0.8827\n",
      "Epoch 81/100\n",
      "455/455 [==============================] - 0s 67us/step - loss: 0.3563 - accuracy: 0.8571 - val_loss: 0.3580 - val_accuracy: 0.8827\n",
      "Epoch 82/100\n",
      "455/455 [==============================] - 0s 64us/step - loss: 0.3551 - accuracy: 0.8571 - val_loss: 0.3588 - val_accuracy: 0.8827\n",
      "Epoch 83/100\n",
      "455/455 [==============================] - 0s 61us/step - loss: 0.3554 - accuracy: 0.8571 - val_loss: 0.3586 - val_accuracy: 0.8827\n",
      "Epoch 84/100\n",
      "455/455 [==============================] - 0s 62us/step - loss: 0.3556 - accuracy: 0.8571 - val_loss: 0.3582 - val_accuracy: 0.8827\n",
      "Epoch 85/100\n",
      "455/455 [==============================] - 0s 56us/step - loss: 0.3552 - accuracy: 0.8571 - val_loss: 0.3582 - val_accuracy: 0.8827\n",
      "Epoch 86/100\n",
      "455/455 [==============================] - 0s 56us/step - loss: 0.3553 - accuracy: 0.8571 - val_loss: 0.3595 - val_accuracy: 0.8827\n",
      "Epoch 87/100\n",
      "455/455 [==============================] - 0s 55us/step - loss: 0.3554 - accuracy: 0.8571 - val_loss: 0.3614 - val_accuracy: 0.8827\n",
      "Epoch 88/100\n",
      "455/455 [==============================] - 0s 54us/step - loss: 0.3555 - accuracy: 0.8571 - val_loss: 0.3586 - val_accuracy: 0.8827\n",
      "Epoch 89/100\n",
      "455/455 [==============================] - 0s 70us/step - loss: 0.3551 - accuracy: 0.8571 - val_loss: 0.3592 - val_accuracy: 0.8827\n",
      "Epoch 90/100\n",
      "455/455 [==============================] - 0s 64us/step - loss: 0.3550 - accuracy: 0.8571 - val_loss: 0.3603 - val_accuracy: 0.8827\n",
      "Epoch 91/100\n",
      "455/455 [==============================] - 0s 60us/step - loss: 0.3554 - accuracy: 0.8571 - val_loss: 0.3589 - val_accuracy: 0.8827\n",
      "Epoch 92/100\n",
      "455/455 [==============================] - 0s 72us/step - loss: 0.3547 - accuracy: 0.8571 - val_loss: 0.3595 - val_accuracy: 0.8827\n",
      "Epoch 93/100\n",
      "455/455 [==============================] - 0s 62us/step - loss: 0.3542 - accuracy: 0.8571 - val_loss: 0.3595 - val_accuracy: 0.8827\n",
      "Epoch 94/100\n",
      "455/455 [==============================] - 0s 69us/step - loss: 0.3554 - accuracy: 0.8571 - val_loss: 0.3619 - val_accuracy: 0.8827\n",
      "Epoch 95/100\n",
      "455/455 [==============================] - 0s 78us/step - loss: 0.3536 - accuracy: 0.8571 - val_loss: 0.3587 - val_accuracy: 0.8827\n",
      "Epoch 96/100\n",
      "455/455 [==============================] - 0s 61us/step - loss: 0.3538 - accuracy: 0.8571 - val_loss: 0.3591 - val_accuracy: 0.8827\n",
      "Epoch 97/100\n",
      "455/455 [==============================] - 0s 67us/step - loss: 0.3542 - accuracy: 0.8571 - val_loss: 0.3618 - val_accuracy: 0.8827\n",
      "Epoch 98/100\n",
      "455/455 [==============================] - 0s 64us/step - loss: 0.3530 - accuracy: 0.8571 - val_loss: 0.3590 - val_accuracy: 0.8827\n",
      "Epoch 99/100\n",
      "455/455 [==============================] - 0s 67us/step - loss: 0.3533 - accuracy: 0.8593 - val_loss: 0.3574 - val_accuracy: 0.8827\n",
      "Epoch 100/100\n",
      "455/455 [==============================] - 0s 65us/step - loss: 0.3531 - accuracy: 0.8593 - val_loss: 0.3576 - val_accuracy: 0.8827\n"
     ]
    }
   ],
   "source": [
    "hist1_over = model1_over.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 85.69%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_2.xlsx\",\n",
    "                        sheet_name=0,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>CFBRSa26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.758914</td>\n",
       "      <td>0.241086</td>\n",
       "      <td>4.638713e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.005361</td>\n",
       "      <td>0.016236</td>\n",
       "      <td>9.784034e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS112</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.726623</td>\n",
       "      <td>0.273376</td>\n",
       "      <td>1.520979e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS216</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.138322</td>\n",
       "      <td>0.861665</td>\n",
       "      <td>1.334123e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS021</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.882176</td>\n",
       "      <td>0.117824</td>\n",
       "      <td>1.414530e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4279</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>9.998934e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4280</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.002048</td>\n",
       "      <td>9.976944e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4281</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS205</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>9.999435e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4282</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.002048</td>\n",
       "      <td>9.976944e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4283</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.000929</td>\n",
       "      <td>9.989737e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4284 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    phage    strain  phenotype  prediction         0  \\\n",
       "0      p002ykpresabs_qual  CFBRSa26          0           0  0.758914   \n",
       "1      p002ykpresabs_qual    NRS109          2           2  0.005361   \n",
       "2      p002ykpresabs_qual    NRS112          0           0  0.726623   \n",
       "3      p002ykpresabs_qual    NRS216          1           1  0.138322   \n",
       "4      p002ykpresabs_qual    NRS021          0           0  0.882176   \n",
       "...                   ...       ...        ...         ...       ...   \n",
       "4279  pyopresabsSTCC_qual    NRS148          2           2  0.000007   \n",
       "4280  pyopresabsSTCC_qual    NRS255          2           2  0.000257   \n",
       "4281  pyopresabsSTCC_qual    NRS205          2           2  0.000011   \n",
       "4282  pyopresabsSTCC_qual    NRS255          2           2  0.000257   \n",
       "4283  pyopresabsSTCC_qual    NRS109          2           2  0.000097   \n",
       "\n",
       "             1             2  \n",
       "0     0.241086  4.638713e-07  \n",
       "1     0.016236  9.784034e-01  \n",
       "2     0.273376  1.520979e-06  \n",
       "3     0.861665  1.334123e-05  \n",
       "4     0.117824  1.414530e-10  \n",
       "...        ...           ...  \n",
       "4279  0.000099  9.998934e-01  \n",
       "4280  0.002048  9.976944e-01  \n",
       "4281  0.000045  9.999435e-01  \n",
       "4282  0.002048  9.976944e-01  \n",
       "4283  0.000929  9.989737e-01  \n",
       "\n",
       "[4284 rows x 7 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.65482600e-01, 7.34014000e-01, 5.03491700e-04],\n",
       "       [8.58843450e-01, 1.41141010e-01, 1.55746110e-05],\n",
       "       [3.34019240e-03, 9.24840030e-01, 7.18197100e-02],\n",
       "       [5.85653000e-01, 4.10576280e-01, 3.77069250e-03],\n",
       "       [8.58843450e-01, 1.41141010e-01, 1.55746110e-05],\n",
       "       [3.08219970e-01, 6.90642700e-01, 1.13732110e-03],\n",
       "       [6.99526250e-01, 2.90807460e-01, 9.66635400e-03],\n",
       "       [6.99526250e-01, 2.90807460e-01, 9.66635400e-03],\n",
       "       [2.03958320e-03, 5.10278750e-02, 9.46932500e-01],\n",
       "       [2.65482600e-01, 7.34014000e-01, 5.03491700e-04],\n",
       "       [8.58843450e-01, 1.41141010e-01, 1.55746110e-05],\n",
       "       [8.58843450e-01, 1.41141010e-01, 1.55746110e-05],\n",
       "       [1.36437710e-01, 8.58879500e-01, 4.68287150e-03],\n",
       "       [2.03958320e-03, 5.10278750e-02, 9.46932500e-01],\n",
       "       [6.99526250e-01, 2.90807460e-01, 9.66635400e-03],\n",
       "       [8.58843450e-01, 1.41141010e-01, 1.55746110e-05],\n",
       "       [3.84846330e-01, 6.15148500e-01, 5.24299200e-06],\n",
       "       [8.58843450e-01, 1.41141010e-01, 1.55746110e-05],\n",
       "       [6.99526250e-01, 2.90807460e-01, 9.66635400e-03],\n",
       "       [1.36437710e-01, 8.58879500e-01, 4.68287150e-03],\n",
       "       [1.43690750e-01, 8.43325700e-01, 1.29834910e-02],\n",
       "       [8.58843450e-01, 1.41141010e-01, 1.55746110e-05],\n",
       "       [8.58843450e-01, 1.41141010e-01, 1.55746110e-05],\n",
       "       [2.65482600e-01, 7.34014000e-01, 5.03491700e-04],\n",
       "       [5.12043100e-01, 4.86037140e-01, 1.91972220e-03],\n",
       "       [2.04505270e-02, 2.77339240e-02, 9.51815500e-01],\n",
       "       [6.99526250e-01, 2.90807460e-01, 9.66635400e-03],\n",
       "       [8.58843450e-01, 1.41141010e-01, 1.55746110e-05],\n",
       "       [8.58843450e-01, 1.41141010e-01, 1.55746110e-05],\n",
       "       [2.03958320e-03, 5.10278750e-02, 9.46932500e-01],\n",
       "       [2.04505270e-02, 2.77339240e-02, 9.51815500e-01],\n",
       "       [5.85653000e-01, 4.10576280e-01, 3.77069250e-03],\n",
       "       [2.03958320e-03, 5.10278750e-02, 9.46932500e-01],\n",
       "       [8.58843450e-01, 1.41141010e-01, 1.55746110e-05],\n",
       "       [8.58843450e-01, 1.41141010e-01, 1.55746110e-05],\n",
       "       [8.58843450e-01, 1.41141010e-01, 1.55746110e-05],\n",
       "       [1.03797040e-02, 1.09147990e-01, 8.80472240e-01],\n",
       "       [1.03797040e-02, 1.09147990e-01, 8.80472240e-01],\n",
       "       [2.03958320e-03, 5.10278750e-02, 9.46932500e-01],\n",
       "       [1.03797040e-02, 1.09147990e-01, 8.80472240e-01],\n",
       "       [8.58843450e-01, 1.41141010e-01, 1.55746110e-05],\n",
       "       [8.58843450e-01, 1.41141010e-01, 1.55746110e-05],\n",
       "       [5.85653000e-01, 4.10576280e-01, 3.77069250e-03],\n",
       "       [8.58843450e-01, 1.41141010e-01, 1.55746110e-05],\n",
       "       [5.85653000e-01, 4.10576280e-01, 3.77069250e-03],\n",
       "       [4.50801500e-02, 9.25975700e-01, 2.89441370e-02],\n",
       "       [8.58843450e-01, 1.41141010e-01, 1.55746110e-05],\n",
       "       [1.43690750e-01, 8.43325700e-01, 1.29834910e-02],\n",
       "       [2.65482600e-01, 7.34014000e-01, 5.03491700e-04],\n",
       "       [2.03958320e-03, 5.10278750e-02, 9.46932500e-01],\n",
       "       [1.03797040e-02, 1.09147990e-01, 8.80472240e-01],\n",
       "       [1.03797040e-02, 1.09147990e-01, 8.80472240e-01],\n",
       "       [2.03958320e-03, 5.10278750e-02, 9.46932500e-01],\n",
       "       [3.08219970e-01, 6.90642700e-01, 1.13732110e-03],\n",
       "       [4.94703650e-03, 9.94421400e-01, 6.31450700e-04],\n",
       "       [5.12043100e-01, 4.86037140e-01, 1.91972220e-03],\n",
       "       [8.58843450e-01, 1.41141010e-01, 1.55746110e-05],\n",
       "       [1.36464520e-02, 9.85880430e-01, 4.73107470e-04],\n",
       "       [2.65482600e-01, 7.34014000e-01, 5.03491700e-04],\n",
       "       [3.82872820e-02, 9.61660860e-01, 5.17632500e-05],\n",
       "       [2.04505270e-02, 2.77339240e-02, 9.51815500e-01],\n",
       "       [2.65482600e-01, 7.34014000e-01, 5.03491700e-04],\n",
       "       [6.99526250e-01, 2.90807460e-01, 9.66635400e-03],\n",
       "       [2.03958320e-03, 5.10278750e-02, 9.46932500e-01],\n",
       "       [1.36437710e-01, 8.58879500e-01, 4.68287150e-03],\n",
       "       [1.36437710e-01, 8.58879500e-01, 4.68287150e-03],\n",
       "       [8.58843450e-01, 1.41141010e-01, 1.55746110e-05],\n",
       "       [3.84846330e-01, 6.15148500e-01, 5.24299200e-06],\n",
       "       [2.03958320e-03, 5.10278750e-02, 9.46932500e-01],\n",
       "       [3.84846330e-01, 6.15148500e-01, 5.24299200e-06],\n",
       "       [6.99526250e-01, 2.90807460e-01, 9.66635400e-03],\n",
       "       [3.84846330e-01, 6.15148500e-01, 5.24299200e-06],\n",
       "       [4.58061140e-02, 1.13872685e-01, 8.40321200e-01],\n",
       "       [1.03797040e-02, 1.09147990e-01, 8.80472240e-01],\n",
       "       [1.03797040e-02, 1.09147990e-01, 8.80472240e-01],\n",
       "       [6.99526250e-01, 2.90807460e-01, 9.66635400e-03],\n",
       "       [3.34019240e-03, 9.24840030e-01, 7.18197100e-02],\n",
       "       [1.03797040e-02, 1.09147990e-01, 8.80472240e-01],\n",
       "       [5.85653000e-01, 4.10576280e-01, 3.77069250e-03],\n",
       "       [1.36437710e-01, 8.58879500e-01, 4.68287150e-03],\n",
       "       [5.85653000e-01, 4.10576280e-01, 3.77069250e-03],\n",
       "       [5.85653000e-01, 4.10576280e-01, 3.77069250e-03],\n",
       "       [5.12043100e-01, 4.86037140e-01, 1.91972220e-03],\n",
       "       [2.65482600e-01, 7.34014000e-01, 5.03491700e-04],\n",
       "       [6.99526250e-01, 2.90807460e-01, 9.66635400e-03],\n",
       "       [1.36437710e-01, 8.58879500e-01, 4.68287150e-03],\n",
       "       [1.03797040e-02, 1.09147990e-01, 8.80472240e-01],\n",
       "       [8.58843450e-01, 1.41141010e-01, 1.55746110e-05],\n",
       "       [8.58843450e-01, 1.41141010e-01, 1.55746110e-05],\n",
       "       [8.58843450e-01, 1.41141010e-01, 1.55746110e-05],\n",
       "       [8.58843450e-01, 1.41141010e-01, 1.55746110e-05],\n",
       "       [3.84846330e-01, 6.15148500e-01, 5.24299200e-06],\n",
       "       [8.58843450e-01, 1.41141010e-01, 1.55746110e-05],\n",
       "       [2.04505270e-02, 2.77339240e-02, 9.51815500e-01],\n",
       "       [1.03797040e-02, 1.09147990e-01, 8.80472240e-01],\n",
       "       [2.03958320e-03, 5.10278750e-02, 9.46932500e-01],\n",
       "       [1.03797040e-02, 1.09147990e-01, 8.80472240e-01],\n",
       "       [2.03958320e-03, 5.10278750e-02, 9.46932500e-01],\n",
       "       [1.36437710e-01, 8.58879500e-01, 4.68287150e-03],\n",
       "       [2.65482600e-01, 7.34014000e-01, 5.03491700e-04],\n",
       "       [2.04505270e-02, 2.77339240e-02, 9.51815500e-01],\n",
       "       [8.58843450e-01, 1.41141010e-01, 1.55746110e-05],\n",
       "       [6.99526250e-01, 2.90807460e-01, 9.66635400e-03],\n",
       "       [6.99526250e-01, 2.90807460e-01, 9.66635400e-03],\n",
       "       [3.82872820e-02, 9.61660860e-01, 5.17632500e-05],\n",
       "       [2.03958320e-03, 5.10278750e-02, 9.46932500e-01],\n",
       "       [5.95275040e-01, 4.04691640e-01, 3.33508140e-05],\n",
       "       [8.58843450e-01, 1.41141010e-01, 1.55746110e-05],\n",
       "       [2.04505270e-02, 2.77339240e-02, 9.51815500e-01],\n",
       "       [3.18699910e-03, 8.66364960e-01, 1.30448100e-01],\n",
       "       [8.58843450e-01, 1.41141010e-01, 1.55746110e-05],\n",
       "       [1.03797040e-02, 1.09147990e-01, 8.80472240e-01],\n",
       "       [8.58843450e-01, 1.41141010e-01, 1.55746110e-05],\n",
       "       [1.03797040e-02, 1.09147990e-01, 8.80472240e-01],\n",
       "       [3.82872820e-02, 9.61660860e-01, 5.17632500e-05],\n",
       "       [2.03958320e-03, 5.10278750e-02, 9.46932500e-01],\n",
       "       [1.03797040e-02, 1.09147990e-01, 8.80472240e-01],\n",
       "       [1.36437710e-01, 8.58879500e-01, 4.68287150e-03],\n",
       "       [1.36437710e-01, 8.58879500e-01, 4.68287150e-03],\n",
       "       [1.03797040e-02, 1.09147990e-01, 8.80472240e-01],\n",
       "       [2.65482600e-01, 7.34014000e-01, 5.03491700e-04],\n",
       "       [2.04505270e-02, 2.77339240e-02, 9.51815500e-01],\n",
       "       [2.03958320e-03, 5.10278750e-02, 9.46932500e-01],\n",
       "       [2.03958320e-03, 5.10278750e-02, 9.46932500e-01],\n",
       "       [2.04505270e-02, 2.77339240e-02, 9.51815500e-01],\n",
       "       [3.84846330e-01, 6.15148500e-01, 5.24299200e-06],\n",
       "       [3.08219970e-01, 6.90642700e-01, 1.13732110e-03],\n",
       "       [8.58843450e-01, 1.41141010e-01, 1.55746110e-05],\n",
       "       [2.03958320e-03, 5.10278750e-02, 9.46932500e-01],\n",
       "       [9.77608700e-02, 6.73665050e-01, 2.28574050e-01],\n",
       "       [6.99526250e-01, 2.90807460e-01, 9.66635400e-03],\n",
       "       [3.84846330e-01, 6.15148500e-01, 5.24299200e-06],\n",
       "       [8.58843450e-01, 1.41141010e-01, 1.55746110e-05],\n",
       "       [2.03958320e-03, 5.10278750e-02, 9.46932500e-01],\n",
       "       [2.03958320e-03, 5.10278750e-02, 9.46932500e-01],\n",
       "       [6.89038000e-01, 3.10271860e-01, 6.90189500e-04],\n",
       "       [1.03797040e-02, 1.09147990e-01, 8.80472240e-01],\n",
       "       [8.67198900e-01, 1.25620160e-01, 7.18099860e-03],\n",
       "       [8.58843450e-01, 1.41141010e-01, 1.55746110e-05],\n",
       "       [5.85653000e-01, 4.10576280e-01, 3.77069250e-03],\n",
       "       [2.03958320e-03, 5.10278750e-02, 9.46932500e-01],\n",
       "       [4.50801500e-02, 9.25975700e-01, 2.89441370e-02],\n",
       "       [5.95275040e-01, 4.04691640e-01, 3.33508140e-05],\n",
       "       [2.04505270e-02, 2.77339240e-02, 9.51815500e-01],\n",
       "       [4.50801500e-02, 9.25975700e-01, 2.89441370e-02],\n",
       "       [5.85653000e-01, 4.10576280e-01, 3.77069250e-03],\n",
       "       [5.85653000e-01, 4.10576280e-01, 3.77069250e-03],\n",
       "       [2.03958320e-03, 5.10278750e-02, 9.46932500e-01],\n",
       "       [2.04505270e-02, 2.77339240e-02, 9.51815500e-01],\n",
       "       [1.36437710e-01, 8.58879500e-01, 4.68287150e-03],\n",
       "       [6.99526250e-01, 2.90807460e-01, 9.66635400e-03],\n",
       "       [2.04505270e-02, 2.77339240e-02, 9.51815500e-01],\n",
       "       [2.04505270e-02, 2.77339240e-02, 9.51815500e-01],\n",
       "       [2.03958320e-03, 5.10278750e-02, 9.46932500e-01],\n",
       "       [2.03958320e-03, 5.10278750e-02, 9.46932500e-01],\n",
       "       [2.04505270e-02, 2.77339240e-02, 9.51815500e-01],\n",
       "       [1.03797040e-02, 1.09147990e-01, 8.80472240e-01],\n",
       "       [6.99526250e-01, 2.90807460e-01, 9.66635400e-03],\n",
       "       [8.58843450e-01, 1.41141010e-01, 1.55746110e-05],\n",
       "       [1.36437710e-01, 8.58879500e-01, 4.68287150e-03],\n",
       "       [3.84846330e-01, 6.15148500e-01, 5.24299200e-06],\n",
       "       [3.18699910e-03, 8.66364960e-01, 1.30448100e-01],\n",
       "       [4.50801500e-02, 9.25975700e-01, 2.89441370e-02],\n",
       "       [3.84846330e-01, 6.15148500e-01, 5.24299200e-06],\n",
       "       [3.97687260e-02, 9.52435600e-01, 7.79574700e-03],\n",
       "       [2.65482600e-01, 7.34014000e-01, 5.03491700e-04],\n",
       "       [3.34019240e-03, 9.24840030e-01, 7.18197100e-02],\n",
       "       [6.99526250e-01, 2.90807460e-01, 9.66635400e-03],\n",
       "       [1.36437710e-01, 8.58879500e-01, 4.68287150e-03],\n",
       "       [1.03797040e-02, 1.09147990e-01, 8.80472240e-01],\n",
       "       [6.99526250e-01, 2.90807460e-01, 9.66635400e-03],\n",
       "       [2.03958320e-03, 5.10278750e-02, 9.46932500e-01],\n",
       "       [1.03797040e-02, 1.09147990e-01, 8.80472240e-01],\n",
       "       [2.03958320e-03, 5.10278750e-02, 9.46932500e-01],\n",
       "       [2.04505270e-02, 2.77339240e-02, 9.51815500e-01],\n",
       "       [2.03958320e-03, 5.10278750e-02, 9.46932500e-01],\n",
       "       [2.03958320e-03, 5.10278750e-02, 9.46932500e-01],\n",
       "       [2.65482600e-01, 7.34014000e-01, 5.03491700e-04],\n",
       "       [2.03958320e-03, 5.10278750e-02, 9.46932500e-01],\n",
       "       [4.50801500e-02, 9.25975700e-01, 2.89441370e-02],\n",
       "       [6.99526250e-01, 2.90807460e-01, 9.66635400e-03],\n",
       "       [2.03958320e-03, 5.10278750e-02, 9.46932500e-01],\n",
       "       [5.12043100e-01, 4.86037140e-01, 1.91972220e-03],\n",
       "       [2.03958320e-03, 5.10278750e-02, 9.46932500e-01],\n",
       "       [1.03797040e-02, 1.09147990e-01, 8.80472240e-01],\n",
       "       [2.03958320e-03, 5.10278750e-02, 9.46932500e-01],\n",
       "       [2.03958320e-03, 5.10278750e-02, 9.46932500e-01],\n",
       "       [3.34019240e-03, 9.24840030e-01, 7.18197100e-02],\n",
       "       [2.03958320e-03, 5.10278750e-02, 9.46932500e-01],\n",
       "       [1.03797040e-02, 1.09147990e-01, 8.80472240e-01],\n",
       "       [8.58843450e-01, 1.41141010e-01, 1.55746110e-05],\n",
       "       [2.03958320e-03, 5.10278750e-02, 9.46932500e-01],\n",
       "       [2.04505270e-02, 2.77339240e-02, 9.51815500e-01],\n",
       "       [2.03958320e-03, 5.10278750e-02, 9.46932500e-01],\n",
       "       [2.04505270e-02, 2.77339240e-02, 9.51815500e-01],\n",
       "       [1.03797040e-02, 1.09147990e-01, 8.80472240e-01]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob = df_proba[df_proba['phage']=='pyokpresabs_qual'].iloc[:,-3:]\n",
    "y_prob = y_prob.to_numpy()\n",
    "y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Retrieved from https://github.com/scikit-learn/scikit-learn/issues/3298\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "def rocauc_ovo(truth, pred, average=\"macro\", multi_class=\"ovo\"):\n",
    "\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(truth)\n",
    "\n",
    "    truth = lb.transform(truth)   \n",
    "    \n",
    "    return roc_auc_score(truth, pred, average=average, multi_class=multi_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9421804658445879"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo1 = rocauc_ovo(y_test_over, y_prob, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rocauc_ovr(truth, pred, average=\"macro\", multi_class=\"ovr\"):\n",
    "\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(truth)\n",
    "\n",
    "    truth = lb.transform(truth)   \n",
    "\n",
    "    return roc_auc_score(truth, pred, average=average, multi_class=multi_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9421804658445879"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr1 = rocauc_ovr(y_test_over, y_prob, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=234,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat2 = pd.DataFrame(X_test_over[:,0])\n",
    "dat2['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BCH-SA-04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS110</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS183</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BCH-SA-05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>NRS112</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>SR1065</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>NRS203</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>CFBREBSa129</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>CFBRSa25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>196 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test\n",
       "0      BCH-SA-04     0\n",
       "1         NRS110     1\n",
       "2         NRS109     2\n",
       "3         NRS183     1\n",
       "4      BCH-SA-05     0\n",
       "..           ...   ...\n",
       "191       NRS112     1\n",
       "192       SR1065     0\n",
       "193       NRS203     0\n",
       "194  CFBREBSa129     0\n",
       "195     CFBRSa25     0\n",
       "\n",
       "[196 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over2 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over2.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 455 samples, validate on 196 samples\n",
      "Epoch 1/100\n",
      "455/455 [==============================] - 0s 322us/step - loss: 1.0771 - accuracy: 0.4308 - val_loss: 1.0479 - val_accuracy: 0.5459\n",
      "Epoch 2/100\n",
      "455/455 [==============================] - 0s 72us/step - loss: 1.0055 - accuracy: 0.5824 - val_loss: 0.9842 - val_accuracy: 0.5765\n",
      "Epoch 3/100\n",
      "455/455 [==============================] - 0s 92us/step - loss: 0.9441 - accuracy: 0.6286 - val_loss: 0.9283 - val_accuracy: 0.6378\n",
      "Epoch 4/100\n",
      "455/455 [==============================] - 0s 72us/step - loss: 0.8907 - accuracy: 0.6857 - val_loss: 0.8801 - val_accuracy: 0.6582\n",
      "Epoch 5/100\n",
      "455/455 [==============================] - 0s 96us/step - loss: 0.8442 - accuracy: 0.7209 - val_loss: 0.8384 - val_accuracy: 0.7092\n",
      "Epoch 6/100\n",
      "455/455 [==============================] - 0s 75us/step - loss: 0.8040 - accuracy: 0.7714 - val_loss: 0.7984 - val_accuracy: 0.7704\n",
      "Epoch 7/100\n",
      "455/455 [==============================] - 0s 83us/step - loss: 0.7648 - accuracy: 0.7758 - val_loss: 0.7582 - val_accuracy: 0.7755\n",
      "Epoch 8/100\n",
      "455/455 [==============================] - 0s 62us/step - loss: 0.7303 - accuracy: 0.7780 - val_loss: 0.7216 - val_accuracy: 0.7755\n",
      "Epoch 9/100\n",
      "455/455 [==============================] - 0s 58us/step - loss: 0.6981 - accuracy: 0.7780 - val_loss: 0.6891 - val_accuracy: 0.7755\n",
      "Epoch 10/100\n",
      "455/455 [==============================] - 0s 83us/step - loss: 0.6701 - accuracy: 0.7780 - val_loss: 0.6578 - val_accuracy: 0.7755\n",
      "Epoch 11/100\n",
      "455/455 [==============================] - 0s 60us/step - loss: 0.6453 - accuracy: 0.7758 - val_loss: 0.6299 - val_accuracy: 0.7653\n",
      "Epoch 12/100\n",
      "455/455 [==============================] - 0s 63us/step - loss: 0.6237 - accuracy: 0.7714 - val_loss: 0.6050 - val_accuracy: 0.7653\n",
      "Epoch 13/100\n",
      "455/455 [==============================] - 0s 70us/step - loss: 0.6034 - accuracy: 0.7714 - val_loss: 0.5851 - val_accuracy: 0.7653\n",
      "Epoch 14/100\n",
      "455/455 [==============================] - 0s 67us/step - loss: 0.5878 - accuracy: 0.7912 - val_loss: 0.5673 - val_accuracy: 0.7908\n",
      "Epoch 15/100\n",
      "455/455 [==============================] - 0s 94us/step - loss: 0.5721 - accuracy: 0.8022 - val_loss: 0.5569 - val_accuracy: 0.7806\n",
      "Epoch 16/100\n",
      "455/455 [==============================] - 0s 75us/step - loss: 0.5591 - accuracy: 0.8000 - val_loss: 0.5430 - val_accuracy: 0.7806\n",
      "Epoch 17/100\n",
      "455/455 [==============================] - 0s 78us/step - loss: 0.5462 - accuracy: 0.7978 - val_loss: 0.5260 - val_accuracy: 0.7806\n",
      "Epoch 18/100\n",
      "455/455 [==============================] - 0s 60us/step - loss: 0.5347 - accuracy: 0.8066 - val_loss: 0.5151 - val_accuracy: 0.7908\n",
      "Epoch 19/100\n",
      "455/455 [==============================] - 0s 58us/step - loss: 0.5252 - accuracy: 0.8022 - val_loss: 0.5061 - val_accuracy: 0.7806\n",
      "Epoch 20/100\n",
      "455/455 [==============================] - 0s 68us/step - loss: 0.5203 - accuracy: 0.8088 - val_loss: 0.5003 - val_accuracy: 0.8214\n",
      "Epoch 21/100\n",
      "455/455 [==============================] - 0s 53us/step - loss: 0.5090 - accuracy: 0.8110 - val_loss: 0.4909 - val_accuracy: 0.7908\n",
      "Epoch 22/100\n",
      "455/455 [==============================] - 0s 69us/step - loss: 0.5019 - accuracy: 0.8066 - val_loss: 0.4847 - val_accuracy: 0.7908\n",
      "Epoch 23/100\n",
      "455/455 [==============================] - 0s 73us/step - loss: 0.4950 - accuracy: 0.8066 - val_loss: 0.4742 - val_accuracy: 0.8214\n",
      "Epoch 24/100\n",
      "455/455 [==============================] - 0s 83us/step - loss: 0.4879 - accuracy: 0.8154 - val_loss: 0.4703 - val_accuracy: 0.8214\n",
      "Epoch 25/100\n",
      "455/455 [==============================] - 0s 110us/step - loss: 0.4821 - accuracy: 0.8132 - val_loss: 0.4657 - val_accuracy: 0.8316\n",
      "Epoch 26/100\n",
      "455/455 [==============================] - 0s 61us/step - loss: 0.4771 - accuracy: 0.8198 - val_loss: 0.4597 - val_accuracy: 0.8163\n",
      "Epoch 27/100\n",
      "455/455 [==============================] - 0s 44us/step - loss: 0.4745 - accuracy: 0.8110 - val_loss: 0.4554 - val_accuracy: 0.8163\n",
      "Epoch 28/100\n",
      "455/455 [==============================] - 0s 53us/step - loss: 0.4704 - accuracy: 0.8242 - val_loss: 0.4525 - val_accuracy: 0.8316\n",
      "Epoch 29/100\n",
      "455/455 [==============================] - 0s 60us/step - loss: 0.4610 - accuracy: 0.8264 - val_loss: 0.4457 - val_accuracy: 0.8316\n",
      "Epoch 30/100\n",
      "455/455 [==============================] - 0s 59us/step - loss: 0.4554 - accuracy: 0.8308 - val_loss: 0.4397 - val_accuracy: 0.8418\n",
      "Epoch 31/100\n",
      "455/455 [==============================] - 0s 69us/step - loss: 0.4518 - accuracy: 0.8308 - val_loss: 0.4344 - val_accuracy: 0.8316\n",
      "Epoch 32/100\n",
      "455/455 [==============================] - 0s 100us/step - loss: 0.4501 - accuracy: 0.8242 - val_loss: 0.4367 - val_accuracy: 0.8265\n",
      "Epoch 33/100\n",
      "455/455 [==============================] - 0s 79us/step - loss: 0.4456 - accuracy: 0.8264 - val_loss: 0.4369 - val_accuracy: 0.8316\n",
      "Epoch 34/100\n",
      "455/455 [==============================] - 0s 87us/step - loss: 0.4430 - accuracy: 0.8330 - val_loss: 0.4322 - val_accuracy: 0.8418\n",
      "Epoch 35/100\n",
      "455/455 [==============================] - 0s 68us/step - loss: 0.4381 - accuracy: 0.8352 - val_loss: 0.4277 - val_accuracy: 0.8316\n",
      "Epoch 36/100\n",
      "455/455 [==============================] - 0s 94us/step - loss: 0.4341 - accuracy: 0.8374 - val_loss: 0.4228 - val_accuracy: 0.8418\n",
      "Epoch 37/100\n",
      "455/455 [==============================] - 0s 43us/step - loss: 0.4304 - accuracy: 0.8396 - val_loss: 0.4187 - val_accuracy: 0.8418\n",
      "Epoch 38/100\n",
      "455/455 [==============================] - 0s 92us/step - loss: 0.4277 - accuracy: 0.8396 - val_loss: 0.4136 - val_accuracy: 0.8418\n",
      "Epoch 39/100\n",
      "455/455 [==============================] - 0s 70us/step - loss: 0.4248 - accuracy: 0.8462 - val_loss: 0.4118 - val_accuracy: 0.8571\n",
      "Epoch 40/100\n",
      "455/455 [==============================] - 0s 86us/step - loss: 0.4218 - accuracy: 0.8527 - val_loss: 0.4082 - val_accuracy: 0.8571\n",
      "Epoch 41/100\n",
      "455/455 [==============================] - 0s 55us/step - loss: 0.4183 - accuracy: 0.8440 - val_loss: 0.4052 - val_accuracy: 0.8520\n",
      "Epoch 42/100\n",
      "455/455 [==============================] - 0s 42us/step - loss: 0.4165 - accuracy: 0.8440 - val_loss: 0.4058 - val_accuracy: 0.8418\n",
      "Epoch 43/100\n",
      "455/455 [==============================] - 0s 40us/step - loss: 0.4200 - accuracy: 0.8396 - val_loss: 0.4138 - val_accuracy: 0.8469\n",
      "Epoch 44/100\n",
      "455/455 [==============================] - 0s 50us/step - loss: 0.4197 - accuracy: 0.8374 - val_loss: 0.4040 - val_accuracy: 0.8418\n",
      "Epoch 45/100\n",
      "455/455 [==============================] - 0s 38us/step - loss: 0.4102 - accuracy: 0.8462 - val_loss: 0.4011 - val_accuracy: 0.8520\n",
      "Epoch 46/100\n",
      "455/455 [==============================] - 0s 36us/step - loss: 0.4080 - accuracy: 0.8462 - val_loss: 0.4012 - val_accuracy: 0.8520\n",
      "Epoch 47/100\n",
      "455/455 [==============================] - 0s 37us/step - loss: 0.4036 - accuracy: 0.8505 - val_loss: 0.3967 - val_accuracy: 0.8571\n",
      "Epoch 48/100\n",
      "455/455 [==============================] - 0s 45us/step - loss: 0.4018 - accuracy: 0.8527 - val_loss: 0.3929 - val_accuracy: 0.8571\n",
      "Epoch 49/100\n",
      "455/455 [==============================] - 0s 38us/step - loss: 0.3990 - accuracy: 0.8527 - val_loss: 0.3965 - val_accuracy: 0.8571\n",
      "Epoch 50/100\n",
      "455/455 [==============================] - 0s 42us/step - loss: 0.3969 - accuracy: 0.8484 - val_loss: 0.3950 - val_accuracy: 0.8418\n",
      "Epoch 51/100\n",
      "455/455 [==============================] - 0s 103us/step - loss: 0.3952 - accuracy: 0.8527 - val_loss: 0.3916 - val_accuracy: 0.8571\n",
      "Epoch 52/100\n",
      "455/455 [==============================] - 0s 126us/step - loss: 0.3929 - accuracy: 0.8484 - val_loss: 0.3965 - val_accuracy: 0.8571\n",
      "Epoch 53/100\n",
      "455/455 [==============================] - 0s 83us/step - loss: 0.3926 - accuracy: 0.8527 - val_loss: 0.3945 - val_accuracy: 0.8571\n",
      "Epoch 54/100\n",
      "455/455 [==============================] - 0s 125us/step - loss: 0.3897 - accuracy: 0.8527 - val_loss: 0.3893 - val_accuracy: 0.8571\n",
      "Epoch 55/100\n",
      "455/455 [==============================] - 0s 80us/step - loss: 0.3881 - accuracy: 0.8527 - val_loss: 0.3882 - val_accuracy: 0.8571\n",
      "Epoch 56/100\n",
      "455/455 [==============================] - 0s 111us/step - loss: 0.3862 - accuracy: 0.8527 - val_loss: 0.3889 - val_accuracy: 0.8571\n",
      "Epoch 57/100\n",
      "455/455 [==============================] - 0s 109us/step - loss: 0.3838 - accuracy: 0.8505 - val_loss: 0.3876 - val_accuracy: 0.8571\n",
      "Epoch 58/100\n",
      "455/455 [==============================] - 0s 94us/step - loss: 0.3830 - accuracy: 0.8527 - val_loss: 0.3844 - val_accuracy: 0.8571\n",
      "Epoch 59/100\n",
      "455/455 [==============================] - 0s 83us/step - loss: 0.3804 - accuracy: 0.8527 - val_loss: 0.3829 - val_accuracy: 0.8571\n",
      "Epoch 60/100\n",
      "455/455 [==============================] - 0s 52us/step - loss: 0.3779 - accuracy: 0.8527 - val_loss: 0.3871 - val_accuracy: 0.8571\n",
      "Epoch 61/100\n",
      "455/455 [==============================] - 0s 64us/step - loss: 0.3782 - accuracy: 0.8681 - val_loss: 0.3890 - val_accuracy: 0.8571\n",
      "Epoch 62/100\n",
      "455/455 [==============================] - 0s 69us/step - loss: 0.3775 - accuracy: 0.8681 - val_loss: 0.3884 - val_accuracy: 0.8571\n",
      "Epoch 63/100\n",
      "455/455 [==============================] - 0s 111us/step - loss: 0.3765 - accuracy: 0.8681 - val_loss: 0.3903 - val_accuracy: 0.8469\n",
      "Epoch 64/100\n",
      "455/455 [==============================] - 0s 107us/step - loss: 0.3743 - accuracy: 0.8681 - val_loss: 0.3886 - val_accuracy: 0.8469\n",
      "Epoch 65/100\n",
      "455/455 [==============================] - 0s 108us/step - loss: 0.3723 - accuracy: 0.8659 - val_loss: 0.3867 - val_accuracy: 0.8418\n",
      "Epoch 66/100\n",
      "455/455 [==============================] - 0s 75us/step - loss: 0.3753 - accuracy: 0.8637 - val_loss: 0.3875 - val_accuracy: 0.8418\n",
      "Epoch 67/100\n",
      "455/455 [==============================] - 0s 76us/step - loss: 0.3718 - accuracy: 0.8703 - val_loss: 0.3803 - val_accuracy: 0.8571\n",
      "Epoch 68/100\n",
      "455/455 [==============================] - 0s 63us/step - loss: 0.3704 - accuracy: 0.8681 - val_loss: 0.3796 - val_accuracy: 0.8571\n",
      "Epoch 69/100\n",
      "455/455 [==============================] - 0s 91us/step - loss: 0.3709 - accuracy: 0.8681 - val_loss: 0.3835 - val_accuracy: 0.8469\n",
      "Epoch 70/100\n",
      "455/455 [==============================] - 0s 61us/step - loss: 0.3674 - accuracy: 0.8703 - val_loss: 0.3823 - val_accuracy: 0.8469\n",
      "Epoch 71/100\n",
      "455/455 [==============================] - 0s 92us/step - loss: 0.3670 - accuracy: 0.8681 - val_loss: 0.3806 - val_accuracy: 0.8571\n",
      "Epoch 72/100\n",
      "455/455 [==============================] - 0s 145us/step - loss: 0.3677 - accuracy: 0.8703 - val_loss: 0.3881 - val_accuracy: 0.8571\n",
      "Epoch 73/100\n",
      "455/455 [==============================] - 0s 72us/step - loss: 0.3686 - accuracy: 0.8681 - val_loss: 0.3861 - val_accuracy: 0.8571\n",
      "Epoch 74/100\n",
      "455/455 [==============================] - 0s 74us/step - loss: 0.3660 - accuracy: 0.8703 - val_loss: 0.3809 - val_accuracy: 0.8571\n",
      "Epoch 75/100\n",
      "455/455 [==============================] - 0s 84us/step - loss: 0.3634 - accuracy: 0.8681 - val_loss: 0.3744 - val_accuracy: 0.8571\n",
      "Epoch 76/100\n",
      "455/455 [==============================] - 0s 73us/step - loss: 0.3628 - accuracy: 0.8681 - val_loss: 0.3729 - val_accuracy: 0.8571\n",
      "Epoch 77/100\n",
      "455/455 [==============================] - 0s 119us/step - loss: 0.3642 - accuracy: 0.8637 - val_loss: 0.3757 - val_accuracy: 0.8571\n",
      "Epoch 78/100\n",
      "455/455 [==============================] - 0s 67us/step - loss: 0.3627 - accuracy: 0.8681 - val_loss: 0.3750 - val_accuracy: 0.8571\n",
      "Epoch 79/100\n",
      "455/455 [==============================] - 0s 155us/step - loss: 0.3616 - accuracy: 0.8681 - val_loss: 0.3772 - val_accuracy: 0.8469\n",
      "Epoch 80/100\n",
      "455/455 [==============================] - 0s 125us/step - loss: 0.3608 - accuracy: 0.8725 - val_loss: 0.3791 - val_accuracy: 0.8469\n",
      "Epoch 81/100\n",
      "455/455 [==============================] - 0s 72us/step - loss: 0.3599 - accuracy: 0.8725 - val_loss: 0.3819 - val_accuracy: 0.8469\n",
      "Epoch 82/100\n",
      "455/455 [==============================] - 0s 82us/step - loss: 0.3605 - accuracy: 0.8725 - val_loss: 0.3830 - val_accuracy: 0.8469\n",
      "Epoch 83/100\n",
      "455/455 [==============================] - 0s 136us/step - loss: 0.3609 - accuracy: 0.8703 - val_loss: 0.3828 - val_accuracy: 0.8418\n",
      "Epoch 84/100\n",
      "455/455 [==============================] - 0s 136us/step - loss: 0.3586 - accuracy: 0.8703 - val_loss: 0.3784 - val_accuracy: 0.8469\n",
      "Epoch 85/100\n",
      "455/455 [==============================] - 0s 68us/step - loss: 0.3575 - accuracy: 0.8725 - val_loss: 0.3788 - val_accuracy: 0.8469\n",
      "Epoch 86/100\n",
      "455/455 [==============================] - 0s 143us/step - loss: 0.3606 - accuracy: 0.8769 - val_loss: 0.3857 - val_accuracy: 0.8571\n",
      "Epoch 87/100\n",
      "455/455 [==============================] - 0s 129us/step - loss: 0.3570 - accuracy: 0.8703 - val_loss: 0.3783 - val_accuracy: 0.8571\n",
      "Epoch 88/100\n",
      "455/455 [==============================] - 0s 74us/step - loss: 0.3587 - accuracy: 0.8703 - val_loss: 0.3783 - val_accuracy: 0.8571\n",
      "Epoch 89/100\n",
      "455/455 [==============================] - 0s 84us/step - loss: 0.3573 - accuracy: 0.8703 - val_loss: 0.3839 - val_accuracy: 0.8571\n",
      "Epoch 90/100\n",
      "455/455 [==============================] - 0s 49us/step - loss: 0.3595 - accuracy: 0.8725 - val_loss: 0.3867 - val_accuracy: 0.8469\n",
      "Epoch 91/100\n",
      "455/455 [==============================] - 0s 84us/step - loss: 0.3570 - accuracy: 0.8725 - val_loss: 0.3783 - val_accuracy: 0.8469\n",
      "Epoch 92/100\n",
      "455/455 [==============================] - 0s 75us/step - loss: 0.3551 - accuracy: 0.8725 - val_loss: 0.3792 - val_accuracy: 0.8469\n",
      "Epoch 93/100\n",
      "455/455 [==============================] - 0s 122us/step - loss: 0.3574 - accuracy: 0.8703 - val_loss: 0.3783 - val_accuracy: 0.8469\n",
      "Epoch 94/100\n",
      "455/455 [==============================] - 0s 79us/step - loss: 0.3545 - accuracy: 0.8725 - val_loss: 0.3821 - val_accuracy: 0.8469\n",
      "Epoch 95/100\n",
      "455/455 [==============================] - 0s 91us/step - loss: 0.3541 - accuracy: 0.8725 - val_loss: 0.3837 - val_accuracy: 0.8469\n",
      "Epoch 96/100\n",
      "455/455 [==============================] - 0s 59us/step - loss: 0.3528 - accuracy: 0.8725 - val_loss: 0.3847 - val_accuracy: 0.8469\n",
      "Epoch 97/100\n",
      "455/455 [==============================] - 0s 105us/step - loss: 0.3525 - accuracy: 0.8725 - val_loss: 0.3842 - val_accuracy: 0.8469\n",
      "Epoch 98/100\n",
      "455/455 [==============================] - 0s 61us/step - loss: 0.3527 - accuracy: 0.8725 - val_loss: 0.3796 - val_accuracy: 0.8469\n",
      "Epoch 99/100\n",
      "455/455 [==============================] - 0s 70us/step - loss: 0.3515 - accuracy: 0.8703 - val_loss: 0.3762 - val_accuracy: 0.8571\n",
      "Epoch 100/100\n",
      "455/455 [==============================] - 0s 52us/step - loss: 0.3501 - accuracy: 0.8703 - val_loss: 0.3790 - val_accuracy: 0.8469\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a3e695160>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over2.fit(X_train_over, y_train_over,\n",
    "          batch_size=64, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196/196 [==============================] - 0s 58us/step\n",
      "over-sampling test accuracy: 85.71%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over2 = model1_over2.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over2*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 0, 0, 0, 2, 2, 2, 2, 1, 0, 0, 2, 0, 0, 2, 1, 2, 1, 2, 0,\n",
       "       2, 1, 0, 1, 0, 0, 2, 2, 2, 2, 1, 0, 0, 2, 0, 2, 1, 1, 1, 0, 1, 2,\n",
       "       1, 2, 0, 1, 2, 1, 2, 0, 1, 0, 0, 2, 2, 1, 0, 1, 2, 0, 1, 1, 1, 0,\n",
       "       0, 2, 0, 2, 1, 2, 2, 0, 1, 0, 0, 1, 0, 1, 2, 1, 1, 2, 0, 1, 1, 1,\n",
       "       2, 1, 1, 0, 1, 1, 0, 2, 1, 2, 0, 1, 2, 0, 2, 1, 0, 0, 0, 1, 2, 2,\n",
       "       0, 2, 0, 2, 1, 2, 1, 2, 1, 2, 0, 1, 2, 1, 0, 1, 2, 0, 0, 1, 2, 2,\n",
       "       0, 2, 1, 2, 2, 1, 1, 2, 1, 0, 1, 2, 2, 0, 0, 0, 0, 2, 2, 2, 1, 1,\n",
       "       0, 2, 1, 2, 1, 0, 2, 1, 2, 1, 0, 1, 2, 1, 2, 0, 1, 0, 0, 2, 0, 2,\n",
       "       1, 0, 0, 0, 0, 0, 2, 2, 2, 0, 2, 1, 2, 0, 2, 1, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred2 = model1_over2.predict_classes(X_test_over)\n",
    "pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BCH-SA-04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS110</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS183</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BCH-SA-05</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>NRS112</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>SR1065</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>NRS203</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>CFBREBSa129</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>CFBRSa25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>196 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test  pred\n",
       "0      BCH-SA-04     0     0\n",
       "1         NRS110     1     1\n",
       "2         NRS109     2     2\n",
       "3         NRS183     1     0\n",
       "4      BCH-SA-05     0     0\n",
       "..           ...   ...   ...\n",
       "191       NRS112     1     1\n",
       "192       SR1065     0     0\n",
       "193       NRS203     0     0\n",
       "194  CFBREBSa129     0     0\n",
       "195     CFBRSa25     0     0\n",
       "\n",
       "[196 rows x 3 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat2['pred'] = pred2\n",
    "dat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba2 = model1_over2.predict_proba(X_test_over)\n",
    "dat_proba2 = pd.DataFrame(proba2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.744439</td>\n",
       "      <td>0.253666</td>\n",
       "      <td>0.001895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.005637</td>\n",
       "      <td>0.992833</td>\n",
       "      <td>0.001530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.023216</td>\n",
       "      <td>0.070600</td>\n",
       "      <td>0.906184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.778771</td>\n",
       "      <td>0.219659</td>\n",
       "      <td>0.001570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.831228</td>\n",
       "      <td>0.168737</td>\n",
       "      <td>0.000035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>0.001488</td>\n",
       "      <td>0.967119</td>\n",
       "      <td>0.031393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>0.831228</td>\n",
       "      <td>0.168737</td>\n",
       "      <td>0.000035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>0.617932</td>\n",
       "      <td>0.382009</td>\n",
       "      <td>0.000060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>0.744439</td>\n",
       "      <td>0.253666</td>\n",
       "      <td>0.001895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.831228</td>\n",
       "      <td>0.168737</td>\n",
       "      <td>0.000035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>196 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2\n",
       "0    0.744439  0.253666  0.001895\n",
       "1    0.005637  0.992833  0.001530\n",
       "2    0.023216  0.070600  0.906184\n",
       "3    0.778771  0.219659  0.001570\n",
       "4    0.831228  0.168737  0.000035\n",
       "..        ...       ...       ...\n",
       "191  0.001488  0.967119  0.031393\n",
       "192  0.831228  0.168737  0.000035\n",
       "193  0.617932  0.382009  0.000060\n",
       "194  0.744439  0.253666  0.001895\n",
       "195  0.831228  0.168737  0.000035\n",
       "\n",
       "[196 rows x 3 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba2.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba2.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat2.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/2pyo.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 455 samples, validate on 196 samples\n",
      "Epoch 1/100\n",
      "455/455 [==============================] - 0s 62us/step - loss: 0.3561 - accuracy: 0.8681 - val_loss: 0.3777 - val_accuracy: 0.8571\n",
      "Epoch 2/100\n",
      "455/455 [==============================] - 0s 71us/step - loss: 0.3543 - accuracy: 0.8681 - val_loss: 0.3812 - val_accuracy: 0.8520\n",
      "Epoch 3/100\n",
      "455/455 [==============================] - 0s 72us/step - loss: 0.3550 - accuracy: 0.8659 - val_loss: 0.3892 - val_accuracy: 0.8520\n",
      "Epoch 4/100\n",
      "455/455 [==============================] - 0s 74us/step - loss: 0.3545 - accuracy: 0.8681 - val_loss: 0.3872 - val_accuracy: 0.8571\n",
      "Epoch 5/100\n",
      "455/455 [==============================] - 0s 72us/step - loss: 0.3567 - accuracy: 0.8681 - val_loss: 0.3932 - val_accuracy: 0.8571\n",
      "Epoch 6/100\n",
      "455/455 [==============================] - 0s 64us/step - loss: 0.3554 - accuracy: 0.8681 - val_loss: 0.3904 - val_accuracy: 0.8571\n",
      "Epoch 7/100\n",
      "455/455 [==============================] - 0s 60us/step - loss: 0.3567 - accuracy: 0.8681 - val_loss: 0.3857 - val_accuracy: 0.8571\n",
      "Epoch 8/100\n",
      "455/455 [==============================] - 0s 69us/step - loss: 0.3529 - accuracy: 0.8681 - val_loss: 0.3843 - val_accuracy: 0.8571\n",
      "Epoch 9/100\n",
      "455/455 [==============================] - 0s 72us/step - loss: 0.3517 - accuracy: 0.8681 - val_loss: 0.3836 - val_accuracy: 0.8571\n",
      "Epoch 10/100\n",
      "455/455 [==============================] - ETA: 0s - loss: 0.3276 - accuracy: 0.87 - 0s 61us/step - loss: 0.3512 - accuracy: 0.8703 - val_loss: 0.3809 - val_accuracy: 0.8571\n",
      "Epoch 11/100\n",
      "455/455 [==============================] - 0s 71us/step - loss: 0.3519 - accuracy: 0.8703 - val_loss: 0.3748 - val_accuracy: 0.8571\n",
      "Epoch 12/100\n",
      "455/455 [==============================] - 0s 73us/step - loss: 0.3531 - accuracy: 0.8703 - val_loss: 0.3767 - val_accuracy: 0.8571\n",
      "Epoch 13/100\n",
      "455/455 [==============================] - 0s 69us/step - loss: 0.3526 - accuracy: 0.8703 - val_loss: 0.3768 - val_accuracy: 0.8571\n",
      "Epoch 14/100\n",
      "455/455 [==============================] - 0s 62us/step - loss: 0.3527 - accuracy: 0.8703 - val_loss: 0.3779 - val_accuracy: 0.8571\n",
      "Epoch 15/100\n",
      "455/455 [==============================] - 0s 52us/step - loss: 0.3522 - accuracy: 0.8703 - val_loss: 0.3869 - val_accuracy: 0.8571\n",
      "Epoch 16/100\n",
      "455/455 [==============================] - 0s 65us/step - loss: 0.3517 - accuracy: 0.8703 - val_loss: 0.3870 - val_accuracy: 0.8571\n",
      "Epoch 17/100\n",
      "455/455 [==============================] - 0s 58us/step - loss: 0.3493 - accuracy: 0.8703 - val_loss: 0.3790 - val_accuracy: 0.8571\n",
      "Epoch 18/100\n",
      "455/455 [==============================] - 0s 50us/step - loss: 0.3538 - accuracy: 0.8703 - val_loss: 0.3755 - val_accuracy: 0.8571\n",
      "Epoch 19/100\n",
      "455/455 [==============================] - 0s 42us/step - loss: 0.3500 - accuracy: 0.8703 - val_loss: 0.3746 - val_accuracy: 0.8571\n",
      "Epoch 20/100\n",
      "455/455 [==============================] - 0s 54us/step - loss: 0.3498 - accuracy: 0.8681 - val_loss: 0.3806 - val_accuracy: 0.8520\n",
      "Epoch 21/100\n",
      "455/455 [==============================] - 0s 50us/step - loss: 0.3522 - accuracy: 0.8681 - val_loss: 0.3798 - val_accuracy: 0.8520\n",
      "Epoch 22/100\n",
      "455/455 [==============================] - 0s 50us/step - loss: 0.3499 - accuracy: 0.8703 - val_loss: 0.3779 - val_accuracy: 0.8571\n",
      "Epoch 23/100\n",
      "455/455 [==============================] - 0s 47us/step - loss: 0.3488 - accuracy: 0.8703 - val_loss: 0.3785 - val_accuracy: 0.8571\n",
      "Epoch 24/100\n",
      "455/455 [==============================] - 0s 44us/step - loss: 0.3493 - accuracy: 0.8681 - val_loss: 0.3784 - val_accuracy: 0.8520\n",
      "Epoch 25/100\n",
      "455/455 [==============================] - 0s 71us/step - loss: 0.3492 - accuracy: 0.8681 - val_loss: 0.3782 - val_accuracy: 0.8571\n",
      "Epoch 26/100\n",
      "455/455 [==============================] - 0s 47us/step - loss: 0.3483 - accuracy: 0.8703 - val_loss: 0.3772 - val_accuracy: 0.8571\n",
      "Epoch 27/100\n",
      "455/455 [==============================] - 0s 50us/step - loss: 0.3478 - accuracy: 0.8703 - val_loss: 0.3778 - val_accuracy: 0.8571\n",
      "Epoch 28/100\n",
      "455/455 [==============================] - 0s 72us/step - loss: 0.3475 - accuracy: 0.8703 - val_loss: 0.3804 - val_accuracy: 0.8571\n",
      "Epoch 29/100\n",
      "455/455 [==============================] - 0s 64us/step - loss: 0.3473 - accuracy: 0.8703 - val_loss: 0.3818 - val_accuracy: 0.8571\n",
      "Epoch 30/100\n",
      "455/455 [==============================] - 0s 67us/step - loss: 0.3456 - accuracy: 0.8703 - val_loss: 0.3896 - val_accuracy: 0.8571\n",
      "Epoch 31/100\n",
      "455/455 [==============================] - 0s 56us/step - loss: 0.3491 - accuracy: 0.8703 - val_loss: 0.3875 - val_accuracy: 0.8571\n",
      "Epoch 32/100\n",
      "455/455 [==============================] - 0s 45us/step - loss: 0.3491 - accuracy: 0.8703 - val_loss: 0.3850 - val_accuracy: 0.8571\n",
      "Epoch 33/100\n",
      "455/455 [==============================] - 0s 79us/step - loss: 0.3472 - accuracy: 0.8703 - val_loss: 0.3808 - val_accuracy: 0.8571\n",
      "Epoch 34/100\n",
      "455/455 [==============================] - 0s 62us/step - loss: 0.3467 - accuracy: 0.8703 - val_loss: 0.3802 - val_accuracy: 0.8571\n",
      "Epoch 35/100\n",
      "455/455 [==============================] - 0s 53us/step - loss: 0.3472 - accuracy: 0.8703 - val_loss: 0.3942 - val_accuracy: 0.8571\n",
      "Epoch 36/100\n",
      "455/455 [==============================] - 0s 56us/step - loss: 0.3527 - accuracy: 0.8681 - val_loss: 0.3951 - val_accuracy: 0.8520\n",
      "Epoch 37/100\n",
      "455/455 [==============================] - 0s 54us/step - loss: 0.3498 - accuracy: 0.8703 - val_loss: 0.3858 - val_accuracy: 0.8571\n",
      "Epoch 38/100\n",
      "455/455 [==============================] - 0s 47us/step - loss: 0.3448 - accuracy: 0.8703 - val_loss: 0.3822 - val_accuracy: 0.8571\n",
      "Epoch 39/100\n",
      "455/455 [==============================] - 0s 46us/step - loss: 0.3470 - accuracy: 0.8703 - val_loss: 0.3836 - val_accuracy: 0.8571\n",
      "Epoch 40/100\n",
      "455/455 [==============================] - 0s 41us/step - loss: 0.3487 - accuracy: 0.8703 - val_loss: 0.3778 - val_accuracy: 0.8571\n",
      "Epoch 41/100\n",
      "455/455 [==============================] - 0s 42us/step - loss: 0.3462 - accuracy: 0.8703 - val_loss: 0.3765 - val_accuracy: 0.8571\n",
      "Epoch 42/100\n",
      "455/455 [==============================] - 0s 44us/step - loss: 0.3446 - accuracy: 0.8703 - val_loss: 0.3778 - val_accuracy: 0.8571\n",
      "Epoch 43/100\n",
      "455/455 [==============================] - 0s 40us/step - loss: 0.3450 - accuracy: 0.8703 - val_loss: 0.3909 - val_accuracy: 0.8571\n",
      "Epoch 44/100\n",
      "455/455 [==============================] - 0s 40us/step - loss: 0.3479 - accuracy: 0.8703 - val_loss: 0.3890 - val_accuracy: 0.8571\n",
      "Epoch 45/100\n",
      "455/455 [==============================] - 0s 38us/step - loss: 0.3473 - accuracy: 0.8703 - val_loss: 0.3849 - val_accuracy: 0.8571\n",
      "Epoch 46/100\n",
      "455/455 [==============================] - 0s 40us/step - loss: 0.3447 - accuracy: 0.8703 - val_loss: 0.3816 - val_accuracy: 0.8571\n",
      "Epoch 47/100\n",
      "455/455 [==============================] - 0s 42us/step - loss: 0.3454 - accuracy: 0.8703 - val_loss: 0.3800 - val_accuracy: 0.8571\n",
      "Epoch 48/100\n",
      "455/455 [==============================] - 0s 46us/step - loss: 0.3440 - accuracy: 0.8703 - val_loss: 0.3801 - val_accuracy: 0.8571\n",
      "Epoch 49/100\n",
      "455/455 [==============================] - 0s 44us/step - loss: 0.3444 - accuracy: 0.8703 - val_loss: 0.3857 - val_accuracy: 0.8571\n",
      "Epoch 50/100\n",
      "455/455 [==============================] - 0s 45us/step - loss: 0.3453 - accuracy: 0.8703 - val_loss: 0.3814 - val_accuracy: 0.8571\n",
      "Epoch 51/100\n",
      "455/455 [==============================] - 0s 47us/step - loss: 0.3440 - accuracy: 0.8703 - val_loss: 0.3824 - val_accuracy: 0.8571\n",
      "Epoch 52/100\n",
      "455/455 [==============================] - 0s 45us/step - loss: 0.3437 - accuracy: 0.8703 - val_loss: 0.3835 - val_accuracy: 0.8571\n",
      "Epoch 53/100\n",
      "455/455 [==============================] - 0s 46us/step - loss: 0.3428 - accuracy: 0.8703 - val_loss: 0.3833 - val_accuracy: 0.8571\n",
      "Epoch 54/100\n",
      "455/455 [==============================] - 0s 52us/step - loss: 0.3440 - accuracy: 0.8703 - val_loss: 0.3861 - val_accuracy: 0.8571\n",
      "Epoch 55/100\n",
      "455/455 [==============================] - 0s 50us/step - loss: 0.3446 - accuracy: 0.8703 - val_loss: 0.3952 - val_accuracy: 0.8571\n",
      "Epoch 56/100\n",
      "455/455 [==============================] - 0s 49us/step - loss: 0.3444 - accuracy: 0.8703 - val_loss: 0.3933 - val_accuracy: 0.8571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "455/455 [==============================] - 0s 92us/step - loss: 0.3444 - accuracy: 0.8703 - val_loss: 0.3932 - val_accuracy: 0.8571\n",
      "Epoch 58/100\n",
      "455/455 [==============================] - 0s 74us/step - loss: 0.3456 - accuracy: 0.8703 - val_loss: 0.3918 - val_accuracy: 0.8571\n",
      "Epoch 59/100\n",
      "455/455 [==============================] - 0s 76us/step - loss: 0.3452 - accuracy: 0.8703 - val_loss: 0.3878 - val_accuracy: 0.8571\n",
      "Epoch 60/100\n",
      "455/455 [==============================] - 0s 126us/step - loss: 0.3448 - accuracy: 0.8703 - val_loss: 0.3791 - val_accuracy: 0.8571\n",
      "Epoch 61/100\n",
      "455/455 [==============================] - 0s 51us/step - loss: 0.3428 - accuracy: 0.8703 - val_loss: 0.3774 - val_accuracy: 0.8571\n",
      "Epoch 62/100\n",
      "455/455 [==============================] - 0s 53us/step - loss: 0.3424 - accuracy: 0.8703 - val_loss: 0.3775 - val_accuracy: 0.8571\n",
      "Epoch 63/100\n",
      "455/455 [==============================] - 0s 50us/step - loss: 0.3441 - accuracy: 0.8703 - val_loss: 0.3800 - val_accuracy: 0.8571\n",
      "Epoch 64/100\n",
      "455/455 [==============================] - 0s 58us/step - loss: 0.3423 - accuracy: 0.8703 - val_loss: 0.3795 - val_accuracy: 0.8571\n",
      "Epoch 65/100\n",
      "455/455 [==============================] - 0s 60us/step - loss: 0.3425 - accuracy: 0.8703 - val_loss: 0.3803 - val_accuracy: 0.8571\n",
      "Epoch 66/100\n",
      "455/455 [==============================] - 0s 54us/step - loss: 0.3416 - accuracy: 0.8703 - val_loss: 0.3855 - val_accuracy: 0.8571\n",
      "Epoch 67/100\n",
      "455/455 [==============================] - 0s 53us/step - loss: 0.3426 - accuracy: 0.8703 - val_loss: 0.3838 - val_accuracy: 0.8571\n",
      "Epoch 68/100\n",
      "455/455 [==============================] - 0s 55us/step - loss: 0.3407 - accuracy: 0.8703 - val_loss: 0.3816 - val_accuracy: 0.8571\n",
      "Epoch 69/100\n",
      "455/455 [==============================] - 0s 62us/step - loss: 0.3415 - accuracy: 0.8703 - val_loss: 0.3809 - val_accuracy: 0.8571\n",
      "Epoch 70/100\n",
      "455/455 [==============================] - 0s 64us/step - loss: 0.3419 - accuracy: 0.8703 - val_loss: 0.3804 - val_accuracy: 0.8571\n",
      "Epoch 71/100\n",
      "455/455 [==============================] - 0s 66us/step - loss: 0.3408 - accuracy: 0.8703 - val_loss: 0.3810 - val_accuracy: 0.8571\n",
      "Epoch 72/100\n",
      "455/455 [==============================] - 0s 55us/step - loss: 0.3446 - accuracy: 0.8703 - val_loss: 0.3937 - val_accuracy: 0.8571\n",
      "Epoch 73/100\n",
      "455/455 [==============================] - 0s 56us/step - loss: 0.3473 - accuracy: 0.8703 - val_loss: 0.3925 - val_accuracy: 0.8571\n",
      "Epoch 74/100\n",
      "455/455 [==============================] - 0s 58us/step - loss: 0.3422 - accuracy: 0.8703 - val_loss: 0.3798 - val_accuracy: 0.8571\n",
      "Epoch 75/100\n",
      "455/455 [==============================] - 0s 57us/step - loss: 0.3439 - accuracy: 0.8703 - val_loss: 0.3833 - val_accuracy: 0.8571\n",
      "Epoch 76/100\n",
      "455/455 [==============================] - 0s 89us/step - loss: 0.3457 - accuracy: 0.8703 - val_loss: 0.3787 - val_accuracy: 0.8571\n",
      "Epoch 77/100\n",
      "455/455 [==============================] - 0s 302us/step - loss: 0.3421 - accuracy: 0.8703 - val_loss: 0.3790 - val_accuracy: 0.8571\n",
      "Epoch 78/100\n",
      "455/455 [==============================] - 0s 87us/step - loss: 0.3418 - accuracy: 0.8703 - val_loss: 0.3836 - val_accuracy: 0.8571\n",
      "Epoch 79/100\n",
      "455/455 [==============================] - 0s 79us/step - loss: 0.3416 - accuracy: 0.8703 - val_loss: 0.3847 - val_accuracy: 0.8571\n",
      "Epoch 80/100\n",
      "455/455 [==============================] - 0s 51us/step - loss: 0.3412 - accuracy: 0.8703 - val_loss: 0.3849 - val_accuracy: 0.8571\n",
      "Epoch 81/100\n",
      "455/455 [==============================] - 0s 45us/step - loss: 0.3420 - accuracy: 0.8703 - val_loss: 0.3942 - val_accuracy: 0.8571\n",
      "Epoch 82/100\n",
      "455/455 [==============================] - 0s 44us/step - loss: 0.3456 - accuracy: 0.8703 - val_loss: 0.3888 - val_accuracy: 0.8571\n",
      "Epoch 83/100\n",
      "455/455 [==============================] - 0s 67us/step - loss: 0.3407 - accuracy: 0.8703 - val_loss: 0.3797 - val_accuracy: 0.8571\n",
      "Epoch 84/100\n",
      "455/455 [==============================] - 0s 314us/step - loss: 0.3408 - accuracy: 0.8703 - val_loss: 0.3781 - val_accuracy: 0.8571\n",
      "Epoch 85/100\n",
      "455/455 [==============================] - 0s 83us/step - loss: 0.3414 - accuracy: 0.8703 - val_loss: 0.3811 - val_accuracy: 0.8571\n",
      "Epoch 86/100\n",
      "455/455 [==============================] - 0s 54us/step - loss: 0.3417 - accuracy: 0.8703 - val_loss: 0.3813 - val_accuracy: 0.8571\n",
      "Epoch 87/100\n",
      "455/455 [==============================] - 0s 76us/step - loss: 0.3424 - accuracy: 0.8703 - val_loss: 0.3800 - val_accuracy: 0.8571\n",
      "Epoch 88/100\n",
      "455/455 [==============================] - 0s 77us/step - loss: 0.3413 - accuracy: 0.8703 - val_loss: 0.3835 - val_accuracy: 0.8571\n",
      "Epoch 89/100\n",
      "455/455 [==============================] - 0s 63us/step - loss: 0.3410 - accuracy: 0.8703 - val_loss: 0.3839 - val_accuracy: 0.8571\n",
      "Epoch 90/100\n",
      "455/455 [==============================] - 0s 68us/step - loss: 0.3415 - accuracy: 0.8703 - val_loss: 0.3886 - val_accuracy: 0.8469\n",
      "Epoch 91/100\n",
      "455/455 [==============================] - 0s 51us/step - loss: 0.3423 - accuracy: 0.8725 - val_loss: 0.3860 - val_accuracy: 0.8469\n",
      "Epoch 92/100\n",
      "455/455 [==============================] - 0s 52us/step - loss: 0.3406 - accuracy: 0.8703 - val_loss: 0.3794 - val_accuracy: 0.8571\n",
      "Epoch 93/100\n",
      "455/455 [==============================] - 0s 68us/step - loss: 0.3399 - accuracy: 0.8703 - val_loss: 0.3801 - val_accuracy: 0.8571\n",
      "Epoch 94/100\n",
      "455/455 [==============================] - 0s 61us/step - loss: 0.3411 - accuracy: 0.8703 - val_loss: 0.3831 - val_accuracy: 0.8571\n",
      "Epoch 95/100\n",
      "455/455 [==============================] - 0s 47us/step - loss: 0.3414 - accuracy: 0.8703 - val_loss: 0.3826 - val_accuracy: 0.8571\n",
      "Epoch 96/100\n",
      "455/455 [==============================] - 0s 58us/step - loss: 0.3433 - accuracy: 0.8703 - val_loss: 0.3801 - val_accuracy: 0.8571\n",
      "Epoch 97/100\n",
      "455/455 [==============================] - 0s 51us/step - loss: 0.3403 - accuracy: 0.8703 - val_loss: 0.3824 - val_accuracy: 0.8571\n",
      "Epoch 98/100\n",
      "455/455 [==============================] - 0s 48us/step - loss: 0.3406 - accuracy: 0.8703 - val_loss: 0.3860 - val_accuracy: 0.8469\n",
      "Epoch 99/100\n",
      "455/455 [==============================] - 0s 47us/step - loss: 0.3426 - accuracy: 0.8703 - val_loss: 0.3881 - val_accuracy: 0.8520\n",
      "Epoch 100/100\n",
      "455/455 [==============================] - 0s 54us/step - loss: 0.3441 - accuracy: 0.8747 - val_loss: 0.3824 - val_accuracy: 0.8571\n"
     ]
    }
   ],
   "source": [
    "hist1_over2 = model1_over2.fit(X_train_over, y_train_over,\n",
    "          batch_size=64, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 87.01%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over2.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba2 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_2.xlsx\",\n",
    "                        sheet_name=1,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>1.748042e-03</td>\n",
       "      <td>9.981960e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>BCH-SA-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.712007</td>\n",
       "      <td>2.879924e-01</td>\n",
       "      <td>9.646217e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS218</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.006222</td>\n",
       "      <td>9.937732e-01</td>\n",
       "      <td>4.482882e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS036</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.882617</td>\n",
       "      <td>1.173831e-01</td>\n",
       "      <td>2.310933e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS386</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.571179</td>\n",
       "      <td>4.288184e-01</td>\n",
       "      <td>2.444667e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4279</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS112</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001860</td>\n",
       "      <td>9.979747e-01</td>\n",
       "      <td>1.653396e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4280</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>SR1065</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.982940</td>\n",
       "      <td>1.705227e-02</td>\n",
       "      <td>7.349168e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4281</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS203</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.997093</td>\n",
       "      <td>1.962516e-03</td>\n",
       "      <td>9.441347e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4282</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>CFBREBSa129</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.031141e-13</td>\n",
       "      <td>3.208205e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4283</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>CFBRSa25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999833</td>\n",
       "      <td>1.669456e-04</td>\n",
       "      <td>4.411099e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4284 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    phage       strain  phenotype  prediction         0  \\\n",
       "0      p002ykpresabs_qual       NRS148          2           2  0.000056   \n",
       "1      p002ykpresabs_qual    BCH-SA-03          1           0  0.712007   \n",
       "2      p002ykpresabs_qual       NRS218          1           1  0.006222   \n",
       "3      p002ykpresabs_qual       NRS036          0           0  0.882617   \n",
       "4      p002ykpresabs_qual       NRS386          1           0  0.571179   \n",
       "...                   ...          ...        ...         ...       ...   \n",
       "4279  pyopresabsSTCC_qual       NRS112          1           1  0.001860   \n",
       "4280  pyopresabsSTCC_qual       SR1065          0           0  0.982940   \n",
       "4281  pyopresabsSTCC_qual       NRS203          0           0  0.997093   \n",
       "4282  pyopresabsSTCC_qual  CFBREBSa129          0           0  1.000000   \n",
       "4283  pyopresabsSTCC_qual     CFBRSa25          0           0  0.999833   \n",
       "\n",
       "                 1             2  \n",
       "0     1.748042e-03  9.981960e-01  \n",
       "1     2.879924e-01  9.646217e-07  \n",
       "2     9.937732e-01  4.482882e-06  \n",
       "3     1.173831e-01  2.310933e-10  \n",
       "4     4.288184e-01  2.444667e-06  \n",
       "...            ...           ...  \n",
       "4279  9.979747e-01  1.653396e-04  \n",
       "4280  1.705227e-02  7.349168e-06  \n",
       "4281  1.962516e-03  9.441347e-04  \n",
       "4282  3.031141e-13  3.208205e-09  \n",
       "4283  1.669456e-04  4.411099e-08  \n",
       "\n",
       "[4284 rows x 7 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.4443877e-01, 2.5366583e-01, 1.8954171e-03],\n",
       "       [5.6372737e-03, 9.9283326e-01, 1.5295038e-03],\n",
       "       [2.3215990e-02, 7.0600264e-02, 9.0618370e-01],\n",
       "       [7.7877074e-01, 2.1965879e-01, 1.5703891e-03],\n",
       "       [8.3122814e-01, 1.6873695e-01, 3.4841340e-05],\n",
       "       [7.4443877e-01, 2.5366583e-01, 1.8954171e-03],\n",
       "       [5.4060670e-03, 1.8711940e-02, 9.7588193e-01],\n",
       "       [3.1530153e-04, 7.6636076e-02, 9.2304870e-01],\n",
       "       [2.3215990e-02, 7.0600264e-02, 9.0618370e-01],\n",
       "       [3.1530153e-04, 7.6636076e-02, 9.2304870e-01],\n",
       "       [9.5427510e-02, 9.0257627e-01, 1.9961866e-03],\n",
       "       [8.4118134e-01, 1.5863627e-01, 1.8238454e-04],\n",
       "       [7.4443877e-01, 2.5366583e-01, 1.8954171e-03],\n",
       "       [2.3215990e-02, 7.0600264e-02, 9.0618370e-01],\n",
       "       [6.8781220e-01, 3.1206520e-01, 1.2260700e-04],\n",
       "       [7.7877074e-01, 2.1965879e-01, 1.5703891e-03],\n",
       "       [3.1530153e-04, 7.6636076e-02, 9.2304870e-01],\n",
       "       [9.5427510e-02, 9.0257627e-01, 1.9961866e-03],\n",
       "       [5.4060670e-03, 1.8711940e-02, 9.7588193e-01],\n",
       "       [9.5427510e-02, 9.0257627e-01, 1.9961866e-03],\n",
       "       [2.3215990e-02, 7.0600264e-02, 9.0618370e-01],\n",
       "       [8.3122814e-01, 1.6873695e-01, 3.4841340e-05],\n",
       "       [3.1530153e-04, 7.6636076e-02, 9.2304870e-01],\n",
       "       [4.9127400e-01, 5.0866950e-01, 5.6536320e-05],\n",
       "       [8.3122814e-01, 1.6873695e-01, 3.4841340e-05],\n",
       "       [2.8903170e-01, 7.1096000e-01, 8.2981700e-06],\n",
       "       [7.4443877e-01, 2.5366583e-01, 1.8954171e-03],\n",
       "       [7.7877074e-01, 2.1965879e-01, 1.5703891e-03],\n",
       "       [3.1530153e-04, 7.6636076e-02, 9.2304870e-01],\n",
       "       [3.1530153e-04, 7.6636076e-02, 9.2304870e-01],\n",
       "       [3.1530153e-04, 7.6636076e-02, 9.2304870e-01],\n",
       "       [2.3215990e-02, 7.0600264e-02, 9.0618370e-01],\n",
       "       [2.8903170e-01, 7.1096000e-01, 8.2981700e-06],\n",
       "       [8.3122814e-01, 1.6873695e-01, 3.4841340e-05],\n",
       "       [7.4443877e-01, 2.5366583e-01, 1.8954171e-03],\n",
       "       [3.1530153e-04, 7.6636076e-02, 9.2304870e-01],\n",
       "       [8.3122814e-01, 1.6873695e-01, 3.4841340e-05],\n",
       "       [3.1530153e-04, 7.6636076e-02, 9.2304870e-01],\n",
       "       [2.1879259e-01, 7.8111434e-01, 9.3068330e-05],\n",
       "       [9.5427510e-02, 9.0257627e-01, 1.9961866e-03],\n",
       "       [2.8903170e-01, 7.1096000e-01, 8.2981700e-06],\n",
       "       [7.4443877e-01, 2.5366583e-01, 1.8954171e-03],\n",
       "       [1.4610296e-02, 9.8536680e-01, 2.2959444e-05],\n",
       "       [3.1530153e-04, 7.6636076e-02, 9.2304870e-01],\n",
       "       [2.0012042e-01, 7.9914093e-01, 7.3865570e-04],\n",
       "       [2.3215990e-02, 7.0600264e-02, 9.0618370e-01],\n",
       "       [8.4118134e-01, 1.5863627e-01, 1.8238454e-04],\n",
       "       [1.1750608e-03, 9.9881786e-01, 7.0744254e-06],\n",
       "       [3.1530153e-04, 7.6636076e-02, 9.2304870e-01],\n",
       "       [1.1420575e-02, 9.6049994e-01, 2.8079432e-02],\n",
       "       [3.1530153e-04, 7.6636076e-02, 9.2304870e-01],\n",
       "       [7.4443877e-01, 2.5366583e-01, 1.8954171e-03],\n",
       "       [2.1879259e-01, 7.8111434e-01, 9.3068330e-05],\n",
       "       [7.4443877e-01, 2.5366583e-01, 1.8954171e-03],\n",
       "       [7.4443877e-01, 2.5366583e-01, 1.8954171e-03],\n",
       "       [2.3215990e-02, 7.0600264e-02, 9.0618370e-01],\n",
       "       [3.1530153e-04, 7.6636076e-02, 9.2304870e-01],\n",
       "       [2.8903170e-01, 7.1096000e-01, 8.2981700e-06],\n",
       "       [7.4443877e-01, 2.5366583e-01, 1.8954171e-03],\n",
       "       [1.6064316e-02, 9.7856474e-01, 5.3709410e-03],\n",
       "       [3.1530153e-04, 7.6636076e-02, 9.2304870e-01],\n",
       "       [8.3122814e-01, 1.6873695e-01, 3.4841340e-05],\n",
       "       [1.6064316e-02, 9.7856474e-01, 5.3709410e-03],\n",
       "       [2.0012042e-01, 7.9914093e-01, 7.3865570e-04],\n",
       "       [1.6064316e-02, 9.7856474e-01, 5.3709410e-03],\n",
       "       [8.4118134e-01, 1.5863627e-01, 1.8238454e-04],\n",
       "       [7.7877074e-01, 2.1965879e-01, 1.5703891e-03],\n",
       "       [3.1530153e-04, 7.6636076e-02, 9.2304870e-01],\n",
       "       [7.4443877e-01, 2.5366583e-01, 1.8954171e-03],\n",
       "       [3.1530153e-04, 7.6636076e-02, 9.2304870e-01],\n",
       "       [2.8903170e-01, 7.1096000e-01, 8.2981700e-06],\n",
       "       [5.4060670e-03, 1.8711940e-02, 9.7588193e-01],\n",
       "       [3.1530153e-04, 7.6636076e-02, 9.2304870e-01],\n",
       "       [8.3122814e-01, 1.6873695e-01, 3.4841340e-05],\n",
       "       [5.1280327e-02, 9.4870220e-01, 1.7453985e-05],\n",
       "       [8.3122814e-01, 1.6873695e-01, 3.4841340e-05],\n",
       "       [8.3122814e-01, 1.6873695e-01, 3.4841340e-05],\n",
       "       [2.8903170e-01, 7.1096000e-01, 8.2981700e-06],\n",
       "       [7.4443877e-01, 2.5366583e-01, 1.8954171e-03],\n",
       "       [1.6064316e-02, 9.7856474e-01, 5.3709410e-03],\n",
       "       [2.3215990e-02, 7.0600264e-02, 9.0618370e-01],\n",
       "       [1.6064316e-02, 9.7856474e-01, 5.3709410e-03],\n",
       "       [2.8903170e-01, 7.1096000e-01, 8.2981700e-06],\n",
       "       [3.1530153e-04, 7.6636076e-02, 9.2304870e-01],\n",
       "       [8.3122814e-01, 1.6873695e-01, 3.4841340e-05],\n",
       "       [6.1673325e-02, 9.2728430e-01, 1.1042427e-02],\n",
       "       [7.0506064e-03, 9.9284900e-01, 1.0032617e-04],\n",
       "       [9.5427510e-02, 9.0257627e-01, 1.9961866e-03],\n",
       "       [5.4060670e-03, 1.8711940e-02, 9.7588193e-01],\n",
       "       [2.8903170e-01, 7.1096000e-01, 8.2981700e-06],\n",
       "       [1.4610296e-02, 9.8536680e-01, 2.2959444e-05],\n",
       "       [8.3122814e-01, 1.6873695e-01, 3.4841340e-05],\n",
       "       [4.9127400e-01, 5.0866950e-01, 5.6536320e-05],\n",
       "       [9.5427510e-02, 9.0257627e-01, 1.9961866e-03],\n",
       "       [7.4443877e-01, 2.5366583e-01, 1.8954171e-03],\n",
       "       [3.1530153e-04, 7.6636076e-02, 9.2304870e-01],\n",
       "       [2.8903170e-01, 7.1096000e-01, 8.2981700e-06],\n",
       "       [5.4060670e-03, 1.8711940e-02, 9.7588193e-01],\n",
       "       [5.1926150e-01, 4.8068306e-01, 5.5499106e-05],\n",
       "       [1.4610296e-02, 9.8536680e-01, 2.2959444e-05],\n",
       "       [2.3215990e-02, 7.0600264e-02, 9.0618370e-01],\n",
       "       [8.3122814e-01, 1.6873695e-01, 3.4841340e-05],\n",
       "       [2.3215990e-02, 7.0600264e-02, 9.0618370e-01],\n",
       "       [2.8903170e-01, 7.1096000e-01, 8.2981700e-06],\n",
       "       [8.3122814e-01, 1.6873695e-01, 3.4841340e-05],\n",
       "       [8.3122814e-01, 1.6873695e-01, 3.4841340e-05],\n",
       "       [7.4443877e-01, 2.5366583e-01, 1.8954171e-03],\n",
       "       [2.1879259e-01, 7.8111434e-01, 9.3068330e-05],\n",
       "       [3.1530153e-04, 7.6636076e-02, 9.2304870e-01],\n",
       "       [2.3215990e-02, 7.0600264e-02, 9.0618370e-01],\n",
       "       [7.7877074e-01, 2.1965879e-01, 1.5703891e-03],\n",
       "       [2.3215990e-02, 7.0600264e-02, 9.0618370e-01],\n",
       "       [8.3122814e-01, 1.6873695e-01, 3.4841340e-05],\n",
       "       [2.3215990e-02, 7.0600264e-02, 9.0618370e-01],\n",
       "       [2.8903170e-01, 7.1096000e-01, 8.2981700e-06],\n",
       "       [5.4060670e-03, 1.8711940e-02, 9.7588193e-01],\n",
       "       [2.1879259e-01, 7.8111434e-01, 9.3068330e-05],\n",
       "       [3.1530153e-04, 7.6636076e-02, 9.2304870e-01],\n",
       "       [1.1420575e-02, 9.6049994e-01, 2.8079432e-02],\n",
       "       [3.1530153e-04, 7.6636076e-02, 9.2304870e-01],\n",
       "       [7.4443877e-01, 2.5366583e-01, 1.8954171e-03],\n",
       "       [2.1879259e-01, 7.8111434e-01, 9.3068330e-05],\n",
       "       [3.1530153e-04, 7.6636076e-02, 9.2304870e-01],\n",
       "       [2.8903170e-01, 7.1096000e-01, 8.2981700e-06],\n",
       "       [7.4443877e-01, 2.5366583e-01, 1.8954171e-03],\n",
       "       [1.6064316e-02, 9.7856474e-01, 5.3709410e-03],\n",
       "       [3.1530153e-04, 7.6636076e-02, 9.2304870e-01],\n",
       "       [7.4443877e-01, 2.5366583e-01, 1.8954171e-03],\n",
       "       [6.1793166e-01, 3.8200855e-01, 5.9805454e-05],\n",
       "       [1.4882761e-03, 9.6711860e-01, 3.1393055e-02],\n",
       "       [3.1530153e-04, 7.6636076e-02, 9.2304870e-01],\n",
       "       [3.1530153e-04, 7.6636076e-02, 9.2304870e-01],\n",
       "       [8.3122814e-01, 1.6873695e-01, 3.4841340e-05],\n",
       "       [3.1530153e-04, 7.6636076e-02, 9.2304870e-01],\n",
       "       [2.1879259e-01, 7.8111434e-01, 9.3068330e-05],\n",
       "       [5.4060670e-03, 1.8711940e-02, 9.7588193e-01],\n",
       "       [3.1530153e-04, 7.6636076e-02, 9.2304870e-01],\n",
       "       [2.8903170e-01, 7.1096000e-01, 8.2981700e-06],\n",
       "       [9.5427510e-02, 9.0257627e-01, 1.9961866e-03],\n",
       "       [2.3215990e-02, 7.0600264e-02, 9.0618370e-01],\n",
       "       [2.1879259e-01, 7.8111434e-01, 9.3068330e-05],\n",
       "       [7.7877074e-01, 2.1965879e-01, 1.5703891e-03],\n",
       "       [2.8903170e-01, 7.1096000e-01, 8.2981700e-06],\n",
       "       [3.1530153e-04, 7.6636076e-02, 9.2304870e-01],\n",
       "       [2.3215990e-02, 7.0600264e-02, 9.0618370e-01],\n",
       "       [8.3122814e-01, 1.6873695e-01, 3.4841340e-05],\n",
       "       [6.1793166e-01, 3.8200855e-01, 5.9805454e-05],\n",
       "       [8.3122814e-01, 1.6873695e-01, 3.4841340e-05],\n",
       "       [7.4443877e-01, 2.5366583e-01, 1.8954171e-03],\n",
       "       [3.1530153e-04, 7.6636076e-02, 9.2304870e-01],\n",
       "       [3.1530153e-04, 7.6636076e-02, 9.2304870e-01],\n",
       "       [5.4060670e-03, 1.8711940e-02, 9.7588193e-01],\n",
       "       [9.5427510e-02, 9.0257627e-01, 1.9961866e-03],\n",
       "       [2.1879259e-01, 7.8111434e-01, 9.3068330e-05],\n",
       "       [7.4443877e-01, 2.5366583e-01, 1.8954171e-03],\n",
       "       [3.1530153e-04, 7.6636076e-02, 9.2304870e-01],\n",
       "       [1.4610296e-02, 9.8536680e-01, 2.2959444e-05],\n",
       "       [3.1530153e-04, 7.6636076e-02, 9.2304870e-01],\n",
       "       [4.9127400e-01, 5.0866950e-01, 5.6536320e-05],\n",
       "       [8.3122814e-01, 1.6873695e-01, 3.4841340e-05],\n",
       "       [5.4060670e-03, 1.8711940e-02, 9.7588193e-01],\n",
       "       [2.1879259e-01, 7.8111434e-01, 9.3068330e-05],\n",
       "       [2.3215990e-02, 7.0600264e-02, 9.0618370e-01],\n",
       "       [2.0012042e-01, 7.9914093e-01, 7.3865570e-04],\n",
       "       [7.7877074e-01, 2.1965879e-01, 1.5703891e-03],\n",
       "       [9.5427510e-02, 9.0257627e-01, 1.9961866e-03],\n",
       "       [3.1530153e-04, 7.6636076e-02, 9.2304870e-01],\n",
       "       [4.9127400e-01, 5.0866950e-01, 5.6536320e-05],\n",
       "       [3.1530153e-04, 7.6636076e-02, 9.2304870e-01],\n",
       "       [7.4443877e-01, 2.5366583e-01, 1.8954171e-03],\n",
       "       [9.5427510e-02, 9.0257627e-01, 1.9961866e-03],\n",
       "       [7.7877074e-01, 2.1965879e-01, 1.5703891e-03],\n",
       "       [6.1793166e-01, 3.8200855e-01, 5.9805454e-05],\n",
       "       [5.4060670e-03, 1.8711940e-02, 9.7588193e-01],\n",
       "       [8.3122814e-01, 1.6873695e-01, 3.4841340e-05],\n",
       "       [2.3215990e-02, 7.0600264e-02, 9.0618370e-01],\n",
       "       [9.5427510e-02, 9.0257627e-01, 1.9961866e-03],\n",
       "       [8.3122814e-01, 1.6873695e-01, 3.4841340e-05],\n",
       "       [6.1793166e-01, 3.8200855e-01, 5.9805454e-05],\n",
       "       [7.7877074e-01, 2.1965879e-01, 1.5703891e-03],\n",
       "       [8.3122814e-01, 1.6873695e-01, 3.4841340e-05],\n",
       "       [8.3122814e-01, 1.6873695e-01, 3.4841340e-05],\n",
       "       [3.1530153e-04, 7.6636076e-02, 9.2304870e-01],\n",
       "       [3.1530153e-04, 7.6636076e-02, 9.2304870e-01],\n",
       "       [2.3215990e-02, 7.0600264e-02, 9.0618370e-01],\n",
       "       [8.3122814e-01, 1.6873695e-01, 3.4841340e-05],\n",
       "       [5.4060670e-03, 1.8711940e-02, 9.7588193e-01],\n",
       "       [1.4882761e-03, 9.6711860e-01, 3.1393055e-02],\n",
       "       [5.4060670e-03, 1.8711940e-02, 9.7588193e-01],\n",
       "       [7.4443877e-01, 2.5366583e-01, 1.8954171e-03],\n",
       "       [5.4060670e-03, 1.8711940e-02, 9.7588193e-01],\n",
       "       [1.4882761e-03, 9.6711860e-01, 3.1393055e-02],\n",
       "       [8.3122814e-01, 1.6873695e-01, 3.4841340e-05],\n",
       "       [6.1793166e-01, 3.8200855e-01, 5.9805454e-05],\n",
       "       [7.4443877e-01, 2.5366583e-01, 1.8954171e-03],\n",
       "       [8.3122814e-01, 1.6873695e-01, 3.4841340e-05]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob2 = df_proba2[df_proba2['phage']=='pyokpresabs_qual'].iloc[:,-3:]\n",
    "y_prob2 = y_prob2.to_numpy()\n",
    "y_prob2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9405159937602686"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo2 = rocauc_ovo(y_test_over, y_prob2, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9405159937602686"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr2 = rocauc_ovr(y_test_over, y_prob2, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=345,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat3 = pd.DataFrame(X_test_over[:,0])\n",
    "dat3['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS168</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS383</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS213</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>NRS266</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>NRS001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>NRS112</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>196 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0  test\n",
       "0    NRS168     1\n",
       "1    NRS383     1\n",
       "2    NRS148     2\n",
       "3    NRS109     2\n",
       "4    NRS213     0\n",
       "..      ...   ...\n",
       "191  NRS255     2\n",
       "192  NRS255     2\n",
       "193  NRS266     1\n",
       "194  NRS001     1\n",
       "195  NRS112     1\n",
       "\n",
       "[196 rows x 2 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over3 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over3.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 455 samples, validate on 196 samples\n",
      "Epoch 1/100\n",
      "455/455 [==============================] - 0s 513us/step - loss: 1.0341 - accuracy: 0.4484 - val_loss: 0.9584 - val_accuracy: 0.5357\n",
      "Epoch 2/100\n",
      "455/455 [==============================] - 0s 141us/step - loss: 0.8932 - accuracy: 0.6352 - val_loss: 0.8620 - val_accuracy: 0.6735\n",
      "Epoch 3/100\n",
      "455/455 [==============================] - 0s 191us/step - loss: 0.7950 - accuracy: 0.7011 - val_loss: 0.7837 - val_accuracy: 0.7449\n",
      "Epoch 4/100\n",
      "455/455 [==============================] - 0s 241us/step - loss: 0.7085 - accuracy: 0.7736 - val_loss: 0.7138 - val_accuracy: 0.7449\n",
      "Epoch 5/100\n",
      "455/455 [==============================] - 0s 173us/step - loss: 0.6338 - accuracy: 0.7780 - val_loss: 0.6605 - val_accuracy: 0.7500\n",
      "Epoch 6/100\n",
      "455/455 [==============================] - 0s 165us/step - loss: 0.5699 - accuracy: 0.7758 - val_loss: 0.6056 - val_accuracy: 0.7347\n",
      "Epoch 7/100\n",
      "455/455 [==============================] - 0s 118us/step - loss: 0.5177 - accuracy: 0.7824 - val_loss: 0.5795 - val_accuracy: 0.7755\n",
      "Epoch 8/100\n",
      "455/455 [==============================] - 0s 115us/step - loss: 0.4852 - accuracy: 0.8022 - val_loss: 0.5470 - val_accuracy: 0.7602\n",
      "Epoch 9/100\n",
      "455/455 [==============================] - 0s 140us/step - loss: 0.4585 - accuracy: 0.8132 - val_loss: 0.5287 - val_accuracy: 0.8316\n",
      "Epoch 10/100\n",
      "455/455 [==============================] - 0s 234us/step - loss: 0.4401 - accuracy: 0.8220 - val_loss: 0.5146 - val_accuracy: 0.8316\n",
      "Epoch 11/100\n",
      "455/455 [==============================] - 0s 118us/step - loss: 0.4221 - accuracy: 0.8352 - val_loss: 0.5101 - val_accuracy: 0.7908\n",
      "Epoch 12/100\n",
      "455/455 [==============================] - 0s 98us/step - loss: 0.4110 - accuracy: 0.8374 - val_loss: 0.4999 - val_accuracy: 0.8163\n",
      "Epoch 13/100\n",
      "455/455 [==============================] - 0s 107us/step - loss: 0.3996 - accuracy: 0.8462 - val_loss: 0.4918 - val_accuracy: 0.8214\n",
      "Epoch 14/100\n",
      "455/455 [==============================] - 0s 100us/step - loss: 0.3941 - accuracy: 0.8418 - val_loss: 0.4917 - val_accuracy: 0.8214\n",
      "Epoch 15/100\n",
      "455/455 [==============================] - 0s 127us/step - loss: 0.3874 - accuracy: 0.8593 - val_loss: 0.4847 - val_accuracy: 0.8214\n",
      "Epoch 16/100\n",
      "455/455 [==============================] - 0s 137us/step - loss: 0.3841 - accuracy: 0.8527 - val_loss: 0.4874 - val_accuracy: 0.8214\n",
      "Epoch 17/100\n",
      "455/455 [==============================] - 0s 265us/step - loss: 0.3772 - accuracy: 0.8659 - val_loss: 0.4900 - val_accuracy: 0.7959\n",
      "Epoch 18/100\n",
      "455/455 [==============================] - 0s 270us/step - loss: 0.3738 - accuracy: 0.8637 - val_loss: 0.4838 - val_accuracy: 0.8214\n",
      "Epoch 19/100\n",
      "455/455 [==============================] - 0s 193us/step - loss: 0.3670 - accuracy: 0.8681 - val_loss: 0.4787 - val_accuracy: 0.8214\n",
      "Epoch 20/100\n",
      "455/455 [==============================] - 0s 156us/step - loss: 0.3649 - accuracy: 0.8703 - val_loss: 0.4838 - val_accuracy: 0.8214\n",
      "Epoch 21/100\n",
      "455/455 [==============================] - 0s 154us/step - loss: 0.3639 - accuracy: 0.8593 - val_loss: 0.4810 - val_accuracy: 0.8214\n",
      "Epoch 22/100\n",
      "455/455 [==============================] - 0s 183us/step - loss: 0.3594 - accuracy: 0.8703 - val_loss: 0.4804 - val_accuracy: 0.8214\n",
      "Epoch 23/100\n",
      "455/455 [==============================] - 0s 165us/step - loss: 0.3565 - accuracy: 0.8615 - val_loss: 0.4777 - val_accuracy: 0.8214\n",
      "Epoch 24/100\n",
      "455/455 [==============================] - 0s 122us/step - loss: 0.3530 - accuracy: 0.8703 - val_loss: 0.4821 - val_accuracy: 0.8265\n",
      "Epoch 25/100\n",
      "455/455 [==============================] - 0s 97us/step - loss: 0.3547 - accuracy: 0.8615 - val_loss: 0.4711 - val_accuracy: 0.8214\n",
      "Epoch 26/100\n",
      "455/455 [==============================] - 0s 99us/step - loss: 0.3523 - accuracy: 0.8659 - val_loss: 0.4879 - val_accuracy: 0.8010\n",
      "Epoch 27/100\n",
      "455/455 [==============================] - 0s 277us/step - loss: 0.3508 - accuracy: 0.8637 - val_loss: 0.4760 - val_accuracy: 0.8265\n",
      "Epoch 28/100\n",
      "455/455 [==============================] - 0s 389us/step - loss: 0.3485 - accuracy: 0.8615 - val_loss: 0.4783 - val_accuracy: 0.8265\n",
      "Epoch 29/100\n",
      "455/455 [==============================] - 0s 186us/step - loss: 0.3496 - accuracy: 0.8747 - val_loss: 0.4819 - val_accuracy: 0.8265\n",
      "Epoch 30/100\n",
      "455/455 [==============================] - 0s 215us/step - loss: 0.3441 - accuracy: 0.8725 - val_loss: 0.4799 - val_accuracy: 0.8265\n",
      "Epoch 31/100\n",
      "455/455 [==============================] - 0s 200us/step - loss: 0.3443 - accuracy: 0.8769 - val_loss: 0.4822 - val_accuracy: 0.8265\n",
      "Epoch 32/100\n",
      "455/455 [==============================] - 0s 353us/step - loss: 0.3468 - accuracy: 0.8681 - val_loss: 0.4840 - val_accuracy: 0.8265\n",
      "Epoch 33/100\n",
      "455/455 [==============================] - 0s 327us/step - loss: 0.3430 - accuracy: 0.8571 - val_loss: 0.4740 - val_accuracy: 0.8265\n",
      "Epoch 34/100\n",
      "455/455 [==============================] - 0s 271us/step - loss: 0.3402 - accuracy: 0.8703 - val_loss: 0.4929 - val_accuracy: 0.8010\n",
      "Epoch 35/100\n",
      "455/455 [==============================] - 0s 354us/step - loss: 0.3380 - accuracy: 0.8637 - val_loss: 0.4847 - val_accuracy: 0.8265\n",
      "Epoch 36/100\n",
      "455/455 [==============================] - 0s 298us/step - loss: 0.3380 - accuracy: 0.8747 - val_loss: 0.4832 - val_accuracy: 0.8265\n",
      "Epoch 37/100\n",
      "455/455 [==============================] - 0s 267us/step - loss: 0.3393 - accuracy: 0.8769 - val_loss: 0.4809 - val_accuracy: 0.8265\n",
      "Epoch 38/100\n",
      "455/455 [==============================] - 0s 278us/step - loss: 0.3353 - accuracy: 0.8725 - val_loss: 0.4895 - val_accuracy: 0.8265\n",
      "Epoch 39/100\n",
      "455/455 [==============================] - 0s 347us/step - loss: 0.3372 - accuracy: 0.8747 - val_loss: 0.4974 - val_accuracy: 0.8265\n",
      "Epoch 40/100\n",
      "455/455 [==============================] - 0s 352us/step - loss: 0.3328 - accuracy: 0.8747 - val_loss: 0.4905 - val_accuracy: 0.8265\n",
      "Epoch 41/100\n",
      "455/455 [==============================] - 0s 244us/step - loss: 0.3334 - accuracy: 0.8747 - val_loss: 0.4919 - val_accuracy: 0.8265\n",
      "Epoch 42/100\n",
      "455/455 [==============================] - 0s 229us/step - loss: 0.3351 - accuracy: 0.8769 - val_loss: 0.4977 - val_accuracy: 0.8265\n",
      "Epoch 43/100\n",
      "455/455 [==============================] - 0s 110us/step - loss: 0.3329 - accuracy: 0.8747 - val_loss: 0.4900 - val_accuracy: 0.8265\n",
      "Epoch 44/100\n",
      "455/455 [==============================] - 0s 100us/step - loss: 0.3328 - accuracy: 0.8681 - val_loss: 0.4903 - val_accuracy: 0.8265\n",
      "Epoch 45/100\n",
      "455/455 [==============================] - 0s 90us/step - loss: 0.3337 - accuracy: 0.8725 - val_loss: 0.4990 - val_accuracy: 0.8265\n",
      "Epoch 46/100\n",
      "455/455 [==============================] - 0s 94us/step - loss: 0.3297 - accuracy: 0.8791 - val_loss: 0.4910 - val_accuracy: 0.8265\n",
      "Epoch 47/100\n",
      "455/455 [==============================] - 0s 93us/step - loss: 0.3288 - accuracy: 0.8769 - val_loss: 0.5063 - val_accuracy: 0.8265\n",
      "Epoch 48/100\n",
      "455/455 [==============================] - 0s 95us/step - loss: 0.3316 - accuracy: 0.8769 - val_loss: 0.4927 - val_accuracy: 0.8265\n",
      "Epoch 49/100\n",
      "455/455 [==============================] - 0s 93us/step - loss: 0.3274 - accuracy: 0.8769 - val_loss: 0.4928 - val_accuracy: 0.8265\n",
      "Epoch 50/100\n",
      "455/455 [==============================] - 0s 218us/step - loss: 0.3319 - accuracy: 0.8791 - val_loss: 0.5124 - val_accuracy: 0.8265\n",
      "Epoch 51/100\n",
      "455/455 [==============================] - 0s 247us/step - loss: 0.3311 - accuracy: 0.8747 - val_loss: 0.4968 - val_accuracy: 0.8265\n",
      "Epoch 52/100\n",
      "455/455 [==============================] - 0s 318us/step - loss: 0.3276 - accuracy: 0.8791 - val_loss: 0.5072 - val_accuracy: 0.8265\n",
      "Epoch 53/100\n",
      "455/455 [==============================] - 0s 133us/step - loss: 0.3257 - accuracy: 0.8747 - val_loss: 0.4976 - val_accuracy: 0.8265\n",
      "Epoch 54/100\n",
      "455/455 [==============================] - 0s 107us/step - loss: 0.3232 - accuracy: 0.8769 - val_loss: 0.5068 - val_accuracy: 0.8265\n",
      "Epoch 55/100\n",
      "455/455 [==============================] - 0s 94us/step - loss: 0.3233 - accuracy: 0.8725 - val_loss: 0.5021 - val_accuracy: 0.8265\n",
      "Epoch 56/100\n",
      "455/455 [==============================] - 0s 92us/step - loss: 0.3248 - accuracy: 0.8791 - val_loss: 0.5043 - val_accuracy: 0.8265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "455/455 [==============================] - 0s 102us/step - loss: 0.3249 - accuracy: 0.8791 - val_loss: 0.5087 - val_accuracy: 0.8265\n",
      "Epoch 58/100\n",
      "455/455 [==============================] - 0s 91us/step - loss: 0.3213 - accuracy: 0.8791 - val_loss: 0.5079 - val_accuracy: 0.8265\n",
      "Epoch 59/100\n",
      "455/455 [==============================] - 0s 92us/step - loss: 0.3251 - accuracy: 0.8791 - val_loss: 0.5159 - val_accuracy: 0.8265\n",
      "Epoch 60/100\n",
      "455/455 [==============================] - 0s 89us/step - loss: 0.3241 - accuracy: 0.8791 - val_loss: 0.5217 - val_accuracy: 0.8265\n",
      "Epoch 61/100\n",
      "455/455 [==============================] - 0s 90us/step - loss: 0.3237 - accuracy: 0.8791 - val_loss: 0.5071 - val_accuracy: 0.8265\n",
      "Epoch 62/100\n",
      "455/455 [==============================] - 0s 89us/step - loss: 0.3220 - accuracy: 0.8791 - val_loss: 0.5121 - val_accuracy: 0.8265\n",
      "Epoch 63/100\n",
      "455/455 [==============================] - 0s 124us/step - loss: 0.3231 - accuracy: 0.8791 - val_loss: 0.5186 - val_accuracy: 0.8265\n",
      "Epoch 64/100\n",
      "455/455 [==============================] - 0s 244us/step - loss: 0.3227 - accuracy: 0.8791 - val_loss: 0.5197 - val_accuracy: 0.8265\n",
      "Epoch 65/100\n",
      "455/455 [==============================] - 0s 257us/step - loss: 0.3226 - accuracy: 0.8791 - val_loss: 0.5239 - val_accuracy: 0.8265\n",
      "Epoch 66/100\n",
      "455/455 [==============================] - 0s 197us/step - loss: 0.3244 - accuracy: 0.8791 - val_loss: 0.5133 - val_accuracy: 0.8265\n",
      "Epoch 67/100\n",
      "455/455 [==============================] - 0s 133us/step - loss: 0.3200 - accuracy: 0.8791 - val_loss: 0.5246 - val_accuracy: 0.8265\n",
      "Epoch 68/100\n",
      "455/455 [==============================] - 0s 96us/step - loss: 0.3184 - accuracy: 0.8791 - val_loss: 0.5167 - val_accuracy: 0.8265\n",
      "Epoch 69/100\n",
      "455/455 [==============================] - 0s 97us/step - loss: 0.3193 - accuracy: 0.8791 - val_loss: 0.5202 - val_accuracy: 0.8265\n",
      "Epoch 70/100\n",
      "455/455 [==============================] - 0s 94us/step - loss: 0.3223 - accuracy: 0.8791 - val_loss: 0.5238 - val_accuracy: 0.8265\n",
      "Epoch 71/100\n",
      "455/455 [==============================] - 0s 140us/step - loss: 0.3185 - accuracy: 0.8791 - val_loss: 0.5174 - val_accuracy: 0.8265\n",
      "Epoch 72/100\n",
      "455/455 [==============================] - 0s 121us/step - loss: 0.3213 - accuracy: 0.8791 - val_loss: 0.5203 - val_accuracy: 0.8265\n",
      "Epoch 73/100\n",
      "455/455 [==============================] - 0s 95us/step - loss: 0.3236 - accuracy: 0.8791 - val_loss: 0.5154 - val_accuracy: 0.8265\n",
      "Epoch 74/100\n",
      "455/455 [==============================] - 0s 93us/step - loss: 0.3205 - accuracy: 0.8791 - val_loss: 0.5240 - val_accuracy: 0.8265\n",
      "Epoch 75/100\n",
      "455/455 [==============================] - 0s 90us/step - loss: 0.3195 - accuracy: 0.8791 - val_loss: 0.5239 - val_accuracy: 0.8265\n",
      "Epoch 76/100\n",
      "455/455 [==============================] - 0s 101us/step - loss: 0.3204 - accuracy: 0.8791 - val_loss: 0.5200 - val_accuracy: 0.8265\n",
      "Epoch 77/100\n",
      "455/455 [==============================] - 0s 89us/step - loss: 0.3182 - accuracy: 0.8791 - val_loss: 0.5281 - val_accuracy: 0.8265\n",
      "Epoch 78/100\n",
      "455/455 [==============================] - 0s 94us/step - loss: 0.3226 - accuracy: 0.8791 - val_loss: 0.5187 - val_accuracy: 0.8265\n",
      "Epoch 79/100\n",
      "455/455 [==============================] - 0s 122us/step - loss: 0.3202 - accuracy: 0.8791 - val_loss: 0.5275 - val_accuracy: 0.8265\n",
      "Epoch 80/100\n",
      "455/455 [==============================] - 0s 96us/step - loss: 0.3177 - accuracy: 0.8791 - val_loss: 0.5291 - val_accuracy: 0.8265\n",
      "Epoch 81/100\n",
      "455/455 [==============================] - 0s 99us/step - loss: 0.3180 - accuracy: 0.8813 - val_loss: 0.5251 - val_accuracy: 0.8265\n",
      "Epoch 82/100\n",
      "455/455 [==============================] - 0s 130us/step - loss: 0.3159 - accuracy: 0.8813 - val_loss: 0.5203 - val_accuracy: 0.8265\n",
      "Epoch 83/100\n",
      "455/455 [==============================] - 0s 116us/step - loss: 0.3172 - accuracy: 0.8813 - val_loss: 0.5334 - val_accuracy: 0.8265\n",
      "Epoch 84/100\n",
      "455/455 [==============================] - 0s 94us/step - loss: 0.3175 - accuracy: 0.8813 - val_loss: 0.5340 - val_accuracy: 0.8265\n",
      "Epoch 85/100\n",
      "455/455 [==============================] - 0s 90us/step - loss: 0.3177 - accuracy: 0.8703 - val_loss: 0.5227 - val_accuracy: 0.8265\n",
      "Epoch 86/100\n",
      "455/455 [==============================] - 0s 93us/step - loss: 0.3219 - accuracy: 0.8813 - val_loss: 0.5392 - val_accuracy: 0.8265\n",
      "Epoch 87/100\n",
      "455/455 [==============================] - 0s 93us/step - loss: 0.3211 - accuracy: 0.8813 - val_loss: 0.5325 - val_accuracy: 0.8265\n",
      "Epoch 88/100\n",
      "455/455 [==============================] - 0s 166us/step - loss: 0.3169 - accuracy: 0.8813 - val_loss: 0.5314 - val_accuracy: 0.8265\n",
      "Epoch 89/100\n",
      "455/455 [==============================] - 0s 104us/step - loss: 0.3246 - accuracy: 0.8813 - val_loss: 0.5332 - val_accuracy: 0.8265\n",
      "Epoch 90/100\n",
      "455/455 [==============================] - 0s 121us/step - loss: 0.3169 - accuracy: 0.8813 - val_loss: 0.5263 - val_accuracy: 0.8265\n",
      "Epoch 91/100\n",
      "455/455 [==============================] - 0s 96us/step - loss: 0.3156 - accuracy: 0.8813 - val_loss: 0.5362 - val_accuracy: 0.8265\n",
      "Epoch 92/100\n",
      "455/455 [==============================] - 0s 88us/step - loss: 0.3197 - accuracy: 0.8813 - val_loss: 0.5248 - val_accuracy: 0.8265\n",
      "Epoch 93/100\n",
      "455/455 [==============================] - 0s 101us/step - loss: 0.3187 - accuracy: 0.8813 - val_loss: 0.5430 - val_accuracy: 0.8265\n",
      "Epoch 94/100\n",
      "455/455 [==============================] - 0s 89us/step - loss: 0.3262 - accuracy: 0.8747 - val_loss: 0.5232 - val_accuracy: 0.8265\n",
      "Epoch 95/100\n",
      "455/455 [==============================] - 0s 102us/step - loss: 0.3175 - accuracy: 0.8813 - val_loss: 0.5345 - val_accuracy: 0.8265\n",
      "Epoch 96/100\n",
      "455/455 [==============================] - 0s 99us/step - loss: 0.3155 - accuracy: 0.8813 - val_loss: 0.5420 - val_accuracy: 0.8265\n",
      "Epoch 97/100\n",
      "455/455 [==============================] - 0s 91us/step - loss: 0.3146 - accuracy: 0.8813 - val_loss: 0.5468 - val_accuracy: 0.8265\n",
      "Epoch 98/100\n",
      "455/455 [==============================] - 0s 93us/step - loss: 0.3172 - accuracy: 0.8813 - val_loss: 0.5357 - val_accuracy: 0.8265\n",
      "Epoch 99/100\n",
      "455/455 [==============================] - 0s 176us/step - loss: 0.3171 - accuracy: 0.8813 - val_loss: 0.5375 - val_accuracy: 0.8265\n",
      "Epoch 100/100\n",
      "455/455 [==============================] - 0s 130us/step - loss: 0.3160 - accuracy: 0.8813 - val_loss: 0.5345 - val_accuracy: 0.8265\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a3eca20f0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over3.fit(X_train_over, y_train_over,\n",
    "          batch_size=16, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196/196 [==============================] - 0s 51us/step\n",
      "over-sampling test accuracy: 83.16%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over3 = model1_over3.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over3*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 2, 2, 0, 0, 0, 2, 1, 0, 0, 2, 1, 0, 0, 1, 0, 0, 2, 2, 2, 1,\n",
       "       0, 2, 0, 1, 2, 1, 1, 0, 0, 2, 1, 2, 1, 1, 1, 2, 1, 2, 0, 2, 0, 2,\n",
       "       0, 1, 2, 1, 1, 2, 0, 2, 1, 0, 0, 2, 0, 0, 2, 1, 2, 1, 0, 0, 2, 1,\n",
       "       1, 0, 2, 0, 1, 0, 0, 0, 0, 2, 2, 0, 0, 0, 2, 0, 0, 2, 0, 2, 0, 0,\n",
       "       2, 1, 2, 0, 0, 2, 0, 1, 2, 2, 1, 2, 2, 1, 2, 2, 0, 0, 2, 1, 2, 1,\n",
       "       1, 2, 1, 1, 1, 1, 1, 2, 2, 1, 1, 2, 0, 2, 0, 1, 0, 1, 0, 2, 2, 0,\n",
       "       1, 2, 2, 2, 2, 2, 2, 0, 1, 0, 0, 2, 1, 1, 1, 2, 0, 2, 2, 0, 2, 0,\n",
       "       0, 1, 2, 0, 1, 0, 0, 0, 2, 0, 0, 0, 0, 2, 2, 0, 1, 1, 2, 0, 1, 2,\n",
       "       2, 0, 2, 0, 1, 2, 0, 2, 0, 2, 1, 1, 0, 0, 2, 2, 2, 1, 1, 1])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred3 = model1_over3.predict_classes(X_test_over)\n",
    "pred3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS168</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS383</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS213</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>NRS266</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>NRS001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>NRS112</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>196 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0  test  pred\n",
       "0    NRS168     1     1\n",
       "1    NRS383     1     1\n",
       "2    NRS148     2     2\n",
       "3    NRS109     2     2\n",
       "4    NRS213     0     0\n",
       "..      ...   ...   ...\n",
       "191  NRS255     2     2\n",
       "192  NRS255     2     2\n",
       "193  NRS266     1     1\n",
       "194  NRS001     1     1\n",
       "195  NRS112     1     1\n",
       "\n",
       "[196 rows x 3 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat3['pred'] = pred3\n",
    "dat3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba3 = model1_over3.predict_proba(X_test_over)\n",
    "dat_proba3 = pd.DataFrame(proba3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.105407</td>\n",
       "      <td>0.894581</td>\n",
       "      <td>1.162835e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.195538</td>\n",
       "      <td>0.804347</td>\n",
       "      <td>1.152475e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.072096</td>\n",
       "      <td>9.278851e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.104697</td>\n",
       "      <td>8.952906e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.693035</td>\n",
       "      <td>0.306428</td>\n",
       "      <td>5.368003e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.001517</td>\n",
       "      <td>9.984261e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.001517</td>\n",
       "      <td>9.984261e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>0.018125</td>\n",
       "      <td>0.981694</td>\n",
       "      <td>1.806314e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>0.321893</td>\n",
       "      <td>0.678106</td>\n",
       "      <td>5.015443e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.997759</td>\n",
       "      <td>2.162200e-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>196 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1             2\n",
       "0    0.105407  0.894581  1.162835e-05\n",
       "1    0.195538  0.804347  1.152475e-04\n",
       "2    0.000019  0.072096  9.278851e-01\n",
       "3    0.000013  0.104697  8.952906e-01\n",
       "4    0.693035  0.306428  5.368003e-04\n",
       "..        ...       ...           ...\n",
       "191  0.000057  0.001517  9.984261e-01\n",
       "192  0.000057  0.001517  9.984261e-01\n",
       "193  0.018125  0.981694  1.806314e-04\n",
       "194  0.321893  0.678106  5.015443e-07\n",
       "195  0.000079  0.997759  2.162200e-03\n",
       "\n",
       "[196 rows x 3 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba3.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba3.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat3.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/3pyo.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 455 samples, validate on 196 samples\n",
      "Epoch 1/100\n",
      "455/455 [==============================] - 0s 194us/step - loss: 0.3208 - accuracy: 0.8791 - val_loss: 0.5455 - val_accuracy: 0.8316\n",
      "Epoch 2/100\n",
      "455/455 [==============================] - 0s 115us/step - loss: 0.3182 - accuracy: 0.8791 - val_loss: 0.5475 - val_accuracy: 0.8316\n",
      "Epoch 3/100\n",
      "455/455 [==============================] - 0s 100us/step - loss: 0.3154 - accuracy: 0.8791 - val_loss: 0.5544 - val_accuracy: 0.8316\n",
      "Epoch 4/100\n",
      "455/455 [==============================] - 0s 95us/step - loss: 0.3138 - accuracy: 0.8791 - val_loss: 0.5540 - val_accuracy: 0.8316\n",
      "Epoch 5/100\n",
      "455/455 [==============================] - 0s 104us/step - loss: 0.3186 - accuracy: 0.8791 - val_loss: 0.5419 - val_accuracy: 0.8316\n",
      "Epoch 6/100\n",
      "455/455 [==============================] - 0s 111us/step - loss: 0.3140 - accuracy: 0.8791 - val_loss: 0.5509 - val_accuracy: 0.8316\n",
      "Epoch 7/100\n",
      "455/455 [==============================] - 0s 109us/step - loss: 0.3164 - accuracy: 0.8813 - val_loss: 0.5511 - val_accuracy: 0.8316\n",
      "Epoch 8/100\n",
      "455/455 [==============================] - 0s 103us/step - loss: 0.3184 - accuracy: 0.8813 - val_loss: 0.5477 - val_accuracy: 0.8316\n",
      "Epoch 9/100\n",
      "455/455 [==============================] - 0s 103us/step - loss: 0.3207 - accuracy: 0.8813 - val_loss: 0.5462 - val_accuracy: 0.8316\n",
      "Epoch 10/100\n",
      "455/455 [==============================] - 0s 135us/step - loss: 0.3160 - accuracy: 0.8791 - val_loss: 0.5517 - val_accuracy: 0.8316\n",
      "Epoch 11/100\n",
      "455/455 [==============================] - 0s 180us/step - loss: 0.3153 - accuracy: 0.8813 - val_loss: 0.5496 - val_accuracy: 0.8316\n",
      "Epoch 12/100\n",
      "455/455 [==============================] - 0s 128us/step - loss: 0.3144 - accuracy: 0.8813 - val_loss: 0.5489 - val_accuracy: 0.8316\n",
      "Epoch 13/100\n",
      "455/455 [==============================] - 0s 105us/step - loss: 0.3132 - accuracy: 0.8791 - val_loss: 0.5535 - val_accuracy: 0.8316\n",
      "Epoch 14/100\n",
      "455/455 [==============================] - 0s 108us/step - loss: 0.3155 - accuracy: 0.8813 - val_loss: 0.5571 - val_accuracy: 0.8316\n",
      "Epoch 15/100\n",
      "455/455 [==============================] - 0s 105us/step - loss: 0.3140 - accuracy: 0.8813 - val_loss: 0.5485 - val_accuracy: 0.8316\n",
      "Epoch 16/100\n",
      "455/455 [==============================] - 0s 103us/step - loss: 0.3144 - accuracy: 0.8813 - val_loss: 0.5521 - val_accuracy: 0.8316\n",
      "Epoch 17/100\n",
      "455/455 [==============================] - 0s 108us/step - loss: 0.3144 - accuracy: 0.8813 - val_loss: 0.5476 - val_accuracy: 0.8316\n",
      "Epoch 18/100\n",
      "455/455 [==============================] - 0s 106us/step - loss: 0.3140 - accuracy: 0.8813 - val_loss: 0.5581 - val_accuracy: 0.8316\n",
      "Epoch 19/100\n",
      "455/455 [==============================] - 0s 111us/step - loss: 0.3124 - accuracy: 0.8813 - val_loss: 0.5533 - val_accuracy: 0.8316\n",
      "Epoch 20/100\n",
      "455/455 [==============================] - 0s 126us/step - loss: 0.3145 - accuracy: 0.8813 - val_loss: 0.5519 - val_accuracy: 0.8316\n",
      "Epoch 21/100\n",
      "455/455 [==============================] - 0s 130us/step - loss: 0.3151 - accuracy: 0.8813 - val_loss: 0.5573 - val_accuracy: 0.8316\n",
      "Epoch 22/100\n",
      "455/455 [==============================] - 0s 139us/step - loss: 0.3181 - accuracy: 0.8813 - val_loss: 0.5526 - val_accuracy: 0.8316\n",
      "Epoch 23/100\n",
      "455/455 [==============================] - 0s 150us/step - loss: 0.3199 - accuracy: 0.8813 - val_loss: 0.5544 - val_accuracy: 0.8316\n",
      "Epoch 24/100\n",
      "455/455 [==============================] - 0s 248us/step - loss: 0.3186 - accuracy: 0.8813 - val_loss: 0.5584 - val_accuracy: 0.8316\n",
      "Epoch 25/100\n",
      "455/455 [==============================] - 0s 205us/step - loss: 0.3140 - accuracy: 0.8813 - val_loss: 0.5592 - val_accuracy: 0.8316\n",
      "Epoch 26/100\n",
      "455/455 [==============================] - 0s 163us/step - loss: 0.3194 - accuracy: 0.8813 - val_loss: 0.5562 - val_accuracy: 0.8316\n",
      "Epoch 27/100\n",
      "455/455 [==============================] - 0s 210us/step - loss: 0.3137 - accuracy: 0.8813 - val_loss: 0.5603 - val_accuracy: 0.8316\n",
      "Epoch 28/100\n",
      "455/455 [==============================] - 0s 183us/step - loss: 0.3153 - accuracy: 0.8813 - val_loss: 0.5530 - val_accuracy: 0.8316\n",
      "Epoch 29/100\n",
      "455/455 [==============================] - 0s 214us/step - loss: 0.3134 - accuracy: 0.8813 - val_loss: 0.5607 - val_accuracy: 0.8316\n",
      "Epoch 30/100\n",
      "455/455 [==============================] - 0s 335us/step - loss: 0.3206 - accuracy: 0.8813 - val_loss: 0.5628 - val_accuracy: 0.8316\n",
      "Epoch 31/100\n",
      "455/455 [==============================] - 0s 248us/step - loss: 0.3159 - accuracy: 0.8813 - val_loss: 0.5529 - val_accuracy: 0.8316\n",
      "Epoch 32/100\n",
      "455/455 [==============================] - 0s 189us/step - loss: 0.3131 - accuracy: 0.8813 - val_loss: 0.5453 - val_accuracy: 0.8316\n",
      "Epoch 33/100\n",
      "455/455 [==============================] - 0s 178us/step - loss: 0.3131 - accuracy: 0.8813 - val_loss: 0.5547 - val_accuracy: 0.8316\n",
      "Epoch 34/100\n",
      "455/455 [==============================] - 0s 189us/step - loss: 0.3115 - accuracy: 0.8813 - val_loss: 0.5620 - val_accuracy: 0.8316\n",
      "Epoch 35/100\n",
      "455/455 [==============================] - 0s 182us/step - loss: 0.3172 - accuracy: 0.8813 - val_loss: 0.5546 - val_accuracy: 0.8316\n",
      "Epoch 36/100\n",
      "455/455 [==============================] - 0s 401us/step - loss: 0.3116 - accuracy: 0.8813 - val_loss: 0.5612 - val_accuracy: 0.8316\n",
      "Epoch 37/100\n",
      "455/455 [==============================] - 0s 206us/step - loss: 0.3137 - accuracy: 0.8813 - val_loss: 0.5652 - val_accuracy: 0.8316\n",
      "Epoch 38/100\n",
      "455/455 [==============================] - 0s 254us/step - loss: 0.3127 - accuracy: 0.8813 - val_loss: 0.5484 - val_accuracy: 0.8316\n",
      "Epoch 39/100\n",
      "455/455 [==============================] - 0s 175us/step - loss: 0.3167 - accuracy: 0.8813 - val_loss: 0.5625 - val_accuracy: 0.8316\n",
      "Epoch 40/100\n",
      "455/455 [==============================] - 0s 139us/step - loss: 0.3120 - accuracy: 0.8813 - val_loss: 0.5559 - val_accuracy: 0.8316\n",
      "Epoch 41/100\n",
      "455/455 [==============================] - 0s 125us/step - loss: 0.3160 - accuracy: 0.8813 - val_loss: 0.5659 - val_accuracy: 0.8316\n",
      "Epoch 42/100\n",
      "455/455 [==============================] - 0s 123us/step - loss: 0.3166 - accuracy: 0.8813 - val_loss: 0.5572 - val_accuracy: 0.8316\n",
      "Epoch 43/100\n",
      "455/455 [==============================] - 0s 126us/step - loss: 0.3150 - accuracy: 0.8813 - val_loss: 0.5680 - val_accuracy: 0.8316\n",
      "Epoch 44/100\n",
      "455/455 [==============================] - 0s 130us/step - loss: 0.3151 - accuracy: 0.8813 - val_loss: 0.5575 - val_accuracy: 0.8316\n",
      "Epoch 45/100\n",
      "455/455 [==============================] - 0s 135us/step - loss: 0.3149 - accuracy: 0.8813 - val_loss: 0.5594 - val_accuracy: 0.8316\n",
      "Epoch 46/100\n",
      "455/455 [==============================] - 0s 124us/step - loss: 0.3113 - accuracy: 0.8813 - val_loss: 0.5652 - val_accuracy: 0.8316\n",
      "Epoch 47/100\n",
      "455/455 [==============================] - 0s 124us/step - loss: 0.3166 - accuracy: 0.8813 - val_loss: 0.5637 - val_accuracy: 0.8316\n",
      "Epoch 48/100\n",
      "455/455 [==============================] - 0s 147us/step - loss: 0.3181 - accuracy: 0.8813 - val_loss: 0.5629 - val_accuracy: 0.8316\n",
      "Epoch 49/100\n",
      "455/455 [==============================] - 0s 310us/step - loss: 0.3104 - accuracy: 0.8813 - val_loss: 0.5626 - val_accuracy: 0.8316\n",
      "Epoch 50/100\n",
      "455/455 [==============================] - 0s 397us/step - loss: 0.3159 - accuracy: 0.8813 - val_loss: 0.5544 - val_accuracy: 0.8316\n",
      "Epoch 51/100\n",
      "455/455 [==============================] - 0s 627us/step - loss: 0.3188 - accuracy: 0.8813 - val_loss: 0.5675 - val_accuracy: 0.8316\n",
      "Epoch 52/100\n",
      "455/455 [==============================] - 0s 242us/step - loss: 0.3135 - accuracy: 0.8813 - val_loss: 0.5621 - val_accuracy: 0.8316\n",
      "Epoch 53/100\n",
      "455/455 [==============================] - 0s 250us/step - loss: 0.3118 - accuracy: 0.8813 - val_loss: 0.5575 - val_accuracy: 0.8316\n",
      "Epoch 54/100\n",
      "455/455 [==============================] - 0s 222us/step - loss: 0.3135 - accuracy: 0.8813 - val_loss: 0.5576 - val_accuracy: 0.8316\n",
      "Epoch 55/100\n",
      "455/455 [==============================] - 0s 197us/step - loss: 0.3122 - accuracy: 0.8813 - val_loss: 0.5685 - val_accuracy: 0.8316\n",
      "Epoch 56/100\n",
      "455/455 [==============================] - 0s 233us/step - loss: 0.3117 - accuracy: 0.8813 - val_loss: 0.5683 - val_accuracy: 0.8316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "455/455 [==============================] - 0s 241us/step - loss: 0.3124 - accuracy: 0.8813 - val_loss: 0.5629 - val_accuracy: 0.8316\n",
      "Epoch 58/100\n",
      "455/455 [==============================] - 0s 213us/step - loss: 0.3124 - accuracy: 0.8813 - val_loss: 0.5675 - val_accuracy: 0.8316\n",
      "Epoch 59/100\n",
      "455/455 [==============================] - 0s 166us/step - loss: 0.3128 - accuracy: 0.8813 - val_loss: 0.5621 - val_accuracy: 0.8316\n",
      "Epoch 60/100\n",
      "455/455 [==============================] - 0s 144us/step - loss: 0.3148 - accuracy: 0.8813 - val_loss: 0.5672 - val_accuracy: 0.8316\n",
      "Epoch 61/100\n",
      "455/455 [==============================] - 0s 145us/step - loss: 0.3150 - accuracy: 0.8813 - val_loss: 0.5613 - val_accuracy: 0.8316\n",
      "Epoch 62/100\n",
      "455/455 [==============================] - 0s 146us/step - loss: 0.3167 - accuracy: 0.8813 - val_loss: 0.5741 - val_accuracy: 0.8316\n",
      "Epoch 63/100\n",
      "455/455 [==============================] - 0s 174us/step - loss: 0.3137 - accuracy: 0.8813 - val_loss: 0.5554 - val_accuracy: 0.8316\n",
      "Epoch 64/100\n",
      "455/455 [==============================] - 0s 159us/step - loss: 0.3193 - accuracy: 0.8813 - val_loss: 0.5695 - val_accuracy: 0.8316\n",
      "Epoch 65/100\n",
      "455/455 [==============================] - 0s 175us/step - loss: 0.3137 - accuracy: 0.8813 - val_loss: 0.5621 - val_accuracy: 0.8316\n",
      "Epoch 66/100\n",
      "455/455 [==============================] - 0s 205us/step - loss: 0.3115 - accuracy: 0.8813 - val_loss: 0.5648 - val_accuracy: 0.8316\n",
      "Epoch 67/100\n",
      "455/455 [==============================] - 0s 211us/step - loss: 0.3109 - accuracy: 0.8813 - val_loss: 0.5697 - val_accuracy: 0.8316\n",
      "Epoch 68/100\n",
      "455/455 [==============================] - 0s 253us/step - loss: 0.3142 - accuracy: 0.8813 - val_loss: 0.5582 - val_accuracy: 0.8316\n",
      "Epoch 69/100\n",
      "455/455 [==============================] - 0s 295us/step - loss: 0.3122 - accuracy: 0.8813 - val_loss: 0.5589 - val_accuracy: 0.8316\n",
      "Epoch 70/100\n",
      "455/455 [==============================] - 0s 177us/step - loss: 0.3129 - accuracy: 0.8813 - val_loss: 0.5563 - val_accuracy: 0.8316\n",
      "Epoch 71/100\n",
      "455/455 [==============================] - 0s 212us/step - loss: 0.3119 - accuracy: 0.8813 - val_loss: 0.5643 - val_accuracy: 0.8316\n",
      "Epoch 72/100\n",
      "455/455 [==============================] - 0s 186us/step - loss: 0.3121 - accuracy: 0.8813 - val_loss: 0.5631 - val_accuracy: 0.8316\n",
      "Epoch 73/100\n",
      "455/455 [==============================] - 0s 200us/step - loss: 0.3122 - accuracy: 0.8813 - val_loss: 0.5594 - val_accuracy: 0.8316\n",
      "Epoch 74/100\n",
      "455/455 [==============================] - 0s 171us/step - loss: 0.3106 - accuracy: 0.8813 - val_loss: 0.5636 - val_accuracy: 0.8316\n",
      "Epoch 75/100\n",
      "455/455 [==============================] - 0s 200us/step - loss: 0.3144 - accuracy: 0.8813 - val_loss: 0.5601 - val_accuracy: 0.8316\n",
      "Epoch 76/100\n",
      "455/455 [==============================] - 0s 159us/step - loss: 0.3135 - accuracy: 0.8813 - val_loss: 0.5580 - val_accuracy: 0.8316\n",
      "Epoch 77/100\n",
      "455/455 [==============================] - 0s 147us/step - loss: 0.3151 - accuracy: 0.8813 - val_loss: 0.5745 - val_accuracy: 0.8316\n",
      "Epoch 78/100\n",
      "455/455 [==============================] - 0s 148us/step - loss: 0.3163 - accuracy: 0.8813 - val_loss: 0.5647 - val_accuracy: 0.8316\n",
      "Epoch 79/100\n",
      "455/455 [==============================] - 0s 144us/step - loss: 0.3131 - accuracy: 0.8813 - val_loss: 0.5705 - val_accuracy: 0.8316\n",
      "Epoch 80/100\n",
      "455/455 [==============================] - 0s 206us/step - loss: 0.3113 - accuracy: 0.8813 - val_loss: 0.5641 - val_accuracy: 0.8316\n",
      "Epoch 81/100\n",
      "455/455 [==============================] - 0s 197us/step - loss: 0.3117 - accuracy: 0.8813 - val_loss: 0.5630 - val_accuracy: 0.8316\n",
      "Epoch 82/100\n",
      "455/455 [==============================] - 0s 175us/step - loss: 0.3119 - accuracy: 0.8813 - val_loss: 0.5642 - val_accuracy: 0.8316\n",
      "Epoch 83/100\n",
      "455/455 [==============================] - 0s 170us/step - loss: 0.3132 - accuracy: 0.8813 - val_loss: 0.5637 - val_accuracy: 0.8316\n",
      "Epoch 84/100\n",
      "455/455 [==============================] - 0s 185us/step - loss: 0.3112 - accuracy: 0.8813 - val_loss: 0.5646 - val_accuracy: 0.8316\n",
      "Epoch 85/100\n",
      "455/455 [==============================] - 0s 193us/step - loss: 0.3123 - accuracy: 0.8813 - val_loss: 0.5606 - val_accuracy: 0.8316\n",
      "Epoch 86/100\n",
      "455/455 [==============================] - 0s 194us/step - loss: 0.3103 - accuracy: 0.8813 - val_loss: 0.5692 - val_accuracy: 0.8316\n",
      "Epoch 87/100\n",
      "455/455 [==============================] - 0s 202us/step - loss: 0.3139 - accuracy: 0.8813 - val_loss: 0.5641 - val_accuracy: 0.8316\n",
      "Epoch 88/100\n",
      "455/455 [==============================] - 0s 207us/step - loss: 0.3133 - accuracy: 0.8813 - val_loss: 0.5724 - val_accuracy: 0.8316\n",
      "Epoch 89/100\n",
      "455/455 [==============================] - 0s 199us/step - loss: 0.3136 - accuracy: 0.8813 - val_loss: 0.5592 - val_accuracy: 0.8316\n",
      "Epoch 90/100\n",
      "455/455 [==============================] - 0s 202us/step - loss: 0.3143 - accuracy: 0.8813 - val_loss: 0.5615 - val_accuracy: 0.8316\n",
      "Epoch 91/100\n",
      "455/455 [==============================] - 0s 174us/step - loss: 0.3144 - accuracy: 0.8813 - val_loss: 0.5623 - val_accuracy: 0.8316\n",
      "Epoch 92/100\n",
      "455/455 [==============================] - 0s 192us/step - loss: 0.3160 - accuracy: 0.8813 - val_loss: 0.5709 - val_accuracy: 0.8316\n",
      "Epoch 93/100\n",
      "455/455 [==============================] - 0s 202us/step - loss: 0.3148 - accuracy: 0.8813 - val_loss: 0.5656 - val_accuracy: 0.8316\n",
      "Epoch 94/100\n",
      "455/455 [==============================] - 0s 192us/step - loss: 0.3137 - accuracy: 0.8813 - val_loss: 0.5641 - val_accuracy: 0.8316\n",
      "Epoch 95/100\n",
      "455/455 [==============================] - 0s 180us/step - loss: 0.3129 - accuracy: 0.8813 - val_loss: 0.5713 - val_accuracy: 0.8316\n",
      "Epoch 96/100\n",
      "455/455 [==============================] - 0s 170us/step - loss: 0.3117 - accuracy: 0.8813 - val_loss: 0.5678 - val_accuracy: 0.8316\n",
      "Epoch 97/100\n",
      "455/455 [==============================] - 0s 184us/step - loss: 0.3116 - accuracy: 0.8813 - val_loss: 0.5677 - val_accuracy: 0.8316\n",
      "Epoch 98/100\n",
      "455/455 [==============================] - 0s 167us/step - loss: 0.3106 - accuracy: 0.8813 - val_loss: 0.5647 - val_accuracy: 0.8316\n",
      "Epoch 99/100\n",
      "455/455 [==============================] - 0s 159us/step - loss: 0.3119 - accuracy: 0.8813 - val_loss: 0.5660 - val_accuracy: 0.8316\n",
      "Epoch 100/100\n",
      "455/455 [==============================] - 0s 186us/step - loss: 0.3159 - accuracy: 0.8813 - val_loss: 0.5603 - val_accuracy: 0.8316\n"
     ]
    }
   ],
   "source": [
    "hist1_over3 = model1_over3.fit(X_train_over, y_train_over,\n",
    "          batch_size=16, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 88.11%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over3.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba3 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_2.xlsx\",\n",
    "                        sheet_name=2,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>0.013518</td>\n",
       "      <td>9.820048e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>0.013518</td>\n",
       "      <td>9.820048e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS222</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.851725</td>\n",
       "      <td>0.148269</td>\n",
       "      <td>5.980786e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>0.013518</td>\n",
       "      <td>9.820048e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>GA50245</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.812055</td>\n",
       "      <td>0.187945</td>\n",
       "      <td>1.161034e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4279</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>0.000928</td>\n",
       "      <td>9.984396e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4280</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>0.000928</td>\n",
       "      <td>9.984396e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4281</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS266</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.025932</td>\n",
       "      <td>0.974061</td>\n",
       "      <td>7.323514e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4282</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000597</td>\n",
       "      <td>0.999403</td>\n",
       "      <td>3.675362e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4283</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS112</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>0.999452</td>\n",
       "      <td>1.168620e-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4284 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    phage   strain  phenotype  prediction         0         1  \\\n",
       "0      p002ykpresabs_qual   NRS109          2           2  0.004477  0.013518   \n",
       "1      p002ykpresabs_qual   NRS109          2           2  0.004477  0.013518   \n",
       "2      p002ykpresabs_qual   NRS222          0           0  0.851725  0.148269   \n",
       "3      p002ykpresabs_qual   NRS109          2           2  0.004477  0.013518   \n",
       "4      p002ykpresabs_qual  GA50245          0           0  0.812055  0.187945   \n",
       "...                   ...      ...        ...         ...       ...       ...   \n",
       "4279  pyopresabsSTCC_qual   NRS255          2           2  0.000633  0.000928   \n",
       "4280  pyopresabsSTCC_qual   NRS255          2           2  0.000633  0.000928   \n",
       "4281  pyopresabsSTCC_qual   NRS266          1           1  0.025932  0.974061   \n",
       "4282  pyopresabsSTCC_qual   NRS001          1           1  0.000597  0.999403   \n",
       "4283  pyopresabsSTCC_qual   NRS112          1           1  0.000537  0.999452   \n",
       "\n",
       "                 2  \n",
       "0     9.820048e-01  \n",
       "1     9.820048e-01  \n",
       "2     5.980786e-06  \n",
       "3     9.820048e-01  \n",
       "4     1.161034e-07  \n",
       "...            ...  \n",
       "4279  9.984396e-01  \n",
       "4280  9.984396e-01  \n",
       "4281  7.323514e-06  \n",
       "4282  3.675362e-10  \n",
       "4283  1.168620e-05  \n",
       "\n",
       "[4284 rows x 7 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.05407440e-01, 8.94580960e-01, 1.16283490e-05],\n",
       "       [1.95538030e-01, 8.04346700e-01, 1.15247545e-04],\n",
       "       [1.91486090e-05, 7.20958300e-02, 9.27885060e-01],\n",
       "       [1.27997320e-05, 1.04696600e-01, 8.95290600e-01],\n",
       "       [6.93035200e-01, 3.06428000e-01, 5.36800300e-04],\n",
       "       [8.91438000e-01, 1.08561660e-01, 3.39223020e-07],\n",
       "       [7.03646800e-01, 2.95027900e-01, 1.32535990e-03],\n",
       "       [1.27997320e-05, 1.04696600e-01, 8.95290600e-01],\n",
       "       [3.21893270e-01, 6.78106300e-01, 5.01544300e-07],\n",
       "       [8.91438000e-01, 1.08561660e-01, 3.39223020e-07],\n",
       "       [6.93035200e-01, 3.06428000e-01, 5.36800300e-04],\n",
       "       [1.27997320e-05, 1.04696600e-01, 8.95290600e-01],\n",
       "       [1.81600250e-02, 9.81579840e-01, 2.60072000e-04],\n",
       "       [7.03646800e-01, 2.95027900e-01, 1.32535990e-03],\n",
       "       [7.51712400e-01, 2.48287440e-01, 1.67258620e-07],\n",
       "       [1.05407440e-01, 8.94580960e-01, 1.16283490e-05],\n",
       "       [8.91438000e-01, 1.08561660e-01, 3.39223020e-07],\n",
       "       [9.57151200e-01, 4.28232000e-02, 2.55411070e-05],\n",
       "       [1.91486090e-05, 7.20958300e-02, 9.27885060e-01],\n",
       "       [5.73793080e-05, 1.51659600e-03, 9.98426100e-01],\n",
       "       [1.91486090e-05, 7.20958300e-02, 9.27885060e-01],\n",
       "       [1.81600250e-02, 9.81579840e-01, 2.60072000e-04],\n",
       "       [8.91438000e-01, 1.08561660e-01, 3.39223020e-07],\n",
       "       [1.27997320e-05, 1.04696600e-01, 8.95290600e-01],\n",
       "       [8.91438000e-01, 1.08561660e-01, 3.39223020e-07],\n",
       "       [1.05407440e-01, 8.94580960e-01, 1.16283490e-05],\n",
       "       [5.73793080e-05, 1.51659600e-03, 9.98426100e-01],\n",
       "       [1.95538030e-01, 8.04346700e-01, 1.15247545e-04],\n",
       "       [3.21893270e-01, 6.78106300e-01, 5.01544300e-07],\n",
       "       [6.93035200e-01, 3.06428000e-01, 5.36800300e-04],\n",
       "       [8.91438000e-01, 1.08561660e-01, 3.39223020e-07],\n",
       "       [1.91486090e-05, 7.20958300e-02, 9.27885060e-01],\n",
       "       [1.92323350e-03, 9.98075000e-01, 1.74456220e-06],\n",
       "       [1.91486090e-05, 7.20958300e-02, 9.27885060e-01],\n",
       "       [3.21893270e-01, 6.78106300e-01, 5.01544300e-07],\n",
       "       [3.21893270e-01, 6.78106300e-01, 5.01544300e-07],\n",
       "       [1.95538030e-01, 8.04346700e-01, 1.15247545e-04],\n",
       "       [1.27997320e-05, 1.04696600e-01, 8.95290600e-01],\n",
       "       [1.92323350e-03, 9.98075000e-01, 1.74456220e-06],\n",
       "       [1.27997320e-05, 1.04696600e-01, 8.95290600e-01],\n",
       "       [8.44304000e-01, 1.55495270e-01, 2.00683920e-04],\n",
       "       [1.91486090e-05, 7.20958300e-02, 9.27885060e-01],\n",
       "       [7.51712400e-01, 2.48287440e-01, 1.67258620e-07],\n",
       "       [1.91486090e-05, 7.20958300e-02, 9.27885060e-01],\n",
       "       [8.91438000e-01, 1.08561660e-01, 3.39223020e-07],\n",
       "       [6.67880750e-04, 9.98692800e-01, 6.39314800e-04],\n",
       "       [5.73793080e-05, 1.51659600e-03, 9.98426100e-01],\n",
       "       [1.81600250e-02, 9.81579840e-01, 2.60072000e-04],\n",
       "       [1.95538030e-01, 8.04346700e-01, 1.15247545e-04],\n",
       "       [5.73793080e-05, 1.51659600e-03, 9.98426100e-01],\n",
       "       [8.91438000e-01, 1.08561660e-01, 3.39223020e-07],\n",
       "       [1.27997320e-05, 1.04696600e-01, 8.95290600e-01],\n",
       "       [7.90375850e-05, 9.97758600e-01, 2.16220020e-03],\n",
       "       [8.91438000e-01, 1.08561660e-01, 3.39223020e-07],\n",
       "       [6.93035200e-01, 3.06428000e-01, 5.36800300e-04],\n",
       "       [1.27997320e-05, 1.04696600e-01, 8.95290600e-01],\n",
       "       [7.03646800e-01, 2.95027900e-01, 1.32535990e-03],\n",
       "       [8.91438000e-01, 1.08561660e-01, 3.39223020e-07],\n",
       "       [1.27997320e-05, 1.04696600e-01, 8.95290600e-01],\n",
       "       [1.81600250e-02, 9.81579840e-01, 2.60072000e-04],\n",
       "       [1.27997320e-05, 1.04696600e-01, 8.95290600e-01],\n",
       "       [3.21893270e-01, 6.78106300e-01, 5.01544300e-07],\n",
       "       [7.03646800e-01, 2.95027900e-01, 1.32535990e-03],\n",
       "       [8.91438000e-01, 1.08561660e-01, 3.39223020e-07],\n",
       "       [1.91486090e-05, 7.20958300e-02, 9.27885060e-01],\n",
       "       [1.95538030e-01, 8.04346700e-01, 1.15247545e-04],\n",
       "       [1.79366240e-06, 9.99323840e-01, 6.74402400e-04],\n",
       "       [7.51712400e-01, 2.48287440e-01, 1.67258620e-07],\n",
       "       [5.73793080e-05, 1.51659600e-03, 9.98426100e-01],\n",
       "       [8.91438000e-01, 1.08561660e-01, 3.39223020e-07],\n",
       "       [1.95538030e-01, 8.04346700e-01, 1.15247545e-04],\n",
       "       [7.03646800e-01, 2.95027900e-01, 1.32535990e-03],\n",
       "       [6.93035200e-01, 3.06428000e-01, 5.36800300e-04],\n",
       "       [8.91438000e-01, 1.08561660e-01, 3.39223020e-07],\n",
       "       [7.03646800e-01, 2.95027900e-01, 1.32535990e-03],\n",
       "       [1.91486090e-05, 7.20958300e-02, 9.27885060e-01],\n",
       "       [1.05885600e-03, 9.27869700e-02, 9.06154160e-01],\n",
       "       [7.03646800e-01, 2.95027900e-01, 1.32535990e-03],\n",
       "       [8.91438000e-01, 1.08561660e-01, 3.39223020e-07],\n",
       "       [6.93035200e-01, 3.06428000e-01, 5.36800300e-04],\n",
       "       [1.91486090e-05, 7.20958300e-02, 9.27885060e-01],\n",
       "       [7.03646800e-01, 2.95027900e-01, 1.32535990e-03],\n",
       "       [8.91438000e-01, 1.08561660e-01, 3.39223020e-07],\n",
       "       [1.27997320e-05, 1.04696600e-01, 8.95290600e-01],\n",
       "       [8.91438000e-01, 1.08561660e-01, 3.39223020e-07],\n",
       "       [1.91486090e-05, 7.20958300e-02, 9.27885060e-01],\n",
       "       [8.44304000e-01, 1.55495270e-01, 2.00683920e-04],\n",
       "       [7.03646800e-01, 2.95027900e-01, 1.32535990e-03],\n",
       "       [1.91486090e-05, 7.20958300e-02, 9.27885060e-01],\n",
       "       [7.02897040e-03, 9.86295160e-01, 6.67585340e-03],\n",
       "       [1.91486090e-05, 7.20958300e-02, 9.27885060e-01],\n",
       "       [8.91438000e-01, 1.08561660e-01, 3.39223020e-07],\n",
       "       [7.03646800e-01, 2.95027900e-01, 1.32535990e-03],\n",
       "       [5.73793080e-05, 1.51659600e-03, 9.98426100e-01],\n",
       "       [7.51712400e-01, 2.48287440e-01, 1.67258620e-07],\n",
       "       [1.95538030e-01, 8.04346700e-01, 1.15247545e-04],\n",
       "       [5.73793080e-05, 1.51659600e-03, 9.98426100e-01],\n",
       "       [5.73793080e-05, 1.51659600e-03, 9.98426100e-01],\n",
       "       [1.05407440e-01, 8.94580960e-01, 1.16283490e-05],\n",
       "       [1.91486090e-05, 7.20958300e-02, 9.27885060e-01],\n",
       "       [1.91486090e-05, 7.20958300e-02, 9.27885060e-01],\n",
       "       [1.95538030e-01, 8.04346700e-01, 1.15247545e-04],\n",
       "       [1.91486090e-05, 7.20958300e-02, 9.27885060e-01],\n",
       "       [1.27997320e-05, 1.04696600e-01, 8.95290600e-01],\n",
       "       [7.03646800e-01, 2.95027900e-01, 1.32535990e-03],\n",
       "       [8.91438000e-01, 1.08561660e-01, 3.39223020e-07],\n",
       "       [1.91486090e-05, 7.20958300e-02, 9.27885060e-01],\n",
       "       [1.95538030e-01, 8.04346700e-01, 1.15247545e-04],\n",
       "       [5.73793080e-05, 1.51659600e-03, 9.98426100e-01],\n",
       "       [6.55503350e-02, 5.80377700e-01, 3.54071970e-01],\n",
       "       [9.10821400e-03, 9.86774100e-01, 4.11771700e-03],\n",
       "       [1.91486090e-05, 7.20958300e-02, 9.27885060e-01],\n",
       "       [9.10821400e-03, 9.86774100e-01, 4.11771700e-03],\n",
       "       [1.95538030e-01, 8.04346700e-01, 1.15247545e-04],\n",
       "       [1.95538030e-01, 8.04346700e-01, 1.15247545e-04],\n",
       "       [1.92323350e-03, 9.98075000e-01, 1.74456220e-06],\n",
       "       [1.95538030e-01, 8.04346700e-01, 1.15247545e-04],\n",
       "       [1.91486090e-05, 7.20958300e-02, 9.27885060e-01],\n",
       "       [1.27997320e-05, 1.04696600e-01, 8.95290600e-01],\n",
       "       [1.79366240e-06, 9.99323840e-01, 6.74402400e-04],\n",
       "       [1.95538030e-01, 8.04346700e-01, 1.15247545e-04],\n",
       "       [1.91486090e-05, 7.20958300e-02, 9.27885060e-01],\n",
       "       [7.03646800e-01, 2.95027900e-01, 1.32535990e-03],\n",
       "       [1.91486090e-05, 7.20958300e-02, 9.27885060e-01],\n",
       "       [7.51712400e-01, 2.48287440e-01, 1.67258620e-07],\n",
       "       [6.67880750e-04, 9.98692800e-01, 6.39314800e-04],\n",
       "       [8.91438000e-01, 1.08561660e-01, 3.39223020e-07],\n",
       "       [1.95538030e-01, 8.04346700e-01, 1.15247545e-04],\n",
       "       [8.91438000e-01, 1.08561660e-01, 3.39223020e-07],\n",
       "       [1.27997320e-05, 1.04696600e-01, 8.95290600e-01],\n",
       "       [1.91486090e-05, 7.20958300e-02, 9.27885060e-01],\n",
       "       [7.03646800e-01, 2.95027900e-01, 1.32535990e-03],\n",
       "       [1.95538030e-01, 8.04346700e-01, 1.15247545e-04],\n",
       "       [1.27997320e-05, 1.04696600e-01, 8.95290600e-01],\n",
       "       [1.91486090e-05, 7.20958300e-02, 9.27885060e-01],\n",
       "       [1.91486090e-05, 7.20958300e-02, 9.27885060e-01],\n",
       "       [1.27997320e-05, 1.04696600e-01, 8.95290600e-01],\n",
       "       [1.91486090e-05, 7.20958300e-02, 9.27885060e-01],\n",
       "       [1.91486090e-05, 7.20958300e-02, 9.27885060e-01],\n",
       "       [8.91438000e-01, 1.08561660e-01, 3.39223020e-07],\n",
       "       [6.67412630e-03, 9.74346900e-01, 1.89790300e-02],\n",
       "       [6.93035200e-01, 3.06428000e-01, 5.36800300e-04],\n",
       "       [8.91438000e-01, 1.08561660e-01, 3.39223020e-07],\n",
       "       [5.73793080e-05, 1.51659600e-03, 9.98426100e-01],\n",
       "       [6.67880750e-04, 9.98692800e-01, 6.39314800e-04],\n",
       "       [1.95538030e-01, 8.04346700e-01, 1.15247545e-04],\n",
       "       [6.67880750e-04, 9.98692800e-01, 6.39314800e-04],\n",
       "       [1.91486090e-05, 7.20958300e-02, 9.27885060e-01],\n",
       "       [7.03646800e-01, 2.95027900e-01, 1.32535990e-03],\n",
       "       [1.27997320e-05, 1.04696600e-01, 8.95290600e-01],\n",
       "       [1.91486090e-05, 7.20958300e-02, 9.27885060e-01],\n",
       "       [7.03646800e-01, 2.95027900e-01, 1.32535990e-03],\n",
       "       [1.91486090e-05, 7.20958300e-02, 9.27885060e-01],\n",
       "       [7.51712400e-01, 2.48287440e-01, 1.67258620e-07],\n",
       "       [8.91438000e-01, 1.08561660e-01, 3.39223020e-07],\n",
       "       [1.05407440e-01, 8.94580960e-01, 1.16283490e-05],\n",
       "       [1.91486090e-05, 7.20958300e-02, 9.27885060e-01],\n",
       "       [8.91438000e-01, 1.08561660e-01, 3.39223020e-07],\n",
       "       [1.95538030e-01, 8.04346700e-01, 1.15247545e-04],\n",
       "       [7.51712400e-01, 2.48287440e-01, 1.67258620e-07],\n",
       "       [8.91438000e-01, 1.08561660e-01, 3.39223020e-07],\n",
       "       [8.91438000e-01, 1.08561660e-01, 3.39223020e-07],\n",
       "       [1.91486090e-05, 7.20958300e-02, 9.27885060e-01],\n",
       "       [7.03646800e-01, 2.95027900e-01, 1.32535990e-03],\n",
       "       [8.91438000e-01, 1.08561660e-01, 3.39223020e-07],\n",
       "       [8.91438000e-01, 1.08561660e-01, 3.39223020e-07],\n",
       "       [7.03646800e-01, 2.95027900e-01, 1.32535990e-03],\n",
       "       [1.27997320e-05, 1.04696600e-01, 8.95290600e-01],\n",
       "       [1.27997320e-05, 1.04696600e-01, 8.95290600e-01],\n",
       "       [6.93035200e-01, 3.06428000e-01, 5.36800300e-04],\n",
       "       [1.92323350e-03, 9.98075000e-01, 1.74456220e-06],\n",
       "       [6.67880750e-04, 9.98692800e-01, 6.39314800e-04],\n",
       "       [1.91486090e-05, 7.20958300e-02, 9.27885060e-01],\n",
       "       [8.91438000e-01, 1.08561660e-01, 3.39223020e-07],\n",
       "       [3.21893270e-01, 6.78106300e-01, 5.01544300e-07],\n",
       "       [5.73793080e-05, 1.51659600e-03, 9.98426100e-01],\n",
       "       [1.91486090e-05, 7.20958300e-02, 9.27885060e-01],\n",
       "       [7.51712400e-01, 2.48287440e-01, 1.67258620e-07],\n",
       "       [1.91486090e-05, 7.20958300e-02, 9.27885060e-01],\n",
       "       [7.03646800e-01, 2.95027900e-01, 1.32535990e-03],\n",
       "       [1.95538030e-01, 8.04346700e-01, 1.15247545e-04],\n",
       "       [5.73793080e-05, 1.51659600e-03, 9.98426100e-01],\n",
       "       [9.45626400e-01, 5.43729180e-02, 7.06847900e-07],\n",
       "       [5.73793080e-05, 1.51659600e-03, 9.98426100e-01],\n",
       "       [8.91438000e-01, 1.08561660e-01, 3.39223020e-07],\n",
       "       [1.27997320e-05, 1.04696600e-01, 8.95290600e-01],\n",
       "       [6.67880750e-04, 9.98692800e-01, 6.39314800e-04],\n",
       "       [1.05407440e-01, 8.94580960e-01, 1.16283490e-05],\n",
       "       [8.44304000e-01, 1.55495270e-01, 2.00683920e-04],\n",
       "       [8.91438000e-01, 1.08561660e-01, 3.39223020e-07],\n",
       "       [1.91486090e-05, 7.20958300e-02, 9.27885060e-01],\n",
       "       [5.73793080e-05, 1.51659600e-03, 9.98426100e-01],\n",
       "       [5.73793080e-05, 1.51659600e-03, 9.98426100e-01],\n",
       "       [1.81253160e-02, 9.81694040e-01, 1.80631410e-04],\n",
       "       [3.21893270e-01, 6.78106300e-01, 5.01544300e-07],\n",
       "       [7.90375850e-05, 9.97758600e-01, 2.16220020e-03]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob3 = df_proba3[df_proba3['phage']=='pyokpresabs_qual'].iloc[:,-3:]\n",
    "y_prob3 = y_prob3.to_numpy()\n",
    "y_prob3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9144387207364306"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo3 = rocauc_ovo(y_test_over, y_prob3, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9144387207364306"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr3 = rocauc_ovr(y_test_over, y_prob3, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=456,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat4 = pd.DataFrame(X_test_over[:,0])\n",
    "dat4['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS178</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS073</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CFBREBSa119</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>NRS236</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>NRS029</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>CFBRSa28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>NRS205</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>196 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test\n",
       "0         NRS178     1\n",
       "1         NRS109     2\n",
       "2         NRS073     1\n",
       "3    CFBREBSa119     0\n",
       "4         NRS109     2\n",
       "..           ...   ...\n",
       "191       NRS236     1\n",
       "192       NRS029     0\n",
       "193       NRS148     2\n",
       "194     CFBRSa28     0\n",
       "195       NRS205     2\n",
       "\n",
       "[196 rows x 2 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over4 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],)),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over4.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 455 samples, validate on 196 samples\n",
      "Epoch 1/100\n",
      "455/455 [==============================] - 0s 345us/step - loss: 1.0029 - accuracy: 0.5143 - val_loss: 0.9277 - val_accuracy: 0.6276\n",
      "Epoch 2/100\n",
      "455/455 [==============================] - 0s 186us/step - loss: 0.9102 - accuracy: 0.6308 - val_loss: 0.8447 - val_accuracy: 0.7347\n",
      "Epoch 3/100\n",
      "455/455 [==============================] - 0s 212us/step - loss: 0.8415 - accuracy: 0.7429 - val_loss: 0.7801 - val_accuracy: 0.7857\n",
      "Epoch 4/100\n",
      "455/455 [==============================] - 0s 127us/step - loss: 0.7842 - accuracy: 0.7714 - val_loss: 0.7245 - val_accuracy: 0.7857\n",
      "Epoch 5/100\n",
      "455/455 [==============================] - 0s 124us/step - loss: 0.7327 - accuracy: 0.7802 - val_loss: 0.6795 - val_accuracy: 0.7857\n",
      "Epoch 6/100\n",
      "455/455 [==============================] - 0s 132us/step - loss: 0.6885 - accuracy: 0.7802 - val_loss: 0.6359 - val_accuracy: 0.7857\n",
      "Epoch 7/100\n",
      "455/455 [==============================] - 0s 113us/step - loss: 0.6514 - accuracy: 0.7824 - val_loss: 0.6038 - val_accuracy: 0.7857\n",
      "Epoch 8/100\n",
      "455/455 [==============================] - 0s 158us/step - loss: 0.6216 - accuracy: 0.7824 - val_loss: 0.5792 - val_accuracy: 0.7857\n",
      "Epoch 9/100\n",
      "455/455 [==============================] - 0s 194us/step - loss: 0.5958 - accuracy: 0.7846 - val_loss: 0.5568 - val_accuracy: 0.7857\n",
      "Epoch 10/100\n",
      "455/455 [==============================] - 0s 171us/step - loss: 0.5739 - accuracy: 0.7846 - val_loss: 0.5396 - val_accuracy: 0.7857\n",
      "Epoch 11/100\n",
      "455/455 [==============================] - 0s 119us/step - loss: 0.5568 - accuracy: 0.7912 - val_loss: 0.5258 - val_accuracy: 0.7857\n",
      "Epoch 12/100\n",
      "455/455 [==============================] - 0s 98us/step - loss: 0.5415 - accuracy: 0.7846 - val_loss: 0.5122 - val_accuracy: 0.7857\n",
      "Epoch 13/100\n",
      "455/455 [==============================] - 0s 111us/step - loss: 0.5287 - accuracy: 0.7846 - val_loss: 0.5025 - val_accuracy: 0.7857\n",
      "Epoch 14/100\n",
      "455/455 [==============================] - 0s 238us/step - loss: 0.5166 - accuracy: 0.7846 - val_loss: 0.4915 - val_accuracy: 0.7857\n",
      "Epoch 15/100\n",
      "455/455 [==============================] - 0s 110us/step - loss: 0.5067 - accuracy: 0.7824 - val_loss: 0.4840 - val_accuracy: 0.7857\n",
      "Epoch 16/100\n",
      "455/455 [==============================] - 0s 96us/step - loss: 0.4992 - accuracy: 0.7868 - val_loss: 0.4786 - val_accuracy: 0.7806\n",
      "Epoch 17/100\n",
      "455/455 [==============================] - 0s 109us/step - loss: 0.4887 - accuracy: 0.7846 - val_loss: 0.4719 - val_accuracy: 0.7857\n",
      "Epoch 18/100\n",
      "455/455 [==============================] - 0s 135us/step - loss: 0.4818 - accuracy: 0.7846 - val_loss: 0.4667 - val_accuracy: 0.7806\n",
      "Epoch 19/100\n",
      "455/455 [==============================] - 0s 211us/step - loss: 0.4746 - accuracy: 0.7912 - val_loss: 0.4609 - val_accuracy: 0.7857\n",
      "Epoch 20/100\n",
      "455/455 [==============================] - 0s 192us/step - loss: 0.4688 - accuracy: 0.8000 - val_loss: 0.4539 - val_accuracy: 0.8010\n",
      "Epoch 21/100\n",
      "455/455 [==============================] - 0s 200us/step - loss: 0.4636 - accuracy: 0.8110 - val_loss: 0.4498 - val_accuracy: 0.8163\n",
      "Epoch 22/100\n",
      "455/455 [==============================] - 0s 189us/step - loss: 0.4581 - accuracy: 0.8220 - val_loss: 0.4469 - val_accuracy: 0.8214\n",
      "Epoch 23/100\n",
      "455/455 [==============================] - 0s 207us/step - loss: 0.4523 - accuracy: 0.8220 - val_loss: 0.4415 - val_accuracy: 0.8163\n",
      "Epoch 24/100\n",
      "455/455 [==============================] - 0s 114us/step - loss: 0.4484 - accuracy: 0.8242 - val_loss: 0.4390 - val_accuracy: 0.8163\n",
      "Epoch 25/100\n",
      "455/455 [==============================] - 0s 87us/step - loss: 0.4432 - accuracy: 0.8286 - val_loss: 0.4352 - val_accuracy: 0.8163\n",
      "Epoch 26/100\n",
      "455/455 [==============================] - 0s 84us/step - loss: 0.4418 - accuracy: 0.8352 - val_loss: 0.4315 - val_accuracy: 0.8163\n",
      "Epoch 27/100\n",
      "455/455 [==============================] - 0s 87us/step - loss: 0.4350 - accuracy: 0.8308 - val_loss: 0.4292 - val_accuracy: 0.8163\n",
      "Epoch 28/100\n",
      "455/455 [==============================] - 0s 103us/step - loss: 0.4339 - accuracy: 0.8286 - val_loss: 0.4265 - val_accuracy: 0.8163\n",
      "Epoch 29/100\n",
      "455/455 [==============================] - 0s 457us/step - loss: 0.4304 - accuracy: 0.8308 - val_loss: 0.4240 - val_accuracy: 0.8418\n",
      "Epoch 30/100\n",
      "455/455 [==============================] - 0s 239us/step - loss: 0.4268 - accuracy: 0.8374 - val_loss: 0.4207 - val_accuracy: 0.8418\n",
      "Epoch 31/100\n",
      "455/455 [==============================] - 0s 192us/step - loss: 0.4234 - accuracy: 0.8484 - val_loss: 0.4181 - val_accuracy: 0.8418\n",
      "Epoch 32/100\n",
      "455/455 [==============================] - 0s 172us/step - loss: 0.4196 - accuracy: 0.8484 - val_loss: 0.4163 - val_accuracy: 0.8418\n",
      "Epoch 33/100\n",
      "455/455 [==============================] - 0s 167us/step - loss: 0.4174 - accuracy: 0.8396 - val_loss: 0.4148 - val_accuracy: 0.8418\n",
      "Epoch 34/100\n",
      "455/455 [==============================] - 0s 237us/step - loss: 0.4170 - accuracy: 0.8462 - val_loss: 0.4117 - val_accuracy: 0.8163\n",
      "Epoch 35/100\n",
      "455/455 [==============================] - 0s 275us/step - loss: 0.4148 - accuracy: 0.8527 - val_loss: 0.4086 - val_accuracy: 0.8418\n",
      "Epoch 36/100\n",
      "455/455 [==============================] - 0s 307us/step - loss: 0.4111 - accuracy: 0.8484 - val_loss: 0.4081 - val_accuracy: 0.8418\n",
      "Epoch 37/100\n",
      "455/455 [==============================] - 0s 201us/step - loss: 0.4091 - accuracy: 0.8484 - val_loss: 0.4057 - val_accuracy: 0.8418\n",
      "Epoch 38/100\n",
      "455/455 [==============================] - 0s 257us/step - loss: 0.4069 - accuracy: 0.8484 - val_loss: 0.4039 - val_accuracy: 0.8418\n",
      "Epoch 39/100\n",
      "455/455 [==============================] - 0s 278us/step - loss: 0.4067 - accuracy: 0.8484 - val_loss: 0.4025 - val_accuracy: 0.8418\n",
      "Epoch 40/100\n",
      "455/455 [==============================] - 0s 335us/step - loss: 0.4042 - accuracy: 0.8462 - val_loss: 0.4008 - val_accuracy: 0.8418\n",
      "Epoch 41/100\n",
      "455/455 [==============================] - 0s 313us/step - loss: 0.4025 - accuracy: 0.8484 - val_loss: 0.3995 - val_accuracy: 0.8418\n",
      "Epoch 42/100\n",
      "455/455 [==============================] - 0s 218us/step - loss: 0.4008 - accuracy: 0.8484 - val_loss: 0.3974 - val_accuracy: 0.8418\n",
      "Epoch 43/100\n",
      "455/455 [==============================] - 0s 110us/step - loss: 0.3998 - accuracy: 0.8527 - val_loss: 0.3946 - val_accuracy: 0.8418\n",
      "Epoch 44/100\n",
      "455/455 [==============================] - 0s 90us/step - loss: 0.3975 - accuracy: 0.8527 - val_loss: 0.3935 - val_accuracy: 0.8520\n",
      "Epoch 45/100\n",
      "455/455 [==============================] - 0s 84us/step - loss: 0.3966 - accuracy: 0.8593 - val_loss: 0.3920 - val_accuracy: 0.8520\n",
      "Epoch 46/100\n",
      "455/455 [==============================] - 0s 83us/step - loss: 0.3957 - accuracy: 0.8637 - val_loss: 0.3916 - val_accuracy: 0.8520\n",
      "Epoch 47/100\n",
      "455/455 [==============================] - 0s 84us/step - loss: 0.3923 - accuracy: 0.8637 - val_loss: 0.3897 - val_accuracy: 0.8520\n",
      "Epoch 48/100\n",
      "455/455 [==============================] - 0s 88us/step - loss: 0.3929 - accuracy: 0.8637 - val_loss: 0.3866 - val_accuracy: 0.8520\n",
      "Epoch 49/100\n",
      "455/455 [==============================] - 0s 118us/step - loss: 0.3926 - accuracy: 0.8637 - val_loss: 0.3875 - val_accuracy: 0.8520\n",
      "Epoch 50/100\n",
      "455/455 [==============================] - 0s 160us/step - loss: 0.3904 - accuracy: 0.8637 - val_loss: 0.3871 - val_accuracy: 0.8520\n",
      "Epoch 51/100\n",
      "455/455 [==============================] - 0s 205us/step - loss: 0.3897 - accuracy: 0.8637 - val_loss: 0.3861 - val_accuracy: 0.8520\n",
      "Epoch 52/100\n",
      "455/455 [==============================] - 0s 194us/step - loss: 0.3876 - accuracy: 0.8637 - val_loss: 0.3849 - val_accuracy: 0.8520\n",
      "Epoch 53/100\n",
      "455/455 [==============================] - 0s 213us/step - loss: 0.3878 - accuracy: 0.8637 - val_loss: 0.3828 - val_accuracy: 0.8520\n",
      "Epoch 54/100\n",
      "455/455 [==============================] - 0s 130us/step - loss: 0.3887 - accuracy: 0.8637 - val_loss: 0.3838 - val_accuracy: 0.8520\n",
      "Epoch 55/100\n",
      "455/455 [==============================] - 0s 115us/step - loss: 0.3856 - accuracy: 0.8637 - val_loss: 0.3821 - val_accuracy: 0.8520\n",
      "Epoch 56/100\n",
      "455/455 [==============================] - 0s 93us/step - loss: 0.3846 - accuracy: 0.8637 - val_loss: 0.3817 - val_accuracy: 0.8520\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "455/455 [==============================] - 0s 153us/step - loss: 0.3849 - accuracy: 0.8637 - val_loss: 0.3816 - val_accuracy: 0.8520\n",
      "Epoch 58/100\n",
      "455/455 [==============================] - 0s 105us/step - loss: 0.3825 - accuracy: 0.8637 - val_loss: 0.3809 - val_accuracy: 0.8520\n",
      "Epoch 59/100\n",
      "455/455 [==============================] - 0s 87us/step - loss: 0.3823 - accuracy: 0.8637 - val_loss: 0.3789 - val_accuracy: 0.8571\n",
      "Epoch 60/100\n",
      "455/455 [==============================] - 0s 91us/step - loss: 0.3836 - accuracy: 0.8637 - val_loss: 0.3782 - val_accuracy: 0.8520\n",
      "Epoch 61/100\n",
      "455/455 [==============================] - 0s 84us/step - loss: 0.3805 - accuracy: 0.8637 - val_loss: 0.3760 - val_accuracy: 0.8520\n",
      "Epoch 62/100\n",
      "455/455 [==============================] - 0s 91us/step - loss: 0.3815 - accuracy: 0.8659 - val_loss: 0.3752 - val_accuracy: 0.8571\n",
      "Epoch 63/100\n",
      "455/455 [==============================] - 0s 92us/step - loss: 0.3800 - accuracy: 0.8637 - val_loss: 0.3765 - val_accuracy: 0.8520\n",
      "Epoch 64/100\n",
      "455/455 [==============================] - 0s 87us/step - loss: 0.3797 - accuracy: 0.8637 - val_loss: 0.3747 - val_accuracy: 0.8520\n",
      "Epoch 65/100\n",
      "455/455 [==============================] - 0s 84us/step - loss: 0.3786 - accuracy: 0.8637 - val_loss: 0.3734 - val_accuracy: 0.8520\n",
      "Epoch 66/100\n",
      "455/455 [==============================] - 0s 84us/step - loss: 0.3785 - accuracy: 0.8637 - val_loss: 0.3722 - val_accuracy: 0.8520\n",
      "Epoch 67/100\n",
      "455/455 [==============================] - 0s 122us/step - loss: 0.3775 - accuracy: 0.8637 - val_loss: 0.3730 - val_accuracy: 0.8520\n",
      "Epoch 68/100\n",
      "455/455 [==============================] - 0s 131us/step - loss: 0.3766 - accuracy: 0.8637 - val_loss: 0.3739 - val_accuracy: 0.8571\n",
      "Epoch 69/100\n",
      "455/455 [==============================] - 0s 90us/step - loss: 0.3758 - accuracy: 0.8637 - val_loss: 0.3746 - val_accuracy: 0.8520\n",
      "Epoch 70/100\n",
      "455/455 [==============================] - 0s 83us/step - loss: 0.3749 - accuracy: 0.8637 - val_loss: 0.3698 - val_accuracy: 0.8571\n",
      "Epoch 71/100\n",
      "455/455 [==============================] - 0s 85us/step - loss: 0.3744 - accuracy: 0.8659 - val_loss: 0.3706 - val_accuracy: 0.8520\n",
      "Epoch 72/100\n",
      "455/455 [==============================] - 0s 124us/step - loss: 0.3760 - accuracy: 0.8637 - val_loss: 0.3707 - val_accuracy: 0.8520\n",
      "Epoch 73/100\n",
      "455/455 [==============================] - 0s 117us/step - loss: 0.3731 - accuracy: 0.8659 - val_loss: 0.3695 - val_accuracy: 0.8520\n",
      "Epoch 74/100\n",
      "455/455 [==============================] - 0s 94us/step - loss: 0.3725 - accuracy: 0.8637 - val_loss: 0.3687 - val_accuracy: 0.8520\n",
      "Epoch 75/100\n",
      "455/455 [==============================] - 0s 116us/step - loss: 0.3728 - accuracy: 0.8659 - val_loss: 0.3663 - val_accuracy: 0.8571\n",
      "Epoch 76/100\n",
      "455/455 [==============================] - 0s 108us/step - loss: 0.3726 - accuracy: 0.8659 - val_loss: 0.3675 - val_accuracy: 0.8520\n",
      "Epoch 77/100\n",
      "455/455 [==============================] - 0s 85us/step - loss: 0.3724 - accuracy: 0.8659 - val_loss: 0.3670 - val_accuracy: 0.8571\n",
      "Epoch 78/100\n",
      "455/455 [==============================] - 0s 87us/step - loss: 0.3708 - accuracy: 0.8659 - val_loss: 0.3654 - val_accuracy: 0.8520\n",
      "Epoch 79/100\n",
      "455/455 [==============================] - 0s 84us/step - loss: 0.3708 - accuracy: 0.8659 - val_loss: 0.3670 - val_accuracy: 0.8520\n",
      "Epoch 80/100\n",
      "455/455 [==============================] - 0s 86us/step - loss: 0.3695 - accuracy: 0.8681 - val_loss: 0.3644 - val_accuracy: 0.8571\n",
      "Epoch 81/100\n",
      "455/455 [==============================] - 0s 92us/step - loss: 0.3717 - accuracy: 0.8659 - val_loss: 0.3646 - val_accuracy: 0.8520\n",
      "Epoch 82/100\n",
      "455/455 [==============================] - 0s 87us/step - loss: 0.3722 - accuracy: 0.8659 - val_loss: 0.3623 - val_accuracy: 0.8571\n",
      "Epoch 83/100\n",
      "455/455 [==============================] - 0s 84us/step - loss: 0.3687 - accuracy: 0.8681 - val_loss: 0.3652 - val_accuracy: 0.8520\n",
      "Epoch 84/100\n",
      "455/455 [==============================] - 0s 133us/step - loss: 0.3693 - accuracy: 0.8659 - val_loss: 0.3619 - val_accuracy: 0.8571\n",
      "Epoch 85/100\n",
      "455/455 [==============================] - 0s 114us/step - loss: 0.3683 - accuracy: 0.8681 - val_loss: 0.3622 - val_accuracy: 0.8520\n",
      "Epoch 86/100\n",
      "455/455 [==============================] - 0s 125us/step - loss: 0.3676 - accuracy: 0.8681 - val_loss: 0.3633 - val_accuracy: 0.8571\n",
      "Epoch 87/100\n",
      "455/455 [==============================] - 0s 138us/step - loss: 0.3678 - accuracy: 0.8681 - val_loss: 0.3618 - val_accuracy: 0.8571\n",
      "Epoch 88/100\n",
      "455/455 [==============================] - 0s 135us/step - loss: 0.3671 - accuracy: 0.8659 - val_loss: 0.3632 - val_accuracy: 0.8571\n",
      "Epoch 89/100\n",
      "455/455 [==============================] - 0s 248us/step - loss: 0.3667 - accuracy: 0.8681 - val_loss: 0.3601 - val_accuracy: 0.8571\n",
      "Epoch 90/100\n",
      "455/455 [==============================] - 0s 147us/step - loss: 0.3667 - accuracy: 0.8659 - val_loss: 0.3634 - val_accuracy: 0.8571\n",
      "Epoch 91/100\n",
      "455/455 [==============================] - 0s 155us/step - loss: 0.3674 - accuracy: 0.8681 - val_loss: 0.3589 - val_accuracy: 0.8571\n",
      "Epoch 92/100\n",
      "455/455 [==============================] - 0s 135us/step - loss: 0.3686 - accuracy: 0.8659 - val_loss: 0.3610 - val_accuracy: 0.8571\n",
      "Epoch 93/100\n",
      "455/455 [==============================] - 0s 128us/step - loss: 0.3674 - accuracy: 0.8681 - val_loss: 0.3606 - val_accuracy: 0.8571\n",
      "Epoch 94/100\n",
      "455/455 [==============================] - 0s 171us/step - loss: 0.3658 - accuracy: 0.8681 - val_loss: 0.3601 - val_accuracy: 0.8571\n",
      "Epoch 95/100\n",
      "455/455 [==============================] - 0s 137us/step - loss: 0.3652 - accuracy: 0.8681 - val_loss: 0.3584 - val_accuracy: 0.8571\n",
      "Epoch 96/100\n",
      "455/455 [==============================] - 0s 130us/step - loss: 0.3644 - accuracy: 0.8681 - val_loss: 0.3587 - val_accuracy: 0.8571\n",
      "Epoch 97/100\n",
      "455/455 [==============================] - 0s 149us/step - loss: 0.3646 - accuracy: 0.8681 - val_loss: 0.3592 - val_accuracy: 0.8571\n",
      "Epoch 98/100\n",
      "455/455 [==============================] - 0s 134us/step - loss: 0.3659 - accuracy: 0.8681 - val_loss: 0.3578 - val_accuracy: 0.8571\n",
      "Epoch 99/100\n",
      "455/455 [==============================] - 0s 96us/step - loss: 0.3629 - accuracy: 0.8681 - val_loss: 0.3588 - val_accuracy: 0.8571\n",
      "Epoch 100/100\n",
      "455/455 [==============================] - 0s 86us/step - loss: 0.3632 - accuracy: 0.8681 - val_loss: 0.3581 - val_accuracy: 0.8571\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a3f155b38>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over4.fit(X_train_over, y_train_over,\n",
    "          batch_size=16, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196/196 [==============================] - 0s 48us/step\n",
      "over-sampling test accuracy: 85.71%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over4 = model1_over4.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over4*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 0, 0, 2, 1, 1, 2, 2, 0, 2, 1, 1, 2, 0, 0, 0, 2, 2, 1, 2, 2,\n",
       "       1, 1, 1, 0, 2, 2, 1, 1, 2, 0, 0, 2, 2, 0, 0, 0, 1, 1, 1, 2, 1, 0,\n",
       "       1, 1, 2, 2, 0, 0, 2, 0, 2, 2, 1, 0, 0, 0, 0, 1, 1, 1, 2, 1, 2, 0,\n",
       "       0, 0, 1, 2, 0, 0, 1, 2, 0, 1, 2, 0, 0, 0, 0, 2, 1, 2, 1, 0, 1, 0,\n",
       "       0, 2, 2, 2, 2, 2, 1, 2, 1, 1, 1, 2, 1, 0, 2, 2, 0, 1, 1, 2, 0, 1,\n",
       "       2, 2, 2, 0, 2, 2, 2, 1, 1, 1, 0, 2, 0, 1, 0, 0, 2, 2, 2, 0, 0, 0,\n",
       "       2, 1, 2, 0, 0, 0, 1, 2, 2, 0, 0, 2, 0, 0, 0, 0, 0, 1, 2, 2, 2, 2,\n",
       "       1, 1, 1, 2, 2, 0, 0, 2, 1, 0, 0, 2, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 2, 1, 1, 1, 0, 2, 0, 0, 0, 1, 2, 0, 2, 2, 1, 1, 2, 0, 2])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred4 = model1_over4.predict_classes(X_test_over)\n",
    "pred4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS178</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS073</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CFBREBSa119</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>NRS236</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>NRS029</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>CFBRSa28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>NRS205</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>196 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test  pred\n",
       "0         NRS178     1     1\n",
       "1         NRS109     2     2\n",
       "2         NRS073     1     0\n",
       "3    CFBREBSa119     0     0\n",
       "4         NRS109     2     2\n",
       "..           ...   ...   ...\n",
       "191       NRS236     1     1\n",
       "192       NRS029     0     1\n",
       "193       NRS148     2     2\n",
       "194     CFBRSa28     0     0\n",
       "195       NRS205     2     2\n",
       "\n",
       "[196 rows x 3 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat4['pred'] = pred4\n",
    "dat4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba4 = model1_over4.predict_proba(X_test_over)\n",
    "dat_proba4 = pd.DataFrame(proba4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.012761</td>\n",
       "      <td>0.987239</td>\n",
       "      <td>1.959349e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.027085</td>\n",
       "      <td>0.109052</td>\n",
       "      <td>8.638632e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.792741</td>\n",
       "      <td>0.204852</td>\n",
       "      <td>2.406992e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.830995</td>\n",
       "      <td>0.168971</td>\n",
       "      <td>3.317414e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.027085</td>\n",
       "      <td>0.109052</td>\n",
       "      <td>8.638632e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>0.152473</td>\n",
       "      <td>0.846993</td>\n",
       "      <td>5.343235e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>0.206379</td>\n",
       "      <td>0.793612</td>\n",
       "      <td>8.724219e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>0.002777</td>\n",
       "      <td>0.057920</td>\n",
       "      <td>9.393021e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>0.830995</td>\n",
       "      <td>0.168971</td>\n",
       "      <td>3.317414e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.002777</td>\n",
       "      <td>0.057920</td>\n",
       "      <td>9.393021e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>196 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1             2\n",
       "0    0.012761  0.987239  1.959349e-07\n",
       "1    0.027085  0.109052  8.638632e-01\n",
       "2    0.792741  0.204852  2.406992e-03\n",
       "3    0.830995  0.168971  3.317414e-05\n",
       "4    0.027085  0.109052  8.638632e-01\n",
       "..        ...       ...           ...\n",
       "191  0.152473  0.846993  5.343235e-04\n",
       "192  0.206379  0.793612  8.724219e-06\n",
       "193  0.002777  0.057920  9.393021e-01\n",
       "194  0.830995  0.168971  3.317414e-05\n",
       "195  0.002777  0.057920  9.393021e-01\n",
       "\n",
       "[196 rows x 3 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba4.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba4.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat4.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/4pyo.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 455 samples, validate on 196 samples\n",
      "Epoch 1/100\n",
      "455/455 [==============================] - 0s 187us/step - loss: 0.3775 - accuracy: 0.8659 - val_loss: 0.3635 - val_accuracy: 0.8571\n",
      "Epoch 2/100\n",
      "455/455 [==============================] - 0s 109us/step - loss: 0.3766 - accuracy: 0.8659 - val_loss: 0.3642 - val_accuracy: 0.8571\n",
      "Epoch 3/100\n",
      "455/455 [==============================] - 0s 94us/step - loss: 0.3734 - accuracy: 0.8659 - val_loss: 0.3648 - val_accuracy: 0.8571\n",
      "Epoch 4/100\n",
      "455/455 [==============================] - 0s 90us/step - loss: 0.3759 - accuracy: 0.8659 - val_loss: 0.3637 - val_accuracy: 0.8571\n",
      "Epoch 5/100\n",
      "455/455 [==============================] - 0s 91us/step - loss: 0.3757 - accuracy: 0.8659 - val_loss: 0.3622 - val_accuracy: 0.8571\n",
      "Epoch 6/100\n",
      "455/455 [==============================] - 0s 90us/step - loss: 0.3752 - accuracy: 0.8637 - val_loss: 0.3634 - val_accuracy: 0.8571\n",
      "Epoch 7/100\n",
      "455/455 [==============================] - 0s 104us/step - loss: 0.3745 - accuracy: 0.8659 - val_loss: 0.3631 - val_accuracy: 0.8571\n",
      "Epoch 8/100\n",
      "455/455 [==============================] - 0s 91us/step - loss: 0.3770 - accuracy: 0.8659 - val_loss: 0.3627 - val_accuracy: 0.8571\n",
      "Epoch 9/100\n",
      "455/455 [==============================] - 0s 97us/step - loss: 0.3722 - accuracy: 0.8659 - val_loss: 0.3625 - val_accuracy: 0.8571\n",
      "Epoch 10/100\n",
      "455/455 [==============================] - 0s 91us/step - loss: 0.3745 - accuracy: 0.8659 - val_loss: 0.3613 - val_accuracy: 0.8571\n",
      "Epoch 11/100\n",
      "455/455 [==============================] - 0s 93us/step - loss: 0.3726 - accuracy: 0.8659 - val_loss: 0.3608 - val_accuracy: 0.8571\n",
      "Epoch 12/100\n",
      "455/455 [==============================] - 0s 91us/step - loss: 0.3749 - accuracy: 0.8659 - val_loss: 0.3619 - val_accuracy: 0.8571\n",
      "Epoch 13/100\n",
      "455/455 [==============================] - 0s 105us/step - loss: 0.3712 - accuracy: 0.8637 - val_loss: 0.3632 - val_accuracy: 0.8571\n",
      "Epoch 14/100\n",
      "455/455 [==============================] - 0s 103us/step - loss: 0.3726 - accuracy: 0.8659 - val_loss: 0.3600 - val_accuracy: 0.8571\n",
      "Epoch 15/100\n",
      "455/455 [==============================] - 0s 94us/step - loss: 0.3733 - accuracy: 0.8637 - val_loss: 0.3603 - val_accuracy: 0.8571\n",
      "Epoch 16/100\n",
      "455/455 [==============================] - 0s 92us/step - loss: 0.3727 - accuracy: 0.8659 - val_loss: 0.3594 - val_accuracy: 0.8571\n",
      "Epoch 17/100\n",
      "455/455 [==============================] - 0s 89us/step - loss: 0.3716 - accuracy: 0.8659 - val_loss: 0.3588 - val_accuracy: 0.8571\n",
      "Epoch 18/100\n",
      "455/455 [==============================] - 0s 92us/step - loss: 0.3708 - accuracy: 0.8659 - val_loss: 0.3587 - val_accuracy: 0.8571\n",
      "Epoch 19/100\n",
      "455/455 [==============================] - 0s 90us/step - loss: 0.3740 - accuracy: 0.8637 - val_loss: 0.3573 - val_accuracy: 0.8571\n",
      "Epoch 20/100\n",
      "455/455 [==============================] - 0s 102us/step - loss: 0.3747 - accuracy: 0.8659 - val_loss: 0.3575 - val_accuracy: 0.8571\n",
      "Epoch 21/100\n",
      "455/455 [==============================] - 0s 97us/step - loss: 0.3718 - accuracy: 0.8637 - val_loss: 0.3581 - val_accuracy: 0.8571\n",
      "Epoch 22/100\n",
      "455/455 [==============================] - 0s 92us/step - loss: 0.3711 - accuracy: 0.8659 - val_loss: 0.3600 - val_accuracy: 0.8571\n",
      "Epoch 23/100\n",
      "455/455 [==============================] - 0s 106us/step - loss: 0.3707 - accuracy: 0.8659 - val_loss: 0.3581 - val_accuracy: 0.8571\n",
      "Epoch 24/100\n",
      "455/455 [==============================] - 0s 109us/step - loss: 0.3692 - accuracy: 0.8659 - val_loss: 0.3561 - val_accuracy: 0.8571\n",
      "Epoch 25/100\n",
      "455/455 [==============================] - 0s 102us/step - loss: 0.3694 - accuracy: 0.8659 - val_loss: 0.3581 - val_accuracy: 0.8571\n",
      "Epoch 26/100\n",
      "455/455 [==============================] - 0s 138us/step - loss: 0.3690 - accuracy: 0.8659 - val_loss: 0.3567 - val_accuracy: 0.8571\n",
      "Epoch 27/100\n",
      "455/455 [==============================] - 0s 115us/step - loss: 0.3693 - accuracy: 0.8681 - val_loss: 0.3545 - val_accuracy: 0.8571\n",
      "Epoch 28/100\n",
      "455/455 [==============================] - 0s 115us/step - loss: 0.3693 - accuracy: 0.8659 - val_loss: 0.3548 - val_accuracy: 0.8571\n",
      "Epoch 29/100\n",
      "455/455 [==============================] - 0s 101us/step - loss: 0.3698 - accuracy: 0.8637 - val_loss: 0.3558 - val_accuracy: 0.8571\n",
      "Epoch 30/100\n",
      "455/455 [==============================] - 0s 97us/step - loss: 0.3689 - accuracy: 0.8659 - val_loss: 0.3553 - val_accuracy: 0.8571\n",
      "Epoch 31/100\n",
      "455/455 [==============================] - 0s 111us/step - loss: 0.3708 - accuracy: 0.8615 - val_loss: 0.3562 - val_accuracy: 0.8571\n",
      "Epoch 32/100\n",
      "455/455 [==============================] - 0s 122us/step - loss: 0.3685 - accuracy: 0.8637 - val_loss: 0.3530 - val_accuracy: 0.8571\n",
      "Epoch 33/100\n",
      "455/455 [==============================] - 0s 128us/step - loss: 0.3676 - accuracy: 0.8681 - val_loss: 0.3546 - val_accuracy: 0.8571\n",
      "Epoch 34/100\n",
      "455/455 [==============================] - 0s 121us/step - loss: 0.3671 - accuracy: 0.8659 - val_loss: 0.3538 - val_accuracy: 0.8571\n",
      "Epoch 35/100\n",
      "455/455 [==============================] - 0s 109us/step - loss: 0.3672 - accuracy: 0.8615 - val_loss: 0.3538 - val_accuracy: 0.8571\n",
      "Epoch 36/100\n",
      "455/455 [==============================] - 0s 104us/step - loss: 0.3701 - accuracy: 0.8659 - val_loss: 0.3530 - val_accuracy: 0.8571\n",
      "Epoch 37/100\n",
      "455/455 [==============================] - 0s 92us/step - loss: 0.3726 - accuracy: 0.8637 - val_loss: 0.3538 - val_accuracy: 0.8571\n",
      "Epoch 38/100\n",
      "455/455 [==============================] - 0s 89us/step - loss: 0.3733 - accuracy: 0.8659 - val_loss: 0.3541 - val_accuracy: 0.8571\n",
      "Epoch 39/100\n",
      "455/455 [==============================] - 0s 97us/step - loss: 0.3670 - accuracy: 0.8637 - val_loss: 0.3536 - val_accuracy: 0.8571\n",
      "Epoch 40/100\n",
      "455/455 [==============================] - 0s 89us/step - loss: 0.3660 - accuracy: 0.8593 - val_loss: 0.3538 - val_accuracy: 0.8571\n",
      "Epoch 41/100\n",
      "455/455 [==============================] - 0s 129us/step - loss: 0.3660 - accuracy: 0.8659 - val_loss: 0.3539 - val_accuracy: 0.8571\n",
      "Epoch 42/100\n",
      "455/455 [==============================] - 0s 111us/step - loss: 0.3666 - accuracy: 0.8659 - val_loss: 0.3529 - val_accuracy: 0.8571\n",
      "Epoch 43/100\n",
      "455/455 [==============================] - 0s 101us/step - loss: 0.3672 - accuracy: 0.8703 - val_loss: 0.3518 - val_accuracy: 0.8571\n",
      "Epoch 44/100\n",
      "455/455 [==============================] - 0s 89us/step - loss: 0.3655 - accuracy: 0.8659 - val_loss: 0.3516 - val_accuracy: 0.8571\n",
      "Epoch 45/100\n",
      "455/455 [==============================] - 0s 92us/step - loss: 0.3651 - accuracy: 0.8615 - val_loss: 0.3516 - val_accuracy: 0.8571\n",
      "Epoch 46/100\n",
      "455/455 [==============================] - 0s 86us/step - loss: 0.3684 - accuracy: 0.8659 - val_loss: 0.3523 - val_accuracy: 0.8571\n",
      "Epoch 47/100\n",
      "455/455 [==============================] - 0s 86us/step - loss: 0.3669 - accuracy: 0.8615 - val_loss: 0.3518 - val_accuracy: 0.8571\n",
      "Epoch 48/100\n",
      "455/455 [==============================] - 0s 98us/step - loss: 0.3653 - accuracy: 0.8593 - val_loss: 0.3503 - val_accuracy: 0.8571\n",
      "Epoch 49/100\n",
      "455/455 [==============================] - 0s 115us/step - loss: 0.3669 - accuracy: 0.8659 - val_loss: 0.3505 - val_accuracy: 0.8571\n",
      "Epoch 50/100\n",
      "455/455 [==============================] - 0s 100us/step - loss: 0.3643 - accuracy: 0.8703 - val_loss: 0.3532 - val_accuracy: 0.8571\n",
      "Epoch 51/100\n",
      "455/455 [==============================] - 0s 96us/step - loss: 0.3644 - accuracy: 0.8637 - val_loss: 0.3507 - val_accuracy: 0.8571\n",
      "Epoch 52/100\n",
      "455/455 [==============================] - 0s 84us/step - loss: 0.3644 - accuracy: 0.8615 - val_loss: 0.3509 - val_accuracy: 0.8571\n",
      "Epoch 53/100\n",
      "455/455 [==============================] - 0s 85us/step - loss: 0.3637 - accuracy: 0.8659 - val_loss: 0.3505 - val_accuracy: 0.8571\n",
      "Epoch 54/100\n",
      "455/455 [==============================] - 0s 85us/step - loss: 0.3650 - accuracy: 0.8637 - val_loss: 0.3503 - val_accuracy: 0.8571\n",
      "Epoch 55/100\n",
      "455/455 [==============================] - 0s 88us/step - loss: 0.3645 - accuracy: 0.8659 - val_loss: 0.3495 - val_accuracy: 0.8571\n",
      "Epoch 56/100\n",
      "455/455 [==============================] - 0s 85us/step - loss: 0.3626 - accuracy: 0.8659 - val_loss: 0.3482 - val_accuracy: 0.8571\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "455/455 [==============================] - 0s 114us/step - loss: 0.3645 - accuracy: 0.8681 - val_loss: 0.3498 - val_accuracy: 0.8571\n",
      "Epoch 58/100\n",
      "455/455 [==============================] - 0s 112us/step - loss: 0.3634 - accuracy: 0.8659 - val_loss: 0.3478 - val_accuracy: 0.8571\n",
      "Epoch 59/100\n",
      "455/455 [==============================] - 0s 99us/step - loss: 0.3629 - accuracy: 0.8637 - val_loss: 0.3501 - val_accuracy: 0.8520\n",
      "Epoch 60/100\n",
      "455/455 [==============================] - 0s 96us/step - loss: 0.3609 - accuracy: 0.8615 - val_loss: 0.3495 - val_accuracy: 0.8571\n",
      "Epoch 61/100\n",
      "455/455 [==============================] - 0s 106us/step - loss: 0.3641 - accuracy: 0.8659 - val_loss: 0.3508 - val_accuracy: 0.8571\n",
      "Epoch 62/100\n",
      "455/455 [==============================] - 0s 118us/step - loss: 0.3643 - accuracy: 0.8637 - val_loss: 0.3470 - val_accuracy: 0.8571\n",
      "Epoch 63/100\n",
      "455/455 [==============================] - 0s 130us/step - loss: 0.3613 - accuracy: 0.8615 - val_loss: 0.3483 - val_accuracy: 0.8571\n",
      "Epoch 64/100\n",
      "455/455 [==============================] - 0s 134us/step - loss: 0.3639 - accuracy: 0.8681 - val_loss: 0.3472 - val_accuracy: 0.8571\n",
      "Epoch 65/100\n",
      "455/455 [==============================] - 0s 112us/step - loss: 0.3638 - accuracy: 0.8681 - val_loss: 0.3480 - val_accuracy: 0.8571\n",
      "Epoch 66/100\n",
      "455/455 [==============================] - 0s 97us/step - loss: 0.3646 - accuracy: 0.8659 - val_loss: 0.3506 - val_accuracy: 0.8571\n",
      "Epoch 67/100\n",
      "455/455 [==============================] - 0s 90us/step - loss: 0.3608 - accuracy: 0.8681 - val_loss: 0.3459 - val_accuracy: 0.8571\n",
      "Epoch 68/100\n",
      "455/455 [==============================] - 0s 87us/step - loss: 0.3611 - accuracy: 0.8659 - val_loss: 0.3457 - val_accuracy: 0.8571\n",
      "Epoch 69/100\n",
      "455/455 [==============================] - 0s 87us/step - loss: 0.3624 - accuracy: 0.8637 - val_loss: 0.3513 - val_accuracy: 0.8520\n",
      "Epoch 70/100\n",
      "455/455 [==============================] - 0s 90us/step - loss: 0.3633 - accuracy: 0.8615 - val_loss: 0.3488 - val_accuracy: 0.8571\n",
      "Epoch 71/100\n",
      "455/455 [==============================] - 0s 86us/step - loss: 0.3612 - accuracy: 0.8681 - val_loss: 0.3454 - val_accuracy: 0.8571\n",
      "Epoch 72/100\n",
      "455/455 [==============================] - 0s 84us/step - loss: 0.3620 - accuracy: 0.8659 - val_loss: 0.3463 - val_accuracy: 0.8571\n",
      "Epoch 73/100\n",
      "455/455 [==============================] - 0s 88us/step - loss: 0.3602 - accuracy: 0.8659 - val_loss: 0.3449 - val_accuracy: 0.8571\n",
      "Epoch 74/100\n",
      "455/455 [==============================] - 0s 97us/step - loss: 0.3618 - accuracy: 0.8615 - val_loss: 0.3456 - val_accuracy: 0.8571\n",
      "Epoch 75/100\n",
      "455/455 [==============================] - 0s 96us/step - loss: 0.3623 - accuracy: 0.8637 - val_loss: 0.3465 - val_accuracy: 0.8571\n",
      "Epoch 76/100\n",
      "455/455 [==============================] - 0s 103us/step - loss: 0.3634 - accuracy: 0.8659 - val_loss: 0.3457 - val_accuracy: 0.8571\n",
      "Epoch 77/100\n",
      "455/455 [==============================] - 0s 103us/step - loss: 0.3613 - accuracy: 0.8615 - val_loss: 0.3439 - val_accuracy: 0.8622\n",
      "Epoch 78/100\n",
      "455/455 [==============================] - 0s 104us/step - loss: 0.3624 - accuracy: 0.8681 - val_loss: 0.3469 - val_accuracy: 0.8571\n",
      "Epoch 79/100\n",
      "455/455 [==============================] - 0s 102us/step - loss: 0.3603 - accuracy: 0.8637 - val_loss: 0.3464 - val_accuracy: 0.8571\n",
      "Epoch 80/100\n",
      "455/455 [==============================] - 0s 103us/step - loss: 0.3602 - accuracy: 0.8659 - val_loss: 0.3453 - val_accuracy: 0.8571\n",
      "Epoch 81/100\n",
      "455/455 [==============================] - 0s 90us/step - loss: 0.3592 - accuracy: 0.8659 - val_loss: 0.3464 - val_accuracy: 0.8571\n",
      "Epoch 82/100\n",
      "455/455 [==============================] - 0s 88us/step - loss: 0.3599 - accuracy: 0.8681 - val_loss: 0.3438 - val_accuracy: 0.8622\n",
      "Epoch 83/100\n",
      "455/455 [==============================] - 0s 87us/step - loss: 0.3668 - accuracy: 0.8681 - val_loss: 0.3456 - val_accuracy: 0.8571\n",
      "Epoch 84/100\n",
      "455/455 [==============================] - 0s 89us/step - loss: 0.3610 - accuracy: 0.8659 - val_loss: 0.3444 - val_accuracy: 0.8622\n",
      "Epoch 85/100\n",
      "455/455 [==============================] - 0s 93us/step - loss: 0.3624 - accuracy: 0.8615 - val_loss: 0.3435 - val_accuracy: 0.8622\n",
      "Epoch 86/100\n",
      "455/455 [==============================] - 0s 95us/step - loss: 0.3614 - accuracy: 0.8681 - val_loss: 0.3465 - val_accuracy: 0.8622\n",
      "Epoch 87/100\n",
      "455/455 [==============================] - 0s 97us/step - loss: 0.3613 - accuracy: 0.8725 - val_loss: 0.3452 - val_accuracy: 0.8571\n",
      "Epoch 88/100\n",
      "455/455 [==============================] - 0s 128us/step - loss: 0.3590 - accuracy: 0.8637 - val_loss: 0.3443 - val_accuracy: 0.8622\n",
      "Epoch 89/100\n",
      "455/455 [==============================] - 0s 115us/step - loss: 0.3612 - accuracy: 0.8681 - val_loss: 0.3461 - val_accuracy: 0.8571\n",
      "Epoch 90/100\n",
      "455/455 [==============================] - 0s 89us/step - loss: 0.3600 - accuracy: 0.8637 - val_loss: 0.3451 - val_accuracy: 0.8622\n",
      "Epoch 91/100\n",
      "455/455 [==============================] - 0s 90us/step - loss: 0.3595 - accuracy: 0.8637 - val_loss: 0.3474 - val_accuracy: 0.8520\n",
      "Epoch 92/100\n",
      "455/455 [==============================] - 0s 96us/step - loss: 0.3590 - accuracy: 0.8659 - val_loss: 0.3444 - val_accuracy: 0.8571\n",
      "Epoch 93/100\n",
      "455/455 [==============================] - 0s 96us/step - loss: 0.3588 - accuracy: 0.8681 - val_loss: 0.3458 - val_accuracy: 0.8622\n",
      "Epoch 94/100\n",
      "455/455 [==============================] - 0s 89us/step - loss: 0.3586 - accuracy: 0.8659 - val_loss: 0.3466 - val_accuracy: 0.8622\n",
      "Epoch 95/100\n",
      "455/455 [==============================] - 0s 87us/step - loss: 0.3583 - accuracy: 0.8681 - val_loss: 0.3461 - val_accuracy: 0.8571\n",
      "Epoch 96/100\n",
      "455/455 [==============================] - 0s 89us/step - loss: 0.3583 - accuracy: 0.8659 - val_loss: 0.3466 - val_accuracy: 0.8571\n",
      "Epoch 97/100\n",
      "455/455 [==============================] - 0s 88us/step - loss: 0.3587 - accuracy: 0.8659 - val_loss: 0.3481 - val_accuracy: 0.8520\n",
      "Epoch 98/100\n",
      "455/455 [==============================] - 0s 91us/step - loss: 0.3575 - accuracy: 0.8637 - val_loss: 0.3449 - val_accuracy: 0.8622\n",
      "Epoch 99/100\n",
      "455/455 [==============================] - 0s 90us/step - loss: 0.3611 - accuracy: 0.8681 - val_loss: 0.3439 - val_accuracy: 0.8622\n",
      "Epoch 100/100\n",
      "455/455 [==============================] - 0s 101us/step - loss: 0.3590 - accuracy: 0.8681 - val_loss: 0.3428 - val_accuracy: 0.8622\n"
     ]
    }
   ],
   "source": [
    "hist1_over4 = model1_over4.fit(X_train_over, y_train_over,\n",
    "          batch_size=16, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 86.54%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over4.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba4 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_2.xlsx\",\n",
    "                        sheet_name=3,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS110</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>5.870196e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS216</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.039254</td>\n",
       "      <td>0.960745</td>\n",
       "      <td>9.078969e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS386</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.326752</td>\n",
       "      <td>0.673248</td>\n",
       "      <td>1.061032e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>CFBRSa25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.611084</td>\n",
       "      <td>0.388916</td>\n",
       "      <td>7.664974e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>BCH-SA-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.611084</td>\n",
       "      <td>0.388916</td>\n",
       "      <td>7.664974e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4279</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS236</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.999768</td>\n",
       "      <td>1.803156e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4280</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS029</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.322350</td>\n",
       "      <td>0.677496</td>\n",
       "      <td>1.533154e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4281</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>9.999682e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4282</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>CFBRSa28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999288</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>5.361527e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4283</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS205</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>9.999868e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4284 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    phage     strain  phenotype  prediction         0  \\\n",
       "0      p002ykpresabs_qual     NRS110          1           1  0.000003   \n",
       "1      p002ykpresabs_qual     NRS216          1           1  0.039254   \n",
       "2      p002ykpresabs_qual     NRS386          1           1  0.326752   \n",
       "3      p002ykpresabs_qual   CFBRSa25          0           0  0.611084   \n",
       "4      p002ykpresabs_qual  BCH-SA-03          1           0  0.611084   \n",
       "...                   ...        ...        ...         ...       ...   \n",
       "4279  pyopresabsSTCC_qual     NRS236          1           1  0.000052   \n",
       "4280  pyopresabsSTCC_qual     NRS029          0           1  0.322350   \n",
       "4281  pyopresabsSTCC_qual     NRS148          2           2  0.000006   \n",
       "4282  pyopresabsSTCC_qual   CFBRSa28          0           0  0.999288   \n",
       "4283  pyopresabsSTCC_qual     NRS205          2           2  0.000007   \n",
       "\n",
       "             1             2  \n",
       "0     0.999997  5.870196e-13  \n",
       "1     0.960745  9.078969e-07  \n",
       "2     0.673248  1.061032e-07  \n",
       "3     0.388916  7.664974e-07  \n",
       "4     0.388916  7.664974e-07  \n",
       "...        ...           ...  \n",
       "4279  0.999768  1.803156e-04  \n",
       "4280  0.677496  1.533154e-04  \n",
       "4281  0.000026  9.999682e-01  \n",
       "4282  0.000176  5.361527e-04  \n",
       "4283  0.000007  9.999868e-01  \n",
       "\n",
       "[4284 rows x 7 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.2761022e-02, 9.8723870e-01, 1.9593487e-07],\n",
       "       [2.7084640e-02, 1.0905208e-01, 8.6386320e-01],\n",
       "       [7.9274064e-01, 2.0485236e-01, 2.4069923e-03],\n",
       "       [8.3099530e-01, 1.6897143e-01, 3.3174143e-05],\n",
       "       [2.7084640e-02, 1.0905208e-01, 8.6386320e-01],\n",
       "       [7.2012990e-02, 9.2530360e-01, 2.6833606e-03],\n",
       "       [6.3467050e-02, 7.4327767e-01, 1.9325529e-01],\n",
       "       [2.7084640e-02, 1.0905208e-01, 8.6386320e-01],\n",
       "       [2.7774759e-03, 5.7920440e-02, 9.3930210e-01],\n",
       "       [8.3099530e-01, 1.6897143e-01, 3.3174143e-05],\n",
       "       [2.7084640e-02, 1.0905208e-01, 8.6386320e-01],\n",
       "       [7.2012990e-02, 9.2530360e-01, 2.6833606e-03],\n",
       "       [3.0826753e-01, 6.9172376e-01, 8.7076450e-06],\n",
       "       [2.7774759e-03, 5.7920440e-02, 9.3930210e-01],\n",
       "       [8.3099530e-01, 1.6897143e-01, 3.3174143e-05],\n",
       "       [7.9274064e-01, 2.0485236e-01, 2.4069923e-03],\n",
       "       [8.3099530e-01, 1.6897143e-01, 3.3174143e-05],\n",
       "       [2.7774759e-03, 5.7920440e-02, 9.3930210e-01],\n",
       "       [6.8332140e-03, 2.0272063e-02, 9.7289480e-01],\n",
       "       [2.0637909e-01, 7.9361220e-01, 8.7242190e-06],\n",
       "       [2.7774759e-03, 5.7920440e-02, 9.3930210e-01],\n",
       "       [2.7774759e-03, 5.7920440e-02, 9.3930210e-01],\n",
       "       [1.3784921e-03, 9.7420245e-01, 2.4419025e-02],\n",
       "       [3.0826753e-01, 6.9172376e-01, 8.7076450e-06],\n",
       "       [3.5318553e-02, 9.6424574e-01, 4.3580100e-04],\n",
       "       [8.3099530e-01, 1.6897143e-01, 3.3174143e-05],\n",
       "       [2.7774759e-03, 5.7920440e-02, 9.3930210e-01],\n",
       "       [2.7774759e-03, 5.7920440e-02, 9.3930210e-01],\n",
       "       [3.0988177e-02, 9.5964950e-01, 9.3623360e-03],\n",
       "       [2.3522975e-01, 7.6442754e-01, 3.4260796e-04],\n",
       "       [2.7774759e-03, 5.7920440e-02, 9.3930210e-01],\n",
       "       [8.3099530e-01, 1.6897143e-01, 3.3174143e-05],\n",
       "       [7.9274064e-01, 2.0485236e-01, 2.4069923e-03],\n",
       "       [2.7774759e-03, 5.7920440e-02, 9.3930210e-01],\n",
       "       [6.8332140e-03, 2.0272063e-02, 9.7289480e-01],\n",
       "       [8.3099530e-01, 1.6897143e-01, 3.3174143e-05],\n",
       "       [7.9274064e-01, 2.0485236e-01, 2.4069923e-03],\n",
       "       [7.9274064e-01, 2.0485236e-01, 2.4069923e-03],\n",
       "       [2.0637909e-01, 7.9361220e-01, 8.7242190e-06],\n",
       "       [1.3784921e-03, 9.7420245e-01, 2.4419025e-02],\n",
       "       [3.0988177e-02, 9.5964950e-01, 9.3623360e-03],\n",
       "       [2.7084640e-02, 1.0905208e-01, 8.6386320e-01],\n",
       "       [3.0826753e-01, 6.9172376e-01, 8.7076450e-06],\n",
       "       [7.9274064e-01, 2.0485236e-01, 2.4069923e-03],\n",
       "       [2.3522975e-01, 7.6442754e-01, 3.4260796e-04],\n",
       "       [2.0637909e-01, 7.9361220e-01, 8.7242190e-06],\n",
       "       [6.8332140e-03, 2.0272063e-02, 9.7289480e-01],\n",
       "       [2.7774759e-03, 5.7920440e-02, 9.3930210e-01],\n",
       "       [8.3099530e-01, 1.6897143e-01, 3.3174143e-05],\n",
       "       [8.3099530e-01, 1.6897143e-01, 3.3174143e-05],\n",
       "       [6.8332140e-03, 2.0272063e-02, 9.7289480e-01],\n",
       "       [7.9274064e-01, 2.0485236e-01, 2.4069923e-03],\n",
       "       [2.7084640e-02, 1.0905208e-01, 8.6386320e-01],\n",
       "       [6.8332140e-03, 2.0272063e-02, 9.7289480e-01],\n",
       "       [2.0637909e-01, 7.9361220e-01, 8.7242190e-06],\n",
       "       [7.9274064e-01, 2.0485236e-01, 2.4069923e-03],\n",
       "       [7.9274064e-01, 2.0485236e-01, 2.4069923e-03],\n",
       "       [7.9274064e-01, 2.0485236e-01, 2.4069923e-03],\n",
       "       [8.3099530e-01, 1.6897143e-01, 3.3174143e-05],\n",
       "       [3.0826753e-01, 6.9172376e-01, 8.7076450e-06],\n",
       "       [3.0988177e-02, 9.5964950e-01, 9.3623360e-03],\n",
       "       [3.0988177e-02, 9.5964950e-01, 9.3623360e-03],\n",
       "       [6.8332140e-03, 2.0272063e-02, 9.7289480e-01],\n",
       "       [1.5247265e-01, 8.4699300e-01, 5.3432345e-04],\n",
       "       [6.8332140e-03, 2.0272063e-02, 9.7289480e-01],\n",
       "       [8.3099530e-01, 1.6897143e-01, 3.3174143e-05],\n",
       "       [7.4803240e-01, 2.5061485e-01, 1.3527069e-03],\n",
       "       [8.3099530e-01, 1.6897143e-01, 3.3174143e-05],\n",
       "       [3.0988177e-02, 9.5964950e-01, 9.3623360e-03],\n",
       "       [2.7774759e-03, 5.7920440e-02, 9.3930210e-01],\n",
       "       [8.3099530e-01, 1.6897143e-01, 3.3174143e-05],\n",
       "       [7.9274064e-01, 2.0485236e-01, 2.4069923e-03],\n",
       "       [3.0826753e-01, 6.9172376e-01, 8.7076450e-06],\n",
       "       [2.7774759e-03, 5.7920440e-02, 9.3930210e-01],\n",
       "       [8.3099530e-01, 1.6897143e-01, 3.3174143e-05],\n",
       "       [2.3522975e-01, 7.6442754e-01, 3.4260796e-04],\n",
       "       [2.7084640e-02, 1.0905208e-01, 8.6386320e-01],\n",
       "       [5.9154093e-01, 4.0836304e-01, 9.6032580e-05],\n",
       "       [7.9274064e-01, 2.0485236e-01, 2.4069923e-03],\n",
       "       [8.3099530e-01, 1.6897143e-01, 3.3174143e-05],\n",
       "       [7.9274064e-01, 2.0485236e-01, 2.4069923e-03],\n",
       "       [2.7774759e-03, 5.7920440e-02, 9.3930210e-01],\n",
       "       [1.5247265e-01, 8.4699300e-01, 5.3432345e-04],\n",
       "       [2.7774759e-03, 5.7920440e-02, 9.3930210e-01],\n",
       "       [2.8618490e-01, 7.1381450e-01, 5.5894400e-07],\n",
       "       [8.3099530e-01, 1.6897143e-01, 3.3174143e-05],\n",
       "       [2.0637909e-01, 7.9361220e-01, 8.7242190e-06],\n",
       "       [8.3099530e-01, 1.6897143e-01, 3.3174143e-05],\n",
       "       [7.4803240e-01, 2.5061485e-01, 1.3527069e-03],\n",
       "       [2.7774759e-03, 5.7920440e-02, 9.3930210e-01],\n",
       "       [2.7774759e-03, 5.7920440e-02, 9.3930210e-01],\n",
       "       [2.7774759e-03, 5.7920440e-02, 9.3930210e-01],\n",
       "       [2.7774759e-03, 5.7920440e-02, 9.3930210e-01],\n",
       "       [2.7774759e-03, 5.7920440e-02, 9.3930210e-01],\n",
       "       [2.0637909e-01, 7.9361220e-01, 8.7242190e-06],\n",
       "       [2.7774759e-03, 5.7920440e-02, 9.3930210e-01],\n",
       "       [3.0988177e-02, 9.5964950e-01, 9.3623360e-03],\n",
       "       [3.0826753e-01, 6.9172376e-01, 8.7076450e-06],\n",
       "       [3.0826753e-01, 6.9172376e-01, 8.7076450e-06],\n",
       "       [6.8332140e-03, 2.0272063e-02, 9.7289480e-01],\n",
       "       [3.0826753e-01, 6.9172376e-01, 8.7076450e-06],\n",
       "       [8.3099530e-01, 1.6897143e-01, 3.3174143e-05],\n",
       "       [2.7774759e-03, 5.7920440e-02, 9.3930210e-01],\n",
       "       [2.7774759e-03, 5.7920440e-02, 9.3930210e-01],\n",
       "       [5.9154093e-01, 4.0836304e-01, 9.6032580e-05],\n",
       "       [3.0988177e-02, 9.5964950e-01, 9.3623360e-03],\n",
       "       [1.5247265e-01, 8.4699300e-01, 5.3432345e-04],\n",
       "       [2.7774759e-03, 5.7920440e-02, 9.3930210e-01],\n",
       "       [8.3099530e-01, 1.6897143e-01, 3.3174143e-05],\n",
       "       [1.2761022e-02, 9.8723870e-01, 1.9593487e-07],\n",
       "       [2.7084640e-02, 1.0905208e-01, 8.6386320e-01],\n",
       "       [2.7774759e-03, 5.7920440e-02, 9.3930210e-01],\n",
       "       [2.7084640e-02, 1.0905208e-01, 8.6386320e-01],\n",
       "       [7.4803240e-01, 2.5061485e-01, 1.3527069e-03],\n",
       "       [2.7774759e-03, 5.7920440e-02, 9.3930210e-01],\n",
       "       [2.7774759e-03, 5.7920440e-02, 9.3930210e-01],\n",
       "       [2.7774759e-03, 5.7920440e-02, 9.3930210e-01],\n",
       "       [1.3784921e-03, 9.7420245e-01, 2.4419025e-02],\n",
       "       [1.5247265e-01, 8.4699300e-01, 5.3432345e-04],\n",
       "       [3.0826753e-01, 6.9172376e-01, 8.7076450e-06],\n",
       "       [7.9274064e-01, 2.0485236e-01, 2.4069923e-03],\n",
       "       [6.8332140e-03, 2.0272063e-02, 9.7289480e-01],\n",
       "       [8.5669860e-01, 1.4225377e-01, 1.0476873e-03],\n",
       "       [1.5247265e-01, 8.4699300e-01, 5.3432345e-04],\n",
       "       [8.4454244e-01, 1.5507548e-01, 3.8206840e-04],\n",
       "       [7.9274064e-01, 2.0485236e-01, 2.4069923e-03],\n",
       "       [6.8332140e-03, 2.0272063e-02, 9.7289480e-01],\n",
       "       [6.8332140e-03, 2.0272063e-02, 9.7289480e-01],\n",
       "       [2.7084640e-02, 1.0905208e-01, 8.6386320e-01],\n",
       "       [8.3099530e-01, 1.6897143e-01, 3.3174143e-05],\n",
       "       [8.3099530e-01, 1.6897143e-01, 3.3174143e-05],\n",
       "       [7.9274064e-01, 2.0485236e-01, 2.4069923e-03],\n",
       "       [2.7774759e-03, 5.7920440e-02, 9.3930210e-01],\n",
       "       [6.3467050e-02, 7.4327767e-01, 1.9325529e-01],\n",
       "       [2.7774759e-03, 5.7920440e-02, 9.3930210e-01],\n",
       "       [5.3984860e-01, 4.5987812e-01, 2.7328558e-04],\n",
       "       [7.4803240e-01, 2.5061485e-01, 1.3527069e-03],\n",
       "       [7.9274064e-01, 2.0485236e-01, 2.4069923e-03],\n",
       "       [2.0637909e-01, 7.9361220e-01, 8.7242190e-06],\n",
       "       [2.7774759e-03, 5.7920440e-02, 9.3930210e-01],\n",
       "       [2.7774759e-03, 5.7920440e-02, 9.3930210e-01],\n",
       "       [7.3658603e-01, 2.6339835e-01, 1.5540843e-05],\n",
       "       [8.3099530e-01, 1.6897143e-01, 3.3174143e-05],\n",
       "       [6.8332140e-03, 2.0272063e-02, 9.7289480e-01],\n",
       "       [5.9154093e-01, 4.0836304e-01, 9.6032580e-05],\n",
       "       [7.9274064e-01, 2.0485236e-01, 2.4069923e-03],\n",
       "       [7.4803240e-01, 2.5061485e-01, 1.3527069e-03],\n",
       "       [7.9274064e-01, 2.0485236e-01, 2.4069923e-03],\n",
       "       [8.3099530e-01, 1.6897143e-01, 3.3174143e-05],\n",
       "       [2.0637909e-01, 7.9361220e-01, 8.7242190e-06],\n",
       "       [2.7084640e-02, 1.0905208e-01, 8.6386320e-01],\n",
       "       [2.7774759e-03, 5.7920440e-02, 9.3930210e-01],\n",
       "       [2.7774759e-03, 5.7920440e-02, 9.3930210e-01],\n",
       "       [2.7084640e-02, 1.0905208e-01, 8.6386320e-01],\n",
       "       [1.3784921e-03, 9.7420245e-01, 2.4419025e-02],\n",
       "       [3.0826753e-01, 6.9172376e-01, 8.7076450e-06],\n",
       "       [2.0637909e-01, 7.9361220e-01, 8.7242190e-06],\n",
       "       [6.8332140e-03, 2.0272063e-02, 9.7289480e-01],\n",
       "       [2.7774759e-03, 5.7920440e-02, 9.3930210e-01],\n",
       "       [8.3099530e-01, 1.6897143e-01, 3.3174143e-05],\n",
       "       [7.9274064e-01, 2.0485236e-01, 2.4069923e-03],\n",
       "       [2.7084640e-02, 1.0905208e-01, 8.6386320e-01],\n",
       "       [3.0826753e-01, 6.9172376e-01, 8.7076450e-06],\n",
       "       [8.5669860e-01, 1.4225377e-01, 1.0476873e-03],\n",
       "       [7.9274064e-01, 2.0485236e-01, 2.4069923e-03],\n",
       "       [2.7774759e-03, 5.7920440e-02, 9.3930210e-01],\n",
       "       [8.3099530e-01, 1.6897143e-01, 3.3174143e-05],\n",
       "       [3.0988177e-02, 9.5964950e-01, 9.3623360e-03],\n",
       "       [1.5247265e-01, 8.4699300e-01, 5.3432345e-04],\n",
       "       [7.9274064e-01, 2.0485236e-01, 2.4069923e-03],\n",
       "       [1.5247265e-01, 8.4699300e-01, 5.3432345e-04],\n",
       "       [7.3658603e-01, 2.6339835e-01, 1.5540843e-05],\n",
       "       [8.3099530e-01, 1.6897143e-01, 3.3174143e-05],\n",
       "       [8.3099530e-01, 1.6897143e-01, 3.3174143e-05],\n",
       "       [5.9154093e-01, 4.0836304e-01, 9.6032580e-05],\n",
       "       [8.3099530e-01, 1.6897143e-01, 3.3174143e-05],\n",
       "       [8.3099530e-01, 1.6897143e-01, 3.3174143e-05],\n",
       "       [2.7774759e-03, 5.7920440e-02, 9.3930210e-01],\n",
       "       [2.0637909e-01, 7.9361220e-01, 8.7242190e-06],\n",
       "       [7.2012990e-02, 9.2530360e-01, 2.6833606e-03],\n",
       "       [1.5247265e-01, 8.4699300e-01, 5.3432345e-04],\n",
       "       [8.3099530e-01, 1.6897143e-01, 3.3174143e-05],\n",
       "       [2.7774759e-03, 5.7920440e-02, 9.3930210e-01],\n",
       "       [8.3099530e-01, 1.6897143e-01, 3.3174143e-05],\n",
       "       [7.9274064e-01, 2.0485236e-01, 2.4069923e-03],\n",
       "       [8.3099530e-01, 1.6897143e-01, 3.3174143e-05],\n",
       "       [2.0637909e-01, 7.9361220e-01, 8.7242190e-06],\n",
       "       [2.7774759e-03, 5.7920440e-02, 9.3930210e-01],\n",
       "       [8.3099530e-01, 1.6897143e-01, 3.3174143e-05],\n",
       "       [2.7774759e-03, 5.7920440e-02, 9.3930210e-01],\n",
       "       [2.7084640e-02, 1.0905208e-01, 8.6386320e-01],\n",
       "       [1.5247265e-01, 8.4699300e-01, 5.3432345e-04],\n",
       "       [2.0637909e-01, 7.9361220e-01, 8.7242190e-06],\n",
       "       [2.7774759e-03, 5.7920440e-02, 9.3930210e-01],\n",
       "       [8.3099530e-01, 1.6897143e-01, 3.3174143e-05],\n",
       "       [2.7774759e-03, 5.7920440e-02, 9.3930210e-01]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob4 = df_proba4[df_proba4['phage']=='pyokpresabs_qual'].iloc[:,-3:]\n",
    "y_prob4 = y_prob4.to_numpy()\n",
    "y_prob4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.947655652235805"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo4 = rocauc_ovo(y_test_over, y_prob4, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.947655652235805"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr4 = rocauc_ovr(y_test_over, y_prob4, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.936197708144273"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovos = [ovo1, ovo2, ovo3, ovo4]\n",
    "np.mean(ovos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.012837240709955034"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(ovos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.936197708144273"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovrs = [ovr1, ovr2, ovr3, ovr4]\n",
    "np.mean(ovrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.012837240709955034"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(ovrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs = [acc_test_over, acc_test_over2, acc_test_over3, acc_test_over4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling test accuracy mean: 85.71%\n"
     ]
    }
   ],
   "source": [
    "mean = np.mean(accs)\n",
    "print('over-sampling test accuracy mean: %.2f%%' % (mean*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling test accuracy standard deviation: 0.018038429694177537\n"
     ]
    }
   ],
   "source": [
    "std = np.std(accs)\n",
    "print('over-sampling test accuracy standard deviation:', std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs_train = [np.mean(hist1_over.history['accuracy']), np.mean(hist1_over2.history['accuracy']), np.mean(hist1_over3.history['accuracy']),\n",
    "             np.mean(hist1_over4.history['accuracy'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy mean: 86.84%\n"
     ]
    }
   ],
   "source": [
    "mean_train = np.mean(accs_train)\n",
    "print('over-sampling train accuracy mean: %.2f%%' % (mean_train*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy standard deviation: 0.008767562\n"
     ]
    }
   ],
   "source": [
    "std_train = np.std(accs_train)\n",
    "print('over-sampling train accuracy standard deviation:', std_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
