{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This file implements neural networks with/without dropout and regularizer for p003ppresabsSTCC_qual with four replicates.\n",
    "## We compute the mean and standarad deviation of training and test accuracies.\n",
    "## We also compute the mean and standard deviation of AUC ROC values for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "import numpy as np\n",
    "seed(100)\n",
    "import tensorflow\n",
    "tensorflow.random.set_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(253, 1093)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/p003ppresabsSTCC_qual.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'Unnamed: 0':'id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      1\n",
       "3      0\n",
       "4      0\n",
       "      ..\n",
       "248    0\n",
       "249    0\n",
       "250    0\n",
       "251    0\n",
       "252    0\n",
       "Name: pheno, Length: 253, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pheno']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>TTTTTTTAGTTTATCCAATGATTGATGTTATAATAATACTAAATTTGTATCTATAAAAAAGTAATGAGCATTTGTGCGCATATGATG</th>\n",
       "      <th>TTTTTTTAGTTTATCCAATGATTGATGTTATAATAATACTAAATTTGTATCTATAAAAAAGTAATGAGCATTTGTGCGCATATGATGA</th>\n",
       "      <th>TTTTTTTAGTTTATCCAATGATTGATGTTATAATAATACTAAATTTGTATCTATAAAAAAGTAATGAGCATTTGTGCGCATATGATGATGTAAAGCGTAA</th>\n",
       "      <th>TTTTTTCTTTTCATAACTGTGTTGGAAATGAATTAAATTAACAGCTCTTTGTGCTTTACGGTGTGTTGC</th>\n",
       "      <th>TTTTTTCAGCATTGTCTACATTACTTAACATTCGTGTTTGTAAGTAATATTGACCGCCAATATTTAGACACTTTATAAGTATGCCATTCATCATTTTTAA</th>\n",
       "      <th>TTTTTTATCTCACCAATTTTGTAATACATCGTTCTCGTCCTCCTTGTCTTCTTCGTCCTCCTCGTTATCTTCTTCGTTTTGTAATTCATAAATTTTGTTT</th>\n",
       "      <th>TTTTTTAGTTTATCCAATGATTGATGTTATAATAATACTAAATTTGTATCTATAAAAAAGTAATGAGCATTTGTGCGCATATGATGATGTAAAGCGTAAA</th>\n",
       "      <th>TTTTTTAGGTACC</th>\n",
       "      <th>TTTTTGCATTCA</th>\n",
       "      <th>...</th>\n",
       "      <th>group_8643</th>\n",
       "      <th>group_8644</th>\n",
       "      <th>group_8645</th>\n",
       "      <th>group_8646</th>\n",
       "      <th>group_8815</th>\n",
       "      <th>group_8892</th>\n",
       "      <th>group_9489</th>\n",
       "      <th>ST</th>\n",
       "      <th>CC</th>\n",
       "      <th>pheno</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>107</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>109</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>120335</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120337</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1093 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  \\\n",
       "0     107   \n",
       "1     109   \n",
       "2     115   \n",
       "3  120335   \n",
       "4  120337   \n",
       "\n",
       "   TTTTTTTAGTTTATCCAATGATTGATGTTATAATAATACTAAATTTGTATCTATAAAAAAGTAATGAGCATTTGTGCGCATATGATG  \\\n",
       "0                                                  1                                         \n",
       "1                                                  1                                         \n",
       "2                                                  1                                         \n",
       "3                                                  1                                         \n",
       "4                                                  1                                         \n",
       "\n",
       "   TTTTTTTAGTTTATCCAATGATTGATGTTATAATAATACTAAATTTGTATCTATAAAAAAGTAATGAGCATTTGTGCGCATATGATGA  \\\n",
       "0                                                  1                                          \n",
       "1                                                  1                                          \n",
       "2                                                  1                                          \n",
       "3                                                  1                                          \n",
       "4                                                  1                                          \n",
       "\n",
       "   TTTTTTTAGTTTATCCAATGATTGATGTTATAATAATACTAAATTTGTATCTATAAAAAAGTAATGAGCATTTGTGCGCATATGATGATGTAAAGCGTAA  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  1                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   TTTTTTCTTTTCATAACTGTGTTGGAAATGAATTAAATTAACAGCTCTTTGTGCTTTACGGTGTGTTGC  \\\n",
       "0                                                  0                       \n",
       "1                                                  0                       \n",
       "2                                                  1                       \n",
       "3                                                  0                       \n",
       "4                                                  0                       \n",
       "\n",
       "   TTTTTTCAGCATTGTCTACATTACTTAACATTCGTGTTTGTAAGTAATATTGACCGCCAATATTTAGACACTTTATAAGTATGCCATTCATCATTTTTAA  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   TTTTTTATCTCACCAATTTTGTAATACATCGTTCTCGTCCTCCTTGTCTTCTTCGTCCTCCTCGTTATCTTCTTCGTTTTGTAATTCATAAATTTTGTTT  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   TTTTTTAGTTTATCCAATGATTGATGTTATAATAATACTAAATTTGTATCTATAAAAAAGTAATGAGCATTTGTGCGCATATGATGATGTAAAGCGTAAA  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  1                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   TTTTTTAGGTACC  TTTTTGCATTCA  ...  group_8643  group_8644  group_8645  \\\n",
       "0              1             1  ...           0           0           0   \n",
       "1              1             1  ...           0           0           0   \n",
       "2              1             1  ...           0           0           0   \n",
       "3              1             1  ...           0           0           0   \n",
       "4              1             1  ...           0           0           0   \n",
       "\n",
       "   group_8646  group_8815  group_8892  group_9489  ST  CC  pheno  \n",
       "0           0           0           0           0   5   5      0  \n",
       "1           0           0           0           0   8   8      0  \n",
       "2           0           0           0           0   5   5      1  \n",
       "3           0           0           0           0   5   5      0  \n",
       "4           0           0           0           0   5   5      0  \n",
       "\n",
       "[5 rows x 1093 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    224\n",
       "1     26\n",
       "2      3\n",
       "Name: pheno, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pheno'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.drop(columns=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(253, 1092)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TTTTTTTAGTTTATCCAATGATTGATGTTATAATAATACTAAATTTGTATCTATAAAAAAGTAATGAGCATTTGTGCGCATATGATG</th>\n",
       "      <th>TTTTTTTAGTTTATCCAATGATTGATGTTATAATAATACTAAATTTGTATCTATAAAAAAGTAATGAGCATTTGTGCGCATATGATGA</th>\n",
       "      <th>TTTTTTTAGTTTATCCAATGATTGATGTTATAATAATACTAAATTTGTATCTATAAAAAAGTAATGAGCATTTGTGCGCATATGATGATGTAAAGCGTAA</th>\n",
       "      <th>TTTTTTCTTTTCATAACTGTGTTGGAAATGAATTAAATTAACAGCTCTTTGTGCTTTACGGTGTGTTGC</th>\n",
       "      <th>TTTTTTCAGCATTGTCTACATTACTTAACATTCGTGTTTGTAAGTAATATTGACCGCCAATATTTAGACACTTTATAAGTATGCCATTCATCATTTTTAA</th>\n",
       "      <th>TTTTTTATCTCACCAATTTTGTAATACATCGTTCTCGTCCTCCTTGTCTTCTTCGTCCTCCTCGTTATCTTCTTCGTTTTGTAATTCATAAATTTTGTTT</th>\n",
       "      <th>TTTTTTAGTTTATCCAATGATTGATGTTATAATAATACTAAATTTGTATCTATAAAAAAGTAATGAGCATTTGTGCGCATATGATGATGTAAAGCGTAAA</th>\n",
       "      <th>TTTTTTAGGTACC</th>\n",
       "      <th>TTTTTGCATTCA</th>\n",
       "      <th>TTTTTGAAAATAATCATTAGCTTGCTCACTATATAATTTGATGAATATATTTCGTGAAAGTGGGTATTTATTTAATGATTATTCTATATATGATAGTATA</th>\n",
       "      <th>...</th>\n",
       "      <th>group_8643</th>\n",
       "      <th>group_8644</th>\n",
       "      <th>group_8645</th>\n",
       "      <th>group_8646</th>\n",
       "      <th>group_8815</th>\n",
       "      <th>group_8892</th>\n",
       "      <th>group_9489</th>\n",
       "      <th>ST</th>\n",
       "      <th>CC</th>\n",
       "      <th>pheno</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1092 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TTTTTTTAGTTTATCCAATGATTGATGTTATAATAATACTAAATTTGTATCTATAAAAAAGTAATGAGCATTTGTGCGCATATGATG  \\\n",
       "0                                                  1                                         \n",
       "1                                                  1                                         \n",
       "2                                                  1                                         \n",
       "3                                                  1                                         \n",
       "4                                                  1                                         \n",
       "\n",
       "   TTTTTTTAGTTTATCCAATGATTGATGTTATAATAATACTAAATTTGTATCTATAAAAAAGTAATGAGCATTTGTGCGCATATGATGA  \\\n",
       "0                                                  1                                          \n",
       "1                                                  1                                          \n",
       "2                                                  1                                          \n",
       "3                                                  1                                          \n",
       "4                                                  1                                          \n",
       "\n",
       "   TTTTTTTAGTTTATCCAATGATTGATGTTATAATAATACTAAATTTGTATCTATAAAAAAGTAATGAGCATTTGTGCGCATATGATGATGTAAAGCGTAA  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  1                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   TTTTTTCTTTTCATAACTGTGTTGGAAATGAATTAAATTAACAGCTCTTTGTGCTTTACGGTGTGTTGC  \\\n",
       "0                                                  0                       \n",
       "1                                                  0                       \n",
       "2                                                  1                       \n",
       "3                                                  0                       \n",
       "4                                                  0                       \n",
       "\n",
       "   TTTTTTCAGCATTGTCTACATTACTTAACATTCGTGTTTGTAAGTAATATTGACCGCCAATATTTAGACACTTTATAAGTATGCCATTCATCATTTTTAA  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   TTTTTTATCTCACCAATTTTGTAATACATCGTTCTCGTCCTCCTTGTCTTCTTCGTCCTCCTCGTTATCTTCTTCGTTTTGTAATTCATAAATTTTGTTT  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   TTTTTTAGTTTATCCAATGATTGATGTTATAATAATACTAAATTTGTATCTATAAAAAAGTAATGAGCATTTGTGCGCATATGATGATGTAAAGCGTAAA  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  1                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   TTTTTTAGGTACC  TTTTTGCATTCA  \\\n",
       "0              1             1   \n",
       "1              1             1   \n",
       "2              1             1   \n",
       "3              1             1   \n",
       "4              1             1   \n",
       "\n",
       "   TTTTTGAAAATAATCATTAGCTTGCTCACTATATAATTTGATGAATATATTTCGTGAAAGTGGGTATTTATTTAATGATTATTCTATATATGATAGTATA  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   ...  group_8643  group_8644  group_8645  group_8646  group_8815  \\\n",
       "0  ...           0           0           0           0           0   \n",
       "1  ...           0           0           0           0           0   \n",
       "2  ...           0           0           0           0           0   \n",
       "3  ...           0           0           0           0           0   \n",
       "4  ...           0           0           0           0           0   \n",
       "\n",
       "   group_8892  group_9489  ST  CC  pheno  \n",
       "0           0           0   5   5      0  \n",
       "1           0           0   8   8      0  \n",
       "2           0           0   5   5      1  \n",
       "3           0           0   5   5      0  \n",
       "4           0           0   5   5      0  \n",
       "\n",
       "[5 rows x 1092 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(253, 1092) (253,)\n"
     ]
    }
   ],
   "source": [
    "X = df.loc[:, df.columns != 'pheno']\n",
    "y = df['pheno']\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.ensemble.bagging module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.ensemble.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.ensemble.forest module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 224), (1, 224), (2, 224)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.utils.testing module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.utils. Anything that cannot be imported from sklearn.utils is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.metrics.classification module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# over-sampling\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "overS = RandomOverSampler(random_state=100)\n",
    "X_over, y_over = overS.fit_resample(X, y)\n",
    "print(sorted(Counter(y_over).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# Fully-Connected Neural Network ################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.regularizers import l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=123,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = pd.DataFrame(X_test_over[:,0])\n",
    "dat['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS265</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GA984</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS119</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS249</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>NRS035</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>NRS387</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>NRS222</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>BCH-SA-11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0  test\n",
       "0       NRS265     1\n",
       "1        GA984     0\n",
       "2       NRS119     0\n",
       "3       NRS249     1\n",
       "4       NRS255     2\n",
       "..         ...   ...\n",
       "197     NRS035     1\n",
       "198     NRS387     1\n",
       "199     NRS222     0\n",
       "200  BCH-SA-11     1\n",
       "201     NRS148     2\n",
       "\n",
       "[202 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### neural network on over-sampling data\n",
    "model1_over = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],)),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 470 samples, validate on 202 samples\n",
      "Epoch 1/100\n",
      "470/470 [==============================] - 0s 336us/step - loss: 6.8981 - accuracy: 0.4234 - val_loss: 2.8814 - val_accuracy: 0.5990\n",
      "Epoch 2/100\n",
      "470/470 [==============================] - 0s 198us/step - loss: 2.0459 - accuracy: 0.6000 - val_loss: 1.1859 - val_accuracy: 0.6238\n",
      "Epoch 3/100\n",
      "470/470 [==============================] - 0s 195us/step - loss: 0.8780 - accuracy: 0.6894 - val_loss: 0.7755 - val_accuracy: 0.7129\n",
      "Epoch 4/100\n",
      "470/470 [==============================] - 0s 204us/step - loss: 0.5573 - accuracy: 0.7702 - val_loss: 0.4714 - val_accuracy: 0.8317\n",
      "Epoch 5/100\n",
      "470/470 [==============================] - 0s 220us/step - loss: 0.4097 - accuracy: 0.8404 - val_loss: 0.4820 - val_accuracy: 0.8317\n",
      "Epoch 6/100\n",
      "470/470 [==============================] - 0s 197us/step - loss: 0.3511 - accuracy: 0.8787 - val_loss: 0.3805 - val_accuracy: 0.8366\n",
      "Epoch 7/100\n",
      "470/470 [==============================] - 0s 189us/step - loss: 0.2910 - accuracy: 0.8957 - val_loss: 0.3393 - val_accuracy: 0.8366\n",
      "Epoch 8/100\n",
      "470/470 [==============================] - 0s 228us/step - loss: 0.2595 - accuracy: 0.9255 - val_loss: 0.2706 - val_accuracy: 0.9010\n",
      "Epoch 9/100\n",
      "470/470 [==============================] - 0s 202us/step - loss: 0.2185 - accuracy: 0.9532 - val_loss: 0.2515 - val_accuracy: 0.8960\n",
      "Epoch 10/100\n",
      "470/470 [==============================] - 0s 146us/step - loss: 0.1964 - accuracy: 0.9553 - val_loss: 0.2651 - val_accuracy: 0.9010\n",
      "Epoch 11/100\n",
      "470/470 [==============================] - 0s 125us/step - loss: 0.1792 - accuracy: 0.9638 - val_loss: 0.2352 - val_accuracy: 0.9307\n",
      "Epoch 12/100\n",
      "470/470 [==============================] - 0s 123us/step - loss: 0.1806 - accuracy: 0.9574 - val_loss: 0.2225 - val_accuracy: 0.9158\n",
      "Epoch 13/100\n",
      "470/470 [==============================] - 0s 138us/step - loss: 0.1823 - accuracy: 0.9596 - val_loss: 0.2042 - val_accuracy: 0.9257\n",
      "Epoch 14/100\n",
      "470/470 [==============================] - 0s 268us/step - loss: 0.1484 - accuracy: 0.9681 - val_loss: 0.2080 - val_accuracy: 0.9307\n",
      "Epoch 15/100\n",
      "470/470 [==============================] - 0s 137us/step - loss: 0.1392 - accuracy: 0.9638 - val_loss: 0.2127 - val_accuracy: 0.9158\n",
      "Epoch 16/100\n",
      "470/470 [==============================] - 0s 215us/step - loss: 0.1303 - accuracy: 0.9702 - val_loss: 0.1859 - val_accuracy: 0.9257\n",
      "Epoch 17/100\n",
      "470/470 [==============================] - 0s 160us/step - loss: 0.1185 - accuracy: 0.9745 - val_loss: 0.2067 - val_accuracy: 0.9109\n",
      "Epoch 18/100\n",
      "470/470 [==============================] - 0s 194us/step - loss: 0.1111 - accuracy: 0.9766 - val_loss: 0.1798 - val_accuracy: 0.9257\n",
      "Epoch 19/100\n",
      "470/470 [==============================] - 0s 256us/step - loss: 0.1049 - accuracy: 0.9723 - val_loss: 0.1693 - val_accuracy: 0.9307\n",
      "Epoch 20/100\n",
      "470/470 [==============================] - 0s 207us/step - loss: 0.0971 - accuracy: 0.9787 - val_loss: 0.1948 - val_accuracy: 0.9257\n",
      "Epoch 21/100\n",
      "470/470 [==============================] - 0s 187us/step - loss: 0.1013 - accuracy: 0.9745 - val_loss: 0.1522 - val_accuracy: 0.9406\n",
      "Epoch 22/100\n",
      "470/470 [==============================] - 0s 149us/step - loss: 0.0873 - accuracy: 0.9745 - val_loss: 0.1822 - val_accuracy: 0.9208\n",
      "Epoch 23/100\n",
      "470/470 [==============================] - 0s 119us/step - loss: 0.0844 - accuracy: 0.9745 - val_loss: 0.2046 - val_accuracy: 0.9356\n",
      "Epoch 24/100\n",
      "470/470 [==============================] - 0s 117us/step - loss: 0.0882 - accuracy: 0.9809 - val_loss: 0.1643 - val_accuracy: 0.9257\n",
      "Epoch 25/100\n",
      "470/470 [==============================] - 0s 145us/step - loss: 0.0887 - accuracy: 0.9766 - val_loss: 0.1927 - val_accuracy: 0.9307\n",
      "Epoch 26/100\n",
      "470/470 [==============================] - 0s 320us/step - loss: 0.0871 - accuracy: 0.9851 - val_loss: 0.1995 - val_accuracy: 0.9208\n",
      "Epoch 27/100\n",
      "470/470 [==============================] - 0s 266us/step - loss: 0.0744 - accuracy: 0.9809 - val_loss: 0.1407 - val_accuracy: 0.9455\n",
      "Epoch 28/100\n",
      "470/470 [==============================] - 0s 123us/step - loss: 0.0698 - accuracy: 0.9809 - val_loss: 0.1546 - val_accuracy: 0.9356\n",
      "Epoch 29/100\n",
      "470/470 [==============================] - 0s 125us/step - loss: 0.0726 - accuracy: 0.9851 - val_loss: 0.1823 - val_accuracy: 0.9455\n",
      "Epoch 30/100\n",
      "470/470 [==============================] - 0s 266us/step - loss: 0.0682 - accuracy: 0.9851 - val_loss: 0.1588 - val_accuracy: 0.9455\n",
      "Epoch 31/100\n",
      "470/470 [==============================] - 0s 319us/step - loss: 0.0662 - accuracy: 0.9766 - val_loss: 0.1706 - val_accuracy: 0.9455\n",
      "Epoch 32/100\n",
      "470/470 [==============================] - 0s 275us/step - loss: 0.0704 - accuracy: 0.9830 - val_loss: 0.1632 - val_accuracy: 0.9455\n",
      "Epoch 33/100\n",
      "470/470 [==============================] - 0s 466us/step - loss: 0.0573 - accuracy: 0.9851 - val_loss: 0.1439 - val_accuracy: 0.9406\n",
      "Epoch 34/100\n",
      "470/470 [==============================] - 0s 247us/step - loss: 0.0529 - accuracy: 0.9936 - val_loss: 0.1226 - val_accuracy: 0.9653\n",
      "Epoch 35/100\n",
      "470/470 [==============================] - 0s 254us/step - loss: 0.0523 - accuracy: 0.9936 - val_loss: 0.1372 - val_accuracy: 0.9604\n",
      "Epoch 36/100\n",
      "470/470 [==============================] - 0s 146us/step - loss: 0.0504 - accuracy: 0.9872 - val_loss: 0.1633 - val_accuracy: 0.9505\n",
      "Epoch 37/100\n",
      "470/470 [==============================] - 0s 279us/step - loss: 0.0511 - accuracy: 0.9957 - val_loss: 0.1366 - val_accuracy: 0.9406\n",
      "Epoch 38/100\n",
      "470/470 [==============================] - 0s 244us/step - loss: 0.0469 - accuracy: 0.9915 - val_loss: 0.1547 - val_accuracy: 0.9505\n",
      "Epoch 39/100\n",
      "470/470 [==============================] - 0s 196us/step - loss: 0.0466 - accuracy: 0.9979 - val_loss: 0.1302 - val_accuracy: 0.9554\n",
      "Epoch 40/100\n",
      "470/470 [==============================] - 0s 124us/step - loss: 0.0466 - accuracy: 0.9915 - val_loss: 0.1251 - val_accuracy: 0.9604\n",
      "Epoch 41/100\n",
      "470/470 [==============================] - 0s 154us/step - loss: 0.0433 - accuracy: 0.9979 - val_loss: 0.1456 - val_accuracy: 0.9505\n",
      "Epoch 42/100\n",
      "470/470 [==============================] - 0s 333us/step - loss: 0.0421 - accuracy: 0.9936 - val_loss: 0.1549 - val_accuracy: 0.9505\n",
      "Epoch 43/100\n",
      "470/470 [==============================] - 0s 232us/step - loss: 0.0394 - accuracy: 0.9979 - val_loss: 0.1309 - val_accuracy: 0.9554\n",
      "Epoch 44/100\n",
      "470/470 [==============================] - 0s 298us/step - loss: 0.0390 - accuracy: 0.9979 - val_loss: 0.1126 - val_accuracy: 0.9653\n",
      "Epoch 45/100\n",
      "470/470 [==============================] - 0s 253us/step - loss: 0.0374 - accuracy: 0.9979 - val_loss: 0.1551 - val_accuracy: 0.9505\n",
      "Epoch 46/100\n",
      "470/470 [==============================] - 0s 247us/step - loss: 0.0374 - accuracy: 0.9979 - val_loss: 0.1572 - val_accuracy: 0.9505\n",
      "Epoch 47/100\n",
      "470/470 [==============================] - 0s 124us/step - loss: 0.0371 - accuracy: 0.9894 - val_loss: 0.1228 - val_accuracy: 0.9604\n",
      "Epoch 48/100\n",
      "470/470 [==============================] - 0s 191us/step - loss: 0.0357 - accuracy: 0.9979 - val_loss: 0.1288 - val_accuracy: 0.9604\n",
      "Epoch 49/100\n",
      "470/470 [==============================] - 0s 295us/step - loss: 0.0330 - accuracy: 0.9979 - val_loss: 0.1405 - val_accuracy: 0.9505\n",
      "Epoch 50/100\n",
      "470/470 [==============================] - 0s 291us/step - loss: 0.0320 - accuracy: 0.9979 - val_loss: 0.1157 - val_accuracy: 0.9604\n",
      "Epoch 51/100\n",
      "470/470 [==============================] - 0s 273us/step - loss: 0.0338 - accuracy: 0.9936 - val_loss: 0.1343 - val_accuracy: 0.9554\n",
      "Epoch 52/100\n",
      "470/470 [==============================] - 0s 164us/step - loss: 0.0339 - accuracy: 0.9979 - val_loss: 0.1527 - val_accuracy: 0.9505\n",
      "Epoch 53/100\n",
      "470/470 [==============================] - 0s 244us/step - loss: 0.0305 - accuracy: 0.9936 - val_loss: 0.1237 - val_accuracy: 0.9604\n",
      "Epoch 54/100\n",
      "470/470 [==============================] - 0s 122us/step - loss: 0.0289 - accuracy: 0.9979 - val_loss: 0.1640 - val_accuracy: 0.9505\n",
      "Epoch 55/100\n",
      "470/470 [==============================] - 0s 117us/step - loss: 0.0315 - accuracy: 0.9979 - val_loss: 0.1660 - val_accuracy: 0.9505\n",
      "Epoch 56/100\n",
      "470/470 [==============================] - 0s 151us/step - loss: 0.0283 - accuracy: 0.9979 - val_loss: 0.1080 - val_accuracy: 0.9653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "470/470 [==============================] - 0s 183us/step - loss: 0.0292 - accuracy: 0.9936 - val_loss: 0.1542 - val_accuracy: 0.9505\n",
      "Epoch 58/100\n",
      "470/470 [==============================] - 0s 174us/step - loss: 0.0269 - accuracy: 0.9979 - val_loss: 0.1313 - val_accuracy: 0.9604\n",
      "Epoch 59/100\n",
      "470/470 [==============================] - 0s 178us/step - loss: 0.0237 - accuracy: 0.9979 - val_loss: 0.1762 - val_accuracy: 0.9505\n",
      "Epoch 60/100\n",
      "470/470 [==============================] - 0s 198us/step - loss: 0.0244 - accuracy: 0.9979 - val_loss: 0.1168 - val_accuracy: 0.9604\n",
      "Epoch 61/100\n",
      "470/470 [==============================] - 0s 172us/step - loss: 0.0301 - accuracy: 0.9979 - val_loss: 0.1461 - val_accuracy: 0.9554\n",
      "Epoch 62/100\n",
      "470/470 [==============================] - 0s 146us/step - loss: 0.0463 - accuracy: 0.9851 - val_loss: 0.0896 - val_accuracy: 0.9752\n",
      "Epoch 63/100\n",
      "470/470 [==============================] - 0s 166us/step - loss: 0.0330 - accuracy: 0.9979 - val_loss: 0.1272 - val_accuracy: 0.9604\n",
      "Epoch 64/100\n",
      "470/470 [==============================] - 0s 166us/step - loss: 0.0204 - accuracy: 0.9979 - val_loss: 0.1378 - val_accuracy: 0.9604\n",
      "Epoch 65/100\n",
      "470/470 [==============================] - 0s 117us/step - loss: 0.0207 - accuracy: 0.9979 - val_loss: 0.1277 - val_accuracy: 0.9604\n",
      "Epoch 66/100\n",
      "470/470 [==============================] - 0s 116us/step - loss: 0.0198 - accuracy: 0.9979 - val_loss: 0.1178 - val_accuracy: 0.9653\n",
      "Epoch 67/100\n",
      "470/470 [==============================] - 0s 118us/step - loss: 0.0195 - accuracy: 0.9979 - val_loss: 0.1340 - val_accuracy: 0.9604\n",
      "Epoch 68/100\n",
      "470/470 [==============================] - 0s 124us/step - loss: 0.0197 - accuracy: 1.0000 - val_loss: 0.1785 - val_accuracy: 0.9505\n",
      "Epoch 69/100\n",
      "470/470 [==============================] - 0s 124us/step - loss: 0.0206 - accuracy: 0.9979 - val_loss: 0.1561 - val_accuracy: 0.9554\n",
      "Epoch 70/100\n",
      "470/470 [==============================] - 0s 116us/step - loss: 0.0184 - accuracy: 0.9979 - val_loss: 0.1038 - val_accuracy: 0.9653\n",
      "Epoch 71/100\n",
      "470/470 [==============================] - 0s 121us/step - loss: 0.0198 - accuracy: 0.9979 - val_loss: 0.1396 - val_accuracy: 0.9604\n",
      "Epoch 72/100\n",
      "470/470 [==============================] - 0s 286us/step - loss: 0.0205 - accuracy: 0.9957 - val_loss: 0.1185 - val_accuracy: 0.9653\n",
      "Epoch 73/100\n",
      "470/470 [==============================] - 0s 262us/step - loss: 0.0183 - accuracy: 0.9979 - val_loss: 0.1452 - val_accuracy: 0.9554\n",
      "Epoch 74/100\n",
      "470/470 [==============================] - 0s 233us/step - loss: 0.0165 - accuracy: 0.9979 - val_loss: 0.1666 - val_accuracy: 0.9505\n",
      "Epoch 75/100\n",
      "470/470 [==============================] - 0s 305us/step - loss: 0.0187 - accuracy: 0.9979 - val_loss: 0.1466 - val_accuracy: 0.9604\n",
      "Epoch 76/100\n",
      "470/470 [==============================] - 0s 335us/step - loss: 0.0149 - accuracy: 0.9979 - val_loss: 0.1491 - val_accuracy: 0.9554\n",
      "Epoch 77/100\n",
      "470/470 [==============================] - 0s 530us/step - loss: 0.0155 - accuracy: 0.9979 - val_loss: 0.1564 - val_accuracy: 0.9505\n",
      "Epoch 78/100\n",
      "470/470 [==============================] - 0s 302us/step - loss: 0.0147 - accuracy: 0.9979 - val_loss: 0.1394 - val_accuracy: 0.9604\n",
      "Epoch 79/100\n",
      "470/470 [==============================] - 0s 271us/step - loss: 0.0133 - accuracy: 0.9979 - val_loss: 0.1510 - val_accuracy: 0.9554\n",
      "Epoch 80/100\n",
      "470/470 [==============================] - 0s 245us/step - loss: 0.0141 - accuracy: 0.9979 - val_loss: 0.1126 - val_accuracy: 0.9653\n",
      "Epoch 81/100\n",
      "470/470 [==============================] - 0s 205us/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 0.1692 - val_accuracy: 0.9505\n",
      "Epoch 82/100\n",
      "470/470 [==============================] - 0s 198us/step - loss: 0.0136 - accuracy: 0.9979 - val_loss: 0.1160 - val_accuracy: 0.9653\n",
      "Epoch 83/100\n",
      "470/470 [==============================] - 0s 150us/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.1661 - val_accuracy: 0.9554\n",
      "Epoch 84/100\n",
      "470/470 [==============================] - 0s 176us/step - loss: 0.0133 - accuracy: 0.9979 - val_loss: 0.1166 - val_accuracy: 0.9653\n",
      "Epoch 85/100\n",
      "470/470 [==============================] - 0s 176us/step - loss: 0.0134 - accuracy: 0.9979 - val_loss: 0.1292 - val_accuracy: 0.9604\n",
      "Epoch 86/100\n",
      "470/470 [==============================] - 0s 154us/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.1547 - val_accuracy: 0.9554\n",
      "Epoch 87/100\n",
      "470/470 [==============================] - 0s 148us/step - loss: 0.0124 - accuracy: 0.9979 - val_loss: 0.1227 - val_accuracy: 0.9653\n",
      "Epoch 88/100\n",
      "470/470 [==============================] - 0s 135us/step - loss: 0.0120 - accuracy: 0.9979 - val_loss: 0.1269 - val_accuracy: 0.9604\n",
      "Epoch 89/100\n",
      "470/470 [==============================] - 0s 124us/step - loss: 0.0112 - accuracy: 0.9979 - val_loss: 0.1189 - val_accuracy: 0.9653\n",
      "Epoch 90/100\n",
      "470/470 [==============================] - 0s 303us/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.1579 - val_accuracy: 0.9604\n",
      "Epoch 91/100\n",
      "470/470 [==============================] - 0s 264us/step - loss: 0.0105 - accuracy: 0.9979 - val_loss: 0.1387 - val_accuracy: 0.9604\n",
      "Epoch 92/100\n",
      "470/470 [==============================] - 0s 246us/step - loss: 0.0101 - accuracy: 0.9979 - val_loss: 0.1304 - val_accuracy: 0.9604\n",
      "Epoch 93/100\n",
      "470/470 [==============================] - 0s 263us/step - loss: 0.0106 - accuracy: 0.9979 - val_loss: 0.1164 - val_accuracy: 0.9653\n",
      "Epoch 94/100\n",
      "470/470 [==============================] - 0s 381us/step - loss: 0.0104 - accuracy: 0.9979 - val_loss: 0.1568 - val_accuracy: 0.9604\n",
      "Epoch 95/100\n",
      "470/470 [==============================] - 0s 316us/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.1630 - val_accuracy: 0.9554\n",
      "Epoch 96/100\n",
      "470/470 [==============================] - 0s 761us/step - loss: 0.0112 - accuracy: 0.9979 - val_loss: 0.1104 - val_accuracy: 0.9653\n",
      "Epoch 97/100\n",
      "470/470 [==============================] - 0s 375us/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.1807 - val_accuracy: 0.9505\n",
      "Epoch 98/100\n",
      "470/470 [==============================] - 0s 483us/step - loss: 0.0099 - accuracy: 0.9979 - val_loss: 0.1406 - val_accuracy: 0.9604\n",
      "Epoch 99/100\n",
      "470/470 [==============================] - 0s 820us/step - loss: 0.0087 - accuracy: 0.9979 - val_loss: 0.1405 - val_accuracy: 0.9604\n",
      "Epoch 100/100\n",
      "470/470 [==============================] - 0s 332us/step - loss: 0.0091 - accuracy: 0.9979 - val_loss: 0.1185 - val_accuracy: 0.9653\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a3c31b358>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202/202 [==============================] - 0s 94us/step\n",
      "over-sampling test accuracy: 96.53%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over = model1_over.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 2, 1, 1, 1, 2, 0, 1, 0, 1, 0, 1, 2, 0, 0, 2, 2, 2, 0,\n",
       "       0, 0, 1, 1, 1, 2, 2, 1, 2, 2, 0, 2, 0, 0, 0, 2, 1, 0, 2, 1, 2, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 1, 1, 0,\n",
       "       0, 2, 1, 2, 1, 2, 1, 2, 0, 2, 1, 0, 2, 2, 0, 2, 1, 2, 2, 1, 1, 0,\n",
       "       2, 1, 2, 2, 0, 0, 2, 2, 1, 1, 0, 0, 1, 2, 0, 0, 2, 1, 2, 2, 1, 1,\n",
       "       1, 1, 2, 0, 2, 0, 0, 0, 2, 0, 0, 1, 1, 2, 0, 0, 0, 1, 0, 1, 0, 1,\n",
       "       1, 2, 2, 1, 1, 2, 0, 0, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 2, 1, 0, 2,\n",
       "       1, 0, 2, 1, 0, 0, 2, 0, 2, 0, 2, 0, 2, 1, 2, 1, 1, 2, 1, 1, 2, 0,\n",
       "       1, 2, 2, 1, 0, 2, 2, 2, 1, 1, 1, 2, 1, 0, 1, 1, 2, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 2])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model1_over.predict_classes(X_test_over)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS265</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GA984</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS119</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS249</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>NRS035</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>NRS387</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>NRS222</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>BCH-SA-11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0  test  pred\n",
       "0       NRS265     1     1\n",
       "1        GA984     0     0\n",
       "2       NRS119     0     0\n",
       "3       NRS249     1     1\n",
       "4       NRS255     2     2\n",
       "..         ...   ...   ...\n",
       "197     NRS035     1     1\n",
       "198     NRS387     1     1\n",
       "199     NRS222     0     0\n",
       "200  BCH-SA-11     1     1\n",
       "201     NRS148     2     2\n",
       "\n",
       "[202 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat['pred'] = pred\n",
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba1 = model1_over.predict_proba(X_test_over)\n",
    "dat_proba1 = pd.DataFrame(proba1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.007024</td>\n",
       "      <td>0.991650</td>\n",
       "      <td>1.325420e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.999941</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>4.880754e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.996793</td>\n",
       "      <td>0.003207</td>\n",
       "      <td>1.617158e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003590</td>\n",
       "      <td>0.996410</td>\n",
       "      <td>1.313869e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000304</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>9.990209e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.004205</td>\n",
       "      <td>0.993926</td>\n",
       "      <td>1.868723e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.007822</td>\n",
       "      <td>0.992174</td>\n",
       "      <td>4.554854e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0.999939</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>1.616807e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0.007896</td>\n",
       "      <td>0.992104</td>\n",
       "      <td>6.915510e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.012029</td>\n",
       "      <td>9.879574e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1             2\n",
       "0    0.007024  0.991650  1.325420e-03\n",
       "1    0.999941  0.000059  4.880754e-09\n",
       "2    0.996793  0.003207  1.617158e-08\n",
       "3    0.003590  0.996410  1.313869e-08\n",
       "4    0.000304  0.000675  9.990209e-01\n",
       "..        ...       ...           ...\n",
       "197  0.004205  0.993926  1.868723e-03\n",
       "198  0.007822  0.992174  4.554854e-06\n",
       "199  0.999939  0.000061  1.616807e-09\n",
       "200  0.007896  0.992104  6.915510e-12\n",
       "201  0.000013  0.012029  9.879574e-01\n",
       "\n",
       "[202 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba1.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba1.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/1p003ppST.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 470 samples, validate on 202 samples\n",
      "Epoch 1/100\n",
      "470/470 [==============================] - 0s 178us/step - loss: 4.7440e-04 - accuracy: 1.0000 - val_loss: 0.1769 - val_accuracy: 0.9653\n",
      "Epoch 2/100\n",
      "470/470 [==============================] - 0s 132us/step - loss: 4.8139e-04 - accuracy: 1.0000 - val_loss: 0.1814 - val_accuracy: 0.9653\n",
      "Epoch 3/100\n",
      "470/470 [==============================] - 0s 118us/step - loss: 4.5614e-04 - accuracy: 1.0000 - val_loss: 0.1831 - val_accuracy: 0.9653\n",
      "Epoch 4/100\n",
      "470/470 [==============================] - 0s 117us/step - loss: 4.5420e-04 - accuracy: 1.0000 - val_loss: 0.1869 - val_accuracy: 0.9653\n",
      "Epoch 5/100\n",
      "470/470 [==============================] - 0s 126us/step - loss: 4.4543e-04 - accuracy: 1.0000 - val_loss: 0.1822 - val_accuracy: 0.9653\n",
      "Epoch 6/100\n",
      "470/470 [==============================] - 0s 118us/step - loss: 4.3990e-04 - accuracy: 1.0000 - val_loss: 0.1859 - val_accuracy: 0.9653\n",
      "Epoch 7/100\n",
      "470/470 [==============================] - 0s 116us/step - loss: 4.3805e-04 - accuracy: 1.0000 - val_loss: 0.1816 - val_accuracy: 0.9653\n",
      "Epoch 8/100\n",
      "470/470 [==============================] - 0s 119us/step - loss: 4.3676e-04 - accuracy: 1.0000 - val_loss: 0.1840 - val_accuracy: 0.9653\n",
      "Epoch 9/100\n",
      "470/470 [==============================] - 0s 128us/step - loss: 4.2636e-04 - accuracy: 1.0000 - val_loss: 0.1804 - val_accuracy: 0.9653\n",
      "Epoch 10/100\n",
      "470/470 [==============================] - 0s 116us/step - loss: 4.2264e-04 - accuracy: 1.0000 - val_loss: 0.1891 - val_accuracy: 0.9653\n",
      "Epoch 11/100\n",
      "470/470 [==============================] - 0s 128us/step - loss: 4.4149e-04 - accuracy: 1.0000 - val_loss: 0.1917 - val_accuracy: 0.9653\n",
      "Epoch 12/100\n",
      "470/470 [==============================] - 0s 120us/step - loss: 4.0375e-04 - accuracy: 1.0000 - val_loss: 0.1790 - val_accuracy: 0.9653\n",
      "Epoch 13/100\n",
      "470/470 [==============================] - 0s 116us/step - loss: 4.1316e-04 - accuracy: 1.0000 - val_loss: 0.1827 - val_accuracy: 0.9653\n",
      "Epoch 14/100\n",
      "470/470 [==============================] - 0s 117us/step - loss: 4.0474e-04 - accuracy: 1.0000 - val_loss: 0.1888 - val_accuracy: 0.9653\n",
      "Epoch 15/100\n",
      "470/470 [==============================] - 0s 116us/step - loss: 4.1495e-04 - accuracy: 1.0000 - val_loss: 0.1856 - val_accuracy: 0.9653\n",
      "Epoch 16/100\n",
      "470/470 [==============================] - 0s 120us/step - loss: 3.9866e-04 - accuracy: 1.0000 - val_loss: 0.1799 - val_accuracy: 0.9653\n",
      "Epoch 17/100\n",
      "470/470 [==============================] - 0s 118us/step - loss: 3.9417e-04 - accuracy: 1.0000 - val_loss: 0.1888 - val_accuracy: 0.9653\n",
      "Epoch 18/100\n",
      "470/470 [==============================] - 0s 120us/step - loss: 4.2047e-04 - accuracy: 1.0000 - val_loss: 0.1897 - val_accuracy: 0.9653\n",
      "Epoch 19/100\n",
      "470/470 [==============================] - 0s 116us/step - loss: 3.8621e-04 - accuracy: 1.0000 - val_loss: 0.1711 - val_accuracy: 0.9653\n",
      "Epoch 20/100\n",
      "470/470 [==============================] - 0s 132us/step - loss: 3.9192e-04 - accuracy: 1.0000 - val_loss: 0.1912 - val_accuracy: 0.9653\n",
      "Epoch 21/100\n",
      "470/470 [==============================] - 0s 169us/step - loss: 3.7313e-04 - accuracy: 1.0000 - val_loss: 0.1875 - val_accuracy: 0.9653\n",
      "Epoch 22/100\n",
      "470/470 [==============================] - 0s 181us/step - loss: 3.7060e-04 - accuracy: 1.0000 - val_loss: 0.1845 - val_accuracy: 0.9653\n",
      "Epoch 23/100\n",
      "470/470 [==============================] - 0s 128us/step - loss: 3.6842e-04 - accuracy: 1.0000 - val_loss: 0.1891 - val_accuracy: 0.9653\n",
      "Epoch 24/100\n",
      "470/470 [==============================] - 0s 136us/step - loss: 3.6209e-04 - accuracy: 1.0000 - val_loss: 0.1877 - val_accuracy: 0.9653\n",
      "Epoch 25/100\n",
      "470/470 [==============================] - 0s 120us/step - loss: 3.6133e-04 - accuracy: 1.0000 - val_loss: 0.1846 - val_accuracy: 0.9653\n",
      "Epoch 26/100\n",
      "470/470 [==============================] - 0s 121us/step - loss: 3.6332e-04 - accuracy: 1.0000 - val_loss: 0.1881 - val_accuracy: 0.9653\n",
      "Epoch 27/100\n",
      "470/470 [==============================] - 0s 118us/step - loss: 3.5658e-04 - accuracy: 1.0000 - val_loss: 0.1837 - val_accuracy: 0.9653\n",
      "Epoch 28/100\n",
      "470/470 [==============================] - 0s 120us/step - loss: 3.5372e-04 - accuracy: 1.0000 - val_loss: 0.1869 - val_accuracy: 0.9653\n",
      "Epoch 29/100\n",
      "470/470 [==============================] - 0s 119us/step - loss: 3.4744e-04 - accuracy: 1.0000 - val_loss: 0.1860 - val_accuracy: 0.9653\n",
      "Epoch 30/100\n",
      "470/470 [==============================] - 0s 147us/step - loss: 3.4283e-04 - accuracy: 1.0000 - val_loss: 0.1906 - val_accuracy: 0.9653\n",
      "Epoch 31/100\n",
      "470/470 [==============================] - 0s 143us/step - loss: 3.5396e-04 - accuracy: 1.0000 - val_loss: 0.1881 - val_accuracy: 0.9653\n",
      "Epoch 32/100\n",
      "470/470 [==============================] - 0s 173us/step - loss: 3.4141e-04 - accuracy: 1.0000 - val_loss: 0.1844 - val_accuracy: 0.9653\n",
      "Epoch 33/100\n",
      "470/470 [==============================] - 0s 226us/step - loss: 3.3664e-04 - accuracy: 1.0000 - val_loss: 0.1864 - val_accuracy: 0.9653\n",
      "Epoch 34/100\n",
      "470/470 [==============================] - 0s 196us/step - loss: 3.4068e-04 - accuracy: 1.0000 - val_loss: 0.1903 - val_accuracy: 0.9653\n",
      "Epoch 35/100\n",
      "470/470 [==============================] - 0s 190us/step - loss: 3.3902e-04 - accuracy: 1.0000 - val_loss: 0.1906 - val_accuracy: 0.9653\n",
      "Epoch 36/100\n",
      "470/470 [==============================] - 0s 139us/step - loss: 3.2024e-04 - accuracy: 1.0000 - val_loss: 0.1856 - val_accuracy: 0.9653\n",
      "Epoch 37/100\n",
      "470/470 [==============================] - 0s 126us/step - loss: 3.1903e-04 - accuracy: 1.0000 - val_loss: 0.1888 - val_accuracy: 0.9653\n",
      "Epoch 38/100\n",
      "470/470 [==============================] - 0s 114us/step - loss: 3.1522e-04 - accuracy: 1.0000 - val_loss: 0.1866 - val_accuracy: 0.9653\n",
      "Epoch 39/100\n",
      "470/470 [==============================] - 0s 111us/step - loss: 3.1281e-04 - accuracy: 1.0000 - val_loss: 0.1865 - val_accuracy: 0.9653\n",
      "Epoch 40/100\n",
      "470/470 [==============================] - 0s 115us/step - loss: 3.1198e-04 - accuracy: 1.0000 - val_loss: 0.1910 - val_accuracy: 0.9653\n",
      "Epoch 41/100\n",
      "470/470 [==============================] - 0s 110us/step - loss: 3.0829e-04 - accuracy: 1.0000 - val_loss: 0.1902 - val_accuracy: 0.9653\n",
      "Epoch 42/100\n",
      "470/470 [==============================] - 0s 113us/step - loss: 3.1105e-04 - accuracy: 1.0000 - val_loss: 0.1861 - val_accuracy: 0.9653\n",
      "Epoch 43/100\n",
      "470/470 [==============================] - 0s 112us/step - loss: 3.0639e-04 - accuracy: 1.0000 - val_loss: 0.1915 - val_accuracy: 0.9653\n",
      "Epoch 44/100\n",
      "470/470 [==============================] - 0s 118us/step - loss: 2.9574e-04 - accuracy: 1.0000 - val_loss: 0.1891 - val_accuracy: 0.9653\n",
      "Epoch 45/100\n",
      "470/470 [==============================] - 0s 112us/step - loss: 2.9868e-04 - accuracy: 1.0000 - val_loss: 0.1913 - val_accuracy: 0.9653\n",
      "Epoch 46/100\n",
      "470/470 [==============================] - 0s 113us/step - loss: 2.9445e-04 - accuracy: 1.0000 - val_loss: 0.1883 - val_accuracy: 0.9653\n",
      "Epoch 47/100\n",
      "470/470 [==============================] - 0s 113us/step - loss: 2.9737e-04 - accuracy: 1.0000 - val_loss: 0.1887 - val_accuracy: 0.9653\n",
      "Epoch 48/100\n",
      "470/470 [==============================] - 0s 116us/step - loss: 2.8169e-04 - accuracy: 1.0000 - val_loss: 0.1976 - val_accuracy: 0.9653\n",
      "Epoch 49/100\n",
      "470/470 [==============================] - 0s 112us/step - loss: 2.8742e-04 - accuracy: 1.0000 - val_loss: 0.1869 - val_accuracy: 0.9653\n",
      "Epoch 50/100\n",
      "470/470 [==============================] - 0s 112us/step - loss: 2.8702e-04 - accuracy: 1.0000 - val_loss: 0.1930 - val_accuracy: 0.9653\n",
      "Epoch 51/100\n",
      "470/470 [==============================] - 0s 116us/step - loss: 2.7850e-04 - accuracy: 1.0000 - val_loss: 0.1871 - val_accuracy: 0.9653\n",
      "Epoch 52/100\n",
      "470/470 [==============================] - 0s 111us/step - loss: 2.7269e-04 - accuracy: 1.0000 - val_loss: 0.1976 - val_accuracy: 0.9653\n",
      "Epoch 53/100\n",
      "470/470 [==============================] - 0s 114us/step - loss: 2.7726e-04 - accuracy: 1.0000 - val_loss: 0.1884 - val_accuracy: 0.9653\n",
      "Epoch 54/100\n",
      "470/470 [==============================] - 0s 119us/step - loss: 2.7185e-04 - accuracy: 1.0000 - val_loss: 0.1902 - val_accuracy: 0.9653\n",
      "Epoch 55/100\n",
      "470/470 [==============================] - 0s 121us/step - loss: 2.7643e-04 - accuracy: 1.0000 - val_loss: 0.1913 - val_accuracy: 0.9653\n",
      "Epoch 56/100\n",
      "470/470 [==============================] - 0s 192us/step - loss: 2.6672e-04 - accuracy: 1.0000 - val_loss: 0.1912 - val_accuracy: 0.9653\n",
      "Epoch 57/100\n",
      "470/470 [==============================] - 0s 127us/step - loss: 2.6532e-04 - accuracy: 1.0000 - val_loss: 0.1923 - val_accuracy: 0.9653\n",
      "Epoch 58/100\n",
      "470/470 [==============================] - 0s 135us/step - loss: 2.6203e-04 - accuracy: 1.0000 - val_loss: 0.1931 - val_accuracy: 0.9653\n",
      "Epoch 59/100\n",
      "470/470 [==============================] - 0s 171us/step - loss: 2.6733e-04 - accuracy: 1.0000 - val_loss: 0.1959 - val_accuracy: 0.9653\n",
      "Epoch 60/100\n",
      "470/470 [==============================] - 0s 177us/step - loss: 2.6025e-04 - accuracy: 1.0000 - val_loss: 0.1871 - val_accuracy: 0.9653\n",
      "Epoch 61/100\n",
      "470/470 [==============================] - 0s 153us/step - loss: 2.5179e-04 - accuracy: 1.0000 - val_loss: 0.1927 - val_accuracy: 0.9653\n",
      "Epoch 62/100\n",
      "470/470 [==============================] - 0s 119us/step - loss: 2.5237e-04 - accuracy: 1.0000 - val_loss: 0.1964 - val_accuracy: 0.9653\n",
      "Epoch 63/100\n",
      "470/470 [==============================] - 0s 117us/step - loss: 2.5314e-04 - accuracy: 1.0000 - val_loss: 0.1893 - val_accuracy: 0.9653\n",
      "Epoch 64/100\n",
      "470/470 [==============================] - 0s 114us/step - loss: 2.4273e-04 - accuracy: 1.0000 - val_loss: 0.2002 - val_accuracy: 0.9653\n",
      "Epoch 65/100\n",
      "470/470 [==============================] - 0s 114us/step - loss: 2.4138e-04 - accuracy: 1.0000 - val_loss: 0.1933 - val_accuracy: 0.9653\n",
      "Epoch 66/100\n",
      "470/470 [==============================] - 0s 119us/step - loss: 2.3799e-04 - accuracy: 1.0000 - val_loss: 0.1918 - val_accuracy: 0.9653\n",
      "Epoch 67/100\n",
      "470/470 [==============================] - 0s 144us/step - loss: 2.3871e-04 - accuracy: 1.0000 - val_loss: 0.1929 - val_accuracy: 0.9653\n",
      "Epoch 68/100\n",
      "470/470 [==============================] - 0s 160us/step - loss: 2.3532e-04 - accuracy: 1.0000 - val_loss: 0.1934 - val_accuracy: 0.9653\n",
      "Epoch 69/100\n",
      "470/470 [==============================] - 0s 183us/step - loss: 2.3591e-04 - accuracy: 1.0000 - val_loss: 0.1969 - val_accuracy: 0.9653\n",
      "Epoch 70/100\n",
      "470/470 [==============================] - 0s 154us/step - loss: 2.3147e-04 - accuracy: 1.0000 - val_loss: 0.1906 - val_accuracy: 0.9653\n",
      "Epoch 71/100\n",
      "470/470 [==============================] - 0s 182us/step - loss: 2.2716e-04 - accuracy: 1.0000 - val_loss: 0.1942 - val_accuracy: 0.9653\n",
      "Epoch 72/100\n",
      "470/470 [==============================] - 0s 173us/step - loss: 2.2948e-04 - accuracy: 1.0000 - val_loss: 0.1937 - val_accuracy: 0.9653\n",
      "Epoch 73/100\n",
      "470/470 [==============================] - 0s 135us/step - loss: 2.3053e-04 - accuracy: 1.0000 - val_loss: 0.1947 - val_accuracy: 0.9653\n",
      "Epoch 74/100\n",
      "470/470 [==============================] - 0s 119us/step - loss: 2.2590e-04 - accuracy: 1.0000 - val_loss: 0.1948 - val_accuracy: 0.9653\n",
      "Epoch 75/100\n",
      "470/470 [==============================] - 0s 116us/step - loss: 2.1814e-04 - accuracy: 1.0000 - val_loss: 0.1941 - val_accuracy: 0.9653\n",
      "Epoch 76/100\n",
      "470/470 [==============================] - 0s 120us/step - loss: 2.1729e-04 - accuracy: 1.0000 - val_loss: 0.1963 - val_accuracy: 0.9653\n",
      "Epoch 77/100\n",
      "470/470 [==============================] - 0s 123us/step - loss: 2.1463e-04 - accuracy: 1.0000 - val_loss: 0.1952 - val_accuracy: 0.9653\n",
      "Epoch 78/100\n",
      "470/470 [==============================] - 0s 154us/step - loss: 2.1503e-04 - accuracy: 1.0000 - val_loss: 0.1928 - val_accuracy: 0.9653\n",
      "Epoch 79/100\n",
      "470/470 [==============================] - 0s 191us/step - loss: 2.1843e-04 - accuracy: 1.0000 - val_loss: 0.1956 - val_accuracy: 0.9653\n",
      "Epoch 80/100\n",
      "470/470 [==============================] - 0s 124us/step - loss: 2.1300e-04 - accuracy: 1.0000 - val_loss: 0.1998 - val_accuracy: 0.9653\n",
      "Epoch 81/100\n",
      "470/470 [==============================] - 0s 113us/step - loss: 2.0748e-04 - accuracy: 1.0000 - val_loss: 0.1943 - val_accuracy: 0.9653\n",
      "Epoch 82/100\n",
      "470/470 [==============================] - 0s 118us/step - loss: 2.0639e-04 - accuracy: 1.0000 - val_loss: 0.2002 - val_accuracy: 0.9653\n",
      "Epoch 83/100\n",
      "470/470 [==============================] - 0s 132us/step - loss: 2.1061e-04 - accuracy: 1.0000 - val_loss: 0.1956 - val_accuracy: 0.9653\n",
      "Epoch 84/100\n",
      "470/470 [==============================] - 0s 119us/step - loss: 2.1059e-04 - accuracy: 1.0000 - val_loss: 0.1947 - val_accuracy: 0.9653\n",
      "Epoch 85/100\n",
      "470/470 [==============================] - 0s 134us/step - loss: 2.0780e-04 - accuracy: 1.0000 - val_loss: 0.2029 - val_accuracy: 0.9653\n",
      "Epoch 86/100\n",
      "470/470 [==============================] - 0s 389us/step - loss: 1.9670e-04 - accuracy: 1.0000 - val_loss: 0.1944 - val_accuracy: 0.9653\n",
      "Epoch 87/100\n",
      "470/470 [==============================] - 0s 412us/step - loss: 1.9747e-04 - accuracy: 1.0000 - val_loss: 0.1964 - val_accuracy: 0.9653\n",
      "Epoch 88/100\n",
      "470/470 [==============================] - 0s 403us/step - loss: 1.9819e-04 - accuracy: 1.0000 - val_loss: 0.1977 - val_accuracy: 0.9653\n",
      "Epoch 89/100\n",
      "470/470 [==============================] - 0s 241us/step - loss: 1.9279e-04 - accuracy: 1.0000 - val_loss: 0.1916 - val_accuracy: 0.9653\n",
      "Epoch 90/100\n",
      "470/470 [==============================] - 0s 165us/step - loss: 1.8823e-04 - accuracy: 1.0000 - val_loss: 0.2026 - val_accuracy: 0.9653\n",
      "Epoch 91/100\n",
      "470/470 [==============================] - 0s 148us/step - loss: 1.9197e-04 - accuracy: 1.0000 - val_loss: 0.1978 - val_accuracy: 0.9653\n",
      "Epoch 92/100\n",
      "470/470 [==============================] - 0s 124us/step - loss: 1.8880e-04 - accuracy: 1.0000 - val_loss: 0.1942 - val_accuracy: 0.9653\n",
      "Epoch 93/100\n",
      "470/470 [==============================] - 0s 119us/step - loss: 1.8429e-04 - accuracy: 1.0000 - val_loss: 0.1977 - val_accuracy: 0.9653\n",
      "Epoch 94/100\n",
      "470/470 [==============================] - 0s 116us/step - loss: 1.8907e-04 - accuracy: 1.0000 - val_loss: 0.1997 - val_accuracy: 0.9653\n",
      "Epoch 95/100\n",
      "470/470 [==============================] - 0s 116us/step - loss: 1.8031e-04 - accuracy: 1.0000 - val_loss: 0.1926 - val_accuracy: 0.9653\n",
      "Epoch 96/100\n",
      "470/470 [==============================] - 0s 204us/step - loss: 1.8067e-04 - accuracy: 1.0000 - val_loss: 0.1997 - val_accuracy: 0.9653\n",
      "Epoch 97/100\n",
      "470/470 [==============================] - 0s 211us/step - loss: 1.7712e-04 - accuracy: 1.0000 - val_loss: 0.2021 - val_accuracy: 0.9653\n",
      "Epoch 98/100\n",
      "470/470 [==============================] - 0s 224us/step - loss: 1.7751e-04 - accuracy: 1.0000 - val_loss: 0.1982 - val_accuracy: 0.9653\n",
      "Epoch 99/100\n",
      "470/470 [==============================] - 0s 199us/step - loss: 1.7518e-04 - accuracy: 1.0000 - val_loss: 0.2012 - val_accuracy: 0.9653\n",
      "Epoch 100/100\n",
      "470/470 [==============================] - 0s 139us/step - loss: 1.7629e-04 - accuracy: 1.0000 - val_loss: 0.1942 - val_accuracy: 0.9653\n"
     ]
    }
   ],
   "source": [
    "hist1_over = model1_over.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_2.xlsx\",\n",
    "                        sheet_name=0,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>CFBRSa26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.758914</td>\n",
       "      <td>0.241086</td>\n",
       "      <td>4.638713e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.005361</td>\n",
       "      <td>0.016236</td>\n",
       "      <td>9.784034e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS112</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.726623</td>\n",
       "      <td>0.273376</td>\n",
       "      <td>1.520979e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS216</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.138322</td>\n",
       "      <td>0.861665</td>\n",
       "      <td>1.334123e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS021</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.882176</td>\n",
       "      <td>0.117824</td>\n",
       "      <td>1.414530e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4279</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>9.998934e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4280</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.002048</td>\n",
       "      <td>9.976944e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4281</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS205</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>9.999435e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4282</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.002048</td>\n",
       "      <td>9.976944e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4283</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.000929</td>\n",
       "      <td>9.989737e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4284 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    phage    strain  phenotype  prediction         0  \\\n",
       "0      p002ykpresabs_qual  CFBRSa26          0           0  0.758914   \n",
       "1      p002ykpresabs_qual    NRS109          2           2  0.005361   \n",
       "2      p002ykpresabs_qual    NRS112          0           0  0.726623   \n",
       "3      p002ykpresabs_qual    NRS216          1           1  0.138322   \n",
       "4      p002ykpresabs_qual    NRS021          0           0  0.882176   \n",
       "...                   ...       ...        ...         ...       ...   \n",
       "4279  pyopresabsSTCC_qual    NRS148          2           2  0.000007   \n",
       "4280  pyopresabsSTCC_qual    NRS255          2           2  0.000257   \n",
       "4281  pyopresabsSTCC_qual    NRS205          2           2  0.000011   \n",
       "4282  pyopresabsSTCC_qual    NRS255          2           2  0.000257   \n",
       "4283  pyopresabsSTCC_qual    NRS109          2           2  0.000097   \n",
       "\n",
       "             1             2  \n",
       "0     0.241086  4.638713e-07  \n",
       "1     0.016236  9.784034e-01  \n",
       "2     0.273376  1.520979e-06  \n",
       "3     0.861665  1.334123e-05  \n",
       "4     0.117824  1.414530e-10  \n",
       "...        ...           ...  \n",
       "4279  0.000099  9.998934e-01  \n",
       "4280  0.002048  9.976944e-01  \n",
       "4281  0.000045  9.999435e-01  \n",
       "4282  0.002048  9.976944e-01  \n",
       "4283  0.000929  9.989737e-01  \n",
       "\n",
       "[4284 rows x 7 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.02440600e-03, 9.91650200e-01, 1.32541950e-03],\n",
       "       [9.99941000e-01, 5.89633860e-05, 4.88075400e-09],\n",
       "       [9.96793100e-01, 3.20686240e-03, 1.61715850e-08],\n",
       "       [3.59037000e-03, 9.96409600e-01, 1.31386875e-08],\n",
       "       [3.03660320e-04, 6.75374300e-04, 9.99020930e-01],\n",
       "       [4.17271400e-03, 9.95708000e-01, 1.19338260e-04],\n",
       "       [3.57785400e-04, 9.27944800e-01, 7.16974960e-02],\n",
       "       [2.42306000e-02, 9.75754800e-01, 1.44839480e-05],\n",
       "       [3.03660320e-04, 6.75374300e-04, 9.99020930e-01],\n",
       "       [9.99743760e-01, 2.56290220e-04, 4.72695300e-08],\n",
       "       [1.07946340e-02, 9.89205360e-01, 1.70191750e-10],\n",
       "       [9.99692560e-01, 3.07434560e-04, 9.32627400e-11],\n",
       "       [7.82173900e-03, 9.92173700e-01, 4.55485360e-06],\n",
       "       [9.99972700e-01, 2.22440760e-05, 4.96942500e-06],\n",
       "       [3.94075100e-03, 9.91183400e-01, 4.87595200e-03],\n",
       "       [3.03660320e-04, 6.75374300e-04, 9.99020930e-01],\n",
       "       [9.95971000e-01, 4.02895550e-03, 2.87199650e-10],\n",
       "       [9.99805030e-01, 1.94940240e-04, 1.32528930e-08],\n",
       "       [1.31652410e-05, 1.20292960e-02, 9.87957540e-01],\n",
       "       [9.39423200e-07, 2.88389970e-04, 9.99710600e-01],\n",
       "       [9.39423200e-07, 2.88389970e-04, 9.99710600e-01],\n",
       "       [9.95418900e-01, 4.58103200e-03, 6.86808100e-08],\n",
       "       [1.00000000e+00, 5.57399850e-08, 1.52077640e-13],\n",
       "       [1.00000000e+00, 8.58676400e-09, 2.37707330e-14],\n",
       "       [8.14780800e-02, 9.18521300e-01, 6.06125350e-07],\n",
       "       [4.17271400e-03, 9.95708000e-01, 1.19338260e-04],\n",
       "       [1.16881830e-02, 9.87603250e-01, 7.08585800e-04],\n",
       "       [3.03660320e-04, 6.75374300e-04, 9.99020930e-01],\n",
       "       [9.39423200e-07, 2.88389970e-04, 9.99710600e-01],\n",
       "       [4.19845950e-02, 9.58005300e-01, 1.00231660e-05],\n",
       "       [9.39423200e-07, 2.88389970e-04, 9.99710600e-01],\n",
       "       [9.39423200e-07, 2.88389970e-04, 9.99710600e-01],\n",
       "       [9.99989300e-01, 1.06989980e-05, 6.75784640e-19],\n",
       "       [9.39423200e-07, 2.88389970e-04, 9.99710600e-01],\n",
       "       [9.94529400e-01, 5.47060800e-03, 3.53836200e-08],\n",
       "       [9.66575000e-01, 3.34249200e-02, 4.94122740e-09],\n",
       "       [9.99999900e-01, 6.37576700e-08, 4.79228000e-20],\n",
       "       [3.03660320e-04, 6.75374300e-04, 9.99020930e-01],\n",
       "       [7.89582400e-03, 9.92104200e-01, 6.91551000e-12],\n",
       "       [9.99998000e-01, 2.07903850e-06, 1.54382270e-18],\n",
       "       [1.31652410e-05, 1.20292960e-02, 9.87957540e-01],\n",
       "       [4.33242800e-03, 9.95667600e-01, 8.17788550e-12],\n",
       "       [9.39423200e-07, 2.88389970e-04, 9.99710600e-01],\n",
       "       [4.17271400e-03, 9.95708000e-01, 1.19338260e-04],\n",
       "       [2.24622530e-02, 9.77535300e-01, 2.46641000e-06],\n",
       "       [4.16912840e-03, 9.95817240e-01, 1.35942055e-05],\n",
       "       [9.06372270e-04, 9.99092700e-01, 9.73982100e-07],\n",
       "       [1.53378980e-02, 9.84657200e-01, 4.94490270e-06],\n",
       "       [6.60645300e-03, 9.93390300e-01, 3.24972000e-06],\n",
       "       [9.99908900e-01, 9.11149100e-05, 1.90864390e-08],\n",
       "       [9.06372270e-04, 9.99092700e-01, 9.73982100e-07],\n",
       "       [7.89582400e-03, 9.92104200e-01, 6.91551000e-12],\n",
       "       [1.07946340e-02, 9.89205360e-01, 1.70191750e-10],\n",
       "       [1.00000000e+00, 3.93299070e-11, 1.02110615e-13],\n",
       "       [9.99628660e-01, 3.71265750e-04, 2.99365000e-11],\n",
       "       [9.99991200e-01, 8.83918700e-06, 1.02927515e-08],\n",
       "       [9.96198830e-01, 3.80115580e-03, 9.91229000e-09],\n",
       "       [9.99594750e-01, 4.02974020e-04, 2.25628260e-06],\n",
       "       [9.44119900e-01, 5.58773730e-02, 2.67176920e-06],\n",
       "       [7.89582400e-03, 9.92104200e-01, 6.91551000e-12],\n",
       "       [1.31652410e-05, 1.20292960e-02, 9.87957540e-01],\n",
       "       [9.39423200e-07, 2.88389970e-04, 9.99710600e-01],\n",
       "       [9.98722730e-01, 1.27718660e-03, 4.90655300e-16],\n",
       "       [6.60645300e-03, 9.93390300e-01, 3.24972000e-06],\n",
       "       [2.24622530e-02, 9.77535300e-01, 2.46641000e-06],\n",
       "       [1.00000000e+00, 1.10187710e-08, 3.94031560e-09],\n",
       "       [9.39911700e-01, 6.00839500e-02, 4.25507640e-06],\n",
       "       [9.39423200e-07, 2.88389970e-04, 9.99710600e-01],\n",
       "       [5.92800230e-03, 9.94070000e-01, 2.00865660e-06],\n",
       "       [3.03660320e-04, 6.75374300e-04, 9.99020930e-01],\n",
       "       [7.82173900e-03, 9.92173700e-01, 4.55485360e-06],\n",
       "       [3.03660320e-04, 6.75374300e-04, 9.99020930e-01],\n",
       "       [1.02030410e-02, 9.89790140e-01, 6.80115360e-06],\n",
       "       [1.31652410e-05, 1.20292960e-02, 9.87957540e-01],\n",
       "       [9.99787300e-01, 2.12734750e-04, 2.51682230e-08],\n",
       "       [9.39423200e-07, 2.88389970e-04, 9.99710600e-01],\n",
       "       [3.94075100e-03, 9.91183400e-01, 4.87595200e-03],\n",
       "       [6.64990840e-01, 3.35009130e-01, 2.91883810e-08],\n",
       "       [1.31652410e-05, 1.20292960e-02, 9.87957540e-01],\n",
       "       [1.31652410e-05, 1.20292960e-02, 9.87957540e-01],\n",
       "       [9.85320400e-01, 1.46794790e-02, 1.12295270e-07],\n",
       "       [9.39423200e-07, 2.88389970e-04, 9.99710600e-01],\n",
       "       [1.23825800e-05, 9.99034500e-01, 9.53111300e-04],\n",
       "       [9.39423200e-07, 2.88389970e-04, 9.99710600e-01],\n",
       "       [3.03660320e-04, 6.75374300e-04, 9.99020930e-01],\n",
       "       [4.20530930e-03, 9.93926000e-01, 1.86873040e-03],\n",
       "       [7.02440600e-03, 9.91650200e-01, 1.32541950e-03],\n",
       "       [9.99772000e-01, 2.27971790e-04, 4.11960300e-08],\n",
       "       [3.03660320e-04, 6.75374300e-04, 9.99020930e-01],\n",
       "       [3.57785400e-04, 9.27944800e-01, 7.16974960e-02],\n",
       "       [1.31652410e-05, 1.20292960e-02, 9.87957540e-01],\n",
       "       [1.31652410e-05, 1.20292960e-02, 9.87957540e-01],\n",
       "       [9.37224900e-01, 6.23728300e-02, 4.02322850e-04],\n",
       "       [1.00000000e+00, 1.72236860e-09, 2.88948160e-15],\n",
       "       [9.39423200e-07, 2.88389970e-04, 9.99710600e-01],\n",
       "       [9.39423200e-07, 2.88389970e-04, 9.99710600e-01],\n",
       "       [4.33242800e-03, 9.95667600e-01, 8.17788550e-12],\n",
       "       [3.78415370e-04, 9.99454100e-01, 1.67521240e-04],\n",
       "       [9.95977940e-01, 4.02179870e-03, 2.68703400e-07],\n",
       "       [9.94923800e-01, 5.07625240e-03, 3.75955450e-11],\n",
       "       [3.57785400e-04, 9.27944800e-01, 7.16974960e-02],\n",
       "       [3.03660320e-04, 6.75374300e-04, 9.99020930e-01],\n",
       "       [9.98522460e-01, 1.47760040e-03, 4.89540100e-08],\n",
       "       [9.99691100e-01, 3.08840560e-04, 2.73475100e-08],\n",
       "       [3.03660320e-04, 6.75374300e-04, 9.99020930e-01],\n",
       "       [4.27209600e-01, 5.72786030e-01, 4.34538500e-06],\n",
       "       [3.03660320e-04, 6.75374300e-04, 9.99020930e-01],\n",
       "       [1.31652410e-05, 1.20292960e-02, 9.87957540e-01],\n",
       "       [3.78415370e-04, 9.99454100e-01, 1.67521240e-04],\n",
       "       [9.06372270e-04, 9.99092700e-01, 9.73982100e-07],\n",
       "       [2.89757710e-03, 9.97102440e-01, 2.90078240e-08],\n",
       "       [7.37693400e-03, 9.92621540e-01, 1.51950090e-06],\n",
       "       [9.39423200e-07, 2.88389970e-04, 9.99710600e-01],\n",
       "       [9.17366300e-01, 8.16620960e-02, 9.71510100e-04],\n",
       "       [1.31652410e-05, 1.20292960e-02, 9.87957540e-01],\n",
       "       [9.92884930e-01, 7.11505250e-03, 5.50588460e-10],\n",
       "       [9.99743300e-01, 2.00891020e-04, 5.58261900e-05],\n",
       "       [9.85661030e-01, 1.43388890e-02, 6.18200800e-08],\n",
       "       [9.39423200e-07, 2.88389970e-04, 9.99710600e-01],\n",
       "       [9.99107800e-01, 8.92216340e-04, 2.50679780e-08],\n",
       "       [9.99425650e-01, 5.74368340e-04, 2.10223230e-11],\n",
       "       [1.47949040e-02, 9.82046960e-01, 3.15809620e-03],\n",
       "       [7.37693400e-03, 9.92621540e-01, 1.51950090e-06],\n",
       "       [1.31652410e-05, 1.20292960e-02, 9.87957540e-01],\n",
       "       [9.99993700e-01, 6.35128300e-06, 9.43171200e-10],\n",
       "       [1.00000000e+00, 4.87589400e-10, 5.56853340e-13],\n",
       "       [9.99960660e-01, 3.91608500e-05, 1.31694080e-07],\n",
       "       [4.20530930e-03, 9.93926000e-01, 1.86873040e-03],\n",
       "       [9.99368250e-01, 6.31681900e-04, 8.24985950e-08],\n",
       "       [4.17271400e-03, 9.95708000e-01, 1.19338260e-04],\n",
       "       [9.99620440e-01, 3.79522210e-04, 7.64801300e-09],\n",
       "       [7.02440600e-03, 9.91650200e-01, 1.32541950e-03],\n",
       "       [3.59037000e-03, 9.96409600e-01, 1.31386875e-08],\n",
       "       [1.31652410e-05, 1.20292960e-02, 9.87957540e-01],\n",
       "       [1.31652410e-05, 1.20292960e-02, 9.87957540e-01],\n",
       "       [2.89757710e-03, 9.97102440e-01, 2.90078240e-08],\n",
       "       [1.47949040e-02, 9.82046960e-01, 3.15809620e-03],\n",
       "       [9.39423200e-07, 2.88389970e-04, 9.99710600e-01],\n",
       "       [9.99999760e-01, 2.05378340e-07, 1.22100640e-13],\n",
       "       [9.99696730e-01, 3.03347700e-04, 6.55436900e-09],\n",
       "       [1.31652410e-05, 1.20292960e-02, 9.87957540e-01],\n",
       "       [9.39423200e-07, 2.88389970e-04, 9.99710600e-01],\n",
       "       [3.03660320e-04, 6.75374300e-04, 9.99020930e-01],\n",
       "       [9.39423200e-07, 2.88389970e-04, 9.99710600e-01],\n",
       "       [2.24622530e-02, 9.77535300e-01, 2.46641000e-06],\n",
       "       [1.31652410e-05, 1.20292960e-02, 9.87957540e-01],\n",
       "       [1.67547170e-02, 9.82827200e-01, 4.18069340e-04],\n",
       "       [1.31652410e-05, 1.20292960e-02, 9.87957540e-01],\n",
       "       [3.03660320e-04, 6.75374300e-04, 9.99020930e-01],\n",
       "       [3.03660320e-04, 6.75374300e-04, 9.99020930e-01],\n",
       "       [9.39423200e-07, 2.88389970e-04, 9.99710600e-01],\n",
       "       [2.89757710e-03, 9.97102440e-01, 2.90078240e-08],\n",
       "       [9.80954500e-01, 1.89951290e-02, 5.04100430e-05],\n",
       "       [3.03660320e-04, 6.75374300e-04, 9.99020930e-01],\n",
       "       [7.37693400e-03, 9.92621540e-01, 1.51950090e-06],\n",
       "       [9.99948740e-01, 5.12633700e-05, 4.09543700e-09],\n",
       "       [9.39423200e-07, 2.88389970e-04, 9.99710600e-01],\n",
       "       [2.17369930e-01, 7.82629130e-01, 9.15700900e-07],\n",
       "       [9.99870800e-01, 1.02471975e-04, 2.67284560e-05],\n",
       "       [9.99997400e-01, 2.67405200e-06, 6.87832500e-10],\n",
       "       [1.31652410e-05, 1.20292960e-02, 9.87957540e-01],\n",
       "       [9.99893400e-01, 1.06582935e-04, 4.45124000e-09],\n",
       "       [1.31652410e-05, 1.20292960e-02, 9.87957540e-01],\n",
       "       [7.77127270e-01, 2.22868170e-01, 4.52304700e-06],\n",
       "       [3.03660320e-04, 6.75374300e-04, 9.99020930e-01],\n",
       "       [1.00000000e+00, 2.99665070e-09, 1.33235210e-14],\n",
       "       [3.03660320e-04, 6.75374300e-04, 9.99020930e-01],\n",
       "       [3.58242240e-03, 9.96417500e-01, 6.06521900e-12],\n",
       "       [1.31652410e-05, 1.20292960e-02, 9.87957540e-01],\n",
       "       [4.16912840e-03, 9.95817240e-01, 1.35942055e-05],\n",
       "       [2.55668040e-01, 7.44309540e-01, 2.24226440e-05],\n",
       "       [1.31652410e-05, 1.20292960e-02, 9.87957540e-01],\n",
       "       [1.23825800e-05, 9.99034500e-01, 9.53111300e-04],\n",
       "       [7.37693400e-03, 9.92621540e-01, 1.51950090e-06],\n",
       "       [1.31652410e-05, 1.20292960e-02, 9.87957540e-01],\n",
       "       [7.28066100e-01, 2.71918860e-01, 1.49871110e-05],\n",
       "       [4.33242800e-03, 9.95667600e-01, 8.17788550e-12],\n",
       "       [3.03660320e-04, 6.75374300e-04, 9.99020930e-01],\n",
       "       [1.31652410e-05, 1.20292960e-02, 9.87957540e-01],\n",
       "       [3.94075100e-03, 9.91183400e-01, 4.87595200e-03],\n",
       "       [9.98764900e-01, 1.23512490e-03, 2.00681000e-08],\n",
       "       [9.39423200e-07, 2.88389970e-04, 9.99710600e-01],\n",
       "       [3.03660320e-04, 6.75374300e-04, 9.99020930e-01],\n",
       "       [9.39423200e-07, 2.88389970e-04, 9.99710600e-01],\n",
       "       [2.89757710e-03, 9.97102440e-01, 2.90078240e-08],\n",
       "       [1.23825800e-05, 9.99034500e-01, 9.53111300e-04],\n",
       "       [2.42306000e-02, 9.75754800e-01, 1.44839480e-05],\n",
       "       [9.39423200e-07, 2.88389970e-04, 9.99710600e-01],\n",
       "       [2.24622530e-02, 9.77535300e-01, 2.46641000e-06],\n",
       "       [9.99609900e-01, 3.90092960e-04, 1.37503340e-12],\n",
       "       [1.87456590e-02, 9.81184660e-01, 6.96681600e-05],\n",
       "       [7.89582400e-03, 9.92104200e-01, 6.91551000e-12],\n",
       "       [3.03660320e-04, 6.75373650e-04, 9.99020930e-01],\n",
       "       [9.99656800e-01, 3.43163530e-04, 1.32238230e-10],\n",
       "       [3.94075800e-03, 9.91183300e-01, 4.87595140e-03],\n",
       "       [1.47948770e-02, 9.82047100e-01, 3.15808430e-03],\n",
       "       [3.94075800e-03, 9.91183300e-01, 4.87595140e-03],\n",
       "       [4.20530930e-03, 9.93926000e-01, 1.86872340e-03],\n",
       "       [7.82174200e-03, 9.92173700e-01, 4.55485360e-06],\n",
       "       [9.99939200e-01, 6.08302730e-05, 1.61680670e-09],\n",
       "       [7.89583100e-03, 9.92104200e-01, 6.91551000e-12],\n",
       "       [1.31651900e-05, 1.20293860e-02, 9.87957400e-01]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob = df_proba[df_proba['phage']=='p003ppresabsSTCC_qual'].iloc[:,-3:]\n",
    "y_prob = y_prob.to_numpy()\n",
    "y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Retrieved from https://github.com/scikit-learn/scikit-learn/issues/3298\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "def rocauc_ovo(truth, pred, average=\"macro\", multi_class=\"ovo\"):\n",
    "\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(truth)\n",
    "\n",
    "    truth = lb.transform(truth)   \n",
    "    \n",
    "    return roc_auc_score(truth, pred, average=average, multi_class=multi_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9921503593145383"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo1 = rocauc_ovo(y_test_over, y_prob, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rocauc_ovr(truth, pred, average=\"macro\", multi_class=\"ovr\"):\n",
    "\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(truth)\n",
    "\n",
    "    truth = lb.transform(truth)   \n",
    "\n",
    "    return roc_auc_score(truth, pred, average=average, multi_class=multi_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9921503593145383"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr1 = rocauc_ovr(y_test_over, y_prob, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=234,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat2 = pd.DataFrame(X_test_over[:,0])\n",
    "dat2['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CFBRSa05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS114</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS168</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>NRS196</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>NRS249</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>CFBRSa28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0  test\n",
       "0    CFBRSa05     0\n",
       "1      NRS114     0\n",
       "2      NRS168     1\n",
       "3      NRS255     2\n",
       "4      NRS209     2\n",
       "..        ...   ...\n",
       "197    NRS196     0\n",
       "198    NRS255     2\n",
       "199    NRS249     1\n",
       "200    NRS209     2\n",
       "201  CFBRSa28     0\n",
       "\n",
       "[202 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over2 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],)),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over2.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 470 samples, validate on 202 samples\n",
      "Epoch 1/100\n",
      "470/470 [==============================] - 0s 346us/step - loss: 1.1844 - accuracy: 0.5681 - val_loss: 0.6902 - val_accuracy: 0.7129\n",
      "Epoch 2/100\n",
      "470/470 [==============================] - 0s 142us/step - loss: 0.6260 - accuracy: 0.7532 - val_loss: 0.5320 - val_accuracy: 0.7871\n",
      "Epoch 3/100\n",
      "470/470 [==============================] - 0s 141us/step - loss: 0.4054 - accuracy: 0.8340 - val_loss: 0.4342 - val_accuracy: 0.8168\n",
      "Epoch 4/100\n",
      "470/470 [==============================] - 0s 148us/step - loss: 0.3519 - accuracy: 0.8681 - val_loss: 0.4104 - val_accuracy: 0.8267\n",
      "Epoch 5/100\n",
      "470/470 [==============================] - 0s 142us/step - loss: 0.3358 - accuracy: 0.8787 - val_loss: 0.3797 - val_accuracy: 0.8366\n",
      "Epoch 6/100\n",
      "470/470 [==============================] - 0s 147us/step - loss: 0.2898 - accuracy: 0.9106 - val_loss: 0.3103 - val_accuracy: 0.8911\n",
      "Epoch 7/100\n",
      "470/470 [==============================] - 0s 135us/step - loss: 0.2388 - accuracy: 0.9319 - val_loss: 0.2888 - val_accuracy: 0.9208\n",
      "Epoch 8/100\n",
      "470/470 [==============================] - 0s 136us/step - loss: 0.2153 - accuracy: 0.9383 - val_loss: 0.2837 - val_accuracy: 0.9257\n",
      "Epoch 9/100\n",
      "470/470 [==============================] - 0s 154us/step - loss: 0.1986 - accuracy: 0.9660 - val_loss: 0.2832 - val_accuracy: 0.9158\n",
      "Epoch 10/100\n",
      "470/470 [==============================] - 0s 248us/step - loss: 0.1791 - accuracy: 0.9681 - val_loss: 0.2515 - val_accuracy: 0.9158\n",
      "Epoch 11/100\n",
      "470/470 [==============================] - 0s 201us/step - loss: 0.1657 - accuracy: 0.9681 - val_loss: 0.2509 - val_accuracy: 0.9307\n",
      "Epoch 12/100\n",
      "470/470 [==============================] - 0s 199us/step - loss: 0.1717 - accuracy: 0.9574 - val_loss: 0.2156 - val_accuracy: 0.9356\n",
      "Epoch 13/100\n",
      "470/470 [==============================] - 0s 266us/step - loss: 0.1791 - accuracy: 0.9596 - val_loss: 0.3090 - val_accuracy: 0.9059\n",
      "Epoch 14/100\n",
      "470/470 [==============================] - 0s 224us/step - loss: 0.1663 - accuracy: 0.9702 - val_loss: 0.2008 - val_accuracy: 0.9208\n",
      "Epoch 15/100\n",
      "470/470 [==============================] - 0s 193us/step - loss: 0.1345 - accuracy: 0.9681 - val_loss: 0.1927 - val_accuracy: 0.9307\n",
      "Epoch 16/100\n",
      "470/470 [==============================] - 0s 157us/step - loss: 0.1427 - accuracy: 0.9723 - val_loss: 0.1959 - val_accuracy: 0.9208\n",
      "Epoch 17/100\n",
      "470/470 [==============================] - 0s 405us/step - loss: 0.1366 - accuracy: 0.9660 - val_loss: 0.2262 - val_accuracy: 0.9208\n",
      "Epoch 18/100\n",
      "470/470 [==============================] - 0s 160us/step - loss: 0.1273 - accuracy: 0.9745 - val_loss: 0.2135 - val_accuracy: 0.9257\n",
      "Epoch 19/100\n",
      "470/470 [==============================] - 0s 468us/step - loss: 0.1210 - accuracy: 0.9702 - val_loss: 0.1939 - val_accuracy: 0.9307\n",
      "Epoch 20/100\n",
      "470/470 [==============================] - 0s 354us/step - loss: 0.1076 - accuracy: 0.9745 - val_loss: 0.1625 - val_accuracy: 0.9703\n",
      "Epoch 21/100\n",
      "470/470 [==============================] - 0s 187us/step - loss: 0.0954 - accuracy: 0.9787 - val_loss: 0.1545 - val_accuracy: 0.9703\n",
      "Epoch 22/100\n",
      "470/470 [==============================] - 0s 150us/step - loss: 0.0971 - accuracy: 0.9766 - val_loss: 0.1706 - val_accuracy: 0.9307\n",
      "Epoch 23/100\n",
      "470/470 [==============================] - 0s 129us/step - loss: 0.0844 - accuracy: 0.9830 - val_loss: 0.1499 - val_accuracy: 0.9554\n",
      "Epoch 24/100\n",
      "470/470 [==============================] - 0s 146us/step - loss: 0.0769 - accuracy: 0.9830 - val_loss: 0.1478 - val_accuracy: 0.9455\n",
      "Epoch 25/100\n",
      "470/470 [==============================] - 0s 433us/step - loss: 0.0753 - accuracy: 0.9809 - val_loss: 0.1458 - val_accuracy: 0.9455\n",
      "Epoch 26/100\n",
      "470/470 [==============================] - 0s 401us/step - loss: 0.0828 - accuracy: 0.9809 - val_loss: 0.1605 - val_accuracy: 0.9307\n",
      "Epoch 27/100\n",
      "470/470 [==============================] - 0s 332us/step - loss: 0.0890 - accuracy: 0.9830 - val_loss: 0.1812 - val_accuracy: 0.9208\n",
      "Epoch 28/100\n",
      "470/470 [==============================] - 0s 312us/step - loss: 0.0693 - accuracy: 0.9851 - val_loss: 0.1375 - val_accuracy: 0.9505\n",
      "Epoch 29/100\n",
      "470/470 [==============================] - 0s 277us/step - loss: 0.0643 - accuracy: 0.9851 - val_loss: 0.1543 - val_accuracy: 0.9505\n",
      "Epoch 30/100\n",
      "470/470 [==============================] - 0s 349us/step - loss: 0.0589 - accuracy: 0.9915 - val_loss: 0.1383 - val_accuracy: 0.9554\n",
      "Epoch 31/100\n",
      "470/470 [==============================] - 0s 259us/step - loss: 0.0570 - accuracy: 0.9894 - val_loss: 0.1354 - val_accuracy: 0.9604\n",
      "Epoch 32/100\n",
      "470/470 [==============================] - 0s 162us/step - loss: 0.0518 - accuracy: 0.9957 - val_loss: 0.1593 - val_accuracy: 0.9406\n",
      "Epoch 33/100\n",
      "470/470 [==============================] - 0s 115us/step - loss: 0.0507 - accuracy: 0.9915 - val_loss: 0.1158 - val_accuracy: 0.9653\n",
      "Epoch 34/100\n",
      "470/470 [==============================] - 0s 135us/step - loss: 0.0495 - accuracy: 0.9936 - val_loss: 0.1375 - val_accuracy: 0.9554\n",
      "Epoch 35/100\n",
      "470/470 [==============================] - 0s 168us/step - loss: 0.0479 - accuracy: 0.9915 - val_loss: 0.1274 - val_accuracy: 0.9505\n",
      "Epoch 36/100\n",
      "470/470 [==============================] - 0s 121us/step - loss: 0.0444 - accuracy: 0.9957 - val_loss: 0.1360 - val_accuracy: 0.9554\n",
      "Epoch 37/100\n",
      "470/470 [==============================] - 0s 186us/step - loss: 0.0449 - accuracy: 0.9957 - val_loss: 0.1133 - val_accuracy: 0.9604\n",
      "Epoch 38/100\n",
      "470/470 [==============================] - 0s 226us/step - loss: 0.0442 - accuracy: 0.9936 - val_loss: 0.1214 - val_accuracy: 0.9505\n",
      "Epoch 39/100\n",
      "470/470 [==============================] - 0s 176us/step - loss: 0.0416 - accuracy: 0.9936 - val_loss: 0.1105 - val_accuracy: 0.9604\n",
      "Epoch 40/100\n",
      "470/470 [==============================] - 0s 182us/step - loss: 0.0410 - accuracy: 0.9957 - val_loss: 0.1066 - val_accuracy: 0.9653\n",
      "Epoch 41/100\n",
      "470/470 [==============================] - 0s 470us/step - loss: 0.0399 - accuracy: 0.9957 - val_loss: 0.1352 - val_accuracy: 0.9554\n",
      "Epoch 42/100\n",
      "470/470 [==============================] - 0s 286us/step - loss: 0.0386 - accuracy: 0.9957 - val_loss: 0.1203 - val_accuracy: 0.9604\n",
      "Epoch 43/100\n",
      "470/470 [==============================] - 0s 130us/step - loss: 0.0367 - accuracy: 0.9957 - val_loss: 0.1065 - val_accuracy: 0.9653\n",
      "Epoch 44/100\n",
      "470/470 [==============================] - 0s 141us/step - loss: 0.0368 - accuracy: 0.9957 - val_loss: 0.1221 - val_accuracy: 0.9406\n",
      "Epoch 45/100\n",
      "470/470 [==============================] - 0s 128us/step - loss: 0.0367 - accuracy: 0.9915 - val_loss: 0.1365 - val_accuracy: 0.9505\n",
      "Epoch 46/100\n",
      "470/470 [==============================] - 0s 198us/step - loss: 0.0337 - accuracy: 0.9957 - val_loss: 0.1056 - val_accuracy: 0.9604\n",
      "Epoch 47/100\n",
      "470/470 [==============================] - 0s 209us/step - loss: 0.0332 - accuracy: 0.9915 - val_loss: 0.1070 - val_accuracy: 0.9604\n",
      "Epoch 48/100\n",
      "470/470 [==============================] - 0s 128us/step - loss: 0.0340 - accuracy: 0.9957 - val_loss: 0.1339 - val_accuracy: 0.9554\n",
      "Epoch 49/100\n",
      "470/470 [==============================] - 0s 127us/step - loss: 0.0328 - accuracy: 0.9915 - val_loss: 0.1119 - val_accuracy: 0.9604\n",
      "Epoch 50/100\n",
      "470/470 [==============================] - 0s 161us/step - loss: 0.0273 - accuracy: 0.9957 - val_loss: 0.1388 - val_accuracy: 0.9455\n",
      "Epoch 51/100\n",
      "470/470 [==============================] - 0s 328us/step - loss: 0.0297 - accuracy: 0.9957 - val_loss: 0.1159 - val_accuracy: 0.9604\n",
      "Epoch 52/100\n",
      "470/470 [==============================] - 0s 510us/step - loss: 0.0279 - accuracy: 0.9957 - val_loss: 0.0993 - val_accuracy: 0.9653\n",
      "Epoch 53/100\n",
      "470/470 [==============================] - 0s 237us/step - loss: 0.0270 - accuracy: 0.9957 - val_loss: 0.1091 - val_accuracy: 0.9604\n",
      "Epoch 54/100\n",
      "470/470 [==============================] - 0s 182us/step - loss: 0.0307 - accuracy: 0.9957 - val_loss: 0.1153 - val_accuracy: 0.9604\n",
      "Epoch 55/100\n",
      "470/470 [==============================] - 0s 327us/step - loss: 0.0280 - accuracy: 0.9957 - val_loss: 0.1047 - val_accuracy: 0.9604\n",
      "Epoch 56/100\n",
      "470/470 [==============================] - 0s 338us/step - loss: 0.0242 - accuracy: 0.9957 - val_loss: 0.1288 - val_accuracy: 0.9505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "470/470 [==============================] - 0s 258us/step - loss: 0.0255 - accuracy: 0.9957 - val_loss: 0.1035 - val_accuracy: 0.9653\n",
      "Epoch 58/100\n",
      "470/470 [==============================] - 0s 300us/step - loss: 0.0215 - accuracy: 0.9957 - val_loss: 0.1471 - val_accuracy: 0.9455\n",
      "Epoch 59/100\n",
      "470/470 [==============================] - 0s 175us/step - loss: 0.0280 - accuracy: 0.9957 - val_loss: 0.1120 - val_accuracy: 0.9604\n",
      "Epoch 60/100\n",
      "470/470 [==============================] - 0s 135us/step - loss: 0.0238 - accuracy: 0.9957 - val_loss: 0.0958 - val_accuracy: 0.9653\n",
      "Epoch 61/100\n",
      "470/470 [==============================] - 0s 155us/step - loss: 0.0244 - accuracy: 0.9957 - val_loss: 0.1078 - val_accuracy: 0.9604\n",
      "Epoch 62/100\n",
      "470/470 [==============================] - 0s 140us/step - loss: 0.0241 - accuracy: 0.9957 - val_loss: 0.1240 - val_accuracy: 0.9554\n",
      "Epoch 63/100\n",
      "470/470 [==============================] - 0s 132us/step - loss: 0.0259 - accuracy: 0.9957 - val_loss: 0.0963 - val_accuracy: 0.9653\n",
      "Epoch 64/100\n",
      "470/470 [==============================] - 0s 127us/step - loss: 0.0217 - accuracy: 0.9979 - val_loss: 0.1123 - val_accuracy: 0.9604\n",
      "Epoch 65/100\n",
      "470/470 [==============================] - 0s 131us/step - loss: 0.0222 - accuracy: 0.9957 - val_loss: 0.1715 - val_accuracy: 0.9356\n",
      "Epoch 66/100\n",
      "470/470 [==============================] - 0s 171us/step - loss: 0.0275 - accuracy: 0.9957 - val_loss: 0.0965 - val_accuracy: 0.9752\n",
      "Epoch 67/100\n",
      "470/470 [==============================] - 0s 127us/step - loss: 0.0293 - accuracy: 0.9957 - val_loss: 0.1049 - val_accuracy: 0.9653\n",
      "Epoch 68/100\n",
      "470/470 [==============================] - 0s 115us/step - loss: 0.0258 - accuracy: 0.9979 - val_loss: 0.1279 - val_accuracy: 0.9505\n",
      "Epoch 69/100\n",
      "470/470 [==============================] - 0s 119us/step - loss: 0.0263 - accuracy: 0.9957 - val_loss: 0.1510 - val_accuracy: 0.9455\n",
      "Epoch 70/100\n",
      "470/470 [==============================] - 0s 204us/step - loss: 0.0239 - accuracy: 0.9936 - val_loss: 0.1065 - val_accuracy: 0.9604\n",
      "Epoch 71/100\n",
      "470/470 [==============================] - 0s 135us/step - loss: 0.0240 - accuracy: 0.9957 - val_loss: 0.1103 - val_accuracy: 0.9653\n",
      "Epoch 72/100\n",
      "470/470 [==============================] - 0s 120us/step - loss: 0.0165 - accuracy: 0.9979 - val_loss: 0.1004 - val_accuracy: 0.9653\n",
      "Epoch 73/100\n",
      "470/470 [==============================] - 0s 156us/step - loss: 0.0198 - accuracy: 0.9957 - val_loss: 0.1040 - val_accuracy: 0.9604\n",
      "Epoch 74/100\n",
      "470/470 [==============================] - 0s 138us/step - loss: 0.0180 - accuracy: 0.9979 - val_loss: 0.1263 - val_accuracy: 0.9505\n",
      "Epoch 75/100\n",
      "470/470 [==============================] - 0s 129us/step - loss: 0.0176 - accuracy: 0.9979 - val_loss: 0.0986 - val_accuracy: 0.9604\n",
      "Epoch 76/100\n",
      "470/470 [==============================] - 0s 120us/step - loss: 0.0156 - accuracy: 0.9979 - val_loss: 0.1560 - val_accuracy: 0.9554\n",
      "Epoch 77/100\n",
      "470/470 [==============================] - 0s 116us/step - loss: 0.0199 - accuracy: 0.9957 - val_loss: 0.0917 - val_accuracy: 0.9653\n",
      "Epoch 78/100\n",
      "470/470 [==============================] - 0s 207us/step - loss: 0.0166 - accuracy: 0.9979 - val_loss: 0.1232 - val_accuracy: 0.9604\n",
      "Epoch 79/100\n",
      "470/470 [==============================] - 0s 149us/step - loss: 0.0151 - accuracy: 0.9979 - val_loss: 0.1054 - val_accuracy: 0.9653\n",
      "Epoch 80/100\n",
      "470/470 [==============================] - 0s 201us/step - loss: 0.0161 - accuracy: 0.9957 - val_loss: 0.0993 - val_accuracy: 0.9703\n",
      "Epoch 81/100\n",
      "470/470 [==============================] - 0s 141us/step - loss: 0.0166 - accuracy: 0.9957 - val_loss: 0.0935 - val_accuracy: 0.9653\n",
      "Epoch 82/100\n",
      "470/470 [==============================] - 0s 141us/step - loss: 0.0161 - accuracy: 0.9957 - val_loss: 0.1066 - val_accuracy: 0.9653\n",
      "Epoch 83/100\n",
      "470/470 [==============================] - 0s 121us/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 0.1337 - val_accuracy: 0.9505\n",
      "Epoch 84/100\n",
      "470/470 [==============================] - 0s 124us/step - loss: 0.0153 - accuracy: 0.9957 - val_loss: 0.0953 - val_accuracy: 0.9653\n",
      "Epoch 85/100\n",
      "470/470 [==============================] - 0s 117us/step - loss: 0.0164 - accuracy: 0.9979 - val_loss: 0.1596 - val_accuracy: 0.9406\n",
      "Epoch 86/100\n",
      "470/470 [==============================] - 0s 131us/step - loss: 0.0171 - accuracy: 0.9957 - val_loss: 0.0781 - val_accuracy: 0.9752\n",
      "Epoch 87/100\n",
      "470/470 [==============================] - 0s 195us/step - loss: 0.0153 - accuracy: 0.9979 - val_loss: 0.1320 - val_accuracy: 0.9604\n",
      "Epoch 88/100\n",
      "470/470 [==============================] - 0s 225us/step - loss: 0.0137 - accuracy: 0.9957 - val_loss: 0.0868 - val_accuracy: 0.9703\n",
      "Epoch 89/100\n",
      "470/470 [==============================] - 0s 192us/step - loss: 0.0136 - accuracy: 0.9979 - val_loss: 0.1172 - val_accuracy: 0.9653\n",
      "Epoch 90/100\n",
      "470/470 [==============================] - 0s 190us/step - loss: 0.0146 - accuracy: 0.9957 - val_loss: 0.1008 - val_accuracy: 0.9653\n",
      "Epoch 91/100\n",
      "470/470 [==============================] - 0s 150us/step - loss: 0.0151 - accuracy: 0.9979 - val_loss: 0.1351 - val_accuracy: 0.9554\n",
      "Epoch 92/100\n",
      "470/470 [==============================] - 0s 145us/step - loss: 0.0118 - accuracy: 0.9979 - val_loss: 0.1288 - val_accuracy: 0.9554\n",
      "Epoch 93/100\n",
      "470/470 [==============================] - 0s 156us/step - loss: 0.0127 - accuracy: 0.9979 - val_loss: 0.0969 - val_accuracy: 0.9703\n",
      "Epoch 94/100\n",
      "470/470 [==============================] - 0s 172us/step - loss: 0.0117 - accuracy: 0.9979 - val_loss: 0.1192 - val_accuracy: 0.9604\n",
      "Epoch 95/100\n",
      "470/470 [==============================] - 0s 160us/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.1225 - val_accuracy: 0.9604\n",
      "Epoch 96/100\n",
      "470/470 [==============================] - 0s 125us/step - loss: 0.0113 - accuracy: 0.9979 - val_loss: 0.0986 - val_accuracy: 0.9703\n",
      "Epoch 97/100\n",
      "470/470 [==============================] - 0s 134us/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.1433 - val_accuracy: 0.9554\n",
      "Epoch 98/100\n",
      "470/470 [==============================] - 0s 257us/step - loss: 0.0128 - accuracy: 0.9979 - val_loss: 0.1152 - val_accuracy: 0.9604\n",
      "Epoch 99/100\n",
      "470/470 [==============================] - 0s 163us/step - loss: 0.0091 - accuracy: 0.9979 - val_loss: 0.1173 - val_accuracy: 0.9604\n",
      "Epoch 100/100\n",
      "470/470 [==============================] - 0s 153us/step - loss: 0.0109 - accuracy: 0.9979 - val_loss: 0.0993 - val_accuracy: 0.9653\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a3c9370f0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over2.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202/202 [==============================] - 0s 83us/step\n",
      "over-sampling test accuracy: 94.06%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over2 = model1_over2.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over2*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 2, 2, 2, 2, 1, 2, 2, 0, 1, 0, 0, 2, 1, 0, 2, 1, 2, 2, 2,\n",
       "       0, 2, 0, 1, 2, 2, 2, 2, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 2, 0, 1, 0,\n",
       "       2, 0, 1, 2, 2, 2, 1, 0, 0, 2, 2, 1, 1, 2, 0, 2, 0, 0, 1, 1, 1, 1,\n",
       "       1, 2, 1, 2, 0, 1, 2, 1, 0, 0, 1, 1, 2, 1, 1, 2, 0, 0, 1, 0, 0, 1,\n",
       "       1, 2, 0, 1, 2, 1, 0, 1, 0, 2, 0, 1, 1, 1, 1, 2, 2, 1, 0, 0, 1, 0,\n",
       "       2, 0, 1, 1, 1, 2, 0, 2, 1, 1, 0, 2, 1, 1, 0, 1, 0, 0, 0, 2, 1, 1,\n",
       "       1, 0, 1, 1, 1, 1, 2, 2, 0, 2, 0, 2, 2, 0, 1, 2, 0, 0, 1, 2, 2, 2,\n",
       "       0, 2, 1, 1, 0, 2, 2, 2, 1, 1, 0, 2, 1, 2, 0, 0, 2, 0, 2, 2, 2, 1,\n",
       "       1, 1, 2, 1, 2, 0, 1, 0, 1, 2, 1, 2, 1, 0, 0, 0, 0, 1, 2, 2, 1, 0,\n",
       "       2, 1, 2, 0])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred2 = model1_over2.predict_classes(X_test_over)\n",
    "pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CFBRSa05</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS114</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS168</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>NRS196</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>NRS249</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>CFBRSa28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0  test  pred\n",
       "0    CFBRSa05     0     0\n",
       "1      NRS114     0     0\n",
       "2      NRS168     1     1\n",
       "3      NRS255     2     2\n",
       "4      NRS209     2     2\n",
       "..        ...   ...   ...\n",
       "197    NRS196     0     0\n",
       "198    NRS255     2     2\n",
       "199    NRS249     1     1\n",
       "200    NRS209     2     2\n",
       "201  CFBRSa28     0     0\n",
       "\n",
       "[202 rows x 3 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat2['pred'] = pred2\n",
    "dat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba2 = model1_over2.predict_proba(X_test_over)\n",
    "dat_proba2 = pd.DataFrame(proba2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.999901e-01</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>4.882489e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.996415e-01</td>\n",
       "      <td>0.000358</td>\n",
       "      <td>4.248437e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.225085e-02</td>\n",
       "      <td>0.907734</td>\n",
       "      <td>1.547077e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.477896e-04</td>\n",
       "      <td>0.000522</td>\n",
       "      <td>9.991297e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.505357e-08</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>9.997205e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>9.984702e-01</td>\n",
       "      <td>0.001519</td>\n",
       "      <td>1.068622e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>3.477892e-04</td>\n",
       "      <td>0.000522</td>\n",
       "      <td>9.991297e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>7.244510e-03</td>\n",
       "      <td>0.992755</td>\n",
       "      <td>9.145550e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>8.505357e-08</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>9.997205e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>9.999973e-01</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>8.889350e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0         1             2\n",
       "0    9.999901e-01  0.000009  4.882489e-07\n",
       "1    9.996415e-01  0.000358  4.248437e-10\n",
       "2    9.225085e-02  0.907734  1.547077e-05\n",
       "3    3.477896e-04  0.000522  9.991297e-01\n",
       "4    8.505357e-08  0.000279  9.997205e-01\n",
       "..            ...       ...           ...\n",
       "197  9.984702e-01  0.001519  1.068622e-05\n",
       "198  3.477892e-04  0.000522  9.991297e-01\n",
       "199  7.244510e-03  0.992755  9.145550e-09\n",
       "200  8.505357e-08  0.000279  9.997205e-01\n",
       "201  9.999973e-01  0.000002  8.889350e-07\n",
       "\n",
       "[202 rows x 3 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba2.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba2.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat2.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/2p003ppST.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 470 samples, validate on 202 samples\n",
      "Epoch 1/100\n",
      "470/470 [==============================] - 0s 210us/step - loss: 0.0157 - accuracy: 0.9979 - val_loss: 0.1100 - val_accuracy: 0.9653\n",
      "Epoch 2/100\n",
      "470/470 [==============================] - 0s 210us/step - loss: 0.0142 - accuracy: 0.9979 - val_loss: 0.1555 - val_accuracy: 0.9554\n",
      "Epoch 3/100\n",
      "470/470 [==============================] - 0s 192us/step - loss: 0.0087 - accuracy: 0.9979 - val_loss: 0.1477 - val_accuracy: 0.9554\n",
      "Epoch 4/100\n",
      "470/470 [==============================] - 0s 169us/step - loss: 0.0094 - accuracy: 0.9979 - val_loss: 0.1452 - val_accuracy: 0.9653\n",
      "Epoch 5/100\n",
      "470/470 [==============================] - 0s 151us/step - loss: 0.0124 - accuracy: 0.9979 - val_loss: 0.1532 - val_accuracy: 0.9505\n",
      "Epoch 6/100\n",
      "470/470 [==============================] - 0s 148us/step - loss: 0.0116 - accuracy: 0.9979 - val_loss: 0.1720 - val_accuracy: 0.9455\n",
      "Epoch 7/100\n",
      "470/470 [==============================] - 0s 130us/step - loss: 0.0072 - accuracy: 0.9979 - val_loss: 0.1408 - val_accuracy: 0.9653\n",
      "Epoch 8/100\n",
      "470/470 [==============================] - 0s 116us/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.1707 - val_accuracy: 0.9505\n",
      "Epoch 9/100\n",
      "470/470 [==============================] - 0s 116us/step - loss: 0.0089 - accuracy: 0.9979 - val_loss: 0.1372 - val_accuracy: 0.9554\n",
      "Epoch 10/100\n",
      "470/470 [==============================] - 0s 115us/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.1790 - val_accuracy: 0.9505\n",
      "Epoch 11/100\n",
      "470/470 [==============================] - 0s 125us/step - loss: 0.0116 - accuracy: 0.9979 - val_loss: 0.1139 - val_accuracy: 0.9653\n",
      "Epoch 12/100\n",
      "470/470 [==============================] - 0s 116us/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.1950 - val_accuracy: 0.9406\n",
      "Epoch 13/100\n",
      "470/470 [==============================] - 0s 122us/step - loss: 0.0091 - accuracy: 0.9979 - val_loss: 0.1253 - val_accuracy: 0.9653\n",
      "Epoch 14/100\n",
      "470/470 [==============================] - 0s 116us/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.1442 - val_accuracy: 0.9653\n",
      "Epoch 15/100\n",
      "470/470 [==============================] - 0s 149us/step - loss: 0.0084 - accuracy: 0.9979 - val_loss: 0.1346 - val_accuracy: 0.9604\n",
      "Epoch 16/100\n",
      "470/470 [==============================] - 0s 213us/step - loss: 0.0076 - accuracy: 0.9979 - val_loss: 0.1382 - val_accuracy: 0.9653\n",
      "Epoch 17/100\n",
      "470/470 [==============================] - 0s 229us/step - loss: 0.0084 - accuracy: 0.9979 - val_loss: 0.1429 - val_accuracy: 0.9653\n",
      "Epoch 18/100\n",
      "470/470 [==============================] - 0s 175us/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.2006 - val_accuracy: 0.9406\n",
      "Epoch 19/100\n",
      "470/470 [==============================] - 0s 162us/step - loss: 0.0122 - accuracy: 0.9979 - val_loss: 0.1239 - val_accuracy: 0.9604\n",
      "Epoch 20/100\n",
      "470/470 [==============================] - 0s 196us/step - loss: 0.0093 - accuracy: 0.9979 - val_loss: 0.1575 - val_accuracy: 0.9604\n",
      "Epoch 21/100\n",
      "470/470 [==============================] - 0s 162us/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.1717 - val_accuracy: 0.9505\n",
      "Epoch 22/100\n",
      "470/470 [==============================] - 0s 142us/step - loss: 0.0098 - accuracy: 0.9979 - val_loss: 0.1322 - val_accuracy: 0.9604\n",
      "Epoch 23/100\n",
      "470/470 [==============================] - 0s 162us/step - loss: 0.0074 - accuracy: 0.9979 - val_loss: 0.1468 - val_accuracy: 0.9604\n",
      "Epoch 24/100\n",
      "470/470 [==============================] - 0s 197us/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.1784 - val_accuracy: 0.9455\n",
      "Epoch 25/100\n",
      "470/470 [==============================] - 0s 202us/step - loss: 0.0093 - accuracy: 0.9979 - val_loss: 0.1510 - val_accuracy: 0.9604\n",
      "Epoch 26/100\n",
      "470/470 [==============================] - 0s 279us/step - loss: 0.0053 - accuracy: 0.9979 - val_loss: 0.1539 - val_accuracy: 0.9604\n",
      "Epoch 27/100\n",
      "470/470 [==============================] - 0s 291us/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.1668 - val_accuracy: 0.9505\n",
      "Epoch 28/100\n",
      "470/470 [==============================] - 0s 212us/step - loss: 0.0062 - accuracy: 0.9979 - val_loss: 0.1525 - val_accuracy: 0.9604\n",
      "Epoch 29/100\n",
      "470/470 [==============================] - 0s 204us/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.1553 - val_accuracy: 0.9604\n",
      "Epoch 30/100\n",
      "470/470 [==============================] - 0s 220us/step - loss: 0.0054 - accuracy: 0.9979 - val_loss: 0.1408 - val_accuracy: 0.9604\n",
      "Epoch 31/100\n",
      "470/470 [==============================] - 0s 200us/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.1761 - val_accuracy: 0.9505\n",
      "Epoch 32/100\n",
      "470/470 [==============================] - 0s 304us/step - loss: 0.0065 - accuracy: 0.9979 - val_loss: 0.1318 - val_accuracy: 0.9653\n",
      "Epoch 33/100\n",
      "470/470 [==============================] - 0s 195us/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.1867 - val_accuracy: 0.9505\n",
      "Epoch 34/100\n",
      "470/470 [==============================] - 0s 148us/step - loss: 0.0053 - accuracy: 0.9979 - val_loss: 0.1558 - val_accuracy: 0.9604\n",
      "Epoch 35/100\n",
      "470/470 [==============================] - 0s 148us/step - loss: 0.0055 - accuracy: 0.9979 - val_loss: 0.1507 - val_accuracy: 0.9604\n",
      "Epoch 36/100\n",
      "470/470 [==============================] - 0s 189us/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.1800 - val_accuracy: 0.9554\n",
      "Epoch 37/100\n",
      "470/470 [==============================] - 0s 133us/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.1649 - val_accuracy: 0.9604\n",
      "Epoch 38/100\n",
      "470/470 [==============================] - 0s 173us/step - loss: 0.0060 - accuracy: 0.9979 - val_loss: 0.1419 - val_accuracy: 0.9653\n",
      "Epoch 39/100\n",
      "470/470 [==============================] - 0s 131us/step - loss: 0.0058 - accuracy: 0.9979 - val_loss: 0.1451 - val_accuracy: 0.9604\n",
      "Epoch 40/100\n",
      "470/470 [==============================] - 0s 124us/step - loss: 0.0049 - accuracy: 0.9979 - val_loss: 0.1607 - val_accuracy: 0.9604\n",
      "Epoch 41/100\n",
      "470/470 [==============================] - 0s 124us/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.1710 - val_accuracy: 0.9604\n",
      "Epoch 42/100\n",
      "470/470 [==============================] - 0s 123us/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.1628 - val_accuracy: 0.9604\n",
      "Epoch 43/100\n",
      "470/470 [==============================] - 0s 124us/step - loss: 0.0053 - accuracy: 0.9979 - val_loss: 0.1411 - val_accuracy: 0.9653\n",
      "Epoch 44/100\n",
      "470/470 [==============================] - 0s 122us/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.1647 - val_accuracy: 0.9604\n",
      "Epoch 45/100\n",
      "470/470 [==============================] - 0s 119us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.1674 - val_accuracy: 0.9604\n",
      "Epoch 46/100\n",
      "470/470 [==============================] - 0s 117us/step - loss: 0.0050 - accuracy: 0.9979 - val_loss: 0.1440 - val_accuracy: 0.9653\n",
      "Epoch 47/100\n",
      "470/470 [==============================] - 0s 124us/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.1674 - val_accuracy: 0.9604\n",
      "Epoch 48/100\n",
      "470/470 [==============================] - 0s 120us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.1771 - val_accuracy: 0.9505\n",
      "Epoch 49/100\n",
      "470/470 [==============================] - 0s 236us/step - loss: 0.0055 - accuracy: 0.9979 - val_loss: 0.1404 - val_accuracy: 0.9653\n",
      "Epoch 50/100\n",
      "470/470 [==============================] - 0s 175us/step - loss: 0.0074 - accuracy: 0.9979 - val_loss: 0.1688 - val_accuracy: 0.9554\n",
      "Epoch 51/100\n",
      "470/470 [==============================] - 0s 255us/step - loss: 0.0156 - accuracy: 0.9936 - val_loss: 0.2698 - val_accuracy: 0.9356\n",
      "Epoch 52/100\n",
      "470/470 [==============================] - 0s 589us/step - loss: 0.0103 - accuracy: 0.9979 - val_loss: 0.2085 - val_accuracy: 0.9554\n",
      "Epoch 53/100\n",
      "470/470 [==============================] - 0s 222us/step - loss: 0.0074 - accuracy: 0.9979 - val_loss: 0.1843 - val_accuracy: 0.9554\n",
      "Epoch 54/100\n",
      "470/470 [==============================] - 0s 247us/step - loss: 0.0603 - accuracy: 0.9915 - val_loss: 0.1887 - val_accuracy: 0.9505\n",
      "Epoch 55/100\n",
      "470/470 [==============================] - 0s 235us/step - loss: 0.3690 - accuracy: 0.9468 - val_loss: 0.4005 - val_accuracy: 0.9505\n",
      "Epoch 56/100\n",
      "470/470 [==============================] - 0s 250us/step - loss: 0.0889 - accuracy: 0.9809 - val_loss: 0.2489 - val_accuracy: 0.9059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "470/470 [==============================] - 0s 233us/step - loss: 0.0418 - accuracy: 0.9830 - val_loss: 0.1800 - val_accuracy: 0.9554\n",
      "Epoch 58/100\n",
      "470/470 [==============================] - 0s 234us/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.1400 - val_accuracy: 0.9604\n",
      "Epoch 59/100\n",
      "470/470 [==============================] - 0s 178us/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.1711 - val_accuracy: 0.9604\n",
      "Epoch 60/100\n",
      "470/470 [==============================] - 0s 203us/step - loss: 0.0052 - accuracy: 0.9979 - val_loss: 0.1386 - val_accuracy: 0.9604\n",
      "Epoch 61/100\n",
      "470/470 [==============================] - 0s 198us/step - loss: 0.0062 - accuracy: 0.9979 - val_loss: 0.1421 - val_accuracy: 0.9604\n",
      "Epoch 62/100\n",
      "470/470 [==============================] - 0s 228us/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.1942 - val_accuracy: 0.9554\n",
      "Epoch 63/100\n",
      "470/470 [==============================] - 0s 186us/step - loss: 0.0092 - accuracy: 0.9979 - val_loss: 0.1108 - val_accuracy: 0.9653\n",
      "Epoch 64/100\n",
      "470/470 [==============================] - 0s 213us/step - loss: 0.0067 - accuracy: 0.9979 - val_loss: 0.1742 - val_accuracy: 0.9604\n",
      "Epoch 65/100\n",
      "470/470 [==============================] - 0s 286us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.1486 - val_accuracy: 0.9604\n",
      "Epoch 66/100\n",
      "470/470 [==============================] - 0s 234us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.1521 - val_accuracy: 0.9604\n",
      "Epoch 67/100\n",
      "470/470 [==============================] - 0s 365us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.1481 - val_accuracy: 0.9604\n",
      "Epoch 68/100\n",
      "470/470 [==============================] - 0s 219us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.1546 - val_accuracy: 0.9604\n",
      "Epoch 69/100\n",
      "470/470 [==============================] - 0s 187us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.1582 - val_accuracy: 0.9604\n",
      "Epoch 70/100\n",
      "470/470 [==============================] - 0s 181us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1575 - val_accuracy: 0.9604\n",
      "Epoch 71/100\n",
      "470/470 [==============================] - 0s 207us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.1547 - val_accuracy: 0.9604\n",
      "Epoch 72/100\n",
      "470/470 [==============================] - 0s 249us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1620 - val_accuracy: 0.9604\n",
      "Epoch 73/100\n",
      "470/470 [==============================] - 0s 223us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.1620 - val_accuracy: 0.9604\n",
      "Epoch 74/100\n",
      "470/470 [==============================] - 0s 194us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.1536 - val_accuracy: 0.9604\n",
      "Epoch 75/100\n",
      "470/470 [==============================] - 0s 194us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1653 - val_accuracy: 0.9604\n",
      "Epoch 76/100\n",
      "470/470 [==============================] - 0s 195us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.1543 - val_accuracy: 0.9604\n",
      "Epoch 77/100\n",
      "470/470 [==============================] - 0s 232us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.1638 - val_accuracy: 0.9604\n",
      "Epoch 78/100\n",
      "470/470 [==============================] - 0s 209us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.1617 - val_accuracy: 0.9604\n",
      "Epoch 79/100\n",
      "470/470 [==============================] - 0s 207us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1734 - val_accuracy: 0.9604\n",
      "Epoch 80/100\n",
      "470/470 [==============================] - 0s 194us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1654 - val_accuracy: 0.9604\n",
      "Epoch 81/100\n",
      "470/470 [==============================] - 0s 198us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1628 - val_accuracy: 0.9604\n",
      "Epoch 82/100\n",
      "470/470 [==============================] - 0s 210us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1698 - val_accuracy: 0.9604\n",
      "Epoch 83/100\n",
      "470/470 [==============================] - 0s 219us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.1483 - val_accuracy: 0.9653\n",
      "Epoch 84/100\n",
      "470/470 [==============================] - 0s 163us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1699 - val_accuracy: 0.9604\n",
      "Epoch 85/100\n",
      "470/470 [==============================] - 0s 249us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1757 - val_accuracy: 0.9604\n",
      "Epoch 86/100\n",
      "470/470 [==============================] - 0s 233us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.1615 - val_accuracy: 0.9653\n",
      "Epoch 87/100\n",
      "470/470 [==============================] - 0s 215us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.1821 - val_accuracy: 0.9604\n",
      "Epoch 88/100\n",
      "470/470 [==============================] - 0s 271us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1679 - val_accuracy: 0.9653\n",
      "Epoch 89/100\n",
      "470/470 [==============================] - 0s 214us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1531 - val_accuracy: 0.9653\n",
      "Epoch 90/100\n",
      "470/470 [==============================] - 0s 200us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1648 - val_accuracy: 0.9653\n",
      "Epoch 91/100\n",
      "470/470 [==============================] - 0s 213us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1675 - val_accuracy: 0.9653\n",
      "Epoch 92/100\n",
      "470/470 [==============================] - 0s 186us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1731 - val_accuracy: 0.9653\n",
      "Epoch 93/100\n",
      "470/470 [==============================] - 0s 210us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1615 - val_accuracy: 0.9653\n",
      "Epoch 94/100\n",
      "470/470 [==============================] - 0s 219us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.1694 - val_accuracy: 0.9653\n",
      "Epoch 95/100\n",
      "470/470 [==============================] - 0s 196us/step - loss: 0.0114 - accuracy: 0.9979 - val_loss: 0.2232 - val_accuracy: 0.9505\n",
      "Epoch 96/100\n",
      "470/470 [==============================] - 0s 178us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.1759 - val_accuracy: 0.9653\n",
      "Epoch 97/100\n",
      "470/470 [==============================] - 0s 188us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1688 - val_accuracy: 0.9653\n",
      "Epoch 98/100\n",
      "470/470 [==============================] - 0s 352us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1664 - val_accuracy: 0.9653\n",
      "Epoch 99/100\n",
      "470/470 [==============================] - 0s 221us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1671 - val_accuracy: 0.9653\n",
      "Epoch 100/100\n",
      "470/470 [==============================] - 0s 355us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1786 - val_accuracy: 0.9653\n"
     ]
    }
   ],
   "source": [
    "hist1_over2 = model1_over2.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 99.81%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over2.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba2 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_2.xlsx\",\n",
    "                        sheet_name=1,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>1.748042e-03</td>\n",
       "      <td>9.981960e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>BCH-SA-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.712007</td>\n",
       "      <td>2.879924e-01</td>\n",
       "      <td>9.646217e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS218</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.006222</td>\n",
       "      <td>9.937732e-01</td>\n",
       "      <td>4.482882e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS036</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.882617</td>\n",
       "      <td>1.173831e-01</td>\n",
       "      <td>2.310933e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS386</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.571179</td>\n",
       "      <td>4.288184e-01</td>\n",
       "      <td>2.444667e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4279</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS112</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001860</td>\n",
       "      <td>9.979747e-01</td>\n",
       "      <td>1.653396e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4280</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>SR1065</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.982940</td>\n",
       "      <td>1.705227e-02</td>\n",
       "      <td>7.349168e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4281</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS203</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.997093</td>\n",
       "      <td>1.962516e-03</td>\n",
       "      <td>9.441347e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4282</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>CFBREBSa129</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.031141e-13</td>\n",
       "      <td>3.208205e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4283</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>CFBRSa25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999833</td>\n",
       "      <td>1.669456e-04</td>\n",
       "      <td>4.411099e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4284 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    phage       strain  phenotype  prediction         0  \\\n",
       "0      p002ykpresabs_qual       NRS148          2           2  0.000056   \n",
       "1      p002ykpresabs_qual    BCH-SA-03          1           0  0.712007   \n",
       "2      p002ykpresabs_qual       NRS218          1           1  0.006222   \n",
       "3      p002ykpresabs_qual       NRS036          0           0  0.882617   \n",
       "4      p002ykpresabs_qual       NRS386          1           0  0.571179   \n",
       "...                   ...          ...        ...         ...       ...   \n",
       "4279  pyopresabsSTCC_qual       NRS112          1           1  0.001860   \n",
       "4280  pyopresabsSTCC_qual       SR1065          0           0  0.982940   \n",
       "4281  pyopresabsSTCC_qual       NRS203          0           0  0.997093   \n",
       "4282  pyopresabsSTCC_qual  CFBREBSa129          0           0  1.000000   \n",
       "4283  pyopresabsSTCC_qual     CFBRSa25          0           0  0.999833   \n",
       "\n",
       "                 1             2  \n",
       "0     1.748042e-03  9.981960e-01  \n",
       "1     2.879924e-01  9.646217e-07  \n",
       "2     9.937732e-01  4.482882e-06  \n",
       "3     1.173831e-01  2.310933e-10  \n",
       "4     4.288184e-01  2.444667e-06  \n",
       "...            ...           ...  \n",
       "4279  9.979747e-01  1.653396e-04  \n",
       "4280  1.705227e-02  7.349168e-06  \n",
       "4281  1.962516e-03  9.441347e-04  \n",
       "4282  3.031141e-13  3.208205e-09  \n",
       "4283  1.669456e-04  4.411099e-08  \n",
       "\n",
       "[4284 rows x 7 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.99990100e-01, 9.44159700e-06, 4.88248900e-07],\n",
       "       [9.99641540e-01, 3.58473360e-04, 4.24843660e-10],\n",
       "       [9.22508540e-02, 9.07733600e-01, 1.54707740e-05],\n",
       "       [3.47789580e-04, 5.22496470e-04, 9.99129700e-01],\n",
       "       [8.50535700e-08, 2.79327240e-04, 9.99720500e-01],\n",
       "       [3.47789580e-04, 5.22496470e-04, 9.99129700e-01],\n",
       "       [8.50535700e-08, 2.79327240e-04, 9.99720500e-01],\n",
       "       [2.94126900e-05, 9.99071100e-01, 8.99392900e-04],\n",
       "       [8.50535700e-08, 2.79327240e-04, 9.99720500e-01],\n",
       "       [2.23307160e-04, 9.53532200e-03, 9.90241350e-01],\n",
       "       [9.99989750e-01, 9.71582500e-06, 4.34336070e-07],\n",
       "       [2.89969840e-03, 9.97099040e-01, 1.32851770e-06],\n",
       "       [9.99998330e-01, 1.53668780e-06, 7.53934900e-08],\n",
       "       [9.95054360e-01, 3.56378830e-03, 1.38182480e-03],\n",
       "       [3.47789580e-04, 5.22496470e-04, 9.99129700e-01],\n",
       "       [9.22508540e-02, 9.07733600e-01, 1.54707740e-05],\n",
       "       [9.98790300e-01, 1.20721850e-03, 2.50849280e-06],\n",
       "       [3.47789580e-04, 5.22496470e-04, 9.99129700e-01],\n",
       "       [6.54026540e-03, 9.93459700e-01, 2.15536720e-11],\n",
       "       [8.50535700e-08, 2.79327240e-04, 9.99720500e-01],\n",
       "       [8.50535700e-08, 2.79327240e-04, 9.99720500e-01],\n",
       "       [8.50535700e-08, 2.79327240e-04, 9.99720500e-01],\n",
       "       [9.99913450e-01, 8.57664400e-05, 7.36837800e-07],\n",
       "       [2.23307160e-04, 9.53532200e-03, 9.90241350e-01],\n",
       "       [9.99787300e-01, 2.11032140e-04, 1.64330820e-06],\n",
       "       [1.52561525e-02, 9.84741750e-01, 2.06448600e-06],\n",
       "       [2.23307160e-04, 9.53532200e-03, 9.90241350e-01],\n",
       "       [3.47789580e-04, 5.22496470e-04, 9.99129700e-01],\n",
       "       [2.23307160e-04, 9.53532200e-03, 9.90241350e-01],\n",
       "       [8.50535700e-08, 2.79327240e-04, 9.99720500e-01],\n",
       "       [9.99827400e-01, 1.72560530e-04, 5.41398280e-11],\n",
       "       [3.61754770e-03, 9.96380030e-01, 2.54461200e-06],\n",
       "       [9.99998800e-01, 1.23392820e-06, 3.77675600e-12],\n",
       "       [9.82834600e-01, 1.71515010e-02, 1.39164310e-05],\n",
       "       [6.12663400e-03, 9.91690160e-01, 2.18318780e-03],\n",
       "       [6.12663400e-03, 9.91690160e-01, 2.18318780e-03],\n",
       "       [3.89379940e-03, 9.96099950e-01, 6.28777400e-06],\n",
       "       [9.99982500e-01, 1.68301520e-05, 6.61765970e-07],\n",
       "       [7.36331300e-02, 9.26366900e-01, 1.54663250e-09],\n",
       "       [1.53126190e-02, 9.84683330e-01, 3.97886470e-06],\n",
       "       [3.47789580e-04, 5.22496470e-04, 9.99129700e-01],\n",
       "       [9.99991400e-01, 8.62529500e-06, 9.56120600e-12],\n",
       "       [1.41961430e-02, 9.85803840e-01, 1.64270750e-10],\n",
       "       [9.95316740e-01, 4.65443030e-03, 2.88718170e-05],\n",
       "       [8.50535700e-08, 2.79327240e-04, 9.99720500e-01],\n",
       "       [9.96143040e-01, 3.83974450e-03, 1.71808350e-05],\n",
       "       [2.21412380e-01, 7.76665500e-01, 1.92215180e-03],\n",
       "       [8.50535700e-08, 2.79327240e-04, 9.99720500e-01],\n",
       "       [8.50535700e-08, 2.79327240e-04, 9.99720500e-01],\n",
       "       [8.50535700e-08, 2.79327240e-04, 9.99720500e-01],\n",
       "       [5.53894700e-02, 9.44596700e-01, 1.38809690e-05],\n",
       "       [9.96705830e-01, 3.09939520e-03, 1.94709380e-04],\n",
       "       [9.99815050e-01, 1.46689810e-04, 3.83001280e-05],\n",
       "       [2.23307160e-04, 9.53532200e-03, 9.90241350e-01],\n",
       "       [3.47789580e-04, 5.22496470e-04, 9.99129700e-01],\n",
       "       [2.23829400e-02, 9.77501900e-01, 1.15165225e-04],\n",
       "       [7.24450300e-03, 9.92755500e-01, 9.14553200e-09],\n",
       "       [2.23307160e-04, 9.53532200e-03, 9.90241350e-01],\n",
       "       [9.99998570e-01, 2.24892050e-07, 1.16517730e-06],\n",
       "       [8.50535700e-08, 2.79327240e-04, 9.99720500e-01],\n",
       "       [9.99999050e-01, 9.76041500e-07, 3.29527730e-08],\n",
       "       [9.96674200e-01, 3.32269840e-03, 3.05718400e-06],\n",
       "       [7.80448800e-04, 9.59785900e-01, 3.94337400e-02],\n",
       "       [4.64059140e-01, 5.35940800e-01, 7.62440400e-09],\n",
       "       [1.41961430e-02, 9.85803840e-01, 1.64270750e-10],\n",
       "       [5.53894700e-02, 9.44596700e-01, 1.38809690e-05],\n",
       "       [9.22508540e-02, 9.07733600e-01, 1.54707740e-05],\n",
       "       [3.47789580e-04, 5.22496470e-04, 9.99129700e-01],\n",
       "       [2.67869740e-01, 7.32085300e-01, 4.49392600e-05],\n",
       "       [2.23307160e-04, 9.53532200e-03, 9.90241350e-01],\n",
       "       [9.96945800e-01, 3.02481700e-03, 2.93000320e-05],\n",
       "       [1.53126190e-02, 9.84683330e-01, 3.97886470e-06],\n",
       "       [3.47789580e-04, 5.22496470e-04, 9.99129700e-01],\n",
       "       [6.12663400e-03, 9.91690160e-01, 2.18318780e-03],\n",
       "       [9.98410100e-01, 1.47060170e-03, 1.19315140e-04],\n",
       "       [9.99888900e-01, 1.11081010e-04, 1.72333290e-10],\n",
       "       [6.12663400e-03, 9.91690160e-01, 2.18318780e-03],\n",
       "       [2.94126900e-05, 9.99071100e-01, 8.99392900e-04],\n",
       "       [2.23307160e-04, 9.53532200e-03, 9.90241350e-01],\n",
       "       [2.89969840e-03, 9.97099040e-01, 1.32851770e-06],\n",
       "       [5.53894700e-02, 9.44596700e-01, 1.38809690e-05],\n",
       "       [2.23307160e-04, 9.53532200e-03, 9.90241350e-01],\n",
       "       [9.99999900e-01, 9.32689450e-08, 8.87041040e-13],\n",
       "       [9.99495500e-01, 5.04483500e-04, 5.44318840e-12],\n",
       "       [7.36331300e-02, 9.26366900e-01, 1.54663250e-09],\n",
       "       [9.99807540e-01, 1.78520730e-04, 1.39898400e-05],\n",
       "       [9.01015940e-01, 9.89840900e-02, 1.62696200e-10],\n",
       "       [4.70983400e-04, 9.99528770e-01, 2.72367940e-07],\n",
       "       [4.46099760e-04, 9.99323370e-01, 2.30522770e-04],\n",
       "       [8.50535700e-08, 2.79327240e-04, 9.99720500e-01],\n",
       "       [9.97621950e-01, 2.37809210e-03, 1.89712400e-10],\n",
       "       [4.70983400e-04, 9.99528770e-01, 2.72367940e-07],\n",
       "       [3.47789580e-04, 5.22496470e-04, 9.99129700e-01],\n",
       "       [2.97422040e-02, 9.70229700e-01, 2.80759540e-05],\n",
       "       [6.46207450e-01, 3.37609560e-01, 1.61830500e-02],\n",
       "       [2.94126900e-05, 9.99071100e-01, 8.99392900e-04],\n",
       "       [9.99992000e-01, 5.73892500e-06, 2.23786290e-06],\n",
       "       [2.23307160e-04, 9.53532200e-03, 9.90241350e-01],\n",
       "       [1.00000000e+00, 3.68359780e-08, 2.35757300e-13],\n",
       "       [6.12663400e-03, 9.91690160e-01, 2.18318780e-03],\n",
       "       [5.53894700e-02, 9.44596700e-01, 1.38809690e-05],\n",
       "       [1.41961430e-02, 9.85803840e-01, 1.64270750e-10],\n",
       "       [1.52561525e-02, 9.84741750e-01, 2.06448600e-06],\n",
       "       [2.23307160e-04, 9.53532200e-03, 9.90241350e-01],\n",
       "       [3.47789580e-04, 5.22496470e-04, 9.99129700e-01],\n",
       "       [2.97422040e-02, 9.70229700e-01, 2.80759540e-05],\n",
       "       [9.99939440e-01, 6.03249650e-05, 2.65616600e-07],\n",
       "       [9.99982240e-01, 1.77058630e-05, 1.48503630e-10],\n",
       "       [3.89379940e-03, 9.96099950e-01, 6.28777400e-06],\n",
       "       [9.94753840e-01, 5.23050870e-03, 1.57024970e-05],\n",
       "       [2.23307160e-04, 9.53532200e-03, 9.90241350e-01],\n",
       "       [9.80745300e-01, 1.87416110e-02, 5.13026670e-04],\n",
       "       [7.80448800e-04, 9.59785900e-01, 3.94337400e-02],\n",
       "       [7.98250800e-03, 9.92014400e-01, 3.12736800e-06],\n",
       "       [4.46099760e-04, 9.99323370e-01, 2.30522770e-04],\n",
       "       [8.50535700e-08, 2.79327240e-04, 9.99720500e-01],\n",
       "       [9.99915360e-01, 8.42994050e-05, 3.21806080e-07],\n",
       "       [3.47789580e-04, 5.22496470e-04, 9.99129700e-01],\n",
       "       [7.36331300e-02, 9.26366900e-01, 1.54663250e-09],\n",
       "       [1.52561525e-02, 9.84741750e-01, 2.06448600e-06],\n",
       "       [9.99997000e-01, 3.00195260e-06, 4.26476700e-10],\n",
       "       [3.47789580e-04, 5.22496470e-04, 9.99129700e-01],\n",
       "       [2.95506420e-02, 9.70387500e-01, 6.19159600e-05],\n",
       "       [7.36331300e-02, 9.26366900e-01, 1.54663250e-09],\n",
       "       [9.99901530e-01, 9.84991900e-05, 2.38699340e-10],\n",
       "       [2.23829400e-02, 9.77501900e-01, 1.15165225e-04],\n",
       "       [9.99675750e-01, 3.24286520e-04, 3.97960000e-12],\n",
       "       [9.97713200e-01, 2.28567930e-03, 1.11327670e-06],\n",
       "       [9.99091500e-01, 9.08118030e-04, 3.63346970e-07],\n",
       "       [3.47789580e-04, 5.22496470e-04, 9.99129700e-01],\n",
       "       [7.24450300e-03, 9.92755500e-01, 9.14553200e-09],\n",
       "       [2.89969840e-03, 9.97099040e-01, 1.32851770e-06],\n",
       "       [7.80448800e-04, 9.59785900e-01, 3.94337400e-02],\n",
       "       [9.84728900e-01, 1.52056890e-02, 6.53343000e-05],\n",
       "       [1.01585730e-02, 9.89799600e-01, 4.18463680e-05],\n",
       "       [3.89379940e-03, 9.96099950e-01, 6.28777400e-06],\n",
       "       [4.46099760e-04, 9.99323370e-01, 2.30522770e-04],\n",
       "       [2.23829400e-02, 9.77501900e-01, 1.15165225e-04],\n",
       "       [2.23307160e-04, 9.53532200e-03, 9.90241350e-01],\n",
       "       [2.23307160e-04, 9.53532200e-03, 9.90241350e-01],\n",
       "       [9.99919900e-01, 8.00980050e-05, 6.71358100e-12],\n",
       "       [3.47789580e-04, 5.22496470e-04, 9.99129700e-01],\n",
       "       [9.99991540e-01, 8.27336100e-06, 2.28803500e-07],\n",
       "       [3.47789580e-04, 5.22496470e-04, 9.99129700e-01],\n",
       "       [8.50535700e-08, 2.79327240e-04, 9.99720500e-01],\n",
       "       [9.99913000e-01, 6.85109200e-05, 1.84528690e-05],\n",
       "       [6.12663400e-03, 9.91690160e-01, 2.18318780e-03],\n",
       "       [8.50535700e-08, 2.79327240e-04, 9.99720500e-01],\n",
       "       [5.48982200e-01, 4.50826440e-01, 1.91282030e-04],\n",
       "       [9.99721100e-01, 2.78831840e-04, 1.78436340e-10],\n",
       "       [9.10046200e-03, 9.89715750e-01, 1.18386990e-03],\n",
       "       [8.50535700e-08, 2.79327240e-04, 9.99720500e-01],\n",
       "       [8.50535700e-08, 2.79327240e-04, 9.99720500e-01],\n",
       "       [3.47789580e-04, 5.22496470e-04, 9.99129700e-01],\n",
       "       [9.99991060e-01, 8.98091000e-06, 1.84233230e-09],\n",
       "       [3.47789580e-04, 5.22496470e-04, 9.99129700e-01],\n",
       "       [7.24450300e-03, 9.92755500e-01, 9.14553200e-09],\n",
       "       [1.47896130e-01, 8.52081400e-01, 2.24536230e-05],\n",
       "       [9.97987400e-01, 2.01166000e-03, 9.81137500e-07],\n",
       "       [8.50535700e-08, 2.79327240e-04, 9.99720500e-01],\n",
       "       [8.50535700e-08, 2.79327240e-04, 9.99720500e-01],\n",
       "       [2.23307160e-04, 9.53532200e-03, 9.90241350e-01],\n",
       "       [9.10046200e-03, 9.89715750e-01, 1.18386990e-03],\n",
       "       [7.36331300e-02, 9.26366900e-01, 1.54663250e-09],\n",
       "       [9.94494140e-01, 5.50389940e-03, 1.90131770e-06],\n",
       "       [3.47789580e-04, 5.22496470e-04, 9.99129700e-01],\n",
       "       [3.61754770e-03, 9.96380030e-01, 2.54461200e-06],\n",
       "       [8.50535700e-08, 2.79327240e-04, 9.99720500e-01],\n",
       "       [9.97638200e-01, 2.35935770e-03, 2.36049160e-06],\n",
       "       [9.99954700e-01, 4.43612900e-05, 1.00978680e-06],\n",
       "       [8.50535700e-08, 2.79327240e-04, 9.99720500e-01],\n",
       "       [9.99998450e-01, 8.01347100e-07, 7.09366700e-07],\n",
       "       [3.47789580e-04, 5.22496470e-04, 9.99129700e-01],\n",
       "       [8.50535700e-08, 2.79327240e-04, 9.99720500e-01],\n",
       "       [8.50535700e-08, 2.79327240e-04, 9.99720500e-01],\n",
       "       [7.24450300e-03, 9.92755500e-01, 9.14553200e-09],\n",
       "       [6.12663400e-03, 9.91690160e-01, 2.18318780e-03],\n",
       "       [7.04321840e-04, 9.99294400e-01, 1.34178300e-06],\n",
       "       [3.47789580e-04, 5.22496470e-04, 9.99129700e-01],\n",
       "       [1.07916820e-03, 9.98884000e-01, 3.68290530e-05],\n",
       "       [3.47789580e-04, 5.22496470e-04, 9.99129700e-01],\n",
       "       [7.80546370e-01, 2.19453320e-01, 4.00317080e-07],\n",
       "       [7.36331300e-02, 9.26366900e-01, 1.54663250e-09],\n",
       "       [9.99991540e-01, 8.27336100e-06, 2.28803500e-07],\n",
       "       [3.61754770e-03, 9.96380030e-01, 2.54461200e-06],\n",
       "       [3.47789580e-04, 5.22496470e-04, 9.99129700e-01],\n",
       "       [7.17116100e-02, 9.28166800e-01, 1.21612225e-04],\n",
       "       [8.50535700e-08, 2.79327240e-04, 9.99720500e-01],\n",
       "       [2.97422040e-02, 9.70229700e-01, 2.80759540e-05],\n",
       "       [8.38415700e-01, 1.61583230e-01, 1.10216260e-06],\n",
       "       [9.99472200e-01, 5.15743000e-04, 1.19920340e-05],\n",
       "       [9.99480200e-01, 5.16336700e-04, 3.44635000e-06],\n",
       "       [9.01536900e-01, 9.84351200e-02, 2.78928260e-05],\n",
       "       [7.80449540e-04, 9.59785900e-01, 3.94337400e-02],\n",
       "       [8.50535700e-08, 2.79326980e-04, 9.99720500e-01],\n",
       "       [8.50535700e-08, 2.79326980e-04, 9.99720500e-01],\n",
       "       [2.97421890e-02, 9.70229700e-01, 2.80760070e-05],\n",
       "       [9.98470250e-01, 1.51901100e-03, 1.06862210e-05],\n",
       "       [3.47789230e-04, 5.22495400e-04, 9.99129700e-01],\n",
       "       [7.24451000e-03, 9.92755500e-01, 9.14555000e-09],\n",
       "       [8.50535700e-08, 2.79326980e-04, 9.99720500e-01],\n",
       "       [9.99997260e-01, 1.91235130e-06, 8.88935000e-07]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob2 = df_proba2[df_proba2['phage']=='p003ppresabsSTCC_qual'].iloc[:,-3:]\n",
    "y_prob2 = y_prob2.to_numpy()\n",
    "y_prob2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9952614379084967"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo2 = rocauc_ovo(y_test_over, y_prob2, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9952614379084967"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr2 = rocauc_ovr(y_test_over, y_prob2, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=345,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat3 = pd.DataFrame(X_test_over[:,0])\n",
    "dat3['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS187</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CFBREBSa116</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS187</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>GA12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>NRS265</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>NRS253</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>SR4187</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test\n",
       "0         NRS148     2\n",
       "1         NRS209     2\n",
       "2         NRS187     1\n",
       "3    CFBREBSa116     0\n",
       "4         NRS187     1\n",
       "..           ...   ...\n",
       "197         GA12     0\n",
       "198       NRS209     2\n",
       "199       NRS265     1\n",
       "200       NRS253     1\n",
       "201       SR4187     0\n",
       "\n",
       "[202 rows x 2 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over3 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],)),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over3.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 470 samples, validate on 202 samples\n",
      "Epoch 1/100\n",
      "470/470 [==============================] - 0s 362us/step - loss: 2.1068 - accuracy: 0.5000 - val_loss: 1.3162 - val_accuracy: 0.5297\n",
      "Epoch 2/100\n",
      "470/470 [==============================] - 0s 150us/step - loss: 0.8341 - accuracy: 0.6574 - val_loss: 0.5909 - val_accuracy: 0.7277\n",
      "Epoch 3/100\n",
      "470/470 [==============================] - 0s 263us/step - loss: 0.4848 - accuracy: 0.8106 - val_loss: 0.4510 - val_accuracy: 0.7970\n",
      "Epoch 4/100\n",
      "470/470 [==============================] - 0s 274us/step - loss: 0.4051 - accuracy: 0.8426 - val_loss: 0.3643 - val_accuracy: 0.8812\n",
      "Epoch 5/100\n",
      "470/470 [==============================] - 0s 239us/step - loss: 0.3350 - accuracy: 0.8851 - val_loss: 0.3231 - val_accuracy: 0.8762\n",
      "Epoch 6/100\n",
      "470/470 [==============================] - 0s 267us/step - loss: 0.2890 - accuracy: 0.9191 - val_loss: 0.3030 - val_accuracy: 0.9059\n",
      "Epoch 7/100\n",
      "470/470 [==============================] - 0s 188us/step - loss: 0.2773 - accuracy: 0.9191 - val_loss: 0.2907 - val_accuracy: 0.9356\n",
      "Epoch 8/100\n",
      "470/470 [==============================] - 0s 176us/step - loss: 0.2449 - accuracy: 0.9383 - val_loss: 0.2472 - val_accuracy: 0.9307\n",
      "Epoch 9/100\n",
      "470/470 [==============================] - 0s 234us/step - loss: 0.2304 - accuracy: 0.9426 - val_loss: 0.2659 - val_accuracy: 0.8960\n",
      "Epoch 10/100\n",
      "470/470 [==============================] - 0s 207us/step - loss: 0.2370 - accuracy: 0.9362 - val_loss: 0.2694 - val_accuracy: 0.9455\n",
      "Epoch 11/100\n",
      "470/470 [==============================] - 0s 143us/step - loss: 0.2003 - accuracy: 0.9447 - val_loss: 0.2120 - val_accuracy: 0.9505\n",
      "Epoch 12/100\n",
      "470/470 [==============================] - 0s 401us/step - loss: 0.1832 - accuracy: 0.9553 - val_loss: 0.1874 - val_accuracy: 0.9356\n",
      "Epoch 13/100\n",
      "470/470 [==============================] - 0s 175us/step - loss: 0.1672 - accuracy: 0.9553 - val_loss: 0.2134 - val_accuracy: 0.9505\n",
      "Epoch 14/100\n",
      "470/470 [==============================] - 0s 342us/step - loss: 0.1893 - accuracy: 0.9574 - val_loss: 0.1743 - val_accuracy: 0.9455\n",
      "Epoch 15/100\n",
      "470/470 [==============================] - 0s 227us/step - loss: 0.1763 - accuracy: 0.9511 - val_loss: 0.1951 - val_accuracy: 0.9455\n",
      "Epoch 16/100\n",
      "470/470 [==============================] - 0s 243us/step - loss: 0.1686 - accuracy: 0.9447 - val_loss: 0.1832 - val_accuracy: 0.9406\n",
      "Epoch 17/100\n",
      "470/470 [==============================] - 0s 173us/step - loss: 0.1427 - accuracy: 0.9617 - val_loss: 0.1438 - val_accuracy: 0.9554\n",
      "Epoch 18/100\n",
      "470/470 [==============================] - 0s 137us/step - loss: 0.1268 - accuracy: 0.9638 - val_loss: 0.1350 - val_accuracy: 0.9406\n",
      "Epoch 19/100\n",
      "470/470 [==============================] - 0s 118us/step - loss: 0.1243 - accuracy: 0.9702 - val_loss: 0.1306 - val_accuracy: 0.9653\n",
      "Epoch 20/100\n",
      "470/470 [==============================] - 0s 126us/step - loss: 0.1171 - accuracy: 0.9723 - val_loss: 0.1348 - val_accuracy: 0.9505\n",
      "Epoch 21/100\n",
      "470/470 [==============================] - 0s 186us/step - loss: 0.1192 - accuracy: 0.9745 - val_loss: 0.1320 - val_accuracy: 0.9703\n",
      "Epoch 22/100\n",
      "470/470 [==============================] - 0s 472us/step - loss: 0.1047 - accuracy: 0.9702 - val_loss: 0.1120 - val_accuracy: 0.9554\n",
      "Epoch 23/100\n",
      "470/470 [==============================] - 0s 265us/step - loss: 0.1011 - accuracy: 0.9723 - val_loss: 0.1079 - val_accuracy: 0.9554\n",
      "Epoch 24/100\n",
      "470/470 [==============================] - 0s 236us/step - loss: 0.1038 - accuracy: 0.9766 - val_loss: 0.1020 - val_accuracy: 0.9554\n",
      "Epoch 25/100\n",
      "470/470 [==============================] - 0s 272us/step - loss: 0.1002 - accuracy: 0.9809 - val_loss: 0.1568 - val_accuracy: 0.9505\n",
      "Epoch 26/100\n",
      "470/470 [==============================] - 0s 347us/step - loss: 0.1231 - accuracy: 0.9723 - val_loss: 0.0922 - val_accuracy: 0.9653\n",
      "Epoch 27/100\n",
      "470/470 [==============================] - 0s 355us/step - loss: 0.0898 - accuracy: 0.9723 - val_loss: 0.0896 - val_accuracy: 0.9752\n",
      "Epoch 28/100\n",
      "470/470 [==============================] - 0s 348us/step - loss: 0.0830 - accuracy: 0.9809 - val_loss: 0.0907 - val_accuracy: 0.9604\n",
      "Epoch 29/100\n",
      "470/470 [==============================] - 0s 178us/step - loss: 0.0730 - accuracy: 0.9851 - val_loss: 0.0897 - val_accuracy: 0.9752\n",
      "Epoch 30/100\n",
      "470/470 [==============================] - 0s 389us/step - loss: 0.0702 - accuracy: 0.9830 - val_loss: 0.0828 - val_accuracy: 0.9851\n",
      "Epoch 31/100\n",
      "470/470 [==============================] - 0s 154us/step - loss: 0.0676 - accuracy: 0.9915 - val_loss: 0.0969 - val_accuracy: 0.9554\n",
      "Epoch 32/100\n",
      "470/470 [==============================] - 0s 128us/step - loss: 0.0728 - accuracy: 0.9830 - val_loss: 0.0957 - val_accuracy: 0.9653\n",
      "Epoch 33/100\n",
      "470/470 [==============================] - 0s 114us/step - loss: 0.0738 - accuracy: 0.9872 - val_loss: 0.1023 - val_accuracy: 0.9604\n",
      "Epoch 34/100\n",
      "470/470 [==============================] - 0s 126us/step - loss: 0.0737 - accuracy: 0.9809 - val_loss: 0.0795 - val_accuracy: 0.9752\n",
      "Epoch 35/100\n",
      "470/470 [==============================] - 0s 120us/step - loss: 0.0681 - accuracy: 0.9851 - val_loss: 0.0871 - val_accuracy: 0.9752\n",
      "Epoch 36/100\n",
      "470/470 [==============================] - 0s 120us/step - loss: 0.0655 - accuracy: 0.9830 - val_loss: 0.0656 - val_accuracy: 0.9851\n",
      "Epoch 37/100\n",
      "470/470 [==============================] - 0s 258us/step - loss: 0.0632 - accuracy: 0.9872 - val_loss: 0.0697 - val_accuracy: 0.9604\n",
      "Epoch 38/100\n",
      "470/470 [==============================] - 0s 385us/step - loss: 0.0605 - accuracy: 0.9830 - val_loss: 0.0839 - val_accuracy: 0.9554\n",
      "Epoch 39/100\n",
      "470/470 [==============================] - 0s 300us/step - loss: 0.0510 - accuracy: 0.9936 - val_loss: 0.0736 - val_accuracy: 0.9752\n",
      "Epoch 40/100\n",
      "470/470 [==============================] - 0s 159us/step - loss: 0.0489 - accuracy: 0.9957 - val_loss: 0.0621 - val_accuracy: 0.9851\n",
      "Epoch 41/100\n",
      "470/470 [==============================] - 0s 121us/step - loss: 0.0495 - accuracy: 0.9936 - val_loss: 0.0632 - val_accuracy: 0.9851\n",
      "Epoch 42/100\n",
      "470/470 [==============================] - 0s 118us/step - loss: 0.0466 - accuracy: 0.9936 - val_loss: 0.0591 - val_accuracy: 0.9703\n",
      "Epoch 43/100\n",
      "470/470 [==============================] - 0s 141us/step - loss: 0.0476 - accuracy: 0.9894 - val_loss: 0.0666 - val_accuracy: 0.9752\n",
      "Epoch 44/100\n",
      "470/470 [==============================] - 0s 196us/step - loss: 0.0445 - accuracy: 0.9894 - val_loss: 0.0898 - val_accuracy: 0.9653\n",
      "Epoch 45/100\n",
      "470/470 [==============================] - 0s 216us/step - loss: 0.0470 - accuracy: 0.9957 - val_loss: 0.0751 - val_accuracy: 0.9752\n",
      "Epoch 46/100\n",
      "470/470 [==============================] - 0s 218us/step - loss: 0.0489 - accuracy: 0.9915 - val_loss: 0.0551 - val_accuracy: 0.9752\n",
      "Epoch 47/100\n",
      "470/470 [==============================] - 0s 175us/step - loss: 0.0387 - accuracy: 0.9957 - val_loss: 0.0684 - val_accuracy: 0.9802\n",
      "Epoch 48/100\n",
      "470/470 [==============================] - 0s 153us/step - loss: 0.0395 - accuracy: 0.9957 - val_loss: 0.0501 - val_accuracy: 0.9851\n",
      "Epoch 49/100\n",
      "470/470 [==============================] - 0s 213us/step - loss: 0.0374 - accuracy: 0.9936 - val_loss: 0.0495 - val_accuracy: 0.9901\n",
      "Epoch 50/100\n",
      "470/470 [==============================] - 0s 146us/step - loss: 0.0354 - accuracy: 0.9957 - val_loss: 0.0783 - val_accuracy: 0.9752\n",
      "Epoch 51/100\n",
      "470/470 [==============================] - 0s 131us/step - loss: 0.0416 - accuracy: 0.9957 - val_loss: 0.0503 - val_accuracy: 0.9851\n",
      "Epoch 52/100\n",
      "470/470 [==============================] - 0s 135us/step - loss: 0.0390 - accuracy: 0.9936 - val_loss: 0.0549 - val_accuracy: 0.9802\n",
      "Epoch 53/100\n",
      "470/470 [==============================] - 0s 137us/step - loss: 0.0340 - accuracy: 0.9957 - val_loss: 0.0558 - val_accuracy: 0.9752\n",
      "Epoch 54/100\n",
      "470/470 [==============================] - 0s 117us/step - loss: 0.0315 - accuracy: 0.9957 - val_loss: 0.0508 - val_accuracy: 0.9851\n",
      "Epoch 55/100\n",
      "470/470 [==============================] - 0s 117us/step - loss: 0.0342 - accuracy: 0.9957 - val_loss: 0.0501 - val_accuracy: 0.9901\n",
      "Epoch 56/100\n",
      "470/470 [==============================] - 0s 113us/step - loss: 0.0303 - accuracy: 0.9957 - val_loss: 0.0577 - val_accuracy: 0.9703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "470/470 [==============================] - 0s 121us/step - loss: 0.0311 - accuracy: 0.9957 - val_loss: 0.0447 - val_accuracy: 0.9901\n",
      "Epoch 58/100\n",
      "470/470 [==============================] - 0s 179us/step - loss: 0.0319 - accuracy: 0.9957 - val_loss: 0.0468 - val_accuracy: 0.9851\n",
      "Epoch 59/100\n",
      "470/470 [==============================] - 0s 136us/step - loss: 0.0284 - accuracy: 0.9957 - val_loss: 0.0466 - val_accuracy: 0.9851\n",
      "Epoch 60/100\n",
      "470/470 [==============================] - 0s 119us/step - loss: 0.0289 - accuracy: 0.9957 - val_loss: 0.0429 - val_accuracy: 0.9851\n",
      "Epoch 61/100\n",
      "470/470 [==============================] - 0s 124us/step - loss: 0.0293 - accuracy: 0.9957 - val_loss: 0.0440 - val_accuracy: 0.9901\n",
      "Epoch 62/100\n",
      "470/470 [==============================] - 0s 193us/step - loss: 0.0284 - accuracy: 0.9957 - val_loss: 0.0500 - val_accuracy: 0.9802\n",
      "Epoch 63/100\n",
      "470/470 [==============================] - 0s 174us/step - loss: 0.0268 - accuracy: 0.9957 - val_loss: 0.0631 - val_accuracy: 0.9703\n",
      "Epoch 64/100\n",
      "470/470 [==============================] - 0s 132us/step - loss: 0.0327 - accuracy: 0.9915 - val_loss: 0.0572 - val_accuracy: 0.9802\n",
      "Epoch 65/100\n",
      "470/470 [==============================] - 0s 134us/step - loss: 0.0303 - accuracy: 0.9957 - val_loss: 0.0418 - val_accuracy: 0.9901\n",
      "Epoch 66/100\n",
      "470/470 [==============================] - 0s 151us/step - loss: 0.0276 - accuracy: 0.9957 - val_loss: 0.0539 - val_accuracy: 0.9752\n",
      "Epoch 67/100\n",
      "470/470 [==============================] - 0s 128us/step - loss: 0.0235 - accuracy: 0.9957 - val_loss: 0.0372 - val_accuracy: 0.9901\n",
      "Epoch 68/100\n",
      "470/470 [==============================] - 0s 138us/step - loss: 0.0221 - accuracy: 0.9957 - val_loss: 0.0511 - val_accuracy: 0.9703\n",
      "Epoch 69/100\n",
      "470/470 [==============================] - 0s 120us/step - loss: 0.0238 - accuracy: 0.9957 - val_loss: 0.0345 - val_accuracy: 0.9901\n",
      "Epoch 70/100\n",
      "470/470 [==============================] - 0s 151us/step - loss: 0.0210 - accuracy: 0.9957 - val_loss: 0.0550 - val_accuracy: 0.9752\n",
      "Epoch 71/100\n",
      "470/470 [==============================] - 0s 161us/step - loss: 0.0219 - accuracy: 0.9957 - val_loss: 0.0386 - val_accuracy: 0.9901\n",
      "Epoch 72/100\n",
      "470/470 [==============================] - 0s 177us/step - loss: 0.0210 - accuracy: 0.9957 - val_loss: 0.0440 - val_accuracy: 0.9851\n",
      "Epoch 73/100\n",
      "470/470 [==============================] - 0s 193us/step - loss: 0.0218 - accuracy: 0.9957 - val_loss: 0.0351 - val_accuracy: 0.9901\n",
      "Epoch 74/100\n",
      "470/470 [==============================] - 0s 135us/step - loss: 0.0212 - accuracy: 0.9957 - val_loss: 0.0518 - val_accuracy: 0.9703\n",
      "Epoch 75/100\n",
      "470/470 [==============================] - 0s 120us/step - loss: 0.0213 - accuracy: 0.9957 - val_loss: 0.0439 - val_accuracy: 0.9851\n",
      "Epoch 76/100\n",
      "470/470 [==============================] - 0s 157us/step - loss: 0.0216 - accuracy: 0.9957 - val_loss: 0.0363 - val_accuracy: 0.9901\n",
      "Epoch 77/100\n",
      "470/470 [==============================] - 0s 138us/step - loss: 0.0200 - accuracy: 0.9979 - val_loss: 0.0577 - val_accuracy: 0.9703\n",
      "Epoch 78/100\n",
      "470/470 [==============================] - 0s 195us/step - loss: 0.0189 - accuracy: 0.9957 - val_loss: 0.0311 - val_accuracy: 0.9901\n",
      "Epoch 79/100\n",
      "470/470 [==============================] - 0s 218us/step - loss: 0.0196 - accuracy: 0.9957 - val_loss: 0.0326 - val_accuracy: 0.9901\n",
      "Epoch 80/100\n",
      "470/470 [==============================] - 0s 166us/step - loss: 0.0188 - accuracy: 0.9957 - val_loss: 0.0459 - val_accuracy: 0.9802\n",
      "Epoch 81/100\n",
      "470/470 [==============================] - 0s 144us/step - loss: 0.0176 - accuracy: 0.9979 - val_loss: 0.0519 - val_accuracy: 0.9703\n",
      "Epoch 82/100\n",
      "470/470 [==============================] - 0s 175us/step - loss: 0.0187 - accuracy: 0.9957 - val_loss: 0.0324 - val_accuracy: 0.9901\n",
      "Epoch 83/100\n",
      "470/470 [==============================] - 0s 190us/step - loss: 0.0173 - accuracy: 0.9957 - val_loss: 0.0368 - val_accuracy: 0.9901\n",
      "Epoch 84/100\n",
      "470/470 [==============================] - 0s 194us/step - loss: 0.0198 - accuracy: 0.9979 - val_loss: 0.0739 - val_accuracy: 0.9604\n",
      "Epoch 85/100\n",
      "470/470 [==============================] - 0s 173us/step - loss: 0.0189 - accuracy: 0.9957 - val_loss: 0.0336 - val_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "470/470 [==============================] - 0s 127us/step - loss: 0.0247 - accuracy: 0.9936 - val_loss: 0.0427 - val_accuracy: 0.9901\n",
      "Epoch 87/100\n",
      "470/470 [==============================] - 0s 130us/step - loss: 0.0163 - accuracy: 0.9957 - val_loss: 0.0456 - val_accuracy: 0.9752\n",
      "Epoch 88/100\n",
      "470/470 [==============================] - 0s 324us/step - loss: 0.0153 - accuracy: 0.9979 - val_loss: 0.0510 - val_accuracy: 0.9703\n",
      "Epoch 89/100\n",
      "470/470 [==============================] - 0s 196us/step - loss: 0.0179 - accuracy: 0.9957 - val_loss: 0.0284 - val_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "470/470 [==============================] - 0s 468us/step - loss: 0.0205 - accuracy: 0.9957 - val_loss: 0.0457 - val_accuracy: 0.9851\n",
      "Epoch 91/100\n",
      "470/470 [==============================] - 0s 300us/step - loss: 0.0179 - accuracy: 1.0000 - val_loss: 0.0800 - val_accuracy: 0.9604\n",
      "Epoch 92/100\n",
      "470/470 [==============================] - 0s 194us/step - loss: 0.0201 - accuracy: 0.9979 - val_loss: 0.0285 - val_accuracy: 0.9851\n",
      "Epoch 93/100\n",
      "470/470 [==============================] - 0s 241us/step - loss: 0.0140 - accuracy: 0.9957 - val_loss: 0.0391 - val_accuracy: 0.9901\n",
      "Epoch 94/100\n",
      "470/470 [==============================] - 0s 183us/step - loss: 0.0132 - accuracy: 0.9979 - val_loss: 0.0547 - val_accuracy: 0.9703\n",
      "Epoch 95/100\n",
      "470/470 [==============================] - 0s 132us/step - loss: 0.0146 - accuracy: 0.9957 - val_loss: 0.0326 - val_accuracy: 0.9851\n",
      "Epoch 96/100\n",
      "470/470 [==============================] - 0s 169us/step - loss: 0.0135 - accuracy: 0.9979 - val_loss: 0.0362 - val_accuracy: 0.9802\n",
      "Epoch 97/100\n",
      "470/470 [==============================] - 0s 436us/step - loss: 0.0113 - accuracy: 0.9979 - val_loss: 0.0506 - val_accuracy: 0.9703\n",
      "Epoch 98/100\n",
      "470/470 [==============================] - 0s 305us/step - loss: 0.0139 - accuracy: 0.9957 - val_loss: 0.0374 - val_accuracy: 0.9851\n",
      "Epoch 99/100\n",
      "470/470 [==============================] - 0s 223us/step - loss: 0.0135 - accuracy: 0.9957 - val_loss: 0.0332 - val_accuracy: 0.9901\n",
      "Epoch 100/100\n",
      "470/470 [==============================] - 0s 196us/step - loss: 0.0132 - accuracy: 0.9979 - val_loss: 0.0344 - val_accuracy: 0.9851\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a3cfb2c88>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over3.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202/202 [==============================] - 0s 85us/step\n",
      "over-sampling test accuracy: 97.52%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over3 = model1_over3.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over3*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 1, 0, 1, 2, 2, 1, 2, 1, 1, 0, 2, 1, 0, 1, 0, 1, 2, 1, 0, 0,\n",
       "       0, 0, 1, 0, 1, 2, 0, 2, 2, 0, 1, 1, 2, 2, 0, 1, 0, 0, 1, 0, 1, 2,\n",
       "       0, 1, 1, 0, 1, 0, 0, 2, 2, 1, 0, 1, 2, 2, 2, 2, 2, 1, 2, 0, 2, 2,\n",
       "       2, 2, 1, 0, 1, 0, 2, 1, 0, 0, 1, 1, 2, 1, 1, 0, 1, 2, 1, 1, 1, 1,\n",
       "       2, 2, 2, 1, 0, 1, 0, 1, 0, 2, 0, 1, 2, 2, 0, 2, 1, 2, 0, 1, 0, 0,\n",
       "       0, 2, 1, 0, 0, 2, 1, 1, 0, 0, 0, 1, 0, 1, 1, 2, 1, 2, 1, 2, 0, 1,\n",
       "       0, 0, 2, 2, 0, 0, 1, 2, 2, 2, 0, 2, 2, 2, 1, 1, 1, 0, 2, 1, 2, 0,\n",
       "       0, 2, 1, 1, 1, 2, 1, 0, 0, 2, 2, 0, 1, 2, 2, 0, 2, 1, 1, 0, 2, 0,\n",
       "       1, 2, 0, 0, 0, 1, 1, 2, 1, 2, 0, 2, 2, 2, 0, 0, 1, 2, 0, 1, 1, 0,\n",
       "       2, 1, 1, 0])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred3 = model1_over3.predict_classes(X_test_over)\n",
    "pred3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS187</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CFBREBSa116</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS187</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>GA12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>NRS265</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>NRS253</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>SR4187</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test  pred\n",
       "0         NRS148     2     2\n",
       "1         NRS209     2     2\n",
       "2         NRS187     1     1\n",
       "3    CFBREBSa116     0     0\n",
       "4         NRS187     1     1\n",
       "..           ...   ...   ...\n",
       "197         GA12     0     0\n",
       "198       NRS209     2     2\n",
       "199       NRS265     1     1\n",
       "200       NRS253     1     1\n",
       "201       SR4187     0     0\n",
       "\n",
       "[202 rows x 3 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat3['pred'] = pred3\n",
    "dat3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba3 = model1_over3.predict_proba(X_test_over)\n",
    "dat_proba3 = pd.DataFrame(proba3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.010629</td>\n",
       "      <td>9.892482e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>9.997830e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.009963</td>\n",
       "      <td>0.990030</td>\n",
       "      <td>7.961025e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.999736</td>\n",
       "      <td>0.000264</td>\n",
       "      <td>1.595297e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.009963</td>\n",
       "      <td>0.990030</td>\n",
       "      <td>7.961025e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.979151</td>\n",
       "      <td>0.020849</td>\n",
       "      <td>2.218113e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>9.997830e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0.001390</td>\n",
       "      <td>0.996783</td>\n",
       "      <td>1.827248e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0.000794</td>\n",
       "      <td>0.998547</td>\n",
       "      <td>6.587048e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>0.999944</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>2.503860e-13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1             2\n",
       "0    0.000123  0.010629  9.892482e-01\n",
       "1    0.000020  0.000197  9.997830e-01\n",
       "2    0.009963  0.990030  7.961025e-06\n",
       "3    0.999736  0.000264  1.595297e-07\n",
       "4    0.009963  0.990030  7.961025e-06\n",
       "..        ...       ...           ...\n",
       "197  0.979151  0.020849  2.218113e-10\n",
       "198  0.000020  0.000197  9.997830e-01\n",
       "199  0.001390  0.996783  1.827248e-03\n",
       "200  0.000794  0.998547  6.587048e-04\n",
       "201  0.999944  0.000056  2.503860e-13\n",
       "\n",
       "[202 rows x 3 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba3.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba3.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat3.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/3p003ppST.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 470 samples, validate on 202 samples\n",
      "Epoch 1/100\n",
      "470/470 [==============================] - 0s 218us/step - loss: 0.0127 - accuracy: 0.9957 - val_loss: 0.0463 - val_accuracy: 0.9752\n",
      "Epoch 2/100\n",
      "470/470 [==============================] - 0s 210us/step - loss: 0.0153 - accuracy: 0.9979 - val_loss: 0.0384 - val_accuracy: 0.9752\n",
      "Epoch 3/100\n",
      "470/470 [==============================] - 0s 206us/step - loss: 0.0133 - accuracy: 0.9957 - val_loss: 0.0454 - val_accuracy: 0.9752\n",
      "Epoch 4/100\n",
      "470/470 [==============================] - 0s 197us/step - loss: 0.0131 - accuracy: 0.9957 - val_loss: 0.0396 - val_accuracy: 0.9752\n",
      "Epoch 5/100\n",
      "470/470 [==============================] - 0s 208us/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 0.0636 - val_accuracy: 0.9752\n",
      "Epoch 6/100\n",
      "470/470 [==============================] - 0s 208us/step - loss: 0.0161 - accuracy: 0.9957 - val_loss: 0.0482 - val_accuracy: 0.9752\n",
      "Epoch 7/100\n",
      "470/470 [==============================] - 0s 205us/step - loss: 0.0139 - accuracy: 0.9957 - val_loss: 0.0506 - val_accuracy: 0.9752\n",
      "Epoch 8/100\n",
      "470/470 [==============================] - 0s 198us/step - loss: 0.0126 - accuracy: 0.9957 - val_loss: 0.0562 - val_accuracy: 0.9752\n",
      "Epoch 9/100\n",
      "470/470 [==============================] - 0s 183us/step - loss: 0.0126 - accuracy: 0.9957 - val_loss: 0.0413 - val_accuracy: 0.9752\n",
      "Epoch 10/100\n",
      "470/470 [==============================] - 0s 152us/step - loss: 0.0112 - accuracy: 0.9957 - val_loss: 0.0603 - val_accuracy: 0.9752\n",
      "Epoch 11/100\n",
      "470/470 [==============================] - 0s 116us/step - loss: 0.0144 - accuracy: 0.9979 - val_loss: 0.0513 - val_accuracy: 0.9752\n",
      "Epoch 12/100\n",
      "470/470 [==============================] - 0s 132us/step - loss: 0.0126 - accuracy: 0.9957 - val_loss: 0.0388 - val_accuracy: 0.9752\n",
      "Epoch 13/100\n",
      "470/470 [==============================] - 0s 117us/step - loss: 0.0116 - accuracy: 0.9979 - val_loss: 0.0645 - val_accuracy: 0.9752\n",
      "Epoch 14/100\n",
      "470/470 [==============================] - 0s 126us/step - loss: 0.0134 - accuracy: 0.9979 - val_loss: 0.0317 - val_accuracy: 0.9851\n",
      "Epoch 15/100\n",
      "470/470 [==============================] - 0s 117us/step - loss: 0.0104 - accuracy: 0.9979 - val_loss: 0.0584 - val_accuracy: 0.9752\n",
      "Epoch 16/100\n",
      "470/470 [==============================] - 0s 119us/step - loss: 0.0105 - accuracy: 0.9957 - val_loss: 0.0334 - val_accuracy: 0.9851\n",
      "Epoch 17/100\n",
      "470/470 [==============================] - 0s 116us/step - loss: 0.0133 - accuracy: 0.9979 - val_loss: 0.0504 - val_accuracy: 0.9752\n",
      "Epoch 18/100\n",
      "470/470 [==============================] - 0s 125us/step - loss: 0.0103 - accuracy: 0.9979 - val_loss: 0.0580 - val_accuracy: 0.9752\n",
      "Epoch 19/100\n",
      "470/470 [==============================] - 0s 116us/step - loss: 0.0123 - accuracy: 0.9979 - val_loss: 0.0319 - val_accuracy: 0.9851\n",
      "Epoch 20/100\n",
      "470/470 [==============================] - 0s 127us/step - loss: 0.0099 - accuracy: 0.9979 - val_loss: 0.0610 - val_accuracy: 0.9752\n",
      "Epoch 21/100\n",
      "470/470 [==============================] - 0s 116us/step - loss: 0.0116 - accuracy: 0.9979 - val_loss: 0.0532 - val_accuracy: 0.9752\n",
      "Epoch 22/100\n",
      "470/470 [==============================] - 0s 123us/step - loss: 0.0111 - accuracy: 0.9979 - val_loss: 0.0361 - val_accuracy: 0.9802\n",
      "Epoch 23/100\n",
      "470/470 [==============================] - 0s 133us/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.0697 - val_accuracy: 0.9752\n",
      "Epoch 24/100\n",
      "470/470 [==============================] - 0s 128us/step - loss: 0.0115 - accuracy: 0.9979 - val_loss: 0.0324 - val_accuracy: 0.9802\n",
      "Epoch 25/100\n",
      "470/470 [==============================] - 0s 153us/step - loss: 0.0102 - accuracy: 0.9957 - val_loss: 0.0420 - val_accuracy: 0.9752\n",
      "Epoch 26/100\n",
      "470/470 [==============================] - 0s 185us/step - loss: 0.0089 - accuracy: 0.9979 - val_loss: 0.0465 - val_accuracy: 0.9752\n",
      "Epoch 27/100\n",
      "470/470 [==============================] - 0s 140us/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.0713 - val_accuracy: 0.9752\n",
      "Epoch 28/100\n",
      "470/470 [==============================] - 0s 135us/step - loss: 0.0104 - accuracy: 0.9979 - val_loss: 0.0303 - val_accuracy: 0.9851\n",
      "Epoch 29/100\n",
      "470/470 [==============================] - 0s 132us/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.0624 - val_accuracy: 0.9752\n",
      "Epoch 30/100\n",
      "470/470 [==============================] - 0s 126us/step - loss: 0.0106 - accuracy: 0.9957 - val_loss: 0.0455 - val_accuracy: 0.9752\n",
      "Epoch 31/100\n",
      "470/470 [==============================] - 0s 118us/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.0713 - val_accuracy: 0.9752\n",
      "Epoch 32/100\n",
      "470/470 [==============================] - 0s 119us/step - loss: 0.0117 - accuracy: 0.9979 - val_loss: 0.0308 - val_accuracy: 0.9851\n",
      "Epoch 33/100\n",
      "470/470 [==============================] - 0s 139us/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.0426 - val_accuracy: 0.9752\n",
      "Epoch 34/100\n",
      "470/470 [==============================] - 0s 143us/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.0587 - val_accuracy: 0.9752\n",
      "Epoch 35/100\n",
      "470/470 [==============================] - 0s 143us/step - loss: 0.0087 - accuracy: 0.9979 - val_loss: 0.0340 - val_accuracy: 0.9802\n",
      "Epoch 36/100\n",
      "470/470 [==============================] - 0s 153us/step - loss: 0.0084 - accuracy: 0.9979 - val_loss: 0.0482 - val_accuracy: 0.9752\n",
      "Epoch 37/100\n",
      "470/470 [==============================] - 0s 122us/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.0440 - val_accuracy: 0.9752\n",
      "Epoch 38/100\n",
      "470/470 [==============================] - 0s 123us/step - loss: 0.0071 - accuracy: 0.9979 - val_loss: 0.0392 - val_accuracy: 0.9752\n",
      "Epoch 39/100\n",
      "470/470 [==============================] - 0s 191us/step - loss: 0.0072 - accuracy: 0.9979 - val_loss: 0.0473 - val_accuracy: 0.9752\n",
      "Epoch 40/100\n",
      "470/470 [==============================] - 0s 199us/step - loss: 0.0074 - accuracy: 0.9979 - val_loss: 0.0514 - val_accuracy: 0.9752\n",
      "Epoch 41/100\n",
      "470/470 [==============================] - 0s 153us/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0528 - val_accuracy: 0.9752\n",
      "Epoch 42/100\n",
      "470/470 [==============================] - 0s 148us/step - loss: 0.0077 - accuracy: 0.9979 - val_loss: 0.0320 - val_accuracy: 0.9851\n",
      "Epoch 43/100\n",
      "470/470 [==============================] - 0s 151us/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.0718 - val_accuracy: 0.9752\n",
      "Epoch 44/100\n",
      "470/470 [==============================] - 0s 160us/step - loss: 0.0085 - accuracy: 0.9979 - val_loss: 0.0447 - val_accuracy: 0.9752\n",
      "Epoch 45/100\n",
      "470/470 [==============================] - 0s 155us/step - loss: 0.0070 - accuracy: 0.9979 - val_loss: 0.0367 - val_accuracy: 0.9802\n",
      "Epoch 46/100\n",
      "470/470 [==============================] - 0s 343us/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0584 - val_accuracy: 0.9752\n",
      "Epoch 47/100\n",
      "470/470 [==============================] - 0s 250us/step - loss: 0.0070 - accuracy: 0.9979 - val_loss: 0.0457 - val_accuracy: 0.9752\n",
      "Epoch 48/100\n",
      "470/470 [==============================] - 0s 265us/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0545 - val_accuracy: 0.9752\n",
      "Epoch 49/100\n",
      "470/470 [==============================] - 0s 190us/step - loss: 0.0072 - accuracy: 0.9979 - val_loss: 0.0366 - val_accuracy: 0.9802\n",
      "Epoch 50/100\n",
      "470/470 [==============================] - 0s 148us/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0582 - val_accuracy: 0.9752\n",
      "Epoch 51/100\n",
      "470/470 [==============================] - 0s 148us/step - loss: 0.0076 - accuracy: 0.9979 - val_loss: 0.0376 - val_accuracy: 0.9752\n",
      "Epoch 52/100\n",
      "470/470 [==============================] - 0s 164us/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0533 - val_accuracy: 0.9752\n",
      "Epoch 53/100\n",
      "470/470 [==============================] - 0s 125us/step - loss: 0.0061 - accuracy: 0.9979 - val_loss: 0.0412 - val_accuracy: 0.9752\n",
      "Epoch 54/100\n",
      "470/470 [==============================] - 0s 124us/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0558 - val_accuracy: 0.9752\n",
      "Epoch 55/100\n",
      "470/470 [==============================] - 0s 324us/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0605 - val_accuracy: 0.9752\n",
      "Epoch 56/100\n",
      "470/470 [==============================] - 0s 144us/step - loss: 0.0068 - accuracy: 0.9979 - val_loss: 0.0393 - val_accuracy: 0.9802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "470/470 [==============================] - 0s 135us/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0604 - val_accuracy: 0.9752\n",
      "Epoch 58/100\n",
      "470/470 [==============================] - 0s 131us/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0507 - val_accuracy: 0.9752\n",
      "Epoch 59/100\n",
      "470/470 [==============================] - 0s 139us/step - loss: 0.0062 - accuracy: 0.9979 - val_loss: 0.0399 - val_accuracy: 0.9752\n",
      "Epoch 60/100\n",
      "470/470 [==============================] - 0s 135us/step - loss: 0.0057 - accuracy: 0.9979 - val_loss: 0.0474 - val_accuracy: 0.9752\n",
      "Epoch 61/100\n",
      "470/470 [==============================] - 0s 134us/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0613 - val_accuracy: 0.9752\n",
      "Epoch 62/100\n",
      "470/470 [==============================] - 0s 132us/step - loss: 0.0066 - accuracy: 0.9979 - val_loss: 0.0314 - val_accuracy: 0.9851\n",
      "Epoch 63/100\n",
      "470/470 [==============================] - 0s 118us/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0682 - val_accuracy: 0.9752\n",
      "Epoch 64/100\n",
      "470/470 [==============================] - 0s 118us/step - loss: 0.0062 - accuracy: 0.9979 - val_loss: 0.0319 - val_accuracy: 0.9851\n",
      "Epoch 65/100\n",
      "470/470 [==============================] - 0s 116us/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0701 - val_accuracy: 0.9752\n",
      "Epoch 66/100\n",
      "470/470 [==============================] - 0s 116us/step - loss: 0.0057 - accuracy: 0.9979 - val_loss: 0.0313 - val_accuracy: 0.9851\n",
      "Epoch 67/100\n",
      "470/470 [==============================] - 0s 141us/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0554 - val_accuracy: 0.9752\n",
      "Epoch 68/100\n",
      "470/470 [==============================] - 0s 264us/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0387 - val_accuracy: 0.9802\n",
      "Epoch 69/100\n",
      "470/470 [==============================] - 0s 429us/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0481 - val_accuracy: 0.9752\n",
      "Epoch 70/100\n",
      "470/470 [==============================] - 0s 254us/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0423 - val_accuracy: 0.9752\n",
      "Epoch 71/100\n",
      "470/470 [==============================] - 0s 236us/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0440 - val_accuracy: 0.9752\n",
      "Epoch 72/100\n",
      "470/470 [==============================] - 0s 241us/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0497 - val_accuracy: 0.9752\n",
      "Epoch 73/100\n",
      "470/470 [==============================] - 0s 216us/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0471 - val_accuracy: 0.9752\n",
      "Epoch 74/100\n",
      "470/470 [==============================] - 0s 207us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0458 - val_accuracy: 0.9752\n",
      "Epoch 75/100\n",
      "470/470 [==============================] - 0s 224us/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0627 - val_accuracy: 0.9752\n",
      "Epoch 76/100\n",
      "470/470 [==============================] - 0s 194us/step - loss: 0.0052 - accuracy: 0.9979 - val_loss: 0.0409 - val_accuracy: 0.9752\n",
      "Epoch 77/100\n",
      "470/470 [==============================] - 0s 202us/step - loss: 0.0047 - accuracy: 0.9979 - val_loss: 0.0422 - val_accuracy: 0.9752\n",
      "Epoch 78/100\n",
      "470/470 [==============================] - 0s 216us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0586 - val_accuracy: 0.9752\n",
      "Epoch 79/100\n",
      "470/470 [==============================] - 0s 228us/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0407 - val_accuracy: 0.9802\n",
      "Epoch 80/100\n",
      "470/470 [==============================] - 0s 226us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0593 - val_accuracy: 0.9752\n",
      "Epoch 81/100\n",
      "470/470 [==============================] - 0s 245us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0421 - val_accuracy: 0.9752\n",
      "Epoch 82/100\n",
      "470/470 [==============================] - 0s 259us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0571 - val_accuracy: 0.9752\n",
      "Epoch 83/100\n",
      "470/470 [==============================] - 0s 282us/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0433 - val_accuracy: 0.9752\n",
      "Epoch 84/100\n",
      "470/470 [==============================] - 0s 246us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0553 - val_accuracy: 0.9752\n",
      "Epoch 85/100\n",
      "470/470 [==============================] - 0s 246us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0402 - val_accuracy: 0.9851\n",
      "Epoch 86/100\n",
      "470/470 [==============================] - 0s 235us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0644 - val_accuracy: 0.9752\n",
      "Epoch 87/100\n",
      "470/470 [==============================] - 0s 248us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0504 - val_accuracy: 0.9752\n",
      "Epoch 88/100\n",
      "470/470 [==============================] - 0s 210us/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.1103 - val_accuracy: 0.9703\n",
      "Epoch 89/100\n",
      "470/470 [==============================] - 0s 222us/step - loss: 0.0089 - accuracy: 0.9979 - val_loss: 0.0222 - val_accuracy: 0.9901\n",
      "Epoch 90/100\n",
      "470/470 [==============================] - 0s 214us/step - loss: 0.0093 - accuracy: 0.9979 - val_loss: 0.0643 - val_accuracy: 0.9752\n",
      "Epoch 91/100\n",
      "470/470 [==============================] - 0s 210us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0503 - val_accuracy: 0.9752\n",
      "Epoch 92/100\n",
      "470/470 [==============================] - 0s 249us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0573 - val_accuracy: 0.9752\n",
      "Epoch 93/100\n",
      "470/470 [==============================] - 0s 221us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0567 - val_accuracy: 0.9752\n",
      "Epoch 94/100\n",
      "470/470 [==============================] - 0s 210us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0531 - val_accuracy: 0.9752\n",
      "Epoch 95/100\n",
      "470/470 [==============================] - 0s 212us/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0720 - val_accuracy: 0.9752\n",
      "Epoch 96/100\n",
      "470/470 [==============================] - 0s 201us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0634 - val_accuracy: 0.9752\n",
      "Epoch 97/100\n",
      "470/470 [==============================] - 0s 193us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0514 - val_accuracy: 0.9752\n",
      "Epoch 98/100\n",
      "470/470 [==============================] - 0s 193us/step - loss: 0.0034 - accuracy: 0.9979 - val_loss: 0.0543 - val_accuracy: 0.9752\n",
      "Epoch 99/100\n",
      "470/470 [==============================] - 0s 195us/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0734 - val_accuracy: 0.9752\n",
      "Epoch 100/100\n",
      "470/470 [==============================] - 0s 232us/step - loss: 0.0049 - accuracy: 0.9979 - val_loss: 0.0370 - val_accuracy: 0.9802\n"
     ]
    }
   ],
   "source": [
    "hist1_over3 = model1_over3.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 99.87%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over3.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba3 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_2.xlsx\",\n",
    "                        sheet_name=2,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>0.013518</td>\n",
       "      <td>9.820048e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>0.013518</td>\n",
       "      <td>9.820048e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS222</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.851725</td>\n",
       "      <td>0.148269</td>\n",
       "      <td>5.980786e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>0.013518</td>\n",
       "      <td>9.820048e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>GA50245</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.812055</td>\n",
       "      <td>0.187945</td>\n",
       "      <td>1.161034e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4279</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>0.000928</td>\n",
       "      <td>9.984396e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4280</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>0.000928</td>\n",
       "      <td>9.984396e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4281</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS266</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.025932</td>\n",
       "      <td>0.974061</td>\n",
       "      <td>7.323514e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4282</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000597</td>\n",
       "      <td>0.999403</td>\n",
       "      <td>3.675362e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4283</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS112</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>0.999452</td>\n",
       "      <td>1.168620e-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4284 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    phage   strain  phenotype  prediction         0         1  \\\n",
       "0      p002ykpresabs_qual   NRS109          2           2  0.004477  0.013518   \n",
       "1      p002ykpresabs_qual   NRS109          2           2  0.004477  0.013518   \n",
       "2      p002ykpresabs_qual   NRS222          0           0  0.851725  0.148269   \n",
       "3      p002ykpresabs_qual   NRS109          2           2  0.004477  0.013518   \n",
       "4      p002ykpresabs_qual  GA50245          0           0  0.812055  0.187945   \n",
       "...                   ...      ...        ...         ...       ...       ...   \n",
       "4279  pyopresabsSTCC_qual   NRS255          2           2  0.000633  0.000928   \n",
       "4280  pyopresabsSTCC_qual   NRS255          2           2  0.000633  0.000928   \n",
       "4281  pyopresabsSTCC_qual   NRS266          1           1  0.025932  0.974061   \n",
       "4282  pyopresabsSTCC_qual   NRS001          1           1  0.000597  0.999403   \n",
       "4283  pyopresabsSTCC_qual   NRS112          1           1  0.000537  0.999452   \n",
       "\n",
       "                 2  \n",
       "0     9.820048e-01  \n",
       "1     9.820048e-01  \n",
       "2     5.980786e-06  \n",
       "3     9.820048e-01  \n",
       "4     1.161034e-07  \n",
       "...            ...  \n",
       "4279  9.984396e-01  \n",
       "4280  9.984396e-01  \n",
       "4281  7.323514e-06  \n",
       "4282  3.675362e-10  \n",
       "4283  1.168620e-05  \n",
       "\n",
       "[4284 rows x 7 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.22783270e-04, 1.06290110e-02, 9.89248200e-01],\n",
       "       [2.00190680e-05, 1.96983950e-04, 9.99783000e-01],\n",
       "       [9.96255400e-03, 9.90029500e-01, 7.96102500e-06],\n",
       "       [9.99736130e-01, 2.63790540e-04, 1.59529660e-07],\n",
       "       [9.96255400e-03, 9.90029500e-01, 7.96102500e-06],\n",
       "       [2.00190680e-05, 1.96983950e-04, 9.99783000e-01],\n",
       "       [5.12395750e-04, 1.28842060e-04, 9.99358700e-01],\n",
       "       [7.92104900e-03, 9.92078840e-01, 1.16210340e-07],\n",
       "       [1.22783270e-04, 1.06290110e-02, 9.89248200e-01],\n",
       "       [1.38985540e-03, 9.96782800e-01, 1.82724940e-03],\n",
       "       [6.71824400e-03, 9.93279040e-01, 2.67666600e-06],\n",
       "       [9.98966600e-01, 1.03315410e-03, 2.15709140e-07],\n",
       "       [2.00190680e-05, 1.96983950e-04, 9.99783000e-01],\n",
       "       [6.07249330e-03, 9.93094300e-01, 8.33168200e-04],\n",
       "       [9.99908300e-01, 9.16254800e-05, 1.36625210e-10],\n",
       "       [7.92104900e-03, 9.92078840e-01, 1.16210340e-07],\n",
       "       [9.99998900e-01, 1.10197580e-06, 5.12359540e-08],\n",
       "       [5.37403100e-03, 9.93032340e-01, 1.59356490e-03],\n",
       "       [1.22783270e-04, 1.06290110e-02, 9.89248200e-01],\n",
       "       [2.01696080e-02, 9.79830400e-01, 4.26539940e-10],\n",
       "       [5.40665600e-01, 4.59333330e-01, 1.05567730e-06],\n",
       "       [9.99989500e-01, 1.04761560e-05, 1.08935964e-10],\n",
       "       [9.63231200e-01, 3.66377500e-02, 1.31013280e-04],\n",
       "       [9.99988300e-01, 1.16110290e-05, 1.08519170e-07],\n",
       "       [9.49849700e-02, 9.04931300e-01, 8.37412300e-05],\n",
       "       [9.99999900e-01, 1.71085490e-07, 9.78754140e-12],\n",
       "       [9.41087800e-03, 9.90586340e-01, 2.82498700e-06],\n",
       "       [2.00190680e-05, 1.96983950e-04, 9.99783000e-01],\n",
       "       [1.00000000e+00, 5.83290200e-09, 9.40115400e-13],\n",
       "       [5.12395750e-04, 1.28842060e-04, 9.99358700e-01],\n",
       "       [1.22783270e-04, 1.06290110e-02, 9.89248200e-01],\n",
       "       [9.99351800e-01, 6.44859330e-04, 3.32342940e-06],\n",
       "       [9.41087800e-03, 9.90586340e-01, 2.82498700e-06],\n",
       "       [6.07249330e-03, 9.93094300e-01, 8.33168200e-04],\n",
       "       [2.00190680e-05, 1.96983950e-04, 9.99783000e-01],\n",
       "       [5.12395750e-04, 1.28842060e-04, 9.99358700e-01],\n",
       "       [9.99991800e-01, 7.26767760e-06, 9.94812400e-07],\n",
       "       [7.93706000e-04, 9.98547500e-01, 6.58705130e-04],\n",
       "       [9.99995600e-01, 4.36804200e-06, 4.82891460e-09],\n",
       "       [9.98833700e-01, 1.16627510e-03, 6.51653250e-11],\n",
       "       [1.02424070e-02, 9.89735840e-01, 2.16713490e-05],\n",
       "       [9.99958750e-01, 4.11898040e-05, 1.03073180e-10],\n",
       "       [5.37403100e-03, 9.93032340e-01, 1.59356490e-03],\n",
       "       [2.00190680e-05, 1.96983950e-04, 9.99783000e-01],\n",
       "       [9.98670100e-01, 1.32532940e-03, 4.63833070e-06],\n",
       "       [4.69225300e-03, 9.95307270e-01, 5.04020100e-07],\n",
       "       [9.41087800e-03, 9.90586340e-01, 2.82498700e-06],\n",
       "       [9.99978900e-01, 2.08369240e-05, 2.80634370e-07],\n",
       "       [2.19426750e-03, 9.40263000e-01, 5.75427400e-02],\n",
       "       [9.08537150e-01, 9.14623800e-02, 4.60863000e-07],\n",
       "       [9.99880550e-01, 1.19341220e-04, 8.91744700e-08],\n",
       "       [2.00190680e-05, 1.96983950e-04, 9.99783000e-01],\n",
       "       [2.00190680e-05, 1.96983950e-04, 9.99783000e-01],\n",
       "       [9.86249400e-04, 9.98912600e-01, 1.01227706e-04],\n",
       "       [9.99821250e-01, 1.78788280e-04, 3.68424960e-10],\n",
       "       [2.19426750e-03, 9.40263000e-01, 5.75427400e-02],\n",
       "       [5.12395750e-04, 1.28842060e-04, 9.99358700e-01],\n",
       "       [5.12395750e-04, 1.28842060e-04, 9.99358700e-01],\n",
       "       [2.00190680e-05, 1.96983950e-04, 9.99783000e-01],\n",
       "       [2.00190680e-05, 1.96983950e-04, 9.99783000e-01],\n",
       "       [5.12395750e-04, 1.28842060e-04, 9.99358700e-01],\n",
       "       [7.12387500e-02, 9.28761240e-01, 1.93275810e-10],\n",
       "       [5.12395750e-04, 1.28842060e-04, 9.99358700e-01],\n",
       "       [9.95428900e-01, 4.56937600e-03, 1.64026910e-06],\n",
       "       [2.00190680e-05, 1.96983950e-04, 9.99783000e-01],\n",
       "       [1.22783270e-04, 1.06290110e-02, 9.89248200e-01],\n",
       "       [1.22783270e-04, 1.06290110e-02, 9.89248200e-01],\n",
       "       [5.12395750e-04, 1.28842060e-04, 9.99358700e-01],\n",
       "       [3.61240500e-02, 9.63802600e-01, 7.34390900e-05],\n",
       "       [9.94078040e-01, 5.90770700e-03, 1.42062690e-05],\n",
       "       [2.64496800e-01, 7.35487600e-01, 1.56135340e-05],\n",
       "       [9.99788200e-01, 2.11749230e-04, 2.74367140e-10],\n",
       "       [2.00190680e-05, 1.96983950e-04, 9.99783000e-01],\n",
       "       [4.80266240e-01, 5.19731600e-01, 2.17750740e-06],\n",
       "       [9.88422800e-01, 1.15749850e-02, 2.19568850e-06],\n",
       "       [8.23628300e-01, 1.76367460e-01, 4.25435900e-06],\n",
       "       [1.17357190e-02, 9.88263600e-01, 6.83474350e-07],\n",
       "       [1.38985540e-03, 9.96782800e-01, 1.82724940e-03],\n",
       "       [1.22783270e-04, 1.06290110e-02, 9.89248200e-01],\n",
       "       [7.93706000e-04, 9.98547500e-01, 6.58705130e-04],\n",
       "       [1.65539350e-02, 9.83338500e-01, 1.07636035e-04],\n",
       "       [9.99966500e-01, 3.34946160e-05, 2.73312840e-10],\n",
       "       [1.53833290e-02, 9.84616640e-01, 2.87686680e-11],\n",
       "       [5.12395750e-04, 1.28842060e-04, 9.99358700e-01],\n",
       "       [5.05943000e-03, 9.94940160e-01, 4.55275230e-07],\n",
       "       [6.71824400e-03, 9.93279040e-01, 2.67666600e-06],\n",
       "       [1.01664370e-02, 9.89817000e-01, 1.64959730e-05],\n",
       "       [1.38985540e-03, 9.96782800e-01, 1.82724940e-03],\n",
       "       [5.12395750e-04, 1.28842060e-04, 9.99358700e-01],\n",
       "       [1.22783270e-04, 1.06290110e-02, 9.89248200e-01],\n",
       "       [2.00190680e-05, 1.96983950e-04, 9.99783000e-01],\n",
       "       [7.12387500e-02, 9.28761240e-01, 1.93275810e-10],\n",
       "       [9.99727550e-01, 2.71818370e-04, 6.13717200e-07],\n",
       "       [7.93706000e-04, 9.98547500e-01, 6.58705130e-04],\n",
       "       [9.98060050e-01, 1.93865090e-03, 1.29236900e-06],\n",
       "       [4.69225300e-03, 9.95307270e-01, 5.04020100e-07],\n",
       "       [9.99988900e-01, 3.45932270e-06, 7.66313400e-06],\n",
       "       [5.12395750e-04, 1.28842060e-04, 9.99358700e-01],\n",
       "       [9.99765800e-01, 2.34147200e-04, 1.48329390e-10],\n",
       "       [5.05943000e-03, 9.94940160e-01, 4.55275230e-07],\n",
       "       [1.22783270e-04, 1.06290110e-02, 9.89248200e-01],\n",
       "       [1.22783270e-04, 1.06290110e-02, 9.89248200e-01],\n",
       "       [9.99886300e-01, 1.13756134e-04, 3.12310350e-11],\n",
       "       [1.22783270e-04, 1.06290110e-02, 9.89248200e-01],\n",
       "       [9.86249400e-04, 9.98912600e-01, 1.01227706e-04],\n",
       "       [2.00190680e-05, 1.96983950e-04, 9.99783000e-01],\n",
       "       [9.99470300e-01, 5.15879250e-04, 1.37965880e-05],\n",
       "       [2.49808650e-03, 9.97501900e-01, 1.41613030e-08],\n",
       "       [9.99540700e-01, 4.49997720e-04, 9.31931500e-06],\n",
       "       [9.49650100e-01, 5.03460760e-02, 3.80122700e-06],\n",
       "       [9.99696970e-01, 3.03068750e-04, 2.45892420e-10],\n",
       "       [1.22783270e-04, 1.06290110e-02, 9.89248200e-01],\n",
       "       [2.01696080e-02, 9.79830400e-01, 4.26539940e-10],\n",
       "       [9.98742640e-01, 1.25348130e-03, 3.87633240e-06],\n",
       "       [9.99818000e-01, 1.81568920e-04, 4.51040620e-07],\n",
       "       [5.12395750e-04, 1.28842060e-04, 9.99358700e-01],\n",
       "       [7.93706000e-04, 9.98547500e-01, 6.58705130e-04],\n",
       "       [9.41087800e-03, 9.90586340e-01, 2.82498700e-06],\n",
       "       [9.95950600e-01, 3.91878800e-03, 1.30630990e-04],\n",
       "       [9.99944700e-01, 5.30401500e-05, 2.24229440e-06],\n",
       "       [9.99900460e-01, 5.13704180e-05, 4.81208150e-05],\n",
       "       [1.02424070e-02, 9.89735840e-01, 2.16713490e-05],\n",
       "       [9.95910050e-01, 4.08978000e-03, 2.64157000e-07],\n",
       "       [9.86249400e-04, 9.98912600e-01, 1.01227706e-04],\n",
       "       [1.02424070e-02, 9.89735840e-01, 2.16713490e-05],\n",
       "       [1.22783270e-04, 1.06290110e-02, 9.89248200e-01],\n",
       "       [9.41087800e-03, 9.90586340e-01, 2.82498700e-06],\n",
       "       [5.12395750e-04, 1.28842060e-04, 9.99358700e-01],\n",
       "       [2.16101140e-01, 7.83870940e-01, 2.79216970e-05],\n",
       "       [5.12395750e-04, 1.28842060e-04, 9.99358700e-01],\n",
       "       [9.99831200e-01, 1.68814440e-04, 1.29464130e-10],\n",
       "       [1.01664370e-02, 9.89817000e-01, 1.64959730e-05],\n",
       "       [9.95736240e-01, 4.26372370e-03, 7.43367100e-10],\n",
       "       [9.96789340e-01, 3.19832750e-03, 1.24165040e-05],\n",
       "       [1.22783270e-04, 1.06290110e-02, 9.89248200e-01],\n",
       "       [5.12395750e-04, 1.28842060e-04, 9.99358700e-01],\n",
       "       [9.93290800e-01, 6.70917400e-03, 5.14166300e-10],\n",
       "       [9.99679900e-01, 3.20062000e-04, 7.03757000e-09],\n",
       "       [7.12387500e-02, 9.28761240e-01, 1.93275810e-10],\n",
       "       [5.12395750e-04, 1.28842060e-04, 9.99358700e-01],\n",
       "       [1.22783270e-04, 1.06290110e-02, 9.89248200e-01],\n",
       "       [2.00190680e-05, 1.96983950e-04, 9.99783000e-01],\n",
       "       [9.65191070e-01, 3.48089300e-02, 1.95324450e-09],\n",
       "       [1.22783270e-04, 1.06290110e-02, 9.89248200e-01],\n",
       "       [1.22783270e-04, 1.06290110e-02, 9.89248200e-01],\n",
       "       [2.00190680e-05, 1.96983950e-04, 9.99783000e-01],\n",
       "       [1.17357190e-02, 9.88263600e-01, 6.83474350e-07],\n",
       "       [7.92104900e-03, 9.92078840e-01, 1.16210340e-07],\n",
       "       [1.02424070e-02, 9.89735840e-01, 2.16713490e-05],\n",
       "       [9.99984150e-01, 1.59035840e-05, 3.06177330e-09],\n",
       "       [2.00190680e-05, 1.96983950e-04, 9.99783000e-01],\n",
       "       [3.61240500e-02, 9.63802600e-01, 7.34390900e-05],\n",
       "       [2.00190680e-05, 1.96983950e-04, 9.99783000e-01],\n",
       "       [9.99999900e-01, 1.22770430e-07, 6.85151900e-12],\n",
       "       [6.87425800e-01, 3.12541130e-01, 3.31310900e-05],\n",
       "       [5.12395750e-04, 1.28842060e-04, 9.99358700e-01],\n",
       "       [1.38985540e-03, 9.96782800e-01, 1.82724940e-03],\n",
       "       [1.01664370e-02, 9.89817000e-01, 1.64959730e-05],\n",
       "       [1.38985540e-03, 9.96782800e-01, 1.82724940e-03],\n",
       "       [1.22783270e-04, 1.06290110e-02, 9.89248200e-01],\n",
       "       [2.01696080e-02, 9.79830400e-01, 4.26539940e-10],\n",
       "       [9.99721940e-01, 2.77927840e-04, 1.30042640e-07],\n",
       "       [9.99858140e-01, 1.41743300e-04, 8.79257100e-08],\n",
       "       [5.12395750e-04, 1.28842060e-04, 9.99358700e-01],\n",
       "       [5.12395750e-04, 1.28842060e-04, 9.99358700e-01],\n",
       "       [9.99987500e-01, 1.24481950e-05, 8.11788040e-08],\n",
       "       [1.53833290e-02, 9.84616640e-01, 2.87686680e-11],\n",
       "       [1.22783270e-04, 1.06290110e-02, 9.89248200e-01],\n",
       "       [2.00190680e-05, 1.96983950e-04, 9.99783000e-01],\n",
       "       [9.98459200e-01, 1.53729610e-03, 3.48292770e-06],\n",
       "       [2.00190680e-05, 1.96983950e-04, 9.99783000e-01],\n",
       "       [6.07249330e-03, 9.93094300e-01, 8.33168200e-04],\n",
       "       [1.17357190e-02, 9.88263600e-01, 6.83474350e-07],\n",
       "       [9.99027250e-01, 9.67535700e-04, 5.21974740e-06],\n",
       "       [5.12395750e-04, 1.28842060e-04, 9.99358700e-01],\n",
       "       [9.99999900e-01, 3.66105550e-09, 1.41540680e-07],\n",
       "       [2.19426750e-03, 9.40263000e-01, 5.75427400e-02],\n",
       "       [1.22783270e-04, 1.06290110e-02, 9.89248200e-01],\n",
       "       [9.99004070e-01, 8.99860170e-04, 9.60948900e-05],\n",
       "       [6.32964300e-01, 3.66092230e-01, 9.43442340e-04],\n",
       "       [9.99915960e-01, 8.38996500e-05, 7.48004700e-08],\n",
       "       [2.14195530e-03, 9.97220040e-01, 6.37987340e-04],\n",
       "       [5.37403100e-03, 9.93032340e-01, 1.59356490e-03],\n",
       "       [1.22783270e-04, 1.06290110e-02, 9.89248200e-01],\n",
       "       [8.18631100e-04, 9.99152300e-01, 2.90954870e-05],\n",
       "       [1.22783270e-04, 1.06290110e-02, 9.89248200e-01],\n",
       "       [9.98966600e-01, 1.03315410e-03, 2.15709140e-07],\n",
       "       [5.12395750e-04, 1.28842060e-04, 9.99358700e-01],\n",
       "       [5.12395750e-04, 1.28842060e-04, 9.99358700e-01],\n",
       "       [5.12395750e-04, 1.28842060e-04, 9.99358700e-01],\n",
       "       [9.99898800e-01, 1.01241970e-04, 5.85933700e-10],\n",
       "       [9.92987800e-01, 6.95844100e-03, 5.37197100e-05],\n",
       "       [7.12387500e-02, 9.28761240e-01, 1.93275810e-10],\n",
       "       [2.00190880e-05, 1.96983950e-04, 9.99783000e-01],\n",
       "       [9.98966600e-01, 1.03315260e-03, 2.15709140e-07],\n",
       "       [2.49808900e-03, 9.97501900e-01, 1.41613310e-08],\n",
       "       [2.19426120e-03, 9.40262900e-01, 5.75429000e-02],\n",
       "       [9.79150530e-01, 2.08494440e-02, 2.21811300e-10],\n",
       "       [2.00190880e-05, 1.96983950e-04, 9.99783000e-01],\n",
       "       [1.38985540e-03, 9.96782800e-01, 1.82724770e-03],\n",
       "       [7.93705640e-04, 9.98547500e-01, 6.58704840e-04],\n",
       "       [9.99944000e-01, 5.60668400e-05, 2.50386000e-13]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob3 = df_proba3[df_proba3['phage']=='p003ppresabsSTCC_qual'].iloc[:,-3:]\n",
    "y_prob3 = y_prob3.to_numpy()\n",
    "y_prob3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo3 = rocauc_ovo(y_test_over, y_prob3, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr3 = rocauc_ovr(y_test_over, y_prob3, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=456,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat4 = pd.DataFrame(X_test_over[:,0])\n",
    "dat4['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CFBRSa04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS021</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS073</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS049</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CA541</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>NRS387</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>SR1746</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>NRS232</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0  test\n",
       "0    CFBRSa04     0\n",
       "1      NRS021     0\n",
       "2      NRS073     0\n",
       "3      NRS049     0\n",
       "4       CA541     1\n",
       "..        ...   ...\n",
       "197    NRS387     1\n",
       "198    SR1746     0\n",
       "199    NRS148     2\n",
       "200    NRS255     2\n",
       "201    NRS232     1\n",
       "\n",
       "[202 rows x 2 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over4 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],)),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over4.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 470 samples, validate on 202 samples\n",
      "Epoch 1/100\n",
      "470/470 [==============================] - 0s 631us/step - loss: 3.9849 - accuracy: 0.5702 - val_loss: 2.8639 - val_accuracy: 0.5941\n",
      "Epoch 2/100\n",
      "470/470 [==============================] - 0s 230us/step - loss: 1.5341 - accuracy: 0.6277 - val_loss: 0.6642 - val_accuracy: 0.8168\n",
      "Epoch 3/100\n",
      "470/470 [==============================] - 0s 136us/step - loss: 0.5829 - accuracy: 0.7298 - val_loss: 0.3898 - val_accuracy: 0.8168\n",
      "Epoch 4/100\n",
      "470/470 [==============================] - 0s 144us/step - loss: 0.4166 - accuracy: 0.8404 - val_loss: 0.3577 - val_accuracy: 0.8416\n",
      "Epoch 5/100\n",
      "470/470 [==============================] - 0s 168us/step - loss: 0.3519 - accuracy: 0.8745 - val_loss: 0.2847 - val_accuracy: 0.8960\n",
      "Epoch 6/100\n",
      "470/470 [==============================] - 0s 242us/step - loss: 0.2743 - accuracy: 0.9085 - val_loss: 0.2463 - val_accuracy: 0.8960\n",
      "Epoch 7/100\n",
      "470/470 [==============================] - 0s 181us/step - loss: 0.2565 - accuracy: 0.9255 - val_loss: 0.2415 - val_accuracy: 0.9554\n",
      "Epoch 8/100\n",
      "470/470 [==============================] - 0s 153us/step - loss: 0.2740 - accuracy: 0.9234 - val_loss: 0.3026 - val_accuracy: 0.9505\n",
      "Epoch 9/100\n",
      "470/470 [==============================] - 0s 384us/step - loss: 0.2307 - accuracy: 0.9191 - val_loss: 0.2262 - val_accuracy: 0.9208\n",
      "Epoch 10/100\n",
      "470/470 [==============================] - 0s 401us/step - loss: 0.1946 - accuracy: 0.9596 - val_loss: 0.1802 - val_accuracy: 0.9554\n",
      "Epoch 11/100\n",
      "470/470 [==============================] - 0s 234us/step - loss: 0.1747 - accuracy: 0.9447 - val_loss: 0.1852 - val_accuracy: 0.9208\n",
      "Epoch 12/100\n",
      "470/470 [==============================] - 0s 266us/step - loss: 0.2183 - accuracy: 0.9426 - val_loss: 0.3292 - val_accuracy: 0.9505\n",
      "Epoch 13/100\n",
      "470/470 [==============================] - 0s 224us/step - loss: 0.2074 - accuracy: 0.9383 - val_loss: 0.2776 - val_accuracy: 0.9554\n",
      "Epoch 14/100\n",
      "470/470 [==============================] - 0s 131us/step - loss: 0.1917 - accuracy: 0.9468 - val_loss: 0.2091 - val_accuracy: 0.8812\n",
      "Epoch 15/100\n",
      "470/470 [==============================] - 0s 129us/step - loss: 0.1898 - accuracy: 0.9426 - val_loss: 0.1367 - val_accuracy: 0.9455\n",
      "Epoch 16/100\n",
      "470/470 [==============================] - 0s 396us/step - loss: 0.1256 - accuracy: 0.9745 - val_loss: 0.1258 - val_accuracy: 0.9752\n",
      "Epoch 17/100\n",
      "470/470 [==============================] - 0s 382us/step - loss: 0.1268 - accuracy: 0.9660 - val_loss: 0.1228 - val_accuracy: 0.9703\n",
      "Epoch 18/100\n",
      "470/470 [==============================] - 0s 368us/step - loss: 0.1241 - accuracy: 0.9596 - val_loss: 0.1534 - val_accuracy: 0.9653\n",
      "Epoch 19/100\n",
      "470/470 [==============================] - 0s 286us/step - loss: 0.1323 - accuracy: 0.9681 - val_loss: 0.2579 - val_accuracy: 0.9455\n",
      "Epoch 20/100\n",
      "470/470 [==============================] - 0s 367us/step - loss: 0.1915 - accuracy: 0.9553 - val_loss: 0.1241 - val_accuracy: 0.9653\n",
      "Epoch 21/100\n",
      "470/470 [==============================] - 0s 215us/step - loss: 0.0944 - accuracy: 0.9894 - val_loss: 0.1190 - val_accuracy: 0.9505\n",
      "Epoch 22/100\n",
      "470/470 [==============================] - 0s 131us/step - loss: 0.1044 - accuracy: 0.9660 - val_loss: 0.1522 - val_accuracy: 0.9356\n",
      "Epoch 23/100\n",
      "470/470 [==============================] - 0s 128us/step - loss: 0.0985 - accuracy: 0.9851 - val_loss: 0.0930 - val_accuracy: 0.9752\n",
      "Epoch 24/100\n",
      "470/470 [==============================] - 0s 170us/step - loss: 0.0944 - accuracy: 0.9745 - val_loss: 0.1017 - val_accuracy: 0.9802\n",
      "Epoch 25/100\n",
      "470/470 [==============================] - 0s 134us/step - loss: 0.0867 - accuracy: 0.9787 - val_loss: 0.0855 - val_accuracy: 0.9851\n",
      "Epoch 26/100\n",
      "470/470 [==============================] - 0s 144us/step - loss: 0.0778 - accuracy: 0.9851 - val_loss: 0.0822 - val_accuracy: 0.9851\n",
      "Epoch 27/100\n",
      "470/470 [==============================] - 0s 412us/step - loss: 0.0756 - accuracy: 0.9894 - val_loss: 0.1022 - val_accuracy: 0.9604\n",
      "Epoch 28/100\n",
      "470/470 [==============================] - 0s 284us/step - loss: 0.0879 - accuracy: 0.9830 - val_loss: 0.1532 - val_accuracy: 0.9554\n",
      "Epoch 29/100\n",
      "470/470 [==============================] - 0s 140us/step - loss: 0.0817 - accuracy: 0.9766 - val_loss: 0.0844 - val_accuracy: 0.9802\n",
      "Epoch 30/100\n",
      "470/470 [==============================] - 0s 123us/step - loss: 0.0663 - accuracy: 0.9872 - val_loss: 0.1134 - val_accuracy: 0.9604\n",
      "Epoch 31/100\n",
      "470/470 [==============================] - 0s 210us/step - loss: 0.0703 - accuracy: 0.9915 - val_loss: 0.0701 - val_accuracy: 0.9802\n",
      "Epoch 32/100\n",
      "470/470 [==============================] - 0s 123us/step - loss: 0.0594 - accuracy: 0.9957 - val_loss: 0.0755 - val_accuracy: 0.9802\n",
      "Epoch 33/100\n",
      "470/470 [==============================] - 0s 170us/step - loss: 0.0573 - accuracy: 0.9915 - val_loss: 0.0735 - val_accuracy: 0.9901\n",
      "Epoch 34/100\n",
      "470/470 [==============================] - 0s 477us/step - loss: 0.0613 - accuracy: 0.9915 - val_loss: 0.0836 - val_accuracy: 0.9604\n",
      "Epoch 35/100\n",
      "470/470 [==============================] - 0s 265us/step - loss: 0.0562 - accuracy: 0.9915 - val_loss: 0.0661 - val_accuracy: 0.9851\n",
      "Epoch 36/100\n",
      "470/470 [==============================] - 0s 251us/step - loss: 0.0556 - accuracy: 0.9915 - val_loss: 0.0680 - val_accuracy: 0.9901\n",
      "Epoch 37/100\n",
      "470/470 [==============================] - 0s 126us/step - loss: 0.0587 - accuracy: 0.9936 - val_loss: 0.0648 - val_accuracy: 0.9851\n",
      "Epoch 38/100\n",
      "470/470 [==============================] - 0s 119us/step - loss: 0.0526 - accuracy: 0.9936 - val_loss: 0.0639 - val_accuracy: 0.9851\n",
      "Epoch 39/100\n",
      "470/470 [==============================] - 0s 118us/step - loss: 0.0454 - accuracy: 0.9957 - val_loss: 0.0656 - val_accuracy: 0.9851\n",
      "Epoch 40/100\n",
      "470/470 [==============================] - 0s 185us/step - loss: 0.0494 - accuracy: 0.9957 - val_loss: 0.0635 - val_accuracy: 0.9901\n",
      "Epoch 41/100\n",
      "470/470 [==============================] - 0s 228us/step - loss: 0.0431 - accuracy: 0.9936 - val_loss: 0.0689 - val_accuracy: 0.9802\n",
      "Epoch 42/100\n",
      "470/470 [==============================] - 0s 131us/step - loss: 0.0466 - accuracy: 0.9915 - val_loss: 0.0774 - val_accuracy: 0.9752\n",
      "Epoch 43/100\n",
      "470/470 [==============================] - 0s 145us/step - loss: 0.0410 - accuracy: 0.9957 - val_loss: 0.0528 - val_accuracy: 0.9901\n",
      "Epoch 44/100\n",
      "470/470 [==============================] - 0s 196us/step - loss: 0.0408 - accuracy: 0.9957 - val_loss: 0.0516 - val_accuracy: 0.9851\n",
      "Epoch 45/100\n",
      "470/470 [==============================] - 0s 207us/step - loss: 0.0428 - accuracy: 0.9957 - val_loss: 0.0563 - val_accuracy: 0.9851\n",
      "Epoch 46/100\n",
      "470/470 [==============================] - 0s 143us/step - loss: 0.0435 - accuracy: 0.9957 - val_loss: 0.0636 - val_accuracy: 0.9802\n",
      "Epoch 47/100\n",
      "470/470 [==============================] - 0s 155us/step - loss: 0.0392 - accuracy: 0.9957 - val_loss: 0.0667 - val_accuracy: 0.9802\n",
      "Epoch 48/100\n",
      "470/470 [==============================] - 0s 126us/step - loss: 0.0370 - accuracy: 0.9957 - val_loss: 0.0481 - val_accuracy: 0.9851\n",
      "Epoch 49/100\n",
      "470/470 [==============================] - 0s 124us/step - loss: 0.0398 - accuracy: 0.9957 - val_loss: 0.0797 - val_accuracy: 0.9752\n",
      "Epoch 50/100\n",
      "470/470 [==============================] - 0s 116us/step - loss: 0.0407 - accuracy: 0.9957 - val_loss: 0.0463 - val_accuracy: 0.9901\n",
      "Epoch 51/100\n",
      "470/470 [==============================] - 0s 136us/step - loss: 0.0373 - accuracy: 0.9957 - val_loss: 0.0543 - val_accuracy: 0.9851\n",
      "Epoch 52/100\n",
      "470/470 [==============================] - 0s 191us/step - loss: 0.0355 - accuracy: 0.9957 - val_loss: 0.0531 - val_accuracy: 0.9802\n",
      "Epoch 53/100\n",
      "470/470 [==============================] - 0s 136us/step - loss: 0.0367 - accuracy: 0.9957 - val_loss: 0.0415 - val_accuracy: 0.9851\n",
      "Epoch 54/100\n",
      "470/470 [==============================] - 0s 127us/step - loss: 0.0373 - accuracy: 0.9957 - val_loss: 0.0529 - val_accuracy: 0.9851\n",
      "Epoch 55/100\n",
      "470/470 [==============================] - 0s 150us/step - loss: 0.0345 - accuracy: 0.9957 - val_loss: 0.0483 - val_accuracy: 0.9851\n",
      "Epoch 56/100\n",
      "470/470 [==============================] - 0s 174us/step - loss: 0.0320 - accuracy: 0.9957 - val_loss: 0.0439 - val_accuracy: 0.9901\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "470/470 [==============================] - 0s 119us/step - loss: 0.0323 - accuracy: 0.9957 - val_loss: 0.0494 - val_accuracy: 0.9851\n",
      "Epoch 58/100\n",
      "470/470 [==============================] - 0s 135us/step - loss: 0.0339 - accuracy: 0.9957 - val_loss: 0.0434 - val_accuracy: 0.9901\n",
      "Epoch 59/100\n",
      "470/470 [==============================] - 0s 184us/step - loss: 0.0398 - accuracy: 0.9936 - val_loss: 0.0424 - val_accuracy: 0.9851\n",
      "Epoch 60/100\n",
      "470/470 [==============================] - 0s 126us/step - loss: 0.0497 - accuracy: 0.9894 - val_loss: 0.0531 - val_accuracy: 0.9851\n",
      "Epoch 61/100\n",
      "470/470 [==============================] - 0s 119us/step - loss: 0.0435 - accuracy: 0.9872 - val_loss: 0.0779 - val_accuracy: 0.9752\n",
      "Epoch 62/100\n",
      "470/470 [==============================] - 0s 132us/step - loss: 0.0536 - accuracy: 0.9872 - val_loss: 0.1798 - val_accuracy: 0.9703\n",
      "Epoch 63/100\n",
      "470/470 [==============================] - 0s 134us/step - loss: 0.0989 - accuracy: 0.9723 - val_loss: 0.0665 - val_accuracy: 0.9752\n",
      "Epoch 64/100\n",
      "470/470 [==============================] - 0s 189us/step - loss: 0.0652 - accuracy: 0.9894 - val_loss: 0.0603 - val_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "470/470 [==============================] - 0s 188us/step - loss: 0.0517 - accuracy: 0.9894 - val_loss: 0.0554 - val_accuracy: 0.9802\n",
      "Epoch 66/100\n",
      "470/470 [==============================] - 0s 177us/step - loss: 0.0294 - accuracy: 0.9957 - val_loss: 0.0448 - val_accuracy: 0.9950\n",
      "Epoch 67/100\n",
      "470/470 [==============================] - 0s 143us/step - loss: 0.0295 - accuracy: 0.9957 - val_loss: 0.0387 - val_accuracy: 0.9851\n",
      "Epoch 68/100\n",
      "470/470 [==============================] - 0s 180us/step - loss: 0.0252 - accuracy: 0.9957 - val_loss: 0.0304 - val_accuracy: 0.9950\n",
      "Epoch 69/100\n",
      "470/470 [==============================] - 0s 212us/step - loss: 0.0222 - accuracy: 0.9957 - val_loss: 0.0356 - val_accuracy: 0.9851\n",
      "Epoch 70/100\n",
      "470/470 [==============================] - 0s 186us/step - loss: 0.0214 - accuracy: 0.9957 - val_loss: 0.0448 - val_accuracy: 0.9802\n",
      "Epoch 71/100\n",
      "470/470 [==============================] - 0s 151us/step - loss: 0.0239 - accuracy: 0.9957 - val_loss: 0.0303 - val_accuracy: 0.9851\n",
      "Epoch 72/100\n",
      "470/470 [==============================] - 0s 157us/step - loss: 0.0209 - accuracy: 0.9957 - val_loss: 0.0356 - val_accuracy: 0.9851\n",
      "Epoch 73/100\n",
      "470/470 [==============================] - 0s 169us/step - loss: 0.0206 - accuracy: 0.9957 - val_loss: 0.0296 - val_accuracy: 0.9950\n",
      "Epoch 74/100\n",
      "470/470 [==============================] - 0s 256us/step - loss: 0.0230 - accuracy: 0.9957 - val_loss: 0.0397 - val_accuracy: 0.9851\n",
      "Epoch 75/100\n",
      "470/470 [==============================] - 0s 151us/step - loss: 0.0189 - accuracy: 0.9957 - val_loss: 0.0335 - val_accuracy: 0.9901\n",
      "Epoch 76/100\n",
      "470/470 [==============================] - 0s 119us/step - loss: 0.0199 - accuracy: 0.9957 - val_loss: 0.0326 - val_accuracy: 0.9851\n",
      "Epoch 77/100\n",
      "470/470 [==============================] - 0s 166us/step - loss: 0.0190 - accuracy: 0.9957 - val_loss: 0.0402 - val_accuracy: 0.9851\n",
      "Epoch 78/100\n",
      "470/470 [==============================] - 0s 120us/step - loss: 0.0204 - accuracy: 0.9957 - val_loss: 0.0306 - val_accuracy: 0.9950\n",
      "Epoch 79/100\n",
      "470/470 [==============================] - 0s 132us/step - loss: 0.0194 - accuracy: 0.9957 - val_loss: 0.0310 - val_accuracy: 0.9950\n",
      "Epoch 80/100\n",
      "470/470 [==============================] - 0s 193us/step - loss: 0.0203 - accuracy: 0.9979 - val_loss: 0.0598 - val_accuracy: 0.9752\n",
      "Epoch 81/100\n",
      "470/470 [==============================] - 0s 161us/step - loss: 0.0240 - accuracy: 0.9957 - val_loss: 0.0280 - val_accuracy: 0.9950\n",
      "Epoch 82/100\n",
      "470/470 [==============================] - 0s 152us/step - loss: 0.0208 - accuracy: 0.9957 - val_loss: 0.0285 - val_accuracy: 0.9950\n",
      "Epoch 83/100\n",
      "470/470 [==============================] - 0s 184us/step - loss: 0.0184 - accuracy: 0.9979 - val_loss: 0.0363 - val_accuracy: 0.9851\n",
      "Epoch 84/100\n",
      "470/470 [==============================] - 0s 258us/step - loss: 0.0189 - accuracy: 0.9957 - val_loss: 0.0355 - val_accuracy: 0.9901\n",
      "Epoch 85/100\n",
      "470/470 [==============================] - 0s 337us/step - loss: 0.0171 - accuracy: 0.9957 - val_loss: 0.0262 - val_accuracy: 0.9950\n",
      "Epoch 86/100\n",
      "470/470 [==============================] - 0s 307us/step - loss: 0.0183 - accuracy: 0.9957 - val_loss: 0.0520 - val_accuracy: 0.9752\n",
      "Epoch 87/100\n",
      "470/470 [==============================] - 0s 336us/step - loss: 0.0221 - accuracy: 0.9957 - val_loss: 0.0287 - val_accuracy: 0.9901\n",
      "Epoch 88/100\n",
      "470/470 [==============================] - 0s 256us/step - loss: 0.0213 - accuracy: 0.9936 - val_loss: 0.0296 - val_accuracy: 0.9950\n",
      "Epoch 89/100\n",
      "470/470 [==============================] - 0s 167us/step - loss: 0.0184 - accuracy: 0.9957 - val_loss: 0.0399 - val_accuracy: 0.9851\n",
      "Epoch 90/100\n",
      "470/470 [==============================] - 0s 143us/step - loss: 0.0182 - accuracy: 0.9957 - val_loss: 0.0276 - val_accuracy: 0.9901\n",
      "Epoch 91/100\n",
      "470/470 [==============================] - 0s 131us/step - loss: 0.0186 - accuracy: 0.9957 - val_loss: 0.0260 - val_accuracy: 0.9950\n",
      "Epoch 92/100\n",
      "470/470 [==============================] - 0s 331us/step - loss: 0.0153 - accuracy: 0.9957 - val_loss: 0.0262 - val_accuracy: 0.9901\n",
      "Epoch 93/100\n",
      "470/470 [==============================] - 0s 277us/step - loss: 0.0190 - accuracy: 0.9979 - val_loss: 0.0487 - val_accuracy: 0.9802\n",
      "Epoch 94/100\n",
      "470/470 [==============================] - 0s 321us/step - loss: 0.0229 - accuracy: 0.9957 - val_loss: 0.0437 - val_accuracy: 0.9851\n",
      "Epoch 95/100\n",
      "470/470 [==============================] - 0s 231us/step - loss: 0.0210 - accuracy: 0.9957 - val_loss: 0.0277 - val_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "470/470 [==============================] - 0s 207us/step - loss: 0.0193 - accuracy: 0.9957 - val_loss: 0.0253 - val_accuracy: 0.9901\n",
      "Epoch 97/100\n",
      "470/470 [==============================] - 0s 146us/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 0.0479 - val_accuracy: 0.9851\n",
      "Epoch 98/100\n",
      "470/470 [==============================] - 0s 142us/step - loss: 0.0174 - accuracy: 0.9957 - val_loss: 0.0227 - val_accuracy: 0.9901\n",
      "Epoch 99/100\n",
      "470/470 [==============================] - 0s 179us/step - loss: 0.0158 - accuracy: 0.9957 - val_loss: 0.0217 - val_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "470/470 [==============================] - 0s 150us/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 0.0544 - val_accuracy: 0.9802\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a3d37bd30>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over4.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202/202 [==============================] - 0s 108us/step\n",
      "over-sampling test accuracy: 99.01%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over4 = model1_over4.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over4*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 2, 2, 2, 2, 1, 0, 2, 1, 2, 0,\n",
       "       0, 1, 0, 0, 0, 2, 1, 1, 0, 0, 2, 0, 2, 2, 1, 1, 1, 1, 1, 2, 0, 0,\n",
       "       0, 1, 2, 1, 1, 0, 1, 2, 0, 1, 2, 1, 1, 1, 2, 1, 0, 2, 2, 2, 0, 0,\n",
       "       2, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 2, 1, 1, 0, 1, 1, 0, 2, 2, 0, 2,\n",
       "       2, 1, 2, 0, 0, 2, 1, 1, 2, 2, 2, 1, 1, 2, 0, 2, 1, 1, 1, 2, 0, 0,\n",
       "       0, 1, 2, 1, 1, 2, 0, 1, 2, 0, 0, 2, 1, 2, 1, 2, 1, 1, 0, 0, 0, 0,\n",
       "       0, 1, 1, 0, 0, 1, 2, 0, 1, 1, 1, 0, 2, 1, 0, 1, 1, 1, 2, 2, 2, 2,\n",
       "       1, 2, 1, 2, 0, 2, 0, 0, 2, 1, 1, 0, 1, 0, 2, 0, 0, 0, 2, 0, 2, 1,\n",
       "       2, 2, 1, 2, 1, 2, 2, 1, 0, 2, 2, 0, 0, 2, 1, 0, 0, 2, 2, 2, 0, 1,\n",
       "       0, 2, 2, 1])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred4 = model1_over4.predict_classes(X_test_over)\n",
    "pred4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CFBRSa04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS021</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS073</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS049</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CA541</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>NRS387</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>SR1746</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>NRS232</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0  test  pred\n",
       "0    CFBRSa04     0     0\n",
       "1      NRS021     0     0\n",
       "2      NRS073     0     0\n",
       "3      NRS049     0     0\n",
       "4       CA541     1     1\n",
       "..        ...   ...   ...\n",
       "197    NRS387     1     1\n",
       "198    SR1746     0     0\n",
       "199    NRS148     2     2\n",
       "200    NRS255     2     2\n",
       "201    NRS232     1     1\n",
       "\n",
       "[202 rows x 3 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat4['pred'] = pred4\n",
    "dat4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba4 = model1_over4.predict_proba(X_test_over)\n",
    "dat_proba4 = pd.DataFrame(proba4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.999366</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>4.865112e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.983386</td>\n",
       "      <td>0.016614</td>\n",
       "      <td>1.033543e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.975474</td>\n",
       "      <td>0.024526</td>\n",
       "      <td>2.480035e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.570170</td>\n",
       "      <td>0.428658</td>\n",
       "      <td>1.171963e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.007818</td>\n",
       "      <td>0.992128</td>\n",
       "      <td>5.324918e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.007140</td>\n",
       "      <td>0.992790</td>\n",
       "      <td>6.977263e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.516005</td>\n",
       "      <td>0.483995</td>\n",
       "      <td>2.800119e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.007481</td>\n",
       "      <td>9.925161e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.001138</td>\n",
       "      <td>9.987515e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>0.003537</td>\n",
       "      <td>0.996274</td>\n",
       "      <td>1.888078e-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1             2\n",
       "0    0.999366  0.000633  4.865112e-07\n",
       "1    0.983386  0.016614  1.033543e-10\n",
       "2    0.975474  0.024526  2.480035e-10\n",
       "3    0.570170  0.428658  1.171963e-03\n",
       "4    0.007818  0.992128  5.324918e-05\n",
       "..        ...       ...           ...\n",
       "197  0.007140  0.992790  6.977263e-05\n",
       "198  0.516005  0.483995  2.800119e-08\n",
       "199  0.000003  0.007481  9.925161e-01\n",
       "200  0.000111  0.001138  9.987515e-01\n",
       "201  0.003537  0.996274  1.888078e-04\n",
       "\n",
       "[202 rows x 3 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba4.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba4.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat4.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/4p003ppST.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 470 samples, validate on 202 samples\n",
      "Epoch 1/100\n",
      "470/470 [==============================] - 0s 298us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0184 - val_accuracy: 0.9901\n",
      "Epoch 2/100\n",
      "470/470 [==============================] - 0s 219us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0281 - val_accuracy: 0.9851\n",
      "Epoch 3/100\n",
      "470/470 [==============================] - 0s 190us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0202 - val_accuracy: 0.9901\n",
      "Epoch 4/100\n",
      "470/470 [==============================] - 0s 175us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0214 - val_accuracy: 0.9901\n",
      "Epoch 5/100\n",
      "470/470 [==============================] - 0s 171us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0186 - val_accuracy: 0.9901\n",
      "Epoch 6/100\n",
      "470/470 [==============================] - 0s 208us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0229 - val_accuracy: 0.9901\n",
      "Epoch 7/100\n",
      "470/470 [==============================] - 0s 137us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0242 - val_accuracy: 0.9901\n",
      "Epoch 8/100\n",
      "470/470 [==============================] - 0s 136us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0218 - val_accuracy: 0.9901\n",
      "Epoch 9/100\n",
      "470/470 [==============================] - 0s 140us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0231 - val_accuracy: 0.9901\n",
      "Epoch 10/100\n",
      "470/470 [==============================] - 0s 144us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0256 - val_accuracy: 0.9901\n",
      "Epoch 11/100\n",
      "470/470 [==============================] - 0s 165us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0153 - val_accuracy: 0.9950\n",
      "Epoch 12/100\n",
      "470/470 [==============================] - 0s 183us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0264 - val_accuracy: 0.9901\n",
      "Epoch 13/100\n",
      "470/470 [==============================] - 0s 151us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0185 - val_accuracy: 0.9950\n",
      "Epoch 14/100\n",
      "470/470 [==============================] - 0s 138us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0258 - val_accuracy: 0.9901\n",
      "Epoch 15/100\n",
      "470/470 [==============================] - 0s 152us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0189 - val_accuracy: 0.9950\n",
      "Epoch 16/100\n",
      "470/470 [==============================] - 0s 161us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0274 - val_accuracy: 0.9901\n",
      "Epoch 17/100\n",
      "470/470 [==============================] - 0s 162us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0174 - val_accuracy: 0.9901\n",
      "Epoch 18/100\n",
      "470/470 [==============================] - 0s 136us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0195 - val_accuracy: 0.9901\n",
      "Epoch 19/100\n",
      "470/470 [==============================] - 0s 134us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0275 - val_accuracy: 0.9901\n",
      "Epoch 20/100\n",
      "470/470 [==============================] - 0s 155us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0195 - val_accuracy: 0.9901\n",
      "Epoch 21/100\n",
      "470/470 [==============================] - 0s 179us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0268 - val_accuracy: 0.9901\n",
      "Epoch 22/100\n",
      "470/470 [==============================] - 0s 185us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0194 - val_accuracy: 0.9901\n",
      "Epoch 23/100\n",
      "470/470 [==============================] - 0s 184us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0186 - val_accuracy: 0.9901\n",
      "Epoch 24/100\n",
      "470/470 [==============================] - 0s 187us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0254 - val_accuracy: 0.9901\n",
      "Epoch 25/100\n",
      "470/470 [==============================] - 0s 181us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0187 - val_accuracy: 0.9901\n",
      "Epoch 26/100\n",
      "470/470 [==============================] - 0s 173us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0241 - val_accuracy: 0.9901\n",
      "Epoch 27/100\n",
      "470/470 [==============================] - 0s 215us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0196 - val_accuracy: 0.9901\n",
      "Epoch 28/100\n",
      "470/470 [==============================] - 0s 192us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0231 - val_accuracy: 0.9901\n",
      "Epoch 29/100\n",
      "470/470 [==============================] - 0s 165us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0194 - val_accuracy: 0.9901\n",
      "Epoch 30/100\n",
      "470/470 [==============================] - 0s 141us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0221 - val_accuracy: 0.9901\n",
      "Epoch 31/100\n",
      "470/470 [==============================] - 0s 131us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0222 - val_accuracy: 0.9901\n",
      "Epoch 32/100\n",
      "470/470 [==============================] - 0s 134us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0228 - val_accuracy: 0.9901\n",
      "Epoch 33/100\n",
      "470/470 [==============================] - 0s 150us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0198 - val_accuracy: 0.9901\n",
      "Epoch 34/100\n",
      "470/470 [==============================] - 0s 142us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0215 - val_accuracy: 0.9901\n",
      "Epoch 35/100\n",
      "470/470 [==============================] - 0s 128us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0247 - val_accuracy: 0.9901\n",
      "Epoch 36/100\n",
      "470/470 [==============================] - 0s 141us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0246 - val_accuracy: 0.9901\n",
      "Epoch 37/100\n",
      "470/470 [==============================] - 0s 140us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0219 - val_accuracy: 0.9901\n",
      "Epoch 38/100\n",
      "470/470 [==============================] - 0s 145us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0230 - val_accuracy: 0.9901\n",
      "Epoch 39/100\n",
      "470/470 [==============================] - ETA: 0s - loss: 9.2704e-04 - accuracy: 1.00 - 0s 140us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0189 - val_accuracy: 0.9901\n",
      "Epoch 40/100\n",
      "470/470 [==============================] - 0s 138us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0212 - val_accuracy: 0.9901\n",
      "Epoch 41/100\n",
      "470/470 [==============================] - 0s 138us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0229 - val_accuracy: 0.9901\n",
      "Epoch 42/100\n",
      "470/470 [==============================] - 0s 138us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0198 - val_accuracy: 0.9901\n",
      "Epoch 43/100\n",
      "470/470 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 1.00 - 0s 140us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0265 - val_accuracy: 0.9901\n",
      "Epoch 44/100\n",
      "470/470 [==============================] - 0s 129us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0155 - val_accuracy: 0.9950\n",
      "Epoch 45/100\n",
      "470/470 [==============================] - 0s 127us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0282 - val_accuracy: 0.9901\n",
      "Epoch 46/100\n",
      "470/470 [==============================] - 0s 137us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0203 - val_accuracy: 0.9901\n",
      "Epoch 47/100\n",
      "470/470 [==============================] - 0s 140us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0225 - val_accuracy: 0.9901\n",
      "Epoch 48/100\n",
      "470/470 [==============================] - 0s 123us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0204 - val_accuracy: 0.9901\n",
      "Epoch 49/100\n",
      "470/470 [==============================] - 0s 121us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0226 - val_accuracy: 0.9901\n",
      "Epoch 50/100\n",
      "470/470 [==============================] - 0s 121us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0207 - val_accuracy: 0.9901\n",
      "Epoch 51/100\n",
      "470/470 [==============================] - 0s 122us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0229 - val_accuracy: 0.9901\n",
      "Epoch 52/100\n",
      "470/470 [==============================] - 0s 122us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0246 - val_accuracy: 0.9901\n",
      "Epoch 53/100\n",
      "470/470 [==============================] - 0s 121us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0163 - val_accuracy: 0.9901\n",
      "Epoch 54/100\n",
      "470/470 [==============================] - 0s 120us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0217 - val_accuracy: 0.9901\n",
      "Epoch 55/100\n",
      "470/470 [==============================] - 0s 121us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0203 - val_accuracy: 0.9901\n",
      "Epoch 56/100\n",
      "470/470 [==============================] - 0s 122us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0265 - val_accuracy: 0.9901\n",
      "Epoch 57/100\n",
      "470/470 [==============================] - 0s 127us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0175 - val_accuracy: 0.9950\n",
      "Epoch 58/100\n",
      "470/470 [==============================] - 0s 120us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0250 - val_accuracy: 0.9901\n",
      "Epoch 59/100\n",
      "470/470 [==============================] - 0s 150us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0199 - val_accuracy: 0.9901\n",
      "Epoch 60/100\n",
      "470/470 [==============================] - 0s 167us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0218 - val_accuracy: 0.9901\n",
      "Epoch 61/100\n",
      "470/470 [==============================] - 0s 137us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0231 - val_accuracy: 0.9901\n",
      "Epoch 62/100\n",
      "470/470 [==============================] - 0s 122us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0200 - val_accuracy: 0.9901\n",
      "Epoch 63/100\n",
      "470/470 [==============================] - 0s 114us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0231 - val_accuracy: 0.9901\n",
      "Epoch 64/100\n",
      "470/470 [==============================] - 0s 120us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0227 - val_accuracy: 0.9901\n",
      "Epoch 65/100\n",
      "470/470 [==============================] - 0s 114us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0208 - val_accuracy: 0.9901\n",
      "Epoch 66/100\n",
      "470/470 [==============================] - 0s 112us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0198 - val_accuracy: 0.9901\n",
      "Epoch 67/100\n",
      "470/470 [==============================] - 0s 114us/step - loss: 9.7219e-04 - accuracy: 1.0000 - val_loss: 0.0233 - val_accuracy: 0.9901\n",
      "Epoch 68/100\n",
      "470/470 [==============================] - 0s 131us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0185 - val_accuracy: 0.9901\n",
      "Epoch 69/100\n",
      "470/470 [==============================] - 0s 141us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0188 - val_accuracy: 0.9901\n",
      "Epoch 70/100\n",
      "470/470 [==============================] - 0s 145us/step - loss: 9.5863e-04 - accuracy: 1.0000 - val_loss: 0.0237 - val_accuracy: 0.9901\n",
      "Epoch 71/100\n",
      "470/470 [==============================] - 0s 136us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0184 - val_accuracy: 0.9901\n",
      "Epoch 72/100\n",
      "470/470 [==============================] - 0s 130us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0254 - val_accuracy: 0.9901\n",
      "Epoch 73/100\n",
      "470/470 [==============================] - 0s 125us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0173 - val_accuracy: 0.9901\n",
      "Epoch 74/100\n",
      "470/470 [==============================] - 0s 116us/step - loss: 9.8561e-04 - accuracy: 1.0000 - val_loss: 0.0241 - val_accuracy: 0.9901\n",
      "Epoch 75/100\n",
      "470/470 [==============================] - 0s 115us/step - loss: 8.8726e-04 - accuracy: 1.0000 - val_loss: 0.0201 - val_accuracy: 0.9901\n",
      "Epoch 76/100\n",
      "470/470 [==============================] - 0s 114us/step - loss: 8.7060e-04 - accuracy: 1.0000 - val_loss: 0.0254 - val_accuracy: 0.9901\n",
      "Epoch 77/100\n",
      "470/470 [==============================] - 0s 114us/step - loss: 9.5134e-04 - accuracy: 1.0000 - val_loss: 0.0185 - val_accuracy: 0.9901\n",
      "Epoch 78/100\n",
      "470/470 [==============================] - 0s 122us/step - loss: 8.5402e-04 - accuracy: 1.0000 - val_loss: 0.0246 - val_accuracy: 0.9901\n",
      "Epoch 79/100\n",
      "470/470 [==============================] - 0s 115us/step - loss: 9.1534e-04 - accuracy: 1.0000 - val_loss: 0.0179 - val_accuracy: 0.9901\n",
      "Epoch 80/100\n",
      "470/470 [==============================] - 0s 115us/step - loss: 8.9277e-04 - accuracy: 1.0000 - val_loss: 0.0221 - val_accuracy: 0.9901\n",
      "Epoch 81/100\n",
      "470/470 [==============================] - 0s 119us/step - loss: 8.6840e-04 - accuracy: 1.0000 - val_loss: 0.0244 - val_accuracy: 0.9901\n",
      "Epoch 82/100\n",
      "470/470 [==============================] - 0s 115us/step - loss: 8.9654e-04 - accuracy: 1.0000 - val_loss: 0.0186 - val_accuracy: 0.9950\n",
      "Epoch 83/100\n",
      "470/470 [==============================] - 0s 121us/step - loss: 7.8464e-04 - accuracy: 1.0000 - val_loss: 0.0242 - val_accuracy: 0.9901\n",
      "Epoch 84/100\n",
      "470/470 [==============================] - 0s 114us/step - loss: 8.6097e-04 - accuracy: 1.0000 - val_loss: 0.0223 - val_accuracy: 0.9901\n",
      "Epoch 85/100\n",
      "470/470 [==============================] - 0s 116us/step - loss: 8.1940e-04 - accuracy: 1.0000 - val_loss: 0.0209 - val_accuracy: 0.9901\n",
      "Epoch 86/100\n",
      "470/470 [==============================] - 0s 124us/step - loss: 8.2316e-04 - accuracy: 1.0000 - val_loss: 0.0220 - val_accuracy: 0.9901\n",
      "Epoch 87/100\n",
      "470/470 [==============================] - 0s 116us/step - loss: 8.2829e-04 - accuracy: 1.0000 - val_loss: 0.0245 - val_accuracy: 0.9901\n",
      "Epoch 88/100\n",
      "470/470 [==============================] - 0s 116us/step - loss: 7.8169e-04 - accuracy: 1.0000 - val_loss: 0.0227 - val_accuracy: 0.9901\n",
      "Epoch 89/100\n",
      "470/470 [==============================] - 0s 118us/step - loss: 8.0992e-04 - accuracy: 1.0000 - val_loss: 0.0224 - val_accuracy: 0.9901\n",
      "Epoch 90/100\n",
      "470/470 [==============================] - 0s 116us/step - loss: 7.6823e-04 - accuracy: 1.0000 - val_loss: 0.0205 - val_accuracy: 0.9901\n",
      "Epoch 91/100\n",
      "470/470 [==============================] - 0s 122us/step - loss: 7.7520e-04 - accuracy: 1.0000 - val_loss: 0.0225 - val_accuracy: 0.9901\n",
      "Epoch 92/100\n",
      "470/470 [==============================] - ETA: 0s - loss: 7.4526e-04 - accuracy: 1.00 - 0s 170us/step - loss: 7.3707e-04 - accuracy: 1.0000 - val_loss: 0.0207 - val_accuracy: 0.9901\n",
      "Epoch 93/100\n",
      "470/470 [==============================] - 0s 139us/step - loss: 7.3604e-04 - accuracy: 1.0000 - val_loss: 0.0219 - val_accuracy: 0.9901\n",
      "Epoch 94/100\n",
      "470/470 [==============================] - 0s 144us/step - loss: 7.3006e-04 - accuracy: 1.0000 - val_loss: 0.0222 - val_accuracy: 0.9901\n",
      "Epoch 95/100\n",
      "470/470 [==============================] - 0s 149us/step - loss: 7.7460e-04 - accuracy: 1.0000 - val_loss: 0.0182 - val_accuracy: 0.9901\n",
      "Epoch 96/100\n",
      "470/470 [==============================] - 0s 152us/step - loss: 7.6087e-04 - accuracy: 1.0000 - val_loss: 0.0206 - val_accuracy: 0.9901\n",
      "Epoch 97/100\n",
      "470/470 [==============================] - 0s 176us/step - loss: 7.2235e-04 - accuracy: 1.0000 - val_loss: 0.0224 - val_accuracy: 0.9901\n",
      "Epoch 98/100\n",
      "470/470 [==============================] - 0s 181us/step - loss: 7.5240e-04 - accuracy: 1.0000 - val_loss: 0.0259 - val_accuracy: 0.9901\n",
      "Epoch 99/100\n",
      "470/470 [==============================] - 0s 294us/step - loss: 7.2538e-04 - accuracy: 1.0000 - val_loss: 0.0183 - val_accuracy: 0.9901\n",
      "Epoch 100/100\n",
      "470/470 [==============================] - 0s 252us/step - loss: 6.8552e-04 - accuracy: 1.0000 - val_loss: 0.0238 - val_accuracy: 0.9901\n"
     ]
    }
   ],
   "source": [
    "hist1_over4 = model1_over4.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over4.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba4 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_2.xlsx\",\n",
    "                        sheet_name=3,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS110</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>5.870196e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS216</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.039254</td>\n",
       "      <td>0.960745</td>\n",
       "      <td>9.078969e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS386</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.326752</td>\n",
       "      <td>0.673248</td>\n",
       "      <td>1.061032e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>CFBRSa25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.611084</td>\n",
       "      <td>0.388916</td>\n",
       "      <td>7.664974e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>BCH-SA-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.611084</td>\n",
       "      <td>0.388916</td>\n",
       "      <td>7.664974e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4279</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS236</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.999768</td>\n",
       "      <td>1.803156e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4280</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS029</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.322350</td>\n",
       "      <td>0.677496</td>\n",
       "      <td>1.533154e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4281</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>9.999682e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4282</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>CFBRSa28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999288</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>5.361527e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4283</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS205</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>9.999868e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4284 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    phage     strain  phenotype  prediction         0  \\\n",
       "0      p002ykpresabs_qual     NRS110          1           1  0.000003   \n",
       "1      p002ykpresabs_qual     NRS216          1           1  0.039254   \n",
       "2      p002ykpresabs_qual     NRS386          1           1  0.326752   \n",
       "3      p002ykpresabs_qual   CFBRSa25          0           0  0.611084   \n",
       "4      p002ykpresabs_qual  BCH-SA-03          1           0  0.611084   \n",
       "...                   ...        ...        ...         ...       ...   \n",
       "4279  pyopresabsSTCC_qual     NRS236          1           1  0.000052   \n",
       "4280  pyopresabsSTCC_qual     NRS029          0           1  0.322350   \n",
       "4281  pyopresabsSTCC_qual     NRS148          2           2  0.000006   \n",
       "4282  pyopresabsSTCC_qual   CFBRSa28          0           0  0.999288   \n",
       "4283  pyopresabsSTCC_qual     NRS205          2           2  0.000007   \n",
       "\n",
       "             1             2  \n",
       "0     0.999997  5.870196e-13  \n",
       "1     0.960745  9.078969e-07  \n",
       "2     0.673248  1.061032e-07  \n",
       "3     0.388916  7.664974e-07  \n",
       "4     0.388916  7.664974e-07  \n",
       "...        ...           ...  \n",
       "4279  0.999768  1.803156e-04  \n",
       "4280  0.677496  1.533154e-04  \n",
       "4281  0.000026  9.999682e-01  \n",
       "4282  0.000176  5.361527e-04  \n",
       "4283  0.000007  9.999868e-01  \n",
       "\n",
       "[4284 rows x 7 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.99366100e-01, 6.33382200e-04, 4.86511200e-07],\n",
       "       [9.83386000e-01, 1.66140370e-02, 1.03354290e-10],\n",
       "       [9.75474100e-01, 2.45258720e-02, 2.48003480e-10],\n",
       "       [5.70169870e-01, 4.28658220e-01, 1.17196330e-03],\n",
       "       [7.81840200e-03, 9.92128400e-01, 5.32491800e-05],\n",
       "       [1.13398490e-03, 9.98866100e-01, 7.69132000e-12],\n",
       "       [4.98751900e-04, 9.97489100e-01, 2.01220740e-03],\n",
       "       [3.22916300e-03, 9.96744160e-01, 2.66253920e-05],\n",
       "       [9.96499660e-01, 3.49792580e-03, 2.34041980e-06],\n",
       "       [9.99869470e-01, 1.30563840e-04, 1.34077836e-11],\n",
       "       [9.99535440e-01, 4.64594220e-04, 9.93066200e-10],\n",
       "       [9.56812860e-01, 4.31799930e-02, 7.20720570e-06],\n",
       "       [1.10811154e-04, 1.13763330e-03, 9.98751500e-01],\n",
       "       [1.34385970e-08, 4.03788030e-04, 9.99596200e-01],\n",
       "       [1.10811154e-04, 1.13763330e-03, 9.98751500e-01],\n",
       "       [1.34385970e-08, 4.03788030e-04, 9.99596200e-01],\n",
       "       [4.32178460e-05, 9.99825660e-01, 1.31092240e-04],\n",
       "       [8.10826000e-01, 1.89174030e-01, 2.39386330e-09],\n",
       "       [1.34385970e-08, 4.03788030e-04, 9.99596200e-01],\n",
       "       [2.93131600e-03, 9.97068100e-01, 6.42830860e-07],\n",
       "       [1.10811154e-04, 1.13763330e-03, 9.98751500e-01],\n",
       "       [9.73964040e-01, 2.60360330e-02, 1.84137750e-10],\n",
       "       [9.99790970e-01, 2.08874500e-04, 1.25513650e-07],\n",
       "       [5.48493160e-03, 9.94515060e-01, 2.37068090e-11],\n",
       "       [7.12228500e-01, 2.87639440e-01, 1.32015700e-04],\n",
       "       [9.99869470e-01, 1.30563840e-04, 1.34077836e-11],\n",
       "       [9.87088600e-01, 1.29113050e-02, 1.13010350e-09],\n",
       "       [1.34385970e-08, 4.03788030e-04, 9.99596200e-01],\n",
       "       [3.24688850e-03, 9.96399300e-01, 3.53813520e-04],\n",
       "       [3.00574520e-04, 9.99699500e-01, 4.63930050e-08],\n",
       "       [9.96839170e-01, 3.16079730e-03, 4.49229350e-08],\n",
       "       [9.99680040e-01, 3.18579930e-04, 1.45145910e-06],\n",
       "       [1.10811154e-04, 1.13763330e-03, 9.98751500e-01],\n",
       "       [9.24532230e-01, 7.54672800e-02, 5.41467560e-07],\n",
       "       [3.04960780e-06, 7.48091300e-03, 9.92516100e-01],\n",
       "       [3.04960780e-06, 7.48091300e-03, 9.92516100e-01],\n",
       "       [1.27173410e-03, 9.98559400e-01, 1.68901960e-04],\n",
       "       [2.93131600e-03, 9.97068100e-01, 6.42830860e-07],\n",
       "       [4.32178460e-05, 9.99825660e-01, 1.31092240e-04],\n",
       "       [4.98751900e-04, 9.97489100e-01, 2.01220740e-03],\n",
       "       [2.51417630e-03, 9.97325400e-01, 1.60441590e-04],\n",
       "       [1.34385970e-08, 4.03788030e-04, 9.99596200e-01],\n",
       "       [9.99995600e-01, 1.76259630e-06, 2.62749840e-06],\n",
       "       [9.99225400e-01, 7.73508200e-04, 1.05955420e-06],\n",
       "       [8.96210000e-01, 1.03790000e-01, 5.63805450e-10],\n",
       "       [4.32178460e-05, 9.99825660e-01, 1.31092240e-04],\n",
       "       [3.04960780e-06, 7.48091300e-03, 9.92516100e-01],\n",
       "       [1.13398490e-03, 9.98866100e-01, 7.69132000e-12],\n",
       "       [3.24688850e-03, 9.96399300e-01, 3.53813520e-04],\n",
       "       [9.38766700e-01, 6.12071640e-02, 2.61719090e-05],\n",
       "       [4.32178460e-05, 9.99825660e-01, 1.31092240e-04],\n",
       "       [1.34385970e-08, 4.03788030e-04, 9.99596200e-01],\n",
       "       [9.99629000e-01, 3.70727760e-04, 1.95399370e-07],\n",
       "       [1.38889640e-03, 9.98555960e-01, 5.51001760e-05],\n",
       "       [3.04960780e-06, 7.48091300e-03, 9.92516100e-01],\n",
       "       [5.48493160e-03, 9.94515060e-01, 2.37068090e-11],\n",
       "       [7.13968000e-03, 9.92790460e-01, 6.97726300e-05],\n",
       "       [2.80915400e-03, 9.97141540e-01, 4.93639600e-05],\n",
       "       [1.34385970e-08, 4.03788030e-04, 9.99596200e-01],\n",
       "       [5.48493160e-03, 9.94515060e-01, 2.37068090e-11],\n",
       "       [9.99993200e-01, 6.75875530e-06, 2.12677930e-08],\n",
       "       [1.10811154e-04, 1.13763330e-03, 9.98751500e-01],\n",
       "       [1.10811154e-04, 1.13763330e-03, 9.98751500e-01],\n",
       "       [1.34385970e-08, 4.03788030e-04, 9.99596200e-01],\n",
       "       [9.98865960e-01, 1.13408970e-03, 2.04425330e-08],\n",
       "       [9.98083350e-01, 1.84857300e-03, 6.80130100e-05],\n",
       "       [3.04960780e-06, 7.48091300e-03, 9.92516100e-01],\n",
       "       [1.27173410e-03, 9.98559400e-01, 1.68901960e-04],\n",
       "       [4.32178460e-05, 9.99825660e-01, 1.31092240e-04],\n",
       "       [5.88733700e-03, 9.93642200e-01, 4.70330470e-04],\n",
       "       [2.93131600e-03, 9.97068100e-01, 6.42830860e-07],\n",
       "       [8.41939700e-03, 9.91451560e-01, 1.29114210e-04],\n",
       "       [1.10811154e-04, 1.13763330e-03, 9.98751500e-01],\n",
       "       [3.04960780e-06, 7.48091300e-03, 9.92516100e-01],\n",
       "       [3.04960780e-06, 7.48091300e-03, 9.92516100e-01],\n",
       "       [1.80092100e-04, 9.86614500e-01, 1.32054770e-02],\n",
       "       [3.51068050e-03, 9.96355800e-01, 1.33649330e-04],\n",
       "       [1.34385970e-08, 4.03788030e-04, 9.99596200e-01],\n",
       "       [5.48493160e-03, 9.94515060e-01, 2.37068090e-11],\n",
       "       [5.24010470e-05, 9.99947200e-01, 3.70964760e-07],\n",
       "       [9.96562800e-01, 3.43725620e-03, 4.76650970e-08],\n",
       "       [2.51417630e-03, 9.97325400e-01, 1.60441590e-04],\n",
       "       [2.80915400e-03, 9.97141540e-01, 4.93639600e-05],\n",
       "       [9.72918450e-01, 2.70815620e-02, 1.06243610e-09],\n",
       "       [1.34385970e-08, 4.03788030e-04, 9.99596200e-01],\n",
       "       [1.10811154e-04, 1.13763330e-03, 9.98751500e-01],\n",
       "       [9.99116000e-01, 8.84008100e-04, 1.00753146e-13],\n",
       "       [3.04960780e-06, 7.48091300e-03, 9.92516100e-01],\n",
       "       [1.34385970e-08, 4.03788030e-04, 9.99596200e-01],\n",
       "       [5.48493160e-03, 9.94515060e-01, 2.37068090e-11],\n",
       "       [1.34385970e-08, 4.03788030e-04, 9.99596200e-01],\n",
       "       [9.99869470e-01, 1.30563840e-04, 1.34077836e-11],\n",
       "       [9.99863500e-01, 1.36527030e-04, 6.97844130e-16],\n",
       "       [1.34385970e-08, 4.03788030e-04, 9.99596200e-01],\n",
       "       [4.98751900e-04, 9.97489100e-01, 2.01220740e-03],\n",
       "       [3.91335280e-01, 6.08664700e-01, 6.18939830e-09],\n",
       "       [1.34385970e-08, 4.03788030e-04, 9.99596200e-01],\n",
       "       [1.34385970e-08, 4.03788030e-04, 9.99596200e-01],\n",
       "       [3.04960780e-06, 7.48091300e-03, 9.92516100e-01],\n",
       "       [7.13968000e-03, 9.92790460e-01, 6.97726300e-05],\n",
       "       [3.51068050e-03, 9.96355800e-01, 1.33649330e-04],\n",
       "       [1.34385970e-08, 4.03788030e-04, 9.99596200e-01],\n",
       "       [9.99999900e-01, 9.68121100e-08, 6.59991560e-10],\n",
       "       [1.10811154e-04, 1.13763330e-03, 9.98751500e-01],\n",
       "       [1.38889640e-03, 9.98555960e-01, 5.51001760e-05],\n",
       "       [3.22916300e-03, 9.96744160e-01, 2.66253920e-05],\n",
       "       [3.22916300e-03, 9.96744160e-01, 2.66253920e-05],\n",
       "       [1.10811154e-04, 1.13763330e-03, 9.98751500e-01],\n",
       "       [9.98119650e-01, 1.87979280e-03, 4.62028450e-07],\n",
       "       [9.68766030e-01, 3.07601560e-02, 4.73894730e-04],\n",
       "       [7.82602400e-01, 2.17379270e-01, 1.84203980e-05],\n",
       "       [1.80092100e-04, 9.86614500e-01, 1.32054770e-02],\n",
       "       [1.10811154e-04, 1.13763330e-03, 9.98751500e-01],\n",
       "       [2.93131600e-03, 9.97068100e-01, 6.42830860e-07],\n",
       "       [2.84580500e-04, 9.99715030e-01, 3.16139000e-07],\n",
       "       [3.04960780e-06, 7.48091300e-03, 9.92516100e-01],\n",
       "       [9.99746400e-01, 2.52413270e-04, 1.14737510e-06],\n",
       "       [7.81840200e-03, 9.92128400e-01, 5.32491800e-05],\n",
       "       [1.10811154e-04, 1.13763330e-03, 9.98751500e-01],\n",
       "       [9.93220100e-01, 6.77114400e-03, 8.78282000e-06],\n",
       "       [9.68169500e-01, 3.17993600e-02, 3.11225120e-05],\n",
       "       [1.34385970e-08, 4.03788030e-04, 9.99596200e-01],\n",
       "       [2.80915400e-03, 9.97141540e-01, 4.93639600e-05],\n",
       "       [1.34385970e-08, 4.03788030e-04, 9.99596200e-01],\n",
       "       [3.51068050e-03, 9.96355800e-01, 1.33649330e-04],\n",
       "       [1.10811154e-04, 1.13763330e-03, 9.98751500e-01],\n",
       "       [2.55581020e-01, 7.43436040e-01, 9.82943700e-04],\n",
       "       [2.80915400e-03, 9.97141540e-01, 4.93639600e-05],\n",
       "       [1.00000000e+00, 1.74392550e-12, 1.94398460e-11],\n",
       "       [9.99999900e-01, 9.95713950e-08, 1.88382580e-22],\n",
       "       [1.00000000e+00, 1.50298810e-08, 3.11932800e-14],\n",
       "       [9.57809870e-01, 4.21900800e-02, 4.28949280e-09],\n",
       "       [9.99869470e-01, 1.30563840e-04, 1.34077836e-11],\n",
       "       [3.22916300e-03, 9.96744160e-01, 2.66253920e-05],\n",
       "       [3.00574520e-04, 9.99699500e-01, 4.63930050e-08],\n",
       "       [9.99970300e-01, 2.95286900e-05, 8.80419800e-08],\n",
       "       [9.97151300e-01, 2.84547680e-03, 3.25554700e-06],\n",
       "       [1.13398490e-03, 9.98866100e-01, 7.69132000e-12],\n",
       "       [1.10811154e-04, 1.13763330e-03, 9.98751500e-01],\n",
       "       [9.99400600e-01, 5.99400700e-04, 1.80537310e-13],\n",
       "       [5.69812800e-03, 9.94139100e-01, 1.62859360e-04],\n",
       "       [8.41939700e-03, 9.91451560e-01, 1.29114210e-04],\n",
       "       [5.24010470e-05, 9.99947200e-01, 3.70964760e-07],\n",
       "       [9.99835700e-01, 1.63595570e-04, 5.73786700e-07],\n",
       "       [3.04960780e-06, 7.48091300e-03, 9.92516100e-01],\n",
       "       [3.00574520e-04, 9.99699500e-01, 4.63930050e-08],\n",
       "       [9.99067840e-01, 9.32230960e-04, 1.11187390e-15],\n",
       "       [7.81840200e-03, 9.92128400e-01, 5.32491800e-05],\n",
       "       [2.08988600e-02, 9.78976400e-01, 1.24733620e-04],\n",
       "       [9.63647200e-04, 9.98093300e-01, 9.43003630e-04],\n",
       "       [1.34385970e-08, 4.03788030e-04, 9.99596200e-01],\n",
       "       [1.10811154e-04, 1.13763330e-03, 9.98751500e-01],\n",
       "       [1.34385970e-08, 4.03788030e-04, 9.99596200e-01],\n",
       "       [3.04960780e-06, 7.48091300e-03, 9.92516100e-01],\n",
       "       [3.51068050e-03, 9.96355800e-01, 1.33649330e-04],\n",
       "       [1.10811154e-04, 1.13763330e-03, 9.98751500e-01],\n",
       "       [1.80092100e-04, 9.86614500e-01, 1.32054770e-02],\n",
       "       [1.34385970e-08, 4.03788030e-04, 9.99596200e-01],\n",
       "       [9.77017760e-01, 2.29788010e-02, 3.53314980e-06],\n",
       "       [1.10811154e-04, 1.13763330e-03, 9.98751500e-01],\n",
       "       [9.39075600e-01, 6.09244440e-02, 3.11732330e-09],\n",
       "       [9.89016230e-01, 1.09711940e-02, 1.26364275e-05],\n",
       "       [1.10811154e-04, 1.13763330e-03, 9.98751500e-01],\n",
       "       [7.81840200e-03, 9.92128400e-01, 5.32491800e-05],\n",
       "       [3.92898080e-01, 6.04194160e-01, 2.90764500e-03],\n",
       "       [9.99909900e-01, 9.00017900e-05, 8.30659200e-08],\n",
       "       [2.84580500e-04, 9.99715030e-01, 3.16139000e-07],\n",
       "       [9.87472650e-01, 1.25210350e-02, 6.28923540e-06],\n",
       "       [1.34385970e-08, 4.03788030e-04, 9.99596200e-01],\n",
       "       [9.99981160e-01, 1.87433430e-05, 8.70543900e-08],\n",
       "       [9.91455400e-01, 8.54423400e-03, 3.25808970e-07],\n",
       "       [9.98130740e-01, 1.86931350e-03, 1.06841890e-14],\n",
       "       [1.34385970e-08, 4.03788030e-04, 9.99596200e-01],\n",
       "       [9.96793000e-01, 3.20686200e-03, 1.61175800e-07],\n",
       "       [1.34385970e-08, 4.03788030e-04, 9.99596200e-01],\n",
       "       [2.93131600e-03, 9.97068100e-01, 6.42830860e-07],\n",
       "       [3.04960780e-06, 7.48091300e-03, 9.92516100e-01],\n",
       "       [1.34385970e-08, 4.03788030e-04, 9.99596200e-01],\n",
       "       [3.22916300e-03, 9.96744160e-01, 2.66253920e-05],\n",
       "       [1.10811154e-04, 1.13763330e-03, 9.98751500e-01],\n",
       "       [2.80915400e-03, 9.97141540e-01, 4.93639600e-05],\n",
       "       [1.10811154e-04, 1.13763330e-03, 9.98751500e-01],\n",
       "       [1.10811154e-04, 1.13763330e-03, 9.98751500e-01],\n",
       "       [1.08292310e-02, 9.89170730e-01, 2.70340850e-11],\n",
       "       [9.99659060e-01, 3.40933600e-04, 1.27624390e-12],\n",
       "       [1.34385970e-08, 4.03788030e-04, 9.99596200e-01],\n",
       "       [1.34385970e-08, 4.03788030e-04, 9.99596200e-01],\n",
       "       [9.99983100e-01, 1.68774500e-05, 2.15619880e-08],\n",
       "       [9.12135660e-01, 8.64492300e-02, 1.41503550e-03],\n",
       "       [1.10811154e-04, 1.13763330e-03, 9.98751500e-01],\n",
       "       [3.22916300e-03, 9.96744160e-01, 2.66253920e-05],\n",
       "       [9.80416600e-01, 1.95834280e-02, 4.56778300e-10],\n",
       "       [9.89755100e-01, 1.02394910e-02, 5.37808230e-06],\n",
       "       [1.10811154e-04, 1.13763440e-03, 9.98751500e-01],\n",
       "       [1.10811154e-04, 1.13763440e-03, 9.98751500e-01],\n",
       "       [1.34385200e-08, 4.03786500e-04, 9.99596200e-01],\n",
       "       [9.99803000e-01, 2.75798520e-05, 1.69518720e-04],\n",
       "       [7.13968700e-03, 9.92790460e-01, 6.97726300e-05],\n",
       "       [5.16004860e-01, 4.83995230e-01, 2.80011900e-08],\n",
       "       [3.04961940e-06, 7.48089140e-03, 9.92516100e-01],\n",
       "       [1.10811154e-04, 1.13763440e-03, 9.98751500e-01],\n",
       "       [3.53724980e-03, 9.96273900e-01, 1.88807830e-04]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob4 = df_proba4[df_proba4['phage']=='p003ppresabsSTCC_qual'].iloc[:,-3:]\n",
    "y_prob4 = y_prob4.to_numpy()\n",
    "y_prob4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9998168200392374"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo4 = rocauc_ovo(y_test_over, y_prob4, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9998168200392374"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr4 = rocauc_ovr(y_test_over, y_prob4, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9968071543155681"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovos = [ovo1, ovo2, ovo3, ovo4]\n",
    "np.mean(ovos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.003291174950740655"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(ovos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9968071543155681"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovrs = [ovr1, ovr2, ovr3, ovr4]\n",
    "np.mean(ovrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.003291174950740655"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(ovrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs = [acc_test_over, acc_test_over2, acc_test_over3, acc_test_over4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling test accuracy mean: 96.78%\n"
     ]
    }
   ],
   "source": [
    "mean = np.mean(accs)\n",
    "print('over-sampling test accuracy mean: %.2f%%' % (mean*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling test accuracy standard deviation: 0.018020066566141215\n"
     ]
    }
   ],
   "source": [
    "std = np.std(accs)\n",
    "print('over-sampling test accuracy standard deviation:', std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs_train = [np.mean(hist1_over.history['accuracy']), np.mean(hist1_over2.history['accuracy']), np.mean(hist1_over3.history['accuracy']),\n",
    "             np.mean(hist1_over4.history['accuracy'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy mean: 99.92%\n"
     ]
    }
   ],
   "source": [
    "mean_train = np.mean(accs_train)\n",
    "print('over-sampling train accuracy mean: %.2f%%' % (mean_train*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy standard deviation: 0.0008180433\n"
     ]
    }
   ],
   "source": [
    "std_train = np.std(accs_train)\n",
    "print('over-sampling train accuracy standard deviation:', std_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=567,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat5 = pd.DataFrame(X_test_over[:,0])\n",
    "dat5['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS386</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS230</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>SR4153</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0  test\n",
       "0    NRS255     2\n",
       "1    NRS148     2\n",
       "2    NRS209     2\n",
       "3    NRS386     1\n",
       "4    NRS230     0\n",
       "..      ...   ...\n",
       "197  NRS209     2\n",
       "198  NRS209     2\n",
       "199  SR4153     0\n",
       "200  NRS255     2\n",
       "201  NRS255     2\n",
       "\n",
       "[202 rows x 2 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### add regularizer and dropout\n",
    "model1_over5 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],), activity_regularizer=l1(0.001)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(3, activation='softmax'),\n",
    "    Dropout(0.2, ),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over5.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 470 samples, validate on 202 samples\n",
      "Epoch 1/100\n",
      "470/470 [==============================] - 0s 809us/step - loss: 7.3546 - accuracy: 0.3745 - val_loss: 2.9202 - val_accuracy: 0.5099\n",
      "Epoch 2/100\n",
      "470/470 [==============================] - 0s 357us/step - loss: 4.8069 - accuracy: 0.5298 - val_loss: 1.8845 - val_accuracy: 0.5990\n",
      "Epoch 3/100\n",
      "470/470 [==============================] - 0s 187us/step - loss: 4.7142 - accuracy: 0.4830 - val_loss: 1.2099 - val_accuracy: 0.7426\n",
      "Epoch 4/100\n",
      "470/470 [==============================] - 0s 229us/step - loss: 3.4922 - accuracy: 0.5851 - val_loss: 1.0248 - val_accuracy: 0.6980\n",
      "Epoch 5/100\n",
      "470/470 [==============================] - 0s 318us/step - loss: 3.5853 - accuracy: 0.5830 - val_loss: 0.8800 - val_accuracy: 0.7277\n",
      "Epoch 6/100\n",
      "470/470 [==============================] - 0s 274us/step - loss: 3.1891 - accuracy: 0.6511 - val_loss: 0.8346 - val_accuracy: 0.7228\n",
      "Epoch 7/100\n",
      "470/470 [==============================] - 0s 457us/step - loss: 3.6344 - accuracy: 0.6319 - val_loss: 0.7968 - val_accuracy: 0.7624\n",
      "Epoch 8/100\n",
      "470/470 [==============================] - 0s 215us/step - loss: 3.1403 - accuracy: 0.6681 - val_loss: 0.7700 - val_accuracy: 0.7822\n",
      "Epoch 9/100\n",
      "470/470 [==============================] - 0s 136us/step - loss: 3.0487 - accuracy: 0.6894 - val_loss: 0.7259 - val_accuracy: 0.8218\n",
      "Epoch 10/100\n",
      "470/470 [==============================] - 0s 131us/step - loss: 3.4690 - accuracy: 0.6617 - val_loss: 0.7624 - val_accuracy: 0.8267\n",
      "Epoch 11/100\n",
      "470/470 [==============================] - 0s 135us/step - loss: 3.3924 - accuracy: 0.6489 - val_loss: 0.7821 - val_accuracy: 0.8416\n",
      "Epoch 12/100\n",
      "470/470 [==============================] - 0s 438us/step - loss: 3.2647 - accuracy: 0.6511 - val_loss: 0.9439 - val_accuracy: 0.7970\n",
      "Epoch 13/100\n",
      "470/470 [==============================] - 0s 251us/step - loss: 2.7108 - accuracy: 0.6830 - val_loss: 0.8103 - val_accuracy: 0.8267\n",
      "Epoch 14/100\n",
      "470/470 [==============================] - 0s 243us/step - loss: 2.8150 - accuracy: 0.6745 - val_loss: 0.7237 - val_accuracy: 0.8366\n",
      "Epoch 15/100\n",
      "470/470 [==============================] - 0s 205us/step - loss: 2.8185 - accuracy: 0.6745 - val_loss: 0.8056 - val_accuracy: 0.8168\n",
      "Epoch 16/100\n",
      "470/470 [==============================] - 0s 199us/step - loss: 2.8026 - accuracy: 0.6787 - val_loss: 0.8147 - val_accuracy: 0.8416\n",
      "Epoch 17/100\n",
      "470/470 [==============================] - 0s 193us/step - loss: 2.4464 - accuracy: 0.7191 - val_loss: 0.8060 - val_accuracy: 0.8218\n",
      "Epoch 18/100\n",
      "470/470 [==============================] - 0s 296us/step - loss: 2.4754 - accuracy: 0.6745 - val_loss: 0.8719 - val_accuracy: 0.8020\n",
      "Epoch 19/100\n",
      "470/470 [==============================] - 0s 307us/step - loss: 2.2566 - accuracy: 0.6745 - val_loss: 0.9213 - val_accuracy: 0.8218\n",
      "Epoch 20/100\n",
      "470/470 [==============================] - 0s 216us/step - loss: 2.2578 - accuracy: 0.7085 - val_loss: 0.7514 - val_accuracy: 0.8812\n",
      "Epoch 21/100\n",
      "470/470 [==============================] - 0s 138us/step - loss: 2.0093 - accuracy: 0.7426 - val_loss: 0.8743 - val_accuracy: 0.8515\n",
      "Epoch 22/100\n",
      "470/470 [==============================] - 0s 129us/step - loss: 2.0773 - accuracy: 0.6830 - val_loss: 0.9727 - val_accuracy: 0.8713\n",
      "Epoch 23/100\n",
      "470/470 [==============================] - 0s 160us/step - loss: 1.9234 - accuracy: 0.7404 - val_loss: 0.9673 - val_accuracy: 0.8911\n",
      "Epoch 24/100\n",
      "470/470 [==============================] - 0s 143us/step - loss: 1.5420 - accuracy: 0.7489 - val_loss: 0.8942 - val_accuracy: 0.8762\n",
      "Epoch 25/100\n",
      "470/470 [==============================] - 0s 146us/step - loss: 1.8422 - accuracy: 0.7149 - val_loss: 0.7424 - val_accuracy: 0.9010\n",
      "Epoch 26/100\n",
      "470/470 [==============================] - 0s 211us/step - loss: 1.5692 - accuracy: 0.7809 - val_loss: 0.8360 - val_accuracy: 0.8911\n",
      "Epoch 27/100\n",
      "470/470 [==============================] - 0s 261us/step - loss: 1.8579 - accuracy: 0.7681 - val_loss: 0.7585 - val_accuracy: 0.9059\n",
      "Epoch 28/100\n",
      "470/470 [==============================] - 0s 293us/step - loss: 1.6806 - accuracy: 0.7170 - val_loss: 0.7554 - val_accuracy: 0.8614\n",
      "Epoch 29/100\n",
      "470/470 [==============================] - 0s 474us/step - loss: 1.5869 - accuracy: 0.7383 - val_loss: 0.6500 - val_accuracy: 0.9455\n",
      "Epoch 30/100\n",
      "470/470 [==============================] - 0s 297us/step - loss: 1.7004 - accuracy: 0.7617 - val_loss: 0.7382 - val_accuracy: 0.9158\n",
      "Epoch 31/100\n",
      "470/470 [==============================] - 0s 211us/step - loss: 1.5922 - accuracy: 0.7532 - val_loss: 0.7263 - val_accuracy: 0.9109\n",
      "Epoch 32/100\n",
      "470/470 [==============================] - 0s 135us/step - loss: 1.5424 - accuracy: 0.7851 - val_loss: 0.7982 - val_accuracy: 0.8960\n",
      "Epoch 33/100\n",
      "470/470 [==============================] - 0s 127us/step - loss: 1.4010 - accuracy: 0.7872 - val_loss: 0.7813 - val_accuracy: 0.9356\n",
      "Epoch 34/100\n",
      "470/470 [==============================] - 0s 146us/step - loss: 1.3257 - accuracy: 0.7681 - val_loss: 0.6508 - val_accuracy: 0.9257\n",
      "Epoch 35/100\n",
      "470/470 [==============================] - 0s 186us/step - loss: 1.6796 - accuracy: 0.7340 - val_loss: 0.6113 - val_accuracy: 0.9604\n",
      "Epoch 36/100\n",
      "470/470 [==============================] - 0s 184us/step - loss: 1.3915 - accuracy: 0.7702 - val_loss: 0.6705 - val_accuracy: 0.9208\n",
      "Epoch 37/100\n",
      "470/470 [==============================] - 0s 141us/step - loss: 1.5391 - accuracy: 0.7617 - val_loss: 0.5765 - val_accuracy: 0.9406\n",
      "Epoch 38/100\n",
      "470/470 [==============================] - 0s 173us/step - loss: 1.2568 - accuracy: 0.7766 - val_loss: 0.7993 - val_accuracy: 0.8663\n",
      "Epoch 39/100\n",
      "470/470 [==============================] - 0s 197us/step - loss: 1.4305 - accuracy: 0.7383 - val_loss: 0.9928 - val_accuracy: 0.9010\n",
      "Epoch 40/100\n",
      "470/470 [==============================] - 0s 314us/step - loss: 1.2791 - accuracy: 0.7745 - val_loss: 0.4952 - val_accuracy: 0.9505\n",
      "Epoch 41/100\n",
      "470/470 [==============================] - 0s 272us/step - loss: 1.5633 - accuracy: 0.7319 - val_loss: 0.7234 - val_accuracy: 0.9059\n",
      "Epoch 42/100\n",
      "470/470 [==============================] - 0s 177us/step - loss: 1.2436 - accuracy: 0.7596 - val_loss: 0.6338 - val_accuracy: 0.9554\n",
      "Epoch 43/100\n",
      "470/470 [==============================] - 0s 130us/step - loss: 1.1510 - accuracy: 0.7915 - val_loss: 0.5538 - val_accuracy: 0.9554\n",
      "Epoch 44/100\n",
      "470/470 [==============================] - 0s 167us/step - loss: 1.2471 - accuracy: 0.7617 - val_loss: 0.5934 - val_accuracy: 0.9554\n",
      "Epoch 45/100\n",
      "470/470 [==============================] - 0s 203us/step - loss: 1.1194 - accuracy: 0.7745 - val_loss: 1.1854 - val_accuracy: 0.8812\n",
      "Epoch 46/100\n",
      "470/470 [==============================] - 0s 202us/step - loss: 1.2431 - accuracy: 0.7957 - val_loss: 0.5312 - val_accuracy: 0.9554\n",
      "Epoch 47/100\n",
      "470/470 [==============================] - 0s 170us/step - loss: 1.2663 - accuracy: 0.7532 - val_loss: 0.5364 - val_accuracy: 0.9505\n",
      "Epoch 48/100\n",
      "470/470 [==============================] - 0s 153us/step - loss: 1.0423 - accuracy: 0.7766 - val_loss: 0.6739 - val_accuracy: 0.9356\n",
      "Epoch 49/100\n",
      "470/470 [==============================] - 0s 154us/step - loss: 1.1431 - accuracy: 0.7617 - val_loss: 0.5496 - val_accuracy: 0.9356\n",
      "Epoch 50/100\n",
      "470/470 [==============================] - 0s 158us/step - loss: 1.0269 - accuracy: 0.7553 - val_loss: 0.6495 - val_accuracy: 0.9406\n",
      "Epoch 51/100\n",
      "470/470 [==============================] - 0s 202us/step - loss: 1.1713 - accuracy: 0.7787 - val_loss: 0.5688 - val_accuracy: 0.9653\n",
      "Epoch 52/100\n",
      "470/470 [==============================] - 0s 141us/step - loss: 1.1523 - accuracy: 0.7745 - val_loss: 0.6009 - val_accuracy: 0.9554\n",
      "Epoch 53/100\n",
      "470/470 [==============================] - 0s 134us/step - loss: 1.1683 - accuracy: 0.7809 - val_loss: 0.6063 - val_accuracy: 0.9554\n",
      "Epoch 54/100\n",
      "470/470 [==============================] - 0s 131us/step - loss: 1.0535 - accuracy: 0.7872 - val_loss: 0.5306 - val_accuracy: 0.9307\n",
      "Epoch 55/100\n",
      "470/470 [==============================] - 0s 142us/step - loss: 0.9854 - accuracy: 0.7830 - val_loss: 0.5804 - val_accuracy: 0.9604\n",
      "Epoch 56/100\n",
      "470/470 [==============================] - 0s 131us/step - loss: 0.8527 - accuracy: 0.8106 - val_loss: 0.4510 - val_accuracy: 0.9604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "470/470 [==============================] - 0s 130us/step - loss: 0.9133 - accuracy: 0.7745 - val_loss: 0.5972 - val_accuracy: 0.9455\n",
      "Epoch 58/100\n",
      "470/470 [==============================] - 0s 135us/step - loss: 0.8894 - accuracy: 0.7872 - val_loss: 0.3665 - val_accuracy: 0.9703\n",
      "Epoch 59/100\n",
      "470/470 [==============================] - 0s 146us/step - loss: 0.9349 - accuracy: 0.7660 - val_loss: 0.4248 - val_accuracy: 0.9653\n",
      "Epoch 60/100\n",
      "470/470 [==============================] - 0s 168us/step - loss: 0.8415 - accuracy: 0.8021 - val_loss: 0.4406 - val_accuracy: 0.9554\n",
      "Epoch 61/100\n",
      "470/470 [==============================] - 0s 130us/step - loss: 0.7811 - accuracy: 0.8170 - val_loss: 0.6464 - val_accuracy: 0.9406\n",
      "Epoch 62/100\n",
      "470/470 [==============================] - 0s 125us/step - loss: 0.9617 - accuracy: 0.7723 - val_loss: 0.3154 - val_accuracy: 0.9901\n",
      "Epoch 63/100\n",
      "470/470 [==============================] - 0s 133us/step - loss: 0.9368 - accuracy: 0.7809 - val_loss: 0.3706 - val_accuracy: 0.9604\n",
      "Epoch 64/100\n",
      "470/470 [==============================] - 0s 184us/step - loss: 0.7532 - accuracy: 0.8000 - val_loss: 0.4015 - val_accuracy: 0.9307\n",
      "Epoch 65/100\n",
      "470/470 [==============================] - 0s 132us/step - loss: 0.8807 - accuracy: 0.7298 - val_loss: 0.3885 - val_accuracy: 0.9901\n",
      "Epoch 66/100\n",
      "470/470 [==============================] - 0s 129us/step - loss: 0.6683 - accuracy: 0.7915 - val_loss: 0.3846 - val_accuracy: 0.9703\n",
      "Epoch 67/100\n",
      "470/470 [==============================] - 0s 155us/step - loss: 0.7372 - accuracy: 0.8213 - val_loss: 0.3362 - val_accuracy: 0.9901\n",
      "Epoch 68/100\n",
      "470/470 [==============================] - ETA: 0s - loss: 0.3681 - accuracy: 0.87 - 0s 133us/step - loss: 0.7298 - accuracy: 0.8000 - val_loss: 0.3631 - val_accuracy: 0.9752\n",
      "Epoch 69/100\n",
      "470/470 [==============================] - 0s 146us/step - loss: 0.7264 - accuracy: 0.7830 - val_loss: 0.3297 - val_accuracy: 0.9901\n",
      "Epoch 70/100\n",
      "470/470 [==============================] - 0s 131us/step - loss: 0.8249 - accuracy: 0.7830 - val_loss: 0.4192 - val_accuracy: 0.9752\n",
      "Epoch 71/100\n",
      "470/470 [==============================] - 0s 150us/step - loss: 0.7239 - accuracy: 0.7957 - val_loss: 0.4004 - val_accuracy: 0.9703\n",
      "Epoch 72/100\n",
      "470/470 [==============================] - 0s 173us/step - loss: 0.8375 - accuracy: 0.7851 - val_loss: 0.5702 - val_accuracy: 0.9703\n",
      "Epoch 73/100\n",
      "470/470 [==============================] - 0s 212us/step - loss: 0.7903 - accuracy: 0.7915 - val_loss: 0.3454 - val_accuracy: 0.9851\n",
      "Epoch 74/100\n",
      "470/470 [==============================] - 0s 225us/step - loss: 0.5880 - accuracy: 0.7872 - val_loss: 0.3358 - val_accuracy: 0.9752\n",
      "Epoch 75/100\n",
      "470/470 [==============================] - 0s 230us/step - loss: 0.6897 - accuracy: 0.8191 - val_loss: 0.4774 - val_accuracy: 0.9653\n",
      "Epoch 76/100\n",
      "470/470 [==============================] - 0s 228us/step - loss: 0.6999 - accuracy: 0.8191 - val_loss: 0.3487 - val_accuracy: 0.9752\n",
      "Epoch 77/100\n",
      "470/470 [==============================] - 0s 217us/step - loss: 0.7228 - accuracy: 0.7681 - val_loss: 0.3026 - val_accuracy: 0.9851\n",
      "Epoch 78/100\n",
      "470/470 [==============================] - 0s 204us/step - loss: 0.6757 - accuracy: 0.8000 - val_loss: 0.3549 - val_accuracy: 0.9752\n",
      "Epoch 79/100\n",
      "470/470 [==============================] - 0s 156us/step - loss: 0.6831 - accuracy: 0.8213 - val_loss: 0.3994 - val_accuracy: 0.9802\n",
      "Epoch 80/100\n",
      "470/470 [==============================] - 0s 162us/step - loss: 0.6407 - accuracy: 0.8000 - val_loss: 0.2966 - val_accuracy: 0.9950\n",
      "Epoch 81/100\n",
      "470/470 [==============================] - 0s 180us/step - loss: 0.5837 - accuracy: 0.8170 - val_loss: 0.3322 - val_accuracy: 0.9752\n",
      "Epoch 82/100\n",
      "470/470 [==============================] - 0s 188us/step - loss: 0.7747 - accuracy: 0.7766 - val_loss: 0.5032 - val_accuracy: 0.9604\n",
      "Epoch 83/100\n",
      "470/470 [==============================] - 0s 142us/step - loss: 0.5778 - accuracy: 0.8085 - val_loss: 0.4604 - val_accuracy: 0.9505\n",
      "Epoch 84/100\n",
      "470/470 [==============================] - 0s 128us/step - loss: 0.7046 - accuracy: 0.7957 - val_loss: 0.3074 - val_accuracy: 0.9950\n",
      "Epoch 85/100\n",
      "470/470 [==============================] - 0s 267us/step - loss: 0.7332 - accuracy: 0.7894 - val_loss: 0.4687 - val_accuracy: 0.9703\n",
      "Epoch 86/100\n",
      "470/470 [==============================] - 0s 192us/step - loss: 0.5977 - accuracy: 0.8021 - val_loss: 0.3082 - val_accuracy: 0.9752\n",
      "Epoch 87/100\n",
      "470/470 [==============================] - 0s 216us/step - loss: 0.7501 - accuracy: 0.7787 - val_loss: 0.2889 - val_accuracy: 0.9950\n",
      "Epoch 88/100\n",
      "470/470 [==============================] - 0s 229us/step - loss: 0.6742 - accuracy: 0.7723 - val_loss: 0.4198 - val_accuracy: 0.9653\n",
      "Epoch 89/100\n",
      "470/470 [==============================] - 0s 287us/step - loss: 0.5520 - accuracy: 0.8319 - val_loss: 0.3172 - val_accuracy: 0.9752\n",
      "Epoch 90/100\n",
      "470/470 [==============================] - 0s 255us/step - loss: 0.5694 - accuracy: 0.7894 - val_loss: 0.2525 - val_accuracy: 0.9950\n",
      "Epoch 91/100\n",
      "470/470 [==============================] - 0s 233us/step - loss: 0.6321 - accuracy: 0.7957 - val_loss: 0.3714 - val_accuracy: 0.9752\n",
      "Epoch 92/100\n",
      "470/470 [==============================] - 0s 181us/step - loss: 0.6293 - accuracy: 0.8021 - val_loss: 0.3307 - val_accuracy: 0.9752\n",
      "Epoch 93/100\n",
      "470/470 [==============================] - 0s 182us/step - loss: 0.5827 - accuracy: 0.8021 - val_loss: 0.3677 - val_accuracy: 0.9752\n",
      "Epoch 94/100\n",
      "470/470 [==============================] - 0s 166us/step - loss: 0.5770 - accuracy: 0.7745 - val_loss: 0.2708 - val_accuracy: 0.9950\n",
      "Epoch 95/100\n",
      "470/470 [==============================] - 0s 553us/step - loss: 0.5610 - accuracy: 0.8021 - val_loss: 0.2602 - val_accuracy: 0.9950\n",
      "Epoch 96/100\n",
      "470/470 [==============================] - 0s 253us/step - loss: 0.7858 - accuracy: 0.7681 - val_loss: 0.6828 - val_accuracy: 0.9406\n",
      "Epoch 97/100\n",
      "470/470 [==============================] - 0s 143us/step - loss: 0.6161 - accuracy: 0.8128 - val_loss: 0.2687 - val_accuracy: 0.9851\n",
      "Epoch 98/100\n",
      "470/470 [==============================] - 0s 188us/step - loss: 0.6943 - accuracy: 0.8128 - val_loss: 0.3878 - val_accuracy: 0.9752\n",
      "Epoch 99/100\n",
      "470/470 [==============================] - 0s 214us/step - loss: 0.7202 - accuracy: 0.7851 - val_loss: 0.3648 - val_accuracy: 0.9851\n",
      "Epoch 100/100\n",
      "470/470 [==============================] - 0s 178us/step - loss: 0.5249 - accuracy: 0.7936 - val_loss: 0.2613 - val_accuracy: 0.9901\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a3e023550>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over5.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202/202 [==============================] - 0s 100us/step\n",
      "over-sampling test accuracy: 96.53%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over5 = model1_over5.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over5*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 1, 0, 0, 1, 1, 2, 0, 1, 0, 2, 0, 1, 0, 0, 2, 0, 1, 1, 2,\n",
       "       2, 2, 0, 0, 0, 1, 2, 1, 2, 1, 1, 2, 1, 2, 0, 2, 0, 1, 1, 2, 2, 0,\n",
       "       2, 2, 2, 1, 0, 0, 0, 0, 0, 0, 2, 1, 2, 2, 1, 1, 2, 2, 0, 0, 1, 0,\n",
       "       1, 2, 1, 0, 2, 0, 1, 2, 0, 2, 1, 2, 1, 2, 2, 0, 1, 2, 2, 2, 0, 1,\n",
       "       1, 1, 0, 1, 1, 0, 1, 2, 0, 2, 1, 2, 0, 0, 1, 0, 1, 2, 1, 1, 2, 0,\n",
       "       0, 2, 1, 0, 1, 2, 0, 2, 1, 2, 0, 1, 0, 2, 0, 1, 2, 0, 1, 0, 1, 1,\n",
       "       2, 2, 1, 0, 1, 1, 0, 2, 1, 1, 1, 1, 0, 2, 1, 1, 1, 1, 0, 0, 0, 2,\n",
       "       0, 0, 1, 1, 2, 0, 2, 1, 0, 2, 1, 1, 1, 1, 0, 2, 0, 0, 0, 0, 2, 1,\n",
       "       1, 1, 1, 0, 2, 0, 2, 0, 1, 0, 0, 1, 2, 0, 1, 2, 2, 2, 2, 0, 2, 2,\n",
       "       2, 0, 2, 2])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred5 = model1_over5.predict_classes(X_test_over)\n",
    "pred5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS386</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS230</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>SR4153</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0  test  pred\n",
       "0    NRS255     2     2\n",
       "1    NRS148     2     2\n",
       "2    NRS209     2     2\n",
       "3    NRS386     1     1\n",
       "4    NRS230     0     0\n",
       "..      ...   ...   ...\n",
       "197  NRS209     2     2\n",
       "198  NRS209     2     2\n",
       "199  SR4153     0     0\n",
       "200  NRS255     2     2\n",
       "201  NRS255     2     2\n",
       "\n",
       "[202 rows x 3 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat5['pred'] = pred5\n",
    "dat5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba5 = model1_over5.predict_proba(X_test_over)\n",
    "dat_proba5 = pd.DataFrame(proba5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.602222e-08</td>\n",
       "      <td>1.254396e-15</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.275652e-08</td>\n",
       "      <td>6.204051e-08</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.458716e-09</td>\n",
       "      <td>2.097634e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.089555e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.170724e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.748846e-18</td>\n",
       "      <td>2.535741e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>4.458708e-09</td>\n",
       "      <td>2.097626e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>4.458708e-09</td>\n",
       "      <td>2.097626e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>8.079975e-17</td>\n",
       "      <td>2.880661e-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>1.602225e-08</td>\n",
       "      <td>1.254401e-15</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>1.602225e-08</td>\n",
       "      <td>1.254401e-15</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0             1             2\n",
       "0    1.602222e-08  1.254396e-15  1.000000e+00\n",
       "1    1.275652e-08  6.204051e-08  9.999999e-01\n",
       "2    4.458716e-09  2.097634e-08  1.000000e+00\n",
       "3    6.089555e-09  1.000000e+00  1.170724e-09\n",
       "4    1.000000e+00  4.748846e-18  2.535741e-13\n",
       "..            ...           ...           ...\n",
       "197  4.458708e-09  2.097626e-08  1.000000e+00\n",
       "198  4.458708e-09  2.097626e-08  1.000000e+00\n",
       "199  1.000000e+00  8.079975e-17  2.880661e-26\n",
       "200  1.602225e-08  1.254401e-15  1.000000e+00\n",
       "201  1.602225e-08  1.254401e-15  1.000000e+00\n",
       "\n",
       "[202 rows x 3 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba5.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba5.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat5.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/5p003ppST.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 470 samples, validate on 202 samples\n",
      "Epoch 1/100\n",
      "470/470 [==============================] - 0s 205us/step - loss: 0.8577 - accuracy: 0.7723 - val_loss: 0.5023 - val_accuracy: 0.9604\n",
      "Epoch 2/100\n",
      "470/470 [==============================] - 0s 142us/step - loss: 0.9891 - accuracy: 0.7553 - val_loss: 0.7670 - val_accuracy: 0.9505\n",
      "Epoch 3/100\n",
      "470/470 [==============================] - 0s 130us/step - loss: 0.8723 - accuracy: 0.7830 - val_loss: 0.4425 - val_accuracy: 0.9703\n",
      "Epoch 4/100\n",
      "470/470 [==============================] - 0s 129us/step - loss: 0.7353 - accuracy: 0.8064 - val_loss: 0.4719 - val_accuracy: 0.9653\n",
      "Epoch 5/100\n",
      "470/470 [==============================] - 0s 128us/step - loss: 0.6944 - accuracy: 0.7979 - val_loss: 0.5076 - val_accuracy: 0.9554\n",
      "Epoch 6/100\n",
      "470/470 [==============================] - 0s 135us/step - loss: 0.7644 - accuracy: 0.7872 - val_loss: 0.4127 - val_accuracy: 0.9653\n",
      "Epoch 7/100\n",
      "470/470 [==============================] - 0s 129us/step - loss: 0.7976 - accuracy: 0.7851 - val_loss: 0.3852 - val_accuracy: 0.9703\n",
      "Epoch 8/100\n",
      "470/470 [==============================] - 0s 127us/step - loss: 0.8435 - accuracy: 0.7681 - val_loss: 0.3802 - val_accuracy: 0.9653\n",
      "Epoch 9/100\n",
      "470/470 [==============================] - 0s 128us/step - loss: 0.7429 - accuracy: 0.7872 - val_loss: 0.5453 - val_accuracy: 0.9703\n",
      "Epoch 10/100\n",
      "470/470 [==============================] - 0s 141us/step - loss: 0.6839 - accuracy: 0.8085 - val_loss: 0.4890 - val_accuracy: 0.9703\n",
      "Epoch 11/100\n",
      "470/470 [==============================] - 0s 139us/step - loss: 0.6096 - accuracy: 0.8191 - val_loss: 0.4109 - val_accuracy: 0.9653\n",
      "Epoch 12/100\n",
      "470/470 [==============================] - 0s 136us/step - loss: 0.6928 - accuracy: 0.8191 - val_loss: 0.4230 - val_accuracy: 0.9653\n",
      "Epoch 13/100\n",
      "470/470 [==============================] - 0s 134us/step - loss: 0.7496 - accuracy: 0.7851 - val_loss: 0.4240 - val_accuracy: 0.9653\n",
      "Epoch 14/100\n",
      "470/470 [==============================] - 0s 130us/step - loss: 0.8825 - accuracy: 0.7574 - val_loss: 0.3789 - val_accuracy: 0.9703\n",
      "Epoch 15/100\n",
      "470/470 [==============================] - 0s 129us/step - loss: 0.8748 - accuracy: 0.7596 - val_loss: 0.4144 - val_accuracy: 0.9653\n",
      "Epoch 16/100\n",
      "470/470 [==============================] - 0s 137us/step - loss: 0.7399 - accuracy: 0.7830 - val_loss: 0.3845 - val_accuracy: 0.9653\n",
      "Epoch 17/100\n",
      "470/470 [==============================] - 0s 143us/step - loss: 0.6148 - accuracy: 0.8298 - val_loss: 0.3652 - val_accuracy: 0.9653\n",
      "Epoch 18/100\n",
      "470/470 [==============================] - 0s 173us/step - loss: 0.7155 - accuracy: 0.7894 - val_loss: 0.3884 - val_accuracy: 0.9653\n",
      "Epoch 19/100\n",
      "470/470 [==============================] - 0s 185us/step - loss: 0.6423 - accuracy: 0.7936 - val_loss: 0.3750 - val_accuracy: 0.9653\n",
      "Epoch 20/100\n",
      "470/470 [==============================] - 0s 136us/step - loss: 0.7576 - accuracy: 0.7894 - val_loss: 0.4708 - val_accuracy: 0.9653\n",
      "Epoch 21/100\n",
      "470/470 [==============================] - 0s 131us/step - loss: 0.6709 - accuracy: 0.7979 - val_loss: 0.4886 - val_accuracy: 0.9604\n",
      "Epoch 22/100\n",
      "470/470 [==============================] - 0s 128us/step - loss: 0.6321 - accuracy: 0.7979 - val_loss: 0.4625 - val_accuracy: 0.9604\n",
      "Epoch 23/100\n",
      "470/470 [==============================] - 0s 130us/step - loss: 0.7245 - accuracy: 0.7809 - val_loss: 0.3713 - val_accuracy: 0.9752\n",
      "Epoch 24/100\n",
      "470/470 [==============================] - 0s 141us/step - loss: 0.7751 - accuracy: 0.7872 - val_loss: 0.4680 - val_accuracy: 0.9703\n",
      "Epoch 25/100\n",
      "470/470 [==============================] - 0s 139us/step - loss: 0.7269 - accuracy: 0.7979 - val_loss: 0.3307 - val_accuracy: 0.9802\n",
      "Epoch 26/100\n",
      "470/470 [==============================] - 0s 176us/step - loss: 0.6389 - accuracy: 0.7957 - val_loss: 0.4125 - val_accuracy: 0.9653\n",
      "Epoch 27/100\n",
      "470/470 [==============================] - 0s 189us/step - loss: 0.7296 - accuracy: 0.7617 - val_loss: 0.3531 - val_accuracy: 0.9752\n",
      "Epoch 28/100\n",
      "470/470 [==============================] - 0s 244us/step - loss: 0.7832 - accuracy: 0.8043 - val_loss: 0.3822 - val_accuracy: 0.9703\n",
      "Epoch 29/100\n",
      "470/470 [==============================] - 0s 320us/step - loss: 0.6247 - accuracy: 0.8043 - val_loss: 0.3530 - val_accuracy: 0.9703\n",
      "Epoch 30/100\n",
      "470/470 [==============================] - 0s 240us/step - loss: 0.6275 - accuracy: 0.7830 - val_loss: 0.5138 - val_accuracy: 0.9653\n",
      "Epoch 31/100\n",
      "470/470 [==============================] - 0s 237us/step - loss: 0.6630 - accuracy: 0.8085 - val_loss: 0.4826 - val_accuracy: 0.9703\n",
      "Epoch 32/100\n",
      "470/470 [==============================] - 0s 248us/step - loss: 0.6501 - accuracy: 0.7957 - val_loss: 0.4393 - val_accuracy: 0.9703\n",
      "Epoch 33/100\n",
      "470/470 [==============================] - 0s 188us/step - loss: 0.6050 - accuracy: 0.8064 - val_loss: 0.4188 - val_accuracy: 0.9653\n",
      "Epoch 34/100\n",
      "470/470 [==============================] - 0s 195us/step - loss: 0.6496 - accuracy: 0.7915 - val_loss: 0.3881 - val_accuracy: 0.9653\n",
      "Epoch 35/100\n",
      "470/470 [==============================] - 0s 188us/step - loss: 0.5949 - accuracy: 0.8085 - val_loss: 0.4451 - val_accuracy: 0.9703\n",
      "Epoch 36/100\n",
      "470/470 [==============================] - 0s 177us/step - loss: 0.6470 - accuracy: 0.8128 - val_loss: 0.3775 - val_accuracy: 0.9703\n",
      "Epoch 37/100\n",
      "470/470 [==============================] - 0s 134us/step - loss: 0.6261 - accuracy: 0.7894 - val_loss: 0.4303 - val_accuracy: 0.9653\n",
      "Epoch 38/100\n",
      "470/470 [==============================] - 0s 131us/step - loss: 0.6920 - accuracy: 0.8128 - val_loss: 0.2894 - val_accuracy: 0.9851\n",
      "Epoch 39/100\n",
      "470/470 [==============================] - 0s 190us/step - loss: 0.7241 - accuracy: 0.7957 - val_loss: 0.4856 - val_accuracy: 0.9653\n",
      "Epoch 40/100\n",
      "470/470 [==============================] - 0s 145us/step - loss: 0.7147 - accuracy: 0.7745 - val_loss: 0.4237 - val_accuracy: 0.9703\n",
      "Epoch 41/100\n",
      "470/470 [==============================] - 0s 132us/step - loss: 0.6825 - accuracy: 0.7766 - val_loss: 0.4025 - val_accuracy: 0.9653\n",
      "Epoch 42/100\n",
      "470/470 [==============================] - 0s 128us/step - loss: 0.6221 - accuracy: 0.8213 - val_loss: 0.3329 - val_accuracy: 0.9752\n",
      "Epoch 43/100\n",
      "470/470 [==============================] - 0s 128us/step - loss: 0.8083 - accuracy: 0.7511 - val_loss: 0.5008 - val_accuracy: 0.9653\n",
      "Epoch 44/100\n",
      "470/470 [==============================] - 0s 125us/step - loss: 0.7099 - accuracy: 0.7894 - val_loss: 0.3518 - val_accuracy: 0.9752\n",
      "Epoch 45/100\n",
      "470/470 [==============================] - 0s 126us/step - loss: 0.6604 - accuracy: 0.7957 - val_loss: 0.3548 - val_accuracy: 0.9752\n",
      "Epoch 46/100\n",
      "470/470 [==============================] - 0s 126us/step - loss: 0.6652 - accuracy: 0.8277 - val_loss: 0.4492 - val_accuracy: 0.9604\n",
      "Epoch 47/100\n",
      "470/470 [==============================] - 0s 130us/step - loss: 0.8162 - accuracy: 0.7702 - val_loss: 0.5718 - val_accuracy: 0.9604\n",
      "Epoch 48/100\n",
      "470/470 [==============================] - 0s 129us/step - loss: 0.6574 - accuracy: 0.8128 - val_loss: 0.3855 - val_accuracy: 0.9703\n",
      "Epoch 49/100\n",
      "470/470 [==============================] - 0s 125us/step - loss: 0.7698 - accuracy: 0.7596 - val_loss: 0.4375 - val_accuracy: 0.9703\n",
      "Epoch 50/100\n",
      "470/470 [==============================] - 0s 127us/step - loss: 0.6927 - accuracy: 0.7872 - val_loss: 0.3949 - val_accuracy: 0.9653\n",
      "Epoch 51/100\n",
      "470/470 [==============================] - 0s 128us/step - loss: 0.6306 - accuracy: 0.7872 - val_loss: 0.3998 - val_accuracy: 0.9653\n",
      "Epoch 52/100\n",
      "470/470 [==============================] - 0s 127us/step - loss: 0.6569 - accuracy: 0.7830 - val_loss: 0.3519 - val_accuracy: 0.9752\n",
      "Epoch 53/100\n",
      "470/470 [==============================] - 0s 129us/step - loss: 0.7121 - accuracy: 0.7830 - val_loss: 0.3974 - val_accuracy: 0.9703\n",
      "Epoch 54/100\n",
      "470/470 [==============================] - 0s 138us/step - loss: 0.7498 - accuracy: 0.7894 - val_loss: 0.3804 - val_accuracy: 0.9703\n",
      "Epoch 55/100\n",
      "470/470 [==============================] - 0s 137us/step - loss: 0.6812 - accuracy: 0.7617 - val_loss: 0.4832 - val_accuracy: 0.9653\n",
      "Epoch 56/100\n",
      "470/470 [==============================] - 0s 133us/step - loss: 0.5656 - accuracy: 0.7957 - val_loss: 0.3992 - val_accuracy: 0.9653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "470/470 [==============================] - 0s 137us/step - loss: 0.5472 - accuracy: 0.7936 - val_loss: 0.4639 - val_accuracy: 0.9653\n",
      "Epoch 58/100\n",
      "470/470 [==============================] - 0s 148us/step - loss: 0.6708 - accuracy: 0.7915 - val_loss: 0.4436 - val_accuracy: 0.9703\n",
      "Epoch 59/100\n",
      "470/470 [==============================] - 0s 134us/step - loss: 0.7360 - accuracy: 0.7702 - val_loss: 0.5082 - val_accuracy: 0.9703\n",
      "Epoch 60/100\n",
      "470/470 [==============================] - 0s 143us/step - loss: 0.6877 - accuracy: 0.8128 - val_loss: 0.3956 - val_accuracy: 0.9752\n",
      "Epoch 61/100\n",
      "470/470 [==============================] - 0s 144us/step - loss: 0.6689 - accuracy: 0.7915 - val_loss: 0.4728 - val_accuracy: 0.9653\n",
      "Epoch 62/100\n",
      "470/470 [==============================] - 0s 136us/step - loss: 0.7254 - accuracy: 0.7702 - val_loss: 0.4125 - val_accuracy: 0.9653\n",
      "Epoch 63/100\n",
      "470/470 [==============================] - 0s 138us/step - loss: 0.5916 - accuracy: 0.8085 - val_loss: 0.3855 - val_accuracy: 0.9703\n",
      "Epoch 64/100\n",
      "470/470 [==============================] - 0s 125us/step - loss: 0.8042 - accuracy: 0.7340 - val_loss: 0.4975 - val_accuracy: 0.9653\n",
      "Epoch 65/100\n",
      "470/470 [==============================] - 0s 127us/step - loss: 0.6375 - accuracy: 0.7872 - val_loss: 0.4716 - val_accuracy: 0.9653\n",
      "Epoch 66/100\n",
      "470/470 [==============================] - 0s 130us/step - loss: 0.6055 - accuracy: 0.7830 - val_loss: 0.3850 - val_accuracy: 0.9752\n",
      "Epoch 67/100\n",
      "470/470 [==============================] - 0s 125us/step - loss: 0.6464 - accuracy: 0.8000 - val_loss: 0.4367 - val_accuracy: 0.9703\n",
      "Epoch 68/100\n",
      "470/470 [==============================] - 0s 125us/step - loss: 0.6764 - accuracy: 0.7851 - val_loss: 0.4014 - val_accuracy: 0.9703\n",
      "Epoch 69/100\n",
      "470/470 [==============================] - 0s 125us/step - loss: 0.7682 - accuracy: 0.7681 - val_loss: 0.5902 - val_accuracy: 0.9604\n",
      "Epoch 70/100\n",
      "470/470 [==============================] - 0s 128us/step - loss: 0.6755 - accuracy: 0.7979 - val_loss: 0.3476 - val_accuracy: 0.9802\n",
      "Epoch 71/100\n",
      "470/470 [==============================] - 0s 130us/step - loss: 0.6866 - accuracy: 0.7979 - val_loss: 0.4426 - val_accuracy: 0.9752\n",
      "Epoch 72/100\n",
      "470/470 [==============================] - 0s 129us/step - loss: 0.7341 - accuracy: 0.7447 - val_loss: 0.5666 - val_accuracy: 0.9604\n",
      "Epoch 73/100\n",
      "470/470 [==============================] - 0s 218us/step - loss: 0.8231 - accuracy: 0.7447 - val_loss: 0.7266 - val_accuracy: 0.9307\n",
      "Epoch 74/100\n",
      "470/470 [==============================] - 0s 321us/step - loss: 0.7133 - accuracy: 0.7894 - val_loss: 0.6369 - val_accuracy: 0.9455\n",
      "Epoch 75/100\n",
      "470/470 [==============================] - 0s 136us/step - loss: 0.7736 - accuracy: 0.7617 - val_loss: 0.3651 - val_accuracy: 0.9752\n",
      "Epoch 76/100\n",
      "470/470 [==============================] - 0s 141us/step - loss: 0.6675 - accuracy: 0.8043 - val_loss: 0.3726 - val_accuracy: 0.9752\n",
      "Epoch 77/100\n",
      "470/470 [==============================] - 0s 137us/step - loss: 0.6733 - accuracy: 0.7957 - val_loss: 0.4314 - val_accuracy: 0.9703\n",
      "Epoch 78/100\n",
      "470/470 [==============================] - 0s 166us/step - loss: 0.6871 - accuracy: 0.7830 - val_loss: 0.3609 - val_accuracy: 0.9752\n",
      "Epoch 79/100\n",
      "470/470 [==============================] - 0s 134us/step - loss: 0.6842 - accuracy: 0.7936 - val_loss: 0.6808 - val_accuracy: 0.9406\n",
      "Epoch 80/100\n",
      "470/470 [==============================] - 0s 127us/step - loss: 0.7265 - accuracy: 0.7957 - val_loss: 0.4544 - val_accuracy: 0.9703\n",
      "Epoch 81/100\n",
      "470/470 [==============================] - 0s 130us/step - loss: 0.5756 - accuracy: 0.7894 - val_loss: 0.4101 - val_accuracy: 0.9752\n",
      "Epoch 82/100\n",
      "470/470 [==============================] - 0s 127us/step - loss: 0.5890 - accuracy: 0.8064 - val_loss: 0.4372 - val_accuracy: 0.9703\n",
      "Epoch 83/100\n",
      "470/470 [==============================] - 0s 127us/step - loss: 0.5909 - accuracy: 0.8128 - val_loss: 0.4288 - val_accuracy: 0.9703\n",
      "Epoch 84/100\n",
      "470/470 [==============================] - 0s 128us/step - loss: 0.6934 - accuracy: 0.7681 - val_loss: 0.4938 - val_accuracy: 0.9604\n",
      "Epoch 85/100\n",
      "470/470 [==============================] - 0s 136us/step - loss: 0.7182 - accuracy: 0.7809 - val_loss: 0.7073 - val_accuracy: 0.9554\n",
      "Epoch 86/100\n",
      "470/470 [==============================] - 0s 133us/step - loss: 0.7211 - accuracy: 0.8000 - val_loss: 0.5609 - val_accuracy: 0.9703\n",
      "Epoch 87/100\n",
      "470/470 [==============================] - 0s 129us/step - loss: 0.7209 - accuracy: 0.8043 - val_loss: 0.3982 - val_accuracy: 0.9752\n",
      "Epoch 88/100\n",
      "470/470 [==============================] - 0s 182us/step - loss: 0.6919 - accuracy: 0.7809 - val_loss: 0.5850 - val_accuracy: 0.9653\n",
      "Epoch 89/100\n",
      "470/470 [==============================] - 0s 472us/step - loss: 0.6371 - accuracy: 0.8021 - val_loss: 0.5453 - val_accuracy: 0.9653\n",
      "Epoch 90/100\n",
      "470/470 [==============================] - 0s 317us/step - loss: 0.6350 - accuracy: 0.8021 - val_loss: 0.4057 - val_accuracy: 0.9752\n",
      "Epoch 91/100\n",
      "470/470 [==============================] - 0s 361us/step - loss: 0.5416 - accuracy: 0.8149 - val_loss: 0.4735 - val_accuracy: 0.9703\n",
      "Epoch 92/100\n",
      "470/470 [==============================] - 0s 224us/step - loss: 0.5926 - accuracy: 0.7872 - val_loss: 0.4156 - val_accuracy: 0.9752\n",
      "Epoch 93/100\n",
      "470/470 [==============================] - 0s 209us/step - loss: 0.6476 - accuracy: 0.7915 - val_loss: 0.5536 - val_accuracy: 0.9604\n",
      "Epoch 94/100\n",
      "470/470 [==============================] - 0s 274us/step - loss: 0.6923 - accuracy: 0.7809 - val_loss: 0.5008 - val_accuracy: 0.9703\n",
      "Epoch 95/100\n",
      "470/470 [==============================] - 0s 235us/step - loss: 0.5074 - accuracy: 0.7830 - val_loss: 0.4823 - val_accuracy: 0.9653\n",
      "Epoch 96/100\n",
      "470/470 [==============================] - 0s 277us/step - loss: 0.5911 - accuracy: 0.8106 - val_loss: 0.5330 - val_accuracy: 0.9653\n",
      "Epoch 97/100\n",
      "470/470 [==============================] - 0s 246us/step - loss: 0.6446 - accuracy: 0.7830 - val_loss: 0.4769 - val_accuracy: 0.9703\n",
      "Epoch 98/100\n",
      "470/470 [==============================] - 0s 251us/step - loss: 0.6283 - accuracy: 0.7787 - val_loss: 0.4802 - val_accuracy: 0.9703\n",
      "Epoch 99/100\n",
      "470/470 [==============================] - 0s 221us/step - loss: 0.5824 - accuracy: 0.8064 - val_loss: 0.4898 - val_accuracy: 0.9653\n",
      "Epoch 100/100\n",
      "470/470 [==============================] - 0s 208us/step - loss: 0.6039 - accuracy: 0.7936 - val_loss: 0.4419 - val_accuracy: 0.9752\n"
     ]
    }
   ],
   "source": [
    "hist1_over5 = model1_over5.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 78.96%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over5.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba5 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_regularizor_dropout_2.xlsx\",\n",
    "                        sheet_name=0,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS241</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.342914e-03</td>\n",
       "      <td>9.986569e-01</td>\n",
       "      <td>2.348628e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5.170289e-08</td>\n",
       "      <td>1.017893e-07</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS255</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.780311e-07</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>2.544841e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS214</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.203547e-10</td>\n",
       "      <td>5.688883e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5.170289e-08</td>\n",
       "      <td>1.017893e-07</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>BCH-SA-12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.152503e-09</td>\n",
       "      <td>1.898730e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS049</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.401357e-11</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.209735e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS022</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.755084e-10</td>\n",
       "      <td>1.974275e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS236</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.357345e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.293117e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4.074704e-08</td>\n",
       "      <td>2.329201e-08</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1982 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       phage     strain  phenotype  prediction             0  \\\n",
       "0     p002ykpresabsSTCC_qual     NRS241          1           1  1.342914e-03   \n",
       "1     p002ykpresabsSTCC_qual     NRS148          2           2  5.170289e-08   \n",
       "2     p002ykpresabsSTCC_qual     NRS255          1           1  1.780311e-07   \n",
       "3     p002ykpresabsSTCC_qual     NRS214          0           0  1.000000e+00   \n",
       "4     p002ykpresabsSTCC_qual     NRS148          2           2  5.170289e-08   \n",
       "...                      ...        ...        ...         ...           ...   \n",
       "1977     pyopresabsSTCC_qual  BCH-SA-12          0           0  1.000000e+00   \n",
       "1978     pyopresabsSTCC_qual     NRS049          0           1  8.401357e-11   \n",
       "1979     pyopresabsSTCC_qual     NRS022          0           0  1.000000e+00   \n",
       "1980     pyopresabsSTCC_qual     NRS236          1           1  1.357345e-08   \n",
       "1981     pyopresabsSTCC_qual     NRS148          2           2  4.074704e-08   \n",
       "\n",
       "                 1             2  \n",
       "0     9.986569e-01  2.348628e-07  \n",
       "1     1.017893e-07  9.999999e-01  \n",
       "2     9.999999e-01  2.544841e-12  \n",
       "3     2.203547e-10  5.688883e-15  \n",
       "4     1.017893e-07  9.999999e-01  \n",
       "...            ...           ...  \n",
       "1977  1.152503e-09  1.898730e-09  \n",
       "1978  1.000000e+00  3.209735e-13  \n",
       "1979  4.755084e-10  1.974275e-10  \n",
       "1980  1.000000e+00  1.293117e-10  \n",
       "1981  2.329201e-08  9.999999e-01  \n",
       "\n",
       "[1982 rows x 7 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.60222200e-08, 1.25439590e-15, 1.00000000e+00],\n",
       "       [1.27565190e-08, 6.20405100e-08, 9.99999900e-01],\n",
       "       [4.45871600e-09, 2.09763420e-08, 1.00000000e+00],\n",
       "       [6.08955500e-09, 1.00000000e+00, 1.17072420e-09],\n",
       "       [1.00000000e+00, 4.74884640e-18, 2.53574070e-13],\n",
       "       [1.00000000e+00, 1.23001175e-11, 4.37043600e-08],\n",
       "       [8.11105140e-11, 1.00000000e+00, 3.30003330e-13],\n",
       "       [1.68053830e-10, 1.00000000e+00, 1.59357100e-10],\n",
       "       [4.45871600e-09, 2.09763420e-08, 1.00000000e+00],\n",
       "       [1.00000000e+00, 5.08875830e-10, 2.96082520e-08],\n",
       "       [1.68053830e-10, 1.00000000e+00, 1.59357100e-10],\n",
       "       [1.00000000e+00, 4.62693750e-14, 1.40624480e-12],\n",
       "       [1.60222200e-08, 1.25439590e-15, 1.00000000e+00],\n",
       "       [1.00000000e+00, 8.76729300e-15, 5.49109900e-12],\n",
       "       [4.54805300e-03, 9.85998150e-01, 9.45374900e-03],\n",
       "       [1.00000000e+00, 1.40867750e-15, 1.78980150e-13],\n",
       "       [1.00000000e+00, 2.67006440e-09, 1.44676155e-11],\n",
       "       [4.45871600e-09, 2.09763420e-08, 1.00000000e+00],\n",
       "       [9.99998800e-01, 9.53495800e-07, 2.06862850e-07],\n",
       "       [2.20255520e-10, 1.00000000e+00, 6.21629100e-11],\n",
       "       [2.20255520e-10, 1.00000000e+00, 6.21629100e-11],\n",
       "       [4.45871600e-09, 2.09763420e-08, 1.00000000e+00],\n",
       "       [1.27565190e-08, 6.20405100e-08, 9.99999900e-01],\n",
       "       [1.27565190e-08, 6.20405100e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 3.99635500e-13, 4.14177760e-12],\n",
       "       [1.00000000e+00, 2.09183550e-13, 1.19094330e-11],\n",
       "       [1.00000000e+00, 6.82721260e-17, 6.07033230e-15],\n",
       "       [6.64197500e-08, 9.99999900e-01, 1.08289086e-10],\n",
       "       [1.60222200e-08, 1.25439590e-15, 1.00000000e+00],\n",
       "       [2.51843720e-09, 1.00000000e+00, 3.23838350e-10],\n",
       "       [4.45871600e-09, 2.09763420e-08, 1.00000000e+00],\n",
       "       [1.45640830e-10, 1.00000000e+00, 1.38179320e-10],\n",
       "       [4.54805300e-03, 9.85998150e-01, 9.45374900e-03],\n",
       "       [1.27565190e-08, 6.20405100e-08, 9.99999900e-01],\n",
       "       [3.34142470e-09, 1.00000000e+00, 1.59459240e-14],\n",
       "       [1.60222200e-08, 1.25439590e-15, 1.00000000e+00],\n",
       "       [1.00000000e+00, 2.25200630e-14, 1.77599430e-14],\n",
       "       [4.45871600e-09, 2.09763420e-08, 1.00000000e+00],\n",
       "       [1.00000000e+00, 1.06176860e-16, 1.22206020e-16],\n",
       "       [1.43939280e-08, 1.00000000e+00, 1.34209920e-08],\n",
       "       [6.64197500e-08, 9.99999900e-01, 1.08289086e-10],\n",
       "       [1.27565190e-08, 6.20405100e-08, 9.99999900e-01],\n",
       "       [1.60222200e-08, 1.25439590e-15, 1.00000000e+00],\n",
       "       [1.00000000e+00, 7.60353300e-17, 3.10445500e-17],\n",
       "       [1.27565190e-08, 6.20405100e-08, 9.99999900e-01],\n",
       "       [1.60222200e-08, 1.25439590e-15, 1.00000000e+00],\n",
       "       [1.60222200e-08, 1.25439590e-15, 1.00000000e+00],\n",
       "       [1.68053830e-10, 1.00000000e+00, 1.59357100e-10],\n",
       "       [1.00000000e+00, 1.00553470e-12, 4.04829200e-10],\n",
       "       [1.00000000e+00, 3.22930500e-17, 6.23896800e-14],\n",
       "       [1.00000000e+00, 8.13133170e-10, 1.25380580e-10],\n",
       "       [9.90381200e-01, 9.58004900e-03, 3.86780920e-05],\n",
       "       [1.00000000e+00, 1.49578090e-16, 1.68044980e-16],\n",
       "       [1.00000000e+00, 9.62493600e-10, 1.28395830e-09],\n",
       "       [1.27565190e-08, 6.20405100e-08, 9.99999900e-01],\n",
       "       [4.54805300e-03, 9.85998150e-01, 9.45374900e-03],\n",
       "       [1.27565190e-08, 6.20405100e-08, 9.99999900e-01],\n",
       "       [4.45871600e-09, 2.09763420e-08, 1.00000000e+00],\n",
       "       [4.54805300e-03, 9.85998150e-01, 9.45374900e-03],\n",
       "       [3.34142470e-09, 1.00000000e+00, 1.59459240e-14],\n",
       "       [1.27565190e-08, 6.20405100e-08, 9.99999900e-01],\n",
       "       [4.45871600e-09, 2.09763420e-08, 1.00000000e+00],\n",
       "       [1.00000000e+00, 1.68249650e-08, 2.11076910e-09],\n",
       "       [9.99978900e-01, 1.07981320e-05, 1.02153580e-05],\n",
       "       [1.68053830e-10, 1.00000000e+00, 1.59357100e-10],\n",
       "       [1.00000000e+00, 1.71491510e-08, 3.42208200e-08],\n",
       "       [1.10784320e-07, 9.99999760e-01, 7.84552700e-08],\n",
       "       [4.45871600e-09, 2.09763420e-08, 1.00000000e+00],\n",
       "       [2.81984200e-10, 1.00000000e+00, 7.75434750e-12],\n",
       "       [9.99999640e-01, 2.64838060e-07, 7.14783540e-08],\n",
       "       [1.27565190e-08, 6.20405100e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 2.92150850e-18, 3.87987900e-16],\n",
       "       [1.06310930e-10, 1.00000000e+00, 2.50360900e-13],\n",
       "       [1.60222200e-08, 1.25439590e-15, 1.00000000e+00],\n",
       "       [1.00000000e+00, 1.99705530e-14, 1.24207280e-15],\n",
       "       [1.27565190e-08, 6.20405100e-08, 9.99999900e-01],\n",
       "       [6.64197500e-08, 9.99999900e-01, 1.08289086e-10],\n",
       "       [1.60222200e-08, 1.25439590e-15, 1.00000000e+00],\n",
       "       [3.34405780e-05, 9.99966500e-01, 5.40737230e-09],\n",
       "       [1.60222200e-08, 1.25439590e-15, 1.00000000e+00],\n",
       "       [4.45871600e-09, 2.09763420e-08, 1.00000000e+00],\n",
       "       [1.00000000e+00, 1.79998020e-16, 1.99594900e-16],\n",
       "       [2.20255520e-10, 1.00000000e+00, 6.21629100e-11],\n",
       "       [1.60222200e-08, 1.25439590e-15, 1.00000000e+00],\n",
       "       [4.45871600e-09, 2.09763420e-08, 1.00000000e+00],\n",
       "       [4.45871600e-09, 2.09763420e-08, 1.00000000e+00],\n",
       "       [1.00000000e+00, 1.40806650e-13, 9.75696440e-14],\n",
       "       [1.43939280e-08, 1.00000000e+00, 1.34209920e-08],\n",
       "       [8.11105140e-11, 1.00000000e+00, 3.30003330e-13],\n",
       "       [4.54805300e-03, 9.85998150e-01, 9.45374900e-03],\n",
       "       [1.00000000e+00, 8.43231560e-17, 1.04872990e-13],\n",
       "       [2.81984200e-10, 1.00000000e+00, 7.75434750e-12],\n",
       "       [4.90920700e-01, 5.09077400e-01, 1.85799430e-06],\n",
       "       [1.00000000e+00, 8.48155840e-14, 8.70412030e-13],\n",
       "       [4.54805300e-03, 9.85998150e-01, 9.45374900e-03],\n",
       "       [1.60222200e-08, 1.25439590e-15, 1.00000000e+00],\n",
       "       [1.00000000e+00, 2.13908030e-15, 1.70198070e-13],\n",
       "       [4.45871600e-09, 2.09763420e-08, 1.00000000e+00],\n",
       "       [2.51843720e-09, 1.00000000e+00, 3.23838350e-10],\n",
       "       [4.45871600e-09, 2.09763420e-08, 1.00000000e+00],\n",
       "       [1.00000000e+00, 1.01445620e-19, 1.90724960e-19],\n",
       "       [1.00000000e+00, 7.01129000e-14, 5.10341550e-14],\n",
       "       [1.68053830e-10, 1.00000000e+00, 1.59357100e-10],\n",
       "       [1.00000000e+00, 6.98092250e-13, 1.85734020e-13],\n",
       "       [3.34142470e-09, 1.00000000e+00, 1.59459240e-14],\n",
       "       [4.45871600e-09, 2.09763420e-08, 1.00000000e+00],\n",
       "       [6.55096900e-13, 1.00000000e+00, 2.02310160e-15],\n",
       "       [1.68053830e-10, 1.00000000e+00, 1.59357100e-10],\n",
       "       [1.60222200e-08, 1.25439590e-15, 1.00000000e+00],\n",
       "       [1.00000000e+00, 2.82953900e-18, 4.20612160e-18],\n",
       "       [1.00000000e+00, 1.40867750e-15, 1.78980150e-13],\n",
       "       [1.27565190e-08, 6.20405100e-08, 9.99999900e-01],\n",
       "       [6.08955500e-09, 1.00000000e+00, 1.17072420e-09],\n",
       "       [1.00000000e+00, 2.19577460e-12, 1.25340290e-12],\n",
       "       [1.54864970e-08, 1.00000000e+00, 2.04591620e-10],\n",
       "       [4.45871600e-09, 2.09763420e-08, 1.00000000e+00],\n",
       "       [1.00000000e+00, 1.03295900e-10, 3.25490330e-11],\n",
       "       [4.45871600e-09, 2.09763420e-08, 1.00000000e+00],\n",
       "       [8.17967360e-11, 1.00000000e+00, 7.43047700e-12],\n",
       "       [1.60222200e-08, 1.25439590e-15, 1.00000000e+00],\n",
       "       [1.00000000e+00, 2.67006440e-09, 1.44676155e-11],\n",
       "       [6.55096900e-13, 1.00000000e+00, 2.02310160e-15],\n",
       "       [1.00000000e+00, 3.19560280e-11, 1.45497490e-11],\n",
       "       [1.27565190e-08, 6.20405100e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 7.10088800e-16, 7.69744440e-14],\n",
       "       [8.67267600e-11, 1.00000000e+00, 8.65380550e-11],\n",
       "       [1.27565190e-08, 6.20405100e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 1.59712500e-10, 4.54601250e-10],\n",
       "       [4.54805300e-03, 9.85998150e-01, 9.45374900e-03],\n",
       "       [1.00000000e+00, 5.20882460e-19, 1.43056560e-16],\n",
       "       [3.45730920e-10, 1.00000000e+00, 3.26945220e-10],\n",
       "       [3.34405780e-05, 9.99966500e-01, 5.40737230e-09],\n",
       "       [1.60222200e-08, 1.25439590e-15, 1.00000000e+00],\n",
       "       [4.45871600e-09, 2.09763420e-08, 1.00000000e+00],\n",
       "       [1.14835630e-09, 1.00000000e+00, 1.56545210e-09],\n",
       "       [9.99712050e-01, 2.73918850e-04, 1.40091710e-05],\n",
       "       [4.54805300e-03, 9.85998150e-01, 9.45374900e-03],\n",
       "       [1.10784320e-07, 9.99999760e-01, 7.84552700e-08],\n",
       "       [1.00000000e+00, 1.54899660e-14, 2.10125100e-11],\n",
       "       [4.45871600e-09, 2.09763420e-08, 1.00000000e+00],\n",
       "       [3.02855700e-10, 1.00000000e+00, 6.52653430e-10],\n",
       "       [4.54805300e-03, 9.85998150e-01, 9.45374900e-03],\n",
       "       [4.54805300e-03, 9.85998150e-01, 9.45374900e-03],\n",
       "       [4.54805300e-03, 9.85998150e-01, 9.45374900e-03],\n",
       "       [1.00000000e+00, 7.49494000e-09, 2.01245860e-09],\n",
       "       [4.45871600e-09, 2.09763420e-08, 1.00000000e+00],\n",
       "       [2.51843720e-09, 1.00000000e+00, 3.23838350e-10],\n",
       "       [4.54805300e-03, 9.85998150e-01, 9.45374900e-03],\n",
       "       [2.20255520e-10, 1.00000000e+00, 6.21629100e-11],\n",
       "       [1.10784320e-07, 9.99999760e-01, 7.84552700e-08],\n",
       "       [1.00000000e+00, 2.67006440e-09, 1.44676155e-11],\n",
       "       [8.95379200e-01, 1.04620430e-01, 4.07442680e-07],\n",
       "       [1.00000000e+00, 1.06930630e-09, 3.46793570e-10],\n",
       "       [4.45871600e-09, 2.09763420e-08, 1.00000000e+00],\n",
       "       [1.00000000e+00, 2.67006440e-09, 1.44676155e-11],\n",
       "       [9.99999900e-01, 9.78683300e-08, 4.33019270e-08],\n",
       "       [8.11105140e-11, 1.00000000e+00, 3.30003330e-13],\n",
       "       [4.54805300e-03, 9.85998150e-01, 9.45374900e-03],\n",
       "       [1.27565190e-08, 6.20405100e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 9.34840900e-12, 4.77358040e-12],\n",
       "       [4.45871600e-09, 2.09763420e-08, 1.00000000e+00],\n",
       "       [8.67267600e-11, 1.00000000e+00, 8.65380550e-11],\n",
       "       [1.00000000e+00, 3.00143520e-15, 4.51067740e-14],\n",
       "       [4.45871600e-09, 2.09763420e-08, 1.00000000e+00],\n",
       "       [4.54805300e-03, 9.85998150e-01, 9.45374900e-03],\n",
       "       [1.45640830e-10, 1.00000000e+00, 1.38179320e-10],\n",
       "       [1.68053830e-10, 1.00000000e+00, 1.59357100e-10],\n",
       "       [1.45640830e-10, 1.00000000e+00, 1.38179320e-10],\n",
       "       [1.00000000e+00, 5.23340900e-09, 7.54556860e-10],\n",
       "       [1.60222200e-08, 1.25439590e-15, 1.00000000e+00],\n",
       "       [9.99999760e-01, 1.86020470e-07, 1.51347550e-09],\n",
       "       [1.00000000e+00, 5.26396200e-13, 1.14399160e-11],\n",
       "       [1.00000000e+00, 3.88026160e-17, 4.79484800e-17],\n",
       "       [1.00000000e+00, 9.84097900e-17, 3.81895000e-26],\n",
       "       [1.60222200e-08, 1.25439590e-15, 1.00000000e+00],\n",
       "       [6.64197500e-08, 9.99999900e-01, 1.08289086e-10],\n",
       "       [5.17726700e-08, 1.00000000e+00, 4.58069940e-09],\n",
       "       [8.11105140e-11, 1.00000000e+00, 3.30003330e-13],\n",
       "       [4.54805300e-03, 9.85998150e-01, 9.45374900e-03],\n",
       "       [1.00000000e+00, 1.59731850e-08, 1.31662780e-08],\n",
       "       [1.27565190e-08, 6.20405100e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 5.23723800e-11, 2.27427890e-11],\n",
       "       [4.45871600e-09, 2.09763420e-08, 1.00000000e+00],\n",
       "       [1.00000000e+00, 2.29396460e-20, 7.88763800e-14],\n",
       "       [1.45640830e-10, 1.00000000e+00, 1.38179320e-10],\n",
       "       [1.00000000e+00, 9.36282700e-12, 2.43198600e-11],\n",
       "       [1.00000000e+00, 2.82224040e-11, 2.71629860e-10],\n",
       "       [5.17726700e-08, 1.00000000e+00, 4.58069940e-09],\n",
       "       [1.27565190e-08, 6.20405100e-08, 9.99999900e-01],\n",
       "       [9.99736000e-01, 2.63800580e-04, 7.23040600e-08],\n",
       "       [6.64197500e-08, 9.99999900e-01, 1.08289086e-10],\n",
       "       [1.60222200e-08, 1.25439590e-15, 1.00000000e+00],\n",
       "       [1.60222500e-08, 1.25440060e-15, 1.00000000e+00],\n",
       "       [1.27565190e-08, 6.20405100e-08, 9.99999900e-01],\n",
       "       [4.45870760e-09, 2.09762630e-08, 1.00000000e+00],\n",
       "       [1.00000000e+00, 1.57187540e-17, 3.19746370e-14],\n",
       "       [1.60222500e-08, 1.25440060e-15, 1.00000000e+00],\n",
       "       [4.45870760e-09, 2.09762630e-08, 1.00000000e+00],\n",
       "       [4.45870760e-09, 2.09762630e-08, 1.00000000e+00],\n",
       "       [1.00000000e+00, 8.07997500e-17, 2.88066100e-26],\n",
       "       [1.60222500e-08, 1.25440060e-15, 1.00000000e+00],\n",
       "       [1.60222500e-08, 1.25440060e-15, 1.00000000e+00]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob5 = df_proba5[df_proba5['phage']=='p003ppresabsSTCC_qual'].iloc[:,-3:]\n",
    "y_prob5 = y_prob5.to_numpy()\n",
    "y_prob5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9944271019629521"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo5 = rocauc_ovo(y_test_over, y_prob5, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9944271019629521"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr5 = rocauc_ovr(y_test_over, y_prob5, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=678,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat6 = pd.DataFrame(X_test_over[:,0])\n",
    "dat6['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GA984</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS187</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>NRS253</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>EUH15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>NRS180</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>NRS266</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>NRS109</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0  test\n",
       "0       115     1\n",
       "1    NRS209     2\n",
       "2     GA984     0\n",
       "3    NRS187     1\n",
       "4    NRS148     2\n",
       "..      ...   ...\n",
       "197  NRS253     1\n",
       "198   EUH15     0\n",
       "199  NRS180     1\n",
       "200  NRS266     1\n",
       "201  NRS109     1\n",
       "\n",
       "[202 rows x 2 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over6 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],), activity_regularizer=l1(0.001)),\n",
    "    Dense(3, activation='softmax'),\n",
    "    Dropout(0.2, ),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over6.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 470 samples, validate on 202 samples\n",
      "Epoch 1/100\n",
      "470/470 [==============================] - 0s 687us/step - loss: 8.4326 - accuracy: 0.4149 - val_loss: 3.5536 - val_accuracy: 0.5000\n",
      "Epoch 2/100\n",
      "470/470 [==============================] - 0s 224us/step - loss: 5.5203 - accuracy: 0.5170 - val_loss: 1.9669 - val_accuracy: 0.7376\n",
      "Epoch 3/100\n",
      "470/470 [==============================] - 0s 244us/step - loss: 4.4551 - accuracy: 0.6213 - val_loss: 1.1876 - val_accuracy: 0.8218\n",
      "Epoch 4/100\n",
      "470/470 [==============================] - 0s 198us/step - loss: 3.9019 - accuracy: 0.5979 - val_loss: 0.8677 - val_accuracy: 0.7178\n",
      "Epoch 5/100\n",
      "470/470 [==============================] - 0s 199us/step - loss: 3.5476 - accuracy: 0.5957 - val_loss: 0.7555 - val_accuracy: 0.7871\n",
      "Epoch 6/100\n",
      "470/470 [==============================] - 0s 330us/step - loss: 3.4033 - accuracy: 0.6362 - val_loss: 0.6909 - val_accuracy: 0.8713\n",
      "Epoch 7/100\n",
      "470/470 [==============================] - 0s 231us/step - loss: 3.4419 - accuracy: 0.6426 - val_loss: 0.6971 - val_accuracy: 0.8762\n",
      "Epoch 8/100\n",
      "470/470 [==============================] - 0s 503us/step - loss: 3.4046 - accuracy: 0.6489 - val_loss: 0.7112 - val_accuracy: 0.8366\n",
      "Epoch 9/100\n",
      "470/470 [==============================] - 0s 233us/step - loss: 3.2150 - accuracy: 0.6447 - val_loss: 0.7377 - val_accuracy: 0.8911\n",
      "Epoch 10/100\n",
      "470/470 [==============================] - 0s 226us/step - loss: 3.0868 - accuracy: 0.6745 - val_loss: 0.7549 - val_accuracy: 0.8713\n",
      "Epoch 11/100\n",
      "470/470 [==============================] - 0s 132us/step - loss: 2.6451 - accuracy: 0.7021 - val_loss: 0.6439 - val_accuracy: 0.9158\n",
      "Epoch 12/100\n",
      "470/470 [==============================] - 0s 132us/step - loss: 2.7841 - accuracy: 0.7000 - val_loss: 0.6188 - val_accuracy: 0.9109\n",
      "Epoch 13/100\n",
      "470/470 [==============================] - 0s 350us/step - loss: 3.1707 - accuracy: 0.6894 - val_loss: 0.6527 - val_accuracy: 0.8960\n",
      "Epoch 14/100\n",
      "470/470 [==============================] - 0s 402us/step - loss: 3.0458 - accuracy: 0.6915 - val_loss: 0.6218 - val_accuracy: 0.9059\n",
      "Epoch 15/100\n",
      "470/470 [==============================] - 0s 445us/step - loss: 2.8139 - accuracy: 0.7255 - val_loss: 0.6215 - val_accuracy: 0.9356\n",
      "Epoch 16/100\n",
      "470/470 [==============================] - 0s 273us/step - loss: 2.9459 - accuracy: 0.6915 - val_loss: 0.6709 - val_accuracy: 0.9010\n",
      "Epoch 17/100\n",
      "470/470 [==============================] - 0s 369us/step - loss: 2.8662 - accuracy: 0.6915 - val_loss: 0.6792 - val_accuracy: 0.8911\n",
      "Epoch 18/100\n",
      "470/470 [==============================] - 0s 333us/step - loss: 2.6750 - accuracy: 0.7383 - val_loss: 0.6849 - val_accuracy: 0.9158\n",
      "Epoch 19/100\n",
      "470/470 [==============================] - 0s 324us/step - loss: 3.3369 - accuracy: 0.6617 - val_loss: 0.6881 - val_accuracy: 0.9208\n",
      "Epoch 20/100\n",
      "470/470 [==============================] - 0s 147us/step - loss: 2.5326 - accuracy: 0.7128 - val_loss: 0.6824 - val_accuracy: 0.9010\n",
      "Epoch 21/100\n",
      "470/470 [==============================] - 0s 286us/step - loss: 2.8449 - accuracy: 0.6809 - val_loss: 0.7001 - val_accuracy: 0.9059\n",
      "Epoch 22/100\n",
      "470/470 [==============================] - 0s 516us/step - loss: 2.5910 - accuracy: 0.6957 - val_loss: 0.6792 - val_accuracy: 0.9010\n",
      "Epoch 23/100\n",
      "470/470 [==============================] - 0s 211us/step - loss: 2.3833 - accuracy: 0.7255 - val_loss: 0.7151 - val_accuracy: 0.9059\n",
      "Epoch 24/100\n",
      "470/470 [==============================] - 0s 222us/step - loss: 2.5649 - accuracy: 0.6830 - val_loss: 0.7583 - val_accuracy: 0.9109\n",
      "Epoch 25/100\n",
      "470/470 [==============================] - 0s 181us/step - loss: 2.5393 - accuracy: 0.6936 - val_loss: 0.7515 - val_accuracy: 0.9059\n",
      "Epoch 26/100\n",
      "470/470 [==============================] - 0s 142us/step - loss: 2.5325 - accuracy: 0.6936 - val_loss: 0.8862 - val_accuracy: 0.9010\n",
      "Epoch 27/100\n",
      "470/470 [==============================] - 0s 127us/step - loss: 2.1843 - accuracy: 0.7468 - val_loss: 0.7644 - val_accuracy: 0.8861\n",
      "Epoch 28/100\n",
      "470/470 [==============================] - 0s 127us/step - loss: 2.6787 - accuracy: 0.6915 - val_loss: 0.8053 - val_accuracy: 0.9059\n",
      "Epoch 29/100\n",
      "470/470 [==============================] - 0s 177us/step - loss: 2.4151 - accuracy: 0.7149 - val_loss: 0.8337 - val_accuracy: 0.9109\n",
      "Epoch 30/100\n",
      "470/470 [==============================] - 0s 193us/step - loss: 2.5106 - accuracy: 0.6894 - val_loss: 0.8014 - val_accuracy: 0.9010\n",
      "Epoch 31/100\n",
      "470/470 [==============================] - 0s 193us/step - loss: 2.5355 - accuracy: 0.6809 - val_loss: 0.8675 - val_accuracy: 0.9010\n",
      "Epoch 32/100\n",
      "470/470 [==============================] - 0s 145us/step - loss: 2.5772 - accuracy: 0.6681 - val_loss: 0.9929 - val_accuracy: 0.9010\n",
      "Epoch 33/100\n",
      "470/470 [==============================] - 0s 134us/step - loss: 2.4644 - accuracy: 0.7043 - val_loss: 0.8759 - val_accuracy: 0.9356\n",
      "Epoch 34/100\n",
      "470/470 [==============================] - 0s 131us/step - loss: 2.3927 - accuracy: 0.7489 - val_loss: 0.9320 - val_accuracy: 0.9109\n",
      "Epoch 35/100\n",
      "470/470 [==============================] - 0s 131us/step - loss: 2.3023 - accuracy: 0.7085 - val_loss: 0.8584 - val_accuracy: 0.9307\n",
      "Epoch 36/100\n",
      "470/470 [==============================] - 0s 138us/step - loss: 2.2130 - accuracy: 0.7234 - val_loss: 0.8879 - val_accuracy: 0.9356\n",
      "Epoch 37/100\n",
      "470/470 [==============================] - 0s 422us/step - loss: 2.1119 - accuracy: 0.7574 - val_loss: 0.9565 - val_accuracy: 0.9307\n",
      "Epoch 38/100\n",
      "470/470 [==============================] - 0s 414us/step - loss: 2.6543 - accuracy: 0.7043 - val_loss: 0.9391 - val_accuracy: 0.9059\n",
      "Epoch 39/100\n",
      "470/470 [==============================] - 0s 251us/step - loss: 1.7303 - accuracy: 0.7596 - val_loss: 0.8902 - val_accuracy: 0.9356\n",
      "Epoch 40/100\n",
      "470/470 [==============================] - 0s 165us/step - loss: 1.9239 - accuracy: 0.7574 - val_loss: 0.8667 - val_accuracy: 0.9703\n",
      "Epoch 41/100\n",
      "470/470 [==============================] - 0s 216us/step - loss: 2.1726 - accuracy: 0.7447 - val_loss: 0.8922 - val_accuracy: 0.9604\n",
      "Epoch 42/100\n",
      "470/470 [==============================] - 0s 323us/step - loss: 1.8791 - accuracy: 0.7617 - val_loss: 0.8929 - val_accuracy: 0.9307\n",
      "Epoch 43/100\n",
      "470/470 [==============================] - 0s 194us/step - loss: 2.0817 - accuracy: 0.7383 - val_loss: 0.9324 - val_accuracy: 0.9406\n",
      "Epoch 44/100\n",
      "470/470 [==============================] - 0s 233us/step - loss: 2.1425 - accuracy: 0.7574 - val_loss: 0.9149 - val_accuracy: 0.9307\n",
      "Epoch 45/100\n",
      "470/470 [==============================] - 0s 184us/step - loss: 1.9656 - accuracy: 0.6809 - val_loss: 0.9138 - val_accuracy: 0.9307\n",
      "Epoch 46/100\n",
      "470/470 [==============================] - 0s 200us/step - loss: 1.9139 - accuracy: 0.7532 - val_loss: 0.8156 - val_accuracy: 0.9406\n",
      "Epoch 47/100\n",
      "470/470 [==============================] - 0s 430us/step - loss: 2.1146 - accuracy: 0.7362 - val_loss: 0.9029 - val_accuracy: 0.9208\n",
      "Epoch 48/100\n",
      "470/470 [==============================] - 0s 248us/step - loss: 1.7624 - accuracy: 0.7489 - val_loss: 0.7785 - val_accuracy: 0.9307\n",
      "Epoch 49/100\n",
      "470/470 [==============================] - 0s 168us/step - loss: 1.7762 - accuracy: 0.7936 - val_loss: 0.8169 - val_accuracy: 0.9604\n",
      "Epoch 50/100\n",
      "470/470 [==============================] - 0s 170us/step - loss: 1.8087 - accuracy: 0.7447 - val_loss: 0.9468 - val_accuracy: 0.9010\n",
      "Epoch 51/100\n",
      "470/470 [==============================] - 0s 193us/step - loss: 1.9297 - accuracy: 0.7383 - val_loss: 0.8338 - val_accuracy: 0.9604\n",
      "Epoch 52/100\n",
      "470/470 [==============================] - 0s 222us/step - loss: 1.5902 - accuracy: 0.7872 - val_loss: 0.9304 - val_accuracy: 0.9604\n",
      "Epoch 53/100\n",
      "470/470 [==============================] - 0s 154us/step - loss: 2.0034 - accuracy: 0.7255 - val_loss: 0.9168 - val_accuracy: 0.9307\n",
      "Epoch 54/100\n",
      "470/470 [==============================] - 0s 169us/step - loss: 1.8349 - accuracy: 0.7426 - val_loss: 0.8168 - val_accuracy: 0.9604\n",
      "Epoch 55/100\n",
      "470/470 [==============================] - 0s 232us/step - loss: 1.9633 - accuracy: 0.7234 - val_loss: 0.8827 - val_accuracy: 0.9554\n",
      "Epoch 56/100\n",
      "470/470 [==============================] - 0s 179us/step - loss: 1.9178 - accuracy: 0.7213 - val_loss: 0.8950 - val_accuracy: 0.9505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "470/470 [==============================] - 0s 166us/step - loss: 1.5973 - accuracy: 0.7851 - val_loss: 1.0340 - val_accuracy: 0.8960\n",
      "Epoch 58/100\n",
      "470/470 [==============================] - 0s 134us/step - loss: 1.7951 - accuracy: 0.7426 - val_loss: 0.6791 - val_accuracy: 0.9455\n",
      "Epoch 59/100\n",
      "470/470 [==============================] - 0s 278us/step - loss: 1.6915 - accuracy: 0.7638 - val_loss: 0.8388 - val_accuracy: 0.9653\n",
      "Epoch 60/100\n",
      "470/470 [==============================] - 0s 143us/step - loss: 1.9093 - accuracy: 0.7362 - val_loss: 0.7838 - val_accuracy: 0.9554\n",
      "Epoch 61/100\n",
      "470/470 [==============================] - 0s 141us/step - loss: 1.7651 - accuracy: 0.7532 - val_loss: 0.9419 - val_accuracy: 0.9356\n",
      "Epoch 62/100\n",
      "470/470 [==============================] - 0s 167us/step - loss: 1.8136 - accuracy: 0.7468 - val_loss: 0.7847 - val_accuracy: 0.9604\n",
      "Epoch 63/100\n",
      "470/470 [==============================] - 0s 171us/step - loss: 1.5301 - accuracy: 0.7596 - val_loss: 0.8855 - val_accuracy: 0.9505\n",
      "Epoch 64/100\n",
      "470/470 [==============================] - 0s 129us/step - loss: 1.6610 - accuracy: 0.7532 - val_loss: 0.8343 - val_accuracy: 0.9604\n",
      "Epoch 65/100\n",
      "470/470 [==============================] - 0s 132us/step - loss: 1.7358 - accuracy: 0.7787 - val_loss: 0.8002 - val_accuracy: 0.9653\n",
      "Epoch 66/100\n",
      "470/470 [==============================] - 0s 159us/step - loss: 1.6139 - accuracy: 0.7553 - val_loss: 0.8853 - val_accuracy: 0.9505\n",
      "Epoch 67/100\n",
      "470/470 [==============================] - 0s 186us/step - loss: 1.7027 - accuracy: 0.7574 - val_loss: 0.7559 - val_accuracy: 0.9356\n",
      "Epoch 68/100\n",
      "470/470 [==============================] - 0s 138us/step - loss: 1.5913 - accuracy: 0.7553 - val_loss: 0.8880 - val_accuracy: 0.9653\n",
      "Epoch 69/100\n",
      "470/470 [==============================] - 0s 130us/step - loss: 1.5686 - accuracy: 0.7681 - val_loss: 0.7116 - val_accuracy: 0.9653\n",
      "Epoch 70/100\n",
      "470/470 [==============================] - 0s 148us/step - loss: 1.6043 - accuracy: 0.7809 - val_loss: 0.7710 - val_accuracy: 0.9604\n",
      "Epoch 71/100\n",
      "470/470 [==============================] - 0s 143us/step - loss: 1.5816 - accuracy: 0.7809 - val_loss: 0.8715 - val_accuracy: 0.9653\n",
      "Epoch 72/100\n",
      "470/470 [==============================] - 0s 131us/step - loss: 1.4374 - accuracy: 0.7872 - val_loss: 0.7788 - val_accuracy: 0.9653\n",
      "Epoch 73/100\n",
      "470/470 [==============================] - 0s 136us/step - loss: 1.5418 - accuracy: 0.7574 - val_loss: 0.6482 - val_accuracy: 0.9554\n",
      "Epoch 74/100\n",
      "470/470 [==============================] - 0s 181us/step - loss: 1.8322 - accuracy: 0.7319 - val_loss: 0.9489 - val_accuracy: 0.9010\n",
      "Epoch 75/100\n",
      "470/470 [==============================] - 0s 185us/step - loss: 1.4896 - accuracy: 0.7745 - val_loss: 0.8956 - val_accuracy: 0.9653\n",
      "Epoch 76/100\n",
      "470/470 [==============================] - 0s 205us/step - loss: 1.2315 - accuracy: 0.7894 - val_loss: 0.7038 - val_accuracy: 0.9653\n",
      "Epoch 77/100\n",
      "470/470 [==============================] - 0s 157us/step - loss: 1.6249 - accuracy: 0.7234 - val_loss: 0.7948 - val_accuracy: 0.9554\n",
      "Epoch 78/100\n",
      "470/470 [==============================] - 0s 128us/step - loss: 1.4057 - accuracy: 0.7915 - val_loss: 0.6788 - val_accuracy: 0.9653\n",
      "Epoch 79/100\n",
      "470/470 [==============================] - 0s 140us/step - loss: 1.5276 - accuracy: 0.7617 - val_loss: 0.7074 - val_accuracy: 0.9653\n",
      "Epoch 80/100\n",
      "470/470 [==============================] - 0s 216us/step - loss: 1.3709 - accuracy: 0.7809 - val_loss: 0.6449 - val_accuracy: 0.9653\n",
      "Epoch 81/100\n",
      "470/470 [==============================] - 0s 205us/step - loss: 1.4429 - accuracy: 0.7511 - val_loss: 0.7274 - val_accuracy: 0.9604\n",
      "Epoch 82/100\n",
      "470/470 [==============================] - 0s 204us/step - loss: 1.3685 - accuracy: 0.7553 - val_loss: 0.6324 - val_accuracy: 0.9653\n",
      "Epoch 83/100\n",
      "470/470 [==============================] - 0s 200us/step - loss: 1.4127 - accuracy: 0.7894 - val_loss: 0.6876 - val_accuracy: 0.9604\n",
      "Epoch 84/100\n",
      "470/470 [==============================] - 0s 184us/step - loss: 1.3194 - accuracy: 0.7872 - val_loss: 0.7508 - val_accuracy: 0.9554\n",
      "Epoch 85/100\n",
      "470/470 [==============================] - 0s 173us/step - loss: 1.3079 - accuracy: 0.7532 - val_loss: 0.7784 - val_accuracy: 0.9653\n",
      "Epoch 86/100\n",
      "470/470 [==============================] - 0s 181us/step - loss: 1.3063 - accuracy: 0.7660 - val_loss: 0.5683 - val_accuracy: 0.9653\n",
      "Epoch 87/100\n",
      "470/470 [==============================] - 0s 187us/step - loss: 1.3759 - accuracy: 0.7574 - val_loss: 0.8800 - val_accuracy: 0.9554\n",
      "Epoch 88/100\n",
      "470/470 [==============================] - 0s 138us/step - loss: 1.5823 - accuracy: 0.7447 - val_loss: 0.6401 - val_accuracy: 0.9653\n",
      "Epoch 89/100\n",
      "470/470 [==============================] - 0s 129us/step - loss: 1.0901 - accuracy: 0.8234 - val_loss: 0.7369 - val_accuracy: 0.9505\n",
      "Epoch 90/100\n",
      "470/470 [==============================] - 0s 239us/step - loss: 1.3242 - accuracy: 0.7660 - val_loss: 0.6719 - val_accuracy: 0.9653\n",
      "Epoch 91/100\n",
      "470/470 [==============================] - 0s 218us/step - loss: 1.3114 - accuracy: 0.7553 - val_loss: 0.6352 - val_accuracy: 0.9653\n",
      "Epoch 92/100\n",
      "470/470 [==============================] - 0s 242us/step - loss: 1.3520 - accuracy: 0.7809 - val_loss: 0.8831 - val_accuracy: 0.9257\n",
      "Epoch 93/100\n",
      "470/470 [==============================] - 0s 237us/step - loss: 1.3702 - accuracy: 0.7681 - val_loss: 0.6764 - val_accuracy: 0.9455\n",
      "Epoch 94/100\n",
      "470/470 [==============================] - 0s 230us/step - loss: 1.3781 - accuracy: 0.7617 - val_loss: 0.6846 - val_accuracy: 0.9653\n",
      "Epoch 95/100\n",
      "470/470 [==============================] - 0s 270us/step - loss: 1.1533 - accuracy: 0.7915 - val_loss: 0.5791 - val_accuracy: 0.9653\n",
      "Epoch 96/100\n",
      "470/470 [==============================] - 0s 190us/step - loss: 1.3120 - accuracy: 0.7383 - val_loss: 0.7037 - val_accuracy: 0.9505\n",
      "Epoch 97/100\n",
      "470/470 [==============================] - 0s 139us/step - loss: 1.2833 - accuracy: 0.7596 - val_loss: 0.7679 - val_accuracy: 0.9604\n",
      "Epoch 98/100\n",
      "470/470 [==============================] - 0s 137us/step - loss: 1.5283 - accuracy: 0.7468 - val_loss: 0.6174 - val_accuracy: 0.9604\n",
      "Epoch 99/100\n",
      "470/470 [==============================] - 0s 254us/step - loss: 1.3741 - accuracy: 0.7723 - val_loss: 0.6923 - val_accuracy: 0.9653\n",
      "Epoch 100/100\n",
      "470/470 [==============================] - 0s 259us/step - loss: 1.3539 - accuracy: 0.7638 - val_loss: 0.6318 - val_accuracy: 0.9604\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a3ea1a048>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over6.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202/202 [==============================] - 0s 124us/step\n",
      "over-sampling test accuracy: 96.04%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over6 = model1_over6.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over6*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 0, 1, 2, 2, 1, 1, 1, 0, 2, 1, 2, 1, 0, 0, 0, 2, 1, 1, 0, 0,\n",
       "       2, 0, 2, 0, 2, 0, 0, 0, 1, 0, 2, 2, 2, 2, 1, 0, 2, 2, 2, 1, 0, 1,\n",
       "       2, 2, 2, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 1, 1, 1, 1, 1, 2, 0,\n",
       "       1, 1, 2, 2, 0, 2, 2, 2, 0, 1, 0, 0, 2, 2, 0, 2, 2, 2, 1, 0, 1, 1,\n",
       "       0, 2, 2, 2, 2, 1, 0, 2, 2, 0, 2, 1, 0, 0, 0, 2, 2, 0, 2, 0, 2, 2,\n",
       "       0, 0, 0, 2, 1, 0, 1, 1, 2, 0, 2, 2, 1, 1, 0, 0, 2, 1, 1, 1, 1, 2,\n",
       "       1, 0, 2, 2, 1, 2, 0, 1, 2, 0, 1, 0, 1, 1, 1, 0, 1, 2, 0, 1, 0, 1,\n",
       "       1, 2, 0, 2, 2, 0, 2, 1, 0, 2, 0, 2, 1, 2, 1, 2, 1, 0, 2, 0, 2, 2,\n",
       "       1, 0, 2, 2, 2, 0, 0, 1, 1, 0, 0, 0, 2, 2, 0, 0, 1, 1, 0, 0, 2, 1,\n",
       "       0, 1, 1, 1])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred6 = model1_over6.predict_classes(X_test_over)\n",
    "pred6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GA984</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS187</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>NRS253</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>EUH15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>NRS180</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>NRS266</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>NRS109</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0  test  pred\n",
       "0       115     1     1\n",
       "1    NRS209     2     2\n",
       "2     GA984     0     0\n",
       "3    NRS187     1     1\n",
       "4    NRS148     2     2\n",
       "..      ...   ...   ...\n",
       "197  NRS253     1     1\n",
       "198   EUH15     0     0\n",
       "199  NRS180     1     1\n",
       "200  NRS266     1     1\n",
       "201  NRS109     1     1\n",
       "\n",
       "[202 rows x 3 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat6['pred'] = pred6\n",
    "dat6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba6 = model1_over6.predict_proba(X_test_over)\n",
    "dat_proba6 = pd.DataFrame(proba6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.250444e-05</td>\n",
       "      <td>9.999866e-01</td>\n",
       "      <td>7.751040e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.182140e-08</td>\n",
       "      <td>6.756152e-08</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.999980e-01</td>\n",
       "      <td>1.788405e-06</td>\n",
       "      <td>1.889782e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.463270e-05</td>\n",
       "      <td>9.999526e-01</td>\n",
       "      <td>2.906656e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.719623e-09</td>\n",
       "      <td>6.788134e-08</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>2.495610e-01</td>\n",
       "      <td>5.174635e-01</td>\n",
       "      <td>2.329755e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.395472e-15</td>\n",
       "      <td>6.243795e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>1.665770e-06</td>\n",
       "      <td>9.999982e-01</td>\n",
       "      <td>1.231557e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>2.495610e-01</td>\n",
       "      <td>5.174635e-01</td>\n",
       "      <td>2.329755e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>1.710007e-07</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>7.988980e-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0             1             2\n",
       "0    1.250444e-05  9.999866e-01  7.751040e-07\n",
       "1    6.182140e-08  6.756152e-08  9.999999e-01\n",
       "2    9.999980e-01  1.788405e-06  1.889782e-07\n",
       "3    4.463270e-05  9.999526e-01  2.906656e-06\n",
       "4    8.719623e-09  6.788134e-08  9.999999e-01\n",
       "..            ...           ...           ...\n",
       "197  2.495610e-01  5.174635e-01  2.329755e-01\n",
       "198  1.000000e+00  1.395472e-15  6.243795e-16\n",
       "199  1.665770e-06  9.999982e-01  1.231557e-07\n",
       "200  2.495610e-01  5.174635e-01  2.329755e-01\n",
       "201  1.710007e-07  9.999999e-01  7.988980e-09\n",
       "\n",
       "[202 rows x 3 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba6.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba6.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat6.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/6p003ppST.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 470 samples, validate on 202 samples\n",
      "Epoch 1/100\n",
      "470/470 [==============================] - 0s 209us/step - loss: 0.9105 - accuracy: 0.8064 - val_loss: 0.5378 - val_accuracy: 0.9554\n",
      "Epoch 2/100\n",
      "470/470 [==============================] - 0s 210us/step - loss: 1.0259 - accuracy: 0.8128 - val_loss: 0.6205 - val_accuracy: 0.9604\n",
      "Epoch 3/100\n",
      "470/470 [==============================] - 0s 162us/step - loss: 1.0646 - accuracy: 0.7340 - val_loss: 0.5300 - val_accuracy: 0.9653\n",
      "Epoch 4/100\n",
      "470/470 [==============================] - 0s 155us/step - loss: 0.9789 - accuracy: 0.7745 - val_loss: 0.4759 - val_accuracy: 0.9653\n",
      "Epoch 5/100\n",
      "470/470 [==============================] - 0s 159us/step - loss: 1.0393 - accuracy: 0.8021 - val_loss: 0.7389 - val_accuracy: 0.9653\n",
      "Epoch 6/100\n",
      "470/470 [==============================] - 0s 137us/step - loss: 0.9923 - accuracy: 0.8064 - val_loss: 0.5495 - val_accuracy: 0.9604\n",
      "Epoch 7/100\n",
      "470/470 [==============================] - 0s 128us/step - loss: 0.9844 - accuracy: 0.7574 - val_loss: 0.6029 - val_accuracy: 0.9554\n",
      "Epoch 8/100\n",
      "470/470 [==============================] - 0s 123us/step - loss: 0.9393 - accuracy: 0.7660 - val_loss: 0.5569 - val_accuracy: 0.9604\n",
      "Epoch 9/100\n",
      "470/470 [==============================] - 0s 124us/step - loss: 0.8433 - accuracy: 0.8085 - val_loss: 0.4952 - val_accuracy: 0.9604\n",
      "Epoch 10/100\n",
      "470/470 [==============================] - 0s 124us/step - loss: 1.0652 - accuracy: 0.7979 - val_loss: 0.4771 - val_accuracy: 0.9604\n",
      "Epoch 11/100\n",
      "470/470 [==============================] - 0s 134us/step - loss: 0.9613 - accuracy: 0.7809 - val_loss: 0.5687 - val_accuracy: 0.9604\n",
      "Epoch 12/100\n",
      "470/470 [==============================] - 0s 136us/step - loss: 1.0483 - accuracy: 0.7660 - val_loss: 0.4822 - val_accuracy: 0.9604\n",
      "Epoch 13/100\n",
      "470/470 [==============================] - 0s 123us/step - loss: 0.8129 - accuracy: 0.8043 - val_loss: 0.5213 - val_accuracy: 0.9604\n",
      "Epoch 14/100\n",
      "470/470 [==============================] - 0s 125us/step - loss: 0.9314 - accuracy: 0.7872 - val_loss: 0.4943 - val_accuracy: 0.9604\n",
      "Epoch 15/100\n",
      "470/470 [==============================] - 0s 141us/step - loss: 1.0051 - accuracy: 0.7574 - val_loss: 0.5391 - val_accuracy: 0.9604\n",
      "Epoch 16/100\n",
      "470/470 [==============================] - 0s 135us/step - loss: 0.8455 - accuracy: 0.8000 - val_loss: 0.4290 - val_accuracy: 0.9901\n",
      "Epoch 17/100\n",
      "470/470 [==============================] - 0s 134us/step - loss: 1.0116 - accuracy: 0.7681 - val_loss: 0.5327 - val_accuracy: 0.9604\n",
      "Epoch 18/100\n",
      "470/470 [==============================] - 0s 128us/step - loss: 0.8497 - accuracy: 0.7894 - val_loss: 0.6057 - val_accuracy: 0.9604\n",
      "Epoch 19/100\n",
      "470/470 [==============================] - 0s 123us/step - loss: 0.9266 - accuracy: 0.7851 - val_loss: 0.4686 - val_accuracy: 0.9653\n",
      "Epoch 20/100\n",
      "470/470 [==============================] - 0s 133us/step - loss: 1.0597 - accuracy: 0.7638 - val_loss: 0.4888 - val_accuracy: 0.9604\n",
      "Epoch 21/100\n",
      "470/470 [==============================] - 0s 135us/step - loss: 0.8629 - accuracy: 0.7915 - val_loss: 0.4634 - val_accuracy: 0.9604\n",
      "Epoch 22/100\n",
      "470/470 [==============================] - 0s 138us/step - loss: 0.9627 - accuracy: 0.7787 - val_loss: 0.4952 - val_accuracy: 0.9604\n",
      "Epoch 23/100\n",
      "470/470 [==============================] - 0s 137us/step - loss: 0.8847 - accuracy: 0.7723 - val_loss: 0.4682 - val_accuracy: 0.9653\n",
      "Epoch 24/100\n",
      "470/470 [==============================] - 0s 186us/step - loss: 0.8165 - accuracy: 0.8106 - val_loss: 0.4488 - val_accuracy: 0.9604\n",
      "Epoch 25/100\n",
      "470/470 [==============================] - 0s 187us/step - loss: 0.7322 - accuracy: 0.8149 - val_loss: 0.4709 - val_accuracy: 0.9604\n",
      "Epoch 26/100\n",
      "470/470 [==============================] - 0s 204us/step - loss: 0.9118 - accuracy: 0.7872 - val_loss: 0.4417 - val_accuracy: 0.9653\n",
      "Epoch 27/100\n",
      "470/470 [==============================] - 0s 148us/step - loss: 0.8742 - accuracy: 0.7830 - val_loss: 0.4608 - val_accuracy: 0.9901\n",
      "Epoch 28/100\n",
      "470/470 [==============================] - 0s 126us/step - loss: 0.9354 - accuracy: 0.7915 - val_loss: 0.4638 - val_accuracy: 0.9604\n",
      "Epoch 29/100\n",
      "470/470 [==============================] - 0s 125us/step - loss: 0.8825 - accuracy: 0.8149 - val_loss: 0.4763 - val_accuracy: 0.9604\n",
      "Epoch 30/100\n",
      "470/470 [==============================] - 0s 129us/step - loss: 0.9065 - accuracy: 0.7766 - val_loss: 0.4583 - val_accuracy: 0.9604\n",
      "Epoch 31/100\n",
      "470/470 [==============================] - 0s 137us/step - loss: 0.9222 - accuracy: 0.7340 - val_loss: 0.4389 - val_accuracy: 0.9604\n",
      "Epoch 32/100\n",
      "470/470 [==============================] - 0s 127us/step - loss: 0.8095 - accuracy: 0.7979 - val_loss: 0.5021 - val_accuracy: 0.9604\n",
      "Epoch 33/100\n",
      "470/470 [==============================] - 0s 126us/step - loss: 0.8439 - accuracy: 0.8340 - val_loss: 0.4099 - val_accuracy: 0.9950\n",
      "Epoch 34/100\n",
      "470/470 [==============================] - 0s 122us/step - loss: 0.7576 - accuracy: 0.7957 - val_loss: 0.4136 - val_accuracy: 0.9901\n",
      "Epoch 35/100\n",
      "470/470 [==============================] - 0s 122us/step - loss: 0.7571 - accuracy: 0.8213 - val_loss: 0.4023 - val_accuracy: 0.9901\n",
      "Epoch 36/100\n",
      "470/470 [==============================] - 0s 126us/step - loss: 0.7845 - accuracy: 0.8043 - val_loss: 0.5226 - val_accuracy: 0.9653\n",
      "Epoch 37/100\n",
      "470/470 [==============================] - 0s 139us/step - loss: 0.7919 - accuracy: 0.8170 - val_loss: 0.4048 - val_accuracy: 0.9950\n",
      "Epoch 38/100\n",
      "470/470 [==============================] - 0s 141us/step - loss: 0.7954 - accuracy: 0.7894 - val_loss: 0.4156 - val_accuracy: 0.9950\n",
      "Epoch 39/100\n",
      "470/470 [==============================] - 0s 144us/step - loss: 0.9073 - accuracy: 0.8021 - val_loss: 0.4079 - val_accuracy: 0.9950\n",
      "Epoch 40/100\n",
      "470/470 [==============================] - 0s 129us/step - loss: 0.8707 - accuracy: 0.8000 - val_loss: 0.4030 - val_accuracy: 0.9950\n",
      "Epoch 41/100\n",
      "470/470 [==============================] - 0s 161us/step - loss: 0.8911 - accuracy: 0.8085 - val_loss: 0.4249 - val_accuracy: 0.9950\n",
      "Epoch 42/100\n",
      "470/470 [==============================] - 0s 149us/step - loss: 0.7918 - accuracy: 0.8000 - val_loss: 0.4011 - val_accuracy: 0.9950\n",
      "Epoch 43/100\n",
      "470/470 [==============================] - 0s 140us/step - loss: 0.7200 - accuracy: 0.8106 - val_loss: 0.4158 - val_accuracy: 0.9901\n",
      "Epoch 44/100\n",
      "470/470 [==============================] - 0s 142us/step - loss: 0.8038 - accuracy: 0.7915 - val_loss: 0.3916 - val_accuracy: 0.9950\n",
      "Epoch 45/100\n",
      "470/470 [==============================] - 0s 126us/step - loss: 0.7613 - accuracy: 0.8170 - val_loss: 0.3926 - val_accuracy: 0.9950\n",
      "Epoch 46/100\n",
      "470/470 [==============================] - 0s 144us/step - loss: 0.8676 - accuracy: 0.8213 - val_loss: 0.3793 - val_accuracy: 0.9950\n",
      "Epoch 47/100\n",
      "470/470 [==============================] - 0s 145us/step - loss: 0.8888 - accuracy: 0.8000 - val_loss: 0.4166 - val_accuracy: 0.9950\n",
      "Epoch 48/100\n",
      "470/470 [==============================] - 0s 149us/step - loss: 0.8125 - accuracy: 0.8426 - val_loss: 0.4009 - val_accuracy: 0.9950\n",
      "Epoch 49/100\n",
      "470/470 [==============================] - 0s 128us/step - loss: 0.7594 - accuracy: 0.8043 - val_loss: 0.3982 - val_accuracy: 0.9950\n",
      "Epoch 50/100\n",
      "470/470 [==============================] - 0s 146us/step - loss: 0.7927 - accuracy: 0.8191 - val_loss: 0.4113 - val_accuracy: 0.9901\n",
      "Epoch 51/100\n",
      "470/470 [==============================] - 0s 133us/step - loss: 0.8001 - accuracy: 0.8106 - val_loss: 0.4191 - val_accuracy: 0.9950\n",
      "Epoch 52/100\n",
      "470/470 [==============================] - 0s 131us/step - loss: 0.7635 - accuracy: 0.7957 - val_loss: 0.4197 - val_accuracy: 0.9653\n",
      "Epoch 53/100\n",
      "470/470 [==============================] - 0s 150us/step - loss: 0.8032 - accuracy: 0.7872 - val_loss: 0.4135 - val_accuracy: 0.9950\n",
      "Epoch 54/100\n",
      "470/470 [==============================] - 0s 178us/step - loss: 0.7263 - accuracy: 0.8064 - val_loss: 0.4066 - val_accuracy: 0.9950\n",
      "Epoch 55/100\n",
      "470/470 [==============================] - 0s 195us/step - loss: 0.6879 - accuracy: 0.7894 - val_loss: 0.3936 - val_accuracy: 0.9950\n",
      "Epoch 56/100\n",
      "470/470 [==============================] - 0s 189us/step - loss: 0.7410 - accuracy: 0.8149 - val_loss: 0.3849 - val_accuracy: 0.9950\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "470/470 [==============================] - 0s 207us/step - loss: 0.8362 - accuracy: 0.7979 - val_loss: 0.3841 - val_accuracy: 0.9950\n",
      "Epoch 58/100\n",
      "470/470 [==============================] - 0s 141us/step - loss: 0.7849 - accuracy: 0.7936 - val_loss: 0.4090 - val_accuracy: 0.9950\n",
      "Epoch 59/100\n",
      "470/470 [==============================] - 0s 132us/step - loss: 0.7447 - accuracy: 0.8085 - val_loss: 0.3857 - val_accuracy: 0.9950\n",
      "Epoch 60/100\n",
      "470/470 [==============================] - 0s 121us/step - loss: 0.8468 - accuracy: 0.7681 - val_loss: 0.4218 - val_accuracy: 0.9901\n",
      "Epoch 61/100\n",
      "470/470 [==============================] - 0s 126us/step - loss: 0.7680 - accuracy: 0.7979 - val_loss: 0.4205 - val_accuracy: 0.9901\n",
      "Epoch 62/100\n",
      "470/470 [==============================] - 0s 122us/step - loss: 0.7581 - accuracy: 0.8234 - val_loss: 0.4109 - val_accuracy: 0.9901\n",
      "Epoch 63/100\n",
      "470/470 [==============================] - 0s 121us/step - loss: 0.7968 - accuracy: 0.7660 - val_loss: 0.3852 - val_accuracy: 0.9950\n",
      "Epoch 64/100\n",
      "470/470 [==============================] - 0s 123us/step - loss: 0.8068 - accuracy: 0.7915 - val_loss: 0.3993 - val_accuracy: 0.9950\n",
      "Epoch 65/100\n",
      "470/470 [==============================] - 0s 131us/step - loss: 0.9281 - accuracy: 0.7596 - val_loss: 0.4118 - val_accuracy: 0.9950\n",
      "Epoch 66/100\n",
      "470/470 [==============================] - 0s 194us/step - loss: 0.7923 - accuracy: 0.7894 - val_loss: 0.4106 - val_accuracy: 0.9950\n",
      "Epoch 67/100\n",
      "470/470 [==============================] - 0s 344us/step - loss: 0.7845 - accuracy: 0.7936 - val_loss: 0.3940 - val_accuracy: 0.9950\n",
      "Epoch 68/100\n",
      "470/470 [==============================] - 0s 290us/step - loss: 0.7429 - accuracy: 0.8085 - val_loss: 0.4109 - val_accuracy: 0.9950\n",
      "Epoch 69/100\n",
      "470/470 [==============================] - 0s 148us/step - loss: 0.7571 - accuracy: 0.8149 - val_loss: 0.4131 - val_accuracy: 0.9901\n",
      "Epoch 70/100\n",
      "470/470 [==============================] - 0s 145us/step - loss: 0.8326 - accuracy: 0.8021 - val_loss: 0.4226 - val_accuracy: 0.9901\n",
      "Epoch 71/100\n",
      "470/470 [==============================] - 0s 132us/step - loss: 0.8079 - accuracy: 0.8021 - val_loss: 0.4032 - val_accuracy: 0.9950\n",
      "Epoch 72/100\n",
      "470/470 [==============================] - 0s 134us/step - loss: 0.6980 - accuracy: 0.8085 - val_loss: 0.3932 - val_accuracy: 0.9950\n",
      "Epoch 73/100\n",
      "470/470 [==============================] - 0s 129us/step - loss: 0.7786 - accuracy: 0.7936 - val_loss: 0.3842 - val_accuracy: 0.9950\n",
      "Epoch 74/100\n",
      "470/470 [==============================] - 0s 125us/step - loss: 0.6936 - accuracy: 0.8128 - val_loss: 0.4034 - val_accuracy: 0.9950\n",
      "Epoch 75/100\n",
      "470/470 [==============================] - 0s 130us/step - loss: 0.8520 - accuracy: 0.7936 - val_loss: 0.4306 - val_accuracy: 0.9901\n",
      "Epoch 76/100\n",
      "470/470 [==============================] - 0s 131us/step - loss: 0.7643 - accuracy: 0.8000 - val_loss: 0.3883 - val_accuracy: 0.9950\n",
      "Epoch 77/100\n",
      "470/470 [==============================] - 0s 122us/step - loss: 0.7075 - accuracy: 0.7979 - val_loss: 0.3918 - val_accuracy: 0.9950\n",
      "Epoch 78/100\n",
      "470/470 [==============================] - 0s 132us/step - loss: 0.7055 - accuracy: 0.8255 - val_loss: 0.4000 - val_accuracy: 0.9950\n",
      "Epoch 79/100\n",
      "470/470 [==============================] - 0s 144us/step - loss: 0.6665 - accuracy: 0.8255 - val_loss: 0.3669 - val_accuracy: 0.9950\n",
      "Epoch 80/100\n",
      "470/470 [==============================] - 0s 147us/step - loss: 0.8631 - accuracy: 0.7766 - val_loss: 0.4096 - val_accuracy: 0.9901\n",
      "Epoch 81/100\n",
      "470/470 [==============================] - 0s 141us/step - loss: 0.7663 - accuracy: 0.7915 - val_loss: 0.4276 - val_accuracy: 0.9901\n",
      "Epoch 82/100\n",
      "470/470 [==============================] - 0s 130us/step - loss: 0.7395 - accuracy: 0.7936 - val_loss: 0.4234 - val_accuracy: 0.9950\n",
      "Epoch 83/100\n",
      "470/470 [==============================] - 0s 122us/step - loss: 0.7459 - accuracy: 0.7957 - val_loss: 0.4254 - val_accuracy: 0.9901\n",
      "Epoch 84/100\n",
      "470/470 [==============================] - 0s 133us/step - loss: 0.6857 - accuracy: 0.7830 - val_loss: 0.3815 - val_accuracy: 0.9950\n",
      "Epoch 85/100\n",
      "470/470 [==============================] - 0s 125us/step - loss: 0.8377 - accuracy: 0.7894 - val_loss: 0.3876 - val_accuracy: 0.9950\n",
      "Epoch 86/100\n",
      "470/470 [==============================] - 0s 126us/step - loss: 0.8268 - accuracy: 0.7894 - val_loss: 0.4159 - val_accuracy: 0.9901\n",
      "Epoch 87/100\n",
      "470/470 [==============================] - 0s 165us/step - loss: 0.8198 - accuracy: 0.7809 - val_loss: 0.4017 - val_accuracy: 0.9950\n",
      "Epoch 88/100\n",
      "470/470 [==============================] - 0s 134us/step - loss: 0.8117 - accuracy: 0.7830 - val_loss: 0.3648 - val_accuracy: 0.9950\n",
      "Epoch 89/100\n",
      "470/470 [==============================] - 0s 121us/step - loss: 0.8386 - accuracy: 0.8085 - val_loss: 0.4001 - val_accuracy: 0.9950\n",
      "Epoch 90/100\n",
      "470/470 [==============================] - 0s 137us/step - loss: 0.7846 - accuracy: 0.7723 - val_loss: 0.4858 - val_accuracy: 0.9653\n",
      "Epoch 91/100\n",
      "470/470 [==============================] - 0s 131us/step - loss: 0.6483 - accuracy: 0.8106 - val_loss: 0.3786 - val_accuracy: 0.9950\n",
      "Epoch 92/100\n",
      "470/470 [==============================] - 0s 125us/step - loss: 0.7557 - accuracy: 0.8000 - val_loss: 0.4150 - val_accuracy: 0.9950\n",
      "Epoch 93/100\n",
      "470/470 [==============================] - 0s 127us/step - loss: 0.7264 - accuracy: 0.7936 - val_loss: 0.4000 - val_accuracy: 0.9950\n",
      "Epoch 94/100\n",
      "470/470 [==============================] - 0s 131us/step - loss: 0.9295 - accuracy: 0.7787 - val_loss: 0.3962 - val_accuracy: 0.9950\n",
      "Epoch 95/100\n",
      "470/470 [==============================] - 0s 125us/step - loss: 0.6694 - accuracy: 0.7830 - val_loss: 0.3835 - val_accuracy: 0.9950\n",
      "Epoch 96/100\n",
      "470/470 [==============================] - 0s 124us/step - loss: 0.6329 - accuracy: 0.8149 - val_loss: 0.3551 - val_accuracy: 0.9950\n",
      "Epoch 97/100\n",
      "470/470 [==============================] - 0s 130us/step - loss: 0.7615 - accuracy: 0.8021 - val_loss: 0.3681 - val_accuracy: 0.9950\n",
      "Epoch 98/100\n",
      "470/470 [==============================] - 0s 124us/step - loss: 0.6959 - accuracy: 0.7979 - val_loss: 0.4089 - val_accuracy: 0.9950\n",
      "Epoch 99/100\n",
      "470/470 [==============================] - 0s 123us/step - loss: 0.7886 - accuracy: 0.7936 - val_loss: 0.3754 - val_accuracy: 0.9950\n",
      "Epoch 100/100\n",
      "470/470 [==============================] - 0s 135us/step - loss: 0.6826 - accuracy: 0.8021 - val_loss: 0.3773 - val_accuracy: 0.9950\n"
     ]
    }
   ],
   "source": [
    "hist1_over6 = model1_over6.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 79.52%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over6.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba6 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_regularizor_dropout_2.xlsx\",\n",
    "                        sheet_name=1,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.790400e-08</td>\n",
       "      <td>4.141849e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS386</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.739934e-04</td>\n",
       "      <td>9.994259e-01</td>\n",
       "      <td>6.773014e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5.286934e-09</td>\n",
       "      <td>1.269109e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS178</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.494936e-12</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.537080e-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS237</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.701098e-02</td>\n",
       "      <td>9.399204e-01</td>\n",
       "      <td>3.068583e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.999607e-01</td>\n",
       "      <td>3.367024e-05</td>\n",
       "      <td>5.776848e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS112</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.275442e-08</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>3.739556e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS064</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.168245e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.603962e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>BCH-SA-04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.026408e-15</td>\n",
       "      <td>1.630406e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.120633e-08</td>\n",
       "      <td>1.998346e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1982 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       phage     strain  phenotype  prediction             0  \\\n",
       "0     p002ykpresabsSTCC_qual     NRS209          2           2  1.790400e-08   \n",
       "1     p002ykpresabsSTCC_qual     NRS386          1           1  5.739934e-04   \n",
       "2     p002ykpresabsSTCC_qual     NRS148          2           2  5.286934e-09   \n",
       "3     p002ykpresabsSTCC_qual     NRS178          0           1  6.494936e-12   \n",
       "4     p002ykpresabsSTCC_qual     NRS237          0           1  5.701098e-02   \n",
       "...                      ...        ...        ...         ...           ...   \n",
       "1977     pyopresabsSTCC_qual     NRS272          0           0  9.999607e-01   \n",
       "1978     pyopresabsSTCC_qual     NRS112          1           1  8.275442e-08   \n",
       "1979     pyopresabsSTCC_qual     NRS064          1           1  2.168245e-08   \n",
       "1980     pyopresabsSTCC_qual  BCH-SA-04          0           0  1.000000e+00   \n",
       "1981     pyopresabsSTCC_qual     NRS148          2           2  2.120633e-08   \n",
       "\n",
       "                 1             2  \n",
       "0     4.141849e-08  1.000000e+00  \n",
       "1     9.994259e-01  6.773014e-08  \n",
       "2     1.269109e-08  1.000000e+00  \n",
       "3     1.000000e+00  2.537080e-25  \n",
       "4     9.399204e-01  3.068583e-03  \n",
       "...            ...           ...  \n",
       "1977  3.367024e-05  5.776848e-06  \n",
       "1978  9.999999e-01  3.739556e-09  \n",
       "1979  1.000000e+00  9.603962e-09  \n",
       "1980  1.026408e-15  1.630406e-14  \n",
       "1981  1.998346e-08  1.000000e+00  \n",
       "\n",
       "[1982 rows x 7 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.25044390e-05, 9.99986650e-01, 7.75104000e-07],\n",
       "       [6.18213960e-08, 6.75615150e-08, 9.99999900e-01],\n",
       "       [9.99998000e-01, 1.78840510e-06, 1.88978180e-07],\n",
       "       [4.46327000e-05, 9.99952550e-01, 2.90665600e-06],\n",
       "       [8.71962300e-09, 6.78813400e-08, 9.99999900e-01],\n",
       "       [6.18213960e-08, 6.75615150e-08, 9.99999900e-01],\n",
       "       [1.71000660e-07, 9.99999900e-01, 7.98898000e-09],\n",
       "       [3.39365070e-05, 9.99965900e-01, 8.48425600e-08],\n",
       "       [1.10746770e-06, 9.99998800e-01, 7.54087700e-08],\n",
       "       [1.00000000e+00, 5.10242600e-09, 3.64943900e-10],\n",
       "       [6.18213960e-08, 6.75615150e-08, 9.99999900e-01],\n",
       "       [2.27158640e-07, 9.99999760e-01, 1.55337300e-09],\n",
       "       [6.18213960e-08, 6.75615150e-08, 9.99999900e-01],\n",
       "       [3.39365070e-05, 9.99965900e-01, 8.48425600e-08],\n",
       "       [1.00000000e+00, 9.29824900e-11, 5.82753640e-11],\n",
       "       [1.00000000e+00, 8.23512540e-10, 8.64572160e-11],\n",
       "       [9.99548260e-01, 4.51167580e-04, 5.44053650e-07],\n",
       "       [6.18213960e-08, 6.75615150e-08, 9.99999900e-01],\n",
       "       [4.46671100e-08, 1.00000000e+00, 1.59192810e-09],\n",
       "       [2.37014760e-07, 9.99999760e-01, 1.18265320e-08],\n",
       "       [1.00000000e+00, 3.74329550e-13, 6.39678740e-13],\n",
       "       [1.00000000e+00, 6.66772300e-14, 9.57576900e-14],\n",
       "       [4.10000500e-04, 1.05611780e-03, 9.98533840e-01],\n",
       "       [1.00000000e+00, 3.57079660e-08, 9.23816750e-10],\n",
       "       [8.71962300e-09, 6.78813400e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 1.73634750e-09, 1.75198970e-09],\n",
       "       [8.71962300e-09, 6.78813400e-08, 9.99999900e-01],\n",
       "       [9.89616900e-01, 1.03771590e-02, 6.03189000e-06],\n",
       "       [1.00000000e+00, 1.84622950e-12, 2.61739300e-12],\n",
       "       [9.99605950e-01, 3.60491300e-04, 3.36316700e-05],\n",
       "       [1.10746770e-06, 9.99998800e-01, 7.54087700e-08],\n",
       "       [1.00000000e+00, 3.43556360e-14, 4.38244300e-14],\n",
       "       [6.18213960e-08, 6.75615150e-08, 9.99999900e-01],\n",
       "       [4.10000500e-04, 1.05611780e-03, 9.98533840e-01],\n",
       "       [5.18350870e-09, 8.15065600e-08, 9.99999900e-01],\n",
       "       [5.18350870e-09, 8.15065600e-08, 9.99999900e-01],\n",
       "       [1.71000660e-07, 9.99999900e-01, 7.98898000e-09],\n",
       "       [1.00000000e+00, 8.19772900e-11, 1.14823304e-10],\n",
       "       [8.71962300e-09, 6.78813400e-08, 9.99999900e-01],\n",
       "       [6.18213960e-08, 6.75615150e-08, 9.99999900e-01],\n",
       "       [6.18213960e-08, 6.75615150e-08, 9.99999900e-01],\n",
       "       [2.49560970e-01, 5.17463500e-01, 2.32975500e-01],\n",
       "       [9.99999640e-01, 2.19400010e-07, 7.87252360e-08],\n",
       "       [1.62635820e-05, 9.99982500e-01, 1.29842590e-06],\n",
       "       [8.71962300e-09, 6.78813400e-08, 9.99999900e-01],\n",
       "       [6.18213960e-08, 6.75615150e-08, 9.99999900e-01],\n",
       "       [6.18213960e-08, 6.75615150e-08, 9.99999900e-01],\n",
       "       [4.10000500e-04, 1.05611780e-03, 9.98533840e-01],\n",
       "       [1.66576960e-06, 9.99998200e-01, 1.23155560e-07],\n",
       "       [2.49560970e-01, 5.17463500e-01, 2.32975500e-01],\n",
       "       [9.97355700e-01, 2.64421430e-03, 1.26170700e-07],\n",
       "       [4.46327000e-05, 9.99952550e-01, 2.90665600e-06],\n",
       "       [5.18350870e-09, 8.15065600e-08, 9.99999900e-01],\n",
       "       [3.39365070e-05, 9.99965900e-01, 8.48425600e-08],\n",
       "       [2.49560970e-01, 5.17463500e-01, 2.32975500e-01],\n",
       "       [5.18350870e-09, 8.15065600e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 7.38076430e-10, 1.31447350e-10],\n",
       "       [9.99999760e-01, 2.68619300e-07, 2.84973070e-10],\n",
       "       [1.00000000e+00, 8.32634600e-19, 7.40707800e-18],\n",
       "       [1.66576960e-06, 9.99998200e-01, 1.23155560e-07],\n",
       "       [4.33957730e-01, 5.65974950e-01, 6.73263350e-05],\n",
       "       [4.27955560e-04, 9.99500900e-01, 7.10742800e-05],\n",
       "       [1.12863340e-06, 9.99998800e-01, 6.58914840e-08],\n",
       "       [1.10746770e-06, 9.99998800e-01, 7.54087700e-08],\n",
       "       [6.18213960e-08, 6.75615150e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 1.08258900e-11, 1.38170810e-11],\n",
       "       [4.46671100e-08, 1.00000000e+00, 1.59192810e-09],\n",
       "       [1.00859320e-07, 9.99999900e-01, 1.68556530e-10],\n",
       "       [5.18350870e-09, 8.15065600e-08, 9.99999900e-01],\n",
       "       [5.18350870e-09, 8.15065600e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 9.32254700e-10, 8.06589100e-12],\n",
       "       [6.18213960e-08, 6.75615150e-08, 9.99999900e-01],\n",
       "       [5.18350870e-09, 8.15065600e-08, 9.99999900e-01],\n",
       "       [5.18350870e-09, 8.15065600e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 4.26514000e-09, 9.03785930e-10],\n",
       "       [2.49560970e-01, 5.17463500e-01, 2.32975500e-01],\n",
       "       [9.30720200e-01, 6.92642800e-02, 1.55759060e-05],\n",
       "       [1.00000000e+00, 9.38822900e-14, 1.19722810e-13],\n",
       "       [5.18350870e-09, 8.15065600e-08, 9.99999900e-01],\n",
       "       [6.18213960e-08, 6.75615150e-08, 9.99999900e-01],\n",
       "       [9.99999900e-01, 6.66906460e-08, 2.00117830e-09],\n",
       "       [5.18350870e-09, 8.15065600e-08, 9.99999900e-01],\n",
       "       [6.18213960e-08, 6.75615150e-08, 9.99999900e-01],\n",
       "       [6.18213960e-08, 6.75615150e-08, 9.99999900e-01],\n",
       "       [2.49560970e-01, 5.17463500e-01, 2.32975500e-01],\n",
       "       [1.00000000e+00, 1.90814860e-15, 2.31797620e-15],\n",
       "       [3.74910700e-08, 1.00000000e+00, 3.86275980e-10],\n",
       "       [1.80055620e-06, 9.99998200e-01, 4.47694650e-08],\n",
       "       [9.99996660e-01, 3.34790000e-06, 1.02510570e-08],\n",
       "       [8.71962300e-09, 6.78813400e-08, 9.99999900e-01],\n",
       "       [5.18350870e-09, 8.15065600e-08, 9.99999900e-01],\n",
       "       [5.18350870e-09, 8.15065600e-08, 9.99999900e-01],\n",
       "       [5.18350870e-09, 8.15065600e-08, 9.99999900e-01],\n",
       "       [3.74910700e-08, 1.00000000e+00, 3.86275980e-10],\n",
       "       [1.00000000e+00, 2.83132640e-14, 4.03560950e-14],\n",
       "       [4.10000500e-04, 1.05611780e-03, 9.98533840e-01],\n",
       "       [8.71962300e-09, 6.78813400e-08, 9.99999900e-01],\n",
       "       [9.99999760e-01, 2.50943660e-07, 4.20344500e-09],\n",
       "       [8.71962300e-09, 6.78813400e-08, 9.99999900e-01],\n",
       "       [1.80055620e-06, 9.99998200e-01, 4.47694650e-08],\n",
       "       [9.99996660e-01, 3.29181150e-06, 1.84401690e-08],\n",
       "       [1.00000000e+00, 4.27964200e-14, 8.13283560e-14],\n",
       "       [1.00000000e+00, 3.71476020e-13, 6.12839000e-13],\n",
       "       [5.18350870e-09, 8.15065600e-08, 9.99999900e-01],\n",
       "       [8.71962300e-09, 6.78813400e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 3.86566050e-08, 5.75277650e-09],\n",
       "       [4.10000500e-04, 1.05611780e-03, 9.98533840e-01],\n",
       "       [1.00000000e+00, 5.68548360e-09, 5.40705840e-09],\n",
       "       [5.18350870e-09, 8.15065600e-08, 9.99999900e-01],\n",
       "       [5.18350870e-09, 8.15065600e-08, 9.99999900e-01],\n",
       "       [9.99999900e-01, 1.05235780e-07, 1.28688130e-08],\n",
       "       [1.00000000e+00, 6.29047160e-13, 9.33835400e-13],\n",
       "       [1.00000000e+00, 9.31629400e-09, 5.87124070e-10],\n",
       "       [6.18213960e-08, 6.75615150e-08, 9.99999900e-01],\n",
       "       [4.46671100e-08, 1.00000000e+00, 1.59192810e-09],\n",
       "       [1.00000000e+00, 3.54258920e-12, 2.12543870e-16],\n",
       "       [3.39365070e-05, 9.99965900e-01, 8.48425600e-08],\n",
       "       [2.33647640e-08, 1.00000000e+00, 7.30716930e-10],\n",
       "       [6.18213960e-08, 6.75615150e-08, 9.99999900e-01],\n",
       "       [9.99999050e-01, 8.89122250e-07, 1.48146770e-07],\n",
       "       [5.18350870e-09, 8.15065600e-08, 9.99999900e-01],\n",
       "       [8.71962300e-09, 6.78813400e-08, 9.99999900e-01],\n",
       "       [3.39365070e-05, 9.99965900e-01, 8.48425600e-08],\n",
       "       [2.49560970e-01, 5.17463500e-01, 2.32975500e-01],\n",
       "       [1.00000000e+00, 1.99255910e-13, 3.11450100e-14],\n",
       "       [1.00000000e+00, 4.65841570e-11, 7.58420150e-12],\n",
       "       [6.18213960e-08, 6.75615150e-08, 9.99999900e-01],\n",
       "       [2.27158640e-07, 9.99999760e-01, 1.55337300e-09],\n",
       "       [1.00859320e-07, 9.99999900e-01, 1.68556530e-10],\n",
       "       [3.74910700e-08, 1.00000000e+00, 3.86275980e-10],\n",
       "       [1.00859320e-07, 9.99999900e-01, 1.68556530e-10],\n",
       "       [8.71962300e-09, 6.78813400e-08, 9.99999900e-01],\n",
       "       [2.49560970e-01, 5.17463500e-01, 2.32975500e-01],\n",
       "       [1.00000000e+00, 3.22165660e-14, 4.03221670e-14],\n",
       "       [5.18350870e-09, 8.15065600e-08, 9.99999900e-01],\n",
       "       [6.18213960e-08, 6.75615150e-08, 9.99999900e-01],\n",
       "       [1.16519080e-05, 9.99987600e-01, 7.65757500e-07],\n",
       "       [6.18213960e-08, 6.75615150e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 2.09795910e-11, 1.70487410e-11],\n",
       "       [2.49560970e-01, 5.17463500e-01, 2.32975500e-01],\n",
       "       [5.18350870e-09, 8.15065600e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 5.94838800e-13, 2.68973300e-13],\n",
       "       [1.00859320e-07, 9.99999900e-01, 1.68556530e-10],\n",
       "       [1.00000000e+00, 4.61809000e-12, 6.21370300e-12],\n",
       "       [2.33647640e-08, 1.00000000e+00, 7.30716930e-10],\n",
       "       [1.10746770e-06, 9.99998800e-01, 7.54087700e-08],\n",
       "       [2.49560970e-01, 5.17463500e-01, 2.32975500e-01],\n",
       "       [9.59308500e-01, 4.06890180e-02, 2.49024100e-06],\n",
       "       [2.37014760e-07, 9.99999760e-01, 1.18265320e-08],\n",
       "       [5.18350870e-09, 8.15065600e-08, 9.99999900e-01],\n",
       "       [9.99995350e-01, 4.41824480e-06, 2.52669880e-07],\n",
       "       [1.62635820e-05, 9.99982500e-01, 1.29842590e-06],\n",
       "       [1.00000000e+00, 4.73073660e-15, 7.90908600e-15],\n",
       "       [3.39365070e-05, 9.99965900e-01, 8.48425600e-08],\n",
       "       [2.33647640e-08, 1.00000000e+00, 7.30716930e-10],\n",
       "       [8.71962300e-09, 6.78813400e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 4.27746800e-08, 2.94720000e-09],\n",
       "       [8.71962300e-09, 6.78813400e-08, 9.99999900e-01],\n",
       "       [5.18350870e-09, 8.15065600e-08, 9.99999900e-01],\n",
       "       [9.99999900e-01, 6.03795100e-08, 3.30114960e-08],\n",
       "       [5.18350870e-09, 8.15065600e-08, 9.99999900e-01],\n",
       "       [3.74910700e-08, 1.00000000e+00, 3.86275980e-10],\n",
       "       [1.00000000e+00, 4.98667850e-14, 2.87848300e-13],\n",
       "       [8.71962300e-09, 6.78813400e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 4.08142440e-12, 5.91499250e-12],\n",
       "       [6.18213960e-08, 6.75615150e-08, 9.99999900e-01],\n",
       "       [3.39365070e-05, 9.99965900e-01, 8.48425600e-08],\n",
       "       [8.71962300e-09, 6.78813400e-08, 9.99999900e-01],\n",
       "       [1.71000660e-07, 9.99999900e-01, 7.98898000e-09],\n",
       "       [8.71962300e-09, 6.78813400e-08, 9.99999900e-01],\n",
       "       [1.71000660e-07, 9.99999900e-01, 7.98898000e-09],\n",
       "       [1.00000000e+00, 2.88332660e-15, 4.45776700e-15],\n",
       "       [6.18213960e-08, 6.75615150e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 2.03430500e-10, 4.07216550e-11],\n",
       "       [5.18350870e-09, 8.15065600e-08, 9.99999900e-01],\n",
       "       [5.18350870e-09, 8.15065600e-08, 9.99999900e-01],\n",
       "       [1.00859320e-07, 9.99999900e-01, 1.68556530e-10],\n",
       "       [9.99999900e-01, 1.24060260e-07, 1.40923060e-08],\n",
       "       [5.18350870e-09, 8.15065600e-08, 9.99999900e-01],\n",
       "       [5.18350870e-09, 8.15065600e-08, 9.99999900e-01],\n",
       "       [8.71962300e-09, 6.78813400e-08, 9.99999900e-01],\n",
       "       [9.99999050e-01, 9.17002300e-07, 1.57487620e-08],\n",
       "       [9.99997140e-01, 2.85360700e-06, 3.53833870e-08],\n",
       "       [2.37014760e-07, 9.99999760e-01, 1.18265320e-08],\n",
       "       [2.13368530e-05, 9.99977700e-01, 9.15315700e-07],\n",
       "       [1.00000000e+00, 1.00460830e-13, 4.25009720e-14],\n",
       "       [9.99999400e-01, 5.28531300e-07, 9.02384160e-08],\n",
       "       [1.00000000e+00, 7.01774960e-11, 2.15328920e-11],\n",
       "       [4.10000500e-04, 1.05611780e-03, 9.98533840e-01],\n",
       "       [5.18350870e-09, 8.15065600e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 2.32604020e-12, 3.26483740e-12],\n",
       "       [1.00000000e+00, 3.17569720e-11, 6.33031430e-12],\n",
       "       [1.00859320e-07, 9.99999900e-01, 1.68556530e-10],\n",
       "       [3.39365720e-05, 9.99965900e-01, 8.48427200e-08],\n",
       "       [1.00000000e+00, 2.14360900e-12, 3.00730190e-12],\n",
       "       [1.00000000e+00, 2.17569650e-20, 6.72040760e-20],\n",
       "       [6.18213960e-08, 6.75615150e-08, 9.99999900e-01],\n",
       "       [2.49560970e-01, 5.17463500e-01, 2.32975500e-01],\n",
       "       [1.00000000e+00, 1.39547230e-15, 6.24379540e-16],\n",
       "       [1.66576960e-06, 9.99998200e-01, 1.23155690e-07],\n",
       "       [2.49560970e-01, 5.17463500e-01, 2.32975500e-01],\n",
       "       [1.71000660e-07, 9.99999900e-01, 7.98898000e-09]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob6 = df_proba6[df_proba6['phage']=='p003ppresabsSTCC_qual'].iloc[:,-3:]\n",
    "y_prob6 = y_prob6.to_numpy()\n",
    "y_prob6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9974728752750409"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo6 = rocauc_ovo(y_test_over, y_prob6, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9974728752750409"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr6 = rocauc_ovr(y_test_over, y_prob6, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=789,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat7 = pd.DataFrame(X_test_over[:,0])\n",
    "dat7['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS260</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS205</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS064</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>GA53649</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>NRS210</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>NRS162</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0  test\n",
       "0     NRS260     0\n",
       "1     NRS148     2\n",
       "2     NRS205     1\n",
       "3     NRS064     1\n",
       "4     NRS209     2\n",
       "..       ...   ...\n",
       "197   NRS255     2\n",
       "198  GA53649     0\n",
       "199   NRS209     2\n",
       "200   NRS210     0\n",
       "201   NRS162     0\n",
       "\n",
       "[202 rows x 2 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over7 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],), activity_regularizer=l1(0.001)),\n",
    "    Dense(3, activation='softmax'),\n",
    "    Dropout(0.2, ),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over7.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 470 samples, validate on 202 samples\n",
      "Epoch 1/100\n",
      "470/470 [==============================] - 0s 657us/step - loss: 6.3820 - accuracy: 0.4234 - val_loss: 3.3629 - val_accuracy: 0.5842\n",
      "Epoch 2/100\n",
      "470/470 [==============================] - 0s 212us/step - loss: 4.5751 - accuracy: 0.5021 - val_loss: 2.2508 - val_accuracy: 0.5594\n",
      "Epoch 3/100\n",
      "470/470 [==============================] - 0s 264us/step - loss: 3.8921 - accuracy: 0.5553 - val_loss: 1.6998 - val_accuracy: 0.5297\n",
      "Epoch 4/100\n",
      "470/470 [==============================] - 0s 197us/step - loss: 4.3578 - accuracy: 0.4787 - val_loss: 1.3396 - val_accuracy: 0.6683\n",
      "Epoch 5/100\n",
      "470/470 [==============================] - 0s 174us/step - loss: 4.4661 - accuracy: 0.4702 - val_loss: 1.1898 - val_accuracy: 0.6089\n",
      "Epoch 6/100\n",
      "470/470 [==============================] - 0s 215us/step - loss: 4.0276 - accuracy: 0.5106 - val_loss: 1.0072 - val_accuracy: 0.6535\n",
      "Epoch 7/100\n",
      "470/470 [==============================] - 0s 229us/step - loss: 3.8183 - accuracy: 0.5596 - val_loss: 0.9114 - val_accuracy: 0.7030\n",
      "Epoch 8/100\n",
      "470/470 [==============================] - 0s 242us/step - loss: 3.2589 - accuracy: 0.5809 - val_loss: 0.8583 - val_accuracy: 0.6040\n",
      "Epoch 9/100\n",
      "470/470 [==============================] - 0s 178us/step - loss: 3.6117 - accuracy: 0.4979 - val_loss: 0.8851 - val_accuracy: 0.6337\n",
      "Epoch 10/100\n",
      "470/470 [==============================] - 0s 328us/step - loss: 3.5690 - accuracy: 0.6149 - val_loss: 0.8900 - val_accuracy: 0.6881\n",
      "Epoch 11/100\n",
      "470/470 [==============================] - 0s 154us/step - loss: 3.3883 - accuracy: 0.6043 - val_loss: 0.8855 - val_accuracy: 0.7327\n",
      "Epoch 12/100\n",
      "470/470 [==============================] - 0s 253us/step - loss: 3.0523 - accuracy: 0.7000 - val_loss: 0.8760 - val_accuracy: 0.8366\n",
      "Epoch 13/100\n",
      "470/470 [==============================] - 0s 370us/step - loss: 3.5558 - accuracy: 0.6383 - val_loss: 0.8190 - val_accuracy: 0.8119\n",
      "Epoch 14/100\n",
      "470/470 [==============================] - 0s 281us/step - loss: 2.6416 - accuracy: 0.6723 - val_loss: 0.8045 - val_accuracy: 0.8416\n",
      "Epoch 15/100\n",
      "470/470 [==============================] - 0s 180us/step - loss: 2.9514 - accuracy: 0.6553 - val_loss: 0.8107 - val_accuracy: 0.7574\n",
      "Epoch 16/100\n",
      "470/470 [==============================] - 0s 141us/step - loss: 3.1781 - accuracy: 0.6553 - val_loss: 0.8126 - val_accuracy: 0.8366\n",
      "Epoch 17/100\n",
      "470/470 [==============================] - 0s 130us/step - loss: 2.7712 - accuracy: 0.7149 - val_loss: 0.7815 - val_accuracy: 0.8762\n",
      "Epoch 18/100\n",
      "470/470 [==============================] - 0s 422us/step - loss: 3.2455 - accuracy: 0.6426 - val_loss: 0.8329 - val_accuracy: 0.7772\n",
      "Epoch 19/100\n",
      "470/470 [==============================] - 0s 317us/step - loss: 3.0611 - accuracy: 0.7277 - val_loss: 0.7689 - val_accuracy: 0.8614\n",
      "Epoch 20/100\n",
      "470/470 [==============================] - 0s 268us/step - loss: 2.8678 - accuracy: 0.7106 - val_loss: 0.7907 - val_accuracy: 0.8663\n",
      "Epoch 21/100\n",
      "470/470 [==============================] - 0s 307us/step - loss: 3.2290 - accuracy: 0.6872 - val_loss: 0.8025 - val_accuracy: 0.8465\n",
      "Epoch 22/100\n",
      "470/470 [==============================] - 0s 321us/step - loss: 3.1579 - accuracy: 0.7149 - val_loss: 0.7970 - val_accuracy: 0.8960\n",
      "Epoch 23/100\n",
      "470/470 [==============================] - 0s 344us/step - loss: 2.5487 - accuracy: 0.7468 - val_loss: 0.8656 - val_accuracy: 0.8119\n",
      "Epoch 24/100\n",
      "470/470 [==============================] - 0s 263us/step - loss: 2.9466 - accuracy: 0.7106 - val_loss: 0.8162 - val_accuracy: 0.8515\n",
      "Epoch 25/100\n",
      "470/470 [==============================] - 0s 372us/step - loss: 2.2911 - accuracy: 0.7553 - val_loss: 0.7464 - val_accuracy: 0.8663\n",
      "Epoch 26/100\n",
      "470/470 [==============================] - 0s 423us/step - loss: 2.6697 - accuracy: 0.7340 - val_loss: 0.8292 - val_accuracy: 0.8812\n",
      "Epoch 27/100\n",
      "470/470 [==============================] - 0s 411us/step - loss: 2.6250 - accuracy: 0.7170 - val_loss: 0.7833 - val_accuracy: 0.8911\n",
      "Epoch 28/100\n",
      "470/470 [==============================] - 0s 380us/step - loss: 2.5685 - accuracy: 0.7489 - val_loss: 0.7300 - val_accuracy: 0.8713\n",
      "Epoch 29/100\n",
      "470/470 [==============================] - 0s 304us/step - loss: 2.5949 - accuracy: 0.7298 - val_loss: 0.8863 - val_accuracy: 0.8861\n",
      "Epoch 30/100\n",
      "470/470 [==============================] - 0s 358us/step - loss: 2.3859 - accuracy: 0.7426 - val_loss: 0.7888 - val_accuracy: 0.8614\n",
      "Epoch 31/100\n",
      "470/470 [==============================] - 0s 238us/step - loss: 2.3469 - accuracy: 0.7532 - val_loss: 0.8047 - val_accuracy: 0.8960\n",
      "Epoch 32/100\n",
      "470/470 [==============================] - 0s 169us/step - loss: 2.5755 - accuracy: 0.7298 - val_loss: 0.7485 - val_accuracy: 0.7822\n",
      "Epoch 33/100\n",
      "470/470 [==============================] - 0s 139us/step - loss: 2.1782 - accuracy: 0.7681 - val_loss: 0.7548 - val_accuracy: 0.9109\n",
      "Epoch 34/100\n",
      "470/470 [==============================] - 0s 210us/step - loss: 2.5164 - accuracy: 0.7319 - val_loss: 0.7761 - val_accuracy: 0.9010\n",
      "Epoch 35/100\n",
      "470/470 [==============================] - 0s 243us/step - loss: 2.4287 - accuracy: 0.7617 - val_loss: 0.9935 - val_accuracy: 0.8614\n",
      "Epoch 36/100\n",
      "470/470 [==============================] - 0s 239us/step - loss: 2.1383 - accuracy: 0.7723 - val_loss: 0.7926 - val_accuracy: 0.9010\n",
      "Epoch 37/100\n",
      "470/470 [==============================] - 0s 193us/step - loss: 2.3166 - accuracy: 0.7638 - val_loss: 0.7869 - val_accuracy: 0.9257\n",
      "Epoch 38/100\n",
      "470/470 [==============================] - 0s 191us/step - loss: 2.6722 - accuracy: 0.7340 - val_loss: 0.8149 - val_accuracy: 0.9208\n",
      "Epoch 39/100\n",
      "470/470 [==============================] - 0s 233us/step - loss: 2.4123 - accuracy: 0.7638 - val_loss: 0.8763 - val_accuracy: 0.9208\n",
      "Epoch 40/100\n",
      "470/470 [==============================] - 0s 212us/step - loss: 2.4224 - accuracy: 0.7511 - val_loss: 0.8535 - val_accuracy: 0.9356\n",
      "Epoch 41/100\n",
      "470/470 [==============================] - 0s 183us/step - loss: 2.2165 - accuracy: 0.7851 - val_loss: 0.8268 - val_accuracy: 0.9257\n",
      "Epoch 42/100\n",
      "470/470 [==============================] - 0s 135us/step - loss: 2.0396 - accuracy: 0.7830 - val_loss: 0.7524 - val_accuracy: 0.9307\n",
      "Epoch 43/100\n",
      "470/470 [==============================] - 0s 136us/step - loss: 2.4793 - accuracy: 0.7447 - val_loss: 0.7567 - val_accuracy: 0.9356\n",
      "Epoch 44/100\n",
      "470/470 [==============================] - 0s 157us/step - loss: 2.3166 - accuracy: 0.7702 - val_loss: 0.7205 - val_accuracy: 0.9356\n",
      "Epoch 45/100\n",
      "470/470 [==============================] - 0s 179us/step - loss: 2.1935 - accuracy: 0.7809 - val_loss: 0.7999 - val_accuracy: 0.9059\n",
      "Epoch 46/100\n",
      "470/470 [==============================] - 0s 142us/step - loss: 2.6840 - accuracy: 0.7085 - val_loss: 0.8972 - val_accuracy: 0.8960\n",
      "Epoch 47/100\n",
      "470/470 [==============================] - 0s 138us/step - loss: 2.3689 - accuracy: 0.7596 - val_loss: 0.8492 - val_accuracy: 0.9158\n",
      "Epoch 48/100\n",
      "470/470 [==============================] - 0s 147us/step - loss: 1.9869 - accuracy: 0.7915 - val_loss: 0.8910 - val_accuracy: 0.9257\n",
      "Epoch 49/100\n",
      "470/470 [==============================] - 0s 128us/step - loss: 2.0912 - accuracy: 0.7617 - val_loss: 0.7982 - val_accuracy: 0.9307\n",
      "Epoch 50/100\n",
      "470/470 [==============================] - 0s 177us/step - loss: 2.6092 - accuracy: 0.7383 - val_loss: 0.8988 - val_accuracy: 0.9109\n",
      "Epoch 51/100\n",
      "470/470 [==============================] - 0s 227us/step - loss: 2.0070 - accuracy: 0.7745 - val_loss: 0.8707 - val_accuracy: 0.9257\n",
      "Epoch 52/100\n",
      "470/470 [==============================] - 0s 143us/step - loss: 2.1788 - accuracy: 0.7617 - val_loss: 0.8167 - val_accuracy: 0.9505\n",
      "Epoch 53/100\n",
      "470/470 [==============================] - 0s 130us/step - loss: 2.2486 - accuracy: 0.7660 - val_loss: 0.8240 - val_accuracy: 0.9356\n",
      "Epoch 54/100\n",
      "470/470 [==============================] - 0s 130us/step - loss: 1.8936 - accuracy: 0.8085 - val_loss: 0.8263 - val_accuracy: 0.9406\n",
      "Epoch 55/100\n",
      "470/470 [==============================] - 0s 210us/step - loss: 2.1393 - accuracy: 0.7766 - val_loss: 0.7832 - val_accuracy: 0.9208\n",
      "Epoch 56/100\n",
      "470/470 [==============================] - 0s 161us/step - loss: 1.6918 - accuracy: 0.7979 - val_loss: 0.8375 - val_accuracy: 0.9455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "470/470 [==============================] - 0s 146us/step - loss: 2.2022 - accuracy: 0.7702 - val_loss: 0.8341 - val_accuracy: 0.9455\n",
      "Epoch 58/100\n",
      "470/470 [==============================] - 0s 140us/step - loss: 1.9290 - accuracy: 0.8000 - val_loss: 0.8023 - val_accuracy: 0.9356\n",
      "Epoch 59/100\n",
      "470/470 [==============================] - 0s 141us/step - loss: 1.8256 - accuracy: 0.8043 - val_loss: 0.7745 - val_accuracy: 0.9604\n",
      "Epoch 60/100\n",
      "470/470 [==============================] - 0s 131us/step - loss: 2.0107 - accuracy: 0.7851 - val_loss: 0.7809 - val_accuracy: 0.9455\n",
      "Epoch 61/100\n",
      "470/470 [==============================] - 0s 134us/step - loss: 1.8318 - accuracy: 0.7915 - val_loss: 0.7610 - val_accuracy: 0.9455\n",
      "Epoch 62/100\n",
      "470/470 [==============================] - 0s 171us/step - loss: 1.8657 - accuracy: 0.7979 - val_loss: 0.7344 - val_accuracy: 0.9604\n",
      "Epoch 63/100\n",
      "470/470 [==============================] - 0s 198us/step - loss: 2.0620 - accuracy: 0.7404 - val_loss: 0.7937 - val_accuracy: 0.9554\n",
      "Epoch 64/100\n",
      "470/470 [==============================] - 0s 183us/step - loss: 2.0366 - accuracy: 0.7532 - val_loss: 0.7734 - val_accuracy: 0.9604\n",
      "Epoch 65/100\n",
      "470/470 [==============================] - 0s 163us/step - loss: 2.0056 - accuracy: 0.7681 - val_loss: 0.7578 - val_accuracy: 0.9455\n",
      "Epoch 66/100\n",
      "470/470 [==============================] - 0s 128us/step - loss: 1.8661 - accuracy: 0.7702 - val_loss: 0.8798 - val_accuracy: 0.9356\n",
      "Epoch 67/100\n",
      "470/470 [==============================] - 0s 133us/step - loss: 1.7966 - accuracy: 0.7851 - val_loss: 0.7074 - val_accuracy: 0.9703\n",
      "Epoch 68/100\n",
      "470/470 [==============================] - 0s 216us/step - loss: 2.0148 - accuracy: 0.7745 - val_loss: 0.7021 - val_accuracy: 0.9653\n",
      "Epoch 69/100\n",
      "470/470 [==============================] - 0s 222us/step - loss: 1.5010 - accuracy: 0.7936 - val_loss: 0.7446 - val_accuracy: 0.9653\n",
      "Epoch 70/100\n",
      "470/470 [==============================] - 0s 204us/step - loss: 1.7229 - accuracy: 0.7915 - val_loss: 0.8040 - val_accuracy: 0.9554\n",
      "Epoch 71/100\n",
      "470/470 [==============================] - 0s 167us/step - loss: 1.6328 - accuracy: 0.8234 - val_loss: 0.6837 - val_accuracy: 0.9554\n",
      "Epoch 72/100\n",
      "470/470 [==============================] - 0s 199us/step - loss: 1.3451 - accuracy: 0.8234 - val_loss: 0.7612 - val_accuracy: 0.9307\n",
      "Epoch 73/100\n",
      "470/470 [==============================] - 0s 173us/step - loss: 1.8173 - accuracy: 0.7532 - val_loss: 0.7591 - val_accuracy: 0.9653\n",
      "Epoch 74/100\n",
      "470/470 [==============================] - 0s 155us/step - loss: 1.7082 - accuracy: 0.7915 - val_loss: 0.6769 - val_accuracy: 0.9752\n",
      "Epoch 75/100\n",
      "470/470 [==============================] - 0s 206us/step - loss: 1.6651 - accuracy: 0.7766 - val_loss: 0.7354 - val_accuracy: 0.9455\n",
      "Epoch 76/100\n",
      "470/470 [==============================] - 0s 205us/step - loss: 1.6417 - accuracy: 0.7809 - val_loss: 0.6988 - val_accuracy: 0.9604\n",
      "Epoch 77/100\n",
      "470/470 [==============================] - 0s 151us/step - loss: 1.8038 - accuracy: 0.7681 - val_loss: 0.7025 - val_accuracy: 0.9703\n",
      "Epoch 78/100\n",
      "470/470 [==============================] - 0s 166us/step - loss: 1.6107 - accuracy: 0.7936 - val_loss: 0.6681 - val_accuracy: 0.9604\n",
      "Epoch 79/100\n",
      "470/470 [==============================] - 0s 328us/step - loss: 1.4659 - accuracy: 0.8043 - val_loss: 0.7252 - val_accuracy: 0.9604\n",
      "Epoch 80/100\n",
      "470/470 [==============================] - 0s 195us/step - loss: 1.6879 - accuracy: 0.7872 - val_loss: 0.7187 - val_accuracy: 0.9653\n",
      "Epoch 81/100\n",
      "470/470 [==============================] - 0s 724us/step - loss: 1.4481 - accuracy: 0.7957 - val_loss: 0.6352 - val_accuracy: 0.9604\n",
      "Epoch 82/100\n",
      "470/470 [==============================] - 0s 256us/step - loss: 1.6601 - accuracy: 0.8021 - val_loss: 0.6892 - val_accuracy: 0.9604\n",
      "Epoch 83/100\n",
      "470/470 [==============================] - 0s 281us/step - loss: 1.8464 - accuracy: 0.7702 - val_loss: 0.7210 - val_accuracy: 0.9653\n",
      "Epoch 84/100\n",
      "470/470 [==============================] - 0s 146us/step - loss: 1.8348 - accuracy: 0.7660 - val_loss: 0.7158 - val_accuracy: 0.9554\n",
      "Epoch 85/100\n",
      "470/470 [==============================] - 0s 146us/step - loss: 1.4581 - accuracy: 0.7638 - val_loss: 0.8081 - val_accuracy: 0.9356\n",
      "Epoch 86/100\n",
      "470/470 [==============================] - 0s 374us/step - loss: 1.4895 - accuracy: 0.7915 - val_loss: 0.8083 - val_accuracy: 0.9356\n",
      "Epoch 87/100\n",
      "470/470 [==============================] - 0s 317us/step - loss: 1.7267 - accuracy: 0.7638 - val_loss: 0.7168 - val_accuracy: 0.9505\n",
      "Epoch 88/100\n",
      "470/470 [==============================] - 0s 175us/step - loss: 1.9009 - accuracy: 0.7872 - val_loss: 0.7863 - val_accuracy: 0.9406\n",
      "Epoch 89/100\n",
      "470/470 [==============================] - 0s 231us/step - loss: 1.6147 - accuracy: 0.7915 - val_loss: 0.6502 - val_accuracy: 0.9703\n",
      "Epoch 90/100\n",
      "470/470 [==============================] - 0s 241us/step - loss: 1.5346 - accuracy: 0.7638 - val_loss: 0.6034 - val_accuracy: 0.9653\n",
      "Epoch 91/100\n",
      "470/470 [==============================] - 0s 144us/step - loss: 1.3763 - accuracy: 0.7936 - val_loss: 0.7496 - val_accuracy: 0.9604\n",
      "Epoch 92/100\n",
      "470/470 [==============================] - 0s 135us/step - loss: 1.3745 - accuracy: 0.7979 - val_loss: 0.6993 - val_accuracy: 0.9604\n",
      "Epoch 93/100\n",
      "470/470 [==============================] - 0s 187us/step - loss: 1.3441 - accuracy: 0.8128 - val_loss: 0.7168 - val_accuracy: 0.9554\n",
      "Epoch 94/100\n",
      "470/470 [==============================] - 0s 185us/step - loss: 1.7014 - accuracy: 0.7532 - val_loss: 0.6818 - val_accuracy: 0.9653\n",
      "Epoch 95/100\n",
      "470/470 [==============================] - 0s 174us/step - loss: 1.5386 - accuracy: 0.7745 - val_loss: 0.7048 - val_accuracy: 0.9505\n",
      "Epoch 96/100\n",
      "470/470 [==============================] - 0s 182us/step - loss: 1.5734 - accuracy: 0.7766 - val_loss: 0.6682 - val_accuracy: 0.9604\n",
      "Epoch 97/100\n",
      "470/470 [==============================] - 0s 156us/step - loss: 1.4392 - accuracy: 0.7830 - val_loss: 0.6490 - val_accuracy: 0.9703\n",
      "Epoch 98/100\n",
      "470/470 [==============================] - 0s 163us/step - loss: 1.4992 - accuracy: 0.7766 - val_loss: 0.7353 - val_accuracy: 0.9554\n",
      "Epoch 99/100\n",
      "470/470 [==============================] - 0s 198us/step - loss: 1.2294 - accuracy: 0.7936 - val_loss: 0.6837 - val_accuracy: 0.9604\n",
      "Epoch 100/100\n",
      "470/470 [==============================] - 0s 174us/step - loss: 1.4601 - accuracy: 0.7723 - val_loss: 0.6283 - val_accuracy: 0.9604\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a3f561ef0>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over7.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202/202 [==============================] - 0s 99us/step\n",
      "over-sampling test accuracy: 93.07%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over7 = model1_over7.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over7*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 2, 1, 2, 1, 1, 1, 2, 0, 0, 1, 2, 1, 2, 0, 2, 0, 1, 0, 0, 1,\n",
       "       2, 0, 1, 2, 2, 2, 2, 1, 0, 1, 2, 1, 2, 1, 1, 1, 1, 0, 2, 0, 1, 1,\n",
       "       0, 0, 2, 2, 2, 2, 0, 2, 2, 2, 2, 1, 2, 1, 2, 2, 1, 0, 0, 2, 0, 1,\n",
       "       2, 2, 2, 0, 1, 1, 2, 2, 1, 0, 2, 1, 2, 2, 2, 2, 0, 0, 0, 0, 0, 1,\n",
       "       0, 2, 1, 2, 0, 2, 2, 1, 2, 0, 0, 2, 1, 1, 2, 2, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 1, 1, 2, 0, 1, 1, 1, 2, 2, 1, 0,\n",
       "       1, 1, 0, 1, 2, 2, 2, 0, 2, 1, 1, 2, 0, 0, 2, 0, 2, 0, 0, 0, 2, 2,\n",
       "       1, 1, 1, 2, 1, 0, 1, 2, 2, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 2,\n",
       "       0, 1, 2, 0, 0, 1, 2, 1, 0, 1, 0, 2, 2, 1, 1, 2, 2, 1, 2, 0, 2, 2,\n",
       "       0, 2, 0, 0])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred7 = model1_over7.predict_classes(X_test_over)\n",
    "pred7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS260</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS205</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS064</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>GA53649</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>NRS210</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>NRS162</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0  test  pred\n",
       "0     NRS260     0     0\n",
       "1     NRS148     2     2\n",
       "2     NRS205     1     2\n",
       "3     NRS064     1     1\n",
       "4     NRS209     2     2\n",
       "..       ...   ...   ...\n",
       "197   NRS255     2     2\n",
       "198  GA53649     0     0\n",
       "199   NRS209     2     2\n",
       "200   NRS210     0     0\n",
       "201   NRS162     0     0\n",
       "\n",
       "[202 rows x 3 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat7['pred'] = pred7\n",
    "dat7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba7 = model1_over7.predict_proba(X_test_over)\n",
    "dat_proba7 = pd.DataFrame(proba7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.498861e-01</td>\n",
       "      <td>4.973201e-02</td>\n",
       "      <td>3.818146e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.827860e-07</td>\n",
       "      <td>3.119154e-06</td>\n",
       "      <td>9.999963e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.094362e-04</td>\n",
       "      <td>9.128791e-04</td>\n",
       "      <td>9.987777e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.611043e-11</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>5.426886e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.801006e-08</td>\n",
       "      <td>3.132352e-08</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>1.471449e-01</td>\n",
       "      <td>2.311823e-01</td>\n",
       "      <td>6.216729e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>1.012713e-07</td>\n",
       "      <td>2.161844e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>3.801013e-08</td>\n",
       "      <td>3.132352e-08</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>9.790896e-01</td>\n",
       "      <td>2.091015e-02</td>\n",
       "      <td>2.395272e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>9.999981e-01</td>\n",
       "      <td>1.903000e-06</td>\n",
       "      <td>1.624835e-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0             1             2\n",
       "0    9.498861e-01  4.973201e-02  3.818146e-04\n",
       "1    5.827860e-07  3.119154e-06  9.999963e-01\n",
       "2    3.094362e-04  9.128791e-04  9.987777e-01\n",
       "3    3.611043e-11  1.000000e+00  5.426886e-09\n",
       "4    3.801006e-08  3.132352e-08  9.999999e-01\n",
       "..            ...           ...           ...\n",
       "197  1.471449e-01  2.311823e-01  6.216729e-01\n",
       "198  9.999999e-01  1.012713e-07  2.161844e-08\n",
       "199  3.801013e-08  3.132352e-08  9.999999e-01\n",
       "200  9.790896e-01  2.091015e-02  2.395272e-07\n",
       "201  9.999981e-01  1.903000e-06  1.624835e-09\n",
       "\n",
       "[202 rows x 3 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba7.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba7.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat7.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/7p003ppST.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 470 samples, validate on 202 samples\n",
      "Epoch 1/100\n",
      "470/470 [==============================] - 0s 200us/step - loss: 1.0190 - accuracy: 0.7851 - val_loss: 0.7314 - val_accuracy: 0.9307\n",
      "Epoch 2/100\n",
      "470/470 [==============================] - 0s 140us/step - loss: 0.8814 - accuracy: 0.8043 - val_loss: 0.5911 - val_accuracy: 0.9307\n",
      "Epoch 3/100\n",
      "470/470 [==============================] - 0s 131us/step - loss: 1.0980 - accuracy: 0.7979 - val_loss: 0.7353 - val_accuracy: 0.9307\n",
      "Epoch 4/100\n",
      "470/470 [==============================] - 0s 133us/step - loss: 1.0050 - accuracy: 0.7596 - val_loss: 0.6711 - val_accuracy: 0.9307\n",
      "Epoch 5/100\n",
      "470/470 [==============================] - 0s 125us/step - loss: 0.8658 - accuracy: 0.7766 - val_loss: 0.6054 - val_accuracy: 0.9307\n",
      "Epoch 6/100\n",
      "470/470 [==============================] - 0s 123us/step - loss: 0.8575 - accuracy: 0.7894 - val_loss: 0.6344 - val_accuracy: 0.9208\n",
      "Epoch 7/100\n",
      "470/470 [==============================] - 0s 133us/step - loss: 0.9313 - accuracy: 0.7766 - val_loss: 0.5760 - val_accuracy: 0.9307\n",
      "Epoch 8/100\n",
      "470/470 [==============================] - 0s 124us/step - loss: 0.8867 - accuracy: 0.7745 - val_loss: 0.5789 - val_accuracy: 0.9307\n",
      "Epoch 9/100\n",
      "470/470 [==============================] - 0s 126us/step - loss: 0.8939 - accuracy: 0.7745 - val_loss: 0.5990 - val_accuracy: 0.9307\n",
      "Epoch 10/100\n",
      "470/470 [==============================] - 0s 131us/step - loss: 0.9522 - accuracy: 0.7894 - val_loss: 0.7111 - val_accuracy: 0.9158\n",
      "Epoch 11/100\n",
      "470/470 [==============================] - 0s 122us/step - loss: 1.0036 - accuracy: 0.7681 - val_loss: 0.7321 - val_accuracy: 0.9208\n",
      "Epoch 12/100\n",
      "470/470 [==============================] - 0s 122us/step - loss: 0.9197 - accuracy: 0.7766 - val_loss: 0.6644 - val_accuracy: 0.9257\n",
      "Epoch 13/100\n",
      "470/470 [==============================] - 0s 135us/step - loss: 1.0708 - accuracy: 0.7681 - val_loss: 0.5792 - val_accuracy: 0.9307\n",
      "Epoch 14/100\n",
      "470/470 [==============================] - 0s 134us/step - loss: 0.9224 - accuracy: 0.7745 - val_loss: 0.6855 - val_accuracy: 0.9356\n",
      "Epoch 15/100\n",
      "470/470 [==============================] - 0s 124us/step - loss: 0.8939 - accuracy: 0.7957 - val_loss: 0.6820 - val_accuracy: 0.9257\n",
      "Epoch 16/100\n",
      "470/470 [==============================] - 0s 122us/step - loss: 0.8534 - accuracy: 0.7979 - val_loss: 0.5536 - val_accuracy: 0.9356\n",
      "Epoch 17/100\n",
      "470/470 [==============================] - 0s 141us/step - loss: 0.8725 - accuracy: 0.7915 - val_loss: 0.5109 - val_accuracy: 0.9356\n",
      "Epoch 18/100\n",
      "470/470 [==============================] - 0s 135us/step - loss: 0.8343 - accuracy: 0.7851 - val_loss: 0.7888 - val_accuracy: 0.9010\n",
      "Epoch 19/100\n",
      "470/470 [==============================] - 0s 141us/step - loss: 1.0396 - accuracy: 0.7489 - val_loss: 0.7374 - val_accuracy: 0.9257\n",
      "Epoch 20/100\n",
      "470/470 [==============================] - 0s 219us/step - loss: 1.0737 - accuracy: 0.7660 - val_loss: 0.6364 - val_accuracy: 0.9257\n",
      "Epoch 21/100\n",
      "470/470 [==============================] - 0s 300us/step - loss: 0.8910 - accuracy: 0.8021 - val_loss: 0.6536 - val_accuracy: 0.9604\n",
      "Epoch 22/100\n",
      "470/470 [==============================] - 0s 184us/step - loss: 0.7546 - accuracy: 0.8213 - val_loss: 0.7299 - val_accuracy: 0.9356\n",
      "Epoch 23/100\n",
      "470/470 [==============================] - 0s 173us/step - loss: 0.7815 - accuracy: 0.8085 - val_loss: 0.5433 - val_accuracy: 0.9554\n",
      "Epoch 24/100\n",
      "470/470 [==============================] - 0s 199us/step - loss: 0.8691 - accuracy: 0.7915 - val_loss: 0.5198 - val_accuracy: 0.9653\n",
      "Epoch 25/100\n",
      "470/470 [==============================] - 0s 206us/step - loss: 0.7205 - accuracy: 0.8064 - val_loss: 0.5717 - val_accuracy: 0.9356\n",
      "Epoch 26/100\n",
      "470/470 [==============================] - 0s 191us/step - loss: 0.7650 - accuracy: 0.7872 - val_loss: 0.5399 - val_accuracy: 0.9653\n",
      "Epoch 27/100\n",
      "470/470 [==============================] - 0s 148us/step - loss: 0.7630 - accuracy: 0.8000 - val_loss: 0.5308 - val_accuracy: 0.9653\n",
      "Epoch 28/100\n",
      "470/470 [==============================] - 0s 145us/step - loss: 0.8887 - accuracy: 0.7936 - val_loss: 0.5610 - val_accuracy: 0.9505\n",
      "Epoch 29/100\n",
      "470/470 [==============================] - 0s 147us/step - loss: 0.7906 - accuracy: 0.7830 - val_loss: 0.6112 - val_accuracy: 0.9554\n",
      "Epoch 30/100\n",
      "470/470 [==============================] - 0s 150us/step - loss: 0.8722 - accuracy: 0.8000 - val_loss: 0.5470 - val_accuracy: 0.9554\n",
      "Epoch 31/100\n",
      "470/470 [==============================] - 0s 146us/step - loss: 0.9069 - accuracy: 0.7787 - val_loss: 0.6560 - val_accuracy: 0.9455\n",
      "Epoch 32/100\n",
      "470/470 [==============================] - 0s 128us/step - loss: 0.8282 - accuracy: 0.7979 - val_loss: 0.5580 - val_accuracy: 0.9554\n",
      "Epoch 33/100\n",
      "470/470 [==============================] - 0s 125us/step - loss: 0.8066 - accuracy: 0.7851 - val_loss: 0.6488 - val_accuracy: 0.9505\n",
      "Epoch 34/100\n",
      "470/470 [==============================] - 0s 133us/step - loss: 0.8447 - accuracy: 0.7787 - val_loss: 0.4870 - val_accuracy: 0.9653\n",
      "Epoch 35/100\n",
      "470/470 [==============================] - 0s 135us/step - loss: 0.8507 - accuracy: 0.7702 - val_loss: 0.5335 - val_accuracy: 0.9653\n",
      "Epoch 36/100\n",
      "470/470 [==============================] - 0s 129us/step - loss: 0.7163 - accuracy: 0.8277 - val_loss: 0.4783 - val_accuracy: 0.9653\n",
      "Epoch 37/100\n",
      "470/470 [==============================] - 0s 127us/step - loss: 0.8626 - accuracy: 0.7617 - val_loss: 0.5039 - val_accuracy: 0.9653\n",
      "Epoch 38/100\n",
      "470/470 [==============================] - 0s 149us/step - loss: 0.9253 - accuracy: 0.7851 - val_loss: 0.4749 - val_accuracy: 0.9653\n",
      "Epoch 39/100\n",
      "470/470 [==============================] - 0s 144us/step - loss: 0.7697 - accuracy: 0.7830 - val_loss: 0.5158 - val_accuracy: 0.9554\n",
      "Epoch 40/100\n",
      "470/470 [==============================] - 0s 164us/step - loss: 0.8298 - accuracy: 0.8064 - val_loss: 0.4896 - val_accuracy: 0.9604\n",
      "Epoch 41/100\n",
      "470/470 [==============================] - 0s 190us/step - loss: 0.8237 - accuracy: 0.7894 - val_loss: 0.5295 - val_accuracy: 0.9604\n",
      "Epoch 42/100\n",
      "470/470 [==============================] - 0s 146us/step - loss: 0.8446 - accuracy: 0.7851 - val_loss: 0.5877 - val_accuracy: 0.9554\n",
      "Epoch 43/100\n",
      "470/470 [==============================] - 0s 138us/step - loss: 0.9440 - accuracy: 0.7702 - val_loss: 0.5413 - val_accuracy: 0.9653\n",
      "Epoch 44/100\n",
      "470/470 [==============================] - 0s 144us/step - loss: 0.8543 - accuracy: 0.7702 - val_loss: 0.4690 - val_accuracy: 0.9653\n",
      "Epoch 45/100\n",
      "470/470 [==============================] - 0s 131us/step - loss: 0.7309 - accuracy: 0.7957 - val_loss: 0.4881 - val_accuracy: 0.9653\n",
      "Epoch 46/100\n",
      "470/470 [==============================] - 0s 144us/step - loss: 0.7802 - accuracy: 0.7979 - val_loss: 0.4807 - val_accuracy: 0.9653\n",
      "Epoch 47/100\n",
      "470/470 [==============================] - 0s 130us/step - loss: 0.7547 - accuracy: 0.8043 - val_loss: 0.5450 - val_accuracy: 0.9554\n",
      "Epoch 48/100\n",
      "470/470 [==============================] - 0s 234us/step - loss: 0.7458 - accuracy: 0.7830 - val_loss: 0.4948 - val_accuracy: 0.9554\n",
      "Epoch 49/100\n",
      "470/470 [==============================] - 0s 372us/step - loss: 0.7858 - accuracy: 0.8085 - val_loss: 0.4796 - val_accuracy: 0.9653\n",
      "Epoch 50/100\n",
      "470/470 [==============================] - 0s 204us/step - loss: 0.7466 - accuracy: 0.7979 - val_loss: 0.5608 - val_accuracy: 0.9505\n",
      "Epoch 51/100\n",
      "470/470 [==============================] - 0s 201us/step - loss: 0.8072 - accuracy: 0.8043 - val_loss: 0.4583 - val_accuracy: 0.9653\n",
      "Epoch 52/100\n",
      "470/470 [==============================] - 0s 254us/step - loss: 0.7722 - accuracy: 0.7617 - val_loss: 0.6154 - val_accuracy: 0.9406\n",
      "Epoch 53/100\n",
      "470/470 [==============================] - 0s 439us/step - loss: 0.8619 - accuracy: 0.8043 - val_loss: 0.8124 - val_accuracy: 0.9406\n",
      "Epoch 54/100\n",
      "470/470 [==============================] - 0s 234us/step - loss: 0.9339 - accuracy: 0.7915 - val_loss: 0.6066 - val_accuracy: 0.9455\n",
      "Epoch 55/100\n",
      "470/470 [==============================] - 0s 283us/step - loss: 0.7709 - accuracy: 0.7787 - val_loss: 0.4560 - val_accuracy: 0.9653\n",
      "Epoch 56/100\n",
      "470/470 [==============================] - 0s 185us/step - loss: 0.7998 - accuracy: 0.7766 - val_loss: 0.5008 - val_accuracy: 0.9604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "470/470 [==============================] - 0s 165us/step - loss: 0.7476 - accuracy: 0.8064 - val_loss: 0.4392 - val_accuracy: 0.9703\n",
      "Epoch 58/100\n",
      "470/470 [==============================] - 0s 466us/step - loss: 0.6842 - accuracy: 0.8149 - val_loss: 0.4946 - val_accuracy: 0.9554\n",
      "Epoch 59/100\n",
      "470/470 [==============================] - 0s 183us/step - loss: 0.7550 - accuracy: 0.7872 - val_loss: 0.5006 - val_accuracy: 0.9604\n",
      "Epoch 60/100\n",
      "470/470 [==============================] - 0s 170us/step - loss: 0.8078 - accuracy: 0.7681 - val_loss: 0.4707 - val_accuracy: 0.9653\n",
      "Epoch 61/100\n",
      "470/470 [==============================] - 0s 143us/step - loss: 0.8197 - accuracy: 0.7766 - val_loss: 0.4902 - val_accuracy: 0.9653\n",
      "Epoch 62/100\n",
      "470/470 [==============================] - 0s 133us/step - loss: 0.7267 - accuracy: 0.7851 - val_loss: 0.4780 - val_accuracy: 0.9604\n",
      "Epoch 63/100\n",
      "470/470 [==============================] - 0s 139us/step - loss: 0.7281 - accuracy: 0.7936 - val_loss: 0.4597 - val_accuracy: 0.9653\n",
      "Epoch 64/100\n",
      "470/470 [==============================] - 0s 135us/step - loss: 0.8885 - accuracy: 0.7702 - val_loss: 0.5780 - val_accuracy: 0.9455\n",
      "Epoch 65/100\n",
      "470/470 [==============================] - 0s 138us/step - loss: 0.8000 - accuracy: 0.7426 - val_loss: 0.6255 - val_accuracy: 0.9455\n",
      "Epoch 66/100\n",
      "470/470 [==============================] - 0s 267us/step - loss: 0.8305 - accuracy: 0.7723 - val_loss: 0.5156 - val_accuracy: 0.9554\n",
      "Epoch 67/100\n",
      "470/470 [==============================] - 0s 218us/step - loss: 0.7359 - accuracy: 0.7957 - val_loss: 0.5218 - val_accuracy: 0.9653\n",
      "Epoch 68/100\n",
      "470/470 [==============================] - 0s 267us/step - loss: 0.7913 - accuracy: 0.7681 - val_loss: 0.5269 - val_accuracy: 0.9653\n",
      "Epoch 69/100\n",
      "470/470 [==============================] - 0s 454us/step - loss: 0.8584 - accuracy: 0.7979 - val_loss: 0.5936 - val_accuracy: 0.9554\n",
      "Epoch 70/100\n",
      "470/470 [==============================] - 0s 283us/step - loss: 0.6751 - accuracy: 0.7851 - val_loss: 0.4960 - val_accuracy: 0.9604\n",
      "Epoch 71/100\n",
      "470/470 [==============================] - 0s 275us/step - loss: 0.7746 - accuracy: 0.7936 - val_loss: 0.4990 - val_accuracy: 0.9653\n",
      "Epoch 72/100\n",
      "470/470 [==============================] - 0s 241us/step - loss: 0.7440 - accuracy: 0.7681 - val_loss: 0.5024 - val_accuracy: 0.9604\n",
      "Epoch 73/100\n",
      "470/470 [==============================] - 0s 264us/step - loss: 0.7875 - accuracy: 0.7511 - val_loss: 0.5158 - val_accuracy: 0.9604\n",
      "Epoch 74/100\n",
      "470/470 [==============================] - 0s 272us/step - loss: 0.7949 - accuracy: 0.7702 - val_loss: 0.5344 - val_accuracy: 0.9653\n",
      "Epoch 75/100\n",
      "470/470 [==============================] - 0s 382us/step - loss: 0.7985 - accuracy: 0.7851 - val_loss: 0.4344 - val_accuracy: 0.9653\n",
      "Epoch 76/100\n",
      "470/470 [==============================] - 0s 269us/step - loss: 0.6731 - accuracy: 0.7851 - val_loss: 0.4902 - val_accuracy: 0.9505\n",
      "Epoch 77/100\n",
      "470/470 [==============================] - 0s 213us/step - loss: 0.7348 - accuracy: 0.7745 - val_loss: 0.5080 - val_accuracy: 0.9604\n",
      "Epoch 78/100\n",
      "470/470 [==============================] - 0s 211us/step - loss: 0.7080 - accuracy: 0.7894 - val_loss: 0.4882 - val_accuracy: 0.9653\n",
      "Epoch 79/100\n",
      "470/470 [==============================] - 0s 286us/step - loss: 0.8222 - accuracy: 0.7702 - val_loss: 0.4515 - val_accuracy: 0.9653\n",
      "Epoch 80/100\n",
      "470/470 [==============================] - 0s 228us/step - loss: 0.7195 - accuracy: 0.7851 - val_loss: 0.4701 - val_accuracy: 0.9653\n",
      "Epoch 81/100\n",
      "470/470 [==============================] - 0s 252us/step - loss: 0.7327 - accuracy: 0.7851 - val_loss: 0.4805 - val_accuracy: 0.9653\n",
      "Epoch 82/100\n",
      "470/470 [==============================] - 0s 321us/step - loss: 0.7206 - accuracy: 0.7617 - val_loss: 0.5430 - val_accuracy: 0.9653\n",
      "Epoch 83/100\n",
      "470/470 [==============================] - 0s 372us/step - loss: 0.6353 - accuracy: 0.7936 - val_loss: 0.4608 - val_accuracy: 0.9653\n",
      "Epoch 84/100\n",
      "470/470 [==============================] - 0s 307us/step - loss: 0.7529 - accuracy: 0.7872 - val_loss: 0.4919 - val_accuracy: 0.9653\n",
      "Epoch 85/100\n",
      "470/470 [==============================] - 0s 279us/step - loss: 0.7465 - accuracy: 0.7894 - val_loss: 0.4803 - val_accuracy: 0.9604\n",
      "Epoch 86/100\n",
      "470/470 [==============================] - 0s 224us/step - loss: 0.7255 - accuracy: 0.7894 - val_loss: 0.4696 - val_accuracy: 0.9653\n",
      "Epoch 87/100\n",
      "470/470 [==============================] - 0s 223us/step - loss: 0.6582 - accuracy: 0.7979 - val_loss: 0.5155 - val_accuracy: 0.9604\n",
      "Epoch 88/100\n",
      "470/470 [==============================] - 0s 250us/step - loss: 0.7417 - accuracy: 0.7660 - val_loss: 0.4234 - val_accuracy: 0.9653\n",
      "Epoch 89/100\n",
      "470/470 [==============================] - 0s 278us/step - loss: 0.7941 - accuracy: 0.7894 - val_loss: 0.5232 - val_accuracy: 0.9604\n",
      "Epoch 90/100\n",
      "470/470 [==============================] - 0s 224us/step - loss: 0.7040 - accuracy: 0.7872 - val_loss: 0.4324 - val_accuracy: 0.9653\n",
      "Epoch 91/100\n",
      "470/470 [==============================] - 0s 271us/step - loss: 0.6882 - accuracy: 0.8106 - val_loss: 0.5012 - val_accuracy: 0.9653\n",
      "Epoch 92/100\n",
      "470/470 [==============================] - 0s 225us/step - loss: 0.8328 - accuracy: 0.7681 - val_loss: 0.4491 - val_accuracy: 0.9653\n",
      "Epoch 93/100\n",
      "470/470 [==============================] - 0s 224us/step - loss: 0.6844 - accuracy: 0.7894 - val_loss: 0.4679 - val_accuracy: 0.9653\n",
      "Epoch 94/100\n",
      "470/470 [==============================] - 0s 210us/step - loss: 0.8293 - accuracy: 0.8085 - val_loss: 0.4780 - val_accuracy: 0.9653\n",
      "Epoch 95/100\n",
      "470/470 [==============================] - 0s 227us/step - loss: 0.8081 - accuracy: 0.7574 - val_loss: 0.4885 - val_accuracy: 0.9604\n",
      "Epoch 96/100\n",
      "470/470 [==============================] - 0s 251us/step - loss: 0.5939 - accuracy: 0.8255 - val_loss: 0.5190 - val_accuracy: 0.9604\n",
      "Epoch 97/100\n",
      "470/470 [==============================] - 0s 225us/step - loss: 0.7258 - accuracy: 0.8106 - val_loss: 0.4612 - val_accuracy: 0.9653\n",
      "Epoch 98/100\n",
      "470/470 [==============================] - 0s 241us/step - loss: 0.8031 - accuracy: 0.7957 - val_loss: 0.4542 - val_accuracy: 0.9703\n",
      "Epoch 99/100\n",
      "470/470 [==============================] - 0s 243us/step - loss: 0.6942 - accuracy: 0.7851 - val_loss: 0.4748 - val_accuracy: 0.9653\n",
      "Epoch 100/100\n",
      "470/470 [==============================] - 0s 259us/step - loss: 0.6756 - accuracy: 0.7787 - val_loss: 0.4743 - val_accuracy: 0.9653\n"
     ]
    }
   ],
   "source": [
    "hist1_over7 = model1_over7.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 78.60%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over7.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba7 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_regularizor_dropout_2.xlsx\",\n",
    "                        sheet_name=2,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8.300497e-12</td>\n",
       "      <td>1.036520e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>BCH-SA-09</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.137139e-06</td>\n",
       "      <td>9.999988e-01</td>\n",
       "      <td>2.067601e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS224</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.093110e-31</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8.300497e-12</td>\n",
       "      <td>1.036520e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS235</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.243513e-02</td>\n",
       "      <td>9.774035e-01</td>\n",
       "      <td>1.615106e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS035</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.354528e-01</td>\n",
       "      <td>6.414209e-02</td>\n",
       "      <td>4.051121e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS260</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.808470e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>7.364639e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>CA9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.361323e-08</td>\n",
       "      <td>2.871247e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS183</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.755864e-07</td>\n",
       "      <td>9.999998e-01</td>\n",
       "      <td>5.310879e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.386494e-08</td>\n",
       "      <td>2.366233e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1982 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       phage     strain  phenotype  prediction             0  \\\n",
       "0     p002ykpresabsSTCC_qual     NRS209          2           2  8.300497e-12   \n",
       "1     p002ykpresabsSTCC_qual  BCH-SA-09          1           1  1.137139e-06   \n",
       "2     p002ykpresabsSTCC_qual     NRS224          0           0  1.000000e+00   \n",
       "3     p002ykpresabsSTCC_qual     NRS209          2           2  8.300497e-12   \n",
       "4     p002ykpresabsSTCC_qual     NRS235          1           1  2.243513e-02   \n",
       "...                      ...        ...        ...         ...           ...   \n",
       "1977     pyopresabsSTCC_qual     NRS035          0           0  9.354528e-01   \n",
       "1978     pyopresabsSTCC_qual     NRS260          1           1  4.808470e-08   \n",
       "1979     pyopresabsSTCC_qual        CA9          0           0  1.000000e+00   \n",
       "1980     pyopresabsSTCC_qual     NRS183          1           1  2.755864e-07   \n",
       "1981     pyopresabsSTCC_qual     NRS148          2           2  2.386494e-08   \n",
       "\n",
       "                 1             2  \n",
       "0     1.036520e-09  1.000000e+00  \n",
       "1     9.999988e-01  2.067601e-09  \n",
       "2     2.093110e-31  0.000000e+00  \n",
       "3     1.036520e-09  1.000000e+00  \n",
       "4     9.774035e-01  1.615106e-04  \n",
       "...            ...           ...  \n",
       "1977  6.414209e-02  4.051121e-04  \n",
       "1978  1.000000e+00  7.364639e-09  \n",
       "1979  2.361323e-08  2.871247e-08  \n",
       "1980  9.999998e-01  5.310879e-08  \n",
       "1981  2.366233e-08  1.000000e+00  \n",
       "\n",
       "[1982 rows x 7 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.49886140e-01, 4.97320070e-02, 3.81814580e-04],\n",
       "       [5.82786000e-07, 3.11915370e-06, 9.99996300e-01],\n",
       "       [3.09436200e-04, 9.12879100e-04, 9.98777700e-01],\n",
       "       [3.61104300e-11, 1.00000000e+00, 5.42688560e-09],\n",
       "       [3.80100600e-08, 3.13235230e-08, 9.99999900e-01],\n",
       "       [3.89797400e-05, 9.99961000e-01, 4.71664020e-08],\n",
       "       [9.99025800e-04, 9.98982500e-01, 1.85122120e-05],\n",
       "       [3.89797400e-05, 9.99961000e-01, 4.71664020e-08],\n",
       "       [3.80100600e-08, 3.13235230e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 5.07421300e-09, 5.74017500e-08],\n",
       "       [1.00000000e+00, 1.04493490e-08, 6.94282350e-10],\n",
       "       [5.43320000e-04, 9.99450600e-01, 6.02986600e-06],\n",
       "       [3.80100600e-08, 3.13235230e-08, 9.99999900e-01],\n",
       "       [1.10361455e-07, 9.99999640e-01, 2.05889580e-07],\n",
       "       [1.47144910e-01, 2.31182260e-01, 6.21672870e-01],\n",
       "       [1.00000000e+00, 4.78651750e-12, 1.24605050e-10],\n",
       "       [5.82786000e-07, 3.11915370e-06, 9.99996300e-01],\n",
       "       [9.99851800e-01, 1.48200650e-04, 2.63378580e-08],\n",
       "       [5.29174500e-07, 9.99999500e-01, 1.72208340e-11],\n",
       "       [8.12517460e-01, 1.87480500e-01, 2.02534030e-06],\n",
       "       [1.00000000e+00, 1.20153740e-14, 1.58250990e-13],\n",
       "       [5.35002030e-06, 9.99994640e-01, 1.97550940e-08],\n",
       "       [3.80100600e-08, 3.13235230e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 3.03931780e-08, 1.22396400e-08],\n",
       "       [6.72748770e-06, 9.99992970e-01, 3.51375800e-07],\n",
       "       [5.82786000e-07, 3.11915370e-06, 9.99996300e-01],\n",
       "       [1.47144910e-01, 2.31182260e-01, 6.21672870e-01],\n",
       "       [5.82786000e-07, 3.11915370e-06, 9.99996300e-01],\n",
       "       [5.82786000e-07, 3.11915370e-06, 9.99996300e-01],\n",
       "       [1.33310860e-08, 1.00000000e+00, 1.80439250e-10],\n",
       "       [1.00000000e+00, 1.11463060e-10, 1.66933220e-09],\n",
       "       [1.27128080e-03, 9.98725700e-01, 2.95606290e-06],\n",
       "       [3.80100600e-08, 3.13235230e-08, 9.99999900e-01],\n",
       "       [5.25140500e-10, 1.00000000e+00, 5.26245960e-08],\n",
       "       [3.80100600e-08, 3.13235230e-08, 9.99999900e-01],\n",
       "       [2.80063280e-09, 1.00000000e+00, 1.80658610e-10],\n",
       "       [2.01197030e-06, 9.99998000e-01, 2.01311790e-10],\n",
       "       [5.21013600e-07, 9.99999500e-01, 1.67350900e-11],\n",
       "       [1.10361455e-07, 9.99999640e-01, 2.05889580e-07],\n",
       "       [1.00000000e+00, 5.07421300e-09, 5.74017500e-08],\n",
       "       [5.82786000e-07, 3.11915370e-06, 9.99996300e-01],\n",
       "       [9.99957800e-01, 9.92832300e-06, 3.22979500e-05],\n",
       "       [3.56887400e-07, 9.99999640e-01, 8.33913600e-12],\n",
       "       [1.10361455e-07, 9.99999640e-01, 2.05889580e-07],\n",
       "       [9.99988300e-01, 1.37136670e-06, 1.02804070e-05],\n",
       "       [9.97326400e-01, 4.53638030e-04, 2.21989020e-03],\n",
       "       [5.82786000e-07, 3.11915370e-06, 9.99996300e-01],\n",
       "       [5.82786000e-07, 3.11915370e-06, 9.99996300e-01],\n",
       "       [3.80100600e-08, 3.13235230e-08, 9.99999900e-01],\n",
       "       [3.80100600e-08, 3.13235230e-08, 9.99999900e-01],\n",
       "       [9.99664300e-01, 3.35647900e-04, 3.29542470e-08],\n",
       "       [3.80100600e-08, 3.13235230e-08, 9.99999900e-01],\n",
       "       [1.47144910e-01, 2.31182260e-01, 6.21672870e-01],\n",
       "       [3.80100600e-08, 3.13235230e-08, 9.99999900e-01],\n",
       "       [5.82786000e-07, 3.11915370e-06, 9.99996300e-01],\n",
       "       [4.52629540e-07, 9.99994900e-01, 4.60627900e-06],\n",
       "       [1.47144910e-01, 2.31182260e-01, 6.21672870e-01],\n",
       "       [5.21013600e-07, 9.99999500e-01, 1.67350900e-11],\n",
       "       [3.80100600e-08, 3.13235230e-08, 9.99999900e-01],\n",
       "       [3.80100600e-08, 3.13235230e-08, 9.99999900e-01],\n",
       "       [1.10361455e-07, 9.99999640e-01, 2.05889580e-07],\n",
       "       [9.99999900e-01, 6.15980000e-08, 3.88206840e-09],\n",
       "       [9.99822440e-01, 1.76245260e-04, 1.30743600e-06],\n",
       "       [5.82786000e-07, 3.11915370e-06, 9.99996300e-01],\n",
       "       [9.99995800e-01, 2.58537600e-07, 3.95150070e-06],\n",
       "       [2.80063280e-09, 1.00000000e+00, 1.80658610e-10],\n",
       "       [5.82786000e-07, 3.11915370e-06, 9.99996300e-01],\n",
       "       [3.09436200e-04, 9.12879100e-04, 9.98777700e-01],\n",
       "       [3.09436200e-04, 9.12879100e-04, 9.98777700e-01],\n",
       "       [9.99785840e-01, 2.70331550e-05, 1.87156150e-04],\n",
       "       [3.61104300e-11, 1.00000000e+00, 5.42688560e-09],\n",
       "       [1.62621140e-09, 1.00000000e+00, 2.56902640e-08],\n",
       "       [3.80100600e-08, 3.13235230e-08, 9.99999900e-01],\n",
       "       [1.47144910e-01, 2.31182260e-01, 6.21672870e-01],\n",
       "       [2.80063280e-09, 1.00000000e+00, 1.80658610e-10],\n",
       "       [9.99418600e-01, 8.92239840e-05, 4.92116400e-04],\n",
       "       [1.47144910e-01, 2.31182260e-01, 6.21672870e-01],\n",
       "       [7.02109250e-05, 9.99929670e-01, 1.39359640e-07],\n",
       "       [3.09436200e-04, 9.12879100e-04, 9.98777700e-01],\n",
       "       [1.47144910e-01, 2.31182260e-01, 6.21672870e-01],\n",
       "       [5.82786000e-07, 3.11915370e-06, 9.99996300e-01],\n",
       "       [1.47144910e-01, 2.31182260e-01, 6.21672870e-01],\n",
       "       [1.00000000e+00, 1.36886790e-11, 4.26457780e-13],\n",
       "       [9.99999640e-01, 9.68089500e-08, 2.33505790e-07],\n",
       "       [9.99819600e-01, 2.56075960e-05, 1.54812090e-04],\n",
       "       [9.93643300e-01, 1.14088920e-03, 5.21571800e-03],\n",
       "       [9.99975560e-01, 2.44091220e-05, 1.68276660e-08],\n",
       "       [5.21013600e-07, 9.99999500e-01, 1.67350900e-11],\n",
       "       [1.00000000e+00, 2.49692890e-12, 7.09657300e-11],\n",
       "       [5.82786000e-07, 3.11915370e-06, 9.99996300e-01],\n",
       "       [1.50342020e-01, 8.49620800e-01, 3.72089740e-05],\n",
       "       [1.47144910e-01, 2.31182260e-01, 6.21672870e-01],\n",
       "       [1.00000000e+00, 4.46492840e-09, 5.09862480e-08],\n",
       "       [1.47144910e-01, 2.31182260e-01, 6.21672870e-01],\n",
       "       [3.80100600e-08, 3.13235230e-08, 9.99999900e-01],\n",
       "       [1.62621140e-09, 1.00000000e+00, 2.56902640e-08],\n",
       "       [5.82786000e-07, 3.11915370e-06, 9.99996300e-01],\n",
       "       [9.99999760e-01, 2.36114830e-07, 5.55956770e-08],\n",
       "       [1.00000000e+00, 2.32795750e-12, 2.02562320e-11],\n",
       "       [1.47144910e-01, 2.31182260e-01, 6.21672870e-01],\n",
       "       [3.53060780e-09, 1.00000000e+00, 9.63221600e-16],\n",
       "       [4.52629540e-07, 9.99994900e-01, 4.60627900e-06],\n",
       "       [3.80100600e-08, 3.13235230e-08, 9.99999900e-01],\n",
       "       [3.80100600e-08, 3.13235230e-08, 9.99999900e-01],\n",
       "       [3.53060780e-09, 1.00000000e+00, 9.63221600e-16],\n",
       "       [9.45325300e-01, 5.46618300e-02, 1.28505560e-05],\n",
       "       [8.60072570e-10, 1.00000000e+00, 4.55381000e-08],\n",
       "       [1.73887940e-09, 9.99999900e-01, 1.45366430e-07],\n",
       "       [5.25140500e-10, 1.00000000e+00, 5.26245960e-08],\n",
       "       [1.10361455e-07, 9.99999640e-01, 2.05889580e-07],\n",
       "       [3.89797400e-05, 9.99961000e-01, 4.71664020e-08],\n",
       "       [1.00000000e+00, 2.93985500e-10, 1.33203650e-11],\n",
       "       [1.00000000e+00, 1.79232870e-14, 1.42458830e-13],\n",
       "       [1.00000000e+00, 9.25732200e-14, 8.75513700e-13],\n",
       "       [9.99999640e-01, 3.20135300e-08, 3.16304440e-07],\n",
       "       [1.47144910e-01, 2.31182260e-01, 6.21672870e-01],\n",
       "       [9.78481600e-02, 9.02151800e-01, 3.12211870e-10],\n",
       "       [1.00000000e+00, 5.07421300e-09, 5.74017500e-08],\n",
       "       [9.86576700e-01, 9.28550200e-03, 4.13783360e-03],\n",
       "       [1.00000000e+00, 5.80620440e-10, 2.41668750e-09],\n",
       "       [9.98924700e-01, 1.07519840e-03, 1.26556360e-07],\n",
       "       [3.10093220e-04, 9.99687800e-01, 2.14695770e-06],\n",
       "       [5.25140500e-10, 1.00000000e+00, 5.26245960e-08],\n",
       "       [1.47144910e-01, 2.31182260e-01, 6.21672870e-01],\n",
       "       [1.00000000e+00, 2.49692890e-12, 7.09657300e-11],\n",
       "       [2.80063280e-09, 1.00000000e+00, 1.80658610e-10],\n",
       "       [5.29174500e-07, 9.99999500e-01, 1.72208340e-11],\n",
       "       [1.62621140e-09, 1.00000000e+00, 2.56902640e-08],\n",
       "       [5.82786000e-07, 3.11915370e-06, 9.99996300e-01],\n",
       "       [3.80100600e-08, 3.13235230e-08, 9.99999900e-01],\n",
       "       [4.52629540e-07, 9.99994900e-01, 4.60627900e-06],\n",
       "       [9.94547600e-01, 5.45202850e-03, 3.09358030e-07],\n",
       "       [4.52629540e-07, 9.99994900e-01, 4.60627900e-06],\n",
       "       [1.73887940e-09, 9.99999900e-01, 1.45366430e-07],\n",
       "       [9.99933100e-01, 6.68387200e-05, 8.63697700e-09],\n",
       "       [5.35002030e-06, 9.99994640e-01, 1.97550940e-08],\n",
       "       [5.82786000e-07, 3.11915370e-06, 9.99996300e-01],\n",
       "       [3.80100600e-08, 3.13235230e-08, 9.99999900e-01],\n",
       "       [5.82786000e-07, 3.11915370e-06, 9.99996300e-01],\n",
       "       [9.99971300e-01, 7.21985540e-06, 2.14730330e-05],\n",
       "       [3.80100600e-08, 3.13235230e-08, 9.99999900e-01],\n",
       "       [4.52888840e-04, 9.99542830e-01, 4.31238400e-06],\n",
       "       [3.89797400e-05, 9.99961000e-01, 4.71664020e-08],\n",
       "       [5.82786000e-07, 3.11915370e-06, 9.99996300e-01],\n",
       "       [9.99999760e-01, 2.30072290e-07, 5.86871460e-08],\n",
       "       [9.99953400e-01, 4.66601120e-05, 7.04912900e-09],\n",
       "       [3.80100600e-08, 3.13235230e-08, 9.99999900e-01],\n",
       "       [9.99999760e-01, 4.02383800e-08, 1.86963260e-07],\n",
       "       [5.82786000e-07, 3.11915370e-06, 9.99996300e-01],\n",
       "       [1.00000000e+00, 2.85652410e-09, 4.45904320e-11],\n",
       "       [9.99998330e-01, 1.62086010e-06, 5.50459700e-08],\n",
       "       [1.00000000e+00, 3.56870600e-12, 1.11617035e-11],\n",
       "       [5.82786000e-07, 3.11915370e-06, 9.99996300e-01],\n",
       "       [5.82786000e-07, 3.11915370e-06, 9.99996300e-01],\n",
       "       [5.25140500e-10, 1.00000000e+00, 5.26245960e-08],\n",
       "       [2.01197030e-06, 9.99998000e-01, 2.01311790e-10],\n",
       "       [1.14853330e-06, 9.99962900e-01, 3.59296170e-05],\n",
       "       [3.80100600e-08, 3.13235230e-08, 9.99999900e-01],\n",
       "       [2.10629450e-07, 9.99999760e-01, 1.77345040e-08],\n",
       "       [9.99999900e-01, 1.25665110e-08, 1.32993320e-07],\n",
       "       [1.33310860e-08, 1.00000000e+00, 1.80439250e-10],\n",
       "       [1.47144910e-01, 2.31182260e-01, 6.21672870e-01],\n",
       "       [1.47144910e-01, 2.31182260e-01, 6.21672870e-01],\n",
       "       [1.00000000e+00, 2.32105020e-08, 7.04433670e-09],\n",
       "       [1.00000000e+00, 4.64741800e-08, 4.32986050e-09],\n",
       "       [5.21013600e-07, 9.99999500e-01, 1.67350900e-11],\n",
       "       [9.99025800e-04, 9.98982500e-01, 1.85122120e-05],\n",
       "       [1.00000000e+00, 9.37675400e-11, 6.97526370e-10],\n",
       "       [5.35002030e-06, 9.99994640e-01, 1.97550940e-08],\n",
       "       [1.00000000e+00, 2.44519200e-10, 4.84861040e-10],\n",
       "       [3.89797400e-05, 9.99961000e-01, 4.71664020e-08],\n",
       "       [7.10562200e-01, 2.89430350e-01, 7.34131900e-06],\n",
       "       [9.99025800e-04, 9.98982500e-01, 1.85122120e-05],\n",
       "       [9.99999640e-01, 6.60116700e-08, 2.74607800e-07],\n",
       "       [5.29174500e-07, 9.99999500e-01, 1.72208340e-11],\n",
       "       [1.47144910e-01, 2.31182260e-01, 6.21672870e-01],\n",
       "       [9.99999760e-01, 2.61346320e-07, 7.53857950e-09],\n",
       "       [6.72748770e-06, 9.99992970e-01, 3.51375800e-07],\n",
       "       [1.47144910e-01, 2.31182260e-01, 6.21672870e-01],\n",
       "       [9.99980450e-01, 2.38301960e-06, 1.71533740e-05],\n",
       "       [1.00000000e+00, 7.05273840e-13, 3.27091620e-11],\n",
       "       [1.10361455e-07, 9.99999640e-01, 2.05889580e-07],\n",
       "       [3.80100600e-08, 3.13235230e-08, 9.99999900e-01],\n",
       "       [6.72748770e-06, 9.99992970e-01, 3.51375800e-07],\n",
       "       [9.99999300e-01, 6.39467700e-08, 6.00494300e-07],\n",
       "       [5.35002030e-06, 9.99994640e-01, 1.97550940e-08],\n",
       "       [6.13439300e-01, 3.86489240e-01, 7.14111200e-05],\n",
       "       [3.80100600e-08, 3.13235230e-08, 9.99999900e-01],\n",
       "       [3.80100600e-08, 3.13235230e-08, 9.99999900e-01],\n",
       "       [5.35002030e-06, 9.99994640e-01, 1.97550940e-08],\n",
       "       [5.43320000e-04, 9.99450600e-01, 6.02986600e-06],\n",
       "       [5.82786000e-07, 3.11915370e-06, 9.99996300e-01],\n",
       "       [5.82786600e-07, 3.11915660e-06, 9.99996300e-01],\n",
       "       [3.53060780e-09, 1.00000000e+00, 9.63221600e-16],\n",
       "       [3.80101320e-08, 3.13235230e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 1.89101200e-14, 1.48196000e-12],\n",
       "       [5.82786600e-07, 3.11915660e-06, 9.99996300e-01],\n",
       "       [1.47144910e-01, 2.31182260e-01, 6.21672870e-01],\n",
       "       [9.99999900e-01, 1.01271260e-07, 2.16184370e-08],\n",
       "       [3.80101320e-08, 3.13235230e-08, 9.99999900e-01],\n",
       "       [9.79089600e-01, 2.09101500e-02, 2.39527170e-07],\n",
       "       [9.99998100e-01, 1.90299980e-06, 1.62483470e-09]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob7 = df_proba7[df_proba7['phage']=='p003ppresabsSTCC_qual'].iloc[:,-3:]\n",
    "y_prob7 = y_prob7.to_numpy()\n",
    "y_prob7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9891847949793516"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo7 = rocauc_ovo(y_test_over, y_prob7, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9891847949793516"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr7 = rocauc_ovr(y_test_over, y_prob7, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=890,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat8 = pd.DataFrame(X_test_over[:,0])\n",
    "dat8['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CA541</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SR3585</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS232</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS180</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>NRS035</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>506</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>SR2091</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>NRS205</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0  test\n",
       "0     CA541     1\n",
       "1    SR3585     0\n",
       "2    NRS232     1\n",
       "3    NRS148     2\n",
       "4    NRS180     1\n",
       "..      ...   ...\n",
       "197  NRS209     2\n",
       "198  NRS035     1\n",
       "199     506     0\n",
       "200  SR2091     0\n",
       "201  NRS205     1\n",
       "\n",
       "[202 rows x 2 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over8 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],), activity_regularizer=l1(0.001)),\n",
    "    Dense(3, activation='softmax'),\n",
    "    Dropout(0.2, ),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over8.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 470 samples, validate on 202 samples\n",
      "Epoch 1/100\n",
      "470/470 [==============================] - 0s 793us/step - loss: 6.2471 - accuracy: 0.4851 - val_loss: 4.2075 - val_accuracy: 0.5545\n",
      "Epoch 2/100\n",
      "470/470 [==============================] - 0s 240us/step - loss: 4.8005 - accuracy: 0.5936 - val_loss: 3.1090 - val_accuracy: 0.6733\n",
      "Epoch 3/100\n",
      "470/470 [==============================] - 0s 333us/step - loss: 3.7839 - accuracy: 0.5936 - val_loss: 2.0792 - val_accuracy: 0.6040\n",
      "Epoch 4/100\n",
      "470/470 [==============================] - 0s 284us/step - loss: 3.5625 - accuracy: 0.5596 - val_loss: 1.6336 - val_accuracy: 0.6139\n",
      "Epoch 5/100\n",
      "470/470 [==============================] - 0s 207us/step - loss: 3.3491 - accuracy: 0.5936 - val_loss: 1.1513 - val_accuracy: 0.6782\n",
      "Epoch 6/100\n",
      "470/470 [==============================] - 0s 138us/step - loss: 3.3176 - accuracy: 0.6149 - val_loss: 1.0274 - val_accuracy: 0.6238\n",
      "Epoch 7/100\n",
      "470/470 [==============================] - 0s 407us/step - loss: 3.1790 - accuracy: 0.6340 - val_loss: 1.0194 - val_accuracy: 0.7079\n",
      "Epoch 8/100\n",
      "470/470 [==============================] - 0s 337us/step - loss: 3.4026 - accuracy: 0.6149 - val_loss: 0.9891 - val_accuracy: 0.6980\n",
      "Epoch 9/100\n",
      "470/470 [==============================] - 0s 243us/step - loss: 3.6596 - accuracy: 0.6340 - val_loss: 1.0666 - val_accuracy: 0.7079\n",
      "Epoch 10/100\n",
      "470/470 [==============================] - 0s 294us/step - loss: 2.9054 - accuracy: 0.6894 - val_loss: 0.9623 - val_accuracy: 0.8168\n",
      "Epoch 11/100\n",
      "470/470 [==============================] - 0s 343us/step - loss: 3.1352 - accuracy: 0.6957 - val_loss: 0.9684 - val_accuracy: 0.8267\n",
      "Epoch 12/100\n",
      "470/470 [==============================] - 0s 370us/step - loss: 2.7277 - accuracy: 0.7021 - val_loss: 0.9272 - val_accuracy: 0.8069\n",
      "Epoch 13/100\n",
      "470/470 [==============================] - 0s 409us/step - loss: 2.3954 - accuracy: 0.7553 - val_loss: 0.9917 - val_accuracy: 0.8465\n",
      "Epoch 14/100\n",
      "470/470 [==============================] - 0s 645us/step - loss: 2.9220 - accuracy: 0.7149 - val_loss: 0.9090 - val_accuracy: 0.8564\n",
      "Epoch 15/100\n",
      "470/470 [==============================] - 0s 230us/step - loss: 3.0415 - accuracy: 0.7170 - val_loss: 0.9867 - val_accuracy: 0.8416\n",
      "Epoch 16/100\n",
      "470/470 [==============================] - 0s 167us/step - loss: 3.0254 - accuracy: 0.6660 - val_loss: 1.0363 - val_accuracy: 0.8069\n",
      "Epoch 17/100\n",
      "470/470 [==============================] - 0s 188us/step - loss: 2.4104 - accuracy: 0.7638 - val_loss: 0.8575 - val_accuracy: 0.8713\n",
      "Epoch 18/100\n",
      "470/470 [==============================] - 0s 212us/step - loss: 2.7701 - accuracy: 0.7489 - val_loss: 0.9580 - val_accuracy: 0.8515\n",
      "Epoch 19/100\n",
      "470/470 [==============================] - 0s 528us/step - loss: 2.9622 - accuracy: 0.7191 - val_loss: 1.2556 - val_accuracy: 0.8366\n",
      "Epoch 20/100\n",
      "470/470 [==============================] - 0s 362us/step - loss: 2.9535 - accuracy: 0.7213 - val_loss: 0.9905 - val_accuracy: 0.8267\n",
      "Epoch 21/100\n",
      "470/470 [==============================] - 0s 178us/step - loss: 2.7096 - accuracy: 0.7298 - val_loss: 1.0774 - val_accuracy: 0.8020\n",
      "Epoch 22/100\n",
      "470/470 [==============================] - 0s 144us/step - loss: 2.3058 - accuracy: 0.7723 - val_loss: 1.1514 - val_accuracy: 0.8713\n",
      "Epoch 23/100\n",
      "470/470 [==============================] - 0s 131us/step - loss: 2.9098 - accuracy: 0.7064 - val_loss: 1.2017 - val_accuracy: 0.8762\n",
      "Epoch 24/100\n",
      "470/470 [==============================] - 0s 124us/step - loss: 2.5360 - accuracy: 0.7404 - val_loss: 1.1201 - val_accuracy: 0.8119\n",
      "Epoch 25/100\n",
      "470/470 [==============================] - 0s 128us/step - loss: 2.7762 - accuracy: 0.7191 - val_loss: 1.3358 - val_accuracy: 0.8267\n",
      "Epoch 26/100\n",
      "470/470 [==============================] - 0s 130us/step - loss: 2.6082 - accuracy: 0.7340 - val_loss: 1.0189 - val_accuracy: 0.8663\n",
      "Epoch 27/100\n",
      "470/470 [==============================] - 0s 126us/step - loss: 2.7476 - accuracy: 0.7170 - val_loss: 1.1450 - val_accuracy: 0.8564\n",
      "Epoch 28/100\n",
      "470/470 [==============================] - 0s 227us/step - loss: 2.2438 - accuracy: 0.7787 - val_loss: 0.9956 - val_accuracy: 0.8317\n",
      "Epoch 29/100\n",
      "470/470 [==============================] - 0s 325us/step - loss: 2.4960 - accuracy: 0.7447 - val_loss: 0.9581 - val_accuracy: 0.8762\n",
      "Epoch 30/100\n",
      "470/470 [==============================] - 0s 223us/step - loss: 2.4386 - accuracy: 0.7489 - val_loss: 1.1021 - val_accuracy: 0.8762\n",
      "Epoch 31/100\n",
      "470/470 [==============================] - 0s 212us/step - loss: 2.3189 - accuracy: 0.7553 - val_loss: 1.1955 - val_accuracy: 0.8317\n",
      "Epoch 32/100\n",
      "470/470 [==============================] - 0s 153us/step - loss: 2.3144 - accuracy: 0.7766 - val_loss: 1.0907 - val_accuracy: 0.8663\n",
      "Epoch 33/100\n",
      "470/470 [==============================] - 0s 144us/step - loss: 2.3591 - accuracy: 0.7404 - val_loss: 1.1319 - val_accuracy: 0.8861\n",
      "Epoch 34/100\n",
      "470/470 [==============================] - 0s 150us/step - loss: 1.8525 - accuracy: 0.7872 - val_loss: 1.0706 - val_accuracy: 0.8911\n",
      "Epoch 35/100\n",
      "470/470 [==============================] - 0s 180us/step - loss: 2.2453 - accuracy: 0.7553 - val_loss: 1.1199 - val_accuracy: 0.8911\n",
      "Epoch 36/100\n",
      "470/470 [==============================] - 0s 133us/step - loss: 2.2213 - accuracy: 0.7660 - val_loss: 1.0497 - val_accuracy: 0.8713\n",
      "Epoch 37/100\n",
      "470/470 [==============================] - 0s 145us/step - loss: 2.0352 - accuracy: 0.7574 - val_loss: 1.0960 - val_accuracy: 0.8911\n",
      "Epoch 38/100\n",
      "470/470 [==============================] - 0s 133us/step - loss: 2.3784 - accuracy: 0.6894 - val_loss: 1.1389 - val_accuracy: 0.8713\n",
      "Epoch 39/100\n",
      "470/470 [==============================] - 0s 132us/step - loss: 2.3143 - accuracy: 0.7404 - val_loss: 1.2015 - val_accuracy: 0.8762\n",
      "Epoch 40/100\n",
      "470/470 [==============================] - 0s 147us/step - loss: 2.2068 - accuracy: 0.7702 - val_loss: 1.0325 - val_accuracy: 0.8960\n",
      "Epoch 41/100\n",
      "470/470 [==============================] - 0s 223us/step - loss: 2.2765 - accuracy: 0.7532 - val_loss: 1.2038 - val_accuracy: 0.8812\n",
      "Epoch 42/100\n",
      "470/470 [==============================] - 0s 167us/step - loss: 2.2703 - accuracy: 0.7383 - val_loss: 1.1144 - val_accuracy: 0.9010\n",
      "Epoch 43/100\n",
      "470/470 [==============================] - 0s 144us/step - loss: 2.0835 - accuracy: 0.7638 - val_loss: 1.1612 - val_accuracy: 0.8762\n",
      "Epoch 44/100\n",
      "470/470 [==============================] - 0s 148us/step - loss: 2.2108 - accuracy: 0.7532 - val_loss: 1.0312 - val_accuracy: 0.9059\n",
      "Epoch 45/100\n",
      "470/470 [==============================] - 0s 156us/step - loss: 1.8195 - accuracy: 0.7766 - val_loss: 1.0620 - val_accuracy: 0.9158\n",
      "Epoch 46/100\n",
      "470/470 [==============================] - 0s 135us/step - loss: 2.0616 - accuracy: 0.7511 - val_loss: 1.0464 - val_accuracy: 0.9059\n",
      "Epoch 47/100\n",
      "470/470 [==============================] - 0s 146us/step - loss: 1.6432 - accuracy: 0.7915 - val_loss: 1.0084 - val_accuracy: 0.9158\n",
      "Epoch 48/100\n",
      "470/470 [==============================] - 0s 139us/step - loss: 1.7435 - accuracy: 0.7809 - val_loss: 1.1577 - val_accuracy: 0.8861\n",
      "Epoch 49/100\n",
      "470/470 [==============================] - 0s 199us/step - loss: 2.1966 - accuracy: 0.7447 - val_loss: 1.0052 - val_accuracy: 0.8812\n",
      "Epoch 50/100\n",
      "470/470 [==============================] - 0s 187us/step - loss: 2.0929 - accuracy: 0.7787 - val_loss: 0.9523 - val_accuracy: 0.9109\n",
      "Epoch 51/100\n",
      "470/470 [==============================] - 0s 177us/step - loss: 1.9045 - accuracy: 0.7894 - val_loss: 1.0293 - val_accuracy: 0.8168\n",
      "Epoch 52/100\n",
      "470/470 [==============================] - 0s 129us/step - loss: 1.9383 - accuracy: 0.7660 - val_loss: 0.9996 - val_accuracy: 0.9257\n",
      "Epoch 53/100\n",
      "470/470 [==============================] - 0s 149us/step - loss: 2.0828 - accuracy: 0.7638 - val_loss: 0.9076 - val_accuracy: 0.9604\n",
      "Epoch 54/100\n",
      "470/470 [==============================] - 0s 249us/step - loss: 1.8151 - accuracy: 0.7617 - val_loss: 1.0133 - val_accuracy: 0.9406\n",
      "Epoch 55/100\n",
      "470/470 [==============================] - 0s 211us/step - loss: 1.8658 - accuracy: 0.7787 - val_loss: 0.9407 - val_accuracy: 0.9554\n",
      "Epoch 56/100\n",
      "470/470 [==============================] - 0s 223us/step - loss: 1.6692 - accuracy: 0.7745 - val_loss: 1.0562 - val_accuracy: 0.9307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "470/470 [==============================] - 0s 236us/step - loss: 1.7996 - accuracy: 0.7553 - val_loss: 0.8988 - val_accuracy: 0.9554\n",
      "Epoch 58/100\n",
      "470/470 [==============================] - 0s 201us/step - loss: 1.5779 - accuracy: 0.7851 - val_loss: 0.8779 - val_accuracy: 0.9653\n",
      "Epoch 59/100\n",
      "470/470 [==============================] - 0s 196us/step - loss: 1.8773 - accuracy: 0.7723 - val_loss: 0.8703 - val_accuracy: 0.9505\n",
      "Epoch 60/100\n",
      "470/470 [==============================] - 0s 216us/step - loss: 1.5385 - accuracy: 0.8000 - val_loss: 0.6631 - val_accuracy: 0.9505\n",
      "Epoch 61/100\n",
      "470/470 [==============================] - 0s 310us/step - loss: 1.7927 - accuracy: 0.7936 - val_loss: 0.7436 - val_accuracy: 0.9653\n",
      "Epoch 62/100\n",
      "470/470 [==============================] - 0s 132us/step - loss: 1.7163 - accuracy: 0.8021 - val_loss: 0.8057 - val_accuracy: 0.9653\n",
      "Epoch 63/100\n",
      "470/470 [==============================] - 0s 167us/step - loss: 1.5865 - accuracy: 0.7872 - val_loss: 0.9997 - val_accuracy: 0.9356\n",
      "Epoch 64/100\n",
      "470/470 [==============================] - 0s 151us/step - loss: 1.5994 - accuracy: 0.7574 - val_loss: 0.8551 - val_accuracy: 0.9653\n",
      "Epoch 65/100\n",
      "470/470 [==============================] - 0s 133us/step - loss: 1.6488 - accuracy: 0.7489 - val_loss: 0.9203 - val_accuracy: 0.9554\n",
      "Epoch 66/100\n",
      "470/470 [==============================] - 0s 158us/step - loss: 1.4306 - accuracy: 0.7894 - val_loss: 0.8807 - val_accuracy: 0.9604\n",
      "Epoch 67/100\n",
      "470/470 [==============================] - 0s 131us/step - loss: 1.5993 - accuracy: 0.7830 - val_loss: 0.9256 - val_accuracy: 0.9356\n",
      "Epoch 68/100\n",
      "470/470 [==============================] - ETA: 0s - loss: 2.2535 - accuracy: 0.68 - 0s 127us/step - loss: 1.6510 - accuracy: 0.7723 - val_loss: 0.8871 - val_accuracy: 0.9703\n",
      "Epoch 69/100\n",
      "470/470 [==============================] - 0s 137us/step - loss: 1.4293 - accuracy: 0.7596 - val_loss: 0.8783 - val_accuracy: 0.9554\n",
      "Epoch 70/100\n",
      "470/470 [==============================] - 0s 135us/step - loss: 1.4601 - accuracy: 0.7830 - val_loss: 0.7801 - val_accuracy: 0.9653\n",
      "Epoch 71/100\n",
      "470/470 [==============================] - 0s 139us/step - loss: 1.7007 - accuracy: 0.7383 - val_loss: 0.8784 - val_accuracy: 0.9554\n",
      "Epoch 72/100\n",
      "470/470 [==============================] - 0s 137us/step - loss: 1.5559 - accuracy: 0.7809 - val_loss: 0.8968 - val_accuracy: 0.9406\n",
      "Epoch 73/100\n",
      "470/470 [==============================] - ETA: 0s - loss: 1.3476 - accuracy: 0.75 - 0s 146us/step - loss: 1.5971 - accuracy: 0.7872 - val_loss: 0.7775 - val_accuracy: 0.9703\n",
      "Epoch 74/100\n",
      "470/470 [==============================] - 0s 194us/step - loss: 1.4793 - accuracy: 0.7957 - val_loss: 0.9129 - val_accuracy: 0.9505\n",
      "Epoch 75/100\n",
      "470/470 [==============================] - 0s 139us/step - loss: 1.4453 - accuracy: 0.8128 - val_loss: 0.8369 - val_accuracy: 0.9653\n",
      "Epoch 76/100\n",
      "470/470 [==============================] - 0s 135us/step - loss: 1.3803 - accuracy: 0.8043 - val_loss: 0.8535 - val_accuracy: 0.9554\n",
      "Epoch 77/100\n",
      "470/470 [==============================] - 0s 167us/step - loss: 1.4189 - accuracy: 0.7766 - val_loss: 0.8406 - val_accuracy: 0.9703\n",
      "Epoch 78/100\n",
      "470/470 [==============================] - 0s 200us/step - loss: 1.5346 - accuracy: 0.7553 - val_loss: 0.8669 - val_accuracy: 0.9554\n",
      "Epoch 79/100\n",
      "470/470 [==============================] - 0s 137us/step - loss: 1.4556 - accuracy: 0.7787 - val_loss: 0.7424 - val_accuracy: 0.9505\n",
      "Epoch 80/100\n",
      "470/470 [==============================] - 0s 138us/step - loss: 1.6760 - accuracy: 0.7745 - val_loss: 0.7748 - val_accuracy: 0.9653\n",
      "Epoch 81/100\n",
      "470/470 [==============================] - 0s 146us/step - loss: 1.6259 - accuracy: 0.7426 - val_loss: 0.8818 - val_accuracy: 0.9554\n",
      "Epoch 82/100\n",
      "470/470 [==============================] - 0s 132us/step - loss: 1.4912 - accuracy: 0.7681 - val_loss: 0.8775 - val_accuracy: 0.9752\n",
      "Epoch 83/100\n",
      "470/470 [==============================] - 0s 132us/step - loss: 1.1914 - accuracy: 0.8213 - val_loss: 0.7939 - val_accuracy: 0.9554\n",
      "Epoch 84/100\n",
      "470/470 [==============================] - 0s 133us/step - loss: 1.4278 - accuracy: 0.8021 - val_loss: 0.7395 - val_accuracy: 0.9703\n",
      "Epoch 85/100\n",
      "470/470 [==============================] - 0s 136us/step - loss: 1.2974 - accuracy: 0.7851 - val_loss: 0.7968 - val_accuracy: 0.9604\n",
      "Epoch 86/100\n",
      "470/470 [==============================] - 0s 224us/step - loss: 1.3247 - accuracy: 0.8213 - val_loss: 0.7821 - val_accuracy: 0.9703\n",
      "Epoch 87/100\n",
      "470/470 [==============================] - 0s 208us/step - loss: 1.3119 - accuracy: 0.8000 - val_loss: 0.7521 - val_accuracy: 0.9703\n",
      "Epoch 88/100\n",
      "470/470 [==============================] - 0s 172us/step - loss: 1.4329 - accuracy: 0.7766 - val_loss: 0.7896 - val_accuracy: 0.9653\n",
      "Epoch 89/100\n",
      "470/470 [==============================] - 0s 134us/step - loss: 1.3637 - accuracy: 0.7936 - val_loss: 0.7685 - val_accuracy: 0.9604\n",
      "Epoch 90/100\n",
      "470/470 [==============================] - 0s 180us/step - loss: 1.3510 - accuracy: 0.7936 - val_loss: 0.7508 - val_accuracy: 0.9752\n",
      "Epoch 91/100\n",
      "470/470 [==============================] - 0s 374us/step - loss: 1.4683 - accuracy: 0.7894 - val_loss: 0.7079 - val_accuracy: 0.9703\n",
      "Epoch 92/100\n",
      "470/470 [==============================] - 0s 183us/step - loss: 1.4305 - accuracy: 0.7979 - val_loss: 0.7396 - val_accuracy: 0.9703\n",
      "Epoch 93/100\n",
      "470/470 [==============================] - 0s 157us/step - loss: 1.2780 - accuracy: 0.7894 - val_loss: 0.7983 - val_accuracy: 0.9554\n",
      "Epoch 94/100\n",
      "470/470 [==============================] - 0s 213us/step - loss: 1.4770 - accuracy: 0.7681 - val_loss: 0.7609 - val_accuracy: 0.9703\n",
      "Epoch 95/100\n",
      "470/470 [==============================] - 0s 215us/step - loss: 1.2398 - accuracy: 0.7830 - val_loss: 0.7503 - val_accuracy: 0.9653\n",
      "Epoch 96/100\n",
      "470/470 [==============================] - 0s 163us/step - loss: 1.4241 - accuracy: 0.7872 - val_loss: 0.8322 - val_accuracy: 0.9505\n",
      "Epoch 97/100\n",
      "470/470 [==============================] - 0s 138us/step - loss: 1.2537 - accuracy: 0.7809 - val_loss: 0.7033 - val_accuracy: 0.9604\n",
      "Epoch 98/100\n",
      "470/470 [==============================] - ETA: 0s - loss: 1.3265 - accuracy: 0.77 - 0s 249us/step - loss: 1.4386 - accuracy: 0.7745 - val_loss: 0.8246 - val_accuracy: 0.9703\n",
      "Epoch 99/100\n",
      "470/470 [==============================] - 0s 337us/step - loss: 1.2476 - accuracy: 0.8021 - val_loss: 0.7215 - val_accuracy: 0.9703\n",
      "Epoch 100/100\n",
      "470/470 [==============================] - 0s 233us/step - loss: 1.2347 - accuracy: 0.7851 - val_loss: 0.9269 - val_accuracy: 0.9455\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a3fc36048>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over8.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202/202 [==============================] - 0s 122us/step\n",
      "over-sampling test accuracy: 96.04%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over8 = model1_over8.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over8*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 2, 1, 2, 2, 2, 1, 1, 1, 1, 1, 2, 0, 2, 1, 1, 1, 0, 0, 2,\n",
       "       1, 0, 2, 0, 1, 1, 1, 1, 2, 1, 0, 0, 1, 0, 1, 2, 2, 0, 2, 2, 2, 2,\n",
       "       2, 2, 0, 0, 2, 2, 1, 1, 1, 0, 0, 2, 0, 2, 0, 1, 2, 0, 2, 1, 0, 2,\n",
       "       0, 1, 0, 2, 2, 0, 2, 1, 0, 2, 2, 2, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1,\n",
       "       1, 0, 1, 1, 0, 0, 2, 2, 0, 1, 1, 0, 0, 0, 2, 0, 1, 2, 0, 2, 0, 1,\n",
       "       1, 2, 2, 2, 2, 1, 0, 1, 1, 2, 0, 0, 0, 0, 0, 1, 1, 2, 2, 1, 2, 0,\n",
       "       0, 2, 1, 0, 2, 2, 2, 2, 0, 1, 2, 2, 2, 0, 1, 0, 1, 2, 1, 0, 0, 2,\n",
       "       1, 0, 0, 0, 2, 1, 0, 0, 0, 2, 2, 2, 2, 2, 1, 1, 1, 1, 2, 0, 0, 0,\n",
       "       2, 1, 2, 0, 1, 2, 2, 1, 0, 2, 1, 2, 2, 2, 0, 0, 1, 0, 0, 2, 2, 2,\n",
       "       1, 0, 0, 2])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred8 = model1_over8.predict_classes(X_test_over)\n",
    "pred8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CA541</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SR3585</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS232</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS180</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>NRS035</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>506</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>SR2091</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>NRS205</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0  test  pred\n",
       "0     CA541     1     1\n",
       "1    SR3585     0     0\n",
       "2    NRS232     1     1\n",
       "3    NRS148     2     2\n",
       "4    NRS180     1     1\n",
       "..      ...   ...   ...\n",
       "197  NRS209     2     2\n",
       "198  NRS035     1     1\n",
       "199     506     0     0\n",
       "200  SR2091     0     0\n",
       "201  NRS205     1     2\n",
       "\n",
       "[202 rows x 3 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat8['pred'] = pred8\n",
    "dat8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba8 = model1_over8.predict_proba(X_test_over)\n",
    "dat_proba8 = pd.DataFrame(proba8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.991661e-03</td>\n",
       "      <td>9.936008e-01</td>\n",
       "      <td>1.407441e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.557761e-13</td>\n",
       "      <td>1.481728e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.490590e-07</td>\n",
       "      <td>9.999998e-01</td>\n",
       "      <td>5.866913e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.942835e-08</td>\n",
       "      <td>2.896774e-07</td>\n",
       "      <td>9.999996e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.009407e-07</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>3.121069e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>6.620966e-08</td>\n",
       "      <td>7.176374e-08</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>2.811108e-06</td>\n",
       "      <td>9.999971e-01</td>\n",
       "      <td>4.550159e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.385389e-14</td>\n",
       "      <td>5.528073e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>9.998230e-01</td>\n",
       "      <td>1.704668e-04</td>\n",
       "      <td>6.498075e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>2.171607e-05</td>\n",
       "      <td>8.484899e-05</td>\n",
       "      <td>9.998934e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0             1             2\n",
       "0    4.991661e-03  9.936008e-01  1.407441e-03\n",
       "1    1.000000e+00  4.557761e-13  1.481728e-12\n",
       "2    2.490590e-07  9.999998e-01  5.866913e-08\n",
       "3    3.942835e-08  2.896774e-07  9.999996e-01\n",
       "4    1.009407e-07  9.999999e-01  3.121069e-08\n",
       "..            ...           ...           ...\n",
       "197  6.620966e-08  7.176374e-08  9.999999e-01\n",
       "198  2.811108e-06  9.999971e-01  4.550159e-08\n",
       "199  1.000000e+00  2.385389e-14  5.528073e-14\n",
       "200  9.998230e-01  1.704668e-04  6.498075e-06\n",
       "201  2.171607e-05  8.484899e-05  9.998934e-01\n",
       "\n",
       "[202 rows x 3 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba8.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba8.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat8.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/8p003ppST.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 470 samples, validate on 202 samples\n",
      "Epoch 1/100\n",
      "470/470 [==============================] - 0s 219us/step - loss: 1.0719 - accuracy: 0.8383 - val_loss: 0.5484 - val_accuracy: 0.9752\n",
      "Epoch 2/100\n",
      "470/470 [==============================] - 0s 219us/step - loss: 1.0321 - accuracy: 0.8213 - val_loss: 0.5543 - val_accuracy: 0.9752\n",
      "Epoch 3/100\n",
      "470/470 [==============================] - 0s 183us/step - loss: 1.4766 - accuracy: 0.7830 - val_loss: 0.6773 - val_accuracy: 0.9752\n",
      "Epoch 4/100\n",
      "470/470 [==============================] - 0s 196us/step - loss: 1.1797 - accuracy: 0.7915 - val_loss: 0.5983 - val_accuracy: 0.9752\n",
      "Epoch 5/100\n",
      "470/470 [==============================] - 0s 175us/step - loss: 1.2408 - accuracy: 0.7894 - val_loss: 0.6757 - val_accuracy: 0.9752\n",
      "Epoch 6/100\n",
      "470/470 [==============================] - 0s 158us/step - loss: 1.3575 - accuracy: 0.7638 - val_loss: 0.6139 - val_accuracy: 0.9752\n",
      "Epoch 7/100\n",
      "470/470 [==============================] - 0s 185us/step - loss: 1.1229 - accuracy: 0.8085 - val_loss: 0.7369 - val_accuracy: 0.9554\n",
      "Epoch 8/100\n",
      "470/470 [==============================] - 0s 148us/step - loss: 1.4114 - accuracy: 0.7915 - val_loss: 0.8753 - val_accuracy: 0.9554\n",
      "Epoch 9/100\n",
      "470/470 [==============================] - 0s 126us/step - loss: 1.2959 - accuracy: 0.8043 - val_loss: 0.6723 - val_accuracy: 0.9554\n",
      "Epoch 10/100\n",
      "470/470 [==============================] - 0s 126us/step - loss: 1.2403 - accuracy: 0.7936 - val_loss: 0.6652 - val_accuracy: 0.9505\n",
      "Epoch 11/100\n",
      "470/470 [==============================] - 0s 126us/step - loss: 1.2083 - accuracy: 0.7979 - val_loss: 0.6026 - val_accuracy: 0.9752\n",
      "Epoch 12/100\n",
      "470/470 [==============================] - 0s 125us/step - loss: 1.2005 - accuracy: 0.7957 - val_loss: 0.6870 - val_accuracy: 0.9752\n",
      "Epoch 13/100\n",
      "470/470 [==============================] - 0s 131us/step - loss: 1.2277 - accuracy: 0.7894 - val_loss: 0.5939 - val_accuracy: 0.9604\n",
      "Epoch 14/100\n",
      "470/470 [==============================] - 0s 180us/step - loss: 1.1864 - accuracy: 0.7979 - val_loss: 0.5383 - val_accuracy: 0.9752\n",
      "Epoch 15/100\n",
      "470/470 [==============================] - 0s 173us/step - loss: 1.2814 - accuracy: 0.7915 - val_loss: 0.6413 - val_accuracy: 0.9752\n",
      "Epoch 16/100\n",
      "470/470 [==============================] - 0s 183us/step - loss: 1.1248 - accuracy: 0.7745 - val_loss: 0.5388 - val_accuracy: 0.9752\n",
      "Epoch 17/100\n",
      "470/470 [==============================] - 0s 145us/step - loss: 1.0725 - accuracy: 0.8106 - val_loss: 0.5131 - val_accuracy: 0.9752\n",
      "Epoch 18/100\n",
      "470/470 [==============================] - 0s 129us/step - loss: 0.9953 - accuracy: 0.7936 - val_loss: 0.5706 - val_accuracy: 0.9752\n",
      "Epoch 19/100\n",
      "470/470 [==============================] - 0s 191us/step - loss: 1.2331 - accuracy: 0.7681 - val_loss: 0.5993 - val_accuracy: 0.9752\n",
      "Epoch 20/100\n",
      "470/470 [==============================] - 0s 215us/step - loss: 1.2064 - accuracy: 0.7681 - val_loss: 0.6133 - val_accuracy: 0.9752\n",
      "Epoch 21/100\n",
      "470/470 [==============================] - 0s 181us/step - loss: 1.0260 - accuracy: 0.8021 - val_loss: 0.5646 - val_accuracy: 0.9653\n",
      "Epoch 22/100\n",
      "470/470 [==============================] - 0s 155us/step - loss: 1.1397 - accuracy: 0.8021 - val_loss: 0.6237 - val_accuracy: 0.9653\n",
      "Epoch 23/100\n",
      "470/470 [==============================] - 0s 154us/step - loss: 1.0742 - accuracy: 0.7489 - val_loss: 0.5814 - val_accuracy: 0.9752\n",
      "Epoch 24/100\n",
      "470/470 [==============================] - 0s 207us/step - loss: 1.2196 - accuracy: 0.7787 - val_loss: 0.5606 - val_accuracy: 0.9703\n",
      "Epoch 25/100\n",
      "470/470 [==============================] - 0s 242us/step - loss: 1.2102 - accuracy: 0.7787 - val_loss: 0.5495 - val_accuracy: 0.9703\n",
      "Epoch 26/100\n",
      "470/470 [==============================] - 0s 147us/step - loss: 1.0295 - accuracy: 0.8170 - val_loss: 0.5455 - val_accuracy: 0.9703\n",
      "Epoch 27/100\n",
      "470/470 [==============================] - 0s 132us/step - loss: 1.2775 - accuracy: 0.7745 - val_loss: 0.4957 - val_accuracy: 0.9752\n",
      "Epoch 28/100\n",
      "470/470 [==============================] - 0s 137us/step - loss: 1.1578 - accuracy: 0.7894 - val_loss: 0.6079 - val_accuracy: 0.9653\n",
      "Epoch 29/100\n",
      "470/470 [==============================] - 0s 150us/step - loss: 1.1199 - accuracy: 0.7766 - val_loss: 0.5536 - val_accuracy: 0.9752\n",
      "Epoch 30/100\n",
      "470/470 [==============================] - 0s 424us/step - loss: 1.1597 - accuracy: 0.8085 - val_loss: 0.4432 - val_accuracy: 0.9752\n",
      "Epoch 31/100\n",
      "470/470 [==============================] - 0s 245us/step - loss: 0.9288 - accuracy: 0.8191 - val_loss: 0.4437 - val_accuracy: 0.9752\n",
      "Epoch 32/100\n",
      "470/470 [==============================] - 0s 266us/step - loss: 0.9790 - accuracy: 0.7681 - val_loss: 0.5403 - val_accuracy: 0.9752\n",
      "Epoch 33/100\n",
      "470/470 [==============================] - 0s 266us/step - loss: 1.0805 - accuracy: 0.7872 - val_loss: 0.4719 - val_accuracy: 0.9752\n",
      "Epoch 34/100\n",
      "470/470 [==============================] - 0s 611us/step - loss: 1.1518 - accuracy: 0.7574 - val_loss: 0.5014 - val_accuracy: 0.9653\n",
      "Epoch 35/100\n",
      "470/470 [==============================] - 0s 378us/step - loss: 1.0611 - accuracy: 0.7915 - val_loss: 0.4894 - val_accuracy: 0.9752\n",
      "Epoch 36/100\n",
      "470/470 [==============================] - 0s 231us/step - loss: 0.9315 - accuracy: 0.8064 - val_loss: 0.5041 - val_accuracy: 0.9752\n",
      "Epoch 37/100\n",
      "470/470 [==============================] - 0s 436us/step - loss: 1.0871 - accuracy: 0.7872 - val_loss: 0.4844 - val_accuracy: 0.9752\n",
      "Epoch 38/100\n",
      "470/470 [==============================] - 0s 260us/step - loss: 1.1535 - accuracy: 0.8021 - val_loss: 0.4684 - val_accuracy: 0.9703\n",
      "Epoch 39/100\n",
      "470/470 [==============================] - 0s 235us/step - loss: 1.2661 - accuracy: 0.7872 - val_loss: 0.4928 - val_accuracy: 0.9752\n",
      "Epoch 40/100\n",
      "470/470 [==============================] - 0s 214us/step - loss: 1.1281 - accuracy: 0.8021 - val_loss: 0.4454 - val_accuracy: 0.9752\n",
      "Epoch 41/100\n",
      "470/470 [==============================] - 0s 198us/step - loss: 1.1028 - accuracy: 0.7723 - val_loss: 0.5256 - val_accuracy: 0.9752\n",
      "Epoch 42/100\n",
      "470/470 [==============================] - 0s 206us/step - loss: 0.9867 - accuracy: 0.8170 - val_loss: 0.4575 - val_accuracy: 0.9653\n",
      "Epoch 43/100\n",
      "470/470 [==============================] - 0s 148us/step - loss: 1.0480 - accuracy: 0.7830 - val_loss: 0.5273 - val_accuracy: 0.9752\n",
      "Epoch 44/100\n",
      "470/470 [==============================] - 0s 140us/step - loss: 1.0905 - accuracy: 0.7681 - val_loss: 0.4581 - val_accuracy: 0.9752\n",
      "Epoch 45/100\n",
      "470/470 [==============================] - 0s 136us/step - loss: 1.0546 - accuracy: 0.7979 - val_loss: 0.4786 - val_accuracy: 0.9653\n",
      "Epoch 46/100\n",
      "470/470 [==============================] - 0s 162us/step - loss: 1.0258 - accuracy: 0.7809 - val_loss: 0.5702 - val_accuracy: 0.9653\n",
      "Epoch 47/100\n",
      "470/470 [==============================] - 0s 134us/step - loss: 1.1211 - accuracy: 0.7723 - val_loss: 0.5182 - val_accuracy: 0.9752\n",
      "Epoch 48/100\n",
      "470/470 [==============================] - 0s 129us/step - loss: 1.1208 - accuracy: 0.8128 - val_loss: 0.4997 - val_accuracy: 0.9703\n",
      "Epoch 49/100\n",
      "470/470 [==============================] - 0s 133us/step - loss: 1.0129 - accuracy: 0.8106 - val_loss: 0.5034 - val_accuracy: 0.9703\n",
      "Epoch 50/100\n",
      "470/470 [==============================] - 0s 317us/step - loss: 1.0263 - accuracy: 0.7745 - val_loss: 0.4332 - val_accuracy: 0.9752\n",
      "Epoch 51/100\n",
      "470/470 [==============================] - 0s 330us/step - loss: 0.7823 - accuracy: 0.8468 - val_loss: 0.4593 - val_accuracy: 0.9752\n",
      "Epoch 52/100\n",
      "470/470 [==============================] - 0s 553us/step - loss: 0.9355 - accuracy: 0.7723 - val_loss: 0.4412 - val_accuracy: 0.9752\n",
      "Epoch 53/100\n",
      "470/470 [==============================] - 0s 273us/step - loss: 0.9446 - accuracy: 0.8106 - val_loss: 0.4623 - val_accuracy: 0.9752\n",
      "Epoch 54/100\n",
      "470/470 [==============================] - 0s 262us/step - loss: 0.9074 - accuracy: 0.7894 - val_loss: 0.4218 - val_accuracy: 0.9752\n",
      "Epoch 55/100\n",
      "470/470 [==============================] - 0s 262us/step - loss: 0.9782 - accuracy: 0.7936 - val_loss: 0.4621 - val_accuracy: 0.9752\n",
      "Epoch 56/100\n",
      "470/470 [==============================] - 0s 245us/step - loss: 1.1728 - accuracy: 0.7745 - val_loss: 0.4409 - val_accuracy: 0.9752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "470/470 [==============================] - 0s 235us/step - loss: 1.0470 - accuracy: 0.8149 - val_loss: 0.4288 - val_accuracy: 0.9703\n",
      "Epoch 58/100\n",
      "470/470 [==============================] - 0s 213us/step - loss: 0.9319 - accuracy: 0.7894 - val_loss: 0.4286 - val_accuracy: 0.9752\n",
      "Epoch 59/100\n",
      "470/470 [==============================] - 0s 235us/step - loss: 1.0923 - accuracy: 0.7809 - val_loss: 0.4331 - val_accuracy: 0.9752\n",
      "Epoch 60/100\n",
      "470/470 [==============================] - 0s 235us/step - loss: 0.8219 - accuracy: 0.8340 - val_loss: 0.4139 - val_accuracy: 0.9752\n",
      "Epoch 61/100\n",
      "470/470 [==============================] - 0s 213us/step - loss: 0.8618 - accuracy: 0.8298 - val_loss: 0.4557 - val_accuracy: 0.9752\n",
      "Epoch 62/100\n",
      "470/470 [==============================] - 0s 245us/step - loss: 0.7571 - accuracy: 0.8255 - val_loss: 0.4303 - val_accuracy: 0.9703\n",
      "Epoch 63/100\n",
      "470/470 [==============================] - 0s 251us/step - loss: 0.9343 - accuracy: 0.8255 - val_loss: 0.4232 - val_accuracy: 0.9752\n",
      "Epoch 64/100\n",
      "470/470 [==============================] - 0s 227us/step - loss: 0.8359 - accuracy: 0.8085 - val_loss: 0.4543 - val_accuracy: 0.9752\n",
      "Epoch 65/100\n",
      "470/470 [==============================] - 0s 230us/step - loss: 0.9526 - accuracy: 0.8106 - val_loss: 0.4521 - val_accuracy: 0.9752\n",
      "Epoch 66/100\n",
      "470/470 [==============================] - 0s 254us/step - loss: 0.8342 - accuracy: 0.7830 - val_loss: 0.4294 - val_accuracy: 0.9752\n",
      "Epoch 67/100\n",
      "470/470 [==============================] - 0s 252us/step - loss: 1.0180 - accuracy: 0.8021 - val_loss: 0.5568 - val_accuracy: 0.9505\n",
      "Epoch 68/100\n",
      "470/470 [==============================] - 0s 367us/step - loss: 1.0885 - accuracy: 0.7702 - val_loss: 0.4229 - val_accuracy: 0.9752\n",
      "Epoch 69/100\n",
      "470/470 [==============================] - 0s 238us/step - loss: 1.0084 - accuracy: 0.8106 - val_loss: 0.4172 - val_accuracy: 0.9752\n",
      "Epoch 70/100\n",
      "470/470 [==============================] - 0s 238us/step - loss: 0.8488 - accuracy: 0.7809 - val_loss: 0.4158 - val_accuracy: 0.9752\n",
      "Epoch 71/100\n",
      "470/470 [==============================] - 0s 229us/step - loss: 1.0248 - accuracy: 0.7787 - val_loss: 0.4449 - val_accuracy: 0.9653\n",
      "Epoch 72/100\n",
      "470/470 [==============================] - 0s 268us/step - loss: 0.9346 - accuracy: 0.8149 - val_loss: 0.4125 - val_accuracy: 0.9653\n",
      "Epoch 73/100\n",
      "470/470 [==============================] - 0s 254us/step - loss: 0.9706 - accuracy: 0.7723 - val_loss: 0.4197 - val_accuracy: 0.9752\n",
      "Epoch 74/100\n",
      "470/470 [==============================] - 0s 264us/step - loss: 0.9038 - accuracy: 0.7830 - val_loss: 0.4690 - val_accuracy: 0.9703\n",
      "Epoch 75/100\n",
      "470/470 [==============================] - 0s 255us/step - loss: 0.7147 - accuracy: 0.8106 - val_loss: 0.4481 - val_accuracy: 0.9703\n",
      "Epoch 76/100\n",
      "470/470 [==============================] - 0s 369us/step - loss: 0.8202 - accuracy: 0.8106 - val_loss: 0.4086 - val_accuracy: 0.9752\n",
      "Epoch 77/100\n",
      "470/470 [==============================] - 0s 230us/step - loss: 0.8324 - accuracy: 0.7957 - val_loss: 0.4067 - val_accuracy: 0.9752\n",
      "Epoch 78/100\n",
      "470/470 [==============================] - 0s 245us/step - loss: 0.9112 - accuracy: 0.8149 - val_loss: 0.4274 - val_accuracy: 0.9703\n",
      "Epoch 79/100\n",
      "470/470 [==============================] - 0s 222us/step - loss: 0.9100 - accuracy: 0.8043 - val_loss: 0.4212 - val_accuracy: 0.9752\n",
      "Epoch 80/100\n",
      "470/470 [==============================] - 0s 238us/step - loss: 0.8891 - accuracy: 0.7872 - val_loss: 0.4159 - val_accuracy: 0.9752\n",
      "Epoch 81/100\n",
      "470/470 [==============================] - 0s 229us/step - loss: 0.9990 - accuracy: 0.8085 - val_loss: 0.4157 - val_accuracy: 0.9752\n",
      "Epoch 82/100\n",
      "470/470 [==============================] - 0s 242us/step - loss: 0.8402 - accuracy: 0.8064 - val_loss: 0.4004 - val_accuracy: 0.9752\n",
      "Epoch 83/100\n",
      "470/470 [==============================] - 0s 216us/step - loss: 0.9813 - accuracy: 0.7723 - val_loss: 0.4296 - val_accuracy: 0.9752\n",
      "Epoch 84/100\n",
      "470/470 [==============================] - 0s 233us/step - loss: 0.8718 - accuracy: 0.8106 - val_loss: 0.4126 - val_accuracy: 0.9752\n",
      "Epoch 85/100\n",
      "470/470 [==============================] - 0s 232us/step - loss: 1.0058 - accuracy: 0.8000 - val_loss: 0.4322 - val_accuracy: 0.9752\n",
      "Epoch 86/100\n",
      "470/470 [==============================] - 0s 243us/step - loss: 0.9673 - accuracy: 0.7723 - val_loss: 0.4069 - val_accuracy: 0.9752\n",
      "Epoch 87/100\n",
      "470/470 [==============================] - 0s 251us/step - loss: 0.7438 - accuracy: 0.8191 - val_loss: 0.4022 - val_accuracy: 0.9752\n",
      "Epoch 88/100\n",
      "470/470 [==============================] - 0s 198us/step - loss: 1.0021 - accuracy: 0.7617 - val_loss: 0.4072 - val_accuracy: 0.9752\n",
      "Epoch 89/100\n",
      "470/470 [==============================] - 0s 238us/step - loss: 1.0114 - accuracy: 0.7957 - val_loss: 0.4004 - val_accuracy: 0.9752\n",
      "Epoch 90/100\n",
      "470/470 [==============================] - 0s 214us/step - loss: 0.9374 - accuracy: 0.7851 - val_loss: 0.4103 - val_accuracy: 0.9752\n",
      "Epoch 91/100\n",
      "470/470 [==============================] - 0s 211us/step - loss: 0.9941 - accuracy: 0.7617 - val_loss: 0.4099 - val_accuracy: 0.9752\n",
      "Epoch 92/100\n",
      "470/470 [==============================] - 0s 215us/step - loss: 0.8754 - accuracy: 0.7936 - val_loss: 0.4000 - val_accuracy: 0.9752\n",
      "Epoch 93/100\n",
      "470/470 [==============================] - 0s 222us/step - loss: 0.9188 - accuracy: 0.7979 - val_loss: 0.4036 - val_accuracy: 0.9752\n",
      "Epoch 94/100\n",
      "470/470 [==============================] - 0s 247us/step - loss: 0.8792 - accuracy: 0.7979 - val_loss: 0.4078 - val_accuracy: 0.9752\n",
      "Epoch 95/100\n",
      "470/470 [==============================] - 0s 197us/step - loss: 0.7357 - accuracy: 0.8000 - val_loss: 0.3945 - val_accuracy: 0.9752\n",
      "Epoch 96/100\n",
      "470/470 [==============================] - 0s 203us/step - loss: 0.9565 - accuracy: 0.7851 - val_loss: 0.3972 - val_accuracy: 0.9752\n",
      "Epoch 97/100\n",
      "470/470 [==============================] - 0s 222us/step - loss: 0.9176 - accuracy: 0.7702 - val_loss: 0.4080 - val_accuracy: 0.9752\n",
      "Epoch 98/100\n",
      "470/470 [==============================] - 0s 361us/step - loss: 0.7457 - accuracy: 0.8191 - val_loss: 0.4000 - val_accuracy: 0.9752\n",
      "Epoch 99/100\n",
      "470/470 [==============================] - 0s 449us/step - loss: 0.9119 - accuracy: 0.7745 - val_loss: 0.3971 - val_accuracy: 0.9752\n",
      "Epoch 100/100\n",
      "470/470 [==============================] - 0s 344us/step - loss: 0.9697 - accuracy: 0.8064 - val_loss: 0.3900 - val_accuracy: 0.9752\n"
     ]
    }
   ],
   "source": [
    "hist1_over8 = model1_over8.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 79.41%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over8.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba8 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_regularizor_dropout_2.xlsx\",\n",
    "                        sheet_name=3,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>CFBREBSa116</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.676203e-01</td>\n",
       "      <td>3.237956e-02</td>\n",
       "      <td>1.480166e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS214</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>6.534852e-11</td>\n",
       "      <td>2.250731e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.948571e-11</td>\n",
       "      <td>2.839096e-07</td>\n",
       "      <td>9.999998e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.948571e-11</td>\n",
       "      <td>2.839096e-07</td>\n",
       "      <td>9.999998e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.948571e-11</td>\n",
       "      <td>2.839096e-07</td>\n",
       "      <td>9.999998e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS205</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.691095e-08</td>\n",
       "      <td>3.571927e-08</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>CFBREBSa122</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.261665e-02</td>\n",
       "      <td>9.073822e-01</td>\n",
       "      <td>1.162373e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.174278e-07</td>\n",
       "      <td>9.999995e-01</td>\n",
       "      <td>3.254024e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.234670e-08</td>\n",
       "      <td>3.121212e-08</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS265</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.250178e-08</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>6.719974e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1982 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       phage       strain  phenotype  prediction  \\\n",
       "0     p002ykpresabsSTCC_qual  CFBREBSa116          0           0   \n",
       "1     p002ykpresabsSTCC_qual       NRS214          0           0   \n",
       "2     p002ykpresabsSTCC_qual       NRS148          2           2   \n",
       "3     p002ykpresabsSTCC_qual       NRS148          2           2   \n",
       "4     p002ykpresabsSTCC_qual       NRS148          2           2   \n",
       "...                      ...          ...        ...         ...   \n",
       "1977     pyopresabsSTCC_qual       NRS205          2           2   \n",
       "1978     pyopresabsSTCC_qual  CFBREBSa122          0           1   \n",
       "1979     pyopresabsSTCC_qual       NRS001          1           1   \n",
       "1980     pyopresabsSTCC_qual       NRS148          2           2   \n",
       "1981     pyopresabsSTCC_qual       NRS265          1           1   \n",
       "\n",
       "                 0             1             2  \n",
       "0     9.676203e-01  3.237956e-02  1.480166e-07  \n",
       "1     1.000000e+00  6.534852e-11  2.250731e-18  \n",
       "2     3.948571e-11  2.839096e-07  9.999998e-01  \n",
       "3     3.948571e-11  2.839096e-07  9.999998e-01  \n",
       "4     3.948571e-11  2.839096e-07  9.999998e-01  \n",
       "...            ...           ...           ...  \n",
       "1977  3.691095e-08  3.571927e-08  9.999999e-01  \n",
       "1978  9.261665e-02  9.073822e-01  1.162373e-06  \n",
       "1979  4.174278e-07  9.999995e-01  3.254024e-09  \n",
       "1980  3.234670e-08  3.121212e-08  9.999999e-01  \n",
       "1981  5.250178e-08  9.999999e-01  6.719974e-08  \n",
       "\n",
       "[1982 rows x 7 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.99166130e-03, 9.93600800e-01, 1.40744110e-03],\n",
       "       [1.00000000e+00, 4.55776100e-13, 1.48172820e-12],\n",
       "       [2.49058960e-07, 9.99999760e-01, 5.86691300e-08],\n",
       "       [3.94283470e-08, 2.89677360e-07, 9.99999640e-01],\n",
       "       [1.00940724e-07, 9.99999900e-01, 3.12106900e-08],\n",
       "       [3.94283470e-08, 2.89677360e-07, 9.99999640e-01],\n",
       "       [1.39685300e-01, 2.17175500e-01, 6.43139240e-01],\n",
       "       [2.17160500e-05, 8.48488340e-05, 9.99893400e-01],\n",
       "       [1.38310700e-09, 1.00000000e+00, 8.87733500e-09],\n",
       "       [4.45697970e-03, 9.94991840e-01, 5.51207400e-04],\n",
       "       [2.78522840e-08, 1.00000000e+00, 1.67346470e-08],\n",
       "       [5.03987800e-04, 9.99466960e-01, 2.91018460e-05],\n",
       "       [4.98125630e-08, 1.00000000e+00, 1.12339960e-08],\n",
       "       [6.62096600e-08, 7.17637400e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 2.99266930e-13, 3.16722530e-13],\n",
       "       [3.94283470e-08, 2.89677360e-07, 9.99999640e-01],\n",
       "       [3.52401630e-08, 1.00000000e+00, 4.19378240e-08],\n",
       "       [5.03987800e-04, 9.99466960e-01, 2.91018460e-05],\n",
       "       [5.03987800e-04, 9.99466960e-01, 2.91018460e-05],\n",
       "       [1.00000000e+00, 5.55311620e-15, 2.30438670e-14],\n",
       "       [1.00000000e+00, 1.78987760e-12, 6.16433640e-12],\n",
       "       [1.39685300e-01, 2.17175500e-01, 6.43139240e-01],\n",
       "       [2.78522840e-08, 1.00000000e+00, 1.67346470e-08],\n",
       "       [7.77024200e-01, 2.22973560e-01, 2.21465260e-06],\n",
       "       [3.94283470e-08, 2.89677360e-07, 9.99999640e-01],\n",
       "       [1.00000000e+00, 1.30092980e-14, 3.14444700e-14],\n",
       "       [4.45697970e-03, 9.94991840e-01, 5.51207400e-04],\n",
       "       [1.38310700e-09, 1.00000000e+00, 8.87733500e-09],\n",
       "       [5.79869200e-09, 1.00000000e+00, 8.18467200e-10],\n",
       "       [1.87601560e-08, 1.00000000e+00, 3.15663120e-08],\n",
       "       [6.62096600e-08, 7.17637400e-08, 9.99999900e-01],\n",
       "       [6.40696240e-08, 9.99999900e-01, 5.45481130e-09],\n",
       "       [1.00000000e+00, 8.17073400e-16, 1.39894140e-16],\n",
       "       [1.00000000e+00, 1.93071670e-13, 5.56841630e-13],\n",
       "       [1.21581800e-08, 1.00000000e+00, 2.97587650e-10],\n",
       "       [1.00000000e+00, 2.27591660e-17, 1.54643260e-16],\n",
       "       [1.00940724e-07, 9.99999900e-01, 3.12106900e-08],\n",
       "       [6.62096600e-08, 7.17637400e-08, 9.99999900e-01],\n",
       "       [1.39685300e-01, 2.17175500e-01, 6.43139240e-01],\n",
       "       [9.99622700e-01, 3.77249320e-04, 9.35515000e-09],\n",
       "       [6.62096600e-08, 7.17637400e-08, 9.99999900e-01],\n",
       "       [1.39685300e-01, 2.17175500e-01, 6.43139240e-01],\n",
       "       [6.62096600e-08, 7.17637400e-08, 9.99999900e-01],\n",
       "       [6.62096600e-08, 7.17637400e-08, 9.99999900e-01],\n",
       "       [1.39685300e-01, 2.17175500e-01, 6.43139240e-01],\n",
       "       [3.94283470e-08, 2.89677360e-07, 9.99999640e-01],\n",
       "       [1.00000000e+00, 5.79454600e-09, 3.37372320e-11],\n",
       "       [9.99899500e-01, 1.00250790e-04, 2.75365950e-07],\n",
       "       [6.62096600e-08, 7.17637400e-08, 9.99999900e-01],\n",
       "       [1.39685300e-01, 2.17175500e-01, 6.43139240e-01],\n",
       "       [4.99166130e-03, 9.93600800e-01, 1.40744110e-03],\n",
       "       [6.40696240e-08, 9.99999900e-01, 5.45481130e-09],\n",
       "       [1.06906420e-04, 9.99892100e-01, 9.23419860e-07],\n",
       "       [1.00000000e+00, 1.75959050e-14, 8.37874500e-15],\n",
       "       [1.00000000e+00, 3.50140230e-09, 1.94397420e-14],\n",
       "       [1.39685300e-01, 2.17175500e-01, 6.43139240e-01],\n",
       "       [9.99956370e-01, 4.36344740e-05, 9.90198900e-09],\n",
       "       [3.94283470e-08, 2.89677360e-07, 9.99999640e-01],\n",
       "       [1.00000000e+00, 3.10591830e-13, 4.51685880e-14],\n",
       "       [5.79869200e-09, 1.00000000e+00, 8.18467200e-10],\n",
       "       [1.39685300e-01, 2.17175500e-01, 6.43139240e-01],\n",
       "       [9.99826000e-01, 1.74069170e-04, 8.92828600e-10],\n",
       "       [3.94283470e-08, 2.89677360e-07, 9.99999640e-01],\n",
       "       [1.38310700e-09, 1.00000000e+00, 8.87733500e-09],\n",
       "       [1.00000000e+00, 2.99266930e-13, 3.16722530e-13],\n",
       "       [1.39685300e-01, 2.17175500e-01, 6.43139240e-01],\n",
       "       [1.00000000e+00, 7.90034650e-10, 1.18745600e-09],\n",
       "       [2.49058960e-07, 9.99999760e-01, 5.86691300e-08],\n",
       "       [9.99999640e-01, 1.10820444e-07, 2.85995500e-07],\n",
       "       [1.39685300e-01, 2.17175500e-01, 6.43139240e-01],\n",
       "       [1.39685300e-01, 2.17175500e-01, 6.43139240e-01],\n",
       "       [1.00000000e+00, 2.45385530e-13, 3.35519500e-12],\n",
       "       [3.94283470e-08, 2.89677360e-07, 9.99999640e-01],\n",
       "       [5.03987800e-04, 9.99466960e-01, 2.91018460e-05],\n",
       "       [9.99999300e-01, 1.37085540e-07, 6.29860200e-07],\n",
       "       [6.62096600e-08, 7.17637400e-08, 9.99999900e-01],\n",
       "       [6.62096600e-08, 7.17637400e-08, 9.99999900e-01],\n",
       "       [3.94283470e-08, 2.89677360e-07, 9.99999640e-01],\n",
       "       [1.00940724e-07, 9.99999900e-01, 3.12106900e-08],\n",
       "       [1.00000000e+00, 7.91820700e-14, 1.87935400e-15],\n",
       "       [1.00000000e+00, 3.38237580e-15, 2.12883270e-14],\n",
       "       [1.00000000e+00, 2.80033730e-14, 1.10911440e-14],\n",
       "       [6.40696240e-08, 9.99999900e-01, 5.45481130e-09],\n",
       "       [4.98125630e-08, 1.00000000e+00, 1.12339960e-08],\n",
       "       [1.00000000e+00, 9.94910900e-12, 3.34879700e-11],\n",
       "       [1.03502450e-01, 8.96491170e-01, 6.25387160e-06],\n",
       "       [9.99781670e-01, 2.18325730e-04, 1.54487770e-12],\n",
       "       [7.08106140e-08, 9.99999900e-01, 2.91199150e-09],\n",
       "       [4.57382600e-01, 5.42617140e-01, 2.37246780e-07],\n",
       "       [1.00000000e+00, 2.57719630e-13, 3.11444570e-15],\n",
       "       [1.00940724e-07, 9.99999900e-01, 3.12106900e-08],\n",
       "       [4.55738060e-08, 9.99999900e-01, 7.65876040e-08],\n",
       "       [1.00000000e+00, 6.52963400e-14, 9.50682840e-15],\n",
       "       [1.00000000e+00, 1.84627790e-13, 2.10264290e-14],\n",
       "       [1.39685300e-01, 2.17175500e-01, 6.43139240e-01],\n",
       "       [3.94283470e-08, 2.89677360e-07, 9.99999640e-01],\n",
       "       [1.00000000e+00, 8.44464200e-10, 8.34893430e-10],\n",
       "       [4.98125630e-08, 1.00000000e+00, 1.12339960e-08],\n",
       "       [4.55738060e-08, 9.99999900e-01, 7.65876040e-08],\n",
       "       [1.00000000e+00, 2.05770590e-38, 2.76151980e-38],\n",
       "       [1.00000000e+00, 1.48731830e-11, 2.52174400e-13],\n",
       "       [1.00000000e+00, 1.01602190e-13, 6.85726200e-15],\n",
       "       [3.94283470e-08, 2.89677360e-07, 9.99999640e-01],\n",
       "       [1.00000000e+00, 5.54051670e-11, 8.10467200e-13],\n",
       "       [5.03987800e-04, 9.99466960e-01, 2.91018460e-05],\n",
       "       [2.17160500e-05, 8.48488340e-05, 9.99893400e-01],\n",
       "       [1.00000000e+00, 2.07808410e-13, 7.10805330e-13],\n",
       "       [1.39685300e-01, 2.17175500e-01, 6.43139240e-01],\n",
       "       [1.00000000e+00, 4.90630960e-09, 1.47014350e-09],\n",
       "       [1.05183830e-03, 9.97963200e-01, 9.84994600e-04],\n",
       "       [4.99166130e-03, 9.93600800e-01, 1.40744110e-03],\n",
       "       [3.94283470e-08, 2.89677360e-07, 9.99999640e-01],\n",
       "       [3.94283470e-08, 2.89677360e-07, 9.99999640e-01],\n",
       "       [6.62096600e-08, 7.17637400e-08, 9.99999900e-01],\n",
       "       [3.94283470e-08, 2.89677360e-07, 9.99999640e-01],\n",
       "       [3.52401630e-08, 1.00000000e+00, 4.19378240e-08],\n",
       "       [1.00000000e+00, 1.85615310e-10, 3.91702450e-10],\n",
       "       [4.98125630e-08, 1.00000000e+00, 1.12339960e-08],\n",
       "       [1.00940724e-07, 9.99999900e-01, 3.12106900e-08],\n",
       "       [6.62096600e-08, 7.17637400e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 4.58976170e-12, 1.43638750e-11],\n",
       "       [1.00000000e+00, 1.07408790e-12, 8.89279000e-13],\n",
       "       [9.99826000e-01, 1.74069170e-04, 8.92828600e-10],\n",
       "       [9.99992970e-01, 6.99658800e-06, 1.12251355e-08],\n",
       "       [1.00000000e+00, 4.23970140e-14, 5.56994300e-14],\n",
       "       [4.99166130e-03, 9.93600800e-01, 1.40744110e-03],\n",
       "       [1.05183830e-03, 9.97963200e-01, 9.84994600e-04],\n",
       "       [6.62096600e-08, 7.17637400e-08, 9.99999900e-01],\n",
       "       [6.62096600e-08, 7.17637400e-08, 9.99999900e-01],\n",
       "       [2.01896100e-08, 1.00000000e+00, 3.61681800e-08],\n",
       "       [3.94283470e-08, 2.89677360e-07, 9.99999640e-01],\n",
       "       [9.99826000e-01, 1.74069170e-04, 8.92828600e-10],\n",
       "       [1.00000000e+00, 2.95034100e-11, 7.70639400e-13],\n",
       "       [3.94283470e-08, 2.89677360e-07, 9.99999640e-01],\n",
       "       [1.07476520e-04, 9.99884370e-01, 8.05882400e-06],\n",
       "       [9.99953400e-01, 4.65122580e-05, 1.13798860e-07],\n",
       "       [6.62096600e-08, 7.17637400e-08, 9.99999900e-01],\n",
       "       [1.39685300e-01, 2.17175500e-01, 6.43139240e-01],\n",
       "       [6.62096600e-08, 7.17637400e-08, 9.99999900e-01],\n",
       "       [1.39685300e-01, 2.17175500e-01, 6.43139240e-01],\n",
       "       [9.99998330e-01, 1.62096520e-06, 4.77181360e-09],\n",
       "       [2.40907190e-08, 9.99999900e-01, 6.64557400e-08],\n",
       "       [3.94283470e-08, 2.89677360e-07, 9.99999640e-01],\n",
       "       [3.94283470e-08, 2.89677360e-07, 9.99999640e-01],\n",
       "       [1.39685300e-01, 2.17175500e-01, 6.43139240e-01],\n",
       "       [9.99826000e-01, 1.74069170e-04, 8.92828600e-10],\n",
       "       [3.52401630e-08, 1.00000000e+00, 4.19378240e-08],\n",
       "       [9.99999900e-01, 1.57208120e-07, 2.79955370e-09],\n",
       "       [4.98125630e-08, 1.00000000e+00, 1.12339960e-08],\n",
       "       [3.94283470e-08, 2.89677360e-07, 9.99999640e-01],\n",
       "       [4.98125630e-08, 1.00000000e+00, 1.12339960e-08],\n",
       "       [9.99999900e-01, 1.44310300e-07, 4.19954880e-10],\n",
       "       [1.00000000e+00, 7.76317500e-10, 2.03250930e-10],\n",
       "       [6.62096600e-08, 7.17637400e-08, 9.99999900e-01],\n",
       "       [1.05183830e-03, 9.97963200e-01, 9.84994600e-04],\n",
       "       [9.94959100e-01, 5.04060140e-03, 1.78365380e-07],\n",
       "       [1.00000000e+00, 2.91047460e-10, 3.24149470e-12],\n",
       "       [1.00000000e+00, 3.62369020e-11, 3.66954830e-10],\n",
       "       [1.39685300e-01, 2.17175500e-01, 6.43139240e-01],\n",
       "       [2.49058960e-07, 9.99999760e-01, 5.86691300e-08],\n",
       "       [1.00000000e+00, 2.98597420e-10, 4.80927940e-11],\n",
       "       [9.99998800e-01, 1.13485450e-06, 5.57054300e-10],\n",
       "       [1.00000000e+00, 3.52341280e-11, 1.21090820e-10],\n",
       "       [1.39685300e-01, 2.17175500e-01, 6.43139240e-01],\n",
       "       [3.94283470e-08, 2.89677360e-07, 9.99999640e-01],\n",
       "       [3.94283470e-08, 2.89677360e-07, 9.99999640e-01],\n",
       "       [3.94283470e-08, 2.89677360e-07, 9.99999640e-01],\n",
       "       [1.39685300e-01, 2.17175500e-01, 6.43139240e-01],\n",
       "       [7.08106140e-08, 9.99999900e-01, 2.91199150e-09],\n",
       "       [3.52401630e-08, 1.00000000e+00, 4.19378240e-08],\n",
       "       [5.79869200e-09, 1.00000000e+00, 8.18467200e-10],\n",
       "       [1.06906420e-04, 9.99892100e-01, 9.23419860e-07],\n",
       "       [3.94283470e-08, 2.89677360e-07, 9.99999640e-01],\n",
       "       [9.99995600e-01, 4.45240600e-06, 6.10940700e-10],\n",
       "       [1.00000000e+00, 1.54791560e-14, 5.72187800e-15],\n",
       "       [1.00000000e+00, 1.45909700e-10, 8.05694200e-12],\n",
       "       [6.62096600e-08, 7.17637400e-08, 9.99999900e-01],\n",
       "       [7.06022430e-07, 9.99999300e-01, 2.87855410e-08],\n",
       "       [3.94283470e-08, 2.89677360e-07, 9.99999640e-01],\n",
       "       [1.00000000e+00, 1.29301780e-34, 3.93670070e-36],\n",
       "       [1.38310700e-09, 1.00000000e+00, 8.87733500e-09],\n",
       "       [3.94283470e-08, 2.89677360e-07, 9.99999640e-01],\n",
       "       [6.62096600e-08, 7.17637400e-08, 9.99999900e-01],\n",
       "       [1.06906420e-04, 9.99892100e-01, 9.23419860e-07],\n",
       "       [1.00000000e+00, 4.47808780e-13, 1.18580200e-12],\n",
       "       [3.94283470e-08, 2.89677360e-07, 9.99999640e-01],\n",
       "       [1.00940724e-07, 9.99999900e-01, 3.12106900e-08],\n",
       "       [6.62096600e-08, 7.17637400e-08, 9.99999900e-01],\n",
       "       [6.62096600e-08, 7.17637400e-08, 9.99999900e-01],\n",
       "       [1.39685300e-01, 2.17175500e-01, 6.43139240e-01],\n",
       "       [1.00000000e+00, 3.88615850e-09, 9.60166100e-15],\n",
       "       [9.99982500e-01, 1.75367100e-05, 2.35369160e-08],\n",
       "       [4.99166870e-03, 9.93600800e-01, 1.40744050e-03],\n",
       "       [9.99996800e-01, 3.16097700e-06, 4.94264540e-08],\n",
       "       [1.00000000e+00, 2.30018350e-11, 7.04930200e-11],\n",
       "       [2.17160700e-05, 8.48489940e-05, 9.99893400e-01],\n",
       "       [1.39685300e-01, 2.17175500e-01, 6.43139240e-01],\n",
       "       [6.62096600e-08, 7.17637400e-08, 9.99999900e-01],\n",
       "       [2.81110800e-06, 9.99997140e-01, 4.55015900e-08],\n",
       "       [1.00000000e+00, 2.38538950e-14, 5.52807350e-14],\n",
       "       [9.99823030e-01, 1.70466800e-04, 6.49807500e-06],\n",
       "       [2.17160700e-05, 8.48489940e-05, 9.99893400e-01]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob8 = df_proba8[df_proba8['phage']=='p003ppresabsSTCC_qual'].iloc[:,-3:]\n",
    "y_prob8 = y_prob8.to_numpy()\n",
    "y_prob8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9808408935713588"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo8 = rocauc_ovo(y_test_over, y_prob8, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9808408935713588"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr8 = rocauc_ovr(y_test_over, y_prob8, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9904814164471759"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovos2 = [ovo5, ovo6, ovo7, ovo8]\n",
    "np.mean(ovos2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00630614460825933"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(ovos2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9904814164471759"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovrs2 = [ovr5, ovr6, ovr7, ovr8]\n",
    "np.mean(ovrs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00630614460825933"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(ovrs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs_reg = [acc_test_over5, acc_test_over6, acc_test_over7, acc_test_over8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling test accuracy regularization mean: 95.42%\n"
     ]
    }
   ],
   "source": [
    "mean_reg = np.mean(accs_reg)\n",
    "print('over-sampling test accuracy regularization mean: %.2f%%' % (mean_reg*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling test accuracy regularization standard deviation: 0.013725901381031714\n"
     ]
    }
   ],
   "source": [
    "std_reg = np.std(accs_reg)\n",
    "print('over-sampling test accuracy regularization standard deviation:', std_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "accs_train_reg = [np.mean(hist1_over5.history['accuracy']), np.mean(hist1_over6.history['accuracy']), np.mean(hist1_over7.history['accuracy']),\n",
    "             np.mean(hist1_over8.history['accuracy'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy regularization mean: 79.12%\n"
     ]
    }
   ],
   "source": [
    "mean_train_reg = np.mean(accs_train_reg)\n",
    "print('over-sampling train accuracy regularization mean: %.2f%%' % (mean_train_reg*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy regularization standard deviation: 0.0036786376\n"
     ]
    }
   ],
   "source": [
    "std_train_reg = np.std(accs_train_reg)\n",
    "print('over-sampling train accuracy regularization standard deviation:', std_train_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
