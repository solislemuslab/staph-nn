{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This file implements neural networks before and after lasso selection for p11kpresabsSTCC_qual with four replicates.\n",
    "## We compute the mean and standarad deviation of training and test accuracies.\n",
    "## We also compute the mean and standard deviation of AUC ROC values for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "import numpy as np\n",
    "seed(100)\n",
    "import tensorflow\n",
    "tensorflow.random.set_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(253, 824)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/p11kpresabsSTCC_qual.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'Unnamed: 0':'id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      2\n",
       "1      1\n",
       "2      2\n",
       "3      2\n",
       "4      2\n",
       "      ..\n",
       "248    2\n",
       "249    1\n",
       "250    2\n",
       "251    2\n",
       "252    2\n",
       "Name: pheno, Length: 253, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pheno']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>TTTTTTGTAATTTT</th>\n",
       "      <th>TTTTTTGTAATTTTT</th>\n",
       "      <th>TTTTTTATTTTGGAT</th>\n",
       "      <th>TTTTTTATTTTGGATAA</th>\n",
       "      <th>TTTTTTATTTTGGATAAAAGGAG</th>\n",
       "      <th>TTTTTTAGTCGTTTTT</th>\n",
       "      <th>TTTTTATCGTTTACT</th>\n",
       "      <th>TTTTTAGTCGTTTTT</th>\n",
       "      <th>TTTTTAGTCGTTTTTT</th>\n",
       "      <th>...</th>\n",
       "      <th>AATCACCCCTT</th>\n",
       "      <th>AAGGGGTGATTT</th>\n",
       "      <th>AAGGGGTGATTTT</th>\n",
       "      <th>AAGATGATTTATCCAACTTT</th>\n",
       "      <th>AACTTTCTAGGTT</th>\n",
       "      <th>AACCTAGAAAGTTT</th>\n",
       "      <th>AACATCTTTTATTT</th>\n",
       "      <th>ST</th>\n",
       "      <th>CC</th>\n",
       "      <th>pheno</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>109</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>120335</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120337</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 824 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  TTTTTTGTAATTTT  TTTTTTGTAATTTTT  TTTTTTATTTTGGAT  \\\n",
       "0     107               0                0                0   \n",
       "1     109               1                1                1   \n",
       "2     115               1                1                1   \n",
       "3  120335               1                1                1   \n",
       "4  120337               1                1                1   \n",
       "\n",
       "   TTTTTTATTTTGGATAA  TTTTTTATTTTGGATAAAAGGAG  TTTTTTAGTCGTTTTT  \\\n",
       "0                  0                        0                 0   \n",
       "1                  1                        1                 1   \n",
       "2                  1                        1                 1   \n",
       "3                  1                        1                 1   \n",
       "4                  1                        1                 1   \n",
       "\n",
       "   TTTTTATCGTTTACT  TTTTTAGTCGTTTTT  TTTTTAGTCGTTTTTT  ...  AATCACCCCTT  \\\n",
       "0                0                0                 0  ...            0   \n",
       "1                1                1                 1  ...            1   \n",
       "2                1                1                 1  ...            1   \n",
       "3                1                1                 1  ...            1   \n",
       "4                1                1                 1  ...            1   \n",
       "\n",
       "   AAGGGGTGATTT  AAGGGGTGATTTT  AAGATGATTTATCCAACTTT  AACTTTCTAGGTT  \\\n",
       "0             0              0                     0              0   \n",
       "1             1              1                     1              1   \n",
       "2             1              1                     1              1   \n",
       "3             1              1                     1              1   \n",
       "4             1              1                     1              1   \n",
       "\n",
       "   AACCTAGAAAGTTT  AACATCTTTTATTT  ST  CC  pheno  \n",
       "0               0               0   5   5      2  \n",
       "1               1               1   8   8      1  \n",
       "2               1               1   5   5      2  \n",
       "3               1               1   5   5      2  \n",
       "4               1               1   5   5      2  \n",
       "\n",
       "[5 rows x 824 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    181\n",
       "1     47\n",
       "0     25\n",
       "Name: pheno, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pheno'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.drop(columns=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(253, 823)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TTTTTTGTAATTTT</th>\n",
       "      <th>TTTTTTGTAATTTTT</th>\n",
       "      <th>TTTTTTATTTTGGAT</th>\n",
       "      <th>TTTTTTATTTTGGATAA</th>\n",
       "      <th>TTTTTTATTTTGGATAAAAGGAG</th>\n",
       "      <th>TTTTTTAGTCGTTTTT</th>\n",
       "      <th>TTTTTATCGTTTACT</th>\n",
       "      <th>TTTTTAGTCGTTTTT</th>\n",
       "      <th>TTTTTAGTCGTTTTTT</th>\n",
       "      <th>TTTTTAGGTAAGG</th>\n",
       "      <th>...</th>\n",
       "      <th>AATCACCCCTT</th>\n",
       "      <th>AAGGGGTGATTT</th>\n",
       "      <th>AAGGGGTGATTTT</th>\n",
       "      <th>AAGATGATTTATCCAACTTT</th>\n",
       "      <th>AACTTTCTAGGTT</th>\n",
       "      <th>AACCTAGAAAGTTT</th>\n",
       "      <th>AACATCTTTTATTT</th>\n",
       "      <th>ST</th>\n",
       "      <th>CC</th>\n",
       "      <th>pheno</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 823 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TTTTTTGTAATTTT  TTTTTTGTAATTTTT  TTTTTTATTTTGGAT  TTTTTTATTTTGGATAA  \\\n",
       "0               0                0                0                  0   \n",
       "1               1                1                1                  1   \n",
       "2               1                1                1                  1   \n",
       "3               1                1                1                  1   \n",
       "4               1                1                1                  1   \n",
       "\n",
       "   TTTTTTATTTTGGATAAAAGGAG  TTTTTTAGTCGTTTTT  TTTTTATCGTTTACT  \\\n",
       "0                        0                 0                0   \n",
       "1                        1                 1                1   \n",
       "2                        1                 1                1   \n",
       "3                        1                 1                1   \n",
       "4                        1                 1                1   \n",
       "\n",
       "   TTTTTAGTCGTTTTT  TTTTTAGTCGTTTTTT  TTTTTAGGTAAGG  ...  AATCACCCCTT  \\\n",
       "0                0                 0              0  ...            0   \n",
       "1                1                 1              1  ...            1   \n",
       "2                1                 1              1  ...            1   \n",
       "3                1                 1              1  ...            1   \n",
       "4                1                 1              1  ...            1   \n",
       "\n",
       "   AAGGGGTGATTT  AAGGGGTGATTTT  AAGATGATTTATCCAACTTT  AACTTTCTAGGTT  \\\n",
       "0             0              0                     0              0   \n",
       "1             1              1                     1              1   \n",
       "2             1              1                     1              1   \n",
       "3             1              1                     1              1   \n",
       "4             1              1                     1              1   \n",
       "\n",
       "   AACCTAGAAAGTTT  AACATCTTTTATTT  ST  CC  pheno  \n",
       "0               0               0   5   5      2  \n",
       "1               1               1   8   8      1  \n",
       "2               1               1   5   5      2  \n",
       "3               1               1   5   5      2  \n",
       "4               1               1   5   5      2  \n",
       "\n",
       "[5 rows x 823 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(253, 823) (253,)\n"
     ]
    }
   ],
   "source": [
    "X = df.loc[:, df.columns != 'pheno']\n",
    "y = df['pheno']\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.ensemble.bagging module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.ensemble.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.ensemble.forest module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 181), (1, 181), (2, 181)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.utils.testing module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.utils. Anything that cannot be imported from sklearn.utils is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.metrics.classification module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# over-sampling\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "overS = RandomOverSampler(random_state=100)\n",
    "X_over, y_over = overS.fit_resample(X, y)\n",
    "print(sorted(Counter(y_over).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# Fully-Connected Neural Network ################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.regularizers import l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=123,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = pd.DataFrame(X_test_over[:,0])\n",
    "dat['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SR1129</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS185</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS243</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BCH-SA-04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>504</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>CFBREBSa131</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>CFBREBSa133</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>NRS256</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>GA48963</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>BCH-SA-07</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test\n",
       "0         SR1129     2\n",
       "1         NRS185     2\n",
       "2         NRS243     1\n",
       "3      BCH-SA-04     0\n",
       "4            504     1\n",
       "..           ...   ...\n",
       "158  CFBREBSa131     2\n",
       "159  CFBREBSa133     1\n",
       "160       NRS256     2\n",
       "161      GA48963     1\n",
       "162    BCH-SA-07     1\n",
       "\n",
       "[163 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### neural network on over-sampling data\n",
    "model1_over = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],)),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 380 samples, validate on 163 samples\n",
      "Epoch 1/100\n",
      "380/380 [==============================] - 0s 509us/step - loss: 9.7014 - accuracy: 0.3368 - val_loss: 4.8091 - val_accuracy: 0.4049\n",
      "Epoch 2/100\n",
      "380/380 [==============================] - 0s 182us/step - loss: 5.0003 - accuracy: 0.3632 - val_loss: 2.6152 - val_accuracy: 0.3558\n",
      "Epoch 3/100\n",
      "380/380 [==============================] - 0s 140us/step - loss: 2.3560 - accuracy: 0.3395 - val_loss: 1.4217 - val_accuracy: 0.4110\n",
      "Epoch 4/100\n",
      "380/380 [==============================] - 0s 166us/step - loss: 1.4706 - accuracy: 0.4632 - val_loss: 1.2999 - val_accuracy: 0.4847\n",
      "Epoch 5/100\n",
      "380/380 [==============================] - 0s 288us/step - loss: 1.2553 - accuracy: 0.5105 - val_loss: 1.1089 - val_accuracy: 0.4479\n",
      "Epoch 6/100\n",
      "380/380 [==============================] - 0s 196us/step - loss: 1.1901 - accuracy: 0.5237 - val_loss: 1.0661 - val_accuracy: 0.5092\n",
      "Epoch 7/100\n",
      "380/380 [==============================] - 0s 176us/step - loss: 1.0650 - accuracy: 0.5605 - val_loss: 1.0338 - val_accuracy: 0.5767\n",
      "Epoch 8/100\n",
      "380/380 [==============================] - ETA: 0s - loss: 1.3455 - accuracy: 0.51 - 0s 135us/step - loss: 1.0243 - accuracy: 0.6079 - val_loss: 0.9213 - val_accuracy: 0.5644\n",
      "Epoch 9/100\n",
      "380/380 [==============================] - 0s 167us/step - loss: 0.8745 - accuracy: 0.6368 - val_loss: 0.8251 - val_accuracy: 0.6380\n",
      "Epoch 10/100\n",
      "380/380 [==============================] - 0s 219us/step - loss: 0.8486 - accuracy: 0.6316 - val_loss: 0.8219 - val_accuracy: 0.6319\n",
      "Epoch 11/100\n",
      "380/380 [==============================] - 0s 225us/step - loss: 0.8035 - accuracy: 0.6395 - val_loss: 0.8171 - val_accuracy: 0.6810\n",
      "Epoch 12/100\n",
      "380/380 [==============================] - 0s 141us/step - loss: 0.7614 - accuracy: 0.6789 - val_loss: 0.7655 - val_accuracy: 0.6933\n",
      "Epoch 13/100\n",
      "380/380 [==============================] - 0s 116us/step - loss: 0.7288 - accuracy: 0.7053 - val_loss: 0.7502 - val_accuracy: 0.7055\n",
      "Epoch 14/100\n",
      "380/380 [==============================] - 0s 175us/step - loss: 0.7313 - accuracy: 0.6895 - val_loss: 0.7672 - val_accuracy: 0.7178\n",
      "Epoch 15/100\n",
      "380/380 [==============================] - 0s 137us/step - loss: 0.6955 - accuracy: 0.7158 - val_loss: 0.7217 - val_accuracy: 0.7178\n",
      "Epoch 16/100\n",
      "380/380 [==============================] - 0s 191us/step - loss: 0.6577 - accuracy: 0.7474 - val_loss: 0.7374 - val_accuracy: 0.7117\n",
      "Epoch 17/100\n",
      "380/380 [==============================] - 0s 339us/step - loss: 0.6632 - accuracy: 0.7263 - val_loss: 0.7389 - val_accuracy: 0.7423\n",
      "Epoch 18/100\n",
      "380/380 [==============================] - 0s 130us/step - loss: 0.6506 - accuracy: 0.7526 - val_loss: 0.6942 - val_accuracy: 0.7117\n",
      "Epoch 19/100\n",
      "380/380 [==============================] - 0s 90us/step - loss: 0.6290 - accuracy: 0.7342 - val_loss: 0.6794 - val_accuracy: 0.7853\n",
      "Epoch 20/100\n",
      "380/380 [==============================] - 0s 87us/step - loss: 0.6103 - accuracy: 0.7711 - val_loss: 0.6839 - val_accuracy: 0.7485\n",
      "Epoch 21/100\n",
      "380/380 [==============================] - 0s 100us/step - loss: 0.5963 - accuracy: 0.7658 - val_loss: 0.6719 - val_accuracy: 0.7669\n",
      "Epoch 22/100\n",
      "380/380 [==============================] - 0s 85us/step - loss: 0.5728 - accuracy: 0.7895 - val_loss: 0.6555 - val_accuracy: 0.7607\n",
      "Epoch 23/100\n",
      "380/380 [==============================] - 0s 94us/step - loss: 0.5573 - accuracy: 0.7974 - val_loss: 0.6611 - val_accuracy: 0.7669\n",
      "Epoch 24/100\n",
      "380/380 [==============================] - 0s 83us/step - loss: 0.5593 - accuracy: 0.7947 - val_loss: 0.6616 - val_accuracy: 0.7730\n",
      "Epoch 25/100\n",
      "380/380 [==============================] - 0s 154us/step - loss: 0.5517 - accuracy: 0.7895 - val_loss: 0.6551 - val_accuracy: 0.7546\n",
      "Epoch 26/100\n",
      "380/380 [==============================] - 0s 158us/step - loss: 0.5334 - accuracy: 0.8079 - val_loss: 0.6533 - val_accuracy: 0.7607\n",
      "Epoch 27/100\n",
      "380/380 [==============================] - 0s 170us/step - loss: 0.5319 - accuracy: 0.8211 - val_loss: 0.6309 - val_accuracy: 0.7669\n",
      "Epoch 28/100\n",
      "380/380 [==============================] - 0s 177us/step - loss: 0.5143 - accuracy: 0.7974 - val_loss: 0.6117 - val_accuracy: 0.7853\n",
      "Epoch 29/100\n",
      "380/380 [==============================] - 0s 159us/step - loss: 0.4945 - accuracy: 0.8316 - val_loss: 0.6143 - val_accuracy: 0.7791\n",
      "Epoch 30/100\n",
      "380/380 [==============================] - 0s 211us/step - loss: 0.5076 - accuracy: 0.8316 - val_loss: 0.6164 - val_accuracy: 0.7730\n",
      "Epoch 31/100\n",
      "380/380 [==============================] - 0s 156us/step - loss: 0.4888 - accuracy: 0.8211 - val_loss: 0.6050 - val_accuracy: 0.7485\n",
      "Epoch 32/100\n",
      "380/380 [==============================] - 0s 189us/step - loss: 0.4794 - accuracy: 0.8316 - val_loss: 0.6053 - val_accuracy: 0.8037\n",
      "Epoch 33/100\n",
      "380/380 [==============================] - 0s 170us/step - loss: 0.4648 - accuracy: 0.8395 - val_loss: 0.5847 - val_accuracy: 0.7914\n",
      "Epoch 34/100\n",
      "380/380 [==============================] - 0s 173us/step - loss: 0.4655 - accuracy: 0.8421 - val_loss: 0.5833 - val_accuracy: 0.7853\n",
      "Epoch 35/100\n",
      "380/380 [==============================] - 0s 152us/step - loss: 0.4595 - accuracy: 0.8395 - val_loss: 0.6006 - val_accuracy: 0.7730\n",
      "Epoch 36/100\n",
      "380/380 [==============================] - 0s 149us/step - loss: 0.4527 - accuracy: 0.8316 - val_loss: 0.5727 - val_accuracy: 0.7791\n",
      "Epoch 37/100\n",
      "380/380 [==============================] - 0s 160us/step - loss: 0.4605 - accuracy: 0.8395 - val_loss: 0.5793 - val_accuracy: 0.8037\n",
      "Epoch 38/100\n",
      "380/380 [==============================] - 0s 151us/step - loss: 0.4461 - accuracy: 0.8658 - val_loss: 0.6406 - val_accuracy: 0.7853\n",
      "Epoch 39/100\n",
      "380/380 [==============================] - 0s 172us/step - loss: 0.4639 - accuracy: 0.8658 - val_loss: 0.5617 - val_accuracy: 0.7975\n",
      "Epoch 40/100\n",
      "380/380 [==============================] - 0s 177us/step - loss: 0.4298 - accuracy: 0.8316 - val_loss: 0.5914 - val_accuracy: 0.7485\n",
      "Epoch 41/100\n",
      "380/380 [==============================] - 0s 173us/step - loss: 0.4357 - accuracy: 0.8737 - val_loss: 0.5745 - val_accuracy: 0.8098\n",
      "Epoch 42/100\n",
      "380/380 [==============================] - 0s 200us/step - loss: 0.4095 - accuracy: 0.8868 - val_loss: 0.5730 - val_accuracy: 0.8098\n",
      "Epoch 43/100\n",
      "380/380 [==============================] - 0s 164us/step - loss: 0.4364 - accuracy: 0.8605 - val_loss: 0.5739 - val_accuracy: 0.8221\n",
      "Epoch 44/100\n",
      "380/380 [==============================] - 0s 171us/step - loss: 0.4165 - accuracy: 0.8789 - val_loss: 0.5750 - val_accuracy: 0.7669\n",
      "Epoch 45/100\n",
      "380/380 [==============================] - 0s 120us/step - loss: 0.3959 - accuracy: 0.8816 - val_loss: 0.5526 - val_accuracy: 0.8098\n",
      "Epoch 46/100\n",
      "380/380 [==============================] - 0s 134us/step - loss: 0.4053 - accuracy: 0.8842 - val_loss: 0.5508 - val_accuracy: 0.7853\n",
      "Epoch 47/100\n",
      "380/380 [==============================] - 0s 173us/step - loss: 0.3891 - accuracy: 0.8868 - val_loss: 0.5499 - val_accuracy: 0.7914\n",
      "Epoch 48/100\n",
      "380/380 [==============================] - 0s 174us/step - loss: 0.3845 - accuracy: 0.8737 - val_loss: 0.5553 - val_accuracy: 0.7975\n",
      "Epoch 49/100\n",
      "380/380 [==============================] - 0s 149us/step - loss: 0.3989 - accuracy: 0.8842 - val_loss: 0.5708 - val_accuracy: 0.7485\n",
      "Epoch 50/100\n",
      "380/380 [==============================] - 0s 98us/step - loss: 0.4081 - accuracy: 0.8658 - val_loss: 0.6292 - val_accuracy: 0.7853\n",
      "Epoch 51/100\n",
      "380/380 [==============================] - 0s 92us/step - loss: 0.4502 - accuracy: 0.8632 - val_loss: 0.6651 - val_accuracy: 0.7485\n",
      "Epoch 52/100\n",
      "380/380 [==============================] - 0s 85us/step - loss: 0.3859 - accuracy: 0.8763 - val_loss: 0.5647 - val_accuracy: 0.7730\n",
      "Epoch 53/100\n",
      "380/380 [==============================] - 0s 84us/step - loss: 0.4004 - accuracy: 0.8579 - val_loss: 0.5843 - val_accuracy: 0.7362\n",
      "Epoch 54/100\n",
      "380/380 [==============================] - 0s 92us/step - loss: 0.3804 - accuracy: 0.8658 - val_loss: 0.5396 - val_accuracy: 0.8098\n",
      "Epoch 55/100\n",
      "380/380 [==============================] - 0s 92us/step - loss: 0.3663 - accuracy: 0.8842 - val_loss: 0.5594 - val_accuracy: 0.7791\n",
      "Epoch 56/100\n",
      "380/380 [==============================] - 0s 86us/step - loss: 0.3626 - accuracy: 0.9026 - val_loss: 0.5499 - val_accuracy: 0.8160\n",
      "Epoch 57/100\n",
      "380/380 [==============================] - 0s 88us/step - loss: 0.3586 - accuracy: 0.8895 - val_loss: 0.5387 - val_accuracy: 0.7853\n",
      "Epoch 58/100\n",
      "380/380 [==============================] - 0s 83us/step - loss: 0.3440 - accuracy: 0.8974 - val_loss: 0.5427 - val_accuracy: 0.7914\n",
      "Epoch 59/100\n",
      "380/380 [==============================] - 0s 82us/step - loss: 0.3491 - accuracy: 0.8842 - val_loss: 0.5479 - val_accuracy: 0.7607\n",
      "Epoch 60/100\n",
      "380/380 [==============================] - 0s 85us/step - loss: 0.3524 - accuracy: 0.8711 - val_loss: 0.6088 - val_accuracy: 0.7914\n",
      "Epoch 61/100\n",
      "380/380 [==============================] - 0s 85us/step - loss: 0.4324 - accuracy: 0.8605 - val_loss: 0.5995 - val_accuracy: 0.7239\n",
      "Epoch 62/100\n",
      "380/380 [==============================] - 0s 84us/step - loss: 0.3683 - accuracy: 0.8500 - val_loss: 0.5734 - val_accuracy: 0.7607\n",
      "Epoch 63/100\n",
      "380/380 [==============================] - 0s 138us/step - loss: 0.3570 - accuracy: 0.8789 - val_loss: 0.5431 - val_accuracy: 0.8037\n",
      "Epoch 64/100\n",
      "380/380 [==============================] - ETA: 0s - loss: 0.3109 - accuracy: 0.93 - 0s 182us/step - loss: 0.3407 - accuracy: 0.8974 - val_loss: 0.5416 - val_accuracy: 0.7607\n",
      "Epoch 65/100\n",
      "380/380 [==============================] - 0s 147us/step - loss: 0.3379 - accuracy: 0.8895 - val_loss: 0.5539 - val_accuracy: 0.7975\n",
      "Epoch 66/100\n",
      "380/380 [==============================] - 0s 176us/step - loss: 0.3619 - accuracy: 0.8868 - val_loss: 0.5263 - val_accuracy: 0.7914\n",
      "Epoch 67/100\n",
      "380/380 [==============================] - 0s 157us/step - loss: 0.3280 - accuracy: 0.8947 - val_loss: 0.5368 - val_accuracy: 0.7914\n",
      "Epoch 68/100\n",
      "380/380 [==============================] - 0s 174us/step - loss: 0.3393 - accuracy: 0.8974 - val_loss: 0.5297 - val_accuracy: 0.8037\n",
      "Epoch 69/100\n",
      "380/380 [==============================] - 0s 166us/step - loss: 0.3214 - accuracy: 0.8921 - val_loss: 0.5448 - val_accuracy: 0.7730\n",
      "Epoch 70/100\n",
      "380/380 [==============================] - 0s 114us/step - loss: 0.3161 - accuracy: 0.9079 - val_loss: 0.5487 - val_accuracy: 0.7914\n",
      "Epoch 71/100\n",
      "380/380 [==============================] - 0s 92us/step - loss: 0.3404 - accuracy: 0.8737 - val_loss: 0.5617 - val_accuracy: 0.7301\n",
      "Epoch 72/100\n",
      "380/380 [==============================] - 0s 87us/step - loss: 0.3311 - accuracy: 0.8737 - val_loss: 0.5394 - val_accuracy: 0.7975\n",
      "Epoch 73/100\n",
      "380/380 [==============================] - 0s 80us/step - loss: 0.3555 - accuracy: 0.8711 - val_loss: 0.5438 - val_accuracy: 0.7423\n",
      "Epoch 74/100\n",
      "380/380 [==============================] - 0s 84us/step - loss: 0.3185 - accuracy: 0.8974 - val_loss: 0.5659 - val_accuracy: 0.7853\n",
      "Epoch 75/100\n",
      "380/380 [==============================] - 0s 87us/step - loss: 0.3389 - accuracy: 0.8868 - val_loss: 0.5312 - val_accuracy: 0.7791\n",
      "Epoch 76/100\n",
      "380/380 [==============================] - 0s 89us/step - loss: 0.3165 - accuracy: 0.8947 - val_loss: 0.5130 - val_accuracy: 0.7975\n",
      "Epoch 77/100\n",
      "380/380 [==============================] - 0s 84us/step - loss: 0.3015 - accuracy: 0.9026 - val_loss: 0.5295 - val_accuracy: 0.7914\n",
      "Epoch 78/100\n",
      "380/380 [==============================] - 0s 94us/step - loss: 0.3019 - accuracy: 0.8974 - val_loss: 0.5300 - val_accuracy: 0.7546\n",
      "Epoch 79/100\n",
      "380/380 [==============================] - 0s 84us/step - loss: 0.3005 - accuracy: 0.9053 - val_loss: 0.5181 - val_accuracy: 0.7853\n",
      "Epoch 80/100\n",
      "380/380 [==============================] - 0s 85us/step - loss: 0.2933 - accuracy: 0.9000 - val_loss: 0.5195 - val_accuracy: 0.7730\n",
      "Epoch 81/100\n",
      "380/380 [==============================] - 0s 80us/step - loss: 0.3070 - accuracy: 0.9000 - val_loss: 0.5079 - val_accuracy: 0.8037\n",
      "Epoch 82/100\n",
      "380/380 [==============================] - 0s 82us/step - loss: 0.3078 - accuracy: 0.8921 - val_loss: 0.5681 - val_accuracy: 0.7423\n",
      "Epoch 83/100\n",
      "380/380 [==============================] - 0s 100us/step - loss: 0.2867 - accuracy: 0.9105 - val_loss: 0.5331 - val_accuracy: 0.8037\n",
      "Epoch 84/100\n",
      "380/380 [==============================] - 0s 158us/step - loss: 0.3185 - accuracy: 0.8842 - val_loss: 0.5343 - val_accuracy: 0.7362\n",
      "Epoch 85/100\n",
      "380/380 [==============================] - 0s 170us/step - loss: 0.3403 - accuracy: 0.8763 - val_loss: 0.7015 - val_accuracy: 0.7485\n",
      "Epoch 86/100\n",
      "380/380 [==============================] - 0s 168us/step - loss: 0.5221 - accuracy: 0.8605 - val_loss: 0.7012 - val_accuracy: 0.7239\n",
      "Epoch 87/100\n",
      "380/380 [==============================] - 0s 167us/step - loss: 0.4469 - accuracy: 0.8474 - val_loss: 0.5884 - val_accuracy: 0.7362\n",
      "Epoch 88/100\n",
      "380/380 [==============================] - 0s 139us/step - loss: 0.3551 - accuracy: 0.8553 - val_loss: 0.5627 - val_accuracy: 0.7730\n",
      "Epoch 89/100\n",
      "380/380 [==============================] - 0s 137us/step - loss: 0.3101 - accuracy: 0.9026 - val_loss: 0.5067 - val_accuracy: 0.7669\n",
      "Epoch 90/100\n",
      "380/380 [==============================] - 0s 148us/step - loss: 0.3042 - accuracy: 0.8842 - val_loss: 0.6139 - val_accuracy: 0.7853\n",
      "Epoch 91/100\n",
      "380/380 [==============================] - 0s 143us/step - loss: 0.3278 - accuracy: 0.8895 - val_loss: 0.5855 - val_accuracy: 0.7791\n",
      "Epoch 92/100\n",
      "380/380 [==============================] - 0s 157us/step - loss: 0.3054 - accuracy: 0.9026 - val_loss: 0.5368 - val_accuracy: 0.7669\n",
      "Epoch 93/100\n",
      "380/380 [==============================] - 0s 121us/step - loss: 0.2792 - accuracy: 0.8947 - val_loss: 0.5170 - val_accuracy: 0.7853\n",
      "Epoch 94/100\n",
      "380/380 [==============================] - 0s 151us/step - loss: 0.2796 - accuracy: 0.9000 - val_loss: 0.5072 - val_accuracy: 0.7791\n",
      "Epoch 95/100\n",
      "380/380 [==============================] - 0s 157us/step - loss: 0.2830 - accuracy: 0.9026 - val_loss: 0.5166 - val_accuracy: 0.7853\n",
      "Epoch 96/100\n",
      "380/380 [==============================] - 0s 148us/step - loss: 0.3049 - accuracy: 0.8921 - val_loss: 0.4978 - val_accuracy: 0.8221\n",
      "Epoch 97/100\n",
      "380/380 [==============================] - 0s 142us/step - loss: 0.3139 - accuracy: 0.8868 - val_loss: 0.5748 - val_accuracy: 0.7607\n",
      "Epoch 98/100\n",
      "380/380 [==============================] - 0s 178us/step - loss: 0.2939 - accuracy: 0.8816 - val_loss: 0.5048 - val_accuracy: 0.8160\n",
      "Epoch 99/100\n",
      "380/380 [==============================] - 0s 129us/step - loss: 0.3042 - accuracy: 0.8763 - val_loss: 0.5041 - val_accuracy: 0.7975\n",
      "Epoch 100/100\n",
      "380/380 [==============================] - 0s 164us/step - loss: 0.2857 - accuracy: 0.8895 - val_loss: 0.5254 - val_accuracy: 0.7485\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a33e8f128>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over.fit(X_train_over, y_train_over,\n",
    "          batch_size=64, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163/163 [==============================] - 0s 86us/step\n",
      "over-sampling test accuracy: 82.82%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over = model1_over.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 2, 0, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1,\n",
       "       1, 1, 1, 1, 0, 0, 0, 2, 1, 1, 1, 2, 1, 2, 0, 2, 0, 1, 0, 1, 1, 2,\n",
       "       0, 0, 2, 1, 1, 1, 0, 1, 1, 1, 1, 2, 0, 0, 2, 1, 2, 1, 1, 0, 0, 1,\n",
       "       1, 2, 0, 0, 1, 0, 1, 2, 2, 0, 2, 1, 0, 0, 0, 1, 2, 1, 1, 0, 1, 2,\n",
       "       2, 1, 1, 1, 2, 0, 0, 1, 1, 1, 0, 2, 1, 2, 0, 2, 1, 0, 2, 0, 0, 1,\n",
       "       2, 1, 1, 1, 0, 0, 2, 0, 0, 2, 0, 2, 2, 0, 0, 1, 0, 1, 0, 0, 1, 0,\n",
       "       1, 1, 0, 0, 2, 2, 2, 1, 1])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model1_over.predict_classes(X_test_over)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SR1129</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS185</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS243</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BCH-SA-04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>504</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>CFBREBSa131</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>CFBREBSa133</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>NRS256</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>GA48963</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>BCH-SA-07</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test  pred\n",
       "0         SR1129     2     0\n",
       "1         NRS185     2     2\n",
       "2         NRS243     1     1\n",
       "3      BCH-SA-04     0     0\n",
       "4            504     1     1\n",
       "..           ...   ...   ...\n",
       "158  CFBREBSa131     2     2\n",
       "159  CFBREBSa133     1     2\n",
       "160       NRS256     2     2\n",
       "161      GA48963     1     1\n",
       "162    BCH-SA-07     1     1\n",
       "\n",
       "[163 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat['pred'] = pred\n",
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba1 = model1_over.predict_proba(X_test_over)\n",
    "dat_proba1 = pd.DataFrame(proba1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.953901</td>\n",
       "      <td>0.017629</td>\n",
       "      <td>0.028470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.061263</td>\n",
       "      <td>0.938579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000603</td>\n",
       "      <td>0.858406</td>\n",
       "      <td>0.140991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.988969</td>\n",
       "      <td>0.008119</td>\n",
       "      <td>0.002912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.062080</td>\n",
       "      <td>0.865571</td>\n",
       "      <td>0.072349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>0.479931</td>\n",
       "      <td>0.014191</td>\n",
       "      <td>0.505878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>0.000769</td>\n",
       "      <td>0.488876</td>\n",
       "      <td>0.510355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.068585</td>\n",
       "      <td>0.931016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>0.001275</td>\n",
       "      <td>0.866945</td>\n",
       "      <td>0.131780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>0.020563</td>\n",
       "      <td>0.973579</td>\n",
       "      <td>0.005858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2\n",
       "0    0.953901  0.017629  0.028470\n",
       "1    0.000158  0.061263  0.938579\n",
       "2    0.000603  0.858406  0.140991\n",
       "3    0.988969  0.008119  0.002912\n",
       "4    0.062080  0.865571  0.072349\n",
       "..        ...       ...       ...\n",
       "158  0.479931  0.014191  0.505878\n",
       "159  0.000769  0.488876  0.510355\n",
       "160  0.000399  0.068585  0.931016\n",
       "161  0.001275  0.866945  0.131780\n",
       "162  0.020563  0.973579  0.005858\n",
       "\n",
       "[163 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba1.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba1.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/1p11ST.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 380 samples, validate on 163 samples\n",
      "Epoch 1/100\n",
      "380/380 [==============================] - 0s 135us/step - loss: 0.2620 - accuracy: 0.8947 - val_loss: 0.4803 - val_accuracy: 0.8160\n",
      "Epoch 2/100\n",
      "380/380 [==============================] - 0s 131us/step - loss: 0.2497 - accuracy: 0.9158 - val_loss: 0.4792 - val_accuracy: 0.8405\n",
      "Epoch 3/100\n",
      "380/380 [==============================] - 0s 102us/step - loss: 0.2452 - accuracy: 0.9184 - val_loss: 0.4823 - val_accuracy: 0.7853\n",
      "Epoch 4/100\n",
      "380/380 [==============================] - 0s 90us/step - loss: 0.2473 - accuracy: 0.9211 - val_loss: 0.4614 - val_accuracy: 0.8282\n",
      "Epoch 5/100\n",
      "380/380 [==============================] - 0s 96us/step - loss: 0.2419 - accuracy: 0.9184 - val_loss: 0.4826 - val_accuracy: 0.8221\n",
      "Epoch 6/100\n",
      "380/380 [==============================] - 0s 95us/step - loss: 0.2462 - accuracy: 0.9026 - val_loss: 0.4758 - val_accuracy: 0.8160\n",
      "Epoch 7/100\n",
      "380/380 [==============================] - 0s 87us/step - loss: 0.2453 - accuracy: 0.9132 - val_loss: 0.4893 - val_accuracy: 0.8282\n",
      "Epoch 8/100\n",
      "380/380 [==============================] - 0s 87us/step - loss: 0.2474 - accuracy: 0.9132 - val_loss: 0.4753 - val_accuracy: 0.8098\n",
      "Epoch 9/100\n",
      "380/380 [==============================] - 0s 91us/step - loss: 0.2397 - accuracy: 0.9158 - val_loss: 0.4525 - val_accuracy: 0.8344\n",
      "Epoch 10/100\n",
      "380/380 [==============================] - 0s 87us/step - loss: 0.2377 - accuracy: 0.9158 - val_loss: 0.4626 - val_accuracy: 0.8282\n",
      "Epoch 11/100\n",
      "380/380 [==============================] - 0s 91us/step - loss: 0.2352 - accuracy: 0.9132 - val_loss: 0.4692 - val_accuracy: 0.7914\n",
      "Epoch 12/100\n",
      "380/380 [==============================] - 0s 101us/step - loss: 0.2294 - accuracy: 0.9184 - val_loss: 0.4589 - val_accuracy: 0.8282\n",
      "Epoch 13/100\n",
      "380/380 [==============================] - 0s 89us/step - loss: 0.2370 - accuracy: 0.9158 - val_loss: 0.4491 - val_accuracy: 0.8344\n",
      "Epoch 14/100\n",
      "380/380 [==============================] - 0s 86us/step - loss: 0.2443 - accuracy: 0.9105 - val_loss: 0.4966 - val_accuracy: 0.8282\n",
      "Epoch 15/100\n",
      "380/380 [==============================] - 0s 88us/step - loss: 0.2446 - accuracy: 0.9158 - val_loss: 0.4649 - val_accuracy: 0.8282\n",
      "Epoch 16/100\n",
      "380/380 [==============================] - 0s 83us/step - loss: 0.2391 - accuracy: 0.9000 - val_loss: 0.4953 - val_accuracy: 0.8160\n",
      "Epoch 17/100\n",
      "380/380 [==============================] - 0s 86us/step - loss: 0.2441 - accuracy: 0.9132 - val_loss: 0.4389 - val_accuracy: 0.8528\n",
      "Epoch 18/100\n",
      "380/380 [==============================] - 0s 84us/step - loss: 0.2466 - accuracy: 0.9053 - val_loss: 0.4823 - val_accuracy: 0.7853\n",
      "Epoch 19/100\n",
      "380/380 [==============================] - 0s 83us/step - loss: 0.2721 - accuracy: 0.8974 - val_loss: 0.4532 - val_accuracy: 0.8221\n",
      "Epoch 20/100\n",
      "380/380 [==============================] - 0s 86us/step - loss: 0.2712 - accuracy: 0.8974 - val_loss: 0.5002 - val_accuracy: 0.7791\n",
      "Epoch 21/100\n",
      "380/380 [==============================] - 0s 86us/step - loss: 0.2637 - accuracy: 0.8868 - val_loss: 0.4977 - val_accuracy: 0.8282\n",
      "Epoch 22/100\n",
      "380/380 [==============================] - 0s 87us/step - loss: 0.2473 - accuracy: 0.8895 - val_loss: 0.4783 - val_accuracy: 0.8037\n",
      "Epoch 23/100\n",
      "380/380 [==============================] - 0s 97us/step - loss: 0.2498 - accuracy: 0.8974 - val_loss: 0.5438 - val_accuracy: 0.8405\n",
      "Epoch 24/100\n",
      "380/380 [==============================] - 0s 104us/step - loss: 0.3429 - accuracy: 0.8974 - val_loss: 0.5048 - val_accuracy: 0.8344\n",
      "Epoch 25/100\n",
      "380/380 [==============================] - 0s 130us/step - loss: 0.2400 - accuracy: 0.9184 - val_loss: 0.5683 - val_accuracy: 0.8221\n",
      "Epoch 26/100\n",
      "380/380 [==============================] - 0s 92us/step - loss: 0.3252 - accuracy: 0.9132 - val_loss: 0.5382 - val_accuracy: 0.8344\n",
      "Epoch 27/100\n",
      "380/380 [==============================] - 0s 106us/step - loss: 0.2934 - accuracy: 0.9211 - val_loss: 0.4779 - val_accuracy: 0.7853\n",
      "Epoch 28/100\n",
      "380/380 [==============================] - 0s 95us/step - loss: 0.2586 - accuracy: 0.9026 - val_loss: 0.4963 - val_accuracy: 0.8160\n",
      "Epoch 29/100\n",
      "380/380 [==============================] - 0s 86us/step - loss: 0.2964 - accuracy: 0.8974 - val_loss: 0.4719 - val_accuracy: 0.7975\n",
      "Epoch 30/100\n",
      "380/380 [==============================] - 0s 87us/step - loss: 0.2322 - accuracy: 0.9184 - val_loss: 0.4757 - val_accuracy: 0.8221\n",
      "Epoch 31/100\n",
      "380/380 [==============================] - 0s 103us/step - loss: 0.2299 - accuracy: 0.9158 - val_loss: 0.4362 - val_accuracy: 0.8282\n",
      "Epoch 32/100\n",
      "380/380 [==============================] - 0s 89us/step - loss: 0.2144 - accuracy: 0.9211 - val_loss: 0.4831 - val_accuracy: 0.8221\n",
      "Epoch 33/100\n",
      "380/380 [==============================] - 0s 109us/step - loss: 0.2221 - accuracy: 0.9105 - val_loss: 0.4501 - val_accuracy: 0.8221\n",
      "Epoch 34/100\n",
      "380/380 [==============================] - 0s 94us/step - loss: 0.2092 - accuracy: 0.9158 - val_loss: 0.4428 - val_accuracy: 0.8221\n",
      "Epoch 35/100\n",
      "380/380 [==============================] - 0s 101us/step - loss: 0.2110 - accuracy: 0.9026 - val_loss: 0.4409 - val_accuracy: 0.8282\n",
      "Epoch 36/100\n",
      "380/380 [==============================] - 0s 112us/step - loss: 0.2102 - accuracy: 0.9237 - val_loss: 0.4382 - val_accuracy: 0.8221\n",
      "Epoch 37/100\n",
      "380/380 [==============================] - 0s 104us/step - loss: 0.2178 - accuracy: 0.9132 - val_loss: 0.4756 - val_accuracy: 0.8344\n",
      "Epoch 38/100\n",
      "380/380 [==============================] - 0s 89us/step - loss: 0.2030 - accuracy: 0.9368 - val_loss: 0.4611 - val_accuracy: 0.7853\n",
      "Epoch 39/100\n",
      "380/380 [==============================] - 0s 94us/step - loss: 0.2199 - accuracy: 0.9026 - val_loss: 0.4909 - val_accuracy: 0.8160\n",
      "Epoch 40/100\n",
      "380/380 [==============================] - 0s 96us/step - loss: 0.2141 - accuracy: 0.9211 - val_loss: 0.4898 - val_accuracy: 0.7730\n",
      "Epoch 41/100\n",
      "380/380 [==============================] - 0s 99us/step - loss: 0.2030 - accuracy: 0.9211 - val_loss: 0.4272 - val_accuracy: 0.8282\n",
      "Epoch 42/100\n",
      "380/380 [==============================] - 0s 89us/step - loss: 0.2268 - accuracy: 0.9263 - val_loss: 0.4425 - val_accuracy: 0.8098\n",
      "Epoch 43/100\n",
      "380/380 [==============================] - 0s 89us/step - loss: 0.2140 - accuracy: 0.9263 - val_loss: 0.4578 - val_accuracy: 0.8221\n",
      "Epoch 44/100\n",
      "380/380 [==============================] - 0s 91us/step - loss: 0.2200 - accuracy: 0.9053 - val_loss: 0.4851 - val_accuracy: 0.7853\n",
      "Epoch 45/100\n",
      "380/380 [==============================] - 0s 90us/step - loss: 0.2115 - accuracy: 0.9184 - val_loss: 0.4343 - val_accuracy: 0.8528\n",
      "Epoch 46/100\n",
      "380/380 [==============================] - 0s 86us/step - loss: 0.2017 - accuracy: 0.9316 - val_loss: 0.4451 - val_accuracy: 0.8160\n",
      "Epoch 47/100\n",
      "380/380 [==============================] - 0s 138us/step - loss: 0.2015 - accuracy: 0.9263 - val_loss: 0.4349 - val_accuracy: 0.8160\n",
      "Epoch 48/100\n",
      "380/380 [==============================] - 0s 212us/step - loss: 0.1947 - accuracy: 0.9263 - val_loss: 0.4772 - val_accuracy: 0.8037\n",
      "Epoch 49/100\n",
      "380/380 [==============================] - 0s 113us/step - loss: 0.1972 - accuracy: 0.9237 - val_loss: 0.4515 - val_accuracy: 0.8221\n",
      "Epoch 50/100\n",
      "380/380 [==============================] - 0s 141us/step - loss: 0.1937 - accuracy: 0.9289 - val_loss: 0.4357 - val_accuracy: 0.8098\n",
      "Epoch 51/100\n",
      "380/380 [==============================] - 0s 120us/step - loss: 0.1923 - accuracy: 0.9316 - val_loss: 0.4433 - val_accuracy: 0.8098\n",
      "Epoch 52/100\n",
      "380/380 [==============================] - 0s 151us/step - loss: 0.1987 - accuracy: 0.9211 - val_loss: 0.4763 - val_accuracy: 0.8098\n",
      "Epoch 53/100\n",
      "380/380 [==============================] - 0s 89us/step - loss: 0.2067 - accuracy: 0.9184 - val_loss: 0.4636 - val_accuracy: 0.8037\n",
      "Epoch 54/100\n",
      "380/380 [==============================] - 0s 200us/step - loss: 0.1991 - accuracy: 0.9211 - val_loss: 0.4500 - val_accuracy: 0.8098\n",
      "Epoch 55/100\n",
      "380/380 [==============================] - 0s 147us/step - loss: 0.1948 - accuracy: 0.9158 - val_loss: 0.4391 - val_accuracy: 0.8098\n",
      "Epoch 56/100\n",
      "380/380 [==============================] - 0s 108us/step - loss: 0.1941 - accuracy: 0.9263 - val_loss: 0.4560 - val_accuracy: 0.7791\n",
      "Epoch 57/100\n",
      "380/380 [==============================] - 0s 114us/step - loss: 0.1989 - accuracy: 0.9316 - val_loss: 0.4671 - val_accuracy: 0.8160\n",
      "Epoch 58/100\n",
      "380/380 [==============================] - 0s 112us/step - loss: 0.1944 - accuracy: 0.9211 - val_loss: 0.4596 - val_accuracy: 0.7853\n",
      "Epoch 59/100\n",
      "380/380 [==============================] - 0s 104us/step - loss: 0.2133 - accuracy: 0.9316 - val_loss: 0.4413 - val_accuracy: 0.8160\n",
      "Epoch 60/100\n",
      "380/380 [==============================] - 0s 111us/step - loss: 0.2044 - accuracy: 0.9211 - val_loss: 0.4679 - val_accuracy: 0.8221\n",
      "Epoch 61/100\n",
      "380/380 [==============================] - 0s 100us/step - loss: 0.1949 - accuracy: 0.9289 - val_loss: 0.5176 - val_accuracy: 0.7669\n",
      "Epoch 62/100\n",
      "380/380 [==============================] - 0s 103us/step - loss: 0.2465 - accuracy: 0.9237 - val_loss: 0.5594 - val_accuracy: 0.8221\n",
      "Epoch 63/100\n",
      "380/380 [==============================] - 0s 107us/step - loss: 0.2018 - accuracy: 0.9211 - val_loss: 0.4746 - val_accuracy: 0.7975\n",
      "Epoch 64/100\n",
      "380/380 [==============================] - 0s 388us/step - loss: 0.1920 - accuracy: 0.9263 - val_loss: 0.4354 - val_accuracy: 0.8344\n",
      "Epoch 65/100\n",
      "380/380 [==============================] - 0s 340us/step - loss: 0.1802 - accuracy: 0.9395 - val_loss: 0.4451 - val_accuracy: 0.8160\n",
      "Epoch 66/100\n",
      "380/380 [==============================] - 0s 121us/step - loss: 0.1865 - accuracy: 0.9316 - val_loss: 0.4425 - val_accuracy: 0.8160\n",
      "Epoch 67/100\n",
      "380/380 [==============================] - 0s 107us/step - loss: 0.1801 - accuracy: 0.9342 - val_loss: 0.4879 - val_accuracy: 0.8037\n",
      "Epoch 68/100\n",
      "380/380 [==============================] - 0s 235us/step - loss: 0.1832 - accuracy: 0.9395 - val_loss: 0.4070 - val_accuracy: 0.8282\n",
      "Epoch 69/100\n",
      "380/380 [==============================] - 0s 132us/step - loss: 0.1928 - accuracy: 0.9211 - val_loss: 0.5366 - val_accuracy: 0.8282\n",
      "Epoch 70/100\n",
      "380/380 [==============================] - 0s 95us/step - loss: 0.1960 - accuracy: 0.9289 - val_loss: 0.4384 - val_accuracy: 0.8344\n",
      "Epoch 71/100\n",
      "380/380 [==============================] - 0s 128us/step - loss: 0.1922 - accuracy: 0.9184 - val_loss: 0.4620 - val_accuracy: 0.7914\n",
      "Epoch 72/100\n",
      "380/380 [==============================] - 0s 114us/step - loss: 0.1799 - accuracy: 0.9289 - val_loss: 0.4093 - val_accuracy: 0.8282\n",
      "Epoch 73/100\n",
      "380/380 [==============================] - 0s 93us/step - loss: 0.1860 - accuracy: 0.9263 - val_loss: 0.4572 - val_accuracy: 0.8098\n",
      "Epoch 74/100\n",
      "380/380 [==============================] - 0s 83us/step - loss: 0.1870 - accuracy: 0.9316 - val_loss: 0.4074 - val_accuracy: 0.8282\n",
      "Epoch 75/100\n",
      "380/380 [==============================] - 0s 80us/step - loss: 0.1754 - accuracy: 0.9342 - val_loss: 0.5123 - val_accuracy: 0.7853\n",
      "Epoch 76/100\n",
      "380/380 [==============================] - 0s 96us/step - loss: 0.1815 - accuracy: 0.9316 - val_loss: 0.4025 - val_accuracy: 0.8344\n",
      "Epoch 77/100\n",
      "380/380 [==============================] - 0s 90us/step - loss: 0.1754 - accuracy: 0.9342 - val_loss: 0.4615 - val_accuracy: 0.8405\n",
      "Epoch 78/100\n",
      "380/380 [==============================] - 0s 91us/step - loss: 0.1719 - accuracy: 0.9395 - val_loss: 0.4088 - val_accuracy: 0.8528\n",
      "Epoch 79/100\n",
      "380/380 [==============================] - 0s 89us/step - loss: 0.1773 - accuracy: 0.9316 - val_loss: 0.4828 - val_accuracy: 0.8221\n",
      "Epoch 80/100\n",
      "380/380 [==============================] - 0s 98us/step - loss: 0.1933 - accuracy: 0.9184 - val_loss: 0.4331 - val_accuracy: 0.8282\n",
      "Epoch 81/100\n",
      "380/380 [==============================] - 0s 105us/step - loss: 0.1737 - accuracy: 0.9263 - val_loss: 0.4486 - val_accuracy: 0.8098\n",
      "Epoch 82/100\n",
      "380/380 [==============================] - 0s 99us/step - loss: 0.1716 - accuracy: 0.9342 - val_loss: 0.4344 - val_accuracy: 0.8160\n",
      "Epoch 83/100\n",
      "380/380 [==============================] - 0s 101us/step - loss: 0.1737 - accuracy: 0.9368 - val_loss: 0.4910 - val_accuracy: 0.8466\n",
      "Epoch 84/100\n",
      "380/380 [==============================] - 0s 97us/step - loss: 0.1803 - accuracy: 0.9342 - val_loss: 0.4524 - val_accuracy: 0.8282\n",
      "Epoch 85/100\n",
      "380/380 [==============================] - 0s 99us/step - loss: 0.1731 - accuracy: 0.9421 - val_loss: 0.4337 - val_accuracy: 0.8528\n",
      "Epoch 86/100\n",
      "380/380 [==============================] - 0s 114us/step - loss: 0.1671 - accuracy: 0.9342 - val_loss: 0.4421 - val_accuracy: 0.8282\n",
      "Epoch 87/100\n",
      "380/380 [==============================] - 0s 97us/step - loss: 0.1709 - accuracy: 0.9421 - val_loss: 0.4270 - val_accuracy: 0.8528\n",
      "Epoch 88/100\n",
      "380/380 [==============================] - 0s 89us/step - loss: 0.1717 - accuracy: 0.9316 - val_loss: 0.4653 - val_accuracy: 0.8344\n",
      "Epoch 89/100\n",
      "380/380 [==============================] - 0s 92us/step - loss: 0.2305 - accuracy: 0.9132 - val_loss: 0.4980 - val_accuracy: 0.8405\n",
      "Epoch 90/100\n",
      "380/380 [==============================] - 0s 100us/step - loss: 0.2145 - accuracy: 0.9105 - val_loss: 0.5943 - val_accuracy: 0.8344\n",
      "Epoch 91/100\n",
      "380/380 [==============================] - 0s 100us/step - loss: 0.3978 - accuracy: 0.9026 - val_loss: 0.5067 - val_accuracy: 0.8221\n",
      "Epoch 92/100\n",
      "380/380 [==============================] - 0s 85us/step - loss: 0.3875 - accuracy: 0.8789 - val_loss: 0.5665 - val_accuracy: 0.8221\n",
      "Epoch 93/100\n",
      "380/380 [==============================] - 0s 428us/step - loss: 0.3445 - accuracy: 0.9184 - val_loss: 0.6168 - val_accuracy: 0.8282\n",
      "Epoch 94/100\n",
      "380/380 [==============================] - 0s 104us/step - loss: 0.2218 - accuracy: 0.9211 - val_loss: 0.4785 - val_accuracy: 0.8160\n",
      "Epoch 95/100\n",
      "380/380 [==============================] - 0s 104us/step - loss: 0.2017 - accuracy: 0.9342 - val_loss: 0.4790 - val_accuracy: 0.8282\n",
      "Epoch 96/100\n",
      "380/380 [==============================] - 0s 98us/step - loss: 0.2433 - accuracy: 0.9342 - val_loss: 0.4615 - val_accuracy: 0.8528\n",
      "Epoch 97/100\n",
      "380/380 [==============================] - 0s 97us/step - loss: 0.2093 - accuracy: 0.9237 - val_loss: 0.4481 - val_accuracy: 0.8405\n",
      "Epoch 98/100\n",
      "380/380 [==============================] - 0s 102us/step - loss: 0.1870 - accuracy: 0.9289 - val_loss: 0.4705 - val_accuracy: 0.8344\n",
      "Epoch 99/100\n",
      "380/380 [==============================] - 0s 114us/step - loss: 0.1820 - accuracy: 0.9289 - val_loss: 0.4767 - val_accuracy: 0.8221\n",
      "Epoch 100/100\n",
      "380/380 [==============================] - 0s 91us/step - loss: 0.1745 - accuracy: 0.9289 - val_loss: 0.4654 - val_accuracy: 0.8344\n"
     ]
    }
   ],
   "source": [
    "hist1_over = model1_over.fit(X_train_over, y_train_over,\n",
    "          batch_size=64, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 91.99%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_2.xlsx\",\n",
    "                        sheet_name=0,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>CFBRSa26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.758914</td>\n",
       "      <td>0.241086</td>\n",
       "      <td>4.638713e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.005361</td>\n",
       "      <td>0.016236</td>\n",
       "      <td>9.784034e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS112</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.726623</td>\n",
       "      <td>0.273376</td>\n",
       "      <td>1.520979e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS216</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.138322</td>\n",
       "      <td>0.861665</td>\n",
       "      <td>1.334123e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS021</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.882176</td>\n",
       "      <td>0.117824</td>\n",
       "      <td>1.414530e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4279</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>9.998934e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4280</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.002048</td>\n",
       "      <td>9.976944e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4281</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS205</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>9.999435e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4282</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.002048</td>\n",
       "      <td>9.976944e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4283</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.000929</td>\n",
       "      <td>9.989737e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4284 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    phage    strain  phenotype  prediction         0  \\\n",
       "0      p002ykpresabs_qual  CFBRSa26          0           0  0.758914   \n",
       "1      p002ykpresabs_qual    NRS109          2           2  0.005361   \n",
       "2      p002ykpresabs_qual    NRS112          0           0  0.726623   \n",
       "3      p002ykpresabs_qual    NRS216          1           1  0.138322   \n",
       "4      p002ykpresabs_qual    NRS021          0           0  0.882176   \n",
       "...                   ...       ...        ...         ...       ...   \n",
       "4279  pyopresabsSTCC_qual    NRS148          2           2  0.000007   \n",
       "4280  pyopresabsSTCC_qual    NRS255          2           2  0.000257   \n",
       "4281  pyopresabsSTCC_qual    NRS205          2           2  0.000011   \n",
       "4282  pyopresabsSTCC_qual    NRS255          2           2  0.000257   \n",
       "4283  pyopresabsSTCC_qual    NRS109          2           2  0.000097   \n",
       "\n",
       "             1             2  \n",
       "0     0.241086  4.638713e-07  \n",
       "1     0.016236  9.784034e-01  \n",
       "2     0.273376  1.520979e-06  \n",
       "3     0.861665  1.334123e-05  \n",
       "4     0.117824  1.414530e-10  \n",
       "...        ...           ...  \n",
       "4279  0.000099  9.998934e-01  \n",
       "4280  0.002048  9.976944e-01  \n",
       "4281  0.000045  9.999435e-01  \n",
       "4282  0.002048  9.976944e-01  \n",
       "4283  0.000929  9.989737e-01  \n",
       "\n",
       "[4284 rows x 7 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.53901300e-01, 1.76289320e-02, 2.84697230e-02],\n",
       "       [1.58122540e-04, 6.12626600e-02, 9.38579200e-01],\n",
       "       [6.03212860e-04, 8.58405650e-01, 1.40991050e-01],\n",
       "       [9.88968600e-01, 8.11905100e-03, 2.91239380e-03],\n",
       "       [6.20801450e-02, 8.65571000e-01, 7.23488550e-02],\n",
       "       [5.02775850e-01, 3.38603700e-01, 1.58620450e-01],\n",
       "       [9.86663800e-01, 8.72669650e-03, 4.60948700e-03],\n",
       "       [6.92549500e-01, 1.37520300e-02, 2.93698460e-01],\n",
       "       [9.80278200e-02, 8.30269600e-01, 7.17025250e-02],\n",
       "       [2.09496920e-02, 9.38645200e-01, 4.04051950e-02],\n",
       "       [2.09350330e-02, 6.03786000e-01, 3.75278950e-01],\n",
       "       [8.83258100e-01, 1.03461710e-01, 1.32801550e-02],\n",
       "       [9.68945550e-02, 5.36189560e-01, 3.66915940e-01],\n",
       "       [2.56062000e-01, 3.86030850e-01, 3.57907180e-01],\n",
       "       [8.83258100e-01, 1.03461710e-01, 1.32801550e-02],\n",
       "       [9.98986300e-01, 9.80773200e-04, 3.28470100e-05],\n",
       "       [5.12586600e-02, 4.81528850e-01, 4.67212470e-01],\n",
       "       [7.62314950e-02, 1.24863550e-01, 7.98904960e-01],\n",
       "       [6.74443540e-01, 3.01717430e-01, 2.38390580e-02],\n",
       "       [4.76468650e-01, 3.73928800e-01, 1.49602590e-01],\n",
       "       [9.54790800e-02, 7.07831560e-01, 1.96689300e-01],\n",
       "       [9.63964940e-01, 2.15386000e-02, 1.44964630e-02],\n",
       "       [9.44113400e-01, 1.72465190e-03, 5.41619170e-02],\n",
       "       [4.44266250e-03, 6.07811300e-01, 3.87746000e-01],\n",
       "       [9.84953500e-01, 6.44912600e-03, 8.59732550e-03],\n",
       "       [9.43686540e-01, 7.46896300e-03, 4.88444980e-02],\n",
       "       [2.05626380e-02, 9.73579100e-01, 5.85823830e-03],\n",
       "       [6.20801450e-02, 8.65571000e-01, 7.23488550e-02],\n",
       "       [9.70478240e-01, 1.86669400e-02, 1.08548090e-02],\n",
       "       [9.84953500e-01, 6.44912600e-03, 8.59732550e-03],\n",
       "       [2.76661550e-03, 5.73948100e-01, 4.23285300e-01],\n",
       "       [8.18683500e-02, 5.28882200e-01, 3.89249470e-01],\n",
       "       [4.03763470e-02, 9.02132500e-01, 5.74911870e-02],\n",
       "       [6.74443540e-01, 3.01717430e-01, 2.38390580e-02],\n",
       "       [4.03763470e-02, 9.02132500e-01, 5.74911870e-02],\n",
       "       [8.45659500e-01, 6.38485200e-02, 9.04919700e-02],\n",
       "       [5.67048750e-02, 7.66736900e-01, 1.76558140e-01],\n",
       "       [1.03611730e-02, 9.87811500e-01, 1.82732320e-03],\n",
       "       [1.27533470e-03, 8.66944850e-01, 1.31779800e-01],\n",
       "       [6.25856600e-02, 8.43604740e-01, 9.38096300e-02],\n",
       "       [9.51496060e-01, 1.36450990e-03, 4.71394430e-02],\n",
       "       [5.68766150e-02, 5.14909270e-01, 4.28214100e-01],\n",
       "       [8.44027940e-01, 5.83661100e-03, 1.50135400e-01],\n",
       "       [5.00289240e-02, 4.89945800e-01, 4.60025280e-01],\n",
       "       [1.27533470e-03, 8.66944850e-01, 1.31779800e-01],\n",
       "       [6.15980550e-02, 6.02105200e-01, 3.36296740e-01],\n",
       "       [5.68766150e-02, 5.14909270e-01, 4.28214100e-01],\n",
       "       [1.38788650e-03, 8.99313150e-01, 9.92989100e-02],\n",
       "       [9.91703870e-01, 2.02301500e-03, 6.27310400e-03],\n",
       "       [6.74443540e-01, 3.01717430e-01, 2.38390580e-02],\n",
       "       [9.72666860e-01, 2.03931600e-02, 6.93991640e-03],\n",
       "       [2.06838590e-02, 3.43989820e-01, 6.35326270e-01],\n",
       "       [1.16713650e-02, 9.66913160e-01, 2.14154900e-02],\n",
       "       [3.17949580e-02, 8.47740050e-01, 1.20465040e-01],\n",
       "       [2.61064580e-02, 9.54632300e-01, 1.92613320e-02],\n",
       "       [3.09486720e-01, 3.62361870e-03, 6.86889650e-01],\n",
       "       [8.91345600e-02, 7.80440300e-01, 1.30425210e-01],\n",
       "       [1.03405840e-02, 2.14426300e-02, 9.68216800e-01],\n",
       "       [8.44027940e-01, 5.83661100e-03, 1.50135400e-01],\n",
       "       [1.70982900e-01, 1.84697360e-01, 6.44319700e-01],\n",
       "       [6.81357260e-01, 7.26629600e-03, 3.11376420e-01],\n",
       "       [1.30075480e-03, 9.76362050e-01, 2.23371950e-02],\n",
       "       [9.43686540e-01, 7.46896300e-03, 4.88444980e-02],\n",
       "       [7.49460900e-02, 7.96773550e-01, 1.28280330e-01],\n",
       "       [5.67048750e-02, 7.66736900e-01, 1.76558140e-01],\n",
       "       [2.19304300e-01, 5.39902100e-03, 7.75296700e-01],\n",
       "       [9.88968600e-01, 8.11905100e-03, 2.91239380e-03],\n",
       "       [9.44113400e-01, 1.72465190e-03, 5.41619170e-02],\n",
       "       [7.69031930e-04, 4.88875930e-01, 5.10355000e-01],\n",
       "       [6.58107000e-02, 6.73316960e-01, 2.60872400e-01],\n",
       "       [9.68945550e-02, 5.36189560e-01, 3.66915940e-01],\n",
       "       [5.67048750e-02, 7.66736900e-01, 1.76558140e-01],\n",
       "       [9.43686540e-01, 7.46896300e-03, 4.88444980e-02],\n",
       "       [6.79356200e-02, 8.74588900e-01, 5.74754140e-02],\n",
       "       [6.38586240e-04, 5.81862900e-01, 4.17498500e-01],\n",
       "       [1.76509670e-04, 6.73848570e-01, 3.25974970e-01],\n",
       "       [5.67048750e-02, 7.66736900e-01, 1.76558140e-01],\n",
       "       [4.20416600e-02, 1.33522780e-01, 8.24435600e-01],\n",
       "       [9.86663800e-01, 8.72669650e-03, 4.60948700e-03],\n",
       "       [4.82182320e-01, 3.70329400e-01, 1.47488240e-01],\n",
       "       [7.69031930e-04, 4.88875930e-01, 5.10355000e-01],\n",
       "       [3.91346700e-05, 9.85801040e-01, 1.41598260e-02],\n",
       "       [2.19304300e-01, 5.39902100e-03, 7.75296700e-01],\n",
       "       [2.00681780e-04, 6.74080800e-01, 3.25718520e-01],\n",
       "       [1.27533470e-03, 8.66944850e-01, 1.31779800e-01],\n",
       "       [9.91703870e-01, 2.02301500e-03, 6.27310400e-03],\n",
       "       [9.86663800e-01, 8.72669650e-03, 4.60948700e-03],\n",
       "       [6.03212860e-04, 8.58405650e-01, 1.40991050e-01],\n",
       "       [6.04876540e-02, 8.33474800e-01, 1.06037580e-01],\n",
       "       [4.98625450e-03, 3.33103300e-02, 9.61703400e-01],\n",
       "       [9.88968600e-01, 8.11905100e-03, 2.91239380e-03],\n",
       "       [4.76468650e-01, 3.73928800e-01, 1.49602590e-01],\n",
       "       [2.53991400e-01, 6.58846440e-01, 8.71621440e-02],\n",
       "       [9.88968600e-01, 8.11905100e-03, 2.91239380e-03],\n",
       "       [1.18136370e-04, 9.90135250e-01, 9.74663700e-03],\n",
       "       [3.33389230e-02, 3.17893500e-02, 9.34871730e-01],\n",
       "       [1.74790480e-03, 5.02775050e-02, 9.47974560e-01],\n",
       "       [9.44113400e-01, 1.72465190e-03, 5.41619170e-02],\n",
       "       [7.34658600e-05, 1.04772310e-01, 8.95154200e-01],\n",
       "       [9.68945550e-02, 5.36189560e-01, 3.66915940e-01],\n",
       "       [9.78204550e-01, 1.60345380e-02, 5.76097750e-03],\n",
       "       [9.78204550e-01, 1.60345380e-02, 5.76097750e-03],\n",
       "       [9.88968600e-01, 8.11905100e-03, 2.91239380e-03],\n",
       "       [6.25856600e-02, 8.43604740e-01, 9.38096300e-02],\n",
       "       [1.54375600e-02, 5.35330620e-02, 9.31029400e-01],\n",
       "       [2.05626380e-02, 9.73579100e-01, 5.85823830e-03],\n",
       "       [3.92960760e-04, 9.74145900e-01, 2.54611020e-02],\n",
       "       [7.09836540e-01, 4.74591140e-02, 2.42704400e-01],\n",
       "       [9.68945550e-02, 5.36189560e-01, 3.66915940e-01],\n",
       "       [1.13776090e-02, 1.14448190e-01, 8.74174200e-01],\n",
       "       [6.98046400e-03, 7.40062400e-02, 9.19013260e-01],\n",
       "       [4.03763470e-02, 9.02132500e-01, 5.74911870e-02],\n",
       "       [6.58107000e-02, 6.73316960e-01, 2.60872400e-01],\n",
       "       [1.30075480e-03, 9.76362050e-01, 2.23371950e-02],\n",
       "       [1.64677370e-01, 8.83673700e-03, 8.26485930e-01],\n",
       "       [9.78204550e-01, 1.60345380e-02, 5.76097750e-03],\n",
       "       [7.09284960e-01, 7.12386000e-03, 2.83591150e-01],\n",
       "       [6.25856600e-02, 8.43604740e-01, 9.38096300e-02],\n",
       "       [3.14429660e-02, 9.07673840e-01, 6.08832580e-02],\n",
       "       [2.54598140e-01, 4.39304860e-01, 3.06096970e-01],\n",
       "       [9.88968600e-01, 8.11905100e-03, 2.91239380e-03],\n",
       "       [7.23669700e-02, 3.91620200e-01, 5.36012900e-01],\n",
       "       [8.05987500e-02, 7.89127000e-01, 1.30274240e-01],\n",
       "       [1.10883170e-02, 5.23814700e-02, 9.36530230e-01],\n",
       "       [9.84953500e-01, 6.44912600e-03, 8.59732550e-03],\n",
       "       [3.68864420e-04, 1.57800990e-01, 8.41830200e-01],\n",
       "       [1.59727950e-02, 6.09180870e-01, 3.74846430e-01],\n",
       "       [9.78204550e-01, 1.60345380e-02, 5.76097750e-03],\n",
       "       [5.94630200e-04, 3.97083820e-01, 6.02321570e-01],\n",
       "       [9.44113400e-01, 1.72465190e-03, 5.41619170e-02],\n",
       "       [9.72666860e-01, 2.03931600e-02, 6.93991640e-03],\n",
       "       [1.30075480e-03, 9.76362050e-01, 2.23371950e-02],\n",
       "       [7.53313900e-04, 2.63048700e-02, 9.72941800e-01],\n",
       "       [1.03611730e-02, 9.87811500e-01, 1.82732320e-03],\n",
       "       [3.54903500e-02, 6.82523250e-01, 2.81986420e-01],\n",
       "       [9.11617700e-02, 5.70719060e-01, 3.38119180e-01],\n",
       "       [8.32170960e-01, 8.63087800e-02, 8.15202150e-02],\n",
       "       [9.72666860e-01, 2.03931600e-02, 6.93991640e-03],\n",
       "       [3.61477750e-03, 1.01104640e-01, 8.95280600e-01],\n",
       "       [9.99594750e-01, 2.77723160e-04, 1.27466120e-04],\n",
       "       [4.90375700e-01, 3.60204550e-01, 1.49419770e-01],\n",
       "       [3.48971600e-04, 3.12786550e-01, 6.86864500e-01],\n",
       "       [9.84953500e-01, 6.44912600e-03, 8.59732550e-03],\n",
       "       [2.74147930e-03, 5.80084600e-02, 9.39250100e-01],\n",
       "       [3.04192370e-03, 1.16574384e-01, 8.80383700e-01],\n",
       "       [7.27214800e-01, 2.31340260e-01, 4.14449160e-02],\n",
       "       [6.74443540e-01, 3.01717430e-01, 2.38390580e-02],\n",
       "       [1.16713650e-02, 9.66913160e-01, 2.14154900e-02],\n",
       "       [9.98986300e-01, 9.80773200e-04, 3.28470100e-05],\n",
       "       [5.68766150e-02, 5.14909270e-01, 4.28214100e-01],\n",
       "       [9.88968600e-01, 8.11905100e-03, 2.91239380e-03],\n",
       "       [9.78204550e-01, 1.60345380e-02, 5.76097750e-03],\n",
       "       [6.58107000e-02, 6.73316960e-01, 2.60872400e-01],\n",
       "       [8.44027940e-01, 5.83661100e-03, 1.50135400e-01],\n",
       "       [4.63610700e-02, 5.36408200e-01, 4.17230730e-01],\n",
       "       [2.86778930e-01, 5.82209100e-01, 1.31011920e-01],\n",
       "       [9.63964940e-01, 2.15386000e-02, 1.44964630e-02],\n",
       "       [3.92459360e-01, 3.80827930e-01, 2.26712690e-01],\n",
       "       [4.79931200e-01, 1.41908820e-02, 5.05877900e-01],\n",
       "       [7.69031930e-04, 4.88875930e-01, 5.10355000e-01],\n",
       "       [3.98932460e-04, 6.85851350e-02, 9.31015900e-01],\n",
       "       [1.27533470e-03, 8.66944850e-01, 1.31779800e-01],\n",
       "       [2.05626380e-02, 9.73579100e-01, 5.85823830e-03]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob = df_proba[df_proba['phage']=='p11kpresabsSTCC_qual'].iloc[:,-3:]\n",
    "y_prob = y_prob.to_numpy()\n",
    "y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Retrieved from https://github.com/scikit-learn/scikit-learn/issues/3298\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "def rocauc_ovo(truth, pred, average=\"macro\", multi_class=\"ovo\"):\n",
    "\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(truth)\n",
    "\n",
    "    truth = lb.transform(truth)   \n",
    "    \n",
    "    return roc_auc_score(truth, pred, average=average, multi_class=multi_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9356207333271552"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo1 = rocauc_ovo(y_test_over, y_prob, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rocauc_ovr(truth, pred, average=\"macro\", multi_class=\"ovr\"):\n",
    "\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(truth)\n",
    "\n",
    "    truth = lb.transform(truth)   \n",
    "\n",
    "    return roc_auc_score(truth, pred, average=average, multi_class=multi_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9356207333271552"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr1 = rocauc_ovr(y_test_over, y_prob, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=234,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat2 = pd.DataFrame(X_test_over[:,0])\n",
    "dat2['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS027</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CFBRSa07</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CFBRSa27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>504</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CFBREBSa129</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>SR3569</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>NRS243</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>GA48963</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>504</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>CFBREBSa123</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test\n",
       "0         NRS027     0\n",
       "1       CFBRSa07     0\n",
       "2       CFBRSa27     1\n",
       "3            504     1\n",
       "4    CFBREBSa129     0\n",
       "..           ...   ...\n",
       "158       SR3569     2\n",
       "159       NRS243     1\n",
       "160      GA48963     1\n",
       "161          504     1\n",
       "162  CFBREBSa123     0\n",
       "\n",
       "[163 rows x 2 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over2 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],)),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over2.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 380 samples, validate on 163 samples\n",
      "Epoch 1/100\n",
      "380/380 [==============================] - 0s 396us/step - loss: 2.0885 - accuracy: 0.3368 - val_loss: 2.2919 - val_accuracy: 0.4294\n",
      "Epoch 2/100\n",
      "380/380 [==============================] - 0s 136us/step - loss: 1.3300 - accuracy: 0.5132 - val_loss: 1.5507 - val_accuracy: 0.5092\n",
      "Epoch 3/100\n",
      "380/380 [==============================] - 0s 177us/step - loss: 1.0378 - accuracy: 0.5868 - val_loss: 1.2166 - val_accuracy: 0.5460\n",
      "Epoch 4/100\n",
      "380/380 [==============================] - 0s 217us/step - loss: 0.8908 - accuracy: 0.6263 - val_loss: 0.9935 - val_accuracy: 0.5828\n",
      "Epoch 5/100\n",
      "380/380 [==============================] - 0s 245us/step - loss: 0.8173 - accuracy: 0.6526 - val_loss: 0.9802 - val_accuracy: 0.6135\n",
      "Epoch 6/100\n",
      "380/380 [==============================] - 0s 209us/step - loss: 0.8034 - accuracy: 0.6895 - val_loss: 0.9021 - val_accuracy: 0.6258\n",
      "Epoch 7/100\n",
      "380/380 [==============================] - 0s 234us/step - loss: 0.7274 - accuracy: 0.6842 - val_loss: 1.0367 - val_accuracy: 0.5828\n",
      "Epoch 8/100\n",
      "380/380 [==============================] - 0s 236us/step - loss: 0.7131 - accuracy: 0.6816 - val_loss: 1.1713 - val_accuracy: 0.6319\n",
      "Epoch 9/100\n",
      "380/380 [==============================] - 0s 219us/step - loss: 0.7180 - accuracy: 0.7211 - val_loss: 0.8181 - val_accuracy: 0.6380\n",
      "Epoch 10/100\n",
      "380/380 [==============================] - 0s 170us/step - loss: 0.6646 - accuracy: 0.7395 - val_loss: 0.9231 - val_accuracy: 0.6442\n",
      "Epoch 11/100\n",
      "380/380 [==============================] - 0s 133us/step - loss: 0.6697 - accuracy: 0.7158 - val_loss: 0.7388 - val_accuracy: 0.6994\n",
      "Epoch 12/100\n",
      "380/380 [==============================] - 0s 374us/step - loss: 0.6036 - accuracy: 0.7658 - val_loss: 0.7141 - val_accuracy: 0.7301\n",
      "Epoch 13/100\n",
      "380/380 [==============================] - 0s 135us/step - loss: 0.5990 - accuracy: 0.7763 - val_loss: 0.8550 - val_accuracy: 0.6687\n",
      "Epoch 14/100\n",
      "380/380 [==============================] - 0s 122us/step - loss: 0.5769 - accuracy: 0.7658 - val_loss: 0.7255 - val_accuracy: 0.6871\n",
      "Epoch 15/100\n",
      "380/380 [==============================] - 0s 110us/step - loss: 0.5677 - accuracy: 0.7658 - val_loss: 0.7363 - val_accuracy: 0.6810\n",
      "Epoch 16/100\n",
      "380/380 [==============================] - 0s 137us/step - loss: 0.5522 - accuracy: 0.7763 - val_loss: 0.8630 - val_accuracy: 0.6933\n",
      "Epoch 17/100\n",
      "380/380 [==============================] - 0s 150us/step - loss: 0.5419 - accuracy: 0.7921 - val_loss: 0.7973 - val_accuracy: 0.6810\n",
      "Epoch 18/100\n",
      "380/380 [==============================] - 0s 201us/step - loss: 0.5658 - accuracy: 0.7684 - val_loss: 0.6709 - val_accuracy: 0.7423\n",
      "Epoch 19/100\n",
      "380/380 [==============================] - 0s 288us/step - loss: 0.5451 - accuracy: 0.7816 - val_loss: 0.7037 - val_accuracy: 0.7485\n",
      "Epoch 20/100\n",
      "380/380 [==============================] - 0s 251us/step - loss: 0.5525 - accuracy: 0.7868 - val_loss: 0.7600 - val_accuracy: 0.7362\n",
      "Epoch 21/100\n",
      "380/380 [==============================] - 0s 176us/step - loss: 0.5209 - accuracy: 0.8289 - val_loss: 0.6587 - val_accuracy: 0.7607\n",
      "Epoch 22/100\n",
      "380/380 [==============================] - 0s 142us/step - loss: 0.4785 - accuracy: 0.8079 - val_loss: 0.7895 - val_accuracy: 0.7362\n",
      "Epoch 23/100\n",
      "380/380 [==============================] - 0s 118us/step - loss: 0.4782 - accuracy: 0.8132 - val_loss: 0.6109 - val_accuracy: 0.7791\n",
      "Epoch 24/100\n",
      "380/380 [==============================] - 0s 109us/step - loss: 0.4643 - accuracy: 0.8079 - val_loss: 0.6006 - val_accuracy: 0.7607\n",
      "Epoch 25/100\n",
      "380/380 [==============================] - 0s 117us/step - loss: 0.4669 - accuracy: 0.8132 - val_loss: 0.6431 - val_accuracy: 0.7914\n",
      "Epoch 26/100\n",
      "380/380 [==============================] - 0s 105us/step - loss: 0.4499 - accuracy: 0.8368 - val_loss: 0.5518 - val_accuracy: 0.8098\n",
      "Epoch 27/100\n",
      "380/380 [==============================] - 0s 115us/step - loss: 0.4965 - accuracy: 0.8105 - val_loss: 0.6313 - val_accuracy: 0.7914\n",
      "Epoch 28/100\n",
      "380/380 [==============================] - 0s 106us/step - loss: 0.4324 - accuracy: 0.8289 - val_loss: 0.5980 - val_accuracy: 0.7669\n",
      "Epoch 29/100\n",
      "380/380 [==============================] - 0s 165us/step - loss: 0.4425 - accuracy: 0.8316 - val_loss: 0.5882 - val_accuracy: 0.7546\n",
      "Epoch 30/100\n",
      "380/380 [==============================] - 0s 311us/step - loss: 0.4664 - accuracy: 0.8053 - val_loss: 0.7534 - val_accuracy: 0.7485\n",
      "Epoch 31/100\n",
      "380/380 [==============================] - 0s 256us/step - loss: 0.4948 - accuracy: 0.8053 - val_loss: 0.6872 - val_accuracy: 0.7730\n",
      "Epoch 32/100\n",
      "380/380 [==============================] - 0s 236us/step - loss: 0.4725 - accuracy: 0.8132 - val_loss: 0.5773 - val_accuracy: 0.7669\n",
      "Epoch 33/100\n",
      "380/380 [==============================] - 0s 263us/step - loss: 0.4451 - accuracy: 0.8158 - val_loss: 0.9089 - val_accuracy: 0.7301\n",
      "Epoch 34/100\n",
      "380/380 [==============================] - 0s 175us/step - loss: 0.4072 - accuracy: 0.8368 - val_loss: 0.5093 - val_accuracy: 0.8466\n",
      "Epoch 35/100\n",
      "380/380 [==============================] - 0s 197us/step - loss: 0.3773 - accuracy: 0.8395 - val_loss: 0.4955 - val_accuracy: 0.8098\n",
      "Epoch 36/100\n",
      "380/380 [==============================] - 0s 346us/step - loss: 0.4035 - accuracy: 0.8474 - val_loss: 0.4862 - val_accuracy: 0.8160\n",
      "Epoch 37/100\n",
      "380/380 [==============================] - 0s 279us/step - loss: 0.3796 - accuracy: 0.8342 - val_loss: 0.6196 - val_accuracy: 0.7730\n",
      "Epoch 38/100\n",
      "380/380 [==============================] - 0s 239us/step - loss: 0.3590 - accuracy: 0.8632 - val_loss: 0.4780 - val_accuracy: 0.8466\n",
      "Epoch 39/100\n",
      "380/380 [==============================] - 0s 297us/step - loss: 0.3674 - accuracy: 0.8684 - val_loss: 0.5502 - val_accuracy: 0.8405\n",
      "Epoch 40/100\n",
      "380/380 [==============================] - 0s 194us/step - loss: 0.3605 - accuracy: 0.8684 - val_loss: 0.5241 - val_accuracy: 0.7914\n",
      "Epoch 41/100\n",
      "380/380 [==============================] - 0s 168us/step - loss: 0.3513 - accuracy: 0.8632 - val_loss: 0.4613 - val_accuracy: 0.8037\n",
      "Epoch 42/100\n",
      "380/380 [==============================] - 0s 157us/step - loss: 0.3593 - accuracy: 0.8789 - val_loss: 0.6841 - val_accuracy: 0.8221\n",
      "Epoch 43/100\n",
      "380/380 [==============================] - 0s 353us/step - loss: 0.3717 - accuracy: 0.8500 - val_loss: 0.9733 - val_accuracy: 0.7730\n",
      "Epoch 44/100\n",
      "380/380 [==============================] - 0s 296us/step - loss: 0.4284 - accuracy: 0.8368 - val_loss: 0.5229 - val_accuracy: 0.7853\n",
      "Epoch 45/100\n",
      "380/380 [==============================] - 0s 339us/step - loss: 0.4079 - accuracy: 0.8263 - val_loss: 0.6280 - val_accuracy: 0.8282\n",
      "Epoch 46/100\n",
      "380/380 [==============================] - 0s 279us/step - loss: 0.3541 - accuracy: 0.8553 - val_loss: 0.5328 - val_accuracy: 0.8160\n",
      "Epoch 47/100\n",
      "380/380 [==============================] - 0s 183us/step - loss: 0.3384 - accuracy: 0.8684 - val_loss: 0.6339 - val_accuracy: 0.8405\n",
      "Epoch 48/100\n",
      "380/380 [==============================] - 0s 110us/step - loss: 0.3230 - accuracy: 0.8684 - val_loss: 0.4883 - val_accuracy: 0.8405\n",
      "Epoch 49/100\n",
      "380/380 [==============================] - 0s 99us/step - loss: 0.3379 - accuracy: 0.8579 - val_loss: 0.4408 - val_accuracy: 0.8405\n",
      "Epoch 50/100\n",
      "380/380 [==============================] - 0s 105us/step - loss: 0.3387 - accuracy: 0.8737 - val_loss: 0.4649 - val_accuracy: 0.8466\n",
      "Epoch 51/100\n",
      "380/380 [==============================] - 0s 101us/step - loss: 0.3132 - accuracy: 0.8921 - val_loss: 0.6423 - val_accuracy: 0.8037\n",
      "Epoch 52/100\n",
      "380/380 [==============================] - 0s 109us/step - loss: 0.3222 - accuracy: 0.8711 - val_loss: 0.5006 - val_accuracy: 0.8160\n",
      "Epoch 53/100\n",
      "380/380 [==============================] - 0s 106us/step - loss: 0.3128 - accuracy: 0.8684 - val_loss: 0.5106 - val_accuracy: 0.8282\n",
      "Epoch 54/100\n",
      "380/380 [==============================] - 0s 138us/step - loss: 0.3264 - accuracy: 0.8737 - val_loss: 0.5553 - val_accuracy: 0.8405\n",
      "Epoch 55/100\n",
      "380/380 [==============================] - 0s 251us/step - loss: 0.3019 - accuracy: 0.8868 - val_loss: 0.5333 - val_accuracy: 0.8344\n",
      "Epoch 56/100\n",
      "380/380 [==============================] - 0s 302us/step - loss: 0.3206 - accuracy: 0.8789 - val_loss: 0.4579 - val_accuracy: 0.8466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "380/380 [==============================] - 0s 170us/step - loss: 0.3204 - accuracy: 0.8684 - val_loss: 0.6727 - val_accuracy: 0.8160\n",
      "Epoch 58/100\n",
      "380/380 [==============================] - 0s 111us/step - loss: 0.3349 - accuracy: 0.8684 - val_loss: 0.5838 - val_accuracy: 0.8528\n",
      "Epoch 59/100\n",
      "380/380 [==============================] - 0s 228us/step - loss: 0.3163 - accuracy: 0.8895 - val_loss: 0.5000 - val_accuracy: 0.8221\n",
      "Epoch 60/100\n",
      "380/380 [==============================] - 0s 302us/step - loss: 0.3234 - accuracy: 0.8816 - val_loss: 0.7760 - val_accuracy: 0.7730\n",
      "Epoch 61/100\n",
      "380/380 [==============================] - 0s 289us/step - loss: 0.3086 - accuracy: 0.8789 - val_loss: 0.5527 - val_accuracy: 0.8466\n",
      "Epoch 62/100\n",
      "380/380 [==============================] - 0s 233us/step - loss: 0.2886 - accuracy: 0.8868 - val_loss: 0.4317 - val_accuracy: 0.8650\n",
      "Epoch 63/100\n",
      "380/380 [==============================] - 0s 172us/step - loss: 0.3072 - accuracy: 0.8658 - val_loss: 0.4304 - val_accuracy: 0.8589\n",
      "Epoch 64/100\n",
      "380/380 [==============================] - 0s 200us/step - loss: 0.3289 - accuracy: 0.8737 - val_loss: 0.5656 - val_accuracy: 0.8098\n",
      "Epoch 65/100\n",
      "380/380 [==============================] - 0s 169us/step - loss: 0.2774 - accuracy: 0.8974 - val_loss: 0.5082 - val_accuracy: 0.7914\n",
      "Epoch 66/100\n",
      "380/380 [==============================] - 0s 155us/step - loss: 0.2772 - accuracy: 0.8684 - val_loss: 0.4029 - val_accuracy: 0.8405\n",
      "Epoch 67/100\n",
      "380/380 [==============================] - 0s 172us/step - loss: 0.2729 - accuracy: 0.9026 - val_loss: 0.4363 - val_accuracy: 0.8589\n",
      "Epoch 68/100\n",
      "380/380 [==============================] - 0s 157us/step - loss: 0.2572 - accuracy: 0.9079 - val_loss: 0.4455 - val_accuracy: 0.8466\n",
      "Epoch 69/100\n",
      "380/380 [==============================] - 0s 176us/step - loss: 0.2659 - accuracy: 0.9132 - val_loss: 0.4600 - val_accuracy: 0.8466\n",
      "Epoch 70/100\n",
      "380/380 [==============================] - 0s 147us/step - loss: 0.2612 - accuracy: 0.9132 - val_loss: 0.6944 - val_accuracy: 0.8405\n",
      "Epoch 71/100\n",
      "380/380 [==============================] - 0s 140us/step - loss: 0.2997 - accuracy: 0.8842 - val_loss: 0.6704 - val_accuracy: 0.8344\n",
      "Epoch 72/100\n",
      "380/380 [==============================] - 0s 140us/step - loss: 0.2626 - accuracy: 0.9158 - val_loss: 0.5578 - val_accuracy: 0.8589\n",
      "Epoch 73/100\n",
      "380/380 [==============================] - 0s 188us/step - loss: 0.2741 - accuracy: 0.9079 - val_loss: 0.5962 - val_accuracy: 0.8344\n",
      "Epoch 74/100\n",
      "380/380 [==============================] - 0s 132us/step - loss: 0.2788 - accuracy: 0.8947 - val_loss: 0.4937 - val_accuracy: 0.8466\n",
      "Epoch 75/100\n",
      "380/380 [==============================] - 0s 116us/step - loss: 0.2585 - accuracy: 0.8974 - val_loss: 0.4436 - val_accuracy: 0.8589\n",
      "Epoch 76/100\n",
      "380/380 [==============================] - 0s 192us/step - loss: 0.2915 - accuracy: 0.9132 - val_loss: 0.6686 - val_accuracy: 0.8037\n",
      "Epoch 77/100\n",
      "380/380 [==============================] - 0s 131us/step - loss: 0.2616 - accuracy: 0.9079 - val_loss: 0.4263 - val_accuracy: 0.8528\n",
      "Epoch 78/100\n",
      "380/380 [==============================] - 0s 124us/step - loss: 0.2683 - accuracy: 0.9132 - val_loss: 0.4716 - val_accuracy: 0.8344\n",
      "Epoch 79/100\n",
      "380/380 [==============================] - 0s 103us/step - loss: 0.2484 - accuracy: 0.9132 - val_loss: 0.4754 - val_accuracy: 0.8221\n",
      "Epoch 80/100\n",
      "380/380 [==============================] - 0s 114us/step - loss: 0.2516 - accuracy: 0.9132 - val_loss: 0.4110 - val_accuracy: 0.8528\n",
      "Epoch 81/100\n",
      "380/380 [==============================] - 0s 101us/step - loss: 0.2312 - accuracy: 0.9211 - val_loss: 0.4589 - val_accuracy: 0.8712\n",
      "Epoch 82/100\n",
      "380/380 [==============================] - 0s 115us/step - loss: 0.2467 - accuracy: 0.9053 - val_loss: 0.4300 - val_accuracy: 0.8466\n",
      "Epoch 83/100\n",
      "380/380 [==============================] - 0s 102us/step - loss: 0.2581 - accuracy: 0.9105 - val_loss: 0.4606 - val_accuracy: 0.8589\n",
      "Epoch 84/100\n",
      "380/380 [==============================] - 0s 108us/step - loss: 0.2670 - accuracy: 0.9053 - val_loss: 0.4431 - val_accuracy: 0.8650\n",
      "Epoch 85/100\n",
      "380/380 [==============================] - 0s 100us/step - loss: 0.2515 - accuracy: 0.8895 - val_loss: 0.3925 - val_accuracy: 0.8528\n",
      "Epoch 86/100\n",
      "380/380 [==============================] - 0s 111us/step - loss: 0.3393 - accuracy: 0.8763 - val_loss: 1.2943 - val_accuracy: 0.8160\n",
      "Epoch 87/100\n",
      "380/380 [==============================] - 0s 169us/step - loss: 0.3753 - accuracy: 0.8789 - val_loss: 0.6993 - val_accuracy: 0.8160\n",
      "Epoch 88/100\n",
      "380/380 [==============================] - 0s 123us/step - loss: 0.2827 - accuracy: 0.8816 - val_loss: 0.6030 - val_accuracy: 0.7975\n",
      "Epoch 89/100\n",
      "380/380 [==============================] - 0s 125us/step - loss: 0.2563 - accuracy: 0.9053 - val_loss: 0.8774 - val_accuracy: 0.8405\n",
      "Epoch 90/100\n",
      "380/380 [==============================] - 0s 111us/step - loss: 0.3014 - accuracy: 0.8921 - val_loss: 0.4669 - val_accuracy: 0.8344\n",
      "Epoch 91/100\n",
      "380/380 [==============================] - 0s 111us/step - loss: 0.2451 - accuracy: 0.9000 - val_loss: 0.5480 - val_accuracy: 0.8098\n",
      "Epoch 92/100\n",
      "380/380 [==============================] - 0s 147us/step - loss: 0.2574 - accuracy: 0.9026 - val_loss: 0.5558 - val_accuracy: 0.8466\n",
      "Epoch 93/100\n",
      "380/380 [==============================] - 0s 127us/step - loss: 0.2291 - accuracy: 0.9158 - val_loss: 0.4394 - val_accuracy: 0.8589\n",
      "Epoch 94/100\n",
      "380/380 [==============================] - 0s 110us/step - loss: 0.2184 - accuracy: 0.9132 - val_loss: 0.4423 - val_accuracy: 0.8589\n",
      "Epoch 95/100\n",
      "380/380 [==============================] - 0s 103us/step - loss: 0.2124 - accuracy: 0.9289 - val_loss: 0.3774 - val_accuracy: 0.8773\n",
      "Epoch 96/100\n",
      "380/380 [==============================] - 0s 119us/step - loss: 0.2068 - accuracy: 0.9237 - val_loss: 0.3906 - val_accuracy: 0.8528\n",
      "Epoch 97/100\n",
      "380/380 [==============================] - 0s 104us/step - loss: 0.2122 - accuracy: 0.9158 - val_loss: 0.5022 - val_accuracy: 0.8466\n",
      "Epoch 98/100\n",
      "380/380 [==============================] - 0s 118us/step - loss: 0.2199 - accuracy: 0.9263 - val_loss: 0.4157 - val_accuracy: 0.8282\n",
      "Epoch 99/100\n",
      "380/380 [==============================] - 0s 107us/step - loss: 0.2022 - accuracy: 0.9184 - val_loss: 0.4670 - val_accuracy: 0.8589\n",
      "Epoch 100/100\n",
      "380/380 [==============================] - 0s 114us/step - loss: 0.2018 - accuracy: 0.9289 - val_loss: 0.3791 - val_accuracy: 0.8528\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a343df0f0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over2.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163/163 [==============================] - 0s 85us/step\n",
      "over-sampling test accuracy: 87.12%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over2 = model1_over2.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over2*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 2, 1, 0, 0, 0, 1, 1, 1, 2, 0, 1, 1, 1, 2, 1, 1, 2, 2, 1, 0,\n",
       "       1, 0, 2, 1, 1, 0, 1, 2, 0, 0, 0, 2, 1, 0, 2, 1, 0, 0, 0, 0, 2, 1,\n",
       "       1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 2, 0, 0, 0, 2, 1, 2, 0, 2, 1,\n",
       "       0, 2, 1, 1, 2, 0, 1, 2, 0, 1, 2, 0, 0, 0, 1, 2, 1, 0, 1, 1, 1, 0,\n",
       "       2, 0, 2, 0, 1, 0, 0, 1, 0, 2, 2, 0, 0, 0, 1, 0, 1, 2, 0, 2, 1, 0,\n",
       "       1, 1, 0, 0, 2, 2, 2, 0, 1, 0, 2, 1, 2, 2, 1, 0, 1, 0, 0, 2, 0, 0,\n",
       "       2, 0, 1, 2, 1, 2, 2, 2, 1, 2, 0, 2, 0, 2, 0, 2, 0, 2, 1, 0, 0, 2,\n",
       "       1, 1, 2, 2, 2, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred2 = model1_over2.predict_classes(X_test_over)\n",
    "pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS027</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CFBRSa07</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CFBRSa27</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>504</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CFBREBSa129</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>SR3569</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>NRS243</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>GA48963</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>504</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>CFBREBSa123</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test  pred\n",
       "0         NRS027     0     0\n",
       "1       CFBRSa07     0     0\n",
       "2       CFBRSa27     1     2\n",
       "3            504     1     1\n",
       "4    CFBREBSa129     0     0\n",
       "..           ...   ...   ...\n",
       "158       SR3569     2     2\n",
       "159       NRS243     1     1\n",
       "160      GA48963     1     1\n",
       "161          504     1     1\n",
       "162  CFBREBSa123     0     0\n",
       "\n",
       "[163 rows x 3 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat2['pred'] = pred2\n",
    "dat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba2 = model1_over2.predict_proba(X_test_over)\n",
    "dat_proba2 = pd.DataFrame(proba2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.994396</td>\n",
       "      <td>0.001330</td>\n",
       "      <td>0.004274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.961208</td>\n",
       "      <td>0.000881</td>\n",
       "      <td>0.037912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.053490</td>\n",
       "      <td>0.266687</td>\n",
       "      <td>0.679823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.085465</td>\n",
       "      <td>0.727735</td>\n",
       "      <td>0.186799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.998393</td>\n",
       "      <td>0.000543</td>\n",
       "      <td>0.001063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>0.006205</td>\n",
       "      <td>0.370404</td>\n",
       "      <td>0.623390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>0.000759</td>\n",
       "      <td>0.846746</td>\n",
       "      <td>0.152496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>0.003221</td>\n",
       "      <td>0.879930</td>\n",
       "      <td>0.116850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>0.085465</td>\n",
       "      <td>0.727735</td>\n",
       "      <td>0.186799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>0.976387</td>\n",
       "      <td>0.013677</td>\n",
       "      <td>0.009936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2\n",
       "0    0.994396  0.001330  0.004274\n",
       "1    0.961208  0.000881  0.037912\n",
       "2    0.053490  0.266687  0.679823\n",
       "3    0.085465  0.727735  0.186799\n",
       "4    0.998393  0.000543  0.001063\n",
       "..        ...       ...       ...\n",
       "158  0.006205  0.370404  0.623390\n",
       "159  0.000759  0.846746  0.152496\n",
       "160  0.003221  0.879930  0.116850\n",
       "161  0.085465  0.727735  0.186799\n",
       "162  0.976387  0.013677  0.009936\n",
       "\n",
       "[163 rows x 3 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba2.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba2.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat2.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/2p11ST.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 380 samples, validate on 163 samples\n",
      "Epoch 1/100\n",
      "380/380 [==============================] - 0s 166us/step - loss: 0.2319 - accuracy: 0.9263 - val_loss: 0.4158 - val_accuracy: 0.8834\n",
      "Epoch 2/100\n",
      "380/380 [==============================] - 0s 134us/step - loss: 0.2278 - accuracy: 0.9211 - val_loss: 0.4776 - val_accuracy: 0.8834\n",
      "Epoch 3/100\n",
      "380/380 [==============================] - 0s 114us/step - loss: 0.2252 - accuracy: 0.9211 - val_loss: 0.4399 - val_accuracy: 0.8773\n",
      "Epoch 4/100\n",
      "380/380 [==============================] - 0s 134us/step - loss: 0.2260 - accuracy: 0.9263 - val_loss: 0.4163 - val_accuracy: 0.8712\n",
      "Epoch 5/100\n",
      "380/380 [==============================] - 0s 145us/step - loss: 0.2176 - accuracy: 0.9289 - val_loss: 0.4424 - val_accuracy: 0.8773\n",
      "Epoch 6/100\n",
      "380/380 [==============================] - 0s 148us/step - loss: 0.2253 - accuracy: 0.9211 - val_loss: 0.4417 - val_accuracy: 0.8896\n",
      "Epoch 7/100\n",
      "380/380 [==============================] - 0s 157us/step - loss: 0.2169 - accuracy: 0.9368 - val_loss: 0.4163 - val_accuracy: 0.8712\n",
      "Epoch 8/100\n",
      "380/380 [==============================] - 0s 110us/step - loss: 0.2385 - accuracy: 0.9158 - val_loss: 0.5503 - val_accuracy: 0.8589\n",
      "Epoch 9/100\n",
      "380/380 [==============================] - 0s 105us/step - loss: 0.2195 - accuracy: 0.9184 - val_loss: 0.5437 - val_accuracy: 0.8589\n",
      "Epoch 10/100\n",
      "380/380 [==============================] - 0s 102us/step - loss: 0.2217 - accuracy: 0.9132 - val_loss: 0.5417 - val_accuracy: 0.8650\n",
      "Epoch 11/100\n",
      "380/380 [==============================] - 0s 122us/step - loss: 0.2408 - accuracy: 0.9079 - val_loss: 0.4430 - val_accuracy: 0.8712\n",
      "Epoch 12/100\n",
      "380/380 [==============================] - 0s 121us/step - loss: 0.2351 - accuracy: 0.9079 - val_loss: 0.4121 - val_accuracy: 0.8834\n",
      "Epoch 13/100\n",
      "380/380 [==============================] - 0s 135us/step - loss: 0.2150 - accuracy: 0.9184 - val_loss: 0.4064 - val_accuracy: 0.8712\n",
      "Epoch 14/100\n",
      "380/380 [==============================] - 0s 148us/step - loss: 0.2101 - accuracy: 0.9237 - val_loss: 0.4240 - val_accuracy: 0.8650\n",
      "Epoch 15/100\n",
      "380/380 [==============================] - 0s 142us/step - loss: 0.2097 - accuracy: 0.9263 - val_loss: 0.4172 - val_accuracy: 0.8773\n",
      "Epoch 16/100\n",
      "380/380 [==============================] - 0s 146us/step - loss: 0.2319 - accuracy: 0.9211 - val_loss: 0.4723 - val_accuracy: 0.8405\n",
      "Epoch 17/100\n",
      "380/380 [==============================] - 0s 115us/step - loss: 0.2293 - accuracy: 0.9184 - val_loss: 0.4254 - val_accuracy: 0.8528\n",
      "Epoch 18/100\n",
      "380/380 [==============================] - 0s 116us/step - loss: 0.2007 - accuracy: 0.9237 - val_loss: 0.3696 - val_accuracy: 0.8834\n",
      "Epoch 19/100\n",
      "380/380 [==============================] - 0s 124us/step - loss: 0.2069 - accuracy: 0.9263 - val_loss: 0.4093 - val_accuracy: 0.8834\n",
      "Epoch 20/100\n",
      "380/380 [==============================] - 0s 123us/step - loss: 0.2137 - accuracy: 0.9211 - val_loss: 0.4322 - val_accuracy: 0.8712\n",
      "Epoch 21/100\n",
      "380/380 [==============================] - 0s 113us/step - loss: 0.2125 - accuracy: 0.9184 - val_loss: 0.4379 - val_accuracy: 0.8834\n",
      "Epoch 22/100\n",
      "380/380 [==============================] - 0s 109us/step - loss: 0.2118 - accuracy: 0.9211 - val_loss: 0.3927 - val_accuracy: 0.8650\n",
      "Epoch 23/100\n",
      "380/380 [==============================] - 0s 108us/step - loss: 0.2043 - accuracy: 0.9184 - val_loss: 0.4263 - val_accuracy: 0.8528\n",
      "Epoch 24/100\n",
      "380/380 [==============================] - 0s 128us/step - loss: 0.2089 - accuracy: 0.9132 - val_loss: 0.3694 - val_accuracy: 0.8712\n",
      "Epoch 25/100\n",
      "380/380 [==============================] - 0s 133us/step - loss: 0.1940 - accuracy: 0.9289 - val_loss: 0.3805 - val_accuracy: 0.8834\n",
      "Epoch 26/100\n",
      "380/380 [==============================] - 0s 138us/step - loss: 0.1953 - accuracy: 0.9342 - val_loss: 0.3797 - val_accuracy: 0.8712\n",
      "Epoch 27/100\n",
      "380/380 [==============================] - 0s 141us/step - loss: 0.1928 - accuracy: 0.9316 - val_loss: 0.3965 - val_accuracy: 0.8773\n",
      "Epoch 28/100\n",
      "380/380 [==============================] - 0s 136us/step - loss: 0.1994 - accuracy: 0.9368 - val_loss: 0.3978 - val_accuracy: 0.8896\n",
      "Epoch 29/100\n",
      "380/380 [==============================] - 0s 125us/step - loss: 0.2025 - accuracy: 0.9211 - val_loss: 0.4587 - val_accuracy: 0.8712\n",
      "Epoch 30/100\n",
      "380/380 [==============================] - 0s 135us/step - loss: 0.2080 - accuracy: 0.9316 - val_loss: 0.4150 - val_accuracy: 0.8834\n",
      "Epoch 31/100\n",
      "380/380 [==============================] - 0s 143us/step - loss: 0.2225 - accuracy: 0.9184 - val_loss: 0.6906 - val_accuracy: 0.8589\n",
      "Epoch 32/100\n",
      "380/380 [==============================] - 0s 120us/step - loss: 0.2102 - accuracy: 0.9079 - val_loss: 0.4228 - val_accuracy: 0.8896\n",
      "Epoch 33/100\n",
      "380/380 [==============================] - 0s 111us/step - loss: 0.1988 - accuracy: 0.9263 - val_loss: 0.5948 - val_accuracy: 0.8466\n",
      "Epoch 34/100\n",
      "380/380 [==============================] - 0s 115us/step - loss: 0.2024 - accuracy: 0.9289 - val_loss: 0.4716 - val_accuracy: 0.8896\n",
      "Epoch 35/100\n",
      "380/380 [==============================] - 0s 111us/step - loss: 0.2060 - accuracy: 0.9263 - val_loss: 0.3998 - val_accuracy: 0.8896\n",
      "Epoch 36/100\n",
      "380/380 [==============================] - 0s 135us/step - loss: 0.2211 - accuracy: 0.9132 - val_loss: 0.3862 - val_accuracy: 0.8650\n",
      "Epoch 37/100\n",
      "380/380 [==============================] - 0s 116us/step - loss: 0.2170 - accuracy: 0.9132 - val_loss: 0.4546 - val_accuracy: 0.8773\n",
      "Epoch 38/100\n",
      "380/380 [==============================] - 0s 142us/step - loss: 0.2261 - accuracy: 0.9263 - val_loss: 0.4467 - val_accuracy: 0.8712\n",
      "Epoch 39/100\n",
      "380/380 [==============================] - 0s 106us/step - loss: 0.2188 - accuracy: 0.9079 - val_loss: 0.4733 - val_accuracy: 0.8528\n",
      "Epoch 40/100\n",
      "380/380 [==============================] - 0s 110us/step - loss: 0.2031 - accuracy: 0.9263 - val_loss: 0.4543 - val_accuracy: 0.8896\n",
      "Epoch 41/100\n",
      "380/380 [==============================] - 0s 101us/step - loss: 0.1921 - accuracy: 0.9395 - val_loss: 0.4086 - val_accuracy: 0.8773\n",
      "Epoch 42/100\n",
      "380/380 [==============================] - 0s 110us/step - loss: 0.1879 - accuracy: 0.9289 - val_loss: 0.4004 - val_accuracy: 0.8712\n",
      "Epoch 43/100\n",
      "380/380 [==============================] - 0s 104us/step - loss: 0.1949 - accuracy: 0.9105 - val_loss: 0.4115 - val_accuracy: 0.8896\n",
      "Epoch 44/100\n",
      "380/380 [==============================] - 0s 103us/step - loss: 0.2243 - accuracy: 0.9105 - val_loss: 0.4250 - val_accuracy: 0.8773\n",
      "Epoch 45/100\n",
      "380/380 [==============================] - 0s 96us/step - loss: 0.1903 - accuracy: 0.9395 - val_loss: 0.4381 - val_accuracy: 0.8466\n",
      "Epoch 46/100\n",
      "380/380 [==============================] - 0s 96us/step - loss: 0.1797 - accuracy: 0.9316 - val_loss: 0.4079 - val_accuracy: 0.8957\n",
      "Epoch 47/100\n",
      "380/380 [==============================] - 0s 100us/step - loss: 0.1832 - accuracy: 0.9368 - val_loss: 0.3755 - val_accuracy: 0.8773\n",
      "Epoch 48/100\n",
      "380/380 [==============================] - 0s 101us/step - loss: 0.1846 - accuracy: 0.9316 - val_loss: 0.3967 - val_accuracy: 0.8896\n",
      "Epoch 49/100\n",
      "380/380 [==============================] - 0s 108us/step - loss: 0.1957 - accuracy: 0.9211 - val_loss: 0.4476 - val_accuracy: 0.9018\n",
      "Epoch 50/100\n",
      "380/380 [==============================] - 0s 107us/step - loss: 0.1823 - accuracy: 0.9368 - val_loss: 0.3731 - val_accuracy: 0.8773\n",
      "Epoch 51/100\n",
      "380/380 [==============================] - 0s 123us/step - loss: 0.1881 - accuracy: 0.9342 - val_loss: 0.5333 - val_accuracy: 0.8650\n",
      "Epoch 52/100\n",
      "380/380 [==============================] - 0s 126us/step - loss: 0.2033 - accuracy: 0.9184 - val_loss: 0.5776 - val_accuracy: 0.8344\n",
      "Epoch 53/100\n",
      "380/380 [==============================] - 0s 133us/step - loss: 0.1837 - accuracy: 0.9263 - val_loss: 0.5025 - val_accuracy: 0.8834\n",
      "Epoch 54/100\n",
      "380/380 [==============================] - 0s 125us/step - loss: 0.1796 - accuracy: 0.9316 - val_loss: 0.4629 - val_accuracy: 0.8773\n",
      "Epoch 55/100\n",
      "380/380 [==============================] - 0s 108us/step - loss: 0.1790 - accuracy: 0.9316 - val_loss: 0.3741 - val_accuracy: 0.8834\n",
      "Epoch 56/100\n",
      "380/380 [==============================] - 0s 101us/step - loss: 0.1887 - accuracy: 0.9158 - val_loss: 0.3835 - val_accuracy: 0.8834\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "380/380 [==============================] - 0s 99us/step - loss: 0.1736 - accuracy: 0.9342 - val_loss: 0.3671 - val_accuracy: 0.8834\n",
      "Epoch 58/100\n",
      "380/380 [==============================] - 0s 99us/step - loss: 0.1984 - accuracy: 0.9132 - val_loss: 0.4490 - val_accuracy: 0.8773\n",
      "Epoch 59/100\n",
      "380/380 [==============================] - 0s 109us/step - loss: 0.1799 - accuracy: 0.9237 - val_loss: 0.5675 - val_accuracy: 0.8098\n",
      "Epoch 60/100\n",
      "380/380 [==============================] - 0s 120us/step - loss: 0.2005 - accuracy: 0.9158 - val_loss: 0.3894 - val_accuracy: 0.8773\n",
      "Epoch 61/100\n",
      "380/380 [==============================] - 0s 192us/step - loss: 0.1734 - accuracy: 0.9500 - val_loss: 0.3917 - val_accuracy: 0.8896\n",
      "Epoch 62/100\n",
      "380/380 [==============================] - 0s 186us/step - loss: 0.1729 - accuracy: 0.9447 - val_loss: 0.4089 - val_accuracy: 0.8957\n",
      "Epoch 63/100\n",
      "380/380 [==============================] - 0s 144us/step - loss: 0.1664 - accuracy: 0.9395 - val_loss: 0.3520 - val_accuracy: 0.8834\n",
      "Epoch 64/100\n",
      "380/380 [==============================] - 0s 129us/step - loss: 0.1772 - accuracy: 0.9316 - val_loss: 0.3702 - val_accuracy: 0.8896\n",
      "Epoch 65/100\n",
      "380/380 [==============================] - 0s 129us/step - loss: 0.1800 - accuracy: 0.9263 - val_loss: 0.3504 - val_accuracy: 0.8773\n",
      "Epoch 66/100\n",
      "380/380 [==============================] - 0s 131us/step - loss: 0.1880 - accuracy: 0.9316 - val_loss: 0.4331 - val_accuracy: 0.8773\n",
      "Epoch 67/100\n",
      "380/380 [==============================] - 0s 148us/step - loss: 0.1871 - accuracy: 0.9368 - val_loss: 0.6411 - val_accuracy: 0.8834\n",
      "Epoch 68/100\n",
      "380/380 [==============================] - 0s 142us/step - loss: 0.2130 - accuracy: 0.9211 - val_loss: 0.4915 - val_accuracy: 0.8160\n",
      "Epoch 69/100\n",
      "380/380 [==============================] - 0s 141us/step - loss: 0.2329 - accuracy: 0.9105 - val_loss: 0.5099 - val_accuracy: 0.8896\n",
      "Epoch 70/100\n",
      "380/380 [==============================] - 0s 176us/step - loss: 0.2727 - accuracy: 0.9132 - val_loss: 1.7981 - val_accuracy: 0.8405\n",
      "Epoch 71/100\n",
      "380/380 [==============================] - 0s 457us/step - loss: 0.3832 - accuracy: 0.8895 - val_loss: 0.5446 - val_accuracy: 0.8160\n",
      "Epoch 72/100\n",
      "380/380 [==============================] - 0s 172us/step - loss: 0.2143 - accuracy: 0.9263 - val_loss: 0.7230 - val_accuracy: 0.8528\n",
      "Epoch 73/100\n",
      "380/380 [==============================] - 0s 192us/step - loss: 0.2157 - accuracy: 0.9079 - val_loss: 0.7463 - val_accuracy: 0.7853\n",
      "Epoch 74/100\n",
      "380/380 [==============================] - 0s 202us/step - loss: 0.1856 - accuracy: 0.9263 - val_loss: 0.5585 - val_accuracy: 0.8834\n",
      "Epoch 75/100\n",
      "380/380 [==============================] - 0s 139us/step - loss: 0.1787 - accuracy: 0.9395 - val_loss: 0.6198 - val_accuracy: 0.8834\n",
      "Epoch 76/100\n",
      "380/380 [==============================] - 0s 118us/step - loss: 0.1628 - accuracy: 0.9342 - val_loss: 0.6373 - val_accuracy: 0.8834\n",
      "Epoch 77/100\n",
      "380/380 [==============================] - 0s 109us/step - loss: 0.1711 - accuracy: 0.9342 - val_loss: 0.6204 - val_accuracy: 0.8712\n",
      "Epoch 78/100\n",
      "380/380 [==============================] - 0s 129us/step - loss: 0.1650 - accuracy: 0.9395 - val_loss: 0.6047 - val_accuracy: 0.8650\n",
      "Epoch 79/100\n",
      "380/380 [==============================] - 0s 154us/step - loss: 0.1629 - accuracy: 0.9395 - val_loss: 0.5088 - val_accuracy: 0.8773\n",
      "Epoch 80/100\n",
      "380/380 [==============================] - 0s 121us/step - loss: 0.1694 - accuracy: 0.9316 - val_loss: 0.5381 - val_accuracy: 0.8896\n",
      "Epoch 81/100\n",
      "380/380 [==============================] - 0s 117us/step - loss: 0.1627 - accuracy: 0.9263 - val_loss: 0.5217 - val_accuracy: 0.8712\n",
      "Epoch 82/100\n",
      "380/380 [==============================] - 0s 114us/step - loss: 0.1943 - accuracy: 0.9079 - val_loss: 0.5077 - val_accuracy: 0.8896\n",
      "Epoch 83/100\n",
      "380/380 [==============================] - 0s 129us/step - loss: 0.1835 - accuracy: 0.9316 - val_loss: 0.6133 - val_accuracy: 0.8466\n",
      "Epoch 84/100\n",
      "380/380 [==============================] - 0s 116us/step - loss: 0.1804 - accuracy: 0.9447 - val_loss: 0.6135 - val_accuracy: 0.8098\n",
      "Epoch 85/100\n",
      "380/380 [==============================] - 0s 109us/step - loss: 0.2166 - accuracy: 0.9105 - val_loss: 0.4935 - val_accuracy: 0.8834\n",
      "Epoch 86/100\n",
      "380/380 [==============================] - 0s 103us/step - loss: 0.2090 - accuracy: 0.9105 - val_loss: 0.5760 - val_accuracy: 0.8957\n",
      "Epoch 87/100\n",
      "380/380 [==============================] - 0s 104us/step - loss: 0.1849 - accuracy: 0.9237 - val_loss: 0.5210 - val_accuracy: 0.8466\n",
      "Epoch 88/100\n",
      "380/380 [==============================] - 0s 275us/step - loss: 0.1794 - accuracy: 0.9289 - val_loss: 0.7123 - val_accuracy: 0.8160\n",
      "Epoch 89/100\n",
      "380/380 [==============================] - 0s 204us/step - loss: 0.1748 - accuracy: 0.9342 - val_loss: 0.4415 - val_accuracy: 0.8834\n",
      "Epoch 90/100\n",
      "380/380 [==============================] - 0s 145us/step - loss: 0.1583 - accuracy: 0.9474 - val_loss: 0.4618 - val_accuracy: 0.8834\n",
      "Epoch 91/100\n",
      "380/380 [==============================] - 0s 132us/step - loss: 0.1523 - accuracy: 0.9447 - val_loss: 0.4928 - val_accuracy: 0.8712\n",
      "Epoch 92/100\n",
      "380/380 [==============================] - 0s 124us/step - loss: 0.1551 - accuracy: 0.9447 - val_loss: 0.4604 - val_accuracy: 0.8773\n",
      "Epoch 93/100\n",
      "380/380 [==============================] - 0s 122us/step - loss: 0.1498 - accuracy: 0.9500 - val_loss: 0.4652 - val_accuracy: 0.8896\n",
      "Epoch 94/100\n",
      "380/380 [==============================] - 0s 119us/step - loss: 0.1599 - accuracy: 0.9395 - val_loss: 0.5085 - val_accuracy: 0.8896\n",
      "Epoch 95/100\n",
      "380/380 [==============================] - 0s 105us/step - loss: 0.1587 - accuracy: 0.9316 - val_loss: 0.4887 - val_accuracy: 0.8834\n",
      "Epoch 96/100\n",
      "380/380 [==============================] - 0s 117us/step - loss: 0.1628 - accuracy: 0.9447 - val_loss: 0.5179 - val_accuracy: 0.8405\n",
      "Epoch 97/100\n",
      "380/380 [==============================] - 0s 111us/step - loss: 0.1488 - accuracy: 0.9395 - val_loss: 0.4275 - val_accuracy: 0.8834\n",
      "Epoch 98/100\n",
      "380/380 [==============================] - 0s 116us/step - loss: 0.1459 - accuracy: 0.9500 - val_loss: 0.4118 - val_accuracy: 0.8712\n",
      "Epoch 99/100\n",
      "380/380 [==============================] - 0s 114us/step - loss: 0.1435 - accuracy: 0.9526 - val_loss: 0.4822 - val_accuracy: 0.8896\n",
      "Epoch 100/100\n",
      "380/380 [==============================] - 0s 112us/step - loss: 0.1500 - accuracy: 0.9421 - val_loss: 0.4064 - val_accuracy: 0.8712\n"
     ]
    }
   ],
   "source": [
    "hist1_over2 = model1_over2.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 92.68%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over2.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba2 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_2.xlsx\",\n",
    "                        sheet_name=1,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>1.748042e-03</td>\n",
       "      <td>9.981960e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>BCH-SA-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.712007</td>\n",
       "      <td>2.879924e-01</td>\n",
       "      <td>9.646217e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS218</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.006222</td>\n",
       "      <td>9.937732e-01</td>\n",
       "      <td>4.482882e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS036</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.882617</td>\n",
       "      <td>1.173831e-01</td>\n",
       "      <td>2.310933e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS386</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.571179</td>\n",
       "      <td>4.288184e-01</td>\n",
       "      <td>2.444667e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4279</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS112</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001860</td>\n",
       "      <td>9.979747e-01</td>\n",
       "      <td>1.653396e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4280</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>SR1065</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.982940</td>\n",
       "      <td>1.705227e-02</td>\n",
       "      <td>7.349168e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4281</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS203</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.997093</td>\n",
       "      <td>1.962516e-03</td>\n",
       "      <td>9.441347e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4282</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>CFBREBSa129</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.031141e-13</td>\n",
       "      <td>3.208205e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4283</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>CFBRSa25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999833</td>\n",
       "      <td>1.669456e-04</td>\n",
       "      <td>4.411099e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4284 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    phage       strain  phenotype  prediction         0  \\\n",
       "0      p002ykpresabs_qual       NRS148          2           2  0.000056   \n",
       "1      p002ykpresabs_qual    BCH-SA-03          1           0  0.712007   \n",
       "2      p002ykpresabs_qual       NRS218          1           1  0.006222   \n",
       "3      p002ykpresabs_qual       NRS036          0           0  0.882617   \n",
       "4      p002ykpresabs_qual       NRS386          1           0  0.571179   \n",
       "...                   ...          ...        ...         ...       ...   \n",
       "4279  pyopresabsSTCC_qual       NRS112          1           1  0.001860   \n",
       "4280  pyopresabsSTCC_qual       SR1065          0           0  0.982940   \n",
       "4281  pyopresabsSTCC_qual       NRS203          0           0  0.997093   \n",
       "4282  pyopresabsSTCC_qual  CFBREBSa129          0           0  1.000000   \n",
       "4283  pyopresabsSTCC_qual     CFBRSa25          0           0  0.999833   \n",
       "\n",
       "                 1             2  \n",
       "0     1.748042e-03  9.981960e-01  \n",
       "1     2.879924e-01  9.646217e-07  \n",
       "2     9.937732e-01  4.482882e-06  \n",
       "3     1.173831e-01  2.310933e-10  \n",
       "4     4.288184e-01  2.444667e-06  \n",
       "...            ...           ...  \n",
       "4279  9.979747e-01  1.653396e-04  \n",
       "4280  1.705227e-02  7.349168e-06  \n",
       "4281  1.962516e-03  9.441347e-04  \n",
       "4282  3.031141e-13  3.208205e-09  \n",
       "4283  1.669456e-04  4.411099e-08  \n",
       "\n",
       "[4284 rows x 7 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.94396000e-01, 1.32980950e-03, 4.27422160e-03],\n",
       "       [9.61207750e-01, 8.80568640e-04, 3.79116500e-02],\n",
       "       [5.34895360e-02, 2.66687100e-01, 6.79823340e-01],\n",
       "       [8.54651000e-02, 7.27735460e-01, 1.86799440e-01],\n",
       "       [9.98393360e-01, 5.43411650e-04, 1.06315510e-03],\n",
       "       [7.70516750e-01, 3.76311040e-03, 2.25720140e-01],\n",
       "       [9.98393360e-01, 5.43411650e-04, 1.06315510e-03],\n",
       "       [9.30541600e-03, 8.23767800e-01, 1.66926770e-01],\n",
       "       [6.01886660e-02, 7.81871300e-01, 1.57940090e-01],\n",
       "       [1.23160430e-02, 9.86002100e-01, 1.68187890e-03],\n",
       "       [5.67502200e-03, 1.92466120e-02, 9.75078340e-01],\n",
       "       [9.99978400e-01, 2.46232960e-06, 1.90811720e-05],\n",
       "       [9.29017500e-02, 6.85308100e-01, 2.21790210e-01],\n",
       "       [4.35464200e-02, 8.62436650e-01, 9.40169900e-02],\n",
       "       [1.13634600e-05, 9.97874000e-01, 2.11451970e-03],\n",
       "       [1.96913160e-03, 7.52602600e-03, 9.90504800e-01],\n",
       "       [7.43332840e-04, 9.15225860e-01, 8.40307700e-02],\n",
       "       [2.34066000e-04, 7.14771870e-01, 2.84994040e-01],\n",
       "       [4.48775850e-02, 2.37815410e-01, 7.17307030e-01],\n",
       "       [3.17002570e-02, 1.39326540e-01, 8.28973230e-01],\n",
       "       [3.22060920e-03, 8.79929660e-01, 1.16849710e-01],\n",
       "       [9.95439100e-01, 2.08244050e-03, 2.47844630e-03],\n",
       "       [6.92383300e-04, 9.99237540e-01, 7.00604360e-05],\n",
       "       [9.95439100e-01, 2.08244050e-03, 2.47844630e-03],\n",
       "       [7.49995200e-05, 1.47486340e-02, 9.85176300e-01],\n",
       "       [9.15521160e-02, 4.61809100e-01, 4.46638730e-01],\n",
       "       [1.23160430e-02, 9.86002100e-01, 1.68187890e-03],\n",
       "       [9.95439100e-01, 2.08244050e-03, 2.47844630e-03],\n",
       "       [3.35655010e-03, 8.12797070e-01, 1.83846310e-01],\n",
       "       [4.79235100e-03, 2.38504950e-02, 9.71357100e-01],\n",
       "       [9.84299540e-01, 9.29215500e-03, 6.40826400e-03],\n",
       "       [8.69885100e-01, 5.39531330e-03, 1.24719630e-01],\n",
       "       [9.94396000e-01, 1.32980950e-03, 4.27422160e-03],\n",
       "       [7.09623700e-03, 1.24723140e-02, 9.80431500e-01],\n",
       "       [3.57626500e-03, 8.72351000e-01, 1.24072716e-01],\n",
       "       [9.94396000e-01, 1.32980950e-03, 4.27422160e-03],\n",
       "       [3.72228350e-05, 6.26192900e-02, 9.37343400e-01],\n",
       "       [5.33703250e-03, 9.33493900e-01, 6.11690000e-02],\n",
       "       [8.69885100e-01, 5.39531330e-03, 1.24719630e-01],\n",
       "       [9.48618650e-01, 1.54932040e-02, 3.58881060e-02],\n",
       "       [8.69885100e-01, 5.39531330e-03, 1.24719630e-01],\n",
       "       [9.99404900e-01, 2.72768920e-06, 5.92410740e-04],\n",
       "       [8.57900130e-04, 1.98306680e-02, 9.79311400e-01],\n",
       "       [2.11303490e-05, 9.88224150e-01, 1.17547390e-02],\n",
       "       [9.97852160e-02, 8.54283870e-01, 4.59308850e-02],\n",
       "       [9.84259900e-01, 1.88152540e-03, 1.38585300e-02],\n",
       "       [5.05506340e-01, 1.02201570e-01, 3.92292080e-01],\n",
       "       [8.54651000e-02, 7.27735460e-01, 1.86799440e-01],\n",
       "       [4.38523500e-02, 9.53073400e-01, 3.07425440e-03],\n",
       "       [9.91640700e-01, 4.96362000e-03, 3.39570690e-03],\n",
       "       [8.18121900e-01, 1.66767340e-01, 1.51107630e-02],\n",
       "       [6.01886660e-02, 7.81871300e-01, 1.57940090e-01],\n",
       "       [9.48618650e-01, 1.54932040e-02, 3.58881060e-02],\n",
       "       [2.34066000e-04, 7.14771870e-01, 2.84994040e-01],\n",
       "       [9.84259900e-01, 1.88152540e-03, 1.38585300e-02],\n",
       "       [5.70517360e-01, 3.55646550e-01, 7.38361300e-02],\n",
       "       [2.39230520e-02, 2.49912930e-01, 7.26164000e-01],\n",
       "       [5.05506340e-01, 1.02201570e-01, 3.92292080e-01],\n",
       "       [9.84299540e-01, 9.29215500e-03, 6.40826400e-03],\n",
       "       [9.84299540e-01, 9.29215500e-03, 6.40826400e-03],\n",
       "       [2.43442820e-01, 1.40634730e-01, 6.15922500e-01],\n",
       "       [3.35655010e-03, 8.12797070e-01, 1.83846310e-01],\n",
       "       [2.79300400e-06, 1.08078370e-03, 9.98916400e-01],\n",
       "       [9.97661350e-01, 1.10928400e-03, 1.22933000e-03],\n",
       "       [2.99130900e-02, 6.53702530e-03, 9.63550000e-01],\n",
       "       [6.68105440e-03, 9.68244400e-01, 2.50745230e-02],\n",
       "       [9.90455100e-01, 4.41680950e-04, 9.10315300e-03],\n",
       "       [2.21715030e-03, 1.84240900e-01, 8.13541900e-01],\n",
       "       [5.18941600e-04, 9.68937600e-01, 3.05434600e-02],\n",
       "       [1.05702110e-02, 9.81724140e-01, 7.70561800e-03],\n",
       "       [2.14013180e-05, 2.67012580e-03, 9.97308500e-01],\n",
       "       [9.98393360e-01, 5.43411650e-04, 1.06315510e-03],\n",
       "       [2.11303490e-05, 9.88224150e-01, 1.17547390e-02],\n",
       "       [4.17984000e-04, 9.75227000e-03, 9.89829700e-01],\n",
       "       [8.62069960e-01, 8.21728600e-02, 5.57571580e-02],\n",
       "       [8.54651000e-02, 7.27735460e-01, 1.86799440e-01],\n",
       "       [2.25196420e-04, 5.41595700e-03, 9.94358840e-01],\n",
       "       [9.50767900e-01, 6.15510860e-03, 4.30770200e-02],\n",
       "       [8.59180900e-01, 4.48218920e-02, 9.59972100e-02],\n",
       "       [3.88415700e-01, 2.54584600e-01, 3.56999750e-01],\n",
       "       [2.19329740e-02, 9.77613700e-01, 4.53366350e-04],\n",
       "       [2.66204380e-03, 3.57475240e-02, 9.61590400e-01],\n",
       "       [7.43332840e-04, 9.15225860e-01, 8.40307700e-02],\n",
       "       [8.59180900e-01, 4.48218920e-02, 9.59972100e-02],\n",
       "       [8.54651000e-02, 7.27735460e-01, 1.86799440e-01],\n",
       "       [7.43332840e-04, 9.15225860e-01, 8.40307700e-02],\n",
       "       [6.54689500e-04, 5.02903460e-01, 4.96441870e-01],\n",
       "       [9.01064930e-01, 3.38566230e-04, 9.85965000e-02],\n",
       "       [9.89889350e-02, 8.20812600e-02, 8.18929850e-01],\n",
       "       [8.82164300e-01, 2.91423930e-02, 8.86932100e-02],\n",
       "       [4.88176200e-02, 1.12310650e-01, 8.38871700e-01],\n",
       "       [9.98393360e-01, 5.43411650e-04, 1.06315510e-03],\n",
       "       [1.54187180e-02, 9.26607800e-01, 5.79735100e-02],\n",
       "       [9.58353160e-01, 1.35915790e-02, 2.80553010e-02],\n",
       "       [9.97661350e-01, 1.10928400e-03, 1.22933000e-03],\n",
       "       [1.09877830e-02, 9.02378300e-01, 8.66339100e-02],\n",
       "       [9.89838100e-01, 7.14417600e-04, 9.44754700e-03],\n",
       "       [1.16367760e-01, 3.51479800e-02, 8.48484200e-01],\n",
       "       [2.97805800e-04, 1.90146200e-01, 8.09556000e-01],\n",
       "       [9.58353160e-01, 1.35915790e-02, 2.80553010e-02],\n",
       "       [9.91640700e-01, 4.96362000e-03, 3.39570690e-03],\n",
       "       [9.94396000e-01, 1.32980950e-03, 4.27422160e-03],\n",
       "       [6.92383300e-04, 9.99237540e-01, 7.00604360e-05],\n",
       "       [9.94396000e-01, 1.32980950e-03, 4.27422160e-03],\n",
       "       [6.92383300e-04, 9.99237540e-01, 7.00604360e-05],\n",
       "       [8.87640200e-03, 2.88395700e-01, 7.02727850e-01],\n",
       "       [4.54123050e-01, 4.21127560e-01, 1.24749390e-01],\n",
       "       [2.01228300e-04, 6.75186500e-03, 9.93046940e-01],\n",
       "       [3.35655010e-03, 8.12797070e-01, 1.83846310e-01],\n",
       "       [9.89838100e-01, 7.14417600e-04, 9.44754700e-03],\n",
       "       [9.13230800e-05, 9.94323130e-01, 5.58556240e-03],\n",
       "       [2.19329740e-02, 9.77613700e-01, 4.53366350e-04],\n",
       "       [9.61207750e-01, 8.80568640e-04, 3.79116500e-02],\n",
       "       [9.91640700e-01, 4.96362000e-03, 3.39570690e-03],\n",
       "       [3.74665380e-01, 8.62989650e-02, 5.39035700e-01],\n",
       "       [3.93690800e-04, 3.62166020e-03, 9.95984700e-01],\n",
       "       [4.04695100e-01, 9.79506400e-04, 5.94325400e-01],\n",
       "       [4.52185480e-01, 4.14822070e-01, 1.32992390e-01],\n",
       "       [1.73156030e-04, 9.65122600e-01, 3.47043240e-02],\n",
       "       [9.95439100e-01, 2.08244050e-03, 2.47844630e-03],\n",
       "       [4.22122500e-02, 2.76403070e-01, 6.81384600e-01],\n",
       "       [9.97852160e-02, 8.54283870e-01, 4.59308850e-02],\n",
       "       [5.17584300e-03, 1.27759050e-01, 8.67065130e-01],\n",
       "       [3.11736410e-03, 4.36138800e-01, 5.60743870e-01],\n",
       "       [3.22060920e-03, 8.79929660e-01, 1.16849710e-01],\n",
       "       [9.94396000e-01, 1.32980950e-03, 4.27422160e-03],\n",
       "       [1.34052470e-02, 9.36846200e-01, 4.97485500e-02],\n",
       "       [9.88934600e-01, 4.09028030e-03, 6.97507800e-03],\n",
       "       [8.69885100e-01, 5.39531330e-03, 1.24719630e-01],\n",
       "       [3.74968830e-02, 4.77052630e-02, 9.14797900e-01],\n",
       "       [9.99404900e-01, 2.72768920e-06, 5.92410740e-04],\n",
       "       [4.75567900e-01, 3.73850170e-01, 1.50581960e-01],\n",
       "       [1.83291300e-04, 9.07749000e-03, 9.90739200e-01],\n",
       "       [9.48618650e-01, 1.54932040e-02, 3.58881060e-02],\n",
       "       [2.47304840e-03, 5.27423700e-01, 4.70103300e-01],\n",
       "       [4.75934500e-02, 8.86228200e-02, 8.63783700e-01],\n",
       "       [1.82427520e-03, 9.97723760e-01, 4.51989380e-04],\n",
       "       [5.34895360e-02, 2.66687100e-01, 6.79823340e-01],\n",
       "       [5.29049500e-03, 8.67261100e-02, 9.07983400e-01],\n",
       "       [2.02176870e-02, 3.77660270e-03, 9.76005730e-01],\n",
       "       [1.82427520e-03, 9.97723760e-01, 4.51989380e-04],\n",
       "       [5.80691130e-03, 3.99932700e-02, 9.54199800e-01],\n",
       "       [8.18121900e-01, 1.66767340e-01, 1.51107630e-02],\n",
       "       [6.08787700e-05, 3.11940500e-03, 9.96819730e-01],\n",
       "       [9.99404900e-01, 2.72768920e-06, 5.92410740e-04],\n",
       "       [1.65558360e-02, 4.23230740e-01, 5.60213400e-01],\n",
       "       [9.58353160e-01, 1.35915790e-02, 2.80553010e-02],\n",
       "       [2.02176870e-02, 3.77660270e-03, 9.76005730e-01],\n",
       "       [8.53277100e-01, 4.27618160e-04, 1.46295280e-01],\n",
       "       [3.69639660e-02, 1.06870710e-01, 8.56165350e-01],\n",
       "       [3.35655010e-03, 8.12797070e-01, 1.83846310e-01],\n",
       "       [8.21621000e-01, 1.57126090e-03, 1.76807820e-01],\n",
       "       [9.84259900e-01, 1.88152540e-03, 1.38585300e-02],\n",
       "       [3.86337210e-03, 9.28308700e-03, 9.86853500e-01],\n",
       "       [2.23511000e-03, 5.56387540e-01, 4.41377300e-01],\n",
       "       [4.24274900e-03, 9.58350300e-01, 3.74069030e-02],\n",
       "       [5.34895360e-02, 2.66687100e-01, 6.79823340e-01],\n",
       "       [3.29140600e-02, 1.38693000e-01, 8.28392900e-01],\n",
       "       [6.20511200e-03, 3.70404450e-01, 6.23390400e-01],\n",
       "       [7.58596300e-04, 8.46745670e-01, 1.52495710e-01],\n",
       "       [3.22060920e-03, 8.79929660e-01, 1.16849710e-01],\n",
       "       [8.54651000e-02, 7.27735460e-01, 1.86799440e-01],\n",
       "       [9.76387400e-01, 1.36769050e-02, 9.93570400e-03]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob2 = df_proba2[df_proba2['phage']=='p11kpresabsSTCC_qual'].iloc[:,-3:]\n",
    "y_prob2 = y_prob2.to_numpy()\n",
    "y_prob2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9582851965114961"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo2 = rocauc_ovo(y_test_over, y_prob2, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9582851965114961"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr2 = rocauc_ovr(y_test_over, y_prob2, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=345,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat3 = pd.DataFrame(X_test_over[:,0])\n",
    "dat3['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS149</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EUH13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS106</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS214</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CFBREBSa129</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>NRS027</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>CFBRSa70</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>CFBREBSa130</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>NRS214</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>NRS073</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test\n",
       "0         NRS149     0\n",
       "1          EUH13     0\n",
       "2         NRS106     2\n",
       "3         NRS214     1\n",
       "4    CFBREBSa129     0\n",
       "..           ...   ...\n",
       "158       NRS027     0\n",
       "159     CFBRSa70     2\n",
       "160  CFBREBSa130     0\n",
       "161       NRS214     1\n",
       "162       NRS073     1\n",
       "\n",
       "[163 rows x 2 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over3 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],)),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over3.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 380 samples, validate on 163 samples\n",
      "Epoch 1/100\n",
      "380/380 [==============================] - 0s 429us/step - loss: 2.5802 - accuracy: 0.3605 - val_loss: 1.6372 - val_accuracy: 0.3497\n",
      "Epoch 2/100\n",
      "380/380 [==============================] - 0s 122us/step - loss: 1.5710 - accuracy: 0.4289 - val_loss: 1.2853 - val_accuracy: 0.4417\n",
      "Epoch 3/100\n",
      "380/380 [==============================] - 0s 152us/step - loss: 1.2688 - accuracy: 0.4684 - val_loss: 1.0450 - val_accuracy: 0.5337\n",
      "Epoch 4/100\n",
      "380/380 [==============================] - 0s 164us/step - loss: 1.1113 - accuracy: 0.4895 - val_loss: 0.9525 - val_accuracy: 0.5521\n",
      "Epoch 5/100\n",
      "380/380 [==============================] - 0s 165us/step - loss: 0.9473 - accuracy: 0.5553 - val_loss: 0.8083 - val_accuracy: 0.6810\n",
      "Epoch 6/100\n",
      "380/380 [==============================] - 0s 132us/step - loss: 0.8868 - accuracy: 0.5921 - val_loss: 0.8395 - val_accuracy: 0.6319\n",
      "Epoch 7/100\n",
      "380/380 [==============================] - 0s 148us/step - loss: 0.8178 - accuracy: 0.6342 - val_loss: 0.7896 - val_accuracy: 0.6564\n",
      "Epoch 8/100\n",
      "380/380 [==============================] - 0s 162us/step - loss: 0.7931 - accuracy: 0.6474 - val_loss: 0.7696 - val_accuracy: 0.6564\n",
      "Epoch 9/100\n",
      "380/380 [==============================] - 0s 146us/step - loss: 0.7574 - accuracy: 0.6842 - val_loss: 0.7430 - val_accuracy: 0.6810\n",
      "Epoch 10/100\n",
      "380/380 [==============================] - 0s 125us/step - loss: 0.7345 - accuracy: 0.6763 - val_loss: 0.7603 - val_accuracy: 0.6933\n",
      "Epoch 11/100\n",
      "380/380 [==============================] - 0s 148us/step - loss: 0.7076 - accuracy: 0.7316 - val_loss: 0.6942 - val_accuracy: 0.7055\n",
      "Epoch 12/100\n",
      "380/380 [==============================] - 0s 151us/step - loss: 0.6756 - accuracy: 0.7316 - val_loss: 0.7567 - val_accuracy: 0.6748\n",
      "Epoch 13/100\n",
      "380/380 [==============================] - 0s 132us/step - loss: 0.6703 - accuracy: 0.7289 - val_loss: 0.6642 - val_accuracy: 0.7301\n",
      "Epoch 14/100\n",
      "380/380 [==============================] - 0s 150us/step - loss: 0.6407 - accuracy: 0.7395 - val_loss: 0.7134 - val_accuracy: 0.6994\n",
      "Epoch 15/100\n",
      "380/380 [==============================] - 0s 112us/step - loss: 0.6270 - accuracy: 0.7632 - val_loss: 0.6517 - val_accuracy: 0.7423\n",
      "Epoch 16/100\n",
      "380/380 [==============================] - 0s 161us/step - loss: 0.5992 - accuracy: 0.7921 - val_loss: 0.6529 - val_accuracy: 0.7485\n",
      "Epoch 17/100\n",
      "380/380 [==============================] - 0s 515us/step - loss: 0.5827 - accuracy: 0.7658 - val_loss: 0.6685 - val_accuracy: 0.7178\n",
      "Epoch 18/100\n",
      "380/380 [==============================] - 0s 163us/step - loss: 0.5935 - accuracy: 0.7711 - val_loss: 0.6403 - val_accuracy: 0.7730\n",
      "Epoch 19/100\n",
      "380/380 [==============================] - 0s 189us/step - loss: 0.5712 - accuracy: 0.7842 - val_loss: 0.6630 - val_accuracy: 0.7362\n",
      "Epoch 20/100\n",
      "380/380 [==============================] - 0s 150us/step - loss: 0.5777 - accuracy: 0.7921 - val_loss: 0.6943 - val_accuracy: 0.7546\n",
      "Epoch 21/100\n",
      "380/380 [==============================] - 0s 162us/step - loss: 0.5730 - accuracy: 0.7974 - val_loss: 0.6022 - val_accuracy: 0.7607\n",
      "Epoch 22/100\n",
      "380/380 [==============================] - 0s 174us/step - loss: 0.5346 - accuracy: 0.8132 - val_loss: 0.6103 - val_accuracy: 0.7669\n",
      "Epoch 23/100\n",
      "380/380 [==============================] - 0s 204us/step - loss: 0.5109 - accuracy: 0.8053 - val_loss: 0.5907 - val_accuracy: 0.7669\n",
      "Epoch 24/100\n",
      "380/380 [==============================] - 0s 150us/step - loss: 0.5461 - accuracy: 0.7895 - val_loss: 0.5763 - val_accuracy: 0.7607\n",
      "Epoch 25/100\n",
      "380/380 [==============================] - 0s 115us/step - loss: 0.5243 - accuracy: 0.7947 - val_loss: 0.6432 - val_accuracy: 0.7485\n",
      "Epoch 26/100\n",
      "380/380 [==============================] - 0s 89us/step - loss: 0.5064 - accuracy: 0.8263 - val_loss: 0.7062 - val_accuracy: 0.7546\n",
      "Epoch 27/100\n",
      "380/380 [==============================] - 0s 85us/step - loss: 0.5343 - accuracy: 0.8026 - val_loss: 0.6053 - val_accuracy: 0.7301\n",
      "Epoch 28/100\n",
      "380/380 [==============================] - 0s 84us/step - loss: 0.5003 - accuracy: 0.8237 - val_loss: 0.6090 - val_accuracy: 0.7362\n",
      "Epoch 29/100\n",
      "380/380 [==============================] - 0s 92us/step - loss: 0.4744 - accuracy: 0.8000 - val_loss: 0.6187 - val_accuracy: 0.7423\n",
      "Epoch 30/100\n",
      "380/380 [==============================] - 0s 87us/step - loss: 0.4837 - accuracy: 0.8105 - val_loss: 0.6362 - val_accuracy: 0.7055\n",
      "Epoch 31/100\n",
      "380/380 [==============================] - 0s 137us/step - loss: 0.5026 - accuracy: 0.8026 - val_loss: 0.5490 - val_accuracy: 0.7730\n",
      "Epoch 32/100\n",
      "380/380 [==============================] - 0s 261us/step - loss: 0.4549 - accuracy: 0.8132 - val_loss: 0.6986 - val_accuracy: 0.6994\n",
      "Epoch 33/100\n",
      "380/380 [==============================] - 0s 219us/step - loss: 0.4854 - accuracy: 0.8263 - val_loss: 0.5895 - val_accuracy: 0.7975\n",
      "Epoch 34/100\n",
      "380/380 [==============================] - 0s 193us/step - loss: 0.4510 - accuracy: 0.8447 - val_loss: 0.5815 - val_accuracy: 0.7914\n",
      "Epoch 35/100\n",
      "380/380 [==============================] - 0s 137us/step - loss: 0.4202 - accuracy: 0.8474 - val_loss: 0.5223 - val_accuracy: 0.8098\n",
      "Epoch 36/100\n",
      "380/380 [==============================] - 0s 198us/step - loss: 0.4031 - accuracy: 0.8711 - val_loss: 0.5412 - val_accuracy: 0.7669\n",
      "Epoch 37/100\n",
      "380/380 [==============================] - 0s 193us/step - loss: 0.4140 - accuracy: 0.8526 - val_loss: 0.4954 - val_accuracy: 0.8160\n",
      "Epoch 38/100\n",
      "380/380 [==============================] - 0s 197us/step - loss: 0.4161 - accuracy: 0.8632 - val_loss: 0.5655 - val_accuracy: 0.7791\n",
      "Epoch 39/100\n",
      "380/380 [==============================] - 0s 190us/step - loss: 0.3982 - accuracy: 0.8632 - val_loss: 0.4928 - val_accuracy: 0.8405\n",
      "Epoch 40/100\n",
      "380/380 [==============================] - 0s 192us/step - loss: 0.3809 - accuracy: 0.8789 - val_loss: 0.4929 - val_accuracy: 0.8282\n",
      "Epoch 41/100\n",
      "380/380 [==============================] - 0s 144us/step - loss: 0.3801 - accuracy: 0.8921 - val_loss: 0.5016 - val_accuracy: 0.8160\n",
      "Epoch 42/100\n",
      "380/380 [==============================] - 0s 148us/step - loss: 0.3998 - accuracy: 0.8711 - val_loss: 0.5848 - val_accuracy: 0.8344\n",
      "Epoch 43/100\n",
      "380/380 [==============================] - 0s 184us/step - loss: 0.4148 - accuracy: 0.8816 - val_loss: 0.5292 - val_accuracy: 0.8221\n",
      "Epoch 44/100\n",
      "380/380 [==============================] - 0s 191us/step - loss: 0.3806 - accuracy: 0.8842 - val_loss: 0.6154 - val_accuracy: 0.7546\n",
      "Epoch 45/100\n",
      "380/380 [==============================] - 0s 179us/step - loss: 0.4135 - accuracy: 0.8816 - val_loss: 0.7216 - val_accuracy: 0.8282\n",
      "Epoch 46/100\n",
      "380/380 [==============================] - 0s 190us/step - loss: 0.4469 - accuracy: 0.8842 - val_loss: 0.5650 - val_accuracy: 0.7730\n",
      "Epoch 47/100\n",
      "380/380 [==============================] - 0s 106us/step - loss: 0.3843 - accuracy: 0.8711 - val_loss: 0.5566 - val_accuracy: 0.7607\n",
      "Epoch 48/100\n",
      "380/380 [==============================] - 0s 202us/step - loss: 0.3654 - accuracy: 0.8711 - val_loss: 0.5339 - val_accuracy: 0.8589\n",
      "Epoch 49/100\n",
      "380/380 [==============================] - 0s 236us/step - loss: 0.4192 - accuracy: 0.8737 - val_loss: 0.5435 - val_accuracy: 0.8344\n",
      "Epoch 50/100\n",
      "380/380 [==============================] - 0s 221us/step - loss: 0.3963 - accuracy: 0.8605 - val_loss: 0.5205 - val_accuracy: 0.8160\n",
      "Epoch 51/100\n",
      "380/380 [==============================] - 0s 136us/step - loss: 0.3485 - accuracy: 0.8947 - val_loss: 0.4803 - val_accuracy: 0.8466\n",
      "Epoch 52/100\n",
      "380/380 [==============================] - 0s 143us/step - loss: 0.3721 - accuracy: 0.8842 - val_loss: 0.5178 - val_accuracy: 0.8160\n",
      "Epoch 53/100\n",
      "380/380 [==============================] - 0s 127us/step - loss: 0.3450 - accuracy: 0.8711 - val_loss: 0.4823 - val_accuracy: 0.8344\n",
      "Epoch 54/100\n",
      "380/380 [==============================] - 0s 168us/step - loss: 0.3295 - accuracy: 0.9053 - val_loss: 0.4571 - val_accuracy: 0.8405\n",
      "Epoch 55/100\n",
      "380/380 [==============================] - 0s 183us/step - loss: 0.3205 - accuracy: 0.9053 - val_loss: 0.4996 - val_accuracy: 0.8405\n",
      "Epoch 56/100\n",
      "380/380 [==============================] - 0s 181us/step - loss: 0.3277 - accuracy: 0.8921 - val_loss: 0.4729 - val_accuracy: 0.8466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "380/380 [==============================] - 0s 116us/step - loss: 0.3280 - accuracy: 0.8974 - val_loss: 0.4806 - val_accuracy: 0.8221\n",
      "Epoch 58/100\n",
      "380/380 [==============================] - 0s 92us/step - loss: 0.3458 - accuracy: 0.9000 - val_loss: 0.5498 - val_accuracy: 0.8466\n",
      "Epoch 59/100\n",
      "380/380 [==============================] - 0s 178us/step - loss: 0.3351 - accuracy: 0.9053 - val_loss: 0.5086 - val_accuracy: 0.8466\n",
      "Epoch 60/100\n",
      "380/380 [==============================] - 0s 227us/step - loss: 0.2993 - accuracy: 0.9158 - val_loss: 0.4274 - val_accuracy: 0.8528\n",
      "Epoch 61/100\n",
      "380/380 [==============================] - 0s 209us/step - loss: 0.3141 - accuracy: 0.9132 - val_loss: 0.4632 - val_accuracy: 0.8344\n",
      "Epoch 62/100\n",
      "380/380 [==============================] - 0s 215us/step - loss: 0.3008 - accuracy: 0.9079 - val_loss: 0.4490 - val_accuracy: 0.8650\n",
      "Epoch 63/100\n",
      "380/380 [==============================] - 0s 151us/step - loss: 0.2915 - accuracy: 0.9132 - val_loss: 0.4569 - val_accuracy: 0.8344\n",
      "Epoch 64/100\n",
      "380/380 [==============================] - 0s 130us/step - loss: 0.2807 - accuracy: 0.9026 - val_loss: 0.4487 - val_accuracy: 0.8466\n",
      "Epoch 65/100\n",
      "380/380 [==============================] - 0s 123us/step - loss: 0.2783 - accuracy: 0.9079 - val_loss: 0.4753 - val_accuracy: 0.8098\n",
      "Epoch 66/100\n",
      "380/380 [==============================] - 0s 82us/step - loss: 0.2940 - accuracy: 0.8947 - val_loss: 0.4461 - val_accuracy: 0.8466\n",
      "Epoch 67/100\n",
      "380/380 [==============================] - 0s 109us/step - loss: 0.2748 - accuracy: 0.9132 - val_loss: 0.4583 - val_accuracy: 0.8466\n",
      "Epoch 68/100\n",
      "380/380 [==============================] - 0s 81us/step - loss: 0.2759 - accuracy: 0.9105 - val_loss: 0.4227 - val_accuracy: 0.8405\n",
      "Epoch 69/100\n",
      "380/380 [==============================] - 0s 98us/step - loss: 0.2806 - accuracy: 0.9158 - val_loss: 0.4878 - val_accuracy: 0.8650\n",
      "Epoch 70/100\n",
      "380/380 [==============================] - 0s 133us/step - loss: 0.2644 - accuracy: 0.9395 - val_loss: 0.4556 - val_accuracy: 0.8589\n",
      "Epoch 71/100\n",
      "380/380 [==============================] - 0s 165us/step - loss: 0.2810 - accuracy: 0.9079 - val_loss: 0.4742 - val_accuracy: 0.8405\n",
      "Epoch 72/100\n",
      "380/380 [==============================] - 0s 207us/step - loss: 0.2640 - accuracy: 0.9263 - val_loss: 0.4245 - val_accuracy: 0.8466\n",
      "Epoch 73/100\n",
      "380/380 [==============================] - 0s 193us/step - loss: 0.2530 - accuracy: 0.9395 - val_loss: 0.4221 - val_accuracy: 0.8466\n",
      "Epoch 74/100\n",
      "380/380 [==============================] - 0s 145us/step - loss: 0.2654 - accuracy: 0.9105 - val_loss: 0.4185 - val_accuracy: 0.8589\n",
      "Epoch 75/100\n",
      "380/380 [==============================] - 0s 157us/step - loss: 0.2766 - accuracy: 0.9237 - val_loss: 0.4903 - val_accuracy: 0.8466\n",
      "Epoch 76/100\n",
      "380/380 [==============================] - 0s 107us/step - loss: 0.2661 - accuracy: 0.9368 - val_loss: 0.4221 - val_accuracy: 0.8589\n",
      "Epoch 77/100\n",
      "380/380 [==============================] - 0s 128us/step - loss: 0.2601 - accuracy: 0.9211 - val_loss: 0.5302 - val_accuracy: 0.8037\n",
      "Epoch 78/100\n",
      "380/380 [==============================] - 0s 113us/step - loss: 0.3183 - accuracy: 0.9316 - val_loss: 0.4729 - val_accuracy: 0.8589\n",
      "Epoch 79/100\n",
      "380/380 [==============================] - 0s 121us/step - loss: 0.3100 - accuracy: 0.9026 - val_loss: 0.5667 - val_accuracy: 0.7607\n",
      "Epoch 80/100\n",
      "380/380 [==============================] - 0s 153us/step - loss: 0.3077 - accuracy: 0.8947 - val_loss: 0.4485 - val_accuracy: 0.8466\n",
      "Epoch 81/100\n",
      "380/380 [==============================] - 0s 128us/step - loss: 0.2639 - accuracy: 0.9053 - val_loss: 0.6021 - val_accuracy: 0.8405\n",
      "Epoch 82/100\n",
      "380/380 [==============================] - 0s 114us/step - loss: 0.2986 - accuracy: 0.9105 - val_loss: 0.4217 - val_accuracy: 0.8589\n",
      "Epoch 83/100\n",
      "380/380 [==============================] - 0s 92us/step - loss: 0.2677 - accuracy: 0.9026 - val_loss: 0.4755 - val_accuracy: 0.8282\n",
      "Epoch 84/100\n",
      "380/380 [==============================] - 0s 83us/step - loss: 0.2654 - accuracy: 0.9289 - val_loss: 0.4532 - val_accuracy: 0.8282\n",
      "Epoch 85/100\n",
      "380/380 [==============================] - 0s 87us/step - loss: 0.2441 - accuracy: 0.9158 - val_loss: 0.4640 - val_accuracy: 0.8466\n",
      "Epoch 86/100\n",
      "380/380 [==============================] - 0s 108us/step - loss: 0.2388 - accuracy: 0.9342 - val_loss: 0.4273 - val_accuracy: 0.8528\n",
      "Epoch 87/100\n",
      "380/380 [==============================] - 0s 147us/step - loss: 0.2283 - accuracy: 0.9368 - val_loss: 0.4296 - val_accuracy: 0.8282\n",
      "Epoch 88/100\n",
      "380/380 [==============================] - 0s 117us/step - loss: 0.2367 - accuracy: 0.9105 - val_loss: 0.4334 - val_accuracy: 0.8466\n",
      "Epoch 89/100\n",
      "380/380 [==============================] - 0s 117us/step - loss: 0.2370 - accuracy: 0.9053 - val_loss: 0.4228 - val_accuracy: 0.8466\n",
      "Epoch 90/100\n",
      "380/380 [==============================] - 0s 116us/step - loss: 0.2311 - accuracy: 0.9368 - val_loss: 0.4146 - val_accuracy: 0.8528\n",
      "Epoch 91/100\n",
      "380/380 [==============================] - 0s 117us/step - loss: 0.2220 - accuracy: 0.9289 - val_loss: 0.4337 - val_accuracy: 0.8528\n",
      "Epoch 92/100\n",
      "380/380 [==============================] - 0s 84us/step - loss: 0.2174 - accuracy: 0.9289 - val_loss: 0.4310 - val_accuracy: 0.8528\n",
      "Epoch 93/100\n",
      "380/380 [==============================] - 0s 85us/step - loss: 0.2226 - accuracy: 0.9211 - val_loss: 0.4519 - val_accuracy: 0.8344\n",
      "Epoch 94/100\n",
      "380/380 [==============================] - 0s 94us/step - loss: 0.2093 - accuracy: 0.9368 - val_loss: 0.4088 - val_accuracy: 0.8466\n",
      "Epoch 95/100\n",
      "380/380 [==============================] - 0s 96us/step - loss: 0.2166 - accuracy: 0.9263 - val_loss: 0.4654 - val_accuracy: 0.8344\n",
      "Epoch 96/100\n",
      "380/380 [==============================] - 0s 86us/step - loss: 0.2165 - accuracy: 0.9289 - val_loss: 0.3807 - val_accuracy: 0.8589\n",
      "Epoch 97/100\n",
      "380/380 [==============================] - 0s 82us/step - loss: 0.2042 - accuracy: 0.9342 - val_loss: 0.4550 - val_accuracy: 0.8405\n",
      "Epoch 98/100\n",
      "380/380 [==============================] - 0s 96us/step - loss: 0.2016 - accuracy: 0.9447 - val_loss: 0.4134 - val_accuracy: 0.8528\n",
      "Epoch 99/100\n",
      "380/380 [==============================] - 0s 81us/step - loss: 0.2000 - accuracy: 0.9526 - val_loss: 0.4219 - val_accuracy: 0.8528\n",
      "Epoch 100/100\n",
      "380/380 [==============================] - 0s 91us/step - loss: 0.2023 - accuracy: 0.9342 - val_loss: 0.4219 - val_accuracy: 0.8405\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a349f0438>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over3.fit(X_train_over, y_train_over,\n",
    "          batch_size=64, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163/163 [==============================] - 0s 97us/step\n",
      "over-sampling test accuracy: 84.66%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over3 = model1_over3.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over3*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 2, 1, 0, 2, 0, 0, 2, 0, 1, 2, 1, 0, 0, 1, 2, 0, 0, 2, 2, 2,\n",
       "       0, 2, 2, 1, 2, 1, 0, 0, 1, 1, 1, 0, 2, 1, 0, 2, 1, 2, 0, 1, 1, 1,\n",
       "       1, 0, 2, 1, 0, 0, 2, 0, 0, 0, 2, 0, 2, 1, 2, 1, 2, 1, 0, 1, 1, 0,\n",
       "       0, 2, 0, 1, 0, 0, 2, 0, 0, 1, 0, 2, 0, 0, 1, 1, 2, 2, 2, 0, 0, 1,\n",
       "       2, 0, 0, 0, 0, 0, 1, 2, 1, 2, 0, 2, 2, 0, 1, 1, 1, 0, 2, 1, 1, 1,\n",
       "       0, 2, 0, 0, 2, 2, 2, 1, 2, 2, 2, 2, 0, 1, 1, 1, 2, 1, 1, 1, 1, 0,\n",
       "       1, 1, 0, 2, 0, 0, 0, 2, 1, 0, 1, 0, 1, 1, 0, 0, 0, 2, 0, 2, 1, 0,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 1])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred3 = model1_over3.predict_classes(X_test_over)\n",
    "pred3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS149</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EUH13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS106</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS214</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CFBREBSa129</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>NRS027</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>CFBRSa70</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>CFBREBSa130</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>NRS214</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>NRS073</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test  pred\n",
       "0         NRS149     0     0\n",
       "1          EUH13     0     0\n",
       "2         NRS106     2     2\n",
       "3         NRS214     1     1\n",
       "4    CFBREBSa129     0     0\n",
       "..           ...   ...   ...\n",
       "158       NRS027     0     0\n",
       "159     CFBRSa70     2     1\n",
       "160  CFBREBSa130     0     0\n",
       "161       NRS214     1     1\n",
       "162       NRS073     1     1\n",
       "\n",
       "[163 rows x 3 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat3['pred'] = pred3\n",
    "dat3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba3 = model1_over3.predict_proba(X_test_over)\n",
    "dat_proba3 = pd.DataFrame(proba3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.945460</td>\n",
       "      <td>0.019924</td>\n",
       "      <td>0.034616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.923442</td>\n",
       "      <td>0.076492</td>\n",
       "      <td>0.000066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.426062</td>\n",
       "      <td>0.041316</td>\n",
       "      <td>0.532622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.035017</td>\n",
       "      <td>0.934156</td>\n",
       "      <td>0.030827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.993218</td>\n",
       "      <td>0.003219</td>\n",
       "      <td>0.003564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>0.988671</td>\n",
       "      <td>0.006116</td>\n",
       "      <td>0.005213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>0.080087</td>\n",
       "      <td>0.609810</td>\n",
       "      <td>0.310103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>0.747739</td>\n",
       "      <td>0.001925</td>\n",
       "      <td>0.250336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>0.035017</td>\n",
       "      <td>0.934156</td>\n",
       "      <td>0.030827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>0.011474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2\n",
       "0    0.945460  0.019924  0.034616\n",
       "1    0.923442  0.076492  0.000066\n",
       "2    0.426062  0.041316  0.532622\n",
       "3    0.035017  0.934156  0.030827\n",
       "4    0.993218  0.003219  0.003564\n",
       "..        ...       ...       ...\n",
       "158  0.988671  0.006116  0.005213\n",
       "159  0.080087  0.609810  0.310103\n",
       "160  0.747739  0.001925  0.250336\n",
       "161  0.035017  0.934156  0.030827\n",
       "162  0.000020  0.988506  0.011474\n",
       "\n",
       "[163 rows x 3 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba3.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba3.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat3.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/3p11ST.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 380 samples, validate on 163 samples\n",
      "Epoch 1/100\n",
      "380/380 [==============================] - 0s 166us/step - loss: 0.2783 - accuracy: 0.9237 - val_loss: 0.4438 - val_accuracy: 0.8466\n",
      "Epoch 2/100\n",
      "380/380 [==============================] - 0s 104us/step - loss: 0.2734 - accuracy: 0.9132 - val_loss: 0.4446 - val_accuracy: 0.8466\n",
      "Epoch 3/100\n",
      "380/380 [==============================] - 0s 88us/step - loss: 0.2722 - accuracy: 0.9132 - val_loss: 0.4907 - val_accuracy: 0.8282\n",
      "Epoch 4/100\n",
      "380/380 [==============================] - 0s 86us/step - loss: 0.2697 - accuracy: 0.9211 - val_loss: 0.4293 - val_accuracy: 0.8466\n",
      "Epoch 5/100\n",
      "380/380 [==============================] - 0s 85us/step - loss: 0.2692 - accuracy: 0.9184 - val_loss: 0.5002 - val_accuracy: 0.8344\n",
      "Epoch 6/100\n",
      "380/380 [==============================] - 0s 99us/step - loss: 0.2666 - accuracy: 0.9316 - val_loss: 0.4581 - val_accuracy: 0.8528\n",
      "Epoch 7/100\n",
      "380/380 [==============================] - 0s 95us/step - loss: 0.2722 - accuracy: 0.9158 - val_loss: 0.4618 - val_accuracy: 0.8221\n",
      "Epoch 8/100\n",
      "380/380 [==============================] - 0s 94us/step - loss: 0.2713 - accuracy: 0.9316 - val_loss: 0.4704 - val_accuracy: 0.8344\n",
      "Epoch 9/100\n",
      "380/380 [==============================] - 0s 87us/step - loss: 0.2614 - accuracy: 0.9316 - val_loss: 0.4790 - val_accuracy: 0.8344\n",
      "Epoch 10/100\n",
      "380/380 [==============================] - 0s 87us/step - loss: 0.2560 - accuracy: 0.9237 - val_loss: 0.4313 - val_accuracy: 0.8528\n",
      "Epoch 11/100\n",
      "380/380 [==============================] - 0s 84us/step - loss: 0.2532 - accuracy: 0.9342 - val_loss: 0.4889 - val_accuracy: 0.8405\n",
      "Epoch 12/100\n",
      "380/380 [==============================] - 0s 82us/step - loss: 0.2566 - accuracy: 0.9079 - val_loss: 0.4708 - val_accuracy: 0.8405\n",
      "Epoch 13/100\n",
      "380/380 [==============================] - 0s 86us/step - loss: 0.2523 - accuracy: 0.9263 - val_loss: 0.4537 - val_accuracy: 0.8405\n",
      "Epoch 14/100\n",
      "380/380 [==============================] - 0s 93us/step - loss: 0.2490 - accuracy: 0.9132 - val_loss: 0.4802 - val_accuracy: 0.8160\n",
      "Epoch 15/100\n",
      "380/380 [==============================] - 0s 93us/step - loss: 0.2520 - accuracy: 0.9158 - val_loss: 0.4411 - val_accuracy: 0.8528\n",
      "Epoch 16/100\n",
      "380/380 [==============================] - 0s 84us/step - loss: 0.2617 - accuracy: 0.9132 - val_loss: 0.4714 - val_accuracy: 0.8160\n",
      "Epoch 17/100\n",
      "380/380 [==============================] - 0s 89us/step - loss: 0.2497 - accuracy: 0.9263 - val_loss: 0.4381 - val_accuracy: 0.8221\n",
      "Epoch 18/100\n",
      "380/380 [==============================] - 0s 85us/step - loss: 0.2477 - accuracy: 0.9158 - val_loss: 0.4374 - val_accuracy: 0.8466\n",
      "Epoch 19/100\n",
      "380/380 [==============================] - 0s 84us/step - loss: 0.2492 - accuracy: 0.9132 - val_loss: 0.4904 - val_accuracy: 0.8344\n",
      "Epoch 20/100\n",
      "380/380 [==============================] - 0s 85us/step - loss: 0.2429 - accuracy: 0.9158 - val_loss: 0.4302 - val_accuracy: 0.8282\n",
      "Epoch 21/100\n",
      "380/380 [==============================] - 0s 86us/step - loss: 0.2403 - accuracy: 0.9184 - val_loss: 0.4659 - val_accuracy: 0.8160\n",
      "Epoch 22/100\n",
      "380/380 [==============================] - 0s 83us/step - loss: 0.2368 - accuracy: 0.9368 - val_loss: 0.4496 - val_accuracy: 0.8344\n",
      "Epoch 23/100\n",
      "380/380 [==============================] - 0s 87us/step - loss: 0.2323 - accuracy: 0.9447 - val_loss: 0.4402 - val_accuracy: 0.8405\n",
      "Epoch 24/100\n",
      "380/380 [==============================] - 0s 87us/step - loss: 0.2347 - accuracy: 0.9289 - val_loss: 0.4518 - val_accuracy: 0.8405\n",
      "Epoch 25/100\n",
      "380/380 [==============================] - 0s 86us/step - loss: 0.2395 - accuracy: 0.9237 - val_loss: 0.4223 - val_accuracy: 0.8405\n",
      "Epoch 26/100\n",
      "380/380 [==============================] - 0s 102us/step - loss: 0.2390 - accuracy: 0.9132 - val_loss: 0.4838 - val_accuracy: 0.8221\n",
      "Epoch 27/100\n",
      "380/380 [==============================] - 0s 101us/step - loss: 0.2356 - accuracy: 0.9211 - val_loss: 0.4153 - val_accuracy: 0.8282\n",
      "Epoch 28/100\n",
      "380/380 [==============================] - 0s 136us/step - loss: 0.2399 - accuracy: 0.9132 - val_loss: 0.5428 - val_accuracy: 0.7975\n",
      "Epoch 29/100\n",
      "380/380 [==============================] - 0s 115us/step - loss: 0.2425 - accuracy: 0.9053 - val_loss: 0.4160 - val_accuracy: 0.8405\n",
      "Epoch 30/100\n",
      "380/380 [==============================] - 0s 95us/step - loss: 0.2556 - accuracy: 0.9105 - val_loss: 0.5742 - val_accuracy: 0.7791\n",
      "Epoch 31/100\n",
      "380/380 [==============================] - 0s 106us/step - loss: 0.2394 - accuracy: 0.9079 - val_loss: 0.4190 - val_accuracy: 0.8466\n",
      "Epoch 32/100\n",
      "380/380 [==============================] - 0s 95us/step - loss: 0.2466 - accuracy: 0.9132 - val_loss: 0.5188 - val_accuracy: 0.8221\n",
      "Epoch 33/100\n",
      "380/380 [==============================] - 0s 90us/step - loss: 0.2215 - accuracy: 0.9421 - val_loss: 0.4357 - val_accuracy: 0.8405\n",
      "Epoch 34/100\n",
      "380/380 [==============================] - 0s 95us/step - loss: 0.2255 - accuracy: 0.9237 - val_loss: 0.5182 - val_accuracy: 0.8098\n",
      "Epoch 35/100\n",
      "380/380 [==============================] - 0s 96us/step - loss: 0.2408 - accuracy: 0.9237 - val_loss: 0.4107 - val_accuracy: 0.8405\n",
      "Epoch 36/100\n",
      "380/380 [==============================] - 0s 97us/step - loss: 0.2380 - accuracy: 0.9184 - val_loss: 0.5566 - val_accuracy: 0.8098\n",
      "Epoch 37/100\n",
      "380/380 [==============================] - 0s 88us/step - loss: 0.2245 - accuracy: 0.9211 - val_loss: 0.4177 - val_accuracy: 0.8344\n",
      "Epoch 38/100\n",
      "380/380 [==============================] - 0s 85us/step - loss: 0.2289 - accuracy: 0.9158 - val_loss: 0.4528 - val_accuracy: 0.8344\n",
      "Epoch 39/100\n",
      "380/380 [==============================] - 0s 81us/step - loss: 0.2157 - accuracy: 0.9395 - val_loss: 0.4645 - val_accuracy: 0.8344\n",
      "Epoch 40/100\n",
      "380/380 [==============================] - 0s 92us/step - loss: 0.2115 - accuracy: 0.9447 - val_loss: 0.4336 - val_accuracy: 0.8466\n",
      "Epoch 41/100\n",
      "380/380 [==============================] - 0s 87us/step - loss: 0.2097 - accuracy: 0.9474 - val_loss: 0.4274 - val_accuracy: 0.8405\n",
      "Epoch 42/100\n",
      "380/380 [==============================] - 0s 87us/step - loss: 0.2095 - accuracy: 0.9368 - val_loss: 0.4478 - val_accuracy: 0.8405\n",
      "Epoch 43/100\n",
      "380/380 [==============================] - 0s 89us/step - loss: 0.2129 - accuracy: 0.9368 - val_loss: 0.4082 - val_accuracy: 0.8528\n",
      "Epoch 44/100\n",
      "380/380 [==============================] - 0s 94us/step - loss: 0.2066 - accuracy: 0.9421 - val_loss: 0.4692 - val_accuracy: 0.8405\n",
      "Epoch 45/100\n",
      "380/380 [==============================] - 0s 89us/step - loss: 0.2127 - accuracy: 0.9395 - val_loss: 0.4560 - val_accuracy: 0.8466\n",
      "Epoch 46/100\n",
      "380/380 [==============================] - 0s 89us/step - loss: 0.2079 - accuracy: 0.9500 - val_loss: 0.4278 - val_accuracy: 0.8528\n",
      "Epoch 47/100\n",
      "380/380 [==============================] - 0s 88us/step - loss: 0.2034 - accuracy: 0.9395 - val_loss: 0.4509 - val_accuracy: 0.8098\n",
      "Epoch 48/100\n",
      "380/380 [==============================] - 0s 88us/step - loss: 0.2056 - accuracy: 0.9421 - val_loss: 0.4250 - val_accuracy: 0.8528\n",
      "Epoch 49/100\n",
      "380/380 [==============================] - 0s 90us/step - loss: 0.2074 - accuracy: 0.9237 - val_loss: 0.4781 - val_accuracy: 0.8098\n",
      "Epoch 50/100\n",
      "380/380 [==============================] - 0s 89us/step - loss: 0.2102 - accuracy: 0.9368 - val_loss: 0.4222 - val_accuracy: 0.8466\n",
      "Epoch 51/100\n",
      "380/380 [==============================] - 0s 80us/step - loss: 0.1993 - accuracy: 0.9447 - val_loss: 0.4604 - val_accuracy: 0.8282\n",
      "Epoch 52/100\n",
      "380/380 [==============================] - 0s 83us/step - loss: 0.1990 - accuracy: 0.9526 - val_loss: 0.4530 - val_accuracy: 0.8405\n",
      "Epoch 53/100\n",
      "380/380 [==============================] - 0s 79us/step - loss: 0.1997 - accuracy: 0.9474 - val_loss: 0.4302 - val_accuracy: 0.8405\n",
      "Epoch 54/100\n",
      "380/380 [==============================] - 0s 80us/step - loss: 0.2044 - accuracy: 0.9395 - val_loss: 0.4764 - val_accuracy: 0.8344\n",
      "Epoch 55/100\n",
      "380/380 [==============================] - 0s 93us/step - loss: 0.2037 - accuracy: 0.9289 - val_loss: 0.4561 - val_accuracy: 0.8466\n",
      "Epoch 56/100\n",
      "380/380 [==============================] - 0s 85us/step - loss: 0.1973 - accuracy: 0.9342 - val_loss: 0.4373 - val_accuracy: 0.8221\n",
      "Epoch 57/100\n",
      "380/380 [==============================] - 0s 89us/step - loss: 0.1982 - accuracy: 0.9316 - val_loss: 0.4882 - val_accuracy: 0.8221\n",
      "Epoch 58/100\n",
      "380/380 [==============================] - 0s 79us/step - loss: 0.2022 - accuracy: 0.9342 - val_loss: 0.4329 - val_accuracy: 0.8344\n",
      "Epoch 59/100\n",
      "380/380 [==============================] - 0s 84us/step - loss: 0.2001 - accuracy: 0.9316 - val_loss: 0.4957 - val_accuracy: 0.8344\n",
      "Epoch 60/100\n",
      "380/380 [==============================] - 0s 86us/step - loss: 0.1981 - accuracy: 0.9421 - val_loss: 0.4305 - val_accuracy: 0.8466\n",
      "Epoch 61/100\n",
      "380/380 [==============================] - 0s 86us/step - loss: 0.1960 - accuracy: 0.9263 - val_loss: 0.4077 - val_accuracy: 0.8528\n",
      "Epoch 62/100\n",
      "380/380 [==============================] - 0s 87us/step - loss: 0.1946 - accuracy: 0.9237 - val_loss: 0.4770 - val_accuracy: 0.8221\n",
      "Epoch 63/100\n",
      "380/380 [==============================] - 0s 81us/step - loss: 0.1911 - accuracy: 0.9395 - val_loss: 0.4635 - val_accuracy: 0.8466\n",
      "Epoch 64/100\n",
      "380/380 [==============================] - 0s 86us/step - loss: 0.1907 - accuracy: 0.9316 - val_loss: 0.4727 - val_accuracy: 0.8344\n",
      "Epoch 65/100\n",
      "380/380 [==============================] - 0s 86us/step - loss: 0.1875 - accuracy: 0.9447 - val_loss: 0.4500 - val_accuracy: 0.8344\n",
      "Epoch 66/100\n",
      "380/380 [==============================] - 0s 99us/step - loss: 0.1837 - accuracy: 0.9526 - val_loss: 0.4497 - val_accuracy: 0.8344\n",
      "Epoch 67/100\n",
      "380/380 [==============================] - 0s 83us/step - loss: 0.1901 - accuracy: 0.9316 - val_loss: 0.4148 - val_accuracy: 0.8405\n",
      "Epoch 68/100\n",
      "380/380 [==============================] - 0s 167us/step - loss: 0.1941 - accuracy: 0.9263 - val_loss: 0.4865 - val_accuracy: 0.8221\n",
      "Epoch 69/100\n",
      "380/380 [==============================] - 0s 160us/step - loss: 0.1844 - accuracy: 0.9421 - val_loss: 0.4448 - val_accuracy: 0.8528\n",
      "Epoch 70/100\n",
      "380/380 [==============================] - 0s 127us/step - loss: 0.1810 - accuracy: 0.9553 - val_loss: 0.4429 - val_accuracy: 0.8466\n",
      "Epoch 71/100\n",
      "380/380 [==============================] - 0s 105us/step - loss: 0.1782 - accuracy: 0.9526 - val_loss: 0.4554 - val_accuracy: 0.8282\n",
      "Epoch 72/100\n",
      "380/380 [==============================] - 0s 106us/step - loss: 0.1805 - accuracy: 0.9526 - val_loss: 0.4852 - val_accuracy: 0.8282\n",
      "Epoch 73/100\n",
      "380/380 [==============================] - 0s 123us/step - loss: 0.1770 - accuracy: 0.9526 - val_loss: 0.4413 - val_accuracy: 0.8344\n",
      "Epoch 74/100\n",
      "380/380 [==============================] - 0s 104us/step - loss: 0.1769 - accuracy: 0.9579 - val_loss: 0.4625 - val_accuracy: 0.8282\n",
      "Epoch 75/100\n",
      "380/380 [==============================] - 0s 121us/step - loss: 0.1796 - accuracy: 0.9553 - val_loss: 0.4449 - val_accuracy: 0.8344\n",
      "Epoch 76/100\n",
      "380/380 [==============================] - 0s 119us/step - loss: 0.1738 - accuracy: 0.9553 - val_loss: 0.4508 - val_accuracy: 0.8282\n",
      "Epoch 77/100\n",
      "380/380 [==============================] - 0s 120us/step - loss: 0.1747 - accuracy: 0.9526 - val_loss: 0.4404 - val_accuracy: 0.8221\n",
      "Epoch 78/100\n",
      "380/380 [==============================] - 0s 118us/step - loss: 0.1699 - accuracy: 0.9553 - val_loss: 0.4538 - val_accuracy: 0.8466\n",
      "Epoch 79/100\n",
      "380/380 [==============================] - 0s 349us/step - loss: 0.1702 - accuracy: 0.9579 - val_loss: 0.4611 - val_accuracy: 0.8282\n",
      "Epoch 80/100\n",
      "380/380 [==============================] - 0s 225us/step - loss: 0.1687 - accuracy: 0.9553 - val_loss: 0.4342 - val_accuracy: 0.8344\n",
      "Epoch 81/100\n",
      "380/380 [==============================] - 0s 141us/step - loss: 0.1737 - accuracy: 0.9579 - val_loss: 0.4817 - val_accuracy: 0.8221\n",
      "Epoch 82/100\n",
      "380/380 [==============================] - 0s 129us/step - loss: 0.1739 - accuracy: 0.9579 - val_loss: 0.4093 - val_accuracy: 0.8528\n",
      "Epoch 83/100\n",
      "380/380 [==============================] - 0s 198us/step - loss: 0.1818 - accuracy: 0.9474 - val_loss: 0.4632 - val_accuracy: 0.8282\n",
      "Epoch 84/100\n",
      "380/380 [==============================] - 0s 134us/step - loss: 0.1698 - accuracy: 0.9500 - val_loss: 0.4576 - val_accuracy: 0.8282\n",
      "Epoch 85/100\n",
      "380/380 [==============================] - 0s 96us/step - loss: 0.1656 - accuracy: 0.9579 - val_loss: 0.4597 - val_accuracy: 0.8221\n",
      "Epoch 86/100\n",
      "380/380 [==============================] - 0s 89us/step - loss: 0.1691 - accuracy: 0.9526 - val_loss: 0.4204 - val_accuracy: 0.8405\n",
      "Epoch 87/100\n",
      "380/380 [==============================] - 0s 85us/step - loss: 0.1667 - accuracy: 0.9579 - val_loss: 0.5092 - val_accuracy: 0.8160\n",
      "Epoch 88/100\n",
      "380/380 [==============================] - 0s 85us/step - loss: 0.1657 - accuracy: 0.9526 - val_loss: 0.4613 - val_accuracy: 0.8405\n",
      "Epoch 89/100\n",
      "380/380 [==============================] - 0s 108us/step - loss: 0.1625 - accuracy: 0.9579 - val_loss: 0.4697 - val_accuracy: 0.8160\n",
      "Epoch 90/100\n",
      "380/380 [==============================] - 0s 118us/step - loss: 0.1736 - accuracy: 0.9474 - val_loss: 0.4381 - val_accuracy: 0.8344\n",
      "Epoch 91/100\n",
      "380/380 [==============================] - 0s 113us/step - loss: 0.1604 - accuracy: 0.9526 - val_loss: 0.4519 - val_accuracy: 0.8282\n",
      "Epoch 92/100\n",
      "380/380 [==============================] - 0s 101us/step - loss: 0.1657 - accuracy: 0.9579 - val_loss: 0.4323 - val_accuracy: 0.8282\n",
      "Epoch 93/100\n",
      "380/380 [==============================] - 0s 130us/step - loss: 0.1652 - accuracy: 0.9553 - val_loss: 0.4668 - val_accuracy: 0.8405\n",
      "Epoch 94/100\n",
      "380/380 [==============================] - 0s 97us/step - loss: 0.1631 - accuracy: 0.9500 - val_loss: 0.4463 - val_accuracy: 0.8344\n",
      "Epoch 95/100\n",
      "380/380 [==============================] - 0s 89us/step - loss: 0.1683 - accuracy: 0.9579 - val_loss: 0.4462 - val_accuracy: 0.8344\n",
      "Epoch 96/100\n",
      "380/380 [==============================] - 0s 89us/step - loss: 0.1575 - accuracy: 0.9553 - val_loss: 0.4618 - val_accuracy: 0.8282\n",
      "Epoch 97/100\n",
      "380/380 [==============================] - 0s 87us/step - loss: 0.1588 - accuracy: 0.9579 - val_loss: 0.4469 - val_accuracy: 0.8344\n",
      "Epoch 98/100\n",
      "380/380 [==============================] - 0s 91us/step - loss: 0.1592 - accuracy: 0.9526 - val_loss: 0.4355 - val_accuracy: 0.8405\n",
      "Epoch 99/100\n",
      "380/380 [==============================] - 0s 105us/step - loss: 0.1557 - accuracy: 0.9579 - val_loss: 0.4834 - val_accuracy: 0.8160\n",
      "Epoch 100/100\n",
      "380/380 [==============================] - 0s 109us/step - loss: 0.1579 - accuracy: 0.9553 - val_loss: 0.4433 - val_accuracy: 0.8344\n"
     ]
    }
   ],
   "source": [
    "hist1_over3 = model1_over3.fit(X_train_over, y_train_over,\n",
    "          batch_size=64, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 93.67%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over3.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba3 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_2.xlsx\",\n",
    "                        sheet_name=2,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>0.013518</td>\n",
       "      <td>9.820048e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>0.013518</td>\n",
       "      <td>9.820048e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS222</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.851725</td>\n",
       "      <td>0.148269</td>\n",
       "      <td>5.980786e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>0.013518</td>\n",
       "      <td>9.820048e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>GA50245</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.812055</td>\n",
       "      <td>0.187945</td>\n",
       "      <td>1.161034e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4279</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>0.000928</td>\n",
       "      <td>9.984396e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4280</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>0.000928</td>\n",
       "      <td>9.984396e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4281</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS266</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.025932</td>\n",
       "      <td>0.974061</td>\n",
       "      <td>7.323514e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4282</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000597</td>\n",
       "      <td>0.999403</td>\n",
       "      <td>3.675362e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4283</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS112</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>0.999452</td>\n",
       "      <td>1.168620e-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4284 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    phage   strain  phenotype  prediction         0         1  \\\n",
       "0      p002ykpresabs_qual   NRS109          2           2  0.004477  0.013518   \n",
       "1      p002ykpresabs_qual   NRS109          2           2  0.004477  0.013518   \n",
       "2      p002ykpresabs_qual   NRS222          0           0  0.851725  0.148269   \n",
       "3      p002ykpresabs_qual   NRS109          2           2  0.004477  0.013518   \n",
       "4      p002ykpresabs_qual  GA50245          0           0  0.812055  0.187945   \n",
       "...                   ...      ...        ...         ...       ...       ...   \n",
       "4279  pyopresabsSTCC_qual   NRS255          2           2  0.000633  0.000928   \n",
       "4280  pyopresabsSTCC_qual   NRS255          2           2  0.000633  0.000928   \n",
       "4281  pyopresabsSTCC_qual   NRS266          1           1  0.025932  0.974061   \n",
       "4282  pyopresabsSTCC_qual   NRS001          1           1  0.000597  0.999403   \n",
       "4283  pyopresabsSTCC_qual   NRS112          1           1  0.000537  0.999452   \n",
       "\n",
       "                 2  \n",
       "0     9.820048e-01  \n",
       "1     9.820048e-01  \n",
       "2     5.980786e-06  \n",
       "3     9.820048e-01  \n",
       "4     1.161034e-07  \n",
       "...            ...  \n",
       "4279  9.984396e-01  \n",
       "4280  9.984396e-01  \n",
       "4281  7.323514e-06  \n",
       "4282  3.675362e-10  \n",
       "4283  1.168620e-05  \n",
       "\n",
       "[4284 rows x 7 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.45459900e-01, 1.99238710e-02, 3.46162500e-02],\n",
       "       [9.23442070e-01, 7.64918850e-02, 6.61021840e-05],\n",
       "       [4.26061870e-01, 4.13158900e-02, 5.32622300e-01],\n",
       "       [3.50171700e-02, 9.34155940e-01, 3.08269100e-02],\n",
       "       [9.93217770e-01, 3.21877580e-03, 3.56351580e-03],\n",
       "       [3.36265560e-02, 4.51625850e-01, 5.14747600e-01],\n",
       "       [9.88671200e-01, 6.11592130e-03, 5.21287800e-03],\n",
       "       [4.46328220e-01, 3.20847060e-01, 2.32824700e-01],\n",
       "       [1.43827280e-03, 3.35688440e-01, 6.62873300e-01],\n",
       "       [8.24092270e-01, 8.68281050e-02, 8.90796200e-02],\n",
       "       [9.02212100e-03, 9.43538500e-01, 4.74393550e-02],\n",
       "       [1.02018565e-02, 3.00128830e-02, 9.59785300e-01],\n",
       "       [4.24063400e-04, 9.65135340e-01, 3.44405960e-02],\n",
       "       [7.82782850e-01, 6.99917600e-03, 2.10217970e-01],\n",
       "       [9.76262300e-01, 1.52440990e-02, 8.49358550e-03],\n",
       "       [3.37084800e-04, 8.58221350e-01, 1.41441550e-01],\n",
       "       [4.07931360e-02, 4.16685340e-01, 5.42521540e-01],\n",
       "       [4.46328220e-01, 3.20847060e-01, 2.32824700e-01],\n",
       "       [8.87135450e-01, 5.13990350e-04, 1.12350590e-01],\n",
       "       [5.01276700e-03, 6.42707800e-02, 9.30716450e-01],\n",
       "       [1.65928840e-02, 3.04843780e-01, 6.78563300e-01],\n",
       "       [4.05090900e-02, 1.56492000e-03, 9.57926030e-01],\n",
       "       [7.47738900e-01, 1.92527760e-03, 2.50335870e-01],\n",
       "       [2.34866070e-03, 1.85310470e-02, 9.79120250e-01],\n",
       "       [5.13641300e-02, 1.88114910e-01, 7.60520940e-01],\n",
       "       [3.50855220e-03, 9.81843770e-01, 1.46476680e-02],\n",
       "       [3.60775370e-02, 1.85331080e-01, 7.78591400e-01],\n",
       "       [2.45323130e-02, 9.68380870e-01, 7.08691000e-03],\n",
       "       [9.40418360e-01, 5.95306200e-02, 5.09643800e-05],\n",
       "       [9.88671200e-01, 6.11592130e-03, 5.21287800e-03],\n",
       "       [3.76651900e-02, 8.98222300e-01, 6.41124600e-02],\n",
       "       [5.81129100e-04, 9.70737400e-01, 2.86813860e-02],\n",
       "       [4.27475700e-04, 9.67356860e-01, 3.22156900e-02],\n",
       "       [8.08817400e-01, 1.59009640e-01, 3.21730230e-02],\n",
       "       [2.91730880e-01, 7.03300860e-03, 7.01236100e-01],\n",
       "       [1.67824010e-04, 9.82274530e-01, 1.75575990e-02],\n",
       "       [4.86399020e-01, 4.27862000e-01, 8.57389500e-02],\n",
       "       [3.12131080e-01, 1.04658395e-01, 5.83210500e-01],\n",
       "       [3.76651900e-02, 8.98222300e-01, 6.41124600e-02],\n",
       "       [3.79045670e-04, 4.31672160e-03, 9.95304200e-01],\n",
       "       [9.88671200e-01, 6.11592130e-03, 5.21287800e-03],\n",
       "       [8.66658000e-05, 9.64854960e-01, 3.50584570e-02],\n",
       "       [5.81129100e-04, 9.70737400e-01, 2.86813860e-02],\n",
       "       [1.96927670e-05, 9.88506440e-01, 1.14738480e-02],\n",
       "       [5.21959900e-02, 6.97583800e-01, 2.50220180e-01],\n",
       "       [8.52365500e-01, 8.26687840e-04, 1.46807750e-01],\n",
       "       [6.37514940e-03, 9.32246800e-02, 9.00400160e-01],\n",
       "       [1.06089620e-03, 7.50458360e-01, 2.48480700e-01],\n",
       "       [9.54599600e-01, 8.27390000e-03, 3.71265230e-02],\n",
       "       [5.23622630e-01, 3.97015040e-01, 7.93624150e-02],\n",
       "       [1.80671400e-02, 2.41905330e-01, 7.40027550e-01],\n",
       "       [9.94976400e-01, 5.61656270e-05, 4.96740800e-03],\n",
       "       [9.40418360e-01, 5.95306200e-02, 5.09643800e-05],\n",
       "       [9.40418360e-01, 5.95306200e-02, 5.09643800e-05],\n",
       "       [8.36379900e-03, 2.99113240e-01, 6.92522940e-01],\n",
       "       [4.06184760e-01, 3.63229630e-01, 2.30585600e-01],\n",
       "       [1.43642120e-02, 1.55630600e-01, 8.30005170e-01],\n",
       "       [8.00873100e-02, 6.09809900e-01, 3.10102820e-01],\n",
       "       [1.10214970e-02, 2.02949720e-02, 9.68683600e-01],\n",
       "       [1.67824010e-04, 9.82274530e-01, 1.75575990e-02],\n",
       "       [4.12434500e-01, 2.29769180e-03, 5.85267840e-01],\n",
       "       [1.50417320e-02, 9.25515230e-01, 5.94430600e-02],\n",
       "       [4.51702330e-01, 2.37435560e-01, 3.10862100e-01],\n",
       "       [3.22657170e-04, 9.85922930e-01, 1.37544240e-02],\n",
       "       [5.81129100e-04, 9.70737400e-01, 2.86813860e-02],\n",
       "       [9.89779830e-01, 3.22422640e-03, 6.99591540e-03],\n",
       "       [9.89779830e-01, 3.22422640e-03, 6.99591540e-03],\n",
       "       [2.50440270e-01, 1.88957780e-01, 5.60601950e-01],\n",
       "       [9.94976400e-01, 5.61656270e-05, 4.96740800e-03],\n",
       "       [1.18838100e-01, 5.71689400e-01, 3.09472500e-01],\n",
       "       [9.84560130e-01, 1.04924040e-02, 4.94748350e-03],\n",
       "       [4.06184760e-01, 3.63229630e-01, 2.30585600e-01],\n",
       "       [4.30417670e-03, 1.65146780e-03, 9.94044360e-01],\n",
       "       [9.89779830e-01, 3.22422640e-03, 6.99591540e-03],\n",
       "       [9.99353470e-01, 2.45278720e-06, 6.44074300e-04],\n",
       "       [3.66158640e-04, 9.98868900e-01, 7.64887800e-04],\n",
       "       [9.86868500e-01, 9.23235500e-05, 1.30392110e-02],\n",
       "       [9.38129100e-02, 1.79861020e-01, 7.26326100e-01],\n",
       "       [8.87135450e-01, 5.13990350e-04, 1.12350590e-01],\n",
       "       [9.94976400e-01, 5.61656270e-05, 4.96740800e-03],\n",
       "       [1.63749650e-01, 7.68046000e-01, 6.82043100e-02],\n",
       "       [4.90204170e-02, 6.53530960e-01, 2.97448720e-01],\n",
       "       [2.99880070e-03, 8.32611800e-03, 9.88675100e-01],\n",
       "       [3.06416840e-03, 6.49610860e-03, 9.90439650e-01],\n",
       "       [9.67820100e-04, 1.03984036e-01, 8.95048140e-01],\n",
       "       [8.24092270e-01, 8.68281050e-02, 8.90796200e-02],\n",
       "       [8.24092270e-01, 8.68281050e-02, 8.90796200e-02],\n",
       "       [9.26130700e-03, 9.56808600e-01, 3.39301700e-02],\n",
       "       [1.81927570e-03, 4.06482440e-03, 9.94115800e-01],\n",
       "       [9.99353470e-01, 2.45278720e-06, 6.44074300e-04],\n",
       "       [4.51702330e-01, 2.37435560e-01, 3.10862100e-01],\n",
       "       [9.45459900e-01, 1.99238710e-02, 3.46162500e-02],\n",
       "       [9.88551400e-01, 6.08929400e-05, 1.13876770e-02],\n",
       "       [9.40418360e-01, 5.95306200e-02, 5.09643800e-05],\n",
       "       [2.64778640e-01, 4.66939000e-01, 2.68282300e-01],\n",
       "       [2.27621400e-02, 2.45942370e-01, 7.31295470e-01],\n",
       "       [7.25909200e-02, 7.72044800e-01, 1.55364320e-01],\n",
       "       [8.54459700e-03, 1.69378650e-01, 8.22076700e-01],\n",
       "       [8.13200350e-01, 2.08034300e-03, 1.84719260e-01],\n",
       "       [3.36265560e-02, 4.51625850e-01, 5.14747600e-01],\n",
       "       [9.04103700e-03, 1.70682550e-01, 8.20276400e-01],\n",
       "       [9.88671200e-01, 6.11592130e-03, 5.21287800e-03],\n",
       "       [9.02212100e-03, 9.43538500e-01, 4.74393550e-02],\n",
       "       [1.72343940e-03, 7.48768000e-01, 2.49508570e-01],\n",
       "       [4.47796960e-02, 4.81733080e-01, 4.73487260e-01],\n",
       "       [9.88671200e-01, 6.11592130e-03, 5.21287800e-03],\n",
       "       [1.45386940e-03, 2.99938620e-01, 6.98607500e-01],\n",
       "       [3.50855220e-03, 9.81843770e-01, 1.46476680e-02],\n",
       "       [3.66158640e-04, 9.98868900e-01, 7.64887800e-04],\n",
       "       [1.49484070e-04, 7.64961540e-01, 2.34889000e-01],\n",
       "       [8.08817400e-01, 1.59009640e-01, 3.21730230e-02],\n",
       "       [2.42049180e-03, 3.34578800e-01, 6.63000700e-01],\n",
       "       [8.08817400e-01, 1.59009640e-01, 3.21730230e-02],\n",
       "       [6.92967100e-01, 1.74893680e-01, 1.32139240e-01],\n",
       "       [2.53597830e-04, 5.34453400e-03, 9.94401900e-01],\n",
       "       [1.63093690e-04, 1.05352240e-01, 8.94484700e-01],\n",
       "       [3.36265560e-02, 4.51625850e-01, 5.14747600e-01],\n",
       "       [1.99811010e-04, 7.53278550e-01, 2.46521640e-01],\n",
       "       [5.40486950e-02, 4.09001980e-01, 5.36949340e-01],\n",
       "       [1.39976280e-01, 2.10281220e-01, 6.49742500e-01],\n",
       "       [6.60503500e-04, 3.87514990e-03, 9.95464400e-01],\n",
       "       [3.58293580e-03, 6.96695150e-02, 9.26747500e-01],\n",
       "       [9.76262300e-01, 1.52440990e-02, 8.49358550e-03],\n",
       "       [1.04455840e-02, 8.99024960e-01, 9.05295000e-02],\n",
       "       [3.76651900e-02, 8.98222300e-01, 6.41124600e-02],\n",
       "       [1.96927670e-05, 9.88506440e-01, 1.14738480e-02],\n",
       "       [1.68936270e-02, 6.57833830e-03, 9.76528000e-01],\n",
       "       [1.84087300e-02, 9.00178300e-01, 8.14129300e-02],\n",
       "       [4.27475700e-04, 9.67356860e-01, 3.22156900e-02],\n",
       "       [1.67824010e-04, 9.82274530e-01, 1.75575990e-02],\n",
       "       [8.66658000e-05, 9.64854960e-01, 3.50584570e-02],\n",
       "       [8.24092270e-01, 8.68281050e-02, 8.90796200e-02],\n",
       "       [9.26130700e-03, 9.56808600e-01, 3.39301700e-02],\n",
       "       [1.18102430e-01, 4.95727480e-01, 3.86170100e-01],\n",
       "       [9.23442070e-01, 7.64918850e-02, 6.61021840e-05],\n",
       "       [2.76755220e-03, 2.61522680e-01, 7.35709700e-01],\n",
       "       [9.23442070e-01, 7.64918850e-02, 6.61021840e-05],\n",
       "       [9.45459900e-01, 1.99238710e-02, 3.46162500e-02],\n",
       "       [9.08474700e-01, 6.74907600e-04, 9.08503700e-02],\n",
       "       [2.75933180e-04, 2.69916650e-03, 9.97024950e-01],\n",
       "       [7.25909200e-02, 7.72044800e-01, 1.55364320e-01],\n",
       "       [9.08474700e-01, 6.74907600e-04, 9.08503700e-02],\n",
       "       [8.00873100e-02, 6.09809900e-01, 3.10102820e-01],\n",
       "       [9.76262300e-01, 1.52440990e-02, 8.49358550e-03],\n",
       "       [1.70041940e-03, 9.86425640e-01, 1.18739650e-02],\n",
       "       [1.67824010e-04, 9.82274530e-01, 1.75575990e-02],\n",
       "       [9.99353470e-01, 2.45278720e-06, 6.44074300e-04],\n",
       "       [9.94976400e-01, 5.61656270e-05, 4.96740800e-03],\n",
       "       [9.88952500e-01, 6.71933730e-03, 4.32811860e-03],\n",
       "       [1.13373960e-02, 1.87158350e-01, 8.01504300e-01],\n",
       "       [9.45459900e-01, 1.99238710e-02, 3.46162500e-02],\n",
       "       [1.15040414e-01, 2.05235620e-01, 6.79724000e-01],\n",
       "       [1.32075750e-06, 9.79427100e-01, 2.05715820e-02],\n",
       "       [9.84560130e-01, 1.04924040e-02, 4.94748350e-03],\n",
       "       [9.02212100e-03, 9.43538500e-01, 4.74393550e-02],\n",
       "       [8.87135450e-01, 5.13990350e-04, 1.12350590e-01],\n",
       "       [3.50171700e-02, 9.34155940e-01, 3.08269100e-02],\n",
       "       [8.79270360e-02, 7.00249800e-01, 2.11823170e-01],\n",
       "       [9.88671200e-01, 6.11592130e-03, 5.21287800e-03],\n",
       "       [8.00873100e-02, 6.09809900e-01, 3.10102820e-01],\n",
       "       [7.47738900e-01, 1.92527760e-03, 2.50335870e-01],\n",
       "       [3.50171700e-02, 9.34155940e-01, 3.08269100e-02],\n",
       "       [1.96927670e-05, 9.88506440e-01, 1.14738480e-02]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob3 = df_proba3[df_proba3['phage']=='p11kpresabsSTCC_qual'].iloc[:,-3:]\n",
    "y_prob3 = y_prob3.to_numpy()\n",
    "y_prob3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9531312101648494"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo3 = rocauc_ovo(y_test_over, y_prob3, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9531312101648494"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr3 = rocauc_ovr(y_test_over, y_prob3, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=456,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat4 = pd.DataFrame(X_test_over[:,0])\n",
    "dat4['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SR2852</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CFBREBSa138</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BCH-SA-12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EUH13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EUH13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>NRS036</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>CA105</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>CFBRSa51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>NRS102</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>NRS189</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test\n",
       "0         SR2852     2\n",
       "1    CFBREBSa138     0\n",
       "2      BCH-SA-12     0\n",
       "3          EUH13     0\n",
       "4          EUH13     0\n",
       "..           ...   ...\n",
       "158       NRS036     1\n",
       "159        CA105     1\n",
       "160     CFBRSa51     1\n",
       "161       NRS102     1\n",
       "162       NRS189     2\n",
       "\n",
       "[163 rows x 2 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over4 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over4.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 380 samples, validate on 163 samples\n",
      "Epoch 1/100\n",
      "380/380 [==============================] - 0s 473us/step - loss: 1.2731 - accuracy: 0.3816 - val_loss: 1.1167 - val_accuracy: 0.3681\n",
      "Epoch 2/100\n",
      "380/380 [==============================] - 0s 151us/step - loss: 1.0736 - accuracy: 0.4553 - val_loss: 1.0479 - val_accuracy: 0.4294\n",
      "Epoch 3/100\n",
      "380/380 [==============================] - 0s 147us/step - loss: 0.9981 - accuracy: 0.5421 - val_loss: 1.0225 - val_accuracy: 0.5153\n",
      "Epoch 4/100\n",
      "380/380 [==============================] - 0s 183us/step - loss: 0.9603 - accuracy: 0.5947 - val_loss: 1.0239 - val_accuracy: 0.5337\n",
      "Epoch 5/100\n",
      "380/380 [==============================] - 0s 157us/step - loss: 0.9086 - accuracy: 0.6474 - val_loss: 0.9870 - val_accuracy: 0.5460\n",
      "Epoch 6/100\n",
      "380/380 [==============================] - 0s 128us/step - loss: 0.8927 - accuracy: 0.6684 - val_loss: 0.9510 - val_accuracy: 0.6074\n",
      "Epoch 7/100\n",
      "380/380 [==============================] - 0s 123us/step - loss: 0.8504 - accuracy: 0.6921 - val_loss: 0.8947 - val_accuracy: 0.6012\n",
      "Epoch 8/100\n",
      "380/380 [==============================] - 0s 299us/step - loss: 0.8154 - accuracy: 0.7026 - val_loss: 0.9334 - val_accuracy: 0.5951\n",
      "Epoch 9/100\n",
      "380/380 [==============================] - 0s 229us/step - loss: 0.7922 - accuracy: 0.7026 - val_loss: 0.8565 - val_accuracy: 0.6196\n",
      "Epoch 10/100\n",
      "380/380 [==============================] - 0s 97us/step - loss: 0.7768 - accuracy: 0.7105 - val_loss: 0.8398 - val_accuracy: 0.6687\n",
      "Epoch 11/100\n",
      "380/380 [==============================] - 0s 114us/step - loss: 0.7379 - accuracy: 0.7132 - val_loss: 0.8384 - val_accuracy: 0.6012\n",
      "Epoch 12/100\n",
      "380/380 [==============================] - 0s 128us/step - loss: 0.7095 - accuracy: 0.7395 - val_loss: 0.8024 - val_accuracy: 0.6503\n",
      "Epoch 13/100\n",
      "380/380 [==============================] - 0s 141us/step - loss: 0.6969 - accuracy: 0.7579 - val_loss: 0.7935 - val_accuracy: 0.6564\n",
      "Epoch 14/100\n",
      "380/380 [==============================] - 0s 195us/step - loss: 0.6733 - accuracy: 0.7763 - val_loss: 0.7578 - val_accuracy: 0.6626\n",
      "Epoch 15/100\n",
      "380/380 [==============================] - 0s 187us/step - loss: 0.6637 - accuracy: 0.7816 - val_loss: 0.8010 - val_accuracy: 0.6626\n",
      "Epoch 16/100\n",
      "380/380 [==============================] - 0s 227us/step - loss: 0.6802 - accuracy: 0.7553 - val_loss: 0.7384 - val_accuracy: 0.6933\n",
      "Epoch 17/100\n",
      "380/380 [==============================] - 0s 216us/step - loss: 0.6425 - accuracy: 0.8000 - val_loss: 0.8132 - val_accuracy: 0.6748\n",
      "Epoch 18/100\n",
      "380/380 [==============================] - 0s 158us/step - loss: 0.6814 - accuracy: 0.7684 - val_loss: 0.8712 - val_accuracy: 0.6503\n",
      "Epoch 19/100\n",
      "380/380 [==============================] - 0s 114us/step - loss: 0.6058 - accuracy: 0.7895 - val_loss: 0.7184 - val_accuracy: 0.7178\n",
      "Epoch 20/100\n",
      "380/380 [==============================] - 0s 96us/step - loss: 0.5924 - accuracy: 0.8000 - val_loss: 0.7410 - val_accuracy: 0.6933\n",
      "Epoch 21/100\n",
      "380/380 [==============================] - 0s 88us/step - loss: 0.5653 - accuracy: 0.8000 - val_loss: 0.7168 - val_accuracy: 0.7178\n",
      "Epoch 22/100\n",
      "380/380 [==============================] - 0s 88us/step - loss: 0.5448 - accuracy: 0.8026 - val_loss: 0.6645 - val_accuracy: 0.7301\n",
      "Epoch 23/100\n",
      "380/380 [==============================] - 0s 87us/step - loss: 0.5448 - accuracy: 0.8263 - val_loss: 0.7399 - val_accuracy: 0.7362\n",
      "Epoch 24/100\n",
      "380/380 [==============================] - 0s 109us/step - loss: 0.5325 - accuracy: 0.7974 - val_loss: 0.6590 - val_accuracy: 0.6933\n",
      "Epoch 25/100\n",
      "380/380 [==============================] - 0s 196us/step - loss: 0.5257 - accuracy: 0.7868 - val_loss: 0.6692 - val_accuracy: 0.7423\n",
      "Epoch 26/100\n",
      "380/380 [==============================] - 0s 238us/step - loss: 0.5231 - accuracy: 0.8079 - val_loss: 0.6705 - val_accuracy: 0.7423\n",
      "Epoch 27/100\n",
      "380/380 [==============================] - 0s 152us/step - loss: 0.5030 - accuracy: 0.8211 - val_loss: 0.6195 - val_accuracy: 0.7607\n",
      "Epoch 28/100\n",
      "380/380 [==============================] - 0s 180us/step - loss: 0.4855 - accuracy: 0.8211 - val_loss: 0.6945 - val_accuracy: 0.7485\n",
      "Epoch 29/100\n",
      "380/380 [==============================] - 0s 201us/step - loss: 0.4712 - accuracy: 0.8342 - val_loss: 0.6049 - val_accuracy: 0.7485\n",
      "Epoch 30/100\n",
      "380/380 [==============================] - 0s 166us/step - loss: 0.4481 - accuracy: 0.8447 - val_loss: 0.6478 - val_accuracy: 0.7607\n",
      "Epoch 31/100\n",
      "380/380 [==============================] - 0s 192us/step - loss: 0.4600 - accuracy: 0.8447 - val_loss: 0.6903 - val_accuracy: 0.7239\n",
      "Epoch 32/100\n",
      "380/380 [==============================] - 0s 138us/step - loss: 0.4626 - accuracy: 0.8368 - val_loss: 0.5802 - val_accuracy: 0.7730\n",
      "Epoch 33/100\n",
      "380/380 [==============================] - 0s 236us/step - loss: 0.4298 - accuracy: 0.8500 - val_loss: 0.7021 - val_accuracy: 0.7239\n",
      "Epoch 34/100\n",
      "380/380 [==============================] - 0s 279us/step - loss: 0.4177 - accuracy: 0.8553 - val_loss: 0.6062 - val_accuracy: 0.7607\n",
      "Epoch 35/100\n",
      "380/380 [==============================] - 0s 146us/step - loss: 0.4415 - accuracy: 0.8474 - val_loss: 0.6458 - val_accuracy: 0.7546\n",
      "Epoch 36/100\n",
      "380/380 [==============================] - 0s 209us/step - loss: 0.3997 - accuracy: 0.8526 - val_loss: 0.5626 - val_accuracy: 0.7607\n",
      "Epoch 37/100\n",
      "380/380 [==============================] - 0s 256us/step - loss: 0.4259 - accuracy: 0.8500 - val_loss: 0.7142 - val_accuracy: 0.7178\n",
      "Epoch 38/100\n",
      "380/380 [==============================] - 0s 218us/step - loss: 0.4113 - accuracy: 0.8447 - val_loss: 0.5984 - val_accuracy: 0.7607\n",
      "Epoch 39/100\n",
      "380/380 [==============================] - 0s 154us/step - loss: 0.4366 - accuracy: 0.8447 - val_loss: 0.6095 - val_accuracy: 0.7301\n",
      "Epoch 40/100\n",
      "380/380 [==============================] - 0s 152us/step - loss: 0.3896 - accuracy: 0.8447 - val_loss: 0.5540 - val_accuracy: 0.7669\n",
      "Epoch 41/100\n",
      "380/380 [==============================] - 0s 153us/step - loss: 0.3762 - accuracy: 0.8632 - val_loss: 0.6608 - val_accuracy: 0.7362\n",
      "Epoch 42/100\n",
      "380/380 [==============================] - 0s 232us/step - loss: 0.3996 - accuracy: 0.8553 - val_loss: 0.5453 - val_accuracy: 0.7853\n",
      "Epoch 43/100\n",
      "380/380 [==============================] - 0s 212us/step - loss: 0.4027 - accuracy: 0.8474 - val_loss: 0.5681 - val_accuracy: 0.7485\n",
      "Epoch 44/100\n",
      "380/380 [==============================] - 0s 130us/step - loss: 0.4515 - accuracy: 0.8447 - val_loss: 0.6702 - val_accuracy: 0.7669\n",
      "Epoch 45/100\n",
      "380/380 [==============================] - 0s 247us/step - loss: 0.4383 - accuracy: 0.8500 - val_loss: 0.5616 - val_accuracy: 0.7669\n",
      "Epoch 46/100\n",
      "380/380 [==============================] - 0s 267us/step - loss: 0.3764 - accuracy: 0.8500 - val_loss: 0.5362 - val_accuracy: 0.7914\n",
      "Epoch 47/100\n",
      "380/380 [==============================] - 0s 150us/step - loss: 0.3490 - accuracy: 0.8632 - val_loss: 0.5917 - val_accuracy: 0.7485\n",
      "Epoch 48/100\n",
      "380/380 [==============================] - 0s 128us/step - loss: 0.3434 - accuracy: 0.8658 - val_loss: 0.5451 - val_accuracy: 0.7975\n",
      "Epoch 49/100\n",
      "380/380 [==============================] - 0s 89us/step - loss: 0.3400 - accuracy: 0.8763 - val_loss: 0.5675 - val_accuracy: 0.8037\n",
      "Epoch 50/100\n",
      "380/380 [==============================] - 0s 100us/step - loss: 0.3398 - accuracy: 0.8763 - val_loss: 0.5995 - val_accuracy: 0.7669\n",
      "Epoch 51/100\n",
      "380/380 [==============================] - 0s 89us/step - loss: 0.3358 - accuracy: 0.8737 - val_loss: 0.5268 - val_accuracy: 0.7975\n",
      "Epoch 52/100\n",
      "380/380 [==============================] - 0s 130us/step - loss: 0.3422 - accuracy: 0.8842 - val_loss: 0.5389 - val_accuracy: 0.7975\n",
      "Epoch 53/100\n",
      "380/380 [==============================] - 0s 144us/step - loss: 0.3338 - accuracy: 0.8763 - val_loss: 0.5725 - val_accuracy: 0.7853\n",
      "Epoch 54/100\n",
      "380/380 [==============================] - 0s 134us/step - loss: 0.3284 - accuracy: 0.8763 - val_loss: 0.5275 - val_accuracy: 0.8160\n",
      "Epoch 55/100\n",
      "380/380 [==============================] - 0s 136us/step - loss: 0.3009 - accuracy: 0.8974 - val_loss: 0.5628 - val_accuracy: 0.8037\n",
      "Epoch 56/100\n",
      "380/380 [==============================] - 0s 116us/step - loss: 0.3090 - accuracy: 0.8868 - val_loss: 0.5404 - val_accuracy: 0.8221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "380/380 [==============================] - 0s 94us/step - loss: 0.3053 - accuracy: 0.9000 - val_loss: 0.5239 - val_accuracy: 0.7975\n",
      "Epoch 58/100\n",
      "380/380 [==============================] - 0s 88us/step - loss: 0.2998 - accuracy: 0.8842 - val_loss: 0.5042 - val_accuracy: 0.8037\n",
      "Epoch 59/100\n",
      "380/380 [==============================] - 0s 125us/step - loss: 0.3213 - accuracy: 0.8763 - val_loss: 0.5201 - val_accuracy: 0.8037\n",
      "Epoch 60/100\n",
      "380/380 [==============================] - 0s 110us/step - loss: 0.3109 - accuracy: 0.8868 - val_loss: 0.5134 - val_accuracy: 0.7730\n",
      "Epoch 61/100\n",
      "380/380 [==============================] - 0s 109us/step - loss: 0.2884 - accuracy: 0.8895 - val_loss: 0.4953 - val_accuracy: 0.8037\n",
      "Epoch 62/100\n",
      "380/380 [==============================] - 0s 122us/step - loss: 0.3011 - accuracy: 0.8895 - val_loss: 0.5460 - val_accuracy: 0.7914\n",
      "Epoch 63/100\n",
      "380/380 [==============================] - 0s 134us/step - loss: 0.2788 - accuracy: 0.8895 - val_loss: 0.4510 - val_accuracy: 0.8160\n",
      "Epoch 64/100\n",
      "380/380 [==============================] - 0s 153us/step - loss: 0.2774 - accuracy: 0.8895 - val_loss: 0.5376 - val_accuracy: 0.7975\n",
      "Epoch 65/100\n",
      "380/380 [==============================] - 0s 114us/step - loss: 0.3101 - accuracy: 0.9053 - val_loss: 0.5662 - val_accuracy: 0.8282\n",
      "Epoch 66/100\n",
      "380/380 [==============================] - 0s 89us/step - loss: 0.2668 - accuracy: 0.9000 - val_loss: 0.5414 - val_accuracy: 0.7791\n",
      "Epoch 67/100\n",
      "380/380 [==============================] - 0s 90us/step - loss: 0.3778 - accuracy: 0.8974 - val_loss: 0.6536 - val_accuracy: 0.8037\n",
      "Epoch 68/100\n",
      "380/380 [==============================] - 0s 91us/step - loss: 0.3215 - accuracy: 0.8842 - val_loss: 0.5207 - val_accuracy: 0.8221\n",
      "Epoch 69/100\n",
      "380/380 [==============================] - 0s 86us/step - loss: 0.2924 - accuracy: 0.8816 - val_loss: 0.4820 - val_accuracy: 0.7914\n",
      "Epoch 70/100\n",
      "380/380 [==============================] - 0s 87us/step - loss: 0.3024 - accuracy: 0.8974 - val_loss: 0.6022 - val_accuracy: 0.7975\n",
      "Epoch 71/100\n",
      "380/380 [==============================] - 0s 86us/step - loss: 0.2807 - accuracy: 0.8711 - val_loss: 0.4942 - val_accuracy: 0.8221\n",
      "Epoch 72/100\n",
      "380/380 [==============================] - 0s 84us/step - loss: 0.2607 - accuracy: 0.8974 - val_loss: 0.4590 - val_accuracy: 0.8773\n",
      "Epoch 73/100\n",
      "380/380 [==============================] - 0s 94us/step - loss: 0.2528 - accuracy: 0.9184 - val_loss: 0.5237 - val_accuracy: 0.8098\n",
      "Epoch 74/100\n",
      "380/380 [==============================] - 0s 84us/step - loss: 0.2468 - accuracy: 0.9158 - val_loss: 0.4870 - val_accuracy: 0.8405\n",
      "Epoch 75/100\n",
      "380/380 [==============================] - 0s 88us/step - loss: 0.2578 - accuracy: 0.9053 - val_loss: 0.6421 - val_accuracy: 0.7730\n",
      "Epoch 76/100\n",
      "380/380 [==============================] - 0s 86us/step - loss: 0.2860 - accuracy: 0.8711 - val_loss: 0.4981 - val_accuracy: 0.8528\n",
      "Epoch 77/100\n",
      "380/380 [==============================] - 0s 89us/step - loss: 0.3527 - accuracy: 0.9132 - val_loss: 0.6168 - val_accuracy: 0.8037\n",
      "Epoch 78/100\n",
      "380/380 [==============================] - 0s 86us/step - loss: 0.2744 - accuracy: 0.8816 - val_loss: 1.1259 - val_accuracy: 0.8160\n",
      "Epoch 79/100\n",
      "380/380 [==============================] - 0s 83us/step - loss: 0.4920 - accuracy: 0.8868 - val_loss: 0.5590 - val_accuracy: 0.8528\n",
      "Epoch 80/100\n",
      "380/380 [==============================] - 0s 99us/step - loss: 0.4621 - accuracy: 0.8921 - val_loss: 0.6838 - val_accuracy: 0.8160\n",
      "Epoch 81/100\n",
      "380/380 [==============================] - 0s 95us/step - loss: 0.3914 - accuracy: 0.8842 - val_loss: 0.5270 - val_accuracy: 0.7853\n",
      "Epoch 82/100\n",
      "380/380 [==============================] - 0s 99us/step - loss: 0.2819 - accuracy: 0.8816 - val_loss: 0.6429 - val_accuracy: 0.8405\n",
      "Epoch 83/100\n",
      "380/380 [==============================] - 0s 83us/step - loss: 0.2773 - accuracy: 0.9184 - val_loss: 0.5870 - val_accuracy: 0.8773\n",
      "Epoch 84/100\n",
      "380/380 [==============================] - 0s 94us/step - loss: 0.2430 - accuracy: 0.9132 - val_loss: 0.6218 - val_accuracy: 0.7975\n",
      "Epoch 85/100\n",
      "380/380 [==============================] - 0s 85us/step - loss: 0.2460 - accuracy: 0.9184 - val_loss: 0.5711 - val_accuracy: 0.8466\n",
      "Epoch 86/100\n",
      "380/380 [==============================] - 0s 92us/step - loss: 0.2708 - accuracy: 0.9158 - val_loss: 0.5361 - val_accuracy: 0.8773\n",
      "Epoch 87/100\n",
      "380/380 [==============================] - 0s 108us/step - loss: 0.2619 - accuracy: 0.9289 - val_loss: 0.5095 - val_accuracy: 0.8466\n",
      "Epoch 88/100\n",
      "380/380 [==============================] - 0s 122us/step - loss: 0.2555 - accuracy: 0.9211 - val_loss: 0.5471 - val_accuracy: 0.8773\n",
      "Epoch 89/100\n",
      "380/380 [==============================] - 0s 92us/step - loss: 0.2519 - accuracy: 0.9211 - val_loss: 0.5317 - val_accuracy: 0.8344\n",
      "Epoch 90/100\n",
      "380/380 [==============================] - 0s 87us/step - loss: 0.2459 - accuracy: 0.9158 - val_loss: 0.5936 - val_accuracy: 0.8528\n",
      "Epoch 91/100\n",
      "380/380 [==============================] - 0s 97us/step - loss: 0.2071 - accuracy: 0.9342 - val_loss: 0.4916 - val_accuracy: 0.8589\n",
      "Epoch 92/100\n",
      "380/380 [==============================] - 0s 92us/step - loss: 0.2281 - accuracy: 0.9158 - val_loss: 0.5605 - val_accuracy: 0.8405\n",
      "Epoch 93/100\n",
      "380/380 [==============================] - 0s 105us/step - loss: 0.2170 - accuracy: 0.9289 - val_loss: 0.4855 - val_accuracy: 0.8896\n",
      "Epoch 94/100\n",
      "380/380 [==============================] - 0s 86us/step - loss: 0.2183 - accuracy: 0.9289 - val_loss: 0.5097 - val_accuracy: 0.8466\n",
      "Epoch 95/100\n",
      "380/380 [==============================] - 0s 95us/step - loss: 0.2269 - accuracy: 0.9158 - val_loss: 0.5286 - val_accuracy: 0.8896\n",
      "Epoch 96/100\n",
      "380/380 [==============================] - 0s 83us/step - loss: 0.2706 - accuracy: 0.9000 - val_loss: 0.4705 - val_accuracy: 0.8405\n",
      "Epoch 97/100\n",
      "380/380 [==============================] - 0s 87us/step - loss: 0.2488 - accuracy: 0.9158 - val_loss: 0.6507 - val_accuracy: 0.8282\n",
      "Epoch 98/100\n",
      "380/380 [==============================] - 0s 82us/step - loss: 0.2765 - accuracy: 0.8947 - val_loss: 0.5157 - val_accuracy: 0.8466\n",
      "Epoch 99/100\n",
      "380/380 [==============================] - 0s 115us/step - loss: 0.2297 - accuracy: 0.9184 - val_loss: 0.4509 - val_accuracy: 0.8773\n",
      "Epoch 100/100\n",
      "380/380 [==============================] - 0s 137us/step - loss: 0.2563 - accuracy: 0.9316 - val_loss: 0.5295 - val_accuracy: 0.8589\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a351f5048>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over4.fit(X_train_over, y_train_over,\n",
    "          batch_size=64, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163/163 [==============================] - 0s 105us/step\n",
      "over-sampling test accuracy: 84.66%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over4 = model1_over4.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over4*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 0, 0, 0, 1, 0, 2, 0, 0, 1, 0, 2, 0, 2, 0, 0, 0, 2, 0, 2, 2,\n",
       "       0, 1, 1, 2, 1, 0, 2, 0, 0, 2, 1, 1, 2, 0, 0, 2, 0, 0, 0, 1, 1, 1,\n",
       "       1, 1, 2, 0, 0, 0, 1, 1, 1, 1, 2, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1,\n",
       "       1, 0, 2, 0, 0, 1, 0, 0, 1, 2, 1, 1, 0, 2, 0, 0, 2, 1, 0, 1, 0, 2,\n",
       "       0, 0, 0, 1, 1, 2, 1, 1, 0, 1, 1, 1, 0, 0, 2, 1, 2, 2, 1, 2, 1, 0,\n",
       "       2, 0, 1, 1, 0, 0, 0, 1, 2, 1, 1, 2, 2, 2, 1, 1, 2, 1, 2, 0, 1, 0,\n",
       "       1, 1, 2, 1, 0, 2, 1, 1, 0, 0, 2, 0, 2, 0, 1, 1, 1, 0, 0, 1, 2, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 2])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred4 = model1_over4.predict_classes(X_test_over)\n",
    "pred4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SR2852</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CFBREBSa138</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BCH-SA-12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EUH13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EUH13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>NRS036</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>CA105</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>CFBRSa51</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>NRS102</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>NRS189</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test  pred\n",
       "0         SR2852     2     2\n",
       "1    CFBREBSa138     0     0\n",
       "2      BCH-SA-12     0     0\n",
       "3          EUH13     0     0\n",
       "4          EUH13     0     0\n",
       "..           ...   ...   ...\n",
       "158       NRS036     1     1\n",
       "159        CA105     1     1\n",
       "160     CFBRSa51     1     1\n",
       "161       NRS102     1     1\n",
       "162       NRS189     2     2\n",
       "\n",
       "[163 rows x 3 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat4['pred'] = pred4\n",
    "dat4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba4 = model1_over4.predict_proba(X_test_over)\n",
    "dat_proba4 = pd.DataFrame(proba4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.028310</td>\n",
       "      <td>0.266584</td>\n",
       "      <td>0.705106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.998137</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>0.001734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.996181</td>\n",
       "      <td>0.000866</td>\n",
       "      <td>0.002953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.999984</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.999984</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>0.015832</td>\n",
       "      <td>0.963925</td>\n",
       "      <td>0.020242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>0.001470</td>\n",
       "      <td>0.996410</td>\n",
       "      <td>0.002120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>0.002234</td>\n",
       "      <td>0.980447</td>\n",
       "      <td>0.017319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>0.002602</td>\n",
       "      <td>0.994918</td>\n",
       "      <td>0.002480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>0.001276</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.998696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2\n",
       "0    0.028310  0.266584  0.705106\n",
       "1    0.998137  0.000130  0.001734\n",
       "2    0.996181  0.000866  0.002953\n",
       "3    0.999984  0.000015  0.000001\n",
       "4    0.999984  0.000015  0.000001\n",
       "..        ...       ...       ...\n",
       "158  0.015832  0.963925  0.020242\n",
       "159  0.001470  0.996410  0.002120\n",
       "160  0.002234  0.980447  0.017319\n",
       "161  0.002602  0.994918  0.002480\n",
       "162  0.001276  0.000028  0.998696\n",
       "\n",
       "[163 rows x 3 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba4.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba4.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat4.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/4p11ST.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 380 samples, validate on 163 samples\n",
      "Epoch 1/100\n",
      "380/380 [==============================] - 0s 136us/step - loss: 0.1653 - accuracy: 0.9342 - val_loss: 0.4255 - val_accuracy: 0.8528\n",
      "Epoch 2/100\n",
      "380/380 [==============================] - 0s 155us/step - loss: 0.1694 - accuracy: 0.9211 - val_loss: 0.4749 - val_accuracy: 0.8282\n",
      "Epoch 3/100\n",
      "380/380 [==============================] - 0s 120us/step - loss: 0.1865 - accuracy: 0.9289 - val_loss: 0.5938 - val_accuracy: 0.7730\n",
      "Epoch 4/100\n",
      "380/380 [==============================] - 0s 127us/step - loss: 0.2453 - accuracy: 0.8921 - val_loss: 0.4616 - val_accuracy: 0.8528\n",
      "Epoch 5/100\n",
      "380/380 [==============================] - 0s 136us/step - loss: 0.1961 - accuracy: 0.9211 - val_loss: 0.4382 - val_accuracy: 0.8344\n",
      "Epoch 6/100\n",
      "380/380 [==============================] - 0s 112us/step - loss: 0.1653 - accuracy: 0.9500 - val_loss: 0.4484 - val_accuracy: 0.8221\n",
      "Epoch 7/100\n",
      "380/380 [==============================] - 0s 108us/step - loss: 0.1767 - accuracy: 0.9342 - val_loss: 0.4993 - val_accuracy: 0.8528\n",
      "Epoch 8/100\n",
      "380/380 [==============================] - 0s 91us/step - loss: 0.1632 - accuracy: 0.9474 - val_loss: 0.4304 - val_accuracy: 0.8282\n",
      "Epoch 9/100\n",
      "380/380 [==============================] - 0s 88us/step - loss: 0.1600 - accuracy: 0.9421 - val_loss: 0.4744 - val_accuracy: 0.8282\n",
      "Epoch 10/100\n",
      "380/380 [==============================] - 0s 88us/step - loss: 0.1716 - accuracy: 0.9421 - val_loss: 0.5124 - val_accuracy: 0.8037\n",
      "Epoch 11/100\n",
      "380/380 [==============================] - 0s 115us/step - loss: 0.1688 - accuracy: 0.9237 - val_loss: 0.5215 - val_accuracy: 0.8528\n",
      "Epoch 12/100\n",
      "380/380 [==============================] - 0s 99us/step - loss: 0.1453 - accuracy: 0.9421 - val_loss: 0.4427 - val_accuracy: 0.8282\n",
      "Epoch 13/100\n",
      "380/380 [==============================] - 0s 101us/step - loss: 0.1705 - accuracy: 0.9395 - val_loss: 0.5209 - val_accuracy: 0.8160\n",
      "Epoch 14/100\n",
      "380/380 [==============================] - 0s 105us/step - loss: 0.1812 - accuracy: 0.9263 - val_loss: 0.4137 - val_accuracy: 0.8344\n",
      "Epoch 15/100\n",
      "380/380 [==============================] - 0s 98us/step - loss: 0.1722 - accuracy: 0.9316 - val_loss: 0.4568 - val_accuracy: 0.8282\n",
      "Epoch 16/100\n",
      "380/380 [==============================] - 0s 100us/step - loss: 0.1674 - accuracy: 0.9263 - val_loss: 0.4718 - val_accuracy: 0.8466\n",
      "Epoch 17/100\n",
      "380/380 [==============================] - 0s 92us/step - loss: 0.1604 - accuracy: 0.9342 - val_loss: 0.4558 - val_accuracy: 0.8405\n",
      "Epoch 18/100\n",
      "380/380 [==============================] - 0s 109us/step - loss: 0.1695 - accuracy: 0.9237 - val_loss: 0.4869 - val_accuracy: 0.8405\n",
      "Epoch 19/100\n",
      "380/380 [==============================] - 0s 106us/step - loss: 0.1587 - accuracy: 0.9395 - val_loss: 0.4550 - val_accuracy: 0.8589\n",
      "Epoch 20/100\n",
      "380/380 [==============================] - 0s 109us/step - loss: 0.1718 - accuracy: 0.9237 - val_loss: 0.4702 - val_accuracy: 0.8344\n",
      "Epoch 21/100\n",
      "380/380 [==============================] - 0s 110us/step - loss: 0.1697 - accuracy: 0.9289 - val_loss: 0.5108 - val_accuracy: 0.8221\n",
      "Epoch 22/100\n",
      "380/380 [==============================] - 0s 112us/step - loss: 0.1498 - accuracy: 0.9474 - val_loss: 0.4128 - val_accuracy: 0.8466\n",
      "Epoch 23/100\n",
      "380/380 [==============================] - 0s 122us/step - loss: 0.1553 - accuracy: 0.9263 - val_loss: 0.4807 - val_accuracy: 0.8344\n",
      "Epoch 24/100\n",
      "380/380 [==============================] - 0s 117us/step - loss: 0.1793 - accuracy: 0.9211 - val_loss: 0.5222 - val_accuracy: 0.8160\n",
      "Epoch 25/100\n",
      "380/380 [==============================] - 0s 99us/step - loss: 0.1499 - accuracy: 0.9368 - val_loss: 0.4309 - val_accuracy: 0.8344\n",
      "Epoch 26/100\n",
      "380/380 [==============================] - 0s 94us/step - loss: 0.1606 - accuracy: 0.9263 - val_loss: 0.4807 - val_accuracy: 0.8528\n",
      "Epoch 27/100\n",
      "380/380 [==============================] - 0s 105us/step - loss: 0.1481 - accuracy: 0.9316 - val_loss: 0.4405 - val_accuracy: 0.8589\n",
      "Epoch 28/100\n",
      "380/380 [==============================] - 0s 91us/step - loss: 0.1335 - accuracy: 0.9632 - val_loss: 0.4564 - val_accuracy: 0.8834\n",
      "Epoch 29/100\n",
      "380/380 [==============================] - 0s 93us/step - loss: 0.1411 - accuracy: 0.9500 - val_loss: 0.4302 - val_accuracy: 0.8282\n",
      "Epoch 30/100\n",
      "380/380 [==============================] - 0s 108us/step - loss: 0.1361 - accuracy: 0.9447 - val_loss: 0.4611 - val_accuracy: 0.8344\n",
      "Epoch 31/100\n",
      "380/380 [==============================] - 0s 108us/step - loss: 0.1349 - accuracy: 0.9500 - val_loss: 0.4413 - val_accuracy: 0.8712\n",
      "Epoch 32/100\n",
      "380/380 [==============================] - 0s 114us/step - loss: 0.1369 - accuracy: 0.9421 - val_loss: 0.4306 - val_accuracy: 0.8896\n",
      "Epoch 33/100\n",
      "380/380 [==============================] - 0s 117us/step - loss: 0.1295 - accuracy: 0.9526 - val_loss: 0.4475 - val_accuracy: 0.8589\n",
      "Epoch 34/100\n",
      "380/380 [==============================] - 0s 121us/step - loss: 0.1387 - accuracy: 0.9474 - val_loss: 0.4307 - val_accuracy: 0.8773\n",
      "Epoch 35/100\n",
      "380/380 [==============================] - 0s 115us/step - loss: 0.1508 - accuracy: 0.9500 - val_loss: 0.4829 - val_accuracy: 0.8712\n",
      "Epoch 36/100\n",
      "380/380 [==============================] - 0s 123us/step - loss: 0.1651 - accuracy: 0.9447 - val_loss: 0.5231 - val_accuracy: 0.8957\n",
      "Epoch 37/100\n",
      "380/380 [==============================] - 0s 111us/step - loss: 0.1709 - accuracy: 0.9421 - val_loss: 0.4639 - val_accuracy: 0.8589\n",
      "Epoch 38/100\n",
      "380/380 [==============================] - 0s 105us/step - loss: 0.1499 - accuracy: 0.9342 - val_loss: 0.4976 - val_accuracy: 0.8834\n",
      "Epoch 39/100\n",
      "380/380 [==============================] - 0s 91us/step - loss: 0.1410 - accuracy: 0.9553 - val_loss: 0.5201 - val_accuracy: 0.8712\n",
      "Epoch 40/100\n",
      "380/380 [==============================] - 0s 91us/step - loss: 0.1275 - accuracy: 0.9579 - val_loss: 0.4867 - val_accuracy: 0.8773\n",
      "Epoch 41/100\n",
      "380/380 [==============================] - 0s 88us/step - loss: 0.1328 - accuracy: 0.9474 - val_loss: 0.4721 - val_accuracy: 0.9080\n",
      "Epoch 42/100\n",
      "380/380 [==============================] - 0s 88us/step - loss: 0.1240 - accuracy: 0.9605 - val_loss: 0.5186 - val_accuracy: 0.8896\n",
      "Epoch 43/100\n",
      "380/380 [==============================] - 0s 119us/step - loss: 0.1224 - accuracy: 0.9711 - val_loss: 0.4482 - val_accuracy: 0.8773\n",
      "Epoch 44/100\n",
      "380/380 [==============================] - 0s 85us/step - loss: 0.1332 - accuracy: 0.9553 - val_loss: 0.4047 - val_accuracy: 0.9018\n",
      "Epoch 45/100\n",
      "380/380 [==============================] - 0s 102us/step - loss: 0.1194 - accuracy: 0.9605 - val_loss: 0.4643 - val_accuracy: 0.8957\n",
      "Epoch 46/100\n",
      "380/380 [==============================] - 0s 100us/step - loss: 0.1233 - accuracy: 0.9684 - val_loss: 0.4555 - val_accuracy: 0.8834\n",
      "Epoch 47/100\n",
      "380/380 [==============================] - 0s 111us/step - loss: 0.1297 - accuracy: 0.9526 - val_loss: 0.4835 - val_accuracy: 0.8957\n",
      "Epoch 48/100\n",
      "380/380 [==============================] - 0s 93us/step - loss: 0.1386 - accuracy: 0.9500 - val_loss: 0.4438 - val_accuracy: 0.8589\n",
      "Epoch 49/100\n",
      "380/380 [==============================] - 0s 104us/step - loss: 0.1347 - accuracy: 0.9579 - val_loss: 0.5002 - val_accuracy: 0.8896\n",
      "Epoch 50/100\n",
      "380/380 [==============================] - 0s 111us/step - loss: 0.1270 - accuracy: 0.9632 - val_loss: 0.4123 - val_accuracy: 0.8773\n",
      "Epoch 51/100\n",
      "380/380 [==============================] - 0s 125us/step - loss: 0.1149 - accuracy: 0.9658 - val_loss: 0.4876 - val_accuracy: 0.8896\n",
      "Epoch 52/100\n",
      "380/380 [==============================] - 0s 111us/step - loss: 0.1435 - accuracy: 0.9579 - val_loss: 0.4089 - val_accuracy: 0.8834\n",
      "Epoch 53/100\n",
      "380/380 [==============================] - 0s 105us/step - loss: 0.1347 - accuracy: 0.9526 - val_loss: 0.4080 - val_accuracy: 0.9018\n",
      "Epoch 54/100\n",
      "380/380 [==============================] - 0s 108us/step - loss: 0.1413 - accuracy: 0.9421 - val_loss: 0.5243 - val_accuracy: 0.8957\n",
      "Epoch 55/100\n",
      "380/380 [==============================] - 0s 104us/step - loss: 0.1494 - accuracy: 0.9368 - val_loss: 0.4313 - val_accuracy: 0.8712\n",
      "Epoch 56/100\n",
      "380/380 [==============================] - 0s 103us/step - loss: 0.1499 - accuracy: 0.9474 - val_loss: 0.4865 - val_accuracy: 0.8650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "380/380 [==============================] - 0s 98us/step - loss: 0.1383 - accuracy: 0.9500 - val_loss: 0.4764 - val_accuracy: 0.8773\n",
      "Epoch 58/100\n",
      "380/380 [==============================] - 0s 102us/step - loss: 0.1272 - accuracy: 0.9553 - val_loss: 0.4791 - val_accuracy: 0.8957\n",
      "Epoch 59/100\n",
      "380/380 [==============================] - 0s 97us/step - loss: 0.1243 - accuracy: 0.9579 - val_loss: 0.4080 - val_accuracy: 0.8896\n",
      "Epoch 60/100\n",
      "380/380 [==============================] - 0s 102us/step - loss: 0.1207 - accuracy: 0.9605 - val_loss: 0.4860 - val_accuracy: 0.8834\n",
      "Epoch 61/100\n",
      "380/380 [==============================] - 0s 102us/step - loss: 0.1223 - accuracy: 0.9579 - val_loss: 0.3992 - val_accuracy: 0.8834\n",
      "Epoch 62/100\n",
      "380/380 [==============================] - 0s 98us/step - loss: 0.1296 - accuracy: 0.9447 - val_loss: 0.7582 - val_accuracy: 0.8834\n",
      "Epoch 63/100\n",
      "380/380 [==============================] - 0s 97us/step - loss: 0.1416 - accuracy: 0.9500 - val_loss: 0.4983 - val_accuracy: 0.9080\n",
      "Epoch 64/100\n",
      "380/380 [==============================] - 0s 99us/step - loss: 0.1291 - accuracy: 0.9553 - val_loss: 0.4929 - val_accuracy: 0.8957\n",
      "Epoch 65/100\n",
      "380/380 [==============================] - 0s 97us/step - loss: 0.1284 - accuracy: 0.9605 - val_loss: 0.4606 - val_accuracy: 0.8712\n",
      "Epoch 66/100\n",
      "380/380 [==============================] - 0s 94us/step - loss: 0.1160 - accuracy: 0.9579 - val_loss: 0.4207 - val_accuracy: 0.9018\n",
      "Epoch 67/100\n",
      "380/380 [==============================] - 0s 94us/step - loss: 0.1262 - accuracy: 0.9553 - val_loss: 0.4422 - val_accuracy: 0.8589\n",
      "Epoch 68/100\n",
      "380/380 [==============================] - 0s 87us/step - loss: 0.1285 - accuracy: 0.9553 - val_loss: 0.4848 - val_accuracy: 0.9018\n",
      "Epoch 69/100\n",
      "380/380 [==============================] - 0s 89us/step - loss: 0.1147 - accuracy: 0.9605 - val_loss: 0.4186 - val_accuracy: 0.8834\n",
      "Epoch 70/100\n",
      "380/380 [==============================] - 0s 83us/step - loss: 0.1122 - accuracy: 0.9632 - val_loss: 0.4755 - val_accuracy: 0.9018\n",
      "Epoch 71/100\n",
      "380/380 [==============================] - 0s 92us/step - loss: 0.1156 - accuracy: 0.9632 - val_loss: 0.4734 - val_accuracy: 0.8773\n",
      "Epoch 72/100\n",
      "380/380 [==============================] - 0s 100us/step - loss: 0.1096 - accuracy: 0.9658 - val_loss: 0.4331 - val_accuracy: 0.9080\n",
      "Epoch 73/100\n",
      "380/380 [==============================] - 0s 122us/step - loss: 0.1089 - accuracy: 0.9684 - val_loss: 0.4627 - val_accuracy: 0.9080\n",
      "Epoch 74/100\n",
      "380/380 [==============================] - 0s 102us/step - loss: 0.1084 - accuracy: 0.9711 - val_loss: 0.4529 - val_accuracy: 0.9018\n",
      "Epoch 75/100\n",
      "380/380 [==============================] - 0s 95us/step - loss: 0.1091 - accuracy: 0.9684 - val_loss: 0.4426 - val_accuracy: 0.9080\n",
      "Epoch 76/100\n",
      "380/380 [==============================] - 0s 87us/step - loss: 0.1129 - accuracy: 0.9526 - val_loss: 0.4355 - val_accuracy: 0.9080\n",
      "Epoch 77/100\n",
      "380/380 [==============================] - 0s 92us/step - loss: 0.1060 - accuracy: 0.9737 - val_loss: 0.4391 - val_accuracy: 0.8773\n",
      "Epoch 78/100\n",
      "380/380 [==============================] - 0s 99us/step - loss: 0.1154 - accuracy: 0.9526 - val_loss: 0.4838 - val_accuracy: 0.8957\n",
      "Epoch 79/100\n",
      "380/380 [==============================] - 0s 87us/step - loss: 0.1091 - accuracy: 0.9684 - val_loss: 0.4163 - val_accuracy: 0.9080\n",
      "Epoch 80/100\n",
      "380/380 [==============================] - 0s 85us/step - loss: 0.1063 - accuracy: 0.9579 - val_loss: 0.4849 - val_accuracy: 0.9018\n",
      "Epoch 81/100\n",
      "380/380 [==============================] - 0s 87us/step - loss: 0.1148 - accuracy: 0.9711 - val_loss: 0.4220 - val_accuracy: 0.9080\n",
      "Epoch 82/100\n",
      "380/380 [==============================] - 0s 92us/step - loss: 0.1040 - accuracy: 0.9711 - val_loss: 0.5513 - val_accuracy: 0.8896\n",
      "Epoch 83/100\n",
      "380/380 [==============================] - 0s 119us/step - loss: 0.1017 - accuracy: 0.9684 - val_loss: 0.4491 - val_accuracy: 0.8834\n",
      "Epoch 84/100\n",
      "380/380 [==============================] - 0s 169us/step - loss: 0.1061 - accuracy: 0.9632 - val_loss: 0.5253 - val_accuracy: 0.8712\n",
      "Epoch 85/100\n",
      "380/380 [==============================] - 0s 124us/step - loss: 0.1334 - accuracy: 0.9421 - val_loss: 0.4772 - val_accuracy: 0.8650\n",
      "Epoch 86/100\n",
      "380/380 [==============================] - 0s 117us/step - loss: 0.1286 - accuracy: 0.9474 - val_loss: 0.4979 - val_accuracy: 0.8650\n",
      "Epoch 87/100\n",
      "380/380 [==============================] - 0s 113us/step - loss: 0.1332 - accuracy: 0.9474 - val_loss: 0.5470 - val_accuracy: 0.8712\n",
      "Epoch 88/100\n",
      "380/380 [==============================] - 0s 114us/step - loss: 0.1459 - accuracy: 0.9447 - val_loss: 0.6260 - val_accuracy: 0.8957\n",
      "Epoch 89/100\n",
      "380/380 [==============================] - 0s 106us/step - loss: 0.1245 - accuracy: 0.9605 - val_loss: 0.5164 - val_accuracy: 0.9080\n",
      "Epoch 90/100\n",
      "380/380 [==============================] - 0s 118us/step - loss: 0.1121 - accuracy: 0.9684 - val_loss: 0.5054 - val_accuracy: 0.8712\n",
      "Epoch 91/100\n",
      "380/380 [==============================] - 0s 125us/step - loss: 0.1069 - accuracy: 0.9579 - val_loss: 0.6196 - val_accuracy: 0.8896\n",
      "Epoch 92/100\n",
      "380/380 [==============================] - 0s 115us/step - loss: 0.1105 - accuracy: 0.9553 - val_loss: 0.5145 - val_accuracy: 0.8589\n",
      "Epoch 93/100\n",
      "380/380 [==============================] - 0s 183us/step - loss: 0.1257 - accuracy: 0.9500 - val_loss: 0.5556 - val_accuracy: 0.8834\n",
      "Epoch 94/100\n",
      "380/380 [==============================] - 0s 167us/step - loss: 0.1226 - accuracy: 0.9526 - val_loss: 0.5343 - val_accuracy: 0.8957\n",
      "Epoch 95/100\n",
      "380/380 [==============================] - 0s 131us/step - loss: 0.1345 - accuracy: 0.9553 - val_loss: 0.4900 - val_accuracy: 0.8773\n",
      "Epoch 96/100\n",
      "380/380 [==============================] - 0s 116us/step - loss: 0.1140 - accuracy: 0.9553 - val_loss: 0.6547 - val_accuracy: 0.8834\n",
      "Epoch 97/100\n",
      "380/380 [==============================] - 0s 114us/step - loss: 0.1200 - accuracy: 0.9579 - val_loss: 0.4999 - val_accuracy: 0.8834\n",
      "Epoch 98/100\n",
      "380/380 [==============================] - 0s 106us/step - loss: 0.1034 - accuracy: 0.9632 - val_loss: 0.4643 - val_accuracy: 0.9141\n",
      "Epoch 99/100\n",
      "380/380 [==============================] - 0s 128us/step - loss: 0.0966 - accuracy: 0.9658 - val_loss: 0.5407 - val_accuracy: 0.9080\n",
      "Epoch 100/100\n",
      "380/380 [==============================] - 0s 139us/step - loss: 0.0978 - accuracy: 0.9737 - val_loss: 0.5495 - val_accuracy: 0.8896\n"
     ]
    }
   ],
   "source": [
    "hist1_over4 = model1_over4.fit(X_train_over, y_train_over,\n",
    "          batch_size=64, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 94.96%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over4.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba4 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_2.xlsx\",\n",
    "                        sheet_name=3,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS110</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>5.870196e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS216</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.039254</td>\n",
       "      <td>0.960745</td>\n",
       "      <td>9.078969e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS386</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.326752</td>\n",
       "      <td>0.673248</td>\n",
       "      <td>1.061032e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>CFBRSa25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.611084</td>\n",
       "      <td>0.388916</td>\n",
       "      <td>7.664974e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>BCH-SA-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.611084</td>\n",
       "      <td>0.388916</td>\n",
       "      <td>7.664974e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4279</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS236</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.999768</td>\n",
       "      <td>1.803156e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4280</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS029</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.322350</td>\n",
       "      <td>0.677496</td>\n",
       "      <td>1.533154e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4281</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>9.999682e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4282</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>CFBRSa28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999288</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>5.361527e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4283</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS205</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>9.999868e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4284 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    phage     strain  phenotype  prediction         0  \\\n",
       "0      p002ykpresabs_qual     NRS110          1           1  0.000003   \n",
       "1      p002ykpresabs_qual     NRS216          1           1  0.039254   \n",
       "2      p002ykpresabs_qual     NRS386          1           1  0.326752   \n",
       "3      p002ykpresabs_qual   CFBRSa25          0           0  0.611084   \n",
       "4      p002ykpresabs_qual  BCH-SA-03          1           0  0.611084   \n",
       "...                   ...        ...        ...         ...       ...   \n",
       "4279  pyopresabsSTCC_qual     NRS236          1           1  0.000052   \n",
       "4280  pyopresabsSTCC_qual     NRS029          0           1  0.322350   \n",
       "4281  pyopresabsSTCC_qual     NRS148          2           2  0.000006   \n",
       "4282  pyopresabsSTCC_qual   CFBRSa28          0           0  0.999288   \n",
       "4283  pyopresabsSTCC_qual     NRS205          2           2  0.000007   \n",
       "\n",
       "             1             2  \n",
       "0     0.999997  5.870196e-13  \n",
       "1     0.960745  9.078969e-07  \n",
       "2     0.673248  1.061032e-07  \n",
       "3     0.388916  7.664974e-07  \n",
       "4     0.388916  7.664974e-07  \n",
       "...        ...           ...  \n",
       "4279  0.999768  1.803156e-04  \n",
       "4280  0.677496  1.533154e-04  \n",
       "4281  0.000026  9.999682e-01  \n",
       "4282  0.000176  5.361527e-04  \n",
       "4283  0.000007  9.999868e-01  \n",
       "\n",
       "[4284 rows x 7 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.83096380e-02, 2.66584280e-01, 7.05106140e-01],\n",
       "       [9.98136500e-01, 1.29698850e-04, 1.73373710e-03],\n",
       "       [9.96180800e-01, 8.66016140e-04, 2.95317940e-03],\n",
       "       [9.99984150e-01, 1.45838620e-05, 1.30405950e-06],\n",
       "       [9.99984150e-01, 1.45838620e-05, 1.30405950e-06],\n",
       "       [2.38913190e-02, 9.45177800e-01, 3.09309740e-02],\n",
       "       [8.25692000e-01, 1.57026050e-01, 1.72819480e-02],\n",
       "       [3.62487980e-03, 5.95922000e-03, 9.90415930e-01],\n",
       "       [9.20543550e-01, 5.36754130e-02, 2.57810260e-02],\n",
       "       [9.97803750e-01, 2.49861480e-04, 1.94638180e-03],\n",
       "       [1.12001800e-01, 8.10517670e-01, 7.74806100e-02],\n",
       "       [4.17404680e-01, 3.62671550e-01, 2.19923700e-01],\n",
       "       [1.47601500e-01, 3.97865150e-01, 4.54533370e-01],\n",
       "       [9.20543550e-01, 5.36754130e-02, 2.57810260e-02],\n",
       "       [9.98682700e-03, 4.00817500e-02, 9.49931440e-01],\n",
       "       [9.42491700e-01, 1.40537550e-03, 5.61030060e-02],\n",
       "       [9.20543550e-01, 5.36754130e-02, 2.57810260e-02],\n",
       "       [9.99516100e-01, 3.55040800e-04, 1.28821820e-04],\n",
       "       [1.38383820e-02, 3.58388700e-01, 6.27773000e-01],\n",
       "       [9.99984150e-01, 1.45838620e-05, 1.30405950e-06],\n",
       "       [1.47098650e-02, 1.61437240e-01, 8.23852840e-01],\n",
       "       [9.70687050e-02, 2.79670480e-01, 6.23260800e-01],\n",
       "       [9.97803750e-01, 2.49861480e-04, 1.94638180e-03],\n",
       "       [1.12134040e-09, 9.99100800e-01, 8.99273400e-04],\n",
       "       [1.00309476e-01, 8.91806660e-01, 7.88388200e-03],\n",
       "       [8.45462840e-04, 1.71851900e-01, 8.27302630e-01],\n",
       "       [3.11434980e-01, 5.93744900e-01, 9.48201500e-02],\n",
       "       [9.97803750e-01, 2.49861480e-04, 1.94638180e-03],\n",
       "       [4.15558160e-01, 6.92014070e-03, 5.77521600e-01],\n",
       "       [8.25692000e-01, 1.57026050e-01, 1.72819480e-02],\n",
       "       [9.99760100e-01, 1.35393740e-04, 1.04519560e-04],\n",
       "       [7.16351500e-04, 2.47185100e-02, 9.74565100e-01],\n",
       "       [2.49587240e-02, 6.17525460e-01, 3.57515800e-01],\n",
       "       [1.18091990e-01, 7.57034960e-01, 1.24873130e-01],\n",
       "       [1.72633570e-01, 4.68954930e-02, 7.80470970e-01],\n",
       "       [4.17404680e-01, 3.62671550e-01, 2.19923700e-01],\n",
       "       [9.91446850e-01, 2.96555000e-04, 8.25666900e-03],\n",
       "       [2.11481200e-02, 1.62929270e-01, 8.15922600e-01],\n",
       "       [9.98136500e-01, 1.29698850e-04, 1.73373710e-03],\n",
       "       [9.99172600e-01, 5.08983970e-04, 3.18332000e-04],\n",
       "       [9.42491700e-01, 1.40537550e-03, 5.61030060e-02],\n",
       "       [2.23369150e-03, 9.80447400e-01, 1.73189000e-02],\n",
       "       [1.10783540e-03, 9.92739740e-01, 6.15242900e-03],\n",
       "       [3.09077650e-03, 9.88720360e-01, 8.18890300e-03],\n",
       "       [3.45449520e-02, 8.00976000e-01, 1.64479030e-01],\n",
       "       [2.19318380e-02, 9.69940360e-01, 8.12775700e-03],\n",
       "       [5.56897330e-02, 4.31699750e-01, 5.12610550e-01],\n",
       "       [9.96180800e-01, 8.66016140e-04, 2.95317940e-03],\n",
       "       [9.99172600e-01, 5.08983970e-04, 3.18332000e-04],\n",
       "       [9.91446850e-01, 2.96555000e-04, 8.25666900e-03],\n",
       "       [2.60224900e-03, 9.94917500e-01, 2.48025260e-03],\n",
       "       [1.71378250e-06, 9.99998200e-01, 6.73892000e-08],\n",
       "       [2.19318380e-02, 9.69940360e-01, 8.12775700e-03],\n",
       "       [1.02720700e-01, 5.55344600e-01, 3.41934650e-01],\n",
       "       [9.54011400e-03, 1.80826130e-02, 9.72377240e-01],\n",
       "       [8.05044900e-04, 9.94073700e-01, 5.12137300e-03],\n",
       "       [2.22741940e-02, 9.64932600e-01, 1.27931220e-02],\n",
       "       [1.03427160e-03, 9.83226700e-01, 1.57390160e-02],\n",
       "       [1.32316770e-03, 9.61323740e-01, 3.73531020e-02],\n",
       "       [9.97803750e-01, 2.49861480e-04, 1.94638180e-03],\n",
       "       [1.18758520e-01, 5.79790500e-01, 3.01451060e-01],\n",
       "       [7.55180400e-04, 9.96980370e-01, 2.26438880e-03],\n",
       "       [9.99172600e-01, 5.08983970e-04, 3.18332000e-04],\n",
       "       [3.95782100e-02, 6.02943600e-01, 3.57478230e-01],\n",
       "       [6.67090800e-02, 6.58270360e-01, 2.75020540e-01],\n",
       "       [1.06542440e-02, 7.91479100e-01, 1.97866590e-01],\n",
       "       [1.18758520e-01, 5.79790500e-01, 3.01451060e-01],\n",
       "       [9.99516100e-01, 3.55040800e-04, 1.28821820e-04],\n",
       "       [4.88332620e-02, 2.55151360e-01, 6.96015360e-01],\n",
       "       [8.77341300e-01, 3.17753000e-02, 9.08834860e-02],\n",
       "       [9.99984150e-01, 1.45838620e-05, 1.30405950e-06],\n",
       "       [2.23369150e-03, 9.80447400e-01, 1.73189000e-02],\n",
       "       [8.01166100e-01, 4.39855150e-04, 1.98394030e-01],\n",
       "       [9.84909360e-01, 1.20924810e-02, 2.99819560e-03],\n",
       "       [4.63687300e-01, 4.85996450e-01, 5.03162480e-02],\n",
       "       [4.46924750e-02, 2.01815560e-01, 7.53492000e-01],\n",
       "       [4.35688670e-11, 9.99999760e-01, 2.22053800e-07],\n",
       "       [1.06542440e-02, 7.91479100e-01, 1.97866590e-01],\n",
       "       [9.41025900e-01, 5.88834320e-02, 9.05945340e-05],\n",
       "       [2.96428960e-03, 7.61627700e-02, 9.20872900e-01],\n",
       "       [9.84909360e-01, 1.20924810e-02, 2.99819560e-03],\n",
       "       [8.01166100e-01, 4.39855150e-04, 1.98394030e-01],\n",
       "       [3.19332000e-04, 7.09275500e-04, 9.98971460e-01],\n",
       "       [2.60224900e-03, 9.94917500e-01, 2.48025260e-03],\n",
       "       [5.14370600e-01, 4.36578320e-04, 4.85192780e-01],\n",
       "       [1.02720700e-01, 5.55344600e-01, 3.41934650e-01],\n",
       "       [4.17404680e-01, 3.62671550e-01, 2.19923700e-01],\n",
       "       [1.13441960e-03, 2.64069000e-01, 7.34796640e-01],\n",
       "       [9.96857640e-01, 2.43987420e-03, 7.02373200e-04],\n",
       "       [4.17404680e-01, 3.62671550e-01, 2.19923700e-01],\n",
       "       [9.92951330e-01, 1.83908790e-03, 5.20957350e-03],\n",
       "       [1.03427160e-03, 9.83226700e-01, 1.57390160e-02],\n",
       "       [2.90415590e-01, 4.25149770e-01, 2.84434650e-01],\n",
       "       [9.96241700e-03, 2.05489360e-02, 9.69488600e-01],\n",
       "       [1.12001800e-01, 8.10517670e-01, 7.74806100e-02],\n",
       "       [2.23369150e-03, 9.80447400e-01, 1.73189000e-02],\n",
       "       [9.96857640e-01, 2.43987420e-03, 7.02373200e-04],\n",
       "       [1.18091990e-01, 7.57034960e-01, 1.24873130e-01],\n",
       "       [2.32071330e-01, 5.82796100e-01, 1.85132610e-01],\n",
       "       [1.02720700e-01, 5.55344600e-01, 3.41934650e-01],\n",
       "       [9.32227250e-01, 8.68692600e-03, 5.90857750e-02],\n",
       "       [4.17404680e-01, 3.62671550e-01, 2.19923700e-01],\n",
       "       [5.12368930e-03, 1.62188800e-02, 9.78657400e-01],\n",
       "       [1.12001800e-01, 8.10517670e-01, 7.74806100e-02],\n",
       "       [2.82033900e-02, 2.19344970e-01, 7.52451660e-01],\n",
       "       [1.03179040e-02, 2.79567520e-02, 9.61725350e-01],\n",
       "       [2.90415590e-01, 4.25149770e-01, 2.84434650e-01],\n",
       "       [4.32082130e-03, 1.36236430e-02, 9.82055500e-01],\n",
       "       [1.12001800e-01, 8.10517670e-01, 7.74806100e-02],\n",
       "       [9.99927900e-01, 1.82847700e-08, 7.21070400e-05],\n",
       "       [9.13410860e-02, 3.97431630e-02, 8.68915740e-01],\n",
       "       [9.97803750e-01, 2.49861480e-04, 1.94638180e-03],\n",
       "       [3.09077650e-03, 9.88720360e-01, 8.18890300e-03],\n",
       "       [1.49586920e-02, 9.70081600e-01, 1.49597125e-02],\n",
       "       [9.42491700e-01, 1.40537550e-03, 5.61030060e-02],\n",
       "       [7.20251600e-01, 4.22013700e-02, 2.37546950e-01],\n",
       "       [9.99172600e-01, 5.08983970e-04, 3.18332000e-04],\n",
       "       [2.18358520e-02, 9.60524260e-01, 1.76399030e-02],\n",
       "       [5.93100100e-04, 2.06166240e-01, 7.93240670e-01],\n",
       "       [1.50247480e-04, 9.99126500e-01, 7.23271800e-04],\n",
       "       [4.11845040e-02, 9.37508760e-01, 2.13067660e-02],\n",
       "       [2.09128280e-04, 9.23621060e-02, 9.07428740e-01],\n",
       "       [1.41783430e-03, 2.39486380e-02, 9.74633460e-01],\n",
       "       [6.91037300e-04, 1.73403250e-02, 9.81968700e-01],\n",
       "       [1.12001800e-01, 8.10517670e-01, 7.74806100e-02],\n",
       "       [5.44077830e-04, 9.93162400e-01, 6.29363950e-03],\n",
       "       [7.16170150e-02, 3.51314930e-01, 5.77068030e-01],\n",
       "       [3.09077650e-03, 9.88720360e-01, 8.18890300e-03],\n",
       "       [9.17298900e-03, 1.68644790e-01, 8.22182240e-01],\n",
       "       [9.97803750e-01, 2.49861480e-04, 1.94638180e-03],\n",
       "       [1.02720700e-01, 5.55344600e-01, 3.41934650e-01],\n",
       "       [5.94772160e-01, 4.05003760e-01, 2.24067250e-04],\n",
       "       [3.32827500e-02, 9.05455230e-01, 6.12620300e-02],\n",
       "       [3.09077650e-03, 9.88720360e-01, 8.18890300e-03],\n",
       "       [9.94022500e-02, 2.42682930e-01, 6.57914800e-01],\n",
       "       [1.03427160e-03, 9.83226700e-01, 1.57390160e-02],\n",
       "       [9.32227250e-01, 8.68692600e-03, 5.90857750e-02],\n",
       "       [1.23841110e-02, 1.32104550e-02, 9.74405470e-01],\n",
       "       [1.23508265e-02, 9.80217100e-01, 7.43204700e-03],\n",
       "       [1.02222780e-02, 9.68461160e-01, 2.13166270e-02],\n",
       "       [9.90647500e-01, 3.80576240e-03, 5.54677800e-03],\n",
       "       [9.24606400e-01, 1.96622220e-03, 7.34273200e-02],\n",
       "       [1.44108380e-03, 2.18929030e-02, 9.76666030e-01],\n",
       "       [9.99927900e-01, 1.82847700e-08, 7.21070400e-05],\n",
       "       [7.71184340e-02, 3.93601330e-01, 5.29280250e-01],\n",
       "       [5.14920530e-01, 3.49573380e-04, 4.84729900e-01],\n",
       "       [4.63687300e-01, 4.85996450e-01, 5.03162480e-02],\n",
       "       [1.45399390e-02, 9.46439700e-01, 3.90204340e-02],\n",
       "       [4.35688670e-11, 9.99999760e-01, 2.22053800e-07],\n",
       "       [9.93704400e-01, 7.63239100e-04, 5.53239300e-03],\n",
       "       [9.99172600e-01, 5.08983970e-04, 3.18332000e-04],\n",
       "       [6.81053240e-03, 9.83763000e-01, 9.42646900e-03],\n",
       "       [5.90638440e-02, 4.41642970e-01, 4.99293150e-01],\n",
       "       [4.56853900e-02, 4.89084420e-01, 4.65230200e-01],\n",
       "       [2.49587240e-02, 6.17525460e-01, 3.57515800e-01],\n",
       "       [1.01202860e-09, 9.99514100e-01, 4.85910450e-04],\n",
       "       [4.35688670e-11, 9.99999760e-01, 2.22053800e-07],\n",
       "       [1.71378250e-06, 9.99998200e-01, 6.73892000e-08],\n",
       "       [1.58323330e-02, 9.63925400e-01, 2.02421790e-02],\n",
       "       [1.47021960e-03, 9.96409830e-01, 2.11987600e-03],\n",
       "       [2.23369150e-03, 9.80447400e-01, 1.73189000e-02],\n",
       "       [2.60224900e-03, 9.94917500e-01, 2.48025260e-03],\n",
       "       [1.27619480e-03, 2.77916130e-05, 9.98696000e-01]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob4 = df_proba4[df_proba4['phage']=='p11kpresabsSTCC_qual'].iloc[:,-3:]\n",
    "y_prob4 = y_prob4.to_numpy()\n",
    "y_prob4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9406575953212037"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo4 = rocauc_ovo(y_test_over, y_prob4, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9406575953212037"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr4 = rocauc_ovr(y_test_over, y_prob4, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9469236838311761"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovos = [ovo1, ovo2, ovo3, ovo4]\n",
    "np.mean(ovos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.009146555483889455"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(ovos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9469236838311761"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovrs = [ovr1, ovr2, ovr3, ovr4]\n",
    "np.mean(ovrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.009146555483889455"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(ovrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs = [acc_test_over, acc_test_over2, acc_test_over3, acc_test_over4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling test accuracy mean: 84.82%\n"
     ]
    }
   ],
   "source": [
    "mean = np.mean(accs)\n",
    "print('over-sampling test accuracy mean: %.2f%%' % (mean*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling test accuracy standard deviation: 0.015260545241225637\n"
     ]
    }
   ],
   "source": [
    "std = np.std(accs)\n",
    "print('over-sampling test accuracy standard deviation:', std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs_train = [np.mean(hist1_over.history['accuracy']), np.mean(hist1_over2.history['accuracy']), np.mean(hist1_over3.history['accuracy']),\n",
    "             np.mean(hist1_over4.history['accuracy'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy mean: 93.33%\n"
     ]
    }
   ],
   "source": [
    "mean_train = np.mean(accs_train)\n",
    "print('over-sampling train accuracy mean: %.2f%%' % (mean_train*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy standard deviation: 0.011173564\n"
     ]
    }
   ],
   "source": [
    "std_train = np.std(accs_train)\n",
    "print('over-sampling train accuracy standard deviation:', std_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ Feature selection using lasso ##########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Retrieved from https://towardsdatascience.com/feature-selection-using-regularisation-a3678b71e499\n",
    "from sklearn.linear_model import Lasso, LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectFromModel(estimator=LogisticRegression(C=1, class_weight=None, dual=False,\n",
       "                                             fit_intercept=True,\n",
       "                                             intercept_scaling=1, l1_ratio=None,\n",
       "                                             max_iter=100, multi_class='auto',\n",
       "                                             n_jobs=None, penalty='l1',\n",
       "                                             random_state=None,\n",
       "                                             solver='liblinear', tol=0.0001,\n",
       "                                             verbose=0, warm_start=False),\n",
       "                max_features=None, norm_order=1, prefit=False, threshold=None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selection = SelectFromModel(LogisticRegression(C=1, penalty='l1', solver='liblinear'))\n",
    "selection.fit(X_over[:,1:], y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = np.array(df_clean.columns).tolist()\n",
    "names.remove('pheno')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_features_over = np.vstack((names, X_over[:,1:]))\n",
    "X_train_features_over = pd.DataFrame(X_train_features_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total features: 822\n",
      "selected features: 184\n"
     ]
    }
   ],
   "source": [
    "sel_features = X_train_features_over.columns[(selection.get_support())]\n",
    "print('total features: {}'.format((X_train_features_over.shape[1])))\n",
    "print('selected features: {}'.format(len(sel_features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   1,   3,   4,  12,  13,  14,  20,  21,  27,  29,  36,  39,\n",
       "         74,  75,  87,  94, 100, 101, 102, 104, 116, 125, 135, 138, 140,\n",
       "        146, 156, 161, 164, 166, 168, 177, 194, 196, 198, 199, 202, 204,\n",
       "        206, 208, 213, 220, 229, 231, 232, 233, 241, 242, 243, 250, 265,\n",
       "        266, 270, 277, 280, 288, 296, 303, 307, 308, 310, 316, 318, 319,\n",
       "        323, 325, 334, 338, 344, 345, 352, 357, 359, 363, 367, 369, 374,\n",
       "        380, 386, 389, 390, 395, 396, 399, 410, 417, 428, 433, 442, 444,\n",
       "        445, 447, 455, 457, 463, 466, 467, 468, 470, 471, 476, 477, 481,\n",
       "        488, 490, 497, 503, 506, 515, 517, 518, 519, 521, 534, 538, 541,\n",
       "        544, 549, 553, 558, 559, 560, 561, 562, 563, 564, 571, 572, 573,\n",
       "        581, 585, 586, 588, 589, 593, 597, 602, 603, 604, 605, 606, 608,\n",
       "        614, 617, 619, 628, 634, 639, 651, 652, 670, 673, 677, 678, 685,\n",
       "        702, 703, 704, 712, 713, 716, 722, 737, 738, 742, 746, 750, 751,\n",
       "        757, 759, 766, 768, 772, 779, 781, 784, 788, 798, 804, 806, 818,\n",
       "        820, 821]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = sel_features.values\n",
    "cols.reshape((1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['TTTTTTGTAATTTT', 'TTTTTTGTAATTTTT', 'TTTTTTATTTTGGATAA',\n",
       "       'TTTTTTATTTTGGATAAAAGGAG', 'TTTTCTTTTCGT', 'TTTTCTTCTAATC',\n",
       "       'TTTTCTATTGTC', 'TTTTATGGAAGGTAATTTTAAAAATGTAAAGAAGCTTAT',\n",
       "       'TTTTATGGAAGGTAATTTTAAAAATGTAAAGAAGCTTATTTACGAAG',\n",
       "       'TTTTAATAGCTAGCACTTAATTGTGTTGGCTATTTTTTATGTCCAAAACGTGCTGATGACATAAAAAGCACGCATGGAAAAACAGTCGACAGACTATAAA',\n",
       "       'TTTGCCAGTATC', 'TTTCGCAAACTA', 'TTTCAGCGACT', 'TTGGTTTTAAATTT',\n",
       "       'TTGGTTTTAAATTTTT', 'TTGATAAAGTTTA', 'TTCTTTACATTTTTA',\n",
       "       'TTCTCTTCCATC', 'TTCTCTTCCATCCCTCATC', 'TTCTCTTCCATCCCTCATCCTCCTC',\n",
       "       'TTCTATAAAAAGT', 'TTCATCGTCGA', 'TTCAATCTAGAT', 'TTATTAGGTTCAAC',\n",
       "       'TTATCATCAAATG',\n",
       "       'TTATAGTCTGTCGACTGTTTTTCCATGCGTGCTTTTTATGTCATCAGCACGTTTTGGACATAAAAAATAGCCAACACAATTAAGTGCTAGCTATTAAAAG',\n",
       "       'TTAGGCGAAGAT', 'TTACGCAATAGTTTAGATGTAGA', 'TTACCTAAAAATAAAT',\n",
       "       'TTAATTGAATAACGGGAAGTAGCTCAGCTTGGTAGAGCACTTGGTTTGGGACCAAGGGGTCGCAGGTTCGAATCCTGTCTTCCCGATTACTTCTTAAATT',\n",
       "       'TTAACGAATAC', 'TTAAATTTTGCAGT', 'TGTTTATGGAAG', 'TGTCTAAATTGTT',\n",
       "       'TGTCCTTTGTT', 'TGTCCAAAACGTG', 'TGTCCAAAACGTGCTGA', 'TGTAGCTGGAT',\n",
       "       'TGTACAAAATAAAAGA', 'TGGTTTTAAATTTT', 'TGGCGATTGTC',\n",
       "       'TGGAATGGGAGCA', 'TGCTCCCATTCC', 'TGCAAAATCG', 'TGATTTTTATCTGC',\n",
       "       'TGATTTGATGAGG', 'TGATTTGATGAGGGCGGAGGTG', 'TGATAACAATGTGCCT',\n",
       "       'TGATAACAATGTGCCTA', 'TGATAACAATGTGCCTAT', 'TGACTTTAAG',\n",
       "       'TCTTTTATTTTGT',\n",
       "       'TCTTTTAATAGCTAGCACTTAATTGTGTTGGCTATTTTTTATGTCCAAAACGTGCTGATGACATAAAAAGCACGCATGGAAAAACAGTCGACAGACTATA',\n",
       "       'TCTTCCATAAAC', 'TCTGTACTAAC', 'TCTGATTTTTTTG', 'TCTACTTCTTAAT',\n",
       "       'TCGTGTCTGT', 'TCGCCGTTATG', 'TCGAAAGAGT', 'TCCTTGCCTTA',\n",
       "       'TCCTCCTCATATTTATAGAC', 'TCCAGTGCTTG', 'TCCAAAGTATTT',\n",
       "       'TCCAAAGTATTTT', 'TCATCAAACTTT', 'TCAGTCTGAT', 'TCACTATAAGTG',\n",
       "       'TCACACCGCCT', 'TCAAAAGTTAATA', 'TCAAAAAGATGAAT', 'TATTGACTCCT',\n",
       "       'TATTAAATTTAAAG', 'TATCTTCGCCTA', 'TATCCAGAATG', 'TATAGTGTTCAT',\n",
       "       'TATAGGAGCC', 'TAGTTTAGATGT', 'TAGGGATTATG', 'TAGCTAAATCC',\n",
       "       'TAGATTCAAATAT', 'TAGAGTCGTTG', 'TACTTGCCTAAAT', 'TACTAGTCATC',\n",
       "       'TACGCCAGTTT', 'TACAGCTTTCT', 'TAATCTTGTTGTT', 'TAACTAAATTCGT',\n",
       "       'TAAATTAATAGGTG', 'TAAACTATTGCG', 'TAAAAGGTATCT', 'TAAAAGATCCAG',\n",
       "       'TAAAAAAGCGAT', 'GTTTATGGAAG', 'GTTTAAAATTATTC', 'GTTCAACTCC',\n",
       "       'GTTACAAACAACAT', 'GTTAATACTGGC',\n",
       "       'GTTAAACTACAAAAACAAAAGTTAACTAAAGATAT', 'GTGTTCATCGT',\n",
       "       'GTGTATTTTAAG', 'GTGAATTCATG', 'GTCTGATTTTTT', 'GTCGCAAATATTTC',\n",
       "       'GTATTGCAACAGATTGGCTCAAAAGTTAGT', 'GTAGCTGGATT',\n",
       "       'GTAATTTTAAAAATGTAAAGAAG', 'GTAATAGGCAT', 'GGTTTTAAATTTTT',\n",
       "       'GGTAACGGTTTAACACGTCC', 'GGTAAAAACGGT', 'GGGGTGATTTT',\n",
       "       'GGGGCTCATTTT', 'GGGCTCATTT',\n",
       "       'GGAGTTGAACCTAATAAAAGTTATCAGGTGACAATAGAAAATGTACGTAGCGGTATAATGAGG',\n",
       "       'GGACGTGTTAAACCG', 'GCTTGACTGT', 'GCTCTGTGTT', 'GCTATAGGAG',\n",
       "       'GCGGAGTTGC', 'GCCAAGTAGT', 'GCATTACACCT', 'GCAGTAGGGATT',\n",
       "       'GCAGTAGGGATTATG', 'GCACGACGTC', 'GCACGACGTCTT', 'GCAACTCCGCT',\n",
       "       'GATTTCCCGT',\n",
       "       'GATTGAAGGATTAGAAAATGCTTTATCAAAAAAATCAGACATAAATCACAGTCATGATGAACGTTAT',\n",
       "       'GATTCGAAATATT', 'GATACGTTAGATG', 'GAGGGGGACGTTTAAAT',\n",
       "       'GAGGGATGGAAGAG', 'GAGGAGCAGG', 'GAGCGATCAG', 'GAGAAAGCTGTAG',\n",
       "       'GACACGTTAG', 'GAAGTCACTCG', 'GAAGGATTACTAAAG', 'GAAGGATTACTAAAGT',\n",
       "       'GAACTAGTTGAT', 'GAACGCTATTT', 'GAACAAGACATG', 'GAAAAAAGAAAATGAG',\n",
       "       'CTTTGCGAAGT', 'CTTGCCTAAAT', 'CTTCAATCTAGATAACATGTAATGATT',\n",
       "       'CTCTTTTAATAGCTAGCACTTAATTGTGTTGGCTATTTTTTATGTCCAAAACGTGCTGATGACATAAAAAGCACGCATGGAAAAACAGTCGACAGACTAT',\n",
       "       'CTCCGCTATTG', 'CTAATGTGGT', 'CTAATCCTTCAAT', 'CGCCTAACATG',\n",
       "       'CGACTAATTTTTT', 'CCTTGCATAGG', 'CCTTCGTAAAT', 'CCTGAAGGATT',\n",
       "       'CCAGTGCTTG', 'CCAGACATTGTT', 'CCAATATTCTTG', 'CATCTAACGTAT',\n",
       "       'CATCAAACTTTT', 'CAGTCTGATTT',\n",
       "       'CAGATTGAAGGATTAGAAAATGCTTTATCAAAAAAATCAGACATAAATCACAGTCATGATGAACGTTAT',\n",
       "       'ATTTATCCAACTTT', 'ATTGTATGACT', 'ATTAATAGGTGGT', 'ATGGCTACTGGT',\n",
       "       'ATGAAGATAGAGT', 'ATCGTCAGCACT', 'ATCATCTCCGT', 'ATCAATACAAGTT',\n",
       "       'ATAGGCACATT', 'ATAGCGGAGTT',\n",
       "       'ATAACGTTCATCATGACTGTGATTTATGTCTGATTTTTTTGATAAAGCATTT',\n",
       "       'AGGTGTAATGCT', 'AGGGGTGATT', 'AGGCTAACTT', 'AGCATCTACTTTT',\n",
       "       'ACTGCGTTAGT', 'ACTAAATTCGT', 'ACGCAATAGTT', 'AACCTAGAAAGTTT',\n",
       "       'ST', 'CC'], dtype='<U100')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names_arr = np.array(names)\n",
    "names_arr[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###### keep selected variables as a new dataframe\n",
    "df_sel = df_clean.loc[:,names_arr[cols]].copy()\n",
    "df_sel['pheno'] = df_clean['pheno']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_sel['strain'] = X.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TTTTTTGTAATTTT</th>\n",
       "      <th>TTTTTTGTAATTTTT</th>\n",
       "      <th>TTTTTTATTTTGGATAA</th>\n",
       "      <th>TTTTTTATTTTGGATAAAAGGAG</th>\n",
       "      <th>TTTTCTTTTCGT</th>\n",
       "      <th>TTTTCTTCTAATC</th>\n",
       "      <th>TTTTCTATTGTC</th>\n",
       "      <th>TTTTATGGAAGGTAATTTTAAAAATGTAAAGAAGCTTAT</th>\n",
       "      <th>TTTTATGGAAGGTAATTTTAAAAATGTAAAGAAGCTTATTTACGAAG</th>\n",
       "      <th>TTTTAATAGCTAGCACTTAATTGTGTTGGCTATTTTTTATGTCCAAAACGTGCTGATGACATAAAAAGCACGCATGGAAAAACAGTCGACAGACTATAAA</th>\n",
       "      <th>...</th>\n",
       "      <th>AGGCTAACTT</th>\n",
       "      <th>AGCATCTACTTTT</th>\n",
       "      <th>ACTGCGTTAGT</th>\n",
       "      <th>ACTAAATTCGT</th>\n",
       "      <th>ACGCAATAGTT</th>\n",
       "      <th>AACCTAGAAAGTTT</th>\n",
       "      <th>ST</th>\n",
       "      <th>CC</th>\n",
       "      <th>pheno</th>\n",
       "      <th>strain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>120335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>120337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>SR4152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3812</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>SR4153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>SR4155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>SR4156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3812</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>SR4187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>253 rows Ã— 186 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     TTTTTTGTAATTTT  TTTTTTGTAATTTTT  TTTTTTATTTTGGATAA  \\\n",
       "0                 0                0                  0   \n",
       "1                 1                1                  1   \n",
       "2                 1                1                  1   \n",
       "3                 1                1                  1   \n",
       "4                 1                1                  1   \n",
       "..              ...              ...                ...   \n",
       "248               1                1                  1   \n",
       "249               1                1                  1   \n",
       "250               1                1                  1   \n",
       "251               1                1                  1   \n",
       "252               1                1                  1   \n",
       "\n",
       "     TTTTTTATTTTGGATAAAAGGAG  TTTTCTTTTCGT  TTTTCTTCTAATC  TTTTCTATTGTC  \\\n",
       "0                          0             0              1             0   \n",
       "1                          1             1              1             1   \n",
       "2                          1             1              1             1   \n",
       "3                          1             1              1             1   \n",
       "4                          1             1              1             1   \n",
       "..                       ...           ...            ...           ...   \n",
       "248                        1             1              1             1   \n",
       "249                        1             1              1             1   \n",
       "250                        1             1              1             1   \n",
       "251                        1             1              1             1   \n",
       "252                        1             1              1             1   \n",
       "\n",
       "     TTTTATGGAAGGTAATTTTAAAAATGTAAAGAAGCTTAT  \\\n",
       "0                                          0   \n",
       "1                                          1   \n",
       "2                                          0   \n",
       "3                                          1   \n",
       "4                                          1   \n",
       "..                                       ...   \n",
       "248                                        1   \n",
       "249                                        1   \n",
       "250                                        1   \n",
       "251                                        0   \n",
       "252                                        1   \n",
       "\n",
       "     TTTTATGGAAGGTAATTTTAAAAATGTAAAGAAGCTTATTTACGAAG  \\\n",
       "0                                                  0   \n",
       "1                                                  1   \n",
       "2                                                  0   \n",
       "3                                                  1   \n",
       "4                                                  1   \n",
       "..                                               ...   \n",
       "248                                                1   \n",
       "249                                                1   \n",
       "250                                                1   \n",
       "251                                                0   \n",
       "252                                                1   \n",
       "\n",
       "     TTTTAATAGCTAGCACTTAATTGTGTTGGCTATTTTTTATGTCCAAAACGTGCTGATGACATAAAAAGCACGCATGGAAAAACAGTCGACAGACTATAAA  \\\n",
       "0                                                    0                                                      \n",
       "1                                                    1                                                      \n",
       "2                                                    1                                                      \n",
       "3                                                    1                                                      \n",
       "4                                                    1                                                      \n",
       "..                                                 ...                                                      \n",
       "248                                                  1                                                      \n",
       "249                                                  1                                                      \n",
       "250                                                  1                                                      \n",
       "251                                                  1                                                      \n",
       "252                                                  1                                                      \n",
       "\n",
       "     ...  AGGCTAACTT  AGCATCTACTTTT  ACTGCGTTAGT  ACTAAATTCGT  ACGCAATAGTT  \\\n",
       "0    ...           1              0            0            0            0   \n",
       "1    ...           1              1            1            1            1   \n",
       "2    ...           1              1            1            1            1   \n",
       "3    ...           1              1            1            1            1   \n",
       "4    ...           1              1            1            1            1   \n",
       "..   ...         ...            ...          ...          ...          ...   \n",
       "248  ...           1              1            1            1            1   \n",
       "249  ...           1              1            1            1            1   \n",
       "250  ...           1              1            1            1            1   \n",
       "251  ...           1              1            1            1            1   \n",
       "252  ...           1              1            1            1            1   \n",
       "\n",
       "     AACCTAGAAAGTTT    ST  CC  pheno  strain  \n",
       "0                 0     5   5      2     107  \n",
       "1                 1     8   8      1     109  \n",
       "2                 1     5   5      2     115  \n",
       "3                 1     5   5      2  120335  \n",
       "4                 1     5   5      2  120337  \n",
       "..              ...   ...  ..    ...     ...  \n",
       "248               1     5   5      2  SR4152  \n",
       "249               1  3812   5      1  SR4153  \n",
       "250               1     5   5      2  SR4155  \n",
       "251               1     5   5      2  SR4156  \n",
       "252               1  3812   5      2  SR4187  \n",
       "\n",
       "[253 rows x 186 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(253, 185) (253,) (253, 186)\n"
     ]
    }
   ],
   "source": [
    "X_sel = df_sel.loc[:, df_sel.columns != 'pheno']\n",
    "y_sel = df_sel['pheno']\n",
    "print(X_sel.shape, y_sel.shape, df_sel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    181\n",
       "1     47\n",
       "0     25\n",
       "Name: pheno, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sel['pheno'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 181), (1, 181), (2, 181)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# over-sampling\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "overS = RandomOverSampler(random_state=100)\n",
    "X_sel_over, y_sel_over = overS.fit_resample(X_sel, y_sel)\n",
    "print(sorted(Counter(y_sel_over).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_sel_train_over, X_sel_test_over, y_sel_train_over, y_sel_test_over = train_test_split(X_sel_over, y_sel_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=567,\n",
    "                                                    stratify=y_sel_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat5 = pd.DataFrame(X_sel_test_over[:,-1])\n",
    "dat5['test'] = y_sel_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CFBRSa49</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS108</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MN105</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CFBRSa03</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BCH-SA-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>NRS027</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>BCH-SA-04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>SR3585</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>504</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>NRS149</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0  test\n",
       "0     CFBRSa49     1\n",
       "1       NRS108     2\n",
       "2        MN105     2\n",
       "3     CFBRSa03     2\n",
       "4    BCH-SA-01     0\n",
       "..         ...   ...\n",
       "158     NRS027     0\n",
       "159  BCH-SA-04     0\n",
       "160     SR3585     2\n",
       "161        504     1\n",
       "162     NRS149     0\n",
       "\n",
       "[163 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sel_train_over = X_sel_train_over[:,:-1]\n",
    "X_sel_test_over = X_sel_test_over[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### neural network on over-sampling data\n",
    "model2_over = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_sel_train_over.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2_over.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 380 samples, validate on 163 samples\n",
      "Epoch 1/100\n",
      "380/380 [==============================] - 0s 477us/step - loss: 6.2248 - accuracy: 0.3289 - val_loss: 3.9021 - val_accuracy: 0.2883\n",
      "Epoch 2/100\n",
      "380/380 [==============================] - 0s 145us/step - loss: 2.5363 - accuracy: 0.3605 - val_loss: 2.1034 - val_accuracy: 0.4110\n",
      "Epoch 3/100\n",
      "380/380 [==============================] - 0s 140us/step - loss: 1.7217 - accuracy: 0.4263 - val_loss: 1.5357 - val_accuracy: 0.4601\n",
      "Epoch 4/100\n",
      "380/380 [==============================] - 0s 115us/step - loss: 1.2731 - accuracy: 0.4579 - val_loss: 1.3855 - val_accuracy: 0.4969\n",
      "Epoch 5/100\n",
      "380/380 [==============================] - 0s 114us/step - loss: 1.1457 - accuracy: 0.5447 - val_loss: 1.3778 - val_accuracy: 0.5153\n",
      "Epoch 6/100\n",
      "380/380 [==============================] - 0s 128us/step - loss: 1.2579 - accuracy: 0.5526 - val_loss: 1.5157 - val_accuracy: 0.5399\n",
      "Epoch 7/100\n",
      "380/380 [==============================] - 0s 131us/step - loss: 1.1692 - accuracy: 0.6342 - val_loss: 0.8871 - val_accuracy: 0.6074\n",
      "Epoch 8/100\n",
      "380/380 [==============================] - 0s 118us/step - loss: 0.9608 - accuracy: 0.6553 - val_loss: 1.0001 - val_accuracy: 0.6135\n",
      "Epoch 9/100\n",
      "380/380 [==============================] - 0s 144us/step - loss: 0.8604 - accuracy: 0.6658 - val_loss: 0.9470 - val_accuracy: 0.5890\n",
      "Epoch 10/100\n",
      "380/380 [==============================] - 0s 140us/step - loss: 0.8963 - accuracy: 0.7026 - val_loss: 0.8651 - val_accuracy: 0.5828\n",
      "Epoch 11/100\n",
      "380/380 [==============================] - 0s 122us/step - loss: 0.8975 - accuracy: 0.7000 - val_loss: 0.9131 - val_accuracy: 0.6135\n",
      "Epoch 12/100\n",
      "380/380 [==============================] - 0s 125us/step - loss: 0.7760 - accuracy: 0.6947 - val_loss: 0.9627 - val_accuracy: 0.6074\n",
      "Epoch 13/100\n",
      "380/380 [==============================] - 0s 120us/step - loss: 0.7934 - accuracy: 0.7263 - val_loss: 1.2452 - val_accuracy: 0.6258\n",
      "Epoch 14/100\n",
      "380/380 [==============================] - 0s 118us/step - loss: 1.0056 - accuracy: 0.6947 - val_loss: 0.7334 - val_accuracy: 0.6442\n",
      "Epoch 15/100\n",
      "380/380 [==============================] - 0s 99us/step - loss: 0.8184 - accuracy: 0.7026 - val_loss: 1.0211 - val_accuracy: 0.6687\n",
      "Epoch 16/100\n",
      "380/380 [==============================] - 0s 114us/step - loss: 0.9096 - accuracy: 0.7263 - val_loss: 1.4123 - val_accuracy: 0.6442\n",
      "Epoch 17/100\n",
      "380/380 [==============================] - 0s 98us/step - loss: 0.9937 - accuracy: 0.7079 - val_loss: 1.1508 - val_accuracy: 0.6626\n",
      "Epoch 18/100\n",
      "380/380 [==============================] - 0s 93us/step - loss: 0.9745 - accuracy: 0.6895 - val_loss: 1.3669 - val_accuracy: 0.6626\n",
      "Epoch 19/100\n",
      "380/380 [==============================] - 0s 114us/step - loss: 0.8400 - accuracy: 0.6816 - val_loss: 0.7351 - val_accuracy: 0.6994\n",
      "Epoch 20/100\n",
      "380/380 [==============================] - 0s 111us/step - loss: 0.9035 - accuracy: 0.7263 - val_loss: 1.2775 - val_accuracy: 0.6871\n",
      "Epoch 21/100\n",
      "380/380 [==============================] - 0s 111us/step - loss: 0.9523 - accuracy: 0.7184 - val_loss: 0.7936 - val_accuracy: 0.6748\n",
      "Epoch 22/100\n",
      "380/380 [==============================] - 0s 98us/step - loss: 0.7294 - accuracy: 0.7447 - val_loss: 1.2520 - val_accuracy: 0.7117\n",
      "Epoch 23/100\n",
      "380/380 [==============================] - 0s 92us/step - loss: 0.8500 - accuracy: 0.7868 - val_loss: 0.8816 - val_accuracy: 0.6810\n",
      "Epoch 24/100\n",
      "380/380 [==============================] - 0s 92us/step - loss: 0.7857 - accuracy: 0.7763 - val_loss: 0.6251 - val_accuracy: 0.7546\n",
      "Epoch 25/100\n",
      "380/380 [==============================] - 0s 98us/step - loss: 0.6304 - accuracy: 0.7947 - val_loss: 0.6120 - val_accuracy: 0.7607\n",
      "Epoch 26/100\n",
      "380/380 [==============================] - 0s 295us/step - loss: 0.6072 - accuracy: 0.8000 - val_loss: 0.9901 - val_accuracy: 0.7117\n",
      "Epoch 27/100\n",
      "380/380 [==============================] - 0s 150us/step - loss: 0.6730 - accuracy: 0.8079 - val_loss: 0.6592 - val_accuracy: 0.7485\n",
      "Epoch 28/100\n",
      "380/380 [==============================] - 0s 94us/step - loss: 0.7028 - accuracy: 0.7947 - val_loss: 0.8971 - val_accuracy: 0.7117\n",
      "Epoch 29/100\n",
      "380/380 [==============================] - 0s 93us/step - loss: 0.7888 - accuracy: 0.8105 - val_loss: 0.5799 - val_accuracy: 0.7055\n",
      "Epoch 30/100\n",
      "380/380 [==============================] - 0s 190us/step - loss: 0.4847 - accuracy: 0.8211 - val_loss: 0.6158 - val_accuracy: 0.7485\n",
      "Epoch 31/100\n",
      "380/380 [==============================] - 0s 151us/step - loss: 0.6074 - accuracy: 0.8211 - val_loss: 0.5633 - val_accuracy: 0.7607\n",
      "Epoch 32/100\n",
      "380/380 [==============================] - 0s 129us/step - loss: 0.6757 - accuracy: 0.8079 - val_loss: 0.7110 - val_accuracy: 0.7485\n",
      "Epoch 33/100\n",
      "380/380 [==============================] - 0s 125us/step - loss: 0.5467 - accuracy: 0.8000 - val_loss: 0.9019 - val_accuracy: 0.7485\n",
      "Epoch 34/100\n",
      "380/380 [==============================] - 0s 124us/step - loss: 0.5787 - accuracy: 0.7789 - val_loss: 0.5609 - val_accuracy: 0.7301\n",
      "Epoch 35/100\n",
      "380/380 [==============================] - 0s 119us/step - loss: 0.4887 - accuracy: 0.8342 - val_loss: 0.6409 - val_accuracy: 0.7975\n",
      "Epoch 36/100\n",
      "380/380 [==============================] - 0s 143us/step - loss: 0.4913 - accuracy: 0.8289 - val_loss: 0.6915 - val_accuracy: 0.7178\n",
      "Epoch 37/100\n",
      "380/380 [==============================] - 0s 106us/step - loss: 0.5960 - accuracy: 0.8342 - val_loss: 0.6631 - val_accuracy: 0.7914\n",
      "Epoch 38/100\n",
      "380/380 [==============================] - 0s 122us/step - loss: 0.4792 - accuracy: 0.8211 - val_loss: 0.5773 - val_accuracy: 0.7669\n",
      "Epoch 39/100\n",
      "380/380 [==============================] - 0s 94us/step - loss: 0.4562 - accuracy: 0.8184 - val_loss: 0.5485 - val_accuracy: 0.7669\n",
      "Epoch 40/100\n",
      "380/380 [==============================] - 0s 75us/step - loss: 0.4699 - accuracy: 0.8447 - val_loss: 0.5457 - val_accuracy: 0.7853\n",
      "Epoch 41/100\n",
      "380/380 [==============================] - 0s 77us/step - loss: 0.4343 - accuracy: 0.8474 - val_loss: 0.5811 - val_accuracy: 0.7853\n",
      "Epoch 42/100\n",
      "380/380 [==============================] - 0s 73us/step - loss: 0.4529 - accuracy: 0.8421 - val_loss: 1.4567 - val_accuracy: 0.7546\n",
      "Epoch 43/100\n",
      "380/380 [==============================] - 0s 72us/step - loss: 0.8138 - accuracy: 0.8368 - val_loss: 0.7831 - val_accuracy: 0.7669\n",
      "Epoch 44/100\n",
      "380/380 [==============================] - 0s 75us/step - loss: 1.0030 - accuracy: 0.7842 - val_loss: 1.1768 - val_accuracy: 0.7485\n",
      "Epoch 45/100\n",
      "380/380 [==============================] - 0s 74us/step - loss: 0.9519 - accuracy: 0.8105 - val_loss: 0.6405 - val_accuracy: 0.7975\n",
      "Epoch 46/100\n",
      "380/380 [==============================] - 0s 169us/step - loss: 0.5353 - accuracy: 0.7947 - val_loss: 0.4940 - val_accuracy: 0.7975\n",
      "Epoch 47/100\n",
      "380/380 [==============================] - 0s 236us/step - loss: 0.4962 - accuracy: 0.8368 - val_loss: 0.6503 - val_accuracy: 0.7853\n",
      "Epoch 48/100\n",
      "380/380 [==============================] - 0s 221us/step - loss: 0.4473 - accuracy: 0.8553 - val_loss: 0.7236 - val_accuracy: 0.7791\n",
      "Epoch 49/100\n",
      "380/380 [==============================] - 0s 143us/step - loss: 0.5313 - accuracy: 0.8342 - val_loss: 0.6015 - val_accuracy: 0.7669\n",
      "Epoch 50/100\n",
      "380/380 [==============================] - 0s 123us/step - loss: 0.4672 - accuracy: 0.8421 - val_loss: 0.4812 - val_accuracy: 0.7975\n",
      "Epoch 51/100\n",
      "380/380 [==============================] - 0s 129us/step - loss: 0.4991 - accuracy: 0.8395 - val_loss: 0.4963 - val_accuracy: 0.7975\n",
      "Epoch 52/100\n",
      "380/380 [==============================] - 0s 137us/step - loss: 0.4106 - accuracy: 0.8500 - val_loss: 0.7251 - val_accuracy: 0.7669\n",
      "Epoch 53/100\n",
      "380/380 [==============================] - 0s 133us/step - loss: 0.5390 - accuracy: 0.8316 - val_loss: 0.5973 - val_accuracy: 0.8037\n",
      "Epoch 54/100\n",
      "380/380 [==============================] - 0s 153us/step - loss: 0.7252 - accuracy: 0.8579 - val_loss: 0.5480 - val_accuracy: 0.8098\n",
      "Epoch 55/100\n",
      "380/380 [==============================] - 0s 140us/step - loss: 0.6649 - accuracy: 0.8421 - val_loss: 1.3079 - val_accuracy: 0.7914\n",
      "Epoch 56/100\n",
      "380/380 [==============================] - 0s 152us/step - loss: 0.8961 - accuracy: 0.8553 - val_loss: 0.5749 - val_accuracy: 0.7853\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "380/380 [==============================] - 0s 147us/step - loss: 0.4634 - accuracy: 0.8605 - val_loss: 0.4923 - val_accuracy: 0.8405\n",
      "Epoch 58/100\n",
      "380/380 [==============================] - 0s 138us/step - loss: 0.3999 - accuracy: 0.8658 - val_loss: 0.5636 - val_accuracy: 0.8037\n",
      "Epoch 59/100\n",
      "380/380 [==============================] - 0s 154us/step - loss: 0.3410 - accuracy: 0.8816 - val_loss: 0.4287 - val_accuracy: 0.8160\n",
      "Epoch 60/100\n",
      "380/380 [==============================] - 0s 174us/step - loss: 0.3270 - accuracy: 0.8737 - val_loss: 0.5588 - val_accuracy: 0.8037\n",
      "Epoch 61/100\n",
      "380/380 [==============================] - 0s 159us/step - loss: 0.2983 - accuracy: 0.8868 - val_loss: 0.5696 - val_accuracy: 0.8221\n",
      "Epoch 62/100\n",
      "380/380 [==============================] - 0s 154us/step - loss: 0.3390 - accuracy: 0.9026 - val_loss: 0.5219 - val_accuracy: 0.8344\n",
      "Epoch 63/100\n",
      "380/380 [==============================] - 0s 177us/step - loss: 0.2942 - accuracy: 0.8842 - val_loss: 0.6631 - val_accuracy: 0.7914\n",
      "Epoch 64/100\n",
      "380/380 [==============================] - 0s 170us/step - loss: 0.7135 - accuracy: 0.8579 - val_loss: 0.6735 - val_accuracy: 0.7975\n",
      "Epoch 65/100\n",
      "380/380 [==============================] - 0s 192us/step - loss: 0.5210 - accuracy: 0.8289 - val_loss: 0.5784 - val_accuracy: 0.8160\n",
      "Epoch 66/100\n",
      "380/380 [==============================] - 0s 168us/step - loss: 0.5012 - accuracy: 0.8553 - val_loss: 0.4425 - val_accuracy: 0.8344\n",
      "Epoch 67/100\n",
      "380/380 [==============================] - 0s 127us/step - loss: 0.3578 - accuracy: 0.9000 - val_loss: 0.4488 - val_accuracy: 0.8160\n",
      "Epoch 68/100\n",
      "380/380 [==============================] - 0s 138us/step - loss: 0.7354 - accuracy: 0.8553 - val_loss: 1.3459 - val_accuracy: 0.7975\n",
      "Epoch 69/100\n",
      "380/380 [==============================] - 0s 123us/step - loss: 0.6792 - accuracy: 0.8921 - val_loss: 0.5149 - val_accuracy: 0.8589\n",
      "Epoch 70/100\n",
      "380/380 [==============================] - 0s 114us/step - loss: 0.4608 - accuracy: 0.8211 - val_loss: 0.4687 - val_accuracy: 0.8282\n",
      "Epoch 71/100\n",
      "380/380 [==============================] - 0s 121us/step - loss: 0.4049 - accuracy: 0.8711 - val_loss: 0.4865 - val_accuracy: 0.8528\n",
      "Epoch 72/100\n",
      "380/380 [==============================] - 0s 141us/step - loss: 0.4428 - accuracy: 0.8921 - val_loss: 0.4301 - val_accuracy: 0.8221\n",
      "Epoch 73/100\n",
      "380/380 [==============================] - 0s 133us/step - loss: 0.3138 - accuracy: 0.9105 - val_loss: 0.8457 - val_accuracy: 0.8098\n",
      "Epoch 74/100\n",
      "380/380 [==============================] - 0s 158us/step - loss: 0.4813 - accuracy: 0.8974 - val_loss: 0.4039 - val_accuracy: 0.8528\n",
      "Epoch 75/100\n",
      "380/380 [==============================] - 0s 163us/step - loss: 0.3246 - accuracy: 0.9000 - val_loss: 0.4098 - val_accuracy: 0.8650\n",
      "Epoch 76/100\n",
      "380/380 [==============================] - 0s 170us/step - loss: 0.4206 - accuracy: 0.8868 - val_loss: 1.2870 - val_accuracy: 0.7853\n",
      "Epoch 77/100\n",
      "380/380 [==============================] - 0s 183us/step - loss: 0.7147 - accuracy: 0.8447 - val_loss: 0.5194 - val_accuracy: 0.8773\n",
      "Epoch 78/100\n",
      "380/380 [==============================] - 0s 135us/step - loss: 0.4660 - accuracy: 0.8553 - val_loss: 0.5302 - val_accuracy: 0.8160\n",
      "Epoch 79/100\n",
      "380/380 [==============================] - 0s 115us/step - loss: 0.3888 - accuracy: 0.8711 - val_loss: 0.6216 - val_accuracy: 0.8466\n",
      "Epoch 80/100\n",
      "380/380 [==============================] - 0s 156us/step - loss: 0.3441 - accuracy: 0.9000 - val_loss: 0.4378 - val_accuracy: 0.8160\n",
      "Epoch 81/100\n",
      "380/380 [==============================] - 0s 219us/step - loss: 0.2927 - accuracy: 0.9132 - val_loss: 0.4590 - val_accuracy: 0.8773\n",
      "Epoch 82/100\n",
      "380/380 [==============================] - 0s 191us/step - loss: 0.3048 - accuracy: 0.9000 - val_loss: 0.5591 - val_accuracy: 0.8344\n",
      "Epoch 83/100\n",
      "380/380 [==============================] - 0s 323us/step - loss: 0.3709 - accuracy: 0.8947 - val_loss: 0.5646 - val_accuracy: 0.8221\n",
      "Epoch 84/100\n",
      "380/380 [==============================] - 0s 169us/step - loss: 0.3248 - accuracy: 0.9105 - val_loss: 0.3748 - val_accuracy: 0.8589\n",
      "Epoch 85/100\n",
      "380/380 [==============================] - 0s 134us/step - loss: 0.2946 - accuracy: 0.9079 - val_loss: 0.3877 - val_accuracy: 0.8834\n",
      "Epoch 86/100\n",
      "380/380 [==============================] - 0s 147us/step - loss: 0.3510 - accuracy: 0.8895 - val_loss: 0.5891 - val_accuracy: 0.8405\n",
      "Epoch 87/100\n",
      "380/380 [==============================] - 0s 143us/step - loss: 0.2768 - accuracy: 0.9026 - val_loss: 0.3697 - val_accuracy: 0.8405\n",
      "Epoch 88/100\n",
      "380/380 [==============================] - 0s 165us/step - loss: 0.2616 - accuracy: 0.9184 - val_loss: 0.4460 - val_accuracy: 0.8712\n",
      "Epoch 89/100\n",
      "380/380 [==============================] - 0s 173us/step - loss: 0.2614 - accuracy: 0.9368 - val_loss: 0.3756 - val_accuracy: 0.8528\n",
      "Epoch 90/100\n",
      "380/380 [==============================] - 0s 175us/step - loss: 0.2546 - accuracy: 0.9211 - val_loss: 0.3398 - val_accuracy: 0.8589\n",
      "Epoch 91/100\n",
      "380/380 [==============================] - 0s 155us/step - loss: 0.2164 - accuracy: 0.9316 - val_loss: 0.5598 - val_accuracy: 0.8528\n",
      "Epoch 92/100\n",
      "380/380 [==============================] - 0s 147us/step - loss: 0.5571 - accuracy: 0.9026 - val_loss: 0.4922 - val_accuracy: 0.8405\n",
      "Epoch 93/100\n",
      "380/380 [==============================] - 0s 140us/step - loss: 0.2974 - accuracy: 0.8842 - val_loss: 0.5864 - val_accuracy: 0.8160\n",
      "Epoch 94/100\n",
      "380/380 [==============================] - 0s 174us/step - loss: 0.3559 - accuracy: 0.9026 - val_loss: 0.8333 - val_accuracy: 0.8098\n",
      "Epoch 95/100\n",
      "380/380 [==============================] - 0s 171us/step - loss: 0.5090 - accuracy: 0.8947 - val_loss: 0.5001 - val_accuracy: 0.8650\n",
      "Epoch 96/100\n",
      "380/380 [==============================] - 0s 127us/step - loss: 0.3539 - accuracy: 0.9053 - val_loss: 0.5247 - val_accuracy: 0.8528\n",
      "Epoch 97/100\n",
      "380/380 [==============================] - 0s 118us/step - loss: 0.3594 - accuracy: 0.9237 - val_loss: 0.4793 - val_accuracy: 0.8650\n",
      "Epoch 98/100\n",
      "380/380 [==============================] - 0s 111us/step - loss: 0.3518 - accuracy: 0.9053 - val_loss: 0.4681 - val_accuracy: 0.8650\n",
      "Epoch 99/100\n",
      "380/380 [==============================] - 0s 113us/step - loss: 0.3418 - accuracy: 0.9053 - val_loss: 0.4401 - val_accuracy: 0.8405\n",
      "Epoch 100/100\n",
      "380/380 [==============================] - 0s 92us/step - loss: 0.3585 - accuracy: 0.9263 - val_loss: 0.5105 - val_accuracy: 0.8957\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a36728128>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2_over.fit(X_sel_train_over, y_sel_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_sel_test_over, y_sel_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163/163 [==============================] - 0s 73us/step\n",
      "over-sampling test accuracy: 87.12%\n"
     ]
    }
   ],
   "source": [
    "acc_test2_over = model2_over.evaluate(X_sel_test_over, y_sel_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test2_over*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 2, 2, 0, 1, 2, 2, 0, 2, 1, 1, 1, 0, 0, 0, 1, 2, 1, 2, 1, 0,\n",
       "       0, 2, 0, 0, 2, 1, 0, 1, 2, 0, 1, 0, 1, 1, 1, 0, 1, 2, 2, 2, 2, 1,\n",
       "       0, 2, 1, 0, 1, 2, 1, 2, 0, 2, 1, 2, 0, 0, 0, 0, 1, 1, 2, 2, 1, 2,\n",
       "       0, 0, 2, 1, 2, 0, 2, 0, 0, 1, 2, 2, 0, 0, 0, 0, 2, 1, 1, 2, 1, 0,\n",
       "       0, 1, 2, 1, 1, 0, 2, 2, 0, 1, 0, 0, 1, 0, 1, 0, 2, 1, 0, 2, 1, 2,\n",
       "       1, 0, 2, 1, 2, 0, 0, 1, 0, 2, 1, 0, 2, 0, 0, 0, 2, 0, 2, 1, 1, 2,\n",
       "       2, 0, 2, 2, 1, 0, 0, 0, 0, 1, 2, 2, 1, 0, 2, 0, 1, 0, 0, 2, 1, 1,\n",
       "       0, 1, 0, 1, 0, 0, 1, 1, 0])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred5 = model2_over.predict_classes(X_sel_test_over)\n",
    "pred5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CFBRSa49</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS108</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MN105</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CFBRSa03</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BCH-SA-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>NRS027</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>BCH-SA-04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>SR3585</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>504</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>NRS149</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0  test  pred\n",
       "0     CFBRSa49     1     1\n",
       "1       NRS108     2     2\n",
       "2        MN105     2     2\n",
       "3     CFBRSa03     2     2\n",
       "4    BCH-SA-01     0     0\n",
       "..         ...   ...   ...\n",
       "158     NRS027     0     0\n",
       "159  BCH-SA-04     0     0\n",
       "160     SR3585     2     1\n",
       "161        504     1     1\n",
       "162     NRS149     0     0\n",
       "\n",
       "[163 rows x 3 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat5['pred'] = pred5\n",
    "dat5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba5 = model2_over.predict_proba(X_sel_test_over)\n",
    "dat_proba5 = pd.DataFrame(proba5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.420049</td>\n",
       "      <td>0.430507</td>\n",
       "      <td>0.149443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000494</td>\n",
       "      <td>0.020135</td>\n",
       "      <td>0.979372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.006240</td>\n",
       "      <td>0.311664</td>\n",
       "      <td>0.682096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.001413</td>\n",
       "      <td>0.998389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.971427</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.028550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>0.999550</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>0.997324</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>0.002445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>0.072240</td>\n",
       "      <td>0.672646</td>\n",
       "      <td>0.255114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>0.010667</td>\n",
       "      <td>0.975452</td>\n",
       "      <td>0.013880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>0.983665</td>\n",
       "      <td>0.004021</td>\n",
       "      <td>0.012314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2\n",
       "0    0.420049  0.430507  0.149443\n",
       "1    0.000494  0.020135  0.979372\n",
       "2    0.006240  0.311664  0.682096\n",
       "3    0.000198  0.001413  0.998389\n",
       "4    0.971427  0.000023  0.028550\n",
       "..        ...       ...       ...\n",
       "158  0.999550  0.000049  0.000401\n",
       "159  0.997324  0.000231  0.002445\n",
       "160  0.072240  0.672646  0.255114\n",
       "161  0.010667  0.975452  0.013880\n",
       "162  0.983665  0.004021  0.012314\n",
       "\n",
       "[163 rows x 3 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba5.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba5.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat5.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/5p11ST.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 380 samples, validate on 163 samples\n",
      "Epoch 1/100\n",
      "380/380 [==============================] - 0s 103us/step - loss: 0.1622 - accuracy: 0.9447 - val_loss: 0.3914 - val_accuracy: 0.8405\n",
      "Epoch 2/100\n",
      "380/380 [==============================] - 0s 133us/step - loss: 0.2065 - accuracy: 0.9500 - val_loss: 0.4302 - val_accuracy: 0.8650\n",
      "Epoch 3/100\n",
      "380/380 [==============================] - 0s 93us/step - loss: 0.1873 - accuracy: 0.9447 - val_loss: 0.4298 - val_accuracy: 0.8712\n",
      "Epoch 4/100\n",
      "380/380 [==============================] - 0s 89us/step - loss: 0.1898 - accuracy: 0.9395 - val_loss: 0.3383 - val_accuracy: 0.8773\n",
      "Epoch 5/100\n",
      "380/380 [==============================] - 0s 82us/step - loss: 0.1741 - accuracy: 0.9421 - val_loss: 0.3753 - val_accuracy: 0.8650\n",
      "Epoch 6/100\n",
      "380/380 [==============================] - 0s 82us/step - loss: 0.1558 - accuracy: 0.9526 - val_loss: 0.4028 - val_accuracy: 0.8405\n",
      "Epoch 7/100\n",
      "380/380 [==============================] - 0s 88us/step - loss: 0.2056 - accuracy: 0.9447 - val_loss: 0.3933 - val_accuracy: 0.8528\n",
      "Epoch 8/100\n",
      "380/380 [==============================] - 0s 89us/step - loss: 0.2764 - accuracy: 0.9342 - val_loss: 0.4732 - val_accuracy: 0.8834\n",
      "Epoch 9/100\n",
      "380/380 [==============================] - 0s 82us/step - loss: 0.2091 - accuracy: 0.9342 - val_loss: 0.4696 - val_accuracy: 0.8773\n",
      "Epoch 10/100\n",
      "380/380 [==============================] - 0s 81us/step - loss: 0.2997 - accuracy: 0.9158 - val_loss: 0.4817 - val_accuracy: 0.8528\n",
      "Epoch 11/100\n",
      "380/380 [==============================] - 0s 83us/step - loss: 0.2071 - accuracy: 0.9447 - val_loss: 0.4384 - val_accuracy: 0.8221\n",
      "Epoch 12/100\n",
      "380/380 [==============================] - 0s 86us/step - loss: 0.2655 - accuracy: 0.9211 - val_loss: 0.4496 - val_accuracy: 0.8528\n",
      "Epoch 13/100\n",
      "380/380 [==============================] - 0s 115us/step - loss: 0.1702 - accuracy: 0.9421 - val_loss: 0.3307 - val_accuracy: 0.8896\n",
      "Epoch 14/100\n",
      "380/380 [==============================] - 0s 109us/step - loss: 0.1551 - accuracy: 0.9526 - val_loss: 0.3841 - val_accuracy: 0.8528\n",
      "Epoch 15/100\n",
      "380/380 [==============================] - 0s 158us/step - loss: 0.2768 - accuracy: 0.9289 - val_loss: 0.3590 - val_accuracy: 0.8773\n",
      "Epoch 16/100\n",
      "380/380 [==============================] - 0s 146us/step - loss: 0.4158 - accuracy: 0.9105 - val_loss: 0.6374 - val_accuracy: 0.8160\n",
      "Epoch 17/100\n",
      "380/380 [==============================] - 0s 98us/step - loss: 0.2341 - accuracy: 0.9184 - val_loss: 0.4674 - val_accuracy: 0.8098\n",
      "Epoch 18/100\n",
      "380/380 [==============================] - 0s 108us/step - loss: 0.2545 - accuracy: 0.9053 - val_loss: 0.6555 - val_accuracy: 0.8528\n",
      "Epoch 19/100\n",
      "380/380 [==============================] - 0s 102us/step - loss: 0.1998 - accuracy: 0.9316 - val_loss: 0.3918 - val_accuracy: 0.8589\n",
      "Epoch 20/100\n",
      "380/380 [==============================] - 0s 106us/step - loss: 0.1843 - accuracy: 0.9500 - val_loss: 0.4293 - val_accuracy: 0.8957\n",
      "Epoch 21/100\n",
      "380/380 [==============================] - 0s 105us/step - loss: 0.1525 - accuracy: 0.9553 - val_loss: 0.3683 - val_accuracy: 0.8773\n",
      "Epoch 22/100\n",
      "380/380 [==============================] - 0s 99us/step - loss: 0.1480 - accuracy: 0.9368 - val_loss: 0.3869 - val_accuracy: 0.8773\n",
      "Epoch 23/100\n",
      "380/380 [==============================] - 0s 116us/step - loss: 0.1554 - accuracy: 0.9500 - val_loss: 0.3883 - val_accuracy: 0.9018\n",
      "Epoch 24/100\n",
      "380/380 [==============================] - 0s 106us/step - loss: 0.1756 - accuracy: 0.9526 - val_loss: 0.4085 - val_accuracy: 0.8957\n",
      "Epoch 25/100\n",
      "380/380 [==============================] - 0s 98us/step - loss: 0.2391 - accuracy: 0.9368 - val_loss: 0.5974 - val_accuracy: 0.8344\n",
      "Epoch 26/100\n",
      "380/380 [==============================] - 0s 97us/step - loss: 0.3107 - accuracy: 0.9395 - val_loss: 0.4124 - val_accuracy: 0.9018\n",
      "Epoch 27/100\n",
      "380/380 [==============================] - 0s 117us/step - loss: 0.2682 - accuracy: 0.9474 - val_loss: 0.5214 - val_accuracy: 0.8589\n",
      "Epoch 28/100\n",
      "380/380 [==============================] - 0s 110us/step - loss: 0.1840 - accuracy: 0.9395 - val_loss: 0.4410 - val_accuracy: 0.8466\n",
      "Epoch 29/100\n",
      "380/380 [==============================] - 0s 101us/step - loss: 0.2396 - accuracy: 0.9368 - val_loss: 0.4106 - val_accuracy: 0.8650\n",
      "Epoch 30/100\n",
      "380/380 [==============================] - 0s 100us/step - loss: 0.1730 - accuracy: 0.9447 - val_loss: 0.3632 - val_accuracy: 0.9080\n",
      "Epoch 31/100\n",
      "380/380 [==============================] - 0s 110us/step - loss: 0.1571 - accuracy: 0.9474 - val_loss: 0.3456 - val_accuracy: 0.8834\n",
      "Epoch 32/100\n",
      "380/380 [==============================] - 0s 117us/step - loss: 0.1836 - accuracy: 0.9447 - val_loss: 0.4961 - val_accuracy: 0.8160\n",
      "Epoch 33/100\n",
      "380/380 [==============================] - 0s 165us/step - loss: 0.2084 - accuracy: 0.9368 - val_loss: 0.4731 - val_accuracy: 0.8773\n",
      "Epoch 34/100\n",
      "380/380 [==============================] - 0s 231us/step - loss: 0.1886 - accuracy: 0.9526 - val_loss: 0.3649 - val_accuracy: 0.8896\n",
      "Epoch 35/100\n",
      "380/380 [==============================] - 0s 118us/step - loss: 0.1900 - accuracy: 0.9553 - val_loss: 0.4284 - val_accuracy: 0.8896\n",
      "Epoch 36/100\n",
      "380/380 [==============================] - 0s 101us/step - loss: 0.1376 - accuracy: 0.9526 - val_loss: 0.4467 - val_accuracy: 0.8466\n",
      "Epoch 37/100\n",
      "380/380 [==============================] - 0s 89us/step - loss: 0.1988 - accuracy: 0.9474 - val_loss: 0.4166 - val_accuracy: 0.8957\n",
      "Epoch 38/100\n",
      "380/380 [==============================] - 0s 77us/step - loss: 0.1278 - accuracy: 0.9579 - val_loss: 0.3350 - val_accuracy: 0.8834\n",
      "Epoch 39/100\n",
      "380/380 [==============================] - 0s 73us/step - loss: 0.1340 - accuracy: 0.9605 - val_loss: 0.3924 - val_accuracy: 0.8773\n",
      "Epoch 40/100\n",
      "380/380 [==============================] - 0s 76us/step - loss: 0.1792 - accuracy: 0.9474 - val_loss: 0.3941 - val_accuracy: 0.8344\n",
      "Epoch 41/100\n",
      "380/380 [==============================] - 0s 70us/step - loss: 0.3165 - accuracy: 0.9289 - val_loss: 0.4395 - val_accuracy: 0.8957\n",
      "Epoch 42/100\n",
      "380/380 [==============================] - 0s 75us/step - loss: 0.2678 - accuracy: 0.9447 - val_loss: 0.4831 - val_accuracy: 0.8712\n",
      "Epoch 43/100\n",
      "380/380 [==============================] - 0s 74us/step - loss: 0.2304 - accuracy: 0.9368 - val_loss: 0.4269 - val_accuracy: 0.8528\n",
      "Epoch 44/100\n",
      "380/380 [==============================] - 0s 70us/step - loss: 0.1858 - accuracy: 0.9447 - val_loss: 0.4795 - val_accuracy: 0.8650\n",
      "Epoch 45/100\n",
      "380/380 [==============================] - 0s 71us/step - loss: 0.1710 - accuracy: 0.9421 - val_loss: 0.3159 - val_accuracy: 0.8957\n",
      "Epoch 46/100\n",
      "380/380 [==============================] - 0s 75us/step - loss: 0.1384 - accuracy: 0.9605 - val_loss: 0.4033 - val_accuracy: 0.9080\n",
      "Epoch 47/100\n",
      "380/380 [==============================] - 0s 76us/step - loss: 0.1313 - accuracy: 0.9553 - val_loss: 0.3786 - val_accuracy: 0.8896\n",
      "Epoch 48/100\n",
      "380/380 [==============================] - 0s 82us/step - loss: 0.1624 - accuracy: 0.9553 - val_loss: 0.4759 - val_accuracy: 0.8712\n",
      "Epoch 49/100\n",
      "380/380 [==============================] - 0s 82us/step - loss: 0.2036 - accuracy: 0.9526 - val_loss: 0.3794 - val_accuracy: 0.8957\n",
      "Epoch 50/100\n",
      "380/380 [==============================] - 0s 82us/step - loss: 0.1323 - accuracy: 0.9605 - val_loss: 0.3229 - val_accuracy: 0.8834\n",
      "Epoch 51/100\n",
      "380/380 [==============================] - 0s 82us/step - loss: 0.1384 - accuracy: 0.9579 - val_loss: 0.3688 - val_accuracy: 0.8773\n",
      "Epoch 52/100\n",
      "380/380 [==============================] - 0s 83us/step - loss: 0.1841 - accuracy: 0.9500 - val_loss: 0.4293 - val_accuracy: 0.9080\n",
      "Epoch 53/100\n",
      "380/380 [==============================] - 0s 92us/step - loss: 0.1279 - accuracy: 0.9579 - val_loss: 0.3204 - val_accuracy: 0.8957\n",
      "Epoch 54/100\n",
      "380/380 [==============================] - 0s 83us/step - loss: 0.1376 - accuracy: 0.9579 - val_loss: 0.3755 - val_accuracy: 0.8589\n",
      "Epoch 55/100\n",
      "380/380 [==============================] - 0s 86us/step - loss: 0.1981 - accuracy: 0.9474 - val_loss: 0.4048 - val_accuracy: 0.8957\n",
      "Epoch 56/100\n",
      "380/380 [==============================] - 0s 104us/step - loss: 0.1379 - accuracy: 0.9526 - val_loss: 0.3471 - val_accuracy: 0.8589\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "380/380 [==============================] - 0s 84us/step - loss: 0.1529 - accuracy: 0.9474 - val_loss: 0.3840 - val_accuracy: 0.8834\n",
      "Epoch 58/100\n",
      "380/380 [==============================] - 0s 92us/step - loss: 0.1327 - accuracy: 0.9579 - val_loss: 0.3702 - val_accuracy: 0.8896\n",
      "Epoch 59/100\n",
      "380/380 [==============================] - 0s 97us/step - loss: 0.1890 - accuracy: 0.9579 - val_loss: 0.3844 - val_accuracy: 0.9080\n",
      "Epoch 60/100\n",
      "380/380 [==============================] - 0s 97us/step - loss: 0.1392 - accuracy: 0.9526 - val_loss: 0.3885 - val_accuracy: 0.8773\n",
      "Epoch 61/100\n",
      "380/380 [==============================] - 0s 96us/step - loss: 0.1202 - accuracy: 0.9632 - val_loss: 0.3792 - val_accuracy: 0.9080\n",
      "Epoch 62/100\n",
      "380/380 [==============================] - 0s 92us/step - loss: 0.1222 - accuracy: 0.9632 - val_loss: 0.4232 - val_accuracy: 0.8773\n",
      "Epoch 63/100\n",
      "380/380 [==============================] - 0s 100us/step - loss: 0.1562 - accuracy: 0.9553 - val_loss: 0.3568 - val_accuracy: 0.8773\n",
      "Epoch 64/100\n",
      "380/380 [==============================] - 0s 103us/step - loss: 0.1461 - accuracy: 0.9579 - val_loss: 0.3823 - val_accuracy: 0.8773\n",
      "Epoch 65/100\n",
      "380/380 [==============================] - 0s 89us/step - loss: 0.1459 - accuracy: 0.9632 - val_loss: 0.3753 - val_accuracy: 0.9080\n",
      "Epoch 66/100\n",
      "380/380 [==============================] - 0s 80us/step - loss: 0.1383 - accuracy: 0.9632 - val_loss: 0.3563 - val_accuracy: 0.8528\n",
      "Epoch 67/100\n",
      "380/380 [==============================] - 0s 83us/step - loss: 0.1179 - accuracy: 0.9553 - val_loss: 0.4113 - val_accuracy: 0.8896\n",
      "Epoch 68/100\n",
      "380/380 [==============================] - 0s 75us/step - loss: 0.1418 - accuracy: 0.9553 - val_loss: 0.4457 - val_accuracy: 0.8528\n",
      "Epoch 69/100\n",
      "380/380 [==============================] - 0s 72us/step - loss: 0.3126 - accuracy: 0.9316 - val_loss: 0.4987 - val_accuracy: 0.8834\n",
      "Epoch 70/100\n",
      "380/380 [==============================] - 0s 85us/step - loss: 0.1539 - accuracy: 0.9500 - val_loss: 0.3632 - val_accuracy: 0.8712\n",
      "Epoch 71/100\n",
      "380/380 [==============================] - 0s 84us/step - loss: 0.1556 - accuracy: 0.9579 - val_loss: 0.3432 - val_accuracy: 0.8712\n",
      "Epoch 72/100\n",
      "380/380 [==============================] - 0s 146us/step - loss: 0.1388 - accuracy: 0.9553 - val_loss: 0.3913 - val_accuracy: 0.8773\n",
      "Epoch 73/100\n",
      "380/380 [==============================] - 0s 183us/step - loss: 0.1801 - accuracy: 0.9684 - val_loss: 0.3594 - val_accuracy: 0.9141\n",
      "Epoch 74/100\n",
      "380/380 [==============================] - 0s 173us/step - loss: 0.1218 - accuracy: 0.9553 - val_loss: 0.3786 - val_accuracy: 0.8957\n",
      "Epoch 75/100\n",
      "380/380 [==============================] - 0s 171us/step - loss: 0.1436 - accuracy: 0.9632 - val_loss: 0.3111 - val_accuracy: 0.8896\n",
      "Epoch 76/100\n",
      "380/380 [==============================] - 0s 177us/step - loss: 0.1371 - accuracy: 0.9632 - val_loss: 0.3998 - val_accuracy: 0.8957\n",
      "Epoch 77/100\n",
      "380/380 [==============================] - 0s 150us/step - loss: 0.1716 - accuracy: 0.9605 - val_loss: 0.4010 - val_accuracy: 0.9018\n",
      "Epoch 78/100\n",
      "380/380 [==============================] - 0s 114us/step - loss: 0.1243 - accuracy: 0.9579 - val_loss: 0.3408 - val_accuracy: 0.8957\n",
      "Epoch 79/100\n",
      "380/380 [==============================] - 0s 105us/step - loss: 0.1053 - accuracy: 0.9658 - val_loss: 0.3738 - val_accuracy: 0.9018\n",
      "Epoch 80/100\n",
      "380/380 [==============================] - 0s 100us/step - loss: 0.1080 - accuracy: 0.9684 - val_loss: 0.3357 - val_accuracy: 0.8957\n",
      "Epoch 81/100\n",
      "380/380 [==============================] - 0s 98us/step - loss: 0.1075 - accuracy: 0.9658 - val_loss: 0.3620 - val_accuracy: 0.9018\n",
      "Epoch 82/100\n",
      "380/380 [==============================] - 0s 81us/step - loss: 0.1081 - accuracy: 0.9684 - val_loss: 0.3405 - val_accuracy: 0.8712\n",
      "Epoch 83/100\n",
      "380/380 [==============================] - 0s 74us/step - loss: 0.1365 - accuracy: 0.9658 - val_loss: 0.4053 - val_accuracy: 0.8834\n",
      "Epoch 84/100\n",
      "380/380 [==============================] - 0s 73us/step - loss: 0.1459 - accuracy: 0.9500 - val_loss: 0.5633 - val_accuracy: 0.8466\n",
      "Epoch 85/100\n",
      "380/380 [==============================] - 0s 73us/step - loss: 0.1855 - accuracy: 0.9553 - val_loss: 0.3619 - val_accuracy: 0.8957\n",
      "Epoch 86/100\n",
      "380/380 [==============================] - 0s 79us/step - loss: 0.1941 - accuracy: 0.9526 - val_loss: 0.8420 - val_accuracy: 0.8344\n",
      "Epoch 87/100\n",
      "380/380 [==============================] - 0s 71us/step - loss: 0.4156 - accuracy: 0.9368 - val_loss: 0.4018 - val_accuracy: 0.8773\n",
      "Epoch 88/100\n",
      "380/380 [==============================] - 0s 74us/step - loss: 0.2807 - accuracy: 0.9316 - val_loss: 0.6602 - val_accuracy: 0.8221\n",
      "Epoch 89/100\n",
      "380/380 [==============================] - 0s 74us/step - loss: 0.4009 - accuracy: 0.9316 - val_loss: 0.5024 - val_accuracy: 0.8896\n",
      "Epoch 90/100\n",
      "380/380 [==============================] - 0s 70us/step - loss: 0.1353 - accuracy: 0.9605 - val_loss: 0.4645 - val_accuracy: 0.9018\n",
      "Epoch 91/100\n",
      "380/380 [==============================] - 0s 71us/step - loss: 0.2125 - accuracy: 0.9526 - val_loss: 0.4939 - val_accuracy: 0.8589\n",
      "Epoch 92/100\n",
      "380/380 [==============================] - 0s 80us/step - loss: 0.1411 - accuracy: 0.9500 - val_loss: 0.3640 - val_accuracy: 0.8896\n",
      "Epoch 93/100\n",
      "380/380 [==============================] - 0s 94us/step - loss: 0.1484 - accuracy: 0.9658 - val_loss: 0.3703 - val_accuracy: 0.8712\n",
      "Epoch 94/100\n",
      "380/380 [==============================] - 0s 86us/step - loss: 0.1147 - accuracy: 0.9605 - val_loss: 0.4473 - val_accuracy: 0.8773\n",
      "Epoch 95/100\n",
      "380/380 [==============================] - 0s 92us/step - loss: 0.1081 - accuracy: 0.9605 - val_loss: 0.3927 - val_accuracy: 0.8466\n",
      "Epoch 96/100\n",
      "380/380 [==============================] - 0s 88us/step - loss: 0.1115 - accuracy: 0.9579 - val_loss: 0.4317 - val_accuracy: 0.8712\n",
      "Epoch 97/100\n",
      "380/380 [==============================] - 0s 82us/step - loss: 0.1112 - accuracy: 0.9632 - val_loss: 0.3667 - val_accuracy: 0.8773\n",
      "Epoch 98/100\n",
      "380/380 [==============================] - 0s 86us/step - loss: 0.1890 - accuracy: 0.9474 - val_loss: 0.4520 - val_accuracy: 0.8650\n",
      "Epoch 99/100\n",
      "380/380 [==============================] - 0s 82us/step - loss: 0.2028 - accuracy: 0.9447 - val_loss: 0.5088 - val_accuracy: 0.8344\n",
      "Epoch 100/100\n",
      "380/380 [==============================] - 0s 95us/step - loss: 0.2566 - accuracy: 0.9447 - val_loss: 0.4801 - val_accuracy: 0.8834\n"
     ]
    }
   ],
   "source": [
    "hist2_over = model2_over.fit(X_sel_train_over, y_sel_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_sel_test_over, y_sel_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 94.91%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist2_over.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba5 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_lasso_2.xlsx\",\n",
    "                        sheet_name=0,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>NRS245</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.345807e-02</td>\n",
       "      <td>2.164788e-01</td>\n",
       "      <td>7.700630e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>NY439</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.674153e-02</td>\n",
       "      <td>9.294230e-04</td>\n",
       "      <td>9.723290e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>CA544</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.147484e-01</td>\n",
       "      <td>3.626331e-01</td>\n",
       "      <td>2.226184e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>CA541</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4.147484e-01</td>\n",
       "      <td>3.626331e-01</td>\n",
       "      <td>2.226184e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>EUH15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.147484e-01</td>\n",
       "      <td>3.626331e-01</td>\n",
       "      <td>2.226184e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>CA541</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.723218e-01</td>\n",
       "      <td>6.276781e-01</td>\n",
       "      <td>1.945911e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>SR4152</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.372800e-01</td>\n",
       "      <td>2.627200e-01</td>\n",
       "      <td>4.197748e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>NRS110</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4.194510e-08</td>\n",
       "      <td>7.508231e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>CFBRSa70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.372800e-01</td>\n",
       "      <td>2.627200e-01</td>\n",
       "      <td>4.197748e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>NRS021</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.943684e-01</td>\n",
       "      <td>6.056316e-01</td>\n",
       "      <td>2.843107e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>989 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   phage    strain  phenotype  prediction             0  \\\n",
       "0     p0006kpresabs_qual    NRS245          1           2  1.345807e-02   \n",
       "1     p0006kpresabs_qual     NY439          2           2  2.674153e-02   \n",
       "2     p0006kpresabs_qual     CA544          1           0  4.147484e-01   \n",
       "3     p0006kpresabs_qual     CA541          2           0  4.147484e-01   \n",
       "4     p0006kpresabs_qual     EUH15          1           0  4.147484e-01   \n",
       "..                   ...       ...        ...         ...           ...   \n",
       "984  p0017Skpresabs_qual     CA541          1           1  3.723218e-01   \n",
       "985  p0017Skpresabs_qual    SR4152          1           0  7.372800e-01   \n",
       "986  p0017Skpresabs_qual    NRS110          2           2  4.194510e-08   \n",
       "987  p0017Skpresabs_qual  CFBRSa70          0           0  7.372800e-01   \n",
       "988  p0017Skpresabs_qual    NRS021          0           1  3.943684e-01   \n",
       "\n",
       "                1             2  \n",
       "0    2.164788e-01  7.700630e-01  \n",
       "1    9.294230e-04  9.723290e-01  \n",
       "2    3.626331e-01  2.226184e-01  \n",
       "3    3.626331e-01  2.226184e-01  \n",
       "4    3.626331e-01  2.226184e-01  \n",
       "..            ...           ...  \n",
       "984  6.276781e-01  1.945911e-08  \n",
       "985  2.627200e-01  4.197748e-08  \n",
       "986  7.508231e-09  1.000000e+00  \n",
       "987  2.627200e-01  4.197748e-08  \n",
       "988  6.056316e-01  2.843107e-08  \n",
       "\n",
       "[989 rows x 7 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.20049160e-01, 4.30507400e-01, 1.49443400e-01],\n",
       "       [4.93855500e-04, 2.01345530e-02, 9.79371670e-01],\n",
       "       [6.23981750e-03, 3.11664460e-01, 6.82095770e-01],\n",
       "       [1.97649230e-04, 1.41288110e-03, 9.98389500e-01],\n",
       "       [9.71426960e-01, 2.32201380e-05, 2.85497400e-02],\n",
       "       [7.35996800e-03, 8.10768660e-01, 1.81871340e-01],\n",
       "       [2.23812120e-04, 3.21989150e-01, 6.77787000e-01],\n",
       "       [1.01898300e-05, 2.37906870e-02, 9.76199150e-01],\n",
       "       [9.89897700e-01, 3.38650870e-03, 6.71580530e-03],\n",
       "       [3.88977230e-01, 7.66556860e-02, 5.34367000e-01],\n",
       "       [1.31853385e-05, 8.71106000e-01, 1.28880770e-01],\n",
       "       [3.46173380e-07, 9.99766900e-01, 2.32738440e-04],\n",
       "       [2.62814160e-01, 5.87796500e-01, 1.49389360e-01],\n",
       "       [9.32949500e-01, 4.66466730e-02, 2.04038080e-02],\n",
       "       [9.83665170e-01, 4.02055540e-03, 1.23142380e-02],\n",
       "       [7.27915500e-01, 1.49583000e-01, 1.22501460e-01],\n",
       "       [6.56433900e-02, 8.57159440e-01, 7.71971600e-02],\n",
       "       [2.38698750e-06, 2.57115420e-03, 9.97426450e-01],\n",
       "       [5.28302900e-08, 9.94862140e-01, 5.13787800e-03],\n",
       "       [3.31001320e-02, 8.25992670e-04, 9.66073900e-01],\n",
       "       [2.62814160e-01, 5.87796500e-01, 1.49389360e-01],\n",
       "       [9.32949500e-01, 4.66466730e-02, 2.04038080e-02],\n",
       "       [9.98081560e-01, 1.92626360e-05, 1.89915260e-03],\n",
       "       [1.70495130e-05, 2.31868400e-02, 9.76796150e-01],\n",
       "       [9.79454000e-01, 1.39079810e-03, 1.91551450e-02],\n",
       "       [6.53568700e-01, 2.48142020e-01, 9.82892800e-02],\n",
       "       [7.19788300e-03, 1.77909460e-01, 8.14892700e-01],\n",
       "       [1.56126500e-07, 9.95110700e-01, 4.88915700e-03],\n",
       "       [9.99999500e-01, 2.39369120e-15, 4.35179540e-07],\n",
       "       [2.09417620e-02, 5.09272750e-01, 4.69785480e-01],\n",
       "       [9.66813530e-04, 3.17829610e-03, 9.95854900e-01],\n",
       "       [9.92162640e-01, 6.62600850e-03, 1.21136360e-03],\n",
       "       [1.55517400e-03, 9.65512160e-01, 3.29326500e-02],\n",
       "       [1.00000000e+00, 4.01433830e-17, 2.58665800e-08],\n",
       "       [2.55791270e-02, 8.13098970e-01, 1.61321850e-01],\n",
       "       [1.58153580e-07, 9.96701200e-01, 3.29865070e-03],\n",
       "       [1.60100070e-02, 9.40741960e-01, 4.32481540e-02],\n",
       "       [9.79454000e-01, 1.39079810e-03, 1.91551450e-02],\n",
       "       [1.55517400e-03, 9.65512160e-01, 3.29326500e-02],\n",
       "       [4.27911660e-03, 2.63816700e-01, 7.31904150e-01],\n",
       "       [7.97223600e-03, 3.09493650e-03, 9.88932850e-01],\n",
       "       [3.82509200e-03, 3.17945100e-01, 6.78229800e-01],\n",
       "       [4.51595500e-03, 1.15618880e-01, 8.79865170e-01],\n",
       "       [1.84329500e-06, 9.96242760e-01, 3.75539440e-03],\n",
       "       [9.95094300e-01, 1.10181660e-04, 4.79552430e-03],\n",
       "       [2.59126330e-04, 4.86069300e-01, 5.13671640e-01],\n",
       "       [7.35996800e-03, 8.10768660e-01, 1.81871340e-01],\n",
       "       [8.91922700e-01, 4.43776140e-04, 1.07633470e-01],\n",
       "       [1.73721120e-03, 9.85275860e-01, 1.29868570e-02],\n",
       "       [6.70591400e-04, 4.89768100e-04, 9.98839700e-01],\n",
       "       [3.46173380e-07, 9.99766900e-01, 2.32738440e-04],\n",
       "       [5.28176870e-02, 1.01958685e-01, 8.45223670e-01],\n",
       "       [9.71426960e-01, 2.32201380e-05, 2.85497400e-02],\n",
       "       [6.18674350e-02, 2.52705000e-01, 6.85427550e-01],\n",
       "       [1.06673455e-02, 9.75452400e-01, 1.38802320e-02],\n",
       "       [9.01024200e-03, 2.46187180e-01, 7.44802600e-01],\n",
       "       [7.27915500e-01, 1.49583000e-01, 1.22501460e-01],\n",
       "       [9.99691700e-01, 2.86278810e-05, 2.79683070e-04],\n",
       "       [9.99549900e-01, 4.92358230e-05, 4.00790360e-04],\n",
       "       [9.99549900e-01, 4.92358230e-05, 4.00790360e-04],\n",
       "       [2.62814160e-01, 5.87796500e-01, 1.49389360e-01],\n",
       "       [6.35242760e-02, 5.84628460e-01, 3.51847300e-01],\n",
       "       [9.02808300e-03, 2.22594800e-01, 7.68377100e-01],\n",
       "       [1.66599920e-03, 1.60033090e-01, 8.38300900e-01],\n",
       "       [2.23278550e-04, 5.58359100e-01, 4.41417660e-01],\n",
       "       [1.32802470e-03, 1.68693270e-02, 9.81802640e-01],\n",
       "       [9.32949500e-01, 4.66466730e-02, 2.04038080e-02],\n",
       "       [7.27915500e-01, 1.49583000e-01, 1.22501460e-01],\n",
       "       [1.01789010e-02, 2.24777120e-02, 9.67343330e-01],\n",
       "       [8.79280800e-04, 9.82924400e-01, 1.61963660e-02],\n",
       "       [3.72714470e-02, 7.93301100e-02, 8.83398500e-01],\n",
       "       [9.13734300e-01, 7.45836400e-03, 7.88073700e-02],\n",
       "       [1.93971940e-06, 2.62439550e-01, 7.37558540e-01],\n",
       "       [9.68648800e-01, 4.09030000e-04, 3.09421920e-02],\n",
       "       [9.92162640e-01, 6.62600850e-03, 1.21136360e-03],\n",
       "       [3.56701900e-03, 7.45693700e-01, 2.50739280e-01],\n",
       "       [9.02808300e-03, 2.22594800e-01, 7.68377100e-01],\n",
       "       [3.60392870e-01, 1.75133440e-01, 4.64473720e-01],\n",
       "       [9.98081560e-01, 1.92626360e-05, 1.89915260e-03],\n",
       "       [9.99691700e-01, 2.86278810e-05, 2.79683070e-04],\n",
       "       [9.68648800e-01, 4.09030000e-04, 3.09421920e-02],\n",
       "       [9.71426960e-01, 2.32201380e-05, 2.85497400e-02],\n",
       "       [2.13482290e-01, 9.05473300e-02, 6.95970360e-01],\n",
       "       [1.06673455e-02, 9.75452400e-01, 1.38802320e-02],\n",
       "       [2.71971700e-03, 8.00285460e-01, 1.96994860e-01],\n",
       "       [3.88977230e-01, 7.66556860e-02, 5.34367000e-01],\n",
       "       [1.31853385e-05, 8.71106000e-01, 1.28880770e-01],\n",
       "       [9.92162640e-01, 6.62600850e-03, 1.21136360e-03],\n",
       "       [9.97324100e-01, 2.30608330e-04, 2.44527150e-03],\n",
       "       [2.07544860e-02, 7.42987040e-01, 2.36258540e-01],\n",
       "       [9.81484400e-04, 8.02839300e-05, 9.98938260e-01],\n",
       "       [1.65792930e-02, 9.11109300e-01, 7.23114160e-02],\n",
       "       [6.35242760e-02, 5.84628460e-01, 3.51847300e-01],\n",
       "       [9.32949500e-01, 4.66466730e-02, 2.04038080e-02],\n",
       "       [4.27911660e-03, 2.63816700e-01, 7.31904150e-01],\n",
       "       [2.13920270e-04, 2.72241200e-04, 9.99513860e-01],\n",
       "       [9.17592350e-01, 2.35680120e-03, 8.00508500e-02],\n",
       "       [2.55791270e-02, 8.13098970e-01, 1.61321850e-01],\n",
       "       [8.91922700e-01, 4.43776140e-04, 1.07633470e-01],\n",
       "       [8.91922700e-01, 4.43776140e-04, 1.07633470e-01],\n",
       "       [9.28356600e-03, 7.72772250e-01, 2.17944230e-01],\n",
       "       [6.08520200e-01, 1.20243160e-02, 3.79455540e-01],\n",
       "       [9.28356600e-03, 7.72772250e-01, 2.17944230e-01],\n",
       "       [9.83665170e-01, 4.02055540e-03, 1.23142380e-02],\n",
       "       [8.77643400e-04, 7.09735700e-02, 9.28148800e-01],\n",
       "       [9.28356600e-03, 7.72772250e-01, 2.17944230e-01],\n",
       "       [4.59086780e-01, 1.48150300e-01, 3.92762960e-01],\n",
       "       [1.33943550e-02, 4.29709670e-02, 9.43634600e-01],\n",
       "       [1.58153580e-07, 9.96701200e-01, 3.29865070e-03],\n",
       "       [4.51216220e-05, 1.19883270e-01, 8.80071600e-01],\n",
       "       [2.55791270e-02, 8.13098970e-01, 1.61321850e-01],\n",
       "       [1.00000000e+00, 4.01433830e-17, 2.58665800e-08],\n",
       "       [1.74870200e-03, 2.03565550e-03, 9.96215640e-01],\n",
       "       [4.08546480e-02, 6.77678000e-01, 2.81467320e-01],\n",
       "       [1.81115180e-02, 1.83589680e-01, 7.98298800e-01],\n",
       "       [8.91922700e-01, 4.43776140e-04, 1.07633470e-01],\n",
       "       [9.99549900e-01, 4.92358230e-05, 4.00790360e-04],\n",
       "       [2.23278550e-04, 5.58359100e-01, 4.41417660e-01],\n",
       "       [9.99947200e-01, 2.64772100e-13, 5.28238200e-05],\n",
       "       [8.46743600e-03, 4.79044040e-04, 9.91053500e-01],\n",
       "       [1.02922060e-06, 8.86089560e-01, 1.13909390e-01],\n",
       "       [9.97324100e-01, 2.30608330e-04, 2.44527150e-03],\n",
       "       [8.54085100e-03, 4.42957730e-01, 5.48501430e-01],\n",
       "       [9.79454000e-01, 1.39079810e-03, 1.91551450e-02],\n",
       "       [9.83665170e-01, 4.02055540e-03, 1.23142380e-02],\n",
       "       [6.53568700e-01, 2.48142020e-01, 9.82892800e-02],\n",
       "       [4.38517400e-01, 4.69638800e-02, 5.14518800e-01],\n",
       "       [9.91567900e-01, 9.91162600e-04, 7.44098000e-03],\n",
       "       [1.98493400e-03, 5.11955130e-02, 9.46819540e-01],\n",
       "       [1.60100070e-02, 9.40741960e-01, 4.32481540e-02],\n",
       "       [9.28356600e-03, 7.72772250e-01, 2.17944230e-01],\n",
       "       [1.33197250e-02, 7.70134850e-03, 9.78978930e-01],\n",
       "       [2.76228930e-03, 1.82533170e-01, 8.14704500e-01],\n",
       "       [9.89897700e-01, 3.38650870e-03, 6.71580530e-03],\n",
       "       [1.22611540e-01, 3.20368530e-01, 5.57019950e-01],\n",
       "       [1.94422500e-04, 1.27351410e-02, 9.87070400e-01],\n",
       "       [1.73721120e-03, 9.85275860e-01, 1.29868570e-02],\n",
       "       [9.98081560e-01, 1.92626360e-05, 1.89915260e-03],\n",
       "       [9.83665170e-01, 4.02055540e-03, 1.23142380e-02],\n",
       "       [9.97324100e-01, 2.30608330e-04, 2.44527150e-03],\n",
       "       [9.99999500e-01, 2.39369120e-15, 4.35179540e-07],\n",
       "       [7.35996800e-03, 8.10768660e-01, 1.81871340e-01],\n",
       "       [1.66169760e-03, 1.40105640e-02, 9.84327700e-01],\n",
       "       [5.70730070e-03, 7.37522900e-02, 9.20540450e-01],\n",
       "       [5.32135140e-02, 9.44816600e-01, 1.96995660e-03],\n",
       "       [9.99626400e-01, 1.21778890e-04, 2.51766590e-04],\n",
       "       [8.50082100e-02, 4.25364140e-01, 4.89627750e-01],\n",
       "       [1.00000000e+00, 4.01433830e-17, 2.58665800e-08],\n",
       "       [2.07544860e-02, 7.42987040e-01, 2.36258540e-01],\n",
       "       [9.79454000e-01, 1.39079810e-03, 1.91551450e-02],\n",
       "       [4.54494180e-01, 2.15039160e-01, 3.30466660e-01],\n",
       "       [2.06587240e-01, 3.84602810e-01, 4.08809930e-01],\n",
       "       [2.07544860e-02, 7.42987040e-01, 2.36258540e-01],\n",
       "       [2.55791270e-02, 8.13098970e-01, 1.61321850e-01],\n",
       "       [6.44861760e-01, 6.34721500e-03, 3.48791060e-01],\n",
       "       [1.55517400e-03, 9.65512160e-01, 3.29326500e-02],\n",
       "       [8.91922700e-01, 4.43776140e-04, 1.07633470e-01],\n",
       "       [6.56433900e-02, 8.57159440e-01, 7.71971600e-02],\n",
       "       [9.99549900e-01, 4.92358230e-05, 4.00790360e-04],\n",
       "       [9.97324100e-01, 2.30608330e-04, 2.44527150e-03],\n",
       "       [7.22396100e-02, 6.72646460e-01, 2.55113930e-01],\n",
       "       [1.06673455e-02, 9.75452400e-01, 1.38802320e-02],\n",
       "       [9.83665170e-01, 4.02055540e-03, 1.23142380e-02]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob5 = df_proba5[df_proba5['phage']=='p11kpresabsSTCC_qual'].iloc[:,-3:]\n",
    "y_prob5 = y_prob5.to_numpy()\n",
    "y_prob5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9579078244215861"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo5 = rocauc_ovo(y_sel_test_over, y_prob5, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9579078244215861"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr5 = rocauc_ovr(y_sel_test_over, y_prob5, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_sel_train_over, X_sel_test_over, y_sel_train_over, y_sel_test_over = train_test_split(X_sel_over, y_sel_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=678,\n",
    "                                                    stratify=y_sel_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat6 = pd.DataFrame(X_sel_test_over[:,-1])\n",
    "dat6['test'] = y_sel_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GA48963</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SR4187</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS182</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CFBREBSa125</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS188</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>BCH-SA-05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>NRS027</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>CFBREBSa123</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>NRS199</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>Grady1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test\n",
       "0        GA48963     1\n",
       "1         SR4187     2\n",
       "2         NRS182     2\n",
       "3    CFBREBSa125     2\n",
       "4         NRS188     1\n",
       "..           ...   ...\n",
       "158    BCH-SA-05     0\n",
       "159       NRS027     0\n",
       "160  CFBREBSa123     0\n",
       "161       NRS199     2\n",
       "162       Grady1     2\n",
       "\n",
       "[163 rows x 2 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sel_train_over = X_sel_train_over[:,:-1]\n",
    "X_sel_test_over = X_sel_test_over[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2_over2 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_sel_train_over.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2_over2.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 380 samples, validate on 163 samples\n",
      "Epoch 1/100\n",
      "380/380 [==============================] - 0s 565us/step - loss: 12.0476 - accuracy: 0.3684 - val_loss: 5.5739 - val_accuracy: 0.4110\n",
      "Epoch 2/100\n",
      "380/380 [==============================] - 0s 134us/step - loss: 4.4048 - accuracy: 0.4421 - val_loss: 2.3338 - val_accuracy: 0.3313\n",
      "Epoch 3/100\n",
      "380/380 [==============================] - 0s 123us/step - loss: 1.8936 - accuracy: 0.4947 - val_loss: 2.0505 - val_accuracy: 0.3497\n",
      "Epoch 4/100\n",
      "380/380 [==============================] - 0s 138us/step - loss: 1.3604 - accuracy: 0.5711 - val_loss: 1.1203 - val_accuracy: 0.4540\n",
      "Epoch 5/100\n",
      "380/380 [==============================] - 0s 139us/step - loss: 0.9653 - accuracy: 0.6211 - val_loss: 1.1628 - val_accuracy: 0.4356\n",
      "Epoch 6/100\n",
      "380/380 [==============================] - 0s 121us/step - loss: 0.9890 - accuracy: 0.5974 - val_loss: 1.0300 - val_accuracy: 0.4847\n",
      "Epoch 7/100\n",
      "380/380 [==============================] - 0s 161us/step - loss: 0.8952 - accuracy: 0.6289 - val_loss: 1.0574 - val_accuracy: 0.4847\n",
      "Epoch 8/100\n",
      "380/380 [==============================] - 0s 149us/step - loss: 0.8755 - accuracy: 0.6342 - val_loss: 1.0617 - val_accuracy: 0.5153\n",
      "Epoch 9/100\n",
      "380/380 [==============================] - 0s 109us/step - loss: 0.8107 - accuracy: 0.6632 - val_loss: 0.9768 - val_accuracy: 0.5521\n",
      "Epoch 10/100\n",
      "380/380 [==============================] - 0s 134us/step - loss: 0.7521 - accuracy: 0.6868 - val_loss: 0.9411 - val_accuracy: 0.5767\n",
      "Epoch 11/100\n",
      "380/380 [==============================] - 0s 93us/step - loss: 0.7262 - accuracy: 0.7211 - val_loss: 0.8744 - val_accuracy: 0.6012\n",
      "Epoch 12/100\n",
      "380/380 [==============================] - 0s 314us/step - loss: 0.7019 - accuracy: 0.7184 - val_loss: 0.8942 - val_accuracy: 0.5828\n",
      "Epoch 13/100\n",
      "380/380 [==============================] - 0s 144us/step - loss: 0.6970 - accuracy: 0.7132 - val_loss: 0.8392 - val_accuracy: 0.5767\n",
      "Epoch 14/100\n",
      "380/380 [==============================] - 0s 99us/step - loss: 0.6769 - accuracy: 0.7289 - val_loss: 0.8514 - val_accuracy: 0.5767\n",
      "Epoch 15/100\n",
      "380/380 [==============================] - 0s 80us/step - loss: 0.6740 - accuracy: 0.7368 - val_loss: 0.7955 - val_accuracy: 0.6258\n",
      "Epoch 16/100\n",
      "380/380 [==============================] - 0s 348us/step - loss: 0.6072 - accuracy: 0.7553 - val_loss: 0.8680 - val_accuracy: 0.5890\n",
      "Epoch 17/100\n",
      "380/380 [==============================] - 0s 378us/step - loss: 0.6082 - accuracy: 0.7553 - val_loss: 0.7906 - val_accuracy: 0.6564\n",
      "Epoch 18/100\n",
      "380/380 [==============================] - 0s 181us/step - loss: 0.5937 - accuracy: 0.7684 - val_loss: 0.8037 - val_accuracy: 0.6380\n",
      "Epoch 19/100\n",
      "380/380 [==============================] - 0s 215us/step - loss: 0.5648 - accuracy: 0.7789 - val_loss: 0.7506 - val_accuracy: 0.6687\n",
      "Epoch 20/100\n",
      "380/380 [==============================] - 0s 205us/step - loss: 0.5378 - accuracy: 0.7921 - val_loss: 0.7723 - val_accuracy: 0.6564\n",
      "Epoch 21/100\n",
      "380/380 [==============================] - 0s 106us/step - loss: 0.5664 - accuracy: 0.8132 - val_loss: 0.7235 - val_accuracy: 0.6442\n",
      "Epoch 22/100\n",
      "380/380 [==============================] - 0s 116us/step - loss: 0.5266 - accuracy: 0.7763 - val_loss: 0.7079 - val_accuracy: 0.6810\n",
      "Epoch 23/100\n",
      "380/380 [==============================] - 0s 94us/step - loss: 0.5353 - accuracy: 0.8079 - val_loss: 0.7843 - val_accuracy: 0.6442\n",
      "Epoch 24/100\n",
      "380/380 [==============================] - 0s 99us/step - loss: 0.5026 - accuracy: 0.8211 - val_loss: 0.6520 - val_accuracy: 0.7055\n",
      "Epoch 25/100\n",
      "380/380 [==============================] - 0s 130us/step - loss: 0.4730 - accuracy: 0.8184 - val_loss: 0.6840 - val_accuracy: 0.6933\n",
      "Epoch 26/100\n",
      "380/380 [==============================] - 0s 530us/step - loss: 0.4971 - accuracy: 0.8053 - val_loss: 0.6783 - val_accuracy: 0.7362\n",
      "Epoch 27/100\n",
      "380/380 [==============================] - 0s 282us/step - loss: 0.4604 - accuracy: 0.8474 - val_loss: 0.6494 - val_accuracy: 0.6933\n",
      "Epoch 28/100\n",
      "380/380 [==============================] - 0s 131us/step - loss: 0.4942 - accuracy: 0.8158 - val_loss: 0.6500 - val_accuracy: 0.7607\n",
      "Epoch 29/100\n",
      "380/380 [==============================] - 0s 233us/step - loss: 0.4620 - accuracy: 0.8263 - val_loss: 0.6826 - val_accuracy: 0.7178\n",
      "Epoch 30/100\n",
      "380/380 [==============================] - 0s 183us/step - loss: 0.4397 - accuracy: 0.8579 - val_loss: 0.7340 - val_accuracy: 0.7055\n",
      "Epoch 31/100\n",
      "380/380 [==============================] - 0s 176us/step - loss: 0.4498 - accuracy: 0.8316 - val_loss: 0.7086 - val_accuracy: 0.7178\n",
      "Epoch 32/100\n",
      "380/380 [==============================] - 0s 407us/step - loss: 0.4149 - accuracy: 0.8474 - val_loss: 0.6151 - val_accuracy: 0.7485\n",
      "Epoch 33/100\n",
      "380/380 [==============================] - 0s 281us/step - loss: 0.4065 - accuracy: 0.8605 - val_loss: 0.6777 - val_accuracy: 0.7423\n",
      "Epoch 34/100\n",
      "380/380 [==============================] - 0s 221us/step - loss: 0.4617 - accuracy: 0.8368 - val_loss: 0.6067 - val_accuracy: 0.8037\n",
      "Epoch 35/100\n",
      "380/380 [==============================] - 0s 198us/step - loss: 0.4005 - accuracy: 0.8632 - val_loss: 0.6314 - val_accuracy: 0.7485\n",
      "Epoch 36/100\n",
      "380/380 [==============================] - 0s 202us/step - loss: 0.3731 - accuracy: 0.8684 - val_loss: 0.5803 - val_accuracy: 0.7546\n",
      "Epoch 37/100\n",
      "380/380 [==============================] - 0s 142us/step - loss: 0.3574 - accuracy: 0.8632 - val_loss: 0.5940 - val_accuracy: 0.7914\n",
      "Epoch 38/100\n",
      "380/380 [==============================] - 0s 250us/step - loss: 0.3955 - accuracy: 0.8632 - val_loss: 0.7837 - val_accuracy: 0.7178\n",
      "Epoch 39/100\n",
      "380/380 [==============================] - 0s 176us/step - loss: 0.4782 - accuracy: 0.8474 - val_loss: 0.5420 - val_accuracy: 0.7669\n",
      "Epoch 40/100\n",
      "380/380 [==============================] - 0s 203us/step - loss: 0.3572 - accuracy: 0.8711 - val_loss: 0.6410 - val_accuracy: 0.7239\n",
      "Epoch 41/100\n",
      "380/380 [==============================] - 0s 220us/step - loss: 0.3642 - accuracy: 0.8789 - val_loss: 0.6069 - val_accuracy: 0.7301\n",
      "Epoch 42/100\n",
      "380/380 [==============================] - 0s 222us/step - loss: 0.3378 - accuracy: 0.8763 - val_loss: 0.5828 - val_accuracy: 0.7546\n",
      "Epoch 43/100\n",
      "380/380 [==============================] - 0s 169us/step - loss: 0.3365 - accuracy: 0.8737 - val_loss: 0.6335 - val_accuracy: 0.7423\n",
      "Epoch 44/100\n",
      "380/380 [==============================] - 0s 89us/step - loss: 0.3320 - accuracy: 0.8895 - val_loss: 0.5602 - val_accuracy: 0.7669\n",
      "Epoch 45/100\n",
      "380/380 [==============================] - 0s 122us/step - loss: 0.3592 - accuracy: 0.8579 - val_loss: 0.6614 - val_accuracy: 0.7607\n",
      "Epoch 46/100\n",
      "380/380 [==============================] - 0s 178us/step - loss: 0.3527 - accuracy: 0.8816 - val_loss: 0.5239 - val_accuracy: 0.8160\n",
      "Epoch 47/100\n",
      "380/380 [==============================] - 0s 174us/step - loss: 0.3157 - accuracy: 0.9026 - val_loss: 0.6105 - val_accuracy: 0.7546\n",
      "Epoch 48/100\n",
      "380/380 [==============================] - 0s 119us/step - loss: 0.2921 - accuracy: 0.9000 - val_loss: 0.5636 - val_accuracy: 0.7975\n",
      "Epoch 49/100\n",
      "380/380 [==============================] - 0s 125us/step - loss: 0.3255 - accuracy: 0.8763 - val_loss: 0.6183 - val_accuracy: 0.7975\n",
      "Epoch 50/100\n",
      "380/380 [==============================] - 0s 131us/step - loss: 0.4449 - accuracy: 0.8658 - val_loss: 0.5691 - val_accuracy: 0.7423\n",
      "Epoch 51/100\n",
      "380/380 [==============================] - 0s 107us/step - loss: 0.3154 - accuracy: 0.8684 - val_loss: 0.6500 - val_accuracy: 0.7669\n",
      "Epoch 52/100\n",
      "380/380 [==============================] - 0s 117us/step - loss: 0.3057 - accuracy: 0.8947 - val_loss: 0.5881 - val_accuracy: 0.7730\n",
      "Epoch 53/100\n",
      "380/380 [==============================] - 0s 79us/step - loss: 0.3182 - accuracy: 0.9026 - val_loss: 0.5439 - val_accuracy: 0.7853\n",
      "Epoch 54/100\n",
      "380/380 [==============================] - 0s 77us/step - loss: 0.2832 - accuracy: 0.9053 - val_loss: 0.5487 - val_accuracy: 0.7791\n",
      "Epoch 55/100\n",
      "380/380 [==============================] - 0s 75us/step - loss: 0.2653 - accuracy: 0.9132 - val_loss: 0.5560 - val_accuracy: 0.7730\n",
      "Epoch 56/100\n",
      "380/380 [==============================] - 0s 75us/step - loss: 0.3236 - accuracy: 0.8921 - val_loss: 0.5537 - val_accuracy: 0.8098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "380/380 [==============================] - 0s 84us/step - loss: 0.2759 - accuracy: 0.9053 - val_loss: 0.6002 - val_accuracy: 0.7791\n",
      "Epoch 58/100\n",
      "380/380 [==============================] - 0s 92us/step - loss: 0.2944 - accuracy: 0.9053 - val_loss: 0.5312 - val_accuracy: 0.7853\n",
      "Epoch 59/100\n",
      "380/380 [==============================] - 0s 223us/step - loss: 0.2995 - accuracy: 0.8921 - val_loss: 0.5412 - val_accuracy: 0.8282\n",
      "Epoch 60/100\n",
      "380/380 [==============================] - 0s 198us/step - loss: 0.2573 - accuracy: 0.9053 - val_loss: 0.5343 - val_accuracy: 0.8160\n",
      "Epoch 61/100\n",
      "380/380 [==============================] - 0s 129us/step - loss: 0.2616 - accuracy: 0.9053 - val_loss: 0.5499 - val_accuracy: 0.8221\n",
      "Epoch 62/100\n",
      "380/380 [==============================] - 0s 127us/step - loss: 0.2750 - accuracy: 0.9079 - val_loss: 0.5197 - val_accuracy: 0.7975\n",
      "Epoch 63/100\n",
      "380/380 [==============================] - 0s 112us/step - loss: 0.2434 - accuracy: 0.9184 - val_loss: 0.5277 - val_accuracy: 0.8282\n",
      "Epoch 64/100\n",
      "380/380 [==============================] - 0s 82us/step - loss: 0.2605 - accuracy: 0.9079 - val_loss: 0.5351 - val_accuracy: 0.8160\n",
      "Epoch 65/100\n",
      "380/380 [==============================] - 0s 82us/step - loss: 0.2769 - accuracy: 0.8895 - val_loss: 0.5458 - val_accuracy: 0.8160\n",
      "Epoch 66/100\n",
      "380/380 [==============================] - 0s 71us/step - loss: 0.2292 - accuracy: 0.9211 - val_loss: 0.5440 - val_accuracy: 0.7853\n",
      "Epoch 67/100\n",
      "380/380 [==============================] - 0s 87us/step - loss: 0.2371 - accuracy: 0.9184 - val_loss: 0.5248 - val_accuracy: 0.8344\n",
      "Epoch 68/100\n",
      "380/380 [==============================] - 0s 70us/step - loss: 0.2456 - accuracy: 0.9237 - val_loss: 0.5275 - val_accuracy: 0.8405\n",
      "Epoch 69/100\n",
      "380/380 [==============================] - 0s 78us/step - loss: 0.2578 - accuracy: 0.9132 - val_loss: 0.5537 - val_accuracy: 0.7914\n",
      "Epoch 70/100\n",
      "380/380 [==============================] - 0s 87us/step - loss: 0.2269 - accuracy: 0.9158 - val_loss: 0.5437 - val_accuracy: 0.8405\n",
      "Epoch 71/100\n",
      "380/380 [==============================] - 0s 102us/step - loss: 0.2229 - accuracy: 0.9211 - val_loss: 0.5764 - val_accuracy: 0.7730\n",
      "Epoch 72/100\n",
      "380/380 [==============================] - 0s 135us/step - loss: 0.2416 - accuracy: 0.9184 - val_loss: 0.5227 - val_accuracy: 0.8528\n",
      "Epoch 73/100\n",
      "380/380 [==============================] - 0s 121us/step - loss: 0.2300 - accuracy: 0.9237 - val_loss: 0.5528 - val_accuracy: 0.7975\n",
      "Epoch 74/100\n",
      "380/380 [==============================] - 0s 115us/step - loss: 0.2249 - accuracy: 0.9158 - val_loss: 0.5135 - val_accuracy: 0.8405\n",
      "Epoch 75/100\n",
      "380/380 [==============================] - 0s 133us/step - loss: 0.2817 - accuracy: 0.9211 - val_loss: 0.5539 - val_accuracy: 0.8221\n",
      "Epoch 76/100\n",
      "380/380 [==============================] - 0s 106us/step - loss: 0.2334 - accuracy: 0.9158 - val_loss: 0.5690 - val_accuracy: 0.8589\n",
      "Epoch 77/100\n",
      "380/380 [==============================] - 0s 110us/step - loss: 0.2472 - accuracy: 0.9211 - val_loss: 0.5490 - val_accuracy: 0.8160\n",
      "Epoch 78/100\n",
      "380/380 [==============================] - 0s 91us/step - loss: 0.2238 - accuracy: 0.9211 - val_loss: 0.5807 - val_accuracy: 0.8589\n",
      "Epoch 79/100\n",
      "380/380 [==============================] - 0s 110us/step - loss: 0.2637 - accuracy: 0.9184 - val_loss: 0.5145 - val_accuracy: 0.8650\n",
      "Epoch 80/100\n",
      "380/380 [==============================] - 0s 98us/step - loss: 0.2101 - accuracy: 0.9368 - val_loss: 0.5863 - val_accuracy: 0.8528\n",
      "Epoch 81/100\n",
      "380/380 [==============================] - 0s 133us/step - loss: 0.2526 - accuracy: 0.9316 - val_loss: 0.5228 - val_accuracy: 0.8589\n",
      "Epoch 82/100\n",
      "380/380 [==============================] - 0s 118us/step - loss: 0.2774 - accuracy: 0.9105 - val_loss: 0.6425 - val_accuracy: 0.8344\n",
      "Epoch 83/100\n",
      "380/380 [==============================] - 0s 89us/step - loss: 0.3320 - accuracy: 0.9158 - val_loss: 0.5901 - val_accuracy: 0.8282\n",
      "Epoch 84/100\n",
      "380/380 [==============================] - 0s 73us/step - loss: 0.2707 - accuracy: 0.9237 - val_loss: 0.5646 - val_accuracy: 0.8589\n",
      "Epoch 85/100\n",
      "380/380 [==============================] - 0s 92us/step - loss: 0.3040 - accuracy: 0.9263 - val_loss: 0.5208 - val_accuracy: 0.8650\n",
      "Epoch 86/100\n",
      "380/380 [==============================] - 0s 71us/step - loss: 0.2154 - accuracy: 0.9289 - val_loss: 0.6276 - val_accuracy: 0.8221\n",
      "Epoch 87/100\n",
      "380/380 [==============================] - 0s 74us/step - loss: 0.2284 - accuracy: 0.9368 - val_loss: 0.5247 - val_accuracy: 0.8528\n",
      "Epoch 88/100\n",
      "380/380 [==============================] - 0s 81us/step - loss: 0.2600 - accuracy: 0.9105 - val_loss: 0.6112 - val_accuracy: 0.8221\n",
      "Epoch 89/100\n",
      "380/380 [==============================] - 0s 83us/step - loss: 0.3116 - accuracy: 0.9237 - val_loss: 0.5599 - val_accuracy: 0.8160\n",
      "Epoch 90/100\n",
      "380/380 [==============================] - 0s 91us/step - loss: 0.1999 - accuracy: 0.9237 - val_loss: 0.5141 - val_accuracy: 0.8773\n",
      "Epoch 91/100\n",
      "380/380 [==============================] - 0s 79us/step - loss: 0.2241 - accuracy: 0.9368 - val_loss: 0.6284 - val_accuracy: 0.7853\n",
      "Epoch 92/100\n",
      "380/380 [==============================] - 0s 74us/step - loss: 0.2696 - accuracy: 0.9237 - val_loss: 0.5335 - val_accuracy: 0.8712\n",
      "Epoch 93/100\n",
      "380/380 [==============================] - 0s 82us/step - loss: 0.1988 - accuracy: 0.9368 - val_loss: 0.5504 - val_accuracy: 0.8773\n",
      "Epoch 94/100\n",
      "380/380 [==============================] - 0s 75us/step - loss: 0.2450 - accuracy: 0.9368 - val_loss: 0.5341 - val_accuracy: 0.8405\n",
      "Epoch 95/100\n",
      "380/380 [==============================] - 0s 103us/step - loss: 0.2453 - accuracy: 0.9184 - val_loss: 0.5466 - val_accuracy: 0.8528\n",
      "Epoch 96/100\n",
      "380/380 [==============================] - 0s 73us/step - loss: 0.2095 - accuracy: 0.9395 - val_loss: 0.6127 - val_accuracy: 0.8160\n",
      "Epoch 97/100\n",
      "380/380 [==============================] - 0s 84us/step - loss: 0.3272 - accuracy: 0.9105 - val_loss: 0.7178 - val_accuracy: 0.8098\n",
      "Epoch 98/100\n",
      "380/380 [==============================] - 0s 102us/step - loss: 0.3891 - accuracy: 0.9053 - val_loss: 0.5772 - val_accuracy: 0.8098\n",
      "Epoch 99/100\n",
      "380/380 [==============================] - 0s 132us/step - loss: 0.2142 - accuracy: 0.9132 - val_loss: 0.5453 - val_accuracy: 0.8344\n",
      "Epoch 100/100\n",
      "380/380 [==============================] - 0s 87us/step - loss: 0.1882 - accuracy: 0.9421 - val_loss: 0.5987 - val_accuracy: 0.8589\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a36dc90f0>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2_over2.fit(X_sel_train_over, y_sel_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_sel_test_over, y_sel_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163/163 [==============================] - 0s 55us/step\n",
      "over-sampling test accuracy: 83.44%\n"
     ]
    }
   ],
   "source": [
    "acc_test2_over2 = model2_over2.evaluate(X_sel_test_over, y_sel_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test2_over2*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 1, 0, 0, 1, 1, 2, 1, 0, 2, 0, 0, 1, 0, 2, 2, 2, 1, 2, 1,\n",
       "       0, 1, 1, 2, 0, 2, 0, 2, 0, 0, 0, 0, 1, 1, 0, 2, 1, 0, 1, 1, 1, 0,\n",
       "       2, 2, 2, 2, 0, 1, 2, 2, 2, 0, 0, 0, 1, 2, 0, 0, 1, 1, 2, 1, 0, 1,\n",
       "       2, 2, 0, 0, 2, 1, 1, 1, 1, 2, 2, 1, 0, 1, 1, 1, 2, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 2, 2, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1,\n",
       "       2, 2, 2, 2, 0, 0, 0, 0, 1, 0, 1, 0, 2, 0, 2, 0, 0, 1, 2, 1, 0, 1,\n",
       "       0, 1, 2, 2, 2, 0, 2, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 2, 0, 0,\n",
       "       2, 1, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred6 = model2_over2.predict_classes(X_sel_test_over)\n",
    "pred6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GA48963</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SR4187</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS182</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CFBREBSa125</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS188</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>BCH-SA-05</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>NRS027</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>CFBREBSa123</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>NRS199</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>Grady1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test  pred\n",
       "0        GA48963     1     1\n",
       "1         SR4187     2     0\n",
       "2         NRS182     2     2\n",
       "3    CFBREBSa125     2     1\n",
       "4         NRS188     1     0\n",
       "..           ...   ...   ...\n",
       "158    BCH-SA-05     0     0\n",
       "159       NRS027     0     0\n",
       "160  CFBREBSa123     0     0\n",
       "161       NRS199     2     0\n",
       "162       Grady1     2     0\n",
       "\n",
       "[163 rows x 3 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat6['pred'] = pred6\n",
    "dat6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba6 = model2_over2.predict_proba(X_sel_test_over)\n",
    "dat_proba6 = pd.DataFrame(proba6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000472</td>\n",
       "      <td>9.793897e-01</td>\n",
       "      <td>2.013863e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.588559e-09</td>\n",
       "      <td>3.666089e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.012329</td>\n",
       "      <td>3.610478e-03</td>\n",
       "      <td>9.840609e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.344447</td>\n",
       "      <td>5.116983e-01</td>\n",
       "      <td>1.438548e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.731556</td>\n",
       "      <td>1.455345e-01</td>\n",
       "      <td>1.229093e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>0.999211</td>\n",
       "      <td>1.880544e-04</td>\n",
       "      <td>6.010687e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>0.999506</td>\n",
       "      <td>2.402587e-04</td>\n",
       "      <td>2.541915e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>0.996627</td>\n",
       "      <td>2.101521e-04</td>\n",
       "      <td>3.162904e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>0.583259</td>\n",
       "      <td>9.557659e-02</td>\n",
       "      <td>3.211643e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>0.957326</td>\n",
       "      <td>1.463309e-02</td>\n",
       "      <td>2.804076e-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0             1             2\n",
       "0    0.000472  9.793897e-01  2.013863e-02\n",
       "1    1.000000  4.588559e-09  3.666089e-07\n",
       "2    0.012329  3.610478e-03  9.840609e-01\n",
       "3    0.344447  5.116983e-01  1.438548e-01\n",
       "4    0.731556  1.455345e-01  1.229093e-01\n",
       "..        ...           ...           ...\n",
       "158  0.999211  1.880544e-04  6.010687e-04\n",
       "159  0.999506  2.402587e-04  2.541915e-04\n",
       "160  0.996627  2.101521e-04  3.162904e-03\n",
       "161  0.583259  9.557659e-02  3.211643e-01\n",
       "162  0.957326  1.463309e-02  2.804076e-02\n",
       "\n",
       "[163 rows x 3 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba6.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba6.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat6.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/6p11ST.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 380 samples, validate on 163 samples\n",
      "Epoch 1/100\n",
      "380/380 [==============================] - 0s 106us/step - loss: 0.3571 - accuracy: 0.9211 - val_loss: 0.4232 - val_accuracy: 0.8589\n",
      "Epoch 2/100\n",
      "380/380 [==============================] - 0s 112us/step - loss: 0.2782 - accuracy: 0.9395 - val_loss: 0.4491 - val_accuracy: 0.8650\n",
      "Epoch 3/100\n",
      "380/380 [==============================] - 0s 117us/step - loss: 0.1729 - accuracy: 0.9500 - val_loss: 0.4353 - val_accuracy: 0.8589\n",
      "Epoch 4/100\n",
      "380/380 [==============================] - 0s 102us/step - loss: 0.2118 - accuracy: 0.9342 - val_loss: 0.4196 - val_accuracy: 0.8834\n",
      "Epoch 5/100\n",
      "380/380 [==============================] - 0s 87us/step - loss: 0.2942 - accuracy: 0.9132 - val_loss: 0.5261 - val_accuracy: 0.8466\n",
      "Epoch 6/100\n",
      "380/380 [==============================] - 0s 89us/step - loss: 0.2182 - accuracy: 0.9184 - val_loss: 0.4378 - val_accuracy: 0.8344\n",
      "Epoch 7/100\n",
      "380/380 [==============================] - 0s 89us/step - loss: 0.1885 - accuracy: 0.9395 - val_loss: 0.4335 - val_accuracy: 0.8650\n",
      "Epoch 8/100\n",
      "380/380 [==============================] - 0s 89us/step - loss: 0.2122 - accuracy: 0.9421 - val_loss: 0.4786 - val_accuracy: 0.8528\n",
      "Epoch 9/100\n",
      "380/380 [==============================] - 0s 88us/step - loss: 0.1858 - accuracy: 0.9526 - val_loss: 0.4140 - val_accuracy: 0.8773\n",
      "Epoch 10/100\n",
      "380/380 [==============================] - 0s 89us/step - loss: 0.1713 - accuracy: 0.9500 - val_loss: 0.4786 - val_accuracy: 0.8589\n",
      "Epoch 11/100\n",
      "380/380 [==============================] - 0s 86us/step - loss: 0.2079 - accuracy: 0.9421 - val_loss: 0.6904 - val_accuracy: 0.7853\n",
      "Epoch 12/100\n",
      "380/380 [==============================] - 0s 87us/step - loss: 0.2165 - accuracy: 0.9237 - val_loss: 0.4735 - val_accuracy: 0.8528\n",
      "Epoch 13/100\n",
      "380/380 [==============================] - 0s 111us/step - loss: 0.2041 - accuracy: 0.9342 - val_loss: 0.6233 - val_accuracy: 0.8160\n",
      "Epoch 14/100\n",
      "380/380 [==============================] - 0s 84us/step - loss: 0.2648 - accuracy: 0.9316 - val_loss: 0.7427 - val_accuracy: 0.8466\n",
      "Epoch 15/100\n",
      "380/380 [==============================] - 0s 90us/step - loss: 0.3001 - accuracy: 0.9289 - val_loss: 0.5856 - val_accuracy: 0.7914\n",
      "Epoch 16/100\n",
      "380/380 [==============================] - 0s 87us/step - loss: 0.2815 - accuracy: 0.9132 - val_loss: 0.5829 - val_accuracy: 0.8834\n",
      "Epoch 17/100\n",
      "380/380 [==============================] - 0s 84us/step - loss: 0.3667 - accuracy: 0.9421 - val_loss: 0.4886 - val_accuracy: 0.8466\n",
      "Epoch 18/100\n",
      "380/380 [==============================] - 0s 91us/step - loss: 0.2080 - accuracy: 0.9211 - val_loss: 0.4478 - val_accuracy: 0.8712\n",
      "Epoch 19/100\n",
      "380/380 [==============================] - 0s 95us/step - loss: 0.2077 - accuracy: 0.9474 - val_loss: 0.4780 - val_accuracy: 0.8650\n",
      "Epoch 20/100\n",
      "380/380 [==============================] - 0s 92us/step - loss: 0.1644 - accuracy: 0.9421 - val_loss: 0.4307 - val_accuracy: 0.8282\n",
      "Epoch 21/100\n",
      "380/380 [==============================] - 0s 88us/step - loss: 0.1886 - accuracy: 0.9474 - val_loss: 0.4763 - val_accuracy: 0.8589\n",
      "Epoch 22/100\n",
      "380/380 [==============================] - 0s 87us/step - loss: 0.3230 - accuracy: 0.9342 - val_loss: 0.5393 - val_accuracy: 0.8834\n",
      "Epoch 23/100\n",
      "380/380 [==============================] - 0s 94us/step - loss: 0.2542 - accuracy: 0.9316 - val_loss: 0.4580 - val_accuracy: 0.8405\n",
      "Epoch 24/100\n",
      "380/380 [==============================] - 0s 86us/step - loss: 0.2011 - accuracy: 0.9421 - val_loss: 0.4446 - val_accuracy: 0.8834\n",
      "Epoch 25/100\n",
      "380/380 [==============================] - 0s 94us/step - loss: 0.1875 - accuracy: 0.9421 - val_loss: 0.5367 - val_accuracy: 0.8466\n",
      "Epoch 26/100\n",
      "380/380 [==============================] - 0s 90us/step - loss: 0.2137 - accuracy: 0.9368 - val_loss: 0.4169 - val_accuracy: 0.8834\n",
      "Epoch 27/100\n",
      "380/380 [==============================] - 0s 87us/step - loss: 0.2077 - accuracy: 0.9553 - val_loss: 0.4826 - val_accuracy: 0.8344\n",
      "Epoch 28/100\n",
      "380/380 [==============================] - 0s 89us/step - loss: 0.1739 - accuracy: 0.9368 - val_loss: 0.4874 - val_accuracy: 0.8528\n",
      "Epoch 29/100\n",
      "380/380 [==============================] - 0s 94us/step - loss: 0.2149 - accuracy: 0.9474 - val_loss: 0.4040 - val_accuracy: 0.8712\n",
      "Epoch 30/100\n",
      "380/380 [==============================] - 0s 86us/step - loss: 0.2364 - accuracy: 0.9474 - val_loss: 0.4136 - val_accuracy: 0.8589\n",
      "Epoch 31/100\n",
      "380/380 [==============================] - 0s 110us/step - loss: 0.2971 - accuracy: 0.9368 - val_loss: 0.5203 - val_accuracy: 0.8528\n",
      "Epoch 32/100\n",
      "380/380 [==============================] - 0s 111us/step - loss: 0.2659 - accuracy: 0.9316 - val_loss: 0.5797 - val_accuracy: 0.8160\n",
      "Epoch 33/100\n",
      "380/380 [==============================] - 0s 135us/step - loss: 0.2223 - accuracy: 0.9184 - val_loss: 0.4623 - val_accuracy: 0.8589\n",
      "Epoch 34/100\n",
      "380/380 [==============================] - 0s 108us/step - loss: 0.1900 - accuracy: 0.9500 - val_loss: 0.5745 - val_accuracy: 0.8528\n",
      "Epoch 35/100\n",
      "380/380 [==============================] - 0s 113us/step - loss: 0.4179 - accuracy: 0.9237 - val_loss: 0.5953 - val_accuracy: 0.8773\n",
      "Epoch 36/100\n",
      "380/380 [==============================] - 0s 109us/step - loss: 0.5880 - accuracy: 0.8921 - val_loss: 1.9420 - val_accuracy: 0.8160\n",
      "Epoch 37/100\n",
      "380/380 [==============================] - 0s 124us/step - loss: 0.5870 - accuracy: 0.9184 - val_loss: 0.6596 - val_accuracy: 0.7914\n",
      "Epoch 38/100\n",
      "380/380 [==============================] - 0s 129us/step - loss: 0.3756 - accuracy: 0.9000 - val_loss: 0.6799 - val_accuracy: 0.8221\n",
      "Epoch 39/100\n",
      "380/380 [==============================] - 0s 120us/step - loss: 0.2540 - accuracy: 0.9263 - val_loss: 0.9543 - val_accuracy: 0.8221\n",
      "Epoch 40/100\n",
      "380/380 [==============================] - 0s 107us/step - loss: 0.3328 - accuracy: 0.9105 - val_loss: 0.5683 - val_accuracy: 0.8405\n",
      "Epoch 41/100\n",
      "380/380 [==============================] - 0s 140us/step - loss: 0.2313 - accuracy: 0.9211 - val_loss: 0.4647 - val_accuracy: 0.8589\n",
      "Epoch 42/100\n",
      "380/380 [==============================] - 0s 157us/step - loss: 0.1919 - accuracy: 0.9421 - val_loss: 0.6742 - val_accuracy: 0.8160\n",
      "Epoch 43/100\n",
      "380/380 [==============================] - 0s 162us/step - loss: 0.2209 - accuracy: 0.9342 - val_loss: 0.5338 - val_accuracy: 0.8221\n",
      "Epoch 44/100\n",
      "380/380 [==============================] - 0s 142us/step - loss: 0.1877 - accuracy: 0.9447 - val_loss: 0.4995 - val_accuracy: 0.8773\n",
      "Epoch 45/100\n",
      "380/380 [==============================] - 0s 139us/step - loss: 0.1490 - accuracy: 0.9605 - val_loss: 0.4112 - val_accuracy: 0.8712\n",
      "Epoch 46/100\n",
      "380/380 [==============================] - 0s 142us/step - loss: 0.1666 - accuracy: 0.9447 - val_loss: 0.4649 - val_accuracy: 0.8834\n",
      "Epoch 47/100\n",
      "380/380 [==============================] - 0s 129us/step - loss: 0.1892 - accuracy: 0.9526 - val_loss: 0.3936 - val_accuracy: 0.8712\n",
      "Epoch 48/100\n",
      "380/380 [==============================] - 0s 139us/step - loss: 0.1707 - accuracy: 0.9316 - val_loss: 0.4437 - val_accuracy: 0.8589\n",
      "Epoch 49/100\n",
      "380/380 [==============================] - 0s 142us/step - loss: 0.1615 - accuracy: 0.9553 - val_loss: 0.4611 - val_accuracy: 0.8528\n",
      "Epoch 50/100\n",
      "380/380 [==============================] - 0s 162us/step - loss: 0.1766 - accuracy: 0.9579 - val_loss: 0.4689 - val_accuracy: 0.8712\n",
      "Epoch 51/100\n",
      "380/380 [==============================] - 0s 125us/step - loss: 0.1572 - accuracy: 0.9579 - val_loss: 0.4154 - val_accuracy: 0.8773\n",
      "Epoch 52/100\n",
      "380/380 [==============================] - 0s 142us/step - loss: 0.2534 - accuracy: 0.9447 - val_loss: 0.4910 - val_accuracy: 0.8773\n",
      "Epoch 53/100\n",
      "380/380 [==============================] - 0s 137us/step - loss: 0.2137 - accuracy: 0.9500 - val_loss: 0.4717 - val_accuracy: 0.8528\n",
      "Epoch 54/100\n",
      "380/380 [==============================] - 0s 138us/step - loss: 0.2246 - accuracy: 0.9421 - val_loss: 0.5549 - val_accuracy: 0.8650\n",
      "Epoch 55/100\n",
      "380/380 [==============================] - 0s 120us/step - loss: 0.1913 - accuracy: 0.9368 - val_loss: 0.5760 - val_accuracy: 0.8773\n",
      "Epoch 56/100\n",
      "380/380 [==============================] - 0s 164us/step - loss: 0.2610 - accuracy: 0.9526 - val_loss: 0.4171 - val_accuracy: 0.8528\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "380/380 [==============================] - 0s 195us/step - loss: 0.1497 - accuracy: 0.9579 - val_loss: 0.4302 - val_accuracy: 0.9080\n",
      "Epoch 58/100\n",
      "380/380 [==============================] - 0s 151us/step - loss: 0.1843 - accuracy: 0.9500 - val_loss: 0.8116 - val_accuracy: 0.8221\n",
      "Epoch 59/100\n",
      "380/380 [==============================] - 0s 123us/step - loss: 0.1892 - accuracy: 0.9395 - val_loss: 0.4385 - val_accuracy: 0.8405\n",
      "Epoch 60/100\n",
      "380/380 [==============================] - 0s 112us/step - loss: 0.2182 - accuracy: 0.9500 - val_loss: 0.5026 - val_accuracy: 0.8650\n",
      "Epoch 61/100\n",
      "380/380 [==============================] - 0s 100us/step - loss: 0.1418 - accuracy: 0.9526 - val_loss: 0.4364 - val_accuracy: 0.8650\n",
      "Epoch 62/100\n",
      "380/380 [==============================] - 0s 91us/step - loss: 0.1925 - accuracy: 0.9447 - val_loss: 0.4638 - val_accuracy: 0.9018\n",
      "Epoch 63/100\n",
      "380/380 [==============================] - 0s 81us/step - loss: 0.1629 - accuracy: 0.9526 - val_loss: 0.6035 - val_accuracy: 0.8528\n",
      "Epoch 64/100\n",
      "380/380 [==============================] - 0s 80us/step - loss: 0.1690 - accuracy: 0.9500 - val_loss: 0.5361 - val_accuracy: 0.8712\n",
      "Epoch 65/100\n",
      "380/380 [==============================] - 0s 81us/step - loss: 0.2311 - accuracy: 0.9395 - val_loss: 0.6209 - val_accuracy: 0.8098\n",
      "Epoch 66/100\n",
      "380/380 [==============================] - 0s 82us/step - loss: 0.1675 - accuracy: 0.9579 - val_loss: 0.4447 - val_accuracy: 0.8896\n",
      "Epoch 67/100\n",
      "380/380 [==============================] - 0s 81us/step - loss: 0.1779 - accuracy: 0.9579 - val_loss: 0.3909 - val_accuracy: 0.9141\n",
      "Epoch 68/100\n",
      "380/380 [==============================] - 0s 84us/step - loss: 0.1401 - accuracy: 0.9526 - val_loss: 0.4570 - val_accuracy: 0.8834\n",
      "Epoch 69/100\n",
      "380/380 [==============================] - 0s 83us/step - loss: 0.1572 - accuracy: 0.9632 - val_loss: 0.3968 - val_accuracy: 0.8957\n",
      "Epoch 70/100\n",
      "380/380 [==============================] - 0s 78us/step - loss: 0.2633 - accuracy: 0.9342 - val_loss: 0.4848 - val_accuracy: 0.9018\n",
      "Epoch 71/100\n",
      "380/380 [==============================] - 0s 79us/step - loss: 0.2145 - accuracy: 0.9316 - val_loss: 0.8446 - val_accuracy: 0.8405\n",
      "Epoch 72/100\n",
      "380/380 [==============================] - 0s 80us/step - loss: 0.2376 - accuracy: 0.9474 - val_loss: 0.5472 - val_accuracy: 0.8589\n",
      "Epoch 73/100\n",
      "380/380 [==============================] - 0s 84us/step - loss: 0.1814 - accuracy: 0.9368 - val_loss: 0.5011 - val_accuracy: 0.8834\n",
      "Epoch 74/100\n",
      "380/380 [==============================] - 0s 135us/step - loss: 0.2025 - accuracy: 0.9658 - val_loss: 0.4500 - val_accuracy: 0.8712\n",
      "Epoch 75/100\n",
      "380/380 [==============================] - 0s 304us/step - loss: 0.1488 - accuracy: 0.9500 - val_loss: 0.4974 - val_accuracy: 0.8344\n",
      "Epoch 76/100\n",
      "380/380 [==============================] - 0s 156us/step - loss: 0.3003 - accuracy: 0.9447 - val_loss: 0.5456 - val_accuracy: 0.8466\n",
      "Epoch 77/100\n",
      "380/380 [==============================] - 0s 131us/step - loss: 0.2497 - accuracy: 0.9474 - val_loss: 0.4672 - val_accuracy: 0.9018\n",
      "Epoch 78/100\n",
      "380/380 [==============================] - 0s 137us/step - loss: 0.2037 - accuracy: 0.9579 - val_loss: 0.4072 - val_accuracy: 0.8712\n",
      "Epoch 79/100\n",
      "380/380 [==============================] - 0s 137us/step - loss: 0.1310 - accuracy: 0.9605 - val_loss: 0.5162 - val_accuracy: 0.8650\n",
      "Epoch 80/100\n",
      "380/380 [==============================] - 0s 131us/step - loss: 0.1644 - accuracy: 0.9500 - val_loss: 0.4339 - val_accuracy: 0.8834\n",
      "Epoch 81/100\n",
      "380/380 [==============================] - 0s 125us/step - loss: 0.2449 - accuracy: 0.9500 - val_loss: 0.4458 - val_accuracy: 0.9018\n",
      "Epoch 82/100\n",
      "380/380 [==============================] - 0s 149us/step - loss: 0.1330 - accuracy: 0.9579 - val_loss: 0.6028 - val_accuracy: 0.8405\n",
      "Epoch 83/100\n",
      "380/380 [==============================] - 0s 520us/step - loss: 0.3290 - accuracy: 0.9263 - val_loss: 0.5133 - val_accuracy: 0.8773\n",
      "Epoch 84/100\n",
      "380/380 [==============================] - 0s 155us/step - loss: 0.1887 - accuracy: 0.9316 - val_loss: 0.6398 - val_accuracy: 0.8589\n",
      "Epoch 85/100\n",
      "380/380 [==============================] - 0s 163us/step - loss: 0.1881 - accuracy: 0.9553 - val_loss: 0.4093 - val_accuracy: 0.8712\n",
      "Epoch 86/100\n",
      "380/380 [==============================] - 0s 224us/step - loss: 0.1642 - accuracy: 0.9500 - val_loss: 0.6576 - val_accuracy: 0.8773\n",
      "Epoch 87/100\n",
      "380/380 [==============================] - 0s 131us/step - loss: 0.2804 - accuracy: 0.9526 - val_loss: 0.4854 - val_accuracy: 0.8589\n",
      "Epoch 88/100\n",
      "380/380 [==============================] - 0s 103us/step - loss: 0.1464 - accuracy: 0.9447 - val_loss: 0.4570 - val_accuracy: 0.8957\n",
      "Epoch 89/100\n",
      "380/380 [==============================] - 0s 91us/step - loss: 0.1581 - accuracy: 0.9658 - val_loss: 0.4217 - val_accuracy: 0.8957\n",
      "Epoch 90/100\n",
      "380/380 [==============================] - 0s 90us/step - loss: 0.2025 - accuracy: 0.9526 - val_loss: 0.4390 - val_accuracy: 0.8957\n",
      "Epoch 91/100\n",
      "380/380 [==============================] - 0s 89us/step - loss: 0.1336 - accuracy: 0.9553 - val_loss: 0.4678 - val_accuracy: 0.8773\n",
      "Epoch 92/100\n",
      "380/380 [==============================] - 0s 104us/step - loss: 0.1374 - accuracy: 0.9579 - val_loss: 0.4681 - val_accuracy: 0.9080\n",
      "Epoch 93/100\n",
      "380/380 [==============================] - 0s 143us/step - loss: 0.1729 - accuracy: 0.9684 - val_loss: 0.4122 - val_accuracy: 0.9018\n",
      "Epoch 94/100\n",
      "380/380 [==============================] - 0s 140us/step - loss: 0.1233 - accuracy: 0.9632 - val_loss: 0.4543 - val_accuracy: 0.9018\n",
      "Epoch 95/100\n",
      "380/380 [==============================] - 0s 114us/step - loss: 0.1698 - accuracy: 0.9579 - val_loss: 0.4522 - val_accuracy: 0.8957\n",
      "Epoch 96/100\n",
      "380/380 [==============================] - 0s 109us/step - loss: 0.1874 - accuracy: 0.9579 - val_loss: 0.4209 - val_accuracy: 0.8834\n",
      "Epoch 97/100\n",
      "380/380 [==============================] - 0s 99us/step - loss: 0.1698 - accuracy: 0.9605 - val_loss: 0.7678 - val_accuracy: 0.8405\n",
      "Epoch 98/100\n",
      "380/380 [==============================] - 0s 107us/step - loss: 0.1751 - accuracy: 0.9579 - val_loss: 0.4274 - val_accuracy: 0.8896\n",
      "Epoch 99/100\n",
      "380/380 [==============================] - 0s 83us/step - loss: 0.1768 - accuracy: 0.9474 - val_loss: 0.5906 - val_accuracy: 0.8834\n",
      "Epoch 100/100\n",
      "380/380 [==============================] - 0s 93us/step - loss: 0.2083 - accuracy: 0.9526 - val_loss: 0.5880 - val_accuracy: 0.8712\n"
     ]
    }
   ],
   "source": [
    "hist2_over2 = model2_over2.fit(X_sel_train_over, y_sel_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_sel_test_over, y_sel_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 94.31%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist2_over2.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba6 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_lasso_2.xlsx\",\n",
    "                        sheet_name=1,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>NRS249</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.888869e-01</td>\n",
       "      <td>5.108038e-01</td>\n",
       "      <td>3.003094e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>NRS188</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.888869e-01</td>\n",
       "      <td>5.108038e-01</td>\n",
       "      <td>3.003094e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>NRS232</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4.222906e-01</td>\n",
       "      <td>7.029924e-02</td>\n",
       "      <td>5.074101e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>NY439</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.558408e-04</td>\n",
       "      <td>2.976018e-04</td>\n",
       "      <td>9.993465e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>GA27</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.940971e-01</td>\n",
       "      <td>4.184215e-01</td>\n",
       "      <td>1.874814e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>NRS252</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.239556e-01</td>\n",
       "      <td>2.760444e-01</td>\n",
       "      <td>1.176030e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>SR2852</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.052276e-07</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>1.101559e-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>NRS108</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.540350e-17</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.011977e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>NRS202</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.888959e-01</td>\n",
       "      <td>3.111042e-01</td>\n",
       "      <td>2.228958e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>NRS110</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.097719e-09</td>\n",
       "      <td>4.404655e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>989 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   phage  strain  phenotype  prediction             0  \\\n",
       "0     p0006kpresabs_qual  NRS249          2           1  1.888869e-01   \n",
       "1     p0006kpresabs_qual  NRS188          1           1  1.888869e-01   \n",
       "2     p0006kpresabs_qual  NRS232          2           2  4.222906e-01   \n",
       "3     p0006kpresabs_qual   NY439          2           2  3.558408e-04   \n",
       "4     p0006kpresabs_qual    GA27          2           1  3.940971e-01   \n",
       "..                   ...     ...        ...         ...           ...   \n",
       "984  p0017Skpresabs_qual  NRS252          0           0  7.239556e-01   \n",
       "985  p0017Skpresabs_qual  SR2852          1           1  1.052276e-07   \n",
       "986  p0017Skpresabs_qual  NRS108          1           1  1.540350e-17   \n",
       "987  p0017Skpresabs_qual  NRS202          0           0  6.888959e-01   \n",
       "988  p0017Skpresabs_qual  NRS110          2           2  1.097719e-09   \n",
       "\n",
       "                1             2  \n",
       "0    5.108038e-01  3.003094e-01  \n",
       "1    5.108038e-01  3.003094e-01  \n",
       "2    7.029924e-02  5.074101e-01  \n",
       "3    2.976018e-04  9.993465e-01  \n",
       "4    4.184215e-01  1.874814e-01  \n",
       "..            ...           ...  \n",
       "984  2.760444e-01  1.176030e-09  \n",
       "985  9.999999e-01  1.101559e-28  \n",
       "986  1.000000e+00  9.011977e-16  \n",
       "987  3.111042e-01  2.228958e-09  \n",
       "988  4.404655e-08  1.000000e+00  \n",
       "\n",
       "[989 rows x 7 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.71694540e-04, 9.79389700e-01, 2.01386330e-02],\n",
       "       [9.99999640e-01, 4.58855900e-09, 3.66608930e-07],\n",
       "       [1.23285720e-02, 3.61047780e-03, 9.84060940e-01],\n",
       "       [3.44446800e-01, 5.11698300e-01, 1.43854830e-01],\n",
       "       [7.31556300e-01, 1.45534460e-01, 1.22909285e-01],\n",
       "       [9.99352400e-01, 1.81110990e-05, 6.29490650e-04],\n",
       "       [1.92075320e-03, 9.87569400e-01, 1.05098240e-02],\n",
       "       [1.90296410e-01, 4.87845700e-01, 3.21857960e-01],\n",
       "       [1.12405255e-01, 2.58055800e-01, 6.29538950e-01],\n",
       "       [1.80047610e-03, 7.55556460e-01, 2.42643000e-01],\n",
       "       [6.89505200e-01, 1.87554820e-01, 1.22939980e-01],\n",
       "       [2.06933800e-03, 3.26454130e-01, 6.71476540e-01],\n",
       "       [9.28176460e-01, 5.24530220e-02, 1.93705170e-02],\n",
       "       [9.90178350e-01, 6.37063500e-03, 3.45102260e-03],\n",
       "       [1.53595830e-02, 9.81426540e-01, 3.21382540e-03],\n",
       "       [9.99479000e-01, 7.68373500e-06, 5.13433600e-04],\n",
       "       [3.83327220e-04, 7.64060700e-03, 9.91976100e-01],\n",
       "       [4.55404070e-02, 3.42202130e-01, 6.12257500e-01],\n",
       "       [1.37736710e-01, 8.18581300e-03, 8.54077460e-01],\n",
       "       [8.91728100e-02, 8.19758300e-01, 9.10688800e-02],\n",
       "       [2.12477780e-02, 1.05226100e-01, 8.73526160e-01],\n",
       "       [1.55138710e-04, 9.98882600e-01, 9.62208960e-04],\n",
       "       [9.99479000e-01, 7.68373500e-06, 5.13433600e-04],\n",
       "       [9.83494740e-02, 8.09880300e-01, 9.17701900e-02],\n",
       "       [1.80047610e-03, 7.55556460e-01, 2.42643000e-01],\n",
       "       [1.97210680e-03, 2.68047840e-03, 9.95347440e-01],\n",
       "       [9.90885560e-01, 6.08995370e-03, 3.02454400e-03],\n",
       "       [8.77773760e-02, 1.10154310e-01, 8.02068300e-01],\n",
       "       [9.99959800e-01, 1.30498390e-05, 2.72169870e-05],\n",
       "       [2.01198680e-02, 3.33044380e-01, 6.46835740e-01],\n",
       "       [9.98650250e-01, 3.76191780e-04, 9.73633900e-04],\n",
       "       [9.83910200e-01, 5.47918630e-03, 1.06105900e-02],\n",
       "       [9.82089160e-01, 1.78248400e-05, 1.78930800e-02],\n",
       "       [5.95790800e-01, 3.06293200e-01, 9.79159800e-02],\n",
       "       [4.71694540e-04, 9.79389700e-01, 2.01386330e-02],\n",
       "       [7.55839800e-02, 5.07611630e-01, 4.16804340e-01],\n",
       "       [8.08636550e-01, 1.90838770e-01, 5.24718800e-04],\n",
       "       [1.51650690e-03, 1.37031350e-01, 8.61452100e-01],\n",
       "       [2.06350100e-01, 4.56523780e-01, 3.37126170e-01],\n",
       "       [9.90885560e-01, 6.08995370e-03, 3.02454400e-03],\n",
       "       [3.03262400e-06, 9.92006000e-01, 7.99093300e-03],\n",
       "       [1.80047610e-03, 7.55556460e-01, 2.42643000e-01],\n",
       "       [6.41367900e-03, 9.89811600e-01, 3.77467790e-03],\n",
       "       [9.99210830e-01, 1.88054440e-04, 6.01068700e-04],\n",
       "       [1.02375730e-01, 1.67130720e-01, 7.30493550e-01],\n",
       "       [1.23873310e-03, 2.32684540e-01, 7.66076700e-01],\n",
       "       [7.67012360e-03, 5.93196830e-03, 9.86397900e-01],\n",
       "       [2.18518100e-01, 1.77409220e-01, 6.04072700e-01],\n",
       "       [9.97387100e-01, 1.17284500e-03, 1.44008650e-03],\n",
       "       [7.55839800e-02, 5.07611630e-01, 4.16804340e-01],\n",
       "       [5.22910000e-04, 2.11334880e-03, 9.97363750e-01],\n",
       "       [2.97269650e-02, 8.91038550e-02, 8.81169140e-01],\n",
       "       [2.59252520e-01, 1.01861075e-01, 6.38886400e-01],\n",
       "       [8.94476100e-01, 6.50716950e-02, 4.04521230e-02],\n",
       "       [9.90885560e-01, 6.08995370e-03, 3.02454400e-03],\n",
       "       [9.99463860e-01, 1.17273760e-05, 5.24460200e-04],\n",
       "       [2.33895540e-04, 9.97937200e-01, 1.82899660e-03],\n",
       "       [6.10496000e-05, 4.40905930e-01, 5.59033040e-01],\n",
       "       [9.98221200e-01, 2.38458650e-05, 1.75494340e-03],\n",
       "       [9.99463860e-01, 1.17273760e-05, 5.24460200e-04],\n",
       "       [1.14924190e-01, 6.40899700e-01, 2.44176060e-01],\n",
       "       [2.49745940e-02, 9.72610700e-01, 2.41460000e-03],\n",
       "       [1.51650690e-03, 1.37031350e-01, 8.61452100e-01],\n",
       "       [5.12127240e-02, 7.53926040e-01, 1.94861190e-01],\n",
       "       [9.82089160e-01, 1.78248400e-05, 1.78930800e-02],\n",
       "       [2.06350100e-01, 4.56523780e-01, 3.37126170e-01],\n",
       "       [2.23069920e-02, 2.64749740e-01, 7.12943260e-01],\n",
       "       [1.91409760e-02, 8.83069500e-02, 8.92552100e-01],\n",
       "       [9.82089160e-01, 1.78248400e-05, 1.78930800e-02],\n",
       "       [5.88144100e-01, 3.16218880e-01, 9.56369900e-02],\n",
       "       [1.51650690e-03, 1.37031350e-01, 8.61452100e-01],\n",
       "       [4.71694540e-04, 9.79389700e-01, 2.01386330e-02],\n",
       "       [4.71694540e-04, 9.79389700e-01, 2.01386330e-02],\n",
       "       [2.79584870e-04, 9.98201600e-01, 1.51870880e-03],\n",
       "       [4.48236060e-03, 9.27537700e-01, 6.79800500e-02],\n",
       "       [5.21036560e-03, 9.25079550e-03, 9.85538840e-01],\n",
       "       [3.83327220e-04, 7.64060700e-03, 9.91976100e-01],\n",
       "       [3.38807900e-03, 7.96531740e-01, 2.00080170e-01],\n",
       "       [9.98945650e-01, 9.41794500e-04, 1.12577190e-04],\n",
       "       [7.95366200e-02, 8.28593800e-01, 9.18696450e-02],\n",
       "       [1.33293765e-02, 4.98669650e-01, 4.88000960e-01],\n",
       "       [5.31529800e-04, 9.99201700e-01, 2.66874120e-04],\n",
       "       [2.03826950e-03, 3.12340520e-02, 9.66727600e-01],\n",
       "       [1.04669260e-01, 8.04422440e-01, 9.09083200e-02],\n",
       "       [4.28896600e-02, 9.37648950e-01, 1.94613600e-02],\n",
       "       [3.10981640e-06, 9.99812540e-01, 1.84424050e-04],\n",
       "       [2.49745940e-02, 9.72610700e-01, 2.41460000e-03],\n",
       "       [1.58214010e-02, 5.41033860e-01, 4.43144680e-01],\n",
       "       [4.44533300e-01, 4.07084050e-01, 1.48382710e-01],\n",
       "       [4.48236060e-03, 9.27537700e-01, 6.79800500e-02],\n",
       "       [2.49745940e-02, 9.72610700e-01, 2.41460000e-03],\n",
       "       [1.90296410e-01, 4.87845700e-01, 3.21857960e-01],\n",
       "       [1.27720610e-01, 6.48582900e-01, 2.23696540e-01],\n",
       "       [8.60889100e-03, 7.24138200e-02, 9.18977260e-01],\n",
       "       [1.51650690e-03, 1.37031350e-01, 8.61452100e-01],\n",
       "       [1.00000000e+00, 1.50046520e-11, 1.03664695e-08],\n",
       "       [9.99210830e-01, 1.88054440e-04, 6.01068700e-04],\n",
       "       [5.12127240e-02, 7.53926040e-01, 1.94861190e-01],\n",
       "       [6.17600050e-04, 9.69630700e-01, 2.97516500e-02],\n",
       "       [9.90178350e-01, 6.37063500e-03, 3.45102260e-03],\n",
       "       [9.99959800e-01, 1.30498390e-05, 2.72169870e-05],\n",
       "       [9.83494740e-02, 8.09880300e-01, 9.17701900e-02],\n",
       "       [1.55138710e-04, 9.98882600e-01, 9.62208960e-04],\n",
       "       [9.82089160e-01, 1.78248400e-05, 1.78930800e-02],\n",
       "       [2.33895540e-04, 9.97937200e-01, 1.82899660e-03],\n",
       "       [1.22063540e-04, 9.98517600e-01, 1.36040950e-03],\n",
       "       [9.99033100e-01, 2.11174800e-06, 9.64834200e-04],\n",
       "       [5.95790800e-01, 3.06293200e-01, 9.79159800e-02],\n",
       "       [6.13288900e-01, 3.73531670e-01, 1.31795260e-02],\n",
       "       [1.80047610e-03, 7.55556460e-01, 2.42643000e-01],\n",
       "       [8.42334300e-02, 2.83238100e-01, 6.32528400e-01],\n",
       "       [7.68606600e-04, 3.21736130e-01, 6.77495240e-01],\n",
       "       [3.34047570e-03, 2.51170960e-01, 7.45488500e-01],\n",
       "       [1.34823370e-02, 1.26946100e-01, 8.59571600e-01],\n",
       "       [9.99272900e-01, 7.26394600e-05, 6.54500560e-04],\n",
       "       [8.64988100e-01, 2.34233460e-02, 1.11588575e-01],\n",
       "       [5.95790800e-01, 3.06293200e-01, 9.79159800e-02],\n",
       "       [9.97651500e-01, 1.58688030e-03, 7.61669800e-04],\n",
       "       [7.95366200e-02, 8.28593800e-01, 9.18696450e-02],\n",
       "       [9.97387100e-01, 1.17284500e-03, 1.44008650e-03],\n",
       "       [1.80047610e-03, 7.55556460e-01, 2.42643000e-01],\n",
       "       [9.82089160e-01, 1.78248400e-05, 1.78930800e-02],\n",
       "       [1.91580370e-01, 1.64575890e-01, 6.43843770e-01],\n",
       "       [9.99505640e-01, 2.40258740e-04, 2.54191550e-04],\n",
       "       [1.64649770e-04, 3.46587480e-05, 9.99800740e-01],\n",
       "       [9.99352400e-01, 1.81110990e-05, 6.29490650e-04],\n",
       "       [9.96627000e-01, 2.10152120e-04, 3.16290440e-03],\n",
       "       [1.58214010e-02, 5.41033860e-01, 4.43144680e-01],\n",
       "       [2.48105850e-03, 8.43439600e-02, 9.13175000e-01],\n",
       "       [4.71694540e-04, 9.79389700e-01, 2.01386330e-02],\n",
       "       [9.96627000e-01, 2.10152120e-04, 3.16290440e-03],\n",
       "       [6.06904000e-02, 5.77490700e-01, 3.61818940e-01],\n",
       "       [3.94864800e-01, 2.41283270e-01, 3.63851930e-01],\n",
       "       [7.95366200e-02, 8.28593800e-01, 9.18696450e-02],\n",
       "       [6.70350100e-02, 3.48694650e-01, 5.84270360e-01],\n",
       "       [1.64394680e-01, 5.01829300e-04, 8.35103500e-01],\n",
       "       [5.84187360e-03, 1.19235190e-01, 8.74922930e-01],\n",
       "       [9.90885560e-01, 6.08995370e-03, 3.02454400e-03],\n",
       "       [2.10358900e-01, 1.45221780e-01, 6.44419300e-01],\n",
       "       [9.90885560e-01, 6.08995370e-03, 3.02454400e-03],\n",
       "       [9.99352400e-01, 1.81110990e-05, 6.29490650e-04],\n",
       "       [1.00000000e+00, 3.62739660e-11, 1.95990700e-08],\n",
       "       [9.97651500e-01, 1.58688030e-03, 7.61669800e-04],\n",
       "       [3.38807900e-03, 7.96531740e-01, 2.00080170e-01],\n",
       "       [5.95790800e-01, 3.06293200e-01, 9.79159800e-02],\n",
       "       [1.14924190e-01, 6.40899700e-01, 2.44176060e-01],\n",
       "       [3.14749000e-02, 9.25781500e-01, 4.27435000e-02],\n",
       "       [1.90296410e-01, 4.87845700e-01, 3.21857960e-01],\n",
       "       [1.80047610e-03, 7.55556460e-01, 2.42643000e-01],\n",
       "       [9.99210830e-01, 1.88054440e-04, 6.01068700e-04],\n",
       "       [9.96627000e-01, 2.10152120e-04, 3.16290440e-03],\n",
       "       [3.49086370e-01, 7.69402200e-03, 6.43219600e-01],\n",
       "       [9.90885560e-01, 6.08995370e-03, 3.02454400e-03],\n",
       "       [7.56815140e-01, 3.94227950e-02, 2.03762040e-01],\n",
       "       [1.09605476e-01, 6.33403540e-04, 8.89761100e-01],\n",
       "       [6.17600050e-04, 9.69630700e-01, 2.97516500e-02],\n",
       "       [9.99463860e-01, 1.17273760e-05, 5.24460200e-04],\n",
       "       [9.98684100e-01, 6.13002750e-04, 7.02894200e-04],\n",
       "       [9.99210830e-01, 1.88054440e-04, 6.01068700e-04],\n",
       "       [9.99505640e-01, 2.40258740e-04, 2.54191550e-04],\n",
       "       [9.96627000e-01, 2.10152120e-04, 3.16290440e-03],\n",
       "       [5.83259050e-01, 9.55765900e-02, 3.21164250e-01],\n",
       "       [9.57326200e-01, 1.46330860e-02, 2.80407560e-02]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob6 = df_proba6[df_proba6['phage']=='p11kpresabsSTCC_qual'].iloc[:,-3:]\n",
    "y_prob6 = y_prob6.to_numpy()\n",
    "y_prob6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9378939754322017"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo6 = rocauc_ovo(y_sel_test_over, y_prob6, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9378939754322017"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr6 = rocauc_ovr(y_sel_test_over, y_prob6, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_sel_train_over, X_sel_test_over, y_sel_train_over, y_sel_test_over = train_test_split(X_sel_over, y_sel_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=789,\n",
    "                                                    stratify=y_sel_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat7 = pd.DataFrame(X_sel_test_over[:,-1])\n",
    "dat7['test'] = y_sel_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CFBREBSa127</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS145</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CFBRSa66B</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS204</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BCH-SA-13</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>NRS233</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>NRS204</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>CFBRSa07</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>CFBREBSa117</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>CFBREBSa126</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test\n",
       "0    CFBREBSa127     1\n",
       "1         NRS145     0\n",
       "2      CFBRSa66B     1\n",
       "3         NRS204     1\n",
       "4      BCH-SA-13     2\n",
       "..           ...   ...\n",
       "158       NRS233     2\n",
       "159       NRS204     1\n",
       "160     CFBRSa07     0\n",
       "161  CFBREBSa117     1\n",
       "162  CFBREBSa126     0\n",
       "\n",
       "[163 rows x 2 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sel_train_over = X_sel_train_over[:,:-1]\n",
    "X_sel_test_over = X_sel_test_over[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2_over3 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_sel_train_over.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2_over3.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 380 samples, validate on 163 samples\n",
      "Epoch 1/100\n",
      "380/380 [==============================] - 0s 388us/step - loss: 23.9572 - accuracy: 0.3500 - val_loss: 24.0988 - val_accuracy: 0.3681\n",
      "Epoch 2/100\n",
      "380/380 [==============================] - 0s 59us/step - loss: 16.3155 - accuracy: 0.4053 - val_loss: 14.2131 - val_accuracy: 0.3313\n",
      "Epoch 3/100\n",
      "380/380 [==============================] - 0s 109us/step - loss: 8.8551 - accuracy: 0.3895 - val_loss: 5.3069 - val_accuracy: 0.3190\n",
      "Epoch 4/100\n",
      "380/380 [==============================] - 0s 74us/step - loss: 3.8948 - accuracy: 0.3737 - val_loss: 2.8484 - val_accuracy: 0.3313\n",
      "Epoch 5/100\n",
      "380/380 [==============================] - 0s 71us/step - loss: 2.6779 - accuracy: 0.3316 - val_loss: 3.1189 - val_accuracy: 0.3497\n",
      "Epoch 6/100\n",
      "380/380 [==============================] - 0s 95us/step - loss: 3.1213 - accuracy: 0.3447 - val_loss: 3.1229 - val_accuracy: 0.3804\n",
      "Epoch 7/100\n",
      "380/380 [==============================] - 0s 88us/step - loss: 2.5681 - accuracy: 0.3632 - val_loss: 1.9979 - val_accuracy: 0.3558\n",
      "Epoch 8/100\n",
      "380/380 [==============================] - 0s 132us/step - loss: 1.5717 - accuracy: 0.3447 - val_loss: 1.4725 - val_accuracy: 0.4601\n",
      "Epoch 9/100\n",
      "380/380 [==============================] - 0s 103us/step - loss: 1.4489 - accuracy: 0.4000 - val_loss: 1.1563 - val_accuracy: 0.3374\n",
      "Epoch 10/100\n",
      "380/380 [==============================] - 0s 86us/step - loss: 1.2376 - accuracy: 0.4342 - val_loss: 1.5681 - val_accuracy: 0.3558\n",
      "Epoch 11/100\n",
      "380/380 [==============================] - 0s 83us/step - loss: 1.3227 - accuracy: 0.4789 - val_loss: 1.3335 - val_accuracy: 0.3804\n",
      "Epoch 12/100\n",
      "380/380 [==============================] - 0s 134us/step - loss: 1.1336 - accuracy: 0.5237 - val_loss: 1.2234 - val_accuracy: 0.4233\n",
      "Epoch 13/100\n",
      "380/380 [==============================] - 0s 126us/step - loss: 1.1036 - accuracy: 0.5158 - val_loss: 1.1646 - val_accuracy: 0.4049\n",
      "Epoch 14/100\n",
      "380/380 [==============================] - 0s 84us/step - loss: 1.0393 - accuracy: 0.5105 - val_loss: 1.0359 - val_accuracy: 0.4172\n",
      "Epoch 15/100\n",
      "380/380 [==============================] - 0s 91us/step - loss: 0.9856 - accuracy: 0.4526 - val_loss: 1.0842 - val_accuracy: 0.4724\n",
      "Epoch 16/100\n",
      "380/380 [==============================] - 0s 99us/step - loss: 0.9645 - accuracy: 0.4816 - val_loss: 0.9870 - val_accuracy: 0.4724\n",
      "Epoch 17/100\n",
      "380/380 [==============================] - 0s 118us/step - loss: 0.9331 - accuracy: 0.5211 - val_loss: 0.9560 - val_accuracy: 0.5644\n",
      "Epoch 18/100\n",
      "380/380 [==============================] - 0s 87us/step - loss: 0.9326 - accuracy: 0.5658 - val_loss: 1.0070 - val_accuracy: 0.5890\n",
      "Epoch 19/100\n",
      "380/380 [==============================] - 0s 89us/step - loss: 0.8958 - accuracy: 0.5895 - val_loss: 0.9470 - val_accuracy: 0.5767\n",
      "Epoch 20/100\n",
      "380/380 [==============================] - 0s 102us/step - loss: 0.8715 - accuracy: 0.6184 - val_loss: 0.9342 - val_accuracy: 0.5767\n",
      "Epoch 21/100\n",
      "380/380 [==============================] - 0s 125us/step - loss: 0.8721 - accuracy: 0.6289 - val_loss: 0.9080 - val_accuracy: 0.5828\n",
      "Epoch 22/100\n",
      "380/380 [==============================] - 0s 76us/step - loss: 0.8510 - accuracy: 0.6132 - val_loss: 0.8839 - val_accuracy: 0.6258\n",
      "Epoch 23/100\n",
      "380/380 [==============================] - 0s 107us/step - loss: 0.8396 - accuracy: 0.6711 - val_loss: 0.9564 - val_accuracy: 0.6442\n",
      "Epoch 24/100\n",
      "380/380 [==============================] - 0s 82us/step - loss: 0.8291 - accuracy: 0.6842 - val_loss: 0.8390 - val_accuracy: 0.6503\n",
      "Epoch 25/100\n",
      "380/380 [==============================] - 0s 78us/step - loss: 0.7994 - accuracy: 0.6947 - val_loss: 0.8687 - val_accuracy: 0.6687\n",
      "Epoch 26/100\n",
      "380/380 [==============================] - 0s 99us/step - loss: 0.7645 - accuracy: 0.7211 - val_loss: 0.8054 - val_accuracy: 0.7239\n",
      "Epoch 27/100\n",
      "380/380 [==============================] - 0s 71us/step - loss: 0.7503 - accuracy: 0.7263 - val_loss: 0.7886 - val_accuracy: 0.6810\n",
      "Epoch 28/100\n",
      "380/380 [==============================] - 0s 112us/step - loss: 0.7509 - accuracy: 0.7132 - val_loss: 0.8654 - val_accuracy: 0.7055\n",
      "Epoch 29/100\n",
      "380/380 [==============================] - 0s 120us/step - loss: 0.7945 - accuracy: 0.6658 - val_loss: 0.9023 - val_accuracy: 0.6135\n",
      "Epoch 30/100\n",
      "380/380 [==============================] - 0s 115us/step - loss: 0.7216 - accuracy: 0.6842 - val_loss: 0.7486 - val_accuracy: 0.6933\n",
      "Epoch 31/100\n",
      "380/380 [==============================] - 0s 190us/step - loss: 0.7345 - accuracy: 0.6842 - val_loss: 0.8128 - val_accuracy: 0.6810\n",
      "Epoch 32/100\n",
      "380/380 [==============================] - 0s 64us/step - loss: 0.7214 - accuracy: 0.7132 - val_loss: 0.8515 - val_accuracy: 0.6319\n",
      "Epoch 33/100\n",
      "380/380 [==============================] - 0s 81us/step - loss: 0.6997 - accuracy: 0.7421 - val_loss: 0.7460 - val_accuracy: 0.7055\n",
      "Epoch 34/100\n",
      "380/380 [==============================] - 0s 174us/step - loss: 0.6534 - accuracy: 0.7368 - val_loss: 0.6972 - val_accuracy: 0.7178\n",
      "Epoch 35/100\n",
      "380/380 [==============================] - 0s 74us/step - loss: 0.6437 - accuracy: 0.7500 - val_loss: 0.8182 - val_accuracy: 0.7362\n",
      "Epoch 36/100\n",
      "380/380 [==============================] - 0s 69us/step - loss: 0.6787 - accuracy: 0.7763 - val_loss: 0.7945 - val_accuracy: 0.7485\n",
      "Epoch 37/100\n",
      "380/380 [==============================] - 0s 69us/step - loss: 0.6277 - accuracy: 0.7553 - val_loss: 0.6706 - val_accuracy: 0.7362\n",
      "Epoch 38/100\n",
      "380/380 [==============================] - 0s 79us/step - loss: 0.6087 - accuracy: 0.7684 - val_loss: 0.7329 - val_accuracy: 0.7669\n",
      "Epoch 39/100\n",
      "380/380 [==============================] - 0s 83us/step - loss: 0.5631 - accuracy: 0.7921 - val_loss: 0.7117 - val_accuracy: 0.7178\n",
      "Epoch 40/100\n",
      "380/380 [==============================] - 0s 122us/step - loss: 0.5963 - accuracy: 0.7605 - val_loss: 0.8208 - val_accuracy: 0.7178\n",
      "Epoch 41/100\n",
      "380/380 [==============================] - 0s 80us/step - loss: 0.5786 - accuracy: 0.7974 - val_loss: 0.6588 - val_accuracy: 0.7423\n",
      "Epoch 42/100\n",
      "380/380 [==============================] - 0s 122us/step - loss: 0.5360 - accuracy: 0.7763 - val_loss: 0.6237 - val_accuracy: 0.7607\n",
      "Epoch 43/100\n",
      "380/380 [==============================] - 0s 96us/step - loss: 0.5207 - accuracy: 0.7974 - val_loss: 0.6339 - val_accuracy: 0.7607\n",
      "Epoch 44/100\n",
      "380/380 [==============================] - 0s 113us/step - loss: 0.5057 - accuracy: 0.8237 - val_loss: 0.5947 - val_accuracy: 0.7791\n",
      "Epoch 45/100\n",
      "380/380 [==============================] - 0s 87us/step - loss: 0.5001 - accuracy: 0.8158 - val_loss: 0.6119 - val_accuracy: 0.7730\n",
      "Epoch 46/100\n",
      "380/380 [==============================] - 0s 79us/step - loss: 0.4950 - accuracy: 0.8105 - val_loss: 0.6404 - val_accuracy: 0.7546\n",
      "Epoch 47/100\n",
      "380/380 [==============================] - 0s 61us/step - loss: 0.4920 - accuracy: 0.8263 - val_loss: 0.6034 - val_accuracy: 0.7791\n",
      "Epoch 48/100\n",
      "380/380 [==============================] - 0s 54us/step - loss: 0.4650 - accuracy: 0.8316 - val_loss: 0.5713 - val_accuracy: 0.7730\n",
      "Epoch 49/100\n",
      "380/380 [==============================] - 0s 68us/step - loss: 0.4491 - accuracy: 0.8421 - val_loss: 0.5958 - val_accuracy: 0.7607\n",
      "Epoch 50/100\n",
      "380/380 [==============================] - 0s 51us/step - loss: 0.4495 - accuracy: 0.8053 - val_loss: 0.5723 - val_accuracy: 0.7791\n",
      "Epoch 51/100\n",
      "380/380 [==============================] - 0s 50us/step - loss: 0.4595 - accuracy: 0.8447 - val_loss: 0.6175 - val_accuracy: 0.7730\n",
      "Epoch 52/100\n",
      "380/380 [==============================] - 0s 54us/step - loss: 0.4342 - accuracy: 0.8289 - val_loss: 0.5211 - val_accuracy: 0.8037\n",
      "Epoch 53/100\n",
      "380/380 [==============================] - 0s 83us/step - loss: 0.4302 - accuracy: 0.8342 - val_loss: 0.5913 - val_accuracy: 0.7546\n",
      "Epoch 54/100\n",
      "380/380 [==============================] - 0s 72us/step - loss: 0.4146 - accuracy: 0.8237 - val_loss: 0.5306 - val_accuracy: 0.7975\n",
      "Epoch 55/100\n",
      "380/380 [==============================] - 0s 154us/step - loss: 0.4002 - accuracy: 0.8605 - val_loss: 0.5553 - val_accuracy: 0.8160\n",
      "Epoch 56/100\n",
      "380/380 [==============================] - 0s 155us/step - loss: 0.3948 - accuracy: 0.8711 - val_loss: 0.5389 - val_accuracy: 0.8037\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "380/380 [==============================] - 0s 87us/step - loss: 0.3887 - accuracy: 0.8447 - val_loss: 0.5510 - val_accuracy: 0.8221\n",
      "Epoch 58/100\n",
      "380/380 [==============================] - 0s 134us/step - loss: 0.3912 - accuracy: 0.8658 - val_loss: 0.5178 - val_accuracy: 0.8160\n",
      "Epoch 59/100\n",
      "380/380 [==============================] - 0s 95us/step - loss: 0.3845 - accuracy: 0.8605 - val_loss: 0.5053 - val_accuracy: 0.8098\n",
      "Epoch 60/100\n",
      "380/380 [==============================] - 0s 85us/step - loss: 0.3762 - accuracy: 0.8658 - val_loss: 0.5114 - val_accuracy: 0.8160\n",
      "Epoch 61/100\n",
      "380/380 [==============================] - 0s 145us/step - loss: 0.3805 - accuracy: 0.8500 - val_loss: 0.5424 - val_accuracy: 0.7975\n",
      "Epoch 62/100\n",
      "380/380 [==============================] - 0s 87us/step - loss: 0.3772 - accuracy: 0.8684 - val_loss: 0.5199 - val_accuracy: 0.8098\n",
      "Epoch 63/100\n",
      "380/380 [==============================] - 0s 157us/step - loss: 0.3663 - accuracy: 0.8658 - val_loss: 0.4968 - val_accuracy: 0.8405\n",
      "Epoch 64/100\n",
      "380/380 [==============================] - 0s 96us/step - loss: 0.3479 - accuracy: 0.9053 - val_loss: 0.5310 - val_accuracy: 0.8282\n",
      "Epoch 65/100\n",
      "380/380 [==============================] - 0s 84us/step - loss: 0.3555 - accuracy: 0.9026 - val_loss: 0.4690 - val_accuracy: 0.8405\n",
      "Epoch 66/100\n",
      "380/380 [==============================] - 0s 72us/step - loss: 0.3445 - accuracy: 0.8816 - val_loss: 0.4909 - val_accuracy: 0.8282\n",
      "Epoch 67/100\n",
      "380/380 [==============================] - 0s 139us/step - loss: 0.3394 - accuracy: 0.9105 - val_loss: 0.4813 - val_accuracy: 0.8405\n",
      "Epoch 68/100\n",
      "380/380 [==============================] - 0s 152us/step - loss: 0.3381 - accuracy: 0.8684 - val_loss: 0.4751 - val_accuracy: 0.8466\n",
      "Epoch 69/100\n",
      "380/380 [==============================] - 0s 105us/step - loss: 0.3312 - accuracy: 0.9000 - val_loss: 0.5335 - val_accuracy: 0.8344\n",
      "Epoch 70/100\n",
      "380/380 [==============================] - 0s 193us/step - loss: 0.3374 - accuracy: 0.8921 - val_loss: 0.5043 - val_accuracy: 0.8282\n",
      "Epoch 71/100\n",
      "380/380 [==============================] - 0s 171us/step - loss: 0.3393 - accuracy: 0.9000 - val_loss: 0.4752 - val_accuracy: 0.8405\n",
      "Epoch 72/100\n",
      "380/380 [==============================] - 0s 145us/step - loss: 0.3166 - accuracy: 0.8974 - val_loss: 0.5201 - val_accuracy: 0.8405\n",
      "Epoch 73/100\n",
      "380/380 [==============================] - 0s 182us/step - loss: 0.3168 - accuracy: 0.9132 - val_loss: 0.4596 - val_accuracy: 0.8344\n",
      "Epoch 74/100\n",
      "380/380 [==============================] - 0s 69us/step - loss: 0.3040 - accuracy: 0.8947 - val_loss: 0.4590 - val_accuracy: 0.8405\n",
      "Epoch 75/100\n",
      "380/380 [==============================] - 0s 110us/step - loss: 0.3158 - accuracy: 0.9105 - val_loss: 0.4758 - val_accuracy: 0.8405\n",
      "Epoch 76/100\n",
      "380/380 [==============================] - 0s 93us/step - loss: 0.3009 - accuracy: 0.9000 - val_loss: 0.4443 - val_accuracy: 0.8344\n",
      "Epoch 77/100\n",
      "380/380 [==============================] - 0s 128us/step - loss: 0.2876 - accuracy: 0.9079 - val_loss: 0.5176 - val_accuracy: 0.8344\n",
      "Epoch 78/100\n",
      "380/380 [==============================] - 0s 71us/step - loss: 0.3148 - accuracy: 0.9184 - val_loss: 0.4706 - val_accuracy: 0.8405\n",
      "Epoch 79/100\n",
      "380/380 [==============================] - 0s 58us/step - loss: 0.3004 - accuracy: 0.8789 - val_loss: 0.4458 - val_accuracy: 0.8466\n",
      "Epoch 80/100\n",
      "380/380 [==============================] - 0s 75us/step - loss: 0.2754 - accuracy: 0.9000 - val_loss: 0.5228 - val_accuracy: 0.7791\n",
      "Epoch 81/100\n",
      "380/380 [==============================] - 0s 104us/step - loss: 0.2886 - accuracy: 0.9105 - val_loss: 0.4235 - val_accuracy: 0.8466\n",
      "Epoch 82/100\n",
      "380/380 [==============================] - 0s 135us/step - loss: 0.2765 - accuracy: 0.8974 - val_loss: 0.4306 - val_accuracy: 0.8466\n",
      "Epoch 83/100\n",
      "380/380 [==============================] - 0s 127us/step - loss: 0.2754 - accuracy: 0.9026 - val_loss: 0.4602 - val_accuracy: 0.8405\n",
      "Epoch 84/100\n",
      "380/380 [==============================] - 0s 94us/step - loss: 0.2708 - accuracy: 0.9263 - val_loss: 0.4557 - val_accuracy: 0.8344\n",
      "Epoch 85/100\n",
      "380/380 [==============================] - 0s 88us/step - loss: 0.2603 - accuracy: 0.9053 - val_loss: 0.4402 - val_accuracy: 0.8466\n",
      "Epoch 86/100\n",
      "380/380 [==============================] - 0s 89us/step - loss: 0.2649 - accuracy: 0.9342 - val_loss: 0.4427 - val_accuracy: 0.8405\n",
      "Epoch 87/100\n",
      "380/380 [==============================] - 0s 145us/step - loss: 0.2619 - accuracy: 0.9237 - val_loss: 0.4392 - val_accuracy: 0.8282\n",
      "Epoch 88/100\n",
      "380/380 [==============================] - 0s 320us/step - loss: 0.2614 - accuracy: 0.9000 - val_loss: 0.5012 - val_accuracy: 0.8282\n",
      "Epoch 89/100\n",
      "380/380 [==============================] - 0s 103us/step - loss: 0.2858 - accuracy: 0.9158 - val_loss: 0.4358 - val_accuracy: 0.8405\n",
      "Epoch 90/100\n",
      "380/380 [==============================] - 0s 133us/step - loss: 0.2974 - accuracy: 0.8921 - val_loss: 0.6888 - val_accuracy: 0.8466\n",
      "Epoch 91/100\n",
      "380/380 [==============================] - 0s 169us/step - loss: 0.3706 - accuracy: 0.8947 - val_loss: 0.7102 - val_accuracy: 0.7791\n",
      "Epoch 92/100\n",
      "380/380 [==============================] - 0s 130us/step - loss: 0.3460 - accuracy: 0.9053 - val_loss: 0.4137 - val_accuracy: 0.8466\n",
      "Epoch 93/100\n",
      "380/380 [==============================] - 0s 131us/step - loss: 0.2949 - accuracy: 0.8789 - val_loss: 0.4630 - val_accuracy: 0.8589\n",
      "Epoch 94/100\n",
      "380/380 [==============================] - 0s 96us/step - loss: 0.2724 - accuracy: 0.8816 - val_loss: 0.5288 - val_accuracy: 0.8589\n",
      "Epoch 95/100\n",
      "380/380 [==============================] - 0s 127us/step - loss: 0.2878 - accuracy: 0.9053 - val_loss: 0.4796 - val_accuracy: 0.8344\n",
      "Epoch 96/100\n",
      "380/380 [==============================] - 0s 132us/step - loss: 0.2672 - accuracy: 0.9132 - val_loss: 0.4507 - val_accuracy: 0.8282\n",
      "Epoch 97/100\n",
      "380/380 [==============================] - 0s 93us/step - loss: 0.2502 - accuracy: 0.9105 - val_loss: 0.4246 - val_accuracy: 0.8589\n",
      "Epoch 98/100\n",
      "380/380 [==============================] - 0s 118us/step - loss: 0.2478 - accuracy: 0.9132 - val_loss: 0.4720 - val_accuracy: 0.8650\n",
      "Epoch 99/100\n",
      "380/380 [==============================] - 0s 101us/step - loss: 0.2462 - accuracy: 0.9526 - val_loss: 0.4518 - val_accuracy: 0.8282\n",
      "Epoch 100/100\n",
      "380/380 [==============================] - 0s 107us/step - loss: 0.2400 - accuracy: 0.9184 - val_loss: 0.4266 - val_accuracy: 0.8589\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a373eb0b8>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2_over3.fit(X_sel_train_over, y_sel_train_over,\n",
    "          batch_size=64, epochs=100,\n",
    "          validation_data=(X_sel_test_over, y_sel_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163/163 [==============================] - 0s 62us/step\n",
      "over-sampling test accuracy: 83.44%\n"
     ]
    }
   ],
   "source": [
    "acc_test2_over3 = model2_over3.evaluate(X_sel_test_over, y_sel_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test2_over3*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 2, 1, 1, 0, 1, 2, 0, 1, 1,\n",
       "       0, 0, 0, 1, 0, 0, 2, 1, 2, 2, 2, 1, 2, 2, 1, 0, 0, 2, 2, 2, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 2, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 0, 1, 2, 1, 1, 0, 1, 1, 2, 0, 0, 0, 2, 2, 0, 2, 0, 2, 0,\n",
       "       0, 0, 1, 1, 2, 2, 2, 2, 1, 0, 2, 0, 0, 2, 1, 2, 1, 2, 1, 1, 1, 2,\n",
       "       0, 0, 0, 1, 2, 0, 0, 1, 0, 2, 2, 2, 0, 1, 1, 1, 1, 2, 0, 2, 1, 0,\n",
       "       2, 1, 1, 0, 0, 1, 1, 1, 1, 2, 0, 1, 2, 2, 0, 1, 1, 2, 1, 1, 0, 1,\n",
       "       2, 0, 0, 2, 2, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred7 = model2_over3.predict_classes(X_sel_test_over)\n",
    "pred7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CFBREBSa127</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS145</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CFBRSa66B</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS204</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BCH-SA-13</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>NRS233</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>NRS204</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>CFBRSa07</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>CFBREBSa117</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>CFBREBSa126</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test  pred\n",
       "0    CFBREBSa127     1     1\n",
       "1         NRS145     0     0\n",
       "2      CFBRSa66B     1     1\n",
       "3         NRS204     1     1\n",
       "4      BCH-SA-13     2     1\n",
       "..           ...   ...   ...\n",
       "158       NRS233     2     2\n",
       "159       NRS204     1     1\n",
       "160     CFBRSa07     0     0\n",
       "161  CFBREBSa117     1     0\n",
       "162  CFBREBSa126     0     0\n",
       "\n",
       "[163 rows x 3 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat7['pred'] = pred7\n",
    "dat7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba7 = model2_over3.predict_proba(X_sel_test_over)\n",
    "dat_proba7 = pd.DataFrame(proba7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002984</td>\n",
       "      <td>0.993895</td>\n",
       "      <td>0.003121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.984843</td>\n",
       "      <td>0.013513</td>\n",
       "      <td>0.001644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.057898</td>\n",
       "      <td>0.705047</td>\n",
       "      <td>0.237055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.011230</td>\n",
       "      <td>0.899893</td>\n",
       "      <td>0.088877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.049694</td>\n",
       "      <td>0.910956</td>\n",
       "      <td>0.039350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000338</td>\n",
       "      <td>0.999660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>0.011230</td>\n",
       "      <td>0.899893</td>\n",
       "      <td>0.088877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>0.993775</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.006161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>0.805753</td>\n",
       "      <td>0.148299</td>\n",
       "      <td>0.045948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>0.980026</td>\n",
       "      <td>0.004510</td>\n",
       "      <td>0.015464</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2\n",
       "0    0.002984  0.993895  0.003121\n",
       "1    0.984843  0.013513  0.001644\n",
       "2    0.057898  0.705047  0.237055\n",
       "3    0.011230  0.899893  0.088877\n",
       "4    0.049694  0.910956  0.039350\n",
       "..        ...       ...       ...\n",
       "158  0.000002  0.000338  0.999660\n",
       "159  0.011230  0.899893  0.088877\n",
       "160  0.993775  0.000064  0.006161\n",
       "161  0.805753  0.148299  0.045948\n",
       "162  0.980026  0.004510  0.015464\n",
       "\n",
       "[163 rows x 3 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba7.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba7.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat7.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/7p11ST.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 380 samples, validate on 163 samples\n",
      "Epoch 1/100\n",
      "380/380 [==============================] - 0s 76us/step - loss: 0.4058 - accuracy: 0.8974 - val_loss: 0.5838 - val_accuracy: 0.7791\n",
      "Epoch 2/100\n",
      "380/380 [==============================] - 0s 62us/step - loss: 0.3161 - accuracy: 0.8842 - val_loss: 0.8085 - val_accuracy: 0.8098\n",
      "Epoch 3/100\n",
      "380/380 [==============================] - 0s 109us/step - loss: 0.6396 - accuracy: 0.8579 - val_loss: 0.8776 - val_accuracy: 0.7730\n",
      "Epoch 4/100\n",
      "380/380 [==============================] - 0s 86us/step - loss: 0.4273 - accuracy: 0.8553 - val_loss: 0.6734 - val_accuracy: 0.7362\n",
      "Epoch 5/100\n",
      "380/380 [==============================] - 0s 79us/step - loss: 0.5249 - accuracy: 0.8474 - val_loss: 1.1194 - val_accuracy: 0.7117\n",
      "Epoch 6/100\n",
      "380/380 [==============================] - 0s 75us/step - loss: 0.4924 - accuracy: 0.8711 - val_loss: 0.6125 - val_accuracy: 0.7669\n",
      "Epoch 7/100\n",
      "380/380 [==============================] - 0s 82us/step - loss: 0.4256 - accuracy: 0.8684 - val_loss: 0.9993 - val_accuracy: 0.8466\n",
      "Epoch 8/100\n",
      "380/380 [==============================] - 0s 75us/step - loss: 0.5638 - accuracy: 0.8921 - val_loss: 0.6934 - val_accuracy: 0.7975\n",
      "Epoch 9/100\n",
      "380/380 [==============================] - 0s 73us/step - loss: 0.3778 - accuracy: 0.8921 - val_loss: 0.5846 - val_accuracy: 0.7975\n",
      "Epoch 10/100\n",
      "380/380 [==============================] - 0s 67us/step - loss: 0.3725 - accuracy: 0.8895 - val_loss: 0.4796 - val_accuracy: 0.8405\n",
      "Epoch 11/100\n",
      "380/380 [==============================] - 0s 72us/step - loss: 0.2912 - accuracy: 0.9263 - val_loss: 0.5264 - val_accuracy: 0.8160\n",
      "Epoch 12/100\n",
      "380/380 [==============================] - 0s 63us/step - loss: 0.2765 - accuracy: 0.9132 - val_loss: 0.4976 - val_accuracy: 0.8221\n",
      "Epoch 13/100\n",
      "380/380 [==============================] - 0s 69us/step - loss: 0.3381 - accuracy: 0.9132 - val_loss: 0.6426 - val_accuracy: 0.8160\n",
      "Epoch 14/100\n",
      "380/380 [==============================] - 0s 71us/step - loss: 0.3676 - accuracy: 0.8921 - val_loss: 0.6487 - val_accuracy: 0.8160\n",
      "Epoch 15/100\n",
      "380/380 [==============================] - 0s 74us/step - loss: 0.5172 - accuracy: 0.8526 - val_loss: 0.9063 - val_accuracy: 0.7301\n",
      "Epoch 16/100\n",
      "380/380 [==============================] - 0s 70us/step - loss: 0.4252 - accuracy: 0.9105 - val_loss: 0.4744 - val_accuracy: 0.7853\n",
      "Epoch 17/100\n",
      "380/380 [==============================] - 0s 67us/step - loss: 0.3067 - accuracy: 0.8921 - val_loss: 0.5146 - val_accuracy: 0.8405\n",
      "Epoch 18/100\n",
      "380/380 [==============================] - 0s 64us/step - loss: 0.3099 - accuracy: 0.9184 - val_loss: 0.4740 - val_accuracy: 0.8344\n",
      "Epoch 19/100\n",
      "380/380 [==============================] - 0s 68us/step - loss: 0.2732 - accuracy: 0.9105 - val_loss: 0.4782 - val_accuracy: 0.8405\n",
      "Epoch 20/100\n",
      "380/380 [==============================] - 0s 84us/step - loss: 0.3898 - accuracy: 0.9237 - val_loss: 0.6808 - val_accuracy: 0.7791\n",
      "Epoch 21/100\n",
      "380/380 [==============================] - 0s 71us/step - loss: 0.3341 - accuracy: 0.9237 - val_loss: 0.3956 - val_accuracy: 0.8650\n",
      "Epoch 22/100\n",
      "380/380 [==============================] - 0s 67us/step - loss: 0.3041 - accuracy: 0.9211 - val_loss: 0.5674 - val_accuracy: 0.8282\n",
      "Epoch 23/100\n",
      "380/380 [==============================] - 0s 64us/step - loss: 0.2956 - accuracy: 0.9158 - val_loss: 0.4555 - val_accuracy: 0.8160\n",
      "Epoch 24/100\n",
      "380/380 [==============================] - 0s 67us/step - loss: 0.2630 - accuracy: 0.9184 - val_loss: 0.6730 - val_accuracy: 0.8466\n",
      "Epoch 25/100\n",
      "380/380 [==============================] - 0s 64us/step - loss: 0.3454 - accuracy: 0.9395 - val_loss: 0.5139 - val_accuracy: 0.8466\n",
      "Epoch 26/100\n",
      "380/380 [==============================] - 0s 90us/step - loss: 0.3662 - accuracy: 0.9053 - val_loss: 0.4354 - val_accuracy: 0.8834\n",
      "Epoch 27/100\n",
      "380/380 [==============================] - 0s 60us/step - loss: 0.4198 - accuracy: 0.9132 - val_loss: 0.7193 - val_accuracy: 0.8405\n",
      "Epoch 28/100\n",
      "380/380 [==============================] - 0s 71us/step - loss: 0.2662 - accuracy: 0.9184 - val_loss: 0.4414 - val_accuracy: 0.8466\n",
      "Epoch 29/100\n",
      "380/380 [==============================] - 0s 78us/step - loss: 0.2497 - accuracy: 0.9211 - val_loss: 0.6995 - val_accuracy: 0.8466\n",
      "Epoch 30/100\n",
      "380/380 [==============================] - 0s 66us/step - loss: 0.3803 - accuracy: 0.9263 - val_loss: 0.5138 - val_accuracy: 0.8466\n",
      "Epoch 31/100\n",
      "380/380 [==============================] - 0s 61us/step - loss: 0.2346 - accuracy: 0.9211 - val_loss: 0.4188 - val_accuracy: 0.7914\n",
      "Epoch 32/100\n",
      "380/380 [==============================] - 0s 65us/step - loss: 0.2623 - accuracy: 0.9342 - val_loss: 0.4859 - val_accuracy: 0.8405\n",
      "Epoch 33/100\n",
      "380/380 [==============================] - 0s 76us/step - loss: 0.2322 - accuracy: 0.9500 - val_loss: 0.5427 - val_accuracy: 0.8344\n",
      "Epoch 34/100\n",
      "380/380 [==============================] - 0s 80us/step - loss: 0.4091 - accuracy: 0.9368 - val_loss: 0.7563 - val_accuracy: 0.8282\n",
      "Epoch 35/100\n",
      "380/380 [==============================] - 0s 75us/step - loss: 0.3934 - accuracy: 0.9263 - val_loss: 0.4540 - val_accuracy: 0.8405\n",
      "Epoch 36/100\n",
      "380/380 [==============================] - 0s 74us/step - loss: 0.3695 - accuracy: 0.9026 - val_loss: 0.6201 - val_accuracy: 0.8466\n",
      "Epoch 37/100\n",
      "380/380 [==============================] - 0s 74us/step - loss: 0.3731 - accuracy: 0.9211 - val_loss: 0.5177 - val_accuracy: 0.8528\n",
      "Epoch 38/100\n",
      "380/380 [==============================] - 0s 70us/step - loss: 0.2966 - accuracy: 0.9158 - val_loss: 0.5412 - val_accuracy: 0.8650\n",
      "Epoch 39/100\n",
      "380/380 [==============================] - 0s 67us/step - loss: 0.3590 - accuracy: 0.9105 - val_loss: 0.6384 - val_accuracy: 0.8344\n",
      "Epoch 40/100\n",
      "380/380 [==============================] - 0s 59us/step - loss: 0.2638 - accuracy: 0.9263 - val_loss: 0.4347 - val_accuracy: 0.7791\n",
      "Epoch 41/100\n",
      "380/380 [==============================] - 0s 51us/step - loss: 0.2719 - accuracy: 0.9289 - val_loss: 0.9419 - val_accuracy: 0.8344\n",
      "Epoch 42/100\n",
      "380/380 [==============================] - 0s 52us/step - loss: 0.4078 - accuracy: 0.9105 - val_loss: 0.6266 - val_accuracy: 0.7669\n",
      "Epoch 43/100\n",
      "380/380 [==============================] - 0s 61us/step - loss: 0.2741 - accuracy: 0.9237 - val_loss: 0.4143 - val_accuracy: 0.8528\n",
      "Epoch 44/100\n",
      "380/380 [==============================] - 0s 57us/step - loss: 0.2309 - accuracy: 0.9237 - val_loss: 0.4630 - val_accuracy: 0.8528\n",
      "Epoch 45/100\n",
      "380/380 [==============================] - 0s 56us/step - loss: 0.2387 - accuracy: 0.9395 - val_loss: 0.3950 - val_accuracy: 0.8712\n",
      "Epoch 46/100\n",
      "380/380 [==============================] - 0s 58us/step - loss: 0.1992 - accuracy: 0.9579 - val_loss: 0.4167 - val_accuracy: 0.8712\n",
      "Epoch 47/100\n",
      "380/380 [==============================] - 0s 56us/step - loss: 0.2052 - accuracy: 0.9474 - val_loss: 0.5097 - val_accuracy: 0.8405\n",
      "Epoch 48/100\n",
      "380/380 [==============================] - 0s 66us/step - loss: 0.1992 - accuracy: 0.9447 - val_loss: 0.4238 - val_accuracy: 0.8466\n",
      "Epoch 49/100\n",
      "380/380 [==============================] - 0s 59us/step - loss: 0.2323 - accuracy: 0.9316 - val_loss: 0.4268 - val_accuracy: 0.8037\n",
      "Epoch 50/100\n",
      "380/380 [==============================] - 0s 62us/step - loss: 0.2135 - accuracy: 0.9421 - val_loss: 0.4306 - val_accuracy: 0.8466\n",
      "Epoch 51/100\n",
      "380/380 [==============================] - 0s 59us/step - loss: 0.2366 - accuracy: 0.9474 - val_loss: 0.3942 - val_accuracy: 0.8712\n",
      "Epoch 52/100\n",
      "380/380 [==============================] - 0s 64us/step - loss: 0.2208 - accuracy: 0.9342 - val_loss: 0.6385 - val_accuracy: 0.8528\n",
      "Epoch 53/100\n",
      "380/380 [==============================] - 0s 61us/step - loss: 0.3284 - accuracy: 0.9237 - val_loss: 0.4232 - val_accuracy: 0.8712\n",
      "Epoch 54/100\n",
      "380/380 [==============================] - 0s 74us/step - loss: 0.2396 - accuracy: 0.9395 - val_loss: 0.4896 - val_accuracy: 0.8037\n",
      "Epoch 55/100\n",
      "380/380 [==============================] - 0s 59us/step - loss: 0.2330 - accuracy: 0.9211 - val_loss: 0.4625 - val_accuracy: 0.8405\n",
      "Epoch 56/100\n",
      "380/380 [==============================] - 0s 62us/step - loss: 0.2662 - accuracy: 0.9263 - val_loss: 0.4568 - val_accuracy: 0.8098\n",
      "Epoch 57/100\n",
      "380/380 [==============================] - 0s 57us/step - loss: 0.1912 - accuracy: 0.9526 - val_loss: 0.4493 - val_accuracy: 0.8282\n",
      "Epoch 58/100\n",
      "380/380 [==============================] - 0s 66us/step - loss: 0.2668 - accuracy: 0.9132 - val_loss: 0.6002 - val_accuracy: 0.8589\n",
      "Epoch 59/100\n",
      "380/380 [==============================] - 0s 72us/step - loss: 0.2507 - accuracy: 0.9421 - val_loss: 0.4058 - val_accuracy: 0.8650\n",
      "Epoch 60/100\n",
      "380/380 [==============================] - 0s 109us/step - loss: 0.2641 - accuracy: 0.9263 - val_loss: 0.4886 - val_accuracy: 0.8528\n",
      "Epoch 61/100\n",
      "380/380 [==============================] - 0s 239us/step - loss: 0.2111 - accuracy: 0.9421 - val_loss: 0.3489 - val_accuracy: 0.8773\n",
      "Epoch 62/100\n",
      "380/380 [==============================] - 0s 94us/step - loss: 0.1941 - accuracy: 0.9342 - val_loss: 0.5181 - val_accuracy: 0.8528\n",
      "Epoch 63/100\n",
      "380/380 [==============================] - 0s 71us/step - loss: 0.2934 - accuracy: 0.9500 - val_loss: 0.3843 - val_accuracy: 0.8589\n",
      "Epoch 64/100\n",
      "380/380 [==============================] - 0s 96us/step - loss: 0.1963 - accuracy: 0.9342 - val_loss: 0.3912 - val_accuracy: 0.8712\n",
      "Epoch 65/100\n",
      "380/380 [==============================] - 0s 87us/step - loss: 0.2118 - accuracy: 0.9263 - val_loss: 0.4069 - val_accuracy: 0.7975\n",
      "Epoch 66/100\n",
      "380/380 [==============================] - 0s 74us/step - loss: 0.1944 - accuracy: 0.9395 - val_loss: 0.4586 - val_accuracy: 0.8466\n",
      "Epoch 67/100\n",
      "380/380 [==============================] - 0s 70us/step - loss: 0.2067 - accuracy: 0.9474 - val_loss: 0.4064 - val_accuracy: 0.8037\n",
      "Epoch 68/100\n",
      "380/380 [==============================] - 0s 87us/step - loss: 0.1794 - accuracy: 0.9605 - val_loss: 0.3685 - val_accuracy: 0.8712\n",
      "Epoch 69/100\n",
      "380/380 [==============================] - 0s 108us/step - loss: 0.2028 - accuracy: 0.9526 - val_loss: 0.3666 - val_accuracy: 0.8773\n",
      "Epoch 70/100\n",
      "380/380 [==============================] - 0s 94us/step - loss: 0.1738 - accuracy: 0.9474 - val_loss: 0.4985 - val_accuracy: 0.8528\n",
      "Epoch 71/100\n",
      "380/380 [==============================] - 0s 89us/step - loss: 0.2506 - accuracy: 0.9474 - val_loss: 0.3700 - val_accuracy: 0.8650\n",
      "Epoch 72/100\n",
      "380/380 [==============================] - 0s 85us/step - loss: 0.2689 - accuracy: 0.9342 - val_loss: 0.5176 - val_accuracy: 0.8528\n",
      "Epoch 73/100\n",
      "380/380 [==============================] - 0s 80us/step - loss: 0.3438 - accuracy: 0.9316 - val_loss: 0.5710 - val_accuracy: 0.8466\n",
      "Epoch 74/100\n",
      "380/380 [==============================] - 0s 85us/step - loss: 0.2215 - accuracy: 0.9368 - val_loss: 0.5067 - val_accuracy: 0.8405\n",
      "Epoch 75/100\n",
      "380/380 [==============================] - 0s 141us/step - loss: 0.2158 - accuracy: 0.9447 - val_loss: 0.5621 - val_accuracy: 0.8466\n",
      "Epoch 76/100\n",
      "380/380 [==============================] - 0s 176us/step - loss: 0.2762 - accuracy: 0.9474 - val_loss: 0.4160 - val_accuracy: 0.8589\n",
      "Epoch 77/100\n",
      "380/380 [==============================] - 0s 75us/step - loss: 0.2002 - accuracy: 0.9368 - val_loss: 0.3756 - val_accuracy: 0.8528\n",
      "Epoch 78/100\n",
      "380/380 [==============================] - 0s 67us/step - loss: 0.3235 - accuracy: 0.9421 - val_loss: 0.6661 - val_accuracy: 0.8466\n",
      "Epoch 79/100\n",
      "380/380 [==============================] - 0s 81us/step - loss: 0.3061 - accuracy: 0.9421 - val_loss: 0.3773 - val_accuracy: 0.8650\n",
      "Epoch 80/100\n",
      "380/380 [==============================] - 0s 79us/step - loss: 0.1773 - accuracy: 0.9368 - val_loss: 0.4059 - val_accuracy: 0.8834\n",
      "Epoch 81/100\n",
      "380/380 [==============================] - 0s 62us/step - loss: 0.2070 - accuracy: 0.9553 - val_loss: 0.4289 - val_accuracy: 0.7975\n",
      "Epoch 82/100\n",
      "380/380 [==============================] - 0s 97us/step - loss: 0.1771 - accuracy: 0.9447 - val_loss: 0.3527 - val_accuracy: 0.8528\n",
      "Epoch 83/100\n",
      "380/380 [==============================] - 0s 182us/step - loss: 0.1871 - accuracy: 0.9553 - val_loss: 0.3913 - val_accuracy: 0.8528\n",
      "Epoch 84/100\n",
      "380/380 [==============================] - 0s 106us/step - loss: 0.2063 - accuracy: 0.9553 - val_loss: 0.3468 - val_accuracy: 0.8712\n",
      "Epoch 85/100\n",
      "380/380 [==============================] - 0s 92us/step - loss: 0.1636 - accuracy: 0.9579 - val_loss: 0.4659 - val_accuracy: 0.8712\n",
      "Epoch 86/100\n",
      "380/380 [==============================] - 0s 75us/step - loss: 0.2585 - accuracy: 0.9474 - val_loss: 0.4246 - val_accuracy: 0.8528\n",
      "Epoch 87/100\n",
      "380/380 [==============================] - 0s 62us/step - loss: 0.1674 - accuracy: 0.9421 - val_loss: 0.3780 - val_accuracy: 0.8712\n",
      "Epoch 88/100\n",
      "380/380 [==============================] - 0s 64us/step - loss: 0.1764 - accuracy: 0.9421 - val_loss: 0.4033 - val_accuracy: 0.8589\n",
      "Epoch 89/100\n",
      "380/380 [==============================] - 0s 61us/step - loss: 0.1970 - accuracy: 0.9526 - val_loss: 0.4462 - val_accuracy: 0.7669\n",
      "Epoch 90/100\n",
      "380/380 [==============================] - 0s 60us/step - loss: 0.2217 - accuracy: 0.9395 - val_loss: 0.4144 - val_accuracy: 0.8834\n",
      "Epoch 91/100\n",
      "380/380 [==============================] - 0s 60us/step - loss: 0.1883 - accuracy: 0.9421 - val_loss: 0.3902 - val_accuracy: 0.8160\n",
      "Epoch 92/100\n",
      "380/380 [==============================] - 0s 76us/step - loss: 0.1776 - accuracy: 0.9579 - val_loss: 0.4097 - val_accuracy: 0.8773\n",
      "Epoch 93/100\n",
      "380/380 [==============================] - 0s 330us/step - loss: 0.1512 - accuracy: 0.9605 - val_loss: 0.4430 - val_accuracy: 0.8466\n",
      "Epoch 94/100\n",
      "380/380 [==============================] - ETA: 0s - loss: 0.1794 - accuracy: 0.95 - 0s 82us/step - loss: 0.1782 - accuracy: 0.9500 - val_loss: 0.3851 - val_accuracy: 0.8712\n",
      "Epoch 95/100\n",
      "380/380 [==============================] - 0s 91us/step - loss: 0.1791 - accuracy: 0.9579 - val_loss: 0.3693 - val_accuracy: 0.8834\n",
      "Epoch 96/100\n",
      "380/380 [==============================] - 0s 113us/step - loss: 0.2516 - accuracy: 0.9368 - val_loss: 0.5715 - val_accuracy: 0.8282\n",
      "Epoch 97/100\n",
      "380/380 [==============================] - 0s 97us/step - loss: 0.5365 - accuracy: 0.8895 - val_loss: 1.0090 - val_accuracy: 0.7178\n",
      "Epoch 98/100\n",
      "380/380 [==============================] - 0s 153us/step - loss: 0.3436 - accuracy: 0.9316 - val_loss: 0.4365 - val_accuracy: 0.8466\n",
      "Epoch 99/100\n",
      "380/380 [==============================] - 0s 79us/step - loss: 0.2468 - accuracy: 0.9079 - val_loss: 0.3788 - val_accuracy: 0.8589\n",
      "Epoch 100/100\n",
      "380/380 [==============================] - 0s 85us/step - loss: 0.2090 - accuracy: 0.9421 - val_loss: 0.5575 - val_accuracy: 0.8466\n"
     ]
    }
   ],
   "source": [
    "hist2_over3 = model2_over3.fit(X_sel_train_over, y_sel_train_over,\n",
    "          batch_size=64, epochs=100,\n",
    "          validation_data=(X_sel_test_over, y_sel_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 92.63%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist2_over3.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba7 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_lasso_2.xlsx\",\n",
    "                        sheet_name=2,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>NRS210</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.132076e-01</td>\n",
       "      <td>2.812180e-01</td>\n",
       "      <td>1.055744e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>NRS205</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.993202e-04</td>\n",
       "      <td>6.834937e-07</td>\n",
       "      <td>9.998000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>312</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.589463e-01</td>\n",
       "      <td>3.982787e-01</td>\n",
       "      <td>2.427750e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>GA15</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.589463e-01</td>\n",
       "      <td>3.982787e-01</td>\n",
       "      <td>2.427750e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>SR4035</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.589463e-01</td>\n",
       "      <td>3.982787e-01</td>\n",
       "      <td>2.427750e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>NRS383</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.477194e-01</td>\n",
       "      <td>4.522807e-01</td>\n",
       "      <td>1.761374e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>NRS218</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6.953657e-05</td>\n",
       "      <td>9.999305e-01</td>\n",
       "      <td>3.132419e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.713214e-09</td>\n",
       "      <td>6.656316e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>SR2852</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9.956684e-12</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>7.441288e-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>NRS248</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.999998e-01</td>\n",
       "      <td>1.958189e-07</td>\n",
       "      <td>1.001001e-12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>989 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   phage  strain  phenotype  prediction             0  \\\n",
       "0     p0006kpresabs_qual  NRS210          0           0  6.132076e-01   \n",
       "1     p0006kpresabs_qual  NRS205          2           2  1.993202e-04   \n",
       "2     p0006kpresabs_qual     312          2           1  3.589463e-01   \n",
       "3     p0006kpresabs_qual    GA15          2           1  3.589463e-01   \n",
       "4     p0006kpresabs_qual  SR4035          0           1  3.589463e-01   \n",
       "..                   ...     ...        ...         ...           ...   \n",
       "984  p0017Skpresabs_qual  NRS383          1           0  5.477194e-01   \n",
       "985  p0017Skpresabs_qual  NRS218          1           1  6.953657e-05   \n",
       "986  p0017Skpresabs_qual  NRS209          2           2  2.713214e-09   \n",
       "987  p0017Skpresabs_qual  SR2852          1           1  9.956684e-12   \n",
       "988  p0017Skpresabs_qual  NRS248          0           0  9.999998e-01   \n",
       "\n",
       "                1             2  \n",
       "0    2.812180e-01  1.055744e-01  \n",
       "1    6.834937e-07  9.998000e-01  \n",
       "2    3.982787e-01  2.427750e-01  \n",
       "3    3.982787e-01  2.427750e-01  \n",
       "4    3.982787e-01  2.427750e-01  \n",
       "..            ...           ...  \n",
       "984  4.522807e-01  1.761374e-08  \n",
       "985  9.999305e-01  3.132419e-10  \n",
       "986  6.656316e-09  1.000000e+00  \n",
       "987  1.000000e+00  7.441288e-26  \n",
       "988  1.958189e-07  1.001001e-12  \n",
       "\n",
       "[989 rows x 7 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.98438450e-03, 9.93894500e-01, 3.12100700e-03],\n",
       "       [9.84843130e-01, 1.35127930e-02, 1.64416230e-03],\n",
       "       [5.78978600e-02, 7.05047100e-01, 2.37055060e-01],\n",
       "       [1.12300610e-02, 8.99893100e-01, 8.88768800e-02],\n",
       "       [4.96935430e-02, 9.10956260e-01, 3.93501370e-02],\n",
       "       [9.80025650e-01, 4.50999480e-03, 1.54642640e-02],\n",
       "       [9.99996400e-01, 3.38867200e-06, 2.77013640e-07],\n",
       "       [9.99754250e-01, 5.15126700e-05, 1.94318390e-04],\n",
       "       [9.16462700e-02, 5.82356450e-01, 3.25997350e-01],\n",
       "       [8.05752900e-01, 1.48298830e-01, 4.59483340e-02],\n",
       "       [1.85752570e-01, 5.78999040e-01, 2.35248360e-01],\n",
       "       [2.98438450e-03, 9.93894500e-01, 3.12100700e-03],\n",
       "       [6.24211200e-02, 5.78912260e-01, 3.58666660e-01],\n",
       "       [1.72049780e-04, 1.63745750e-04, 9.99664200e-01],\n",
       "       [2.21175800e-01, 5.84191500e-01, 1.94632660e-01],\n",
       "       [7.39271640e-02, 4.86829340e-01, 4.39243470e-01],\n",
       "       [9.95143530e-01, 7.18895750e-04, 4.13758500e-03],\n",
       "       [9.23220700e-02, 4.88149670e-01, 4.19528370e-01],\n",
       "       [1.51050370e-03, 6.50761800e-02, 9.33413300e-01],\n",
       "       [4.98479430e-01, 4.20050350e-01, 8.14703200e-02],\n",
       "       [1.60005910e-05, 9.99961850e-01, 2.21884750e-05],\n",
       "       [7.52003400e-02, 8.43647400e-01, 8.11522800e-02],\n",
       "       [9.86606600e-01, 1.18507670e-02, 1.54259270e-03],\n",
       "       [4.98479430e-01, 4.20050350e-01, 8.14703200e-02],\n",
       "       [9.55367800e-01, 3.43981500e-02, 1.02340750e-02],\n",
       "       [4.15132460e-01, 4.77002380e-01, 1.07865160e-01],\n",
       "       [9.86864150e-01, 1.64163760e-05, 1.31193940e-02],\n",
       "       [9.86864150e-01, 1.64163760e-05, 1.31193940e-02],\n",
       "       [3.54076560e-04, 1.11366530e-02, 9.88509240e-01],\n",
       "       [1.85752570e-01, 5.78999040e-01, 2.35248360e-01],\n",
       "       [1.42873020e-02, 3.45800700e-01, 6.39912000e-01],\n",
       "       [2.66897470e-02, 2.64179900e-01, 7.09130350e-01],\n",
       "       [3.08718770e-01, 2.32426840e-01, 4.58854380e-01],\n",
       "       [6.41045800e-02, 8.51132000e-01, 8.47633400e-02],\n",
       "       [1.03749110e-03, 4.38751840e-03, 9.94574900e-01],\n",
       "       [1.92433920e-03, 1.46932970e-02, 9.83382400e-01],\n",
       "       [4.15132460e-01, 4.77002380e-01, 1.07865160e-01],\n",
       "       [9.83099700e-01, 1.67471710e-02, 1.53084900e-04],\n",
       "       [4.98479430e-01, 4.20050350e-01, 8.14703200e-02],\n",
       "       [4.86301540e-03, 8.91731600e-02, 9.05963840e-01],\n",
       "       [5.51043860e-02, 4.56959640e-01, 4.87936000e-01],\n",
       "       [7.16396670e-04, 4.03396670e-04, 9.98880200e-01],\n",
       "       [1.30513890e-01, 6.48068000e-01, 2.21418100e-01],\n",
       "       [3.37703000e-02, 9.48758240e-01, 1.74714400e-02],\n",
       "       [2.21175800e-01, 5.84191500e-01, 1.94632660e-01],\n",
       "       [1.69559360e-02, 8.49275350e-01, 1.33768700e-01],\n",
       "       [7.80277900e-01, 1.65112030e-01, 5.46099880e-02],\n",
       "       [9.23220700e-02, 4.88149670e-01, 4.19528370e-01],\n",
       "       [5.78978600e-02, 7.05047100e-01, 2.37055060e-01],\n",
       "       [1.82865040e-01, 4.95173070e-01, 3.21961940e-01],\n",
       "       [6.34475900e-03, 9.45578700e-01, 4.80765550e-02],\n",
       "       [2.27741400e-02, 7.67158600e-01, 2.10067300e-01],\n",
       "       [2.05730980e-02, 8.11108500e-01, 1.68318380e-01],\n",
       "       [5.60862050e-02, 5.28457900e-01, 4.15456000e-01],\n",
       "       [9.67679140e-01, 1.11171560e-02, 2.12037230e-02],\n",
       "       [3.97836400e-01, 4.47753220e-01, 1.54410380e-01],\n",
       "       [9.99930000e-01, 4.71704600e-05, 2.28231980e-05],\n",
       "       [2.54004910e-02, 5.32159030e-01, 4.42440450e-01],\n",
       "       [1.00046680e-02, 9.77158670e-01, 1.28366705e-02],\n",
       "       [9.99754250e-01, 5.15126700e-05, 1.94318390e-04],\n",
       "       [2.21068410e-01, 1.09711570e-01, 6.69220030e-01],\n",
       "       [9.86864150e-01, 1.64163760e-05, 1.31193940e-02],\n",
       "       [9.99996400e-01, 3.38867200e-06, 2.77013640e-07],\n",
       "       [9.99996400e-01, 3.38867200e-06, 2.77013640e-07],\n",
       "       [9.99930000e-01, 4.71704600e-05, 2.28231980e-05],\n",
       "       [9.98486400e-01, 7.25262700e-06, 1.50629470e-03],\n",
       "       [2.98438450e-03, 9.93894500e-01, 3.12100700e-03],\n",
       "       [7.83406300e-01, 2.08723550e-01, 7.87017200e-03],\n",
       "       [4.33928550e-01, 4.53925970e-01, 1.12145460e-01],\n",
       "       [4.98479430e-01, 4.20050350e-01, 8.14703200e-02],\n",
       "       [3.37703000e-02, 9.48758240e-01, 1.74714400e-02],\n",
       "       [1.01616600e-04, 9.94649700e-04, 9.98903750e-01],\n",
       "       [5.78978600e-02, 7.05047100e-01, 2.37055060e-01],\n",
       "       [2.05730980e-02, 8.11108500e-01, 1.68318380e-01],\n",
       "       [9.93774800e-01, 6.42727800e-05, 6.16085300e-03],\n",
       "       [2.27741400e-02, 7.67158600e-01, 2.10067300e-01],\n",
       "       [1.34323110e-03, 9.50257060e-01, 4.83996640e-02],\n",
       "       [7.23296250e-04, 1.60915400e-01, 8.38361300e-01],\n",
       "       [8.96794440e-01, 2.88872380e-02, 7.43183340e-02],\n",
       "       [9.99930000e-01, 4.71704600e-05, 2.28231980e-05],\n",
       "       [8.05752900e-01, 1.48298830e-01, 4.59483340e-02],\n",
       "       [6.61299560e-04, 5.78917750e-03, 9.93549500e-01],\n",
       "       [1.31012650e-01, 7.38841300e-02, 7.95103250e-01],\n",
       "       [7.44520660e-01, 8.03760250e-03, 2.47441770e-01],\n",
       "       [1.31012650e-01, 7.38841300e-02, 7.95103250e-01],\n",
       "       [9.98486400e-01, 7.25262700e-06, 1.50629470e-03],\n",
       "       [1.09196620e-03, 4.58986870e-03, 9.94318200e-01],\n",
       "       [9.67679140e-01, 1.11171560e-02, 2.12037230e-02],\n",
       "       [7.80277900e-01, 1.65112030e-01, 5.46099880e-02],\n",
       "       [9.95143530e-01, 7.18895750e-04, 4.13758500e-03],\n",
       "       [1.12300610e-02, 8.99893100e-01, 8.88768800e-02],\n",
       "       [2.90753990e-02, 5.07021500e-01, 4.63903100e-01],\n",
       "       [1.42873020e-02, 3.45800700e-01, 6.39912000e-01],\n",
       "       [1.61102920e-02, 1.22082360e-01, 8.61807350e-01],\n",
       "       [4.46454760e-03, 5.46318930e-02, 9.40903600e-01],\n",
       "       [1.42873020e-02, 3.45800700e-01, 6.39912000e-01],\n",
       "       [4.15132460e-01, 4.77002380e-01, 1.07865160e-01],\n",
       "       [9.86747600e-01, 6.85091740e-03, 6.40138750e-03],\n",
       "       [2.74411400e-07, 1.66149770e-04, 9.99833600e-01],\n",
       "       [9.29126000e-01, 6.85524640e-02, 2.32158580e-03],\n",
       "       [7.84925900e-01, 1.26427460e-02, 2.02431300e-01],\n",
       "       [1.81579420e-04, 3.32235400e-02, 9.66594900e-01],\n",
       "       [7.74621440e-02, 8.52951100e-01, 6.95867600e-02],\n",
       "       [6.61299560e-04, 5.78917750e-03, 9.93549500e-01],\n",
       "       [5.78978600e-02, 7.05047100e-01, 2.37055060e-01],\n",
       "       [1.42873020e-02, 3.45800700e-01, 6.39912000e-01],\n",
       "       [2.36399200e-02, 9.53719200e-01, 2.26408450e-02],\n",
       "       [4.74272600e-02, 8.49734200e-01, 1.02838580e-01],\n",
       "       [4.74272600e-02, 8.49734200e-01, 1.02838580e-01],\n",
       "       [6.68702830e-03, 2.98166620e-03, 9.90331300e-01],\n",
       "       [9.99754250e-01, 5.15126700e-05, 1.94318390e-04],\n",
       "       [8.96794440e-01, 2.88872380e-02, 7.43183340e-02],\n",
       "       [9.86747600e-01, 6.85091740e-03, 6.40138750e-03],\n",
       "       [1.58040000e-02, 5.43304440e-01, 4.40891600e-01],\n",
       "       [1.42873020e-02, 3.45800700e-01, 6.39912000e-01],\n",
       "       [9.99754250e-01, 5.15126700e-05, 1.94318390e-04],\n",
       "       [9.99996400e-01, 3.38867200e-06, 2.77013640e-07],\n",
       "       [7.39812040e-04, 9.93058200e-01, 6.20205750e-03],\n",
       "       [9.86747600e-01, 6.85091740e-03, 6.40138750e-03],\n",
       "       [4.83028600e-03, 1.17379080e-02, 9.83431760e-01],\n",
       "       [2.65554060e-04, 3.04185880e-03, 9.96692540e-01],\n",
       "       [1.42873020e-02, 3.45800700e-01, 6.39912000e-01],\n",
       "       [9.29126000e-01, 6.85524640e-02, 2.32158580e-03],\n",
       "       [2.13744360e-02, 8.68807550e-01, 1.09817960e-01],\n",
       "       [2.44819730e-02, 5.17155950e-01, 4.58362040e-01],\n",
       "       [3.37703000e-02, 9.48758240e-01, 1.74714400e-02],\n",
       "       [2.44395750e-02, 5.43883560e-01, 4.31676800e-01],\n",
       "       [1.35666630e-05, 1.28216450e-02, 9.87164860e-01],\n",
       "       [9.98212460e-01, 2.73958520e-04, 1.51366440e-03],\n",
       "       [5.29381900e-03, 1.66979830e-01, 8.27726360e-01],\n",
       "       [9.23220700e-02, 4.88149670e-01, 4.19528370e-01],\n",
       "       [9.86606600e-01, 1.18507670e-02, 1.54259270e-03],\n",
       "       [3.54076560e-04, 1.11366530e-02, 9.88509240e-01],\n",
       "       [6.34475900e-03, 9.45578700e-01, 4.80765550e-02],\n",
       "       [7.56983370e-03, 9.49089700e-01, 4.33404800e-02],\n",
       "       [9.98486400e-01, 7.25262700e-06, 1.50629470e-03],\n",
       "       [9.84843130e-01, 1.35127930e-02, 1.64416230e-03],\n",
       "       [2.21175800e-01, 5.84191500e-01, 1.94632660e-01],\n",
       "       [1.30552410e-01, 8.08507560e-01, 6.09401050e-02],\n",
       "       [3.16456560e-02, 7.44351450e-01, 2.24002820e-01],\n",
       "       [3.37703000e-02, 9.48758240e-01, 1.74714400e-02],\n",
       "       [1.42873020e-02, 3.45800700e-01, 6.39912000e-01],\n",
       "       [7.44520660e-01, 8.03760250e-03, 2.47441770e-01],\n",
       "       [3.89540980e-02, 8.90112760e-01, 7.09331000e-02],\n",
       "       [1.59260900e-01, 9.56709760e-02, 7.45068200e-01],\n",
       "       [6.86704700e-03, 3.17014930e-04, 9.92816000e-01],\n",
       "       [9.83099700e-01, 1.67471710e-02, 1.53084900e-04],\n",
       "       [2.13744360e-02, 8.68807550e-01, 1.09817960e-01],\n",
       "       [3.60175900e-03, 9.92595850e-01, 3.80244920e-03],\n",
       "       [1.42873020e-02, 3.45800700e-01, 6.39912000e-01],\n",
       "       [1.85752570e-01, 5.78999040e-01, 2.35248360e-01],\n",
       "       [2.13744360e-02, 8.68807550e-01, 1.09817960e-01],\n",
       "       [9.84843130e-01, 1.35127930e-02, 1.64416230e-03],\n",
       "       [1.60005910e-05, 9.99961850e-01, 2.21884750e-05],\n",
       "       [1.23313880e-01, 7.93369340e-02, 7.97349200e-01],\n",
       "       [9.98486400e-01, 7.25262700e-06, 1.50629470e-03],\n",
       "       [9.29126000e-01, 6.85524640e-02, 2.32158580e-03],\n",
       "       [2.60720160e-02, 9.19776560e-02, 8.81950300e-01],\n",
       "       [1.92747730e-06, 3.38090440e-04, 9.99660000e-01],\n",
       "       [1.12300610e-02, 8.99893100e-01, 8.88768800e-02],\n",
       "       [9.93774800e-01, 6.42727800e-05, 6.16085300e-03],\n",
       "       [8.05752900e-01, 1.48298830e-01, 4.59483340e-02],\n",
       "       [9.80025650e-01, 4.50999480e-03, 1.54642640e-02]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob7 = df_proba7[df_proba7['phage']=='p11kpresabsSTCC_qual'].iloc[:,-3:]\n",
    "y_prob7 = y_prob7.to_numpy()\n",
    "y_prob7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9534383076432006"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo7 = rocauc_ovo(y_sel_test_over, y_prob7, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9534383076432006"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr7 = rocauc_ovr(y_sel_test_over, y_prob7, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_sel_train_over, X_sel_test_over, y_sel_train_over, y_sel_test_over = train_test_split(X_sel_over, y_sel_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=890,\n",
    "                                                    stratify=y_sel_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat8 = pd.DataFrame(X_sel_test_over[:,-1])\n",
    "dat8['test'] = y_sel_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SR2852</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS054</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS157</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NY224</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS070</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>NY417</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>NRS051</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>NRS226</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>EUH13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>NRS110</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0  test\n",
       "0    SR2852     2\n",
       "1    NRS054     1\n",
       "2    NRS157     2\n",
       "3     NY224     1\n",
       "4    NRS070     1\n",
       "..      ...   ...\n",
       "158   NY417     2\n",
       "159  NRS051     1\n",
       "160  NRS226     1\n",
       "161   EUH13     0\n",
       "162  NRS110     2\n",
       "\n",
       "[163 rows x 2 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sel_train_over = X_sel_train_over[:,:-1]\n",
    "X_sel_test_over = X_sel_test_over[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2_over4 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_sel_train_over.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2_over4.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 380 samples, validate on 163 samples\n",
      "Epoch 1/100\n",
      "380/380 [==============================] - 0s 507us/step - loss: 23.6673 - accuracy: 0.3895 - val_loss: 11.0530 - val_accuracy: 0.3865\n",
      "Epoch 2/100\n",
      "380/380 [==============================] - 0s 140us/step - loss: 9.1186 - accuracy: 0.4316 - val_loss: 2.7990 - val_accuracy: 0.3620\n",
      "Epoch 3/100\n",
      "380/380 [==============================] - 0s 152us/step - loss: 2.7624 - accuracy: 0.3526 - val_loss: 2.8274 - val_accuracy: 0.3436\n",
      "Epoch 4/100\n",
      "380/380 [==============================] - 0s 194us/step - loss: 2.7151 - accuracy: 0.4000 - val_loss: 1.6933 - val_accuracy: 0.3926\n",
      "Epoch 5/100\n",
      "380/380 [==============================] - 0s 147us/step - loss: 1.3560 - accuracy: 0.5026 - val_loss: 1.1563 - val_accuracy: 0.4540\n",
      "Epoch 6/100\n",
      "380/380 [==============================] - 0s 106us/step - loss: 1.1565 - accuracy: 0.5605 - val_loss: 1.0801 - val_accuracy: 0.4663\n",
      "Epoch 7/100\n",
      "380/380 [==============================] - 0s 128us/step - loss: 1.1691 - accuracy: 0.5842 - val_loss: 1.2237 - val_accuracy: 0.4663\n",
      "Epoch 8/100\n",
      "380/380 [==============================] - 0s 122us/step - loss: 1.0701 - accuracy: 0.6289 - val_loss: 1.0558 - val_accuracy: 0.5399\n",
      "Epoch 9/100\n",
      "380/380 [==============================] - 0s 110us/step - loss: 1.0213 - accuracy: 0.6474 - val_loss: 1.1290 - val_accuracy: 0.5644\n",
      "Epoch 10/100\n",
      "380/380 [==============================] - 0s 242us/step - loss: 1.0075 - accuracy: 0.6474 - val_loss: 1.2389 - val_accuracy: 0.4908\n",
      "Epoch 11/100\n",
      "380/380 [==============================] - 0s 132us/step - loss: 0.9620 - accuracy: 0.6632 - val_loss: 1.0574 - val_accuracy: 0.5644\n",
      "Epoch 12/100\n",
      "380/380 [==============================] - 0s 131us/step - loss: 0.9529 - accuracy: 0.6474 - val_loss: 1.0173 - val_accuracy: 0.5521\n",
      "Epoch 13/100\n",
      "380/380 [==============================] - 0s 183us/step - loss: 1.1290 - accuracy: 0.6763 - val_loss: 0.9207 - val_accuracy: 0.5460\n",
      "Epoch 14/100\n",
      "380/380 [==============================] - 0s 123us/step - loss: 0.8623 - accuracy: 0.6895 - val_loss: 0.9460 - val_accuracy: 0.5399\n",
      "Epoch 15/100\n",
      "380/380 [==============================] - 0s 150us/step - loss: 0.8964 - accuracy: 0.6921 - val_loss: 0.8824 - val_accuracy: 0.6012\n",
      "Epoch 16/100\n",
      "380/380 [==============================] - 0s 139us/step - loss: 1.0469 - accuracy: 0.7289 - val_loss: 1.0698 - val_accuracy: 0.5583\n",
      "Epoch 17/100\n",
      "380/380 [==============================] - 0s 113us/step - loss: 0.8652 - accuracy: 0.7053 - val_loss: 1.2021 - val_accuracy: 0.5890\n",
      "Epoch 18/100\n",
      "380/380 [==============================] - 0s 111us/step - loss: 1.2848 - accuracy: 0.7263 - val_loss: 1.2238 - val_accuracy: 0.5644\n",
      "Epoch 19/100\n",
      "380/380 [==============================] - 0s 159us/step - loss: 1.1697 - accuracy: 0.7105 - val_loss: 1.1703 - val_accuracy: 0.6012\n",
      "Epoch 20/100\n",
      "380/380 [==============================] - 0s 110us/step - loss: 1.1533 - accuracy: 0.7289 - val_loss: 1.0808 - val_accuracy: 0.5828\n",
      "Epoch 21/100\n",
      "380/380 [==============================] - 0s 130us/step - loss: 0.9458 - accuracy: 0.7447 - val_loss: 0.8833 - val_accuracy: 0.6442\n",
      "Epoch 22/100\n",
      "380/380 [==============================] - 0s 80us/step - loss: 0.7848 - accuracy: 0.7421 - val_loss: 0.8675 - val_accuracy: 0.5951\n",
      "Epoch 23/100\n",
      "380/380 [==============================] - 0s 94us/step - loss: 0.7024 - accuracy: 0.7895 - val_loss: 1.1969 - val_accuracy: 0.5890\n",
      "Epoch 24/100\n",
      "380/380 [==============================] - 0s 69us/step - loss: 0.8497 - accuracy: 0.7816 - val_loss: 0.8044 - val_accuracy: 0.6564\n",
      "Epoch 25/100\n",
      "380/380 [==============================] - 0s 79us/step - loss: 0.6225 - accuracy: 0.8053 - val_loss: 0.8938 - val_accuracy: 0.6503\n",
      "Epoch 26/100\n",
      "380/380 [==============================] - 0s 79us/step - loss: 0.6824 - accuracy: 0.8079 - val_loss: 0.8824 - val_accuracy: 0.6074\n",
      "Epoch 27/100\n",
      "380/380 [==============================] - 0s 187us/step - loss: 0.5939 - accuracy: 0.7895 - val_loss: 0.9370 - val_accuracy: 0.5951\n",
      "Epoch 28/100\n",
      "380/380 [==============================] - 0s 283us/step - loss: 0.7784 - accuracy: 0.8000 - val_loss: 1.0627 - val_accuracy: 0.6442\n",
      "Epoch 29/100\n",
      "380/380 [==============================] - 0s 133us/step - loss: 0.9718 - accuracy: 0.7789 - val_loss: 1.2012 - val_accuracy: 0.5890\n",
      "Epoch 30/100\n",
      "380/380 [==============================] - 0s 110us/step - loss: 1.3894 - accuracy: 0.7684 - val_loss: 1.0151 - val_accuracy: 0.6503\n",
      "Epoch 31/100\n",
      "380/380 [==============================] - 0s 140us/step - loss: 0.9563 - accuracy: 0.7816 - val_loss: 1.1744 - val_accuracy: 0.5767\n",
      "Epoch 32/100\n",
      "380/380 [==============================] - 0s 175us/step - loss: 0.8341 - accuracy: 0.7842 - val_loss: 0.9709 - val_accuracy: 0.6196\n",
      "Epoch 33/100\n",
      "380/380 [==============================] - 0s 196us/step - loss: 0.6179 - accuracy: 0.8053 - val_loss: 0.7852 - val_accuracy: 0.6196\n",
      "Epoch 34/100\n",
      "380/380 [==============================] - 0s 175us/step - loss: 0.5817 - accuracy: 0.8211 - val_loss: 0.7536 - val_accuracy: 0.6687\n",
      "Epoch 35/100\n",
      "380/380 [==============================] - 0s 176us/step - loss: 0.7466 - accuracy: 0.8105 - val_loss: 0.9677 - val_accuracy: 0.6319\n",
      "Epoch 36/100\n",
      "380/380 [==============================] - 0s 208us/step - loss: 0.8336 - accuracy: 0.7895 - val_loss: 0.9740 - val_accuracy: 0.6810\n",
      "Epoch 37/100\n",
      "380/380 [==============================] - 0s 190us/step - loss: 0.6836 - accuracy: 0.8026 - val_loss: 0.8662 - val_accuracy: 0.6503\n",
      "Epoch 38/100\n",
      "380/380 [==============================] - 0s 158us/step - loss: 0.8177 - accuracy: 0.8000 - val_loss: 0.8463 - val_accuracy: 0.6380\n",
      "Epoch 39/100\n",
      "380/380 [==============================] - 0s 172us/step - loss: 0.5763 - accuracy: 0.8184 - val_loss: 0.7474 - val_accuracy: 0.6933\n",
      "Epoch 40/100\n",
      "380/380 [==============================] - 0s 186us/step - loss: 0.5679 - accuracy: 0.8342 - val_loss: 0.7828 - val_accuracy: 0.6687\n",
      "Epoch 41/100\n",
      "380/380 [==============================] - 0s 241us/step - loss: 0.4982 - accuracy: 0.8211 - val_loss: 0.6808 - val_accuracy: 0.6994\n",
      "Epoch 42/100\n",
      "380/380 [==============================] - 0s 144us/step - loss: 0.4868 - accuracy: 0.8342 - val_loss: 0.7552 - val_accuracy: 0.6380\n",
      "Epoch 43/100\n",
      "380/380 [==============================] - 0s 166us/step - loss: 0.4523 - accuracy: 0.8289 - val_loss: 0.7265 - val_accuracy: 0.6748\n",
      "Epoch 44/100\n",
      "380/380 [==============================] - 0s 118us/step - loss: 0.4542 - accuracy: 0.8500 - val_loss: 0.6883 - val_accuracy: 0.6994\n",
      "Epoch 45/100\n",
      "380/380 [==============================] - 0s 224us/step - loss: 0.4554 - accuracy: 0.8289 - val_loss: 0.7055 - val_accuracy: 0.6871\n",
      "Epoch 46/100\n",
      "380/380 [==============================] - 0s 147us/step - loss: 0.5243 - accuracy: 0.8395 - val_loss: 0.7957 - val_accuracy: 0.6319\n",
      "Epoch 47/100\n",
      "380/380 [==============================] - 0s 169us/step - loss: 0.4216 - accuracy: 0.8500 - val_loss: 0.7308 - val_accuracy: 0.6871\n",
      "Epoch 48/100\n",
      "380/380 [==============================] - 0s 145us/step - loss: 0.4364 - accuracy: 0.8395 - val_loss: 0.9015 - val_accuracy: 0.6074\n",
      "Epoch 49/100\n",
      "380/380 [==============================] - 0s 158us/step - loss: 0.4952 - accuracy: 0.8395 - val_loss: 0.9129 - val_accuracy: 0.6994\n",
      "Epoch 50/100\n",
      "380/380 [==============================] - 0s 131us/step - loss: 0.5711 - accuracy: 0.8395 - val_loss: 1.1314 - val_accuracy: 0.6258\n",
      "Epoch 51/100\n",
      "380/380 [==============================] - 0s 126us/step - loss: 0.8430 - accuracy: 0.8368 - val_loss: 1.1513 - val_accuracy: 0.7117\n",
      "Epoch 52/100\n",
      "380/380 [==============================] - 0s 174us/step - loss: 1.0676 - accuracy: 0.8342 - val_loss: 0.7006 - val_accuracy: 0.7178\n",
      "Epoch 53/100\n",
      "380/380 [==============================] - 0s 163us/step - loss: 0.5460 - accuracy: 0.8500 - val_loss: 0.8047 - val_accuracy: 0.6687\n",
      "Epoch 54/100\n",
      "380/380 [==============================] - 0s 103us/step - loss: 0.5046 - accuracy: 0.8763 - val_loss: 0.6851 - val_accuracy: 0.7423\n",
      "Epoch 55/100\n",
      "380/380 [==============================] - 0s 101us/step - loss: 0.4433 - accuracy: 0.8684 - val_loss: 0.8046 - val_accuracy: 0.6871\n",
      "Epoch 56/100\n",
      "380/380 [==============================] - 0s 76us/step - loss: 0.5599 - accuracy: 0.8579 - val_loss: 0.8615 - val_accuracy: 0.7117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "380/380 [==============================] - 0s 86us/step - loss: 1.1973 - accuracy: 0.8053 - val_loss: 1.3176 - val_accuracy: 0.6380\n",
      "Epoch 58/100\n",
      "380/380 [==============================] - 0s 74us/step - loss: 0.9236 - accuracy: 0.8342 - val_loss: 0.8826 - val_accuracy: 0.6135\n",
      "Epoch 59/100\n",
      "380/380 [==============================] - 0s 75us/step - loss: 0.8995 - accuracy: 0.8447 - val_loss: 0.9381 - val_accuracy: 0.7485\n",
      "Epoch 60/100\n",
      "380/380 [==============================] - 0s 88us/step - loss: 0.4548 - accuracy: 0.8842 - val_loss: 0.9305 - val_accuracy: 0.6810\n",
      "Epoch 61/100\n",
      "380/380 [==============================] - 0s 84us/step - loss: 0.3935 - accuracy: 0.8526 - val_loss: 0.7013 - val_accuracy: 0.7607\n",
      "Epoch 62/100\n",
      "380/380 [==============================] - 0s 100us/step - loss: 0.4821 - accuracy: 0.8658 - val_loss: 1.1115 - val_accuracy: 0.7362\n",
      "Epoch 63/100\n",
      "380/380 [==============================] - 0s 127us/step - loss: 0.5977 - accuracy: 0.8711 - val_loss: 0.6336 - val_accuracy: 0.7791\n",
      "Epoch 64/100\n",
      "380/380 [==============================] - 0s 245us/step - loss: 0.5314 - accuracy: 0.8684 - val_loss: 0.7944 - val_accuracy: 0.7607\n",
      "Epoch 65/100\n",
      "380/380 [==============================] - 0s 176us/step - loss: 0.4688 - accuracy: 0.8789 - val_loss: 0.7261 - val_accuracy: 0.6933\n",
      "Epoch 66/100\n",
      "380/380 [==============================] - 0s 144us/step - loss: 0.4074 - accuracy: 0.8605 - val_loss: 0.9209 - val_accuracy: 0.7301\n",
      "Epoch 67/100\n",
      "380/380 [==============================] - 0s 228us/step - loss: 0.4138 - accuracy: 0.8789 - val_loss: 0.6604 - val_accuracy: 0.7730\n",
      "Epoch 68/100\n",
      "380/380 [==============================] - 0s 104us/step - loss: 0.5465 - accuracy: 0.8789 - val_loss: 0.8935 - val_accuracy: 0.7730\n",
      "Epoch 69/100\n",
      "380/380 [==============================] - 0s 135us/step - loss: 0.6150 - accuracy: 0.8816 - val_loss: 0.8299 - val_accuracy: 0.7423\n",
      "Epoch 70/100\n",
      "380/380 [==============================] - 0s 109us/step - loss: 0.3998 - accuracy: 0.8947 - val_loss: 0.6789 - val_accuracy: 0.7546\n",
      "Epoch 71/100\n",
      "380/380 [==============================] - 0s 132us/step - loss: 0.3230 - accuracy: 0.8921 - val_loss: 0.6664 - val_accuracy: 0.7669\n",
      "Epoch 72/100\n",
      "380/380 [==============================] - 0s 115us/step - loss: 0.4044 - accuracy: 0.8921 - val_loss: 0.6668 - val_accuracy: 0.7362\n",
      "Epoch 73/100\n",
      "380/380 [==============================] - 0s 92us/step - loss: 0.5369 - accuracy: 0.8579 - val_loss: 1.1003 - val_accuracy: 0.6994\n",
      "Epoch 74/100\n",
      "380/380 [==============================] - 0s 75us/step - loss: 0.7878 - accuracy: 0.8684 - val_loss: 0.9453 - val_accuracy: 0.6933\n",
      "Epoch 75/100\n",
      "380/380 [==============================] - 0s 87us/step - loss: 0.5561 - accuracy: 0.8553 - val_loss: 0.6252 - val_accuracy: 0.7791\n",
      "Epoch 76/100\n",
      "380/380 [==============================] - 0s 83us/step - loss: 0.5171 - accuracy: 0.8842 - val_loss: 0.7237 - val_accuracy: 0.7546\n",
      "Epoch 77/100\n",
      "380/380 [==============================] - 0s 121us/step - loss: 0.5044 - accuracy: 0.8579 - val_loss: 0.9325 - val_accuracy: 0.6564\n",
      "Epoch 78/100\n",
      "380/380 [==============================] - 0s 103us/step - loss: 0.6589 - accuracy: 0.8553 - val_loss: 0.6992 - val_accuracy: 0.7730\n",
      "Epoch 79/100\n",
      "380/380 [==============================] - 0s 118us/step - loss: 0.5435 - accuracy: 0.8684 - val_loss: 0.8229 - val_accuracy: 0.7055\n",
      "Epoch 80/100\n",
      "380/380 [==============================] - 0s 85us/step - loss: 0.5133 - accuracy: 0.8816 - val_loss: 0.9564 - val_accuracy: 0.6994\n",
      "Epoch 81/100\n",
      "380/380 [==============================] - 0s 104us/step - loss: 0.4620 - accuracy: 0.8789 - val_loss: 0.6408 - val_accuracy: 0.7607\n",
      "Epoch 82/100\n",
      "380/380 [==============================] - 0s 90us/step - loss: 0.4156 - accuracy: 0.9026 - val_loss: 0.7813 - val_accuracy: 0.7607\n",
      "Epoch 83/100\n",
      "380/380 [==============================] - 0s 102us/step - loss: 0.4914 - accuracy: 0.8763 - val_loss: 0.7592 - val_accuracy: 0.6810\n",
      "Epoch 84/100\n",
      "380/380 [==============================] - 0s 109us/step - loss: 0.3577 - accuracy: 0.8789 - val_loss: 0.6059 - val_accuracy: 0.7853\n",
      "Epoch 85/100\n",
      "380/380 [==============================] - 0s 109us/step - loss: 0.4821 - accuracy: 0.8816 - val_loss: 0.9213 - val_accuracy: 0.7607\n",
      "Epoch 86/100\n",
      "380/380 [==============================] - 0s 75us/step - loss: 0.5487 - accuracy: 0.8789 - val_loss: 0.7700 - val_accuracy: 0.6810\n",
      "Epoch 87/100\n",
      "380/380 [==============================] - 0s 79us/step - loss: 0.3677 - accuracy: 0.8684 - val_loss: 0.7432 - val_accuracy: 0.8037\n",
      "Epoch 88/100\n",
      "380/380 [==============================] - 0s 89us/step - loss: 0.6793 - accuracy: 0.8553 - val_loss: 0.7513 - val_accuracy: 0.7853\n",
      "Epoch 89/100\n",
      "380/380 [==============================] - 0s 71us/step - loss: 0.5128 - accuracy: 0.8632 - val_loss: 0.9010 - val_accuracy: 0.7669\n",
      "Epoch 90/100\n",
      "380/380 [==============================] - 0s 77us/step - loss: 0.6031 - accuracy: 0.8789 - val_loss: 0.7458 - val_accuracy: 0.6933\n",
      "Epoch 91/100\n",
      "380/380 [==============================] - 0s 73us/step - loss: 0.3547 - accuracy: 0.8684 - val_loss: 0.6576 - val_accuracy: 0.7485\n",
      "Epoch 92/100\n",
      "380/380 [==============================] - 0s 84us/step - loss: 0.2781 - accuracy: 0.9000 - val_loss: 0.5867 - val_accuracy: 0.7914\n",
      "Epoch 93/100\n",
      "380/380 [==============================] - 0s 93us/step - loss: 0.2874 - accuracy: 0.9053 - val_loss: 0.6175 - val_accuracy: 0.7853\n",
      "Epoch 94/100\n",
      "380/380 [==============================] - 0s 69us/step - loss: 0.3147 - accuracy: 0.9053 - val_loss: 0.6519 - val_accuracy: 0.7546\n",
      "Epoch 95/100\n",
      "380/380 [==============================] - 0s 114us/step - loss: 0.3584 - accuracy: 0.8947 - val_loss: 0.6761 - val_accuracy: 0.7607\n",
      "Epoch 96/100\n",
      "380/380 [==============================] - 0s 117us/step - loss: 0.4134 - accuracy: 0.8711 - val_loss: 0.7185 - val_accuracy: 0.7853\n",
      "Epoch 97/100\n",
      "380/380 [==============================] - 0s 117us/step - loss: 0.4890 - accuracy: 0.8842 - val_loss: 0.5784 - val_accuracy: 0.8282\n",
      "Epoch 98/100\n",
      "380/380 [==============================] - 0s 81us/step - loss: 0.3800 - accuracy: 0.9105 - val_loss: 0.7693 - val_accuracy: 0.7791\n",
      "Epoch 99/100\n",
      "380/380 [==============================] - 0s 102us/step - loss: 0.5251 - accuracy: 0.8868 - val_loss: 0.7172 - val_accuracy: 0.7301\n",
      "Epoch 100/100\n",
      "380/380 [==============================] - 0s 104us/step - loss: 0.3007 - accuracy: 0.8868 - val_loss: 0.9470 - val_accuracy: 0.7730\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a357a75f8>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2_over4.fit(X_sel_train_over, y_sel_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_sel_test_over, y_sel_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163/163 [==============================] - 0s 62us/step\n",
      "over-sampling test accuracy: 81.60%\n"
     ]
    }
   ],
   "source": [
    "acc_test2_over4 = model2_over4.evaluate(X_sel_test_over, y_sel_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test2_over4*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 2, 2, 1, 1, 2, 0, 2, 0, 2, 2, 2, 1, 1, 0, 2, 1, 2, 0, 0, 1,\n",
       "       2, 2, 0, 2, 2, 2, 2, 0, 0, 0, 2, 2, 1, 0, 0, 2, 1, 0, 2, 1, 1, 0,\n",
       "       0, 2, 2, 0, 1, 2, 1, 0, 1, 1, 1, 1, 0, 1, 2, 1, 0, 2, 2, 0, 0, 0,\n",
       "       0, 1, 1, 0, 2, 0, 1, 2, 1, 1, 1, 2, 1, 0, 0, 0, 2, 2, 2, 1, 2, 2,\n",
       "       0, 2, 0, 2, 0, 2, 2, 1, 2, 0, 2, 1, 1, 2, 0, 1, 1, 2, 2, 0, 2, 2,\n",
       "       1, 1, 1, 0, 0, 2, 0, 2, 1, 2, 1, 2, 2, 2, 2, 2, 0, 0, 0, 1, 2, 0,\n",
       "       2, 1, 1, 1, 0, 1, 0, 1, 1, 1, 2, 1, 1, 1, 2, 0, 0, 1, 1, 2, 0, 0,\n",
       "       2, 2, 2, 2, 2, 1, 1, 2, 0])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred8 = model2_over4.predict_classes(X_sel_test_over)\n",
    "pred8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SR2852</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS054</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS157</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NY224</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS070</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>NY417</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>NRS051</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>NRS226</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>EUH13</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>NRS110</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0  test  pred\n",
       "0    SR2852     2     2\n",
       "1    NRS054     1     1\n",
       "2    NRS157     2     2\n",
       "3     NY224     1     2\n",
       "4    NRS070     1     1\n",
       "..      ...   ...   ...\n",
       "158   NY417     2     2\n",
       "159  NRS051     1     1\n",
       "160  NRS226     1     1\n",
       "161   EUH13     0     2\n",
       "162  NRS110     2     0\n",
       "\n",
       "[163 rows x 3 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat8['pred'] = pred8\n",
    "dat8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba8 = model2_over4.predict_proba(X_sel_test_over)\n",
    "dat_proba8 = pd.DataFrame(proba8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.758889e-03</td>\n",
       "      <td>4.763594e-01</td>\n",
       "      <td>0.517882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.463946e-04</td>\n",
       "      <td>7.362460e-01</td>\n",
       "      <td>0.262808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.785490e-03</td>\n",
       "      <td>2.730639e-02</td>\n",
       "      <td>0.970908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.112390e-02</td>\n",
       "      <td>7.180278e-02</td>\n",
       "      <td>0.897073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.501458e-06</td>\n",
       "      <td>9.983050e-01</td>\n",
       "      <td>0.001693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>3.112390e-02</td>\n",
       "      <td>7.180278e-02</td>\n",
       "      <td>0.897073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>1.700311e-02</td>\n",
       "      <td>9.685482e-01</td>\n",
       "      <td>0.014449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>4.715491e-05</td>\n",
       "      <td>9.585645e-01</td>\n",
       "      <td>0.041388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>4.814243e-07</td>\n",
       "      <td>6.112870e-10</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>9.710062e-01</td>\n",
       "      <td>1.498518e-02</td>\n",
       "      <td>0.014009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0             1         2\n",
       "0    5.758889e-03  4.763594e-01  0.517882\n",
       "1    9.463946e-04  7.362460e-01  0.262808\n",
       "2    1.785490e-03  2.730639e-02  0.970908\n",
       "3    3.112390e-02  7.180278e-02  0.897073\n",
       "4    2.501458e-06  9.983050e-01  0.001693\n",
       "..            ...           ...       ...\n",
       "158  3.112390e-02  7.180278e-02  0.897073\n",
       "159  1.700311e-02  9.685482e-01  0.014449\n",
       "160  4.715491e-05  9.585645e-01  0.041388\n",
       "161  4.814243e-07  6.112870e-10  1.000000\n",
       "162  9.710062e-01  1.498518e-02  0.014009\n",
       "\n",
       "[163 rows x 3 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba8.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba8.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat8.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/8p11ST.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 380 samples, validate on 163 samples\n",
      "Epoch 1/100\n",
      "380/380 [==============================] - 0s 177us/step - loss: 0.5560 - accuracy: 0.8974 - val_loss: 0.4792 - val_accuracy: 0.8589\n",
      "Epoch 2/100\n",
      "380/380 [==============================] - 0s 170us/step - loss: 0.4037 - accuracy: 0.8868 - val_loss: 0.4027 - val_accuracy: 0.8773\n",
      "Epoch 3/100\n",
      "380/380 [==============================] - 0s 135us/step - loss: 1.4824 - accuracy: 0.8632 - val_loss: 0.7971 - val_accuracy: 0.8037\n",
      "Epoch 4/100\n",
      "380/380 [==============================] - 0s 112us/step - loss: 0.5743 - accuracy: 0.8684 - val_loss: 0.5470 - val_accuracy: 0.7914\n",
      "Epoch 5/100\n",
      "380/380 [==============================] - 0s 128us/step - loss: 0.4272 - accuracy: 0.8789 - val_loss: 0.6317 - val_accuracy: 0.7975\n",
      "Epoch 6/100\n",
      "380/380 [==============================] - 0s 124us/step - loss: 0.4645 - accuracy: 0.8974 - val_loss: 0.5139 - val_accuracy: 0.8528\n",
      "Epoch 7/100\n",
      "380/380 [==============================] - 0s 123us/step - loss: 0.3236 - accuracy: 0.9053 - val_loss: 0.5066 - val_accuracy: 0.7975\n",
      "Epoch 8/100\n",
      "380/380 [==============================] - 0s 129us/step - loss: 0.3179 - accuracy: 0.9026 - val_loss: 0.4070 - val_accuracy: 0.8466\n",
      "Epoch 9/100\n",
      "380/380 [==============================] - 0s 122us/step - loss: 0.2485 - accuracy: 0.9132 - val_loss: 0.4370 - val_accuracy: 0.8405\n",
      "Epoch 10/100\n",
      "380/380 [==============================] - 0s 130us/step - loss: 0.2663 - accuracy: 0.8947 - val_loss: 0.4648 - val_accuracy: 0.8098\n",
      "Epoch 11/100\n",
      "380/380 [==============================] - 0s 124us/step - loss: 0.3852 - accuracy: 0.8868 - val_loss: 0.5718 - val_accuracy: 0.8282\n",
      "Epoch 12/100\n",
      "380/380 [==============================] - 0s 110us/step - loss: 0.3073 - accuracy: 0.9026 - val_loss: 0.4059 - val_accuracy: 0.8466\n",
      "Epoch 13/100\n",
      "380/380 [==============================] - 0s 128us/step - loss: 0.3130 - accuracy: 0.9079 - val_loss: 0.5505 - val_accuracy: 0.8282\n",
      "Epoch 14/100\n",
      "380/380 [==============================] - 0s 132us/step - loss: 0.4193 - accuracy: 0.8868 - val_loss: 0.3953 - val_accuracy: 0.8528\n",
      "Epoch 15/100\n",
      "380/380 [==============================] - 0s 142us/step - loss: 0.2167 - accuracy: 0.9289 - val_loss: 0.4366 - val_accuracy: 0.8528\n",
      "Epoch 16/100\n",
      "380/380 [==============================] - 0s 133us/step - loss: 0.2907 - accuracy: 0.9158 - val_loss: 0.4482 - val_accuracy: 0.8528\n",
      "Epoch 17/100\n",
      "380/380 [==============================] - 0s 182us/step - loss: 0.2885 - accuracy: 0.8947 - val_loss: 0.4016 - val_accuracy: 0.8834\n",
      "Epoch 18/100\n",
      "380/380 [==============================] - 0s 143us/step - loss: 0.3516 - accuracy: 0.9026 - val_loss: 0.4219 - val_accuracy: 0.8466\n",
      "Epoch 19/100\n",
      "380/380 [==============================] - 0s 134us/step - loss: 0.2647 - accuracy: 0.9105 - val_loss: 0.3990 - val_accuracy: 0.8773\n",
      "Epoch 20/100\n",
      "380/380 [==============================] - 0s 107us/step - loss: 0.3602 - accuracy: 0.8974 - val_loss: 0.4182 - val_accuracy: 0.8466\n",
      "Epoch 21/100\n",
      "380/380 [==============================] - 0s 106us/step - loss: 0.4567 - accuracy: 0.8789 - val_loss: 0.4968 - val_accuracy: 0.8528\n",
      "Epoch 22/100\n",
      "380/380 [==============================] - 0s 115us/step - loss: 0.2305 - accuracy: 0.9237 - val_loss: 0.4358 - val_accuracy: 0.8773\n",
      "Epoch 23/100\n",
      "380/380 [==============================] - 0s 119us/step - loss: 0.3363 - accuracy: 0.9105 - val_loss: 0.4203 - val_accuracy: 0.8528\n",
      "Epoch 24/100\n",
      "380/380 [==============================] - 0s 120us/step - loss: 0.4155 - accuracy: 0.8947 - val_loss: 0.5837 - val_accuracy: 0.8344\n",
      "Epoch 25/100\n",
      "380/380 [==============================] - 0s 128us/step - loss: 0.5589 - accuracy: 0.8895 - val_loss: 0.4662 - val_accuracy: 0.8098\n",
      "Epoch 26/100\n",
      "380/380 [==============================] - 0s 135us/step - loss: 0.6141 - accuracy: 0.8368 - val_loss: 0.6705 - val_accuracy: 0.8221\n",
      "Epoch 27/100\n",
      "380/380 [==============================] - 0s 147us/step - loss: 0.4415 - accuracy: 0.8579 - val_loss: 0.5656 - val_accuracy: 0.7914\n",
      "Epoch 28/100\n",
      "380/380 [==============================] - 0s 141us/step - loss: 0.5017 - accuracy: 0.8632 - val_loss: 0.4660 - val_accuracy: 0.8405\n",
      "Epoch 29/100\n",
      "380/380 [==============================] - 0s 116us/step - loss: 0.2931 - accuracy: 0.9105 - val_loss: 0.5229 - val_accuracy: 0.7975\n",
      "Epoch 30/100\n",
      "380/380 [==============================] - 0s 107us/step - loss: 0.2747 - accuracy: 0.8868 - val_loss: 0.6938 - val_accuracy: 0.7791\n",
      "Epoch 31/100\n",
      "380/380 [==============================] - 0s 114us/step - loss: 0.5361 - accuracy: 0.9132 - val_loss: 0.3707 - val_accuracy: 0.9018\n",
      "Epoch 32/100\n",
      "380/380 [==============================] - 0s 122us/step - loss: 0.2313 - accuracy: 0.9211 - val_loss: 0.4575 - val_accuracy: 0.8528\n",
      "Epoch 33/100\n",
      "380/380 [==============================] - 0s 99us/step - loss: 0.3338 - accuracy: 0.8868 - val_loss: 0.4339 - val_accuracy: 0.8712\n",
      "Epoch 34/100\n",
      "380/380 [==============================] - 0s 98us/step - loss: 0.3295 - accuracy: 0.9105 - val_loss: 0.4518 - val_accuracy: 0.8344\n",
      "Epoch 35/100\n",
      "380/380 [==============================] - 0s 89us/step - loss: 0.2177 - accuracy: 0.9105 - val_loss: 0.3789 - val_accuracy: 0.8834\n",
      "Epoch 36/100\n",
      "380/380 [==============================] - 0s 97us/step - loss: 0.2483 - accuracy: 0.9211 - val_loss: 0.4263 - val_accuracy: 0.8405\n",
      "Epoch 37/100\n",
      "380/380 [==============================] - 0s 121us/step - loss: 0.2572 - accuracy: 0.9237 - val_loss: 0.3869 - val_accuracy: 0.8834\n",
      "Epoch 38/100\n",
      "380/380 [==============================] - 0s 138us/step - loss: 0.3095 - accuracy: 0.9263 - val_loss: 0.5493 - val_accuracy: 0.8098\n",
      "Epoch 39/100\n",
      "380/380 [==============================] - 0s 118us/step - loss: 0.2956 - accuracy: 0.9132 - val_loss: 0.4609 - val_accuracy: 0.8589\n",
      "Epoch 40/100\n",
      "380/380 [==============================] - 0s 125us/step - loss: 0.3858 - accuracy: 0.9000 - val_loss: 0.5266 - val_accuracy: 0.8160\n",
      "Epoch 41/100\n",
      "380/380 [==============================] - 0s 119us/step - loss: 0.2495 - accuracy: 0.9158 - val_loss: 0.4402 - val_accuracy: 0.8528\n",
      "Epoch 42/100\n",
      "380/380 [==============================] - 0s 134us/step - loss: 0.4721 - accuracy: 0.8974 - val_loss: 0.5059 - val_accuracy: 0.8528\n",
      "Epoch 43/100\n",
      "380/380 [==============================] - 0s 114us/step - loss: 0.3916 - accuracy: 0.8947 - val_loss: 0.3747 - val_accuracy: 0.9018\n",
      "Epoch 44/100\n",
      "380/380 [==============================] - 0s 117us/step - loss: 0.2309 - accuracy: 0.9263 - val_loss: 0.4021 - val_accuracy: 0.8712\n",
      "Epoch 45/100\n",
      "380/380 [==============================] - 0s 86us/step - loss: 0.1988 - accuracy: 0.9263 - val_loss: 0.4190 - val_accuracy: 0.8528\n",
      "Epoch 46/100\n",
      "380/380 [==============================] - 0s 82us/step - loss: 0.1817 - accuracy: 0.9237 - val_loss: 0.4368 - val_accuracy: 0.8650\n",
      "Epoch 47/100\n",
      "380/380 [==============================] - 0s 81us/step - loss: 0.3618 - accuracy: 0.9105 - val_loss: 0.4210 - val_accuracy: 0.8528\n",
      "Epoch 48/100\n",
      "380/380 [==============================] - 0s 78us/step - loss: 0.2887 - accuracy: 0.9158 - val_loss: 0.3895 - val_accuracy: 0.9018\n",
      "Epoch 49/100\n",
      "380/380 [==============================] - 0s 81us/step - loss: 0.2084 - accuracy: 0.9395 - val_loss: 0.4057 - val_accuracy: 0.8896\n",
      "Epoch 50/100\n",
      "380/380 [==============================] - 0s 89us/step - loss: 0.3626 - accuracy: 0.9026 - val_loss: 0.4198 - val_accuracy: 0.8528\n",
      "Epoch 51/100\n",
      "380/380 [==============================] - 0s 85us/step - loss: 0.2384 - accuracy: 0.9132 - val_loss: 0.5015 - val_accuracy: 0.8712\n",
      "Epoch 52/100\n",
      "380/380 [==============================] - 0s 93us/step - loss: 0.4357 - accuracy: 0.9289 - val_loss: 0.4186 - val_accuracy: 0.8712\n",
      "Epoch 53/100\n",
      "380/380 [==============================] - 0s 91us/step - loss: 0.2663 - accuracy: 0.9079 - val_loss: 0.4734 - val_accuracy: 0.8344\n",
      "Epoch 54/100\n",
      "380/380 [==============================] - 0s 113us/step - loss: 0.1951 - accuracy: 0.9158 - val_loss: 0.4049 - val_accuracy: 0.8712\n",
      "Epoch 55/100\n",
      "380/380 [==============================] - 0s 101us/step - loss: 0.1678 - accuracy: 0.9368 - val_loss: 0.3761 - val_accuracy: 0.8957\n",
      "Epoch 56/100\n",
      "380/380 [==============================] - 0s 87us/step - loss: 0.1820 - accuracy: 0.9447 - val_loss: 0.4233 - val_accuracy: 0.8466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "380/380 [==============================] - 0s 83us/step - loss: 0.3118 - accuracy: 0.9158 - val_loss: 0.6091 - val_accuracy: 0.8466\n",
      "Epoch 58/100\n",
      "380/380 [==============================] - 0s 81us/step - loss: 0.5464 - accuracy: 0.8947 - val_loss: 0.3799 - val_accuracy: 0.8773\n",
      "Epoch 59/100\n",
      "380/380 [==============================] - 0s 82us/step - loss: 0.3682 - accuracy: 0.8842 - val_loss: 0.4992 - val_accuracy: 0.8221\n",
      "Epoch 60/100\n",
      "380/380 [==============================] - 0s 81us/step - loss: 0.2859 - accuracy: 0.9158 - val_loss: 0.4161 - val_accuracy: 0.8896\n",
      "Epoch 61/100\n",
      "380/380 [==============================] - 0s 82us/step - loss: 0.2633 - accuracy: 0.9211 - val_loss: 0.4277 - val_accuracy: 0.8466\n",
      "Epoch 62/100\n",
      "380/380 [==============================] - 0s 81us/step - loss: 0.1886 - accuracy: 0.9289 - val_loss: 0.3790 - val_accuracy: 0.8896\n",
      "Epoch 63/100\n",
      "380/380 [==============================] - 0s 97us/step - loss: 0.2333 - accuracy: 0.9237 - val_loss: 0.4022 - val_accuracy: 0.8957\n",
      "Epoch 64/100\n",
      "380/380 [==============================] - 0s 90us/step - loss: 0.3059 - accuracy: 0.9237 - val_loss: 0.5290 - val_accuracy: 0.8037\n",
      "Epoch 65/100\n",
      "380/380 [==============================] - 0s 98us/step - loss: 0.2941 - accuracy: 0.9132 - val_loss: 0.4017 - val_accuracy: 0.8712\n",
      "Epoch 66/100\n",
      "380/380 [==============================] - 0s 87us/step - loss: 0.2015 - accuracy: 0.9237 - val_loss: 0.4248 - val_accuracy: 0.8650\n",
      "Epoch 67/100\n",
      "380/380 [==============================] - 0s 81us/step - loss: 0.2193 - accuracy: 0.9342 - val_loss: 0.3634 - val_accuracy: 0.9141\n",
      "Epoch 68/100\n",
      "380/380 [==============================] - 0s 79us/step - loss: 0.1879 - accuracy: 0.9342 - val_loss: 0.3811 - val_accuracy: 0.8957\n",
      "Epoch 69/100\n",
      "380/380 [==============================] - 0s 91us/step - loss: 0.2407 - accuracy: 0.9421 - val_loss: 0.3838 - val_accuracy: 0.8834\n",
      "Epoch 70/100\n",
      "380/380 [==============================] - 0s 93us/step - loss: 0.1860 - accuracy: 0.9289 - val_loss: 0.4462 - val_accuracy: 0.9018\n",
      "Epoch 71/100\n",
      "380/380 [==============================] - 0s 91us/step - loss: 0.2651 - accuracy: 0.9316 - val_loss: 0.4985 - val_accuracy: 0.8221\n",
      "Epoch 72/100\n",
      "380/380 [==============================] - 0s 89us/step - loss: 0.2313 - accuracy: 0.9237 - val_loss: 0.6232 - val_accuracy: 0.8098\n",
      "Epoch 73/100\n",
      "380/380 [==============================] - 0s 101us/step - loss: 0.4225 - accuracy: 0.9211 - val_loss: 0.4430 - val_accuracy: 0.8528\n",
      "Epoch 74/100\n",
      "380/380 [==============================] - 0s 112us/step - loss: 0.4634 - accuracy: 0.9053 - val_loss: 0.5638 - val_accuracy: 0.8405\n",
      "Epoch 75/100\n",
      "380/380 [==============================] - 0s 114us/step - loss: 0.6301 - accuracy: 0.9079 - val_loss: 0.3786 - val_accuracy: 0.8712\n",
      "Epoch 76/100\n",
      "380/380 [==============================] - 0s 110us/step - loss: 0.1888 - accuracy: 0.9316 - val_loss: 0.4126 - val_accuracy: 0.8896\n",
      "Epoch 77/100\n",
      "380/380 [==============================] - 0s 98us/step - loss: 0.1484 - accuracy: 0.9474 - val_loss: 0.3982 - val_accuracy: 0.8957\n",
      "Epoch 78/100\n",
      "380/380 [==============================] - 0s 89us/step - loss: 0.1641 - accuracy: 0.9421 - val_loss: 0.4934 - val_accuracy: 0.8344\n",
      "Epoch 79/100\n",
      "380/380 [==============================] - 0s 88us/step - loss: 0.3039 - accuracy: 0.9368 - val_loss: 0.3992 - val_accuracy: 0.8834\n",
      "Epoch 80/100\n",
      "380/380 [==============================] - 0s 86us/step - loss: 0.1536 - accuracy: 0.9421 - val_loss: 0.4478 - val_accuracy: 0.8589\n",
      "Epoch 81/100\n",
      "380/380 [==============================] - 0s 82us/step - loss: 0.1723 - accuracy: 0.9395 - val_loss: 0.4516 - val_accuracy: 0.8957\n",
      "Epoch 82/100\n",
      "380/380 [==============================] - 0s 88us/step - loss: 0.2193 - accuracy: 0.9447 - val_loss: 0.4640 - val_accuracy: 0.8466\n",
      "Epoch 83/100\n",
      "380/380 [==============================] - 0s 83us/step - loss: 0.1499 - accuracy: 0.9316 - val_loss: 0.4026 - val_accuracy: 0.8712\n",
      "Epoch 84/100\n",
      "380/380 [==============================] - 0s 94us/step - loss: 0.1540 - accuracy: 0.9342 - val_loss: 0.4163 - val_accuracy: 0.8405\n",
      "Epoch 85/100\n",
      "380/380 [==============================] - 0s 103us/step - loss: 0.1941 - accuracy: 0.9289 - val_loss: 0.3928 - val_accuracy: 0.8834\n",
      "Epoch 86/100\n",
      "380/380 [==============================] - 0s 116us/step - loss: 0.1974 - accuracy: 0.9395 - val_loss: 0.5137 - val_accuracy: 0.8405\n",
      "Epoch 87/100\n",
      "380/380 [==============================] - 0s 94us/step - loss: 0.1727 - accuracy: 0.9263 - val_loss: 0.5083 - val_accuracy: 0.8528\n",
      "Epoch 88/100\n",
      "380/380 [==============================] - 0s 84us/step - loss: 0.1893 - accuracy: 0.9421 - val_loss: 0.4376 - val_accuracy: 0.8712\n",
      "Epoch 89/100\n",
      "380/380 [==============================] - 0s 90us/step - loss: 0.1623 - accuracy: 0.9500 - val_loss: 0.3973 - val_accuracy: 0.8896\n",
      "Epoch 90/100\n",
      "380/380 [==============================] - 0s 86us/step - loss: 0.1856 - accuracy: 0.9289 - val_loss: 0.4318 - val_accuracy: 0.8650\n",
      "Epoch 91/100\n",
      "380/380 [==============================] - 0s 79us/step - loss: 0.2294 - accuracy: 0.9395 - val_loss: 0.4263 - val_accuracy: 0.8834\n",
      "Epoch 92/100\n",
      "380/380 [==============================] - 0s 74us/step - loss: 0.1830 - accuracy: 0.9289 - val_loss: 0.4213 - val_accuracy: 0.8834\n",
      "Epoch 93/100\n",
      "380/380 [==============================] - 0s 79us/step - loss: 0.1585 - accuracy: 0.9447 - val_loss: 0.3907 - val_accuracy: 0.8896\n",
      "Epoch 94/100\n",
      "380/380 [==============================] - 0s 84us/step - loss: 0.1224 - accuracy: 0.9500 - val_loss: 0.4006 - val_accuracy: 0.8773\n",
      "Epoch 95/100\n",
      "380/380 [==============================] - 0s 84us/step - loss: 0.1504 - accuracy: 0.9447 - val_loss: 0.4066 - val_accuracy: 0.8773\n",
      "Epoch 96/100\n",
      "380/380 [==============================] - 0s 80us/step - loss: 0.1398 - accuracy: 0.9553 - val_loss: 0.4363 - val_accuracy: 0.8712\n",
      "Epoch 97/100\n",
      "380/380 [==============================] - 0s 85us/step - loss: 0.1757 - accuracy: 0.9474 - val_loss: 0.4019 - val_accuracy: 0.8896\n",
      "Epoch 98/100\n",
      "380/380 [==============================] - 0s 97us/step - loss: 0.1805 - accuracy: 0.9579 - val_loss: 0.4127 - val_accuracy: 0.8834\n",
      "Epoch 99/100\n",
      "380/380 [==============================] - 0s 92us/step - loss: 0.2714 - accuracy: 0.9316 - val_loss: 0.4627 - val_accuracy: 0.8896\n",
      "Epoch 100/100\n",
      "380/380 [==============================] - 0s 135us/step - loss: 0.2842 - accuracy: 0.9263 - val_loss: 0.4723 - val_accuracy: 0.8650\n"
     ]
    }
   ],
   "source": [
    "hist2_over4 = model2_over4.fit(X_sel_train_over, y_sel_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_sel_test_over, y_sel_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 91.59%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist2_over4.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba8 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_lasso_2.xlsx\",\n",
    "                        sheet_name=3,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>NRS236</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.321970e-02</td>\n",
       "      <td>2.446264e-01</td>\n",
       "      <td>7.421539e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>NRS113</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.478230e-02</td>\n",
       "      <td>2.806685e-01</td>\n",
       "      <td>6.845492e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>CFBRSa23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.090251e-01</td>\n",
       "      <td>3.405008e-01</td>\n",
       "      <td>2.504741e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>NRS249</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.987907e-01</td>\n",
       "      <td>5.331044e-01</td>\n",
       "      <td>2.681049e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>107</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.090251e-01</td>\n",
       "      <td>3.405008e-01</td>\n",
       "      <td>2.504741e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>CFBRSa30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.207667e-01</td>\n",
       "      <td>2.792331e-01</td>\n",
       "      <td>2.571588e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>NRS383</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6.129044e-01</td>\n",
       "      <td>3.870795e-01</td>\n",
       "      <td>1.601290e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>NRS110</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.260306e-07</td>\n",
       "      <td>7.910664e-07</td>\n",
       "      <td>9.999989e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.604249e-12</td>\n",
       "      <td>2.698129e-07</td>\n",
       "      <td>9.999998e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>NY439</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.207667e-01</td>\n",
       "      <td>2.792331e-01</td>\n",
       "      <td>2.571588e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>989 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   phage    strain  phenotype  prediction             0  \\\n",
       "0     p0006kpresabs_qual    NRS236          1           2  1.321970e-02   \n",
       "1     p0006kpresabs_qual    NRS113          2           2  3.478230e-02   \n",
       "2     p0006kpresabs_qual  CFBRSa23          0           0  4.090251e-01   \n",
       "3     p0006kpresabs_qual    NRS249          2           1  1.987907e-01   \n",
       "4     p0006kpresabs_qual       107          1           0  4.090251e-01   \n",
       "..                   ...       ...        ...         ...           ...   \n",
       "984  p0017Skpresabs_qual  CFBRSa30          0           0  7.207667e-01   \n",
       "985  p0017Skpresabs_qual    NRS383          1           0  6.129044e-01   \n",
       "986  p0017Skpresabs_qual    NRS110          2           2  3.260306e-07   \n",
       "987  p0017Skpresabs_qual    NRS209          2           2  3.604249e-12   \n",
       "988  p0017Skpresabs_qual     NY439          0           0  7.207667e-01   \n",
       "\n",
       "                1             2  \n",
       "0    2.446264e-01  7.421539e-01  \n",
       "1    2.806685e-01  6.845492e-01  \n",
       "2    3.405008e-01  2.504741e-01  \n",
       "3    5.331044e-01  2.681049e-01  \n",
       "4    3.405008e-01  2.504741e-01  \n",
       "..            ...           ...  \n",
       "984  2.792331e-01  2.571588e-07  \n",
       "985  3.870795e-01  1.601290e-05  \n",
       "986  7.910664e-07  9.999989e-01  \n",
       "987  2.698129e-07  9.999998e-01  \n",
       "988  2.792331e-01  2.571588e-07  \n",
       "\n",
       "[989 rows x 7 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.75888860e-03, 4.76359430e-01, 5.17881750e-01],\n",
       "       [9.46394600e-04, 7.36246050e-01, 2.62807550e-01],\n",
       "       [1.78548960e-03, 2.73063930e-02, 9.70908100e-01],\n",
       "       [3.11238950e-02, 7.18027800e-02, 8.97073300e-01],\n",
       "       [2.50145800e-06, 9.98304960e-01, 1.69252790e-03],\n",
       "       [2.07022240e-04, 9.94086500e-01, 5.70646800e-03],\n",
       "       [1.34257070e-02, 1.39981250e-01, 8.46592960e-01],\n",
       "       [8.06272400e-01, 1.56548770e-02, 1.78072770e-01],\n",
       "       [2.40216720e-05, 2.15479170e-02, 9.78428070e-01],\n",
       "       [9.78429800e-01, 7.14531400e-03, 1.44248900e-02],\n",
       "       [5.60953430e-02, 3.99860350e-01, 5.44044300e-01],\n",
       "       [2.99292150e-04, 1.10775860e-03, 9.98592900e-01],\n",
       "       [4.99543800e-02, 3.52227630e-01, 5.97818100e-01],\n",
       "       [9.46394600e-04, 7.36246050e-01, 2.62807550e-01],\n",
       "       [5.50834760e-02, 5.23399400e-01, 4.21517100e-01],\n",
       "       [9.84205300e-01, 6.10456000e-04, 1.51843260e-02],\n",
       "       [1.58854690e-02, 1.61717610e-03, 9.82497400e-01],\n",
       "       [2.53534400e-03, 6.31727600e-01, 3.65737140e-01],\n",
       "       [1.39938110e-03, 2.07017690e-01, 7.91582940e-01],\n",
       "       [5.10524330e-01, 2.62407300e-01, 2.27068410e-01],\n",
       "       [9.97540100e-01, 7.35351200e-05, 2.38640020e-03],\n",
       "       [1.35621710e-02, 7.01211450e-01, 2.85226320e-01],\n",
       "       [1.37731405e-02, 3.75155060e-02, 9.48711340e-01],\n",
       "       [3.08717660e-02, 1.83044690e-01, 7.86083500e-01],\n",
       "       [9.99850150e-01, 1.94384170e-05, 1.30440850e-04],\n",
       "       [3.11238950e-02, 7.18027800e-02, 8.97073300e-01],\n",
       "       [1.01069370e-03, 5.27176340e-02, 9.46271600e-01],\n",
       "       [1.12142100e-04, 1.05866435e-04, 9.99782000e-01],\n",
       "       [1.63906890e-02, 6.88226800e-02, 9.14786640e-01],\n",
       "       [5.73783160e-01, 3.25239180e-01, 1.00977630e-01],\n",
       "       [6.15408800e-01, 1.74904310e-04, 3.84416340e-01],\n",
       "       [5.10524330e-01, 2.62407300e-01, 2.27068410e-01],\n",
       "       [4.52059730e-02, 1.05504090e-04, 9.54688500e-01],\n",
       "       [4.49633230e-02, 2.67356700e-01, 6.87680000e-01],\n",
       "       [2.53534400e-03, 6.31727600e-01, 3.65737140e-01],\n",
       "       [3.83764120e-01, 3.15368530e-01, 3.00867230e-01],\n",
       "       [9.98736900e-01, 3.93493220e-04, 8.69629200e-04],\n",
       "       [3.06711440e-02, 8.38506200e-02, 8.85478200e-01],\n",
       "       [1.38914100e-04, 8.33598800e-01, 1.66262310e-01],\n",
       "       [9.98736900e-01, 3.93493220e-04, 8.69629200e-04],\n",
       "       [2.39584580e-04, 3.77186950e-04, 9.99383200e-01],\n",
       "       [7.32829150e-04, 9.85846000e-01, 1.34211280e-02],\n",
       "       [4.59357100e-02, 7.70202930e-01, 1.83861450e-01],\n",
       "       [9.98648940e-01, 3.68324070e-08, 1.35103070e-03],\n",
       "       [9.99543300e-01, 4.51626970e-06, 4.52248530e-04],\n",
       "       [4.99543800e-02, 3.52227630e-01, 5.97818100e-01],\n",
       "       [4.81424250e-07, 6.11287000e-10, 9.99999500e-01],\n",
       "       [6.15408800e-01, 1.74904310e-04, 3.84416340e-01],\n",
       "       [1.66891780e-01, 7.48100600e-01, 8.50076600e-02],\n",
       "       [4.99543800e-02, 3.52227630e-01, 5.97818100e-01],\n",
       "       [2.30479720e-04, 9.85981460e-01, 1.37880410e-02],\n",
       "       [9.76549600e-01, 1.94208580e-04, 2.32562590e-02],\n",
       "       [1.89149440e-02, 6.66172500e-01, 3.14912530e-01],\n",
       "       [1.25578330e-02, 5.53069530e-01, 4.34372630e-01],\n",
       "       [4.71549100e-05, 9.58564500e-01, 4.13883100e-02],\n",
       "       [3.14563370e-03, 7.22484300e-01, 2.74370130e-01],\n",
       "       [5.73783160e-01, 3.25239180e-01, 1.00977630e-01],\n",
       "       [2.86252690e-05, 9.58146900e-01, 4.18244230e-02],\n",
       "       [2.35098770e-02, 2.72750530e-01, 7.03739600e-01],\n",
       "       [3.14563370e-03, 7.22484300e-01, 2.74370130e-01],\n",
       "       [9.92427400e-01, 4.15923720e-07, 7.57203950e-03],\n",
       "       [4.99543800e-02, 3.52227630e-01, 5.97818100e-01],\n",
       "       [2.48788880e-01, 2.07298250e-01, 5.43912800e-01],\n",
       "       [9.97202400e-01, 1.88997110e-06, 2.79572960e-03],\n",
       "       [9.84205300e-01, 6.10456000e-04, 1.51843260e-02],\n",
       "       [9.93330900e-01, 5.83197460e-04, 6.08589600e-03],\n",
       "       [9.98736900e-01, 3.93493220e-04, 8.69629200e-04],\n",
       "       [2.30479720e-04, 9.85981460e-01, 1.37880410e-02],\n",
       "       [1.35621710e-02, 7.01211450e-01, 2.85226320e-01],\n",
       "       [9.79883250e-01, 5.24112370e-06, 2.01115070e-02],\n",
       "       [3.27339230e-03, 6.95391900e-02, 9.27187440e-01],\n",
       "       [9.84205300e-01, 6.10456000e-04, 1.51843260e-02],\n",
       "       [7.04441160e-04, 8.46191350e-01, 1.53104250e-01],\n",
       "       [3.02779100e-04, 4.15658620e-03, 9.95540700e-01],\n",
       "       [7.68959570e-03, 7.14953360e-01, 2.77357040e-01],\n",
       "       [2.30479720e-04, 9.85981460e-01, 1.37880410e-02],\n",
       "       [1.30505910e-02, 9.76850500e-01, 1.00988340e-02],\n",
       "       [3.61475700e-02, 3.37819040e-01, 6.26033370e-01],\n",
       "       [4.60234470e-02, 7.73905630e-01, 1.80070880e-01],\n",
       "       [9.84205300e-01, 6.10456000e-04, 1.51843260e-02],\n",
       "       [9.98420600e-01, 4.79039850e-04, 1.10039440e-03],\n",
       "       [5.10524330e-01, 2.62407300e-01, 2.27068410e-01],\n",
       "       [5.07703000e-04, 9.16834300e-02, 9.07808900e-01],\n",
       "       [3.46723600e-02, 2.56199700e-01, 7.09127960e-01],\n",
       "       [4.97219260e-02, 5.77058830e-02, 8.92572200e-01],\n",
       "       [4.79682400e-03, 9.28926940e-01, 6.62762800e-02],\n",
       "       [3.46723600e-02, 2.56199700e-01, 7.09127960e-01],\n",
       "       [5.98302100e-03, 1.14673260e-03, 9.92870300e-01],\n",
       "       [9.97623000e-01, 9.70161600e-06, 2.36720080e-03],\n",
       "       [4.90060120e-05, 7.78773400e-03, 9.92163240e-01],\n",
       "       [9.98648940e-01, 3.68324070e-08, 1.35103070e-03],\n",
       "       [1.58854690e-02, 1.61717610e-03, 9.82497400e-01],\n",
       "       [9.79883250e-01, 5.24112370e-06, 2.01115070e-02],\n",
       "       [3.11238950e-02, 7.18027800e-02, 8.97073300e-01],\n",
       "       [1.72516640e-04, 9.05272670e-04, 9.98922200e-01],\n",
       "       [2.24156960e-02, 7.84118400e-01, 1.93465920e-01],\n",
       "       [8.94128170e-04, 7.81091500e-02, 9.20996800e-01],\n",
       "       [9.98420600e-01, 4.79039850e-04, 1.10039440e-03],\n",
       "       [2.40216720e-05, 2.15479170e-02, 9.78428070e-01],\n",
       "       [2.07355660e-05, 9.98492240e-01, 1.48703480e-03],\n",
       "       [2.30479720e-04, 9.85981460e-01, 1.37880410e-02],\n",
       "       [3.10126580e-02, 4.29245980e-01, 5.39741400e-01],\n",
       "       [9.98420600e-01, 4.79039850e-04, 1.10039440e-03],\n",
       "       [7.41561800e-02, 5.44767400e-01, 3.81076480e-01],\n",
       "       [8.59082400e-05, 9.89180860e-01, 1.07331860e-02],\n",
       "       [6.26769300e-03, 1.26101030e-03, 9.92471340e-01],\n",
       "       [3.11238950e-02, 7.18027800e-02, 8.97073300e-01],\n",
       "       [9.92427400e-01, 4.15923720e-07, 7.57203950e-03],\n",
       "       [1.58854690e-02, 1.61717610e-03, 9.82497400e-01],\n",
       "       [4.49366600e-02, 2.98228350e-01, 6.56835000e-01],\n",
       "       [2.86252690e-05, 9.58146900e-01, 4.18244230e-02],\n",
       "       [5.50834760e-02, 5.23399400e-01, 4.21517100e-01],\n",
       "       [1.63991760e-03, 9.28778100e-01, 6.95818660e-02],\n",
       "       [9.82910930e-01, 5.72746740e-04, 1.65163730e-02],\n",
       "       [9.98648940e-01, 3.68324070e-08, 1.35103070e-03],\n",
       "       [6.06208050e-04, 3.16770050e-01, 6.82623740e-01],\n",
       "       [5.73783160e-01, 3.25239180e-01, 1.00977630e-01],\n",
       "       [3.02265450e-02, 5.78379330e-02, 9.11935450e-01],\n",
       "       [4.48874000e-03, 9.56112860e-01, 3.93983400e-02],\n",
       "       [4.99543800e-02, 3.52227630e-01, 5.97818100e-01],\n",
       "       [4.79682400e-03, 9.28926940e-01, 6.62762800e-02],\n",
       "       [2.93891020e-03, 2.15104620e-01, 7.81956500e-01],\n",
       "       [5.43333660e-02, 2.55054030e-01, 6.90612700e-01],\n",
       "       [1.58854690e-02, 1.61717610e-03, 9.82497400e-01],\n",
       "       [2.52836760e-01, 2.30609640e-04, 7.46932700e-01],\n",
       "       [3.08717660e-02, 1.83044690e-01, 7.86083500e-01],\n",
       "       [6.15408800e-01, 1.74904310e-04, 3.84416340e-01],\n",
       "       [9.59057570e-01, 2.36241750e-03, 3.85801050e-02],\n",
       "       [5.10524330e-01, 2.62407300e-01, 2.27068410e-01],\n",
       "       [9.40350700e-03, 9.58699170e-01, 3.18972650e-02],\n",
       "       [4.31390200e-04, 2.46324250e-03, 9.97105400e-01],\n",
       "       [9.97623000e-01, 9.70161600e-06, 2.36720080e-03],\n",
       "       [4.95442640e-02, 3.87781850e-06, 9.50451850e-01],\n",
       "       [5.50834760e-02, 5.23399400e-01, 4.21517100e-01],\n",
       "       [7.04441160e-04, 8.46191350e-01, 1.53104250e-01],\n",
       "       [4.79682400e-03, 9.28926940e-01, 6.62762800e-02],\n",
       "       [3.83764120e-01, 3.15368530e-01, 3.00867230e-01],\n",
       "       [1.30505910e-02, 9.76850500e-01, 1.00988340e-02],\n",
       "       [8.39554970e-01, 2.90863800e-05, 1.60415960e-01],\n",
       "       [5.69619560e-03, 8.96428940e-01, 9.78748350e-02],\n",
       "       [7.31729300e-02, 7.00451200e-01, 2.26375910e-01],\n",
       "       [5.50834760e-02, 5.23399400e-01, 4.21517100e-01],\n",
       "       [1.58854690e-02, 1.61717610e-03, 9.82497400e-01],\n",
       "       [5.50834760e-02, 5.23399400e-01, 4.21517100e-01],\n",
       "       [4.48874000e-03, 9.56112860e-01, 3.93983400e-02],\n",
       "       [5.25107870e-02, 5.80935540e-01, 3.66553660e-01],\n",
       "       [1.58854690e-02, 1.61717610e-03, 9.82497400e-01],\n",
       "       [9.99850150e-01, 1.94384170e-05, 1.30440850e-04],\n",
       "       [9.78429800e-01, 7.14531400e-03, 1.44248900e-02],\n",
       "       [1.30505910e-02, 9.76850500e-01, 1.00988340e-02],\n",
       "       [9.46394600e-04, 7.36246050e-01, 2.62807550e-01],\n",
       "       [3.11238950e-02, 7.18027800e-02, 8.97073300e-01],\n",
       "       [9.97623000e-01, 9.70161600e-06, 2.36720080e-03],\n",
       "       [9.97623000e-01, 9.70161600e-06, 2.36720080e-03],\n",
       "       [1.19352400e-03, 3.59950200e-01, 6.38856230e-01],\n",
       "       [1.78630210e-03, 1.93219740e-02, 9.78891730e-01],\n",
       "       [3.70818040e-04, 6.54099740e-04, 9.98975160e-01],\n",
       "       [3.80831600e-02, 2.07835050e-01, 7.54081800e-01],\n",
       "       [3.11238950e-02, 7.18027800e-02, 8.97073300e-01],\n",
       "       [1.70031130e-02, 9.68548240e-01, 1.44486490e-02],\n",
       "       [4.71549100e-05, 9.58564500e-01, 4.13883100e-02],\n",
       "       [4.81424250e-07, 6.11287000e-10, 9.99999500e-01],\n",
       "       [9.71006200e-01, 1.49851780e-02, 1.40086620e-02]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob8 = df_proba8[df_proba8['phage']=='p11kpresabsSTCC_qual'].iloc[:,-3:]\n",
    "y_prob8 = y_prob8.to_numpy()\n",
    "y_prob8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8725504278256572"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo8 = rocauc_ovo(y_sel_test_over, y_prob8, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8725504278256572"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr8 = rocauc_ovr(y_sel_test_over, y_prob8, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9304476338306613"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovos2 = [ovo5, ovo6, ovo7, ovo8]\n",
    "np.mean(ovos2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03424239921529013"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(ovos2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9304476338306613"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovrs2 = [ovr5, ovr6, ovr7, ovr8]\n",
    "np.mean(ovrs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03424239921529013"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(ovrs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs_l_over = [acc_test2_over, acc_test2_over2, acc_test2_over3, acc_test2_over4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling test accuracy mean after lasso: 83.90%\n"
     ]
    }
   ],
   "source": [
    "mean_l_over = np.mean(accs_l_over)\n",
    "print('over-sampling test accuracy mean after lasso: %.2f%%' % (mean_l_over*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling test accuracy standard deviation after lasso: 0.020056275911380646\n"
     ]
    }
   ],
   "source": [
    "std_l_over = np.std(accs_l_over)\n",
    "print('over-sampling test accuracy standard deviation after lasso:', std_l_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs_train_l_over = [np.mean(hist2_over.history['accuracy']), np.mean(hist2_over2.history['accuracy']), np.mean(hist2_over3.history['accuracy']),\n",
    "             np.mean(hist2_over4.history['accuracy'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy mean after lasso: 93.36%\n"
     ]
    }
   ],
   "source": [
    "mean_train_l_over = np.mean(accs_train_l_over)\n",
    "print('over-sampling train accuracy mean after lasso: %.2f%%' % (mean_train_l_over*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy standard deviation after lasso: 0.013198962\n"
     ]
    }
   ],
   "source": [
    "std_train_l_over = np.std(accs_train_l_over)\n",
    "print('over-sampling train accuracy standard deviation after lasso:', std_train_l_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
