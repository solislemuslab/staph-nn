{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This file implements neural networks for p11presabsSTCC_qual with four replicates.\n",
    "## We compute the mean and standarad deviation of training and test accuracies.\n",
    "## We also compute the mean and standard deviation of AUC ROC values for four replicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "import numpy as np\n",
    "seed(100)\n",
    "import tensorflow\n",
    "tensorflow.random.set_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(253, 955)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/p11presabsSTCC_qual.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'Unnamed: 0':'id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      2\n",
       "1      1\n",
       "2      2\n",
       "3      2\n",
       "4      2\n",
       "      ..\n",
       "248    2\n",
       "249    1\n",
       "250    2\n",
       "251    2\n",
       "252    2\n",
       "Name: pheno, Length: 253, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pheno']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>TTTTTTGTAATTTT</th>\n",
       "      <th>TTTTTTGTAATTTTT</th>\n",
       "      <th>TTTTTTATTTTGGAT</th>\n",
       "      <th>TTTTTTATTTTGGATAA</th>\n",
       "      <th>TTTTTTATTTTGGATAAAAGGAG</th>\n",
       "      <th>TTTTTTAGTCGTTTTT</th>\n",
       "      <th>TTTTTATCGTTTACT</th>\n",
       "      <th>TTTTTAGTCGTTTTT</th>\n",
       "      <th>TTTTTAGTCGTTTTTT</th>\n",
       "      <th>...</th>\n",
       "      <th>group_10026</th>\n",
       "      <th>group_10028</th>\n",
       "      <th>group_10211</th>\n",
       "      <th>group_2860</th>\n",
       "      <th>group_5746</th>\n",
       "      <th>group_7042</th>\n",
       "      <th>group_867</th>\n",
       "      <th>ST</th>\n",
       "      <th>CC</th>\n",
       "      <th>pheno</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>109</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>120335</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120337</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 955 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  TTTTTTGTAATTTT  TTTTTTGTAATTTTT  TTTTTTATTTTGGAT  \\\n",
       "0     107               0                0                0   \n",
       "1     109               1                1                1   \n",
       "2     115               1                1                1   \n",
       "3  120335               1                1                1   \n",
       "4  120337               1                1                1   \n",
       "\n",
       "   TTTTTTATTTTGGATAA  TTTTTTATTTTGGATAAAAGGAG  TTTTTTAGTCGTTTTT  \\\n",
       "0                  0                        0                 0   \n",
       "1                  1                        1                 1   \n",
       "2                  1                        1                 1   \n",
       "3                  1                        1                 1   \n",
       "4                  1                        1                 1   \n",
       "\n",
       "   TTTTTATCGTTTACT  TTTTTAGTCGTTTTT  TTTTTAGTCGTTTTTT  ...  group_10026  \\\n",
       "0                0                0                 0  ...            0   \n",
       "1                1                1                 1  ...            0   \n",
       "2                1                1                 1  ...            0   \n",
       "3                1                1                 1  ...            0   \n",
       "4                1                1                 1  ...            0   \n",
       "\n",
       "   group_10028  group_10211  group_2860  group_5746  group_7042  group_867  \\\n",
       "0            0            0           0           0           0          0   \n",
       "1            0            0           0           0           0          0   \n",
       "2            0            0           0           0           0          0   \n",
       "3            0            0           0           0           0          0   \n",
       "4            0            0           0           0           0          0   \n",
       "\n",
       "   ST  CC  pheno  \n",
       "0   5   5      2  \n",
       "1   8   8      1  \n",
       "2   5   5      2  \n",
       "3   5   5      2  \n",
       "4   5   5      2  \n",
       "\n",
       "[5 rows x 955 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    181\n",
       "1     47\n",
       "0     25\n",
       "Name: pheno, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pheno'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.drop(columns=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(253, 954)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TTTTTTGTAATTTT</th>\n",
       "      <th>TTTTTTGTAATTTTT</th>\n",
       "      <th>TTTTTTATTTTGGAT</th>\n",
       "      <th>TTTTTTATTTTGGATAA</th>\n",
       "      <th>TTTTTTATTTTGGATAAAAGGAG</th>\n",
       "      <th>TTTTTTAGTCGTTTTT</th>\n",
       "      <th>TTTTTATCGTTTACT</th>\n",
       "      <th>TTTTTAGTCGTTTTT</th>\n",
       "      <th>TTTTTAGTCGTTTTTT</th>\n",
       "      <th>TTTTTAGGTAAGG</th>\n",
       "      <th>...</th>\n",
       "      <th>group_10026</th>\n",
       "      <th>group_10028</th>\n",
       "      <th>group_10211</th>\n",
       "      <th>group_2860</th>\n",
       "      <th>group_5746</th>\n",
       "      <th>group_7042</th>\n",
       "      <th>group_867</th>\n",
       "      <th>ST</th>\n",
       "      <th>CC</th>\n",
       "      <th>pheno</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 954 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TTTTTTGTAATTTT  TTTTTTGTAATTTTT  TTTTTTATTTTGGAT  TTTTTTATTTTGGATAA  \\\n",
       "0               0                0                0                  0   \n",
       "1               1                1                1                  1   \n",
       "2               1                1                1                  1   \n",
       "3               1                1                1                  1   \n",
       "4               1                1                1                  1   \n",
       "\n",
       "   TTTTTTATTTTGGATAAAAGGAG  TTTTTTAGTCGTTTTT  TTTTTATCGTTTACT  \\\n",
       "0                        0                 0                0   \n",
       "1                        1                 1                1   \n",
       "2                        1                 1                1   \n",
       "3                        1                 1                1   \n",
       "4                        1                 1                1   \n",
       "\n",
       "   TTTTTAGTCGTTTTT  TTTTTAGTCGTTTTTT  TTTTTAGGTAAGG  ...  group_10026  \\\n",
       "0                0                 0              0  ...            0   \n",
       "1                1                 1              1  ...            0   \n",
       "2                1                 1              1  ...            0   \n",
       "3                1                 1              1  ...            0   \n",
       "4                1                 1              1  ...            0   \n",
       "\n",
       "   group_10028  group_10211  group_2860  group_5746  group_7042  group_867  \\\n",
       "0            0            0           0           0           0          0   \n",
       "1            0            0           0           0           0          0   \n",
       "2            0            0           0           0           0          0   \n",
       "3            0            0           0           0           0          0   \n",
       "4            0            0           0           0           0          0   \n",
       "\n",
       "   ST  CC  pheno  \n",
       "0   5   5      2  \n",
       "1   8   8      1  \n",
       "2   5   5      2  \n",
       "3   5   5      2  \n",
       "4   5   5      2  \n",
       "\n",
       "[5 rows x 954 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(253, 954) (253,)\n"
     ]
    }
   ],
   "source": [
    "X = df.loc[:, df.columns != 'pheno']\n",
    "y = df['pheno']\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.ensemble.bagging module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.ensemble.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.ensemble.forest module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 181), (1, 181), (2, 181)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.utils.testing module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.utils. Anything that cannot be imported from sklearn.utils is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.metrics.classification module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# over-sampling\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "overS = RandomOverSampler(random_state=100)\n",
    "X_over, y_over = overS.fit_resample(X, y)\n",
    "print(sorted(Counter(y_over).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# Fully-Connected Neural Network ################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.regularizers import l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=123,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = pd.DataFrame(X_test_over[:,0])\n",
    "dat['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SR1129</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS185</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS243</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BCH-SA-04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>504</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>CFBREBSa131</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>CFBREBSa133</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>NRS256</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>GA48963</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>BCH-SA-07</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test\n",
       "0         SR1129     2\n",
       "1         NRS185     2\n",
       "2         NRS243     1\n",
       "3      BCH-SA-04     0\n",
       "4            504     1\n",
       "..           ...   ...\n",
       "158  CFBREBSa131     2\n",
       "159  CFBREBSa133     1\n",
       "160       NRS256     2\n",
       "161      GA48963     1\n",
       "162    BCH-SA-07     1\n",
       "\n",
       "[163 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### neural network on over-sampling data\n",
    "model1_over = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 380 samples, validate on 163 samples\n",
      "Epoch 1/100\n",
      "380/380 [==============================] - 0s 430us/step - loss: 1.4423 - accuracy: 0.3763 - val_loss: 1.0344 - val_accuracy: 0.4724\n",
      "Epoch 2/100\n",
      "380/380 [==============================] - 0s 133us/step - loss: 0.9962 - accuracy: 0.5368 - val_loss: 0.9052 - val_accuracy: 0.6196\n",
      "Epoch 3/100\n",
      "380/380 [==============================] - 0s 152us/step - loss: 0.9405 - accuracy: 0.6132 - val_loss: 0.9476 - val_accuracy: 0.6626\n",
      "Epoch 4/100\n",
      "380/380 [==============================] - 0s 167us/step - loss: 0.8408 - accuracy: 0.6158 - val_loss: 0.8174 - val_accuracy: 0.6319\n",
      "Epoch 5/100\n",
      "380/380 [==============================] - 0s 171us/step - loss: 0.7786 - accuracy: 0.6553 - val_loss: 0.7769 - val_accuracy: 0.6442\n",
      "Epoch 6/100\n",
      "380/380 [==============================] - 0s 226us/step - loss: 0.7238 - accuracy: 0.6447 - val_loss: 0.7710 - val_accuracy: 0.6810\n",
      "Epoch 7/100\n",
      "380/380 [==============================] - 0s 226us/step - loss: 0.6947 - accuracy: 0.6816 - val_loss: 0.7864 - val_accuracy: 0.6319\n",
      "Epoch 8/100\n",
      "380/380 [==============================] - 0s 183us/step - loss: 0.6688 - accuracy: 0.7237 - val_loss: 0.7127 - val_accuracy: 0.7055\n",
      "Epoch 9/100\n",
      "380/380 [==============================] - 0s 168us/step - loss: 0.6255 - accuracy: 0.7342 - val_loss: 0.6774 - val_accuracy: 0.6871\n",
      "Epoch 10/100\n",
      "380/380 [==============================] - 0s 170us/step - loss: 0.6007 - accuracy: 0.7447 - val_loss: 0.7072 - val_accuracy: 0.7178\n",
      "Epoch 11/100\n",
      "380/380 [==============================] - 0s 180us/step - loss: 0.6542 - accuracy: 0.7447 - val_loss: 0.6081 - val_accuracy: 0.7239\n",
      "Epoch 12/100\n",
      "380/380 [==============================] - 0s 140us/step - loss: 0.6292 - accuracy: 0.7237 - val_loss: 0.6846 - val_accuracy: 0.7669\n",
      "Epoch 13/100\n",
      "380/380 [==============================] - 0s 134us/step - loss: 0.5685 - accuracy: 0.8105 - val_loss: 0.6027 - val_accuracy: 0.7423\n",
      "Epoch 14/100\n",
      "380/380 [==============================] - 0s 127us/step - loss: 0.5164 - accuracy: 0.7737 - val_loss: 0.5755 - val_accuracy: 0.7607\n",
      "Epoch 15/100\n",
      "380/380 [==============================] - 0s 130us/step - loss: 0.4484 - accuracy: 0.8368 - val_loss: 0.5135 - val_accuracy: 0.7669\n",
      "Epoch 16/100\n",
      "380/380 [==============================] - 0s 198us/step - loss: 0.4850 - accuracy: 0.8316 - val_loss: 0.6208 - val_accuracy: 0.7301\n",
      "Epoch 17/100\n",
      "380/380 [==============================] - 0s 255us/step - loss: 0.5809 - accuracy: 0.7737 - val_loss: 0.9910 - val_accuracy: 0.6871\n",
      "Epoch 18/100\n",
      "380/380 [==============================] - 0s 136us/step - loss: 0.6812 - accuracy: 0.7842 - val_loss: 0.5638 - val_accuracy: 0.7730\n",
      "Epoch 19/100\n",
      "380/380 [==============================] - 0s 125us/step - loss: 0.5837 - accuracy: 0.8395 - val_loss: 0.6548 - val_accuracy: 0.7485\n",
      "Epoch 20/100\n",
      "380/380 [==============================] - 0s 193us/step - loss: 0.4357 - accuracy: 0.8263 - val_loss: 0.5354 - val_accuracy: 0.7423\n",
      "Epoch 21/100\n",
      "380/380 [==============================] - 0s 138us/step - loss: 0.4313 - accuracy: 0.8263 - val_loss: 0.5131 - val_accuracy: 0.8344\n",
      "Epoch 22/100\n",
      "380/380 [==============================] - 0s 137us/step - loss: 0.3692 - accuracy: 0.8605 - val_loss: 0.5008 - val_accuracy: 0.7791\n",
      "Epoch 23/100\n",
      "380/380 [==============================] - 0s 171us/step - loss: 0.3675 - accuracy: 0.8684 - val_loss: 0.4970 - val_accuracy: 0.7975\n",
      "Epoch 24/100\n",
      "380/380 [==============================] - 0s 188us/step - loss: 0.3560 - accuracy: 0.8447 - val_loss: 0.5208 - val_accuracy: 0.7975\n",
      "Epoch 25/100\n",
      "380/380 [==============================] - 0s 211us/step - loss: 0.4003 - accuracy: 0.8579 - val_loss: 0.4324 - val_accuracy: 0.8405\n",
      "Epoch 26/100\n",
      "380/380 [==============================] - 0s 154us/step - loss: 0.3593 - accuracy: 0.8684 - val_loss: 0.4657 - val_accuracy: 0.8221\n",
      "Epoch 27/100\n",
      "380/380 [==============================] - 0s 192us/step - loss: 0.3213 - accuracy: 0.8947 - val_loss: 0.4522 - val_accuracy: 0.8160\n",
      "Epoch 28/100\n",
      "380/380 [==============================] - 0s 119us/step - loss: 0.3182 - accuracy: 0.9000 - val_loss: 0.4146 - val_accuracy: 0.8405\n",
      "Epoch 29/100\n",
      "380/380 [==============================] - 0s 114us/step - loss: 0.2993 - accuracy: 0.8816 - val_loss: 0.4535 - val_accuracy: 0.8221\n",
      "Epoch 30/100\n",
      "380/380 [==============================] - 0s 117us/step - loss: 0.3655 - accuracy: 0.8763 - val_loss: 0.4778 - val_accuracy: 0.7975\n",
      "Epoch 31/100\n",
      "380/380 [==============================] - 0s 198us/step - loss: 0.2857 - accuracy: 0.8974 - val_loss: 0.5290 - val_accuracy: 0.8037\n",
      "Epoch 32/100\n",
      "380/380 [==============================] - 0s 260us/step - loss: 0.2991 - accuracy: 0.9000 - val_loss: 0.5321 - val_accuracy: 0.7485\n",
      "Epoch 33/100\n",
      "380/380 [==============================] - 0s 234us/step - loss: 0.2901 - accuracy: 0.8789 - val_loss: 0.4007 - val_accuracy: 0.8834\n",
      "Epoch 34/100\n",
      "380/380 [==============================] - 0s 229us/step - loss: 0.2543 - accuracy: 0.9237 - val_loss: 0.4597 - val_accuracy: 0.8221\n",
      "Epoch 35/100\n",
      "380/380 [==============================] - 0s 189us/step - loss: 0.2806 - accuracy: 0.9079 - val_loss: 0.4401 - val_accuracy: 0.8160\n",
      "Epoch 36/100\n",
      "380/380 [==============================] - 0s 206us/step - loss: 0.3479 - accuracy: 0.8711 - val_loss: 0.5617 - val_accuracy: 0.7853\n",
      "Epoch 37/100\n",
      "380/380 [==============================] - 0s 226us/step - loss: 0.4320 - accuracy: 0.8974 - val_loss: 0.4666 - val_accuracy: 0.8160\n",
      "Epoch 38/100\n",
      "380/380 [==============================] - 0s 285us/step - loss: 0.2580 - accuracy: 0.9000 - val_loss: 0.5232 - val_accuracy: 0.7975\n",
      "Epoch 39/100\n",
      "380/380 [==============================] - 0s 225us/step - loss: 0.2856 - accuracy: 0.9026 - val_loss: 0.5343 - val_accuracy: 0.7914\n",
      "Epoch 40/100\n",
      "380/380 [==============================] - 0s 248us/step - loss: 0.2655 - accuracy: 0.9184 - val_loss: 0.4374 - val_accuracy: 0.8466\n",
      "Epoch 41/100\n",
      "380/380 [==============================] - 0s 273us/step - loss: 0.2429 - accuracy: 0.9184 - val_loss: 0.4734 - val_accuracy: 0.8221\n",
      "Epoch 42/100\n",
      "380/380 [==============================] - 0s 171us/step - loss: 0.2356 - accuracy: 0.9026 - val_loss: 0.4237 - val_accuracy: 0.8405\n",
      "Epoch 43/100\n",
      "380/380 [==============================] - 0s 261us/step - loss: 0.2552 - accuracy: 0.9132 - val_loss: 0.4470 - val_accuracy: 0.8344\n",
      "Epoch 44/100\n",
      "380/380 [==============================] - 0s 257us/step - loss: 0.2723 - accuracy: 0.9000 - val_loss: 0.4502 - val_accuracy: 0.8589\n",
      "Epoch 45/100\n",
      "380/380 [==============================] - 0s 244us/step - loss: 0.2190 - accuracy: 0.9211 - val_loss: 0.4302 - val_accuracy: 0.8650\n",
      "Epoch 46/100\n",
      "380/380 [==============================] - 0s 293us/step - loss: 0.2578 - accuracy: 0.9158 - val_loss: 0.4255 - val_accuracy: 0.8589\n",
      "Epoch 47/100\n",
      "380/380 [==============================] - 0s 229us/step - loss: 0.2300 - accuracy: 0.9211 - val_loss: 0.3770 - val_accuracy: 0.8773\n",
      "Epoch 48/100\n",
      "380/380 [==============================] - 0s 214us/step - loss: 0.1985 - accuracy: 0.9421 - val_loss: 0.3800 - val_accuracy: 0.8650\n",
      "Epoch 49/100\n",
      "380/380 [==============================] - 0s 191us/step - loss: 0.1891 - accuracy: 0.9421 - val_loss: 0.3864 - val_accuracy: 0.8773\n",
      "Epoch 50/100\n",
      "380/380 [==============================] - 0s 183us/step - loss: 0.2014 - accuracy: 0.9316 - val_loss: 0.3778 - val_accuracy: 0.8712\n",
      "Epoch 51/100\n",
      "380/380 [==============================] - 0s 262us/step - loss: 0.2201 - accuracy: 0.9368 - val_loss: 0.3969 - val_accuracy: 0.8834\n",
      "Epoch 52/100\n",
      "380/380 [==============================] - 0s 185us/step - loss: 0.1813 - accuracy: 0.9500 - val_loss: 0.4112 - val_accuracy: 0.8528\n",
      "Epoch 53/100\n",
      "380/380 [==============================] - 0s 240us/step - loss: 0.2314 - accuracy: 0.9026 - val_loss: 0.7293 - val_accuracy: 0.7853\n",
      "Epoch 54/100\n",
      "380/380 [==============================] - 0s 182us/step - loss: 0.2790 - accuracy: 0.9132 - val_loss: 0.4768 - val_accuracy: 0.8160\n",
      "Epoch 55/100\n",
      "380/380 [==============================] - 0s 199us/step - loss: 0.2406 - accuracy: 0.9263 - val_loss: 0.4526 - val_accuracy: 0.8589\n",
      "Epoch 56/100\n",
      "380/380 [==============================] - 0s 183us/step - loss: 0.2304 - accuracy: 0.9289 - val_loss: 0.4363 - val_accuracy: 0.8773\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "380/380 [==============================] - 0s 155us/step - loss: 0.1904 - accuracy: 0.9368 - val_loss: 0.3735 - val_accuracy: 0.8957\n",
      "Epoch 58/100\n",
      "380/380 [==============================] - 0s 120us/step - loss: 0.1723 - accuracy: 0.9500 - val_loss: 0.4602 - val_accuracy: 0.8834\n",
      "Epoch 59/100\n",
      "380/380 [==============================] - 0s 175us/step - loss: 0.2091 - accuracy: 0.9447 - val_loss: 0.4077 - val_accuracy: 0.8650\n",
      "Epoch 60/100\n",
      "380/380 [==============================] - 0s 295us/step - loss: 0.1935 - accuracy: 0.9474 - val_loss: 0.4881 - val_accuracy: 0.8528\n",
      "Epoch 61/100\n",
      "380/380 [==============================] - 0s 277us/step - loss: 0.2296 - accuracy: 0.9447 - val_loss: 0.4431 - val_accuracy: 0.8650\n",
      "Epoch 62/100\n",
      "380/380 [==============================] - 0s 284us/step - loss: 0.1729 - accuracy: 0.9474 - val_loss: 0.3723 - val_accuracy: 0.8957\n",
      "Epoch 63/100\n",
      "380/380 [==============================] - 0s 209us/step - loss: 0.1759 - accuracy: 0.9474 - val_loss: 0.3964 - val_accuracy: 0.8834\n",
      "Epoch 64/100\n",
      "380/380 [==============================] - 0s 195us/step - loss: 0.1765 - accuracy: 0.9184 - val_loss: 0.4521 - val_accuracy: 0.8957\n",
      "Epoch 65/100\n",
      "380/380 [==============================] - 0s 197us/step - loss: 0.2273 - accuracy: 0.9447 - val_loss: 0.4162 - val_accuracy: 0.8650\n",
      "Epoch 66/100\n",
      "380/380 [==============================] - 0s 198us/step - loss: 0.1849 - accuracy: 0.9421 - val_loss: 0.4407 - val_accuracy: 0.8528\n",
      "Epoch 67/100\n",
      "380/380 [==============================] - 0s 170us/step - loss: 0.1609 - accuracy: 0.9553 - val_loss: 0.4926 - val_accuracy: 0.8712\n",
      "Epoch 68/100\n",
      "380/380 [==============================] - 0s 315us/step - loss: 0.1652 - accuracy: 0.9500 - val_loss: 0.4914 - val_accuracy: 0.8773\n",
      "Epoch 69/100\n",
      "380/380 [==============================] - 0s 253us/step - loss: 0.1544 - accuracy: 0.9395 - val_loss: 0.4039 - val_accuracy: 0.8712\n",
      "Epoch 70/100\n",
      "380/380 [==============================] - 0s 237us/step - loss: 0.1688 - accuracy: 0.9368 - val_loss: 0.3739 - val_accuracy: 0.8957\n",
      "Epoch 71/100\n",
      "380/380 [==============================] - 0s 224us/step - loss: 0.2315 - accuracy: 0.9316 - val_loss: 0.3669 - val_accuracy: 0.9018\n",
      "Epoch 72/100\n",
      "380/380 [==============================] - 0s 127us/step - loss: 0.1602 - accuracy: 0.9421 - val_loss: 0.4533 - val_accuracy: 0.8528\n",
      "Epoch 73/100\n",
      "380/380 [==============================] - 0s 161us/step - loss: 0.1359 - accuracy: 0.9553 - val_loss: 0.3959 - val_accuracy: 0.8896\n",
      "Epoch 74/100\n",
      "380/380 [==============================] - 0s 280us/step - loss: 0.1666 - accuracy: 0.9395 - val_loss: 0.4438 - val_accuracy: 0.8773\n",
      "Epoch 75/100\n",
      "380/380 [==============================] - 0s 337us/step - loss: 0.1353 - accuracy: 0.9605 - val_loss: 0.3870 - val_accuracy: 0.8650\n",
      "Epoch 76/100\n",
      "380/380 [==============================] - 0s 325us/step - loss: 0.1793 - accuracy: 0.9447 - val_loss: 0.4107 - val_accuracy: 0.8282\n",
      "Epoch 77/100\n",
      "380/380 [==============================] - 0s 425us/step - loss: 0.1879 - accuracy: 0.9447 - val_loss: 0.4181 - val_accuracy: 0.8589\n",
      "Epoch 78/100\n",
      "380/380 [==============================] - 0s 544us/step - loss: 0.2018 - accuracy: 0.9447 - val_loss: 0.4239 - val_accuracy: 0.8957\n",
      "Epoch 79/100\n",
      "380/380 [==============================] - 0s 516us/step - loss: 0.1472 - accuracy: 0.9421 - val_loss: 0.4285 - val_accuracy: 0.8773\n",
      "Epoch 80/100\n",
      "380/380 [==============================] - 0s 226us/step - loss: 0.1326 - accuracy: 0.9500 - val_loss: 0.3799 - val_accuracy: 0.8896\n",
      "Epoch 81/100\n",
      "380/380 [==============================] - 0s 153us/step - loss: 0.1417 - accuracy: 0.9395 - val_loss: 0.4338 - val_accuracy: 0.8896\n",
      "Epoch 82/100\n",
      "380/380 [==============================] - 0s 127us/step - loss: 0.2407 - accuracy: 0.9289 - val_loss: 0.5094 - val_accuracy: 0.8221\n",
      "Epoch 83/100\n",
      "380/380 [==============================] - 0s 142us/step - loss: 0.2309 - accuracy: 0.9342 - val_loss: 0.5243 - val_accuracy: 0.8221\n",
      "Epoch 84/100\n",
      "380/380 [==============================] - 0s 154us/step - loss: 0.2253 - accuracy: 0.9184 - val_loss: 0.4784 - val_accuracy: 0.8528\n",
      "Epoch 85/100\n",
      "380/380 [==============================] - 0s 143us/step - loss: 0.1513 - accuracy: 0.9447 - val_loss: 0.4475 - val_accuracy: 0.8405\n",
      "Epoch 86/100\n",
      "380/380 [==============================] - 0s 143us/step - loss: 0.1692 - accuracy: 0.9447 - val_loss: 0.4714 - val_accuracy: 0.8282\n",
      "Epoch 87/100\n",
      "380/380 [==============================] - 0s 141us/step - loss: 0.1602 - accuracy: 0.9421 - val_loss: 0.4895 - val_accuracy: 0.8712\n",
      "Epoch 88/100\n",
      "380/380 [==============================] - 0s 151us/step - loss: 0.1615 - accuracy: 0.9421 - val_loss: 0.4793 - val_accuracy: 0.8957\n",
      "Epoch 89/100\n",
      "380/380 [==============================] - 0s 148us/step - loss: 0.1815 - accuracy: 0.9447 - val_loss: 0.5691 - val_accuracy: 0.8037\n",
      "Epoch 90/100\n",
      "380/380 [==============================] - 0s 144us/step - loss: 0.2430 - accuracy: 0.9237 - val_loss: 0.6727 - val_accuracy: 0.8344\n",
      "Epoch 91/100\n",
      "380/380 [==============================] - 0s 107us/step - loss: 0.1895 - accuracy: 0.9421 - val_loss: 0.4585 - val_accuracy: 0.8712\n",
      "Epoch 92/100\n",
      "380/380 [==============================] - 0s 106us/step - loss: 0.2208 - accuracy: 0.9500 - val_loss: 0.4827 - val_accuracy: 0.8528\n",
      "Epoch 93/100\n",
      "380/380 [==============================] - 0s 118us/step - loss: 0.1825 - accuracy: 0.9316 - val_loss: 0.4013 - val_accuracy: 0.8834\n",
      "Epoch 94/100\n",
      "380/380 [==============================] - 0s 110us/step - loss: 0.4626 - accuracy: 0.9263 - val_loss: 0.4884 - val_accuracy: 0.8896\n",
      "Epoch 95/100\n",
      "380/380 [==============================] - 0s 108us/step - loss: 0.3495 - accuracy: 0.8789 - val_loss: 0.4958 - val_accuracy: 0.8282\n",
      "Epoch 96/100\n",
      "380/380 [==============================] - 0s 150us/step - loss: 0.1693 - accuracy: 0.9447 - val_loss: 0.5443 - val_accuracy: 0.8405\n",
      "Epoch 97/100\n",
      "380/380 [==============================] - 0s 140us/step - loss: 0.1389 - accuracy: 0.9474 - val_loss: 0.4708 - val_accuracy: 0.8344\n",
      "Epoch 98/100\n",
      "380/380 [==============================] - 0s 127us/step - loss: 0.1105 - accuracy: 0.9658 - val_loss: 0.4116 - val_accuracy: 0.8712\n",
      "Epoch 99/100\n",
      "380/380 [==============================] - 0s 131us/step - loss: 0.1187 - accuracy: 0.9553 - val_loss: 0.4144 - val_accuracy: 0.8896\n",
      "Epoch 100/100\n",
      "380/380 [==============================] - 0s 131us/step - loss: 0.1189 - accuracy: 0.9684 - val_loss: 0.3613 - val_accuracy: 0.9018\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a4061e358>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163/163 [==============================] - 0s 114us/step\n",
      "over-sampling test accuracy: 89.57%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over = model1_over.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 1, 0, 1, 0, 0, 0, 1, 1, 2, 0, 0, 2, 0, 0, 2, 2, 0, 1, 1, 0,\n",
       "       0, 2, 0, 0, 1, 1, 0, 0, 1, 2, 1, 1, 1, 0, 1, 1, 1, 1, 0, 2, 0, 2,\n",
       "       1, 1, 2, 1, 0, 0, 0, 2, 1, 1, 1, 2, 2, 2, 0, 2, 0, 1, 0, 1, 1, 2,\n",
       "       0, 0, 1, 2, 0, 1, 0, 1, 1, 1, 1, 2, 0, 1, 1, 1, 2, 1, 1, 0, 0, 1,\n",
       "       1, 2, 0, 1, 2, 0, 1, 2, 2, 0, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2,\n",
       "       2, 1, 1, 1, 2, 0, 0, 1, 1, 1, 0, 2, 1, 2, 0, 2, 2, 0, 2, 0, 0, 1,\n",
       "       2, 1, 2, 2, 0, 0, 2, 0, 1, 2, 0, 2, 2, 0, 0, 1, 0, 2, 0, 0, 1, 0,\n",
       "       1, 2, 0, 0, 2, 1, 2, 1, 1])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model1_over.predict_classes(X_test_over)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SR1129</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS185</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS243</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BCH-SA-04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>504</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>CFBREBSa131</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>CFBREBSa133</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>NRS256</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>GA48963</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>BCH-SA-07</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test  pred\n",
       "0         SR1129     2     0\n",
       "1         NRS185     2     2\n",
       "2         NRS243     1     1\n",
       "3      BCH-SA-04     0     0\n",
       "4            504     1     1\n",
       "..           ...   ...   ...\n",
       "158  CFBREBSa131     2     2\n",
       "159  CFBREBSa133     1     1\n",
       "160       NRS256     2     2\n",
       "161      GA48963     1     1\n",
       "162    BCH-SA-07     1     1\n",
       "\n",
       "[163 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat['pred'] = pred\n",
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba1 = model1_over.predict_proba(X_test_over)\n",
    "dat_proba1 = pd.DataFrame(proba1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.458099e-01</td>\n",
       "      <td>4.042330e-03</td>\n",
       "      <td>0.250148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.313246e-04</td>\n",
       "      <td>2.231654e-03</td>\n",
       "      <td>0.997437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.059137e-05</td>\n",
       "      <td>9.862996e-01</td>\n",
       "      <td>0.013620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.979766e-01</td>\n",
       "      <td>1.724426e-06</td>\n",
       "      <td>0.002022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.604608e-04</td>\n",
       "      <td>9.862773e-01</td>\n",
       "      <td>0.013362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>5.107138e-07</td>\n",
       "      <td>3.921908e-07</td>\n",
       "      <td>0.999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>4.293338e-04</td>\n",
       "      <td>9.504268e-01</td>\n",
       "      <td>0.049144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>6.359447e-04</td>\n",
       "      <td>2.067653e-03</td>\n",
       "      <td>0.997296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>3.365450e-05</td>\n",
       "      <td>9.926442e-01</td>\n",
       "      <td>0.007322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>2.204828e-04</td>\n",
       "      <td>9.983461e-01</td>\n",
       "      <td>0.001433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0             1         2\n",
       "0    7.458099e-01  4.042330e-03  0.250148\n",
       "1    3.313246e-04  2.231654e-03  0.997437\n",
       "2    8.059137e-05  9.862996e-01  0.013620\n",
       "3    9.979766e-01  1.724426e-06  0.002022\n",
       "4    3.604608e-04  9.862773e-01  0.013362\n",
       "..            ...           ...       ...\n",
       "158  5.107138e-07  3.921908e-07  0.999999\n",
       "159  4.293338e-04  9.504268e-01  0.049144\n",
       "160  6.359447e-04  2.067653e-03  0.997296\n",
       "161  3.365450e-05  9.926442e-01  0.007322\n",
       "162  2.204828e-04  9.983461e-01  0.001433\n",
       "\n",
       "[163 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba1.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba1.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/1p11pST.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 380 samples, validate on 163 samples\n",
      "Epoch 1/100\n",
      "380/380 [==============================] - 0s 188us/step - loss: 0.0915 - accuracy: 0.9684 - val_loss: 0.2984 - val_accuracy: 0.9202\n",
      "Epoch 2/100\n",
      "380/380 [==============================] - 0s 152us/step - loss: 0.0916 - accuracy: 0.9632 - val_loss: 0.3110 - val_accuracy: 0.9080\n",
      "Epoch 3/100\n",
      "380/380 [==============================] - 0s 153us/step - loss: 0.1246 - accuracy: 0.9553 - val_loss: 0.3622 - val_accuracy: 0.8896\n",
      "Epoch 4/100\n",
      "380/380 [==============================] - 0s 169us/step - loss: 0.1503 - accuracy: 0.9289 - val_loss: 0.4260 - val_accuracy: 0.8896\n",
      "Epoch 5/100\n",
      "380/380 [==============================] - 0s 129us/step - loss: 0.1227 - accuracy: 0.9553 - val_loss: 0.4931 - val_accuracy: 0.8589\n",
      "Epoch 6/100\n",
      "380/380 [==============================] - 0s 136us/step - loss: 0.1411 - accuracy: 0.9474 - val_loss: 0.4209 - val_accuracy: 0.8466\n",
      "Epoch 7/100\n",
      "380/380 [==============================] - 0s 123us/step - loss: 0.1387 - accuracy: 0.9474 - val_loss: 0.6279 - val_accuracy: 0.8528\n",
      "Epoch 8/100\n",
      "380/380 [==============================] - 0s 132us/step - loss: 0.1424 - accuracy: 0.9342 - val_loss: 0.5022 - val_accuracy: 0.8712\n",
      "Epoch 9/100\n",
      "380/380 [==============================] - 0s 126us/step - loss: 0.1166 - accuracy: 0.9474 - val_loss: 0.4125 - val_accuracy: 0.8957\n",
      "Epoch 10/100\n",
      "380/380 [==============================] - 0s 126us/step - loss: 0.1096 - accuracy: 0.9553 - val_loss: 0.3890 - val_accuracy: 0.8650\n",
      "Epoch 11/100\n",
      "380/380 [==============================] - 0s 142us/step - loss: 0.1436 - accuracy: 0.9421 - val_loss: 0.5332 - val_accuracy: 0.8896\n",
      "Epoch 12/100\n",
      "380/380 [==============================] - 0s 135us/step - loss: 0.1318 - accuracy: 0.9368 - val_loss: 0.4759 - val_accuracy: 0.8834\n",
      "Epoch 13/100\n",
      "380/380 [==============================] - 0s 267us/step - loss: 0.0878 - accuracy: 0.9658 - val_loss: 0.4563 - val_accuracy: 0.8528\n",
      "Epoch 14/100\n",
      "380/380 [==============================] - 0s 172us/step - loss: 0.0983 - accuracy: 0.9526 - val_loss: 0.4635 - val_accuracy: 0.8957\n",
      "Epoch 15/100\n",
      "380/380 [==============================] - 0s 150us/step - loss: 0.1285 - accuracy: 0.9526 - val_loss: 0.3740 - val_accuracy: 0.8712\n",
      "Epoch 16/100\n",
      "380/380 [==============================] - 0s 172us/step - loss: 0.0833 - accuracy: 0.9711 - val_loss: 0.4030 - val_accuracy: 0.8957\n",
      "Epoch 17/100\n",
      "380/380 [==============================] - 0s 175us/step - loss: 0.1039 - accuracy: 0.9684 - val_loss: 0.4092 - val_accuracy: 0.8712\n",
      "Epoch 18/100\n",
      "380/380 [==============================] - 0s 215us/step - loss: 0.1515 - accuracy: 0.9500 - val_loss: 0.4634 - val_accuracy: 0.8650\n",
      "Epoch 19/100\n",
      "380/380 [==============================] - 0s 186us/step - loss: 0.1302 - accuracy: 0.9579 - val_loss: 0.5403 - val_accuracy: 0.8528\n",
      "Epoch 20/100\n",
      "380/380 [==============================] - 0s 210us/step - loss: 0.0938 - accuracy: 0.9737 - val_loss: 0.3172 - val_accuracy: 0.9141\n",
      "Epoch 21/100\n",
      "380/380 [==============================] - 0s 265us/step - loss: 0.1084 - accuracy: 0.9579 - val_loss: 0.5327 - val_accuracy: 0.8896\n",
      "Epoch 22/100\n",
      "380/380 [==============================] - 0s 261us/step - loss: 0.1051 - accuracy: 0.9605 - val_loss: 0.4919 - val_accuracy: 0.9080\n",
      "Epoch 23/100\n",
      "380/380 [==============================] - 0s 177us/step - loss: 0.0841 - accuracy: 0.9711 - val_loss: 0.3999 - val_accuracy: 0.9141\n",
      "Epoch 24/100\n",
      "380/380 [==============================] - 0s 224us/step - loss: 0.0866 - accuracy: 0.9711 - val_loss: 0.3882 - val_accuracy: 0.8712\n",
      "Epoch 25/100\n",
      "380/380 [==============================] - 0s 271us/step - loss: 0.0708 - accuracy: 0.9816 - val_loss: 0.4179 - val_accuracy: 0.8896\n",
      "Epoch 26/100\n",
      "380/380 [==============================] - 0s 334us/step - loss: 0.0765 - accuracy: 0.9684 - val_loss: 0.3522 - val_accuracy: 0.8957\n",
      "Epoch 27/100\n",
      "380/380 [==============================] - 0s 194us/step - loss: 0.0713 - accuracy: 0.9763 - val_loss: 0.4939 - val_accuracy: 0.8650\n",
      "Epoch 28/100\n",
      "380/380 [==============================] - 0s 171us/step - loss: 0.0730 - accuracy: 0.9737 - val_loss: 0.3392 - val_accuracy: 0.9202\n",
      "Epoch 29/100\n",
      "380/380 [==============================] - 0s 173us/step - loss: 0.0734 - accuracy: 0.9789 - val_loss: 0.3877 - val_accuracy: 0.8957\n",
      "Epoch 30/100\n",
      "380/380 [==============================] - 0s 195us/step - loss: 0.0693 - accuracy: 0.9711 - val_loss: 0.3373 - val_accuracy: 0.9080\n",
      "Epoch 31/100\n",
      "380/380 [==============================] - 0s 171us/step - loss: 0.0764 - accuracy: 0.9684 - val_loss: 0.3725 - val_accuracy: 0.8957\n",
      "Epoch 32/100\n",
      "380/380 [==============================] - 0s 454us/step - loss: 0.0736 - accuracy: 0.9684 - val_loss: 0.2997 - val_accuracy: 0.9141\n",
      "Epoch 33/100\n",
      "380/380 [==============================] - 0s 296us/step - loss: 0.0875 - accuracy: 0.9632 - val_loss: 0.5045 - val_accuracy: 0.8712\n",
      "Epoch 34/100\n",
      "380/380 [==============================] - 0s 181us/step - loss: 0.0934 - accuracy: 0.9553 - val_loss: 0.4334 - val_accuracy: 0.8773\n",
      "Epoch 35/100\n",
      "380/380 [==============================] - 0s 175us/step - loss: 0.0782 - accuracy: 0.9711 - val_loss: 0.5226 - val_accuracy: 0.8650\n",
      "Epoch 36/100\n",
      "380/380 [==============================] - 0s 268us/step - loss: 0.0800 - accuracy: 0.9711 - val_loss: 0.3826 - val_accuracy: 0.8896\n",
      "Epoch 37/100\n",
      "380/380 [==============================] - 0s 373us/step - loss: 0.0633 - accuracy: 0.9789 - val_loss: 0.3006 - val_accuracy: 0.9202\n",
      "Epoch 38/100\n",
      "380/380 [==============================] - 0s 162us/step - loss: 0.0735 - accuracy: 0.9737 - val_loss: 0.3309 - val_accuracy: 0.9202\n",
      "Epoch 39/100\n",
      "380/380 [==============================] - 0s 172us/step - loss: 0.0658 - accuracy: 0.9763 - val_loss: 0.3740 - val_accuracy: 0.9080\n",
      "Epoch 40/100\n",
      "380/380 [==============================] - 0s 138us/step - loss: 0.0673 - accuracy: 0.9763 - val_loss: 0.4067 - val_accuracy: 0.8773\n",
      "Epoch 41/100\n",
      "380/380 [==============================] - 0s 139us/step - loss: 0.0619 - accuracy: 0.9789 - val_loss: 0.3281 - val_accuracy: 0.9141\n",
      "Epoch 42/100\n",
      "380/380 [==============================] - 0s 150us/step - loss: 0.0696 - accuracy: 0.9711 - val_loss: 0.3698 - val_accuracy: 0.8896\n",
      "Epoch 43/100\n",
      "380/380 [==============================] - 0s 131us/step - loss: 0.0715 - accuracy: 0.9658 - val_loss: 0.3735 - val_accuracy: 0.9018\n",
      "Epoch 44/100\n",
      "380/380 [==============================] - 0s 116us/step - loss: 0.0662 - accuracy: 0.9763 - val_loss: 0.3644 - val_accuracy: 0.9080\n",
      "Epoch 45/100\n",
      "380/380 [==============================] - 0s 117us/step - loss: 0.0628 - accuracy: 0.9816 - val_loss: 0.5504 - val_accuracy: 0.8405\n",
      "Epoch 46/100\n",
      "380/380 [==============================] - 0s 117us/step - loss: 0.0827 - accuracy: 0.9579 - val_loss: 0.3760 - val_accuracy: 0.8896\n",
      "Epoch 47/100\n",
      "380/380 [==============================] - 0s 124us/step - loss: 0.0614 - accuracy: 0.9842 - val_loss: 0.3135 - val_accuracy: 0.9141\n",
      "Epoch 48/100\n",
      "380/380 [==============================] - 0s 124us/step - loss: 0.0594 - accuracy: 0.9816 - val_loss: 0.3990 - val_accuracy: 0.8896\n",
      "Epoch 49/100\n",
      "380/380 [==============================] - 0s 117us/step - loss: 0.0660 - accuracy: 0.9684 - val_loss: 0.3535 - val_accuracy: 0.9018\n",
      "Epoch 50/100\n",
      "380/380 [==============================] - 0s 115us/step - loss: 0.0527 - accuracy: 0.9763 - val_loss: 0.3334 - val_accuracy: 0.9202\n",
      "Epoch 51/100\n",
      "380/380 [==============================] - 0s 113us/step - loss: 0.0578 - accuracy: 0.9763 - val_loss: 0.3221 - val_accuracy: 0.9080\n",
      "Epoch 52/100\n",
      "380/380 [==============================] - 0s 109us/step - loss: 0.0730 - accuracy: 0.9684 - val_loss: 0.3594 - val_accuracy: 0.9202\n",
      "Epoch 53/100\n",
      "380/380 [==============================] - 0s 109us/step - loss: 0.0682 - accuracy: 0.9711 - val_loss: 0.3891 - val_accuracy: 0.8834\n",
      "Epoch 54/100\n",
      "380/380 [==============================] - 0s 108us/step - loss: 0.0625 - accuracy: 0.9789 - val_loss: 0.4174 - val_accuracy: 0.8773\n",
      "Epoch 55/100\n",
      "380/380 [==============================] - 0s 112us/step - loss: 0.0775 - accuracy: 0.9579 - val_loss: 0.5135 - val_accuracy: 0.8405\n",
      "Epoch 56/100\n",
      "380/380 [==============================] - 0s 130us/step - loss: 0.0772 - accuracy: 0.9658 - val_loss: 0.3227 - val_accuracy: 0.9141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "380/380 [==============================] - 0s 233us/step - loss: 0.0538 - accuracy: 0.9763 - val_loss: 0.4437 - val_accuracy: 0.8712\n",
      "Epoch 58/100\n",
      "380/380 [==============================] - 0s 174us/step - loss: 0.0588 - accuracy: 0.9711 - val_loss: 0.3741 - val_accuracy: 0.9018\n",
      "Epoch 59/100\n",
      "380/380 [==============================] - 0s 164us/step - loss: 0.0512 - accuracy: 0.9816 - val_loss: 0.3441 - val_accuracy: 0.9080\n",
      "Epoch 60/100\n",
      "380/380 [==============================] - 0s 246us/step - loss: 0.0492 - accuracy: 0.9816 - val_loss: 0.3876 - val_accuracy: 0.8957\n",
      "Epoch 61/100\n",
      "380/380 [==============================] - 0s 211us/step - loss: 0.0630 - accuracy: 0.9711 - val_loss: 0.3175 - val_accuracy: 0.9080\n",
      "Epoch 62/100\n",
      "380/380 [==============================] - 0s 223us/step - loss: 0.0608 - accuracy: 0.9789 - val_loss: 0.3260 - val_accuracy: 0.9080\n",
      "Epoch 63/100\n",
      "380/380 [==============================] - 0s 246us/step - loss: 0.0638 - accuracy: 0.9658 - val_loss: 0.3189 - val_accuracy: 0.9264\n",
      "Epoch 64/100\n",
      "380/380 [==============================] - 0s 208us/step - loss: 0.0678 - accuracy: 0.9711 - val_loss: 0.3716 - val_accuracy: 0.9018\n",
      "Epoch 65/100\n",
      "380/380 [==============================] - 0s 189us/step - loss: 0.0536 - accuracy: 0.9789 - val_loss: 0.3844 - val_accuracy: 0.9018\n",
      "Epoch 66/100\n",
      "380/380 [==============================] - 0s 182us/step - loss: 0.0588 - accuracy: 0.9763 - val_loss: 0.3110 - val_accuracy: 0.9080\n",
      "Epoch 67/100\n",
      "380/380 [==============================] - 0s 129us/step - loss: 0.0768 - accuracy: 0.9658 - val_loss: 0.3979 - val_accuracy: 0.9080\n",
      "Epoch 68/100\n",
      "380/380 [==============================] - 0s 139us/step - loss: 0.0883 - accuracy: 0.9553 - val_loss: 0.3238 - val_accuracy: 0.8957\n",
      "Epoch 69/100\n",
      "380/380 [==============================] - 0s 145us/step - loss: 0.0854 - accuracy: 0.9632 - val_loss: 0.5207 - val_accuracy: 0.8589\n",
      "Epoch 70/100\n",
      "380/380 [==============================] - 0s 196us/step - loss: 0.0645 - accuracy: 0.9789 - val_loss: 0.4021 - val_accuracy: 0.9018\n",
      "Epoch 71/100\n",
      "380/380 [==============================] - 0s 187us/step - loss: 0.0541 - accuracy: 0.9789 - val_loss: 0.4432 - val_accuracy: 0.8896\n",
      "Epoch 72/100\n",
      "380/380 [==============================] - 0s 169us/step - loss: 0.0574 - accuracy: 0.9868 - val_loss: 0.3561 - val_accuracy: 0.9018\n",
      "Epoch 73/100\n",
      "380/380 [==============================] - 0s 195us/step - loss: 0.0570 - accuracy: 0.9711 - val_loss: 0.3974 - val_accuracy: 0.8896\n",
      "Epoch 74/100\n",
      "380/380 [==============================] - 0s 159us/step - loss: 0.0660 - accuracy: 0.9684 - val_loss: 0.3251 - val_accuracy: 0.9018\n",
      "Epoch 75/100\n",
      "380/380 [==============================] - 0s 148us/step - loss: 0.0877 - accuracy: 0.9632 - val_loss: 0.5494 - val_accuracy: 0.8466\n",
      "Epoch 76/100\n",
      "380/380 [==============================] - 0s 166us/step - loss: 0.0683 - accuracy: 0.9684 - val_loss: 0.4142 - val_accuracy: 0.8773\n",
      "Epoch 77/100\n",
      "380/380 [==============================] - 0s 132us/step - loss: 0.0708 - accuracy: 0.9658 - val_loss: 0.4167 - val_accuracy: 0.8834\n",
      "Epoch 78/100\n",
      "380/380 [==============================] - 0s 171us/step - loss: 0.0807 - accuracy: 0.9579 - val_loss: 0.3936 - val_accuracy: 0.8957\n",
      "Epoch 79/100\n",
      "380/380 [==============================] - 0s 169us/step - loss: 0.0561 - accuracy: 0.9763 - val_loss: 0.3993 - val_accuracy: 0.9141\n",
      "Epoch 80/100\n",
      "380/380 [==============================] - 0s 192us/step - loss: 0.0534 - accuracy: 0.9816 - val_loss: 0.3474 - val_accuracy: 0.9080\n",
      "Epoch 81/100\n",
      "380/380 [==============================] - 0s 203us/step - loss: 0.0644 - accuracy: 0.9684 - val_loss: 0.6196 - val_accuracy: 0.8466\n",
      "Epoch 82/100\n",
      "380/380 [==============================] - 0s 167us/step - loss: 0.0674 - accuracy: 0.9763 - val_loss: 0.3668 - val_accuracy: 0.8896\n",
      "Epoch 83/100\n",
      "380/380 [==============================] - 0s 170us/step - loss: 0.0492 - accuracy: 0.9868 - val_loss: 0.4004 - val_accuracy: 0.9202\n",
      "Epoch 84/100\n",
      "380/380 [==============================] - 0s 161us/step - loss: 0.0452 - accuracy: 0.9816 - val_loss: 0.3897 - val_accuracy: 0.9141\n",
      "Epoch 85/100\n",
      "380/380 [==============================] - 0s 264us/step - loss: 0.0531 - accuracy: 0.9763 - val_loss: 0.4027 - val_accuracy: 0.9080\n",
      "Epoch 86/100\n",
      "380/380 [==============================] - 0s 208us/step - loss: 0.0417 - accuracy: 0.9868 - val_loss: 0.5673 - val_accuracy: 0.8466\n",
      "Epoch 87/100\n",
      "380/380 [==============================] - 0s 197us/step - loss: 0.0697 - accuracy: 0.9632 - val_loss: 0.3740 - val_accuracy: 0.9141\n",
      "Epoch 88/100\n",
      "380/380 [==============================] - 0s 190us/step - loss: 0.0493 - accuracy: 0.9816 - val_loss: 0.3379 - val_accuracy: 0.9202\n",
      "Epoch 89/100\n",
      "380/380 [==============================] - 0s 185us/step - loss: 0.0483 - accuracy: 0.9842 - val_loss: 0.4023 - val_accuracy: 0.8896\n",
      "Epoch 90/100\n",
      "380/380 [==============================] - 0s 204us/step - loss: 0.0474 - accuracy: 0.9816 - val_loss: 0.4036 - val_accuracy: 0.8957\n",
      "Epoch 91/100\n",
      "380/380 [==============================] - 0s 156us/step - loss: 0.0482 - accuracy: 0.9737 - val_loss: 0.4293 - val_accuracy: 0.8712\n",
      "Epoch 92/100\n",
      "380/380 [==============================] - 0s 159us/step - loss: 0.0558 - accuracy: 0.9737 - val_loss: 0.4483 - val_accuracy: 0.8773\n",
      "Epoch 93/100\n",
      "380/380 [==============================] - 0s 153us/step - loss: 0.0455 - accuracy: 0.9842 - val_loss: 0.3976 - val_accuracy: 0.9080\n",
      "Epoch 94/100\n",
      "380/380 [==============================] - 0s 151us/step - loss: 0.0441 - accuracy: 0.9868 - val_loss: 0.4110 - val_accuracy: 0.8896\n",
      "Epoch 95/100\n",
      "380/380 [==============================] - 0s 156us/step - loss: 0.0439 - accuracy: 0.9816 - val_loss: 0.4115 - val_accuracy: 0.8957\n",
      "Epoch 96/100\n",
      "380/380 [==============================] - 0s 164us/step - loss: 0.0428 - accuracy: 0.9842 - val_loss: 0.3439 - val_accuracy: 0.9141\n",
      "Epoch 97/100\n",
      "380/380 [==============================] - 0s 147us/step - loss: 0.0501 - accuracy: 0.9789 - val_loss: 0.3825 - val_accuracy: 0.9141\n",
      "Epoch 98/100\n",
      "380/380 [==============================] - 0s 156us/step - loss: 0.0446 - accuracy: 0.9816 - val_loss: 0.3433 - val_accuracy: 0.9264\n",
      "Epoch 99/100\n",
      "380/380 [==============================] - 0s 166us/step - loss: 0.0549 - accuracy: 0.9816 - val_loss: 0.7554 - val_accuracy: 0.8466\n",
      "Epoch 100/100\n",
      "380/380 [==============================] - 0s 156us/step - loss: 0.1029 - accuracy: 0.9579 - val_loss: 0.5046 - val_accuracy: 0.8589\n"
     ]
    }
   ],
   "source": [
    "hist1_over = model1_over.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 96.95%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_2.xlsx\",\n",
    "                        sheet_name=0,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>CFBRSa26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.758914</td>\n",
       "      <td>0.241086</td>\n",
       "      <td>4.638713e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.005361</td>\n",
       "      <td>0.016236</td>\n",
       "      <td>9.784034e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS112</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.726623</td>\n",
       "      <td>0.273376</td>\n",
       "      <td>1.520979e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS216</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.138322</td>\n",
       "      <td>0.861665</td>\n",
       "      <td>1.334123e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS021</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.882176</td>\n",
       "      <td>0.117824</td>\n",
       "      <td>1.414530e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4279</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>9.998934e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4280</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.002048</td>\n",
       "      <td>9.976944e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4281</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS205</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>9.999435e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4282</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.002048</td>\n",
       "      <td>9.976944e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4283</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.000929</td>\n",
       "      <td>9.989737e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4284 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    phage    strain  phenotype  prediction         0  \\\n",
       "0      p002ykpresabs_qual  CFBRSa26          0           0  0.758914   \n",
       "1      p002ykpresabs_qual    NRS109          2           2  0.005361   \n",
       "2      p002ykpresabs_qual    NRS112          0           0  0.726623   \n",
       "3      p002ykpresabs_qual    NRS216          1           1  0.138322   \n",
       "4      p002ykpresabs_qual    NRS021          0           0  0.882176   \n",
       "...                   ...       ...        ...         ...       ...   \n",
       "4279  pyopresabsSTCC_qual    NRS148          2           2  0.000007   \n",
       "4280  pyopresabsSTCC_qual    NRS255          2           2  0.000257   \n",
       "4281  pyopresabsSTCC_qual    NRS205          2           2  0.000011   \n",
       "4282  pyopresabsSTCC_qual    NRS255          2           2  0.000257   \n",
       "4283  pyopresabsSTCC_qual    NRS109          2           2  0.000097   \n",
       "\n",
       "             1             2  \n",
       "0     0.241086  4.638713e-07  \n",
       "1     0.016236  9.784034e-01  \n",
       "2     0.273376  1.520979e-06  \n",
       "3     0.861665  1.334123e-05  \n",
       "4     0.117824  1.414530e-10  \n",
       "...        ...           ...  \n",
       "4279  0.000099  9.998934e-01  \n",
       "4280  0.002048  9.976944e-01  \n",
       "4281  0.000045  9.999435e-01  \n",
       "4282  0.002048  9.976944e-01  \n",
       "4283  0.000929  9.989737e-01  \n",
       "\n",
       "[4284 rows x 7 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.45809850e-01, 4.04232970e-03, 2.50147850e-01],\n",
       "       [3.31324580e-04, 2.23165380e-03, 9.97437000e-01],\n",
       "       [8.05913660e-05, 9.86299600e-01, 1.36198530e-02],\n",
       "       [9.97976600e-01, 1.72442580e-06, 2.02174600e-03],\n",
       "       [3.60460840e-04, 9.86277300e-01, 1.33621900e-02],\n",
       "       [9.27506700e-01, 2.92116140e-02, 4.32817230e-02],\n",
       "       [9.97403200e-01, 5.61293740e-04, 2.03540480e-03],\n",
       "       [9.31508960e-01, 1.55653310e-04, 6.83353500e-02],\n",
       "       [1.75666000e-02, 6.27354700e-01, 3.55078700e-01],\n",
       "       [3.75761370e-05, 9.98351450e-01, 1.61093470e-03],\n",
       "       [9.38545100e-06, 1.65671540e-03, 9.98333900e-01],\n",
       "       [9.93878800e-01, 4.75678640e-03, 1.36438130e-03],\n",
       "       [7.00319230e-01, 1.62725100e-01, 1.36955660e-01],\n",
       "       [1.96539000e-02, 2.34565590e-02, 9.56889570e-01],\n",
       "       [9.93878800e-01, 4.75678640e-03, 1.36438130e-03],\n",
       "       [9.97550800e-01, 1.54193510e-06, 2.44762300e-03],\n",
       "       [8.12448900e-05, 7.73149640e-03, 9.92187260e-01],\n",
       "       [8.06043100e-04, 7.18011870e-04, 9.98475970e-01],\n",
       "       [6.42946700e-01, 3.44566900e-01, 1.24863890e-02],\n",
       "       [6.18108000e-02, 8.48696770e-01, 8.94924250e-02],\n",
       "       [2.77116110e-02, 8.99475630e-01, 7.28126540e-02],\n",
       "       [9.93962600e-01, 1.96009180e-03, 4.07739360e-03],\n",
       "       [9.78030100e-01, 2.54746560e-05, 2.19444860e-02],\n",
       "       [4.45834850e-06, 4.33304830e-02, 9.56665000e-01],\n",
       "       [9.99675500e-01, 1.05813466e-04, 2.18646750e-04],\n",
       "       [9.89706750e-01, 6.24968900e-03, 4.04356200e-03],\n",
       "       [2.20482820e-04, 9.98346100e-01, 1.43335390e-03],\n",
       "       [3.60460840e-04, 9.86277300e-01, 1.33621900e-02],\n",
       "       [9.95518000e-01, 2.20026260e-03, 2.28181530e-03],\n",
       "       [9.99675500e-01, 1.05813466e-04, 2.18646750e-04],\n",
       "       [7.12923100e-03, 5.13503200e-01, 4.79367580e-01],\n",
       "       [2.14195720e-04, 8.32455100e-02, 9.16540300e-01],\n",
       "       [1.00360830e-02, 9.47626300e-01, 4.23376150e-02],\n",
       "       [4.20115380e-01, 5.76673500e-01, 3.21105220e-03],\n",
       "       [1.00360830e-02, 9.47626300e-01, 4.23376150e-02],\n",
       "       [9.86008700e-01, 2.05284330e-03, 1.19384440e-02],\n",
       "       [2.38861590e-03, 9.80035070e-01, 1.75764150e-02],\n",
       "       [9.53514300e-05, 9.98488660e-01, 1.41595480e-03],\n",
       "       [3.36545000e-05, 9.92644200e-01, 7.32215070e-03],\n",
       "       [8.49332100e-02, 7.47487070e-01, 1.67579710e-01],\n",
       "       [9.92295270e-01, 1.19442490e-07, 7.70466400e-03],\n",
       "       [3.45560200e-04, 1.70784380e-01, 8.28870100e-01],\n",
       "       [9.89161200e-01, 4.01110260e-06, 1.08348750e-02],\n",
       "       [3.79001980e-04, 3.14793230e-01, 6.84827700e-01],\n",
       "       [3.36545000e-05, 9.92644200e-01, 7.32215070e-03],\n",
       "       [5.70348060e-04, 7.41661970e-01, 2.57767650e-01],\n",
       "       [4.55744100e-05, 9.43757900e-04, 9.99010700e-01],\n",
       "       [7.88179000e-03, 8.61138900e-01, 1.30979280e-01],\n",
       "       [9.83296450e-01, 1.78024210e-03, 1.49233370e-02],\n",
       "       [6.42946700e-01, 3.44566900e-01, 1.24863890e-02],\n",
       "       [9.99951960e-01, 6.20655960e-06, 4.17817030e-05],\n",
       "       [9.92569700e-08, 5.07628670e-07, 9.99999400e-01],\n",
       "       [8.74812700e-08, 9.98970030e-01, 1.02983370e-03],\n",
       "       [7.88188300e-05, 9.86671400e-01, 1.32498420e-02],\n",
       "       [3.23009440e-04, 9.98039660e-01, 1.63739830e-03],\n",
       "       [6.62198800e-02, 2.38672530e-06, 9.33777700e-01],\n",
       "       [1.25364240e-03, 4.30524100e-01, 5.68222200e-01],\n",
       "       [1.47792340e-06, 3.44331800e-06, 9.99995100e-01],\n",
       "       [9.89161200e-01, 4.01110260e-06, 1.08348750e-02],\n",
       "       [3.60921030e-02, 1.56875890e-02, 9.48220250e-01],\n",
       "       [9.53530250e-01, 9.99888600e-07, 4.64687400e-02],\n",
       "       [2.17806600e-05, 9.88925040e-01, 1.10531070e-02],\n",
       "       [9.89706750e-01, 6.24968900e-03, 4.04356200e-03],\n",
       "       [1.15446920e-01, 7.62052000e-01, 1.22501135e-01],\n",
       "       [2.38861590e-03, 9.80035070e-01, 1.75764150e-02],\n",
       "       [4.23768640e-01, 1.56682650e-05, 5.76215700e-01],\n",
       "       [9.97976600e-01, 1.72442580e-06, 2.02174600e-03],\n",
       "       [9.78030100e-01, 2.54746560e-05, 2.19444860e-02],\n",
       "       [4.29333830e-04, 9.50426800e-01, 4.91438170e-02],\n",
       "       [5.87379970e-04, 2.22398470e-01, 7.77014140e-01],\n",
       "       [7.00319230e-01, 1.62725100e-01, 1.36955660e-01],\n",
       "       [2.38861590e-03, 9.80035070e-01, 1.75764150e-02],\n",
       "       [9.89706750e-01, 6.24968900e-03, 4.04356200e-03],\n",
       "       [9.52864000e-03, 9.67837200e-01, 2.26341840e-02],\n",
       "       [1.17093460e-02, 7.41765200e-01, 2.46525360e-01],\n",
       "       [3.97762500e-05, 7.52717300e-01, 2.47242910e-01],\n",
       "       [2.38861590e-03, 9.80035070e-01, 1.75764150e-02],\n",
       "       [4.70822360e-07, 5.79691100e-05, 9.99941600e-01],\n",
       "       [9.97403200e-01, 5.61293740e-04, 2.03540480e-03],\n",
       "       [1.65397320e-02, 8.84287200e-01, 9.91730300e-02],\n",
       "       [4.29333830e-04, 9.50426800e-01, 4.91438170e-02],\n",
       "       [1.08112786e-07, 9.99568760e-01, 4.31085150e-04],\n",
       "       [4.23768640e-01, 1.56682650e-05, 5.76215700e-01],\n",
       "       [2.00528760e-05, 9.25460900e-01, 7.45190500e-02],\n",
       "       [3.36545000e-05, 9.92644200e-01, 7.32215070e-03],\n",
       "       [9.83296450e-01, 1.78024210e-03, 1.49233370e-02],\n",
       "       [9.97403200e-01, 5.61293740e-04, 2.03540480e-03],\n",
       "       [8.05913660e-05, 9.86299600e-01, 1.36198530e-02],\n",
       "       [9.81048300e-04, 9.98433050e-01, 5.85781100e-04],\n",
       "       [6.96527060e-05, 5.96655070e-04, 9.99333700e-01],\n",
       "       [9.97976600e-01, 1.72442580e-06, 2.02174600e-03],\n",
       "       [6.18108000e-02, 8.48696770e-01, 8.94924250e-02],\n",
       "       [2.63002070e-02, 3.40708550e-01, 6.32991250e-01],\n",
       "       [9.97976600e-01, 1.72442580e-06, 2.02174600e-03],\n",
       "       [1.39734080e-03, 9.94088300e-01, 4.51440460e-03],\n",
       "       [2.76463900e-08, 1.87553670e-07, 9.99999760e-01],\n",
       "       [1.39260170e-07, 1.31026780e-04, 9.99868870e-01],\n",
       "       [9.78030100e-01, 2.54746560e-05, 2.19444860e-02],\n",
       "       [4.36319350e-05, 2.00147230e-03, 9.97954850e-01],\n",
       "       [7.00319230e-01, 1.62725100e-01, 1.36955660e-01],\n",
       "       [9.99730770e-01, 1.20630330e-04, 1.48655450e-04],\n",
       "       [9.99730770e-01, 1.20630330e-04, 1.48655450e-04],\n",
       "       [9.97976600e-01, 1.72442580e-06, 2.02174600e-03],\n",
       "       [8.49332100e-02, 7.47487070e-01, 1.67579710e-01],\n",
       "       [4.35354020e-07, 1.57447960e-06, 9.99998000e-01],\n",
       "       [2.20482820e-04, 9.98346100e-01, 1.43335390e-03],\n",
       "       [5.83638260e-04, 9.59392960e-01, 4.00233600e-02],\n",
       "       [1.68081750e-03, 3.15946680e-02, 9.66724500e-01],\n",
       "       [7.00319230e-01, 1.62725100e-01, 1.36955660e-01],\n",
       "       [3.10376920e-03, 3.21829460e-04, 9.96574400e-01],\n",
       "       [9.92080100e-05, 1.19304890e-02, 9.87970300e-01],\n",
       "       [1.00360830e-02, 9.47626300e-01, 4.23376150e-02],\n",
       "       [1.81775110e-03, 6.50779840e-01, 3.47402400e-01],\n",
       "       [2.17806600e-05, 9.88925040e-01, 1.10531070e-02],\n",
       "       [2.30662440e-01, 3.29284700e-05, 7.69304630e-01],\n",
       "       [9.99730770e-01, 1.20630330e-04, 1.48655450e-04],\n",
       "       [9.87243300e-01, 4.53273800e-06, 1.27521950e-02],\n",
       "       [8.49332100e-02, 7.47487070e-01, 1.67579710e-01],\n",
       "       [1.20194470e-02, 9.41527500e-01, 4.64531200e-02],\n",
       "       [3.25820370e-02, 7.40931100e-01, 2.26486880e-01],\n",
       "       [9.97976600e-01, 1.72442580e-06, 2.02174600e-03],\n",
       "       [1.84103570e-04, 2.89046620e-02, 9.70911200e-01],\n",
       "       [1.01469140e-03, 9.76514700e-01, 2.24705920e-02],\n",
       "       [3.01984600e-04, 1.93610680e-02, 9.80336960e-01],\n",
       "       [9.99675500e-01, 1.05813466e-04, 2.18646750e-04],\n",
       "       [5.13585660e-09, 2.73361220e-07, 9.99999760e-01],\n",
       "       [2.58328000e-04, 4.25945100e-01, 5.73796500e-01],\n",
       "       [9.99730770e-01, 1.20630330e-04, 1.48655450e-04],\n",
       "       [5.32780900e-04, 4.25180530e-02, 9.56949200e-01],\n",
       "       [9.78030100e-01, 2.54746560e-05, 2.19444860e-02],\n",
       "       [9.99951960e-01, 6.20655960e-06, 4.17817030e-05],\n",
       "       [2.17806600e-05, 9.88925040e-01, 1.10531070e-02],\n",
       "       [1.02604470e-04, 1.25894190e-04, 9.99771540e-01],\n",
       "       [9.53514300e-05, 9.98488660e-01, 1.41595480e-03],\n",
       "       [2.29145580e-06, 3.41835780e-03, 9.96579350e-01],\n",
       "       [6.60095600e-04, 1.22272894e-01, 8.77067100e-01],\n",
       "       [8.14094360e-01, 6.55094000e-02, 1.20396290e-01],\n",
       "       [9.99951960e-01, 6.20655960e-06, 4.17817030e-05],\n",
       "       [6.77956150e-04, 1.86078600e-02, 9.80714140e-01],\n",
       "       [9.97988340e-01, 4.05767350e-05, 1.97109300e-03],\n",
       "       [1.41498740e-01, 7.00033800e-01, 1.58467470e-01],\n",
       "       [1.18135890e-03, 3.60131120e-03, 9.95217300e-01],\n",
       "       [9.99675500e-01, 1.05813466e-04, 2.18646750e-04],\n",
       "       [3.70130130e-08, 5.90190300e-07, 9.99999400e-01],\n",
       "       [5.25224430e-04, 7.08295900e-02, 9.28645200e-01],\n",
       "       [7.83120400e-01, 2.14612630e-02, 1.95418360e-01],\n",
       "       [6.42946700e-01, 3.44566900e-01, 1.24863890e-02],\n",
       "       [8.74812700e-08, 9.98970030e-01, 1.02983370e-03],\n",
       "       [9.97550800e-01, 1.54193510e-06, 2.44762300e-03],\n",
       "       [3.60897980e-04, 2.76993800e-01, 7.22645300e-01],\n",
       "       [9.97976600e-01, 1.72442580e-06, 2.02174600e-03],\n",
       "       [9.99730770e-01, 1.20630330e-04, 1.48655450e-04],\n",
       "       [1.81775110e-03, 6.50779840e-01, 3.47402400e-01],\n",
       "       [9.89161200e-01, 4.01110260e-06, 1.08348750e-02],\n",
       "       [3.38096400e-04, 6.26057900e-01, 3.73603970e-01],\n",
       "       [1.28036830e-06, 1.25221310e-05, 9.99986200e-01],\n",
       "       [9.93962600e-01, 1.96009180e-03, 4.07739360e-03],\n",
       "       [4.79336650e-01, 4.09013570e-01, 1.11649780e-01],\n",
       "       [5.10713850e-07, 3.92190830e-07, 9.99999050e-01],\n",
       "       [4.29333830e-04, 9.50426800e-01, 4.91438170e-02],\n",
       "       [6.35944660e-04, 2.06765250e-03, 9.97296400e-01],\n",
       "       [3.36545000e-05, 9.92644200e-01, 7.32215070e-03],\n",
       "       [2.20482820e-04, 9.98346100e-01, 1.43335390e-03]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob = df_proba[df_proba['phage']=='p11presabsSTCC_qual'].iloc[:,-3:]\n",
    "y_prob = y_prob.to_numpy()\n",
    "y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Retrieved from https://github.com/scikit-learn/scikit-learn/issues/3298\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "def rocauc_ovo(truth, pred, average=\"macro\", multi_class=\"ovo\"):\n",
    "\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(truth)\n",
    "\n",
    "    truth = lb.transform(truth)   \n",
    "    \n",
    "    return roc_auc_score(truth, pred, average=average, multi_class=multi_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.976633305532388"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo1 = rocauc_ovo(y_test_over, y_prob, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rocauc_ovr(truth, pred, average=\"macro\", multi_class=\"ovr\"):\n",
    "\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(truth)\n",
    "\n",
    "    truth = lb.transform(truth)   \n",
    "\n",
    "    return roc_auc_score(truth, pred, average=average, multi_class=multi_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.976633305532388"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr1 = rocauc_ovr(y_test_over, y_prob, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=234,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat2 = pd.DataFrame(X_test_over[:,0])\n",
    "dat2['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS027</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CFBRSa07</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CFBRSa27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>504</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CFBREBSa129</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>SR3569</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>NRS243</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>GA48963</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>504</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>CFBREBSa123</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test\n",
       "0         NRS027     0\n",
       "1       CFBRSa07     0\n",
       "2       CFBRSa27     1\n",
       "3            504     1\n",
       "4    CFBREBSa129     0\n",
       "..           ...   ...\n",
       "158       SR3569     2\n",
       "159       NRS243     1\n",
       "160      GA48963     1\n",
       "161          504     1\n",
       "162  CFBREBSa123     0\n",
       "\n",
       "[163 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over2 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over2.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 380 samples, validate on 163 samples\n",
      "Epoch 1/100\n",
      "380/380 [==============================] - 0s 410us/step - loss: 3.9275 - accuracy: 0.3605 - val_loss: 5.6058 - val_accuracy: 0.3988\n",
      "Epoch 2/100\n",
      "380/380 [==============================] - 0s 104us/step - loss: 2.6435 - accuracy: 0.3132 - val_loss: 4.2434 - val_accuracy: 0.3558\n",
      "Epoch 3/100\n",
      "380/380 [==============================] - 0s 119us/step - loss: 1.8634 - accuracy: 0.3895 - val_loss: 3.0833 - val_accuracy: 0.3988\n",
      "Epoch 4/100\n",
      "380/380 [==============================] - 0s 127us/step - loss: 1.4835 - accuracy: 0.4526 - val_loss: 2.4358 - val_accuracy: 0.4540\n",
      "Epoch 5/100\n",
      "380/380 [==============================] - 0s 166us/step - loss: 1.1900 - accuracy: 0.5289 - val_loss: 1.9104 - val_accuracy: 0.4724\n",
      "Epoch 6/100\n",
      "380/380 [==============================] - 0s 160us/step - loss: 1.1021 - accuracy: 0.5789 - val_loss: 1.5635 - val_accuracy: 0.4785\n",
      "Epoch 7/100\n",
      "380/380 [==============================] - 0s 149us/step - loss: 0.9683 - accuracy: 0.5921 - val_loss: 1.2629 - val_accuracy: 0.5276\n",
      "Epoch 8/100\n",
      "380/380 [==============================] - 0s 127us/step - loss: 0.8670 - accuracy: 0.6605 - val_loss: 1.0846 - val_accuracy: 0.5706\n",
      "Epoch 9/100\n",
      "380/380 [==============================] - 0s 116us/step - loss: 0.8155 - accuracy: 0.6737 - val_loss: 0.9783 - val_accuracy: 0.5767\n",
      "Epoch 10/100\n",
      "380/380 [==============================] - 0s 156us/step - loss: 0.8015 - accuracy: 0.6737 - val_loss: 0.9731 - val_accuracy: 0.6012\n",
      "Epoch 11/100\n",
      "380/380 [==============================] - 0s 145us/step - loss: 0.7782 - accuracy: 0.6842 - val_loss: 0.9046 - val_accuracy: 0.6319\n",
      "Epoch 12/100\n",
      "380/380 [==============================] - 0s 132us/step - loss: 0.7378 - accuracy: 0.7263 - val_loss: 0.8948 - val_accuracy: 0.6626\n",
      "Epoch 13/100\n",
      "380/380 [==============================] - 0s 122us/step - loss: 0.7168 - accuracy: 0.7237 - val_loss: 0.8063 - val_accuracy: 0.6871\n",
      "Epoch 14/100\n",
      "380/380 [==============================] - 0s 135us/step - loss: 0.6853 - accuracy: 0.7263 - val_loss: 0.8406 - val_accuracy: 0.6626\n",
      "Epoch 15/100\n",
      "380/380 [==============================] - 0s 166us/step - loss: 0.6584 - accuracy: 0.7421 - val_loss: 0.8182 - val_accuracy: 0.7239\n",
      "Epoch 16/100\n",
      "380/380 [==============================] - 0s 131us/step - loss: 0.6346 - accuracy: 0.7526 - val_loss: 0.7497 - val_accuracy: 0.6626\n",
      "Epoch 17/100\n",
      "380/380 [==============================] - 0s 151us/step - loss: 0.6156 - accuracy: 0.7658 - val_loss: 0.7900 - val_accuracy: 0.6933\n",
      "Epoch 18/100\n",
      "380/380 [==============================] - 0s 118us/step - loss: 0.5971 - accuracy: 0.7895 - val_loss: 0.7180 - val_accuracy: 0.6933\n",
      "Epoch 19/100\n",
      "380/380 [==============================] - 0s 114us/step - loss: 0.5838 - accuracy: 0.8000 - val_loss: 0.7136 - val_accuracy: 0.7239\n",
      "Epoch 20/100\n",
      "380/380 [==============================] - 0s 113us/step - loss: 0.5775 - accuracy: 0.7711 - val_loss: 0.7278 - val_accuracy: 0.7423\n",
      "Epoch 21/100\n",
      "380/380 [==============================] - 0s 274us/step - loss: 0.5474 - accuracy: 0.8079 - val_loss: 0.6812 - val_accuracy: 0.7055\n",
      "Epoch 22/100\n",
      "380/380 [==============================] - 0s 115us/step - loss: 0.5290 - accuracy: 0.8158 - val_loss: 0.6755 - val_accuracy: 0.7362\n",
      "Epoch 23/100\n",
      "380/380 [==============================] - 0s 104us/step - loss: 0.5128 - accuracy: 0.8105 - val_loss: 0.6394 - val_accuracy: 0.7301\n",
      "Epoch 24/100\n",
      "380/380 [==============================] - 0s 111us/step - loss: 0.4982 - accuracy: 0.8000 - val_loss: 0.6398 - val_accuracy: 0.7607\n",
      "Epoch 25/100\n",
      "380/380 [==============================] - 0s 108us/step - loss: 0.4813 - accuracy: 0.8289 - val_loss: 0.6202 - val_accuracy: 0.7730\n",
      "Epoch 26/100\n",
      "380/380 [==============================] - 0s 240us/step - loss: 0.4702 - accuracy: 0.8237 - val_loss: 0.5939 - val_accuracy: 0.7669\n",
      "Epoch 27/100\n",
      "380/380 [==============================] - 0s 185us/step - loss: 0.4433 - accuracy: 0.8395 - val_loss: 0.5837 - val_accuracy: 0.7914\n",
      "Epoch 28/100\n",
      "380/380 [==============================] - 0s 141us/step - loss: 0.4343 - accuracy: 0.8553 - val_loss: 0.6004 - val_accuracy: 0.7607\n",
      "Epoch 29/100\n",
      "380/380 [==============================] - 0s 164us/step - loss: 0.4236 - accuracy: 0.8263 - val_loss: 0.5569 - val_accuracy: 0.7853\n",
      "Epoch 30/100\n",
      "380/380 [==============================] - 0s 147us/step - loss: 0.4259 - accuracy: 0.8289 - val_loss: 0.5496 - val_accuracy: 0.7853\n",
      "Epoch 31/100\n",
      "380/380 [==============================] - 0s 107us/step - loss: 0.4080 - accuracy: 0.8553 - val_loss: 0.5431 - val_accuracy: 0.7914\n",
      "Epoch 32/100\n",
      "380/380 [==============================] - 0s 89us/step - loss: 0.3913 - accuracy: 0.8579 - val_loss: 0.5178 - val_accuracy: 0.8344\n",
      "Epoch 33/100\n",
      "380/380 [==============================] - 0s 88us/step - loss: 0.3829 - accuracy: 0.8474 - val_loss: 0.5225 - val_accuracy: 0.8098\n",
      "Epoch 34/100\n",
      "380/380 [==============================] - 0s 86us/step - loss: 0.3649 - accuracy: 0.8579 - val_loss: 0.5166 - val_accuracy: 0.8589\n",
      "Epoch 35/100\n",
      "380/380 [==============================] - 0s 90us/step - loss: 0.3624 - accuracy: 0.8947 - val_loss: 0.4914 - val_accuracy: 0.8160\n",
      "Epoch 36/100\n",
      "380/380 [==============================] - 0s 260us/step - loss: 0.3577 - accuracy: 0.8711 - val_loss: 0.5013 - val_accuracy: 0.8466\n",
      "Epoch 37/100\n",
      "380/380 [==============================] - 0s 384us/step - loss: 0.3507 - accuracy: 0.8579 - val_loss: 0.4902 - val_accuracy: 0.8589\n",
      "Epoch 38/100\n",
      "380/380 [==============================] - 0s 184us/step - loss: 0.3409 - accuracy: 0.8921 - val_loss: 0.4729 - val_accuracy: 0.8344\n",
      "Epoch 39/100\n",
      "380/380 [==============================] - 0s 159us/step - loss: 0.3274 - accuracy: 0.8763 - val_loss: 0.4625 - val_accuracy: 0.8405\n",
      "Epoch 40/100\n",
      "380/380 [==============================] - 0s 120us/step - loss: 0.3248 - accuracy: 0.8763 - val_loss: 0.4590 - val_accuracy: 0.8528\n",
      "Epoch 41/100\n",
      "380/380 [==============================] - 0s 107us/step - loss: 0.3106 - accuracy: 0.9026 - val_loss: 0.4443 - val_accuracy: 0.8466\n",
      "Epoch 42/100\n",
      "380/380 [==============================] - 0s 117us/step - loss: 0.3095 - accuracy: 0.8974 - val_loss: 0.4457 - val_accuracy: 0.8344\n",
      "Epoch 43/100\n",
      "380/380 [==============================] - 0s 224us/step - loss: 0.3106 - accuracy: 0.8868 - val_loss: 0.4442 - val_accuracy: 0.8528\n",
      "Epoch 44/100\n",
      "380/380 [==============================] - 0s 157us/step - loss: 0.3035 - accuracy: 0.8789 - val_loss: 0.4216 - val_accuracy: 0.8589\n",
      "Epoch 45/100\n",
      "380/380 [==============================] - 0s 105us/step - loss: 0.2995 - accuracy: 0.8895 - val_loss: 0.4664 - val_accuracy: 0.8712\n",
      "Epoch 46/100\n",
      "380/380 [==============================] - 0s 101us/step - loss: 0.2947 - accuracy: 0.8921 - val_loss: 0.4468 - val_accuracy: 0.8834\n",
      "Epoch 47/100\n",
      "380/380 [==============================] - 0s 87us/step - loss: 0.2782 - accuracy: 0.9105 - val_loss: 0.4113 - val_accuracy: 0.8773\n",
      "Epoch 48/100\n",
      "380/380 [==============================] - 0s 109us/step - loss: 0.2769 - accuracy: 0.8974 - val_loss: 0.4482 - val_accuracy: 0.8650\n",
      "Epoch 49/100\n",
      "380/380 [==============================] - 0s 234us/step - loss: 0.2770 - accuracy: 0.8974 - val_loss: 0.4409 - val_accuracy: 0.8834\n",
      "Epoch 50/100\n",
      "380/380 [==============================] - 0s 282us/step - loss: 0.2592 - accuracy: 0.9184 - val_loss: 0.3869 - val_accuracy: 0.8589\n",
      "Epoch 51/100\n",
      "380/380 [==============================] - 0s 223us/step - loss: 0.2612 - accuracy: 0.9053 - val_loss: 0.4268 - val_accuracy: 0.8282\n",
      "Epoch 52/100\n",
      "380/380 [==============================] - 0s 166us/step - loss: 0.2723 - accuracy: 0.8921 - val_loss: 0.4284 - val_accuracy: 0.8773\n",
      "Epoch 53/100\n",
      "380/380 [==============================] - 0s 177us/step - loss: 0.2563 - accuracy: 0.9211 - val_loss: 0.3978 - val_accuracy: 0.8773\n",
      "Epoch 54/100\n",
      "380/380 [==============================] - 0s 136us/step - loss: 0.2572 - accuracy: 0.9079 - val_loss: 0.3848 - val_accuracy: 0.9080\n",
      "Epoch 55/100\n",
      "380/380 [==============================] - 0s 99us/step - loss: 0.2515 - accuracy: 0.9237 - val_loss: 0.4244 - val_accuracy: 0.8834\n",
      "Epoch 56/100\n",
      "380/380 [==============================] - 0s 100us/step - loss: 0.2481 - accuracy: 0.9158 - val_loss: 0.3816 - val_accuracy: 0.8834\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "380/380 [==============================] - 0s 195us/step - loss: 0.2377 - accuracy: 0.9184 - val_loss: 0.3990 - val_accuracy: 0.8834\n",
      "Epoch 58/100\n",
      "380/380 [==============================] - 0s 230us/step - loss: 0.2293 - accuracy: 0.9184 - val_loss: 0.4213 - val_accuracy: 0.8896\n",
      "Epoch 59/100\n",
      "380/380 [==============================] - 0s 248us/step - loss: 0.2253 - accuracy: 0.9289 - val_loss: 0.3639 - val_accuracy: 0.8650\n",
      "Epoch 60/100\n",
      "380/380 [==============================] - 0s 215us/step - loss: 0.2219 - accuracy: 0.9263 - val_loss: 0.3938 - val_accuracy: 0.8957\n",
      "Epoch 61/100\n",
      "380/380 [==============================] - 0s 101us/step - loss: 0.2220 - accuracy: 0.9211 - val_loss: 0.3639 - val_accuracy: 0.8834\n",
      "Epoch 62/100\n",
      "380/380 [==============================] - 0s 87us/step - loss: 0.2130 - accuracy: 0.9237 - val_loss: 0.3691 - val_accuracy: 0.9080\n",
      "Epoch 63/100\n",
      "380/380 [==============================] - 0s 84us/step - loss: 0.2247 - accuracy: 0.9079 - val_loss: 0.3981 - val_accuracy: 0.8773\n",
      "Epoch 64/100\n",
      "380/380 [==============================] - 0s 96us/step - loss: 0.2047 - accuracy: 0.9368 - val_loss: 0.3512 - val_accuracy: 0.8896\n",
      "Epoch 65/100\n",
      "380/380 [==============================] - 0s 83us/step - loss: 0.2156 - accuracy: 0.9184 - val_loss: 0.4156 - val_accuracy: 0.8650\n",
      "Epoch 66/100\n",
      "380/380 [==============================] - 0s 86us/step - loss: 0.2029 - accuracy: 0.9421 - val_loss: 0.3665 - val_accuracy: 0.8957\n",
      "Epoch 67/100\n",
      "380/380 [==============================] - 0s 86us/step - loss: 0.1975 - accuracy: 0.9447 - val_loss: 0.3623 - val_accuracy: 0.8834\n",
      "Epoch 68/100\n",
      "380/380 [==============================] - 0s 88us/step - loss: 0.1929 - accuracy: 0.9421 - val_loss: 0.3449 - val_accuracy: 0.8957\n",
      "Epoch 69/100\n",
      "380/380 [==============================] - 0s 153us/step - loss: 0.2030 - accuracy: 0.9395 - val_loss: 0.3505 - val_accuracy: 0.9018\n",
      "Epoch 70/100\n",
      "380/380 [==============================] - 0s 328us/step - loss: 0.1834 - accuracy: 0.9474 - val_loss: 0.3508 - val_accuracy: 0.9080\n",
      "Epoch 71/100\n",
      "380/380 [==============================] - 0s 208us/step - loss: 0.1857 - accuracy: 0.9474 - val_loss: 0.3521 - val_accuracy: 0.9080\n",
      "Epoch 72/100\n",
      "380/380 [==============================] - 0s 103us/step - loss: 0.1793 - accuracy: 0.9526 - val_loss: 0.3449 - val_accuracy: 0.9141\n",
      "Epoch 73/100\n",
      "380/380 [==============================] - 0s 92us/step - loss: 0.1868 - accuracy: 0.9395 - val_loss: 0.3188 - val_accuracy: 0.8773\n",
      "Epoch 74/100\n",
      "380/380 [==============================] - 0s 87us/step - loss: 0.1837 - accuracy: 0.9237 - val_loss: 0.3830 - val_accuracy: 0.8773\n",
      "Epoch 75/100\n",
      "380/380 [==============================] - 0s 118us/step - loss: 0.2010 - accuracy: 0.9368 - val_loss: 0.3601 - val_accuracy: 0.8957\n",
      "Epoch 76/100\n",
      "380/380 [==============================] - 0s 117us/step - loss: 0.2053 - accuracy: 0.9263 - val_loss: 0.3522 - val_accuracy: 0.8896\n",
      "Epoch 77/100\n",
      "380/380 [==============================] - 0s 163us/step - loss: 0.1747 - accuracy: 0.9421 - val_loss: 0.3345 - val_accuracy: 0.9141\n",
      "Epoch 78/100\n",
      "380/380 [==============================] - 0s 139us/step - loss: 0.1640 - accuracy: 0.9500 - val_loss: 0.3285 - val_accuracy: 0.9141\n",
      "Epoch 79/100\n",
      "380/380 [==============================] - 0s 118us/step - loss: 0.1621 - accuracy: 0.9526 - val_loss: 0.3187 - val_accuracy: 0.9141\n",
      "Epoch 80/100\n",
      "380/380 [==============================] - 0s 125us/step - loss: 0.1561 - accuracy: 0.9553 - val_loss: 0.3241 - val_accuracy: 0.9264\n",
      "Epoch 81/100\n",
      "380/380 [==============================] - 0s 115us/step - loss: 0.1645 - accuracy: 0.9526 - val_loss: 0.3455 - val_accuracy: 0.8896\n",
      "Epoch 82/100\n",
      "380/380 [==============================] - 0s 154us/step - loss: 0.1604 - accuracy: 0.9447 - val_loss: 0.3192 - val_accuracy: 0.9141\n",
      "Epoch 83/100\n",
      "380/380 [==============================] - 0s 134us/step - loss: 0.1541 - accuracy: 0.9500 - val_loss: 0.3411 - val_accuracy: 0.9018\n",
      "Epoch 84/100\n",
      "380/380 [==============================] - 0s 101us/step - loss: 0.1589 - accuracy: 0.9500 - val_loss: 0.3175 - val_accuracy: 0.9264\n",
      "Epoch 85/100\n",
      "380/380 [==============================] - 0s 113us/step - loss: 0.1674 - accuracy: 0.9342 - val_loss: 0.3296 - val_accuracy: 0.8834\n",
      "Epoch 86/100\n",
      "380/380 [==============================] - 0s 110us/step - loss: 0.1542 - accuracy: 0.9447 - val_loss: 0.3285 - val_accuracy: 0.9325\n",
      "Epoch 87/100\n",
      "380/380 [==============================] - 0s 113us/step - loss: 0.1457 - accuracy: 0.9526 - val_loss: 0.3397 - val_accuracy: 0.9018\n",
      "Epoch 88/100\n",
      "380/380 [==============================] - 0s 119us/step - loss: 0.1492 - accuracy: 0.9526 - val_loss: 0.3525 - val_accuracy: 0.8650\n",
      "Epoch 89/100\n",
      "380/380 [==============================] - 0s 102us/step - loss: 0.1626 - accuracy: 0.9421 - val_loss: 0.3202 - val_accuracy: 0.9018\n",
      "Epoch 90/100\n",
      "380/380 [==============================] - 0s 89us/step - loss: 0.1595 - accuracy: 0.9395 - val_loss: 0.3724 - val_accuracy: 0.8834\n",
      "Epoch 91/100\n",
      "380/380 [==============================] - 0s 88us/step - loss: 0.1756 - accuracy: 0.9342 - val_loss: 0.3179 - val_accuracy: 0.9202\n",
      "Epoch 92/100\n",
      "380/380 [==============================] - 0s 85us/step - loss: 0.1443 - accuracy: 0.9553 - val_loss: 0.3326 - val_accuracy: 0.9018\n",
      "Epoch 93/100\n",
      "380/380 [==============================] - 0s 87us/step - loss: 0.1425 - accuracy: 0.9500 - val_loss: 0.3169 - val_accuracy: 0.9141\n",
      "Epoch 94/100\n",
      "380/380 [==============================] - 0s 87us/step - loss: 0.1367 - accuracy: 0.9553 - val_loss: 0.3246 - val_accuracy: 0.9264\n",
      "Epoch 95/100\n",
      "380/380 [==============================] - 0s 84us/step - loss: 0.1398 - accuracy: 0.9579 - val_loss: 0.3381 - val_accuracy: 0.9141\n",
      "Epoch 96/100\n",
      "380/380 [==============================] - 0s 88us/step - loss: 0.1404 - accuracy: 0.9553 - val_loss: 0.3160 - val_accuracy: 0.9325\n",
      "Epoch 97/100\n",
      "380/380 [==============================] - 0s 85us/step - loss: 0.1319 - accuracy: 0.9632 - val_loss: 0.3288 - val_accuracy: 0.9080\n",
      "Epoch 98/100\n",
      "380/380 [==============================] - 0s 85us/step - loss: 0.1336 - accuracy: 0.9553 - val_loss: 0.3354 - val_accuracy: 0.9202\n",
      "Epoch 99/100\n",
      "380/380 [==============================] - 0s 82us/step - loss: 0.1386 - accuracy: 0.9579 - val_loss: 0.3415 - val_accuracy: 0.9080\n",
      "Epoch 100/100\n",
      "380/380 [==============================] - 0s 82us/step - loss: 0.1370 - accuracy: 0.9526 - val_loss: 0.3355 - val_accuracy: 0.8896\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a40db0080>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over2.fit(X_train_over, y_train_over,\n",
    "          batch_size=64, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163/163 [==============================] - 0s 117us/step\n",
      "over-sampling test accuracy: 91.41%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over2 = model1_over2.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over2*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 2, 0, 2, 1, 1, 2, 1, 1, 1, 2, 1, 0,\n",
       "       1, 0, 2, 1, 1, 0, 1, 2, 0, 0, 0, 2, 1, 0, 2, 1, 0, 0, 0, 0, 2, 1,\n",
       "       1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 2, 0, 0, 0, 2, 1, 2, 0, 2, 1,\n",
       "       0, 1, 1, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 2, 1, 2, 1, 0, 1, 1, 1, 0,\n",
       "       2, 2, 2, 0, 1, 0, 0, 1, 0, 2, 1, 0, 0, 0, 1, 0, 1, 2, 1, 2, 1, 0,\n",
       "       1, 1, 0, 0, 0, 2, 2, 1, 1, 0, 1, 1, 1, 1, 1, 0, 2, 0, 0, 2, 0, 0,\n",
       "       2, 0, 2, 2, 1, 1, 1, 2, 1, 2, 0, 2, 0, 1, 0, 2, 0, 2, 1, 0, 0, 2,\n",
       "       1, 1, 1, 2, 1, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred2 = model1_over2.predict_classes(X_test_over)\n",
    "pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS027</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CFBRSa07</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CFBRSa27</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>504</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CFBREBSa129</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>SR3569</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>NRS243</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>GA48963</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>504</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>CFBREBSa123</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test  pred\n",
       "0         NRS027     0     0\n",
       "1       CFBRSa07     0     0\n",
       "2       CFBRSa27     1     1\n",
       "3            504     1     1\n",
       "4    CFBREBSa129     0     0\n",
       "..           ...   ...   ...\n",
       "158       SR3569     2     1\n",
       "159       NRS243     1     1\n",
       "160      GA48963     1     1\n",
       "161          504     1     1\n",
       "162  CFBREBSa123     0     0\n",
       "\n",
       "[163 rows x 3 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat2['pred'] = pred2\n",
    "dat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba2 = model1_over2.predict_proba(X_test_over)\n",
    "dat_proba2 = pd.DataFrame(proba2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.998794</td>\n",
       "      <td>0.000903</td>\n",
       "      <td>0.000303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.996671</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.000329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.034051</td>\n",
       "      <td>0.827807</td>\n",
       "      <td>0.138142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.007163</td>\n",
       "      <td>0.935975</td>\n",
       "      <td>0.056862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.999048</td>\n",
       "      <td>0.000870</td>\n",
       "      <td>0.000081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>0.009522</td>\n",
       "      <td>0.608981</td>\n",
       "      <td>0.381497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>0.000305</td>\n",
       "      <td>0.957949</td>\n",
       "      <td>0.041746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>0.000363</td>\n",
       "      <td>0.941257</td>\n",
       "      <td>0.058380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>0.007163</td>\n",
       "      <td>0.935975</td>\n",
       "      <td>0.056862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>0.977433</td>\n",
       "      <td>0.022561</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2\n",
       "0    0.998794  0.000903  0.000303\n",
       "1    0.996671  0.003000  0.000329\n",
       "2    0.034051  0.827807  0.138142\n",
       "3    0.007163  0.935975  0.056862\n",
       "4    0.999048  0.000870  0.000081\n",
       "..        ...       ...       ...\n",
       "158  0.009522  0.608981  0.381497\n",
       "159  0.000305  0.957949  0.041746\n",
       "160  0.000363  0.941257  0.058380\n",
       "161  0.007163  0.935975  0.056862\n",
       "162  0.977433  0.022561  0.000005\n",
       "\n",
       "[163 rows x 3 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba2.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba2.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat2.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/2p11pST.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 380 samples, validate on 163 samples\n",
      "Epoch 1/100\n",
      "380/380 [==============================] - 0s 204us/step - loss: 0.1113 - accuracy: 0.9632 - val_loss: 0.4424 - val_accuracy: 0.8957\n",
      "Epoch 2/100\n",
      "380/380 [==============================] - 0s 125us/step - loss: 0.1064 - accuracy: 0.9632 - val_loss: 0.3629 - val_accuracy: 0.8957\n",
      "Epoch 3/100\n",
      "380/380 [==============================] - 0s 150us/step - loss: 0.1076 - accuracy: 0.9632 - val_loss: 0.3570 - val_accuracy: 0.9080\n",
      "Epoch 4/100\n",
      "380/380 [==============================] - 0s 138us/step - loss: 0.1048 - accuracy: 0.9632 - val_loss: 0.4801 - val_accuracy: 0.8834\n",
      "Epoch 5/100\n",
      "380/380 [==============================] - 0s 127us/step - loss: 0.1136 - accuracy: 0.9579 - val_loss: 0.3654 - val_accuracy: 0.9080\n",
      "Epoch 6/100\n",
      "380/380 [==============================] - 0s 141us/step - loss: 0.1054 - accuracy: 0.9658 - val_loss: 0.3911 - val_accuracy: 0.8957\n",
      "Epoch 7/100\n",
      "380/380 [==============================] - 0s 129us/step - loss: 0.0993 - accuracy: 0.9684 - val_loss: 0.3884 - val_accuracy: 0.8957\n",
      "Epoch 8/100\n",
      "380/380 [==============================] - 0s 115us/step - loss: 0.1034 - accuracy: 0.9605 - val_loss: 0.3600 - val_accuracy: 0.9080\n",
      "Epoch 9/100\n",
      "380/380 [==============================] - 0s 129us/step - loss: 0.0999 - accuracy: 0.9632 - val_loss: 0.4028 - val_accuracy: 0.8957\n",
      "Epoch 10/100\n",
      "380/380 [==============================] - 0s 118us/step - loss: 0.0998 - accuracy: 0.9684 - val_loss: 0.3478 - val_accuracy: 0.9080\n",
      "Epoch 11/100\n",
      "380/380 [==============================] - 0s 123us/step - loss: 0.1022 - accuracy: 0.9684 - val_loss: 0.4293 - val_accuracy: 0.8957\n",
      "Epoch 12/100\n",
      "380/380 [==============================] - 0s 119us/step - loss: 0.1045 - accuracy: 0.9579 - val_loss: 0.4020 - val_accuracy: 0.8834\n",
      "Epoch 13/100\n",
      "380/380 [==============================] - 0s 116us/step - loss: 0.0990 - accuracy: 0.9632 - val_loss: 0.4377 - val_accuracy: 0.9080\n",
      "Epoch 14/100\n",
      "380/380 [==============================] - 0s 110us/step - loss: 0.1017 - accuracy: 0.9632 - val_loss: 0.4235 - val_accuracy: 0.8896\n",
      "Epoch 15/100\n",
      "380/380 [==============================] - 0s 121us/step - loss: 0.0970 - accuracy: 0.9605 - val_loss: 0.3423 - val_accuracy: 0.9080\n",
      "Epoch 16/100\n",
      "380/380 [==============================] - 0s 121us/step - loss: 0.0938 - accuracy: 0.9658 - val_loss: 0.4283 - val_accuracy: 0.8834\n",
      "Epoch 17/100\n",
      "380/380 [==============================] - 0s 115us/step - loss: 0.1059 - accuracy: 0.9605 - val_loss: 0.3420 - val_accuracy: 0.9141\n",
      "Epoch 18/100\n",
      "380/380 [==============================] - 0s 124us/step - loss: 0.1004 - accuracy: 0.9658 - val_loss: 0.5056 - val_accuracy: 0.8896\n",
      "Epoch 19/100\n",
      "380/380 [==============================] - 0s 133us/step - loss: 0.0974 - accuracy: 0.9658 - val_loss: 0.3896 - val_accuracy: 0.8957\n",
      "Epoch 20/100\n",
      "380/380 [==============================] - 0s 104us/step - loss: 0.0927 - accuracy: 0.9658 - val_loss: 0.4013 - val_accuracy: 0.9080\n",
      "Epoch 21/100\n",
      "380/380 [==============================] - 0s 120us/step - loss: 0.0919 - accuracy: 0.9711 - val_loss: 0.3873 - val_accuracy: 0.9080\n",
      "Epoch 22/100\n",
      "380/380 [==============================] - 0s 123us/step - loss: 0.0909 - accuracy: 0.9658 - val_loss: 0.6870 - val_accuracy: 0.8834\n",
      "Epoch 23/100\n",
      "380/380 [==============================] - 0s 110us/step - loss: 0.0967 - accuracy: 0.9684 - val_loss: 0.3724 - val_accuracy: 0.9080\n",
      "Epoch 24/100\n",
      "380/380 [==============================] - 0s 123us/step - loss: 0.2014 - accuracy: 0.9500 - val_loss: 2.2770 - val_accuracy: 0.8466\n",
      "Epoch 25/100\n",
      "380/380 [==============================] - 0s 102us/step - loss: 0.3620 - accuracy: 0.9263 - val_loss: 0.7691 - val_accuracy: 0.8405\n",
      "Epoch 26/100\n",
      "380/380 [==============================] - 0s 99us/step - loss: 0.2060 - accuracy: 0.9079 - val_loss: 0.8669 - val_accuracy: 0.8650\n",
      "Epoch 27/100\n",
      "380/380 [==============================] - 0s 99us/step - loss: 0.2093 - accuracy: 0.9342 - val_loss: 0.6790 - val_accuracy: 0.8834\n",
      "Epoch 28/100\n",
      "380/380 [==============================] - 0s 122us/step - loss: 0.1250 - accuracy: 0.9447 - val_loss: 0.3971 - val_accuracy: 0.8650\n",
      "Epoch 29/100\n",
      "380/380 [==============================] - 0s 111us/step - loss: 0.1153 - accuracy: 0.9500 - val_loss: 0.6216 - val_accuracy: 0.8957\n",
      "Epoch 30/100\n",
      "380/380 [==============================] - 0s 140us/step - loss: 0.1238 - accuracy: 0.9579 - val_loss: 0.8147 - val_accuracy: 0.8773\n",
      "Epoch 31/100\n",
      "380/380 [==============================] - 0s 142us/step - loss: 0.1358 - accuracy: 0.9421 - val_loss: 0.9035 - val_accuracy: 0.8589\n",
      "Epoch 32/100\n",
      "380/380 [==============================] - 0s 126us/step - loss: 0.1265 - accuracy: 0.9447 - val_loss: 0.5360 - val_accuracy: 0.9080\n",
      "Epoch 33/100\n",
      "380/380 [==============================] - 0s 144us/step - loss: 0.1291 - accuracy: 0.9553 - val_loss: 0.5222 - val_accuracy: 0.8957\n",
      "Epoch 34/100\n",
      "380/380 [==============================] - 0s 208us/step - loss: 0.1439 - accuracy: 0.9316 - val_loss: 0.8383 - val_accuracy: 0.8221\n",
      "Epoch 35/100\n",
      "380/380 [==============================] - 0s 202us/step - loss: 0.1627 - accuracy: 0.9289 - val_loss: 0.5596 - val_accuracy: 0.8896\n",
      "Epoch 36/100\n",
      "380/380 [==============================] - 0s 155us/step - loss: 0.1041 - accuracy: 0.9526 - val_loss: 0.6345 - val_accuracy: 0.8834\n",
      "Epoch 37/100\n",
      "380/380 [==============================] - 0s 123us/step - loss: 0.1002 - accuracy: 0.9579 - val_loss: 0.6131 - val_accuracy: 0.8834\n",
      "Epoch 38/100\n",
      "380/380 [==============================] - 0s 111us/step - loss: 0.0864 - accuracy: 0.9632 - val_loss: 0.5755 - val_accuracy: 0.8957\n",
      "Epoch 39/100\n",
      "380/380 [==============================] - 0s 127us/step - loss: 0.0802 - accuracy: 0.9816 - val_loss: 0.5821 - val_accuracy: 0.8957\n",
      "Epoch 40/100\n",
      "380/380 [==============================] - 0s 131us/step - loss: 0.0841 - accuracy: 0.9684 - val_loss: 0.5727 - val_accuracy: 0.8896\n",
      "Epoch 41/100\n",
      "380/380 [==============================] - 0s 140us/step - loss: 0.0870 - accuracy: 0.9711 - val_loss: 0.6238 - val_accuracy: 0.8773\n",
      "Epoch 42/100\n",
      "380/380 [==============================] - 0s 127us/step - loss: 0.0871 - accuracy: 0.9711 - val_loss: 0.5448 - val_accuracy: 0.9080\n",
      "Epoch 43/100\n",
      "380/380 [==============================] - 0s 437us/step - loss: 0.0817 - accuracy: 0.9684 - val_loss: 0.6108 - val_accuracy: 0.8896\n",
      "Epoch 44/100\n",
      "380/380 [==============================] - 0s 165us/step - loss: 0.0830 - accuracy: 0.9684 - val_loss: 0.5869 - val_accuracy: 0.8896\n",
      "Epoch 45/100\n",
      "380/380 [==============================] - 0s 130us/step - loss: 0.0793 - accuracy: 0.9816 - val_loss: 0.5416 - val_accuracy: 0.9080\n",
      "Epoch 46/100\n",
      "380/380 [==============================] - 0s 145us/step - loss: 0.0843 - accuracy: 0.9684 - val_loss: 0.5428 - val_accuracy: 0.9080\n",
      "Epoch 47/100\n",
      "380/380 [==============================] - 0s 216us/step - loss: 0.0779 - accuracy: 0.9711 - val_loss: 0.6211 - val_accuracy: 0.8896\n",
      "Epoch 48/100\n",
      "380/380 [==============================] - 0s 110us/step - loss: 0.0754 - accuracy: 0.9789 - val_loss: 0.5512 - val_accuracy: 0.9018\n",
      "Epoch 49/100\n",
      "380/380 [==============================] - 0s 117us/step - loss: 0.0756 - accuracy: 0.9711 - val_loss: 0.5197 - val_accuracy: 0.9018\n",
      "Epoch 50/100\n",
      "380/380 [==============================] - 0s 93us/step - loss: 0.0720 - accuracy: 0.9737 - val_loss: 0.5711 - val_accuracy: 0.8896\n",
      "Epoch 51/100\n",
      "380/380 [==============================] - 0s 108us/step - loss: 0.0756 - accuracy: 0.9789 - val_loss: 0.5381 - val_accuracy: 0.9080\n",
      "Epoch 52/100\n",
      "380/380 [==============================] - 0s 119us/step - loss: 0.0731 - accuracy: 0.9789 - val_loss: 0.6293 - val_accuracy: 0.8834\n",
      "Epoch 53/100\n",
      "380/380 [==============================] - 0s 91us/step - loss: 0.0789 - accuracy: 0.9711 - val_loss: 0.5341 - val_accuracy: 0.9018\n",
      "Epoch 54/100\n",
      "380/380 [==============================] - 0s 96us/step - loss: 0.0778 - accuracy: 0.9763 - val_loss: 0.5798 - val_accuracy: 0.8957\n",
      "Epoch 55/100\n",
      "380/380 [==============================] - 0s 97us/step - loss: 0.0738 - accuracy: 0.9684 - val_loss: 0.5985 - val_accuracy: 0.8896\n",
      "Epoch 56/100\n",
      "380/380 [==============================] - 0s 103us/step - loss: 0.0738 - accuracy: 0.9711 - val_loss: 0.5664 - val_accuracy: 0.9018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "380/380 [==============================] - 0s 99us/step - loss: 0.0805 - accuracy: 0.9684 - val_loss: 0.6558 - val_accuracy: 0.8712\n",
      "Epoch 58/100\n",
      "380/380 [==============================] - 0s 95us/step - loss: 0.0838 - accuracy: 0.9684 - val_loss: 0.6620 - val_accuracy: 0.8896\n",
      "Epoch 59/100\n",
      "380/380 [==============================] - 0s 99us/step - loss: 0.0800 - accuracy: 0.9737 - val_loss: 0.5494 - val_accuracy: 0.9141\n",
      "Epoch 60/100\n",
      "380/380 [==============================] - 0s 102us/step - loss: 0.0769 - accuracy: 0.9711 - val_loss: 0.6479 - val_accuracy: 0.8834\n",
      "Epoch 61/100\n",
      "380/380 [==============================] - 0s 102us/step - loss: 0.0731 - accuracy: 0.9789 - val_loss: 0.5620 - val_accuracy: 0.9141\n",
      "Epoch 62/100\n",
      "380/380 [==============================] - 0s 359us/step - loss: 0.0685 - accuracy: 0.9737 - val_loss: 0.6522 - val_accuracy: 0.8957\n",
      "Epoch 63/100\n",
      "380/380 [==============================] - 0s 139us/step - loss: 0.0657 - accuracy: 0.9763 - val_loss: 0.5741 - val_accuracy: 0.9141\n",
      "Epoch 64/100\n",
      "380/380 [==============================] - 0s 228us/step - loss: 0.0659 - accuracy: 0.9711 - val_loss: 0.5919 - val_accuracy: 0.8957\n",
      "Epoch 65/100\n",
      "380/380 [==============================] - 0s 165us/step - loss: 0.0646 - accuracy: 0.9816 - val_loss: 0.5828 - val_accuracy: 0.8957\n",
      "Epoch 66/100\n",
      "380/380 [==============================] - 0s 108us/step - loss: 0.0661 - accuracy: 0.9763 - val_loss: 0.6358 - val_accuracy: 0.8957\n",
      "Epoch 67/100\n",
      "380/380 [==============================] - 0s 123us/step - loss: 0.0629 - accuracy: 0.9763 - val_loss: 0.5748 - val_accuracy: 0.8957\n",
      "Epoch 68/100\n",
      "380/380 [==============================] - 0s 98us/step - loss: 0.0637 - accuracy: 0.9842 - val_loss: 0.5615 - val_accuracy: 0.8957\n",
      "Epoch 69/100\n",
      "380/380 [==============================] - 0s 98us/step - loss: 0.0661 - accuracy: 0.9737 - val_loss: 0.5655 - val_accuracy: 0.9018\n",
      "Epoch 70/100\n",
      "380/380 [==============================] - 0s 102us/step - loss: 0.0602 - accuracy: 0.9789 - val_loss: 0.6097 - val_accuracy: 0.8957\n",
      "Epoch 71/100\n",
      "380/380 [==============================] - 0s 100us/step - loss: 0.0642 - accuracy: 0.9763 - val_loss: 0.6729 - val_accuracy: 0.8773\n",
      "Epoch 72/100\n",
      "380/380 [==============================] - 0s 101us/step - loss: 0.0896 - accuracy: 0.9737 - val_loss: 0.5341 - val_accuracy: 0.8957\n",
      "Epoch 73/100\n",
      "380/380 [==============================] - 0s 107us/step - loss: 0.0669 - accuracy: 0.9737 - val_loss: 0.6250 - val_accuracy: 0.8896\n",
      "Epoch 74/100\n",
      "380/380 [==============================] - 0s 107us/step - loss: 0.0661 - accuracy: 0.9816 - val_loss: 0.5409 - val_accuracy: 0.9018\n",
      "Epoch 75/100\n",
      "380/380 [==============================] - 0s 91us/step - loss: 0.0638 - accuracy: 0.9816 - val_loss: 0.7370 - val_accuracy: 0.8773\n",
      "Epoch 76/100\n",
      "380/380 [==============================] - 0s 94us/step - loss: 0.0694 - accuracy: 0.9737 - val_loss: 0.5968 - val_accuracy: 0.8957\n",
      "Epoch 77/100\n",
      "380/380 [==============================] - 0s 99us/step - loss: 0.0656 - accuracy: 0.9763 - val_loss: 0.7160 - val_accuracy: 0.8834\n",
      "Epoch 78/100\n",
      "380/380 [==============================] - 0s 97us/step - loss: 0.0604 - accuracy: 0.9816 - val_loss: 0.6222 - val_accuracy: 0.9080\n",
      "Epoch 79/100\n",
      "380/380 [==============================] - 0s 101us/step - loss: 0.0585 - accuracy: 0.9895 - val_loss: 0.6803 - val_accuracy: 0.8957\n",
      "Epoch 80/100\n",
      "380/380 [==============================] - 0s 94us/step - loss: 0.0659 - accuracy: 0.9763 - val_loss: 0.6870 - val_accuracy: 0.8957\n",
      "Epoch 81/100\n",
      "380/380 [==============================] - 0s 121us/step - loss: 0.0590 - accuracy: 0.9789 - val_loss: 0.6704 - val_accuracy: 0.8957\n",
      "Epoch 82/100\n",
      "380/380 [==============================] - 0s 217us/step - loss: 0.0628 - accuracy: 0.9737 - val_loss: 0.6416 - val_accuracy: 0.8957\n",
      "Epoch 83/100\n",
      "380/380 [==============================] - 0s 122us/step - loss: 0.0561 - accuracy: 0.9763 - val_loss: 0.6753 - val_accuracy: 0.8957\n",
      "Epoch 84/100\n",
      "380/380 [==============================] - 0s 226us/step - loss: 0.0589 - accuracy: 0.9763 - val_loss: 0.6379 - val_accuracy: 0.9018\n",
      "Epoch 85/100\n",
      "380/380 [==============================] - 0s 182us/step - loss: 0.0566 - accuracy: 0.9816 - val_loss: 0.7325 - val_accuracy: 0.8957\n",
      "Epoch 86/100\n",
      "380/380 [==============================] - 0s 510us/step - loss: 0.0586 - accuracy: 0.9763 - val_loss: 0.5630 - val_accuracy: 0.8957\n",
      "Epoch 87/100\n",
      "380/380 [==============================] - 0s 200us/step - loss: 0.0651 - accuracy: 0.9737 - val_loss: 0.7543 - val_accuracy: 0.8712\n",
      "Epoch 88/100\n",
      "380/380 [==============================] - 0s 179us/step - loss: 0.0644 - accuracy: 0.9763 - val_loss: 0.6444 - val_accuracy: 0.9080\n",
      "Epoch 89/100\n",
      "380/380 [==============================] - 0s 150us/step - loss: 0.0556 - accuracy: 0.9763 - val_loss: 0.6910 - val_accuracy: 0.8957\n",
      "Epoch 90/100\n",
      "380/380 [==============================] - 0s 157us/step - loss: 0.0551 - accuracy: 0.9763 - val_loss: 0.6057 - val_accuracy: 0.9080\n",
      "Epoch 91/100\n",
      "380/380 [==============================] - 0s 187us/step - loss: 0.0598 - accuracy: 0.9763 - val_loss: 0.6238 - val_accuracy: 0.9018\n",
      "Epoch 92/100\n",
      "380/380 [==============================] - 0s 140us/step - loss: 0.0535 - accuracy: 0.9816 - val_loss: 0.7295 - val_accuracy: 0.8957\n",
      "Epoch 93/100\n",
      "380/380 [==============================] - 0s 123us/step - loss: 0.0534 - accuracy: 0.9789 - val_loss: 0.6613 - val_accuracy: 0.9080\n",
      "Epoch 94/100\n",
      "380/380 [==============================] - 0s 115us/step - loss: 0.0512 - accuracy: 0.9763 - val_loss: 0.7036 - val_accuracy: 0.8957\n",
      "Epoch 95/100\n",
      "380/380 [==============================] - 0s 114us/step - loss: 0.0502 - accuracy: 0.9868 - val_loss: 0.6358 - val_accuracy: 0.9080\n",
      "Epoch 96/100\n",
      "380/380 [==============================] - 0s 130us/step - loss: 0.0563 - accuracy: 0.9763 - val_loss: 0.7205 - val_accuracy: 0.8896\n",
      "Epoch 97/100\n",
      "380/380 [==============================] - 0s 185us/step - loss: 0.0574 - accuracy: 0.9842 - val_loss: 0.6710 - val_accuracy: 0.9080\n",
      "Epoch 98/100\n",
      "380/380 [==============================] - 0s 165us/step - loss: 0.0506 - accuracy: 0.9789 - val_loss: 0.7767 - val_accuracy: 0.8957\n",
      "Epoch 99/100\n",
      "380/380 [==============================] - 0s 131us/step - loss: 0.0515 - accuracy: 0.9816 - val_loss: 0.7388 - val_accuracy: 0.8957\n",
      "Epoch 100/100\n",
      "380/380 [==============================] - 0s 108us/step - loss: 0.0510 - accuracy: 0.9816 - val_loss: 0.7125 - val_accuracy: 0.8957\n"
     ]
    }
   ],
   "source": [
    "hist1_over2 = model1_over2.fit(X_train_over, y_train_over,\n",
    "          batch_size=64, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 96.85%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over2.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba2 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_2.xlsx\",\n",
    "                        sheet_name=1,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>1.748042e-03</td>\n",
       "      <td>9.981960e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>BCH-SA-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.712007</td>\n",
       "      <td>2.879924e-01</td>\n",
       "      <td>9.646217e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS218</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.006222</td>\n",
       "      <td>9.937732e-01</td>\n",
       "      <td>4.482882e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS036</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.882617</td>\n",
       "      <td>1.173831e-01</td>\n",
       "      <td>2.310933e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS386</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.571179</td>\n",
       "      <td>4.288184e-01</td>\n",
       "      <td>2.444667e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4279</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS112</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001860</td>\n",
       "      <td>9.979747e-01</td>\n",
       "      <td>1.653396e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4280</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>SR1065</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.982940</td>\n",
       "      <td>1.705227e-02</td>\n",
       "      <td>7.349168e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4281</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS203</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.997093</td>\n",
       "      <td>1.962516e-03</td>\n",
       "      <td>9.441347e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4282</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>CFBREBSa129</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.031141e-13</td>\n",
       "      <td>3.208205e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4283</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>CFBRSa25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999833</td>\n",
       "      <td>1.669456e-04</td>\n",
       "      <td>4.411099e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4284 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    phage       strain  phenotype  prediction         0  \\\n",
       "0      p002ykpresabs_qual       NRS148          2           2  0.000056   \n",
       "1      p002ykpresabs_qual    BCH-SA-03          1           0  0.712007   \n",
       "2      p002ykpresabs_qual       NRS218          1           1  0.006222   \n",
       "3      p002ykpresabs_qual       NRS036          0           0  0.882617   \n",
       "4      p002ykpresabs_qual       NRS386          1           0  0.571179   \n",
       "...                   ...          ...        ...         ...       ...   \n",
       "4279  pyopresabsSTCC_qual       NRS112          1           1  0.001860   \n",
       "4280  pyopresabsSTCC_qual       SR1065          0           0  0.982940   \n",
       "4281  pyopresabsSTCC_qual       NRS203          0           0  0.997093   \n",
       "4282  pyopresabsSTCC_qual  CFBREBSa129          0           0  1.000000   \n",
       "4283  pyopresabsSTCC_qual     CFBRSa25          0           0  0.999833   \n",
       "\n",
       "                 1             2  \n",
       "0     1.748042e-03  9.981960e-01  \n",
       "1     2.879924e-01  9.646217e-07  \n",
       "2     9.937732e-01  4.482882e-06  \n",
       "3     1.173831e-01  2.310933e-10  \n",
       "4     4.288184e-01  2.444667e-06  \n",
       "...            ...           ...  \n",
       "4279  9.979747e-01  1.653396e-04  \n",
       "4280  1.705227e-02  7.349168e-06  \n",
       "4281  1.962516e-03  9.441347e-04  \n",
       "4282  3.031141e-13  3.208205e-09  \n",
       "4283  1.669456e-04  4.411099e-08  \n",
       "\n",
       "[4284 rows x 7 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.9879396e-01, 9.0337130e-04, 3.0261776e-04],\n",
       "       [9.9667080e-01, 2.9997230e-03, 3.2942856e-04],\n",
       "       [3.4051300e-02, 8.2780695e-01, 1.3814175e-01],\n",
       "       [7.1629840e-03, 9.3597496e-01, 5.6861997e-02],\n",
       "       [9.9904805e-01, 8.7045950e-04, 8.1462895e-05],\n",
       "       [9.3585515e-01, 4.0976547e-02, 2.3168314e-02],\n",
       "       [9.9904805e-01, 8.7045950e-04, 8.1462895e-05],\n",
       "       [3.5724414e-03, 9.2506860e-01, 7.1358990e-02],\n",
       "       [3.9170510e-02, 8.9149505e-01, 6.9334470e-02],\n",
       "       [3.3237330e-02, 9.3049830e-01, 3.6264442e-02],\n",
       "       [7.2584805e-07, 2.0911873e-03, 9.9790810e-01],\n",
       "       [9.9993060e-01, 5.1309958e-06, 6.4307810e-05],\n",
       "       [1.2467727e-02, 3.1199074e-01, 6.7554146e-01],\n",
       "       [7.4236420e-03, 9.5181200e-01, 4.0764310e-02],\n",
       "       [5.1882220e-04, 9.9699030e-01, 2.4908240e-03],\n",
       "       [2.1552147e-08, 1.1833746e-05, 9.9998820e-01],\n",
       "       [9.1492676e-04, 9.6463670e-01, 3.4448408e-02],\n",
       "       [1.3996516e-03, 9.6731836e-01, 3.1282004e-02],\n",
       "       [1.6539750e-02, 7.0573540e-01, 2.7772483e-01],\n",
       "       [7.3877810e-05, 1.4937812e-02, 9.8498833e-01],\n",
       "       [3.6322625e-04, 9.4125670e-01, 5.8380060e-02],\n",
       "       [9.9642986e-01, 3.5052844e-03, 6.4887600e-05],\n",
       "       [1.9599004e-03, 9.9587315e-01, 2.1670030e-03],\n",
       "       [9.9642986e-01, 3.5052844e-03, 6.4887600e-05],\n",
       "       [3.0415885e-03, 1.7053463e-01, 8.2642376e-01],\n",
       "       [4.0827612e-03, 9.5193356e-01, 4.3983620e-02],\n",
       "       [3.3237330e-02, 9.3049830e-01, 3.6264442e-02],\n",
       "       [9.9642986e-01, 3.5052844e-03, 6.4887600e-05],\n",
       "       [2.9309362e-04, 9.2828080e-01, 7.1426040e-02],\n",
       "       [4.3094475e-03, 4.1931635e-01, 5.7637423e-01],\n",
       "       [9.6825826e-01, 3.1281255e-02, 4.6055924e-04],\n",
       "       [9.8274773e-01, 1.5673866e-02, 1.5784480e-03],\n",
       "       [9.9879396e-01, 9.0337130e-04, 3.0261776e-04],\n",
       "       [1.9668428e-04, 9.8886870e-03, 9.8991466e-01],\n",
       "       [7.1167800e-05, 9.3152064e-01, 6.8408230e-02],\n",
       "       [9.9879396e-01, 9.0337130e-04, 3.0261776e-04],\n",
       "       [1.9846723e-06, 3.4324310e-03, 9.9656564e-01],\n",
       "       [5.6891067e-06, 9.6493300e-01, 3.5061400e-02],\n",
       "       [9.8274773e-01, 1.5673866e-02, 1.5784480e-03],\n",
       "       [9.5202130e-01, 3.8301220e-02, 9.6774680e-03],\n",
       "       [9.8274773e-01, 1.5673866e-02, 1.5784480e-03],\n",
       "       [9.9866950e-01, 3.5086160e-05, 1.2953462e-03],\n",
       "       [1.9580000e-04, 1.2783495e-02, 9.8702070e-01],\n",
       "       [7.3363060e-07, 9.9831450e-01, 1.6847994e-03],\n",
       "       [3.4661055e-02, 8.6899460e-01, 9.6344360e-02],\n",
       "       [9.8941517e-01, 3.6387458e-03, 6.9460357e-03],\n",
       "       [7.7868330e-01, 1.8331286e-01, 3.8003860e-02],\n",
       "       [7.1629840e-03, 9.3597496e-01, 5.6861997e-02],\n",
       "       [7.5835840e-02, 8.9369710e-01, 3.0467127e-02],\n",
       "       [9.9358165e-01, 5.8505875e-03, 5.6786276e-04],\n",
       "       [5.1754767e-01, 4.8151594e-01, 9.3637995e-04],\n",
       "       [3.9170510e-02, 8.9149505e-01, 6.9334470e-02],\n",
       "       [9.5202130e-01, 3.8301220e-02, 9.6774680e-03],\n",
       "       [1.3996516e-03, 9.6731836e-01, 3.1282004e-02],\n",
       "       [9.8941517e-01, 3.6387458e-03, 6.9460357e-03],\n",
       "       [3.2634646e-02, 8.7783253e-01, 8.9532810e-02],\n",
       "       [1.7878940e-02, 3.9449820e-01, 5.8762290e-01],\n",
       "       [7.7868330e-01, 1.8331286e-01, 3.8003860e-02],\n",
       "       [9.6825826e-01, 3.1281255e-02, 4.6055924e-04],\n",
       "       [9.6825826e-01, 3.1281255e-02, 4.6055924e-04],\n",
       "       [2.5600918e-06, 1.5391382e-04, 9.9984350e-01],\n",
       "       [2.9309362e-04, 9.2828080e-01, 7.1426040e-02],\n",
       "       [7.7830337e-04, 8.0420190e-02, 9.1880150e-01],\n",
       "       [9.9741400e-01, 2.5382100e-03, 4.7798420e-05],\n",
       "       [1.9321053e-06, 2.1630242e-04, 9.9978180e-01],\n",
       "       [5.7888357e-04, 9.9598724e-01, 3.4337610e-03],\n",
       "       [9.9963903e-01, 3.4451202e-04, 1.6418031e-05],\n",
       "       [8.8119230e-04, 8.0230340e-01, 1.9681543e-01],\n",
       "       [1.9715673e-05, 9.9741155e-01, 2.5686733e-03],\n",
       "       [5.6788940e-03, 5.8002716e-01, 4.1429390e-01],\n",
       "       [6.3632970e-02, 6.4764100e-01, 2.8872600e-01],\n",
       "       [9.9904805e-01, 8.7045950e-04, 8.1462895e-05],\n",
       "       [7.3363060e-07, 9.9831450e-01, 1.6847994e-03],\n",
       "       [2.9391353e-04, 4.3224810e-03, 9.9538356e-01],\n",
       "       [2.9740655e-01, 3.6379984e-01, 3.3879360e-01],\n",
       "       [7.1629840e-03, 9.3597496e-01, 5.6861997e-02],\n",
       "       [2.6530267e-06, 6.6948680e-04, 9.9932790e-01],\n",
       "       [9.7816810e-01, 1.4903607e-02, 6.9282700e-03],\n",
       "       [8.2571095e-01, 1.4316417e-01, 3.1124936e-02],\n",
       "       [2.3736225e-02, 3.9723128e-01, 5.7903250e-01],\n",
       "       [1.3229423e-07, 9.9770665e-01, 2.2931510e-03],\n",
       "       [3.9020980e-03, 7.6503370e-02, 9.1959460e-01],\n",
       "       [9.1492676e-04, 9.6463670e-01, 3.4448408e-02],\n",
       "       [8.2571095e-01, 1.4316417e-01, 3.1124936e-02],\n",
       "       [7.1629840e-03, 9.3597496e-01, 5.6861997e-02],\n",
       "       [9.1492676e-04, 9.6463670e-01, 3.4448408e-02],\n",
       "       [2.0638802e-04, 8.5068196e-01, 1.4911169e-01],\n",
       "       [9.9490070e-01, 5.2594660e-04, 4.5733247e-03],\n",
       "       [2.1522226e-05, 4.4351984e-03, 9.9554330e-01],\n",
       "       [1.3591342e-01, 1.8162042e-01, 6.8246615e-01],\n",
       "       [3.6992535e-02, 1.0166780e-01, 8.6133970e-01],\n",
       "       [9.9904805e-01, 8.7045950e-04, 8.1462895e-05],\n",
       "       [2.8289428e-03, 9.6992670e-01, 2.7244339e-02],\n",
       "       [9.7245026e-01, 2.4635555e-02, 2.9141083e-03],\n",
       "       [9.9741400e-01, 2.5382100e-03, 4.7798420e-05],\n",
       "       [5.8465237e-03, 9.4046240e-01, 5.3691026e-02],\n",
       "       [9.9264020e-01, 2.7708223e-04, 7.0826346e-03],\n",
       "       [1.7303630e-06, 1.8412806e-04, 9.9981420e-01],\n",
       "       [2.0974876e-05, 6.4921180e-01, 3.5076723e-01],\n",
       "       [9.7245026e-01, 2.4635555e-02, 2.9141083e-03],\n",
       "       [9.9358165e-01, 5.8505875e-03, 5.6786276e-04],\n",
       "       [9.9879396e-01, 9.0337130e-04, 3.0261776e-04],\n",
       "       [1.9599004e-03, 9.9587315e-01, 2.1670030e-03],\n",
       "       [9.9879396e-01, 9.0337130e-04, 3.0261776e-04],\n",
       "       [1.9599004e-03, 9.9587315e-01, 2.1670030e-03],\n",
       "       [8.7997810e-04, 2.0643651e-01, 7.9268350e-01],\n",
       "       [8.8021060e-02, 6.5438440e-01, 2.5759465e-01],\n",
       "       [9.4516645e-06, 1.9776387e-02, 9.8021420e-01],\n",
       "       [2.9309362e-04, 9.2828080e-01, 7.1426040e-02],\n",
       "       [9.9264020e-01, 2.7708223e-04, 7.0826346e-03],\n",
       "       [1.4818230e-05, 9.9446060e-01, 5.5246227e-03],\n",
       "       [1.3229423e-07, 9.9770665e-01, 2.2931510e-03],\n",
       "       [9.9667080e-01, 2.9997230e-03, 3.2942856e-04],\n",
       "       [9.9358165e-01, 5.8505875e-03, 5.6786276e-04],\n",
       "       [7.5564605e-01, 2.2646880e-01, 1.7885232e-02],\n",
       "       [1.0755525e-02, 2.9316261e-02, 9.5992820e-01],\n",
       "       [2.4530664e-04, 1.4696148e-03, 9.9828500e-01],\n",
       "       [2.3180199e-01, 6.1014867e-01, 1.5804937e-01],\n",
       "       [6.4865190e-05, 9.8498154e-01, 1.4953631e-02],\n",
       "       [9.9642986e-01, 3.5052844e-03, 6.4887600e-05],\n",
       "       [1.5288164e-02, 7.3918210e-01, 2.4552970e-01],\n",
       "       [3.4661055e-02, 8.6899460e-01, 9.6344360e-02],\n",
       "       [1.8135503e-02, 5.8296263e-01, 3.9890194e-01],\n",
       "       [3.8590056e-03, 8.6565500e-01, 1.3048600e-01],\n",
       "       [3.6322625e-04, 9.4125670e-01, 5.8380060e-02],\n",
       "       [9.9879396e-01, 9.0337130e-04, 3.0261776e-04],\n",
       "       [2.9811237e-02, 2.7676020e-01, 6.9342860e-01],\n",
       "       [9.9170446e-01, 6.4367387e-03, 1.8588154e-03],\n",
       "       [9.8274773e-01, 1.5673866e-02, 1.5784480e-03],\n",
       "       [2.7138816e-02, 1.5093190e-01, 8.2192930e-01],\n",
       "       [9.9866950e-01, 3.5086160e-05, 1.2953462e-03],\n",
       "       [8.4040260e-01, 1.2937923e-01, 3.0218182e-02],\n",
       "       [6.1012570e-07, 2.7396770e-04, 9.9972540e-01],\n",
       "       [9.5202130e-01, 3.8301220e-02, 9.6774680e-03],\n",
       "       [8.7420220e-06, 8.2433870e-02, 9.1755740e-01],\n",
       "       [2.2530317e-04, 2.7686613e-02, 9.7208810e-01],\n",
       "       [2.9419074e-02, 9.4230413e-01, 2.8276889e-02],\n",
       "       [2.0897614e-02, 7.3024267e-01, 2.4885969e-01],\n",
       "       [2.4091465e-02, 8.0106930e-01, 1.7483927e-01],\n",
       "       [1.2445372e-02, 2.3338070e-01, 7.5417393e-01],\n",
       "       [2.9419074e-02, 9.4230413e-01, 2.8276889e-02],\n",
       "       [3.3800658e-05, 7.9728634e-04, 9.9916900e-01],\n",
       "       [5.1754767e-01, 4.8151594e-01, 9.3637995e-04],\n",
       "       [7.0048986e-06, 4.6480615e-03, 9.9534494e-01],\n",
       "       [9.9866950e-01, 3.5086160e-05, 1.2953462e-03],\n",
       "       [1.6171737e-02, 8.2630104e-01, 1.5752728e-01],\n",
       "       [9.7245026e-01, 2.4635555e-02, 2.9141083e-03],\n",
       "       [1.2445372e-02, 2.3338070e-01, 7.5417393e-01],\n",
       "       [9.9274105e-01, 1.1989900e-03, 6.0600545e-03],\n",
       "       [1.6385177e-04, 3.2257367e-02, 9.6757877e-01],\n",
       "       [2.9309362e-04, 9.2828080e-01, 7.1426040e-02],\n",
       "       [9.7607553e-01, 2.0387188e-02, 3.5373082e-03],\n",
       "       [9.8941517e-01, 3.6387458e-03, 6.9460357e-03],\n",
       "       [3.2564346e-03, 4.6741053e-02, 9.5000255e-01],\n",
       "       [8.4430670e-03, 4.9867216e-01, 4.9288480e-01],\n",
       "       [6.7999610e-02, 7.0426750e-01, 2.2773284e-01],\n",
       "       [2.0897614e-02, 7.3024267e-01, 2.4885969e-01],\n",
       "       [1.9702755e-03, 3.5400970e-01, 6.4402010e-01],\n",
       "       [9.5221210e-03, 6.0898090e-01, 3.8149703e-01],\n",
       "       [3.0461920e-04, 9.5794946e-01, 4.1745890e-02],\n",
       "       [3.6322625e-04, 9.4125670e-01, 5.8380060e-02],\n",
       "       [7.1629840e-03, 9.3597496e-01, 5.6861997e-02],\n",
       "       [9.7743326e-01, 2.2561291e-02, 5.4223310e-06]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob2 = df_proba2[df_proba2['phage']=='p11presabsSTCC_qual'].iloc[:,-3:]\n",
    "y_prob2 = y_prob2.to_numpy()\n",
    "y_prob2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.973249312698854"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo2 = rocauc_ovo(y_test_over, y_prob2, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.973249312698854"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr2 = rocauc_ovr(y_test_over, y_prob2, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=345,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat3 = pd.DataFrame(X_test_over[:,0])\n",
    "dat3['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS149</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EUH13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS106</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS214</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CFBREBSa129</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>NRS027</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>CFBRSa70</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>CFBREBSa130</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>NRS214</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>NRS073</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test\n",
       "0         NRS149     0\n",
       "1          EUH13     0\n",
       "2         NRS106     2\n",
       "3         NRS214     1\n",
       "4    CFBREBSa129     0\n",
       "..           ...   ...\n",
       "158       NRS027     0\n",
       "159     CFBRSa70     2\n",
       "160  CFBREBSa130     0\n",
       "161       NRS214     1\n",
       "162       NRS073     1\n",
       "\n",
       "[163 rows x 2 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over3 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over3.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 380 samples, validate on 163 samples\n",
      "Epoch 1/100\n",
      "380/380 [==============================] - 0s 549us/step - loss: 1.7203 - accuracy: 0.3711 - val_loss: 0.9571 - val_accuracy: 0.5951\n",
      "Epoch 2/100\n",
      "380/380 [==============================] - 0s 185us/step - loss: 1.0711 - accuracy: 0.5895 - val_loss: 1.1015 - val_accuracy: 0.6319\n",
      "Epoch 3/100\n",
      "380/380 [==============================] - 0s 197us/step - loss: 0.9029 - accuracy: 0.6342 - val_loss: 0.7664 - val_accuracy: 0.6626\n",
      "Epoch 4/100\n",
      "380/380 [==============================] - 0s 168us/step - loss: 0.7758 - accuracy: 0.6500 - val_loss: 0.8073 - val_accuracy: 0.6810\n",
      "Epoch 5/100\n",
      "380/380 [==============================] - 0s 133us/step - loss: 0.7581 - accuracy: 0.6763 - val_loss: 0.7102 - val_accuracy: 0.6871\n",
      "Epoch 6/100\n",
      "380/380 [==============================] - 0s 346us/step - loss: 0.7388 - accuracy: 0.7132 - val_loss: 1.0132 - val_accuracy: 0.6748\n",
      "Epoch 7/100\n",
      "380/380 [==============================] - 0s 135us/step - loss: 0.7215 - accuracy: 0.7105 - val_loss: 0.6372 - val_accuracy: 0.6994\n",
      "Epoch 8/100\n",
      "380/380 [==============================] - 0s 149us/step - loss: 0.6134 - accuracy: 0.7737 - val_loss: 0.7662 - val_accuracy: 0.7239\n",
      "Epoch 9/100\n",
      "380/380 [==============================] - 0s 281us/step - loss: 0.5847 - accuracy: 0.8132 - val_loss: 0.6031 - val_accuracy: 0.7669\n",
      "Epoch 10/100\n",
      "380/380 [==============================] - 0s 211us/step - loss: 0.5470 - accuracy: 0.7868 - val_loss: 0.6165 - val_accuracy: 0.7485\n",
      "Epoch 11/100\n",
      "380/380 [==============================] - 0s 182us/step - loss: 0.5216 - accuracy: 0.8263 - val_loss: 0.5733 - val_accuracy: 0.7975\n",
      "Epoch 12/100\n",
      "380/380 [==============================] - 0s 193us/step - loss: 0.5136 - accuracy: 0.8211 - val_loss: 0.7347 - val_accuracy: 0.7914\n",
      "Epoch 13/100\n",
      "380/380 [==============================] - 0s 165us/step - loss: 0.4683 - accuracy: 0.8474 - val_loss: 0.5319 - val_accuracy: 0.8037\n",
      "Epoch 14/100\n",
      "380/380 [==============================] - 0s 121us/step - loss: 0.4487 - accuracy: 0.8368 - val_loss: 0.5797 - val_accuracy: 0.7301\n",
      "Epoch 15/100\n",
      "380/380 [==============================] - 0s 109us/step - loss: 0.4382 - accuracy: 0.8474 - val_loss: 0.4935 - val_accuracy: 0.8405\n",
      "Epoch 16/100\n",
      "380/380 [==============================] - 0s 117us/step - loss: 0.4088 - accuracy: 0.8526 - val_loss: 0.4953 - val_accuracy: 0.8405\n",
      "Epoch 17/100\n",
      "380/380 [==============================] - 0s 112us/step - loss: 0.3520 - accuracy: 0.8895 - val_loss: 0.5659 - val_accuracy: 0.7975\n",
      "Epoch 18/100\n",
      "380/380 [==============================] - 0s 287us/step - loss: 0.3366 - accuracy: 0.8947 - val_loss: 0.4734 - val_accuracy: 0.8282\n",
      "Epoch 19/100\n",
      "380/380 [==============================] - 0s 401us/step - loss: 0.4400 - accuracy: 0.8289 - val_loss: 0.4856 - val_accuracy: 0.8160\n",
      "Epoch 20/100\n",
      "380/380 [==============================] - 0s 242us/step - loss: 0.5074 - accuracy: 0.8553 - val_loss: 0.9545 - val_accuracy: 0.7853\n",
      "Epoch 21/100\n",
      "380/380 [==============================] - 0s 200us/step - loss: 0.4380 - accuracy: 0.8447 - val_loss: 0.6259 - val_accuracy: 0.8282\n",
      "Epoch 22/100\n",
      "380/380 [==============================] - 0s 141us/step - loss: 0.4022 - accuracy: 0.8737 - val_loss: 0.5181 - val_accuracy: 0.8221\n",
      "Epoch 23/100\n",
      "380/380 [==============================] - 0s 147us/step - loss: 0.3403 - accuracy: 0.8684 - val_loss: 0.5336 - val_accuracy: 0.8282\n",
      "Epoch 24/100\n",
      "380/380 [==============================] - 0s 338us/step - loss: 0.3628 - accuracy: 0.8789 - val_loss: 0.4643 - val_accuracy: 0.8344\n",
      "Epoch 25/100\n",
      "380/380 [==============================] - 0s 448us/step - loss: 0.2989 - accuracy: 0.8842 - val_loss: 0.4628 - val_accuracy: 0.8466\n",
      "Epoch 26/100\n",
      "380/380 [==============================] - 0s 304us/step - loss: 0.2988 - accuracy: 0.8921 - val_loss: 0.4630 - val_accuracy: 0.8466\n",
      "Epoch 27/100\n",
      "380/380 [==============================] - 0s 368us/step - loss: 0.2795 - accuracy: 0.8763 - val_loss: 0.4828 - val_accuracy: 0.8405\n",
      "Epoch 28/100\n",
      "380/380 [==============================] - 0s 297us/step - loss: 0.2909 - accuracy: 0.9053 - val_loss: 0.4209 - val_accuracy: 0.8528\n",
      "Epoch 29/100\n",
      "380/380 [==============================] - 0s 297us/step - loss: 0.3037 - accuracy: 0.9105 - val_loss: 0.4989 - val_accuracy: 0.8528\n",
      "Epoch 30/100\n",
      "380/380 [==============================] - 0s 352us/step - loss: 0.2823 - accuracy: 0.8737 - val_loss: 0.4596 - val_accuracy: 0.8344\n",
      "Epoch 31/100\n",
      "380/380 [==============================] - 0s 343us/step - loss: 0.2679 - accuracy: 0.9105 - val_loss: 0.4863 - val_accuracy: 0.8405\n",
      "Epoch 32/100\n",
      "380/380 [==============================] - 0s 377us/step - loss: 0.2400 - accuracy: 0.9289 - val_loss: 0.4196 - val_accuracy: 0.8344\n",
      "Epoch 33/100\n",
      "380/380 [==============================] - 0s 242us/step - loss: 0.2457 - accuracy: 0.9211 - val_loss: 0.3885 - val_accuracy: 0.8589\n",
      "Epoch 34/100\n",
      "380/380 [==============================] - 0s 354us/step - loss: 0.2178 - accuracy: 0.9053 - val_loss: 0.3509 - val_accuracy: 0.8712\n",
      "Epoch 35/100\n",
      "380/380 [==============================] - 0s 339us/step - loss: 0.2271 - accuracy: 0.9211 - val_loss: 0.4859 - val_accuracy: 0.8221\n",
      "Epoch 36/100\n",
      "380/380 [==============================] - 0s 492us/step - loss: 0.2508 - accuracy: 0.9053 - val_loss: 0.3745 - val_accuracy: 0.8650\n",
      "Epoch 37/100\n",
      "380/380 [==============================] - 0s 576us/step - loss: 0.2481 - accuracy: 0.9079 - val_loss: 0.4397 - val_accuracy: 0.8466\n",
      "Epoch 38/100\n",
      "380/380 [==============================] - 0s 291us/step - loss: 0.1931 - accuracy: 0.9289 - val_loss: 0.3277 - val_accuracy: 0.8773\n",
      "Epoch 39/100\n",
      "380/380 [==============================] - 0s 189us/step - loss: 0.1892 - accuracy: 0.9316 - val_loss: 0.4422 - val_accuracy: 0.8712\n",
      "Epoch 40/100\n",
      "380/380 [==============================] - 0s 125us/step - loss: 0.1782 - accuracy: 0.9447 - val_loss: 0.3772 - val_accuracy: 0.8712\n",
      "Epoch 41/100\n",
      "380/380 [==============================] - 0s 128us/step - loss: 0.1805 - accuracy: 0.9553 - val_loss: 0.3535 - val_accuracy: 0.8589\n",
      "Epoch 42/100\n",
      "380/380 [==============================] - 0s 124us/step - loss: 0.1760 - accuracy: 0.9421 - val_loss: 0.3686 - val_accuracy: 0.8712\n",
      "Epoch 43/100\n",
      "380/380 [==============================] - 0s 158us/step - loss: 0.1659 - accuracy: 0.9395 - val_loss: 0.3957 - val_accuracy: 0.8896\n",
      "Epoch 44/100\n",
      "380/380 [==============================] - 0s 165us/step - loss: 0.1531 - accuracy: 0.9526 - val_loss: 0.4330 - val_accuracy: 0.8712\n",
      "Epoch 45/100\n",
      "380/380 [==============================] - 0s 155us/step - loss: 0.1521 - accuracy: 0.9553 - val_loss: 0.4405 - val_accuracy: 0.8466\n",
      "Epoch 46/100\n",
      "380/380 [==============================] - 0s 143us/step - loss: 0.1444 - accuracy: 0.9500 - val_loss: 0.4073 - val_accuracy: 0.8834\n",
      "Epoch 47/100\n",
      "380/380 [==============================] - 0s 146us/step - loss: 0.2525 - accuracy: 0.9447 - val_loss: 0.5194 - val_accuracy: 0.8712\n",
      "Epoch 48/100\n",
      "380/380 [==============================] - 0s 155us/step - loss: 0.2383 - accuracy: 0.9263 - val_loss: 0.4115 - val_accuracy: 0.8712\n",
      "Epoch 49/100\n",
      "380/380 [==============================] - 0s 121us/step - loss: 0.2768 - accuracy: 0.9395 - val_loss: 0.5694 - val_accuracy: 0.8589\n",
      "Epoch 50/100\n",
      "380/380 [==============================] - 0s 126us/step - loss: 0.2335 - accuracy: 0.9368 - val_loss: 0.4079 - val_accuracy: 0.8773\n",
      "Epoch 51/100\n",
      "380/380 [==============================] - 0s 112us/step - loss: 0.1463 - accuracy: 0.9632 - val_loss: 0.3796 - val_accuracy: 0.8896\n",
      "Epoch 52/100\n",
      "380/380 [==============================] - 0s 113us/step - loss: 0.1418 - accuracy: 0.9605 - val_loss: 0.4884 - val_accuracy: 0.8466\n",
      "Epoch 53/100\n",
      "380/380 [==============================] - 0s 114us/step - loss: 0.1451 - accuracy: 0.9553 - val_loss: 0.3750 - val_accuracy: 0.8957\n",
      "Epoch 54/100\n",
      "380/380 [==============================] - 0s 154us/step - loss: 0.1468 - accuracy: 0.9658 - val_loss: 0.4055 - val_accuracy: 0.8650\n",
      "Epoch 55/100\n",
      "380/380 [==============================] - 0s 170us/step - loss: 0.2401 - accuracy: 0.9526 - val_loss: 0.5410 - val_accuracy: 0.8896\n",
      "Epoch 56/100\n",
      "380/380 [==============================] - 0s 118us/step - loss: 0.2017 - accuracy: 0.9553 - val_loss: 0.5675 - val_accuracy: 0.8405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "380/380 [==============================] - 0s 117us/step - loss: 0.1625 - accuracy: 0.9474 - val_loss: 0.4954 - val_accuracy: 0.9018\n",
      "Epoch 58/100\n",
      "380/380 [==============================] - 0s 117us/step - loss: 0.1990 - accuracy: 0.9500 - val_loss: 0.4463 - val_accuracy: 0.8712\n",
      "Epoch 59/100\n",
      "380/380 [==============================] - 0s 160us/step - loss: 0.1758 - accuracy: 0.9474 - val_loss: 0.6068 - val_accuracy: 0.8896\n",
      "Epoch 60/100\n",
      "380/380 [==============================] - 0s 127us/step - loss: 0.1490 - accuracy: 0.9658 - val_loss: 0.4388 - val_accuracy: 0.8773\n",
      "Epoch 61/100\n",
      "380/380 [==============================] - 0s 112us/step - loss: 0.1189 - accuracy: 0.9684 - val_loss: 0.3431 - val_accuracy: 0.9018\n",
      "Epoch 62/100\n",
      "380/380 [==============================] - 0s 110us/step - loss: 0.1351 - accuracy: 0.9421 - val_loss: 0.4391 - val_accuracy: 0.8712\n",
      "Epoch 63/100\n",
      "380/380 [==============================] - 0s 111us/step - loss: 0.1506 - accuracy: 0.9579 - val_loss: 0.4676 - val_accuracy: 0.8834\n",
      "Epoch 64/100\n",
      "380/380 [==============================] - 0s 112us/step - loss: 0.2264 - accuracy: 0.9447 - val_loss: 0.5110 - val_accuracy: 0.8650\n",
      "Epoch 65/100\n",
      "380/380 [==============================] - 0s 123us/step - loss: 0.1117 - accuracy: 0.9711 - val_loss: 0.5191 - val_accuracy: 0.8589\n",
      "Epoch 66/100\n",
      "380/380 [==============================] - 0s 110us/step - loss: 0.1181 - accuracy: 0.9816 - val_loss: 0.5214 - val_accuracy: 0.8712\n",
      "Epoch 67/100\n",
      "380/380 [==============================] - 0s 111us/step - loss: 0.1271 - accuracy: 0.9684 - val_loss: 0.7530 - val_accuracy: 0.8466\n",
      "Epoch 68/100\n",
      "380/380 [==============================] - 0s 109us/step - loss: 0.2239 - accuracy: 0.9474 - val_loss: 0.5310 - val_accuracy: 0.8834\n",
      "Epoch 69/100\n",
      "380/380 [==============================] - 0s 117us/step - loss: 0.0968 - accuracy: 0.9789 - val_loss: 0.3969 - val_accuracy: 0.9080\n",
      "Epoch 70/100\n",
      "380/380 [==============================] - 0s 146us/step - loss: 0.0905 - accuracy: 0.9842 - val_loss: 0.3735 - val_accuracy: 0.9141\n",
      "Epoch 71/100\n",
      "380/380 [==============================] - 0s 141us/step - loss: 0.0797 - accuracy: 0.9895 - val_loss: 0.5294 - val_accuracy: 0.8712\n",
      "Epoch 72/100\n",
      "380/380 [==============================] - 0s 158us/step - loss: 0.0739 - accuracy: 0.9842 - val_loss: 0.3805 - val_accuracy: 0.9080\n",
      "Epoch 73/100\n",
      "380/380 [==============================] - 0s 144us/step - loss: 0.0899 - accuracy: 0.9816 - val_loss: 0.4206 - val_accuracy: 0.8834\n",
      "Epoch 74/100\n",
      "380/380 [==============================] - 0s 154us/step - loss: 0.1362 - accuracy: 0.9632 - val_loss: 0.6754 - val_accuracy: 0.8282\n",
      "Epoch 75/100\n",
      "380/380 [==============================] - 0s 135us/step - loss: 0.1593 - accuracy: 0.9553 - val_loss: 0.6838 - val_accuracy: 0.8037\n",
      "Epoch 76/100\n",
      "380/380 [==============================] - 0s 151us/step - loss: 0.1286 - accuracy: 0.9579 - val_loss: 0.4490 - val_accuracy: 0.8834\n",
      "Epoch 77/100\n",
      "380/380 [==============================] - 0s 160us/step - loss: 0.1030 - accuracy: 0.9658 - val_loss: 0.7425 - val_accuracy: 0.8528\n",
      "Epoch 78/100\n",
      "380/380 [==============================] - 0s 154us/step - loss: 0.1417 - accuracy: 0.9658 - val_loss: 0.5548 - val_accuracy: 0.8344\n",
      "Epoch 79/100\n",
      "380/380 [==============================] - 0s 151us/step - loss: 0.1369 - accuracy: 0.9737 - val_loss: 0.5901 - val_accuracy: 0.8650\n",
      "Epoch 80/100\n",
      "380/380 [==============================] - 0s 140us/step - loss: 0.1484 - accuracy: 0.9711 - val_loss: 0.5380 - val_accuracy: 0.8466\n",
      "Epoch 81/100\n",
      "380/380 [==============================] - 0s 133us/step - loss: 0.1561 - accuracy: 0.9605 - val_loss: 0.5497 - val_accuracy: 0.8773\n",
      "Epoch 82/100\n",
      "380/380 [==============================] - 0s 154us/step - loss: 0.2284 - accuracy: 0.9684 - val_loss: 0.5160 - val_accuracy: 0.8773\n",
      "Epoch 83/100\n",
      "380/380 [==============================] - 0s 140us/step - loss: 0.1037 - accuracy: 0.9711 - val_loss: 0.6166 - val_accuracy: 0.8712\n",
      "Epoch 84/100\n",
      "380/380 [==============================] - 0s 142us/step - loss: 0.1492 - accuracy: 0.9684 - val_loss: 0.3532 - val_accuracy: 0.8957\n",
      "Epoch 85/100\n",
      "380/380 [==============================] - 0s 148us/step - loss: 0.0785 - accuracy: 0.9789 - val_loss: 0.5247 - val_accuracy: 0.8589\n",
      "Epoch 86/100\n",
      "380/380 [==============================] - 0s 135us/step - loss: 0.0804 - accuracy: 0.9816 - val_loss: 0.4567 - val_accuracy: 0.8773\n",
      "Epoch 87/100\n",
      "380/380 [==============================] - 0s 136us/step - loss: 0.0655 - accuracy: 0.9842 - val_loss: 0.5258 - val_accuracy: 0.8773\n",
      "Epoch 88/100\n",
      "380/380 [==============================] - 0s 110us/step - loss: 0.0795 - accuracy: 0.9789 - val_loss: 0.7280 - val_accuracy: 0.8282\n",
      "Epoch 89/100\n",
      "380/380 [==============================] - 0s 113us/step - loss: 0.1585 - accuracy: 0.9526 - val_loss: 0.5844 - val_accuracy: 0.8650\n",
      "Epoch 90/100\n",
      "380/380 [==============================] - 0s 261us/step - loss: 0.0823 - accuracy: 0.9711 - val_loss: 0.6396 - val_accuracy: 0.8282\n",
      "Epoch 91/100\n",
      "380/380 [==============================] - 0s 168us/step - loss: 0.0884 - accuracy: 0.9816 - val_loss: 0.5961 - val_accuracy: 0.8589\n",
      "Epoch 92/100\n",
      "380/380 [==============================] - 0s 152us/step - loss: 0.0736 - accuracy: 0.9842 - val_loss: 0.4188 - val_accuracy: 0.8896\n",
      "Epoch 93/100\n",
      "380/380 [==============================] - 0s 205us/step - loss: 0.0716 - accuracy: 0.9842 - val_loss: 0.6336 - val_accuracy: 0.8282\n",
      "Epoch 94/100\n",
      "380/380 [==============================] - 0s 165us/step - loss: 0.0798 - accuracy: 0.9816 - val_loss: 0.6403 - val_accuracy: 0.8405\n",
      "Epoch 95/100\n",
      "380/380 [==============================] - 0s 170us/step - loss: 0.0803 - accuracy: 0.9816 - val_loss: 0.5273 - val_accuracy: 0.8650\n",
      "Epoch 96/100\n",
      "380/380 [==============================] - 0s 170us/step - loss: 0.0710 - accuracy: 0.9763 - val_loss: 0.4457 - val_accuracy: 0.8773\n",
      "Epoch 97/100\n",
      "380/380 [==============================] - 0s 235us/step - loss: 0.0594 - accuracy: 0.9868 - val_loss: 0.5278 - val_accuracy: 0.8650\n",
      "Epoch 98/100\n",
      "380/380 [==============================] - 0s 178us/step - loss: 0.0615 - accuracy: 0.9842 - val_loss: 0.4607 - val_accuracy: 0.8957\n",
      "Epoch 99/100\n",
      "380/380 [==============================] - 0s 166us/step - loss: 0.0632 - accuracy: 0.9816 - val_loss: 0.5208 - val_accuracy: 0.8712\n",
      "Epoch 100/100\n",
      "380/380 [==============================] - 0s 159us/step - loss: 0.0926 - accuracy: 0.9632 - val_loss: 0.5178 - val_accuracy: 0.8712\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a416ee5c0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over3.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163/163 [==============================] - 0s 133us/step\n",
      "over-sampling test accuracy: 90.80%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over3 = model1_over3.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over3*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 0, 2, 0, 0, 2, 0, 1, 2, 1, 2, 0, 1, 1, 0, 0, 2, 1, 2,\n",
       "       0, 2, 2, 1, 2, 1, 0, 0, 1, 1, 1, 0, 2, 1, 2, 2, 1, 2, 0, 1, 1, 1,\n",
       "       1, 0, 2, 1, 0, 0, 2, 0, 0, 0, 1, 1, 2, 1, 2, 1, 2, 1, 0, 1, 1, 0,\n",
       "       0, 2, 0, 2, 0, 1, 2, 0, 0, 1, 0, 2, 0, 0, 1, 1, 2, 2, 2, 0, 0, 1,\n",
       "       2, 0, 0, 0, 0, 0, 1, 2, 1, 1, 0, 1, 2, 0, 1, 1, 1, 0, 2, 1, 1, 1,\n",
       "       0, 1, 0, 0, 2, 2, 1, 1, 1, 2, 2, 2, 0, 2, 1, 1, 2, 1, 1, 1, 1, 0,\n",
       "       1, 1, 0, 2, 0, 0, 0, 2, 1, 0, 1, 0, 1, 1, 0, 0, 0, 2, 0, 2, 1, 0,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 1])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred3 = model1_over3.predict_classes(X_test_over)\n",
    "pred3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS149</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EUH13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS106</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS214</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CFBREBSa129</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>NRS027</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>CFBRSa70</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>CFBREBSa130</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>NRS214</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>NRS073</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test  pred\n",
       "0         NRS149     0     0\n",
       "1          EUH13     0     0\n",
       "2         NRS106     2     0\n",
       "3         NRS214     1     1\n",
       "4    CFBREBSa129     0     0\n",
       "..           ...   ...   ...\n",
       "158       NRS027     0     0\n",
       "159     CFBRSa70     2     1\n",
       "160  CFBREBSa130     0     0\n",
       "161       NRS214     1     1\n",
       "162       NRS073     1     1\n",
       "\n",
       "[163 rows x 3 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat3['pred'] = pred3\n",
    "dat3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba3 = model1_over3.predict_proba(X_test_over)\n",
    "dat_proba3 = pd.DataFrame(proba3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.995607</td>\n",
       "      <td>0.004015</td>\n",
       "      <td>3.779488e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.997946</td>\n",
       "      <td>0.002054</td>\n",
       "      <td>2.988466e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.988839</td>\n",
       "      <td>0.009925</td>\n",
       "      <td>1.236040e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002792</td>\n",
       "      <td>0.993562</td>\n",
       "      <td>3.645902e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.999961</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>4.804003e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>0.999872</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>2.939901e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>0.254730</td>\n",
       "      <td>0.739795</td>\n",
       "      <td>5.474732e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>0.999541</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>2.159090e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>0.002792</td>\n",
       "      <td>0.993562</td>\n",
       "      <td>3.645902e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.999043</td>\n",
       "      <td>9.563074e-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1             2\n",
       "0    0.995607  0.004015  3.779488e-04\n",
       "1    0.997946  0.002054  2.988466e-09\n",
       "2    0.988839  0.009925  1.236040e-03\n",
       "3    0.002792  0.993562  3.645902e-03\n",
       "4    0.999961  0.000039  4.804003e-07\n",
       "..        ...       ...           ...\n",
       "158  0.999872  0.000099  2.939901e-05\n",
       "159  0.254730  0.739795  5.474732e-03\n",
       "160  0.999541  0.000243  2.159090e-04\n",
       "161  0.002792  0.993562  3.645902e-03\n",
       "162  0.000001  0.999043  9.563074e-04\n",
       "\n",
       "[163 rows x 3 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba3.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba3.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat3.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/3p11pST.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 380 samples, validate on 163 samples\n",
      "Epoch 1/100\n",
      "380/380 [==============================] - 0s 185us/step - loss: 0.0804 - accuracy: 0.9684 - val_loss: 0.3838 - val_accuracy: 0.8957\n",
      "Epoch 2/100\n",
      "380/380 [==============================] - 0s 146us/step - loss: 0.1294 - accuracy: 0.9526 - val_loss: 0.5415 - val_accuracy: 0.8650\n",
      "Epoch 3/100\n",
      "380/380 [==============================] - 0s 143us/step - loss: 0.1452 - accuracy: 0.9447 - val_loss: 0.4494 - val_accuracy: 0.8650\n",
      "Epoch 4/100\n",
      "380/380 [==============================] - 0s 119us/step - loss: 0.1224 - accuracy: 0.9658 - val_loss: 0.5133 - val_accuracy: 0.8712\n",
      "Epoch 5/100\n",
      "380/380 [==============================] - 0s 133us/step - loss: 0.0841 - accuracy: 0.9789 - val_loss: 0.6128 - val_accuracy: 0.8221\n",
      "Epoch 6/100\n",
      "380/380 [==============================] - 0s 122us/step - loss: 0.0704 - accuracy: 0.9763 - val_loss: 0.5470 - val_accuracy: 0.8712\n",
      "Epoch 7/100\n",
      "380/380 [==============================] - 0s 132us/step - loss: 0.0643 - accuracy: 0.9816 - val_loss: 0.4030 - val_accuracy: 0.8957\n",
      "Epoch 8/100\n",
      "380/380 [==============================] - 0s 137us/step - loss: 0.0634 - accuracy: 0.9737 - val_loss: 0.4097 - val_accuracy: 0.8834\n",
      "Epoch 9/100\n",
      "380/380 [==============================] - 0s 171us/step - loss: 0.0571 - accuracy: 0.9763 - val_loss: 0.5460 - val_accuracy: 0.8589\n",
      "Epoch 10/100\n",
      "380/380 [==============================] - 0s 179us/step - loss: 0.0644 - accuracy: 0.9737 - val_loss: 0.4200 - val_accuracy: 0.8650\n",
      "Epoch 11/100\n",
      "380/380 [==============================] - 0s 253us/step - loss: 0.0969 - accuracy: 0.9763 - val_loss: 0.3977 - val_accuracy: 0.8957\n",
      "Epoch 12/100\n",
      "380/380 [==============================] - 0s 220us/step - loss: 0.1257 - accuracy: 0.9737 - val_loss: 0.4260 - val_accuracy: 0.9018\n",
      "Epoch 13/100\n",
      "380/380 [==============================] - 0s 172us/step - loss: 0.0633 - accuracy: 0.9737 - val_loss: 0.4680 - val_accuracy: 0.8712\n",
      "Epoch 14/100\n",
      "380/380 [==============================] - 0s 160us/step - loss: 0.0740 - accuracy: 0.9816 - val_loss: 0.3698 - val_accuracy: 0.8957\n",
      "Epoch 15/100\n",
      "380/380 [==============================] - 0s 179us/step - loss: 0.1023 - accuracy: 0.9763 - val_loss: 0.5318 - val_accuracy: 0.8528\n",
      "Epoch 16/100\n",
      "380/380 [==============================] - 0s 182us/step - loss: 0.0745 - accuracy: 0.9816 - val_loss: 0.6026 - val_accuracy: 0.8466\n",
      "Epoch 17/100\n",
      "380/380 [==============================] - 0s 165us/step - loss: 0.1212 - accuracy: 0.9737 - val_loss: 0.6531 - val_accuracy: 0.8466\n",
      "Epoch 18/100\n",
      "380/380 [==============================] - 0s 167us/step - loss: 0.0981 - accuracy: 0.9658 - val_loss: 0.5612 - val_accuracy: 0.8589\n",
      "Epoch 19/100\n",
      "380/380 [==============================] - 0s 257us/step - loss: 0.1225 - accuracy: 0.9632 - val_loss: 0.8801 - val_accuracy: 0.7853\n",
      "Epoch 20/100\n",
      "380/380 [==============================] - 0s 282us/step - loss: 0.1250 - accuracy: 0.9684 - val_loss: 0.5006 - val_accuracy: 0.8712\n",
      "Epoch 21/100\n",
      "380/380 [==============================] - 0s 323us/step - loss: 0.1614 - accuracy: 0.9763 - val_loss: 0.5634 - val_accuracy: 0.8589\n",
      "Epoch 22/100\n",
      "380/380 [==============================] - 0s 311us/step - loss: 0.0941 - accuracy: 0.9842 - val_loss: 0.4819 - val_accuracy: 0.8712\n",
      "Epoch 23/100\n",
      "380/380 [==============================] - 0s 301us/step - loss: 0.0575 - accuracy: 0.9816 - val_loss: 0.4142 - val_accuracy: 0.8834\n",
      "Epoch 24/100\n",
      "380/380 [==============================] - 0s 526us/step - loss: 0.1450 - accuracy: 0.9737 - val_loss: 0.4535 - val_accuracy: 0.8957\n",
      "Epoch 25/100\n",
      "380/380 [==============================] - 0s 303us/step - loss: 0.0830 - accuracy: 0.9737 - val_loss: 0.4383 - val_accuracy: 0.9018\n",
      "Epoch 26/100\n",
      "380/380 [==============================] - 0s 251us/step - loss: 0.0770 - accuracy: 0.9737 - val_loss: 0.3921 - val_accuracy: 0.9080\n",
      "Epoch 27/100\n",
      "380/380 [==============================] - 0s 228us/step - loss: 0.0517 - accuracy: 0.9789 - val_loss: 0.6217 - val_accuracy: 0.8528\n",
      "Epoch 28/100\n",
      "380/380 [==============================] - 0s 294us/step - loss: 0.0534 - accuracy: 0.9816 - val_loss: 0.4411 - val_accuracy: 0.8773\n",
      "Epoch 29/100\n",
      "380/380 [==============================] - 0s 147us/step - loss: 0.0493 - accuracy: 0.9789 - val_loss: 0.4646 - val_accuracy: 0.8773\n",
      "Epoch 30/100\n",
      "380/380 [==============================] - 0s 279us/step - loss: 0.0496 - accuracy: 0.9895 - val_loss: 0.4606 - val_accuracy: 0.8834\n",
      "Epoch 31/100\n",
      "380/380 [==============================] - 0s 371us/step - loss: 0.0515 - accuracy: 0.9842 - val_loss: 0.4216 - val_accuracy: 0.8834\n",
      "Epoch 32/100\n",
      "380/380 [==============================] - 0s 230us/step - loss: 0.0920 - accuracy: 0.9789 - val_loss: 0.5361 - val_accuracy: 0.8650\n",
      "Epoch 33/100\n",
      "380/380 [==============================] - 0s 179us/step - loss: 0.0521 - accuracy: 0.9842 - val_loss: 0.5093 - val_accuracy: 0.8712\n",
      "Epoch 34/100\n",
      "380/380 [==============================] - 0s 170us/step - loss: 0.0840 - accuracy: 0.9816 - val_loss: 0.4829 - val_accuracy: 0.8773\n",
      "Epoch 35/100\n",
      "380/380 [==============================] - 0s 173us/step - loss: 0.0557 - accuracy: 0.9816 - val_loss: 0.4096 - val_accuracy: 0.9080\n",
      "Epoch 36/100\n",
      "380/380 [==============================] - 0s 186us/step - loss: 0.0780 - accuracy: 0.9816 - val_loss: 0.5693 - val_accuracy: 0.8650\n",
      "Epoch 37/100\n",
      "380/380 [==============================] - 0s 152us/step - loss: 0.0775 - accuracy: 0.9737 - val_loss: 0.3985 - val_accuracy: 0.9018\n",
      "Epoch 38/100\n",
      "380/380 [==============================] - 0s 139us/step - loss: 0.0835 - accuracy: 0.9842 - val_loss: 0.4752 - val_accuracy: 0.9080\n",
      "Epoch 39/100\n",
      "380/380 [==============================] - 0s 125us/step - loss: 0.0500 - accuracy: 0.9895 - val_loss: 0.8163 - val_accuracy: 0.8405\n",
      "Epoch 40/100\n",
      "380/380 [==============================] - 0s 126us/step - loss: 0.0802 - accuracy: 0.9789 - val_loss: 0.6285 - val_accuracy: 0.8650\n",
      "Epoch 41/100\n",
      "380/380 [==============================] - 0s 137us/step - loss: 0.0598 - accuracy: 0.9816 - val_loss: 0.4354 - val_accuracy: 0.8896\n",
      "Epoch 42/100\n",
      "380/380 [==============================] - 0s 157us/step - loss: 0.0561 - accuracy: 0.9816 - val_loss: 0.5363 - val_accuracy: 0.8589\n",
      "Epoch 43/100\n",
      "380/380 [==============================] - 0s 279us/step - loss: 0.0821 - accuracy: 0.9711 - val_loss: 0.4327 - val_accuracy: 0.8834\n",
      "Epoch 44/100\n",
      "380/380 [==============================] - 0s 267us/step - loss: 0.0719 - accuracy: 0.9816 - val_loss: 0.4994 - val_accuracy: 0.8773\n",
      "Epoch 45/100\n",
      "380/380 [==============================] - 0s 706us/step - loss: 0.0629 - accuracy: 0.9789 - val_loss: 0.4770 - val_accuracy: 0.8773\n",
      "Epoch 46/100\n",
      "380/380 [==============================] - 0s 264us/step - loss: 0.0654 - accuracy: 0.9842 - val_loss: 0.4901 - val_accuracy: 0.8896\n",
      "Epoch 47/100\n",
      "380/380 [==============================] - 0s 242us/step - loss: 0.0724 - accuracy: 0.9868 - val_loss: 0.4977 - val_accuracy: 0.8834\n",
      "Epoch 48/100\n",
      "380/380 [==============================] - 0s 277us/step - loss: 0.0724 - accuracy: 0.9763 - val_loss: 0.5251 - val_accuracy: 0.8773\n",
      "Epoch 49/100\n",
      "380/380 [==============================] - 0s 186us/step - loss: 0.0631 - accuracy: 0.9763 - val_loss: 0.4498 - val_accuracy: 0.8957\n",
      "Epoch 50/100\n",
      "380/380 [==============================] - 0s 177us/step - loss: 0.0909 - accuracy: 0.9789 - val_loss: 0.4774 - val_accuracy: 0.8834\n",
      "Epoch 51/100\n",
      "380/380 [==============================] - 0s 196us/step - loss: 0.0540 - accuracy: 0.9895 - val_loss: 0.4969 - val_accuracy: 0.8834\n",
      "Epoch 52/100\n",
      "380/380 [==============================] - 0s 183us/step - loss: 0.0950 - accuracy: 0.9816 - val_loss: 0.5831 - val_accuracy: 0.8712\n",
      "Epoch 53/100\n",
      "380/380 [==============================] - 0s 277us/step - loss: 0.0983 - accuracy: 0.9711 - val_loss: 0.5935 - val_accuracy: 0.8466\n",
      "Epoch 54/100\n",
      "380/380 [==============================] - 0s 242us/step - loss: 0.0963 - accuracy: 0.9737 - val_loss: 0.4714 - val_accuracy: 0.9018\n",
      "Epoch 55/100\n",
      "380/380 [==============================] - 0s 163us/step - loss: 0.0585 - accuracy: 0.9816 - val_loss: 0.6045 - val_accuracy: 0.8712\n",
      "Epoch 56/100\n",
      "380/380 [==============================] - 0s 166us/step - loss: 0.0741 - accuracy: 0.9895 - val_loss: 0.5014 - val_accuracy: 0.8834\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "380/380 [==============================] - 0s 278us/step - loss: 0.0404 - accuracy: 0.9895 - val_loss: 0.4190 - val_accuracy: 0.8896\n",
      "Epoch 58/100\n",
      "380/380 [==============================] - 0s 288us/step - loss: 0.0413 - accuracy: 0.9868 - val_loss: 0.5719 - val_accuracy: 0.8773\n",
      "Epoch 59/100\n",
      "380/380 [==============================] - 0s 202us/step - loss: 0.0403 - accuracy: 0.9895 - val_loss: 0.6281 - val_accuracy: 0.8712\n",
      "Epoch 60/100\n",
      "380/380 [==============================] - 0s 199us/step - loss: 0.0734 - accuracy: 0.9711 - val_loss: 0.4930 - val_accuracy: 0.8834\n",
      "Epoch 61/100\n",
      "380/380 [==============================] - 0s 156us/step - loss: 0.0505 - accuracy: 0.9842 - val_loss: 0.4648 - val_accuracy: 0.8957\n",
      "Epoch 62/100\n",
      "380/380 [==============================] - 0s 230us/step - loss: 0.0511 - accuracy: 0.9842 - val_loss: 0.4731 - val_accuracy: 0.8957\n",
      "Epoch 63/100\n",
      "380/380 [==============================] - 0s 261us/step - loss: 0.0552 - accuracy: 0.9868 - val_loss: 0.5033 - val_accuracy: 0.8773\n",
      "Epoch 64/100\n",
      "380/380 [==============================] - 0s 173us/step - loss: 0.0404 - accuracy: 0.9895 - val_loss: 0.4214 - val_accuracy: 0.8896\n",
      "Epoch 65/100\n",
      "380/380 [==============================] - 0s 203us/step - loss: 0.0402 - accuracy: 0.9895 - val_loss: 0.4646 - val_accuracy: 0.8896\n",
      "Epoch 66/100\n",
      "380/380 [==============================] - 0s 168us/step - loss: 0.0640 - accuracy: 0.9842 - val_loss: 0.5498 - val_accuracy: 0.8773\n",
      "Epoch 67/100\n",
      "380/380 [==============================] - 0s 200us/step - loss: 0.0474 - accuracy: 0.9842 - val_loss: 0.5582 - val_accuracy: 0.8773\n",
      "Epoch 68/100\n",
      "380/380 [==============================] - 0s 187us/step - loss: 0.0630 - accuracy: 0.9737 - val_loss: 0.4869 - val_accuracy: 0.8834\n",
      "Epoch 69/100\n",
      "380/380 [==============================] - 0s 172us/step - loss: 0.0425 - accuracy: 0.9868 - val_loss: 0.4439 - val_accuracy: 0.9018\n",
      "Epoch 70/100\n",
      "380/380 [==============================] - 0s 158us/step - loss: 0.0736 - accuracy: 0.9816 - val_loss: 0.4794 - val_accuracy: 0.8834\n",
      "Epoch 71/100\n",
      "380/380 [==============================] - 0s 270us/step - loss: 0.0627 - accuracy: 0.9842 - val_loss: 0.5664 - val_accuracy: 0.8773\n",
      "Epoch 72/100\n",
      "380/380 [==============================] - 0s 175us/step - loss: 0.0547 - accuracy: 0.9816 - val_loss: 0.4884 - val_accuracy: 0.8834\n",
      "Epoch 73/100\n",
      "380/380 [==============================] - 0s 162us/step - loss: 0.0434 - accuracy: 0.9895 - val_loss: 0.6444 - val_accuracy: 0.8712\n",
      "Epoch 74/100\n",
      "380/380 [==============================] - 0s 160us/step - loss: 0.0608 - accuracy: 0.9789 - val_loss: 0.6123 - val_accuracy: 0.8712\n",
      "Epoch 75/100\n",
      "380/380 [==============================] - 0s 164us/step - loss: 0.0649 - accuracy: 0.9789 - val_loss: 0.4899 - val_accuracy: 0.8896\n",
      "Epoch 76/100\n",
      "380/380 [==============================] - 0s 161us/step - loss: 0.1202 - accuracy: 0.9789 - val_loss: 0.5751 - val_accuracy: 0.8712\n",
      "Epoch 77/100\n",
      "380/380 [==============================] - 0s 162us/step - loss: 0.0968 - accuracy: 0.9763 - val_loss: 0.7385 - val_accuracy: 0.8344\n",
      "Epoch 78/100\n",
      "380/380 [==============================] - 0s 179us/step - loss: 0.0921 - accuracy: 0.9816 - val_loss: 0.5439 - val_accuracy: 0.8773\n",
      "Epoch 79/100\n",
      "380/380 [==============================] - 0s 190us/step - loss: 0.1205 - accuracy: 0.9658 - val_loss: 0.5511 - val_accuracy: 0.8773\n",
      "Epoch 80/100\n",
      "380/380 [==============================] - 0s 177us/step - loss: 0.1472 - accuracy: 0.9763 - val_loss: 0.5716 - val_accuracy: 0.8773\n",
      "Epoch 81/100\n",
      "380/380 [==============================] - 0s 169us/step - loss: 0.0587 - accuracy: 0.9816 - val_loss: 0.6827 - val_accuracy: 0.8712\n",
      "Epoch 82/100\n",
      "380/380 [==============================] - 0s 186us/step - loss: 0.0488 - accuracy: 0.9868 - val_loss: 0.7260 - val_accuracy: 0.8773\n",
      "Epoch 83/100\n",
      "380/380 [==============================] - 0s 202us/step - loss: 0.0693 - accuracy: 0.9763 - val_loss: 0.6384 - val_accuracy: 0.8773\n",
      "Epoch 84/100\n",
      "380/380 [==============================] - 0s 186us/step - loss: 0.0473 - accuracy: 0.9789 - val_loss: 0.5465 - val_accuracy: 0.8773\n",
      "Epoch 85/100\n",
      "380/380 [==============================] - 0s 166us/step - loss: 0.0520 - accuracy: 0.9842 - val_loss: 0.6045 - val_accuracy: 0.8650\n",
      "Epoch 86/100\n",
      "380/380 [==============================] - 0s 169us/step - loss: 0.1053 - accuracy: 0.9711 - val_loss: 0.6226 - val_accuracy: 0.8896\n",
      "Epoch 87/100\n",
      "380/380 [==============================] - 0s 173us/step - loss: 0.3229 - accuracy: 0.9658 - val_loss: 0.7382 - val_accuracy: 0.8589\n",
      "Epoch 88/100\n",
      "380/380 [==============================] - 0s 231us/step - loss: 0.1731 - accuracy: 0.9632 - val_loss: 0.5949 - val_accuracy: 0.8834\n",
      "Epoch 89/100\n",
      "380/380 [==============================] - 0s 187us/step - loss: 0.0759 - accuracy: 0.9816 - val_loss: 0.6316 - val_accuracy: 0.8589\n",
      "Epoch 90/100\n",
      "380/380 [==============================] - 0s 271us/step - loss: 0.0618 - accuracy: 0.9842 - val_loss: 0.4795 - val_accuracy: 0.8834\n",
      "Epoch 91/100\n",
      "380/380 [==============================] - 0s 181us/step - loss: 0.0845 - accuracy: 0.9789 - val_loss: 0.5197 - val_accuracy: 0.9018\n",
      "Epoch 92/100\n",
      "380/380 [==============================] - 0s 176us/step - loss: 0.0639 - accuracy: 0.9789 - val_loss: 0.5059 - val_accuracy: 0.8957\n",
      "Epoch 93/100\n",
      "380/380 [==============================] - 0s 157us/step - loss: 0.0892 - accuracy: 0.9842 - val_loss: 0.4603 - val_accuracy: 0.8834\n",
      "Epoch 94/100\n",
      "380/380 [==============================] - 0s 159us/step - loss: 0.0980 - accuracy: 0.9632 - val_loss: 0.5150 - val_accuracy: 0.8957\n",
      "Epoch 95/100\n",
      "380/380 [==============================] - 0s 145us/step - loss: 0.0710 - accuracy: 0.9789 - val_loss: 0.4291 - val_accuracy: 0.9202\n",
      "Epoch 96/100\n",
      "380/380 [==============================] - 0s 158us/step - loss: 0.0406 - accuracy: 0.9921 - val_loss: 0.5709 - val_accuracy: 0.8834\n",
      "Epoch 97/100\n",
      "380/380 [==============================] - 0s 149us/step - loss: 0.0348 - accuracy: 0.9921 - val_loss: 0.4572 - val_accuracy: 0.8834\n",
      "Epoch 98/100\n",
      "380/380 [==============================] - 0s 156us/step - loss: 0.0325 - accuracy: 0.9868 - val_loss: 0.5817 - val_accuracy: 0.8773\n",
      "Epoch 99/100\n",
      "380/380 [==============================] - 0s 152us/step - loss: 0.0402 - accuracy: 0.9816 - val_loss: 0.4940 - val_accuracy: 0.8896\n",
      "Epoch 100/100\n",
      "380/380 [==============================] - 0s 168us/step - loss: 0.0383 - accuracy: 0.9868 - val_loss: 0.4954 - val_accuracy: 0.9018\n"
     ]
    }
   ],
   "source": [
    "hist1_over3 = model1_over3.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 97.89%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over3.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba3 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_2.xlsx\",\n",
    "                        sheet_name=2,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>0.013518</td>\n",
       "      <td>9.820048e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>0.013518</td>\n",
       "      <td>9.820048e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS222</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.851725</td>\n",
       "      <td>0.148269</td>\n",
       "      <td>5.980786e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>0.013518</td>\n",
       "      <td>9.820048e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>GA50245</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.812055</td>\n",
       "      <td>0.187945</td>\n",
       "      <td>1.161034e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4279</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>0.000928</td>\n",
       "      <td>9.984396e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4280</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>0.000928</td>\n",
       "      <td>9.984396e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4281</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS266</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.025932</td>\n",
       "      <td>0.974061</td>\n",
       "      <td>7.323514e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4282</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000597</td>\n",
       "      <td>0.999403</td>\n",
       "      <td>3.675362e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4283</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS112</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>0.999452</td>\n",
       "      <td>1.168620e-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4284 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    phage   strain  phenotype  prediction         0         1  \\\n",
       "0      p002ykpresabs_qual   NRS109          2           2  0.004477  0.013518   \n",
       "1      p002ykpresabs_qual   NRS109          2           2  0.004477  0.013518   \n",
       "2      p002ykpresabs_qual   NRS222          0           0  0.851725  0.148269   \n",
       "3      p002ykpresabs_qual   NRS109          2           2  0.004477  0.013518   \n",
       "4      p002ykpresabs_qual  GA50245          0           0  0.812055  0.187945   \n",
       "...                   ...      ...        ...         ...       ...       ...   \n",
       "4279  pyopresabsSTCC_qual   NRS255          2           2  0.000633  0.000928   \n",
       "4280  pyopresabsSTCC_qual   NRS255          2           2  0.000633  0.000928   \n",
       "4281  pyopresabsSTCC_qual   NRS266          1           1  0.025932  0.974061   \n",
       "4282  pyopresabsSTCC_qual   NRS001          1           1  0.000597  0.999403   \n",
       "4283  pyopresabsSTCC_qual   NRS112          1           1  0.000537  0.999452   \n",
       "\n",
       "                 2  \n",
       "0     9.820048e-01  \n",
       "1     9.820048e-01  \n",
       "2     5.980786e-06  \n",
       "3     9.820048e-01  \n",
       "4     1.161034e-07  \n",
       "...            ...  \n",
       "4279  9.984396e-01  \n",
       "4280  9.984396e-01  \n",
       "4281  7.323514e-06  \n",
       "4282  3.675362e-10  \n",
       "4283  1.168620e-05  \n",
       "\n",
       "[4284 rows x 7 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.95606960e-01, 4.01509600e-03, 3.77948830e-04],\n",
       "       [9.97945960e-01, 2.05399350e-03, 2.98846570e-09],\n",
       "       [9.88838800e-01, 9.92516800e-03, 1.23604010e-03],\n",
       "       [2.79162400e-03, 9.93562460e-01, 3.64590180e-03],\n",
       "       [9.99960800e-01, 3.87630130e-05, 4.80400330e-07],\n",
       "       [1.01636810e-04, 1.35213510e-01, 8.64684900e-01],\n",
       "       [9.99871850e-01, 9.87020100e-05, 2.93990070e-05],\n",
       "       [9.37966640e-01, 5.81597600e-02, 3.87363860e-03],\n",
       "       [4.70202200e-03, 6.74733500e-02, 9.27824600e-01],\n",
       "       [9.93875440e-01, 6.11242370e-03, 1.20862480e-05],\n",
       "       [1.65065940e-02, 9.78892200e-01, 4.60123220e-03],\n",
       "       [1.06632440e-08, 3.11665170e-05, 9.99968770e-01],\n",
       "       [3.08829390e-06, 9.98231700e-01, 1.76521110e-03],\n",
       "       [1.16661930e-11, 7.00288800e-09, 1.00000000e+00],\n",
       "       [9.99004540e-01, 9.93439900e-04, 1.97578130e-06],\n",
       "       [1.80316440e-03, 9.89571800e-01, 8.62508100e-03],\n",
       "       [8.32595500e-03, 9.26772400e-01, 6.49015750e-02],\n",
       "       [9.37966640e-01, 5.81597600e-02, 3.87363860e-03],\n",
       "       [9.97267000e-01, 2.55142970e-03, 1.81509910e-04],\n",
       "       [8.31564200e-03, 3.79400040e-01, 6.12284360e-01],\n",
       "       [1.18618630e-04, 8.39285140e-01, 1.60596220e-01],\n",
       "       [4.15511500e-09, 3.44743600e-07, 9.99999640e-01],\n",
       "       [9.99540700e-01, 2.43465940e-04, 2.15908990e-04],\n",
       "       [4.65302300e-15, 4.34729460e-07, 9.99999500e-01],\n",
       "       [7.94641200e-05, 8.38195760e-02, 9.16100900e-01],\n",
       "       [2.64610860e-03, 9.97351900e-01, 2.06488220e-06],\n",
       "       [1.69264840e-06, 1.27264850e-02, 9.87271850e-01],\n",
       "       [5.30891750e-02, 9.46904900e-01, 5.82038200e-06],\n",
       "       [9.99962900e-01, 3.70541000e-05, 3.27636000e-10],\n",
       "       [9.99871850e-01, 9.87020100e-05, 2.93990070e-05],\n",
       "       [4.23548570e-04, 9.96730900e-01, 2.84552390e-03],\n",
       "       [4.14912940e-05, 9.96965100e-01, 2.99341770e-03],\n",
       "       [3.47206170e-04, 9.98688760e-01, 9.64101640e-04],\n",
       "       [8.74959350e-01, 1.24986650e-01, 5.40419020e-05],\n",
       "       [5.94415550e-07, 1.60747950e-05, 9.99983300e-01],\n",
       "       [5.37669840e-03, 9.91841900e-01, 2.78145700e-03],\n",
       "       [9.72865560e-04, 1.79671440e-01, 8.19355700e-01],\n",
       "       [7.00241950e-09, 6.00795700e-08, 9.99999900e-01],\n",
       "       [4.23548570e-04, 9.96730900e-01, 2.84552390e-03],\n",
       "       [7.97470800e-07, 2.88901120e-05, 9.99970300e-01],\n",
       "       [9.99871850e-01, 9.87020100e-05, 2.93990070e-05],\n",
       "       [5.99432040e-06, 9.99567200e-01, 4.26843880e-04],\n",
       "       [4.14912940e-05, 9.96965100e-01, 2.99341770e-03],\n",
       "       [1.10725220e-06, 9.99042600e-01, 9.56307400e-04],\n",
       "       [1.57445610e-03, 9.54790700e-01, 4.36347650e-02],\n",
       "       [9.99506350e-01, 4.87439450e-04, 6.21013940e-06],\n",
       "       [1.30226300e-04, 2.67745720e-02, 9.73095200e-01],\n",
       "       [2.08481450e-05, 9.47270800e-01, 5.27082530e-02],\n",
       "       [9.99518160e-01, 4.40856880e-04, 4.10369200e-05],\n",
       "       [4.56814500e-01, 3.29512860e-01, 2.13672620e-01],\n",
       "       [5.63570400e-05, 1.35868850e-02, 9.86356740e-01],\n",
       "       [9.98679940e-01, 1.14337880e-03, 1.76677440e-04],\n",
       "       [9.99962900e-01, 3.70541000e-05, 3.27636000e-10],\n",
       "       [9.99962900e-01, 3.70541000e-05, 3.27636000e-10],\n",
       "       [2.06754760e-04, 9.05579570e-01, 9.42137240e-02],\n",
       "       [1.59247920e-01, 7.30146650e-01, 1.10605486e-01],\n",
       "       [5.02465880e-11, 1.46876190e-06, 9.99998570e-01],\n",
       "       [5.29944900e-03, 9.54516050e-01, 4.01845160e-02],\n",
       "       [4.60302000e-05, 1.55299280e-02, 9.84424050e-01],\n",
       "       [5.37669840e-03, 9.91841900e-01, 2.78145700e-03],\n",
       "       [7.72173900e-09, 3.25506400e-07, 9.99999640e-01],\n",
       "       [2.27289500e-02, 9.74002900e-01, 3.26815600e-03],\n",
       "       [9.67172500e-01, 3.24191200e-02, 4.08410900e-04],\n",
       "       [1.27802990e-03, 9.98669000e-01, 5.29802640e-05],\n",
       "       [4.14912940e-05, 9.96965100e-01, 2.99341770e-03],\n",
       "       [9.99817550e-01, 1.72770250e-04, 9.62595400e-06],\n",
       "       [9.99817550e-01, 1.72770250e-04, 9.62595400e-06],\n",
       "       [2.94289250e-02, 2.14641800e-01, 7.55929300e-01],\n",
       "       [9.98679940e-01, 1.14337880e-03, 1.76677440e-04],\n",
       "       [2.77293730e-11, 1.86383460e-09, 1.00000000e+00],\n",
       "       [9.97471000e-01, 2.49854780e-03, 3.06113870e-05],\n",
       "       [1.59247920e-01, 7.30146650e-01, 1.10605486e-01],\n",
       "       [2.19700270e-06, 4.08890060e-02, 9.59108770e-01],\n",
       "       [9.99817550e-01, 1.72770250e-04, 9.62595400e-06],\n",
       "       [9.99387740e-01, 5.43776260e-04, 6.84742100e-05],\n",
       "       [5.40859730e-05, 9.99941100e-01, 4.74559870e-06],\n",
       "       [9.99732300e-01, 2.65278970e-04, 2.38489040e-06],\n",
       "       [1.18458370e-09, 2.47400280e-04, 9.99752600e-01],\n",
       "       [9.97267000e-01, 2.55142970e-03, 1.81509910e-04],\n",
       "       [9.98679940e-01, 1.14337880e-03, 1.76677440e-04],\n",
       "       [1.83282550e-02, 9.79911860e-01, 1.75988590e-03],\n",
       "       [4.11883000e-03, 8.27531800e-01, 1.68349340e-01],\n",
       "       [1.84174680e-14, 5.43885430e-09, 1.00000000e+00],\n",
       "       [2.15777240e-13, 3.67424420e-08, 1.00000000e+00],\n",
       "       [9.89009600e-05, 1.90137230e-02, 9.80887400e-01],\n",
       "       [9.93875440e-01, 6.11242370e-03, 1.20862480e-05],\n",
       "       [9.93875440e-01, 6.11242370e-03, 1.20862480e-05],\n",
       "       [1.29888890e-02, 9.83026560e-01, 3.98457940e-03],\n",
       "       [2.78527920e-17, 5.42354050e-10, 1.00000000e+00],\n",
       "       [9.99387740e-01, 5.43776260e-04, 6.84742100e-05],\n",
       "       [9.67172500e-01, 3.24191200e-02, 4.08410900e-04],\n",
       "       [9.95606960e-01, 4.01509600e-03, 3.77948830e-04],\n",
       "       [9.99149800e-01, 3.38277260e-04, 5.11915700e-04],\n",
       "       [9.99962900e-01, 3.70541000e-05, 3.27636000e-10],\n",
       "       [1.49911430e-03, 9.65690550e-01, 3.28104200e-02],\n",
       "       [1.43636050e-05, 1.80532050e-01, 8.19453600e-01],\n",
       "       [9.52893900e-02, 7.88657960e-01, 1.16052635e-01],\n",
       "       [1.61904880e-02, 9.26161940e-01, 5.76474930e-02],\n",
       "       [9.94186900e-01, 4.48105070e-03, 1.33204150e-03],\n",
       "       [6.00821430e-03, 9.26091250e-01, 6.79005000e-02],\n",
       "       [1.18100770e-09, 2.06150830e-05, 9.99979400e-01],\n",
       "       [9.99871850e-01, 9.87020100e-05, 2.93990070e-05],\n",
       "       [1.65065940e-02, 9.78892200e-01, 4.60123220e-03],\n",
       "       [4.34422500e-03, 9.76759300e-01, 1.88964940e-02],\n",
       "       [8.70431100e-03, 8.01245800e-01, 1.90049930e-01],\n",
       "       [9.99871850e-01, 9.87020100e-05, 2.93990070e-05],\n",
       "       [4.26625020e-04, 4.12003960e-01, 5.87569400e-01],\n",
       "       [2.64610860e-03, 9.97351900e-01, 2.06488220e-06],\n",
       "       [5.40859730e-05, 9.99941100e-01, 4.74559870e-06],\n",
       "       [1.09134200e-04, 8.96958770e-01, 1.02932000e-01],\n",
       "       [9.09162200e-01, 9.06246100e-02, 2.13148500e-04],\n",
       "       [5.08333000e-04, 5.37477140e-01, 4.62014530e-01],\n",
       "       [8.74959350e-01, 1.24986650e-01, 5.40419020e-05],\n",
       "       [9.73121400e-01, 2.56558270e-02, 1.22286520e-03],\n",
       "       [6.12403400e-16, 2.27670620e-10, 1.00000000e+00],\n",
       "       [4.02753240e-07, 4.48721370e-05, 9.99954700e-01],\n",
       "       [6.00821430e-03, 9.26091250e-01, 6.79005000e-02],\n",
       "       [9.83564460e-05, 5.89448870e-01, 4.10452800e-01],\n",
       "       [7.47336400e-03, 9.30302400e-01, 6.22242200e-02],\n",
       "       [4.27758350e-05, 6.95663400e-02, 9.30390900e-01],\n",
       "       [6.25731160e-07, 2.31343250e-03, 9.97685900e-01],\n",
       "       [3.11595340e-16, 7.24834500e-09, 1.00000000e+00],\n",
       "       [9.99004540e-01, 9.93439900e-04, 1.97578130e-06],\n",
       "       [9.65044200e-09, 1.09651000e-05, 9.99989030e-01],\n",
       "       [4.23548570e-04, 9.96730900e-01, 2.84552390e-03],\n",
       "       [1.10725220e-06, 9.99042600e-01, 9.56307400e-04],\n",
       "       [1.26618700e-04, 6.34590450e-04, 9.99238850e-01],\n",
       "       [1.42804250e-01, 8.55170400e-01, 2.02533040e-03],\n",
       "       [3.47206170e-04, 9.98688760e-01, 9.64101640e-04],\n",
       "       [5.37669840e-03, 9.91841900e-01, 2.78145700e-03],\n",
       "       [5.99432040e-06, 9.99567200e-01, 4.26843880e-04],\n",
       "       [9.93875440e-01, 6.11242370e-03, 1.20862480e-05],\n",
       "       [1.29888890e-02, 9.83026560e-01, 3.98457940e-03],\n",
       "       [2.04200090e-03, 6.23413000e-01, 3.74544950e-01],\n",
       "       [9.97945960e-01, 2.05399350e-03, 2.98846570e-09],\n",
       "       [8.38550900e-07, 5.34731760e-03, 9.94651800e-01],\n",
       "       [9.97945960e-01, 2.05399350e-03, 2.98846570e-09],\n",
       "       [9.95606960e-01, 4.01509600e-03, 3.77948830e-04],\n",
       "       [9.98744000e-01, 8.18348100e-04, 4.37644340e-04],\n",
       "       [9.17498700e-06, 1.65741380e-03, 9.98333400e-01],\n",
       "       [9.52893900e-02, 7.88657960e-01, 1.16052635e-01],\n",
       "       [9.98744000e-01, 8.18348100e-04, 4.37644340e-04],\n",
       "       [5.29944900e-03, 9.54516050e-01, 4.01845160e-02],\n",
       "       [9.99004540e-01, 9.93439900e-04, 1.97578130e-06],\n",
       "       [1.68923650e-05, 9.99543850e-01, 4.39175800e-04],\n",
       "       [5.37669840e-03, 9.91841900e-01, 2.78145700e-03],\n",
       "       [9.99387740e-01, 5.43776260e-04, 6.84742100e-05],\n",
       "       [9.98679940e-01, 1.14337880e-03, 1.76677440e-04],\n",
       "       [9.93422450e-01, 6.55765400e-03, 1.99419480e-05],\n",
       "       [6.35835070e-06, 1.61673930e-01, 8.38319700e-01],\n",
       "       [9.95606960e-01, 4.01509600e-03, 3.77948830e-04],\n",
       "       [8.29863000e-05, 2.67322860e-02, 9.73184700e-01],\n",
       "       [4.82120900e-04, 9.97987030e-01, 1.53092830e-03],\n",
       "       [9.97471000e-01, 2.49854780e-03, 3.06113870e-05],\n",
       "       [1.65065940e-02, 9.78892200e-01, 4.60123220e-03],\n",
       "       [9.97267000e-01, 2.55142970e-03, 1.81509910e-04],\n",
       "       [2.79162400e-03, 9.93562460e-01, 3.64590180e-03],\n",
       "       [3.96386600e-03, 9.80023600e-01, 1.60125050e-02],\n",
       "       [9.99871850e-01, 9.87020100e-05, 2.93990070e-05],\n",
       "       [2.54730140e-01, 7.39795100e-01, 5.47473200e-03],\n",
       "       [9.99540700e-01, 2.43465940e-04, 2.15908990e-04],\n",
       "       [2.79162400e-03, 9.93562460e-01, 3.64590180e-03],\n",
       "       [1.10725220e-06, 9.99042600e-01, 9.56307400e-04]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob3 = df_proba3[df_proba3['phage']=='p11presabsSTCC_qual'].iloc[:,-3:]\n",
    "y_prob3 = y_prob3.to_numpy()\n",
    "y_prob3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9630983638628899"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo3 = rocauc_ovo(y_test_over, y_prob3, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9630983638628899"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr3 = rocauc_ovr(y_test_over, y_prob3, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=456,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat4 = pd.DataFrame(X_test_over[:,0])\n",
    "dat4['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SR2852</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CFBREBSa138</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BCH-SA-12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EUH13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EUH13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>NRS036</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>CA105</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>CFBRSa51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>NRS102</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>NRS189</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test\n",
       "0         SR2852     2\n",
       "1    CFBREBSa138     0\n",
       "2      BCH-SA-12     0\n",
       "3          EUH13     0\n",
       "4          EUH13     0\n",
       "..           ...   ...\n",
       "158       NRS036     1\n",
       "159        CA105     1\n",
       "160     CFBRSa51     1\n",
       "161       NRS102     1\n",
       "162       NRS189     2\n",
       "\n",
       "[163 rows x 2 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over4 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over4.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 380 samples, validate on 163 samples\n",
      "Epoch 1/100\n",
      "380/380 [==============================] - 0s 533us/step - loss: 2.4192 - accuracy: 0.3684 - val_loss: 1.3242 - val_accuracy: 0.5092\n",
      "Epoch 2/100\n",
      "380/380 [==============================] - 0s 172us/step - loss: 1.1238 - accuracy: 0.4816 - val_loss: 1.0534 - val_accuracy: 0.4847\n",
      "Epoch 3/100\n",
      "380/380 [==============================] - 0s 198us/step - loss: 0.9654 - accuracy: 0.5553 - val_loss: 0.9950 - val_accuracy: 0.5521\n",
      "Epoch 4/100\n",
      "380/380 [==============================] - 0s 226us/step - loss: 0.8759 - accuracy: 0.6395 - val_loss: 0.9492 - val_accuracy: 0.5276\n",
      "Epoch 5/100\n",
      "380/380 [==============================] - 0s 177us/step - loss: 0.7825 - accuracy: 0.6737 - val_loss: 0.9549 - val_accuracy: 0.5644\n",
      "Epoch 6/100\n",
      "380/380 [==============================] - 0s 167us/step - loss: 0.7440 - accuracy: 0.6789 - val_loss: 0.8881 - val_accuracy: 0.6135\n",
      "Epoch 7/100\n",
      "380/380 [==============================] - 0s 181us/step - loss: 0.7032 - accuracy: 0.7184 - val_loss: 0.8183 - val_accuracy: 0.6258\n",
      "Epoch 8/100\n",
      "380/380 [==============================] - 0s 179us/step - loss: 0.6520 - accuracy: 0.7474 - val_loss: 0.8454 - val_accuracy: 0.7055\n",
      "Epoch 9/100\n",
      "380/380 [==============================] - 0s 173us/step - loss: 0.6414 - accuracy: 0.7605 - val_loss: 0.7240 - val_accuracy: 0.6687\n",
      "Epoch 10/100\n",
      "380/380 [==============================] - 0s 200us/step - loss: 0.6018 - accuracy: 0.7658 - val_loss: 0.7531 - val_accuracy: 0.6687\n",
      "Epoch 11/100\n",
      "380/380 [==============================] - 0s 217us/step - loss: 0.6218 - accuracy: 0.7447 - val_loss: 0.8244 - val_accuracy: 0.6626\n",
      "Epoch 12/100\n",
      "380/380 [==============================] - 0s 211us/step - loss: 0.5649 - accuracy: 0.7921 - val_loss: 0.6930 - val_accuracy: 0.6871\n",
      "Epoch 13/100\n",
      "380/380 [==============================] - 0s 168us/step - loss: 0.5899 - accuracy: 0.7868 - val_loss: 0.6407 - val_accuracy: 0.7423\n",
      "Epoch 14/100\n",
      "380/380 [==============================] - 0s 140us/step - loss: 0.5117 - accuracy: 0.8263 - val_loss: 0.7213 - val_accuracy: 0.6503\n",
      "Epoch 15/100\n",
      "380/380 [==============================] - 0s 134us/step - loss: 0.4887 - accuracy: 0.8105 - val_loss: 0.5723 - val_accuracy: 0.8221\n",
      "Epoch 16/100\n",
      "380/380 [==============================] - 0s 398us/step - loss: 0.4495 - accuracy: 0.8368 - val_loss: 0.6565 - val_accuracy: 0.7239\n",
      "Epoch 17/100\n",
      "380/380 [==============================] - 0s 142us/step - loss: 0.4310 - accuracy: 0.8395 - val_loss: 0.6188 - val_accuracy: 0.7914\n",
      "Epoch 18/100\n",
      "380/380 [==============================] - 0s 156us/step - loss: 0.4331 - accuracy: 0.8605 - val_loss: 0.5120 - val_accuracy: 0.8221\n",
      "Epoch 19/100\n",
      "380/380 [==============================] - 0s 296us/step - loss: 0.4115 - accuracy: 0.8500 - val_loss: 0.6394 - val_accuracy: 0.7546\n",
      "Epoch 20/100\n",
      "380/380 [==============================] - 0s 272us/step - loss: 0.3910 - accuracy: 0.8579 - val_loss: 0.5491 - val_accuracy: 0.7546\n",
      "Epoch 21/100\n",
      "380/380 [==============================] - 0s 167us/step - loss: 0.3669 - accuracy: 0.8737 - val_loss: 0.5218 - val_accuracy: 0.8098\n",
      "Epoch 22/100\n",
      "380/380 [==============================] - 0s 217us/step - loss: 0.3567 - accuracy: 0.8632 - val_loss: 0.5659 - val_accuracy: 0.7975\n",
      "Epoch 23/100\n",
      "380/380 [==============================] - 0s 133us/step - loss: 0.3663 - accuracy: 0.8711 - val_loss: 0.7664 - val_accuracy: 0.7239\n",
      "Epoch 24/100\n",
      "380/380 [==============================] - 0s 108us/step - loss: 0.4784 - accuracy: 0.8526 - val_loss: 0.5726 - val_accuracy: 0.7423\n",
      "Epoch 25/100\n",
      "380/380 [==============================] - 0s 116us/step - loss: 0.3874 - accuracy: 0.8579 - val_loss: 0.5007 - val_accuracy: 0.8160\n",
      "Epoch 26/100\n",
      "380/380 [==============================] - 0s 116us/step - loss: 0.3882 - accuracy: 0.8895 - val_loss: 0.5210 - val_accuracy: 0.8037\n",
      "Epoch 27/100\n",
      "380/380 [==============================] - 0s 534us/step - loss: 0.2955 - accuracy: 0.8947 - val_loss: 0.4672 - val_accuracy: 0.8098\n",
      "Epoch 28/100\n",
      "380/380 [==============================] - 0s 260us/step - loss: 0.2880 - accuracy: 0.8947 - val_loss: 0.5115 - val_accuracy: 0.7730\n",
      "Epoch 29/100\n",
      "380/380 [==============================] - 0s 211us/step - loss: 0.2784 - accuracy: 0.8974 - val_loss: 0.5646 - val_accuracy: 0.8405\n",
      "Epoch 30/100\n",
      "380/380 [==============================] - 0s 222us/step - loss: 0.2738 - accuracy: 0.8947 - val_loss: 0.4828 - val_accuracy: 0.8405\n",
      "Epoch 31/100\n",
      "380/380 [==============================] - 0s 256us/step - loss: 0.2713 - accuracy: 0.9105 - val_loss: 0.5261 - val_accuracy: 0.8282\n",
      "Epoch 32/100\n",
      "380/380 [==============================] - 0s 332us/step - loss: 0.2371 - accuracy: 0.9184 - val_loss: 0.4284 - val_accuracy: 0.8221\n",
      "Epoch 33/100\n",
      "380/380 [==============================] - 0s 210us/step - loss: 0.2238 - accuracy: 0.9079 - val_loss: 0.4420 - val_accuracy: 0.8466\n",
      "Epoch 34/100\n",
      "380/380 [==============================] - 0s 187us/step - loss: 0.2214 - accuracy: 0.9158 - val_loss: 0.4419 - val_accuracy: 0.8221\n",
      "Epoch 35/100\n",
      "380/380 [==============================] - 0s 204us/step - loss: 0.2345 - accuracy: 0.9053 - val_loss: 0.4306 - val_accuracy: 0.8589\n",
      "Epoch 36/100\n",
      "380/380 [==============================] - 0s 206us/step - loss: 0.2756 - accuracy: 0.9053 - val_loss: 0.4942 - val_accuracy: 0.8466\n",
      "Epoch 37/100\n",
      "380/380 [==============================] - 0s 198us/step - loss: 0.2163 - accuracy: 0.9184 - val_loss: 0.4401 - val_accuracy: 0.8466\n",
      "Epoch 38/100\n",
      "380/380 [==============================] - 0s 259us/step - loss: 0.1950 - accuracy: 0.9421 - val_loss: 0.3957 - val_accuracy: 0.8712\n",
      "Epoch 39/100\n",
      "380/380 [==============================] - 0s 344us/step - loss: 0.2404 - accuracy: 0.9158 - val_loss: 0.5233 - val_accuracy: 0.8834\n",
      "Epoch 40/100\n",
      "380/380 [==============================] - 0s 293us/step - loss: 0.3055 - accuracy: 0.9211 - val_loss: 0.4130 - val_accuracy: 0.8405\n",
      "Epoch 41/100\n",
      "380/380 [==============================] - 0s 294us/step - loss: 0.2087 - accuracy: 0.9158 - val_loss: 0.4657 - val_accuracy: 0.8466\n",
      "Epoch 42/100\n",
      "380/380 [==============================] - 0s 222us/step - loss: 0.1920 - accuracy: 0.9500 - val_loss: 0.3843 - val_accuracy: 0.8344\n",
      "Epoch 43/100\n",
      "380/380 [==============================] - 0s 215us/step - loss: 0.1964 - accuracy: 0.9368 - val_loss: 0.5020 - val_accuracy: 0.8221\n",
      "Epoch 44/100\n",
      "380/380 [==============================] - 0s 349us/step - loss: 0.2204 - accuracy: 0.9263 - val_loss: 0.5375 - val_accuracy: 0.7853\n",
      "Epoch 45/100\n",
      "380/380 [==============================] - 0s 337us/step - loss: 0.1894 - accuracy: 0.9342 - val_loss: 0.3961 - val_accuracy: 0.8650\n",
      "Epoch 46/100\n",
      "380/380 [==============================] - 0s 301us/step - loss: 0.1587 - accuracy: 0.9500 - val_loss: 0.4254 - val_accuracy: 0.8650\n",
      "Epoch 47/100\n",
      "380/380 [==============================] - 0s 241us/step - loss: 0.1627 - accuracy: 0.9368 - val_loss: 0.4211 - val_accuracy: 0.8896\n",
      "Epoch 48/100\n",
      "380/380 [==============================] - 0s 243us/step - loss: 0.1501 - accuracy: 0.9500 - val_loss: 0.3684 - val_accuracy: 0.8834\n",
      "Epoch 49/100\n",
      "380/380 [==============================] - 0s 256us/step - loss: 0.1671 - accuracy: 0.9395 - val_loss: 0.4856 - val_accuracy: 0.8160\n",
      "Epoch 50/100\n",
      "380/380 [==============================] - 0s 165us/step - loss: 0.2357 - accuracy: 0.9395 - val_loss: 0.5165 - val_accuracy: 0.8773\n",
      "Epoch 51/100\n",
      "380/380 [==============================] - 0s 305us/step - loss: 0.2168 - accuracy: 0.9289 - val_loss: 0.3540 - val_accuracy: 0.8957\n",
      "Epoch 52/100\n",
      "380/380 [==============================] - 0s 427us/step - loss: 0.2156 - accuracy: 0.9263 - val_loss: 0.6642 - val_accuracy: 0.8282\n",
      "Epoch 53/100\n",
      "380/380 [==============================] - 0s 129us/step - loss: 0.2197 - accuracy: 0.9105 - val_loss: 0.4588 - val_accuracy: 0.8405\n",
      "Epoch 54/100\n",
      "380/380 [==============================] - 0s 110us/step - loss: 0.2056 - accuracy: 0.9132 - val_loss: 0.5604 - val_accuracy: 0.8405\n",
      "Epoch 55/100\n",
      "380/380 [==============================] - 0s 115us/step - loss: 0.2376 - accuracy: 0.9553 - val_loss: 0.4656 - val_accuracy: 0.8282\n",
      "Epoch 56/100\n",
      "380/380 [==============================] - 0s 129us/step - loss: 0.1663 - accuracy: 0.9211 - val_loss: 0.3556 - val_accuracy: 0.8773\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "380/380 [==============================] - 0s 186us/step - loss: 0.1509 - accuracy: 0.9579 - val_loss: 0.4994 - val_accuracy: 0.8466\n",
      "Epoch 58/100\n",
      "380/380 [==============================] - 0s 167us/step - loss: 0.1578 - accuracy: 0.9368 - val_loss: 0.6018 - val_accuracy: 0.8282\n",
      "Epoch 59/100\n",
      "380/380 [==============================] - 0s 156us/step - loss: 0.1480 - accuracy: 0.9289 - val_loss: 0.4710 - val_accuracy: 0.8650\n",
      "Epoch 60/100\n",
      "380/380 [==============================] - 0s 123us/step - loss: 0.1337 - accuracy: 0.9474 - val_loss: 0.4916 - val_accuracy: 0.8466\n",
      "Epoch 61/100\n",
      "380/380 [==============================] - 0s 116us/step - loss: 0.1238 - accuracy: 0.9526 - val_loss: 0.4140 - val_accuracy: 0.8834\n",
      "Epoch 62/100\n",
      "380/380 [==============================] - 0s 172us/step - loss: 0.1190 - accuracy: 0.9579 - val_loss: 0.4955 - val_accuracy: 0.8589\n",
      "Epoch 63/100\n",
      "380/380 [==============================] - 0s 188us/step - loss: 0.1504 - accuracy: 0.9395 - val_loss: 0.5107 - val_accuracy: 0.8528\n",
      "Epoch 64/100\n",
      "380/380 [==============================] - 0s 154us/step - loss: 0.1308 - accuracy: 0.9421 - val_loss: 0.3951 - val_accuracy: 0.8773\n",
      "Epoch 65/100\n",
      "380/380 [==============================] - 0s 141us/step - loss: 0.1240 - accuracy: 0.9500 - val_loss: 0.4547 - val_accuracy: 0.8712\n",
      "Epoch 66/100\n",
      "380/380 [==============================] - 0s 123us/step - loss: 0.1156 - accuracy: 0.9579 - val_loss: 0.4269 - val_accuracy: 0.8834\n",
      "Epoch 67/100\n",
      "380/380 [==============================] - 0s 151us/step - loss: 0.1080 - accuracy: 0.9632 - val_loss: 0.4017 - val_accuracy: 0.8773\n",
      "Epoch 68/100\n",
      "380/380 [==============================] - 0s 225us/step - loss: 0.1056 - accuracy: 0.9658 - val_loss: 0.4015 - val_accuracy: 0.8773\n",
      "Epoch 69/100\n",
      "380/380 [==============================] - 0s 184us/step - loss: 0.1042 - accuracy: 0.9737 - val_loss: 0.3593 - val_accuracy: 0.8773\n",
      "Epoch 70/100\n",
      "380/380 [==============================] - 0s 191us/step - loss: 0.1209 - accuracy: 0.9553 - val_loss: 0.4187 - val_accuracy: 0.8589\n",
      "Epoch 71/100\n",
      "380/380 [==============================] - 0s 116us/step - loss: 0.1249 - accuracy: 0.9526 - val_loss: 0.4150 - val_accuracy: 0.8773\n",
      "Epoch 72/100\n",
      "380/380 [==============================] - 0s 109us/step - loss: 0.1203 - accuracy: 0.9605 - val_loss: 0.3634 - val_accuracy: 0.8957\n",
      "Epoch 73/100\n",
      "380/380 [==============================] - 0s 113us/step - loss: 0.1146 - accuracy: 0.9632 - val_loss: 0.5290 - val_accuracy: 0.8466\n",
      "Epoch 74/100\n",
      "380/380 [==============================] - 0s 107us/step - loss: 0.1486 - accuracy: 0.9553 - val_loss: 0.4271 - val_accuracy: 0.8834\n",
      "Epoch 75/100\n",
      "380/380 [==============================] - 0s 112us/step - loss: 0.1358 - accuracy: 0.9526 - val_loss: 0.4944 - val_accuracy: 0.8650\n",
      "Epoch 76/100\n",
      "380/380 [==============================] - 0s 113us/step - loss: 0.1535 - accuracy: 0.9368 - val_loss: 0.4107 - val_accuracy: 0.8834\n",
      "Epoch 77/100\n",
      "380/380 [==============================] - 0s 151us/step - loss: 0.1532 - accuracy: 0.9368 - val_loss: 0.4059 - val_accuracy: 0.8589\n",
      "Epoch 78/100\n",
      "380/380 [==============================] - 0s 129us/step - loss: 0.1097 - accuracy: 0.9553 - val_loss: 0.3504 - val_accuracy: 0.8957\n",
      "Epoch 79/100\n",
      "380/380 [==============================] - 0s 118us/step - loss: 0.1009 - accuracy: 0.9658 - val_loss: 0.4254 - val_accuracy: 0.8773\n",
      "Epoch 80/100\n",
      "380/380 [==============================] - 0s 125us/step - loss: 0.0943 - accuracy: 0.9684 - val_loss: 0.3594 - val_accuracy: 0.8712\n",
      "Epoch 81/100\n",
      "380/380 [==============================] - 0s 110us/step - loss: 0.0976 - accuracy: 0.9658 - val_loss: 0.3479 - val_accuracy: 0.8896\n",
      "Epoch 82/100\n",
      "380/380 [==============================] - 0s 183us/step - loss: 0.1015 - accuracy: 0.9605 - val_loss: 0.4770 - val_accuracy: 0.8650\n",
      "Epoch 83/100\n",
      "380/380 [==============================] - 0s 123us/step - loss: 0.0914 - accuracy: 0.9658 - val_loss: 0.4287 - val_accuracy: 0.8773\n",
      "Epoch 84/100\n",
      "380/380 [==============================] - 0s 114us/step - loss: 0.0868 - accuracy: 0.9737 - val_loss: 0.3324 - val_accuracy: 0.9018\n",
      "Epoch 85/100\n",
      "380/380 [==============================] - 0s 113us/step - loss: 0.0877 - accuracy: 0.9684 - val_loss: 0.3534 - val_accuracy: 0.8589\n",
      "Epoch 86/100\n",
      "380/380 [==============================] - 0s 122us/step - loss: 0.0907 - accuracy: 0.9763 - val_loss: 0.4519 - val_accuracy: 0.8712\n",
      "Epoch 87/100\n",
      "380/380 [==============================] - 0s 114us/step - loss: 0.0965 - accuracy: 0.9632 - val_loss: 0.3674 - val_accuracy: 0.8957\n",
      "Epoch 88/100\n",
      "380/380 [==============================] - 0s 107us/step - loss: 0.0884 - accuracy: 0.9632 - val_loss: 0.3838 - val_accuracy: 0.8773\n",
      "Epoch 89/100\n",
      "380/380 [==============================] - 0s 119us/step - loss: 0.0914 - accuracy: 0.9711 - val_loss: 0.3311 - val_accuracy: 0.9018\n",
      "Epoch 90/100\n",
      "380/380 [==============================] - 0s 118us/step - loss: 0.0916 - accuracy: 0.9711 - val_loss: 0.3821 - val_accuracy: 0.8896\n",
      "Epoch 91/100\n",
      "380/380 [==============================] - 0s 119us/step - loss: 0.0755 - accuracy: 0.9763 - val_loss: 0.4016 - val_accuracy: 0.8834\n",
      "Epoch 92/100\n",
      "380/380 [==============================] - 0s 111us/step - loss: 0.0783 - accuracy: 0.9684 - val_loss: 0.3497 - val_accuracy: 0.9018\n",
      "Epoch 93/100\n",
      "380/380 [==============================] - 0s 146us/step - loss: 0.0811 - accuracy: 0.9789 - val_loss: 0.4328 - val_accuracy: 0.8650\n",
      "Epoch 94/100\n",
      "380/380 [==============================] - 0s 152us/step - loss: 0.0906 - accuracy: 0.9553 - val_loss: 0.4337 - val_accuracy: 0.8712\n",
      "Epoch 95/100\n",
      "380/380 [==============================] - 0s 141us/step - loss: 0.0775 - accuracy: 0.9711 - val_loss: 0.4122 - val_accuracy: 0.8773\n",
      "Epoch 96/100\n",
      "380/380 [==============================] - 0s 144us/step - loss: 0.0925 - accuracy: 0.9632 - val_loss: 0.3352 - val_accuracy: 0.8957\n",
      "Epoch 97/100\n",
      "380/380 [==============================] - 0s 142us/step - loss: 0.0822 - accuracy: 0.9684 - val_loss: 0.3886 - val_accuracy: 0.8896\n",
      "Epoch 98/100\n",
      "380/380 [==============================] - 0s 127us/step - loss: 0.0767 - accuracy: 0.9711 - val_loss: 0.3267 - val_accuracy: 0.8957\n",
      "Epoch 99/100\n",
      "380/380 [==============================] - 0s 140us/step - loss: 0.0788 - accuracy: 0.9684 - val_loss: 0.3479 - val_accuracy: 0.8957\n",
      "Epoch 100/100\n",
      "380/380 [==============================] - 0s 211us/step - loss: 0.0742 - accuracy: 0.9763 - val_loss: 0.3151 - val_accuracy: 0.8834\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a41deb208>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over4.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163/163 [==============================] - 0s 155us/step\n",
      "over-sampling test accuracy: 89.57%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over4 = model1_over4.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over4*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 0, 0, 0, 1, 0, 2, 0, 0, 1, 0, 2, 0, 2, 0, 0, 0, 2, 0, 2, 2,\n",
       "       0, 1, 1, 1, 2, 0, 0, 0, 0, 2, 2, 1, 2, 0, 0, 2, 0, 0, 0, 1, 1, 1,\n",
       "       1, 1, 2, 0, 0, 0, 1, 1, 1, 2, 2, 1, 2, 1, 1, 0, 2, 1, 0, 2, 2, 1,\n",
       "       2, 0, 2, 2, 0, 1, 0, 0, 0, 2, 1, 1, 1, 2, 0, 0, 2, 1, 2, 2, 0, 2,\n",
       "       0, 0, 0, 1, 0, 2, 1, 1, 0, 1, 1, 2, 0, 0, 2, 1, 2, 2, 0, 2, 1, 0,\n",
       "       2, 0, 1, 1, 0, 1, 0, 1, 2, 1, 1, 2, 2, 2, 1, 1, 2, 1, 2, 0, 1, 0,\n",
       "       1, 1, 2, 1, 0, 2, 1, 2, 0, 0, 2, 0, 2, 2, 0, 1, 1, 0, 0, 1, 2, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 2])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred4 = model1_over4.predict_classes(X_test_over)\n",
    "pred4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SR2852</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CFBREBSa138</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BCH-SA-12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EUH13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EUH13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>NRS036</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>CA105</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>CFBRSa51</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>NRS102</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>NRS189</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test  pred\n",
       "0         SR2852     2     2\n",
       "1    CFBREBSa138     0     0\n",
       "2      BCH-SA-12     0     0\n",
       "3          EUH13     0     0\n",
       "4          EUH13     0     0\n",
       "..           ...   ...   ...\n",
       "158       NRS036     1     1\n",
       "159        CA105     1     1\n",
       "160     CFBRSa51     1     1\n",
       "161       NRS102     1     1\n",
       "162       NRS189     2     2\n",
       "\n",
       "[163 rows x 3 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat4['pred'] = pred4\n",
    "dat4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba4 = model1_over4.predict_proba(X_test_over)\n",
    "dat_proba4 = pd.DataFrame(proba4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.275610e-05</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.999829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.952727e-01</td>\n",
       "      <td>0.000311</td>\n",
       "      <td>0.004416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.997271e-01</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>0.000106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.994013e-01</td>\n",
       "      <td>0.000506</td>\n",
       "      <td>0.000093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.994013e-01</td>\n",
       "      <td>0.000506</td>\n",
       "      <td>0.000093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>7.718902e-04</td>\n",
       "      <td>0.952838</td>\n",
       "      <td>0.046390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>4.223498e-04</td>\n",
       "      <td>0.997404</td>\n",
       "      <td>0.002173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>1.017573e-03</td>\n",
       "      <td>0.928870</td>\n",
       "      <td>0.070113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>6.538353e-06</td>\n",
       "      <td>0.978036</td>\n",
       "      <td>0.021957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>6.962887e-08</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>0.999844</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0         1         2\n",
       "0    1.275610e-05  0.000159  0.999829\n",
       "1    9.952727e-01  0.000311  0.004416\n",
       "2    9.997271e-01  0.000167  0.000106\n",
       "3    9.994013e-01  0.000506  0.000093\n",
       "4    9.994013e-01  0.000506  0.000093\n",
       "..            ...       ...       ...\n",
       "158  7.718902e-04  0.952838  0.046390\n",
       "159  4.223498e-04  0.997404  0.002173\n",
       "160  1.017573e-03  0.928870  0.070113\n",
       "161  6.538353e-06  0.978036  0.021957\n",
       "162  6.962887e-08  0.000156  0.999844\n",
       "\n",
       "[163 rows x 3 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba4.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba4.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat4.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/4p11pST.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 380 samples, validate on 163 samples\n",
      "Epoch 1/100\n",
      "380/380 [==============================] - 0s 202us/step - loss: 0.0714 - accuracy: 0.9711 - val_loss: 0.4821 - val_accuracy: 0.8650\n",
      "Epoch 2/100\n",
      "380/380 [==============================] - 0s 175us/step - loss: 0.0804 - accuracy: 0.9711 - val_loss: 0.2909 - val_accuracy: 0.8896\n",
      "Epoch 3/100\n",
      "380/380 [==============================] - 0s 152us/step - loss: 0.0902 - accuracy: 0.9579 - val_loss: 0.3454 - val_accuracy: 0.8957\n",
      "Epoch 4/100\n",
      "380/380 [==============================] - 0s 145us/step - loss: 0.0978 - accuracy: 0.9632 - val_loss: 0.5128 - val_accuracy: 0.8650\n",
      "Epoch 5/100\n",
      "380/380 [==============================] - 0s 151us/step - loss: 0.1002 - accuracy: 0.9579 - val_loss: 0.4730 - val_accuracy: 0.8712\n",
      "Epoch 6/100\n",
      "380/380 [==============================] - 0s 155us/step - loss: 0.0811 - accuracy: 0.9684 - val_loss: 0.3803 - val_accuracy: 0.9080\n",
      "Epoch 7/100\n",
      "380/380 [==============================] - 0s 167us/step - loss: 0.0771 - accuracy: 0.9711 - val_loss: 0.3931 - val_accuracy: 0.8957\n",
      "Epoch 8/100\n",
      "380/380 [==============================] - 0s 161us/step - loss: 0.0862 - accuracy: 0.9605 - val_loss: 0.3281 - val_accuracy: 0.8896\n",
      "Epoch 9/100\n",
      "380/380 [==============================] - 0s 150us/step - loss: 0.0828 - accuracy: 0.9632 - val_loss: 0.3452 - val_accuracy: 0.8589\n",
      "Epoch 10/100\n",
      "380/380 [==============================] - 0s 147us/step - loss: 0.0825 - accuracy: 0.9763 - val_loss: 0.3996 - val_accuracy: 0.8896\n",
      "Epoch 11/100\n",
      "380/380 [==============================] - 0s 154us/step - loss: 0.0699 - accuracy: 0.9711 - val_loss: 0.4130 - val_accuracy: 0.8834\n",
      "Epoch 12/100\n",
      "380/380 [==============================] - 0s 159us/step - loss: 0.0739 - accuracy: 0.9684 - val_loss: 0.4271 - val_accuracy: 0.8712\n",
      "Epoch 13/100\n",
      "380/380 [==============================] - 0s 126us/step - loss: 0.0641 - accuracy: 0.9737 - val_loss: 0.4013 - val_accuracy: 0.8712\n",
      "Epoch 14/100\n",
      "380/380 [==============================] - 0s 126us/step - loss: 0.0895 - accuracy: 0.9526 - val_loss: 0.4177 - val_accuracy: 0.8834\n",
      "Epoch 15/100\n",
      "380/380 [==============================] - 0s 146us/step - loss: 0.0684 - accuracy: 0.9684 - val_loss: 0.3637 - val_accuracy: 0.8528\n",
      "Epoch 16/100\n",
      "380/380 [==============================] - 0s 159us/step - loss: 0.0817 - accuracy: 0.9632 - val_loss: 0.3983 - val_accuracy: 0.8589\n",
      "Epoch 17/100\n",
      "380/380 [==============================] - 0s 148us/step - loss: 0.0742 - accuracy: 0.9711 - val_loss: 0.3711 - val_accuracy: 0.8957\n",
      "Epoch 18/100\n",
      "380/380 [==============================] - 0s 129us/step - loss: 0.0806 - accuracy: 0.9632 - val_loss: 0.3407 - val_accuracy: 0.9080\n",
      "Epoch 19/100\n",
      "380/380 [==============================] - 0s 121us/step - loss: 0.0844 - accuracy: 0.9658 - val_loss: 0.3499 - val_accuracy: 0.8834\n",
      "Epoch 20/100\n",
      "380/380 [==============================] - 0s 130us/step - loss: 0.0662 - accuracy: 0.9711 - val_loss: 0.3635 - val_accuracy: 0.8957\n",
      "Epoch 21/100\n",
      "380/380 [==============================] - 0s 120us/step - loss: 0.0630 - accuracy: 0.9763 - val_loss: 0.4070 - val_accuracy: 0.8896\n",
      "Epoch 22/100\n",
      "380/380 [==============================] - 0s 124us/step - loss: 0.0559 - accuracy: 0.9763 - val_loss: 0.3386 - val_accuracy: 0.8896\n",
      "Epoch 23/100\n",
      "380/380 [==============================] - 0s 131us/step - loss: 0.0667 - accuracy: 0.9711 - val_loss: 0.4323 - val_accuracy: 0.8773\n",
      "Epoch 24/100\n",
      "380/380 [==============================] - 0s 143us/step - loss: 0.0626 - accuracy: 0.9816 - val_loss: 0.3878 - val_accuracy: 0.8957\n",
      "Epoch 25/100\n",
      "380/380 [==============================] - 0s 151us/step - loss: 0.0731 - accuracy: 0.9763 - val_loss: 0.3676 - val_accuracy: 0.8957\n",
      "Epoch 26/100\n",
      "380/380 [==============================] - 0s 128us/step - loss: 0.0592 - accuracy: 0.9789 - val_loss: 0.3708 - val_accuracy: 0.8834\n",
      "Epoch 27/100\n",
      "380/380 [==============================] - 0s 121us/step - loss: 0.0558 - accuracy: 0.9789 - val_loss: 0.4753 - val_accuracy: 0.8712\n",
      "Epoch 28/100\n",
      "380/380 [==============================] - 0s 131us/step - loss: 0.0639 - accuracy: 0.9763 - val_loss: 0.5163 - val_accuracy: 0.8650\n",
      "Epoch 29/100\n",
      "380/380 [==============================] - 0s 119us/step - loss: 0.0625 - accuracy: 0.9711 - val_loss: 0.4589 - val_accuracy: 0.8834\n",
      "Epoch 30/100\n",
      "380/380 [==============================] - 0s 129us/step - loss: 0.0546 - accuracy: 0.9763 - val_loss: 0.3742 - val_accuracy: 0.8896\n",
      "Epoch 31/100\n",
      "380/380 [==============================] - 0s 136us/step - loss: 0.0745 - accuracy: 0.9684 - val_loss: 0.4239 - val_accuracy: 0.8834\n",
      "Epoch 32/100\n",
      "380/380 [==============================] - 0s 146us/step - loss: 0.0489 - accuracy: 0.9868 - val_loss: 0.3673 - val_accuracy: 0.8712\n",
      "Epoch 33/100\n",
      "380/380 [==============================] - 0s 199us/step - loss: 0.0544 - accuracy: 0.9763 - val_loss: 0.4682 - val_accuracy: 0.8773\n",
      "Epoch 34/100\n",
      "380/380 [==============================] - 0s 191us/step - loss: 0.0613 - accuracy: 0.9763 - val_loss: 0.3937 - val_accuracy: 0.8834\n",
      "Epoch 35/100\n",
      "380/380 [==============================] - 0s 215us/step - loss: 0.0629 - accuracy: 0.9684 - val_loss: 0.3926 - val_accuracy: 0.8896\n",
      "Epoch 36/100\n",
      "380/380 [==============================] - 0s 182us/step - loss: 0.0918 - accuracy: 0.9605 - val_loss: 0.3270 - val_accuracy: 0.8957\n",
      "Epoch 37/100\n",
      "380/380 [==============================] - 0s 119us/step - loss: 0.0698 - accuracy: 0.9684 - val_loss: 0.3694 - val_accuracy: 0.9080\n",
      "Epoch 38/100\n",
      "380/380 [==============================] - 0s 118us/step - loss: 0.0666 - accuracy: 0.9684 - val_loss: 0.4841 - val_accuracy: 0.8712\n",
      "Epoch 39/100\n",
      "380/380 [==============================] - 0s 107us/step - loss: 0.0917 - accuracy: 0.9579 - val_loss: 0.3327 - val_accuracy: 0.8650\n",
      "Epoch 40/100\n",
      "380/380 [==============================] - 0s 119us/step - loss: 0.0818 - accuracy: 0.9684 - val_loss: 0.4515 - val_accuracy: 0.8773\n",
      "Epoch 41/100\n",
      "380/380 [==============================] - 0s 134us/step - loss: 0.0738 - accuracy: 0.9632 - val_loss: 0.4551 - val_accuracy: 0.8712\n",
      "Epoch 42/100\n",
      "380/380 [==============================] - 0s 123us/step - loss: 0.0606 - accuracy: 0.9763 - val_loss: 0.5885 - val_accuracy: 0.8650\n",
      "Epoch 43/100\n",
      "380/380 [==============================] - 0s 117us/step - loss: 0.1066 - accuracy: 0.9474 - val_loss: 0.6133 - val_accuracy: 0.8650\n",
      "Epoch 44/100\n",
      "380/380 [==============================] - 0s 105us/step - loss: 0.1150 - accuracy: 0.9553 - val_loss: 0.3683 - val_accuracy: 0.9018\n",
      "Epoch 45/100\n",
      "380/380 [==============================] - 0s 107us/step - loss: 0.0618 - accuracy: 0.9816 - val_loss: 0.4047 - val_accuracy: 0.8650\n",
      "Epoch 46/100\n",
      "380/380 [==============================] - 0s 105us/step - loss: 0.0647 - accuracy: 0.9789 - val_loss: 0.4635 - val_accuracy: 0.8773\n",
      "Epoch 47/100\n",
      "380/380 [==============================] - 0s 111us/step - loss: 0.0922 - accuracy: 0.9711 - val_loss: 0.5321 - val_accuracy: 0.8712\n",
      "Epoch 48/100\n",
      "380/380 [==============================] - 0s 107us/step - loss: 0.0515 - accuracy: 0.9868 - val_loss: 0.4239 - val_accuracy: 0.8834\n",
      "Epoch 49/100\n",
      "380/380 [==============================] - 0s 142us/step - loss: 0.0569 - accuracy: 0.9763 - val_loss: 0.4826 - val_accuracy: 0.8834\n",
      "Epoch 50/100\n",
      "380/380 [==============================] - 0s 121us/step - loss: 0.0466 - accuracy: 0.9842 - val_loss: 0.4701 - val_accuracy: 0.8773\n",
      "Epoch 51/100\n",
      "380/380 [==============================] - 0s 112us/step - loss: 0.0533 - accuracy: 0.9711 - val_loss: 0.4309 - val_accuracy: 0.8957\n",
      "Epoch 52/100\n",
      "380/380 [==============================] - 0s 122us/step - loss: 0.0609 - accuracy: 0.9763 - val_loss: 0.6455 - val_accuracy: 0.8650\n",
      "Epoch 53/100\n",
      "380/380 [==============================] - 0s 143us/step - loss: 0.0543 - accuracy: 0.9816 - val_loss: 0.3837 - val_accuracy: 0.8712\n",
      "Epoch 54/100\n",
      "380/380 [==============================] - 0s 125us/step - loss: 0.0626 - accuracy: 0.9711 - val_loss: 0.3940 - val_accuracy: 0.8589\n",
      "Epoch 55/100\n",
      "380/380 [==============================] - 0s 136us/step - loss: 0.0670 - accuracy: 0.9605 - val_loss: 0.4750 - val_accuracy: 0.8834\n",
      "Epoch 56/100\n",
      "380/380 [==============================] - 0s 134us/step - loss: 0.0728 - accuracy: 0.9632 - val_loss: 0.4814 - val_accuracy: 0.8712\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "380/380 [==============================] - 0s 156us/step - loss: 0.0548 - accuracy: 0.9842 - val_loss: 0.3985 - val_accuracy: 0.8957\n",
      "Epoch 58/100\n",
      "380/380 [==============================] - 0s 140us/step - loss: 0.0470 - accuracy: 0.9842 - val_loss: 0.4347 - val_accuracy: 0.8834\n",
      "Epoch 59/100\n",
      "380/380 [==============================] - 0s 111us/step - loss: 0.0599 - accuracy: 0.9816 - val_loss: 0.5595 - val_accuracy: 0.8712\n",
      "Epoch 60/100\n",
      "380/380 [==============================] - 0s 117us/step - loss: 0.0883 - accuracy: 0.9500 - val_loss: 0.5781 - val_accuracy: 0.8221\n",
      "Epoch 61/100\n",
      "380/380 [==============================] - 0s 116us/step - loss: 0.0641 - accuracy: 0.9816 - val_loss: 0.3750 - val_accuracy: 0.9018\n",
      "Epoch 62/100\n",
      "380/380 [==============================] - 0s 107us/step - loss: 0.0468 - accuracy: 0.9842 - val_loss: 0.4964 - val_accuracy: 0.8834\n",
      "Epoch 63/100\n",
      "380/380 [==============================] - 0s 120us/step - loss: 0.0503 - accuracy: 0.9737 - val_loss: 0.3606 - val_accuracy: 0.9018\n",
      "Epoch 64/100\n",
      "380/380 [==============================] - 0s 137us/step - loss: 0.0766 - accuracy: 0.9711 - val_loss: 0.3896 - val_accuracy: 0.9018\n",
      "Epoch 65/100\n",
      "380/380 [==============================] - 0s 149us/step - loss: 0.0498 - accuracy: 0.9842 - val_loss: 0.3975 - val_accuracy: 0.8957\n",
      "Epoch 66/100\n",
      "380/380 [==============================] - 0s 128us/step - loss: 0.0511 - accuracy: 0.9789 - val_loss: 0.3584 - val_accuracy: 0.8834\n",
      "Epoch 67/100\n",
      "380/380 [==============================] - 0s 118us/step - loss: 0.0650 - accuracy: 0.9711 - val_loss: 0.4314 - val_accuracy: 0.8834\n",
      "Epoch 68/100\n",
      "380/380 [==============================] - 0s 109us/step - loss: 0.0563 - accuracy: 0.9763 - val_loss: 0.5155 - val_accuracy: 0.8773\n",
      "Epoch 69/100\n",
      "380/380 [==============================] - 0s 115us/step - loss: 0.0543 - accuracy: 0.9789 - val_loss: 0.5356 - val_accuracy: 0.8773\n",
      "Epoch 70/100\n",
      "380/380 [==============================] - 0s 130us/step - loss: 0.0657 - accuracy: 0.9737 - val_loss: 0.4800 - val_accuracy: 0.8834\n",
      "Epoch 71/100\n",
      "380/380 [==============================] - 0s 121us/step - loss: 0.0651 - accuracy: 0.9684 - val_loss: 0.4802 - val_accuracy: 0.8834\n",
      "Epoch 72/100\n",
      "380/380 [==============================] - 0s 118us/step - loss: 0.0503 - accuracy: 0.9842 - val_loss: 0.3592 - val_accuracy: 0.8957\n",
      "Epoch 73/100\n",
      "380/380 [==============================] - 0s 110us/step - loss: 0.0609 - accuracy: 0.9763 - val_loss: 0.5026 - val_accuracy: 0.8834\n",
      "Epoch 74/100\n",
      "380/380 [==============================] - 0s 108us/step - loss: 0.0404 - accuracy: 0.9789 - val_loss: 0.5064 - val_accuracy: 0.8712\n",
      "Epoch 75/100\n",
      "380/380 [==============================] - 0s 119us/step - loss: 0.0480 - accuracy: 0.9842 - val_loss: 0.5471 - val_accuracy: 0.8712\n",
      "Epoch 76/100\n",
      "380/380 [==============================] - 0s 127us/step - loss: 0.0459 - accuracy: 0.9868 - val_loss: 0.4230 - val_accuracy: 0.8712\n",
      "Epoch 77/100\n",
      "380/380 [==============================] - 0s 148us/step - loss: 0.0385 - accuracy: 0.9868 - val_loss: 0.5057 - val_accuracy: 0.8834\n",
      "Epoch 78/100\n",
      "380/380 [==============================] - 0s 253us/step - loss: 0.0624 - accuracy: 0.9711 - val_loss: 0.7483 - val_accuracy: 0.8650\n",
      "Epoch 79/100\n",
      "380/380 [==============================] - 0s 226us/step - loss: 0.0789 - accuracy: 0.9658 - val_loss: 0.3648 - val_accuracy: 0.9080\n",
      "Epoch 80/100\n",
      "380/380 [==============================] - 0s 163us/step - loss: 0.0544 - accuracy: 0.9711 - val_loss: 0.4984 - val_accuracy: 0.8773\n",
      "Epoch 81/100\n",
      "380/380 [==============================] - 0s 156us/step - loss: 0.0461 - accuracy: 0.9868 - val_loss: 0.3453 - val_accuracy: 0.9202\n",
      "Epoch 82/100\n",
      "380/380 [==============================] - 0s 168us/step - loss: 0.0444 - accuracy: 0.9789 - val_loss: 0.6120 - val_accuracy: 0.8896\n",
      "Epoch 83/100\n",
      "380/380 [==============================] - 0s 193us/step - loss: 0.0602 - accuracy: 0.9816 - val_loss: 0.5094 - val_accuracy: 0.9080\n",
      "Epoch 84/100\n",
      "380/380 [==============================] - 0s 155us/step - loss: 0.0559 - accuracy: 0.9763 - val_loss: 0.7957 - val_accuracy: 0.8712\n",
      "Epoch 85/100\n",
      "380/380 [==============================] - 0s 178us/step - loss: 0.3087 - accuracy: 0.9474 - val_loss: 0.8358 - val_accuracy: 0.8466\n",
      "Epoch 86/100\n",
      "380/380 [==============================] - 0s 500us/step - loss: 0.1611 - accuracy: 0.9474 - val_loss: 0.8704 - val_accuracy: 0.8650\n",
      "Epoch 87/100\n",
      "380/380 [==============================] - 0s 218us/step - loss: 0.2748 - accuracy: 0.9447 - val_loss: 0.7703 - val_accuracy: 0.8589\n",
      "Epoch 88/100\n",
      "380/380 [==============================] - 0s 171us/step - loss: 0.6510 - accuracy: 0.9132 - val_loss: 0.3621 - val_accuracy: 0.8834\n",
      "Epoch 89/100\n",
      "380/380 [==============================] - 0s 222us/step - loss: 0.7145 - accuracy: 0.8711 - val_loss: 0.8179 - val_accuracy: 0.8344\n",
      "Epoch 90/100\n",
      "380/380 [==============================] - 0s 159us/step - loss: 0.2845 - accuracy: 0.9000 - val_loss: 0.6485 - val_accuracy: 0.8773\n",
      "Epoch 91/100\n",
      "380/380 [==============================] - 0s 119us/step - loss: 0.2741 - accuracy: 0.9579 - val_loss: 0.8108 - val_accuracy: 0.8405\n",
      "Epoch 92/100\n",
      "380/380 [==============================] - 0s 119us/step - loss: 0.1322 - accuracy: 0.9553 - val_loss: 0.5278 - val_accuracy: 0.8834\n",
      "Epoch 93/100\n",
      "380/380 [==============================] - 0s 116us/step - loss: 0.1130 - accuracy: 0.9658 - val_loss: 0.6042 - val_accuracy: 0.8466\n",
      "Epoch 94/100\n",
      "380/380 [==============================] - 0s 117us/step - loss: 0.1320 - accuracy: 0.9579 - val_loss: 0.7127 - val_accuracy: 0.8405\n",
      "Epoch 95/100\n",
      "380/380 [==============================] - 0s 153us/step - loss: 0.0958 - accuracy: 0.9711 - val_loss: 0.7913 - val_accuracy: 0.8589\n",
      "Epoch 96/100\n",
      "380/380 [==============================] - 0s 172us/step - loss: 0.1537 - accuracy: 0.9763 - val_loss: 0.7119 - val_accuracy: 0.8773\n",
      "Epoch 97/100\n",
      "380/380 [==============================] - 0s 140us/step - loss: 0.0947 - accuracy: 0.9658 - val_loss: 0.8202 - val_accuracy: 0.8773\n",
      "Epoch 98/100\n",
      "380/380 [==============================] - 0s 136us/step - loss: 0.1846 - accuracy: 0.9684 - val_loss: 0.7984 - val_accuracy: 0.8834\n",
      "Epoch 99/100\n",
      "380/380 [==============================] - 0s 137us/step - loss: 0.1158 - accuracy: 0.9684 - val_loss: 0.6160 - val_accuracy: 0.8957\n",
      "Epoch 100/100\n",
      "380/380 [==============================] - 0s 132us/step - loss: 0.0617 - accuracy: 0.9684 - val_loss: 0.7112 - val_accuracy: 0.8650\n"
     ]
    }
   ],
   "source": [
    "hist1_over4 = model1_over4.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 96.89%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over4.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba4 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_2.xlsx\",\n",
    "                        sheet_name=3,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS110</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>5.870196e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS216</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.039254</td>\n",
       "      <td>0.960745</td>\n",
       "      <td>9.078969e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS386</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.326752</td>\n",
       "      <td>0.673248</td>\n",
       "      <td>1.061032e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>CFBRSa25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.611084</td>\n",
       "      <td>0.388916</td>\n",
       "      <td>7.664974e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>BCH-SA-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.611084</td>\n",
       "      <td>0.388916</td>\n",
       "      <td>7.664974e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4279</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS236</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.999768</td>\n",
       "      <td>1.803156e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4280</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS029</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.322350</td>\n",
       "      <td>0.677496</td>\n",
       "      <td>1.533154e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4281</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>9.999682e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4282</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>CFBRSa28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999288</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>5.361527e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4283</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS205</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>9.999868e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4284 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    phage     strain  phenotype  prediction         0  \\\n",
       "0      p002ykpresabs_qual     NRS110          1           1  0.000003   \n",
       "1      p002ykpresabs_qual     NRS216          1           1  0.039254   \n",
       "2      p002ykpresabs_qual     NRS386          1           1  0.326752   \n",
       "3      p002ykpresabs_qual   CFBRSa25          0           0  0.611084   \n",
       "4      p002ykpresabs_qual  BCH-SA-03          1           0  0.611084   \n",
       "...                   ...        ...        ...         ...       ...   \n",
       "4279  pyopresabsSTCC_qual     NRS236          1           1  0.000052   \n",
       "4280  pyopresabsSTCC_qual     NRS029          0           1  0.322350   \n",
       "4281  pyopresabsSTCC_qual     NRS148          2           2  0.000006   \n",
       "4282  pyopresabsSTCC_qual   CFBRSa28          0           0  0.999288   \n",
       "4283  pyopresabsSTCC_qual     NRS205          2           2  0.000007   \n",
       "\n",
       "             1             2  \n",
       "0     0.999997  5.870196e-13  \n",
       "1     0.960745  9.078969e-07  \n",
       "2     0.673248  1.061032e-07  \n",
       "3     0.388916  7.664974e-07  \n",
       "4     0.388916  7.664974e-07  \n",
       "...        ...           ...  \n",
       "4279  0.999768  1.803156e-04  \n",
       "4280  0.677496  1.533154e-04  \n",
       "4281  0.000026  9.999682e-01  \n",
       "4282  0.000176  5.361527e-04  \n",
       "4283  0.000007  9.999868e-01  \n",
       "\n",
       "[4284 rows x 7 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.27560950e-05, 1.58516250e-04, 9.99828700e-01],\n",
       "       [9.95272700e-01, 3.11062000e-04, 4.41623600e-03],\n",
       "       [9.99727100e-01, 1.66907030e-04, 1.06122614e-04],\n",
       "       [9.99401330e-01, 5.05912930e-04, 9.28402950e-05],\n",
       "       [9.99401330e-01, 5.05912930e-04, 9.28402950e-05],\n",
       "       [1.28870890e-03, 9.54523270e-01, 4.41879480e-02],\n",
       "       [9.25535000e-01, 4.42059040e-02, 3.02591120e-02],\n",
       "       [8.23833430e-07, 2.01525520e-03, 9.97983930e-01],\n",
       "       [9.72353200e-01, 2.21995860e-02, 5.44721000e-03],\n",
       "       [9.99486450e-01, 5.46639060e-05, 4.58875580e-04],\n",
       "       [2.89341550e-03, 8.20992230e-01, 1.76114320e-01],\n",
       "       [9.15407360e-01, 5.15081920e-02, 3.30844630e-02],\n",
       "       [2.94101200e-05, 6.73784640e-03, 9.93232700e-01],\n",
       "       [9.72353200e-01, 2.21995860e-02, 5.44721000e-03],\n",
       "       [1.47318420e-03, 1.32832410e-01, 8.65694400e-01],\n",
       "       [9.95265360e-01, 1.51526980e-04, 4.58311940e-03],\n",
       "       [9.72353200e-01, 2.21995860e-02, 5.44721000e-03],\n",
       "       [9.99595700e-01, 8.14329540e-05, 3.22883340e-04],\n",
       "       [2.21629500e-16, 1.58274850e-09, 1.00000000e+00],\n",
       "       [9.99401330e-01, 5.05912930e-04, 9.28402950e-05],\n",
       "       [8.37273500e-10, 1.61949630e-05, 9.99983800e-01],\n",
       "       [2.02343020e-07, 2.63888480e-03, 9.97360900e-01],\n",
       "       [9.99486450e-01, 5.46639060e-05, 4.58875580e-04],\n",
       "       [5.50458100e-07, 9.95251200e-01, 4.74823360e-03],\n",
       "       [7.46363730e-03, 9.76763600e-01, 1.57727880e-02],\n",
       "       [8.79738540e-04, 5.18674430e-01, 4.80445860e-01],\n",
       "       [1.55853770e-08, 1.97003630e-07, 9.99999760e-01],\n",
       "       [9.99486450e-01, 5.46639060e-05, 4.58875580e-04],\n",
       "       [9.63263900e-01, 1.75591930e-02, 1.91768500e-02],\n",
       "       [9.25535000e-01, 4.42059040e-02, 3.02591120e-02],\n",
       "       [9.99917860e-01, 7.63069500e-07, 8.13653300e-05],\n",
       "       [6.74141500e-04, 5.98347930e-02, 9.39491100e-01],\n",
       "       [3.51581700e-04, 4.29127870e-01, 5.70520600e-01],\n",
       "       [1.43771960e-02, 8.96326900e-01, 8.92959300e-02],\n",
       "       [3.43150880e-01, 1.96477310e-01, 4.60371820e-01],\n",
       "       [9.15407360e-01, 5.15081920e-02, 3.30844630e-02],\n",
       "       [9.98532400e-01, 1.19183490e-04, 1.34845850e-03],\n",
       "       [4.60913720e-07, 2.58586670e-03, 9.97413700e-01],\n",
       "       [9.95272700e-01, 3.11062000e-04, 4.41623600e-03],\n",
       "       [9.98783770e-01, 1.32151740e-06, 1.21493030e-03],\n",
       "       [9.95265360e-01, 1.51526980e-04, 4.58311940e-03],\n",
       "       [1.01757340e-03, 9.28869800e-01, 7.01125900e-02],\n",
       "       [7.63399750e-06, 9.99171600e-01, 8.20770450e-04],\n",
       "       [1.76415210e-05, 9.94517150e-01, 5.46513600e-03],\n",
       "       [9.89424000e-02, 7.31961600e-01, 1.69096040e-01],\n",
       "       [1.31586600e-11, 9.95010260e-01, 4.98970920e-03],\n",
       "       [5.12929400e-03, 4.83157370e-01, 5.11713300e-01],\n",
       "       [9.99727100e-01, 1.66907030e-04, 1.06122614e-04],\n",
       "       [9.98783770e-01, 1.32151740e-06, 1.21493030e-03],\n",
       "       [9.98532400e-01, 1.19183490e-04, 1.34845850e-03],\n",
       "       [6.53835300e-06, 9.78036460e-01, 2.19570120e-02],\n",
       "       [8.85746100e-09, 9.99647140e-01, 3.52862380e-04],\n",
       "       [1.31586600e-11, 9.95010260e-01, 4.98970920e-03],\n",
       "       [2.26507000e-03, 3.66732270e-01, 6.31002700e-01],\n",
       "       [1.24810660e-10, 1.03046180e-06, 9.99998900e-01],\n",
       "       [2.79487810e-05, 9.02443950e-01, 9.75280700e-02],\n",
       "       [1.01490160e-02, 3.21916200e-01, 6.67934830e-01],\n",
       "       [9.98264900e-09, 9.96560630e-01, 3.43932100e-03],\n",
       "       [9.24924200e-06, 9.82929800e-01, 1.70609700e-02],\n",
       "       [9.99486450e-01, 5.46639060e-05, 4.58875580e-04],\n",
       "       [1.51944300e-03, 4.71829180e-01, 5.26651440e-01],\n",
       "       [2.80685200e-03, 9.90029500e-01, 7.16361870e-03],\n",
       "       [9.98783770e-01, 1.32151740e-06, 1.21493030e-03],\n",
       "       [1.43027910e-04, 1.67334790e-02, 9.83123400e-01],\n",
       "       [2.97246650e-04, 2.05675240e-01, 7.94027570e-01],\n",
       "       [1.61231690e-03, 9.13251200e-01, 8.51364300e-02],\n",
       "       [1.51944300e-03, 4.71829180e-01, 5.26651440e-01],\n",
       "       [9.99595700e-01, 8.14329540e-05, 3.22883340e-04],\n",
       "       [3.44110300e-06, 1.78471880e-02, 9.82149300e-01],\n",
       "       [1.11922715e-02, 7.44084900e-03, 9.81366900e-01],\n",
       "       [9.99401330e-01, 5.05912930e-04, 9.28402950e-05],\n",
       "       [1.01757340e-03, 9.28869800e-01, 7.01125900e-02],\n",
       "       [9.96488450e-01, 5.44458100e-05, 3.45710850e-03],\n",
       "       [9.99520660e-01, 4.67457700e-04, 1.19516040e-05],\n",
       "       [5.43786000e-01, 1.27788110e-01, 3.28425880e-01],\n",
       "       [1.85210200e-05, 8.01505200e-03, 9.91966500e-01],\n",
       "       [1.18081360e-06, 9.99987000e-01, 1.17649330e-05],\n",
       "       [1.61231690e-03, 9.13251200e-01, 8.51364300e-02],\n",
       "       [6.01207100e-02, 9.34367950e-01, 5.51133040e-03],\n",
       "       [1.63674910e-06, 3.57112920e-02, 9.64287040e-01],\n",
       "       [9.99520660e-01, 4.67457700e-04, 1.19516040e-05],\n",
       "       [9.96488450e-01, 5.44458100e-05, 3.45710850e-03],\n",
       "       [5.99503800e-14, 1.50021630e-11, 1.00000000e+00],\n",
       "       [6.53835300e-06, 9.78036460e-01, 2.19570120e-02],\n",
       "       [4.16022450e-03, 4.22719540e-06, 9.95835540e-01],\n",
       "       [2.26507000e-03, 3.66732270e-01, 6.31002700e-01],\n",
       "       [9.15407360e-01, 5.15081920e-02, 3.30844630e-02],\n",
       "       [1.68582890e-04, 1.75332220e-01, 8.24499200e-01],\n",
       "       [9.97621830e-01, 5.90053900e-04, 1.78809660e-03],\n",
       "       [9.15407360e-01, 5.15081920e-02, 3.30844630e-02],\n",
       "       [9.97619700e-01, 2.16390400e-03, 2.16486270e-04],\n",
       "       [9.98264900e-09, 9.96560630e-01, 3.43932100e-03],\n",
       "       [8.39882800e-01, 1.18152320e-01, 4.19649150e-02],\n",
       "       [2.78182490e-08, 5.78781080e-08, 9.99999900e-01],\n",
       "       [2.89341550e-03, 8.20992230e-01, 1.76114320e-01],\n",
       "       [1.01757340e-03, 9.28869800e-01, 7.01125900e-02],\n",
       "       [9.97621830e-01, 5.90053900e-04, 1.78809660e-03],\n",
       "       [1.43771960e-02, 8.96326900e-01, 8.92959300e-02],\n",
       "       [6.93616800e-02, 8.67875640e-01, 6.27626400e-02],\n",
       "       [2.26507000e-03, 3.66732270e-01, 6.31002700e-01],\n",
       "       [9.60863000e-01, 5.03041000e-03, 3.41065900e-02],\n",
       "       [9.15407360e-01, 5.15081920e-02, 3.30844630e-02],\n",
       "       [1.44455560e-03, 6.97158840e-03, 9.91583800e-01],\n",
       "       [2.89341550e-03, 8.20992230e-01, 1.76114320e-01],\n",
       "       [1.08011830e-08, 6.07611030e-04, 9.99392400e-01],\n",
       "       [8.51244100e-08, 1.16416910e-08, 9.99999900e-01],\n",
       "       [8.39882800e-01, 1.18152320e-01, 4.19649150e-02],\n",
       "       [3.90816900e-07, 3.91955300e-07, 9.99999170e-01],\n",
       "       [2.89341550e-03, 8.20992230e-01, 1.76114320e-01],\n",
       "       [9.99891760e-01, 1.08277920e-04, 2.44118930e-11],\n",
       "       [1.36615230e-09, 5.00395250e-06, 9.99995000e-01],\n",
       "       [9.99486450e-01, 5.46639060e-05, 4.58875580e-04],\n",
       "       [1.76415210e-05, 9.94517150e-01, 5.46513600e-03],\n",
       "       [2.87945300e-03, 9.85412200e-01, 1.17083880e-02],\n",
       "       [9.95265360e-01, 1.51526980e-04, 4.58311940e-03],\n",
       "       [3.33569050e-01, 5.13363700e-01, 1.53067220e-01],\n",
       "       [9.98783770e-01, 1.32151740e-06, 1.21493030e-03],\n",
       "       [1.85252850e-03, 9.75368600e-01, 2.27788000e-02],\n",
       "       [1.31118480e-08, 4.04179900e-04, 9.99595800e-01],\n",
       "       [5.40599600e-10, 9.99792640e-01, 2.07386370e-04],\n",
       "       [2.61033720e-03, 9.76341100e-01, 2.10485200e-02],\n",
       "       [2.35596720e-04, 4.04770170e-01, 5.94994300e-01],\n",
       "       [1.91699590e-11, 8.34841800e-05, 9.99916550e-01],\n",
       "       [7.19830100e-13, 4.25570360e-07, 9.99999500e-01],\n",
       "       [2.89341550e-03, 8.20992230e-01, 1.76114320e-01],\n",
       "       [1.73687620e-07, 9.99229900e-01, 7.69940100e-04],\n",
       "       [7.13172200e-07, 5.41616320e-03, 9.94583100e-01],\n",
       "       [1.76415210e-05, 9.94517150e-01, 5.46513600e-03],\n",
       "       [2.66344760e-08, 1.48684110e-03, 9.98513160e-01],\n",
       "       [9.99486450e-01, 5.46639060e-05, 4.58875580e-04],\n",
       "       [1.15787360e-02, 6.38299800e-01, 3.50121380e-01],\n",
       "       [8.44683500e-01, 1.53558420e-01, 1.75806730e-03],\n",
       "       [1.56136610e-05, 9.00451500e-01, 9.95329700e-02],\n",
       "       [1.76415210e-05, 9.94517150e-01, 5.46513600e-03],\n",
       "       [6.86909200e-07, 4.30708330e-03, 9.95692200e-01],\n",
       "       [9.98264900e-09, 9.96560630e-01, 3.43932100e-03],\n",
       "       [9.60863000e-01, 5.03041000e-03, 3.41065900e-02],\n",
       "       [1.00871650e-03, 2.18172100e-02, 9.77174100e-01],\n",
       "       [2.53365700e-02, 9.67440840e-01, 7.22248850e-03],\n",
       "       [1.62720800e-04, 2.52149550e-01, 7.47687760e-01],\n",
       "       [9.97741940e-01, 1.52531310e-04, 2.10555530e-03],\n",
       "       [9.95249750e-01, 3.56939650e-04, 4.39325800e-03],\n",
       "       [1.74558620e-10, 2.47044840e-04, 9.99752940e-01],\n",
       "       [9.99891760e-01, 1.08277920e-04, 2.44118930e-11],\n",
       "       [5.08110350e-05, 8.59808700e-02, 9.13968300e-01],\n",
       "       [3.15146080e-07, 6.96071500e-08, 9.99999640e-01],\n",
       "       [5.43786000e-01, 1.27788110e-01, 3.28425880e-01],\n",
       "       [5.82230900e-04, 6.65156000e-01, 3.34261750e-01],\n",
       "       [1.18081360e-06, 9.99987000e-01, 1.17649330e-05],\n",
       "       [9.98885600e-01, 2.75721420e-04, 8.38716000e-04],\n",
       "       [9.98783770e-01, 1.32151740e-06, 1.21493030e-03],\n",
       "       [1.26502430e-04, 9.83325700e-01, 1.65478570e-02],\n",
       "       [2.42355860e-04, 2.11771060e-01, 7.87986600e-01],\n",
       "       [5.11786760e-03, 5.43041940e-01, 4.51840220e-01],\n",
       "       [5.41656800e-04, 6.15791560e-01, 3.83666800e-01],\n",
       "       [3.13641580e-07, 9.99695540e-01, 3.04183430e-04],\n",
       "       [1.18081360e-06, 9.99987000e-01, 1.17649330e-05],\n",
       "       [8.85746100e-09, 9.99647140e-01, 3.52862380e-04],\n",
       "       [7.71890200e-04, 9.52838240e-01, 4.63897660e-02],\n",
       "       [4.22349800e-04, 9.97404160e-01, 2.17344030e-03],\n",
       "       [1.01757340e-03, 9.28869800e-01, 7.01125900e-02],\n",
       "       [6.53835300e-06, 9.78036460e-01, 2.19570120e-02],\n",
       "       [6.96288700e-08, 1.55560060e-04, 9.99844300e-01]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob4 = df_proba4[df_proba4['phage']=='p11presabsSTCC_qual'].iloc[:,-3:]\n",
    "y_prob4 = y_prob4.to_numpy()\n",
    "y_prob4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9672772577971355"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo4 = rocauc_ovo(y_test_over, y_prob4, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9672772577971355"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr4 = rocauc_ovr(y_test_over, y_prob4, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9700645599728168"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovos = [ovo1, ovo2, ovo3, ovo4]\n",
    "np.mean(ovos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005234214597552001"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(ovos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9700645599728168"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovrs = [ovr1, ovr2, ovr3, ovr4]\n",
    "np.mean(ovrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005234214597552001"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(ovrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs = [acc_test_over, acc_test_over2, acc_test_over3, acc_test_over4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling test accuracy mean: 90.34%\n"
     ]
    }
   ],
   "source": [
    "mean = np.mean(accs)\n",
    "print('over-sampling test accuracy mean: %.2f%%' % (mean*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling test accuracy standard deviation: 0.00796955305432868\n"
     ]
    }
   ],
   "source": [
    "std = np.std(accs)\n",
    "print('over-sampling test accuracy standard deviation:', std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs_train = [np.mean(hist1_over.history['accuracy']), np.mean(hist1_over2.history['accuracy']), np.mean(hist1_over3.history['accuracy']),\n",
    "             np.mean(hist1_over4.history['accuracy'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy mean: 97.15%\n"
     ]
    }
   ],
   "source": [
    "mean_train = np.mean(accs_train)\n",
    "print('over-sampling train accuracy mean: %.2f%%' % (mean_train*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy standard deviation: 0.004326739\n"
     ]
    }
   ],
   "source": [
    "std_train = np.std(accs_train)\n",
    "print('over-sampling train accuracy standard deviation:', std_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
