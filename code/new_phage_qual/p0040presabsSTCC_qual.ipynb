{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This file implements neural networks before and after lasso selection for p0040presabsSTCC_qual with four replicates.\n",
    "## We compute the mean and standarad deviation of training and test accuracies.\n",
    "## We also compute the mean and standard deviation of AUC ROC values for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "import numpy as np\n",
    "seed(100)\n",
    "import tensorflow\n",
    "tensorflow.random.set_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(253, 353)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/p0040presabsSTCC_qual.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'Unnamed: 0':'id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      2\n",
       "1      0\n",
       "2      2\n",
       "3      2\n",
       "4      2\n",
       "      ..\n",
       "248    2\n",
       "249    1\n",
       "250    1\n",
       "251    2\n",
       "252    2\n",
       "Name: pheno, Length: 253, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pheno']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>TTTTTATATTGCGAAAAATAATTGGCGAACGAGGTAACTGGATACCTCATCCGCCAATTAAAATTTGTTAATTTAATAATTAAATATAAAGACGATTTAT</th>\n",
       "      <th>TTTTGTTCTTGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGTTTTAGTTTGATCTTTTGTTGTGT</th>\n",
       "      <th>TTTTACAAAAGAGGAAGCAGATAAACTTTATCAACCTATCGGTTCTTCGCAGCCGTCACTGAATATTTGGACAGGCAGTGAAACAGAATATAATTATTTG</th>\n",
       "      <th>TTTTAACTGTATGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGTTTTAGTTTGATCTTTTGTTGTGTCAGTACTTACAACTTTAGTAGAGTG</th>\n",
       "      <th>TTTGTTCTTGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGTTTTAGTTTGATCTTTTGTTGTGTC</th>\n",
       "      <th>TTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGTTTTAGTTTGATCTTTTGTTGTGTCAGTACTTACAACTTT</th>\n",
       "      <th>TTTGGACAGGCAGTGAAAC</th>\n",
       "      <th>TTTGAACTTTATTTTGTTCTTGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGTTTTAGTTTGATC</th>\n",
       "      <th>TTTCGCTGTTGCAACATCTTTAACAGGTGTTTGAACTTTATTTTGTTCTTGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGCTGTTTTAACT</th>\n",
       "      <th>...</th>\n",
       "      <th>group_8800</th>\n",
       "      <th>group_10077</th>\n",
       "      <th>group_1598</th>\n",
       "      <th>group_8093</th>\n",
       "      <th>group_8182</th>\n",
       "      <th>group_8892</th>\n",
       "      <th>group_9858</th>\n",
       "      <th>ST</th>\n",
       "      <th>CC</th>\n",
       "      <th>pheno</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>107</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>109</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>120335</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120337</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 353 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  \\\n",
       "0     107   \n",
       "1     109   \n",
       "2     115   \n",
       "3  120335   \n",
       "4  120337   \n",
       "\n",
       "   TTTTTATATTGCGAAAAATAATTGGCGAACGAGGTAACTGGATACCTCATCCGCCAATTAAAATTTGTTAATTTAATAATTAAATATAAAGACGATTTAT  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  1                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   TTTTGTTCTTGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGTTTTAGTTTGATCTTTTGTTGTGT  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   TTTTACAAAAGAGGAAGCAGATAAACTTTATCAACCTATCGGTTCTTCGCAGCCGTCACTGAATATTTGGACAGGCAGTGAAACAGAATATAATTATTTG  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  1                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   TTTTAACTGTATGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGTTTTAGTTTGATCTTTTGTTGTGTCAGTACTTACAACTTTAGTAGAGTG  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   TTTGTTCTTGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGTTTTAGTTTGATCTTTTGTTGTGTC  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   TTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGTTTTAGTTTGATCTTTTGTTGTGTCAGTACTTACAACTTT  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   TTTGGACAGGCAGTGAAAC  \\\n",
       "0                    0   \n",
       "1                    1   \n",
       "2                    1   \n",
       "3                    1   \n",
       "4                    1   \n",
       "\n",
       "   TTTGAACTTTATTTTGTTCTTGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGTTTTAGTTTGATC  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   TTTCGCTGTTGCAACATCTTTAACAGGTGTTTGAACTTTATTTTGTTCTTGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGCTGTTTTAACT  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   ...  group_8800  group_10077  group_1598  group_8093  group_8182  \\\n",
       "0  ...           0            0           0           0           0   \n",
       "1  ...           0            0           0           0           0   \n",
       "2  ...           0            0           0           0           0   \n",
       "3  ...           0            0           0           0           0   \n",
       "4  ...           0            0           0           0           0   \n",
       "\n",
       "   group_8892  group_9858  ST  CC  pheno  \n",
       "0           0           0   5   5      2  \n",
       "1           0           0   8   8      0  \n",
       "2           0           0   5   5      2  \n",
       "3           0           0   5   5      2  \n",
       "4           0           0   5   5      2  \n",
       "\n",
       "[5 rows x 353 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    95\n",
       "1    94\n",
       "0    64\n",
       "Name: pheno, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pheno'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.drop(columns=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(253, 352)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TTTTTATATTGCGAAAAATAATTGGCGAACGAGGTAACTGGATACCTCATCCGCCAATTAAAATTTGTTAATTTAATAATTAAATATAAAGACGATTTAT</th>\n",
       "      <th>TTTTGTTCTTGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGTTTTAGTTTGATCTTTTGTTGTGT</th>\n",
       "      <th>TTTTACAAAAGAGGAAGCAGATAAACTTTATCAACCTATCGGTTCTTCGCAGCCGTCACTGAATATTTGGACAGGCAGTGAAACAGAATATAATTATTTG</th>\n",
       "      <th>TTTTAACTGTATGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGTTTTAGTTTGATCTTTTGTTGTGTCAGTACTTACAACTTTAGTAGAGTG</th>\n",
       "      <th>TTTGTTCTTGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGTTTTAGTTTGATCTTTTGTTGTGTC</th>\n",
       "      <th>TTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGTTTTAGTTTGATCTTTTGTTGTGTCAGTACTTACAACTTT</th>\n",
       "      <th>TTTGGACAGGCAGTGAAAC</th>\n",
       "      <th>TTTGAACTTTATTTTGTTCTTGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGTTTTAGTTTGATC</th>\n",
       "      <th>TTTCGCTGTTGCAACATCTTTAACAGGTGTTTGAACTTTATTTTGTTCTTGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGCTGTTTTAACT</th>\n",
       "      <th>TTTCAGCGACTT</th>\n",
       "      <th>...</th>\n",
       "      <th>group_8800</th>\n",
       "      <th>group_10077</th>\n",
       "      <th>group_1598</th>\n",
       "      <th>group_8093</th>\n",
       "      <th>group_8182</th>\n",
       "      <th>group_8892</th>\n",
       "      <th>group_9858</th>\n",
       "      <th>ST</th>\n",
       "      <th>CC</th>\n",
       "      <th>pheno</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 352 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TTTTTATATTGCGAAAAATAATTGGCGAACGAGGTAACTGGATACCTCATCCGCCAATTAAAATTTGTTAATTTAATAATTAAATATAAAGACGATTTAT  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  1                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   TTTTGTTCTTGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGTTTTAGTTTGATCTTTTGTTGTGT  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   TTTTACAAAAGAGGAAGCAGATAAACTTTATCAACCTATCGGTTCTTCGCAGCCGTCACTGAATATTTGGACAGGCAGTGAAACAGAATATAATTATTTG  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  1                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   TTTTAACTGTATGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGTTTTAGTTTGATCTTTTGTTGTGTCAGTACTTACAACTTTAGTAGAGTG  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   TTTGTTCTTGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGTTTTAGTTTGATCTTTTGTTGTGTC  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   TTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGTTTTAGTTTGATCTTTTGTTGTGTCAGTACTTACAACTTT  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   TTTGGACAGGCAGTGAAAC  \\\n",
       "0                    0   \n",
       "1                    1   \n",
       "2                    1   \n",
       "3                    1   \n",
       "4                    1   \n",
       "\n",
       "   TTTGAACTTTATTTTGTTCTTGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGTTTTAGTTTGATC  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   TTTCGCTGTTGCAACATCTTTAACAGGTGTTTGAACTTTATTTTGTTCTTGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGCTGTTTTAACT  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   TTTCAGCGACTT  ...  group_8800  group_10077  group_1598  group_8093  \\\n",
       "0             0  ...           0            0           0           0   \n",
       "1             1  ...           0            0           0           0   \n",
       "2             1  ...           0            0           0           0   \n",
       "3             1  ...           0            0           0           0   \n",
       "4             1  ...           0            0           0           0   \n",
       "\n",
       "   group_8182  group_8892  group_9858  ST  CC  pheno  \n",
       "0           0           0           0   5   5      2  \n",
       "1           0           0           0   8   8      0  \n",
       "2           0           0           0   5   5      2  \n",
       "3           0           0           0   5   5      2  \n",
       "4           0           0           0   5   5      2  \n",
       "\n",
       "[5 rows x 352 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(253, 352) (253,)\n"
     ]
    }
   ],
   "source": [
    "X = df.loc[:, df.columns != 'pheno']\n",
    "y = df['pheno']\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# Fully-Connected Neural Network ################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.regularizers import l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=123,\n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = pd.DataFrame(X_test.iloc[:,0])\n",
    "dat['test'] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>NRS266</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>NRS272</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>CFBREBSa114</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>CFBREBSa119</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>NRS187</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>SR1287</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>CFBRSa50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>NRS196</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>NRS072</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  test\n",
       "221       NRS266     2\n",
       "177       NRS209     1\n",
       "223       NRS272     2\n",
       "49   CFBREBSa114     2\n",
       "53   CFBREBSa119     1\n",
       "..           ...   ...\n",
       "162       NRS187     1\n",
       "237       SR1287     0\n",
       "84      CFBRSa50     0\n",
       "168       NRS196     2\n",
       "124       NRS072     0\n",
       "\n",
       "[76 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(['id'], axis=1)\n",
    "X_test = X_test.drop(['id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### neural network on over-sampling data\n",
    "model1 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 177 samples, validate on 76 samples\n",
      "Epoch 1/100\n",
      "177/177 [==============================] - 0s 615us/step - loss: 23.5059 - accuracy: 0.2147 - val_loss: 12.7146 - val_accuracy: 0.1974\n",
      "Epoch 2/100\n",
      "177/177 [==============================] - 0s 96us/step - loss: 16.4104 - accuracy: 0.2881 - val_loss: 8.2075 - val_accuracy: 0.3158\n",
      "Epoch 3/100\n",
      "177/177 [==============================] - 0s 141us/step - loss: 11.3311 - accuracy: 0.3164 - val_loss: 5.3159 - val_accuracy: 0.3553\n",
      "Epoch 4/100\n",
      "177/177 [==============================] - 0s 152us/step - loss: 8.7051 - accuracy: 0.3446 - val_loss: 4.3300 - val_accuracy: 0.4211\n",
      "Epoch 5/100\n",
      "177/177 [==============================] - 0s 148us/step - loss: 7.2854 - accuracy: 0.4181 - val_loss: 3.0499 - val_accuracy: 0.4211\n",
      "Epoch 6/100\n",
      "177/177 [==============================] - 0s 143us/step - loss: 4.9591 - accuracy: 0.4068 - val_loss: 2.3373 - val_accuracy: 0.5000\n",
      "Epoch 7/100\n",
      "177/177 [==============================] - 0s 163us/step - loss: 3.7774 - accuracy: 0.4350 - val_loss: 1.7072 - val_accuracy: 0.5263\n",
      "Epoch 8/100\n",
      "177/177 [==============================] - 0s 158us/step - loss: 2.2145 - accuracy: 0.4576 - val_loss: 1.4845 - val_accuracy: 0.5789\n",
      "Epoch 9/100\n",
      "177/177 [==============================] - 0s 188us/step - loss: 1.6764 - accuracy: 0.5367 - val_loss: 1.5125 - val_accuracy: 0.5395\n",
      "Epoch 10/100\n",
      "177/177 [==============================] - 0s 148us/step - loss: 1.4643 - accuracy: 0.5367 - val_loss: 1.1779 - val_accuracy: 0.5263\n",
      "Epoch 11/100\n",
      "177/177 [==============================] - 0s 183us/step - loss: 1.2167 - accuracy: 0.5593 - val_loss: 1.0645 - val_accuracy: 0.5789\n",
      "Epoch 12/100\n",
      "177/177 [==============================] - 0s 174us/step - loss: 1.1227 - accuracy: 0.5706 - val_loss: 1.0149 - val_accuracy: 0.5395\n",
      "Epoch 13/100\n",
      "177/177 [==============================] - 0s 180us/step - loss: 0.9541 - accuracy: 0.6045 - val_loss: 0.9766 - val_accuracy: 0.5789\n",
      "Epoch 14/100\n",
      "177/177 [==============================] - 0s 158us/step - loss: 0.8602 - accuracy: 0.6497 - val_loss: 0.9629 - val_accuracy: 0.5658\n",
      "Epoch 15/100\n",
      "177/177 [==============================] - 0s 151us/step - loss: 0.8295 - accuracy: 0.6158 - val_loss: 0.9227 - val_accuracy: 0.5263\n",
      "Epoch 16/100\n",
      "177/177 [==============================] - 0s 182us/step - loss: 0.9105 - accuracy: 0.6497 - val_loss: 0.8838 - val_accuracy: 0.5395\n",
      "Epoch 17/100\n",
      "177/177 [==============================] - 0s 134us/step - loss: 0.7929 - accuracy: 0.6893 - val_loss: 0.8675 - val_accuracy: 0.5658\n",
      "Epoch 18/100\n",
      "177/177 [==============================] - 0s 173us/step - loss: 0.9496 - accuracy: 0.7006 - val_loss: 0.9008 - val_accuracy: 0.5789\n",
      "Epoch 19/100\n",
      "177/177 [==============================] - 0s 185us/step - loss: 0.9141 - accuracy: 0.6441 - val_loss: 0.9175 - val_accuracy: 0.5921\n",
      "Epoch 20/100\n",
      "177/177 [==============================] - 0s 230us/step - loss: 0.7758 - accuracy: 0.7345 - val_loss: 0.9257 - val_accuracy: 0.5395\n",
      "Epoch 21/100\n",
      "177/177 [==============================] - 0s 185us/step - loss: 0.8777 - accuracy: 0.7062 - val_loss: 0.8963 - val_accuracy: 0.5789\n",
      "Epoch 22/100\n",
      "177/177 [==============================] - 0s 285us/step - loss: 0.8122 - accuracy: 0.7119 - val_loss: 1.0554 - val_accuracy: 0.5658\n",
      "Epoch 23/100\n",
      "177/177 [==============================] - 0s 144us/step - loss: 0.8213 - accuracy: 0.7062 - val_loss: 0.9176 - val_accuracy: 0.5263\n",
      "Epoch 24/100\n",
      "177/177 [==============================] - 0s 140us/step - loss: 0.6941 - accuracy: 0.7232 - val_loss: 0.9013 - val_accuracy: 0.5263\n",
      "Epoch 25/100\n",
      "177/177 [==============================] - 0s 144us/step - loss: 0.7595 - accuracy: 0.7514 - val_loss: 0.9093 - val_accuracy: 0.5263\n",
      "Epoch 26/100\n",
      "177/177 [==============================] - 0s 102us/step - loss: 0.6872 - accuracy: 0.7458 - val_loss: 0.8535 - val_accuracy: 0.5263\n",
      "Epoch 27/100\n",
      "177/177 [==============================] - 0s 101us/step - loss: 0.6985 - accuracy: 0.7627 - val_loss: 0.8429 - val_accuracy: 0.5132\n",
      "Epoch 28/100\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.7124 - accuracy: 0.7684 - val_loss: 0.8499 - val_accuracy: 0.5789\n",
      "Epoch 29/100\n",
      "177/177 [==============================] - 0s 123us/step - loss: 0.9417 - accuracy: 0.7288 - val_loss: 0.9682 - val_accuracy: 0.6053\n",
      "Epoch 30/100\n",
      "177/177 [==============================] - 0s 112us/step - loss: 0.9571 - accuracy: 0.7740 - val_loss: 0.8959 - val_accuracy: 0.5658\n",
      "Epoch 31/100\n",
      "177/177 [==============================] - 0s 157us/step - loss: 0.9179 - accuracy: 0.7401 - val_loss: 0.8735 - val_accuracy: 0.6184\n",
      "Epoch 32/100\n",
      "177/177 [==============================] - 0s 96us/step - loss: 0.8968 - accuracy: 0.7797 - val_loss: 0.9765 - val_accuracy: 0.5658\n",
      "Epoch 33/100\n",
      "177/177 [==============================] - 0s 122us/step - loss: 0.8354 - accuracy: 0.7797 - val_loss: 0.8727 - val_accuracy: 0.6316\n",
      "Epoch 34/100\n",
      "177/177 [==============================] - 0s 87us/step - loss: 1.1240 - accuracy: 0.7797 - val_loss: 0.8207 - val_accuracy: 0.6053\n",
      "Epoch 35/100\n",
      "177/177 [==============================] - 0s 92us/step - loss: 0.9250 - accuracy: 0.7345 - val_loss: 1.1301 - val_accuracy: 0.5132\n",
      "Epoch 36/100\n",
      "177/177 [==============================] - 0s 95us/step - loss: 1.1792 - accuracy: 0.7119 - val_loss: 0.8473 - val_accuracy: 0.5658\n",
      "Epoch 37/100\n",
      "177/177 [==============================] - 0s 122us/step - loss: 0.6350 - accuracy: 0.7740 - val_loss: 0.9500 - val_accuracy: 0.5658\n",
      "Epoch 38/100\n",
      "177/177 [==============================] - 0s 122us/step - loss: 0.7818 - accuracy: 0.8079 - val_loss: 0.8304 - val_accuracy: 0.5789\n",
      "Epoch 39/100\n",
      "177/177 [==============================] - 0s 83us/step - loss: 0.6524 - accuracy: 0.7684 - val_loss: 0.8699 - val_accuracy: 0.6053\n",
      "Epoch 40/100\n",
      "177/177 [==============================] - 0s 152us/step - loss: 0.5509 - accuracy: 0.8588 - val_loss: 0.8778 - val_accuracy: 0.5789\n",
      "Epoch 41/100\n",
      "177/177 [==============================] - 0s 126us/step - loss: 0.5611 - accuracy: 0.8249 - val_loss: 0.8289 - val_accuracy: 0.5658\n",
      "Epoch 42/100\n",
      "177/177 [==============================] - 0s 134us/step - loss: 0.5688 - accuracy: 0.8588 - val_loss: 0.8501 - val_accuracy: 0.6053\n",
      "Epoch 43/100\n",
      "177/177 [==============================] - 0s 118us/step - loss: 0.5464 - accuracy: 0.8192 - val_loss: 0.8479 - val_accuracy: 0.6184\n",
      "Epoch 44/100\n",
      "177/177 [==============================] - 0s 104us/step - loss: 0.5168 - accuracy: 0.8475 - val_loss: 0.8193 - val_accuracy: 0.5789\n",
      "Epoch 45/100\n",
      "177/177 [==============================] - 0s 153us/step - loss: 0.5454 - accuracy: 0.8362 - val_loss: 0.8549 - val_accuracy: 0.5921\n",
      "Epoch 46/100\n",
      "177/177 [==============================] - 0s 166us/step - loss: 0.5512 - accuracy: 0.8814 - val_loss: 0.8918 - val_accuracy: 0.5658\n",
      "Epoch 47/100\n",
      "177/177 [==============================] - 0s 156us/step - loss: 0.5651 - accuracy: 0.8079 - val_loss: 0.8292 - val_accuracy: 0.6053\n",
      "Epoch 48/100\n",
      "177/177 [==============================] - 0s 166us/step - loss: 0.6423 - accuracy: 0.8249 - val_loss: 0.8041 - val_accuracy: 0.6447\n",
      "Epoch 49/100\n",
      "177/177 [==============================] - 0s 176us/step - loss: 0.5691 - accuracy: 0.8475 - val_loss: 0.8723 - val_accuracy: 0.6053\n",
      "Epoch 50/100\n",
      "177/177 [==============================] - 0s 131us/step - loss: 0.4983 - accuracy: 0.8701 - val_loss: 0.8247 - val_accuracy: 0.5921\n",
      "Epoch 51/100\n",
      "177/177 [==============================] - 0s 134us/step - loss: 0.5367 - accuracy: 0.8475 - val_loss: 0.8363 - val_accuracy: 0.5921\n",
      "Epoch 52/100\n",
      "177/177 [==============================] - 0s 143us/step - loss: 0.7087 - accuracy: 0.8475 - val_loss: 0.8863 - val_accuracy: 0.5921\n",
      "Epoch 53/100\n",
      "177/177 [==============================] - 0s 146us/step - loss: 0.5851 - accuracy: 0.8249 - val_loss: 0.8617 - val_accuracy: 0.5789\n",
      "Epoch 54/100\n",
      "177/177 [==============================] - 0s 170us/step - loss: 0.5953 - accuracy: 0.8531 - val_loss: 0.8244 - val_accuracy: 0.6053\n",
      "Epoch 55/100\n",
      "177/177 [==============================] - 0s 128us/step - loss: 0.5413 - accuracy: 0.8644 - val_loss: 1.1392 - val_accuracy: 0.5789\n",
      "Epoch 56/100\n",
      "177/177 [==============================] - 0s 137us/step - loss: 0.7434 - accuracy: 0.8475 - val_loss: 1.0180 - val_accuracy: 0.5658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "177/177 [==============================] - 0s 139us/step - loss: 0.5343 - accuracy: 0.8305 - val_loss: 0.8937 - val_accuracy: 0.5526\n",
      "Epoch 58/100\n",
      "177/177 [==============================] - 0s 130us/step - loss: 0.5373 - accuracy: 0.8475 - val_loss: 0.8582 - val_accuracy: 0.5921\n",
      "Epoch 59/100\n",
      "177/177 [==============================] - 0s 147us/step - loss: 0.5718 - accuracy: 0.8249 - val_loss: 1.1325 - val_accuracy: 0.5921\n",
      "Epoch 60/100\n",
      "177/177 [==============================] - 0s 97us/step - loss: 0.7553 - accuracy: 0.8249 - val_loss: 1.0689 - val_accuracy: 0.5789\n",
      "Epoch 61/100\n",
      "177/177 [==============================] - 0s 94us/step - loss: 0.5286 - accuracy: 0.8588 - val_loss: 0.8555 - val_accuracy: 0.5789\n",
      "Epoch 62/100\n",
      "177/177 [==============================] - 0s 99us/step - loss: 0.4633 - accuracy: 0.8644 - val_loss: 0.8326 - val_accuracy: 0.6184\n",
      "Epoch 63/100\n",
      "177/177 [==============================] - 0s 110us/step - loss: 0.4666 - accuracy: 0.8644 - val_loss: 0.8478 - val_accuracy: 0.6184\n",
      "Epoch 64/100\n",
      "177/177 [==============================] - 0s 110us/step - loss: 0.4194 - accuracy: 0.8983 - val_loss: 0.8275 - val_accuracy: 0.6053\n",
      "Epoch 65/100\n",
      "177/177 [==============================] - 0s 97us/step - loss: 0.4296 - accuracy: 0.8757 - val_loss: 0.8506 - val_accuracy: 0.5921\n",
      "Epoch 66/100\n",
      "177/177 [==============================] - 0s 102us/step - loss: 0.4264 - accuracy: 0.8644 - val_loss: 0.8400 - val_accuracy: 0.6053\n",
      "Epoch 67/100\n",
      "177/177 [==============================] - 0s 97us/step - loss: 0.4053 - accuracy: 0.8870 - val_loss: 0.8437 - val_accuracy: 0.6053\n",
      "Epoch 68/100\n",
      "177/177 [==============================] - 0s 122us/step - loss: 0.4360 - accuracy: 0.8870 - val_loss: 0.8238 - val_accuracy: 0.6316\n",
      "Epoch 69/100\n",
      "177/177 [==============================] - 0s 105us/step - loss: 0.4456 - accuracy: 0.8814 - val_loss: 0.8667 - val_accuracy: 0.6184\n",
      "Epoch 70/100\n",
      "177/177 [==============================] - 0s 91us/step - loss: 0.4027 - accuracy: 0.9096 - val_loss: 0.8854 - val_accuracy: 0.6053\n",
      "Epoch 71/100\n",
      "177/177 [==============================] - 0s 109us/step - loss: 0.4233 - accuracy: 0.8927 - val_loss: 0.8682 - val_accuracy: 0.6053\n",
      "Epoch 72/100\n",
      "177/177 [==============================] - 0s 167us/step - loss: 0.3760 - accuracy: 0.9209 - val_loss: 0.8944 - val_accuracy: 0.5789\n",
      "Epoch 73/100\n",
      "177/177 [==============================] - 0s 225us/step - loss: 0.3817 - accuracy: 0.9153 - val_loss: 0.8369 - val_accuracy: 0.6447\n",
      "Epoch 74/100\n",
      "177/177 [==============================] - 0s 163us/step - loss: 0.4469 - accuracy: 0.8983 - val_loss: 0.8860 - val_accuracy: 0.5921\n",
      "Epoch 75/100\n",
      "177/177 [==============================] - 0s 199us/step - loss: 0.5769 - accuracy: 0.8927 - val_loss: 1.1058 - val_accuracy: 0.5658\n",
      "Epoch 76/100\n",
      "177/177 [==============================] - 0s 168us/step - loss: 0.4668 - accuracy: 0.9096 - val_loss: 0.8705 - val_accuracy: 0.6316\n",
      "Epoch 77/100\n",
      "177/177 [==============================] - 0s 190us/step - loss: 0.4984 - accuracy: 0.8757 - val_loss: 0.8768 - val_accuracy: 0.6184\n",
      "Epoch 78/100\n",
      "177/177 [==============================] - 0s 192us/step - loss: 0.4723 - accuracy: 0.8701 - val_loss: 1.0274 - val_accuracy: 0.5395\n",
      "Epoch 79/100\n",
      "177/177 [==============================] - 0s 177us/step - loss: 0.4259 - accuracy: 0.9040 - val_loss: 0.9233 - val_accuracy: 0.5789\n",
      "Epoch 80/100\n",
      "177/177 [==============================] - 0s 121us/step - loss: 0.4774 - accuracy: 0.8814 - val_loss: 0.8688 - val_accuracy: 0.5921\n",
      "Epoch 81/100\n",
      "177/177 [==============================] - 0s 148us/step - loss: 0.4859 - accuracy: 0.8927 - val_loss: 1.0289 - val_accuracy: 0.5526\n",
      "Epoch 82/100\n",
      "177/177 [==============================] - 0s 157us/step - loss: 0.4531 - accuracy: 0.8757 - val_loss: 0.8762 - val_accuracy: 0.6053\n",
      "Epoch 83/100\n",
      "177/177 [==============================] - 0s 217us/step - loss: 0.4254 - accuracy: 0.8757 - val_loss: 0.9418 - val_accuracy: 0.5921\n",
      "Epoch 84/100\n",
      "177/177 [==============================] - 0s 169us/step - loss: 0.6151 - accuracy: 0.8927 - val_loss: 0.9126 - val_accuracy: 0.6053\n",
      "Epoch 85/100\n",
      "177/177 [==============================] - 0s 187us/step - loss: 0.4704 - accuracy: 0.8927 - val_loss: 0.8742 - val_accuracy: 0.6053\n",
      "Epoch 86/100\n",
      "177/177 [==============================] - 0s 166us/step - loss: 0.4072 - accuracy: 0.9153 - val_loss: 0.9222 - val_accuracy: 0.6053\n",
      "Epoch 87/100\n",
      "177/177 [==============================] - 0s 143us/step - loss: 0.3879 - accuracy: 0.9153 - val_loss: 0.9126 - val_accuracy: 0.6053\n",
      "Epoch 88/100\n",
      "177/177 [==============================] - 0s 110us/step - loss: 0.5295 - accuracy: 0.9040 - val_loss: 1.0130 - val_accuracy: 0.5658\n",
      "Epoch 89/100\n",
      "177/177 [==============================] - 0s 114us/step - loss: 0.4180 - accuracy: 0.8870 - val_loss: 0.9491 - val_accuracy: 0.6184\n",
      "Epoch 90/100\n",
      "177/177 [==============================] - 0s 112us/step - loss: 0.5548 - accuracy: 0.8757 - val_loss: 0.9030 - val_accuracy: 0.6053\n",
      "Epoch 91/100\n",
      "177/177 [==============================] - 0s 167us/step - loss: 0.3977 - accuracy: 0.8983 - val_loss: 1.0242 - val_accuracy: 0.5658\n",
      "Epoch 92/100\n",
      "177/177 [==============================] - 0s 215us/step - loss: 0.3814 - accuracy: 0.9153 - val_loss: 0.9435 - val_accuracy: 0.6053\n",
      "Epoch 93/100\n",
      "177/177 [==============================] - 0s 178us/step - loss: 0.3621 - accuracy: 0.9040 - val_loss: 0.8561 - val_accuracy: 0.6184\n",
      "Epoch 94/100\n",
      "177/177 [==============================] - 0s 119us/step - loss: 0.3621 - accuracy: 0.9435 - val_loss: 0.9192 - val_accuracy: 0.6184\n",
      "Epoch 95/100\n",
      "177/177 [==============================] - 0s 118us/step - loss: 0.3330 - accuracy: 0.9209 - val_loss: 0.9734 - val_accuracy: 0.5789\n",
      "Epoch 96/100\n",
      "177/177 [==============================] - 0s 133us/step - loss: 0.3560 - accuracy: 0.9322 - val_loss: 0.8875 - val_accuracy: 0.5658\n",
      "Epoch 97/100\n",
      "177/177 [==============================] - 0s 131us/step - loss: 0.3636 - accuracy: 0.9209 - val_loss: 0.8899 - val_accuracy: 0.5789\n",
      "Epoch 98/100\n",
      "177/177 [==============================] - 0s 152us/step - loss: 0.4232 - accuracy: 0.9209 - val_loss: 0.9397 - val_accuracy: 0.5789\n",
      "Epoch 99/100\n",
      "177/177 [==============================] - 0s 157us/step - loss: 0.3596 - accuracy: 0.9209 - val_loss: 0.9114 - val_accuracy: 0.5921\n",
      "Epoch 100/100\n",
      "177/177 [==============================] - 0s 177us/step - loss: 0.3170 - accuracy: 0.9435 - val_loss: 0.9627 - val_accuracy: 0.5789\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a3d208208>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(X_train, y_train,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 0s 79us/step\n",
      "test accuracy: 61.84%\n"
     ]
    }
   ],
   "source": [
    "acc_test1 = model1.evaluate(X_test, y_test)[1]\n",
    "print('test accuracy: %.2f%%' % (acc_test1*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 2, 2, 0, 2, 1, 2, 2, 1, 2, 0, 1, 1, 2, 0, 1, 1, 0, 2, 2,\n",
       "       1, 1, 2, 1, 2, 2, 2, 1, 1, 0, 2, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 0,\n",
       "       2, 2, 1, 1, 0, 2, 0, 1, 0, 2, 1, 0, 2, 2, 0, 2, 0, 1, 0, 1, 2, 0,\n",
       "       2, 0, 1, 2, 1, 1, 1, 0, 2, 0])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model1.predict_classes(X_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>NRS266</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>NRS272</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>CFBREBSa114</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>CFBREBSa119</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>NRS187</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>SR1287</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>CFBRSa50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>NRS196</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>NRS072</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  test  pred\n",
       "221       NRS266     2     1\n",
       "177       NRS209     1     1\n",
       "223       NRS272     2     1\n",
       "49   CFBREBSa114     2     2\n",
       "53   CFBREBSa119     1     2\n",
       "..           ...   ...   ...\n",
       "162       NRS187     1     1\n",
       "237       SR1287     0     1\n",
       "84      CFBRSa50     0     0\n",
       "168       NRS196     2     2\n",
       "124       NRS072     0     0\n",
       "\n",
       "[76 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat['pred'] = pred\n",
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba1 = model1.predict_proba(X_test)\n",
    "dat_proba1 = pd.DataFrame(proba1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.621460</td>\n",
       "      <td>0.378507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.023729</td>\n",
       "      <td>0.973869</td>\n",
       "      <td>0.002402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.020596</td>\n",
       "      <td>0.897287</td>\n",
       "      <td>0.082117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.022055</td>\n",
       "      <td>0.257970</td>\n",
       "      <td>0.719975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.003793</td>\n",
       "      <td>0.053047</td>\n",
       "      <td>0.943160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.216843</td>\n",
       "      <td>0.568123</td>\n",
       "      <td>0.215034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.418802</td>\n",
       "      <td>0.553160</td>\n",
       "      <td>0.028038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.948100</td>\n",
       "      <td>0.035031</td>\n",
       "      <td>0.016869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.000964</td>\n",
       "      <td>0.039095</td>\n",
       "      <td>0.959940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.795570</td>\n",
       "      <td>0.187358</td>\n",
       "      <td>0.017072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2\n",
       "0   0.000033  0.621460  0.378507\n",
       "1   0.023729  0.973869  0.002402\n",
       "2   0.020596  0.897287  0.082117\n",
       "3   0.022055  0.257970  0.719975\n",
       "4   0.003793  0.053047  0.943160\n",
       "..       ...       ...       ...\n",
       "71  0.216843  0.568123  0.215034\n",
       "72  0.418802  0.553160  0.028038\n",
       "73  0.948100  0.035031  0.016869\n",
       "74  0.000964  0.039095  0.959940\n",
       "75  0.795570  0.187358  0.017072\n",
       "\n",
       "[76 rows x 3 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba1.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba1.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/1p40pST.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 177 samples, validate on 76 samples\n",
      "Epoch 1/100\n",
      "177/177 [==============================] - 0s 151us/step - loss: 0.2791 - accuracy: 0.9322 - val_loss: 0.9579 - val_accuracy: 0.6053\n",
      "Epoch 2/100\n",
      "177/177 [==============================] - 0s 139us/step - loss: 0.2981 - accuracy: 0.9266 - val_loss: 0.9306 - val_accuracy: 0.6316\n",
      "Epoch 3/100\n",
      "177/177 [==============================] - 0s 177us/step - loss: 0.3080 - accuracy: 0.9322 - val_loss: 0.9278 - val_accuracy: 0.6184\n",
      "Epoch 4/100\n",
      "177/177 [==============================] - 0s 143us/step - loss: 0.3252 - accuracy: 0.9322 - val_loss: 0.9654 - val_accuracy: 0.6053\n",
      "Epoch 5/100\n",
      "177/177 [==============================] - 0s 133us/step - loss: 0.2661 - accuracy: 0.9266 - val_loss: 1.0083 - val_accuracy: 0.5921\n",
      "Epoch 6/100\n",
      "177/177 [==============================] - 0s 153us/step - loss: 0.2927 - accuracy: 0.9322 - val_loss: 0.9266 - val_accuracy: 0.6316\n",
      "Epoch 7/100\n",
      "177/177 [==============================] - 0s 124us/step - loss: 0.2967 - accuracy: 0.9435 - val_loss: 0.9649 - val_accuracy: 0.6184\n",
      "Epoch 8/100\n",
      "177/177 [==============================] - 0s 167us/step - loss: 0.2818 - accuracy: 0.9379 - val_loss: 0.9416 - val_accuracy: 0.6053\n",
      "Epoch 9/100\n",
      "177/177 [==============================] - 0s 158us/step - loss: 0.3258 - accuracy: 0.9492 - val_loss: 0.9639 - val_accuracy: 0.6053\n",
      "Epoch 10/100\n",
      "177/177 [==============================] - 0s 137us/step - loss: 0.3018 - accuracy: 0.9379 - val_loss: 1.0237 - val_accuracy: 0.6053\n",
      "Epoch 11/100\n",
      "177/177 [==============================] - 0s 241us/step - loss: 0.2744 - accuracy: 0.9379 - val_loss: 0.9473 - val_accuracy: 0.6316\n",
      "Epoch 12/100\n",
      "177/177 [==============================] - 0s 123us/step - loss: 0.4314 - accuracy: 0.9322 - val_loss: 1.0545 - val_accuracy: 0.5789\n",
      "Epoch 13/100\n",
      "177/177 [==============================] - 0s 125us/step - loss: 0.4248 - accuracy: 0.9040 - val_loss: 1.1266 - val_accuracy: 0.5658\n",
      "Epoch 14/100\n",
      "177/177 [==============================] - 0s 127us/step - loss: 0.4636 - accuracy: 0.9209 - val_loss: 0.9620 - val_accuracy: 0.6447\n",
      "Epoch 15/100\n",
      "177/177 [==============================] - 0s 131us/step - loss: 0.2514 - accuracy: 0.9435 - val_loss: 1.1081 - val_accuracy: 0.6053\n",
      "Epoch 16/100\n",
      "177/177 [==============================] - 0s 129us/step - loss: 0.3485 - accuracy: 0.9322 - val_loss: 0.9837 - val_accuracy: 0.6053\n",
      "Epoch 17/100\n",
      "177/177 [==============================] - 0s 146us/step - loss: 0.3449 - accuracy: 0.9209 - val_loss: 0.9700 - val_accuracy: 0.6184\n",
      "Epoch 18/100\n",
      "177/177 [==============================] - 0s 138us/step - loss: 0.3442 - accuracy: 0.9322 - val_loss: 1.0397 - val_accuracy: 0.5921\n",
      "Epoch 19/100\n",
      "177/177 [==============================] - 0s 141us/step - loss: 0.2401 - accuracy: 0.9492 - val_loss: 0.9803 - val_accuracy: 0.6053\n",
      "Epoch 20/100\n",
      "177/177 [==============================] - 0s 138us/step - loss: 0.2463 - accuracy: 0.9322 - val_loss: 0.9801 - val_accuracy: 0.6184\n",
      "Epoch 21/100\n",
      "177/177 [==============================] - 0s 120us/step - loss: 0.2316 - accuracy: 0.9492 - val_loss: 0.9545 - val_accuracy: 0.6184\n",
      "Epoch 22/100\n",
      "177/177 [==============================] - 0s 149us/step - loss: 0.2331 - accuracy: 0.9548 - val_loss: 1.0246 - val_accuracy: 0.6053\n",
      "Epoch 23/100\n",
      "177/177 [==============================] - 0s 118us/step - loss: 0.2957 - accuracy: 0.9322 - val_loss: 1.0249 - val_accuracy: 0.5921\n",
      "Epoch 24/100\n",
      "177/177 [==============================] - 0s 165us/step - loss: 0.3396 - accuracy: 0.9379 - val_loss: 0.9618 - val_accuracy: 0.6316\n",
      "Epoch 25/100\n",
      "177/177 [==============================] - 0s 131us/step - loss: 0.2372 - accuracy: 0.9435 - val_loss: 1.1394 - val_accuracy: 0.5921\n",
      "Epoch 26/100\n",
      "177/177 [==============================] - 0s 195us/step - loss: 0.3628 - accuracy: 0.9435 - val_loss: 1.0438 - val_accuracy: 0.6053\n",
      "Epoch 27/100\n",
      "177/177 [==============================] - 0s 255us/step - loss: 0.2715 - accuracy: 0.9492 - val_loss: 0.9641 - val_accuracy: 0.6316\n",
      "Epoch 28/100\n",
      "177/177 [==============================] - 0s 161us/step - loss: 0.2929 - accuracy: 0.9492 - val_loss: 1.1033 - val_accuracy: 0.6316\n",
      "Epoch 29/100\n",
      "177/177 [==============================] - 0s 160us/step - loss: 0.3160 - accuracy: 0.9435 - val_loss: 1.0153 - val_accuracy: 0.6053\n",
      "Epoch 30/100\n",
      "177/177 [==============================] - 0s 157us/step - loss: 0.2721 - accuracy: 0.9492 - val_loss: 1.0535 - val_accuracy: 0.6053\n",
      "Epoch 31/100\n",
      "177/177 [==============================] - 0s 132us/step - loss: 0.3012 - accuracy: 0.9492 - val_loss: 0.9861 - val_accuracy: 0.6316\n",
      "Epoch 32/100\n",
      "177/177 [==============================] - 0s 124us/step - loss: 0.2110 - accuracy: 0.9605 - val_loss: 1.0262 - val_accuracy: 0.6184\n",
      "Epoch 33/100\n",
      "177/177 [==============================] - 0s 190us/step - loss: 0.2225 - accuracy: 0.9605 - val_loss: 0.9631 - val_accuracy: 0.6447\n",
      "Epoch 34/100\n",
      "177/177 [==============================] - 0s 144us/step - loss: 0.3232 - accuracy: 0.9435 - val_loss: 1.0332 - val_accuracy: 0.6053\n",
      "Epoch 35/100\n",
      "177/177 [==============================] - 0s 140us/step - loss: 0.2979 - accuracy: 0.9548 - val_loss: 1.0244 - val_accuracy: 0.6053\n",
      "Epoch 36/100\n",
      "177/177 [==============================] - 0s 176us/step - loss: 0.2046 - accuracy: 0.9605 - val_loss: 1.0038 - val_accuracy: 0.6184\n",
      "Epoch 37/100\n",
      "177/177 [==============================] - 0s 159us/step - loss: 0.3023 - accuracy: 0.9492 - val_loss: 1.0896 - val_accuracy: 0.6316\n",
      "Epoch 38/100\n",
      "177/177 [==============================] - 0s 140us/step - loss: 0.3158 - accuracy: 0.9548 - val_loss: 1.0805 - val_accuracy: 0.6053\n",
      "Epoch 39/100\n",
      "177/177 [==============================] - 0s 129us/step - loss: 0.3341 - accuracy: 0.9096 - val_loss: 1.0426 - val_accuracy: 0.6184\n",
      "Epoch 40/100\n",
      "177/177 [==============================] - 0s 108us/step - loss: 0.4491 - accuracy: 0.9209 - val_loss: 1.1461 - val_accuracy: 0.6316\n",
      "Epoch 41/100\n",
      "177/177 [==============================] - 0s 97us/step - loss: 0.2994 - accuracy: 0.9322 - val_loss: 1.1010 - val_accuracy: 0.6316\n",
      "Epoch 42/100\n",
      "177/177 [==============================] - 0s 124us/step - loss: 0.2404 - accuracy: 0.9379 - val_loss: 1.0861 - val_accuracy: 0.5921\n",
      "Epoch 43/100\n",
      "177/177 [==============================] - 0s 117us/step - loss: 0.2200 - accuracy: 0.9492 - val_loss: 1.0399 - val_accuracy: 0.6053\n",
      "Epoch 44/100\n",
      "177/177 [==============================] - 0s 136us/step - loss: 0.2033 - accuracy: 0.9718 - val_loss: 1.1825 - val_accuracy: 0.6316\n",
      "Epoch 45/100\n",
      "177/177 [==============================] - 0s 258us/step - loss: 0.3082 - accuracy: 0.9379 - val_loss: 1.0593 - val_accuracy: 0.6184\n",
      "Epoch 46/100\n",
      "177/177 [==============================] - 0s 320us/step - loss: 0.2596 - accuracy: 0.9548 - val_loss: 1.0940 - val_accuracy: 0.6053\n",
      "Epoch 47/100\n",
      "177/177 [==============================] - 0s 164us/step - loss: 0.2153 - accuracy: 0.9605 - val_loss: 1.0204 - val_accuracy: 0.6316\n",
      "Epoch 48/100\n",
      "177/177 [==============================] - 0s 217us/step - loss: 0.2407 - accuracy: 0.9605 - val_loss: 1.0887 - val_accuracy: 0.6184\n",
      "Epoch 49/100\n",
      "177/177 [==============================] - 0s 110us/step - loss: 0.2512 - accuracy: 0.9435 - val_loss: 1.0485 - val_accuracy: 0.6053\n",
      "Epoch 50/100\n",
      "177/177 [==============================] - 0s 246us/step - loss: 0.2040 - accuracy: 0.9548 - val_loss: 1.0232 - val_accuracy: 0.6184\n",
      "Epoch 51/100\n",
      "177/177 [==============================] - 0s 211us/step - loss: 0.2115 - accuracy: 0.9548 - val_loss: 1.1247 - val_accuracy: 0.6053\n",
      "Epoch 52/100\n",
      "177/177 [==============================] - 0s 188us/step - loss: 0.2535 - accuracy: 0.9492 - val_loss: 1.0464 - val_accuracy: 0.5921\n",
      "Epoch 53/100\n",
      "177/177 [==============================] - 0s 159us/step - loss: 0.2409 - accuracy: 0.9492 - val_loss: 1.0691 - val_accuracy: 0.5921\n",
      "Epoch 54/100\n",
      "177/177 [==============================] - 0s 196us/step - loss: 0.2492 - accuracy: 0.9492 - val_loss: 1.0947 - val_accuracy: 0.6053\n",
      "Epoch 55/100\n",
      "177/177 [==============================] - 0s 145us/step - loss: 0.1767 - accuracy: 0.9718 - val_loss: 1.0230 - val_accuracy: 0.6184\n",
      "Epoch 56/100\n",
      "177/177 [==============================] - 0s 151us/step - loss: 0.2477 - accuracy: 0.9492 - val_loss: 1.0825 - val_accuracy: 0.6053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "177/177 [==============================] - 0s 179us/step - loss: 0.2945 - accuracy: 0.9492 - val_loss: 1.1570 - val_accuracy: 0.6184\n",
      "Epoch 58/100\n",
      "177/177 [==============================] - 0s 269us/step - loss: 0.1739 - accuracy: 0.9492 - val_loss: 1.0361 - val_accuracy: 0.6184\n",
      "Epoch 59/100\n",
      "177/177 [==============================] - 0s 182us/step - loss: 0.2724 - accuracy: 0.9548 - val_loss: 1.0872 - val_accuracy: 0.5921\n",
      "Epoch 60/100\n",
      "177/177 [==============================] - 0s 169us/step - loss: 0.1871 - accuracy: 0.9492 - val_loss: 1.1286 - val_accuracy: 0.6184\n",
      "Epoch 61/100\n",
      "177/177 [==============================] - 0s 176us/step - loss: 0.2718 - accuracy: 0.9435 - val_loss: 1.0751 - val_accuracy: 0.6053\n",
      "Epoch 62/100\n",
      "177/177 [==============================] - 0s 198us/step - loss: 0.2000 - accuracy: 0.9492 - val_loss: 1.4353 - val_accuracy: 0.5921\n",
      "Epoch 63/100\n",
      "177/177 [==============================] - 0s 504us/step - loss: 0.4476 - accuracy: 0.9266 - val_loss: 1.2447 - val_accuracy: 0.5658\n",
      "Epoch 64/100\n",
      "177/177 [==============================] - 0s 118us/step - loss: 0.3082 - accuracy: 0.9492 - val_loss: 1.0701 - val_accuracy: 0.6579\n",
      "Epoch 65/100\n",
      "177/177 [==============================] - 0s 150us/step - loss: 0.2426 - accuracy: 0.9548 - val_loss: 1.2500 - val_accuracy: 0.6184\n",
      "Epoch 66/100\n",
      "177/177 [==============================] - 0s 140us/step - loss: 0.3226 - accuracy: 0.9492 - val_loss: 1.1114 - val_accuracy: 0.6053\n",
      "Epoch 67/100\n",
      "177/177 [==============================] - 0s 111us/step - loss: 0.2781 - accuracy: 0.9435 - val_loss: 1.0618 - val_accuracy: 0.6447\n",
      "Epoch 68/100\n",
      "177/177 [==============================] - 0s 158us/step - loss: 0.1920 - accuracy: 0.9605 - val_loss: 1.1614 - val_accuracy: 0.6184\n",
      "Epoch 69/100\n",
      "177/177 [==============================] - 0s 137us/step - loss: 0.2584 - accuracy: 0.9435 - val_loss: 1.1348 - val_accuracy: 0.5789\n",
      "Epoch 70/100\n",
      "177/177 [==============================] - 0s 120us/step - loss: 0.2326 - accuracy: 0.9492 - val_loss: 1.0638 - val_accuracy: 0.6184\n",
      "Epoch 71/100\n",
      "177/177 [==============================] - 0s 123us/step - loss: 0.2078 - accuracy: 0.9661 - val_loss: 1.1536 - val_accuracy: 0.6316\n",
      "Epoch 72/100\n",
      "177/177 [==============================] - 0s 120us/step - loss: 0.2323 - accuracy: 0.9605 - val_loss: 1.1104 - val_accuracy: 0.6053\n",
      "Epoch 73/100\n",
      "177/177 [==============================] - 0s 152us/step - loss: 0.1718 - accuracy: 0.9435 - val_loss: 1.0755 - val_accuracy: 0.6184\n",
      "Epoch 74/100\n",
      "177/177 [==============================] - 0s 106us/step - loss: 0.3003 - accuracy: 0.9379 - val_loss: 1.1180 - val_accuracy: 0.5789\n",
      "Epoch 75/100\n",
      "177/177 [==============================] - 0s 105us/step - loss: 0.2079 - accuracy: 0.9548 - val_loss: 1.1787 - val_accuracy: 0.6316\n",
      "Epoch 76/100\n",
      "177/177 [==============================] - 0s 104us/step - loss: 0.3446 - accuracy: 0.9492 - val_loss: 1.1482 - val_accuracy: 0.6184\n",
      "Epoch 77/100\n",
      "177/177 [==============================] - 0s 104us/step - loss: 0.3561 - accuracy: 0.9379 - val_loss: 1.0636 - val_accuracy: 0.6316\n",
      "Epoch 78/100\n",
      "177/177 [==============================] - 0s 99us/step - loss: 0.4052 - accuracy: 0.9322 - val_loss: 1.1881 - val_accuracy: 0.6184\n",
      "Epoch 79/100\n",
      "177/177 [==============================] - 0s 116us/step - loss: 0.3238 - accuracy: 0.9209 - val_loss: 1.3091 - val_accuracy: 0.5395\n",
      "Epoch 80/100\n",
      "177/177 [==============================] - 0s 122us/step - loss: 0.4056 - accuracy: 0.9153 - val_loss: 1.1645 - val_accuracy: 0.6053\n",
      "Epoch 81/100\n",
      "177/177 [==============================] - 0s 99us/step - loss: 0.1810 - accuracy: 0.9661 - val_loss: 1.1774 - val_accuracy: 0.5921\n",
      "Epoch 82/100\n",
      "177/177 [==============================] - 0s 130us/step - loss: 0.2660 - accuracy: 0.9435 - val_loss: 1.1679 - val_accuracy: 0.6184\n",
      "Epoch 83/100\n",
      "177/177 [==============================] - 0s 106us/step - loss: 0.4061 - accuracy: 0.9379 - val_loss: 1.1391 - val_accuracy: 0.6053\n",
      "Epoch 84/100\n",
      "177/177 [==============================] - 0s 127us/step - loss: 0.2091 - accuracy: 0.9605 - val_loss: 1.2036 - val_accuracy: 0.5658\n",
      "Epoch 85/100\n",
      "177/177 [==============================] - 0s 121us/step - loss: 0.2116 - accuracy: 0.9379 - val_loss: 1.1542 - val_accuracy: 0.6184\n",
      "Epoch 86/100\n",
      "177/177 [==============================] - 0s 136us/step - loss: 0.1640 - accuracy: 0.9605 - val_loss: 1.1119 - val_accuracy: 0.6316\n",
      "Epoch 87/100\n",
      "177/177 [==============================] - 0s 241us/step - loss: 0.2221 - accuracy: 0.9492 - val_loss: 1.2027 - val_accuracy: 0.6053\n",
      "Epoch 88/100\n",
      "177/177 [==============================] - 0s 142us/step - loss: 0.2275 - accuracy: 0.9322 - val_loss: 1.1390 - val_accuracy: 0.6053\n",
      "Epoch 89/100\n",
      "177/177 [==============================] - 0s 122us/step - loss: 0.1788 - accuracy: 0.9605 - val_loss: 1.1332 - val_accuracy: 0.6053\n",
      "Epoch 90/100\n",
      "177/177 [==============================] - 0s 125us/step - loss: 0.1561 - accuracy: 0.9661 - val_loss: 1.1773 - val_accuracy: 0.5789\n",
      "Epoch 91/100\n",
      "177/177 [==============================] - 0s 143us/step - loss: 0.1816 - accuracy: 0.9548 - val_loss: 1.1780 - val_accuracy: 0.6184\n",
      "Epoch 92/100\n",
      "177/177 [==============================] - 0s 138us/step - loss: 0.1562 - accuracy: 0.9548 - val_loss: 1.1276 - val_accuracy: 0.6447\n",
      "Epoch 93/100\n",
      "177/177 [==============================] - 0s 160us/step - loss: 0.1898 - accuracy: 0.9605 - val_loss: 1.1921 - val_accuracy: 0.6053\n",
      "Epoch 94/100\n",
      "177/177 [==============================] - 0s 107us/step - loss: 0.2112 - accuracy: 0.9492 - val_loss: 1.1686 - val_accuracy: 0.5921\n",
      "Epoch 95/100\n",
      "177/177 [==============================] - 0s 101us/step - loss: 0.1431 - accuracy: 0.9661 - val_loss: 1.1302 - val_accuracy: 0.6184\n",
      "Epoch 96/100\n",
      "177/177 [==============================] - 0s 104us/step - loss: 0.1509 - accuracy: 0.9661 - val_loss: 1.2152 - val_accuracy: 0.6184\n",
      "Epoch 97/100\n",
      "177/177 [==============================] - 0s 114us/step - loss: 0.2006 - accuracy: 0.9661 - val_loss: 1.1606 - val_accuracy: 0.6184\n",
      "Epoch 98/100\n",
      "177/177 [==============================] - 0s 108us/step - loss: 0.1468 - accuracy: 0.9661 - val_loss: 1.1902 - val_accuracy: 0.6053\n",
      "Epoch 99/100\n",
      "177/177 [==============================] - 0s 107us/step - loss: 0.2073 - accuracy: 0.9718 - val_loss: 1.1771 - val_accuracy: 0.5921\n",
      "Epoch 100/100\n",
      "177/177 [==============================] - 0s 109us/step - loss: 0.2718 - accuracy: 0.9605 - val_loss: 1.1064 - val_accuracy: 0.6447\n"
     ]
    }
   ],
   "source": [
    "hist1 = model1.fit(X_train, y_train,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 94.62%\n"
     ]
    }
   ],
   "source": [
    "print('train accuracy: %.2f%%' % (np.mean(hist1.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_2.xlsx\",\n",
    "                        sheet_name=0,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NRS027</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.759813</td>\n",
       "      <td>0.001304</td>\n",
       "      <td>0.238883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NRS246</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.947819</td>\n",
       "      <td>0.009591</td>\n",
       "      <td>0.042591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NRS218</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.008693</td>\n",
       "      <td>0.989390</td>\n",
       "      <td>0.001916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>CFBRSa70</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.813774</td>\n",
       "      <td>0.001482</td>\n",
       "      <td>0.184744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NRS177</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000916</td>\n",
       "      <td>0.998926</td>\n",
       "      <td>0.000157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>NRS187</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.216843</td>\n",
       "      <td>0.568123</td>\n",
       "      <td>0.215034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>SR1287</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.418802</td>\n",
       "      <td>0.553160</td>\n",
       "      <td>0.028038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>CFBRSa50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.948100</td>\n",
       "      <td>0.035031</td>\n",
       "      <td>0.016869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>NRS196</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000964</td>\n",
       "      <td>0.039095</td>\n",
       "      <td>0.959940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>NRS072</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.795570</td>\n",
       "      <td>0.187358</td>\n",
       "      <td>0.017072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>608 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     phage    strain  phenotype  prediction         0  \\\n",
       "0       p0017kpresabs_qual    NRS027          1           0  0.759813   \n",
       "1       p0017kpresabs_qual    NRS246          1           0  0.947819   \n",
       "2       p0017kpresabs_qual    NRS218          2           1  0.008693   \n",
       "3       p0017kpresabs_qual  CFBRSa70          2           0  0.813774   \n",
       "4       p0017kpresabs_qual    NRS177          1           1  0.000916   \n",
       "..                     ...       ...        ...         ...       ...   \n",
       "603  p0040presabsSTCC_qual    NRS187          1           1  0.216843   \n",
       "604  p0040presabsSTCC_qual    SR1287          0           1  0.418802   \n",
       "605  p0040presabsSTCC_qual  CFBRSa50          0           0  0.948100   \n",
       "606  p0040presabsSTCC_qual    NRS196          2           2  0.000964   \n",
       "607  p0040presabsSTCC_qual    NRS072          0           0  0.795570   \n",
       "\n",
       "            1         2  \n",
       "0    0.001304  0.238883  \n",
       "1    0.009591  0.042591  \n",
       "2    0.989390  0.001916  \n",
       "3    0.001482  0.184744  \n",
       "4    0.998926  0.000157  \n",
       "..        ...       ...  \n",
       "603  0.568123  0.215034  \n",
       "604  0.553160  0.028038  \n",
       "605  0.035031  0.016869  \n",
       "606  0.039095  0.959940  \n",
       "607  0.187358  0.017072  \n",
       "\n",
       "[608 rows x 7 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.26926200e-05, 6.21460500e-01, 3.78506870e-01],\n",
       "       [2.37294160e-02, 9.73868600e-01, 2.40204410e-03],\n",
       "       [2.05960570e-02, 8.97286700e-01, 8.21171800e-02],\n",
       "       [2.20549650e-02, 2.57970040e-01, 7.19974940e-01],\n",
       "       [3.79307130e-03, 5.30473850e-02, 9.43159500e-01],\n",
       "       [8.32770900e-01, 4.40549630e-02, 1.23174110e-01],\n",
       "       [2.72915100e-01, 3.47662660e-01, 3.79422300e-01],\n",
       "       [2.23826620e-01, 7.47172500e-01, 2.90008620e-02],\n",
       "       [9.85465500e-04, 2.10302550e-01, 7.88711970e-01],\n",
       "       [8.70288200e-03, 5.44080600e-02, 9.36889100e-01],\n",
       "       [1.87536720e-01, 5.78544700e-01, 2.33918650e-01],\n",
       "       [1.74566960e-03, 2.52782850e-02, 9.72976000e-01],\n",
       "       [8.60968770e-01, 1.06446830e-01, 3.25843800e-02],\n",
       "       [3.62345130e-02, 9.46887850e-01, 1.68777020e-02],\n",
       "       [2.53141580e-02, 6.95132300e-01, 2.79553560e-01],\n",
       "       [3.09931860e-02, 1.47556990e-01, 8.21449800e-01],\n",
       "       [9.51052900e-01, 3.14109470e-02, 1.75361240e-02],\n",
       "       [4.09228350e-03, 8.51971100e-01, 1.43936620e-01],\n",
       "       [2.43394920e-05, 8.10301200e-01, 1.89674510e-01],\n",
       "       [4.89176900e-01, 4.50816330e-01, 6.00068100e-02],\n",
       "       [1.12908760e-02, 1.27501090e-01, 8.61208000e-01],\n",
       "       [2.69461300e-02, 7.34104100e-02, 8.99643500e-01],\n",
       "       [2.59975350e-05, 7.20311160e-01, 2.79662800e-01],\n",
       "       [5.90590100e-03, 9.52773870e-01, 4.13202350e-02],\n",
       "       [4.14397600e-03, 4.36509600e-01, 5.59346440e-01],\n",
       "       [1.66601210e-01, 8.13996700e-01, 1.94020700e-02],\n",
       "       [1.49188630e-02, 3.78254770e-01, 6.06826300e-01],\n",
       "       [4.46836300e-03, 8.86220860e-02, 9.06909600e-01],\n",
       "       [2.20549650e-02, 2.57970040e-01, 7.19974940e-01],\n",
       "       [1.00528780e-01, 8.62229650e-01, 3.72415000e-02],\n",
       "       [1.49303570e-01, 7.52866500e-01, 9.78299100e-02],\n",
       "       [4.51854380e-01, 1.97478980e-01, 3.50666670e-01],\n",
       "       [2.76028850e-02, 6.51569000e-02, 9.07240200e-01],\n",
       "       [1.08135510e-01, 5.38211050e-01, 3.53653500e-01],\n",
       "       [2.24652190e-03, 8.01837270e-01, 1.95916200e-01],\n",
       "       [5.34930830e-02, 1.94925050e-01, 7.51581850e-01],\n",
       "       [5.11380050e-03, 2.99326840e-01, 6.95559440e-01],\n",
       "       [1.08151820e-03, 1.15164740e-02, 9.87402000e-01],\n",
       "       [3.17690520e-03, 4.70677440e-01, 5.26145700e-01],\n",
       "       [1.68443230e-01, 7.24215800e-01, 1.07340960e-01],\n",
       "       [3.21412400e-02, 5.90922360e-01, 3.76936400e-01],\n",
       "       [2.05661040e-01, 7.26081500e-01, 6.82574100e-02],\n",
       "       [2.43302910e-04, 7.26131200e-01, 2.73625520e-01],\n",
       "       [6.59728800e-01, 2.96580170e-01, 4.36909830e-02],\n",
       "       [4.90227760e-03, 2.51422170e-01, 7.43675530e-01],\n",
       "       [2.10126200e-01, 2.17989620e-01, 5.71884160e-01],\n",
       "       [3.77565920e-02, 5.00378130e-01, 4.61865300e-01],\n",
       "       [5.01782450e-05, 8.58583330e-01, 1.41366530e-01],\n",
       "       [8.31425960e-01, 9.80089500e-02, 7.05651000e-02],\n",
       "       [6.78644600e-02, 2.49245180e-01, 6.82890400e-01],\n",
       "       [9.13390160e-01, 4.19942330e-02, 4.46155500e-02],\n",
       "       [2.25800800e-01, 7.31396850e-01, 4.28023930e-02],\n",
       "       [5.42135800e-01, 2.62713850e-01, 1.95150300e-01],\n",
       "       [1.11488450e-02, 4.80166260e-02, 9.40834600e-01],\n",
       "       [6.99246000e-02, 7.57892000e-01, 1.72183470e-01],\n",
       "       [6.45974800e-01, 2.30409220e-01, 1.23615950e-01],\n",
       "       [7.35706400e-03, 5.35587000e-02, 9.39084200e-01],\n",
       "       [5.46833270e-03, 3.20004670e-02, 9.62531270e-01],\n",
       "       [5.31281900e-01, 3.13189570e-01, 1.55528620e-01],\n",
       "       [1.27219730e-02, 3.14893000e-02, 9.55788730e-01],\n",
       "       [8.92187830e-01, 8.87790400e-02, 1.90331600e-02],\n",
       "       [1.17160180e-03, 8.98915800e-01, 9.99125900e-02],\n",
       "       [4.49517700e-01, 2.26240170e-01, 3.24242140e-01],\n",
       "       [4.43286500e-05, 9.80720700e-01, 1.92350630e-02],\n",
       "       [4.03309240e-03, 2.97645800e-02, 9.66202300e-01],\n",
       "       [5.55198700e-01, 2.05629930e-01, 2.39171340e-01],\n",
       "       [6.50948000e-02, 1.19202785e-01, 8.15702440e-01],\n",
       "       [7.52946300e-01, 1.98456730e-01, 4.85969500e-02],\n",
       "       [3.18706770e-05, 9.99836440e-01, 1.31740480e-04],\n",
       "       [1.18082590e-01, 4.39015720e-01, 4.42901700e-01],\n",
       "       [5.50616800e-02, 5.98489300e-01, 3.46449050e-01],\n",
       "       [2.16842980e-01, 5.68123300e-01, 2.15033770e-01],\n",
       "       [4.18802080e-01, 5.53159950e-01, 2.80379490e-02],\n",
       "       [9.48100270e-01, 3.50310100e-02, 1.68687420e-02],\n",
       "       [9.64328360e-04, 3.90954200e-02, 9.59940250e-01],\n",
       "       [7.95569960e-01, 1.87357650e-01, 1.70724130e-02]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob = df_proba[df_proba['phage']=='p0040presabsSTCC_qual'].iloc[:,-3:]\n",
    "y_prob = y_prob.to_numpy()\n",
    "y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Retrieved from https://github.com/scikit-learn/scikit-learn/issues/3298\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "def rocauc_ovo(truth, pred, average=\"macro\", multi_class=\"ovo\"):\n",
    "\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(truth)\n",
    "\n",
    "    truth = lb.transform(truth)   \n",
    "    \n",
    "    return roc_auc_score(truth, pred, average=average, multi_class=multi_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.779854769012316"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo1 = rocauc_ovo(y_test, y_prob, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rocauc_ovr(truth, pred, average=\"macro\", multi_class=\"ovr\"):\n",
    "\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(truth)\n",
    "\n",
    "    truth = lb.transform(truth)   \n",
    "\n",
    "    return roc_auc_score(truth, pred, average=average, multi_class=multi_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.779854769012316"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr1 = rocauc_ovr(y_test, y_prob, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=234,\n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat2 = pd.DataFrame(X_test.iloc[:,0])\n",
    "dat2['test'] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>NRS191</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>SR1287</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>SR3569</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>NRS100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>NRS001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>NRS265</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>NY439</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>CFBRSa05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>NRS205</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>CA105</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  test\n",
       "165    NRS191     2\n",
       "237    SR1287     0\n",
       "243    SR3569     2\n",
       "128    NRS100     0\n",
       "107    NRS001     1\n",
       "..        ...   ...\n",
       "220    NRS265     1\n",
       "233     NY439     2\n",
       "68   CFBRSa05     0\n",
       "175    NRS205     2\n",
       "31      CA105     1\n",
       "\n",
       "[76 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(['id'], axis=1)\n",
    "X_test = X_test.drop(['id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 177 samples, validate on 76 samples\n",
      "Epoch 1/100\n",
      "177/177 [==============================] - 0s 974us/step - loss: 11.0972 - accuracy: 0.2655 - val_loss: 7.2993 - val_accuracy: 0.3158\n",
      "Epoch 2/100\n",
      "177/177 [==============================] - 0s 161us/step - loss: 8.2942 - accuracy: 0.3051 - val_loss: 4.9131 - val_accuracy: 0.3421\n",
      "Epoch 3/100\n",
      "177/177 [==============================] - 0s 162us/step - loss: 5.4000 - accuracy: 0.3277 - val_loss: 2.6774 - val_accuracy: 0.3947\n",
      "Epoch 4/100\n",
      "177/177 [==============================] - 0s 178us/step - loss: 2.9504 - accuracy: 0.3277 - val_loss: 1.2709 - val_accuracy: 0.4474\n",
      "Epoch 5/100\n",
      "177/177 [==============================] - 0s 174us/step - loss: 1.8934 - accuracy: 0.4068 - val_loss: 1.1951 - val_accuracy: 0.4079\n",
      "Epoch 6/100\n",
      "177/177 [==============================] - 0s 159us/step - loss: 1.4566 - accuracy: 0.4407 - val_loss: 1.9150 - val_accuracy: 0.4474\n",
      "Epoch 7/100\n",
      "177/177 [==============================] - 0s 220us/step - loss: 1.2930 - accuracy: 0.4859 - val_loss: 1.0528 - val_accuracy: 0.4605\n",
      "Epoch 8/100\n",
      "177/177 [==============================] - 0s 161us/step - loss: 1.0289 - accuracy: 0.4972 - val_loss: 1.0302 - val_accuracy: 0.5263\n",
      "Epoch 9/100\n",
      "177/177 [==============================] - 0s 165us/step - loss: 0.9821 - accuracy: 0.5424 - val_loss: 1.1466 - val_accuracy: 0.5395\n",
      "Epoch 10/100\n",
      "177/177 [==============================] - 0s 171us/step - loss: 0.8918 - accuracy: 0.5706 - val_loss: 0.9355 - val_accuracy: 0.5658\n",
      "Epoch 11/100\n",
      "177/177 [==============================] - 0s 158us/step - loss: 0.9146 - accuracy: 0.5876 - val_loss: 0.9775 - val_accuracy: 0.6184\n",
      "Epoch 12/100\n",
      "177/177 [==============================] - 0s 216us/step - loss: 0.8514 - accuracy: 0.6384 - val_loss: 1.1115 - val_accuracy: 0.5658\n",
      "Epoch 13/100\n",
      "177/177 [==============================] - 0s 225us/step - loss: 0.8643 - accuracy: 0.6215 - val_loss: 0.9515 - val_accuracy: 0.5395\n",
      "Epoch 14/100\n",
      "177/177 [==============================] - 0s 198us/step - loss: 0.8264 - accuracy: 0.6328 - val_loss: 0.9555 - val_accuracy: 0.5263\n",
      "Epoch 15/100\n",
      "177/177 [==============================] - 0s 154us/step - loss: 0.8214 - accuracy: 0.6384 - val_loss: 0.9726 - val_accuracy: 0.5789\n",
      "Epoch 16/100\n",
      "177/177 [==============================] - 0s 150us/step - loss: 0.8063 - accuracy: 0.6723 - val_loss: 0.9351 - val_accuracy: 0.5921\n",
      "Epoch 17/100\n",
      "177/177 [==============================] - 0s 125us/step - loss: 0.8794 - accuracy: 0.6328 - val_loss: 0.9363 - val_accuracy: 0.6053\n",
      "Epoch 18/100\n",
      "177/177 [==============================] - 0s 99us/step - loss: 0.8034 - accuracy: 0.6780 - val_loss: 1.1354 - val_accuracy: 0.5526\n",
      "Epoch 19/100\n",
      "177/177 [==============================] - 0s 104us/step - loss: 0.8067 - accuracy: 0.6328 - val_loss: 0.8964 - val_accuracy: 0.5658\n",
      "Epoch 20/100\n",
      "177/177 [==============================] - 0s 149us/step - loss: 0.7632 - accuracy: 0.7006 - val_loss: 0.9676 - val_accuracy: 0.5921\n",
      "Epoch 21/100\n",
      "177/177 [==============================] - 0s 127us/step - loss: 0.7459 - accuracy: 0.7062 - val_loss: 0.9244 - val_accuracy: 0.5789\n",
      "Epoch 22/100\n",
      "177/177 [==============================] - 0s 136us/step - loss: 0.7301 - accuracy: 0.7175 - val_loss: 0.9519 - val_accuracy: 0.5789\n",
      "Epoch 23/100\n",
      "177/177 [==============================] - 0s 124us/step - loss: 0.7386 - accuracy: 0.7232 - val_loss: 0.8878 - val_accuracy: 0.6053\n",
      "Epoch 24/100\n",
      "177/177 [==============================] - 0s 148us/step - loss: 0.7250 - accuracy: 0.7401 - val_loss: 0.9432 - val_accuracy: 0.6053\n",
      "Epoch 25/100\n",
      "177/177 [==============================] - 0s 177us/step - loss: 0.7430 - accuracy: 0.7288 - val_loss: 0.9453 - val_accuracy: 0.6053\n",
      "Epoch 26/100\n",
      "177/177 [==============================] - 0s 169us/step - loss: 0.7330 - accuracy: 0.7288 - val_loss: 0.8834 - val_accuracy: 0.5921\n",
      "Epoch 27/100\n",
      "177/177 [==============================] - 0s 161us/step - loss: 0.6840 - accuracy: 0.7627 - val_loss: 1.0219 - val_accuracy: 0.6447\n",
      "Epoch 28/100\n",
      "177/177 [==============================] - 0s 256us/step - loss: 0.7118 - accuracy: 0.7288 - val_loss: 0.9052 - val_accuracy: 0.6316\n",
      "Epoch 29/100\n",
      "177/177 [==============================] - 0s 120us/step - loss: 0.6930 - accuracy: 0.7627 - val_loss: 0.9108 - val_accuracy: 0.6053\n",
      "Epoch 30/100\n",
      "177/177 [==============================] - 0s 106us/step - loss: 0.6975 - accuracy: 0.7740 - val_loss: 0.9211 - val_accuracy: 0.6053\n",
      "Epoch 31/100\n",
      "177/177 [==============================] - 0s 124us/step - loss: 0.7282 - accuracy: 0.7345 - val_loss: 0.8965 - val_accuracy: 0.6316\n",
      "Epoch 32/100\n",
      "177/177 [==============================] - 0s 100us/step - loss: 0.6710 - accuracy: 0.7401 - val_loss: 1.1750 - val_accuracy: 0.5789\n",
      "Epoch 33/100\n",
      "177/177 [==============================] - 0s 118us/step - loss: 0.7198 - accuracy: 0.7458 - val_loss: 0.8779 - val_accuracy: 0.5658\n",
      "Epoch 34/100\n",
      "177/177 [==============================] - 0s 158us/step - loss: 0.6496 - accuracy: 0.7571 - val_loss: 0.9740 - val_accuracy: 0.6316\n",
      "Epoch 35/100\n",
      "177/177 [==============================] - 0s 150us/step - loss: 0.6585 - accuracy: 0.7571 - val_loss: 1.0188 - val_accuracy: 0.6053\n",
      "Epoch 36/100\n",
      "177/177 [==============================] - 0s 117us/step - loss: 0.6398 - accuracy: 0.7740 - val_loss: 0.8637 - val_accuracy: 0.5921\n",
      "Epoch 37/100\n",
      "177/177 [==============================] - 0s 158us/step - loss: 0.6218 - accuracy: 0.7740 - val_loss: 0.9660 - val_accuracy: 0.6184\n",
      "Epoch 38/100\n",
      "177/177 [==============================] - 0s 133us/step - loss: 0.6107 - accuracy: 0.7853 - val_loss: 0.9555 - val_accuracy: 0.6184\n",
      "Epoch 39/100\n",
      "177/177 [==============================] - 0s 131us/step - loss: 0.6021 - accuracy: 0.8136 - val_loss: 0.9030 - val_accuracy: 0.6316\n",
      "Epoch 40/100\n",
      "177/177 [==============================] - 0s 153us/step - loss: 0.5943 - accuracy: 0.8192 - val_loss: 0.9270 - val_accuracy: 0.6053\n",
      "Epoch 41/100\n",
      "177/177 [==============================] - 0s 197us/step - loss: 0.5820 - accuracy: 0.8192 - val_loss: 0.9077 - val_accuracy: 0.6053\n",
      "Epoch 42/100\n",
      "177/177 [==============================] - 0s 152us/step - loss: 0.5861 - accuracy: 0.8136 - val_loss: 0.9322 - val_accuracy: 0.6184\n",
      "Epoch 43/100\n",
      "177/177 [==============================] - 0s 168us/step - loss: 0.5794 - accuracy: 0.8136 - val_loss: 0.9548 - val_accuracy: 0.6184\n",
      "Epoch 44/100\n",
      "177/177 [==============================] - 0s 166us/step - loss: 0.5662 - accuracy: 0.8305 - val_loss: 0.9018 - val_accuracy: 0.6053\n",
      "Epoch 45/100\n",
      "177/177 [==============================] - 0s 199us/step - loss: 0.5587 - accuracy: 0.8362 - val_loss: 0.9333 - val_accuracy: 0.6053\n",
      "Epoch 46/100\n",
      "177/177 [==============================] - 0s 160us/step - loss: 0.5550 - accuracy: 0.8305 - val_loss: 0.9177 - val_accuracy: 0.6316\n",
      "Epoch 47/100\n",
      "177/177 [==============================] - 0s 125us/step - loss: 0.5555 - accuracy: 0.8192 - val_loss: 0.9627 - val_accuracy: 0.6316\n",
      "Epoch 48/100\n",
      "177/177 [==============================] - 0s 147us/step - loss: 0.5353 - accuracy: 0.8362 - val_loss: 0.8819 - val_accuracy: 0.6184\n",
      "Epoch 49/100\n",
      "177/177 [==============================] - 0s 151us/step - loss: 0.5338 - accuracy: 0.8362 - val_loss: 0.9942 - val_accuracy: 0.6316\n",
      "Epoch 50/100\n",
      "177/177 [==============================] - 0s 112us/step - loss: 0.5345 - accuracy: 0.8362 - val_loss: 0.9622 - val_accuracy: 0.6184\n",
      "Epoch 51/100\n",
      "177/177 [==============================] - 0s 95us/step - loss: 0.5138 - accuracy: 0.8305 - val_loss: 0.9011 - val_accuracy: 0.5921\n",
      "Epoch 52/100\n",
      "177/177 [==============================] - 0s 83us/step - loss: 0.5275 - accuracy: 0.8362 - val_loss: 1.0038 - val_accuracy: 0.6053\n",
      "Epoch 53/100\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.5378 - accuracy: 0.8249 - val_loss: 0.9907 - val_accuracy: 0.5921\n",
      "Epoch 54/100\n",
      "177/177 [==============================] - 0s 86us/step - loss: 0.5042 - accuracy: 0.8475 - val_loss: 0.8844 - val_accuracy: 0.5789\n",
      "Epoch 55/100\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.5325 - accuracy: 0.8136 - val_loss: 1.0219 - val_accuracy: 0.6053\n",
      "Epoch 56/100\n",
      "177/177 [==============================] - 0s 119us/step - loss: 0.5093 - accuracy: 0.8305 - val_loss: 1.0074 - val_accuracy: 0.6316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "177/177 [==============================] - 0s 105us/step - loss: 0.4964 - accuracy: 0.8531 - val_loss: 0.9159 - val_accuracy: 0.5921\n",
      "Epoch 58/100\n",
      "177/177 [==============================] - 0s 92us/step - loss: 0.4889 - accuracy: 0.8418 - val_loss: 0.9693 - val_accuracy: 0.5921\n",
      "Epoch 59/100\n",
      "177/177 [==============================] - 0s 105us/step - loss: 0.4755 - accuracy: 0.8475 - val_loss: 0.9435 - val_accuracy: 0.6184\n",
      "Epoch 60/100\n",
      "177/177 [==============================] - 0s 117us/step - loss: 0.4766 - accuracy: 0.8701 - val_loss: 0.9344 - val_accuracy: 0.6184\n",
      "Epoch 61/100\n",
      "177/177 [==============================] - 0s 95us/step - loss: 0.4666 - accuracy: 0.8644 - val_loss: 0.9467 - val_accuracy: 0.6184\n",
      "Epoch 62/100\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.4641 - accuracy: 0.8588 - val_loss: 1.0258 - val_accuracy: 0.5921\n",
      "Epoch 63/100\n",
      "177/177 [==============================] - 0s 99us/step - loss: 0.4571 - accuracy: 0.8814 - val_loss: 0.9201 - val_accuracy: 0.6184\n",
      "Epoch 64/100\n",
      "177/177 [==============================] - 0s 102us/step - loss: 0.4626 - accuracy: 0.8475 - val_loss: 0.9849 - val_accuracy: 0.6184\n",
      "Epoch 65/100\n",
      "177/177 [==============================] - 0s 100us/step - loss: 0.4551 - accuracy: 0.8644 - val_loss: 0.9992 - val_accuracy: 0.6053\n",
      "Epoch 66/100\n",
      "177/177 [==============================] - 0s 81us/step - loss: 0.4434 - accuracy: 0.8757 - val_loss: 0.9165 - val_accuracy: 0.6053\n",
      "Epoch 67/100\n",
      "177/177 [==============================] - 0s 97us/step - loss: 0.4427 - accuracy: 0.8814 - val_loss: 0.9645 - val_accuracy: 0.6053\n",
      "Epoch 68/100\n",
      "177/177 [==============================] - 0s 170us/step - loss: 0.4737 - accuracy: 0.8588 - val_loss: 0.9912 - val_accuracy: 0.6184\n",
      "Epoch 69/100\n",
      "177/177 [==============================] - 0s 122us/step - loss: 0.4443 - accuracy: 0.8644 - val_loss: 0.9209 - val_accuracy: 0.6053\n",
      "Epoch 70/100\n",
      "177/177 [==============================] - 0s 124us/step - loss: 0.4438 - accuracy: 0.8701 - val_loss: 0.9447 - val_accuracy: 0.6053\n",
      "Epoch 71/100\n",
      "177/177 [==============================] - 0s 109us/step - loss: 0.4439 - accuracy: 0.8757 - val_loss: 0.9899 - val_accuracy: 0.6184\n",
      "Epoch 72/100\n",
      "177/177 [==============================] - 0s 196us/step - loss: 0.4266 - accuracy: 0.8644 - val_loss: 1.0654 - val_accuracy: 0.5921\n",
      "Epoch 73/100\n",
      "177/177 [==============================] - 0s 161us/step - loss: 0.4540 - accuracy: 0.8701 - val_loss: 0.9473 - val_accuracy: 0.6053\n",
      "Epoch 74/100\n",
      "177/177 [==============================] - 0s 224us/step - loss: 0.4320 - accuracy: 0.8701 - val_loss: 1.1248 - val_accuracy: 0.5921\n",
      "Epoch 75/100\n",
      "177/177 [==============================] - 0s 132us/step - loss: 0.4219 - accuracy: 0.8757 - val_loss: 0.9555 - val_accuracy: 0.6184\n",
      "Epoch 76/100\n",
      "177/177 [==============================] - 0s 200us/step - loss: 0.4050 - accuracy: 0.8757 - val_loss: 1.0020 - val_accuracy: 0.6053\n",
      "Epoch 77/100\n",
      "177/177 [==============================] - 0s 113us/step - loss: 0.4030 - accuracy: 0.8870 - val_loss: 0.9956 - val_accuracy: 0.6053\n",
      "Epoch 78/100\n",
      "177/177 [==============================] - 0s 113us/step - loss: 0.3865 - accuracy: 0.8927 - val_loss: 0.9570 - val_accuracy: 0.6184\n",
      "Epoch 79/100\n",
      "177/177 [==============================] - 0s 114us/step - loss: 0.3863 - accuracy: 0.8870 - val_loss: 0.9932 - val_accuracy: 0.6053\n",
      "Epoch 80/100\n",
      "177/177 [==============================] - 0s 126us/step - loss: 0.3815 - accuracy: 0.8870 - val_loss: 0.9642 - val_accuracy: 0.6053\n",
      "Epoch 81/100\n",
      "177/177 [==============================] - 0s 146us/step - loss: 0.3738 - accuracy: 0.9040 - val_loss: 0.9836 - val_accuracy: 0.5921\n",
      "Epoch 82/100\n",
      "177/177 [==============================] - 0s 111us/step - loss: 0.3745 - accuracy: 0.8983 - val_loss: 0.9677 - val_accuracy: 0.6184\n",
      "Epoch 83/100\n",
      "177/177 [==============================] - 0s 150us/step - loss: 0.3690 - accuracy: 0.8927 - val_loss: 0.9655 - val_accuracy: 0.6053\n",
      "Epoch 84/100\n",
      "177/177 [==============================] - 0s 113us/step - loss: 0.3659 - accuracy: 0.9040 - val_loss: 1.0256 - val_accuracy: 0.5921\n",
      "Epoch 85/100\n",
      "177/177 [==============================] - 0s 97us/step - loss: 0.3605 - accuracy: 0.8927 - val_loss: 0.9428 - val_accuracy: 0.6184\n",
      "Epoch 86/100\n",
      "177/177 [==============================] - 0s 103us/step - loss: 0.3685 - accuracy: 0.8983 - val_loss: 1.0115 - val_accuracy: 0.6184\n",
      "Epoch 87/100\n",
      "177/177 [==============================] - 0s 125us/step - loss: 0.3850 - accuracy: 0.8927 - val_loss: 0.9731 - val_accuracy: 0.6053\n",
      "Epoch 88/100\n",
      "177/177 [==============================] - 0s 133us/step - loss: 0.3769 - accuracy: 0.8870 - val_loss: 0.9586 - val_accuracy: 0.6184\n",
      "Epoch 89/100\n",
      "177/177 [==============================] - 0s 172us/step - loss: 0.3484 - accuracy: 0.9096 - val_loss: 1.1470 - val_accuracy: 0.5789\n",
      "Epoch 90/100\n",
      "177/177 [==============================] - 0s 149us/step - loss: 0.3672 - accuracy: 0.8983 - val_loss: 0.9224 - val_accuracy: 0.6184\n",
      "Epoch 91/100\n",
      "177/177 [==============================] - 0s 156us/step - loss: 0.3725 - accuracy: 0.8983 - val_loss: 1.1253 - val_accuracy: 0.6053\n",
      "Epoch 92/100\n",
      "177/177 [==============================] - 0s 211us/step - loss: 0.3683 - accuracy: 0.9040 - val_loss: 1.0119 - val_accuracy: 0.6184\n",
      "Epoch 93/100\n",
      "177/177 [==============================] - 0s 184us/step - loss: 0.3582 - accuracy: 0.9040 - val_loss: 0.9834 - val_accuracy: 0.6053\n",
      "Epoch 94/100\n",
      "177/177 [==============================] - 0s 195us/step - loss: 0.3355 - accuracy: 0.9096 - val_loss: 1.0503 - val_accuracy: 0.6184\n",
      "Epoch 95/100\n",
      "177/177 [==============================] - 0s 167us/step - loss: 0.3319 - accuracy: 0.9153 - val_loss: 1.0518 - val_accuracy: 0.6184\n",
      "Epoch 96/100\n",
      "177/177 [==============================] - 0s 175us/step - loss: 0.3216 - accuracy: 0.9266 - val_loss: 0.9829 - val_accuracy: 0.6184\n",
      "Epoch 97/100\n",
      "177/177 [==============================] - 0s 137us/step - loss: 0.3194 - accuracy: 0.9040 - val_loss: 1.0521 - val_accuracy: 0.6184\n",
      "Epoch 98/100\n",
      "177/177 [==============================] - 0s 151us/step - loss: 0.3167 - accuracy: 0.9153 - val_loss: 1.0432 - val_accuracy: 0.6184\n",
      "Epoch 99/100\n",
      "177/177 [==============================] - 0s 162us/step - loss: 0.3125 - accuracy: 0.9322 - val_loss: 1.0193 - val_accuracy: 0.6184\n",
      "Epoch 100/100\n",
      "177/177 [==============================] - 0s 190us/step - loss: 0.3108 - accuracy: 0.9209 - val_loss: 1.0544 - val_accuracy: 0.6053\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a3d79f0f0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(X_train, y_train,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 0s 112us/step\n",
      "test accuracy: 64.47%\n"
     ]
    }
   ],
   "source": [
    "acc_test2 = model2.evaluate(X_test, y_test)[1]\n",
    "print('test accuracy: %.2f%%' % (acc_test2*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 2, 1, 1, 1, 1, 2, 2, 1, 1, 1, 2, 2, 1, 1, 2, 2, 2, 1, 1, 2,\n",
       "       0, 2, 0, 1, 1, 0, 2, 0, 2, 2, 1, 0, 1, 1, 2, 0, 1, 2, 2, 2, 2, 1,\n",
       "       1, 1, 0, 1, 2, 1, 2, 2, 2, 1, 1, 1, 1, 0, 1, 1, 2, 2, 2, 2, 1, 2,\n",
       "       1, 2, 1, 2, 2, 1, 2, 0, 2, 0])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred2 = model2.predict_classes(X_test)\n",
    "pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>NRS191</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>SR1287</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>SR3569</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>NRS100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>NRS001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>NRS265</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>NY439</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>CFBRSa05</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>NRS205</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>CA105</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  test  pred\n",
       "165    NRS191     2     2\n",
       "237    SR1287     0     0\n",
       "243    SR3569     2     2\n",
       "128    NRS100     0     1\n",
       "107    NRS001     1     1\n",
       "..        ...   ...   ...\n",
       "220    NRS265     1     1\n",
       "233     NY439     2     2\n",
       "68   CFBRSa05     0     0\n",
       "175    NRS205     2     2\n",
       "31      CA105     1     0\n",
       "\n",
       "[76 rows x 3 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat2['pred'] = pred2\n",
    "dat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba2 = model2.predict_proba(X_test)\n",
    "dat_proba2 = pd.DataFrame(proba2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.074384</td>\n",
       "      <td>0.160355</td>\n",
       "      <td>0.765261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.575869</td>\n",
       "      <td>0.423838</td>\n",
       "      <td>0.000294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.206686</td>\n",
       "      <td>0.294262</td>\n",
       "      <td>0.499052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.100446</td>\n",
       "      <td>0.820180</td>\n",
       "      <td>0.079374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.163093</td>\n",
       "      <td>0.773945</td>\n",
       "      <td>0.062962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.025601</td>\n",
       "      <td>0.687962</td>\n",
       "      <td>0.286437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.161947</td>\n",
       "      <td>0.266501</td>\n",
       "      <td>0.571552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.652983</td>\n",
       "      <td>0.254172</td>\n",
       "      <td>0.092845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.000927</td>\n",
       "      <td>0.033760</td>\n",
       "      <td>0.965313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.736115</td>\n",
       "      <td>0.260109</td>\n",
       "      <td>0.003775</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2\n",
       "0   0.074384  0.160355  0.765261\n",
       "1   0.575869  0.423838  0.000294\n",
       "2   0.206686  0.294262  0.499052\n",
       "3   0.100446  0.820180  0.079374\n",
       "4   0.163093  0.773945  0.062962\n",
       "..       ...       ...       ...\n",
       "71  0.025601  0.687962  0.286437\n",
       "72  0.161947  0.266501  0.571552\n",
       "73  0.652983  0.254172  0.092845\n",
       "74  0.000927  0.033760  0.965313\n",
       "75  0.736115  0.260109  0.003775\n",
       "\n",
       "[76 rows x 3 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba2.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba2.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat2.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/2p40pST.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 177 samples, validate on 76 samples\n",
      "Epoch 1/100\n",
      "177/177 [==============================] - 0s 176us/step - loss: 0.2759 - accuracy: 0.9435 - val_loss: 1.2241 - val_accuracy: 0.6184\n",
      "Epoch 2/100\n",
      "177/177 [==============================] - 0s 185us/step - loss: 0.2754 - accuracy: 0.9322 - val_loss: 1.0206 - val_accuracy: 0.6579\n",
      "Epoch 3/100\n",
      "177/177 [==============================] - 0s 255us/step - loss: 0.3745 - accuracy: 0.8927 - val_loss: 1.3395 - val_accuracy: 0.6316\n",
      "Epoch 4/100\n",
      "177/177 [==============================] - 0s 136us/step - loss: 0.2695 - accuracy: 0.9548 - val_loss: 1.0070 - val_accuracy: 0.6316\n",
      "Epoch 5/100\n",
      "177/177 [==============================] - 0s 150us/step - loss: 0.2615 - accuracy: 0.9492 - val_loss: 1.1151 - val_accuracy: 0.6579\n",
      "Epoch 6/100\n",
      "177/177 [==============================] - 0s 134us/step - loss: 0.2604 - accuracy: 0.9322 - val_loss: 1.1596 - val_accuracy: 0.6053\n",
      "Epoch 7/100\n",
      "177/177 [==============================] - 0s 170us/step - loss: 0.2479 - accuracy: 0.9548 - val_loss: 1.0631 - val_accuracy: 0.6447\n",
      "Epoch 8/100\n",
      "177/177 [==============================] - 0s 200us/step - loss: 0.2520 - accuracy: 0.9435 - val_loss: 1.1174 - val_accuracy: 0.6316\n",
      "Epoch 9/100\n",
      "177/177 [==============================] - 0s 136us/step - loss: 0.2434 - accuracy: 0.9492 - val_loss: 1.1340 - val_accuracy: 0.6316\n",
      "Epoch 10/100\n",
      "177/177 [==============================] - 0s 203us/step - loss: 0.2398 - accuracy: 0.9492 - val_loss: 1.1026 - val_accuracy: 0.6184\n",
      "Epoch 11/100\n",
      "177/177 [==============================] - 0s 139us/step - loss: 0.2401 - accuracy: 0.9492 - val_loss: 1.1261 - val_accuracy: 0.6316\n",
      "Epoch 12/100\n",
      "177/177 [==============================] - 0s 142us/step - loss: 0.2361 - accuracy: 0.9548 - val_loss: 1.1585 - val_accuracy: 0.6053\n",
      "Epoch 13/100\n",
      "177/177 [==============================] - 0s 162us/step - loss: 0.2355 - accuracy: 0.9492 - val_loss: 1.1214 - val_accuracy: 0.6316\n",
      "Epoch 14/100\n",
      "177/177 [==============================] - 0s 112us/step - loss: 0.2344 - accuracy: 0.9492 - val_loss: 1.1343 - val_accuracy: 0.6316\n",
      "Epoch 15/100\n",
      "177/177 [==============================] - 0s 177us/step - loss: 0.2305 - accuracy: 0.9548 - val_loss: 1.1044 - val_accuracy: 0.6447\n",
      "Epoch 16/100\n",
      "177/177 [==============================] - 0s 121us/step - loss: 0.2359 - accuracy: 0.9435 - val_loss: 1.1353 - val_accuracy: 0.6184\n",
      "Epoch 17/100\n",
      "177/177 [==============================] - 0s 114us/step - loss: 0.2346 - accuracy: 0.9492 - val_loss: 1.3008 - val_accuracy: 0.6184\n",
      "Epoch 18/100\n",
      "177/177 [==============================] - 0s 117us/step - loss: 0.2507 - accuracy: 0.9379 - val_loss: 1.0483 - val_accuracy: 0.6579\n",
      "Epoch 19/100\n",
      "177/177 [==============================] - 0s 103us/step - loss: 0.2306 - accuracy: 0.9605 - val_loss: 1.2009 - val_accuracy: 0.6184\n",
      "Epoch 20/100\n",
      "177/177 [==============================] - 0s 240us/step - loss: 0.2251 - accuracy: 0.9661 - val_loss: 1.1334 - val_accuracy: 0.6184\n",
      "Epoch 21/100\n",
      "177/177 [==============================] - 0s 216us/step - loss: 0.2227 - accuracy: 0.9661 - val_loss: 1.1146 - val_accuracy: 0.6447\n",
      "Epoch 22/100\n",
      "177/177 [==============================] - 0s 173us/step - loss: 0.2162 - accuracy: 0.9718 - val_loss: 1.1712 - val_accuracy: 0.6053\n",
      "Epoch 23/100\n",
      "177/177 [==============================] - 0s 123us/step - loss: 0.2193 - accuracy: 0.9548 - val_loss: 1.1429 - val_accuracy: 0.6184\n",
      "Epoch 24/100\n",
      "177/177 [==============================] - 0s 172us/step - loss: 0.2160 - accuracy: 0.9718 - val_loss: 1.1402 - val_accuracy: 0.6053\n",
      "Epoch 25/100\n",
      "177/177 [==============================] - 0s 166us/step - loss: 0.2140 - accuracy: 0.9661 - val_loss: 1.1794 - val_accuracy: 0.6316\n",
      "Epoch 26/100\n",
      "177/177 [==============================] - 0s 153us/step - loss: 0.2123 - accuracy: 0.9605 - val_loss: 1.1127 - val_accuracy: 0.6447\n",
      "Epoch 27/100\n",
      "177/177 [==============================] - 0s 227us/step - loss: 0.2089 - accuracy: 0.9718 - val_loss: 1.2099 - val_accuracy: 0.6053\n",
      "Epoch 28/100\n",
      "177/177 [==============================] - 0s 670us/step - loss: 0.2209 - accuracy: 0.9435 - val_loss: 1.1569 - val_accuracy: 0.6184\n",
      "Epoch 29/100\n",
      "177/177 [==============================] - 0s 140us/step - loss: 0.2212 - accuracy: 0.9548 - val_loss: 1.1501 - val_accuracy: 0.6316\n",
      "Epoch 30/100\n",
      "177/177 [==============================] - 0s 136us/step - loss: 0.2153 - accuracy: 0.9661 - val_loss: 1.2247 - val_accuracy: 0.6316\n",
      "Epoch 31/100\n",
      "177/177 [==============================] - 0s 452us/step - loss: 0.2080 - accuracy: 0.9661 - val_loss: 1.1593 - val_accuracy: 0.6447\n",
      "Epoch 32/100\n",
      "177/177 [==============================] - 0s 199us/step - loss: 0.2009 - accuracy: 0.9661 - val_loss: 1.2042 - val_accuracy: 0.6184\n",
      "Epoch 33/100\n",
      "177/177 [==============================] - 0s 246us/step - loss: 0.1947 - accuracy: 0.9605 - val_loss: 1.1598 - val_accuracy: 0.6316\n",
      "Epoch 34/100\n",
      "177/177 [==============================] - 0s 296us/step - loss: 0.2029 - accuracy: 0.9718 - val_loss: 1.1609 - val_accuracy: 0.6316\n",
      "Epoch 35/100\n",
      "177/177 [==============================] - 0s 281us/step - loss: 0.1972 - accuracy: 0.9661 - val_loss: 1.1967 - val_accuracy: 0.6184\n",
      "Epoch 36/100\n",
      "177/177 [==============================] - 0s 703us/step - loss: 0.1938 - accuracy: 0.9605 - val_loss: 1.1608 - val_accuracy: 0.6447\n",
      "Epoch 37/100\n",
      "177/177 [==============================] - 0s 437us/step - loss: 0.1915 - accuracy: 0.9718 - val_loss: 1.1922 - val_accuracy: 0.6316\n",
      "Epoch 38/100\n",
      "177/177 [==============================] - 0s 279us/step - loss: 0.1929 - accuracy: 0.9605 - val_loss: 1.2028 - val_accuracy: 0.6184\n",
      "Epoch 39/100\n",
      "177/177 [==============================] - 0s 159us/step - loss: 0.1865 - accuracy: 0.9661 - val_loss: 1.1928 - val_accuracy: 0.6184\n",
      "Epoch 40/100\n",
      "177/177 [==============================] - 0s 176us/step - loss: 0.1866 - accuracy: 0.9718 - val_loss: 1.2284 - val_accuracy: 0.6447\n",
      "Epoch 41/100\n",
      "177/177 [==============================] - 0s 165us/step - loss: 0.1994 - accuracy: 0.9548 - val_loss: 1.2160 - val_accuracy: 0.6579\n",
      "Epoch 42/100\n",
      "177/177 [==============================] - 0s 230us/step - loss: 0.1897 - accuracy: 0.9548 - val_loss: 1.1623 - val_accuracy: 0.6316\n",
      "Epoch 43/100\n",
      "177/177 [==============================] - 0s 1ms/step - loss: 0.1873 - accuracy: 0.9605 - val_loss: 1.3064 - val_accuracy: 0.6316\n",
      "Epoch 44/100\n",
      "177/177 [==============================] - 0s 391us/step - loss: 0.1984 - accuracy: 0.9492 - val_loss: 1.0677 - val_accuracy: 0.6184\n",
      "Epoch 45/100\n",
      "177/177 [==============================] - 0s 443us/step - loss: 0.2262 - accuracy: 0.9435 - val_loss: 1.2184 - val_accuracy: 0.6842\n",
      "Epoch 46/100\n",
      "177/177 [==============================] - 0s 218us/step - loss: 0.2605 - accuracy: 0.9435 - val_loss: 1.1962 - val_accuracy: 0.6842\n",
      "Epoch 47/100\n",
      "177/177 [==============================] - 0s 345us/step - loss: 0.1895 - accuracy: 0.9661 - val_loss: 1.1222 - val_accuracy: 0.6711\n",
      "Epoch 48/100\n",
      "177/177 [==============================] - 0s 364us/step - loss: 0.1864 - accuracy: 0.9661 - val_loss: 1.1803 - val_accuracy: 0.6316\n",
      "Epoch 49/100\n",
      "177/177 [==============================] - 0s 392us/step - loss: 0.1821 - accuracy: 0.9605 - val_loss: 1.1932 - val_accuracy: 0.6579\n",
      "Epoch 50/100\n",
      "177/177 [==============================] - 0s 262us/step - loss: 0.1753 - accuracy: 0.9718 - val_loss: 1.2197 - val_accuracy: 0.6316\n",
      "Epoch 51/100\n",
      "177/177 [==============================] - 0s 446us/step - loss: 0.1700 - accuracy: 0.9605 - val_loss: 1.1961 - val_accuracy: 0.6316\n",
      "Epoch 52/100\n",
      "177/177 [==============================] - 0s 187us/step - loss: 0.1882 - accuracy: 0.9492 - val_loss: 1.1848 - val_accuracy: 0.6447\n",
      "Epoch 53/100\n",
      "177/177 [==============================] - 0s 161us/step - loss: 0.1836 - accuracy: 0.9661 - val_loss: 1.2408 - val_accuracy: 0.6316\n",
      "Epoch 54/100\n",
      "177/177 [==============================] - 0s 137us/step - loss: 0.1793 - accuracy: 0.9661 - val_loss: 1.2697 - val_accuracy: 0.6316\n",
      "Epoch 55/100\n",
      "177/177 [==============================] - 0s 153us/step - loss: 0.1764 - accuracy: 0.9718 - val_loss: 1.1994 - val_accuracy: 0.6579\n",
      "Epoch 56/100\n",
      "177/177 [==============================] - 0s 136us/step - loss: 0.1698 - accuracy: 0.9774 - val_loss: 1.2644 - val_accuracy: 0.6579\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "177/177 [==============================] - 0s 133us/step - loss: 0.1708 - accuracy: 0.9718 - val_loss: 1.2437 - val_accuracy: 0.6579\n",
      "Epoch 58/100\n",
      "177/177 [==============================] - 0s 125us/step - loss: 0.1646 - accuracy: 0.9661 - val_loss: 1.1902 - val_accuracy: 0.6579\n",
      "Epoch 59/100\n",
      "177/177 [==============================] - 0s 131us/step - loss: 0.1712 - accuracy: 0.9605 - val_loss: 1.2996 - val_accuracy: 0.6053\n",
      "Epoch 60/100\n",
      "177/177 [==============================] - 0s 132us/step - loss: 0.1741 - accuracy: 0.9492 - val_loss: 1.2368 - val_accuracy: 0.6316\n",
      "Epoch 61/100\n",
      "177/177 [==============================] - 0s 139us/step - loss: 0.1649 - accuracy: 0.9548 - val_loss: 1.1552 - val_accuracy: 0.6447\n",
      "Epoch 62/100\n",
      "177/177 [==============================] - 0s 177us/step - loss: 0.1618 - accuracy: 0.9661 - val_loss: 1.3421 - val_accuracy: 0.6316\n",
      "Epoch 63/100\n",
      "177/177 [==============================] - 0s 197us/step - loss: 0.1607 - accuracy: 0.9661 - val_loss: 1.2467 - val_accuracy: 0.6447\n",
      "Epoch 64/100\n",
      "177/177 [==============================] - 0s 221us/step - loss: 0.1620 - accuracy: 0.9661 - val_loss: 1.1985 - val_accuracy: 0.6579\n",
      "Epoch 65/100\n",
      "177/177 [==============================] - 0s 434us/step - loss: 0.1571 - accuracy: 0.9661 - val_loss: 1.2400 - val_accuracy: 0.6447\n",
      "Epoch 66/100\n",
      "177/177 [==============================] - 0s 277us/step - loss: 0.1685 - accuracy: 0.9548 - val_loss: 1.4118 - val_accuracy: 0.6053\n",
      "Epoch 67/100\n",
      "177/177 [==============================] - 0s 523us/step - loss: 0.1592 - accuracy: 0.9605 - val_loss: 1.2578 - val_accuracy: 0.5789\n",
      "Epoch 68/100\n",
      "177/177 [==============================] - 0s 217us/step - loss: 0.1626 - accuracy: 0.9605 - val_loss: 1.2205 - val_accuracy: 0.6316\n",
      "Epoch 69/100\n",
      "177/177 [==============================] - 0s 708us/step - loss: 0.1594 - accuracy: 0.9774 - val_loss: 1.3449 - val_accuracy: 0.6316\n",
      "Epoch 70/100\n",
      "177/177 [==============================] - 0s 353us/step - loss: 0.1585 - accuracy: 0.9605 - val_loss: 1.2266 - val_accuracy: 0.6316\n",
      "Epoch 71/100\n",
      "177/177 [==============================] - 0s 325us/step - loss: 0.1585 - accuracy: 0.9548 - val_loss: 1.2194 - val_accuracy: 0.6579\n",
      "Epoch 72/100\n",
      "177/177 [==============================] - 0s 187us/step - loss: 0.1789 - accuracy: 0.9718 - val_loss: 1.1529 - val_accuracy: 0.6316\n",
      "Epoch 73/100\n",
      "177/177 [==============================] - 0s 190us/step - loss: 0.4852 - accuracy: 0.9379 - val_loss: 1.0650 - val_accuracy: 0.6579\n",
      "Epoch 74/100\n",
      "177/177 [==============================] - 0s 135us/step - loss: 0.4356 - accuracy: 0.9209 - val_loss: 1.8433 - val_accuracy: 0.6184\n",
      "Epoch 75/100\n",
      "177/177 [==============================] - 0s 122us/step - loss: 0.2310 - accuracy: 0.9492 - val_loss: 1.3988 - val_accuracy: 0.5921\n",
      "Epoch 76/100\n",
      "177/177 [==============================] - 0s 263us/step - loss: 0.7523 - accuracy: 0.8814 - val_loss: 1.1256 - val_accuracy: 0.6579\n",
      "Epoch 77/100\n",
      "177/177 [==============================] - 0s 243us/step - loss: 0.9204 - accuracy: 0.8814 - val_loss: 3.2135 - val_accuracy: 0.6053\n",
      "Epoch 78/100\n",
      "177/177 [==============================] - 0s 293us/step - loss: 1.1339 - accuracy: 0.9322 - val_loss: 2.5038 - val_accuracy: 0.5789\n",
      "Epoch 79/100\n",
      "177/177 [==============================] - 0s 188us/step - loss: 0.8557 - accuracy: 0.9266 - val_loss: 2.2262 - val_accuracy: 0.6184\n",
      "Epoch 80/100\n",
      "177/177 [==============================] - 0s 205us/step - loss: 0.4645 - accuracy: 0.8927 - val_loss: 1.5956 - val_accuracy: 0.6184\n",
      "Epoch 81/100\n",
      "177/177 [==============================] - 0s 276us/step - loss: 0.3394 - accuracy: 0.9153 - val_loss: 1.5958 - val_accuracy: 0.5921\n",
      "Epoch 82/100\n",
      "177/177 [==============================] - 0s 170us/step - loss: 0.3605 - accuracy: 0.9435 - val_loss: 1.5084 - val_accuracy: 0.6184\n",
      "Epoch 83/100\n",
      "177/177 [==============================] - 0s 214us/step - loss: 0.1932 - accuracy: 0.9492 - val_loss: 1.2486 - val_accuracy: 0.6447\n",
      "Epoch 84/100\n",
      "177/177 [==============================] - 0s 110us/step - loss: 0.1859 - accuracy: 0.9548 - val_loss: 1.2368 - val_accuracy: 0.6711\n",
      "Epoch 85/100\n",
      "177/177 [==============================] - 0s 104us/step - loss: 0.1739 - accuracy: 0.9548 - val_loss: 1.2567 - val_accuracy: 0.6711\n",
      "Epoch 86/100\n",
      "177/177 [==============================] - 0s 103us/step - loss: 0.1837 - accuracy: 0.9718 - val_loss: 1.3093 - val_accuracy: 0.6447\n",
      "Epoch 87/100\n",
      "177/177 [==============================] - 0s 101us/step - loss: 0.2074 - accuracy: 0.9492 - val_loss: 1.5912 - val_accuracy: 0.6184\n",
      "Epoch 88/100\n",
      "177/177 [==============================] - 0s 97us/step - loss: 0.2484 - accuracy: 0.9492 - val_loss: 1.3831 - val_accuracy: 0.5921\n",
      "Epoch 89/100\n",
      "177/177 [==============================] - 0s 107us/step - loss: 0.1779 - accuracy: 0.9661 - val_loss: 1.2916 - val_accuracy: 0.6184\n",
      "Epoch 90/100\n",
      "177/177 [==============================] - 0s 142us/step - loss: 0.1588 - accuracy: 0.9661 - val_loss: 1.4513 - val_accuracy: 0.6184\n",
      "Epoch 91/100\n",
      "177/177 [==============================] - 0s 114us/step - loss: 0.1504 - accuracy: 0.9605 - val_loss: 1.3287 - val_accuracy: 0.6316\n",
      "Epoch 92/100\n",
      "177/177 [==============================] - 0s 110us/step - loss: 0.1354 - accuracy: 0.9718 - val_loss: 1.3059 - val_accuracy: 0.6053\n",
      "Epoch 93/100\n",
      "177/177 [==============================] - 0s 128us/step - loss: 0.1427 - accuracy: 0.9548 - val_loss: 1.3384 - val_accuracy: 0.6316\n",
      "Epoch 94/100\n",
      "177/177 [==============================] - 0s 153us/step - loss: 0.1339 - accuracy: 0.9718 - val_loss: 1.3286 - val_accuracy: 0.6316\n",
      "Epoch 95/100\n",
      "177/177 [==============================] - 0s 262us/step - loss: 0.1315 - accuracy: 0.9661 - val_loss: 1.3356 - val_accuracy: 0.6316\n",
      "Epoch 96/100\n",
      "177/177 [==============================] - 0s 200us/step - loss: 0.1282 - accuracy: 0.9661 - val_loss: 1.3410 - val_accuracy: 0.6184\n",
      "Epoch 97/100\n",
      "177/177 [==============================] - 0s 196us/step - loss: 0.1324 - accuracy: 0.9605 - val_loss: 1.2880 - val_accuracy: 0.6579\n",
      "Epoch 98/100\n",
      "177/177 [==============================] - 0s 257us/step - loss: 0.1238 - accuracy: 0.9774 - val_loss: 1.4046 - val_accuracy: 0.6316\n",
      "Epoch 99/100\n",
      "177/177 [==============================] - 0s 266us/step - loss: 0.1473 - accuracy: 0.9492 - val_loss: 1.3481 - val_accuracy: 0.6447\n",
      "Epoch 100/100\n",
      "177/177 [==============================] - 0s 176us/step - loss: 0.1471 - accuracy: 0.9661 - val_loss: 1.3339 - val_accuracy: 0.6316\n"
     ]
    }
   ],
   "source": [
    "hist2 = model2.fit(X_train, y_train,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 95.46%\n"
     ]
    }
   ],
   "source": [
    "print('train accuracy: %.2f%%' % (np.mean(hist2.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba2 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_2.xlsx\",\n",
    "                        sheet_name=1,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NRS210</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999887</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>8.851192e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>Grady1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.625329</td>\n",
       "      <td>0.369782</td>\n",
       "      <td>4.889404e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>CFBRSa29</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999098</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>6.335156e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>CFBRSa03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.647338</td>\n",
       "      <td>0.331796</td>\n",
       "      <td>2.086646e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>217</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.613342</td>\n",
       "      <td>0.381903</td>\n",
       "      <td>4.754707e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>NRS265</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.025601</td>\n",
       "      <td>0.687962</td>\n",
       "      <td>2.864372e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>NY439</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.161947</td>\n",
       "      <td>0.266501</td>\n",
       "      <td>5.715521e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>CFBRSa05</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.652983</td>\n",
       "      <td>0.254172</td>\n",
       "      <td>9.284494e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>NRS205</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000927</td>\n",
       "      <td>0.033760</td>\n",
       "      <td>9.653131e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>CA105</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.736115</td>\n",
       "      <td>0.260109</td>\n",
       "      <td>3.775318e-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>608 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     phage    strain  phenotype  prediction         0  \\\n",
       "0       p0017kpresabs_qual    NRS210          2           0  0.999887   \n",
       "1       p0017kpresabs_qual    Grady1          0           0  0.625329   \n",
       "2       p0017kpresabs_qual  CFBRSa29          2           0  0.999098   \n",
       "3       p0017kpresabs_qual  CFBRSa03          0           0  0.647338   \n",
       "4       p0017kpresabs_qual       217          1           0  0.613342   \n",
       "..                     ...       ...        ...         ...       ...   \n",
       "603  p0040presabsSTCC_qual    NRS265          1           1  0.025601   \n",
       "604  p0040presabsSTCC_qual     NY439          2           2  0.161947   \n",
       "605  p0040presabsSTCC_qual  CFBRSa05          0           0  0.652983   \n",
       "606  p0040presabsSTCC_qual    NRS205          2           2  0.000927   \n",
       "607  p0040presabsSTCC_qual     CA105          1           0  0.736115   \n",
       "\n",
       "            1             2  \n",
       "0    0.000112  8.851192e-07  \n",
       "1    0.369782  4.889404e-03  \n",
       "2    0.000269  6.335156e-04  \n",
       "3    0.331796  2.086646e-02  \n",
       "4    0.381903  4.754707e-03  \n",
       "..        ...           ...  \n",
       "603  0.687962  2.864372e-01  \n",
       "604  0.266501  5.715521e-01  \n",
       "605  0.254172  9.284494e-02  \n",
       "606  0.033760  9.653131e-01  \n",
       "607  0.260109  3.775318e-03  \n",
       "\n",
       "[608 rows x 7 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.43840000e-02, 1.60354990e-01, 7.65261050e-01],\n",
       "       [5.75868960e-01, 4.23837500e-01, 2.93562500e-04],\n",
       "       [2.06685980e-01, 2.94262170e-01, 4.99051800e-01],\n",
       "       [1.00446410e-01, 8.20179800e-01, 7.93738000e-02],\n",
       "       [1.63093390e-01, 7.73944560e-01, 6.29620000e-02],\n",
       "       [1.15806780e-01, 7.69957070e-01, 1.14236120e-01],\n",
       "       [5.42172700e-02, 9.22629800e-01, 2.31529850e-02],\n",
       "       [2.17800420e-03, 4.38636870e-03, 9.93435600e-01],\n",
       "       [5.26644480e-02, 3.76925770e-02, 9.09642930e-01],\n",
       "       [1.02666944e-01, 7.95859300e-01, 1.01473846e-01],\n",
       "       [3.14865080e-01, 6.53080640e-01, 3.20542570e-02],\n",
       "       [6.90679700e-03, 7.29548450e-01, 2.63544700e-01],\n",
       "       [1.06337580e-01, 2.74829700e-01, 6.18832770e-01],\n",
       "       [3.07671900e-01, 1.50208520e-01, 5.42119500e-01],\n",
       "       [3.31465000e-01, 4.43395530e-01, 2.25139450e-01],\n",
       "       [8.92775000e-02, 5.85423600e-01, 3.25298900e-01],\n",
       "       [2.55964930e-03, 5.61172240e-03, 9.91828600e-01],\n",
       "       [2.42558480e-01, 2.66818400e-01, 4.90623030e-01],\n",
       "       [8.86217100e-02, 1.27096640e-01, 7.84281600e-01],\n",
       "       [1.26317710e-01, 6.03760060e-01, 2.69922200e-01],\n",
       "       [3.56036300e-01, 4.46879300e-01, 1.97084460e-01],\n",
       "       [6.23429800e-02, 1.17848390e-01, 8.19808600e-01],\n",
       "       [8.94297500e-01, 1.55016520e-02, 9.02009100e-02],\n",
       "       [3.06395680e-01, 3.10246700e-01, 3.83357600e-01],\n",
       "       [8.56819600e-01, 1.31543770e-01, 1.16366430e-02],\n",
       "       [5.41845700e-02, 6.41221340e-01, 3.04594100e-01],\n",
       "       [1.78036960e-01, 6.92261500e-01, 1.29701520e-01],\n",
       "       [9.04273100e-01, 9.42025260e-02, 1.52435860e-03],\n",
       "       [8.86217100e-02, 1.27096640e-01, 7.84281600e-01],\n",
       "       [9.01119600e-01, 9.88153440e-02, 6.50515650e-05],\n",
       "       [4.55566450e-03, 1.60981450e-01, 8.34462800e-01],\n",
       "       [6.59110500e-03, 4.47540020e-02, 9.48654900e-01],\n",
       "       [2.07291470e-03, 5.84152160e-01, 4.13774880e-01],\n",
       "       [9.38654500e-01, 5.94669900e-02, 1.87849980e-03],\n",
       "       [5.40817760e-03, 6.23592140e-01, 3.70999720e-01],\n",
       "       [4.33493260e-02, 9.20016050e-01, 3.66345570e-02],\n",
       "       [1.03040930e-02, 6.72722000e-02, 9.22423700e-01],\n",
       "       [8.30694100e-01, 1.66105990e-01, 3.19991960e-03],\n",
       "       [4.47077100e-01, 5.51889400e-01, 1.03340250e-03],\n",
       "       [2.39245600e-03, 1.31961030e-01, 8.65646500e-01],\n",
       "       [7.74234160e-02, 3.34818740e-02, 8.89094770e-01],\n",
       "       [1.86298610e-01, 2.73960700e-01, 5.39740600e-01],\n",
       "       [1.55075430e-01, 2.57031080e-01, 5.87893400e-01],\n",
       "       [5.91148920e-02, 8.20013940e-01, 1.20871186e-01],\n",
       "       [1.66228580e-01, 6.19814000e-01, 2.13957430e-01],\n",
       "       [9.24283500e-02, 8.18303050e-01, 8.92686100e-02],\n",
       "       [4.91109500e-01, 3.31042230e-01, 1.77848220e-01],\n",
       "       [9.94030400e-02, 8.78496650e-01, 2.21002980e-02],\n",
       "       [1.28401350e-02, 1.62552120e-01, 8.24607800e-01],\n",
       "       [1.22836430e-01, 6.17572200e-01, 2.59591300e-01],\n",
       "       [2.14681680e-01, 3.68288840e-01, 4.17029530e-01],\n",
       "       [4.37734800e-03, 4.64142770e-03, 9.90981300e-01],\n",
       "       [2.83195300e-02, 2.93137340e-01, 6.78543150e-01],\n",
       "       [5.72313100e-02, 5.66468060e-01, 3.76300630e-01],\n",
       "       [5.78367670e-02, 9.27355050e-01, 1.48081840e-02],\n",
       "       [1.02623490e-05, 9.99467300e-01, 5.22417370e-04],\n",
       "       [1.78484500e-01, 5.92645900e-01, 2.28869590e-01],\n",
       "       [7.78093700e-01, 2.10143280e-01, 1.17630230e-02],\n",
       "       [3.60774960e-01, 6.30507800e-01, 8.71718700e-03],\n",
       "       [2.36839100e-02, 9.00114500e-01, 7.62016250e-02],\n",
       "       [2.83590180e-02, 1.72808220e-01, 7.98832700e-01],\n",
       "       [9.69521550e-02, 2.16938050e-01, 6.86109800e-01],\n",
       "       [1.38608920e-01, 1.29960920e-01, 7.31430200e-01],\n",
       "       [1.60635800e-01, 2.66365800e-01, 5.72998400e-01],\n",
       "       [4.25383300e-02, 8.95082830e-01, 6.23788460e-02],\n",
       "       [2.10834760e-01, 2.22705720e-01, 5.66459600e-01],\n",
       "       [3.69639520e-01, 5.00259600e-01, 1.30100880e-01],\n",
       "       [3.45072400e-02, 3.05002330e-01, 6.60490450e-01],\n",
       "       [1.59472360e-01, 8.40456900e-01, 7.07034700e-05],\n",
       "       [2.80123680e-01, 3.17802600e-01, 4.02073680e-01],\n",
       "       [3.07372330e-01, 2.79043820e-01, 4.13583840e-01],\n",
       "       [2.56011240e-02, 6.87961700e-01, 2.86437180e-01],\n",
       "       [1.61947350e-01, 2.66500620e-01, 5.71552100e-01],\n",
       "       [6.52983070e-01, 2.54172030e-01, 9.28449400e-02],\n",
       "       [9.27129640e-04, 3.37597360e-02, 9.65313140e-01],\n",
       "       [7.36115460e-01, 2.60109250e-01, 3.77531770e-03]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob2 = df_proba2[df_proba2['phage']=='p0040presabsSTCC_qual'].iloc[:,-3:]\n",
    "y_prob2 = y_prob2.to_numpy()\n",
    "y_prob2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7528018903746926"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo2 = rocauc_ovo(y_test, y_prob2, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7528018903746926"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr2 = rocauc_ovr(y_test, y_prob2, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=345,\n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat3 = pd.DataFrame(X_test.iloc[:,0])\n",
    "dat3['test'] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>NRS191</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>CFBREBSa135</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>NRS064</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>NY224</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>NRS035</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>BCH-SA-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>504</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>GA27</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>BCH-SA-13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  test\n",
       "165       NRS191     2\n",
       "64   CFBREBSa135     0\n",
       "121       NRS064     1\n",
       "228        NY224     1\n",
       "114       NRS035     1\n",
       "..           ...   ...\n",
       "16     BCH-SA-01     0\n",
       "13           504     0\n",
       "96          GA27     2\n",
       "177       NRS209     1\n",
       "28     BCH-SA-13     1\n",
       "\n",
       "[76 rows x 2 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(['id'], axis=1)\n",
    "X_test = X_test.drop(['id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 177 samples, validate on 76 samples\n",
      "Epoch 1/100\n",
      "177/177 [==============================] - 0s 1ms/step - loss: 2.0879 - accuracy: 0.4068 - val_loss: 1.8626 - val_accuracy: 0.3026\n",
      "Epoch 2/100\n",
      "177/177 [==============================] - 0s 254us/step - loss: 1.0469 - accuracy: 0.4689 - val_loss: 1.1992 - val_accuracy: 0.3816\n",
      "Epoch 3/100\n",
      "177/177 [==============================] - 0s 258us/step - loss: 1.2567 - accuracy: 0.5254 - val_loss: 1.1634 - val_accuracy: 0.3947\n",
      "Epoch 4/100\n",
      "177/177 [==============================] - 0s 214us/step - loss: 1.2061 - accuracy: 0.5424 - val_loss: 1.3853 - val_accuracy: 0.4211\n",
      "Epoch 5/100\n",
      "177/177 [==============================] - 0s 217us/step - loss: 1.5367 - accuracy: 0.5085 - val_loss: 1.3924 - val_accuracy: 0.4211\n",
      "Epoch 6/100\n",
      "177/177 [==============================] - 0s 217us/step - loss: 1.5927 - accuracy: 0.5537 - val_loss: 2.0409 - val_accuracy: 0.3816\n",
      "Epoch 7/100\n",
      "177/177 [==============================] - 0s 208us/step - loss: 1.6523 - accuracy: 0.5424 - val_loss: 1.3041 - val_accuracy: 0.3816\n",
      "Epoch 8/100\n",
      "177/177 [==============================] - 0s 227us/step - loss: 1.3331 - accuracy: 0.5989 - val_loss: 1.3812 - val_accuracy: 0.4211\n",
      "Epoch 9/100\n",
      "177/177 [==============================] - 0s 232us/step - loss: 1.5753 - accuracy: 0.5706 - val_loss: 1.6410 - val_accuracy: 0.4342\n",
      "Epoch 10/100\n",
      "177/177 [==============================] - 0s 210us/step - loss: 1.3256 - accuracy: 0.5424 - val_loss: 1.0352 - val_accuracy: 0.5263\n",
      "Epoch 11/100\n",
      "177/177 [==============================] - 0s 327us/step - loss: 2.0751 - accuracy: 0.5198 - val_loss: 2.0188 - val_accuracy: 0.4342\n",
      "Epoch 12/100\n",
      "177/177 [==============================] - 0s 269us/step - loss: 1.9309 - accuracy: 0.5480 - val_loss: 1.5933 - val_accuracy: 0.3947\n",
      "Epoch 13/100\n",
      "177/177 [==============================] - 0s 252us/step - loss: 1.8289 - accuracy: 0.5819 - val_loss: 1.5566 - val_accuracy: 0.4211\n",
      "Epoch 14/100\n",
      "177/177 [==============================] - 0s 206us/step - loss: 1.1834 - accuracy: 0.6780 - val_loss: 1.4853 - val_accuracy: 0.4737\n",
      "Epoch 15/100\n",
      "177/177 [==============================] - 0s 259us/step - loss: 0.8872 - accuracy: 0.6554 - val_loss: 1.0912 - val_accuracy: 0.4737\n",
      "Epoch 16/100\n",
      "177/177 [==============================] - 0s 206us/step - loss: 1.0540 - accuracy: 0.6102 - val_loss: 1.6296 - val_accuracy: 0.4605\n",
      "Epoch 17/100\n",
      "177/177 [==============================] - 0s 378us/step - loss: 1.2228 - accuracy: 0.6441 - val_loss: 2.4770 - val_accuracy: 0.4868\n",
      "Epoch 18/100\n",
      "177/177 [==============================] - 0s 274us/step - loss: 5.3770 - accuracy: 0.6045 - val_loss: 5.2346 - val_accuracy: 0.3947\n",
      "Epoch 19/100\n",
      "177/177 [==============================] - 0s 267us/step - loss: 4.5940 - accuracy: 0.6102 - val_loss: 1.9809 - val_accuracy: 0.4605\n",
      "Epoch 20/100\n",
      "177/177 [==============================] - 0s 190us/step - loss: 2.4247 - accuracy: 0.5819 - val_loss: 1.3357 - val_accuracy: 0.4079\n",
      "Epoch 21/100\n",
      "177/177 [==============================] - 0s 209us/step - loss: 1.6326 - accuracy: 0.6384 - val_loss: 2.0997 - val_accuracy: 0.4079\n",
      "Epoch 22/100\n",
      "177/177 [==============================] - 0s 257us/step - loss: 1.3786 - accuracy: 0.6384 - val_loss: 1.1969 - val_accuracy: 0.5132\n",
      "Epoch 23/100\n",
      "177/177 [==============================] - 0s 297us/step - loss: 0.9127 - accuracy: 0.6610 - val_loss: 1.3822 - val_accuracy: 0.4737\n",
      "Epoch 24/100\n",
      "177/177 [==============================] - 0s 259us/step - loss: 1.0313 - accuracy: 0.7062 - val_loss: 1.0834 - val_accuracy: 0.4605\n",
      "Epoch 25/100\n",
      "177/177 [==============================] - 0s 253us/step - loss: 0.8427 - accuracy: 0.6836 - val_loss: 1.1066 - val_accuracy: 0.4342\n",
      "Epoch 26/100\n",
      "177/177 [==============================] - 0s 232us/step - loss: 0.9570 - accuracy: 0.7006 - val_loss: 1.1297 - val_accuracy: 0.5000\n",
      "Epoch 27/100\n",
      "177/177 [==============================] - 0s 254us/step - loss: 1.2437 - accuracy: 0.7119 - val_loss: 1.1099 - val_accuracy: 0.4868\n",
      "Epoch 28/100\n",
      "177/177 [==============================] - 0s 209us/step - loss: 0.7319 - accuracy: 0.7006 - val_loss: 1.0998 - val_accuracy: 0.5132\n",
      "Epoch 29/100\n",
      "177/177 [==============================] - 0s 314us/step - loss: 1.0371 - accuracy: 0.7006 - val_loss: 1.0345 - val_accuracy: 0.5263\n",
      "Epoch 30/100\n",
      "177/177 [==============================] - 0s 156us/step - loss: 0.6785 - accuracy: 0.7345 - val_loss: 1.6307 - val_accuracy: 0.5263\n",
      "Epoch 31/100\n",
      "177/177 [==============================] - 0s 174us/step - loss: 0.8504 - accuracy: 0.7175 - val_loss: 1.1022 - val_accuracy: 0.5000\n",
      "Epoch 32/100\n",
      "177/177 [==============================] - 0s 137us/step - loss: 0.6296 - accuracy: 0.7514 - val_loss: 1.1055 - val_accuracy: 0.5263\n",
      "Epoch 33/100\n",
      "177/177 [==============================] - 0s 135us/step - loss: 0.7831 - accuracy: 0.7684 - val_loss: 1.0112 - val_accuracy: 0.5526\n",
      "Epoch 34/100\n",
      "177/177 [==============================] - 0s 162us/step - loss: 0.7714 - accuracy: 0.7288 - val_loss: 1.2394 - val_accuracy: 0.5395\n",
      "Epoch 35/100\n",
      "177/177 [==============================] - 0s 129us/step - loss: 1.3966 - accuracy: 0.7175 - val_loss: 1.5130 - val_accuracy: 0.5132\n",
      "Epoch 36/100\n",
      "177/177 [==============================] - 0s 139us/step - loss: 0.9810 - accuracy: 0.7062 - val_loss: 1.1299 - val_accuracy: 0.5395\n",
      "Epoch 37/100\n",
      "177/177 [==============================] - 0s 166us/step - loss: 0.8630 - accuracy: 0.7119 - val_loss: 1.0748 - val_accuracy: 0.5395\n",
      "Epoch 38/100\n",
      "177/177 [==============================] - 0s 164us/step - loss: 0.8638 - accuracy: 0.7571 - val_loss: 1.0964 - val_accuracy: 0.5263\n",
      "Epoch 39/100\n",
      "177/177 [==============================] - 0s 234us/step - loss: 0.7689 - accuracy: 0.7514 - val_loss: 1.1285 - val_accuracy: 0.5658\n",
      "Epoch 40/100\n",
      "177/177 [==============================] - 0s 781us/step - loss: 0.7164 - accuracy: 0.7684 - val_loss: 1.0444 - val_accuracy: 0.5395\n",
      "Epoch 41/100\n",
      "177/177 [==============================] - 0s 412us/step - loss: 0.6751 - accuracy: 0.7966 - val_loss: 1.0441 - val_accuracy: 0.5658\n",
      "Epoch 42/100\n",
      "177/177 [==============================] - 0s 326us/step - loss: 0.7970 - accuracy: 0.7514 - val_loss: 1.0017 - val_accuracy: 0.5658\n",
      "Epoch 43/100\n",
      "177/177 [==============================] - 0s 320us/step - loss: 0.7047 - accuracy: 0.7910 - val_loss: 1.1697 - val_accuracy: 0.4737\n",
      "Epoch 44/100\n",
      "177/177 [==============================] - 0s 373us/step - loss: 0.9781 - accuracy: 0.7119 - val_loss: 1.2567 - val_accuracy: 0.5526\n",
      "Epoch 45/100\n",
      "177/177 [==============================] - 0s 319us/step - loss: 1.3699 - accuracy: 0.7288 - val_loss: 2.9778 - val_accuracy: 0.5263\n",
      "Epoch 46/100\n",
      "177/177 [==============================] - 0s 208us/step - loss: 2.6786 - accuracy: 0.7006 - val_loss: 3.4102 - val_accuracy: 0.5000\n",
      "Epoch 47/100\n",
      "177/177 [==============================] - 0s 152us/step - loss: 1.6107 - accuracy: 0.7401 - val_loss: 1.2556 - val_accuracy: 0.4868\n",
      "Epoch 48/100\n",
      "177/177 [==============================] - 0s 248us/step - loss: 1.3554 - accuracy: 0.7175 - val_loss: 1.4041 - val_accuracy: 0.5000\n",
      "Epoch 49/100\n",
      "177/177 [==============================] - 0s 358us/step - loss: 0.7240 - accuracy: 0.7627 - val_loss: 1.6436 - val_accuracy: 0.5526\n",
      "Epoch 50/100\n",
      "177/177 [==============================] - 0s 295us/step - loss: 0.6564 - accuracy: 0.7740 - val_loss: 1.1643 - val_accuracy: 0.5395\n",
      "Epoch 51/100\n",
      "177/177 [==============================] - 0s 331us/step - loss: 0.6767 - accuracy: 0.8136 - val_loss: 1.3685 - val_accuracy: 0.5658\n",
      "Epoch 52/100\n",
      "177/177 [==============================] - 0s 316us/step - loss: 0.6379 - accuracy: 0.8079 - val_loss: 1.1169 - val_accuracy: 0.5789\n",
      "Epoch 53/100\n",
      "177/177 [==============================] - 0s 357us/step - loss: 0.5611 - accuracy: 0.7966 - val_loss: 1.2013 - val_accuracy: 0.5395\n",
      "Epoch 54/100\n",
      "177/177 [==============================] - 0s 302us/step - loss: 0.4643 - accuracy: 0.8475 - val_loss: 1.1540 - val_accuracy: 0.6053\n",
      "Epoch 55/100\n",
      "177/177 [==============================] - 0s 286us/step - loss: 0.4585 - accuracy: 0.8531 - val_loss: 1.2346 - val_accuracy: 0.5658\n",
      "Epoch 56/100\n",
      "177/177 [==============================] - 0s 215us/step - loss: 0.5839 - accuracy: 0.8192 - val_loss: 1.2163 - val_accuracy: 0.5789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "177/177 [==============================] - 0s 176us/step - loss: 0.6251 - accuracy: 0.8023 - val_loss: 1.3753 - val_accuracy: 0.5526\n",
      "Epoch 58/100\n",
      "177/177 [==============================] - 0s 162us/step - loss: 0.6119 - accuracy: 0.7910 - val_loss: 1.2778 - val_accuracy: 0.5000\n",
      "Epoch 59/100\n",
      "177/177 [==============================] - 0s 275us/step - loss: 0.7384 - accuracy: 0.7966 - val_loss: 1.2939 - val_accuracy: 0.5789\n",
      "Epoch 60/100\n",
      "177/177 [==============================] - 0s 363us/step - loss: 0.6418 - accuracy: 0.8362 - val_loss: 1.2806 - val_accuracy: 0.5263\n",
      "Epoch 61/100\n",
      "177/177 [==============================] - 0s 358us/step - loss: 0.4708 - accuracy: 0.8531 - val_loss: 1.3276 - val_accuracy: 0.5921\n",
      "Epoch 62/100\n",
      "177/177 [==============================] - 0s 234us/step - loss: 0.5776 - accuracy: 0.8475 - val_loss: 1.3404 - val_accuracy: 0.5658\n",
      "Epoch 63/100\n",
      "177/177 [==============================] - 0s 382us/step - loss: 0.6107 - accuracy: 0.8531 - val_loss: 2.0003 - val_accuracy: 0.5526\n",
      "Epoch 64/100\n",
      "177/177 [==============================] - 0s 406us/step - loss: 0.9322 - accuracy: 0.8588 - val_loss: 2.1520 - val_accuracy: 0.5921\n",
      "Epoch 65/100\n",
      "177/177 [==============================] - 0s 370us/step - loss: 0.6404 - accuracy: 0.8757 - val_loss: 1.3261 - val_accuracy: 0.5789\n",
      "Epoch 66/100\n",
      "177/177 [==============================] - 0s 288us/step - loss: 0.6322 - accuracy: 0.7797 - val_loss: 1.2073 - val_accuracy: 0.6184\n",
      "Epoch 67/100\n",
      "177/177 [==============================] - 0s 247us/step - loss: 0.4186 - accuracy: 0.8475 - val_loss: 1.5242 - val_accuracy: 0.5395\n",
      "Epoch 68/100\n",
      "177/177 [==============================] - 0s 202us/step - loss: 0.4618 - accuracy: 0.8531 - val_loss: 1.3402 - val_accuracy: 0.5395\n",
      "Epoch 69/100\n",
      "177/177 [==============================] - 0s 274us/step - loss: 0.4048 - accuracy: 0.8418 - val_loss: 1.5021 - val_accuracy: 0.6053\n",
      "Epoch 70/100\n",
      "177/177 [==============================] - 0s 333us/step - loss: 0.5085 - accuracy: 0.8531 - val_loss: 1.2953 - val_accuracy: 0.5921\n",
      "Epoch 71/100\n",
      "177/177 [==============================] - 0s 329us/step - loss: 0.4951 - accuracy: 0.8249 - val_loss: 1.2934 - val_accuracy: 0.5921\n",
      "Epoch 72/100\n",
      "177/177 [==============================] - 0s 253us/step - loss: 0.6598 - accuracy: 0.8475 - val_loss: 1.3734 - val_accuracy: 0.5789\n",
      "Epoch 73/100\n",
      "177/177 [==============================] - 0s 316us/step - loss: 0.6693 - accuracy: 0.8418 - val_loss: 1.2716 - val_accuracy: 0.5921\n",
      "Epoch 74/100\n",
      "177/177 [==============================] - 0s 364us/step - loss: 0.4653 - accuracy: 0.8418 - val_loss: 1.5832 - val_accuracy: 0.5526\n",
      "Epoch 75/100\n",
      "177/177 [==============================] - 0s 218us/step - loss: 0.6269 - accuracy: 0.8701 - val_loss: 1.3369 - val_accuracy: 0.5658\n",
      "Epoch 76/100\n",
      "177/177 [==============================] - 0s 371us/step - loss: 0.5097 - accuracy: 0.8305 - val_loss: 1.5405 - val_accuracy: 0.5263\n",
      "Epoch 77/100\n",
      "177/177 [==============================] - 0s 353us/step - loss: 0.6212 - accuracy: 0.8644 - val_loss: 1.7865 - val_accuracy: 0.5526\n",
      "Epoch 78/100\n",
      "177/177 [==============================] - 0s 190us/step - loss: 0.4606 - accuracy: 0.8531 - val_loss: 1.3488 - val_accuracy: 0.5658\n",
      "Epoch 79/100\n",
      "177/177 [==============================] - 0s 168us/step - loss: 0.4420 - accuracy: 0.8757 - val_loss: 1.3297 - val_accuracy: 0.5658\n",
      "Epoch 80/100\n",
      "177/177 [==============================] - 0s 144us/step - loss: 0.3973 - accuracy: 0.8757 - val_loss: 1.4512 - val_accuracy: 0.5526\n",
      "Epoch 81/100\n",
      "177/177 [==============================] - 0s 139us/step - loss: 0.4163 - accuracy: 0.8418 - val_loss: 1.2993 - val_accuracy: 0.5526\n",
      "Epoch 82/100\n",
      "177/177 [==============================] - 0s 161us/step - loss: 0.3936 - accuracy: 0.8870 - val_loss: 1.2976 - val_accuracy: 0.6053\n",
      "Epoch 83/100\n",
      "177/177 [==============================] - 0s 157us/step - loss: 0.3602 - accuracy: 0.8983 - val_loss: 1.3258 - val_accuracy: 0.6053\n",
      "Epoch 84/100\n",
      "177/177 [==============================] - 0s 144us/step - loss: 0.3388 - accuracy: 0.8927 - val_loss: 1.3576 - val_accuracy: 0.5658\n",
      "Epoch 85/100\n",
      "177/177 [==============================] - 0s 416us/step - loss: 0.3673 - accuracy: 0.8927 - val_loss: 1.5939 - val_accuracy: 0.5789\n",
      "Epoch 86/100\n",
      "177/177 [==============================] - 0s 262us/step - loss: 0.5431 - accuracy: 0.8644 - val_loss: 1.6564 - val_accuracy: 0.5526\n",
      "Epoch 87/100\n",
      "177/177 [==============================] - 0s 218us/step - loss: 0.3110 - accuracy: 0.8983 - val_loss: 1.3830 - val_accuracy: 0.5789\n",
      "Epoch 88/100\n",
      "177/177 [==============================] - 0s 238us/step - loss: 0.3119 - accuracy: 0.8983 - val_loss: 1.5790 - val_accuracy: 0.5658\n",
      "Epoch 89/100\n",
      "177/177 [==============================] - 0s 164us/step - loss: 0.3709 - accuracy: 0.8870 - val_loss: 1.4609 - val_accuracy: 0.5921\n",
      "Epoch 90/100\n",
      "177/177 [==============================] - 0s 191us/step - loss: 0.3496 - accuracy: 0.8927 - val_loss: 1.4891 - val_accuracy: 0.5789\n",
      "Epoch 91/100\n",
      "177/177 [==============================] - 0s 154us/step - loss: 0.3954 - accuracy: 0.8983 - val_loss: 1.5055 - val_accuracy: 0.5658\n",
      "Epoch 92/100\n",
      "177/177 [==============================] - 0s 153us/step - loss: 0.4500 - accuracy: 0.8814 - val_loss: 1.4254 - val_accuracy: 0.5789\n",
      "Epoch 93/100\n",
      "177/177 [==============================] - 0s 200us/step - loss: 0.4332 - accuracy: 0.8927 - val_loss: 1.5691 - val_accuracy: 0.5921\n",
      "Epoch 94/100\n",
      "177/177 [==============================] - 0s 174us/step - loss: 0.5266 - accuracy: 0.8192 - val_loss: 1.4794 - val_accuracy: 0.5658\n",
      "Epoch 95/100\n",
      "177/177 [==============================] - 0s 240us/step - loss: 0.5927 - accuracy: 0.8701 - val_loss: 1.6490 - val_accuracy: 0.5658\n",
      "Epoch 96/100\n",
      "177/177 [==============================] - 0s 169us/step - loss: 0.3674 - accuracy: 0.9266 - val_loss: 1.5180 - val_accuracy: 0.5526\n",
      "Epoch 97/100\n",
      "177/177 [==============================] - 0s 221us/step - loss: 0.3774 - accuracy: 0.8757 - val_loss: 1.4840 - val_accuracy: 0.5921\n",
      "Epoch 98/100\n",
      "177/177 [==============================] - 0s 218us/step - loss: 0.2853 - accuracy: 0.9153 - val_loss: 1.5448 - val_accuracy: 0.5658\n",
      "Epoch 99/100\n",
      "177/177 [==============================] - 0s 174us/step - loss: 0.4832 - accuracy: 0.8701 - val_loss: 1.4951 - val_accuracy: 0.5658\n",
      "Epoch 100/100\n",
      "177/177 [==============================] - 0s 144us/step - loss: 0.2859 - accuracy: 0.9153 - val_loss: 1.5211 - val_accuracy: 0.5658\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a3daec0f0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.fit(X_train, y_train,\n",
    "          batch_size=16, epochs=100,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 0s 125us/step\n",
      "test accuracy: 56.58%\n"
     ]
    }
   ],
   "source": [
    "acc_test3 = model3.evaluate(X_test, y_test)[1]\n",
    "print('test accuracy: %.2f%%' % (acc_test3*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 1, 1, 2, 1, 0, 1, 1, 1, 2, 0, 2, 1, 2, 1, 0, 0, 2, 0, 0, 1,\n",
       "       2, 2, 2, 2, 2, 2, 0, 1, 2, 0, 1, 1, 2, 0, 0, 0, 0, 2, 0, 2, 1, 1,\n",
       "       2, 0, 2, 0, 0, 1, 2, 2, 0, 0, 2, 2, 1, 1, 0, 0, 0, 1, 1, 1, 2, 0,\n",
       "       0, 2, 2, 1, 1, 0, 1, 1, 0, 1])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred3 = model3.predict_classes(X_test)\n",
    "pred3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>NRS191</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>CFBREBSa135</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>NRS064</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>NY224</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>NRS035</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>BCH-SA-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>504</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>GA27</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>BCH-SA-13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  test  pred\n",
       "165       NRS191     2     2\n",
       "64   CFBREBSa135     0     0\n",
       "121       NRS064     1     1\n",
       "228        NY224     1     1\n",
       "114       NRS035     1     2\n",
       "..           ...   ...   ...\n",
       "16     BCH-SA-01     0     0\n",
       "13           504     0     1\n",
       "96          GA27     2     1\n",
       "177       NRS209     1     0\n",
       "28     BCH-SA-13     1     1\n",
       "\n",
       "[76 rows x 3 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat3['pred'] = pred3\n",
    "dat3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba3 = model3.predict_proba(X_test)\n",
    "dat_proba3 = pd.DataFrame(proba3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.045016</td>\n",
       "      <td>0.407758</td>\n",
       "      <td>0.547227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.873840</td>\n",
       "      <td>0.126159</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.152263</td>\n",
       "      <td>0.507359</td>\n",
       "      <td>0.340378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.188533</td>\n",
       "      <td>0.611574</td>\n",
       "      <td>0.199892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.221121</td>\n",
       "      <td>0.120028</td>\n",
       "      <td>0.658852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.930541</td>\n",
       "      <td>0.063563</td>\n",
       "      <td>0.005897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.044764</td>\n",
       "      <td>0.857755</td>\n",
       "      <td>0.097481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.277946</td>\n",
       "      <td>0.538438</td>\n",
       "      <td>0.183617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.421018</td>\n",
       "      <td>0.355939</td>\n",
       "      <td>0.223043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.005484</td>\n",
       "      <td>0.994479</td>\n",
       "      <td>0.000037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2\n",
       "0   0.045016  0.407758  0.547227\n",
       "1   0.873840  0.126159  0.000001\n",
       "2   0.152263  0.507359  0.340378\n",
       "3   0.188533  0.611574  0.199892\n",
       "4   0.221121  0.120028  0.658852\n",
       "..       ...       ...       ...\n",
       "71  0.930541  0.063563  0.005897\n",
       "72  0.044764  0.857755  0.097481\n",
       "73  0.277946  0.538438  0.183617\n",
       "74  0.421018  0.355939  0.223043\n",
       "75  0.005484  0.994479  0.000037\n",
       "\n",
       "[76 rows x 3 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba3.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba3.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat3.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/3p40pST.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 177 samples, validate on 76 samples\n",
      "Epoch 1/100\n",
      "177/177 [==============================] - 0s 244us/step - loss: 0.2279 - accuracy: 0.9322 - val_loss: 1.5155 - val_accuracy: 0.5789\n",
      "Epoch 2/100\n",
      "177/177 [==============================] - 0s 297us/step - loss: 0.2667 - accuracy: 0.9209 - val_loss: 1.5713 - val_accuracy: 0.5789\n",
      "Epoch 3/100\n",
      "177/177 [==============================] - 0s 245us/step - loss: 0.2626 - accuracy: 0.9209 - val_loss: 1.6000 - val_accuracy: 0.5526\n",
      "Epoch 4/100\n",
      "177/177 [==============================] - 0s 257us/step - loss: 0.2335 - accuracy: 0.9266 - val_loss: 1.5858 - val_accuracy: 0.5658\n",
      "Epoch 5/100\n",
      "177/177 [==============================] - 0s 205us/step - loss: 0.2772 - accuracy: 0.8983 - val_loss: 1.6683 - val_accuracy: 0.5789\n",
      "Epoch 6/100\n",
      "177/177 [==============================] - 0s 203us/step - loss: 0.3017 - accuracy: 0.9040 - val_loss: 1.6611 - val_accuracy: 0.5526\n",
      "Epoch 7/100\n",
      "177/177 [==============================] - 0s 201us/step - loss: 0.5454 - accuracy: 0.8588 - val_loss: 1.8672 - val_accuracy: 0.5263\n",
      "Epoch 8/100\n",
      "177/177 [==============================] - 0s 238us/step - loss: 0.4016 - accuracy: 0.8757 - val_loss: 1.5484 - val_accuracy: 0.5132\n",
      "Epoch 9/100\n",
      "177/177 [==============================] - 0s 189us/step - loss: 0.2625 - accuracy: 0.9266 - val_loss: 1.6815 - val_accuracy: 0.4737\n",
      "Epoch 10/100\n",
      "177/177 [==============================] - 0s 216us/step - loss: 0.3711 - accuracy: 0.8757 - val_loss: 1.5881 - val_accuracy: 0.5921\n",
      "Epoch 11/100\n",
      "177/177 [==============================] - 0s 283us/step - loss: 0.2833 - accuracy: 0.9266 - val_loss: 1.6082 - val_accuracy: 0.5658\n",
      "Epoch 12/100\n",
      "177/177 [==============================] - 0s 188us/step - loss: 0.2882 - accuracy: 0.9266 - val_loss: 1.6628 - val_accuracy: 0.5526\n",
      "Epoch 13/100\n",
      "177/177 [==============================] - 0s 221us/step - loss: 0.2261 - accuracy: 0.9096 - val_loss: 1.7222 - val_accuracy: 0.5526\n",
      "Epoch 14/100\n",
      "177/177 [==============================] - 0s 221us/step - loss: 0.9131 - accuracy: 0.8757 - val_loss: 2.6084 - val_accuracy: 0.5263\n",
      "Epoch 15/100\n",
      "177/177 [==============================] - 0s 234us/step - loss: 0.6583 - accuracy: 0.8701 - val_loss: 2.1353 - val_accuracy: 0.5263\n",
      "Epoch 16/100\n",
      "177/177 [==============================] - 0s 209us/step - loss: 0.3418 - accuracy: 0.8983 - val_loss: 1.7675 - val_accuracy: 0.5000\n",
      "Epoch 17/100\n",
      "177/177 [==============================] - 0s 210us/step - loss: 0.3319 - accuracy: 0.8983 - val_loss: 1.6834 - val_accuracy: 0.5263\n",
      "Epoch 18/100\n",
      "177/177 [==============================] - 0s 242us/step - loss: 0.4226 - accuracy: 0.9096 - val_loss: 1.6176 - val_accuracy: 0.5658\n",
      "Epoch 19/100\n",
      "177/177 [==============================] - 0s 246us/step - loss: 0.2160 - accuracy: 0.9266 - val_loss: 1.7165 - val_accuracy: 0.5132\n",
      "Epoch 20/100\n",
      "177/177 [==============================] - 0s 248us/step - loss: 0.2440 - accuracy: 0.9322 - val_loss: 1.7244 - val_accuracy: 0.5263\n",
      "Epoch 21/100\n",
      "177/177 [==============================] - 0s 219us/step - loss: 0.2222 - accuracy: 0.9322 - val_loss: 1.6139 - val_accuracy: 0.5263\n",
      "Epoch 22/100\n",
      "177/177 [==============================] - 0s 255us/step - loss: 0.2060 - accuracy: 0.9266 - val_loss: 1.7033 - val_accuracy: 0.5263\n",
      "Epoch 23/100\n",
      "177/177 [==============================] - 0s 237us/step - loss: 0.2471 - accuracy: 0.9266 - val_loss: 1.6965 - val_accuracy: 0.5395\n",
      "Epoch 24/100\n",
      "177/177 [==============================] - 0s 223us/step - loss: 0.2230 - accuracy: 0.9209 - val_loss: 1.7425 - val_accuracy: 0.5526\n",
      "Epoch 25/100\n",
      "177/177 [==============================] - 0s 241us/step - loss: 0.2936 - accuracy: 0.9040 - val_loss: 1.7780 - val_accuracy: 0.5263\n",
      "Epoch 26/100\n",
      "177/177 [==============================] - 0s 253us/step - loss: 0.2953 - accuracy: 0.9153 - val_loss: 1.6599 - val_accuracy: 0.5395\n",
      "Epoch 27/100\n",
      "177/177 [==============================] - 0s 254us/step - loss: 0.1978 - accuracy: 0.9322 - val_loss: 1.7412 - val_accuracy: 0.5395\n",
      "Epoch 28/100\n",
      "177/177 [==============================] - 0s 233us/step - loss: 0.2069 - accuracy: 0.9379 - val_loss: 1.7348 - val_accuracy: 0.5526\n",
      "Epoch 29/100\n",
      "177/177 [==============================] - 0s 212us/step - loss: 0.2500 - accuracy: 0.9266 - val_loss: 1.7153 - val_accuracy: 0.5263\n",
      "Epoch 30/100\n",
      "177/177 [==============================] - 0s 212us/step - loss: 0.2636 - accuracy: 0.9435 - val_loss: 1.7477 - val_accuracy: 0.5395\n",
      "Epoch 31/100\n",
      "177/177 [==============================] - 0s 240us/step - loss: 0.1829 - accuracy: 0.9266 - val_loss: 1.8087 - val_accuracy: 0.5658\n",
      "Epoch 32/100\n",
      "177/177 [==============================] - 0s 246us/step - loss: 0.1771 - accuracy: 0.9266 - val_loss: 1.7616 - val_accuracy: 0.5395\n",
      "Epoch 33/100\n",
      "177/177 [==============================] - 0s 297us/step - loss: 0.2546 - accuracy: 0.9548 - val_loss: 1.7754 - val_accuracy: 0.5526\n",
      "Epoch 34/100\n",
      "177/177 [==============================] - 0s 307us/step - loss: 0.2209 - accuracy: 0.9379 - val_loss: 1.7922 - val_accuracy: 0.5263\n",
      "Epoch 35/100\n",
      "177/177 [==============================] - 0s 510us/step - loss: 0.2967 - accuracy: 0.9209 - val_loss: 1.7628 - val_accuracy: 0.5395\n",
      "Epoch 36/100\n",
      "177/177 [==============================] - 0s 672us/step - loss: 0.1674 - accuracy: 0.9548 - val_loss: 1.8182 - val_accuracy: 0.5263\n",
      "Epoch 37/100\n",
      "177/177 [==============================] - 0s 284us/step - loss: 0.2100 - accuracy: 0.9492 - val_loss: 1.8348 - val_accuracy: 0.5395\n",
      "Epoch 38/100\n",
      "177/177 [==============================] - 0s 257us/step - loss: 0.1868 - accuracy: 0.9379 - val_loss: 1.8643 - val_accuracy: 0.5000\n",
      "Epoch 39/100\n",
      "177/177 [==============================] - 0s 254us/step - loss: 0.3720 - accuracy: 0.9096 - val_loss: 1.8241 - val_accuracy: 0.5132\n",
      "Epoch 40/100\n",
      "177/177 [==============================] - 0s 255us/step - loss: 0.2347 - accuracy: 0.9435 - val_loss: 1.8605 - val_accuracy: 0.5395\n",
      "Epoch 41/100\n",
      "177/177 [==============================] - 0s 344us/step - loss: 0.2399 - accuracy: 0.9322 - val_loss: 1.8858 - val_accuracy: 0.5263\n",
      "Epoch 42/100\n",
      "177/177 [==============================] - 0s 270us/step - loss: 0.2058 - accuracy: 0.9492 - val_loss: 1.8252 - val_accuracy: 0.5395\n",
      "Epoch 43/100\n",
      "177/177 [==============================] - 0s 259us/step - loss: 0.1828 - accuracy: 0.9548 - val_loss: 1.8697 - val_accuracy: 0.5263\n",
      "Epoch 44/100\n",
      "177/177 [==============================] - 0s 1ms/step - loss: 0.1684 - accuracy: 0.9492 - val_loss: 1.8339 - val_accuracy: 0.5263\n",
      "Epoch 45/100\n",
      "177/177 [==============================] - 0s 341us/step - loss: 0.1810 - accuracy: 0.9605 - val_loss: 1.8549 - val_accuracy: 0.5395\n",
      "Epoch 46/100\n",
      "177/177 [==============================] - 0s 225us/step - loss: 0.2379 - accuracy: 0.9435 - val_loss: 1.8570 - val_accuracy: 0.5395\n",
      "Epoch 47/100\n",
      "177/177 [==============================] - 0s 241us/step - loss: 0.2205 - accuracy: 0.9605 - val_loss: 1.8736 - val_accuracy: 0.5395\n",
      "Epoch 48/100\n",
      "177/177 [==============================] - 0s 361us/step - loss: 0.1856 - accuracy: 0.9492 - val_loss: 1.8745 - val_accuracy: 0.5395\n",
      "Epoch 49/100\n",
      "177/177 [==============================] - 0s 1ms/step - loss: 0.1841 - accuracy: 0.9492 - val_loss: 1.8942 - val_accuracy: 0.5526\n",
      "Epoch 50/100\n",
      "177/177 [==============================] - 0s 352us/step - loss: 0.1811 - accuracy: 0.9492 - val_loss: 1.8927 - val_accuracy: 0.5526\n",
      "Epoch 51/100\n",
      "177/177 [==============================] - 0s 273us/step - loss: 0.2362 - accuracy: 0.9605 - val_loss: 1.8751 - val_accuracy: 0.5263\n",
      "Epoch 52/100\n",
      "177/177 [==============================] - 0s 251us/step - loss: 0.2518 - accuracy: 0.9492 - val_loss: 1.9174 - val_accuracy: 0.5395\n",
      "Epoch 53/100\n",
      "177/177 [==============================] - 0s 414us/step - loss: 0.1763 - accuracy: 0.9548 - val_loss: 2.0236 - val_accuracy: 0.5132\n",
      "Epoch 54/100\n",
      "177/177 [==============================] - 0s 247us/step - loss: 0.1756 - accuracy: 0.9548 - val_loss: 2.0449 - val_accuracy: 0.5132\n",
      "Epoch 55/100\n",
      "177/177 [==============================] - 0s 247us/step - loss: 0.1760 - accuracy: 0.9435 - val_loss: 1.9133 - val_accuracy: 0.4868\n",
      "Epoch 56/100\n",
      "177/177 [==============================] - 0s 225us/step - loss: 0.2459 - accuracy: 0.9266 - val_loss: 2.0313 - val_accuracy: 0.5263\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "177/177 [==============================] - 0s 232us/step - loss: 0.2776 - accuracy: 0.9266 - val_loss: 2.0380 - val_accuracy: 0.5658\n",
      "Epoch 58/100\n",
      "177/177 [==============================] - 0s 248us/step - loss: 0.1961 - accuracy: 0.9153 - val_loss: 1.8605 - val_accuracy: 0.5526\n",
      "Epoch 59/100\n",
      "177/177 [==============================] - 0s 205us/step - loss: 0.1919 - accuracy: 0.9379 - val_loss: 1.8463 - val_accuracy: 0.5263\n",
      "Epoch 60/100\n",
      "177/177 [==============================] - 0s 167us/step - loss: 0.2452 - accuracy: 0.9661 - val_loss: 1.8740 - val_accuracy: 0.5395\n",
      "Epoch 61/100\n",
      "177/177 [==============================] - 0s 204us/step - loss: 0.1761 - accuracy: 0.9492 - val_loss: 1.9183 - val_accuracy: 0.5000\n",
      "Epoch 62/100\n",
      "177/177 [==============================] - 0s 162us/step - loss: 0.2160 - accuracy: 0.9492 - val_loss: 1.9003 - val_accuracy: 0.5263\n",
      "Epoch 63/100\n",
      "177/177 [==============================] - 0s 191us/step - loss: 0.2874 - accuracy: 0.9209 - val_loss: 1.9066 - val_accuracy: 0.5395\n",
      "Epoch 64/100\n",
      "177/177 [==============================] - 0s 179us/step - loss: 0.2226 - accuracy: 0.9605 - val_loss: 1.8866 - val_accuracy: 0.5132\n",
      "Epoch 65/100\n",
      "177/177 [==============================] - 0s 310us/step - loss: 0.1726 - accuracy: 0.9605 - val_loss: 1.9668 - val_accuracy: 0.5395\n",
      "Epoch 66/100\n",
      "177/177 [==============================] - 0s 494us/step - loss: 0.1873 - accuracy: 0.9548 - val_loss: 1.9951 - val_accuracy: 0.5000\n",
      "Epoch 67/100\n",
      "177/177 [==============================] - 0s 332us/step - loss: 0.2478 - accuracy: 0.9605 - val_loss: 1.9333 - val_accuracy: 0.5395\n",
      "Epoch 68/100\n",
      "177/177 [==============================] - 0s 815us/step - loss: 0.1421 - accuracy: 0.9605 - val_loss: 1.9795 - val_accuracy: 0.5132\n",
      "Epoch 69/100\n",
      "177/177 [==============================] - 0s 733us/step - loss: 0.1551 - accuracy: 0.9718 - val_loss: 2.0063 - val_accuracy: 0.5395\n",
      "Epoch 70/100\n",
      "177/177 [==============================] - 0s 361us/step - loss: 0.1522 - accuracy: 0.9492 - val_loss: 2.0187 - val_accuracy: 0.5132\n",
      "Epoch 71/100\n",
      "177/177 [==============================] - 0s 366us/step - loss: 0.1789 - accuracy: 0.9661 - val_loss: 2.1212 - val_accuracy: 0.5000\n",
      "Epoch 72/100\n",
      "177/177 [==============================] - 0s 268us/step - loss: 0.1530 - accuracy: 0.9661 - val_loss: 2.0396 - val_accuracy: 0.5132\n",
      "Epoch 73/100\n",
      "177/177 [==============================] - 0s 307us/step - loss: 0.1472 - accuracy: 0.9548 - val_loss: 2.0850 - val_accuracy: 0.5395\n",
      "Epoch 74/100\n",
      "177/177 [==============================] - 0s 336us/step - loss: 0.1504 - accuracy: 0.9548 - val_loss: 2.0988 - val_accuracy: 0.5263\n",
      "Epoch 75/100\n",
      "177/177 [==============================] - 0s 287us/step - loss: 0.2222 - accuracy: 0.9379 - val_loss: 2.0274 - val_accuracy: 0.5263\n",
      "Epoch 76/100\n",
      "177/177 [==============================] - 0s 309us/step - loss: 0.2268 - accuracy: 0.9548 - val_loss: 2.0312 - val_accuracy: 0.5132\n",
      "Epoch 77/100\n",
      "177/177 [==============================] - 0s 241us/step - loss: 0.1657 - accuracy: 0.9548 - val_loss: 2.1034 - val_accuracy: 0.5132\n",
      "Epoch 78/100\n",
      "177/177 [==============================] - 0s 296us/step - loss: 0.2054 - accuracy: 0.9605 - val_loss: 2.0806 - val_accuracy: 0.5395\n",
      "Epoch 79/100\n",
      "177/177 [==============================] - 0s 294us/step - loss: 0.1394 - accuracy: 0.9661 - val_loss: 2.0961 - val_accuracy: 0.5132\n",
      "Epoch 80/100\n",
      "177/177 [==============================] - 0s 215us/step - loss: 0.2504 - accuracy: 0.9379 - val_loss: 2.0591 - val_accuracy: 0.5132\n",
      "Epoch 81/100\n",
      "177/177 [==============================] - 0s 217us/step - loss: 0.2365 - accuracy: 0.9492 - val_loss: 2.1183 - val_accuracy: 0.5263\n",
      "Epoch 82/100\n",
      "177/177 [==============================] - 0s 315us/step - loss: 0.1670 - accuracy: 0.9548 - val_loss: 2.1004 - val_accuracy: 0.5000\n",
      "Epoch 83/100\n",
      "177/177 [==============================] - 0s 459us/step - loss: 0.2686 - accuracy: 0.9492 - val_loss: 2.1040 - val_accuracy: 0.5395\n",
      "Epoch 84/100\n",
      "177/177 [==============================] - 0s 508us/step - loss: 0.1968 - accuracy: 0.9492 - val_loss: 2.1426 - val_accuracy: 0.5263\n",
      "Epoch 85/100\n",
      "177/177 [==============================] - 0s 334us/step - loss: 0.1514 - accuracy: 0.9548 - val_loss: 2.1794 - val_accuracy: 0.5132\n",
      "Epoch 86/100\n",
      "177/177 [==============================] - 0s 301us/step - loss: 0.1675 - accuracy: 0.9548 - val_loss: 2.1638 - val_accuracy: 0.5000\n",
      "Epoch 87/100\n",
      "177/177 [==============================] - 0s 355us/step - loss: 0.1511 - accuracy: 0.9661 - val_loss: 2.0900 - val_accuracy: 0.5132\n",
      "Epoch 88/100\n",
      "177/177 [==============================] - 0s 456us/step - loss: 0.2114 - accuracy: 0.9605 - val_loss: 2.1494 - val_accuracy: 0.5263\n",
      "Epoch 89/100\n",
      "177/177 [==============================] - 0s 311us/step - loss: 0.1542 - accuracy: 0.9548 - val_loss: 2.1668 - val_accuracy: 0.5000\n",
      "Epoch 90/100\n",
      "177/177 [==============================] - 0s 298us/step - loss: 0.2091 - accuracy: 0.9605 - val_loss: 2.2211 - val_accuracy: 0.5000\n",
      "Epoch 91/100\n",
      "177/177 [==============================] - 0s 338us/step - loss: 0.1462 - accuracy: 0.9605 - val_loss: 2.1707 - val_accuracy: 0.5000\n",
      "Epoch 92/100\n",
      "177/177 [==============================] - 0s 504us/step - loss: 0.1447 - accuracy: 0.9661 - val_loss: 2.1531 - val_accuracy: 0.5000\n",
      "Epoch 93/100\n",
      "177/177 [==============================] - 0s 301us/step - loss: 0.2199 - accuracy: 0.9661 - val_loss: 2.1762 - val_accuracy: 0.5132\n",
      "Epoch 94/100\n",
      "177/177 [==============================] - 0s 230us/step - loss: 0.1338 - accuracy: 0.9774 - val_loss: 2.2090 - val_accuracy: 0.5000\n",
      "Epoch 95/100\n",
      "177/177 [==============================] - 0s 588us/step - loss: 0.1046 - accuracy: 0.9774 - val_loss: 2.1804 - val_accuracy: 0.5000\n",
      "Epoch 96/100\n",
      "177/177 [==============================] - 0s 403us/step - loss: 0.1207 - accuracy: 0.9661 - val_loss: 2.1333 - val_accuracy: 0.5395\n",
      "Epoch 97/100\n",
      "177/177 [==============================] - 0s 323us/step - loss: 0.1643 - accuracy: 0.9661 - val_loss: 2.2139 - val_accuracy: 0.5000\n",
      "Epoch 98/100\n",
      "177/177 [==============================] - 0s 250us/step - loss: 0.1314 - accuracy: 0.9661 - val_loss: 2.2570 - val_accuracy: 0.5000\n",
      "Epoch 99/100\n",
      "177/177 [==============================] - 0s 318us/step - loss: 0.1971 - accuracy: 0.9266 - val_loss: 2.3378 - val_accuracy: 0.5132\n",
      "Epoch 100/100\n",
      "177/177 [==============================] - 0s 392us/step - loss: 0.3112 - accuracy: 0.9209 - val_loss: 2.2374 - val_accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "hist3 = model3.fit(X_train, y_train,\n",
    "          batch_size=16, epochs=100,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 93.91%\n"
     ]
    }
   ],
   "source": [
    "print('train accuracy: %.2f%%' % (np.mean(hist3.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba3 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_2.xlsx\",\n",
    "                        sheet_name=2,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NY360</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.165526e-02</td>\n",
       "      <td>4.848140e-01</td>\n",
       "      <td>0.493531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>EUH25</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>9.986388e-01</td>\n",
       "      <td>1.245148e-03</td>\n",
       "      <td>0.000116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>EUH15</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9.227520e-04</td>\n",
       "      <td>1.424882e-02</td>\n",
       "      <td>0.984828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NRS241</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.374333e-01</td>\n",
       "      <td>1.614128e-01</td>\n",
       "      <td>0.001154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>SR2852</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.976981e-09</td>\n",
       "      <td>5.145955e-10</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>BCH-SA-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.305407e-01</td>\n",
       "      <td>6.356251e-02</td>\n",
       "      <td>0.005897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>504</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.476389e-02</td>\n",
       "      <td>8.577548e-01</td>\n",
       "      <td>0.097481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>GA27</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.779456e-01</td>\n",
       "      <td>5.384378e-01</td>\n",
       "      <td>0.183617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>NRS209</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.210180e-01</td>\n",
       "      <td>3.559393e-01</td>\n",
       "      <td>0.223043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>BCH-SA-13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.484084e-03</td>\n",
       "      <td>9.944786e-01</td>\n",
       "      <td>0.000037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>608 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     phage     strain  phenotype  prediction             0  \\\n",
       "0       p0017kpresabs_qual      NY360          2           2  2.165526e-02   \n",
       "1       p0017kpresabs_qual      EUH25          2           0  9.986388e-01   \n",
       "2       p0017kpresabs_qual      EUH15          2           2  9.227520e-04   \n",
       "3       p0017kpresabs_qual     NRS241          0           0  8.374333e-01   \n",
       "4       p0017kpresabs_qual     SR2852          2           2  3.976981e-09   \n",
       "..                     ...        ...        ...         ...           ...   \n",
       "603  p0040presabsSTCC_qual  BCH-SA-01          0           0  9.305407e-01   \n",
       "604  p0040presabsSTCC_qual        504          0           1  4.476389e-02   \n",
       "605  p0040presabsSTCC_qual       GA27          2           1  2.779456e-01   \n",
       "606  p0040presabsSTCC_qual     NRS209          1           0  4.210180e-01   \n",
       "607  p0040presabsSTCC_qual  BCH-SA-13          1           1  5.484084e-03   \n",
       "\n",
       "                1         2  \n",
       "0    4.848140e-01  0.493531  \n",
       "1    1.245148e-03  0.000116  \n",
       "2    1.424882e-02  0.984828  \n",
       "3    1.614128e-01  0.001154  \n",
       "4    5.145955e-10  1.000000  \n",
       "..            ...       ...  \n",
       "603  6.356251e-02  0.005897  \n",
       "604  8.577548e-01  0.097481  \n",
       "605  5.384378e-01  0.183617  \n",
       "606  3.559393e-01  0.223043  \n",
       "607  9.944786e-01  0.000037  \n",
       "\n",
       "[608 rows x 7 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.50156550e-02, 4.07757820e-01, 5.47226550e-01],\n",
       "       [8.73840000e-01, 1.26158580e-01, 1.37086910e-06],\n",
       "       [1.52262800e-01, 5.07358800e-01, 3.40378430e-01],\n",
       "       [1.88533440e-01, 6.11574350e-01, 1.99892160e-01],\n",
       "       [2.21120770e-01, 1.20027676e-01, 6.58851560e-01],\n",
       "       [1.33512830e-02, 8.20513300e-01, 1.66135420e-01],\n",
       "       [9.93191400e-01, 6.79963450e-03, 8.95339500e-06],\n",
       "       [2.46647900e-01, 7.44919500e-01, 8.43269900e-03],\n",
       "       [4.17147200e-03, 7.21055200e-01, 2.74773300e-01],\n",
       "       [4.80132130e-03, 8.53080800e-01, 1.42117840e-01],\n",
       "       [2.34693440e-01, 1.82161480e-02, 7.47090400e-01],\n",
       "       [7.66563600e-01, 1.04251890e-01, 1.29184620e-01],\n",
       "       [1.00096810e-02, 1.29414470e-01, 8.60575850e-01],\n",
       "       [7.73045350e-04, 8.84358600e-01, 1.14868370e-01],\n",
       "       [1.55933620e-01, 6.19436300e-02, 7.82122730e-01],\n",
       "       [3.62336780e-04, 9.90075050e-01, 9.56265400e-03],\n",
       "       [8.50974140e-01, 1.28803410e-02, 1.36145500e-01],\n",
       "       [8.41443300e-01, 1.12916710e-01, 4.56399900e-02],\n",
       "       [1.02246130e-01, 2.76264880e-01, 6.21489000e-01],\n",
       "       [9.69551000e-01, 3.02639380e-02, 1.85070200e-04],\n",
       "       [9.08403460e-01, 5.53505900e-02, 3.62460130e-02],\n",
       "       [4.63923350e-03, 9.95357800e-01, 2.92637000e-06],\n",
       "       [2.23597400e-01, 2.93469160e-01, 4.82933430e-01],\n",
       "       [6.56553500e-03, 4.68877900e-01, 5.24556500e-01],\n",
       "       [6.21391740e-03, 5.15986470e-03, 9.88626200e-01],\n",
       "       [2.41792510e-01, 1.59073190e-01, 5.99134300e-01],\n",
       "       [3.30539940e-02, 4.51677530e-01, 5.15268500e-01],\n",
       "       [2.96016410e-02, 3.46244360e-01, 6.24154000e-01],\n",
       "       [9.65569850e-01, 2.53532130e-03, 3.18948300e-02],\n",
       "       [9.53320200e-03, 7.22776600e-01, 2.67690240e-01],\n",
       "       [1.52584100e-01, 1.87359590e-01, 6.60056300e-01],\n",
       "       [9.88707200e-01, 1.10610950e-02, 2.31738610e-04],\n",
       "       [3.92400400e-02, 8.87307500e-01, 7.34525250e-02],\n",
       "       [1.06471240e-02, 7.96274600e-01, 1.93078230e-01],\n",
       "       [5.60787100e-04, 1.52967890e-03, 9.97909500e-01],\n",
       "       [8.43736400e-01, 5.62028180e-02, 1.00060770e-01],\n",
       "       [9.99918700e-01, 6.17290500e-05, 1.95878270e-05],\n",
       "       [9.63042200e-01, 3.61884300e-02, 7.69387400e-04],\n",
       "       [9.72954000e-01, 2.61047970e-02, 9.41216500e-04],\n",
       "       [9.48304400e-02, 5.00153040e-02, 8.55154200e-01],\n",
       "       [8.04263530e-01, 1.39474590e-01, 5.62618300e-02],\n",
       "       [1.04411820e-01, 1.82132940e-02, 8.77374950e-01],\n",
       "       [3.20265600e-03, 9.59941000e-01, 3.68563000e-02],\n",
       "       [6.38361200e-03, 9.93602930e-01, 1.35380790e-05],\n",
       "       [1.23329364e-01, 3.61878200e-01, 5.14792440e-01],\n",
       "       [5.10026800e-01, 4.23911150e-01, 6.60620700e-02],\n",
       "       [2.22580560e-02, 6.80514300e-02, 9.09690500e-01],\n",
       "       [9.82272740e-01, 1.73295550e-02, 3.97737340e-04],\n",
       "       [6.80550300e-01, 1.44923090e-01, 1.74526590e-01],\n",
       "       [5.10217670e-03, 9.63814740e-01, 3.10831000e-02],\n",
       "       [2.98954700e-03, 4.80761680e-02, 9.48934300e-01],\n",
       "       [1.09478000e-02, 4.48356330e-01, 5.40695900e-01],\n",
       "       [9.70556740e-01, 2.92615350e-02, 1.81744200e-04],\n",
       "       [8.21924570e-01, 1.77564780e-01, 5.10685100e-04],\n",
       "       [1.04411820e-01, 1.82132940e-02, 8.77374950e-01],\n",
       "       [2.52658840e-02, 9.54306200e-02, 8.79303460e-01],\n",
       "       [1.29985360e-03, 9.29280760e-01, 6.94194100e-02],\n",
       "       [2.41904760e-02, 9.75698650e-01, 1.10841320e-04],\n",
       "       [9.85478160e-01, 1.08164570e-02, 3.70535700e-03],\n",
       "       [9.99208750e-01, 6.24680540e-04, 1.66628570e-04],\n",
       "       [9.71522500e-01, 2.79692700e-02, 5.08185700e-04],\n",
       "       [6.62466400e-02, 9.33685700e-01, 6.76176100e-05],\n",
       "       [1.02089140e-02, 9.44499900e-01, 4.52911600e-02],\n",
       "       [2.41674600e-01, 7.13205340e-01, 4.51200230e-02],\n",
       "       [1.91150430e-01, 3.10097520e-01, 4.98752100e-01],\n",
       "       [4.02460070e-01, 3.90119000e-01, 2.07420990e-01],\n",
       "       [6.27898000e-01, 2.81170500e-01, 9.09316000e-02],\n",
       "       [2.41377400e-03, 4.03496000e-02, 9.57236600e-01],\n",
       "       [2.26141920e-02, 5.67304000e-02, 9.20655400e-01],\n",
       "       [1.24846900e-08, 9.82268330e-01, 1.77317080e-02],\n",
       "       [3.13834370e-04, 9.84601100e-01, 1.50851190e-02],\n",
       "       [9.30540740e-01, 6.35625050e-02, 5.89672940e-03],\n",
       "       [4.47638850e-02, 8.57754800e-01, 9.74812950e-02],\n",
       "       [2.77945600e-01, 5.38437800e-01, 1.83616560e-01],\n",
       "       [4.21017970e-01, 3.55939300e-01, 2.23042760e-01],\n",
       "       [5.48408400e-03, 9.94478600e-01, 3.73266000e-05]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob3 = df_proba3[df_proba3['phage']=='p0040presabsSTCC_qual'].iloc[:,-3:]\n",
    "y_prob3 = y_prob3.to_numpy()\n",
    "y_prob3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7187085396040204"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo3 = rocauc_ovo(y_test, y_prob3, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7187085396040204"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr3 = rocauc_ovr(y_test, y_prob3, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=456,\n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat4 = pd.DataFrame(X_test.iloc[:,0])\n",
    "dat4['test'] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>CFBREBSa121</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>BCH-SA-13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>CFBRSa23</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>CFBREBSa125</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>NRS247</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>NRS215</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>SR4152</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>NRS035</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>SR4187</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  test\n",
       "54   CFBREBSa121     1\n",
       "28     BCH-SA-13     1\n",
       "143       NRS148     2\n",
       "73      CFBRSa23     2\n",
       "57   CFBREBSa125     0\n",
       "..           ...   ...\n",
       "208       NRS247     1\n",
       "183       NRS215     1\n",
       "248       SR4152     2\n",
       "114       NRS035     1\n",
       "252       SR4187     2\n",
       "\n",
       "[76 rows x 2 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(['id'], axis=1)\n",
    "X_test = X_test.drop(['id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 177 samples, validate on 76 samples\n",
      "Epoch 1/100\n",
      "177/177 [==============================] - 0s 909us/step - loss: 3.6790 - accuracy: 0.3107 - val_loss: 4.0488 - val_accuracy: 0.3158\n",
      "Epoch 2/100\n",
      "177/177 [==============================] - 0s 121us/step - loss: 2.4450 - accuracy: 0.3390 - val_loss: 2.6795 - val_accuracy: 0.3816\n",
      "Epoch 3/100\n",
      "177/177 [==============================] - 0s 198us/step - loss: 1.9212 - accuracy: 0.3955 - val_loss: 2.2386 - val_accuracy: 0.3816\n",
      "Epoch 4/100\n",
      "177/177 [==============================] - 0s 163us/step - loss: 1.3075 - accuracy: 0.4068 - val_loss: 2.3380 - val_accuracy: 0.3947\n",
      "Epoch 5/100\n",
      "177/177 [==============================] - 0s 236us/step - loss: 1.2188 - accuracy: 0.4972 - val_loss: 1.9985 - val_accuracy: 0.4605\n",
      "Epoch 6/100\n",
      "177/177 [==============================] - 0s 233us/step - loss: 0.9939 - accuracy: 0.5424 - val_loss: 1.6562 - val_accuracy: 0.4605\n",
      "Epoch 7/100\n",
      "177/177 [==============================] - 0s 213us/step - loss: 0.9501 - accuracy: 0.5989 - val_loss: 1.6297 - val_accuracy: 0.4737\n",
      "Epoch 8/100\n",
      "177/177 [==============================] - 0s 152us/step - loss: 0.9680 - accuracy: 0.6102 - val_loss: 1.6645 - val_accuracy: 0.4342\n",
      "Epoch 9/100\n",
      "177/177 [==============================] - 0s 211us/step - loss: 0.8981 - accuracy: 0.6271 - val_loss: 1.6029 - val_accuracy: 0.4474\n",
      "Epoch 10/100\n",
      "177/177 [==============================] - 0s 152us/step - loss: 0.9057 - accuracy: 0.6328 - val_loss: 1.4786 - val_accuracy: 0.4211\n",
      "Epoch 11/100\n",
      "177/177 [==============================] - 0s 240us/step - loss: 0.8402 - accuracy: 0.6384 - val_loss: 1.3876 - val_accuracy: 0.4474\n",
      "Epoch 12/100\n",
      "177/177 [==============================] - 0s 166us/step - loss: 0.8899 - accuracy: 0.6441 - val_loss: 1.5973 - val_accuracy: 0.4605\n",
      "Epoch 13/100\n",
      "177/177 [==============================] - 0s 115us/step - loss: 0.8810 - accuracy: 0.6441 - val_loss: 1.2998 - val_accuracy: 0.3816\n",
      "Epoch 14/100\n",
      "177/177 [==============================] - 0s 122us/step - loss: 0.8095 - accuracy: 0.6384 - val_loss: 1.3293 - val_accuracy: 0.4342\n",
      "Epoch 15/100\n",
      "177/177 [==============================] - 0s 119us/step - loss: 0.7724 - accuracy: 0.7062 - val_loss: 1.2506 - val_accuracy: 0.4605\n",
      "Epoch 16/100\n",
      "177/177 [==============================] - 0s 139us/step - loss: 0.7406 - accuracy: 0.6836 - val_loss: 1.2680 - val_accuracy: 0.4737\n",
      "Epoch 17/100\n",
      "177/177 [==============================] - 0s 170us/step - loss: 0.7495 - accuracy: 0.7006 - val_loss: 1.1782 - val_accuracy: 0.4868\n",
      "Epoch 18/100\n",
      "177/177 [==============================] - 0s 138us/step - loss: 0.7669 - accuracy: 0.7119 - val_loss: 1.1986 - val_accuracy: 0.4605\n",
      "Epoch 19/100\n",
      "177/177 [==============================] - 0s 127us/step - loss: 0.6995 - accuracy: 0.7288 - val_loss: 1.2250 - val_accuracy: 0.4474\n",
      "Epoch 20/100\n",
      "177/177 [==============================] - 0s 177us/step - loss: 0.6773 - accuracy: 0.7514 - val_loss: 1.2002 - val_accuracy: 0.4474\n",
      "Epoch 21/100\n",
      "177/177 [==============================] - 0s 134us/step - loss: 0.7019 - accuracy: 0.7232 - val_loss: 1.3536 - val_accuracy: 0.4605\n",
      "Epoch 22/100\n",
      "177/177 [==============================] - 0s 136us/step - loss: 0.7023 - accuracy: 0.7345 - val_loss: 1.2462 - val_accuracy: 0.4737\n",
      "Epoch 23/100\n",
      "177/177 [==============================] - 0s 200us/step - loss: 0.6904 - accuracy: 0.7288 - val_loss: 1.4686 - val_accuracy: 0.4342\n",
      "Epoch 24/100\n",
      "177/177 [==============================] - 0s 170us/step - loss: 0.7240 - accuracy: 0.7571 - val_loss: 1.3915 - val_accuracy: 0.4474\n",
      "Epoch 25/100\n",
      "177/177 [==============================] - 0s 92us/step - loss: 0.6786 - accuracy: 0.7401 - val_loss: 1.3212 - val_accuracy: 0.4342\n",
      "Epoch 26/100\n",
      "177/177 [==============================] - 0s 109us/step - loss: 0.6996 - accuracy: 0.7627 - val_loss: 1.2918 - val_accuracy: 0.4868\n",
      "Epoch 27/100\n",
      "177/177 [==============================] - 0s 100us/step - loss: 0.6514 - accuracy: 0.7797 - val_loss: 1.3438 - val_accuracy: 0.4079\n",
      "Epoch 28/100\n",
      "177/177 [==============================] - 0s 101us/step - loss: 0.6546 - accuracy: 0.7345 - val_loss: 1.1814 - val_accuracy: 0.4605\n",
      "Epoch 29/100\n",
      "177/177 [==============================] - 0s 190us/step - loss: 0.6724 - accuracy: 0.7627 - val_loss: 1.3081 - val_accuracy: 0.4211\n",
      "Epoch 30/100\n",
      "177/177 [==============================] - 0s 240us/step - loss: 0.7435 - accuracy: 0.7175 - val_loss: 1.3562 - val_accuracy: 0.4211\n",
      "Epoch 31/100\n",
      "177/177 [==============================] - 0s 110us/step - loss: 0.7880 - accuracy: 0.7345 - val_loss: 1.5612 - val_accuracy: 0.4211\n",
      "Epoch 32/100\n",
      "177/177 [==============================] - 0s 112us/step - loss: 0.7612 - accuracy: 0.7684 - val_loss: 1.4901 - val_accuracy: 0.4342\n",
      "Epoch 33/100\n",
      "177/177 [==============================] - 0s 103us/step - loss: 0.8468 - accuracy: 0.7119 - val_loss: 1.7711 - val_accuracy: 0.4868\n",
      "Epoch 34/100\n",
      "177/177 [==============================] - 0s 114us/step - loss: 0.6951 - accuracy: 0.7345 - val_loss: 1.3554 - val_accuracy: 0.5000\n",
      "Epoch 35/100\n",
      "177/177 [==============================] - 0s 99us/step - loss: 0.7436 - accuracy: 0.7514 - val_loss: 1.6037 - val_accuracy: 0.4079\n",
      "Epoch 36/100\n",
      "177/177 [==============================] - 0s 114us/step - loss: 0.7771 - accuracy: 0.7175 - val_loss: 1.7514 - val_accuracy: 0.4079\n",
      "Epoch 37/100\n",
      "177/177 [==============================] - 0s 86us/step - loss: 0.5991 - accuracy: 0.7910 - val_loss: 1.2373 - val_accuracy: 0.4605\n",
      "Epoch 38/100\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.6775 - accuracy: 0.7910 - val_loss: 1.2555 - val_accuracy: 0.4474\n",
      "Epoch 39/100\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.5458 - accuracy: 0.7910 - val_loss: 1.2958 - val_accuracy: 0.4605\n",
      "Epoch 40/100\n",
      "177/177 [==============================] - 0s 142us/step - loss: 0.5507 - accuracy: 0.8023 - val_loss: 1.2276 - val_accuracy: 0.4737\n",
      "Epoch 41/100\n",
      "177/177 [==============================] - 0s 114us/step - loss: 0.5493 - accuracy: 0.7853 - val_loss: 1.2955 - val_accuracy: 0.4474\n",
      "Epoch 42/100\n",
      "177/177 [==============================] - 0s 133us/step - loss: 0.5807 - accuracy: 0.7627 - val_loss: 1.3254 - val_accuracy: 0.4474\n",
      "Epoch 43/100\n",
      "177/177 [==============================] - 0s 172us/step - loss: 0.5236 - accuracy: 0.8023 - val_loss: 1.3338 - val_accuracy: 0.4342\n",
      "Epoch 44/100\n",
      "177/177 [==============================] - 0s 141us/step - loss: 0.5694 - accuracy: 0.8023 - val_loss: 1.3480 - val_accuracy: 0.4474\n",
      "Epoch 45/100\n",
      "177/177 [==============================] - 0s 163us/step - loss: 0.5322 - accuracy: 0.7853 - val_loss: 1.1652 - val_accuracy: 0.4211\n",
      "Epoch 46/100\n",
      "177/177 [==============================] - 0s 251us/step - loss: 0.5056 - accuracy: 0.8023 - val_loss: 1.3432 - val_accuracy: 0.4605\n",
      "Epoch 47/100\n",
      "177/177 [==============================] - 0s 252us/step - loss: 0.5117 - accuracy: 0.8192 - val_loss: 1.1777 - val_accuracy: 0.4474\n",
      "Epoch 48/100\n",
      "177/177 [==============================] - 0s 172us/step - loss: 0.5077 - accuracy: 0.8362 - val_loss: 1.2152 - val_accuracy: 0.4342\n",
      "Epoch 49/100\n",
      "177/177 [==============================] - 0s 135us/step - loss: 0.4936 - accuracy: 0.8362 - val_loss: 1.3155 - val_accuracy: 0.4605\n",
      "Epoch 50/100\n",
      "177/177 [==============================] - 0s 121us/step - loss: 0.4738 - accuracy: 0.8249 - val_loss: 1.2004 - val_accuracy: 0.4342\n",
      "Epoch 51/100\n",
      "177/177 [==============================] - 0s 139us/step - loss: 0.4847 - accuracy: 0.8079 - val_loss: 1.4840 - val_accuracy: 0.4605\n",
      "Epoch 52/100\n",
      "177/177 [==============================] - 0s 126us/step - loss: 0.5152 - accuracy: 0.8136 - val_loss: 1.2196 - val_accuracy: 0.4737\n",
      "Epoch 53/100\n",
      "177/177 [==============================] - 0s 169us/step - loss: 0.4579 - accuracy: 0.8192 - val_loss: 1.3041 - val_accuracy: 0.4474\n",
      "Epoch 54/100\n",
      "177/177 [==============================] - 0s 120us/step - loss: 0.4957 - accuracy: 0.8305 - val_loss: 1.6234 - val_accuracy: 0.5000\n",
      "Epoch 55/100\n",
      "177/177 [==============================] - 0s 169us/step - loss: 0.5273 - accuracy: 0.8136 - val_loss: 1.2533 - val_accuracy: 0.4605\n",
      "Epoch 56/100\n",
      "177/177 [==============================] - 0s 128us/step - loss: 0.4514 - accuracy: 0.8475 - val_loss: 1.3466 - val_accuracy: 0.4211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "177/177 [==============================] - 0s 145us/step - loss: 0.4877 - accuracy: 0.8192 - val_loss: 1.5163 - val_accuracy: 0.4605\n",
      "Epoch 58/100\n",
      "177/177 [==============================] - 0s 150us/step - loss: 0.4608 - accuracy: 0.8305 - val_loss: 1.2087 - val_accuracy: 0.4474\n",
      "Epoch 59/100\n",
      "177/177 [==============================] - 0s 141us/step - loss: 0.5310 - accuracy: 0.8249 - val_loss: 1.1988 - val_accuracy: 0.4605\n",
      "Epoch 60/100\n",
      "177/177 [==============================] - 0s 125us/step - loss: 0.5984 - accuracy: 0.8079 - val_loss: 2.0378 - val_accuracy: 0.4868\n",
      "Epoch 61/100\n",
      "177/177 [==============================] - 0s 160us/step - loss: 0.6259 - accuracy: 0.8249 - val_loss: 1.2315 - val_accuracy: 0.4737\n",
      "Epoch 62/100\n",
      "177/177 [==============================] - 0s 126us/step - loss: 0.4690 - accuracy: 0.8249 - val_loss: 1.3871 - val_accuracy: 0.4474\n",
      "Epoch 63/100\n",
      "177/177 [==============================] - 0s 125us/step - loss: 0.4409 - accuracy: 0.8588 - val_loss: 1.3567 - val_accuracy: 0.4474\n",
      "Epoch 64/100\n",
      "177/177 [==============================] - 0s 141us/step - loss: 0.4318 - accuracy: 0.8418 - val_loss: 1.2310 - val_accuracy: 0.4605\n",
      "Epoch 65/100\n",
      "177/177 [==============================] - 0s 102us/step - loss: 0.4094 - accuracy: 0.8475 - val_loss: 1.2415 - val_accuracy: 0.4605\n",
      "Epoch 66/100\n",
      "177/177 [==============================] - 0s 111us/step - loss: 0.4023 - accuracy: 0.8644 - val_loss: 1.3066 - val_accuracy: 0.4605\n",
      "Epoch 67/100\n",
      "177/177 [==============================] - 0s 94us/step - loss: 0.5790 - accuracy: 0.8305 - val_loss: 1.6468 - val_accuracy: 0.4211\n",
      "Epoch 68/100\n",
      "177/177 [==============================] - 0s 117us/step - loss: 0.5083 - accuracy: 0.8305 - val_loss: 1.4069 - val_accuracy: 0.4737\n",
      "Epoch 69/100\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.4338 - accuracy: 0.8475 - val_loss: 1.4235 - val_accuracy: 0.4342\n",
      "Epoch 70/100\n",
      "177/177 [==============================] - 0s 94us/step - loss: 0.4140 - accuracy: 0.8531 - val_loss: 1.2712 - val_accuracy: 0.4342\n",
      "Epoch 71/100\n",
      "177/177 [==============================] - 0s 103us/step - loss: 0.3811 - accuracy: 0.8701 - val_loss: 1.3724 - val_accuracy: 0.4342\n",
      "Epoch 72/100\n",
      "177/177 [==============================] - 0s 110us/step - loss: 0.3817 - accuracy: 0.8757 - val_loss: 1.3049 - val_accuracy: 0.4737\n",
      "Epoch 73/100\n",
      "177/177 [==============================] - 0s 97us/step - loss: 0.3703 - accuracy: 0.8814 - val_loss: 1.1816 - val_accuracy: 0.5000\n",
      "Epoch 74/100\n",
      "177/177 [==============================] - 0s 118us/step - loss: 0.3645 - accuracy: 0.8814 - val_loss: 1.2608 - val_accuracy: 0.4737\n",
      "Epoch 75/100\n",
      "177/177 [==============================] - 0s 103us/step - loss: 0.3702 - accuracy: 0.8814 - val_loss: 1.4034 - val_accuracy: 0.4868\n",
      "Epoch 76/100\n",
      "177/177 [==============================] - 0s 135us/step - loss: 0.3702 - accuracy: 0.8757 - val_loss: 1.2448 - val_accuracy: 0.4868\n",
      "Epoch 77/100\n",
      "177/177 [==============================] - 0s 105us/step - loss: 0.4062 - accuracy: 0.8701 - val_loss: 1.2365 - val_accuracy: 0.5132\n",
      "Epoch 78/100\n",
      "177/177 [==============================] - 0s 102us/step - loss: 0.3680 - accuracy: 0.8927 - val_loss: 1.4204 - val_accuracy: 0.4737\n",
      "Epoch 79/100\n",
      "177/177 [==============================] - 0s 135us/step - loss: 0.3607 - accuracy: 0.8870 - val_loss: 1.2122 - val_accuracy: 0.4605\n",
      "Epoch 80/100\n",
      "177/177 [==============================] - 0s 173us/step - loss: 0.3533 - accuracy: 0.8814 - val_loss: 1.4384 - val_accuracy: 0.5000\n",
      "Epoch 81/100\n",
      "177/177 [==============================] - 0s 191us/step - loss: 0.3588 - accuracy: 0.8927 - val_loss: 1.2380 - val_accuracy: 0.4868\n",
      "Epoch 82/100\n",
      "177/177 [==============================] - 0s 215us/step - loss: 0.3410 - accuracy: 0.9040 - val_loss: 1.3038 - val_accuracy: 0.4605\n",
      "Epoch 83/100\n",
      "177/177 [==============================] - 0s 222us/step - loss: 0.3338 - accuracy: 0.8927 - val_loss: 1.5634 - val_accuracy: 0.4868\n",
      "Epoch 84/100\n",
      "177/177 [==============================] - 0s 236us/step - loss: 0.4151 - accuracy: 0.8757 - val_loss: 1.2378 - val_accuracy: 0.4605\n",
      "Epoch 85/100\n",
      "177/177 [==============================] - 0s 205us/step - loss: 0.3901 - accuracy: 0.8814 - val_loss: 1.3673 - val_accuracy: 0.4737\n",
      "Epoch 86/100\n",
      "177/177 [==============================] - 0s 221us/step - loss: 0.3464 - accuracy: 0.8870 - val_loss: 1.3013 - val_accuracy: 0.5000\n",
      "Epoch 87/100\n",
      "177/177 [==============================] - 0s 156us/step - loss: 0.3365 - accuracy: 0.8983 - val_loss: 1.5772 - val_accuracy: 0.4605\n",
      "Epoch 88/100\n",
      "177/177 [==============================] - 0s 192us/step - loss: 0.4492 - accuracy: 0.8757 - val_loss: 1.2418 - val_accuracy: 0.5395\n",
      "Epoch 89/100\n",
      "177/177 [==============================] - 0s 108us/step - loss: 0.4651 - accuracy: 0.8644 - val_loss: 1.8612 - val_accuracy: 0.5132\n",
      "Epoch 90/100\n",
      "177/177 [==============================] - 0s 159us/step - loss: 0.3927 - accuracy: 0.8870 - val_loss: 1.2634 - val_accuracy: 0.4605\n",
      "Epoch 91/100\n",
      "177/177 [==============================] - 0s 145us/step - loss: 0.4575 - accuracy: 0.8870 - val_loss: 1.3956 - val_accuracy: 0.4605\n",
      "Epoch 92/100\n",
      "177/177 [==============================] - 0s 153us/step - loss: 0.3890 - accuracy: 0.8927 - val_loss: 1.7539 - val_accuracy: 0.4737\n",
      "Epoch 93/100\n",
      "177/177 [==============================] - 0s 189us/step - loss: 0.4008 - accuracy: 0.8870 - val_loss: 1.3393 - val_accuracy: 0.4605\n",
      "Epoch 94/100\n",
      "177/177 [==============================] - 0s 172us/step - loss: 0.3517 - accuracy: 0.8870 - val_loss: 1.4486 - val_accuracy: 0.4868\n",
      "Epoch 95/100\n",
      "177/177 [==============================] - 0s 163us/step - loss: 0.3438 - accuracy: 0.8870 - val_loss: 1.4030 - val_accuracy: 0.4868\n",
      "Epoch 96/100\n",
      "177/177 [==============================] - 0s 96us/step - loss: 0.3050 - accuracy: 0.8983 - val_loss: 1.3556 - val_accuracy: 0.5132\n",
      "Epoch 97/100\n",
      "177/177 [==============================] - 0s 101us/step - loss: 0.3183 - accuracy: 0.9040 - val_loss: 1.3159 - val_accuracy: 0.5000\n",
      "Epoch 98/100\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.2995 - accuracy: 0.9096 - val_loss: 1.2999 - val_accuracy: 0.4737\n",
      "Epoch 99/100\n",
      "177/177 [==============================] - 0s 140us/step - loss: 0.3011 - accuracy: 0.9209 - val_loss: 1.6242 - val_accuracy: 0.5000\n",
      "Epoch 100/100\n",
      "177/177 [==============================] - 0s 153us/step - loss: 0.3253 - accuracy: 0.9040 - val_loss: 1.3346 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a3e186cc0>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.fit(X_train, y_train,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 0s 67us/step\n",
      "test accuracy: 55.26%\n"
     ]
    }
   ],
   "source": [
    "acc_test4 = model4.evaluate(X_test, y_test)[1]\n",
    "print('test accuracy: %.2f%%' % (acc_test4*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 2, 2, 0, 0, 2, 0, 2, 1, 2, 2, 0, 1, 0, 1, 2, 0, 1, 2, 2, 1,\n",
       "       0, 2, 2, 2, 1, 0, 2, 2, 0, 2, 2, 2, 0, 1, 0, 0, 2, 2, 1, 0, 2, 1,\n",
       "       0, 1, 0, 1, 1, 0, 0, 2, 1, 1, 1, 1, 1, 1, 2, 1, 0, 1, 0, 2, 2, 1,\n",
       "       1, 1, 1, 1, 1, 2, 2, 2, 1, 2])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred4 = model4.predict_classes(X_test)\n",
    "pred4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>CFBREBSa121</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>BCH-SA-13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>CFBRSa23</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>CFBREBSa125</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>NRS247</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>NRS215</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>SR4152</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>NRS035</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>SR4187</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  test  pred\n",
       "54   CFBREBSa121     1     0\n",
       "28     BCH-SA-13     1     0\n",
       "143       NRS148     2     2\n",
       "73      CFBRSa23     2     2\n",
       "57   CFBREBSa125     0     0\n",
       "..           ...   ...   ...\n",
       "208       NRS247     1     2\n",
       "183       NRS215     1     2\n",
       "248       SR4152     2     2\n",
       "114       NRS035     1     1\n",
       "252       SR4187     2     2\n",
       "\n",
       "[76 rows x 3 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat4['pred'] = pred4\n",
    "dat4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba4 = model4.predict_proba(X_test)\n",
    "dat_proba4 = pd.DataFrame(proba4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.948243</td>\n",
       "      <td>0.044020</td>\n",
       "      <td>0.007737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.562979</td>\n",
       "      <td>0.390488</td>\n",
       "      <td>0.046532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.012425</td>\n",
       "      <td>0.987523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.039255</td>\n",
       "      <td>0.300029</td>\n",
       "      <td>0.660716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.926907</td>\n",
       "      <td>0.063109</td>\n",
       "      <td>0.009983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.029574</td>\n",
       "      <td>0.385730</td>\n",
       "      <td>0.584696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.003197</td>\n",
       "      <td>0.445057</td>\n",
       "      <td>0.551746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.043194</td>\n",
       "      <td>0.028984</td>\n",
       "      <td>0.927822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.004902</td>\n",
       "      <td>0.680427</td>\n",
       "      <td>0.314671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.055815</td>\n",
       "      <td>0.943928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2\n",
       "0   0.948243  0.044020  0.007737\n",
       "1   0.562979  0.390488  0.046532\n",
       "2   0.000052  0.012425  0.987523\n",
       "3   0.039255  0.300029  0.660716\n",
       "4   0.926907  0.063109  0.009983\n",
       "..       ...       ...       ...\n",
       "71  0.029574  0.385730  0.584696\n",
       "72  0.003197  0.445057  0.551746\n",
       "73  0.043194  0.028984  0.927822\n",
       "74  0.004902  0.680427  0.314671\n",
       "75  0.000257  0.055815  0.943928\n",
       "\n",
       "[76 rows x 3 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba4.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba4.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat4.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/4p40pST.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 177 samples, validate on 76 samples\n",
      "Epoch 1/100\n",
      "177/177 [==============================] - 0s 139us/step - loss: 0.2495 - accuracy: 0.9322 - val_loss: 1.2903 - val_accuracy: 0.5132\n",
      "Epoch 2/100\n",
      "177/177 [==============================] - 0s 125us/step - loss: 0.2448 - accuracy: 0.9435 - val_loss: 1.2871 - val_accuracy: 0.5263\n",
      "Epoch 3/100\n",
      "177/177 [==============================] - 0s 193us/step - loss: 0.2421 - accuracy: 0.9379 - val_loss: 1.2827 - val_accuracy: 0.5395\n",
      "Epoch 4/100\n",
      "177/177 [==============================] - 0s 155us/step - loss: 0.2426 - accuracy: 0.9379 - val_loss: 1.2937 - val_accuracy: 0.5132\n",
      "Epoch 5/100\n",
      "177/177 [==============================] - 0s 142us/step - loss: 0.2456 - accuracy: 0.9322 - val_loss: 1.3298 - val_accuracy: 0.5263\n",
      "Epoch 6/100\n",
      "177/177 [==============================] - 0s 150us/step - loss: 0.2346 - accuracy: 0.9322 - val_loss: 1.3244 - val_accuracy: 0.5395\n",
      "Epoch 7/100\n",
      "177/177 [==============================] - 0s 124us/step - loss: 0.2398 - accuracy: 0.9379 - val_loss: 1.3001 - val_accuracy: 0.5395\n",
      "Epoch 8/100\n",
      "177/177 [==============================] - 0s 121us/step - loss: 0.2318 - accuracy: 0.9492 - val_loss: 1.3468 - val_accuracy: 0.5000\n",
      "Epoch 9/100\n",
      "177/177 [==============================] - 0s 138us/step - loss: 0.2350 - accuracy: 0.9492 - val_loss: 1.2957 - val_accuracy: 0.5395\n",
      "Epoch 10/100\n",
      "177/177 [==============================] - 0s 131us/step - loss: 0.2266 - accuracy: 0.9492 - val_loss: 1.2926 - val_accuracy: 0.5526\n",
      "Epoch 11/100\n",
      "177/177 [==============================] - 0s 144us/step - loss: 0.2294 - accuracy: 0.9322 - val_loss: 1.3343 - val_accuracy: 0.5132\n",
      "Epoch 12/100\n",
      "177/177 [==============================] - 0s 160us/step - loss: 0.2193 - accuracy: 0.9435 - val_loss: 1.3653 - val_accuracy: 0.5526\n",
      "Epoch 13/100\n",
      "177/177 [==============================] - 0s 114us/step - loss: 0.2282 - accuracy: 0.9548 - val_loss: 1.3230 - val_accuracy: 0.5000\n",
      "Epoch 14/100\n",
      "177/177 [==============================] - 0s 124us/step - loss: 0.2168 - accuracy: 0.9492 - val_loss: 1.3432 - val_accuracy: 0.5000\n",
      "Epoch 15/100\n",
      "177/177 [==============================] - 0s 122us/step - loss: 0.2174 - accuracy: 0.9548 - val_loss: 1.3509 - val_accuracy: 0.5263\n",
      "Epoch 16/100\n",
      "177/177 [==============================] - 0s 118us/step - loss: 0.2137 - accuracy: 0.9435 - val_loss: 1.3526 - val_accuracy: 0.5000\n",
      "Epoch 17/100\n",
      "177/177 [==============================] - 0s 206us/step - loss: 0.2095 - accuracy: 0.9492 - val_loss: 1.3583 - val_accuracy: 0.5132\n",
      "Epoch 18/100\n",
      "177/177 [==============================] - 0s 139us/step - loss: 0.2107 - accuracy: 0.9492 - val_loss: 1.3725 - val_accuracy: 0.5132\n",
      "Epoch 19/100\n",
      "177/177 [==============================] - 0s 146us/step - loss: 0.2059 - accuracy: 0.9548 - val_loss: 1.3804 - val_accuracy: 0.5132\n",
      "Epoch 20/100\n",
      "177/177 [==============================] - 0s 130us/step - loss: 0.2072 - accuracy: 0.9492 - val_loss: 1.3539 - val_accuracy: 0.5395\n",
      "Epoch 21/100\n",
      "177/177 [==============================] - 0s 158us/step - loss: 0.2027 - accuracy: 0.9548 - val_loss: 1.3721 - val_accuracy: 0.5263\n",
      "Epoch 22/100\n",
      "177/177 [==============================] - 0s 140us/step - loss: 0.2044 - accuracy: 0.9605 - val_loss: 1.3922 - val_accuracy: 0.5263\n",
      "Epoch 23/100\n",
      "177/177 [==============================] - 0s 141us/step - loss: 0.2038 - accuracy: 0.9548 - val_loss: 1.4168 - val_accuracy: 0.5132\n",
      "Epoch 24/100\n",
      "177/177 [==============================] - 0s 129us/step - loss: 0.1956 - accuracy: 0.9492 - val_loss: 1.4047 - val_accuracy: 0.5132\n",
      "Epoch 25/100\n",
      "177/177 [==============================] - 0s 119us/step - loss: 0.2004 - accuracy: 0.9548 - val_loss: 1.4413 - val_accuracy: 0.5000\n",
      "Epoch 26/100\n",
      "177/177 [==============================] - 0s 135us/step - loss: 0.1953 - accuracy: 0.9661 - val_loss: 1.4257 - val_accuracy: 0.5000\n",
      "Epoch 27/100\n",
      "177/177 [==============================] - 0s 138us/step - loss: 0.1993 - accuracy: 0.9435 - val_loss: 1.4053 - val_accuracy: 0.5263\n",
      "Epoch 28/100\n",
      "177/177 [==============================] - 0s 131us/step - loss: 0.1916 - accuracy: 0.9661 - val_loss: 1.4072 - val_accuracy: 0.5132\n",
      "Epoch 29/100\n",
      "177/177 [==============================] - 0s 119us/step - loss: 0.1956 - accuracy: 0.9774 - val_loss: 1.4393 - val_accuracy: 0.4868\n",
      "Epoch 30/100\n",
      "177/177 [==============================] - 0s 128us/step - loss: 0.1911 - accuracy: 0.9605 - val_loss: 1.4628 - val_accuracy: 0.5263\n",
      "Epoch 31/100\n",
      "177/177 [==============================] - 0s 142us/step - loss: 0.1890 - accuracy: 0.9718 - val_loss: 1.4818 - val_accuracy: 0.4868\n",
      "Epoch 32/100\n",
      "177/177 [==============================] - 0s 121us/step - loss: 0.1957 - accuracy: 0.9605 - val_loss: 1.4340 - val_accuracy: 0.5263\n",
      "Epoch 33/100\n",
      "177/177 [==============================] - 0s 140us/step - loss: 0.1838 - accuracy: 0.9605 - val_loss: 1.4299 - val_accuracy: 0.5132\n",
      "Epoch 34/100\n",
      "177/177 [==============================] - 0s 113us/step - loss: 0.1820 - accuracy: 0.9548 - val_loss: 1.4833 - val_accuracy: 0.5263\n",
      "Epoch 35/100\n",
      "177/177 [==============================] - 0s 214us/step - loss: 0.1814 - accuracy: 0.9605 - val_loss: 1.4712 - val_accuracy: 0.5000\n",
      "Epoch 36/100\n",
      "177/177 [==============================] - 0s 132us/step - loss: 0.1787 - accuracy: 0.9605 - val_loss: 1.4574 - val_accuracy: 0.5263\n",
      "Epoch 37/100\n",
      "177/177 [==============================] - 0s 135us/step - loss: 0.1767 - accuracy: 0.9605 - val_loss: 1.5160 - val_accuracy: 0.5263\n",
      "Epoch 38/100\n",
      "177/177 [==============================] - 0s 146us/step - loss: 0.1766 - accuracy: 0.9661 - val_loss: 1.4971 - val_accuracy: 0.5132\n",
      "Epoch 39/100\n",
      "177/177 [==============================] - 0s 108us/step - loss: 0.1803 - accuracy: 0.9774 - val_loss: 1.4966 - val_accuracy: 0.4868\n",
      "Epoch 40/100\n",
      "177/177 [==============================] - 0s 97us/step - loss: 0.1863 - accuracy: 0.9605 - val_loss: 1.5210 - val_accuracy: 0.5395\n",
      "Epoch 41/100\n",
      "177/177 [==============================] - 0s 169us/step - loss: 0.1681 - accuracy: 0.9718 - val_loss: 1.6278 - val_accuracy: 0.4868\n",
      "Epoch 42/100\n",
      "177/177 [==============================] - 0s 172us/step - loss: 0.1774 - accuracy: 0.9718 - val_loss: 1.6135 - val_accuracy: 0.4868\n",
      "Epoch 43/100\n",
      "177/177 [==============================] - 0s 149us/step - loss: 0.1940 - accuracy: 0.9492 - val_loss: 1.5659 - val_accuracy: 0.5132\n",
      "Epoch 44/100\n",
      "177/177 [==============================] - 0s 128us/step - loss: 0.1616 - accuracy: 0.9774 - val_loss: 1.6257 - val_accuracy: 0.5132\n",
      "Epoch 45/100\n",
      "177/177 [==============================] - 0s 183us/step - loss: 0.2049 - accuracy: 0.9492 - val_loss: 1.8955 - val_accuracy: 0.5263\n",
      "Epoch 46/100\n",
      "177/177 [==============================] - 0s 153us/step - loss: 0.2012 - accuracy: 0.9492 - val_loss: 1.5364 - val_accuracy: 0.5395\n",
      "Epoch 47/100\n",
      "177/177 [==============================] - 0s 125us/step - loss: 0.2415 - accuracy: 0.9435 - val_loss: 1.5599 - val_accuracy: 0.5132\n",
      "Epoch 48/100\n",
      "177/177 [==============================] - 0s 149us/step - loss: 0.1887 - accuracy: 0.9605 - val_loss: 1.9272 - val_accuracy: 0.5263\n",
      "Epoch 49/100\n",
      "177/177 [==============================] - 0s 130us/step - loss: 0.1854 - accuracy: 0.9661 - val_loss: 1.5088 - val_accuracy: 0.5132\n",
      "Epoch 50/100\n",
      "177/177 [==============================] - 0s 208us/step - loss: 0.1655 - accuracy: 0.9774 - val_loss: 1.5780 - val_accuracy: 0.5132\n",
      "Epoch 51/100\n",
      "177/177 [==============================] - 0s 110us/step - loss: 0.1644 - accuracy: 0.9718 - val_loss: 1.5589 - val_accuracy: 0.5132\n",
      "Epoch 52/100\n",
      "177/177 [==============================] - 0s 232us/step - loss: 0.1578 - accuracy: 0.9661 - val_loss: 1.5449 - val_accuracy: 0.5132\n",
      "Epoch 53/100\n",
      "177/177 [==============================] - 0s 181us/step - loss: 0.1717 - accuracy: 0.9661 - val_loss: 1.5841 - val_accuracy: 0.5000\n",
      "Epoch 54/100\n",
      "177/177 [==============================] - 0s 135us/step - loss: 0.1837 - accuracy: 0.9605 - val_loss: 1.5953 - val_accuracy: 0.5132\n",
      "Epoch 55/100\n",
      "177/177 [==============================] - 0s 145us/step - loss: 0.1957 - accuracy: 0.9605 - val_loss: 1.6362 - val_accuracy: 0.5000\n",
      "Epoch 56/100\n",
      "177/177 [==============================] - 0s 156us/step - loss: 0.2159 - accuracy: 0.9435 - val_loss: 1.6332 - val_accuracy: 0.5395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "177/177 [==============================] - 0s 122us/step - loss: 0.1880 - accuracy: 0.9661 - val_loss: 1.6281 - val_accuracy: 0.5000\n",
      "Epoch 58/100\n",
      "177/177 [==============================] - 0s 169us/step - loss: 0.2002 - accuracy: 0.9661 - val_loss: 2.1486 - val_accuracy: 0.5000\n",
      "Epoch 59/100\n",
      "177/177 [==============================] - 0s 135us/step - loss: 0.2242 - accuracy: 0.9492 - val_loss: 1.5632 - val_accuracy: 0.5132\n",
      "Epoch 60/100\n",
      "177/177 [==============================] - 0s 159us/step - loss: 0.1818 - accuracy: 0.9605 - val_loss: 1.5838 - val_accuracy: 0.5000\n",
      "Epoch 61/100\n",
      "177/177 [==============================] - 0s 171us/step - loss: 0.1591 - accuracy: 0.9661 - val_loss: 1.7335 - val_accuracy: 0.5132\n",
      "Epoch 62/100\n",
      "177/177 [==============================] - 0s 121us/step - loss: 0.1584 - accuracy: 0.9605 - val_loss: 1.6705 - val_accuracy: 0.5132\n",
      "Epoch 63/100\n",
      "177/177 [==============================] - 0s 317us/step - loss: 0.1470 - accuracy: 0.9718 - val_loss: 1.6382 - val_accuracy: 0.5263\n",
      "Epoch 64/100\n",
      "177/177 [==============================] - 0s 159us/step - loss: 0.1458 - accuracy: 0.9774 - val_loss: 1.5841 - val_accuracy: 0.5132\n",
      "Epoch 65/100\n",
      "177/177 [==============================] - 0s 181us/step - loss: 0.1393 - accuracy: 0.9718 - val_loss: 1.6844 - val_accuracy: 0.5132\n",
      "Epoch 66/100\n",
      "177/177 [==============================] - 0s 122us/step - loss: 0.1480 - accuracy: 0.9605 - val_loss: 1.6594 - val_accuracy: 0.5395\n",
      "Epoch 67/100\n",
      "177/177 [==============================] - 0s 205us/step - loss: 0.1442 - accuracy: 0.9774 - val_loss: 1.5944 - val_accuracy: 0.5132\n",
      "Epoch 68/100\n",
      "177/177 [==============================] - 0s 169us/step - loss: 0.1446 - accuracy: 0.9887 - val_loss: 1.6880 - val_accuracy: 0.5132\n",
      "Epoch 69/100\n",
      "177/177 [==============================] - 0s 141us/step - loss: 0.1363 - accuracy: 0.9831 - val_loss: 1.6520 - val_accuracy: 0.5000\n",
      "Epoch 70/100\n",
      "177/177 [==============================] - 0s 137us/step - loss: 0.1387 - accuracy: 0.9831 - val_loss: 1.6669 - val_accuracy: 0.5000\n",
      "Epoch 71/100\n",
      "177/177 [==============================] - 0s 163us/step - loss: 0.1379 - accuracy: 0.9774 - val_loss: 1.6782 - val_accuracy: 0.5000\n",
      "Epoch 72/100\n",
      "177/177 [==============================] - 0s 122us/step - loss: 0.1336 - accuracy: 0.9774 - val_loss: 1.6464 - val_accuracy: 0.5263\n",
      "Epoch 73/100\n",
      "177/177 [==============================] - 0s 137us/step - loss: 0.1309 - accuracy: 0.9831 - val_loss: 1.6577 - val_accuracy: 0.5263\n",
      "Epoch 74/100\n",
      "177/177 [==============================] - 0s 150us/step - loss: 0.1306 - accuracy: 0.9774 - val_loss: 1.6741 - val_accuracy: 0.5263\n",
      "Epoch 75/100\n",
      "177/177 [==============================] - 0s 136us/step - loss: 0.1294 - accuracy: 0.9718 - val_loss: 1.6927 - val_accuracy: 0.5000\n",
      "Epoch 76/100\n",
      "177/177 [==============================] - 0s 142us/step - loss: 0.1347 - accuracy: 0.9718 - val_loss: 1.6763 - val_accuracy: 0.5000\n",
      "Epoch 77/100\n",
      "177/177 [==============================] - 0s 180us/step - loss: 0.1272 - accuracy: 0.9831 - val_loss: 1.6735 - val_accuracy: 0.5132\n",
      "Epoch 78/100\n",
      "177/177 [==============================] - 0s 166us/step - loss: 0.1277 - accuracy: 0.9887 - val_loss: 1.7212 - val_accuracy: 0.4737\n",
      "Epoch 79/100\n",
      "177/177 [==============================] - 0s 137us/step - loss: 0.1261 - accuracy: 0.9774 - val_loss: 1.7280 - val_accuracy: 0.5000\n",
      "Epoch 80/100\n",
      "177/177 [==============================] - 0s 162us/step - loss: 0.1262 - accuracy: 0.9887 - val_loss: 1.7107 - val_accuracy: 0.5132\n",
      "Epoch 81/100\n",
      "177/177 [==============================] - 0s 122us/step - loss: 0.1317 - accuracy: 0.9774 - val_loss: 1.7617 - val_accuracy: 0.5132\n",
      "Epoch 82/100\n",
      "177/177 [==============================] - 0s 129us/step - loss: 0.1217 - accuracy: 0.9774 - val_loss: 1.7977 - val_accuracy: 0.5000\n",
      "Epoch 83/100\n",
      "177/177 [==============================] - 0s 108us/step - loss: 0.1419 - accuracy: 0.9774 - val_loss: 1.7651 - val_accuracy: 0.5132\n",
      "Epoch 84/100\n",
      "177/177 [==============================] - 0s 167us/step - loss: 0.1405 - accuracy: 0.9718 - val_loss: 1.7794 - val_accuracy: 0.5132\n",
      "Epoch 85/100\n",
      "177/177 [==============================] - 0s 106us/step - loss: 0.1347 - accuracy: 0.9774 - val_loss: 1.8164 - val_accuracy: 0.5000\n",
      "Epoch 86/100\n",
      "177/177 [==============================] - 0s 135us/step - loss: 0.1393 - accuracy: 0.9718 - val_loss: 1.8099 - val_accuracy: 0.5132\n",
      "Epoch 87/100\n",
      "177/177 [==============================] - 0s 199us/step - loss: 0.1197 - accuracy: 0.9831 - val_loss: 1.7575 - val_accuracy: 0.5000\n",
      "Epoch 88/100\n",
      "177/177 [==============================] - 0s 100us/step - loss: 0.1177 - accuracy: 0.9831 - val_loss: 1.7552 - val_accuracy: 0.5132\n",
      "Epoch 89/100\n",
      "177/177 [==============================] - 0s 106us/step - loss: 0.1200 - accuracy: 0.9774 - val_loss: 1.7959 - val_accuracy: 0.5000\n",
      "Epoch 90/100\n",
      "177/177 [==============================] - 0s 119us/step - loss: 0.1163 - accuracy: 0.9831 - val_loss: 1.7729 - val_accuracy: 0.4868\n",
      "Epoch 91/100\n",
      "177/177 [==============================] - 0s 122us/step - loss: 0.1165 - accuracy: 0.9887 - val_loss: 1.7375 - val_accuracy: 0.5132\n",
      "Epoch 92/100\n",
      "177/177 [==============================] - 0s 119us/step - loss: 0.1177 - accuracy: 0.9887 - val_loss: 1.7662 - val_accuracy: 0.5000\n",
      "Epoch 93/100\n",
      "177/177 [==============================] - 0s 119us/step - loss: 0.1161 - accuracy: 0.9831 - val_loss: 1.9042 - val_accuracy: 0.4868\n",
      "Epoch 94/100\n",
      "177/177 [==============================] - 0s 118us/step - loss: 0.1153 - accuracy: 0.9774 - val_loss: 1.8349 - val_accuracy: 0.4868\n",
      "Epoch 95/100\n",
      "177/177 [==============================] - 0s 125us/step - loss: 0.1171 - accuracy: 0.9831 - val_loss: 1.7745 - val_accuracy: 0.5000\n",
      "Epoch 96/100\n",
      "177/177 [==============================] - 0s 103us/step - loss: 0.1153 - accuracy: 0.9887 - val_loss: 1.7562 - val_accuracy: 0.5000\n",
      "Epoch 97/100\n",
      "177/177 [==============================] - 0s 107us/step - loss: 0.1118 - accuracy: 0.9944 - val_loss: 1.8057 - val_accuracy: 0.4868\n",
      "Epoch 98/100\n",
      "177/177 [==============================] - 0s 115us/step - loss: 0.1129 - accuracy: 0.9887 - val_loss: 1.8544 - val_accuracy: 0.5000\n",
      "Epoch 99/100\n",
      "177/177 [==============================] - 0s 97us/step - loss: 0.1090 - accuracy: 0.9887 - val_loss: 1.8373 - val_accuracy: 0.5000\n",
      "Epoch 100/100\n",
      "177/177 [==============================] - 0s 136us/step - loss: 0.1112 - accuracy: 0.9944 - val_loss: 1.8324 - val_accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "hist4 = model4.fit(X_train, y_train,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 96.52%\n"
     ]
    }
   ],
   "source": [
    "print('train accuracy: %.2f%%' % (np.mean(hist4.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba4 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_2.xlsx\",\n",
    "                        sheet_name=3,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>SR1129</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4.821690e-07</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>9.999983e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>CA105</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.652370e-03</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>9.972990e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NRS175</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.198157e-02</td>\n",
       "      <td>0.988018</td>\n",
       "      <td>5.232074e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>EUH25</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.388957e-01</td>\n",
       "      <td>0.735954</td>\n",
       "      <td>1.251503e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NRS070</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7.231966e-03</td>\n",
       "      <td>0.810317</td>\n",
       "      <td>1.824512e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>NRS247</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.957360e-02</td>\n",
       "      <td>0.385730</td>\n",
       "      <td>5.846961e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>NRS215</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.196635e-03</td>\n",
       "      <td>0.445057</td>\n",
       "      <td>5.517461e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>SR4152</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4.319404e-02</td>\n",
       "      <td>0.028984</td>\n",
       "      <td>9.278219e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>NRS035</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.902312e-03</td>\n",
       "      <td>0.680427</td>\n",
       "      <td>3.146706e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>SR4187</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.566210e-04</td>\n",
       "      <td>0.055815</td>\n",
       "      <td>9.439281e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>608 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     phage  strain  phenotype  prediction             0  \\\n",
       "0       p0017kpresabs_qual  SR1129          2           2  4.821690e-07   \n",
       "1       p0017kpresabs_qual   CA105          2           2  2.652370e-03   \n",
       "2       p0017kpresabs_qual  NRS175          1           1  1.198157e-02   \n",
       "3       p0017kpresabs_qual   EUH25          2           1  1.388957e-01   \n",
       "4       p0017kpresabs_qual  NRS070          2           1  7.231966e-03   \n",
       "..                     ...     ...        ...         ...           ...   \n",
       "603  p0040presabsSTCC_qual  NRS247          1           2  2.957360e-02   \n",
       "604  p0040presabsSTCC_qual  NRS215          1           2  3.196635e-03   \n",
       "605  p0040presabsSTCC_qual  SR4152          2           2  4.319404e-02   \n",
       "606  p0040presabsSTCC_qual  NRS035          1           1  4.902312e-03   \n",
       "607  p0040presabsSTCC_qual  SR4187          2           2  2.566210e-04   \n",
       "\n",
       "            1             2  \n",
       "0    0.000001  9.999983e-01  \n",
       "1    0.000049  9.972990e-01  \n",
       "2    0.988018  5.232074e-09  \n",
       "3    0.735954  1.251503e-01  \n",
       "4    0.810317  1.824512e-01  \n",
       "..        ...           ...  \n",
       "603  0.385730  5.846961e-01  \n",
       "604  0.445057  5.517461e-01  \n",
       "605  0.028984  9.278219e-01  \n",
       "606  0.680427  3.146706e-01  \n",
       "607  0.055815  9.439281e-01  \n",
       "\n",
       "[608 rows x 7 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.48242660e-01, 4.40203060e-02, 7.73694370e-03],\n",
       "       [5.62979200e-01, 3.90488420e-01, 4.65323850e-02],\n",
       "       [5.24542340e-05, 1.24247240e-02, 9.87522800e-01],\n",
       "       [3.92548900e-02, 3.00029250e-01, 6.60715900e-01],\n",
       "       [9.26907360e-01, 6.31094800e-02, 9.98317900e-03],\n",
       "       [8.29304700e-01, 1.40034930e-01, 3.06603090e-02],\n",
       "       [4.29202300e-02, 6.74751400e-02, 8.89604600e-01],\n",
       "       [9.54042850e-01, 3.26463700e-02, 1.33106920e-02],\n",
       "       [4.61252300e-02, 1.82908760e-01, 7.70966000e-01],\n",
       "       [1.02906720e-01, 4.93208940e-01, 4.03884350e-01],\n",
       "       [9.12523100e-03, 6.08816520e-02, 9.29993150e-01],\n",
       "       [3.35121300e-03, 1.36009580e-02, 9.83047840e-01],\n",
       "       [8.46580450e-01, 1.45369840e-01, 8.04969100e-03],\n",
       "       [3.06489170e-01, 6.50479850e-01, 4.30308950e-02],\n",
       "       [9.00800900e-01, 8.67017400e-02, 1.24974090e-02],\n",
       "       [6.83358730e-03, 9.80030100e-01, 1.31362940e-02],\n",
       "       [2.09346340e-01, 6.95708400e-02, 7.21082800e-01],\n",
       "       [6.94021460e-01, 2.75985000e-01, 2.99935300e-02],\n",
       "       [3.56352660e-01, 6.03633400e-01, 4.00140250e-02],\n",
       "       [2.53185600e-02, 1.32797480e-01, 8.41884000e-01],\n",
       "       [4.99886540e-02, 4.47809800e-01, 5.02201500e-01],\n",
       "       [1.50341080e-01, 5.26883100e-01, 3.22775800e-01],\n",
       "       [8.87961300e-01, 9.18850800e-02, 2.01536140e-02],\n",
       "       [5.19568730e-02, 3.83683150e-01, 5.64359960e-01],\n",
       "       [3.28564760e-02, 4.38768920e-01, 5.28374700e-01],\n",
       "       [4.56213950e-01, 7.66447100e-02, 4.67141330e-01],\n",
       "       [1.44126710e-03, 9.42210000e-01, 5.63486480e-02],\n",
       "       [6.03714800e-01, 2.26293100e-01, 1.69992070e-01],\n",
       "       [9.72837850e-04, 4.38388500e-03, 9.94643330e-01],\n",
       "       [5.50288630e-02, 9.15828400e-02, 8.53388300e-01],\n",
       "       [7.09460600e-01, 1.11184340e-01, 1.79355000e-01],\n",
       "       [8.56098160e-02, 1.70787800e-01, 7.43602340e-01],\n",
       "       [1.09702385e-04, 5.17406800e-04, 9.99372900e-01],\n",
       "       [3.80479320e-02, 2.97755360e-01, 6.64196700e-01],\n",
       "       [6.23293040e-01, 2.07006070e-01, 1.69700900e-01],\n",
       "       [6.60309800e-02, 7.61282700e-01, 1.72686370e-01],\n",
       "       [6.79730600e-01, 2.23039760e-01, 9.72296700e-02],\n",
       "       [4.92659630e-01, 4.85911040e-01, 2.14294230e-02],\n",
       "       [2.95773180e-01, 1.60057890e-01, 5.44168900e-01],\n",
       "       [4.15963560e-04, 9.28545200e-03, 9.90298570e-01],\n",
       "       [3.67422250e-02, 9.25796200e-01, 3.74615100e-02],\n",
       "       [4.23739580e-01, 3.43338970e-01, 2.32921530e-01],\n",
       "       [1.43493470e-04, 4.85073550e-02, 9.51349200e-01],\n",
       "       [8.66878400e-03, 8.55682430e-01, 1.35648740e-01],\n",
       "       [8.14318100e-01, 1.71021360e-01, 1.46604800e-02],\n",
       "       [3.31848100e-01, 4.70234270e-01, 1.97917600e-01],\n",
       "       [8.78281400e-01, 1.08203710e-01, 1.35148800e-02],\n",
       "       [2.53326800e-01, 5.45698900e-01, 2.00974270e-01],\n",
       "       [2.36646100e-02, 6.71175400e-01, 3.05160000e-01],\n",
       "       [8.30589800e-01, 1.53875130e-01, 1.55351490e-02],\n",
       "       [6.02036950e-01, 6.89058000e-02, 3.29057250e-01],\n",
       "       [1.16536030e-02, 1.64580480e-02, 9.71888300e-01],\n",
       "       [8.88385800e-02, 9.09646300e-01, 1.51508770e-03],\n",
       "       [1.88129650e-01, 8.10389340e-01, 1.48107500e-03],\n",
       "       [4.41291780e-02, 9.20064000e-01, 3.58068240e-02],\n",
       "       [3.90278940e-01, 6.07796800e-01, 1.92416370e-03],\n",
       "       [5.76562160e-03, 9.69343660e-01, 2.48907670e-02],\n",
       "       [3.07076660e-01, 6.91885230e-01, 1.03817030e-03],\n",
       "       [6.01720770e-02, 4.25061200e-01, 5.14766700e-01],\n",
       "       [9.17068700e-03, 9.86549850e-01, 4.27944070e-03],\n",
       "       [8.64382900e-01, 9.57672000e-02, 3.98499100e-02],\n",
       "       [2.06770200e-01, 7.51146900e-01, 4.20829730e-02],\n",
       "       [5.53770500e-01, 1.26164840e-01, 3.20064720e-01],\n",
       "       [2.54729060e-01, 1.55919050e-01, 5.89351900e-01],\n",
       "       [1.91773960e-02, 1.11541660e-01, 8.69280930e-01],\n",
       "       [5.79639600e-02, 7.05188630e-01, 2.36847420e-01],\n",
       "       [3.50978800e-02, 9.37257600e-01, 2.76445700e-02],\n",
       "       [3.34065330e-02, 7.37598660e-01, 2.28994790e-01],\n",
       "       [2.84735950e-01, 3.94392460e-01, 3.20871500e-01],\n",
       "       [4.25064860e-02, 8.25510300e-01, 1.31983180e-01],\n",
       "       [3.35579660e-02, 9.44078740e-01, 2.23633070e-02],\n",
       "       [2.95736000e-02, 3.85730360e-01, 5.84696050e-01],\n",
       "       [3.19663550e-03, 4.45057330e-01, 5.51746100e-01],\n",
       "       [4.31940440e-02, 2.89840330e-02, 9.27821930e-01],\n",
       "       [4.90231160e-03, 6.80427130e-01, 3.14670560e-01],\n",
       "       [2.56621000e-04, 5.58152500e-02, 9.43928100e-01]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob4 = df_proba4[df_proba4['phage']=='p0040presabsSTCC_qual'].iloc[:,-3:]\n",
    "y_prob4 = y_prob4.to_numpy()\n",
    "y_prob4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6696745988881343"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo4 = rocauc_ovo(y_test, y_prob4, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6696745988881343"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr4 = rocauc_ovr(y_test, y_prob4, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7302599494697908"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovos = [ovo1, ovo2, ovo3, ovo4]\n",
    "np.mean(ovos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04114548881774576"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(ovos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7302599494697908"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovrs = [ovr1, ovr2, ovr3, ovr4]\n",
    "np.mean(ovrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04114548881774576"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(ovrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs = [acc_test1, acc_test2, acc_test3, acc_test4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy mean: 59.54%\n"
     ]
    }
   ],
   "source": [
    "mean = np.mean(accs)\n",
    "print('test accuracy mean: %.2f%%' % (mean*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy standard deviation: 0.0376497545788795\n"
     ]
    }
   ],
   "source": [
    "std = np.std(accs)\n",
    "print('test accuracy standard deviation:', std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs_train = [np.mean(hist1.history['accuracy']), np.mean(hist2.history['accuracy']), np.mean(hist3.history['accuracy']),\n",
    "             np.mean(hist4.history['accuracy'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy mean: 95.13%\n"
     ]
    }
   ],
   "source": [
    "mean_train = np.mean(accs_train)\n",
    "print('train accuracy mean: %.2f%%' % (mean_train*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy standard deviation: 0.009737109\n"
     ]
    }
   ],
   "source": [
    "std_train = np.std(accs_train)\n",
    "print('train accuracy standard deviation:', std_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ Feature selection using lasso ##########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Retrieved from https://towardsdatascience.com/feature-selection-using-regularisation-a3678b71e499\n",
    "from sklearn.linear_model import Lasso, LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectFromModel(estimator=LogisticRegression(C=1, class_weight=None, dual=False,\n",
       "                                             fit_intercept=True,\n",
       "                                             intercept_scaling=1, l1_ratio=None,\n",
       "                                             max_iter=100, multi_class='auto',\n",
       "                                             n_jobs=None, penalty='l1',\n",
       "                                             random_state=None,\n",
       "                                             solver='liblinear', tol=0.0001,\n",
       "                                             verbose=0, warm_start=False),\n",
       "                max_features=None, norm_order=1, prefit=False, threshold=None)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selection = SelectFromModel(LogisticRegression(C=1, penalty='l1', solver='liblinear'))\n",
    "selection.fit(X.loc[:, X.columns != 'id'], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = np.array(df_clean.columns).tolist()\n",
    "names.remove('pheno')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_features = np.vstack((names, X.loc[:, X.columns != 'id']))\n",
    "X_train_features = pd.DataFrame(X_train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total features: 351\n",
      "selected features: 121\n"
     ]
    }
   ],
   "source": [
    "sel_features = X_train_features.columns[(selection.get_support())]\n",
    "print('total features: {}'.format((X_train_features.shape[1])))\n",
    "print('selected features: {}'.format(len(sel_features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,  12,  41,  44,  56,  62,  65,  68,  70,  71,  75,  76,  81,\n",
       "         82,  83,  87,  88,  93,  94, 113, 116, 125, 126, 132, 134, 135,\n",
       "        146, 148, 153, 164, 174, 180, 183, 184, 185, 186, 188, 189, 191,\n",
       "        192, 193, 196, 197, 198, 200, 201, 202, 203, 206, 207, 210, 211,\n",
       "        213, 215, 216, 217, 219, 220, 221, 225, 227, 228, 230, 231, 232,\n",
       "        234, 236, 237, 239, 241, 244, 246, 247, 248, 251, 252, 253, 254,\n",
       "        255, 263, 266, 269, 271, 273, 274, 279, 281, 284, 288, 291, 294,\n",
       "        295, 298, 299, 301, 303, 304, 306, 308, 309, 311, 312, 313, 316,\n",
       "        318, 319, 321, 323, 324, 325, 326, 329, 330, 332, 333, 334, 340,\n",
       "        342, 345, 349, 350]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = sel_features.values\n",
    "cols.reshape((1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['TTTTTATATTGCGAAAAATAATTGGCGAACGAGGTAACTGGATACCTCATCCGCCAATTAAAATTTGTTAATTTAATAATTAAATATAAAGACGATTTAT',\n",
       "       'TTTCACTGCCTGT', 'TGTCTGATTTTTT',\n",
       "       'TGGCTTAGGCTATAAATTGGAAAGACCTAAAGAACAATGATGAAGTTTCACCACCGCTTAATGTTATTGATAAGCAGTATATTAATTATCAGTTTTGTTA',\n",
       "       'TGAACGTTATCT', 'TCGTGTCTGT', 'TCGCTGAAATATT',\n",
       "       'TCGCTGAAATATTTGCGACAT', 'TCATCAAACTTT', 'TCAGTAGAGAT',\n",
       "       'TCACACCGCCT', 'TCACACCGCCTAT', 'TAGTCATACAAT', 'TAGCTAAATCC',\n",
       "       'TAGATTCAAATAT', 'TAATGGTAGTAGATAATTTTTC', 'TAATCTTGTTGTT',\n",
       "       'TAAATTCCATAC',\n",
       "       'TAAATCGTCTTTATATTTAATTATTAAATTAACAAATTTTAATTGGCGGATGAGGTATCCAGTTACCTCGTTCGCCAATTATTTTTCGCAATATAAAAAG',\n",
       "       'GTGGCTTAGGCTATAAATTGGAAAGACCTAAAGAACAATGATGAAGTTTCACCACCGCTTAATGTTATTGATAAGCAGTATATTAATTATCAGTTTTGTT',\n",
       "       'GTGAATTCATG', 'GGAGGATGAG', 'GGAGGATGAGG', 'GCTAATTATGTTTCTGGATT',\n",
       "       'GAGGAGGATGAGG', 'GAGGAAGCAGAT', 'CTGTTTAATGATT', 'CTAATCCTTCAAT',\n",
       "       'CGCTGAAATATTTGCG', 'ATGTCGCAAATATTTCAGCGACTTGT',\n",
       "       'ACTTTTTATATTGCGAAAAATAATTGGCGAACGAGGTAACTGGATACCTCATCCGCCAATTAAAATTTGTTAATTTAATAATTAAATATAAAGACGATTT',\n",
       "       'X1_75766_G_A', 'X1_432673_G_A', 'X1_733616_T_A', 'X1_896342_C_T',\n",
       "       'group_8306', 'cap5B', 'cap5A', 'group_2730', 'ylmA', 'maeB',\n",
       "       'traP', 'set10', 'lytS', 'group_4072', 'group_6630', 'metB',\n",
       "       'group_5568', 'group_643', 'esaA', 'group_4184', 'group_4563',\n",
       "       'sec3_1', 'cycA_1', 'yezG_1', 'sei', 'group_2979', 'group_1914',\n",
       "       'group_3022', 'group_2565', 'group_8515', 'group_1454',\n",
       "       'group_5336', 'group_6104', 'gloB', 'group_3364', 'group_5566',\n",
       "       'group_7783', 'group_3621', 'group_4708', 'group_6869',\n",
       "       'group_6875', 'group_6865', 'group_854', 'group_2820',\n",
       "       'group_3620', 'group_5295', 'coaBC_2', 'group_7706', 'group_5650',\n",
       "       'group_7697', 'repE', 'group_7691', 'group_8543', 'group_1251',\n",
       "       'group_7857', 'group_1167', 'group_4108', 'group_4529',\n",
       "       'group_4706', 'group_6857', 'group_1087', 'group_8507', 'nisC',\n",
       "       'lpl8_2', 'group_7690', 'lpl3', 'group_6196', 'group_2822',\n",
       "       'group_2712', 'group_4791', 'group_6719', 'group_3572',\n",
       "       'group_848', 'group_4069', 'yezG_6', 'group_4206', 'group_6920',\n",
       "       'group_1053', 'group_3236', 'group_420', 'dus_1', 'group_4168',\n",
       "       'group_861', 'group_862', 'group_210', 'group_2236', 'group_8800',\n",
       "       'group_8093', 'ST', 'CC'], dtype='<U100')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names_arr = np.array(names)\n",
    "names_arr[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###### keep selected variables as a new dataframe\n",
    "df_sel = df_clean.loc[:,names_arr[cols]].copy()\n",
    "df_sel['pheno'] = df_clean['pheno']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_sel['strain'] = X.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TTTTTATATTGCGAAAAATAATTGGCGAACGAGGTAACTGGATACCTCATCCGCCAATTAAAATTTGTTAATTTAATAATTAAATATAAAGACGATTTAT</th>\n",
       "      <th>TTTCACTGCCTGT</th>\n",
       "      <th>TGTCTGATTTTTT</th>\n",
       "      <th>TGGCTTAGGCTATAAATTGGAAAGACCTAAAGAACAATGATGAAGTTTCACCACCGCTTAATGTTATTGATAAGCAGTATATTAATTATCAGTTTTGTTA</th>\n",
       "      <th>TGAACGTTATCT</th>\n",
       "      <th>TCGTGTCTGT</th>\n",
       "      <th>TCGCTGAAATATT</th>\n",
       "      <th>TCGCTGAAATATTTGCGACAT</th>\n",
       "      <th>TCATCAAACTTT</th>\n",
       "      <th>TCAGTAGAGAT</th>\n",
       "      <th>...</th>\n",
       "      <th>group_861</th>\n",
       "      <th>group_862</th>\n",
       "      <th>group_210</th>\n",
       "      <th>group_2236</th>\n",
       "      <th>group_8800</th>\n",
       "      <th>group_8093</th>\n",
       "      <th>ST</th>\n",
       "      <th>CC</th>\n",
       "      <th>pheno</th>\n",
       "      <th>strain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>120335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>120337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>SR4152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3812</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>SR4153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>SR4155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>SR4156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3812</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>SR4187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>253 rows Ã— 123 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     TTTTTATATTGCGAAAAATAATTGGCGAACGAGGTAACTGGATACCTCATCCGCCAATTAAAATTTGTTAATTTAATAATTAAATATAAAGACGATTTAT  \\\n",
       "0                                                    1                                                      \n",
       "1                                                    1                                                      \n",
       "2                                                    0                                                      \n",
       "3                                                    0                                                      \n",
       "4                                                    0                                                      \n",
       "..                                                 ...                                                      \n",
       "248                                                  0                                                      \n",
       "249                                                  0                                                      \n",
       "250                                                  0                                                      \n",
       "251                                                  1                                                      \n",
       "252                                                  0                                                      \n",
       "\n",
       "     TTTCACTGCCTGT  TGTCTGATTTTTT  \\\n",
       "0                0              0   \n",
       "1                1              1   \n",
       "2                1              1   \n",
       "3                1              1   \n",
       "4                1              1   \n",
       "..             ...            ...   \n",
       "248              1              1   \n",
       "249              1              1   \n",
       "250              1              1   \n",
       "251              0              0   \n",
       "252              1              1   \n",
       "\n",
       "     TGGCTTAGGCTATAAATTGGAAAGACCTAAAGAACAATGATGAAGTTTCACCACCGCTTAATGTTATTGATAAGCAGTATATTAATTATCAGTTTTGTTA  \\\n",
       "0                                                    1                                                      \n",
       "1                                                    1                                                      \n",
       "2                                                    1                                                      \n",
       "3                                                    0                                                      \n",
       "4                                                    0                                                      \n",
       "..                                                 ...                                                      \n",
       "248                                                  0                                                      \n",
       "249                                                  0                                                      \n",
       "250                                                  1                                                      \n",
       "251                                                  0                                                      \n",
       "252                                                  0                                                      \n",
       "\n",
       "     TGAACGTTATCT  TCGTGTCTGT  TCGCTGAAATATT  TCGCTGAAATATTTGCGACAT  \\\n",
       "0               0           1              0                      0   \n",
       "1               1           1              1                      1   \n",
       "2               1           1              1                      1   \n",
       "3               1           1              1                      1   \n",
       "4               1           1              1                      1   \n",
       "..            ...         ...            ...                    ...   \n",
       "248             1           1              1                      1   \n",
       "249             1           1              1                      1   \n",
       "250             1           1              1                      1   \n",
       "251             0           1              1                      1   \n",
       "252             1           1              1                      1   \n",
       "\n",
       "     TCATCAAACTTT  TCAGTAGAGAT  ...  group_861  group_862  group_210  \\\n",
       "0               0            0  ...          0          0          0   \n",
       "1               1            1  ...          0          0          0   \n",
       "2               1            1  ...          0          0          0   \n",
       "3               1            1  ...          0          0          0   \n",
       "4               1            1  ...          0          0          0   \n",
       "..            ...          ...  ...        ...        ...        ...   \n",
       "248             1            1  ...          0          0          0   \n",
       "249             1            1  ...          0          0          0   \n",
       "250             1            1  ...          0          0          0   \n",
       "251             1            1  ...          0          0          0   \n",
       "252             1            1  ...          0          0          0   \n",
       "\n",
       "     group_2236  group_8800  group_8093    ST  CC  pheno  strain  \n",
       "0             0           0           0     5   5      2     107  \n",
       "1             0           0           0     8   8      0     109  \n",
       "2             0           0           0     5   5      2     115  \n",
       "3             0           0           0     5   5      2  120335  \n",
       "4             0           0           0     5   5      2  120337  \n",
       "..          ...         ...         ...   ...  ..    ...     ...  \n",
       "248           0           0           0     5   5      2  SR4152  \n",
       "249           0           0           0  3812   5      1  SR4153  \n",
       "250           0           0           0     5   5      1  SR4155  \n",
       "251           0           0           0     5   5      2  SR4156  \n",
       "252           0           0           0  3812   5      2  SR4187  \n",
       "\n",
       "[253 rows x 123 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(253, 122) (253,) (253, 123)\n"
     ]
    }
   ],
   "source": [
    "X_sel = df_sel.loc[:, df_sel.columns != 'pheno']\n",
    "y_sel = df_sel['pheno']\n",
    "print(X_sel.shape, y_sel.shape, df_sel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    95\n",
       "1    94\n",
       "0    64\n",
       "Name: pheno, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sel['pheno'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_sel_train, X_sel_test, y_sel_train, y_sel_test = train_test_split(X_sel, y_sel,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=567,\n",
    "                                                    stratify=y_sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat5 = pd.DataFrame(X_sel_test.iloc[:,-1])\n",
    "dat5['test'] = y_sel_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strain</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>SR4156</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>BCH-SA-02</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>NRS180</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>NY417</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>CFBREBSa110</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>CFBREBSa131</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>NRS112</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>BCH-SA-06</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>834N</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>CA9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          strain  test\n",
       "251       SR4156     2\n",
       "17     BCH-SA-02     0\n",
       "158       NRS180     2\n",
       "232        NY417     1\n",
       "47   CFBREBSa110     2\n",
       "..           ...   ...\n",
       "62   CFBREBSa131     2\n",
       "138       NRS112     2\n",
       "21     BCH-SA-06     0\n",
       "15          834N     2\n",
       "40           CA9     1\n",
       "\n",
       "[76 rows x 2 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sel_train = X_sel_train.drop(['strain'], axis=1)\n",
    "X_sel_test = X_sel_test.drop(['strain'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### neural network on over-sampling data\n",
    "model_sel = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_sel_train.shape[1],)),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sel.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 177 samples, validate on 76 samples\n",
      "Epoch 1/1000\n",
      "177/177 [==============================] - 0s 671us/step - loss: 16.6302 - accuracy: 0.2373 - val_loss: 7.0770 - val_accuracy: 0.2105\n",
      "Epoch 2/1000\n",
      "177/177 [==============================] - 0s 81us/step - loss: 14.7159 - accuracy: 0.2768 - val_loss: 6.1042 - val_accuracy: 0.2500\n",
      "Epoch 3/1000\n",
      "177/177 [==============================] - 0s 98us/step - loss: 12.8403 - accuracy: 0.2881 - val_loss: 5.2717 - val_accuracy: 0.2237\n",
      "Epoch 4/1000\n",
      "177/177 [==============================] - 0s 105us/step - loss: 11.2429 - accuracy: 0.3107 - val_loss: 4.5567 - val_accuracy: 0.1842\n",
      "Epoch 5/1000\n",
      "177/177 [==============================] - 0s 117us/step - loss: 9.2450 - accuracy: 0.2938 - val_loss: 3.8828 - val_accuracy: 0.3684\n",
      "Epoch 6/1000\n",
      "177/177 [==============================] - 0s 101us/step - loss: 7.8674 - accuracy: 0.3503 - val_loss: 3.1239 - val_accuracy: 0.3421\n",
      "Epoch 7/1000\n",
      "177/177 [==============================] - 0s 101us/step - loss: 6.2304 - accuracy: 0.3333 - val_loss: 2.4936 - val_accuracy: 0.3684\n",
      "Epoch 8/1000\n",
      "177/177 [==============================] - 0s 96us/step - loss: 4.7008 - accuracy: 0.3559 - val_loss: 1.9289 - val_accuracy: 0.3684\n",
      "Epoch 9/1000\n",
      "177/177 [==============================] - 0s 111us/step - loss: 3.3755 - accuracy: 0.3559 - val_loss: 1.4382 - val_accuracy: 0.3421\n",
      "Epoch 10/1000\n",
      "177/177 [==============================] - 0s 88us/step - loss: 2.0646 - accuracy: 0.3729 - val_loss: 1.3504 - val_accuracy: 0.3816\n",
      "Epoch 11/1000\n",
      "177/177 [==============================] - 0s 90us/step - loss: 1.7982 - accuracy: 0.3729 - val_loss: 2.1703 - val_accuracy: 0.3684\n",
      "Epoch 12/1000\n",
      "177/177 [==============================] - 0s 87us/step - loss: 2.0607 - accuracy: 0.4011 - val_loss: 1.8933 - val_accuracy: 0.3421\n",
      "Epoch 13/1000\n",
      "177/177 [==============================] - 0s 85us/step - loss: 1.6058 - accuracy: 0.4520 - val_loss: 1.7684 - val_accuracy: 0.4605\n",
      "Epoch 14/1000\n",
      "177/177 [==============================] - 0s 79us/step - loss: 1.7981 - accuracy: 0.4802 - val_loss: 1.6973 - val_accuracy: 0.5132\n",
      "Epoch 15/1000\n",
      "177/177 [==============================] - 0s 70us/step - loss: 1.4979 - accuracy: 0.4972 - val_loss: 0.9967 - val_accuracy: 0.4868\n",
      "Epoch 16/1000\n",
      "177/177 [==============================] - 0s 76us/step - loss: 1.2171 - accuracy: 0.5198 - val_loss: 1.1624 - val_accuracy: 0.4342\n",
      "Epoch 17/1000\n",
      "177/177 [==============================] - 0s 87us/step - loss: 1.4942 - accuracy: 0.5198 - val_loss: 1.2530 - val_accuracy: 0.4605\n",
      "Epoch 18/1000\n",
      "177/177 [==============================] - 0s 117us/step - loss: 1.3179 - accuracy: 0.5311 - val_loss: 1.0160 - val_accuracy: 0.5263\n",
      "Epoch 19/1000\n",
      "177/177 [==============================] - 0s 92us/step - loss: 0.9572 - accuracy: 0.5593 - val_loss: 1.2185 - val_accuracy: 0.5132\n",
      "Epoch 20/1000\n",
      "177/177 [==============================] - 0s 102us/step - loss: 1.1562 - accuracy: 0.5424 - val_loss: 1.0216 - val_accuracy: 0.5395\n",
      "Epoch 21/1000\n",
      "177/177 [==============================] - 0s 132us/step - loss: 0.9107 - accuracy: 0.5593 - val_loss: 1.0679 - val_accuracy: 0.4868\n",
      "Epoch 22/1000\n",
      "177/177 [==============================] - 0s 141us/step - loss: 1.1017 - accuracy: 0.5537 - val_loss: 1.0410 - val_accuracy: 0.4868\n",
      "Epoch 23/1000\n",
      "177/177 [==============================] - 0s 111us/step - loss: 0.9749 - accuracy: 0.5706 - val_loss: 1.1041 - val_accuracy: 0.5263\n",
      "Epoch 24/1000\n",
      "177/177 [==============================] - 0s 142us/step - loss: 0.9644 - accuracy: 0.5763 - val_loss: 1.0353 - val_accuracy: 0.5132\n",
      "Epoch 25/1000\n",
      "177/177 [==============================] - 0s 112us/step - loss: 0.8699 - accuracy: 0.5876 - val_loss: 1.0592 - val_accuracy: 0.5132\n",
      "Epoch 26/1000\n",
      "177/177 [==============================] - 0s 113us/step - loss: 1.0034 - accuracy: 0.5763 - val_loss: 1.0170 - val_accuracy: 0.4868\n",
      "Epoch 27/1000\n",
      "177/177 [==============================] - 0s 107us/step - loss: 0.8722 - accuracy: 0.5876 - val_loss: 1.1136 - val_accuracy: 0.5132\n",
      "Epoch 28/1000\n",
      "177/177 [==============================] - 0s 109us/step - loss: 0.9770 - accuracy: 0.5932 - val_loss: 1.0504 - val_accuracy: 0.5263\n",
      "Epoch 29/1000\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.8497 - accuracy: 0.6215 - val_loss: 0.9982 - val_accuracy: 0.5263\n",
      "Epoch 30/1000\n",
      "177/177 [==============================] - 0s 119us/step - loss: 0.8260 - accuracy: 0.6497 - val_loss: 1.0541 - val_accuracy: 0.5395\n",
      "Epoch 31/1000\n",
      "177/177 [==============================] - 0s 131us/step - loss: 0.8142 - accuracy: 0.6384 - val_loss: 1.0434 - val_accuracy: 0.5132\n",
      "Epoch 32/1000\n",
      "177/177 [==============================] - 0s 105us/step - loss: 0.8153 - accuracy: 0.6441 - val_loss: 1.0157 - val_accuracy: 0.5000\n",
      "Epoch 33/1000\n",
      "177/177 [==============================] - 0s 94us/step - loss: 0.8466 - accuracy: 0.6610 - val_loss: 1.0027 - val_accuracy: 0.5000\n",
      "Epoch 34/1000\n",
      "177/177 [==============================] - 0s 148us/step - loss: 0.8185 - accuracy: 0.6610 - val_loss: 1.0331 - val_accuracy: 0.4868\n",
      "Epoch 35/1000\n",
      "177/177 [==============================] - 0s 111us/step - loss: 0.8707 - accuracy: 0.6441 - val_loss: 1.1336 - val_accuracy: 0.5132\n",
      "Epoch 36/1000\n",
      "177/177 [==============================] - 0s 105us/step - loss: 0.8189 - accuracy: 0.6667 - val_loss: 1.0044 - val_accuracy: 0.4737\n",
      "Epoch 37/1000\n",
      "177/177 [==============================] - 0s 89us/step - loss: 0.8060 - accuracy: 0.6893 - val_loss: 0.9930 - val_accuracy: 0.5263\n",
      "Epoch 38/1000\n",
      "177/177 [==============================] - 0s 76us/step - loss: 0.7756 - accuracy: 0.6780 - val_loss: 1.0614 - val_accuracy: 0.5263\n",
      "Epoch 39/1000\n",
      "177/177 [==============================] - 0s 87us/step - loss: 0.7820 - accuracy: 0.7062 - val_loss: 1.0494 - val_accuracy: 0.5132\n",
      "Epoch 40/1000\n",
      "177/177 [==============================] - 0s 89us/step - loss: 0.7525 - accuracy: 0.7119 - val_loss: 0.9986 - val_accuracy: 0.5000\n",
      "Epoch 41/1000\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.8053 - accuracy: 0.6893 - val_loss: 1.0154 - val_accuracy: 0.5263\n",
      "Epoch 42/1000\n",
      "177/177 [==============================] - 0s 83us/step - loss: 0.7450 - accuracy: 0.6949 - val_loss: 1.1175 - val_accuracy: 0.5000\n",
      "Epoch 43/1000\n",
      "177/177 [==============================] - 0s 89us/step - loss: 0.7643 - accuracy: 0.7119 - val_loss: 1.0074 - val_accuracy: 0.5000\n",
      "Epoch 44/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.7893 - accuracy: 0.7288 - val_loss: 1.0126 - val_accuracy: 0.5263\n",
      "Epoch 45/1000\n",
      "177/177 [==============================] - 0s 83us/step - loss: 0.7260 - accuracy: 0.7458 - val_loss: 1.0985 - val_accuracy: 0.5263\n",
      "Epoch 46/1000\n",
      "177/177 [==============================] - 0s 86us/step - loss: 0.7929 - accuracy: 0.7175 - val_loss: 1.0439 - val_accuracy: 0.4868\n",
      "Epoch 47/1000\n",
      "177/177 [==============================] - 0s 78us/step - loss: 0.7729 - accuracy: 0.7458 - val_loss: 1.0728 - val_accuracy: 0.4737\n",
      "Epoch 48/1000\n",
      "177/177 [==============================] - 0s 86us/step - loss: 0.8619 - accuracy: 0.7288 - val_loss: 1.0459 - val_accuracy: 0.4737\n",
      "Epoch 49/1000\n",
      "177/177 [==============================] - 0s 94us/step - loss: 0.6799 - accuracy: 0.7627 - val_loss: 1.0730 - val_accuracy: 0.4737\n",
      "Epoch 50/1000\n",
      "177/177 [==============================] - 0s 123us/step - loss: 0.7704 - accuracy: 0.7232 - val_loss: 1.0937 - val_accuracy: 0.4868\n",
      "Epoch 51/1000\n",
      "177/177 [==============================] - 0s 77us/step - loss: 0.6854 - accuracy: 0.7740 - val_loss: 1.0524 - val_accuracy: 0.4737\n",
      "Epoch 52/1000\n",
      "177/177 [==============================] - 0s 87us/step - loss: 0.6955 - accuracy: 0.7740 - val_loss: 1.0084 - val_accuracy: 0.4605\n",
      "Epoch 53/1000\n",
      "177/177 [==============================] - 0s 120us/step - loss: 0.6649 - accuracy: 0.7853 - val_loss: 1.0714 - val_accuracy: 0.5000\n",
      "Epoch 54/1000\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.6671 - accuracy: 0.7684 - val_loss: 1.0477 - val_accuracy: 0.5000\n",
      "Epoch 55/1000\n",
      "177/177 [==============================] - 0s 94us/step - loss: 0.6566 - accuracy: 0.7797 - val_loss: 1.0186 - val_accuracy: 0.4737\n",
      "Epoch 56/1000\n",
      "177/177 [==============================] - 0s 86us/step - loss: 0.6573 - accuracy: 0.7684 - val_loss: 1.0370 - val_accuracy: 0.4737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/1000\n",
      "177/177 [==============================] - 0s 115us/step - loss: 0.6710 - accuracy: 0.8079 - val_loss: 1.0933 - val_accuracy: 0.4737\n",
      "Epoch 58/1000\n",
      "177/177 [==============================] - 0s 81us/step - loss: 0.6564 - accuracy: 0.7853 - val_loss: 1.0101 - val_accuracy: 0.4605\n",
      "Epoch 59/1000\n",
      "177/177 [==============================] - 0s 95us/step - loss: 0.6303 - accuracy: 0.8079 - val_loss: 1.0139 - val_accuracy: 0.4737\n",
      "Epoch 60/1000\n",
      "177/177 [==============================] - 0s 177us/step - loss: 0.6241 - accuracy: 0.8023 - val_loss: 1.0101 - val_accuracy: 0.4868\n",
      "Epoch 61/1000\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.6074 - accuracy: 0.8079 - val_loss: 1.0182 - val_accuracy: 0.4605\n",
      "Epoch 62/1000\n",
      "177/177 [==============================] - 0s 79us/step - loss: 0.6340 - accuracy: 0.8079 - val_loss: 1.0196 - val_accuracy: 0.4605\n",
      "Epoch 63/1000\n",
      "177/177 [==============================] - 0s 78us/step - loss: 0.6116 - accuracy: 0.8079 - val_loss: 1.0899 - val_accuracy: 0.5132\n",
      "Epoch 64/1000\n",
      "177/177 [==============================] - 0s 84us/step - loss: 0.7029 - accuracy: 0.7966 - val_loss: 1.1502 - val_accuracy: 0.4868\n",
      "Epoch 65/1000\n",
      "177/177 [==============================] - 0s 95us/step - loss: 0.6710 - accuracy: 0.7966 - val_loss: 1.0202 - val_accuracy: 0.4737\n",
      "Epoch 66/1000\n",
      "177/177 [==============================] - 0s 127us/step - loss: 0.6334 - accuracy: 0.8079 - val_loss: 1.0694 - val_accuracy: 0.4605\n",
      "Epoch 67/1000\n",
      "177/177 [==============================] - 0s 131us/step - loss: 0.6074 - accuracy: 0.8023 - val_loss: 1.0312 - val_accuracy: 0.4474\n",
      "Epoch 68/1000\n",
      "177/177 [==============================] - 0s 119us/step - loss: 0.6156 - accuracy: 0.7853 - val_loss: 1.0243 - val_accuracy: 0.4474\n",
      "Epoch 69/1000\n",
      "177/177 [==============================] - 0s 110us/step - loss: 0.6150 - accuracy: 0.8023 - val_loss: 1.0790 - val_accuracy: 0.4868\n",
      "Epoch 70/1000\n",
      "177/177 [==============================] - 0s 110us/step - loss: 0.5895 - accuracy: 0.8136 - val_loss: 1.0282 - val_accuracy: 0.4868\n",
      "Epoch 71/1000\n",
      "177/177 [==============================] - 0s 120us/step - loss: 0.5854 - accuracy: 0.8136 - val_loss: 1.0193 - val_accuracy: 0.4737\n",
      "Epoch 72/1000\n",
      "177/177 [==============================] - 0s 68us/step - loss: 0.5533 - accuracy: 0.8305 - val_loss: 1.1181 - val_accuracy: 0.4737\n",
      "Epoch 73/1000\n",
      "177/177 [==============================] - 0s 102us/step - loss: 0.6069 - accuracy: 0.8136 - val_loss: 1.0450 - val_accuracy: 0.4868\n",
      "Epoch 74/1000\n",
      "177/177 [==============================] - 0s 128us/step - loss: 0.5834 - accuracy: 0.8023 - val_loss: 1.0235 - val_accuracy: 0.4737\n",
      "Epoch 75/1000\n",
      "177/177 [==============================] - 0s 124us/step - loss: 0.5664 - accuracy: 0.8136 - val_loss: 1.0746 - val_accuracy: 0.4474\n",
      "Epoch 76/1000\n",
      "177/177 [==============================] - 0s 94us/step - loss: 0.5586 - accuracy: 0.8192 - val_loss: 1.0369 - val_accuracy: 0.4605\n",
      "Epoch 77/1000\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.6606 - accuracy: 0.7740 - val_loss: 1.0322 - val_accuracy: 0.4474\n",
      "Epoch 78/1000\n",
      "177/177 [==============================] - 0s 82us/step - loss: 0.5933 - accuracy: 0.8023 - val_loss: 1.1791 - val_accuracy: 0.4737\n",
      "Epoch 79/1000\n",
      "177/177 [==============================] - 0s 69us/step - loss: 0.7592 - accuracy: 0.7910 - val_loss: 1.1729 - val_accuracy: 0.5000\n",
      "Epoch 80/1000\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.8404 - accuracy: 0.7740 - val_loss: 1.1541 - val_accuracy: 0.4605\n",
      "Epoch 81/1000\n",
      "177/177 [==============================] - 0s 97us/step - loss: 0.8393 - accuracy: 0.7684 - val_loss: 1.0695 - val_accuracy: 0.4474\n",
      "Epoch 82/1000\n",
      "177/177 [==============================] - 0s 91us/step - loss: 0.7447 - accuracy: 0.7740 - val_loss: 1.2097 - val_accuracy: 0.4737\n",
      "Epoch 83/1000\n",
      "177/177 [==============================] - 0s 94us/step - loss: 0.7448 - accuracy: 0.7740 - val_loss: 1.3208 - val_accuracy: 0.4737\n",
      "Epoch 84/1000\n",
      "177/177 [==============================] - 0s 76us/step - loss: 0.7115 - accuracy: 0.8079 - val_loss: 1.3816 - val_accuracy: 0.5000\n",
      "Epoch 85/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.7280 - accuracy: 0.7853 - val_loss: 1.2393 - val_accuracy: 0.5000\n",
      "Epoch 86/1000\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.6844 - accuracy: 0.8023 - val_loss: 1.0644 - val_accuracy: 0.4737\n",
      "Epoch 87/1000\n",
      "177/177 [==============================] - 0s 58us/step - loss: 0.6232 - accuracy: 0.8136 - val_loss: 1.0701 - val_accuracy: 0.4079\n",
      "Epoch 88/1000\n",
      "177/177 [==============================] - 0s 75us/step - loss: 0.6345 - accuracy: 0.7966 - val_loss: 1.0504 - val_accuracy: 0.4737\n",
      "Epoch 89/1000\n",
      "177/177 [==============================] - 0s 77us/step - loss: 0.5985 - accuracy: 0.8249 - val_loss: 1.1857 - val_accuracy: 0.4474\n",
      "Epoch 90/1000\n",
      "177/177 [==============================] - 0s 75us/step - loss: 0.6737 - accuracy: 0.8136 - val_loss: 1.0374 - val_accuracy: 0.4737\n",
      "Epoch 91/1000\n",
      "177/177 [==============================] - 0s 94us/step - loss: 0.5021 - accuracy: 0.8531 - val_loss: 1.1001 - val_accuracy: 0.4868\n",
      "Epoch 92/1000\n",
      "177/177 [==============================] - 0s 86us/step - loss: 0.6038 - accuracy: 0.8475 - val_loss: 1.1218 - val_accuracy: 0.4868\n",
      "Epoch 93/1000\n",
      "177/177 [==============================] - 0s 106us/step - loss: 0.6096 - accuracy: 0.8249 - val_loss: 1.0433 - val_accuracy: 0.4474\n",
      "Epoch 94/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.6034 - accuracy: 0.8192 - val_loss: 1.0417 - val_accuracy: 0.4868\n",
      "Epoch 95/1000\n",
      "177/177 [==============================] - ETA: 0s - loss: 0.4306 - accuracy: 0.85 - 0s 74us/step - loss: 0.5846 - accuracy: 0.8362 - val_loss: 1.2107 - val_accuracy: 0.5000\n",
      "Epoch 96/1000\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.5358 - accuracy: 0.8475 - val_loss: 1.2247 - val_accuracy: 0.4737\n",
      "Epoch 97/1000\n",
      "177/177 [==============================] - 0s 86us/step - loss: 0.7671 - accuracy: 0.8023 - val_loss: 1.0533 - val_accuracy: 0.4474\n",
      "Epoch 98/1000\n",
      "177/177 [==============================] - 0s 74us/step - loss: 0.5136 - accuracy: 0.8475 - val_loss: 1.1389 - val_accuracy: 0.5000\n",
      "Epoch 99/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.7182 - accuracy: 0.8136 - val_loss: 1.1458 - val_accuracy: 0.4605\n",
      "Epoch 100/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.5469 - accuracy: 0.8475 - val_loss: 1.0484 - val_accuracy: 0.4737\n",
      "Epoch 101/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.6401 - accuracy: 0.8079 - val_loss: 1.1907 - val_accuracy: 0.5000\n",
      "Epoch 102/1000\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.6402 - accuracy: 0.8418 - val_loss: 1.1764 - val_accuracy: 0.4605\n",
      "Epoch 103/1000\n",
      "177/177 [==============================] - 0s 60us/step - loss: 0.5307 - accuracy: 0.8475 - val_loss: 1.0450 - val_accuracy: 0.4868\n",
      "Epoch 104/1000\n",
      "177/177 [==============================] - 0s 60us/step - loss: 0.4556 - accuracy: 0.8814 - val_loss: 1.0601 - val_accuracy: 0.4868\n",
      "Epoch 105/1000\n",
      "177/177 [==============================] - 0s 70us/step - loss: 0.4505 - accuracy: 0.8701 - val_loss: 1.0849 - val_accuracy: 0.4868\n",
      "Epoch 106/1000\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.4874 - accuracy: 0.8588 - val_loss: 1.0447 - val_accuracy: 0.5000\n",
      "Epoch 107/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.4449 - accuracy: 0.8701 - val_loss: 1.0786 - val_accuracy: 0.5000\n",
      "Epoch 108/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.4927 - accuracy: 0.8644 - val_loss: 1.1115 - val_accuracy: 0.4868\n",
      "Epoch 109/1000\n",
      "177/177 [==============================] - 0s 59us/step - loss: 0.4422 - accuracy: 0.8814 - val_loss: 1.0361 - val_accuracy: 0.4737\n",
      "Epoch 110/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.4868 - accuracy: 0.8531 - val_loss: 1.0386 - val_accuracy: 0.4868\n",
      "Epoch 111/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.5034 - accuracy: 0.8475 - val_loss: 1.1577 - val_accuracy: 0.4868\n",
      "Epoch 112/1000\n",
      "177/177 [==============================] - 0s 60us/step - loss: 0.4849 - accuracy: 0.8701 - val_loss: 1.0708 - val_accuracy: 0.4605\n",
      "Epoch 113/1000\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.4274 - accuracy: 0.8757 - val_loss: 1.0401 - val_accuracy: 0.4868\n",
      "Epoch 114/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.4379 - accuracy: 0.8757 - val_loss: 1.0917 - val_accuracy: 0.5000\n",
      "Epoch 115/1000\n",
      "177/177 [==============================] - 0s 82us/step - loss: 0.4514 - accuracy: 0.8927 - val_loss: 1.0944 - val_accuracy: 0.4737\n",
      "Epoch 116/1000\n",
      "177/177 [==============================] - 0s 102us/step - loss: 0.4199 - accuracy: 0.8870 - val_loss: 1.0479 - val_accuracy: 0.4737\n",
      "Epoch 117/1000\n",
      "177/177 [==============================] - 0s 91us/step - loss: 0.4431 - accuracy: 0.8644 - val_loss: 1.0657 - val_accuracy: 0.4605\n",
      "Epoch 118/1000\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.4352 - accuracy: 0.8701 - val_loss: 1.0665 - val_accuracy: 0.4474\n",
      "Epoch 119/1000\n",
      "177/177 [==============================] - 0s 121us/step - loss: 0.4158 - accuracy: 0.8757 - val_loss: 1.0501 - val_accuracy: 0.4737\n",
      "Epoch 120/1000\n",
      "177/177 [==============================] - 0s 152us/step - loss: 0.4232 - accuracy: 0.8644 - val_loss: 1.0572 - val_accuracy: 0.5000\n",
      "Epoch 121/1000\n",
      "177/177 [==============================] - 0s 149us/step - loss: 0.4085 - accuracy: 0.8870 - val_loss: 1.1272 - val_accuracy: 0.4868\n",
      "Epoch 122/1000\n",
      "177/177 [==============================] - 0s 99us/step - loss: 0.4622 - accuracy: 0.8927 - val_loss: 1.1014 - val_accuracy: 0.4605\n",
      "Epoch 123/1000\n",
      "177/177 [==============================] - 0s 147us/step - loss: 0.4214 - accuracy: 0.8870 - val_loss: 1.0669 - val_accuracy: 0.4474\n",
      "Epoch 124/1000\n",
      "177/177 [==============================] - 0s 190us/step - loss: 0.5063 - accuracy: 0.8701 - val_loss: 1.1415 - val_accuracy: 0.4737\n",
      "Epoch 125/1000\n",
      "177/177 [==============================] - 0s 118us/step - loss: 0.4949 - accuracy: 0.8531 - val_loss: 1.1006 - val_accuracy: 0.4474\n",
      "Epoch 126/1000\n",
      "177/177 [==============================] - 0s 109us/step - loss: 0.5062 - accuracy: 0.8362 - val_loss: 1.0636 - val_accuracy: 0.4737\n",
      "Epoch 127/1000\n",
      "177/177 [==============================] - 0s 121us/step - loss: 0.5077 - accuracy: 0.8588 - val_loss: 1.1283 - val_accuracy: 0.4474\n",
      "Epoch 128/1000\n",
      "177/177 [==============================] - 0s 102us/step - loss: 0.5143 - accuracy: 0.8644 - val_loss: 1.0529 - val_accuracy: 0.4868\n",
      "Epoch 129/1000\n",
      "177/177 [==============================] - 0s 129us/step - loss: 0.4769 - accuracy: 0.8588 - val_loss: 1.0806 - val_accuracy: 0.4342\n",
      "Epoch 130/1000\n",
      "177/177 [==============================] - 0s 95us/step - loss: 0.5606 - accuracy: 0.8305 - val_loss: 1.0517 - val_accuracy: 0.4737\n",
      "Epoch 131/1000\n",
      "177/177 [==============================] - 0s 117us/step - loss: 0.4209 - accuracy: 0.8927 - val_loss: 1.1843 - val_accuracy: 0.5263\n",
      "Epoch 132/1000\n",
      "177/177 [==============================] - 0s 105us/step - loss: 0.5331 - accuracy: 0.8701 - val_loss: 1.1486 - val_accuracy: 0.5132\n",
      "Epoch 133/1000\n",
      "177/177 [==============================] - 0s 100us/step - loss: 0.4233 - accuracy: 0.9040 - val_loss: 1.0945 - val_accuracy: 0.4737\n",
      "Epoch 134/1000\n",
      "177/177 [==============================] - 0s 94us/step - loss: 0.4484 - accuracy: 0.8644 - val_loss: 1.0863 - val_accuracy: 0.4737\n",
      "Epoch 135/1000\n",
      "177/177 [==============================] - 0s 96us/step - loss: 0.3988 - accuracy: 0.8927 - val_loss: 1.1322 - val_accuracy: 0.4737\n",
      "Epoch 136/1000\n",
      "177/177 [==============================] - 0s 109us/step - loss: 0.4396 - accuracy: 0.8870 - val_loss: 1.1180 - val_accuracy: 0.4868\n",
      "Epoch 137/1000\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.4470 - accuracy: 0.8870 - val_loss: 1.0735 - val_accuracy: 0.4737\n",
      "Epoch 138/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.4061 - accuracy: 0.8757 - val_loss: 1.0612 - val_accuracy: 0.4737\n",
      "Epoch 139/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.4201 - accuracy: 0.8927 - val_loss: 1.1443 - val_accuracy: 0.4868\n",
      "Epoch 140/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.4120 - accuracy: 0.8927 - val_loss: 1.0721 - val_accuracy: 0.4737\n",
      "Epoch 141/1000\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.4117 - accuracy: 0.8927 - val_loss: 1.0775 - val_accuracy: 0.5000\n",
      "Epoch 142/1000\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.3965 - accuracy: 0.8870 - val_loss: 1.0866 - val_accuracy: 0.5000\n",
      "Epoch 143/1000\n",
      "177/177 [==============================] - 0s 68us/step - loss: 0.4073 - accuracy: 0.9040 - val_loss: 1.2062 - val_accuracy: 0.5000\n",
      "Epoch 144/1000\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.4598 - accuracy: 0.8983 - val_loss: 1.1757 - val_accuracy: 0.4868\n",
      "Epoch 145/1000\n",
      "177/177 [==============================] - 0s 104us/step - loss: 0.3945 - accuracy: 0.8927 - val_loss: 1.0670 - val_accuracy: 0.4868\n",
      "Epoch 146/1000\n",
      "177/177 [==============================] - 0s 89us/step - loss: 0.5856 - accuracy: 0.8814 - val_loss: 1.0672 - val_accuracy: 0.4737\n",
      "Epoch 147/1000\n",
      "177/177 [==============================] - 0s 113us/step - loss: 0.3897 - accuracy: 0.8927 - val_loss: 1.3185 - val_accuracy: 0.5132\n",
      "Epoch 148/1000\n",
      "177/177 [==============================] - 0s 105us/step - loss: 0.6226 - accuracy: 0.8757 - val_loss: 1.3513 - val_accuracy: 0.5000\n",
      "Epoch 149/1000\n",
      "177/177 [==============================] - 0s 145us/step - loss: 0.5778 - accuracy: 0.8814 - val_loss: 1.2817 - val_accuracy: 0.4868\n",
      "Epoch 150/1000\n",
      "177/177 [==============================] - 0s 105us/step - loss: 0.5067 - accuracy: 0.8757 - val_loss: 1.1269 - val_accuracy: 0.4868\n",
      "Epoch 151/1000\n",
      "177/177 [==============================] - 0s 93us/step - loss: 0.4479 - accuracy: 0.8814 - val_loss: 1.1148 - val_accuracy: 0.4737\n",
      "Epoch 152/1000\n",
      "177/177 [==============================] - 0s 109us/step - loss: 0.4953 - accuracy: 0.8757 - val_loss: 1.0973 - val_accuracy: 0.4474\n",
      "Epoch 153/1000\n",
      "177/177 [==============================] - 0s 113us/step - loss: 0.3602 - accuracy: 0.9153 - val_loss: 1.3551 - val_accuracy: 0.5263\n",
      "Epoch 154/1000\n",
      "177/177 [==============================] - 0s 110us/step - loss: 0.5318 - accuracy: 0.8927 - val_loss: 1.3823 - val_accuracy: 0.4868\n",
      "Epoch 155/1000\n",
      "177/177 [==============================] - 0s 92us/step - loss: 0.4932 - accuracy: 0.9096 - val_loss: 1.2423 - val_accuracy: 0.5132\n",
      "Epoch 156/1000\n",
      "177/177 [==============================] - 0s 92us/step - loss: 0.4363 - accuracy: 0.9096 - val_loss: 1.0820 - val_accuracy: 0.5000\n",
      "Epoch 157/1000\n",
      "177/177 [==============================] - 0s 130us/step - loss: 0.5152 - accuracy: 0.8983 - val_loss: 1.1051 - val_accuracy: 0.4868\n",
      "Epoch 158/1000\n",
      "177/177 [==============================] - 0s 131us/step - loss: 0.4515 - accuracy: 0.8983 - val_loss: 1.3320 - val_accuracy: 0.5263\n",
      "Epoch 159/1000\n",
      "177/177 [==============================] - 0s 113us/step - loss: 0.5623 - accuracy: 0.8927 - val_loss: 1.4713 - val_accuracy: 0.4737\n",
      "Epoch 160/1000\n",
      "177/177 [==============================] - 0s 147us/step - loss: 0.6154 - accuracy: 0.8644 - val_loss: 1.2866 - val_accuracy: 0.5263\n",
      "Epoch 161/1000\n",
      "177/177 [==============================] - 0s 111us/step - loss: 0.4950 - accuracy: 0.9040 - val_loss: 1.1118 - val_accuracy: 0.4868\n",
      "Epoch 162/1000\n",
      "177/177 [==============================] - 0s 102us/step - loss: 0.4025 - accuracy: 0.8927 - val_loss: 1.0984 - val_accuracy: 0.4342\n",
      "Epoch 163/1000\n",
      "177/177 [==============================] - 0s 93us/step - loss: 0.4915 - accuracy: 0.8701 - val_loss: 1.0957 - val_accuracy: 0.4605\n",
      "Epoch 164/1000\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.3347 - accuracy: 0.9153 - val_loss: 1.2240 - val_accuracy: 0.4737\n",
      "Epoch 165/1000\n",
      "177/177 [==============================] - 0s 93us/step - loss: 0.5185 - accuracy: 0.8814 - val_loss: 1.1470 - val_accuracy: 0.4737\n",
      "Epoch 166/1000\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.4299 - accuracy: 0.8983 - val_loss: 1.1440 - val_accuracy: 0.4737\n",
      "Epoch 167/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177/177 [==============================] - 0s 65us/step - loss: 0.4559 - accuracy: 0.8757 - val_loss: 1.2454 - val_accuracy: 0.4868\n",
      "Epoch 168/1000\n",
      "177/177 [==============================] - 0s 106us/step - loss: 0.4520 - accuracy: 0.9153 - val_loss: 1.2049 - val_accuracy: 0.5000\n",
      "Epoch 169/1000\n",
      "177/177 [==============================] - 0s 213us/step - loss: 0.3444 - accuracy: 0.9209 - val_loss: 1.0781 - val_accuracy: 0.4605\n",
      "Epoch 170/1000\n",
      "177/177 [==============================] - 0s 146us/step - loss: 0.3912 - accuracy: 0.9096 - val_loss: 1.0883 - val_accuracy: 0.4868\n",
      "Epoch 171/1000\n",
      "177/177 [==============================] - 0s 170us/step - loss: 0.3114 - accuracy: 0.9322 - val_loss: 1.1617 - val_accuracy: 0.5000\n",
      "Epoch 172/1000\n",
      "177/177 [==============================] - 0s 109us/step - loss: 0.3692 - accuracy: 0.9209 - val_loss: 1.1750 - val_accuracy: 0.4868\n",
      "Epoch 173/1000\n",
      "177/177 [==============================] - 0s 132us/step - loss: 0.3618 - accuracy: 0.9153 - val_loss: 1.1016 - val_accuracy: 0.4605\n",
      "Epoch 174/1000\n",
      "177/177 [==============================] - 0s 139us/step - loss: 0.4340 - accuracy: 0.8983 - val_loss: 1.0939 - val_accuracy: 0.4868\n",
      "Epoch 175/1000\n",
      "177/177 [==============================] - 0s 116us/step - loss: 0.3732 - accuracy: 0.9209 - val_loss: 1.2024 - val_accuracy: 0.5132\n",
      "Epoch 176/1000\n",
      "177/177 [==============================] - 0s 86us/step - loss: 0.3425 - accuracy: 0.9322 - val_loss: 1.1087 - val_accuracy: 0.4868\n",
      "Epoch 177/1000\n",
      "177/177 [==============================] - 0s 161us/step - loss: 0.3946 - accuracy: 0.8983 - val_loss: 1.0924 - val_accuracy: 0.4737\n",
      "Epoch 178/1000\n",
      "177/177 [==============================] - 0s 127us/step - loss: 0.3976 - accuracy: 0.9096 - val_loss: 1.1430 - val_accuracy: 0.4868\n",
      "Epoch 179/1000\n",
      "177/177 [==============================] - 0s 149us/step - loss: 0.3766 - accuracy: 0.9153 - val_loss: 1.0923 - val_accuracy: 0.4342\n",
      "Epoch 180/1000\n",
      "177/177 [==============================] - 0s 155us/step - loss: 0.4735 - accuracy: 0.8814 - val_loss: 1.0950 - val_accuracy: 0.4605\n",
      "Epoch 181/1000\n",
      "177/177 [==============================] - 0s 331us/step - loss: 0.3293 - accuracy: 0.9096 - val_loss: 1.3476 - val_accuracy: 0.4737\n",
      "Epoch 182/1000\n",
      "177/177 [==============================] - 0s 114us/step - loss: 0.6364 - accuracy: 0.8814 - val_loss: 1.1744 - val_accuracy: 0.4342\n",
      "Epoch 183/1000\n",
      "177/177 [==============================] - 0s 70us/step - loss: 0.5090 - accuracy: 0.9040 - val_loss: 1.0963 - val_accuracy: 0.4737\n",
      "Epoch 184/1000\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.5013 - accuracy: 0.8757 - val_loss: 1.2261 - val_accuracy: 0.4737\n",
      "Epoch 185/1000\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.4149 - accuracy: 0.9153 - val_loss: 1.4598 - val_accuracy: 0.4868\n",
      "Epoch 186/1000\n",
      "177/177 [==============================] - 0s 70us/step - loss: 0.7147 - accuracy: 0.8870 - val_loss: 1.1603 - val_accuracy: 0.4605\n",
      "Epoch 187/1000\n",
      "177/177 [==============================] - 0s 82us/step - loss: 0.4650 - accuracy: 0.8757 - val_loss: 1.1782 - val_accuracy: 0.4079\n",
      "Epoch 188/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.7064 - accuracy: 0.8531 - val_loss: 1.3241 - val_accuracy: 0.4605\n",
      "Epoch 189/1000\n",
      "177/177 [==============================] - 0s 76us/step - loss: 0.6662 - accuracy: 0.8701 - val_loss: 1.1077 - val_accuracy: 0.4868\n",
      "Epoch 190/1000\n",
      "177/177 [==============================] - 0s 77us/step - loss: 0.4419 - accuracy: 0.9040 - val_loss: 1.2179 - val_accuracy: 0.4605\n",
      "Epoch 191/1000\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.4041 - accuracy: 0.8870 - val_loss: 1.1189 - val_accuracy: 0.4868\n",
      "Epoch 192/1000\n",
      "177/177 [==============================] - 0s 109us/step - loss: 0.3656 - accuracy: 0.8983 - val_loss: 1.1698 - val_accuracy: 0.4868\n",
      "Epoch 193/1000\n",
      "177/177 [==============================] - 0s 135us/step - loss: 0.3835 - accuracy: 0.9209 - val_loss: 1.3111 - val_accuracy: 0.4868\n",
      "Epoch 194/1000\n",
      "177/177 [==============================] - 0s 144us/step - loss: 0.4268 - accuracy: 0.9096 - val_loss: 1.2426 - val_accuracy: 0.4211\n",
      "Epoch 195/1000\n",
      "177/177 [==============================] - 0s 115us/step - loss: 0.4493 - accuracy: 0.8870 - val_loss: 1.1934 - val_accuracy: 0.4079\n",
      "Epoch 196/1000\n",
      "177/177 [==============================] - 0s 119us/step - loss: 0.7323 - accuracy: 0.8701 - val_loss: 1.1682 - val_accuracy: 0.4474\n",
      "Epoch 197/1000\n",
      "177/177 [==============================] - 0s 144us/step - loss: 0.5594 - accuracy: 0.8644 - val_loss: 1.1521 - val_accuracy: 0.4737\n",
      "Epoch 198/1000\n",
      "177/177 [==============================] - 0s 131us/step - loss: 0.3192 - accuracy: 0.9209 - val_loss: 1.3338 - val_accuracy: 0.4868\n",
      "Epoch 199/1000\n",
      "177/177 [==============================] - 0s 109us/step - loss: 0.4209 - accuracy: 0.8870 - val_loss: 1.1510 - val_accuracy: 0.4868\n",
      "Epoch 200/1000\n",
      "177/177 [==============================] - 0s 93us/step - loss: 0.3470 - accuracy: 0.9153 - val_loss: 1.1050 - val_accuracy: 0.4474\n",
      "Epoch 201/1000\n",
      "177/177 [==============================] - 0s 121us/step - loss: 0.3859 - accuracy: 0.9153 - val_loss: 1.1225 - val_accuracy: 0.4605\n",
      "Epoch 202/1000\n",
      "177/177 [==============================] - 0s 96us/step - loss: 0.2737 - accuracy: 0.9435 - val_loss: 1.2034 - val_accuracy: 0.4605\n",
      "Epoch 203/1000\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.3477 - accuracy: 0.9266 - val_loss: 1.1463 - val_accuracy: 0.4737\n",
      "Epoch 204/1000\n",
      "177/177 [==============================] - 0s 99us/step - loss: 0.3735 - accuracy: 0.9209 - val_loss: 1.1083 - val_accuracy: 0.4474\n",
      "Epoch 205/1000\n",
      "177/177 [==============================] - 0s 119us/step - loss: 0.3676 - accuracy: 0.9153 - val_loss: 1.1227 - val_accuracy: 0.4737\n",
      "Epoch 206/1000\n",
      "177/177 [==============================] - 0s 102us/step - loss: 0.3578 - accuracy: 0.9153 - val_loss: 1.3463 - val_accuracy: 0.4737\n",
      "Epoch 207/1000\n",
      "177/177 [==============================] - 0s 120us/step - loss: 0.3722 - accuracy: 0.9096 - val_loss: 1.1071 - val_accuracy: 0.4605\n",
      "Epoch 208/1000\n",
      "177/177 [==============================] - 0s 325us/step - loss: 0.3428 - accuracy: 0.9379 - val_loss: 1.1096 - val_accuracy: 0.4737\n",
      "Epoch 209/1000\n",
      "177/177 [==============================] - 0s 85us/step - loss: 0.4095 - accuracy: 0.9096 - val_loss: 1.1108 - val_accuracy: 0.4605\n",
      "Epoch 210/1000\n",
      "177/177 [==============================] - 0s 81us/step - loss: 0.2652 - accuracy: 0.9379 - val_loss: 1.3145 - val_accuracy: 0.5000\n",
      "Epoch 211/1000\n",
      "177/177 [==============================] - 0s 69us/step - loss: 0.3715 - accuracy: 0.9209 - val_loss: 1.2137 - val_accuracy: 0.4868\n",
      "Epoch 212/1000\n",
      "177/177 [==============================] - 0s 69us/step - loss: 0.3349 - accuracy: 0.9379 - val_loss: 1.1336 - val_accuracy: 0.4737\n",
      "Epoch 213/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.3033 - accuracy: 0.9322 - val_loss: 1.1436 - val_accuracy: 0.4737\n",
      "Epoch 214/1000\n",
      "177/177 [==============================] - 0s 85us/step - loss: 0.2826 - accuracy: 0.9266 - val_loss: 1.1107 - val_accuracy: 0.5000\n",
      "Epoch 215/1000\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.2744 - accuracy: 0.9492 - val_loss: 1.1386 - val_accuracy: 0.5000\n",
      "Epoch 216/1000\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.2951 - accuracy: 0.9379 - val_loss: 1.1480 - val_accuracy: 0.4868\n",
      "Epoch 217/1000\n",
      "177/177 [==============================] - 0s 93us/step - loss: 0.2788 - accuracy: 0.9492 - val_loss: 1.1115 - val_accuracy: 0.4868\n",
      "Epoch 218/1000\n",
      "177/177 [==============================] - 0s 70us/step - loss: 0.2879 - accuracy: 0.9435 - val_loss: 1.1274 - val_accuracy: 0.4737\n",
      "Epoch 219/1000\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.2693 - accuracy: 0.9492 - val_loss: 1.1281 - val_accuracy: 0.5000\n",
      "Epoch 220/1000\n",
      "177/177 [==============================] - 0s 68us/step - loss: 0.2740 - accuracy: 0.9379 - val_loss: 1.1278 - val_accuracy: 0.4868\n",
      "Epoch 221/1000\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.2749 - accuracy: 0.9435 - val_loss: 1.1346 - val_accuracy: 0.5000\n",
      "Epoch 222/1000\n",
      "177/177 [==============================] - 0s 94us/step - loss: 0.2714 - accuracy: 0.9435 - val_loss: 1.1584 - val_accuracy: 0.5000\n",
      "Epoch 223/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.2885 - accuracy: 0.9492 - val_loss: 1.2540 - val_accuracy: 0.5000\n",
      "Epoch 224/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.3479 - accuracy: 0.9322 - val_loss: 1.1175 - val_accuracy: 0.4868\n",
      "Epoch 225/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.3198 - accuracy: 0.9266 - val_loss: 1.1080 - val_accuracy: 0.5132\n",
      "Epoch 226/1000\n",
      "177/177 [==============================] - 0s 56us/step - loss: 0.3427 - accuracy: 0.9379 - val_loss: 1.1869 - val_accuracy: 0.5132\n",
      "Epoch 227/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.3369 - accuracy: 0.9266 - val_loss: 1.1936 - val_accuracy: 0.5132\n",
      "Epoch 228/1000\n",
      "177/177 [==============================] - 0s 74us/step - loss: 0.3244 - accuracy: 0.9266 - val_loss: 1.1416 - val_accuracy: 0.4868\n",
      "Epoch 229/1000\n",
      "177/177 [==============================] - 0s 78us/step - loss: 0.3309 - accuracy: 0.9322 - val_loss: 1.1678 - val_accuracy: 0.5132\n",
      "Epoch 230/1000\n",
      "177/177 [==============================] - 0s 89us/step - loss: 0.3171 - accuracy: 0.9379 - val_loss: 1.2274 - val_accuracy: 0.5000\n",
      "Epoch 231/1000\n",
      "177/177 [==============================] - 0s 92us/step - loss: 0.3987 - accuracy: 0.9322 - val_loss: 1.2599 - val_accuracy: 0.5000\n",
      "Epoch 232/1000\n",
      "177/177 [==============================] - 0s 100us/step - loss: 0.2497 - accuracy: 0.9492 - val_loss: 1.1183 - val_accuracy: 0.4605\n",
      "Epoch 233/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.3915 - accuracy: 0.9040 - val_loss: 1.1219 - val_accuracy: 0.4605\n",
      "Epoch 234/1000\n",
      "177/177 [==============================] - 0s 69us/step - loss: 0.3502 - accuracy: 0.9266 - val_loss: 1.1864 - val_accuracy: 0.4868\n",
      "Epoch 235/1000\n",
      "177/177 [==============================] - 0s 87us/step - loss: 0.3350 - accuracy: 0.9209 - val_loss: 1.2449 - val_accuracy: 0.5132\n",
      "Epoch 236/1000\n",
      "177/177 [==============================] - 0s 108us/step - loss: 0.2980 - accuracy: 0.9322 - val_loss: 1.1543 - val_accuracy: 0.5132\n",
      "Epoch 237/1000\n",
      "177/177 [==============================] - 0s 115us/step - loss: 0.3099 - accuracy: 0.9492 - val_loss: 1.1922 - val_accuracy: 0.5132\n",
      "Epoch 238/1000\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.3554 - accuracy: 0.9209 - val_loss: 1.2965 - val_accuracy: 0.5132\n",
      "Epoch 239/1000\n",
      "177/177 [==============================] - 0s 100us/step - loss: 0.3611 - accuracy: 0.9322 - val_loss: 1.1987 - val_accuracy: 0.5000\n",
      "Epoch 240/1000\n",
      "177/177 [==============================] - 0s 78us/step - loss: 0.2690 - accuracy: 0.9492 - val_loss: 1.1246 - val_accuracy: 0.5000\n",
      "Epoch 241/1000\n",
      "177/177 [==============================] - 0s 81us/step - loss: 0.2487 - accuracy: 0.9492 - val_loss: 1.1518 - val_accuracy: 0.4737\n",
      "Epoch 242/1000\n",
      "177/177 [==============================] - 0s 112us/step - loss: 0.2524 - accuracy: 0.9492 - val_loss: 1.1471 - val_accuracy: 0.4868\n",
      "Epoch 243/1000\n",
      "177/177 [==============================] - 0s 84us/step - loss: 0.2316 - accuracy: 0.9548 - val_loss: 1.1249 - val_accuracy: 0.5000\n",
      "Epoch 244/1000\n",
      "177/177 [==============================] - 0s 130us/step - loss: 0.2946 - accuracy: 0.9379 - val_loss: 1.1298 - val_accuracy: 0.5263\n",
      "Epoch 245/1000\n",
      "177/177 [==============================] - 0s 108us/step - loss: 0.3161 - accuracy: 0.9435 - val_loss: 1.2669 - val_accuracy: 0.5395\n",
      "Epoch 246/1000\n",
      "177/177 [==============================] - 0s 97us/step - loss: 0.2909 - accuracy: 0.9379 - val_loss: 1.1575 - val_accuracy: 0.4868\n",
      "Epoch 247/1000\n",
      "177/177 [==============================] - 0s 79us/step - loss: 0.4061 - accuracy: 0.9153 - val_loss: 1.1298 - val_accuracy: 0.4474\n",
      "Epoch 248/1000\n",
      "177/177 [==============================] - 0s 109us/step - loss: 0.3447 - accuracy: 0.9266 - val_loss: 1.1580 - val_accuracy: 0.5132\n",
      "Epoch 249/1000\n",
      "177/177 [==============================] - 0s 83us/step - loss: 0.3188 - accuracy: 0.9379 - val_loss: 1.2997 - val_accuracy: 0.5132\n",
      "Epoch 250/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.3346 - accuracy: 0.9379 - val_loss: 1.1684 - val_accuracy: 0.5132\n",
      "Epoch 251/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.2694 - accuracy: 0.9379 - val_loss: 1.1926 - val_accuracy: 0.4737\n",
      "Epoch 252/1000\n",
      "177/177 [==============================] - 0s 56us/step - loss: 0.3405 - accuracy: 0.9322 - val_loss: 1.1949 - val_accuracy: 0.4737\n",
      "Epoch 253/1000\n",
      "177/177 [==============================] - 0s 57us/step - loss: 0.2816 - accuracy: 0.9435 - val_loss: 1.1765 - val_accuracy: 0.5000\n",
      "Epoch 254/1000\n",
      "177/177 [==============================] - 0s 49us/step - loss: 0.2853 - accuracy: 0.9435 - val_loss: 1.2340 - val_accuracy: 0.4737\n",
      "Epoch 255/1000\n",
      "177/177 [==============================] - 0s 57us/step - loss: 0.3267 - accuracy: 0.9266 - val_loss: 1.1625 - val_accuracy: 0.4737\n",
      "Epoch 256/1000\n",
      "177/177 [==============================] - 0s 68us/step - loss: 0.3064 - accuracy: 0.9266 - val_loss: 1.1544 - val_accuracy: 0.4605\n",
      "Epoch 257/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.3699 - accuracy: 0.9322 - val_loss: 1.1363 - val_accuracy: 0.5263\n",
      "Epoch 258/1000\n",
      "177/177 [==============================] - 0s 74us/step - loss: 0.2896 - accuracy: 0.9379 - val_loss: 1.1860 - val_accuracy: 0.5132\n",
      "Epoch 259/1000\n",
      "177/177 [==============================] - 0s 68us/step - loss: 0.2529 - accuracy: 0.9379 - val_loss: 1.1539 - val_accuracy: 0.5132\n",
      "Epoch 260/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.2500 - accuracy: 0.9492 - val_loss: 1.1953 - val_accuracy: 0.5000\n",
      "Epoch 261/1000\n",
      "177/177 [==============================] - 0s 60us/step - loss: 0.2361 - accuracy: 0.9548 - val_loss: 1.1726 - val_accuracy: 0.4868\n",
      "Epoch 262/1000\n",
      "177/177 [==============================] - 0s 68us/step - loss: 0.2345 - accuracy: 0.9492 - val_loss: 1.1636 - val_accuracy: 0.4737\n",
      "Epoch 263/1000\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.2521 - accuracy: 0.9379 - val_loss: 1.2312 - val_accuracy: 0.4868\n",
      "Epoch 264/1000\n",
      "177/177 [==============================] - 0s 76us/step - loss: 0.2930 - accuracy: 0.9435 - val_loss: 1.2828 - val_accuracy: 0.5000\n",
      "Epoch 265/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.2862 - accuracy: 0.9492 - val_loss: 1.1539 - val_accuracy: 0.5000\n",
      "Epoch 266/1000\n",
      "177/177 [==============================] - 0s 58us/step - loss: 0.2963 - accuracy: 0.9435 - val_loss: 1.1379 - val_accuracy: 0.4605\n",
      "Epoch 267/1000\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.3317 - accuracy: 0.9266 - val_loss: 1.1627 - val_accuracy: 0.5132\n",
      "Epoch 268/1000\n",
      "177/177 [==============================] - 0s 75us/step - loss: 0.2399 - accuracy: 0.9435 - val_loss: 1.4735 - val_accuracy: 0.5132\n",
      "Epoch 269/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.4580 - accuracy: 0.9153 - val_loss: 1.1927 - val_accuracy: 0.4868\n",
      "Epoch 270/1000\n",
      "177/177 [==============================] - 0s 58us/step - loss: 0.2861 - accuracy: 0.9435 - val_loss: 1.1720 - val_accuracy: 0.5000\n",
      "Epoch 271/1000\n",
      "177/177 [==============================] - 0s 59us/step - loss: 0.2955 - accuracy: 0.9379 - val_loss: 1.1964 - val_accuracy: 0.5132\n",
      "Epoch 272/1000\n",
      "177/177 [==============================] - 0s 60us/step - loss: 0.2608 - accuracy: 0.9492 - val_loss: 1.1889 - val_accuracy: 0.4868\n",
      "Epoch 273/1000\n",
      "177/177 [==============================] - 0s 58us/step - loss: 0.2064 - accuracy: 0.9605 - val_loss: 1.1455 - val_accuracy: 0.4868\n",
      "Epoch 274/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.2599 - accuracy: 0.9435 - val_loss: 1.1674 - val_accuracy: 0.5000\n",
      "Epoch 275/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.2372 - accuracy: 0.9548 - val_loss: 1.2636 - val_accuracy: 0.5132\n",
      "Epoch 276/1000\n",
      "177/177 [==============================] - 0s 63us/step - loss: 0.2551 - accuracy: 0.9492 - val_loss: 1.1764 - val_accuracy: 0.4868\n",
      "Epoch 277/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.2193 - accuracy: 0.9492 - val_loss: 1.1766 - val_accuracy: 0.4737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 278/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.2172 - accuracy: 0.9548 - val_loss: 1.1782 - val_accuracy: 0.4868\n",
      "Epoch 279/1000\n",
      "177/177 [==============================] - 0s 69us/step - loss: 0.2190 - accuracy: 0.9548 - val_loss: 1.1910 - val_accuracy: 0.4737\n",
      "Epoch 280/1000\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.2177 - accuracy: 0.9435 - val_loss: 1.1796 - val_accuracy: 0.4868\n",
      "Epoch 281/1000\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.2153 - accuracy: 0.9492 - val_loss: 1.1740 - val_accuracy: 0.4737\n",
      "Epoch 282/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.2002 - accuracy: 0.9605 - val_loss: 1.1985 - val_accuracy: 0.4737\n",
      "Epoch 283/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.2234 - accuracy: 0.9605 - val_loss: 1.1870 - val_accuracy: 0.4737\n",
      "Epoch 284/1000\n",
      "177/177 [==============================] - 0s 77us/step - loss: 0.2259 - accuracy: 0.9492 - val_loss: 1.1692 - val_accuracy: 0.4868\n",
      "Epoch 285/1000\n",
      "177/177 [==============================] - 0s 63us/step - loss: 0.1966 - accuracy: 0.9605 - val_loss: 1.2497 - val_accuracy: 0.4737\n",
      "Epoch 286/1000\n",
      "177/177 [==============================] - 0s 59us/step - loss: 0.2710 - accuracy: 0.9492 - val_loss: 1.1726 - val_accuracy: 0.4605\n",
      "Epoch 287/1000\n",
      "177/177 [==============================] - 0s 53us/step - loss: 0.2798 - accuracy: 0.9435 - val_loss: 1.1677 - val_accuracy: 0.4474\n",
      "Epoch 288/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.2514 - accuracy: 0.9492 - val_loss: 1.3142 - val_accuracy: 0.4737\n",
      "Epoch 289/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.2910 - accuracy: 0.9379 - val_loss: 1.1935 - val_accuracy: 0.4605\n",
      "Epoch 290/1000\n",
      "177/177 [==============================] - 0s 53us/step - loss: 0.2179 - accuracy: 0.9435 - val_loss: 1.1941 - val_accuracy: 0.4868\n",
      "Epoch 291/1000\n",
      "177/177 [==============================] - 0s 77us/step - loss: 0.2197 - accuracy: 0.9492 - val_loss: 1.2048 - val_accuracy: 0.4737\n",
      "Epoch 292/1000\n",
      "177/177 [==============================] - 0s 77us/step - loss: 0.1995 - accuracy: 0.9605 - val_loss: 1.1980 - val_accuracy: 0.4737\n",
      "Epoch 293/1000\n",
      "177/177 [==============================] - 0s 77us/step - loss: 0.2084 - accuracy: 0.9548 - val_loss: 1.1647 - val_accuracy: 0.4868\n",
      "Epoch 294/1000\n",
      "177/177 [==============================] - 0s 60us/step - loss: 0.2223 - accuracy: 0.9492 - val_loss: 1.1882 - val_accuracy: 0.5000\n",
      "Epoch 295/1000\n",
      "177/177 [==============================] - 0s 60us/step - loss: 0.1907 - accuracy: 0.9548 - val_loss: 1.2056 - val_accuracy: 0.5132\n",
      "Epoch 296/1000\n",
      "177/177 [==============================] - 0s 57us/step - loss: 0.2037 - accuracy: 0.9605 - val_loss: 1.1885 - val_accuracy: 0.4737\n",
      "Epoch 297/1000\n",
      "177/177 [==============================] - 0s 70us/step - loss: 0.2364 - accuracy: 0.9492 - val_loss: 1.1779 - val_accuracy: 0.4737\n",
      "Epoch 298/1000\n",
      "177/177 [==============================] - 0s 84us/step - loss: 0.1961 - accuracy: 0.9605 - val_loss: 1.3197 - val_accuracy: 0.4868\n",
      "Epoch 299/1000\n",
      "177/177 [==============================] - 0s 59us/step - loss: 0.3792 - accuracy: 0.9322 - val_loss: 1.2864 - val_accuracy: 0.4737\n",
      "Epoch 300/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.2404 - accuracy: 0.9492 - val_loss: 1.2152 - val_accuracy: 0.4474\n",
      "Epoch 301/1000\n",
      "177/177 [==============================] - 0s 56us/step - loss: 0.5674 - accuracy: 0.9153 - val_loss: 1.2265 - val_accuracy: 0.4342\n",
      "Epoch 302/1000\n",
      "177/177 [==============================] - 0s 63us/step - loss: 0.3926 - accuracy: 0.9153 - val_loss: 1.2399 - val_accuracy: 0.5395\n",
      "Epoch 303/1000\n",
      "177/177 [==============================] - 0s 60us/step - loss: 0.3279 - accuracy: 0.9435 - val_loss: 1.6511 - val_accuracy: 0.5263\n",
      "Epoch 304/1000\n",
      "177/177 [==============================] - 0s 59us/step - loss: 0.4111 - accuracy: 0.9209 - val_loss: 1.3801 - val_accuracy: 0.5263\n",
      "Epoch 305/1000\n",
      "177/177 [==============================] - 0s 57us/step - loss: 0.3895 - accuracy: 0.9209 - val_loss: 1.2279 - val_accuracy: 0.4737\n",
      "Epoch 306/1000\n",
      "177/177 [==============================] - 0s 58us/step - loss: 0.3236 - accuracy: 0.9379 - val_loss: 1.2542 - val_accuracy: 0.4605\n",
      "Epoch 307/1000\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.3475 - accuracy: 0.9266 - val_loss: 1.4343 - val_accuracy: 0.4605\n",
      "Epoch 308/1000\n",
      "177/177 [==============================] - 0s 59us/step - loss: 0.2736 - accuracy: 0.9322 - val_loss: 1.2179 - val_accuracy: 0.4605\n",
      "Epoch 309/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.2395 - accuracy: 0.9379 - val_loss: 1.2123 - val_accuracy: 0.4079\n",
      "Epoch 310/1000\n",
      "177/177 [==============================] - 0s 76us/step - loss: 0.4096 - accuracy: 0.9096 - val_loss: 1.1933 - val_accuracy: 0.4737\n",
      "Epoch 311/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.2160 - accuracy: 0.9492 - val_loss: 1.3558 - val_accuracy: 0.5263\n",
      "Epoch 312/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.4187 - accuracy: 0.9266 - val_loss: 1.4338 - val_accuracy: 0.5132\n",
      "Epoch 313/1000\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.2760 - accuracy: 0.9379 - val_loss: 1.2233 - val_accuracy: 0.4737\n",
      "Epoch 314/1000\n",
      "177/177 [==============================] - 0s 70us/step - loss: 0.2898 - accuracy: 0.9322 - val_loss: 1.1928 - val_accuracy: 0.4868\n",
      "Epoch 315/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.2242 - accuracy: 0.9492 - val_loss: 1.3370 - val_accuracy: 0.4868\n",
      "Epoch 316/1000\n",
      "177/177 [==============================] - 0s 68us/step - loss: 0.3351 - accuracy: 0.9266 - val_loss: 1.2678 - val_accuracy: 0.4605\n",
      "Epoch 317/1000\n",
      "177/177 [==============================] - 0s 68us/step - loss: 0.2666 - accuracy: 0.9435 - val_loss: 1.1909 - val_accuracy: 0.4868\n",
      "Epoch 318/1000\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.2897 - accuracy: 0.9379 - val_loss: 1.2038 - val_accuracy: 0.4868\n",
      "Epoch 319/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.2355 - accuracy: 0.9492 - val_loss: 1.3000 - val_accuracy: 0.4868\n",
      "Epoch 320/1000\n",
      "177/177 [==============================] - 0s 56us/step - loss: 0.2329 - accuracy: 0.9492 - val_loss: 1.1904 - val_accuracy: 0.5000\n",
      "Epoch 321/1000\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.3176 - accuracy: 0.9322 - val_loss: 1.1928 - val_accuracy: 0.5132\n",
      "Epoch 322/1000\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.2773 - accuracy: 0.9322 - val_loss: 1.4254 - val_accuracy: 0.5132\n",
      "Epoch 323/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.2685 - accuracy: 0.9435 - val_loss: 1.2453 - val_accuracy: 0.5000\n",
      "Epoch 324/1000\n",
      "177/177 [==============================] - 0s 68us/step - loss: 0.1947 - accuracy: 0.9548 - val_loss: 1.2291 - val_accuracy: 0.4737\n",
      "Epoch 325/1000\n",
      "177/177 [==============================] - 0s 58us/step - loss: 0.1783 - accuracy: 0.9548 - val_loss: 1.2386 - val_accuracy: 0.4737\n",
      "Epoch 326/1000\n",
      "177/177 [==============================] - 0s 56us/step - loss: 0.1874 - accuracy: 0.9548 - val_loss: 1.2270 - val_accuracy: 0.4868\n",
      "Epoch 327/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.1817 - accuracy: 0.9492 - val_loss: 1.2259 - val_accuracy: 0.4605\n",
      "Epoch 328/1000\n",
      "177/177 [==============================] - 0s 63us/step - loss: 0.1968 - accuracy: 0.9492 - val_loss: 1.2347 - val_accuracy: 0.5000\n",
      "Epoch 329/1000\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.1886 - accuracy: 0.9605 - val_loss: 1.3141 - val_accuracy: 0.5132\n",
      "Epoch 330/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.2115 - accuracy: 0.9492 - val_loss: 1.2231 - val_accuracy: 0.4868\n",
      "Epoch 331/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.2022 - accuracy: 0.9492 - val_loss: 1.2446 - val_accuracy: 0.5000\n",
      "Epoch 332/1000\n",
      "177/177 [==============================] - 0s 60us/step - loss: 0.2393 - accuracy: 0.9435 - val_loss: 1.2764 - val_accuracy: 0.5000\n",
      "Epoch 333/1000\n",
      "177/177 [==============================] - 0s 53us/step - loss: 0.2339 - accuracy: 0.9492 - val_loss: 1.2064 - val_accuracy: 0.4868\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 334/1000\n",
      "177/177 [==============================] - 0s 60us/step - loss: 0.2256 - accuracy: 0.9435 - val_loss: 1.2397 - val_accuracy: 0.4868\n",
      "Epoch 335/1000\n",
      "177/177 [==============================] - 0s 52us/step - loss: 0.2591 - accuracy: 0.9435 - val_loss: 1.2848 - val_accuracy: 0.4868\n",
      "Epoch 336/1000\n",
      "177/177 [==============================] - 0s 57us/step - loss: 0.2046 - accuracy: 0.9492 - val_loss: 1.2030 - val_accuracy: 0.4605\n",
      "Epoch 337/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.2994 - accuracy: 0.9209 - val_loss: 1.2108 - val_accuracy: 0.5132\n",
      "Epoch 338/1000\n",
      "177/177 [==============================] - 0s 52us/step - loss: 0.1804 - accuracy: 0.9548 - val_loss: 1.3052 - val_accuracy: 0.5263\n",
      "Epoch 339/1000\n",
      "177/177 [==============================] - 0s 57us/step - loss: 0.2170 - accuracy: 0.9492 - val_loss: 1.2943 - val_accuracy: 0.5263\n",
      "Epoch 340/1000\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.1735 - accuracy: 0.9492 - val_loss: 1.2508 - val_accuracy: 0.4605\n",
      "Epoch 341/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.1818 - accuracy: 0.9492 - val_loss: 1.2626 - val_accuracy: 0.4868\n",
      "Epoch 342/1000\n",
      "177/177 [==============================] - 0s 57us/step - loss: 0.1661 - accuracy: 0.9548 - val_loss: 1.2729 - val_accuracy: 0.4868\n",
      "Epoch 343/1000\n",
      "177/177 [==============================] - 0s 53us/step - loss: 0.2007 - accuracy: 0.9492 - val_loss: 1.2523 - val_accuracy: 0.4737\n",
      "Epoch 344/1000\n",
      "177/177 [==============================] - 0s 55us/step - loss: 0.2288 - accuracy: 0.9605 - val_loss: 1.3184 - val_accuracy: 0.4605\n",
      "Epoch 345/1000\n",
      "177/177 [==============================] - 0s 59us/step - loss: 0.2248 - accuracy: 0.9548 - val_loss: 1.2294 - val_accuracy: 0.5000\n",
      "Epoch 346/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.1747 - accuracy: 0.9548 - val_loss: 1.2618 - val_accuracy: 0.5132\n",
      "Epoch 347/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.1966 - accuracy: 0.9492 - val_loss: 1.3238 - val_accuracy: 0.5000\n",
      "Epoch 348/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.2470 - accuracy: 0.9492 - val_loss: 1.2603 - val_accuracy: 0.4737\n",
      "Epoch 349/1000\n",
      "177/177 [==============================] - 0s 58us/step - loss: 0.2487 - accuracy: 0.9435 - val_loss: 1.2368 - val_accuracy: 0.5132\n",
      "Epoch 350/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.1582 - accuracy: 0.9605 - val_loss: 1.3796 - val_accuracy: 0.5132\n",
      "Epoch 351/1000\n",
      "177/177 [==============================] - 0s 52us/step - loss: 0.2611 - accuracy: 0.9492 - val_loss: 1.4652 - val_accuracy: 0.5132\n",
      "Epoch 352/1000\n",
      "177/177 [==============================] - 0s 56us/step - loss: 0.2290 - accuracy: 0.9492 - val_loss: 1.2480 - val_accuracy: 0.5000\n",
      "Epoch 353/1000\n",
      "177/177 [==============================] - 0s 55us/step - loss: 0.2039 - accuracy: 0.9548 - val_loss: 1.2412 - val_accuracy: 0.4474\n",
      "Epoch 354/1000\n",
      "177/177 [==============================] - 0s 54us/step - loss: 0.2600 - accuracy: 0.9435 - val_loss: 1.2585 - val_accuracy: 0.4868\n",
      "Epoch 355/1000\n",
      "177/177 [==============================] - 0s 54us/step - loss: 0.2105 - accuracy: 0.9605 - val_loss: 1.5693 - val_accuracy: 0.5132\n",
      "Epoch 356/1000\n",
      "177/177 [==============================] - 0s 57us/step - loss: 0.3905 - accuracy: 0.9548 - val_loss: 1.4409 - val_accuracy: 0.5132\n",
      "Epoch 357/1000\n",
      "177/177 [==============================] - 0s 56us/step - loss: 0.2513 - accuracy: 0.9605 - val_loss: 1.2519 - val_accuracy: 0.4868\n",
      "Epoch 358/1000\n",
      "177/177 [==============================] - 0s 63us/step - loss: 0.1954 - accuracy: 0.9548 - val_loss: 1.2668 - val_accuracy: 0.4605\n",
      "Epoch 359/1000\n",
      "177/177 [==============================] - 0s 55us/step - loss: 0.1888 - accuracy: 0.9492 - val_loss: 1.2605 - val_accuracy: 0.4868\n",
      "Epoch 360/1000\n",
      "177/177 [==============================] - 0s 60us/step - loss: 0.2114 - accuracy: 0.9548 - val_loss: 1.3992 - val_accuracy: 0.5000\n",
      "Epoch 361/1000\n",
      "177/177 [==============================] - ETA: 0s - loss: 0.1908 - accuracy: 0.95 - 0s 89us/step - loss: 0.2094 - accuracy: 0.9548 - val_loss: 1.2594 - val_accuracy: 0.4868\n",
      "Epoch 362/1000\n",
      "177/177 [==============================] - 0s 76us/step - loss: 0.1853 - accuracy: 0.9492 - val_loss: 1.2765 - val_accuracy: 0.4868\n",
      "Epoch 363/1000\n",
      "177/177 [==============================] - 0s 60us/step - loss: 0.1720 - accuracy: 0.9605 - val_loss: 1.3037 - val_accuracy: 0.5000\n",
      "Epoch 364/1000\n",
      "177/177 [==============================] - 0s 91us/step - loss: 0.1967 - accuracy: 0.9605 - val_loss: 1.2735 - val_accuracy: 0.4868\n",
      "Epoch 365/1000\n",
      "177/177 [==============================] - 0s 89us/step - loss: 0.1509 - accuracy: 0.9661 - val_loss: 1.2648 - val_accuracy: 0.5000\n",
      "Epoch 366/1000\n",
      "177/177 [==============================] - 0s 70us/step - loss: 0.1625 - accuracy: 0.9548 - val_loss: 1.2593 - val_accuracy: 0.5000\n",
      "Epoch 367/1000\n",
      "177/177 [==============================] - 0s 68us/step - loss: 0.1651 - accuracy: 0.9605 - val_loss: 1.2896 - val_accuracy: 0.5000\n",
      "Epoch 368/1000\n",
      "177/177 [==============================] - 0s 70us/step - loss: 0.1692 - accuracy: 0.9661 - val_loss: 1.3113 - val_accuracy: 0.5000\n",
      "Epoch 369/1000\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.1761 - accuracy: 0.9492 - val_loss: 1.2675 - val_accuracy: 0.4868\n",
      "Epoch 370/1000\n",
      "177/177 [==============================] - 0s 58us/step - loss: 0.1520 - accuracy: 0.9718 - val_loss: 1.2604 - val_accuracy: 0.4868\n",
      "Epoch 371/1000\n",
      "177/177 [==============================] - 0s 53us/step - loss: 0.1536 - accuracy: 0.9605 - val_loss: 1.3033 - val_accuracy: 0.5132\n",
      "Epoch 372/1000\n",
      "177/177 [==============================] - 0s 49us/step - loss: 0.1721 - accuracy: 0.9548 - val_loss: 1.2785 - val_accuracy: 0.5132\n",
      "Epoch 373/1000\n",
      "177/177 [==============================] - 0s 47us/step - loss: 0.1454 - accuracy: 0.9605 - val_loss: 1.2519 - val_accuracy: 0.4868\n",
      "Epoch 374/1000\n",
      "177/177 [==============================] - 0s 58us/step - loss: 0.1897 - accuracy: 0.9605 - val_loss: 1.2721 - val_accuracy: 0.5132\n",
      "Epoch 375/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.1890 - accuracy: 0.9661 - val_loss: 1.3607 - val_accuracy: 0.5132\n",
      "Epoch 376/1000\n",
      "177/177 [==============================] - 0s 74us/step - loss: 0.1580 - accuracy: 0.9605 - val_loss: 1.2567 - val_accuracy: 0.5000\n",
      "Epoch 377/1000\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.2683 - accuracy: 0.9379 - val_loss: 1.2651 - val_accuracy: 0.5000\n",
      "Epoch 378/1000\n",
      "177/177 [==============================] - 0s 57us/step - loss: 0.2150 - accuracy: 0.9435 - val_loss: 1.4270 - val_accuracy: 0.5132\n",
      "Epoch 379/1000\n",
      "177/177 [==============================] - 0s 55us/step - loss: 0.2438 - accuracy: 0.9492 - val_loss: 1.3323 - val_accuracy: 0.5132\n",
      "Epoch 380/1000\n",
      "177/177 [==============================] - 0s 58us/step - loss: 0.1987 - accuracy: 0.9548 - val_loss: 1.2806 - val_accuracy: 0.4868\n",
      "Epoch 381/1000\n",
      "177/177 [==============================] - 0s 50us/step - loss: 0.1844 - accuracy: 0.9548 - val_loss: 1.3026 - val_accuracy: 0.5000\n",
      "Epoch 382/1000\n",
      "177/177 [==============================] - 0s 49us/step - loss: 0.1795 - accuracy: 0.9548 - val_loss: 1.3038 - val_accuracy: 0.5000\n",
      "Epoch 383/1000\n",
      "177/177 [==============================] - 0s 58us/step - loss: 0.1419 - accuracy: 0.9605 - val_loss: 1.2965 - val_accuracy: 0.5132\n",
      "Epoch 384/1000\n",
      "177/177 [==============================] - 0s 54us/step - loss: 0.1650 - accuracy: 0.9605 - val_loss: 1.2802 - val_accuracy: 0.5000\n",
      "Epoch 385/1000\n",
      "177/177 [==============================] - 0s 57us/step - loss: 0.1836 - accuracy: 0.9661 - val_loss: 1.2680 - val_accuracy: 0.5132\n",
      "Epoch 386/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.1362 - accuracy: 0.9718 - val_loss: 1.3858 - val_accuracy: 0.5132\n",
      "Epoch 387/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.2008 - accuracy: 0.9605 - val_loss: 1.2868 - val_accuracy: 0.5263\n",
      "Epoch 388/1000\n",
      "177/177 [==============================] - 0s 60us/step - loss: 0.1392 - accuracy: 0.9718 - val_loss: 1.2591 - val_accuracy: 0.5000\n",
      "Epoch 389/1000\n",
      "177/177 [==============================] - 0s 54us/step - loss: 0.1901 - accuracy: 0.9605 - val_loss: 1.2961 - val_accuracy: 0.5263\n",
      "Epoch 390/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.1425 - accuracy: 0.9605 - val_loss: 1.3108 - val_accuracy: 0.5263\n",
      "Epoch 391/1000\n",
      "177/177 [==============================] - 0s 78us/step - loss: 0.1558 - accuracy: 0.9661 - val_loss: 1.2846 - val_accuracy: 0.5132\n",
      "Epoch 392/1000\n",
      "177/177 [==============================] - 0s 70us/step - loss: 0.1500 - accuracy: 0.9661 - val_loss: 1.2922 - val_accuracy: 0.5132\n",
      "Epoch 393/1000\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.1391 - accuracy: 0.9605 - val_loss: 1.3229 - val_accuracy: 0.5132\n",
      "Epoch 394/1000\n",
      "177/177 [==============================] - 0s 57us/step - loss: 0.1529 - accuracy: 0.9661 - val_loss: 1.2795 - val_accuracy: 0.5263\n",
      "Epoch 395/1000\n",
      "177/177 [==============================] - 0s 60us/step - loss: 0.2395 - accuracy: 0.9492 - val_loss: 1.2682 - val_accuracy: 0.5263\n",
      "Epoch 396/1000\n",
      "177/177 [==============================] - 0s 54us/step - loss: 0.1615 - accuracy: 0.9605 - val_loss: 1.3636 - val_accuracy: 0.5132\n",
      "Epoch 397/1000\n",
      "177/177 [==============================] - 0s 68us/step - loss: 0.2174 - accuracy: 0.9548 - val_loss: 1.3811 - val_accuracy: 0.5000\n",
      "Epoch 398/1000\n",
      "177/177 [==============================] - 0s 77us/step - loss: 0.2022 - accuracy: 0.9548 - val_loss: 1.2802 - val_accuracy: 0.5263\n",
      "Epoch 399/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.1672 - accuracy: 0.9661 - val_loss: 1.3121 - val_accuracy: 0.5000\n",
      "Epoch 400/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.1938 - accuracy: 0.9605 - val_loss: 1.3424 - val_accuracy: 0.5000\n",
      "Epoch 401/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.1739 - accuracy: 0.9661 - val_loss: 1.3279 - val_accuracy: 0.5263\n",
      "Epoch 402/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.2053 - accuracy: 0.9605 - val_loss: 1.2934 - val_accuracy: 0.5132\n",
      "Epoch 403/1000\n",
      "177/177 [==============================] - 0s 68us/step - loss: 0.1638 - accuracy: 0.9605 - val_loss: 1.3050 - val_accuracy: 0.5132\n",
      "Epoch 404/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.1388 - accuracy: 0.9661 - val_loss: 1.2851 - val_accuracy: 0.5132\n",
      "Epoch 405/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.2312 - accuracy: 0.9605 - val_loss: 1.3050 - val_accuracy: 0.5132\n",
      "Epoch 406/1000\n",
      "177/177 [==============================] - 0s 75us/step - loss: 0.2194 - accuracy: 0.9492 - val_loss: 1.3639 - val_accuracy: 0.5263\n",
      "Epoch 407/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.2175 - accuracy: 0.9548 - val_loss: 1.3057 - val_accuracy: 0.5132\n",
      "Epoch 408/1000\n",
      "177/177 [==============================] - 0s 58us/step - loss: 0.1531 - accuracy: 0.9661 - val_loss: 1.5560 - val_accuracy: 0.5263\n",
      "Epoch 409/1000\n",
      "177/177 [==============================] - 0s 63us/step - loss: 0.3546 - accuracy: 0.9548 - val_loss: 1.6680 - val_accuracy: 0.5263\n",
      "Epoch 410/1000\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.2968 - accuracy: 0.9605 - val_loss: 1.4569 - val_accuracy: 0.5395\n",
      "Epoch 411/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.1641 - accuracy: 0.9661 - val_loss: 1.2941 - val_accuracy: 0.4737\n",
      "Epoch 412/1000\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.2265 - accuracy: 0.9435 - val_loss: 1.3262 - val_accuracy: 0.5263\n",
      "Epoch 413/1000\n",
      "177/177 [==============================] - 0s 100us/step - loss: 0.1724 - accuracy: 0.9605 - val_loss: 1.3456 - val_accuracy: 0.5132\n",
      "Epoch 414/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.1651 - accuracy: 0.9718 - val_loss: 1.3232 - val_accuracy: 0.5000\n",
      "Epoch 415/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.1357 - accuracy: 0.9661 - val_loss: 1.3059 - val_accuracy: 0.5132\n",
      "Epoch 416/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.1403 - accuracy: 0.9718 - val_loss: 1.2972 - val_accuracy: 0.5132\n",
      "Epoch 417/1000\n",
      "177/177 [==============================] - 0s 60us/step - loss: 0.1546 - accuracy: 0.9661 - val_loss: 1.3203 - val_accuracy: 0.5395\n",
      "Epoch 418/1000\n",
      "177/177 [==============================] - 0s 59us/step - loss: 0.2251 - accuracy: 0.9492 - val_loss: 1.3424 - val_accuracy: 0.5263\n",
      "Epoch 419/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.2148 - accuracy: 0.9548 - val_loss: 1.2771 - val_accuracy: 0.4605\n",
      "Epoch 420/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.2567 - accuracy: 0.9548 - val_loss: 1.3176 - val_accuracy: 0.5132\n",
      "Epoch 421/1000\n",
      "177/177 [==============================] - 0s 57us/step - loss: 0.1639 - accuracy: 0.9605 - val_loss: 1.5053 - val_accuracy: 0.5132\n",
      "Epoch 422/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.2727 - accuracy: 0.9435 - val_loss: 1.3346 - val_accuracy: 0.5132\n",
      "Epoch 423/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.3309 - accuracy: 0.9435 - val_loss: 1.2882 - val_accuracy: 0.5263\n",
      "Epoch 424/1000\n",
      "177/177 [==============================] - 0s 70us/step - loss: 0.2366 - accuracy: 0.9605 - val_loss: 1.5071 - val_accuracy: 0.5263\n",
      "Epoch 425/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.2863 - accuracy: 0.9548 - val_loss: 1.5562 - val_accuracy: 0.5132\n",
      "Epoch 426/1000\n",
      "177/177 [==============================] - 0s 63us/step - loss: 0.1980 - accuracy: 0.9661 - val_loss: 1.3522 - val_accuracy: 0.5263\n",
      "Epoch 427/1000\n",
      "177/177 [==============================] - 0s 60us/step - loss: 0.2457 - accuracy: 0.9492 - val_loss: 1.3219 - val_accuracy: 0.4868\n",
      "Epoch 428/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.3231 - accuracy: 0.9492 - val_loss: 1.3726 - val_accuracy: 0.5000\n",
      "Epoch 429/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.2690 - accuracy: 0.9605 - val_loss: 1.4344 - val_accuracy: 0.5132\n",
      "Epoch 430/1000\n",
      "177/177 [==============================] - 0s 69us/step - loss: 0.2875 - accuracy: 0.9548 - val_loss: 1.3285 - val_accuracy: 0.4605\n",
      "Epoch 431/1000\n",
      "177/177 [==============================] - 0s 89us/step - loss: 0.2754 - accuracy: 0.9379 - val_loss: 1.3381 - val_accuracy: 0.5132\n",
      "Epoch 432/1000\n",
      "177/177 [==============================] - 0s 55us/step - loss: 0.2718 - accuracy: 0.9492 - val_loss: 1.6118 - val_accuracy: 0.5132\n",
      "Epoch 433/1000\n",
      "177/177 [==============================] - 0s 63us/step - loss: 0.4751 - accuracy: 0.9266 - val_loss: 1.5505 - val_accuracy: 0.5000\n",
      "Epoch 434/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.1758 - accuracy: 0.9718 - val_loss: 1.3737 - val_accuracy: 0.4605\n",
      "Epoch 435/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.5619 - accuracy: 0.9153 - val_loss: 1.3689 - val_accuracy: 0.4605\n",
      "Epoch 436/1000\n",
      "177/177 [==============================] - 0s 52us/step - loss: 0.4456 - accuracy: 0.9492 - val_loss: 1.3381 - val_accuracy: 0.5263\n",
      "Epoch 437/1000\n",
      "177/177 [==============================] - 0s 58us/step - loss: 0.1737 - accuracy: 0.9605 - val_loss: 1.5318 - val_accuracy: 0.5263\n",
      "Epoch 438/1000\n",
      "177/177 [==============================] - 0s 68us/step - loss: 0.1931 - accuracy: 0.9548 - val_loss: 1.3787 - val_accuracy: 0.5263\n",
      "Epoch 439/1000\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.2842 - accuracy: 0.9379 - val_loss: 1.3387 - val_accuracy: 0.5132\n",
      "Epoch 440/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.2528 - accuracy: 0.9379 - val_loss: 1.4936 - val_accuracy: 0.5132\n",
      "Epoch 441/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.2292 - accuracy: 0.9379 - val_loss: 1.4178 - val_accuracy: 0.5000\n",
      "Epoch 442/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.1541 - accuracy: 0.9605 - val_loss: 1.3531 - val_accuracy: 0.5132\n",
      "Epoch 443/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.2052 - accuracy: 0.9605 - val_loss: 1.3593 - val_accuracy: 0.5132\n",
      "Epoch 444/1000\n",
      "177/177 [==============================] - 0s 70us/step - loss: 0.1219 - accuracy: 0.9831 - val_loss: 1.5056 - val_accuracy: 0.4737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 445/1000\n",
      "177/177 [==============================] - 0s 69us/step - loss: 0.2398 - accuracy: 0.9548 - val_loss: 1.3818 - val_accuracy: 0.4868\n",
      "Epoch 446/1000\n",
      "177/177 [==============================] - 0s 70us/step - loss: 0.2309 - accuracy: 0.9661 - val_loss: 1.3080 - val_accuracy: 0.4605\n",
      "Epoch 447/1000\n",
      "177/177 [==============================] - 0s 60us/step - loss: 0.2926 - accuracy: 0.9379 - val_loss: 1.3129 - val_accuracy: 0.5132\n",
      "Epoch 448/1000\n",
      "177/177 [==============================] - 0s 69us/step - loss: 0.1392 - accuracy: 0.9774 - val_loss: 1.5758 - val_accuracy: 0.5132\n",
      "Epoch 449/1000\n",
      "177/177 [==============================] - 0s 70us/step - loss: 0.4063 - accuracy: 0.9379 - val_loss: 1.4506 - val_accuracy: 0.5000\n",
      "Epoch 450/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.1562 - accuracy: 0.9661 - val_loss: 1.3698 - val_accuracy: 0.5000\n",
      "Epoch 451/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.3650 - accuracy: 0.9435 - val_loss: 1.4213 - val_accuracy: 0.5132\n",
      "Epoch 452/1000\n",
      "177/177 [==============================] - 0s 63us/step - loss: 0.1854 - accuracy: 0.9605 - val_loss: 1.4755 - val_accuracy: 0.5000\n",
      "Epoch 453/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.3611 - accuracy: 0.9379 - val_loss: 1.4804 - val_accuracy: 0.5000\n",
      "Epoch 454/1000\n",
      "177/177 [==============================] - 0s 60us/step - loss: 0.3449 - accuracy: 0.9548 - val_loss: 1.3989 - val_accuracy: 0.5132\n",
      "Epoch 455/1000\n",
      "177/177 [==============================] - 0s 56us/step - loss: 0.2028 - accuracy: 0.9605 - val_loss: 1.4944 - val_accuracy: 0.5132\n",
      "Epoch 456/1000\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.1904 - accuracy: 0.9661 - val_loss: 1.3772 - val_accuracy: 0.5132\n",
      "Epoch 457/1000\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.1790 - accuracy: 0.9548 - val_loss: 1.3226 - val_accuracy: 0.5000\n",
      "Epoch 458/1000\n",
      "177/177 [==============================] - 0s 63us/step - loss: 0.1302 - accuracy: 0.9774 - val_loss: 1.3767 - val_accuracy: 0.5132\n",
      "Epoch 459/1000\n",
      "177/177 [==============================] - 0s 59us/step - loss: 0.1398 - accuracy: 0.9661 - val_loss: 1.4134 - val_accuracy: 0.5263\n",
      "Epoch 460/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.1393 - accuracy: 0.9661 - val_loss: 1.3420 - val_accuracy: 0.5395\n",
      "Epoch 461/1000\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.1203 - accuracy: 0.9718 - val_loss: 1.3808 - val_accuracy: 0.5395\n",
      "Epoch 462/1000\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.1375 - accuracy: 0.9718 - val_loss: 1.3670 - val_accuracy: 0.5263\n",
      "Epoch 463/1000\n",
      "177/177 [==============================] - 0s 74us/step - loss: 0.1406 - accuracy: 0.9661 - val_loss: 1.3683 - val_accuracy: 0.5263\n",
      "Epoch 464/1000\n",
      "177/177 [==============================] - 0s 57us/step - loss: 0.1091 - accuracy: 0.9831 - val_loss: 1.4915 - val_accuracy: 0.5000\n",
      "Epoch 465/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.1646 - accuracy: 0.9661 - val_loss: 1.3785 - val_accuracy: 0.5263\n",
      "Epoch 466/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.1449 - accuracy: 0.9718 - val_loss: 1.3628 - val_accuracy: 0.5132\n",
      "Epoch 467/1000\n",
      "177/177 [==============================] - 0s 60us/step - loss: 0.1648 - accuracy: 0.9718 - val_loss: 1.5133 - val_accuracy: 0.5132\n",
      "Epoch 468/1000\n",
      "177/177 [==============================] - 0s 58us/step - loss: 0.1707 - accuracy: 0.9661 - val_loss: 1.4528 - val_accuracy: 0.5263\n",
      "Epoch 469/1000\n",
      "177/177 [==============================] - 0s 59us/step - loss: 0.1421 - accuracy: 0.9774 - val_loss: 1.3424 - val_accuracy: 0.5000\n",
      "Epoch 470/1000\n",
      "177/177 [==============================] - 0s 78us/step - loss: 0.1878 - accuracy: 0.9718 - val_loss: 1.3950 - val_accuracy: 0.5132\n",
      "Epoch 471/1000\n",
      "177/177 [==============================] - 0s 59us/step - loss: 0.1639 - accuracy: 0.9661 - val_loss: 1.4244 - val_accuracy: 0.5132\n",
      "Epoch 472/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.1753 - accuracy: 0.9718 - val_loss: 1.4400 - val_accuracy: 0.5132\n",
      "Epoch 473/1000\n",
      "177/177 [==============================] - 0s 81us/step - loss: 0.1856 - accuracy: 0.9718 - val_loss: 1.3894 - val_accuracy: 0.5132\n",
      "Epoch 474/1000\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.2793 - accuracy: 0.9548 - val_loss: 1.3496 - val_accuracy: 0.4605\n",
      "Epoch 475/1000\n",
      "177/177 [==============================] - 0s 70us/step - loss: 0.2959 - accuracy: 0.9379 - val_loss: 1.4246 - val_accuracy: 0.5263\n",
      "Epoch 476/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.1580 - accuracy: 0.9718 - val_loss: 1.7449 - val_accuracy: 0.5132\n",
      "Epoch 477/1000\n",
      "177/177 [==============================] - 0s 74us/step - loss: 0.3941 - accuracy: 0.9379 - val_loss: 1.5638 - val_accuracy: 0.5132\n",
      "Epoch 478/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.1254 - accuracy: 0.9718 - val_loss: 1.3458 - val_accuracy: 0.5000\n",
      "Epoch 479/1000\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.1966 - accuracy: 0.9661 - val_loss: 1.4052 - val_accuracy: 0.5132\n",
      "Epoch 480/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.2351 - accuracy: 0.9605 - val_loss: 1.4678 - val_accuracy: 0.5000\n",
      "Epoch 481/1000\n",
      "177/177 [==============================] - 0s 56us/step - loss: 0.2241 - accuracy: 0.9661 - val_loss: 1.4389 - val_accuracy: 0.5132\n",
      "Epoch 482/1000\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.2218 - accuracy: 0.9548 - val_loss: 1.3726 - val_accuracy: 0.5132\n",
      "Epoch 483/1000\n",
      "177/177 [==============================] - 0s 70us/step - loss: 0.1700 - accuracy: 0.9661 - val_loss: 1.4844 - val_accuracy: 0.5132\n",
      "Epoch 484/1000\n",
      "177/177 [==============================] - 0s 68us/step - loss: 0.1498 - accuracy: 0.9718 - val_loss: 1.4262 - val_accuracy: 0.5132\n",
      "Epoch 485/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.1273 - accuracy: 0.9718 - val_loss: 1.4081 - val_accuracy: 0.5132\n",
      "Epoch 486/1000\n",
      "177/177 [==============================] - 0s 58us/step - loss: 0.1461 - accuracy: 0.9774 - val_loss: 1.4292 - val_accuracy: 0.5132\n",
      "Epoch 487/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.1386 - accuracy: 0.9718 - val_loss: 1.3774 - val_accuracy: 0.5132\n",
      "Epoch 488/1000\n",
      "177/177 [==============================] - 0s 59us/step - loss: 0.1491 - accuracy: 0.9718 - val_loss: 1.3947 - val_accuracy: 0.5263\n",
      "Epoch 489/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.1190 - accuracy: 0.9774 - val_loss: 1.4014 - val_accuracy: 0.5132\n",
      "Epoch 490/1000\n",
      "177/177 [==============================] - 0s 56us/step - loss: 0.1040 - accuracy: 0.9774 - val_loss: 1.3830 - val_accuracy: 0.5132\n",
      "Epoch 491/1000\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.1110 - accuracy: 0.9718 - val_loss: 1.3977 - val_accuracy: 0.5132\n",
      "Epoch 492/1000\n",
      "177/177 [==============================] - 0s 63us/step - loss: 0.1068 - accuracy: 0.9718 - val_loss: 1.3876 - val_accuracy: 0.5132\n",
      "Epoch 493/1000\n",
      "177/177 [==============================] - 0s 63us/step - loss: 0.1154 - accuracy: 0.9774 - val_loss: 1.4170 - val_accuracy: 0.5132\n",
      "Epoch 494/1000\n",
      "177/177 [==============================] - 0s 59us/step - loss: 0.1353 - accuracy: 0.9774 - val_loss: 1.4098 - val_accuracy: 0.5132\n",
      "Epoch 495/1000\n",
      "177/177 [==============================] - 0s 58us/step - loss: 0.1148 - accuracy: 0.9774 - val_loss: 1.3969 - val_accuracy: 0.5132\n",
      "Epoch 496/1000\n",
      "177/177 [==============================] - 0s 58us/step - loss: 0.1153 - accuracy: 0.9774 - val_loss: 1.4130 - val_accuracy: 0.5132\n",
      "Epoch 497/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.1036 - accuracy: 0.9774 - val_loss: 1.3947 - val_accuracy: 0.5132\n",
      "Epoch 498/1000\n",
      "177/177 [==============================] - 0s 76us/step - loss: 0.1295 - accuracy: 0.9718 - val_loss: 1.4047 - val_accuracy: 0.5132\n",
      "Epoch 499/1000\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.1302 - accuracy: 0.9774 - val_loss: 1.4358 - val_accuracy: 0.5132\n",
      "Epoch 500/1000\n",
      "177/177 [==============================] - 0s 59us/step - loss: 0.1376 - accuracy: 0.9718 - val_loss: 1.3922 - val_accuracy: 0.5132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 501/1000\n",
      "177/177 [==============================] - 0s 69us/step - loss: 0.1290 - accuracy: 0.9718 - val_loss: 1.4314 - val_accuracy: 0.5132\n",
      "Epoch 502/1000\n",
      "177/177 [==============================] - 0s 75us/step - loss: 0.1220 - accuracy: 0.9774 - val_loss: 1.4252 - val_accuracy: 0.5132\n",
      "Epoch 503/1000\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.1004 - accuracy: 0.9831 - val_loss: 1.3984 - val_accuracy: 0.5132\n",
      "Epoch 504/1000\n",
      "177/177 [==============================] - 0s 101us/step - loss: 0.1382 - accuracy: 0.9774 - val_loss: 1.4066 - val_accuracy: 0.5132\n",
      "Epoch 505/1000\n",
      "177/177 [==============================] - 0s 96us/step - loss: 0.0975 - accuracy: 0.9774 - val_loss: 1.5459 - val_accuracy: 0.4868\n",
      "Epoch 506/1000\n",
      "177/177 [==============================] - 0s 111us/step - loss: 0.1731 - accuracy: 0.9774 - val_loss: 1.4306 - val_accuracy: 0.5132\n",
      "Epoch 507/1000\n",
      "177/177 [==============================] - 0s 125us/step - loss: 0.1639 - accuracy: 0.9661 - val_loss: 1.4480 - val_accuracy: 0.5132\n",
      "Epoch 508/1000\n",
      "177/177 [==============================] - 0s 129us/step - loss: 0.1848 - accuracy: 0.9718 - val_loss: 1.5080 - val_accuracy: 0.5263\n",
      "Epoch 509/1000\n",
      "177/177 [==============================] - 0s 125us/step - loss: 0.2520 - accuracy: 0.9605 - val_loss: 1.5895 - val_accuracy: 0.5000\n",
      "Epoch 510/1000\n",
      "177/177 [==============================] - 0s 94us/step - loss: 0.1321 - accuracy: 0.9831 - val_loss: 1.4028 - val_accuracy: 0.5132\n",
      "Epoch 511/1000\n",
      "177/177 [==============================] - 0s 126us/step - loss: 0.1261 - accuracy: 0.9718 - val_loss: 1.4410 - val_accuracy: 0.5132\n",
      "Epoch 512/1000\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.2132 - accuracy: 0.9718 - val_loss: 1.4223 - val_accuracy: 0.5132\n",
      "Epoch 513/1000\n",
      "177/177 [==============================] - 0s 99us/step - loss: 0.1200 - accuracy: 0.9774 - val_loss: 1.4436 - val_accuracy: 0.5132\n",
      "Epoch 514/1000\n",
      "177/177 [==============================] - 0s 121us/step - loss: 0.1159 - accuracy: 0.9774 - val_loss: 1.3998 - val_accuracy: 0.5132\n",
      "Epoch 515/1000\n",
      "177/177 [==============================] - 0s 87us/step - loss: 0.1370 - accuracy: 0.9718 - val_loss: 1.4311 - val_accuracy: 0.5132\n",
      "Epoch 516/1000\n",
      "177/177 [==============================] - 0s 102us/step - loss: 0.0963 - accuracy: 0.9831 - val_loss: 1.4834 - val_accuracy: 0.5000\n",
      "Epoch 517/1000\n",
      "177/177 [==============================] - 0s 122us/step - loss: 0.1328 - accuracy: 0.9831 - val_loss: 1.4266 - val_accuracy: 0.5132\n",
      "Epoch 518/1000\n",
      "177/177 [==============================] - 0s 144us/step - loss: 0.0991 - accuracy: 0.9774 - val_loss: 1.4146 - val_accuracy: 0.5132\n",
      "Epoch 519/1000\n",
      "177/177 [==============================] - 0s 77us/step - loss: 0.1079 - accuracy: 0.9774 - val_loss: 1.4624 - val_accuracy: 0.5132\n",
      "Epoch 520/1000\n",
      "177/177 [==============================] - 0s 68us/step - loss: 0.1416 - accuracy: 0.9831 - val_loss: 1.4712 - val_accuracy: 0.5000\n",
      "Epoch 521/1000\n",
      "177/177 [==============================] - 0s 63us/step - loss: 0.1192 - accuracy: 0.9774 - val_loss: 1.4114 - val_accuracy: 0.5000\n",
      "Epoch 522/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.1940 - accuracy: 0.9661 - val_loss: 1.4101 - val_accuracy: 0.5132\n",
      "Epoch 523/1000\n",
      "177/177 [==============================] - 0s 63us/step - loss: 0.1375 - accuracy: 0.9661 - val_loss: 1.5317 - val_accuracy: 0.5132\n",
      "Epoch 524/1000\n",
      "177/177 [==============================] - 0s 60us/step - loss: 0.2115 - accuracy: 0.9605 - val_loss: 1.4533 - val_accuracy: 0.5132\n",
      "Epoch 525/1000\n",
      "177/177 [==============================] - 0s 56us/step - loss: 0.1325 - accuracy: 0.9718 - val_loss: 1.3988 - val_accuracy: 0.4605\n",
      "Epoch 526/1000\n",
      "177/177 [==============================] - 0s 56us/step - loss: 0.2877 - accuracy: 0.9435 - val_loss: 1.4084 - val_accuracy: 0.5132\n",
      "Epoch 527/1000\n",
      "177/177 [==============================] - 0s 58us/step - loss: 0.1827 - accuracy: 0.9605 - val_loss: 1.7333 - val_accuracy: 0.5000\n",
      "Epoch 528/1000\n",
      "177/177 [==============================] - 0s 57us/step - loss: 0.3011 - accuracy: 0.9435 - val_loss: 1.5265 - val_accuracy: 0.5000\n",
      "Epoch 529/1000\n",
      "177/177 [==============================] - 0s 59us/step - loss: 0.2213 - accuracy: 0.9548 - val_loss: 1.4229 - val_accuracy: 0.5132\n",
      "Epoch 530/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.2048 - accuracy: 0.9605 - val_loss: 1.4683 - val_accuracy: 0.5132\n",
      "Epoch 531/1000\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.1529 - accuracy: 0.9661 - val_loss: 1.6248 - val_accuracy: 0.4868\n",
      "Epoch 532/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.1711 - accuracy: 0.9661 - val_loss: 1.4307 - val_accuracy: 0.5263\n",
      "Epoch 533/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.1931 - accuracy: 0.9605 - val_loss: 1.4104 - val_accuracy: 0.5263\n",
      "Epoch 534/1000\n",
      "177/177 [==============================] - 0s 55us/step - loss: 0.1234 - accuracy: 0.9661 - val_loss: 1.5055 - val_accuracy: 0.5000\n",
      "Epoch 535/1000\n",
      "177/177 [==============================] - 0s 59us/step - loss: 0.2009 - accuracy: 0.9661 - val_loss: 1.5061 - val_accuracy: 0.5000\n",
      "Epoch 536/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.1075 - accuracy: 0.9718 - val_loss: 1.4277 - val_accuracy: 0.5132\n",
      "Epoch 537/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.1568 - accuracy: 0.9718 - val_loss: 1.4544 - val_accuracy: 0.5263\n",
      "Epoch 538/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.1238 - accuracy: 0.9718 - val_loss: 1.5301 - val_accuracy: 0.5132\n",
      "Epoch 539/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.2053 - accuracy: 0.9718 - val_loss: 1.5074 - val_accuracy: 0.5000\n",
      "Epoch 540/1000\n",
      "177/177 [==============================] - 0s 68us/step - loss: 0.1907 - accuracy: 0.9661 - val_loss: 1.4278 - val_accuracy: 0.5132\n",
      "Epoch 541/1000\n",
      "177/177 [==============================] - 0s 69us/step - loss: 0.1497 - accuracy: 0.9718 - val_loss: 1.4441 - val_accuracy: 0.5263\n",
      "Epoch 542/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.0989 - accuracy: 0.9774 - val_loss: 1.5264 - val_accuracy: 0.5132\n",
      "Epoch 543/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.1496 - accuracy: 0.9718 - val_loss: 1.4314 - val_accuracy: 0.5132\n",
      "Epoch 544/1000\n",
      "177/177 [==============================] - 0s 58us/step - loss: 0.1429 - accuracy: 0.9774 - val_loss: 1.4158 - val_accuracy: 0.5263\n",
      "Epoch 545/1000\n",
      "177/177 [==============================] - 0s 60us/step - loss: 0.1269 - accuracy: 0.9718 - val_loss: 1.5448 - val_accuracy: 0.5132\n",
      "Epoch 546/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.1412 - accuracy: 0.9718 - val_loss: 1.4775 - val_accuracy: 0.5132\n",
      "Epoch 547/1000\n",
      "177/177 [==============================] - 0s 58us/step - loss: 0.1264 - accuracy: 0.9774 - val_loss: 1.4401 - val_accuracy: 0.5132\n",
      "Epoch 548/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.1142 - accuracy: 0.9774 - val_loss: 1.5599 - val_accuracy: 0.5000\n",
      "Epoch 549/1000\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.2444 - accuracy: 0.9718 - val_loss: 1.5419 - val_accuracy: 0.5132\n",
      "Epoch 550/1000\n",
      "177/177 [==============================] - 0s 59us/step - loss: 0.2454 - accuracy: 0.9661 - val_loss: 1.4199 - val_accuracy: 0.4605\n",
      "Epoch 551/1000\n",
      "177/177 [==============================] - 0s 60us/step - loss: 0.3432 - accuracy: 0.9492 - val_loss: 1.4390 - val_accuracy: 0.5132\n",
      "Epoch 552/1000\n",
      "177/177 [==============================] - 0s 60us/step - loss: 0.1782 - accuracy: 0.9661 - val_loss: 1.8398 - val_accuracy: 0.5000\n",
      "Epoch 553/1000\n",
      "177/177 [==============================] - 0s 56us/step - loss: 0.4061 - accuracy: 0.9492 - val_loss: 1.9420 - val_accuracy: 0.5132\n",
      "Epoch 554/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.3109 - accuracy: 0.9492 - val_loss: 1.7755 - val_accuracy: 0.5395\n",
      "Epoch 555/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.2760 - accuracy: 0.9605 - val_loss: 1.4844 - val_accuracy: 0.5132\n",
      "Epoch 556/1000\n",
      "177/177 [==============================] - 0s 63us/step - loss: 0.1757 - accuracy: 0.9661 - val_loss: 1.4509 - val_accuracy: 0.5132\n",
      "Epoch 557/1000\n",
      "177/177 [==============================] - 0s 58us/step - loss: 0.1426 - accuracy: 0.9605 - val_loss: 1.6244 - val_accuracy: 0.5132\n",
      "Epoch 558/1000\n",
      "177/177 [==============================] - 0s 57us/step - loss: 0.2389 - accuracy: 0.9605 - val_loss: 1.6619 - val_accuracy: 0.5132\n",
      "Epoch 559/1000\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.1628 - accuracy: 0.9774 - val_loss: 1.4989 - val_accuracy: 0.5000\n",
      "Epoch 560/1000\n",
      "177/177 [==============================] - 0s 81us/step - loss: 0.1281 - accuracy: 0.9774 - val_loss: 1.5003 - val_accuracy: 0.5132\n",
      "Epoch 561/1000\n",
      "177/177 [==============================] - 0s 83us/step - loss: 0.1094 - accuracy: 0.9661 - val_loss: 1.5379 - val_accuracy: 0.5000\n",
      "Epoch 562/1000\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.1353 - accuracy: 0.9774 - val_loss: 1.5033 - val_accuracy: 0.5000\n",
      "Epoch 563/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.1143 - accuracy: 0.9831 - val_loss: 1.4876 - val_accuracy: 0.5000\n",
      "Epoch 564/1000\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.1037 - accuracy: 0.9774 - val_loss: 1.5189 - val_accuracy: 0.5132\n",
      "Epoch 565/1000\n",
      "177/177 [==============================] - 0s 82us/step - loss: 0.1430 - accuracy: 0.9774 - val_loss: 1.5298 - val_accuracy: 0.5000\n",
      "Epoch 566/1000\n",
      "177/177 [==============================] - 0s 87us/step - loss: 0.1269 - accuracy: 0.9661 - val_loss: 1.4712 - val_accuracy: 0.5132\n",
      "Epoch 567/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.1529 - accuracy: 0.9774 - val_loss: 1.4811 - val_accuracy: 0.5000\n",
      "Epoch 568/1000\n",
      "177/177 [==============================] - 0s 56us/step - loss: 0.1026 - accuracy: 0.9774 - val_loss: 1.5677 - val_accuracy: 0.5000\n",
      "Epoch 569/1000\n",
      "177/177 [==============================] - 0s 59us/step - loss: 0.1119 - accuracy: 0.9831 - val_loss: 1.4835 - val_accuracy: 0.5132\n",
      "Epoch 570/1000\n",
      "177/177 [==============================] - 0s 50us/step - loss: 0.0955 - accuracy: 0.9718 - val_loss: 1.4952 - val_accuracy: 0.5132\n",
      "Epoch 571/1000\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.0863 - accuracy: 0.9831 - val_loss: 1.5123 - val_accuracy: 0.5132\n",
      "Epoch 572/1000\n",
      "177/177 [==============================] - 0s 74us/step - loss: 0.0927 - accuracy: 0.9774 - val_loss: 1.5078 - val_accuracy: 0.5000\n",
      "Epoch 573/1000\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.0965 - accuracy: 0.9831 - val_loss: 1.5060 - val_accuracy: 0.5132\n",
      "Epoch 574/1000\n",
      "177/177 [==============================] - 0s 74us/step - loss: 0.0869 - accuracy: 0.9831 - val_loss: 1.4952 - val_accuracy: 0.5132\n",
      "Epoch 575/1000\n",
      "177/177 [==============================] - 0s 60us/step - loss: 0.0941 - accuracy: 0.9718 - val_loss: 1.5051 - val_accuracy: 0.5132\n",
      "Epoch 576/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.0846 - accuracy: 0.9831 - val_loss: 1.5016 - val_accuracy: 0.5132\n",
      "Epoch 577/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.0883 - accuracy: 0.9774 - val_loss: 1.5217 - val_accuracy: 0.5132\n",
      "Epoch 578/1000\n",
      "177/177 [==============================] - 0s 75us/step - loss: 0.1229 - accuracy: 0.9774 - val_loss: 1.5199 - val_accuracy: 0.5132\n",
      "Epoch 579/1000\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.1716 - accuracy: 0.9661 - val_loss: 1.4697 - val_accuracy: 0.4868\n",
      "Epoch 580/1000\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.1308 - accuracy: 0.9661 - val_loss: 1.5332 - val_accuracy: 0.5132\n",
      "Epoch 581/1000\n",
      "177/177 [==============================] - 0s 54us/step - loss: 0.1005 - accuracy: 0.9831 - val_loss: 1.6119 - val_accuracy: 0.5132\n",
      "Epoch 582/1000\n",
      "177/177 [==============================] - 0s 59us/step - loss: 0.1939 - accuracy: 0.9718 - val_loss: 1.5419 - val_accuracy: 0.5132\n",
      "Epoch 583/1000\n",
      "177/177 [==============================] - 0s 58us/step - loss: 0.1789 - accuracy: 0.9605 - val_loss: 1.4985 - val_accuracy: 0.5132\n",
      "Epoch 584/1000\n",
      "177/177 [==============================] - 0s 51us/step - loss: 0.1075 - accuracy: 0.9718 - val_loss: 1.5870 - val_accuracy: 0.5000\n",
      "Epoch 585/1000\n",
      "177/177 [==============================] - 0s 48us/step - loss: 0.1415 - accuracy: 0.9831 - val_loss: 1.5609 - val_accuracy: 0.5132\n",
      "Epoch 586/1000\n",
      "177/177 [==============================] - 0s 59us/step - loss: 0.1368 - accuracy: 0.9831 - val_loss: 1.4780 - val_accuracy: 0.5000\n",
      "Epoch 587/1000\n",
      "177/177 [==============================] - 0s 55us/step - loss: 0.1353 - accuracy: 0.9718 - val_loss: 1.4815 - val_accuracy: 0.5263\n",
      "Epoch 588/1000\n",
      "177/177 [==============================] - 0s 55us/step - loss: 0.0830 - accuracy: 0.9887 - val_loss: 1.6096 - val_accuracy: 0.5132\n",
      "Epoch 589/1000\n",
      "177/177 [==============================] - 0s 55us/step - loss: 0.1662 - accuracy: 0.9718 - val_loss: 1.4970 - val_accuracy: 0.5132\n",
      "Epoch 590/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.1102 - accuracy: 0.9831 - val_loss: 1.4839 - val_accuracy: 0.5132\n",
      "Epoch 591/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.1042 - accuracy: 0.9718 - val_loss: 1.5233 - val_accuracy: 0.5132\n",
      "Epoch 592/1000\n",
      "177/177 [==============================] - 0s 58us/step - loss: 0.1196 - accuracy: 0.9774 - val_loss: 1.7045 - val_accuracy: 0.5132\n",
      "Epoch 593/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.1711 - accuracy: 0.9774 - val_loss: 1.6369 - val_accuracy: 0.5263\n",
      "Epoch 594/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.1484 - accuracy: 0.9661 - val_loss: 1.5109 - val_accuracy: 0.5132\n",
      "Epoch 595/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.1715 - accuracy: 0.9605 - val_loss: 1.5244 - val_accuracy: 0.5132\n",
      "Epoch 596/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.0938 - accuracy: 0.9831 - val_loss: 1.5883 - val_accuracy: 0.5263\n",
      "Epoch 597/1000\n",
      "177/177 [==============================] - 0s 70us/step - loss: 0.1470 - accuracy: 0.9774 - val_loss: 1.6507 - val_accuracy: 0.5132\n",
      "Epoch 598/1000\n",
      "177/177 [==============================] - 0s 51us/step - loss: 0.1663 - accuracy: 0.9774 - val_loss: 1.5186 - val_accuracy: 0.5132\n",
      "Epoch 599/1000\n",
      "177/177 [==============================] - 0s 59us/step - loss: 0.1717 - accuracy: 0.9661 - val_loss: 1.4720 - val_accuracy: 0.5000\n",
      "Epoch 600/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.1745 - accuracy: 0.9661 - val_loss: 1.6067 - val_accuracy: 0.5263\n",
      "Epoch 601/1000\n",
      "177/177 [==============================] - 0s 52us/step - loss: 0.1446 - accuracy: 0.9831 - val_loss: 1.7879 - val_accuracy: 0.5132\n",
      "Epoch 602/1000\n",
      "177/177 [==============================] - 0s 50us/step - loss: 0.2252 - accuracy: 0.9661 - val_loss: 1.5427 - val_accuracy: 0.5132\n",
      "Epoch 603/1000\n",
      "177/177 [==============================] - 0s 59us/step - loss: 0.1045 - accuracy: 0.9718 - val_loss: 1.4843 - val_accuracy: 0.5000\n",
      "Epoch 604/1000\n",
      "177/177 [==============================] - 0s 55us/step - loss: 0.2513 - accuracy: 0.9661 - val_loss: 1.4926 - val_accuracy: 0.5132\n",
      "Epoch 605/1000\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.1804 - accuracy: 0.9774 - val_loss: 1.6965 - val_accuracy: 0.5000\n",
      "Epoch 606/1000\n",
      "177/177 [==============================] - 0s 54us/step - loss: 0.1428 - accuracy: 0.9661 - val_loss: 1.5777 - val_accuracy: 0.5132\n",
      "Epoch 607/1000\n",
      "177/177 [==============================] - 0s 59us/step - loss: 0.0999 - accuracy: 0.9831 - val_loss: 1.5619 - val_accuracy: 0.5132\n",
      "Epoch 608/1000\n",
      "177/177 [==============================] - 0s 69us/step - loss: 0.0956 - accuracy: 0.9774 - val_loss: 1.5669 - val_accuracy: 0.5132\n",
      "Epoch 609/1000\n",
      "177/177 [==============================] - 0s 63us/step - loss: 0.0844 - accuracy: 0.9831 - val_loss: 1.5610 - val_accuracy: 0.5000\n",
      "Epoch 610/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.0932 - accuracy: 0.9718 - val_loss: 1.5619 - val_accuracy: 0.5132\n",
      "Epoch 611/1000\n",
      "177/177 [==============================] - 0s 69us/step - loss: 0.0807 - accuracy: 0.9887 - val_loss: 1.5447 - val_accuracy: 0.5132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 612/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.0789 - accuracy: 0.9831 - val_loss: 1.5502 - val_accuracy: 0.5132\n",
      "Epoch 613/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.0884 - accuracy: 0.9774 - val_loss: 1.5383 - val_accuracy: 0.5132\n",
      "Epoch 614/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.0850 - accuracy: 0.9831 - val_loss: 1.5518 - val_accuracy: 0.5132\n",
      "Epoch 615/1000\n",
      "177/177 [==============================] - 0s 48us/step - loss: 0.1024 - accuracy: 0.9831 - val_loss: 1.5443 - val_accuracy: 0.5132\n",
      "Epoch 616/1000\n",
      "177/177 [==============================] - 0s 79us/step - loss: 0.1073 - accuracy: 0.9831 - val_loss: 1.5228 - val_accuracy: 0.5000\n",
      "Epoch 617/1000\n",
      "177/177 [==============================] - 0s 70us/step - loss: 0.0760 - accuracy: 0.9887 - val_loss: 1.5669 - val_accuracy: 0.5132\n",
      "Epoch 618/1000\n",
      "177/177 [==============================] - ETA: 0s - loss: 0.1421 - accuracy: 0.95 - 0s 75us/step - loss: 0.0927 - accuracy: 0.9774 - val_loss: 1.5385 - val_accuracy: 0.5132\n",
      "Epoch 619/1000\n",
      "177/177 [==============================] - 0s 78us/step - loss: 0.0895 - accuracy: 0.9831 - val_loss: 1.5617 - val_accuracy: 0.5132\n",
      "Epoch 620/1000\n",
      "177/177 [==============================] - 0s 58us/step - loss: 0.0768 - accuracy: 0.9831 - val_loss: 1.6236 - val_accuracy: 0.5000\n",
      "Epoch 621/1000\n",
      "177/177 [==============================] - 0s 53us/step - loss: 0.1204 - accuracy: 0.9774 - val_loss: 1.5380 - val_accuracy: 0.5132\n",
      "Epoch 622/1000\n",
      "177/177 [==============================] - 0s 55us/step - loss: 0.0928 - accuracy: 0.9774 - val_loss: 1.5344 - val_accuracy: 0.5132\n",
      "Epoch 623/1000\n",
      "177/177 [==============================] - 0s 56us/step - loss: 0.0861 - accuracy: 0.9774 - val_loss: 1.5750 - val_accuracy: 0.5132\n",
      "Epoch 624/1000\n",
      "177/177 [==============================] - 0s 57us/step - loss: 0.1869 - accuracy: 0.9718 - val_loss: 1.5922 - val_accuracy: 0.5132\n",
      "Epoch 625/1000\n",
      "177/177 [==============================] - 0s 54us/step - loss: 0.1292 - accuracy: 0.9831 - val_loss: 1.5026 - val_accuracy: 0.4868\n",
      "Epoch 626/1000\n",
      "177/177 [==============================] - 0s 55us/step - loss: 0.2494 - accuracy: 0.9605 - val_loss: 1.5114 - val_accuracy: 0.5000\n",
      "Epoch 627/1000\n",
      "177/177 [==============================] - 0s 53us/step - loss: 0.0990 - accuracy: 0.9774 - val_loss: 1.6139 - val_accuracy: 0.5263\n",
      "Epoch 628/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.2660 - accuracy: 0.9605 - val_loss: 1.6941 - val_accuracy: 0.5000\n",
      "Epoch 629/1000\n",
      "177/177 [==============================] - 0s 57us/step - loss: 0.0903 - accuracy: 0.9831 - val_loss: 1.5080 - val_accuracy: 0.5000\n",
      "Epoch 630/1000\n",
      "177/177 [==============================] - 0s 53us/step - loss: 0.2524 - accuracy: 0.9492 - val_loss: 1.5074 - val_accuracy: 0.4868\n",
      "Epoch 631/1000\n",
      "177/177 [==============================] - 0s 59us/step - loss: 0.2223 - accuracy: 0.9548 - val_loss: 1.5741 - val_accuracy: 0.5132\n",
      "Epoch 632/1000\n",
      "177/177 [==============================] - 0s 58us/step - loss: 0.0808 - accuracy: 0.9831 - val_loss: 1.8749 - val_accuracy: 0.5132\n",
      "Epoch 633/1000\n",
      "177/177 [==============================] - 0s 74us/step - loss: 0.2582 - accuracy: 0.9492 - val_loss: 1.6205 - val_accuracy: 0.5000\n",
      "Epoch 634/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.1470 - accuracy: 0.9605 - val_loss: 1.5513 - val_accuracy: 0.5395\n",
      "Epoch 635/1000\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.1243 - accuracy: 0.9718 - val_loss: 1.7633 - val_accuracy: 0.5263\n",
      "Epoch 636/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.2086 - accuracy: 0.9661 - val_loss: 1.9281 - val_accuracy: 0.5000\n",
      "Epoch 637/1000\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.2483 - accuracy: 0.9661 - val_loss: 1.5527 - val_accuracy: 0.5132\n",
      "Epoch 638/1000\n",
      "177/177 [==============================] - 0s 59us/step - loss: 0.1273 - accuracy: 0.9774 - val_loss: 1.5175 - val_accuracy: 0.5132\n",
      "Epoch 639/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.1544 - accuracy: 0.9774 - val_loss: 1.5651 - val_accuracy: 0.5132\n",
      "Epoch 640/1000\n",
      "177/177 [==============================] - 0s 60us/step - loss: 0.1075 - accuracy: 0.9831 - val_loss: 1.6673 - val_accuracy: 0.5132\n",
      "Epoch 641/1000\n",
      "177/177 [==============================] - 0s 56us/step - loss: 0.1348 - accuracy: 0.9774 - val_loss: 1.6068 - val_accuracy: 0.5263\n",
      "Epoch 642/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.0897 - accuracy: 0.9831 - val_loss: 1.5695 - val_accuracy: 0.5132\n",
      "Epoch 643/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.1155 - accuracy: 0.9718 - val_loss: 1.5572 - val_accuracy: 0.5132\n",
      "Epoch 644/1000\n",
      "177/177 [==============================] - 0s 58us/step - loss: 0.1126 - accuracy: 0.9831 - val_loss: 1.6923 - val_accuracy: 0.5000\n",
      "Epoch 645/1000\n",
      "177/177 [==============================] - 0s 57us/step - loss: 0.1088 - accuracy: 0.9774 - val_loss: 1.5469 - val_accuracy: 0.5132\n",
      "Epoch 646/1000\n",
      "177/177 [==============================] - 0s 60us/step - loss: 0.1499 - accuracy: 0.9661 - val_loss: 1.5565 - val_accuracy: 0.5132\n",
      "Epoch 647/1000\n",
      "177/177 [==============================] - 0s 60us/step - loss: 0.0759 - accuracy: 0.9887 - val_loss: 1.7450 - val_accuracy: 0.5000\n",
      "Epoch 648/1000\n",
      "177/177 [==============================] - 0s 68us/step - loss: 0.1428 - accuracy: 0.9774 - val_loss: 1.6135 - val_accuracy: 0.5263\n",
      "Epoch 649/1000\n",
      "177/177 [==============================] - 0s 69us/step - loss: 0.1264 - accuracy: 0.9774 - val_loss: 1.5748 - val_accuracy: 0.5132\n",
      "Epoch 650/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.1033 - accuracy: 0.9774 - val_loss: 1.6518 - val_accuracy: 0.5000\n",
      "Epoch 651/1000\n",
      "177/177 [==============================] - 0s 68us/step - loss: 0.1859 - accuracy: 0.9774 - val_loss: 1.6410 - val_accuracy: 0.5000\n",
      "Epoch 652/1000\n",
      "177/177 [==============================] - 0s 57us/step - loss: 0.1508 - accuracy: 0.9718 - val_loss: 1.5428 - val_accuracy: 0.5000\n",
      "Epoch 653/1000\n",
      "177/177 [==============================] - 0s 59us/step - loss: 0.1462 - accuracy: 0.9661 - val_loss: 1.6315 - val_accuracy: 0.5132\n",
      "Epoch 654/1000\n",
      "177/177 [==============================] - 0s 55us/step - loss: 0.1473 - accuracy: 0.9831 - val_loss: 1.6590 - val_accuracy: 0.5000\n",
      "Epoch 655/1000\n",
      "177/177 [==============================] - 0s 60us/step - loss: 0.0838 - accuracy: 0.9831 - val_loss: 1.5791 - val_accuracy: 0.5263\n",
      "Epoch 656/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.1951 - accuracy: 0.9661 - val_loss: 1.5369 - val_accuracy: 0.5132\n",
      "Epoch 657/1000\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.1230 - accuracy: 0.9661 - val_loss: 1.6192 - val_accuracy: 0.5132\n",
      "Epoch 658/1000\n",
      "177/177 [==============================] - 0s 58us/step - loss: 0.1011 - accuracy: 0.9831 - val_loss: 1.5899 - val_accuracy: 0.5132\n",
      "Epoch 659/1000\n",
      "177/177 [==============================] - 0s 59us/step - loss: 0.0742 - accuracy: 0.9944 - val_loss: 1.6051 - val_accuracy: 0.5132\n",
      "Epoch 660/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.0718 - accuracy: 0.9887 - val_loss: 1.6135 - val_accuracy: 0.5132\n",
      "Epoch 661/1000\n",
      "177/177 [==============================] - 0s 56us/step - loss: 0.0750 - accuracy: 0.9831 - val_loss: 1.5908 - val_accuracy: 0.5132\n",
      "Epoch 662/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.1031 - accuracy: 0.9831 - val_loss: 1.5790 - val_accuracy: 0.5132\n",
      "Epoch 663/1000\n",
      "177/177 [==============================] - 0s 55us/step - loss: 0.0724 - accuracy: 0.9774 - val_loss: 1.6186 - val_accuracy: 0.5132\n",
      "Epoch 664/1000\n",
      "177/177 [==============================] - 0s 58us/step - loss: 0.0880 - accuracy: 0.9887 - val_loss: 1.5766 - val_accuracy: 0.5132\n",
      "Epoch 665/1000\n",
      "177/177 [==============================] - 0s 58us/step - loss: 0.0947 - accuracy: 0.9831 - val_loss: 1.5974 - val_accuracy: 0.5132\n",
      "Epoch 666/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.0696 - accuracy: 0.9887 - val_loss: 1.6772 - val_accuracy: 0.5000\n",
      "Epoch 667/1000\n",
      "177/177 [==============================] - 0s 57us/step - loss: 0.1616 - accuracy: 0.9774 - val_loss: 1.6261 - val_accuracy: 0.5132\n",
      "Epoch 668/1000\n",
      "177/177 [==============================] - 0s 57us/step - loss: 0.0857 - accuracy: 0.9718 - val_loss: 1.5848 - val_accuracy: 0.5000\n",
      "Epoch 669/1000\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.1001 - accuracy: 0.9831 - val_loss: 1.6975 - val_accuracy: 0.5132\n",
      "Epoch 670/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.1212 - accuracy: 0.9774 - val_loss: 1.8395 - val_accuracy: 0.5000\n",
      "Epoch 671/1000\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.2374 - accuracy: 0.9605 - val_loss: 1.5965 - val_accuracy: 0.5132\n",
      "Epoch 672/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.1260 - accuracy: 0.9661 - val_loss: 1.5422 - val_accuracy: 0.4605\n",
      "Epoch 673/1000\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.2773 - accuracy: 0.9492 - val_loss: 1.5507 - val_accuracy: 0.5000\n",
      "Epoch 674/1000\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.1437 - accuracy: 0.9887 - val_loss: 1.8178 - val_accuracy: 0.5132\n",
      "Epoch 675/1000\n",
      "177/177 [==============================] - 0s 63us/step - loss: 0.2375 - accuracy: 0.9548 - val_loss: 1.6614 - val_accuracy: 0.5132\n",
      "Epoch 676/1000\n",
      "177/177 [==============================] - 0s 57us/step - loss: 0.1081 - accuracy: 0.9774 - val_loss: 1.5841 - val_accuracy: 0.5132\n",
      "Epoch 677/1000\n",
      "177/177 [==============================] - 0s 63us/step - loss: 0.1330 - accuracy: 0.9718 - val_loss: 1.6465 - val_accuracy: 0.5132\n",
      "Epoch 678/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.1458 - accuracy: 0.9774 - val_loss: 1.8037 - val_accuracy: 0.5132\n",
      "Epoch 679/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.2258 - accuracy: 0.9548 - val_loss: 1.6553 - val_accuracy: 0.5132\n",
      "Epoch 680/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.1186 - accuracy: 0.9831 - val_loss: 1.5671 - val_accuracy: 0.5000\n",
      "Epoch 681/1000\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.1823 - accuracy: 0.9661 - val_loss: 1.6578 - val_accuracy: 0.5132\n",
      "Epoch 682/1000\n",
      "177/177 [==============================] - 0s 76us/step - loss: 0.1764 - accuracy: 0.9774 - val_loss: 1.7654 - val_accuracy: 0.5132\n",
      "Epoch 683/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.1287 - accuracy: 0.9718 - val_loss: 1.6311 - val_accuracy: 0.5000\n",
      "Epoch 684/1000\n",
      "177/177 [==============================] - 0s 60us/step - loss: 0.0713 - accuracy: 0.9944 - val_loss: 1.5911 - val_accuracy: 0.5132\n",
      "Epoch 685/1000\n",
      "177/177 [==============================] - 0s 59us/step - loss: 0.1291 - accuracy: 0.9718 - val_loss: 1.6322 - val_accuracy: 0.5000\n",
      "Epoch 686/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.1146 - accuracy: 0.9831 - val_loss: 1.7278 - val_accuracy: 0.5132\n",
      "Epoch 687/1000\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.1278 - accuracy: 0.9774 - val_loss: 1.6429 - val_accuracy: 0.5000\n",
      "Epoch 688/1000\n",
      "177/177 [==============================] - 0s 56us/step - loss: 0.0699 - accuracy: 0.9887 - val_loss: 1.6572 - val_accuracy: 0.5132\n",
      "Epoch 689/1000\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.2061 - accuracy: 0.9661 - val_loss: 1.7042 - val_accuracy: 0.5000\n",
      "Epoch 690/1000\n",
      "177/177 [==============================] - 0s 58us/step - loss: 0.1530 - accuracy: 0.9887 - val_loss: 1.6367 - val_accuracy: 0.5263\n",
      "Epoch 691/1000\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.0982 - accuracy: 0.9831 - val_loss: 1.6358 - val_accuracy: 0.5000\n",
      "Epoch 692/1000\n",
      "177/177 [==============================] - 0s 63us/step - loss: 0.0797 - accuracy: 0.9831 - val_loss: 1.6273 - val_accuracy: 0.5132\n",
      "Epoch 693/1000\n",
      "177/177 [==============================] - 0s 55us/step - loss: 0.1371 - accuracy: 0.9718 - val_loss: 1.6426 - val_accuracy: 0.5132\n",
      "Epoch 694/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.1104 - accuracy: 0.9774 - val_loss: 1.6079 - val_accuracy: 0.5263\n",
      "Epoch 695/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.0661 - accuracy: 0.9887 - val_loss: 1.7746 - val_accuracy: 0.5132\n",
      "Epoch 696/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.1810 - accuracy: 0.9718 - val_loss: 1.7981 - val_accuracy: 0.5263\n",
      "Epoch 697/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.1924 - accuracy: 0.9774 - val_loss: 1.6553 - val_accuracy: 0.5132\n",
      "Epoch 698/1000\n",
      "177/177 [==============================] - 0s 74us/step - loss: 0.1255 - accuracy: 0.9774 - val_loss: 1.5897 - val_accuracy: 0.5000\n",
      "Epoch 699/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.3007 - accuracy: 0.9492 - val_loss: 1.5773 - val_accuracy: 0.4868\n",
      "Epoch 700/1000\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.1718 - accuracy: 0.9774 - val_loss: 1.9518 - val_accuracy: 0.5000\n",
      "Epoch 701/1000\n",
      "177/177 [==============================] - 0s 68us/step - loss: 0.3503 - accuracy: 0.9435 - val_loss: 1.8377 - val_accuracy: 0.4868\n",
      "Epoch 702/1000\n",
      "177/177 [==============================] - 0s 58us/step - loss: 0.1932 - accuracy: 0.9661 - val_loss: 1.5901 - val_accuracy: 0.4737\n",
      "Epoch 703/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.3051 - accuracy: 0.9435 - val_loss: 1.6310 - val_accuracy: 0.4605\n",
      "Epoch 704/1000\n",
      "177/177 [==============================] - 0s 57us/step - loss: 0.2666 - accuracy: 0.9548 - val_loss: 1.6445 - val_accuracy: 0.5132\n",
      "Epoch 705/1000\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.0908 - accuracy: 0.9831 - val_loss: 1.7828 - val_accuracy: 0.5000\n",
      "Epoch 706/1000\n",
      "177/177 [==============================] - 0s 58us/step - loss: 0.1239 - accuracy: 0.9718 - val_loss: 1.6695 - val_accuracy: 0.5132\n",
      "Epoch 707/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.0937 - accuracy: 0.9831 - val_loss: 1.6686 - val_accuracy: 0.5132\n",
      "Epoch 708/1000\n",
      "177/177 [==============================] - 0s 59us/step - loss: 0.0718 - accuracy: 0.9887 - val_loss: 1.7113 - val_accuracy: 0.5132\n",
      "Epoch 709/1000\n",
      "177/177 [==============================] - 0s 58us/step - loss: 0.1038 - accuracy: 0.9831 - val_loss: 1.6887 - val_accuracy: 0.5132\n",
      "Epoch 710/1000\n",
      "177/177 [==============================] - 0s 59us/step - loss: 0.0670 - accuracy: 0.9887 - val_loss: 1.6532 - val_accuracy: 0.5132\n",
      "Epoch 711/1000\n",
      "177/177 [==============================] - 0s 59us/step - loss: 0.0776 - accuracy: 0.9831 - val_loss: 1.6688 - val_accuracy: 0.5132\n",
      "Epoch 712/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.1227 - accuracy: 0.9831 - val_loss: 1.7205 - val_accuracy: 0.5000\n",
      "Epoch 713/1000\n",
      "177/177 [==============================] - 0s 55us/step - loss: 0.0867 - accuracy: 0.9831 - val_loss: 1.6150 - val_accuracy: 0.5132\n",
      "Epoch 714/1000\n",
      "177/177 [==============================] - 0s 69us/step - loss: 0.0839 - accuracy: 0.9831 - val_loss: 1.6490 - val_accuracy: 0.5132\n",
      "Epoch 715/1000\n",
      "177/177 [==============================] - 0s 70us/step - loss: 0.0872 - accuracy: 0.9887 - val_loss: 1.6368 - val_accuracy: 0.5132\n",
      "Epoch 716/1000\n",
      "177/177 [==============================] - 0s 68us/step - loss: 0.0676 - accuracy: 0.9831 - val_loss: 1.6322 - val_accuracy: 0.5263\n",
      "Epoch 717/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.0623 - accuracy: 0.9887 - val_loss: 1.6859 - val_accuracy: 0.5000\n",
      "Epoch 718/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.0922 - accuracy: 0.9831 - val_loss: 1.6233 - val_accuracy: 0.5132\n",
      "Epoch 719/1000\n",
      "177/177 [==============================] - 0s 68us/step - loss: 0.0970 - accuracy: 0.9831 - val_loss: 1.6278 - val_accuracy: 0.5132\n",
      "Epoch 720/1000\n",
      "177/177 [==============================] - 0s 69us/step - loss: 0.1096 - accuracy: 0.9718 - val_loss: 1.6829 - val_accuracy: 0.5132\n",
      "Epoch 721/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.0916 - accuracy: 0.9831 - val_loss: 1.6252 - val_accuracy: 0.5000\n",
      "Epoch 722/1000\n",
      "177/177 [==============================] - 0s 63us/step - loss: 0.1277 - accuracy: 0.9718 - val_loss: 1.6390 - val_accuracy: 0.5132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 723/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.0769 - accuracy: 0.9831 - val_loss: 1.8070 - val_accuracy: 0.4868\n",
      "Epoch 724/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.1834 - accuracy: 0.9718 - val_loss: 1.7152 - val_accuracy: 0.5132\n",
      "Epoch 725/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.1490 - accuracy: 0.9661 - val_loss: 1.6346 - val_accuracy: 0.5132\n",
      "Epoch 726/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.1816 - accuracy: 0.9661 - val_loss: 1.7536 - val_accuracy: 0.5263\n",
      "Epoch 727/1000\n",
      "177/177 [==============================] - 0s 70us/step - loss: 0.1450 - accuracy: 0.9774 - val_loss: 1.8421 - val_accuracy: 0.5000\n",
      "Epoch 728/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.2012 - accuracy: 0.9661 - val_loss: 1.7032 - val_accuracy: 0.5000\n",
      "Epoch 729/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.3286 - accuracy: 0.9492 - val_loss: 1.6333 - val_accuracy: 0.5263\n",
      "Epoch 730/1000\n",
      "177/177 [==============================] - 0s 70us/step - loss: 0.0867 - accuracy: 0.9831 - val_loss: 1.9164 - val_accuracy: 0.5526\n",
      "Epoch 731/1000\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.1735 - accuracy: 0.9831 - val_loss: 1.9259 - val_accuracy: 0.5526\n",
      "Epoch 732/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.1797 - accuracy: 0.9774 - val_loss: 1.7223 - val_accuracy: 0.5263\n",
      "Epoch 733/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.0688 - accuracy: 0.9831 - val_loss: 1.6424 - val_accuracy: 0.5132\n",
      "Epoch 734/1000\n",
      "177/177 [==============================] - 0s 60us/step - loss: 0.0931 - accuracy: 0.9718 - val_loss: 1.6567 - val_accuracy: 0.5132\n",
      "Epoch 735/1000\n",
      "177/177 [==============================] - 0s 58us/step - loss: 0.0618 - accuracy: 0.9887 - val_loss: 1.7570 - val_accuracy: 0.5263\n",
      "Epoch 736/1000\n",
      "177/177 [==============================] - 0s 59us/step - loss: 0.1155 - accuracy: 0.9831 - val_loss: 1.7415 - val_accuracy: 0.5132\n",
      "Epoch 737/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.0842 - accuracy: 0.9774 - val_loss: 1.6431 - val_accuracy: 0.5132\n",
      "Epoch 738/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.1184 - accuracy: 0.9718 - val_loss: 1.6296 - val_accuracy: 0.5000\n",
      "Epoch 739/1000\n",
      "177/177 [==============================] - 0s 59us/step - loss: 0.1718 - accuracy: 0.9605 - val_loss: 1.6909 - val_accuracy: 0.5132\n",
      "Epoch 740/1000\n",
      "177/177 [==============================] - 0s 57us/step - loss: 0.1429 - accuracy: 0.9887 - val_loss: 1.9129 - val_accuracy: 0.5132\n",
      "Epoch 741/1000\n",
      "177/177 [==============================] - 0s 63us/step - loss: 0.1431 - accuracy: 0.9718 - val_loss: 1.7324 - val_accuracy: 0.5132\n",
      "Epoch 742/1000\n",
      "177/177 [==============================] - 0s 58us/step - loss: 0.1585 - accuracy: 0.9661 - val_loss: 1.6439 - val_accuracy: 0.5132\n",
      "Epoch 743/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.1140 - accuracy: 0.9774 - val_loss: 1.7887 - val_accuracy: 0.5132\n",
      "Epoch 744/1000\n",
      "177/177 [==============================] - 0s 59us/step - loss: 0.1901 - accuracy: 0.9718 - val_loss: 1.8004 - val_accuracy: 0.5000\n",
      "Epoch 745/1000\n",
      "177/177 [==============================] - 0s 56us/step - loss: 0.1495 - accuracy: 0.9718 - val_loss: 1.6818 - val_accuracy: 0.5132\n",
      "Epoch 746/1000\n",
      "177/177 [==============================] - 0s 63us/step - loss: 0.0681 - accuracy: 0.9774 - val_loss: 1.7570 - val_accuracy: 0.5263\n",
      "Epoch 747/1000\n",
      "177/177 [==============================] - 0s 54us/step - loss: 0.1574 - accuracy: 0.9774 - val_loss: 1.7203 - val_accuracy: 0.5000\n",
      "Epoch 748/1000\n",
      "177/177 [==============================] - 0s 59us/step - loss: 0.1249 - accuracy: 0.9831 - val_loss: 1.7040 - val_accuracy: 0.5132\n",
      "Epoch 749/1000\n",
      "177/177 [==============================] - 0s 58us/step - loss: 0.1072 - accuracy: 0.9718 - val_loss: 1.6168 - val_accuracy: 0.5000\n",
      "Epoch 750/1000\n",
      "177/177 [==============================] - 0s 59us/step - loss: 0.2211 - accuracy: 0.9605 - val_loss: 1.6288 - val_accuracy: 0.5000\n",
      "Epoch 751/1000\n",
      "177/177 [==============================] - 0s 59us/step - loss: 0.1367 - accuracy: 0.9605 - val_loss: 1.8004 - val_accuracy: 0.5132\n",
      "Epoch 752/1000\n",
      "177/177 [==============================] - 0s 63us/step - loss: 0.2321 - accuracy: 0.9661 - val_loss: 1.7796 - val_accuracy: 0.5132\n",
      "Epoch 753/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.1276 - accuracy: 0.9661 - val_loss: 1.6646 - val_accuracy: 0.5132\n",
      "Epoch 754/1000\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.1363 - accuracy: 0.9774 - val_loss: 1.7614 - val_accuracy: 0.5395\n",
      "Epoch 755/1000\n",
      "177/177 [==============================] - 0s 55us/step - loss: 0.1109 - accuracy: 0.9831 - val_loss: 1.8144 - val_accuracy: 0.5132\n",
      "Epoch 756/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.1160 - accuracy: 0.9774 - val_loss: 1.7394 - val_accuracy: 0.5132\n",
      "Epoch 757/1000\n",
      "177/177 [==============================] - 0s 59us/step - loss: 0.1007 - accuracy: 0.9774 - val_loss: 1.6967 - val_accuracy: 0.5132\n",
      "Epoch 758/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.0789 - accuracy: 0.9831 - val_loss: 1.6936 - val_accuracy: 0.5132\n",
      "Epoch 759/1000\n",
      "177/177 [==============================] - 0s 69us/step - loss: 0.0697 - accuracy: 0.9887 - val_loss: 1.7588 - val_accuracy: 0.5000\n",
      "Epoch 760/1000\n",
      "177/177 [==============================] - 0s 60us/step - loss: 0.0813 - accuracy: 0.9887 - val_loss: 1.6596 - val_accuracy: 0.5132\n",
      "Epoch 761/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.1118 - accuracy: 0.9718 - val_loss: 1.6579 - val_accuracy: 0.5132\n",
      "Epoch 762/1000\n",
      "177/177 [==============================] - 0s 68us/step - loss: 0.0630 - accuracy: 0.9887 - val_loss: 1.6998 - val_accuracy: 0.5132\n",
      "Epoch 763/1000\n",
      "177/177 [==============================] - 0s 58us/step - loss: 0.0635 - accuracy: 0.9887 - val_loss: 1.7074 - val_accuracy: 0.5132\n",
      "Epoch 764/1000\n",
      "177/177 [==============================] - 0s 60us/step - loss: 0.0597 - accuracy: 0.9944 - val_loss: 1.7111 - val_accuracy: 0.5000\n",
      "Epoch 765/1000\n",
      "177/177 [==============================] - 0s 68us/step - loss: 0.0766 - accuracy: 0.9831 - val_loss: 1.7072 - val_accuracy: 0.5132\n",
      "Epoch 766/1000\n",
      "177/177 [==============================] - 0s 59us/step - loss: 0.0601 - accuracy: 0.9887 - val_loss: 1.7130 - val_accuracy: 0.5132\n",
      "Epoch 767/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.0825 - accuracy: 0.9831 - val_loss: 1.6955 - val_accuracy: 0.5132\n",
      "Epoch 768/1000\n",
      "177/177 [==============================] - 0s 59us/step - loss: 0.0581 - accuracy: 0.9944 - val_loss: 1.6960 - val_accuracy: 0.5132\n",
      "Epoch 769/1000\n",
      "177/177 [==============================] - 0s 59us/step - loss: 0.0797 - accuracy: 0.9831 - val_loss: 1.7298 - val_accuracy: 0.5000\n",
      "Epoch 770/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.0666 - accuracy: 0.9887 - val_loss: 1.7465 - val_accuracy: 0.5132\n",
      "Epoch 771/1000\n",
      "177/177 [==============================] - 0s 54us/step - loss: 0.1063 - accuracy: 0.9831 - val_loss: 1.6990 - val_accuracy: 0.5132\n",
      "Epoch 772/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.1227 - accuracy: 0.9774 - val_loss: 1.7832 - val_accuracy: 0.5263\n",
      "Epoch 773/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.1009 - accuracy: 0.9831 - val_loss: 1.7678 - val_accuracy: 0.5263\n",
      "Epoch 774/1000\n",
      "177/177 [==============================] - 0s 59us/step - loss: 0.0613 - accuracy: 0.9944 - val_loss: 1.6958 - val_accuracy: 0.5132\n",
      "Epoch 775/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.1099 - accuracy: 0.9774 - val_loss: 1.7239 - val_accuracy: 0.5132\n",
      "Epoch 776/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.0744 - accuracy: 0.9887 - val_loss: 1.7952 - val_accuracy: 0.5132\n",
      "Epoch 777/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.1702 - accuracy: 0.9831 - val_loss: 1.8090 - val_accuracy: 0.5132\n",
      "Epoch 778/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.0899 - accuracy: 0.9831 - val_loss: 1.6965 - val_accuracy: 0.5263\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 779/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.0760 - accuracy: 0.9831 - val_loss: 1.6886 - val_accuracy: 0.5132\n",
      "Epoch 780/1000\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.0649 - accuracy: 0.9831 - val_loss: 1.7226 - val_accuracy: 0.5132\n",
      "Epoch 781/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.0574 - accuracy: 0.9944 - val_loss: 1.8351 - val_accuracy: 0.5263\n",
      "Epoch 782/1000\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.1090 - accuracy: 0.9887 - val_loss: 1.7545 - val_accuracy: 0.5132\n",
      "Epoch 783/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.0561 - accuracy: 0.9944 - val_loss: 1.7051 - val_accuracy: 0.5263\n",
      "Epoch 784/1000\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.0604 - accuracy: 0.9887 - val_loss: 1.7032 - val_accuracy: 0.5263\n",
      "Epoch 785/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.0584 - accuracy: 0.9944 - val_loss: 1.7020 - val_accuracy: 0.5000\n",
      "Epoch 786/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.0584 - accuracy: 0.9887 - val_loss: 1.7226 - val_accuracy: 0.5263\n",
      "Epoch 787/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.0554 - accuracy: 0.9944 - val_loss: 1.7868 - val_accuracy: 0.5000\n",
      "Epoch 788/1000\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.0674 - accuracy: 0.9831 - val_loss: 1.6985 - val_accuracy: 0.5132\n",
      "Epoch 789/1000\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.0661 - accuracy: 0.9887 - val_loss: 1.6844 - val_accuracy: 0.5132\n",
      "Epoch 790/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.0852 - accuracy: 0.9831 - val_loss: 1.7668 - val_accuracy: 0.5132\n",
      "Epoch 791/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.1176 - accuracy: 0.9831 - val_loss: 1.7486 - val_accuracy: 0.5132\n",
      "Epoch 792/1000\n",
      "177/177 [==============================] - 0s 60us/step - loss: 0.0754 - accuracy: 0.9887 - val_loss: 1.6714 - val_accuracy: 0.5000\n",
      "Epoch 793/1000\n",
      "177/177 [==============================] - 0s 53us/step - loss: 0.1933 - accuracy: 0.9661 - val_loss: 1.6809 - val_accuracy: 0.5000\n",
      "Epoch 794/1000\n",
      "177/177 [==============================] - 0s 63us/step - loss: 0.1278 - accuracy: 0.9831 - val_loss: 1.9109 - val_accuracy: 0.5000\n",
      "Epoch 795/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.3123 - accuracy: 0.9492 - val_loss: 1.8161 - val_accuracy: 0.5132\n",
      "Epoch 796/1000\n",
      "177/177 [==============================] - 0s 47us/step - loss: 0.2423 - accuracy: 0.9605 - val_loss: 1.6824 - val_accuracy: 0.5000\n",
      "Epoch 797/1000\n",
      "177/177 [==============================] - 0s 69us/step - loss: 0.2572 - accuracy: 0.9548 - val_loss: 1.6931 - val_accuracy: 0.5132\n",
      "Epoch 798/1000\n",
      "177/177 [==============================] - 0s 56us/step - loss: 0.1553 - accuracy: 0.9831 - val_loss: 1.8879 - val_accuracy: 0.5000\n",
      "Epoch 799/1000\n",
      "177/177 [==============================] - 0s 59us/step - loss: 0.1595 - accuracy: 0.9774 - val_loss: 1.8290 - val_accuracy: 0.5000\n",
      "Epoch 800/1000\n",
      "177/177 [==============================] - 0s 49us/step - loss: 0.1388 - accuracy: 0.9774 - val_loss: 1.7020 - val_accuracy: 0.5263\n",
      "Epoch 801/1000\n",
      "177/177 [==============================] - 0s 51us/step - loss: 0.1508 - accuracy: 0.9718 - val_loss: 1.6850 - val_accuracy: 0.5263\n",
      "Epoch 802/1000\n",
      "177/177 [==============================] - 0s 51us/step - loss: 0.1181 - accuracy: 0.9831 - val_loss: 1.8934 - val_accuracy: 0.5132\n",
      "Epoch 803/1000\n",
      "177/177 [==============================] - 0s 49us/step - loss: 0.2535 - accuracy: 0.9548 - val_loss: 1.8041 - val_accuracy: 0.5000\n",
      "Epoch 804/1000\n",
      "177/177 [==============================] - 0s 60us/step - loss: 0.0801 - accuracy: 0.9718 - val_loss: 1.6790 - val_accuracy: 0.5263\n",
      "Epoch 805/1000\n",
      "177/177 [==============================] - 0s 51us/step - loss: 0.1527 - accuracy: 0.9718 - val_loss: 1.7903 - val_accuracy: 0.5263\n",
      "Epoch 806/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.1229 - accuracy: 0.9831 - val_loss: 1.8558 - val_accuracy: 0.5263\n",
      "Epoch 807/1000\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.1860 - accuracy: 0.9718 - val_loss: 1.7864 - val_accuracy: 0.5263\n",
      "Epoch 808/1000\n",
      "177/177 [==============================] - 0s 53us/step - loss: 0.1236 - accuracy: 0.9831 - val_loss: 1.7464 - val_accuracy: 0.5263\n",
      "Epoch 809/1000\n",
      "177/177 [==============================] - 0s 51us/step - loss: 0.0752 - accuracy: 0.9774 - val_loss: 1.8310 - val_accuracy: 0.5263\n",
      "Epoch 810/1000\n",
      "177/177 [==============================] - 0s 51us/step - loss: 0.1045 - accuracy: 0.9831 - val_loss: 2.0466 - val_accuracy: 0.5395\n",
      "Epoch 811/1000\n",
      "177/177 [==============================] - 0s 48us/step - loss: 0.1904 - accuracy: 0.9774 - val_loss: 1.8158 - val_accuracy: 0.5395\n",
      "Epoch 812/1000\n",
      "177/177 [==============================] - 0s 52us/step - loss: 0.1261 - accuracy: 0.9774 - val_loss: 1.6905 - val_accuracy: 0.5263\n",
      "Epoch 813/1000\n",
      "177/177 [==============================] - 0s 52us/step - loss: 0.0961 - accuracy: 0.9661 - val_loss: 1.7631 - val_accuracy: 0.5263\n",
      "Epoch 814/1000\n",
      "177/177 [==============================] - 0s 53us/step - loss: 0.1279 - accuracy: 0.9887 - val_loss: 1.7832 - val_accuracy: 0.5263\n",
      "Epoch 815/1000\n",
      "177/177 [==============================] - 0s 52us/step - loss: 0.1329 - accuracy: 0.9831 - val_loss: 1.7077 - val_accuracy: 0.5000\n",
      "Epoch 816/1000\n",
      "177/177 [==============================] - 0s 53us/step - loss: 0.0879 - accuracy: 0.9887 - val_loss: 1.7587 - val_accuracy: 0.5263\n",
      "Epoch 817/1000\n",
      "177/177 [==============================] - 0s 47us/step - loss: 0.1216 - accuracy: 0.9887 - val_loss: 1.8224 - val_accuracy: 0.5132\n",
      "Epoch 818/1000\n",
      "177/177 [==============================] - 0s 54us/step - loss: 0.0614 - accuracy: 0.9887 - val_loss: 1.7139 - val_accuracy: 0.5132\n",
      "Epoch 819/1000\n",
      "177/177 [==============================] - 0s 50us/step - loss: 0.1626 - accuracy: 0.9718 - val_loss: 1.6918 - val_accuracy: 0.4868\n",
      "Epoch 820/1000\n",
      "177/177 [==============================] - 0s 49us/step - loss: 0.1202 - accuracy: 0.9718 - val_loss: 1.8283 - val_accuracy: 0.5132\n",
      "Epoch 821/1000\n",
      "177/177 [==============================] - 0s 48us/step - loss: 0.0996 - accuracy: 0.9887 - val_loss: 1.8635 - val_accuracy: 0.5263\n",
      "Epoch 822/1000\n",
      "177/177 [==============================] - 0s 54us/step - loss: 0.1197 - accuracy: 0.9831 - val_loss: 1.7736 - val_accuracy: 0.5263\n",
      "Epoch 823/1000\n",
      "177/177 [==============================] - 0s 52us/step - loss: 0.1046 - accuracy: 0.9718 - val_loss: 1.6979 - val_accuracy: 0.5132\n",
      "Epoch 824/1000\n",
      "177/177 [==============================] - 0s 49us/step - loss: 0.1551 - accuracy: 0.9774 - val_loss: 1.7228 - val_accuracy: 0.5263\n",
      "Epoch 825/1000\n",
      "177/177 [==============================] - 0s 58us/step - loss: 0.0608 - accuracy: 0.9887 - val_loss: 1.9193 - val_accuracy: 0.5132\n",
      "Epoch 826/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.1267 - accuracy: 0.9774 - val_loss: 1.7996 - val_accuracy: 0.5263\n",
      "Epoch 827/1000\n",
      "177/177 [==============================] - 0s 49us/step - loss: 0.0797 - accuracy: 0.9774 - val_loss: 1.7610 - val_accuracy: 0.5263\n",
      "Epoch 828/1000\n",
      "177/177 [==============================] - 0s 49us/step - loss: 0.0559 - accuracy: 0.9944 - val_loss: 1.8812 - val_accuracy: 0.5395\n",
      "Epoch 829/1000\n",
      "177/177 [==============================] - 0s 63us/step - loss: 0.1010 - accuracy: 0.9774 - val_loss: 1.8157 - val_accuracy: 0.5263\n",
      "Epoch 830/1000\n",
      "177/177 [==============================] - 0s 59us/step - loss: 0.0966 - accuracy: 0.9831 - val_loss: 1.7446 - val_accuracy: 0.5132\n",
      "Epoch 831/1000\n",
      "177/177 [==============================] - 0s 54us/step - loss: 0.1168 - accuracy: 0.9661 - val_loss: 1.7732 - val_accuracy: 0.5263\n",
      "Epoch 832/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.1160 - accuracy: 0.9831 - val_loss: 1.8687 - val_accuracy: 0.5395\n",
      "Epoch 833/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.0787 - accuracy: 0.9887 - val_loss: 1.7129 - val_accuracy: 0.5395\n",
      "Epoch 834/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.1280 - accuracy: 0.9718 - val_loss: 1.7379 - val_accuracy: 0.5263\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 835/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.0719 - accuracy: 0.9831 - val_loss: 1.7993 - val_accuracy: 0.5395\n",
      "Epoch 836/1000\n",
      "177/177 [==============================] - 0s 58us/step - loss: 0.1030 - accuracy: 0.9831 - val_loss: 1.8610 - val_accuracy: 0.5263\n",
      "Epoch 837/1000\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.0576 - accuracy: 0.9887 - val_loss: 1.7614 - val_accuracy: 0.5395\n",
      "Epoch 838/1000\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.0768 - accuracy: 0.9831 - val_loss: 1.7896 - val_accuracy: 0.5395\n",
      "Epoch 839/1000\n",
      "177/177 [==============================] - 0s 57us/step - loss: 0.0541 - accuracy: 0.9944 - val_loss: 1.7964 - val_accuracy: 0.5395\n",
      "Epoch 840/1000\n",
      "177/177 [==============================] - 0s 56us/step - loss: 0.0578 - accuracy: 0.9887 - val_loss: 1.7733 - val_accuracy: 0.5132\n",
      "Epoch 841/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.0738 - accuracy: 0.9887 - val_loss: 1.8033 - val_accuracy: 0.5132\n",
      "Epoch 842/1000\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.0966 - accuracy: 0.9887 - val_loss: 1.8167 - val_accuracy: 0.5132\n",
      "Epoch 843/1000\n",
      "177/177 [==============================] - 0s 60us/step - loss: 0.1201 - accuracy: 0.9831 - val_loss: 1.7375 - val_accuracy: 0.5132\n",
      "Epoch 844/1000\n",
      "177/177 [==============================] - 0s 76us/step - loss: 0.1053 - accuracy: 0.9887 - val_loss: 1.8022 - val_accuracy: 0.5263\n",
      "Epoch 845/1000\n",
      "177/177 [==============================] - 0s 60us/step - loss: 0.0775 - accuracy: 0.9887 - val_loss: 1.7971 - val_accuracy: 0.5263\n",
      "Epoch 846/1000\n",
      "177/177 [==============================] - 0s 84us/step - loss: 0.0777 - accuracy: 0.9887 - val_loss: 1.7429 - val_accuracy: 0.5263\n",
      "Epoch 847/1000\n",
      "177/177 [==============================] - 0s 82us/step - loss: 0.0714 - accuracy: 0.9887 - val_loss: 1.8000 - val_accuracy: 0.5132\n",
      "Epoch 848/1000\n",
      "177/177 [==============================] - 0s 79us/step - loss: 0.0573 - accuracy: 0.9887 - val_loss: 1.8111 - val_accuracy: 0.5132\n",
      "Epoch 849/1000\n",
      "177/177 [==============================] - 0s 86us/step - loss: 0.0617 - accuracy: 0.9887 - val_loss: 1.7786 - val_accuracy: 0.5395\n",
      "Epoch 850/1000\n",
      "177/177 [==============================] - 0s 83us/step - loss: 0.0484 - accuracy: 0.9944 - val_loss: 1.7900 - val_accuracy: 0.5263\n",
      "Epoch 851/1000\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.0625 - accuracy: 0.9774 - val_loss: 1.7857 - val_accuracy: 0.5395\n",
      "Epoch 852/1000\n",
      "177/177 [==============================] - 0s 176us/step - loss: 0.0512 - accuracy: 0.9887 - val_loss: 1.8358 - val_accuracy: 0.5263\n",
      "Epoch 853/1000\n",
      "177/177 [==============================] - 0s 141us/step - loss: 0.0583 - accuracy: 0.9887 - val_loss: 1.8029 - val_accuracy: 0.5395\n",
      "Epoch 854/1000\n",
      "177/177 [==============================] - 0s 132us/step - loss: 0.0504 - accuracy: 0.9887 - val_loss: 1.7838 - val_accuracy: 0.5263\n",
      "Epoch 855/1000\n",
      "177/177 [==============================] - 0s 169us/step - loss: 0.0583 - accuracy: 0.9887 - val_loss: 1.7891 - val_accuracy: 0.5132\n",
      "Epoch 856/1000\n",
      "177/177 [==============================] - 0s 119us/step - loss: 0.0604 - accuracy: 0.9887 - val_loss: 1.7877 - val_accuracy: 0.5263\n",
      "Epoch 857/1000\n",
      "177/177 [==============================] - 0s 84us/step - loss: 0.0569 - accuracy: 0.9887 - val_loss: 1.7803 - val_accuracy: 0.5263\n",
      "Epoch 858/1000\n",
      "177/177 [==============================] - 0s 110us/step - loss: 0.0512 - accuracy: 0.9944 - val_loss: 1.8217 - val_accuracy: 0.5132\n",
      "Epoch 859/1000\n",
      "177/177 [==============================] - 0s 116us/step - loss: 0.0613 - accuracy: 0.9831 - val_loss: 1.7910 - val_accuracy: 0.5263\n",
      "Epoch 860/1000\n",
      "177/177 [==============================] - 0s 138us/step - loss: 0.0467 - accuracy: 0.9944 - val_loss: 1.8161 - val_accuracy: 0.5263\n",
      "Epoch 861/1000\n",
      "177/177 [==============================] - 0s 107us/step - loss: 0.0551 - accuracy: 0.9887 - val_loss: 1.7883 - val_accuracy: 0.5263\n",
      "Epoch 862/1000\n",
      "177/177 [==============================] - 0s 111us/step - loss: 0.0495 - accuracy: 0.9944 - val_loss: 1.7920 - val_accuracy: 0.5263\n",
      "Epoch 863/1000\n",
      "177/177 [==============================] - 0s 142us/step - loss: 0.0491 - accuracy: 0.9944 - val_loss: 1.7970 - val_accuracy: 0.5263\n",
      "Epoch 864/1000\n",
      "177/177 [==============================] - 0s 124us/step - loss: 0.0477 - accuracy: 0.9944 - val_loss: 1.7855 - val_accuracy: 0.5263\n",
      "Epoch 865/1000\n",
      "177/177 [==============================] - 0s 137us/step - loss: 0.0474 - accuracy: 0.9944 - val_loss: 1.8052 - val_accuracy: 0.5395\n",
      "Epoch 866/1000\n",
      "177/177 [==============================] - 0s 101us/step - loss: 0.0471 - accuracy: 0.9944 - val_loss: 1.8046 - val_accuracy: 0.5263\n",
      "Epoch 867/1000\n",
      "177/177 [==============================] - 0s 123us/step - loss: 0.0462 - accuracy: 0.9944 - val_loss: 1.7992 - val_accuracy: 0.5263\n",
      "Epoch 868/1000\n",
      "177/177 [==============================] - 0s 117us/step - loss: 0.0477 - accuracy: 0.9944 - val_loss: 1.8035 - val_accuracy: 0.5263\n",
      "Epoch 869/1000\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.0452 - accuracy: 0.9944 - val_loss: 1.8219 - val_accuracy: 0.5395\n",
      "Epoch 870/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.0530 - accuracy: 0.9887 - val_loss: 1.7989 - val_accuracy: 0.5263\n",
      "Epoch 871/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.0510 - accuracy: 0.9944 - val_loss: 1.7700 - val_accuracy: 0.5263\n",
      "Epoch 872/1000\n",
      "177/177 [==============================] - 0s 55us/step - loss: 0.0851 - accuracy: 0.9887 - val_loss: 1.8360 - val_accuracy: 0.5263\n",
      "Epoch 873/1000\n",
      "177/177 [==============================] - 0s 56us/step - loss: 0.0929 - accuracy: 0.9887 - val_loss: 1.8353 - val_accuracy: 0.5263\n",
      "Epoch 874/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.0511 - accuracy: 0.9944 - val_loss: 1.8001 - val_accuracy: 0.5132\n",
      "Epoch 875/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.0505 - accuracy: 0.9944 - val_loss: 1.8076 - val_accuracy: 0.5132\n",
      "Epoch 876/1000\n",
      "177/177 [==============================] - 0s 59us/step - loss: 0.0541 - accuracy: 0.9887 - val_loss: 1.8337 - val_accuracy: 0.5395\n",
      "Epoch 877/1000\n",
      "177/177 [==============================] - 0s 55us/step - loss: 0.0758 - accuracy: 0.9887 - val_loss: 1.8261 - val_accuracy: 0.5263\n",
      "Epoch 878/1000\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.0478 - accuracy: 0.9944 - val_loss: 1.7955 - val_accuracy: 0.5132\n",
      "Epoch 879/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.0505 - accuracy: 0.9887 - val_loss: 1.8253 - val_accuracy: 0.5263\n",
      "Epoch 880/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.0675 - accuracy: 0.9887 - val_loss: 1.8143 - val_accuracy: 0.5263\n",
      "Epoch 881/1000\n",
      "177/177 [==============================] - 0s 55us/step - loss: 0.0469 - accuracy: 0.9944 - val_loss: 1.7974 - val_accuracy: 0.4868\n",
      "Epoch 882/1000\n",
      "177/177 [==============================] - 0s 63us/step - loss: 0.1099 - accuracy: 0.9831 - val_loss: 1.8285 - val_accuracy: 0.5263\n",
      "Epoch 883/1000\n",
      "177/177 [==============================] - 0s 52us/step - loss: 0.0499 - accuracy: 0.9887 - val_loss: 1.8517 - val_accuracy: 0.5263\n",
      "Epoch 884/1000\n",
      "177/177 [==============================] - 0s 51us/step - loss: 0.0820 - accuracy: 0.9887 - val_loss: 1.8296 - val_accuracy: 0.5263\n",
      "Epoch 885/1000\n",
      "177/177 [==============================] - 0s 48us/step - loss: 0.0538 - accuracy: 0.9944 - val_loss: 1.7911 - val_accuracy: 0.5132\n",
      "Epoch 886/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.1737 - accuracy: 0.9718 - val_loss: 1.7971 - val_accuracy: 0.5263\n",
      "Epoch 887/1000\n",
      "177/177 [==============================] - 0s 69us/step - loss: 0.0584 - accuracy: 0.9831 - val_loss: 1.9874 - val_accuracy: 0.5132\n",
      "Epoch 888/1000\n",
      "177/177 [==============================] - 0s 59us/step - loss: 0.2340 - accuracy: 0.9605 - val_loss: 1.8953 - val_accuracy: 0.5263\n",
      "Epoch 889/1000\n",
      "177/177 [==============================] - 0s 69us/step - loss: 0.1864 - accuracy: 0.9718 - val_loss: 1.7862 - val_accuracy: 0.5132\n",
      "Epoch 890/1000\n",
      "177/177 [==============================] - 0s 69us/step - loss: 0.1219 - accuracy: 0.9887 - val_loss: 2.0056 - val_accuracy: 0.5395\n",
      "Epoch 891/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.1574 - accuracy: 0.9774 - val_loss: 2.1474 - val_accuracy: 0.5395\n",
      "Epoch 892/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.1887 - accuracy: 0.9831 - val_loss: 1.8178 - val_accuracy: 0.5263\n",
      "Epoch 893/1000\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.0661 - accuracy: 0.9831 - val_loss: 1.7953 - val_accuracy: 0.5132\n",
      "Epoch 894/1000\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.0788 - accuracy: 0.9831 - val_loss: 1.8602 - val_accuracy: 0.5132\n",
      "Epoch 895/1000\n",
      "177/177 [==============================] - 0s 83us/step - loss: 0.0599 - accuracy: 0.9887 - val_loss: 1.8826 - val_accuracy: 0.5132\n",
      "Epoch 896/1000\n",
      "177/177 [==============================] - 0s 141us/step - loss: 0.0666 - accuracy: 0.9887 - val_loss: 1.8320 - val_accuracy: 0.5132\n",
      "Epoch 897/1000\n",
      "177/177 [==============================] - 0s 126us/step - loss: 0.0509 - accuracy: 0.9887 - val_loss: 1.8080 - val_accuracy: 0.5263\n",
      "Epoch 898/1000\n",
      "177/177 [==============================] - 0s 148us/step - loss: 0.0502 - accuracy: 0.9887 - val_loss: 1.8269 - val_accuracy: 0.5263\n",
      "Epoch 899/1000\n",
      "177/177 [==============================] - 0s 112us/step - loss: 0.0487 - accuracy: 0.9887 - val_loss: 1.8224 - val_accuracy: 0.5263\n",
      "Epoch 900/1000\n",
      "177/177 [==============================] - 0s 150us/step - loss: 0.0463 - accuracy: 0.9944 - val_loss: 1.8267 - val_accuracy: 0.5263\n",
      "Epoch 901/1000\n",
      "177/177 [==============================] - 0s 153us/step - loss: 0.0443 - accuracy: 0.9944 - val_loss: 1.8371 - val_accuracy: 0.5395\n",
      "Epoch 902/1000\n",
      "177/177 [==============================] - 0s 112us/step - loss: 0.0507 - accuracy: 0.9887 - val_loss: 1.8044 - val_accuracy: 0.5263\n",
      "Epoch 903/1000\n",
      "177/177 [==============================] - 0s 128us/step - loss: 0.0769 - accuracy: 0.9887 - val_loss: 1.8126 - val_accuracy: 0.5263\n",
      "Epoch 904/1000\n",
      "177/177 [==============================] - 0s 141us/step - loss: 0.0761 - accuracy: 0.9887 - val_loss: 1.8595 - val_accuracy: 0.5263\n",
      "Epoch 905/1000\n",
      "177/177 [==============================] - 0s 118us/step - loss: 0.0468 - accuracy: 0.9944 - val_loss: 1.8041 - val_accuracy: 0.5263\n",
      "Epoch 906/1000\n",
      "177/177 [==============================] - 0s 104us/step - loss: 0.0923 - accuracy: 0.9887 - val_loss: 1.8199 - val_accuracy: 0.5263\n",
      "Epoch 907/1000\n",
      "177/177 [==============================] - 0s 124us/step - loss: 0.0480 - accuracy: 0.9887 - val_loss: 1.8492 - val_accuracy: 0.5395\n",
      "Epoch 908/1000\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.0424 - accuracy: 0.9944 - val_loss: 1.8378 - val_accuracy: 0.5263\n",
      "Epoch 909/1000\n",
      "177/177 [==============================] - 0s 85us/step - loss: 0.0430 - accuracy: 0.9944 - val_loss: 1.8361 - val_accuracy: 0.5263\n",
      "Epoch 910/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.0421 - accuracy: 0.9944 - val_loss: 1.8429 - val_accuracy: 0.5132\n",
      "Epoch 911/1000\n",
      "177/177 [==============================] - 0s 69us/step - loss: 0.0436 - accuracy: 0.9944 - val_loss: 1.8367 - val_accuracy: 0.5132\n",
      "Epoch 912/1000\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.0429 - accuracy: 0.9944 - val_loss: 1.8388 - val_accuracy: 0.5132\n",
      "Epoch 913/1000\n",
      "177/177 [==============================] - 0s 68us/step - loss: 0.0420 - accuracy: 0.9944 - val_loss: 1.8458 - val_accuracy: 0.5132\n",
      "Epoch 914/1000\n",
      "177/177 [==============================] - 0s 74us/step - loss: 0.0437 - accuracy: 0.9944 - val_loss: 1.8446 - val_accuracy: 0.5263\n",
      "Epoch 915/1000\n",
      "177/177 [==============================] - 0s 57us/step - loss: 0.0430 - accuracy: 0.9944 - val_loss: 1.8416 - val_accuracy: 0.5263\n",
      "Epoch 916/1000\n",
      "177/177 [==============================] - 0s 58us/step - loss: 0.0430 - accuracy: 0.9944 - val_loss: 1.8514 - val_accuracy: 0.5132\n",
      "Epoch 917/1000\n",
      "177/177 [==============================] - 0s 58us/step - loss: 0.0418 - accuracy: 0.9944 - val_loss: 1.8464 - val_accuracy: 0.5263\n",
      "Epoch 918/1000\n",
      "177/177 [==============================] - 0s 70us/step - loss: 0.0415 - accuracy: 0.9944 - val_loss: 1.8595 - val_accuracy: 0.5132\n",
      "Epoch 919/1000\n",
      "177/177 [==============================] - 0s 68us/step - loss: 0.0435 - accuracy: 0.9944 - val_loss: 1.8496 - val_accuracy: 0.5263\n",
      "Epoch 920/1000\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.0426 - accuracy: 0.9944 - val_loss: 1.8516 - val_accuracy: 0.5263\n",
      "Epoch 921/1000\n",
      "177/177 [==============================] - 0s 58us/step - loss: 0.0413 - accuracy: 0.9944 - val_loss: 1.8659 - val_accuracy: 0.5132\n",
      "Epoch 922/1000\n",
      "177/177 [==============================] - 0s 63us/step - loss: 0.0478 - accuracy: 0.9887 - val_loss: 1.8436 - val_accuracy: 0.5263\n",
      "Epoch 923/1000\n",
      "177/177 [==============================] - 0s 57us/step - loss: 0.0633 - accuracy: 0.9887 - val_loss: 1.8361 - val_accuracy: 0.5132\n",
      "Epoch 924/1000\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.0443 - accuracy: 0.9944 - val_loss: 1.8505 - val_accuracy: 0.5132\n",
      "Epoch 925/1000\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.0508 - accuracy: 0.9887 - val_loss: 1.8502 - val_accuracy: 0.5132\n",
      "Epoch 926/1000\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.0417 - accuracy: 0.9944 - val_loss: 1.9334 - val_accuracy: 0.5132\n",
      "Epoch 927/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.0912 - accuracy: 0.9831 - val_loss: 1.8589 - val_accuracy: 0.5132\n",
      "Epoch 928/1000\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.1363 - accuracy: 0.9718 - val_loss: 1.8040 - val_accuracy: 0.4868\n",
      "Epoch 929/1000\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.0966 - accuracy: 0.9718 - val_loss: 1.9218 - val_accuracy: 0.5132\n",
      "Epoch 930/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.0726 - accuracy: 0.9831 - val_loss: 1.9155 - val_accuracy: 0.5263\n",
      "Epoch 931/1000\n",
      "177/177 [==============================] - 0s 84us/step - loss: 0.0565 - accuracy: 0.9887 - val_loss: 1.8317 - val_accuracy: 0.5395\n",
      "Epoch 932/1000\n",
      "177/177 [==============================] - 0s 84us/step - loss: 0.1272 - accuracy: 0.9831 - val_loss: 1.8228 - val_accuracy: 0.5395\n",
      "Epoch 933/1000\n",
      "177/177 [==============================] - 0s 99us/step - loss: 0.0741 - accuracy: 0.9831 - val_loss: 1.9355 - val_accuracy: 0.5263\n",
      "Epoch 934/1000\n",
      "177/177 [==============================] - 0s 101us/step - loss: 0.0802 - accuracy: 0.9887 - val_loss: 1.8868 - val_accuracy: 0.5395\n",
      "Epoch 935/1000\n",
      "177/177 [==============================] - 0s 130us/step - loss: 0.0965 - accuracy: 0.9887 - val_loss: 1.8420 - val_accuracy: 0.5395\n",
      "Epoch 936/1000\n",
      "177/177 [==============================] - 0s 95us/step - loss: 0.0760 - accuracy: 0.9887 - val_loss: 2.0493 - val_accuracy: 0.5132\n",
      "Epoch 937/1000\n",
      "177/177 [==============================] - 0s 91us/step - loss: 0.1502 - accuracy: 0.9831 - val_loss: 1.9163 - val_accuracy: 0.5263\n",
      "Epoch 938/1000\n",
      "177/177 [==============================] - 0s 96us/step - loss: 0.1193 - accuracy: 0.9718 - val_loss: 1.8658 - val_accuracy: 0.5263\n",
      "Epoch 939/1000\n",
      "177/177 [==============================] - 0s 83us/step - loss: 0.1294 - accuracy: 0.9831 - val_loss: 2.1816 - val_accuracy: 0.5395\n",
      "Epoch 940/1000\n",
      "177/177 [==============================] - 0s 118us/step - loss: 0.2250 - accuracy: 0.9774 - val_loss: 2.0253 - val_accuracy: 0.5263\n",
      "Epoch 941/1000\n",
      "177/177 [==============================] - 0s 108us/step - loss: 0.1137 - accuracy: 0.9831 - val_loss: 1.8420 - val_accuracy: 0.5132\n",
      "Epoch 942/1000\n",
      "177/177 [==============================] - 0s 111us/step - loss: 0.1051 - accuracy: 0.9831 - val_loss: 1.8861 - val_accuracy: 0.5000\n",
      "Epoch 943/1000\n",
      "177/177 [==============================] - 0s 115us/step - loss: 0.0883 - accuracy: 0.9887 - val_loss: 1.9439 - val_accuracy: 0.5000\n",
      "Epoch 944/1000\n",
      "177/177 [==============================] - 0s 103us/step - loss: 0.0797 - accuracy: 0.9831 - val_loss: 1.8712 - val_accuracy: 0.5000\n",
      "Epoch 945/1000\n",
      "177/177 [==============================] - 0s 105us/step - loss: 0.1499 - accuracy: 0.9718 - val_loss: 1.8362 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 946/1000\n",
      "177/177 [==============================] - 0s 85us/step - loss: 0.0712 - accuracy: 0.9887 - val_loss: 2.0811 - val_accuracy: 0.5395\n",
      "Epoch 947/1000\n",
      "177/177 [==============================] - 0s 70us/step - loss: 0.2373 - accuracy: 0.9605 - val_loss: 1.9118 - val_accuracy: 0.5263\n",
      "Epoch 948/1000\n",
      "177/177 [==============================] - 0s 97us/step - loss: 0.1447 - accuracy: 0.9661 - val_loss: 1.8186 - val_accuracy: 0.5263\n",
      "Epoch 949/1000\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.1666 - accuracy: 0.9774 - val_loss: 1.9808 - val_accuracy: 0.5132\n",
      "Epoch 950/1000\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.0668 - accuracy: 0.9887 - val_loss: 1.9842 - val_accuracy: 0.5263\n",
      "Epoch 951/1000\n",
      "177/177 [==============================] - 0s 69us/step - loss: 0.1368 - accuracy: 0.9831 - val_loss: 1.9100 - val_accuracy: 0.5395\n",
      "Epoch 952/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.1639 - accuracy: 0.9661 - val_loss: 1.8781 - val_accuracy: 0.5263\n",
      "Epoch 953/1000\n",
      "177/177 [==============================] - 0s 75us/step - loss: 0.0578 - accuracy: 0.9887 - val_loss: 2.0448 - val_accuracy: 0.5263\n",
      "Epoch 954/1000\n",
      "177/177 [==============================] - 0s 68us/step - loss: 0.1192 - accuracy: 0.9774 - val_loss: 1.9762 - val_accuracy: 0.5132\n",
      "Epoch 955/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.0476 - accuracy: 0.9887 - val_loss: 1.8667 - val_accuracy: 0.5263\n",
      "Epoch 956/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.0402 - accuracy: 0.9944 - val_loss: 1.8618 - val_accuracy: 0.5132\n",
      "Epoch 957/1000\n",
      "177/177 [==============================] - 0s 78us/step - loss: 0.0459 - accuracy: 0.9944 - val_loss: 1.8764 - val_accuracy: 0.5000\n",
      "Epoch 958/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.0652 - accuracy: 0.9887 - val_loss: 1.8754 - val_accuracy: 0.5263\n",
      "Epoch 959/1000\n",
      "177/177 [==============================] - 0s 91us/step - loss: 0.0432 - accuracy: 0.9944 - val_loss: 1.9046 - val_accuracy: 0.5000\n",
      "Epoch 960/1000\n",
      "177/177 [==============================] - 0s 76us/step - loss: 0.1491 - accuracy: 0.9831 - val_loss: 1.8557 - val_accuracy: 0.5263\n",
      "Epoch 961/1000\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.0640 - accuracy: 0.9831 - val_loss: 1.9304 - val_accuracy: 0.5263\n",
      "Epoch 962/1000\n",
      "177/177 [==============================] - 0s 74us/step - loss: 0.0944 - accuracy: 0.9887 - val_loss: 1.8994 - val_accuracy: 0.5132\n",
      "Epoch 963/1000\n",
      "177/177 [==============================] - 0s 63us/step - loss: 0.0564 - accuracy: 0.9831 - val_loss: 1.8570 - val_accuracy: 0.5000\n",
      "Epoch 964/1000\n",
      "177/177 [==============================] - 0s 76us/step - loss: 0.1030 - accuracy: 0.9887 - val_loss: 1.9022 - val_accuracy: 0.5395\n",
      "Epoch 965/1000\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.0457 - accuracy: 0.9887 - val_loss: 1.9474 - val_accuracy: 0.5263\n",
      "Epoch 966/1000\n",
      "177/177 [==============================] - 0s 60us/step - loss: 0.0457 - accuracy: 0.9887 - val_loss: 1.8835 - val_accuracy: 0.5395\n",
      "Epoch 967/1000\n",
      "177/177 [==============================] - 0s 59us/step - loss: 0.0497 - accuracy: 0.9887 - val_loss: 1.9004 - val_accuracy: 0.5395\n",
      "Epoch 968/1000\n",
      "177/177 [==============================] - 0s 79us/step - loss: 0.0386 - accuracy: 0.9944 - val_loss: 1.9141 - val_accuracy: 0.5132\n",
      "Epoch 969/1000\n",
      "177/177 [==============================] - 0s 76us/step - loss: 0.0502 - accuracy: 0.9887 - val_loss: 1.8908 - val_accuracy: 0.5263\n",
      "Epoch 970/1000\n",
      "177/177 [==============================] - 0s 58us/step - loss: 0.0867 - accuracy: 0.9887 - val_loss: 1.8692 - val_accuracy: 0.5263\n",
      "Epoch 971/1000\n",
      "177/177 [==============================] - 0s 85us/step - loss: 0.0569 - accuracy: 0.9831 - val_loss: 1.9353 - val_accuracy: 0.5132\n",
      "Epoch 972/1000\n",
      "177/177 [==============================] - 0s 76us/step - loss: 0.0559 - accuracy: 0.9831 - val_loss: 1.8935 - val_accuracy: 0.5395\n",
      "Epoch 973/1000\n",
      "177/177 [==============================] - 0s 69us/step - loss: 0.0553 - accuracy: 0.9887 - val_loss: 1.9024 - val_accuracy: 0.5263\n",
      "Epoch 974/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.0729 - accuracy: 0.9887 - val_loss: 1.8794 - val_accuracy: 0.5132\n",
      "Epoch 975/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.0389 - accuracy: 0.9944 - val_loss: 1.9703 - val_accuracy: 0.5132\n",
      "Epoch 976/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.1048 - accuracy: 0.9887 - val_loss: 1.9574 - val_accuracy: 0.5132\n",
      "Epoch 977/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.0404 - accuracy: 0.9944 - val_loss: 1.8677 - val_accuracy: 0.5132\n",
      "Epoch 978/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.1537 - accuracy: 0.9718 - val_loss: 1.8727 - val_accuracy: 0.4868\n",
      "Epoch 979/1000\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.0977 - accuracy: 0.9887 - val_loss: 2.1819 - val_accuracy: 0.5263\n",
      "Epoch 980/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.2071 - accuracy: 0.9718 - val_loss: 1.9466 - val_accuracy: 0.5263\n",
      "Epoch 981/1000\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.0746 - accuracy: 0.9831 - val_loss: 1.8737 - val_accuracy: 0.5263\n",
      "Epoch 982/1000\n",
      "177/177 [==============================] - 0s 69us/step - loss: 0.0771 - accuracy: 0.9831 - val_loss: 1.9480 - val_accuracy: 0.5132\n",
      "Epoch 983/1000\n",
      "177/177 [==============================] - 0s 60us/step - loss: 0.0637 - accuracy: 0.9887 - val_loss: 1.9648 - val_accuracy: 0.5132\n",
      "Epoch 984/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.0467 - accuracy: 0.9887 - val_loss: 1.8931 - val_accuracy: 0.5263\n",
      "Epoch 985/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.0480 - accuracy: 0.9831 - val_loss: 1.8979 - val_accuracy: 0.5132\n",
      "Epoch 986/1000\n",
      "177/177 [==============================] - 0s 124us/step - loss: 0.0422 - accuracy: 0.9944 - val_loss: 1.9319 - val_accuracy: 0.5263\n",
      "Epoch 987/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.0742 - accuracy: 0.9887 - val_loss: 1.9776 - val_accuracy: 0.5132\n",
      "Epoch 988/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.0639 - accuracy: 0.9887 - val_loss: 1.8766 - val_accuracy: 0.5000\n",
      "Epoch 989/1000\n",
      "177/177 [==============================] - 0s 85us/step - loss: 0.1521 - accuracy: 0.9774 - val_loss: 1.8682 - val_accuracy: 0.5263\n",
      "Epoch 990/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.0504 - accuracy: 0.9944 - val_loss: 2.0976 - val_accuracy: 0.5395\n",
      "Epoch 991/1000\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.1776 - accuracy: 0.9718 - val_loss: 1.9715 - val_accuracy: 0.5395\n",
      "Epoch 992/1000\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.0750 - accuracy: 0.9774 - val_loss: 1.9091 - val_accuracy: 0.5263\n",
      "Epoch 993/1000\n",
      "177/177 [==============================] - 0s 105us/step - loss: 0.1163 - accuracy: 0.9774 - val_loss: 2.0641 - val_accuracy: 0.5263\n",
      "Epoch 994/1000\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.1097 - accuracy: 0.9774 - val_loss: 1.9070 - val_accuracy: 0.5395\n",
      "Epoch 995/1000\n",
      "177/177 [==============================] - 0s 97us/step - loss: 0.0557 - accuracy: 0.9831 - val_loss: 1.9546 - val_accuracy: 0.5132\n",
      "Epoch 996/1000\n",
      "177/177 [==============================] - 0s 96us/step - loss: 0.0630 - accuracy: 0.9887 - val_loss: 1.9115 - val_accuracy: 0.5395\n",
      "Epoch 997/1000\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.0422 - accuracy: 0.9887 - val_loss: 1.9221 - val_accuracy: 0.5395\n",
      "Epoch 998/1000\n",
      "177/177 [==============================] - 0s 100us/step - loss: 0.0455 - accuracy: 0.9887 - val_loss: 1.9227 - val_accuracy: 0.5395\n",
      "Epoch 999/1000\n",
      "177/177 [==============================] - 0s 95us/step - loss: 0.0532 - accuracy: 0.9887 - val_loss: 1.9080 - val_accuracy: 0.5395\n",
      "Epoch 1000/1000\n",
      "177/177 [==============================] - 0s 74us/step - loss: 0.0374 - accuracy: 0.9944 - val_loss: 1.9353 - val_accuracy: 0.5132\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a40c660f0>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sel.fit(X_sel_train, y_sel_train,\n",
    "          batch_size=64, epochs=1000,\n",
    "          validation_data=(X_sel_test, y_sel_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 0s 111us/step\n",
      "over-sampling test accuracy: 52.63%\n"
     ]
    }
   ],
   "source": [
    "acc_test_sel = model_sel.evaluate(X_sel_test, y_sel_test)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_sel*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 2, 1, 2, 2, 2, 2, 2, 1, 1, 2, 2, 1, 1, 2, 0, 2, 0, 2, 1, 2,\n",
       "       2, 0, 0, 1, 0, 1, 2, 0, 0, 2, 2, 1, 1, 0, 1, 2, 2, 1, 0, 0, 2, 2,\n",
       "       1, 2, 2, 0, 2, 1, 1, 2, 0, 1, 1, 1, 1, 1, 1, 2, 2, 1, 0, 0, 2, 1,\n",
       "       0, 1, 2, 2, 1, 1, 2, 0, 2, 2])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred5 = model_sel.predict_classes(X_sel_test)\n",
    "pred5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strain</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>SR4156</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>BCH-SA-02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>NRS180</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>NY417</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>CFBREBSa110</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>CFBREBSa131</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>NRS112</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>BCH-SA-06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>834N</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>CA9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          strain  test  pred\n",
       "251       SR4156     2     2\n",
       "17     BCH-SA-02     0     0\n",
       "158       NRS180     2     2\n",
       "232        NY417     1     1\n",
       "47   CFBREBSa110     2     2\n",
       "..           ...   ...   ...\n",
       "62   CFBREBSa131     2     1\n",
       "138       NRS112     2     2\n",
       "21     BCH-SA-06     0     0\n",
       "15          834N     2     2\n",
       "40           CA9     1     2\n",
       "\n",
       "[76 rows x 3 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat5['pred'] = pred5\n",
    "dat5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba5 = model_sel.predict_proba(X_sel_test)\n",
    "dat_proba5 = pd.DataFrame(proba5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000752</td>\n",
       "      <td>0.002747</td>\n",
       "      <td>0.996501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.897230</td>\n",
       "      <td>0.060890</td>\n",
       "      <td>0.041880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.047086</td>\n",
       "      <td>0.952844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.288528</td>\n",
       "      <td>0.536828</td>\n",
       "      <td>0.174645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.015682</td>\n",
       "      <td>0.005863</td>\n",
       "      <td>0.978455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.006617</td>\n",
       "      <td>0.565843</td>\n",
       "      <td>0.427540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.001056</td>\n",
       "      <td>0.045611</td>\n",
       "      <td>0.953333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.874708</td>\n",
       "      <td>0.071162</td>\n",
       "      <td>0.054130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.999985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.383900</td>\n",
       "      <td>0.142659</td>\n",
       "      <td>0.473441</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2\n",
       "0   0.000752  0.002747  0.996501\n",
       "1   0.897230  0.060890  0.041880\n",
       "2   0.000070  0.047086  0.952844\n",
       "3   0.288528  0.536828  0.174645\n",
       "4   0.015682  0.005863  0.978455\n",
       "..       ...       ...       ...\n",
       "71  0.006617  0.565843  0.427540\n",
       "72  0.001056  0.045611  0.953333\n",
       "73  0.874708  0.071162  0.054130\n",
       "74  0.000003  0.000013  0.999985\n",
       "75  0.383900  0.142659  0.473441\n",
       "\n",
       "[76 rows x 3 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba5.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba5.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat5.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/5p40pST.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 177 samples, validate on 76 samples\n",
      "Epoch 1/1000\n",
      "177/177 [==============================] - 0s 93us/step - loss: 0.0445 - accuracy: 0.9887 - val_loss: 2.1354 - val_accuracy: 0.5263\n",
      "Epoch 2/1000\n",
      "177/177 [==============================] - 0s 70us/step - loss: 0.0304 - accuracy: 0.9944 - val_loss: 2.1791 - val_accuracy: 0.5000\n",
      "Epoch 3/1000\n",
      "177/177 [==============================] - 0s 84us/step - loss: 0.0714 - accuracy: 0.9887 - val_loss: 2.1723 - val_accuracy: 0.5132\n",
      "Epoch 4/1000\n",
      "177/177 [==============================] - 0s 110us/step - loss: 0.0841 - accuracy: 0.9774 - val_loss: 2.1208 - val_accuracy: 0.5263\n",
      "Epoch 5/1000\n",
      "177/177 [==============================] - 0s 121us/step - loss: 0.0758 - accuracy: 0.9887 - val_loss: 2.1347 - val_accuracy: 0.5263\n",
      "Epoch 6/1000\n",
      "177/177 [==============================] - 0s 122us/step - loss: 0.0539 - accuracy: 0.9831 - val_loss: 2.2580 - val_accuracy: 0.5132\n",
      "Epoch 7/1000\n",
      "177/177 [==============================] - 0s 95us/step - loss: 0.0880 - accuracy: 0.9831 - val_loss: 2.1552 - val_accuracy: 0.5132\n",
      "Epoch 8/1000\n",
      "177/177 [==============================] - 0s 103us/step - loss: 0.0458 - accuracy: 0.9831 - val_loss: 2.1382 - val_accuracy: 0.5263\n",
      "Epoch 9/1000\n",
      "177/177 [==============================] - 0s 94us/step - loss: 0.0361 - accuracy: 0.9944 - val_loss: 2.1988 - val_accuracy: 0.5132\n",
      "Epoch 10/1000\n",
      "177/177 [==============================] - 0s 93us/step - loss: 0.0424 - accuracy: 0.9887 - val_loss: 2.1732 - val_accuracy: 0.5132\n",
      "Epoch 11/1000\n",
      "177/177 [==============================] - 0s 84us/step - loss: 0.0329 - accuracy: 0.9944 - val_loss: 2.1485 - val_accuracy: 0.5263\n",
      "Epoch 12/1000\n",
      "177/177 [==============================] - 0s 91us/step - loss: 0.0330 - accuracy: 0.9944 - val_loss: 2.1505 - val_accuracy: 0.5132\n",
      "Epoch 13/1000\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.0338 - accuracy: 0.9944 - val_loss: 2.1536 - val_accuracy: 0.5132\n",
      "Epoch 14/1000\n",
      "177/177 [==============================] - ETA: 0s - loss: 0.0427 - accuracy: 0.98 - 0s 84us/step - loss: 0.0321 - accuracy: 0.9944 - val_loss: 2.1602 - val_accuracy: 0.5132\n",
      "Epoch 15/1000\n",
      "177/177 [==============================] - 0s 92us/step - loss: 0.0312 - accuracy: 0.9944 - val_loss: 2.1577 - val_accuracy: 0.5132\n",
      "Epoch 16/1000\n",
      "177/177 [==============================] - 0s 109us/step - loss: 0.0323 - accuracy: 0.9944 - val_loss: 2.1876 - val_accuracy: 0.5132\n",
      "Epoch 17/1000\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.0330 - accuracy: 0.9944 - val_loss: 2.1824 - val_accuracy: 0.5132\n",
      "Epoch 18/1000\n",
      "177/177 [==============================] - 0s 100us/step - loss: 0.0310 - accuracy: 0.9944 - val_loss: 2.1604 - val_accuracy: 0.5395\n",
      "Epoch 19/1000\n",
      "177/177 [==============================] - 0s 118us/step - loss: 0.0319 - accuracy: 0.9944 - val_loss: 2.1581 - val_accuracy: 0.5395\n",
      "Epoch 20/1000\n",
      "177/177 [==============================] - 0s 99us/step - loss: 0.0329 - accuracy: 0.9944 - val_loss: 2.1669 - val_accuracy: 0.5263\n",
      "Epoch 21/1000\n",
      "177/177 [==============================] - 0s 79us/step - loss: 0.0317 - accuracy: 0.9944 - val_loss: 2.1648 - val_accuracy: 0.5263\n",
      "Epoch 22/1000\n",
      "177/177 [==============================] - 0s 95us/step - loss: 0.0313 - accuracy: 0.9944 - val_loss: 2.1802 - val_accuracy: 0.5263\n",
      "Epoch 23/1000\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.0315 - accuracy: 0.9944 - val_loss: 2.1927 - val_accuracy: 0.5263\n",
      "Epoch 24/1000\n",
      "177/177 [==============================] - 0s 103us/step - loss: 0.0360 - accuracy: 0.9887 - val_loss: 2.1915 - val_accuracy: 0.5263\n",
      "Epoch 25/1000\n",
      "177/177 [==============================] - 0s 101us/step - loss: 0.0300 - accuracy: 0.9944 - val_loss: 2.2213 - val_accuracy: 0.5132\n",
      "Epoch 26/1000\n",
      "177/177 [==============================] - 0s 70us/step - loss: 0.0483 - accuracy: 0.9887 - val_loss: 2.1827 - val_accuracy: 0.5263\n",
      "Epoch 27/1000\n",
      "177/177 [==============================] - 0s 97us/step - loss: 0.0377 - accuracy: 0.9887 - val_loss: 2.1856 - val_accuracy: 0.5263\n",
      "Epoch 28/1000\n",
      "177/177 [==============================] - 0s 94us/step - loss: 0.0286 - accuracy: 0.9944 - val_loss: 2.2222 - val_accuracy: 0.5263\n",
      "Epoch 29/1000\n",
      "177/177 [==============================] - 0s 91us/step - loss: 0.0492 - accuracy: 0.9887 - val_loss: 2.1964 - val_accuracy: 0.5263\n",
      "Epoch 30/1000\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.0358 - accuracy: 0.9887 - val_loss: 2.1985 - val_accuracy: 0.5263\n",
      "Epoch 31/1000\n",
      "177/177 [==============================] - 0s 89us/step - loss: 0.0301 - accuracy: 0.9944 - val_loss: 2.2329 - val_accuracy: 0.5132\n",
      "Epoch 32/1000\n",
      "177/177 [==============================] - 0s 94us/step - loss: 0.0389 - accuracy: 0.9887 - val_loss: 2.2020 - val_accuracy: 0.5263\n",
      "Epoch 33/1000\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.0517 - accuracy: 0.9887 - val_loss: 2.1859 - val_accuracy: 0.5263\n",
      "Epoch 34/1000\n",
      "177/177 [==============================] - 0s 84us/step - loss: 0.0414 - accuracy: 0.9887 - val_loss: 2.2646 - val_accuracy: 0.5132\n",
      "Epoch 35/1000\n",
      "177/177 [==============================] - 0s 94us/step - loss: 0.0867 - accuracy: 0.9831 - val_loss: 2.2285 - val_accuracy: 0.5263\n",
      "Epoch 36/1000\n",
      "177/177 [==============================] - 0s 91us/step - loss: 0.0513 - accuracy: 0.9887 - val_loss: 2.1707 - val_accuracy: 0.5263\n",
      "Epoch 37/1000\n",
      "177/177 [==============================] - 0s 83us/step - loss: 0.1220 - accuracy: 0.9774 - val_loss: 2.1817 - val_accuracy: 0.5263\n",
      "Epoch 38/1000\n",
      "177/177 [==============================] - 0s 89us/step - loss: 0.0611 - accuracy: 0.9944 - val_loss: 2.2342 - val_accuracy: 0.5132\n",
      "Epoch 39/1000\n",
      "177/177 [==============================] - 0s 89us/step - loss: 0.1383 - accuracy: 0.9831 - val_loss: 2.2987 - val_accuracy: 0.5263\n",
      "Epoch 40/1000\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.0887 - accuracy: 0.9944 - val_loss: 2.1993 - val_accuracy: 0.5132\n",
      "Epoch 41/1000\n",
      "177/177 [==============================] - 0s 113us/step - loss: 0.1717 - accuracy: 0.9661 - val_loss: 2.2403 - val_accuracy: 0.5132\n",
      "Epoch 42/1000\n",
      "177/177 [==============================] - 0s 94us/step - loss: 0.1733 - accuracy: 0.9831 - val_loss: 2.3772 - val_accuracy: 0.5000\n",
      "Epoch 43/1000\n",
      "177/177 [==============================] - 0s 74us/step - loss: 0.0795 - accuracy: 0.9887 - val_loss: 2.3897 - val_accuracy: 0.4868\n",
      "Epoch 44/1000\n",
      "177/177 [==============================] - 0s 85us/step - loss: 0.1136 - accuracy: 0.9774 - val_loss: 2.2595 - val_accuracy: 0.5132\n",
      "Epoch 45/1000\n",
      "177/177 [==============================] - 0s 136us/step - loss: 0.1336 - accuracy: 0.9718 - val_loss: 2.2153 - val_accuracy: 0.5263\n",
      "Epoch 46/1000\n",
      "177/177 [==============================] - 0s 93us/step - loss: 0.0717 - accuracy: 0.9831 - val_loss: 2.2938 - val_accuracy: 0.5263\n",
      "Epoch 47/1000\n",
      "177/177 [==============================] - 0s 81us/step - loss: 0.0416 - accuracy: 0.9887 - val_loss: 2.3096 - val_accuracy: 0.5263\n",
      "Epoch 48/1000\n",
      "177/177 [==============================] - 0s 81us/step - loss: 0.0928 - accuracy: 0.9831 - val_loss: 2.2581 - val_accuracy: 0.5395\n",
      "Epoch 49/1000\n",
      "177/177 [==============================] - 0s 70us/step - loss: 0.0711 - accuracy: 0.9774 - val_loss: 2.2158 - val_accuracy: 0.5395\n",
      "Epoch 50/1000\n",
      "177/177 [==============================] - 0s 78us/step - loss: 0.0559 - accuracy: 0.9831 - val_loss: 2.3562 - val_accuracy: 0.5263\n",
      "Epoch 51/1000\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.0689 - accuracy: 0.9831 - val_loss: 2.2408 - val_accuracy: 0.5395\n",
      "Epoch 52/1000\n",
      "177/177 [==============================] - 0s 130us/step - loss: 0.0283 - accuracy: 0.9944 - val_loss: 2.2011 - val_accuracy: 0.5395\n",
      "Epoch 53/1000\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.0555 - accuracy: 0.9831 - val_loss: 2.2245 - val_accuracy: 0.5263\n",
      "Epoch 54/1000\n",
      "177/177 [==============================] - 0s 97us/step - loss: 0.0323 - accuracy: 0.9944 - val_loss: 2.2508 - val_accuracy: 0.5263\n",
      "Epoch 55/1000\n",
      "177/177 [==============================] - 0s 111us/step - loss: 0.0553 - accuracy: 0.9887 - val_loss: 2.2536 - val_accuracy: 0.5263\n",
      "Epoch 56/1000\n",
      "177/177 [==============================] - 0s 86us/step - loss: 0.0713 - accuracy: 0.9831 - val_loss: 2.2277 - val_accuracy: 0.5263\n",
      "Epoch 57/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.0632 - accuracy: 0.9887 - val_loss: 2.2876 - val_accuracy: 0.5132\n",
      "Epoch 58/1000\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.0363 - accuracy: 0.9887 - val_loss: 2.2796 - val_accuracy: 0.5132\n",
      "Epoch 59/1000\n",
      "177/177 [==============================] - 0s 75us/step - loss: 0.0314 - accuracy: 0.9887 - val_loss: 2.2475 - val_accuracy: 0.5263\n",
      "Epoch 60/1000\n",
      "177/177 [==============================] - 0s 76us/step - loss: 0.0358 - accuracy: 0.9887 - val_loss: 2.2533 - val_accuracy: 0.5263\n",
      "Epoch 61/1000\n",
      "177/177 [==============================] - 0s 50us/step - loss: 0.0279 - accuracy: 0.9944 - val_loss: 2.2644 - val_accuracy: 0.5132\n",
      "Epoch 62/1000\n",
      "177/177 [==============================] - 0s 56us/step - loss: 0.0316 - accuracy: 0.9887 - val_loss: 2.2508 - val_accuracy: 0.5263\n",
      "Epoch 63/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.0295 - accuracy: 0.9944 - val_loss: 2.2398 - val_accuracy: 0.5263\n",
      "Epoch 64/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.0339 - accuracy: 0.9887 - val_loss: 2.2564 - val_accuracy: 0.5263\n",
      "Epoch 65/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.0525 - accuracy: 0.9887 - val_loss: 2.2708 - val_accuracy: 0.5263\n",
      "Epoch 66/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.0617 - accuracy: 0.9831 - val_loss: 2.2286 - val_accuracy: 0.5263\n",
      "Epoch 67/1000\n",
      "177/177 [==============================] - 0s 69us/step - loss: 0.0477 - accuracy: 0.9944 - val_loss: 2.2605 - val_accuracy: 0.5263\n",
      "Epoch 68/1000\n",
      "177/177 [==============================] - 0s 82us/step - loss: 0.0483 - accuracy: 0.9887 - val_loss: 2.3017 - val_accuracy: 0.5263\n",
      "Epoch 69/1000\n",
      "177/177 [==============================] - 0s 89us/step - loss: 0.0594 - accuracy: 0.9887 - val_loss: 2.2776 - val_accuracy: 0.5263\n",
      "Epoch 70/1000\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.0422 - accuracy: 0.9831 - val_loss: 2.2413 - val_accuracy: 0.5263\n",
      "Epoch 71/1000\n",
      "177/177 [==============================] - 0s 77us/step - loss: 0.0704 - accuracy: 0.9887 - val_loss: 2.2570 - val_accuracy: 0.5263\n",
      "Epoch 72/1000\n",
      "177/177 [==============================] - 0s 70us/step - loss: 0.0297 - accuracy: 0.9944 - val_loss: 2.2933 - val_accuracy: 0.5132\n",
      "Epoch 73/1000\n",
      "177/177 [==============================] - 0s 92us/step - loss: 0.0325 - accuracy: 0.9887 - val_loss: 2.2666 - val_accuracy: 0.5263\n",
      "Epoch 74/1000\n",
      "177/177 [==============================] - 0s 77us/step - loss: 0.0263 - accuracy: 0.9944 - val_loss: 2.2537 - val_accuracy: 0.5263\n",
      "Epoch 75/1000\n",
      "177/177 [==============================] - 0s 76us/step - loss: 0.0326 - accuracy: 0.9887 - val_loss: 2.2782 - val_accuracy: 0.5263\n",
      "Epoch 76/1000\n",
      "177/177 [==============================] - 0s 87us/step - loss: 0.0281 - accuracy: 0.9944 - val_loss: 2.2762 - val_accuracy: 0.5263\n",
      "Epoch 77/1000\n",
      "177/177 [==============================] - 0s 75us/step - loss: 0.0276 - accuracy: 0.9944 - val_loss: 2.2571 - val_accuracy: 0.5263\n",
      "Epoch 78/1000\n",
      "177/177 [==============================] - 0s 77us/step - loss: 0.0282 - accuracy: 0.9944 - val_loss: 2.2636 - val_accuracy: 0.5263\n",
      "Epoch 79/1000\n",
      "177/177 [==============================] - 0s 99us/step - loss: 0.0261 - accuracy: 0.9944 - val_loss: 2.2743 - val_accuracy: 0.5263\n",
      "Epoch 80/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.0264 - accuracy: 0.9944 - val_loss: 2.2797 - val_accuracy: 0.5263\n",
      "Epoch 81/1000\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.0258 - accuracy: 0.9944 - val_loss: 2.2769 - val_accuracy: 0.5263\n",
      "Epoch 82/1000\n",
      "177/177 [==============================] - 0s 79us/step - loss: 0.0260 - accuracy: 0.9944 - val_loss: 2.2778 - val_accuracy: 0.5263\n",
      "Epoch 83/1000\n",
      "177/177 [==============================] - 0s 87us/step - loss: 0.0260 - accuracy: 0.9944 - val_loss: 2.2812 - val_accuracy: 0.5263\n",
      "Epoch 84/1000\n",
      "177/177 [==============================] - 0s 81us/step - loss: 0.0258 - accuracy: 0.9944 - val_loss: 2.2819 - val_accuracy: 0.5263\n",
      "Epoch 85/1000\n",
      "177/177 [==============================] - 0s 107us/step - loss: 0.0255 - accuracy: 0.9944 - val_loss: 2.2824 - val_accuracy: 0.5263\n",
      "Epoch 86/1000\n",
      "177/177 [==============================] - 0s 124us/step - loss: 0.0257 - accuracy: 0.9944 - val_loss: 2.2818 - val_accuracy: 0.5263\n",
      "Epoch 87/1000\n",
      "177/177 [==============================] - 0s 106us/step - loss: 0.0258 - accuracy: 0.9944 - val_loss: 2.2803 - val_accuracy: 0.5263\n",
      "Epoch 88/1000\n",
      "177/177 [==============================] - 0s 94us/step - loss: 0.0254 - accuracy: 0.9944 - val_loss: 2.2837 - val_accuracy: 0.5263\n",
      "Epoch 89/1000\n",
      "177/177 [==============================] - 0s 103us/step - loss: 0.0254 - accuracy: 0.9944 - val_loss: 2.2871 - val_accuracy: 0.5263\n",
      "Epoch 90/1000\n",
      "177/177 [==============================] - 0s 137us/step - loss: 0.0253 - accuracy: 0.9944 - val_loss: 2.2881 - val_accuracy: 0.5263\n",
      "Epoch 91/1000\n",
      "177/177 [==============================] - 0s 96us/step - loss: 0.0254 - accuracy: 0.9944 - val_loss: 2.2894 - val_accuracy: 0.5263\n",
      "Epoch 92/1000\n",
      "177/177 [==============================] - 0s 108us/step - loss: 0.0252 - accuracy: 0.9944 - val_loss: 2.2885 - val_accuracy: 0.5263\n",
      "Epoch 93/1000\n",
      "177/177 [==============================] - 0s 83us/step - loss: 0.0256 - accuracy: 0.9944 - val_loss: 2.2880 - val_accuracy: 0.5263\n",
      "Epoch 94/1000\n",
      "177/177 [==============================] - 0s 75us/step - loss: 0.0257 - accuracy: 0.9944 - val_loss: 2.2897 - val_accuracy: 0.5263\n",
      "Epoch 95/1000\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.0249 - accuracy: 0.9944 - val_loss: 2.2850 - val_accuracy: 0.5263\n",
      "Epoch 96/1000\n",
      "177/177 [==============================] - 0s 74us/step - loss: 0.0258 - accuracy: 0.9944 - val_loss: 2.2838 - val_accuracy: 0.5263\n",
      "Epoch 97/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.0249 - accuracy: 0.9944 - val_loss: 2.2934 - val_accuracy: 0.5263\n",
      "Epoch 98/1000\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.0252 - accuracy: 0.9944 - val_loss: 2.2956 - val_accuracy: 0.5263\n",
      "Epoch 99/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.0251 - accuracy: 0.9944 - val_loss: 2.2949 - val_accuracy: 0.5263\n",
      "Epoch 100/1000\n",
      "177/177 [==============================] - 0s 82us/step - loss: 0.0249 - accuracy: 0.9944 - val_loss: 2.2955 - val_accuracy: 0.5263\n",
      "Epoch 101/1000\n",
      "177/177 [==============================] - 0s 94us/step - loss: 0.0250 - accuracy: 0.9944 - val_loss: 2.2961 - val_accuracy: 0.5263\n",
      "Epoch 102/1000\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.0246 - accuracy: 0.9944 - val_loss: 2.2977 - val_accuracy: 0.5263\n",
      "Epoch 103/1000\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.0250 - accuracy: 0.9944 - val_loss: 2.2994 - val_accuracy: 0.5263\n",
      "Epoch 104/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.0246 - accuracy: 0.9944 - val_loss: 2.3033 - val_accuracy: 0.5263\n",
      "Epoch 105/1000\n",
      "177/177 [==============================] - 0s 75us/step - loss: 0.0245 - accuracy: 0.9944 - val_loss: 2.3015 - val_accuracy: 0.5263\n",
      "Epoch 106/1000\n",
      "177/177 [==============================] - 0s 55us/step - loss: 0.0245 - accuracy: 0.9944 - val_loss: 2.2964 - val_accuracy: 0.5263\n",
      "Epoch 107/1000\n",
      "177/177 [==============================] - 0s 59us/step - loss: 0.0252 - accuracy: 0.9944 - val_loss: 2.2977 - val_accuracy: 0.5132\n",
      "Epoch 108/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.0243 - accuracy: 0.9944 - val_loss: 2.2975 - val_accuracy: 0.5000\n",
      "Epoch 109/1000\n",
      "177/177 [==============================] - 0s 70us/step - loss: 0.0252 - accuracy: 0.9944 - val_loss: 2.2971 - val_accuracy: 0.5000\n",
      "Epoch 110/1000\n",
      "177/177 [==============================] - 0s 78us/step - loss: 0.0245 - accuracy: 0.9944 - val_loss: 2.2996 - val_accuracy: 0.5132\n",
      "Epoch 111/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.0243 - accuracy: 0.9944 - val_loss: 2.3064 - val_accuracy: 0.5263\n",
      "Epoch 112/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177/177 [==============================] - 0s 59us/step - loss: 0.0244 - accuracy: 0.9944 - val_loss: 2.3139 - val_accuracy: 0.5132\n",
      "Epoch 113/1000\n",
      "177/177 [==============================] - 0s 53us/step - loss: 0.0243 - accuracy: 0.9944 - val_loss: 2.3048 - val_accuracy: 0.5263\n",
      "Epoch 114/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.0241 - accuracy: 0.9944 - val_loss: 2.3053 - val_accuracy: 0.5263\n",
      "Epoch 115/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.0241 - accuracy: 0.9944 - val_loss: 2.3111 - val_accuracy: 0.5263\n",
      "Epoch 116/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.0247 - accuracy: 0.9944 - val_loss: 2.3081 - val_accuracy: 0.5263\n",
      "Epoch 117/1000\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.0252 - accuracy: 0.9944 - val_loss: 2.3034 - val_accuracy: 0.5263\n",
      "Epoch 118/1000\n",
      "177/177 [==============================] - 0s 75us/step - loss: 0.0246 - accuracy: 1.0000 - val_loss: 2.3151 - val_accuracy: 0.5263\n",
      "Epoch 119/1000\n",
      "177/177 [==============================] - ETA: 0s - loss: 0.0251 - accuracy: 1.00 - 0s 69us/step - loss: 0.0247 - accuracy: 0.9944 - val_loss: 2.3252 - val_accuracy: 0.5132\n",
      "Epoch 120/1000\n",
      "177/177 [==============================] - 0s 60us/step - loss: 0.0238 - accuracy: 0.9944 - val_loss: 2.3107 - val_accuracy: 0.5132\n",
      "Epoch 121/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.0244 - accuracy: 0.9944 - val_loss: 2.3121 - val_accuracy: 0.5132\n",
      "Epoch 122/1000\n",
      "177/177 [==============================] - 0s 76us/step - loss: 0.0239 - accuracy: 0.9944 - val_loss: 2.3177 - val_accuracy: 0.5132\n",
      "Epoch 123/1000\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.0246 - accuracy: 0.9944 - val_loss: 2.3163 - val_accuracy: 0.5132\n",
      "Epoch 124/1000\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.0237 - accuracy: 0.9944 - val_loss: 2.3154 - val_accuracy: 0.5263\n",
      "Epoch 125/1000\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.0238 - accuracy: 0.9944 - val_loss: 2.3217 - val_accuracy: 0.5263\n",
      "Epoch 126/1000\n",
      "177/177 [==============================] - 0s 74us/step - loss: 0.0236 - accuracy: 0.9944 - val_loss: 2.3379 - val_accuracy: 0.5132\n",
      "Epoch 127/1000\n",
      "177/177 [==============================] - 0s 81us/step - loss: 0.0246 - accuracy: 0.9944 - val_loss: 2.3234 - val_accuracy: 0.5132\n",
      "Epoch 128/1000\n",
      "177/177 [==============================] - 0s 81us/step - loss: 0.0238 - accuracy: 0.9944 - val_loss: 2.3154 - val_accuracy: 0.5132\n",
      "Epoch 129/1000\n",
      "177/177 [==============================] - 0s 89us/step - loss: 0.0236 - accuracy: 0.9944 - val_loss: 2.3172 - val_accuracy: 0.5000\n",
      "Epoch 130/1000\n",
      "177/177 [==============================] - 0s 69us/step - loss: 0.0234 - accuracy: 0.9944 - val_loss: 2.3191 - val_accuracy: 0.5000\n",
      "Epoch 131/1000\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.0239 - accuracy: 0.9944 - val_loss: 2.3182 - val_accuracy: 0.5132\n",
      "Epoch 132/1000\n",
      "177/177 [==============================] - 0s 86us/step - loss: 0.0234 - accuracy: 0.9944 - val_loss: 2.3204 - val_accuracy: 0.5263\n",
      "Epoch 133/1000\n",
      "177/177 [==============================] - 0s 92us/step - loss: 0.0233 - accuracy: 0.9944 - val_loss: 2.3261 - val_accuracy: 0.5263\n",
      "Epoch 134/1000\n",
      "177/177 [==============================] - 0s 87us/step - loss: 0.0230 - accuracy: 0.9944 - val_loss: 2.3297 - val_accuracy: 0.5263\n",
      "Epoch 135/1000\n",
      "177/177 [==============================] - 0s 70us/step - loss: 0.0232 - accuracy: 0.9944 - val_loss: 2.3306 - val_accuracy: 0.5263\n",
      "Epoch 136/1000\n",
      "177/177 [==============================] - 0s 79us/step - loss: 0.0233 - accuracy: 0.9944 - val_loss: 2.3289 - val_accuracy: 0.5263\n",
      "Epoch 137/1000\n",
      "177/177 [==============================] - 0s 77us/step - loss: 0.0232 - accuracy: 0.9944 - val_loss: 2.3262 - val_accuracy: 0.5132\n",
      "Epoch 138/1000\n",
      "177/177 [==============================] - 0s 69us/step - loss: 0.0234 - accuracy: 0.9944 - val_loss: 2.3274 - val_accuracy: 0.5132\n",
      "Epoch 139/1000\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.0227 - accuracy: 0.9944 - val_loss: 2.3231 - val_accuracy: 0.5132\n",
      "Epoch 140/1000\n",
      "177/177 [==============================] - 0s 77us/step - loss: 0.0231 - accuracy: 0.9944 - val_loss: 2.3219 - val_accuracy: 0.5132\n",
      "Epoch 141/1000\n",
      "177/177 [==============================] - 0s 100us/step - loss: 0.0230 - accuracy: 0.9944 - val_loss: 2.3342 - val_accuracy: 0.5132\n",
      "Epoch 142/1000\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.0242 - accuracy: 0.9944 - val_loss: 2.3336 - val_accuracy: 0.5132\n",
      "Epoch 143/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.0246 - accuracy: 0.9944 - val_loss: 2.3261 - val_accuracy: 0.5132\n",
      "Epoch 144/1000\n",
      "177/177 [==============================] - 0s 69us/step - loss: 0.0227 - accuracy: 0.9944 - val_loss: 2.3358 - val_accuracy: 0.5132\n",
      "Epoch 145/1000\n",
      "177/177 [==============================] - 0s 68us/step - loss: 0.0238 - accuracy: 0.9944 - val_loss: 2.3346 - val_accuracy: 0.5132\n",
      "Epoch 146/1000\n",
      "177/177 [==============================] - 0s 89us/step - loss: 0.0225 - accuracy: 0.9944 - val_loss: 2.3287 - val_accuracy: 0.5132\n",
      "Epoch 147/1000\n",
      "177/177 [==============================] - 0s 83us/step - loss: 0.0236 - accuracy: 0.9944 - val_loss: 2.3361 - val_accuracy: 0.5132\n",
      "Epoch 148/1000\n",
      "177/177 [==============================] - 0s 92us/step - loss: 0.0226 - accuracy: 0.9944 - val_loss: 2.3560 - val_accuracy: 0.5132\n",
      "Epoch 149/1000\n",
      "177/177 [==============================] - 0s 79us/step - loss: 0.0273 - accuracy: 0.9887 - val_loss: 2.3304 - val_accuracy: 0.5132\n",
      "Epoch 150/1000\n",
      "177/177 [==============================] - 0s 83us/step - loss: 0.0298 - accuracy: 0.9944 - val_loss: 2.3342 - val_accuracy: 0.5000\n",
      "Epoch 151/1000\n",
      "177/177 [==============================] - 0s 81us/step - loss: 0.0233 - accuracy: 0.9944 - val_loss: 2.3518 - val_accuracy: 0.5132\n",
      "Epoch 152/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.0258 - accuracy: 0.9887 - val_loss: 2.3345 - val_accuracy: 0.5132\n",
      "Epoch 153/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.0246 - accuracy: 1.0000 - val_loss: 2.3325 - val_accuracy: 0.5132\n",
      "Epoch 154/1000\n",
      "177/177 [==============================] - 0s 68us/step - loss: 0.0227 - accuracy: 0.9944 - val_loss: 2.3417 - val_accuracy: 0.5132\n",
      "Epoch 155/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.0222 - accuracy: 0.9944 - val_loss: 2.3437 - val_accuracy: 0.5132\n",
      "Epoch 156/1000\n",
      "177/177 [==============================] - 0s 82us/step - loss: 0.0224 - accuracy: 0.9944 - val_loss: 2.3420 - val_accuracy: 0.5132\n",
      "Epoch 157/1000\n",
      "177/177 [==============================] - 0s 77us/step - loss: 0.0222 - accuracy: 0.9944 - val_loss: 2.3435 - val_accuracy: 0.5132\n",
      "Epoch 158/1000\n",
      "177/177 [==============================] - 0s 81us/step - loss: 0.0221 - accuracy: 0.9944 - val_loss: 2.3457 - val_accuracy: 0.5132\n",
      "Epoch 159/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.0221 - accuracy: 0.9944 - val_loss: 2.3415 - val_accuracy: 0.5132\n",
      "Epoch 160/1000\n",
      "177/177 [==============================] - 0s 63us/step - loss: 0.0224 - accuracy: 1.0000 - val_loss: 2.3402 - val_accuracy: 0.5132\n",
      "Epoch 161/1000\n",
      "177/177 [==============================] - 0s 70us/step - loss: 0.0223 - accuracy: 1.0000 - val_loss: 2.3482 - val_accuracy: 0.5132\n",
      "Epoch 162/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.0225 - accuracy: 0.9944 - val_loss: 2.3525 - val_accuracy: 0.5263\n",
      "Epoch 163/1000\n",
      "177/177 [==============================] - 0s 79us/step - loss: 0.0221 - accuracy: 0.9944 - val_loss: 2.3460 - val_accuracy: 0.5263\n",
      "Epoch 164/1000\n",
      "177/177 [==============================] - 0s 78us/step - loss: 0.0223 - accuracy: 0.9944 - val_loss: 2.3503 - val_accuracy: 0.5263\n",
      "Epoch 165/1000\n",
      "177/177 [==============================] - 0s 81us/step - loss: 0.0217 - accuracy: 0.9944 - val_loss: 2.3507 - val_accuracy: 0.5263\n",
      "Epoch 166/1000\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.0218 - accuracy: 0.9944 - val_loss: 2.3495 - val_accuracy: 0.5132\n",
      "Epoch 167/1000\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.0218 - accuracy: 0.9944 - val_loss: 2.3516 - val_accuracy: 0.5132\n",
      "Epoch 168/1000\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.0216 - accuracy: 0.9944 - val_loss: 2.3588 - val_accuracy: 0.5132\n",
      "Epoch 169/1000\n",
      "177/177 [==============================] - 0s 82us/step - loss: 0.0220 - accuracy: 0.9944 - val_loss: 2.3617 - val_accuracy: 0.5132\n",
      "Epoch 170/1000\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.0217 - accuracy: 0.9944 - val_loss: 2.3550 - val_accuracy: 0.5132\n",
      "Epoch 171/1000\n",
      "177/177 [==============================] - 0s 92us/step - loss: 0.0218 - accuracy: 0.9944 - val_loss: 2.3555 - val_accuracy: 0.5132\n",
      "Epoch 172/1000\n",
      "177/177 [==============================] - 0s 95us/step - loss: 0.0220 - accuracy: 0.9944 - val_loss: 2.3598 - val_accuracy: 0.5000\n",
      "Epoch 173/1000\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.0223 - accuracy: 0.9944 - val_loss: 2.3485 - val_accuracy: 0.5000\n",
      "Epoch 174/1000\n",
      "177/177 [==============================] - 0s 68us/step - loss: 0.0226 - accuracy: 1.0000 - val_loss: 2.3603 - val_accuracy: 0.5000\n",
      "Epoch 175/1000\n",
      "177/177 [==============================] - 0s 74us/step - loss: 0.0222 - accuracy: 0.9944 - val_loss: 2.3677 - val_accuracy: 0.5132\n",
      "Epoch 176/1000\n",
      "177/177 [==============================] - 0s 75us/step - loss: 0.0222 - accuracy: 0.9944 - val_loss: 2.3654 - val_accuracy: 0.5132\n",
      "Epoch 177/1000\n",
      "177/177 [==============================] - 0s 91us/step - loss: 0.0219 - accuracy: 0.9944 - val_loss: 2.3651 - val_accuracy: 0.5132\n",
      "Epoch 178/1000\n",
      "177/177 [==============================] - 0s 112us/step - loss: 0.0211 - accuracy: 0.9944 - val_loss: 2.3761 - val_accuracy: 0.5263\n",
      "Epoch 179/1000\n",
      "177/177 [==============================] - 0s 95us/step - loss: 0.0224 - accuracy: 0.9944 - val_loss: 2.3640 - val_accuracy: 0.5263\n",
      "Epoch 180/1000\n",
      "177/177 [==============================] - 0s 79us/step - loss: 0.0215 - accuracy: 1.0000 - val_loss: 2.3642 - val_accuracy: 0.5263\n",
      "Epoch 181/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.0213 - accuracy: 1.0000 - val_loss: 2.3699 - val_accuracy: 0.5263\n",
      "Epoch 182/1000\n",
      "177/177 [==============================] - 0s 57us/step - loss: 0.0213 - accuracy: 0.9944 - val_loss: 2.3751 - val_accuracy: 0.5132\n",
      "Epoch 183/1000\n",
      "177/177 [==============================] - 0s 69us/step - loss: 0.0216 - accuracy: 0.9944 - val_loss: 2.3686 - val_accuracy: 0.5132\n",
      "Epoch 184/1000\n",
      "177/177 [==============================] - 0s 70us/step - loss: 0.0212 - accuracy: 1.0000 - val_loss: 2.3640 - val_accuracy: 0.5132\n",
      "Epoch 185/1000\n",
      "177/177 [==============================] - 0s 81us/step - loss: 0.0217 - accuracy: 1.0000 - val_loss: 2.3697 - val_accuracy: 0.5132\n",
      "Epoch 186/1000\n",
      "177/177 [==============================] - 0s 68us/step - loss: 0.0219 - accuracy: 0.9944 - val_loss: 2.3802 - val_accuracy: 0.5132\n",
      "Epoch 187/1000\n",
      "177/177 [==============================] - 0s 87us/step - loss: 0.0213 - accuracy: 0.9944 - val_loss: 2.3715 - val_accuracy: 0.5132\n",
      "Epoch 188/1000\n",
      "177/177 [==============================] - 0s 84us/step - loss: 0.0216 - accuracy: 1.0000 - val_loss: 2.3700 - val_accuracy: 0.5132\n",
      "Epoch 189/1000\n",
      "177/177 [==============================] - 0s 75us/step - loss: 0.0208 - accuracy: 1.0000 - val_loss: 2.3798 - val_accuracy: 0.5132\n",
      "Epoch 190/1000\n",
      "177/177 [==============================] - 0s 82us/step - loss: 0.0230 - accuracy: 0.9944 - val_loss: 2.3765 - val_accuracy: 0.5132\n",
      "Epoch 191/1000\n",
      "177/177 [==============================] - 0s 79us/step - loss: 0.0212 - accuracy: 1.0000 - val_loss: 2.3676 - val_accuracy: 0.5263\n",
      "Epoch 192/1000\n",
      "177/177 [==============================] - 0s 70us/step - loss: 0.0251 - accuracy: 0.9944 - val_loss: 2.3864 - val_accuracy: 0.5263\n",
      "Epoch 193/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.0218 - accuracy: 0.9944 - val_loss: 2.4120 - val_accuracy: 0.5132\n",
      "Epoch 194/1000\n",
      "177/177 [==============================] - 0s 58us/step - loss: 0.0332 - accuracy: 0.9887 - val_loss: 2.3705 - val_accuracy: 0.5132\n",
      "Epoch 195/1000\n",
      "177/177 [==============================] - 0s 74us/step - loss: 0.0428 - accuracy: 0.9944 - val_loss: 2.3548 - val_accuracy: 0.5132\n",
      "Epoch 196/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.0309 - accuracy: 0.9944 - val_loss: 2.3862 - val_accuracy: 0.5263\n",
      "Epoch 197/1000\n",
      "177/177 [==============================] - 0s 60us/step - loss: 0.0305 - accuracy: 0.9887 - val_loss: 2.4220 - val_accuracy: 0.5263\n",
      "Epoch 198/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.0564 - accuracy: 0.9887 - val_loss: 2.3919 - val_accuracy: 0.5263\n",
      "Epoch 199/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.0242 - accuracy: 1.0000 - val_loss: 2.3813 - val_accuracy: 0.5132\n",
      "Epoch 200/1000\n",
      "177/177 [==============================] - 0s 77us/step - loss: 0.0527 - accuracy: 0.9887 - val_loss: 2.4649 - val_accuracy: 0.5132\n",
      "Epoch 201/1000\n",
      "177/177 [==============================] - 0s 68us/step - loss: 0.0677 - accuracy: 0.9887 - val_loss: 2.4637 - val_accuracy: 0.5132\n",
      "Epoch 202/1000\n",
      "177/177 [==============================] - 0s 57us/step - loss: 0.1131 - accuracy: 0.9718 - val_loss: 2.3535 - val_accuracy: 0.5263\n",
      "Epoch 203/1000\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.1227 - accuracy: 0.9718 - val_loss: 2.4756 - val_accuracy: 0.5132\n",
      "Epoch 204/1000\n",
      "177/177 [==============================] - 0s 63us/step - loss: 0.1427 - accuracy: 0.9774 - val_loss: 2.7683 - val_accuracy: 0.5132\n",
      "Epoch 205/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.1912 - accuracy: 0.9718 - val_loss: 2.5473 - val_accuracy: 0.5000\n",
      "Epoch 206/1000\n",
      "177/177 [==============================] - 0s 120us/step - loss: 0.0815 - accuracy: 0.9887 - val_loss: 2.3898 - val_accuracy: 0.5132\n",
      "Epoch 207/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.1429 - accuracy: 0.9774 - val_loss: 2.4342 - val_accuracy: 0.5000\n",
      "Epoch 208/1000\n",
      "177/177 [==============================] - 0s 53us/step - loss: 0.0889 - accuracy: 0.9831 - val_loss: 2.4025 - val_accuracy: 0.5000\n",
      "Epoch 209/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.0426 - accuracy: 0.9887 - val_loss: 2.3771 - val_accuracy: 0.5263\n",
      "Epoch 210/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.0323 - accuracy: 0.9887 - val_loss: 2.4384 - val_accuracy: 0.5132\n",
      "Epoch 211/1000\n",
      "177/177 [==============================] - 0s 82us/step - loss: 0.0924 - accuracy: 0.9831 - val_loss: 2.4172 - val_accuracy: 0.5263\n",
      "Epoch 212/1000\n",
      "177/177 [==============================] - 0s 81us/step - loss: 0.0533 - accuracy: 0.9831 - val_loss: 2.3825 - val_accuracy: 0.5263\n",
      "Epoch 213/1000\n",
      "177/177 [==============================] - 0s 100us/step - loss: 0.0502 - accuracy: 0.9831 - val_loss: 2.6012 - val_accuracy: 0.5132\n",
      "Epoch 214/1000\n",
      "177/177 [==============================] - 0s 243us/step - loss: 0.0910 - accuracy: 0.9831 - val_loss: 2.4327 - val_accuracy: 0.5132\n",
      "Epoch 215/1000\n",
      "177/177 [==============================] - 0s 79us/step - loss: 0.0491 - accuracy: 0.9887 - val_loss: 2.4137 - val_accuracy: 0.5263\n",
      "Epoch 216/1000\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.0472 - accuracy: 0.9887 - val_loss: 2.4429 - val_accuracy: 0.5263\n",
      "Epoch 217/1000\n",
      "177/177 [==============================] - 0s 78us/step - loss: 0.0776 - accuracy: 0.9831 - val_loss: 2.5279 - val_accuracy: 0.5132\n",
      "Epoch 218/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.0648 - accuracy: 0.9774 - val_loss: 2.4383 - val_accuracy: 0.5263\n",
      "Epoch 219/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.2474 - accuracy: 0.9548 - val_loss: 2.3643 - val_accuracy: 0.5263\n",
      "Epoch 220/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.2103 - accuracy: 0.9661 - val_loss: 2.4456 - val_accuracy: 0.5263\n",
      "Epoch 221/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.1322 - accuracy: 0.9718 - val_loss: 2.8658 - val_accuracy: 0.5132\n",
      "Epoch 222/1000\n",
      "177/177 [==============================] - 0s 75us/step - loss: 0.2465 - accuracy: 0.9661 - val_loss: 2.6632 - val_accuracy: 0.5132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 223/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.1969 - accuracy: 0.9831 - val_loss: 2.4336 - val_accuracy: 0.5132\n",
      "Epoch 224/1000\n",
      "177/177 [==============================] - 0s 56us/step - loss: 0.1117 - accuracy: 0.9831 - val_loss: 2.4052 - val_accuracy: 0.5132\n",
      "Epoch 225/1000\n",
      "177/177 [==============================] - 0s 55us/step - loss: 0.0445 - accuracy: 0.9831 - val_loss: 2.5071 - val_accuracy: 0.5000\n",
      "Epoch 226/1000\n",
      "177/177 [==============================] - 0s 51us/step - loss: 0.1614 - accuracy: 0.9661 - val_loss: 2.5845 - val_accuracy: 0.5132\n",
      "Epoch 227/1000\n",
      "177/177 [==============================] - 0s 54us/step - loss: 0.0670 - accuracy: 0.9831 - val_loss: 2.4216 - val_accuracy: 0.5395\n",
      "Epoch 228/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.0977 - accuracy: 0.9887 - val_loss: 2.4246 - val_accuracy: 0.5263\n",
      "Epoch 229/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.1214 - accuracy: 0.9831 - val_loss: 2.4262 - val_accuracy: 0.5395\n",
      "Epoch 230/1000\n",
      "177/177 [==============================] - ETA: 0s - loss: 0.1002 - accuracy: 0.98 - 0s 75us/step - loss: 0.0559 - accuracy: 0.9887 - val_loss: 2.5976 - val_accuracy: 0.5000\n",
      "Epoch 231/1000\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.1579 - accuracy: 0.9718 - val_loss: 2.5071 - val_accuracy: 0.5000\n",
      "Epoch 232/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.0626 - accuracy: 0.9774 - val_loss: 2.4173 - val_accuracy: 0.5263\n",
      "Epoch 233/1000\n",
      "177/177 [==============================] - 0s 69us/step - loss: 0.1335 - accuracy: 0.9774 - val_loss: 2.4085 - val_accuracy: 0.5263\n",
      "Epoch 234/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.0939 - accuracy: 0.9944 - val_loss: 2.5684 - val_accuracy: 0.5263\n",
      "Epoch 235/1000\n",
      "177/177 [==============================] - ETA: 0s - loss: 0.0359 - accuracy: 0.98 - 0s 62us/step - loss: 0.1127 - accuracy: 0.9831 - val_loss: 2.5006 - val_accuracy: 0.5132\n",
      "Epoch 236/1000\n",
      "177/177 [==============================] - 0s 92us/step - loss: 0.0242 - accuracy: 0.9944 - val_loss: 2.4227 - val_accuracy: 0.5263\n",
      "Epoch 237/1000\n",
      "177/177 [==============================] - 0s 86us/step - loss: 0.0560 - accuracy: 0.9831 - val_loss: 2.4135 - val_accuracy: 0.5395\n",
      "Epoch 238/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.0365 - accuracy: 0.9887 - val_loss: 2.5328 - val_accuracy: 0.5132\n",
      "Epoch 239/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.0435 - accuracy: 0.9831 - val_loss: 2.4838 - val_accuracy: 0.5132\n",
      "Epoch 240/1000\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.0313 - accuracy: 0.9887 - val_loss: 2.4323 - val_accuracy: 0.5263\n",
      "Epoch 241/1000\n",
      "177/177 [==============================] - 0s 69us/step - loss: 0.0208 - accuracy: 0.9944 - val_loss: 2.4539 - val_accuracy: 0.5263\n",
      "Epoch 242/1000\n",
      "177/177 [==============================] - 0s 81us/step - loss: 0.0316 - accuracy: 0.9887 - val_loss: 2.4388 - val_accuracy: 0.5263\n",
      "Epoch 243/1000\n",
      "177/177 [==============================] - 0s 100us/step - loss: 0.0212 - accuracy: 0.9944 - val_loss: 2.4226 - val_accuracy: 0.5263\n",
      "Epoch 244/1000\n",
      "177/177 [==============================] - 0s 93us/step - loss: 0.0300 - accuracy: 0.9887 - val_loss: 2.4552 - val_accuracy: 0.5263\n",
      "Epoch 245/1000\n",
      "177/177 [==============================] - 0s 75us/step - loss: 0.0405 - accuracy: 0.9887 - val_loss: 2.4578 - val_accuracy: 0.5395\n",
      "Epoch 246/1000\n",
      "177/177 [==============================] - 0s 83us/step - loss: 0.0332 - accuracy: 0.9887 - val_loss: 2.4374 - val_accuracy: 0.5395\n",
      "Epoch 247/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.0212 - accuracy: 0.9944 - val_loss: 2.5473 - val_accuracy: 0.5132\n",
      "Epoch 248/1000\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.0787 - accuracy: 0.9831 - val_loss: 2.4595 - val_accuracy: 0.5263\n",
      "Epoch 249/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.0716 - accuracy: 0.9774 - val_loss: 2.4210 - val_accuracy: 0.5395\n",
      "Epoch 250/1000\n",
      "177/177 [==============================] - 0s 49us/step - loss: 0.0864 - accuracy: 0.9774 - val_loss: 2.6311 - val_accuracy: 0.5132\n",
      "Epoch 251/1000\n",
      "177/177 [==============================] - 0s 49us/step - loss: 0.0886 - accuracy: 0.9831 - val_loss: 2.4474 - val_accuracy: 0.5395\n",
      "Epoch 252/1000\n",
      "177/177 [==============================] - 0s 52us/step - loss: 0.0476 - accuracy: 0.9944 - val_loss: 2.4330 - val_accuracy: 0.5263\n",
      "Epoch 253/1000\n",
      "177/177 [==============================] - 0s 50us/step - loss: 0.0263 - accuracy: 0.9944 - val_loss: 2.4701 - val_accuracy: 0.5132\n",
      "Epoch 254/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.0490 - accuracy: 0.9887 - val_loss: 2.4859 - val_accuracy: 0.5000\n",
      "Epoch 255/1000\n",
      "177/177 [==============================] - 0s 56us/step - loss: 0.0201 - accuracy: 0.9944 - val_loss: 2.4529 - val_accuracy: 0.5132\n",
      "Epoch 256/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.0412 - accuracy: 0.9887 - val_loss: 2.4693 - val_accuracy: 0.5132\n",
      "Epoch 257/1000\n",
      "177/177 [==============================] - 0s 70us/step - loss: 0.0209 - accuracy: 0.9944 - val_loss: 2.4803 - val_accuracy: 0.5132\n",
      "Epoch 258/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.0213 - accuracy: 0.9944 - val_loss: 2.4669 - val_accuracy: 0.5132\n",
      "Epoch 259/1000\n",
      "177/177 [==============================] - 0s 58us/step - loss: 0.0241 - accuracy: 0.9887 - val_loss: 2.4582 - val_accuracy: 0.5395\n",
      "Epoch 260/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.0194 - accuracy: 0.9944 - val_loss: 2.4738 - val_accuracy: 0.5132\n",
      "Epoch 261/1000\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.0285 - accuracy: 0.9887 - val_loss: 2.4674 - val_accuracy: 0.5263\n",
      "Epoch 262/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.0327 - accuracy: 0.9887 - val_loss: 2.4556 - val_accuracy: 0.5263\n",
      "Epoch 263/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.0224 - accuracy: 0.9944 - val_loss: 2.5349 - val_accuracy: 0.5132\n",
      "Epoch 264/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.0446 - accuracy: 0.9887 - val_loss: 2.4737 - val_accuracy: 0.5263\n",
      "Epoch 265/1000\n",
      "177/177 [==============================] - 0s 78us/step - loss: 0.0184 - accuracy: 0.9944 - val_loss: 2.4601 - val_accuracy: 0.5263\n",
      "Epoch 266/1000\n",
      "177/177 [==============================] - 0s 87us/step - loss: 0.0224 - accuracy: 1.0000 - val_loss: 2.4673 - val_accuracy: 0.5263\n",
      "Epoch 267/1000\n",
      "177/177 [==============================] - 0s 69us/step - loss: 0.0191 - accuracy: 0.9944 - val_loss: 2.4857 - val_accuracy: 0.5263\n",
      "Epoch 268/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.0232 - accuracy: 0.9887 - val_loss: 2.4834 - val_accuracy: 0.5263\n",
      "Epoch 269/1000\n",
      "177/177 [==============================] - 0s 75us/step - loss: 0.0205 - accuracy: 0.9944 - val_loss: 2.4728 - val_accuracy: 0.5132\n",
      "Epoch 270/1000\n",
      "177/177 [==============================] - 0s 118us/step - loss: 0.0334 - accuracy: 0.9887 - val_loss: 2.4802 - val_accuracy: 0.5263\n",
      "Epoch 271/1000\n",
      "177/177 [==============================] - 0s 150us/step - loss: 0.0252 - accuracy: 0.9887 - val_loss: 2.5246 - val_accuracy: 0.5132\n",
      "Epoch 272/1000\n",
      "177/177 [==============================] - 0s 103us/step - loss: 0.0340 - accuracy: 0.9887 - val_loss: 2.4804 - val_accuracy: 0.5263\n",
      "Epoch 273/1000\n",
      "177/177 [==============================] - 0s 97us/step - loss: 0.0526 - accuracy: 0.9944 - val_loss: 2.4540 - val_accuracy: 0.5263\n",
      "Epoch 274/1000\n",
      "177/177 [==============================] - 0s 119us/step - loss: 0.0237 - accuracy: 1.0000 - val_loss: 2.4894 - val_accuracy: 0.5263\n",
      "Epoch 275/1000\n",
      "177/177 [==============================] - 0s 109us/step - loss: 0.0187 - accuracy: 0.9944 - val_loss: 2.5752 - val_accuracy: 0.5132\n",
      "Epoch 276/1000\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.0533 - accuracy: 0.9887 - val_loss: 2.4978 - val_accuracy: 0.5263\n",
      "Epoch 277/1000\n",
      "177/177 [==============================] - 0s 125us/step - loss: 0.0205 - accuracy: 0.9944 - val_loss: 2.4824 - val_accuracy: 0.5263\n",
      "Epoch 278/1000\n",
      "177/177 [==============================] - 0s 78us/step - loss: 0.0192 - accuracy: 0.9944 - val_loss: 2.4997 - val_accuracy: 0.5263\n",
      "Epoch 279/1000\n",
      "177/177 [==============================] - 0s 96us/step - loss: 0.0189 - accuracy: 0.9944 - val_loss: 2.5057 - val_accuracy: 0.5132\n",
      "Epoch 280/1000\n",
      "177/177 [==============================] - 0s 86us/step - loss: 0.0187 - accuracy: 0.9944 - val_loss: 2.4913 - val_accuracy: 0.5263\n",
      "Epoch 281/1000\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.0182 - accuracy: 0.9944 - val_loss: 2.4862 - val_accuracy: 0.5263\n",
      "Epoch 282/1000\n",
      "177/177 [==============================] - 0s 76us/step - loss: 0.0184 - accuracy: 0.9944 - val_loss: 2.4972 - val_accuracy: 0.5263\n",
      "Epoch 283/1000\n",
      "177/177 [==============================] - 0s 93us/step - loss: 0.0181 - accuracy: 0.9944 - val_loss: 2.5098 - val_accuracy: 0.5132\n",
      "Epoch 284/1000\n",
      "177/177 [==============================] - 0s 120us/step - loss: 0.0181 - accuracy: 0.9944 - val_loss: 2.4983 - val_accuracy: 0.5263\n",
      "Epoch 285/1000\n",
      "177/177 [==============================] - 0s 125us/step - loss: 0.0178 - accuracy: 0.9944 - val_loss: 2.4918 - val_accuracy: 0.5263\n",
      "Epoch 286/1000\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.0178 - accuracy: 1.0000 - val_loss: 2.4915 - val_accuracy: 0.5132\n",
      "Epoch 287/1000\n",
      "177/177 [==============================] - 0s 68us/step - loss: 0.0179 - accuracy: 0.9944 - val_loss: 2.4964 - val_accuracy: 0.5132\n",
      "Epoch 288/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.0176 - accuracy: 0.9944 - val_loss: 2.4960 - val_accuracy: 0.5132\n",
      "Epoch 289/1000\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.0177 - accuracy: 0.9944 - val_loss: 2.5000 - val_accuracy: 0.5132\n",
      "Epoch 290/1000\n",
      "177/177 [==============================] - 0s 69us/step - loss: 0.0178 - accuracy: 0.9944 - val_loss: 2.4954 - val_accuracy: 0.5132\n",
      "Epoch 291/1000\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.0178 - accuracy: 0.9944 - val_loss: 2.5052 - val_accuracy: 0.5263\n",
      "Epoch 292/1000\n",
      "177/177 [==============================] - 0s 70us/step - loss: 0.0176 - accuracy: 0.9944 - val_loss: 2.5076 - val_accuracy: 0.5263\n",
      "Epoch 293/1000\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.0175 - accuracy: 1.0000 - val_loss: 2.5009 - val_accuracy: 0.5263\n",
      "Epoch 294/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.0178 - accuracy: 1.0000 - val_loss: 2.4971 - val_accuracy: 0.5263\n",
      "Epoch 295/1000\n",
      "177/177 [==============================] - 0s 92us/step - loss: 0.0175 - accuracy: 1.0000 - val_loss: 2.4993 - val_accuracy: 0.5132\n",
      "Epoch 296/1000\n",
      "177/177 [==============================] - 0s 69us/step - loss: 0.0180 - accuracy: 0.9944 - val_loss: 2.5098 - val_accuracy: 0.5000\n",
      "Epoch 297/1000\n",
      "177/177 [==============================] - 0s 81us/step - loss: 0.0175 - accuracy: 0.9944 - val_loss: 2.5077 - val_accuracy: 0.5132\n",
      "Epoch 298/1000\n",
      "177/177 [==============================] - 0s 81us/step - loss: 0.0174 - accuracy: 0.9944 - val_loss: 2.5090 - val_accuracy: 0.5132\n",
      "Epoch 299/1000\n",
      "177/177 [==============================] - 0s 85us/step - loss: 0.0175 - accuracy: 0.9944 - val_loss: 2.5069 - val_accuracy: 0.5132\n",
      "Epoch 300/1000\n",
      "177/177 [==============================] - 0s 107us/step - loss: 0.0175 - accuracy: 0.9944 - val_loss: 2.5082 - val_accuracy: 0.5132\n",
      "Epoch 301/1000\n",
      "177/177 [==============================] - 0s 76us/step - loss: 0.0177 - accuracy: 0.9944 - val_loss: 2.5021 - val_accuracy: 0.5132\n",
      "Epoch 302/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 2.5057 - val_accuracy: 0.5132\n",
      "Epoch 303/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 2.5056 - val_accuracy: 0.5132\n",
      "Epoch 304/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.0171 - accuracy: 1.0000 - val_loss: 2.5064 - val_accuracy: 0.5132\n",
      "Epoch 305/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.0172 - accuracy: 0.9944 - val_loss: 2.5136 - val_accuracy: 0.5132\n",
      "Epoch 306/1000\n",
      "177/177 [==============================] - 0s 56us/step - loss: 0.0175 - accuracy: 0.9944 - val_loss: 2.5158 - val_accuracy: 0.5132\n",
      "Epoch 307/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.0171 - accuracy: 0.9944 - val_loss: 2.5117 - val_accuracy: 0.5132\n",
      "Epoch 308/1000\n",
      "177/177 [==============================] - 0s 57us/step - loss: 0.0170 - accuracy: 1.0000 - val_loss: 2.5106 - val_accuracy: 0.5132\n",
      "Epoch 309/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 2.5124 - val_accuracy: 0.5132\n",
      "Epoch 310/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.0175 - accuracy: 1.0000 - val_loss: 2.5113 - val_accuracy: 0.5263\n",
      "Epoch 311/1000\n",
      "177/177 [==============================] - 0s 59us/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 2.5169 - val_accuracy: 0.5263\n",
      "Epoch 312/1000\n",
      "177/177 [==============================] - 0s 58us/step - loss: 0.0170 - accuracy: 0.9944 - val_loss: 2.5198 - val_accuracy: 0.5263\n",
      "Epoch 313/1000\n",
      "177/177 [==============================] - 0s 59us/step - loss: 0.0175 - accuracy: 0.9944 - val_loss: 2.5235 - val_accuracy: 0.5263\n",
      "Epoch 314/1000\n",
      "177/177 [==============================] - 0s 58us/step - loss: 0.0173 - accuracy: 0.9944 - val_loss: 2.5162 - val_accuracy: 0.5132\n",
      "Epoch 315/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.0171 - accuracy: 1.0000 - val_loss: 2.5164 - val_accuracy: 0.5132\n",
      "Epoch 316/1000\n",
      "177/177 [==============================] - 0s 58us/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 2.5210 - val_accuracy: 0.5263\n",
      "Epoch 317/1000\n",
      "177/177 [==============================] - 0s 60us/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 2.5191 - val_accuracy: 0.5263\n",
      "Epoch 318/1000\n",
      "177/177 [==============================] - 0s 69us/step - loss: 0.0173 - accuracy: 0.9944 - val_loss: 2.5273 - val_accuracy: 0.5263\n",
      "Epoch 319/1000\n",
      "177/177 [==============================] - 0s 69us/step - loss: 0.0168 - accuracy: 0.9944 - val_loss: 2.5341 - val_accuracy: 0.5132\n",
      "Epoch 320/1000\n",
      "177/177 [==============================] - 0s 82us/step - loss: 0.0169 - accuracy: 0.9944 - val_loss: 2.5355 - val_accuracy: 0.5132\n",
      "Epoch 321/1000\n",
      "177/177 [==============================] - 0s 104us/step - loss: 0.0168 - accuracy: 0.9944 - val_loss: 2.5283 - val_accuracy: 0.5263\n",
      "Epoch 322/1000\n",
      "177/177 [==============================] - 0s 104us/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 2.5226 - val_accuracy: 0.5263\n",
      "Epoch 323/1000\n",
      "177/177 [==============================] - 0s 106us/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 2.5252 - val_accuracy: 0.5263\n",
      "Epoch 324/1000\n",
      "177/177 [==============================] - 0s 121us/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 2.5280 - val_accuracy: 0.5263\n",
      "Epoch 325/1000\n",
      "177/177 [==============================] - 0s 109us/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 2.5266 - val_accuracy: 0.5263\n",
      "Epoch 326/1000\n",
      "177/177 [==============================] - 0s 113us/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 2.5257 - val_accuracy: 0.5132\n",
      "Epoch 327/1000\n",
      "177/177 [==============================] - 0s 99us/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 2.5291 - val_accuracy: 0.5132\n",
      "Epoch 328/1000\n",
      "177/177 [==============================] - 0s 116us/step - loss: 0.0166 - accuracy: 0.9944 - val_loss: 2.5436 - val_accuracy: 0.5132\n",
      "Epoch 329/1000\n",
      "177/177 [==============================] - 0s 121us/step - loss: 0.0167 - accuracy: 0.9944 - val_loss: 2.5388 - val_accuracy: 0.5263\n",
      "Epoch 330/1000\n",
      "177/177 [==============================] - 0s 104us/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 2.5323 - val_accuracy: 0.5263\n",
      "Epoch 331/1000\n",
      "177/177 [==============================] - 0s 115us/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 2.5374 - val_accuracy: 0.5263\n",
      "Epoch 332/1000\n",
      "177/177 [==============================] - 0s 78us/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 2.5320 - val_accuracy: 0.5263\n",
      "Epoch 333/1000\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.0168 - accuracy: 1.0000 - val_loss: 2.5291 - val_accuracy: 0.5263\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 334/1000\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 2.5377 - val_accuracy: 0.5263\n",
      "Epoch 335/1000\n",
      "177/177 [==============================] - 0s 94us/step - loss: 0.0160 - accuracy: 1.0000 - val_loss: 2.5452 - val_accuracy: 0.5263\n",
      "Epoch 336/1000\n",
      "177/177 [==============================] - 0s 101us/step - loss: 0.0172 - accuracy: 1.0000 - val_loss: 2.5470 - val_accuracy: 0.5263\n",
      "Epoch 337/1000\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 2.5346 - val_accuracy: 0.5263\n",
      "Epoch 338/1000\n",
      "177/177 [==============================] - 0s 110us/step - loss: 0.0172 - accuracy: 1.0000 - val_loss: 2.5438 - val_accuracy: 0.5263\n",
      "Epoch 339/1000\n",
      "177/177 [==============================] - 0s 131us/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 2.5522 - val_accuracy: 0.5263\n",
      "Epoch 340/1000\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.0162 - accuracy: 1.0000 - val_loss: 2.5463 - val_accuracy: 0.5263\n",
      "Epoch 341/1000\n",
      "177/177 [==============================] - 0s 122us/step - loss: 0.0162 - accuracy: 1.0000 - val_loss: 2.5438 - val_accuracy: 0.5263\n",
      "Epoch 342/1000\n",
      "177/177 [==============================] - 0s 85us/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 2.5498 - val_accuracy: 0.5263\n",
      "Epoch 343/1000\n",
      "177/177 [==============================] - 0s 83us/step - loss: 0.0159 - accuracy: 1.0000 - val_loss: 2.5587 - val_accuracy: 0.5263\n",
      "Epoch 344/1000\n",
      "177/177 [==============================] - 0s 86us/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 2.5590 - val_accuracy: 0.5263\n",
      "Epoch 345/1000\n",
      "177/177 [==============================] - 0s 97us/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 2.5468 - val_accuracy: 0.5263\n",
      "Epoch 346/1000\n",
      "177/177 [==============================] - 0s 87us/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 2.5510 - val_accuracy: 0.5263\n",
      "Epoch 347/1000\n",
      "177/177 [==============================] - 0s 93us/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 2.5656 - val_accuracy: 0.5132\n",
      "Epoch 348/1000\n",
      "177/177 [==============================] - 0s 94us/step - loss: 0.0171 - accuracy: 1.0000 - val_loss: 2.5539 - val_accuracy: 0.5132\n",
      "Epoch 349/1000\n",
      "177/177 [==============================] - 0s 93us/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 2.5523 - val_accuracy: 0.5132\n",
      "Epoch 350/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 2.5486 - val_accuracy: 0.5263\n",
      "Epoch 351/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.0162 - accuracy: 1.0000 - val_loss: 2.5525 - val_accuracy: 0.5263\n",
      "Epoch 352/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 2.5586 - val_accuracy: 0.5132\n",
      "Epoch 353/1000\n",
      "177/177 [==============================] - 0s 63us/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 2.5570 - val_accuracy: 0.5132\n",
      "Epoch 354/1000\n",
      "177/177 [==============================] - 0s 63us/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 2.5541 - val_accuracy: 0.5263\n",
      "Epoch 355/1000\n",
      "177/177 [==============================] - 0s 63us/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 2.5515 - val_accuracy: 0.5263\n",
      "Epoch 356/1000\n",
      "177/177 [==============================] - 0s 63us/step - loss: 0.0160 - accuracy: 1.0000 - val_loss: 2.5576 - val_accuracy: 0.5263\n",
      "Epoch 357/1000\n",
      "177/177 [==============================] - 0s 60us/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 2.5594 - val_accuracy: 0.5263\n",
      "Epoch 358/1000\n",
      "177/177 [==============================] - 0s 59us/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 2.5606 - val_accuracy: 0.5263\n",
      "Epoch 359/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 2.5572 - val_accuracy: 0.5263\n",
      "Epoch 360/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 2.5605 - val_accuracy: 0.5263\n",
      "Epoch 361/1000\n",
      "177/177 [==============================] - 0s 56us/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 2.5655 - val_accuracy: 0.5132\n",
      "Epoch 362/1000\n",
      "177/177 [==============================] - 0s 60us/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 2.5673 - val_accuracy: 0.5132\n",
      "Epoch 363/1000\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 2.5692 - val_accuracy: 0.5132\n",
      "Epoch 364/1000\n",
      "177/177 [==============================] - 0s 69us/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 2.5587 - val_accuracy: 0.5132\n",
      "Epoch 365/1000\n",
      "177/177 [==============================] - 0s 58us/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 2.5620 - val_accuracy: 0.5263\n",
      "Epoch 366/1000\n",
      "177/177 [==============================] - 0s 56us/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 2.5790 - val_accuracy: 0.5263\n",
      "Epoch 367/1000\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 2.5705 - val_accuracy: 0.5263\n",
      "Epoch 368/1000\n",
      "177/177 [==============================] - 0s 59us/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 2.5670 - val_accuracy: 0.5263\n",
      "Epoch 369/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 2.5677 - val_accuracy: 0.5263\n",
      "Epoch 370/1000\n",
      "177/177 [==============================] - 0s 74us/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 2.5816 - val_accuracy: 0.5132\n",
      "Epoch 371/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 2.5710 - val_accuracy: 0.5263\n",
      "Epoch 372/1000\n",
      "177/177 [==============================] - 0s 75us/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 2.5686 - val_accuracy: 0.5263\n",
      "Epoch 373/1000\n",
      "177/177 [==============================] - 0s 81us/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 2.5738 - val_accuracy: 0.5132\n",
      "Epoch 374/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 2.5756 - val_accuracy: 0.5132\n",
      "Epoch 375/1000\n",
      "177/177 [==============================] - 0s 57us/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 2.5736 - val_accuracy: 0.5132\n",
      "Epoch 376/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 2.5674 - val_accuracy: 0.5263\n",
      "Epoch 377/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.0159 - accuracy: 1.0000 - val_loss: 2.5734 - val_accuracy: 0.5263\n",
      "Epoch 378/1000\n",
      "177/177 [==============================] - 0s 60us/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 2.5844 - val_accuracy: 0.5263\n",
      "Epoch 379/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 2.5711 - val_accuracy: 0.5263\n",
      "Epoch 380/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 2.5722 - val_accuracy: 0.5263\n",
      "Epoch 381/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 2.5854 - val_accuracy: 0.5263\n",
      "Epoch 382/1000\n",
      "177/177 [==============================] - 0s 69us/step - loss: 0.0183 - accuracy: 1.0000 - val_loss: 2.5805 - val_accuracy: 0.5263\n",
      "Epoch 383/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.0181 - accuracy: 1.0000 - val_loss: 2.5803 - val_accuracy: 0.5263\n",
      "Epoch 384/1000\n",
      "177/177 [==============================] - 0s 69us/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 2.6180 - val_accuracy: 0.5132\n",
      "Epoch 385/1000\n",
      "177/177 [==============================] - 0s 77us/step - loss: 0.0196 - accuracy: 0.9944 - val_loss: 2.5787 - val_accuracy: 0.5263\n",
      "Epoch 386/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.0183 - accuracy: 1.0000 - val_loss: 2.5842 - val_accuracy: 0.5263\n",
      "Epoch 387/1000\n",
      "177/177 [==============================] - 0s 83us/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 2.6044 - val_accuracy: 0.5263\n",
      "Epoch 388/1000\n",
      "177/177 [==============================] - 0s 68us/step - loss: 0.0195 - accuracy: 0.9944 - val_loss: 2.5815 - val_accuracy: 0.5132\n",
      "Epoch 389/1000\n",
      "177/177 [==============================] - 0s 70us/step - loss: 0.0177 - accuracy: 1.0000 - val_loss: 2.5879 - val_accuracy: 0.5132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 390/1000\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 2.6194 - val_accuracy: 0.5132\n",
      "Epoch 391/1000\n",
      "177/177 [==============================] - 0s 60us/step - loss: 0.0217 - accuracy: 0.9944 - val_loss: 2.5875 - val_accuracy: 0.5263\n",
      "Epoch 392/1000\n",
      "177/177 [==============================] - 0s 57us/step - loss: 0.0230 - accuracy: 0.9944 - val_loss: 2.5931 - val_accuracy: 0.5132\n",
      "Epoch 393/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 2.6244 - val_accuracy: 0.5000\n",
      "Epoch 394/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.0252 - accuracy: 0.9944 - val_loss: 2.5840 - val_accuracy: 0.5132\n",
      "Epoch 395/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.0271 - accuracy: 0.9944 - val_loss: 2.5872 - val_accuracy: 0.5263\n",
      "Epoch 396/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 2.6009 - val_accuracy: 0.5263\n",
      "Epoch 397/1000\n",
      "177/177 [==============================] - 0s 58us/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 2.6001 - val_accuracy: 0.5263\n",
      "Epoch 398/1000\n",
      "177/177 [==============================] - 0s 69us/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 2.5993 - val_accuracy: 0.5263\n",
      "Epoch 399/1000\n",
      "177/177 [==============================] - 0s 63us/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 2.6157 - val_accuracy: 0.5263\n",
      "Epoch 400/1000\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.0148 - accuracy: 0.9944 - val_loss: 2.6214 - val_accuracy: 0.5132\n",
      "Epoch 401/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 2.6093 - val_accuracy: 0.5263\n",
      "Epoch 402/1000\n",
      "177/177 [==============================] - 0s 60us/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 2.5936 - val_accuracy: 0.5263\n",
      "Epoch 403/1000\n",
      "177/177 [==============================] - 0s 59us/step - loss: 0.0188 - accuracy: 0.9944 - val_loss: 2.6074 - val_accuracy: 0.5132\n",
      "Epoch 404/1000\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.0176 - accuracy: 1.0000 - val_loss: 2.6092 - val_accuracy: 0.5132\n",
      "Epoch 405/1000\n",
      "177/177 [==============================] - 0s 60us/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 2.5975 - val_accuracy: 0.5132\n",
      "Epoch 406/1000\n",
      "177/177 [==============================] - 0s 57us/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 2.5971 - val_accuracy: 0.5132\n",
      "Epoch 407/1000\n",
      "177/177 [==============================] - 0s 58us/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 2.6086 - val_accuracy: 0.5263\n",
      "Epoch 408/1000\n",
      "177/177 [==============================] - 0s 68us/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 2.6188 - val_accuracy: 0.5263\n",
      "Epoch 409/1000\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 2.6134 - val_accuracy: 0.5263\n",
      "Epoch 410/1000\n",
      "177/177 [==============================] - 0s 56us/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 2.6131 - val_accuracy: 0.5263\n",
      "Epoch 411/1000\n",
      "177/177 [==============================] - 0s 56us/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 2.6123 - val_accuracy: 0.5263\n",
      "Epoch 412/1000\n",
      "177/177 [==============================] - 0s 55us/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 2.6207 - val_accuracy: 0.5263\n",
      "Epoch 413/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 2.6139 - val_accuracy: 0.5263\n",
      "Epoch 414/1000\n",
      "177/177 [==============================] - 0s 76us/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 2.6104 - val_accuracy: 0.5263\n",
      "Epoch 415/1000\n",
      "177/177 [==============================] - 0s 68us/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 2.6127 - val_accuracy: 0.5132\n",
      "Epoch 416/1000\n",
      "177/177 [==============================] - 0s 63us/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 2.6138 - val_accuracy: 0.5132\n",
      "Epoch 417/1000\n",
      "177/177 [==============================] - 0s 58us/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 2.6192 - val_accuracy: 0.5132\n",
      "Epoch 418/1000\n",
      "177/177 [==============================] - 0s 54us/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 2.6204 - val_accuracy: 0.5263\n",
      "Epoch 419/1000\n",
      "177/177 [==============================] - 0s 70us/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 2.6179 - val_accuracy: 0.5132\n",
      "Epoch 420/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 2.6115 - val_accuracy: 0.5132\n",
      "Epoch 421/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 2.6148 - val_accuracy: 0.5132\n",
      "Epoch 422/1000\n",
      "177/177 [==============================] - 0s 59us/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 2.6199 - val_accuracy: 0.5132\n",
      "Epoch 423/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 2.6133 - val_accuracy: 0.5132\n",
      "Epoch 424/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 2.6178 - val_accuracy: 0.5132\n",
      "Epoch 425/1000\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 2.6307 - val_accuracy: 0.5000\n",
      "Epoch 426/1000\n",
      "177/177 [==============================] - 0s 59us/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 2.6243 - val_accuracy: 0.5132\n",
      "Epoch 427/1000\n",
      "177/177 [==============================] - 0s 57us/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 2.6146 - val_accuracy: 0.5132\n",
      "Epoch 428/1000\n",
      "177/177 [==============================] - 0s 54us/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 2.6288 - val_accuracy: 0.5132\n",
      "Epoch 429/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 2.6243 - val_accuracy: 0.5132\n",
      "Epoch 430/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 2.6187 - val_accuracy: 0.5132\n",
      "Epoch 431/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 2.6220 - val_accuracy: 0.5132\n",
      "Epoch 432/1000\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 2.6302 - val_accuracy: 0.5132\n",
      "Epoch 433/1000\n",
      "177/177 [==============================] - 0s 55us/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 2.6316 - val_accuracy: 0.5132\n",
      "Epoch 434/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 2.6313 - val_accuracy: 0.5132\n",
      "Epoch 435/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 2.6277 - val_accuracy: 0.5132\n",
      "Epoch 436/1000\n",
      "177/177 [==============================] - 0s 58us/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 2.6303 - val_accuracy: 0.5132\n",
      "Epoch 437/1000\n",
      "177/177 [==============================] - 0s 68us/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 2.6287 - val_accuracy: 0.5132\n",
      "Epoch 438/1000\n",
      "177/177 [==============================] - 0s 63us/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 2.6266 - val_accuracy: 0.5132\n",
      "Epoch 439/1000\n",
      "177/177 [==============================] - 0s 58us/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 2.6251 - val_accuracy: 0.5132\n",
      "Epoch 440/1000\n",
      "177/177 [==============================] - 0s 57us/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 2.6311 - val_accuracy: 0.5132\n",
      "Epoch 441/1000\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 2.6366 - val_accuracy: 0.5132\n",
      "Epoch 442/1000\n",
      "177/177 [==============================] - 0s 59us/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 2.6443 - val_accuracy: 0.5263\n",
      "Epoch 443/1000\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 2.6485 - val_accuracy: 0.5263\n",
      "Epoch 444/1000\n",
      "177/177 [==============================] - 0s 63us/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 2.6448 - val_accuracy: 0.5263\n",
      "Epoch 445/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 2.6383 - val_accuracy: 0.5263\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 446/1000\n",
      "177/177 [==============================] - 0s 59us/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 2.6400 - val_accuracy: 0.5263\n",
      "Epoch 447/1000\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 2.6425 - val_accuracy: 0.5132\n",
      "Epoch 448/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 2.6416 - val_accuracy: 0.5263\n",
      "Epoch 449/1000\n",
      "177/177 [==============================] - 0s 58us/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 2.6440 - val_accuracy: 0.5132\n",
      "Epoch 450/1000\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 2.6429 - val_accuracy: 0.5132\n",
      "Epoch 451/1000\n",
      "177/177 [==============================] - 0s 60us/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 2.6435 - val_accuracy: 0.5132\n",
      "Epoch 452/1000\n",
      "177/177 [==============================] - 0s 74us/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 2.6507 - val_accuracy: 0.5132\n",
      "Epoch 453/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 2.6471 - val_accuracy: 0.5132\n",
      "Epoch 454/1000\n",
      "177/177 [==============================] - 0s 220us/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 2.6433 - val_accuracy: 0.5132\n",
      "Epoch 455/1000\n",
      "177/177 [==============================] - 0s 154us/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 2.6484 - val_accuracy: 0.5132\n",
      "Epoch 456/1000\n",
      "177/177 [==============================] - 0s 157us/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 2.6487 - val_accuracy: 0.5132\n",
      "Epoch 457/1000\n",
      "177/177 [==============================] - 0s 171us/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 2.6464 - val_accuracy: 0.5132\n",
      "Epoch 458/1000\n",
      "177/177 [==============================] - 0s 247us/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 2.6547 - val_accuracy: 0.5132\n",
      "Epoch 459/1000\n",
      "177/177 [==============================] - 0s 177us/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 2.6575 - val_accuracy: 0.5132\n",
      "Epoch 460/1000\n",
      "177/177 [==============================] - 0s 133us/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 2.6448 - val_accuracy: 0.5132\n",
      "Epoch 461/1000\n",
      "177/177 [==============================] - 0s 118us/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 2.6433 - val_accuracy: 0.5132\n",
      "Epoch 462/1000\n",
      "177/177 [==============================] - 0s 175us/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 2.6503 - val_accuracy: 0.5132\n",
      "Epoch 463/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 2.6580 - val_accuracy: 0.5132\n",
      "Epoch 464/1000\n",
      "177/177 [==============================] - 0s 228us/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 2.6662 - val_accuracy: 0.5132\n",
      "Epoch 465/1000\n",
      "177/177 [==============================] - 0s 194us/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 2.6654 - val_accuracy: 0.5132\n",
      "Epoch 466/1000\n",
      "177/177 [==============================] - 0s 248us/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 2.6684 - val_accuracy: 0.5263\n",
      "Epoch 467/1000\n",
      "177/177 [==============================] - 0s 102us/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 2.6728 - val_accuracy: 0.5263\n",
      "Epoch 468/1000\n",
      "177/177 [==============================] - 0s 109us/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 2.6671 - val_accuracy: 0.5132\n",
      "Epoch 469/1000\n",
      "177/177 [==============================] - 0s 95us/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 2.6579 - val_accuracy: 0.5132\n",
      "Epoch 470/1000\n",
      "177/177 [==============================] - 0s 121us/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 2.6619 - val_accuracy: 0.5132\n",
      "Epoch 471/1000\n",
      "177/177 [==============================] - 0s 99us/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 2.6635 - val_accuracy: 0.5132\n",
      "Epoch 472/1000\n",
      "177/177 [==============================] - 0s 86us/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 2.6604 - val_accuracy: 0.5132\n",
      "Epoch 473/1000\n",
      "177/177 [==============================] - 0s 84us/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 2.6656 - val_accuracy: 0.5132\n",
      "Epoch 474/1000\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 2.6691 - val_accuracy: 0.5132\n",
      "Epoch 475/1000\n",
      "177/177 [==============================] - 0s 79us/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 2.6702 - val_accuracy: 0.5132\n",
      "Epoch 476/1000\n",
      "177/177 [==============================] - 0s 85us/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 2.6708 - val_accuracy: 0.5132\n",
      "Epoch 477/1000\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 2.6688 - val_accuracy: 0.5132\n",
      "Epoch 478/1000\n",
      "177/177 [==============================] - 0s 75us/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 2.6695 - val_accuracy: 0.5132\n",
      "Epoch 479/1000\n",
      "177/177 [==============================] - 0s 92us/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 2.6644 - val_accuracy: 0.5132\n",
      "Epoch 480/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 2.6717 - val_accuracy: 0.5132\n",
      "Epoch 481/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 2.6731 - val_accuracy: 0.5132\n",
      "Epoch 482/1000\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 2.6683 - val_accuracy: 0.5132\n",
      "Epoch 483/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 2.6742 - val_accuracy: 0.5132\n",
      "Epoch 484/1000\n",
      "177/177 [==============================] - 0s 56us/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 2.6760 - val_accuracy: 0.5132\n",
      "Epoch 485/1000\n",
      "177/177 [==============================] - 0s 60us/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 2.6802 - val_accuracy: 0.5132\n",
      "Epoch 486/1000\n",
      "177/177 [==============================] - 0s 77us/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 2.6773 - val_accuracy: 0.5132\n",
      "Epoch 487/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 2.6817 - val_accuracy: 0.5132\n",
      "Epoch 488/1000\n",
      "177/177 [==============================] - 0s 59us/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 2.6827 - val_accuracy: 0.5132\n",
      "Epoch 489/1000\n",
      "177/177 [==============================] - 0s 281us/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 2.6774 - val_accuracy: 0.5132\n",
      "Epoch 490/1000\n",
      "177/177 [==============================] - 0s 144us/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 2.6692 - val_accuracy: 0.5132\n",
      "Epoch 491/1000\n",
      "177/177 [==============================] - 0s 132us/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 2.6770 - val_accuracy: 0.5132\n",
      "Epoch 492/1000\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 2.6838 - val_accuracy: 0.5132\n",
      "Epoch 493/1000\n",
      "177/177 [==============================] - 0s 439us/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 2.6864 - val_accuracy: 0.5132\n",
      "Epoch 494/1000\n",
      "177/177 [==============================] - 0s 77us/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 2.6824 - val_accuracy: 0.5132\n",
      "Epoch 495/1000\n",
      "177/177 [==============================] - 0s 92us/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 2.6857 - val_accuracy: 0.5132\n",
      "Epoch 496/1000\n",
      "177/177 [==============================] - 0s 83us/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 2.6814 - val_accuracy: 0.5132\n",
      "Epoch 497/1000\n",
      "177/177 [==============================] - 0s 120us/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 2.6809 - val_accuracy: 0.5132\n",
      "Epoch 498/1000\n",
      "177/177 [==============================] - 0s 174us/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 2.6811 - val_accuracy: 0.5132\n",
      "Epoch 499/1000\n",
      "177/177 [==============================] - 0s 785us/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 2.6828 - val_accuracy: 0.5132\n",
      "Epoch 500/1000\n",
      "177/177 [==============================] - 0s 389us/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 2.6917 - val_accuracy: 0.5132\n",
      "Epoch 501/1000\n",
      "177/177 [==============================] - 0s 179us/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 2.6967 - val_accuracy: 0.5132\n",
      "Epoch 502/1000\n",
      "177/177 [==============================] - 0s 106us/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 2.6921 - val_accuracy: 0.5132\n",
      "Epoch 503/1000\n",
      "177/177 [==============================] - 0s 150us/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 2.6832 - val_accuracy: 0.5132\n",
      "Epoch 504/1000\n",
      "177/177 [==============================] - 0s 152us/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 2.6910 - val_accuracy: 0.5132\n",
      "Epoch 505/1000\n",
      "177/177 [==============================] - 0s 230us/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 2.6905 - val_accuracy: 0.5132\n",
      "Epoch 506/1000\n",
      "177/177 [==============================] - 0s 149us/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 2.6861 - val_accuracy: 0.5132\n",
      "Epoch 507/1000\n",
      "177/177 [==============================] - 0s 594us/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 2.7037 - val_accuracy: 0.5132\n",
      "Epoch 508/1000\n",
      "177/177 [==============================] - 0s 75us/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 2.7105 - val_accuracy: 0.5132\n",
      "Epoch 509/1000\n",
      "177/177 [==============================] - 0s 94us/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 2.6939 - val_accuracy: 0.5132\n",
      "Epoch 510/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 2.6923 - val_accuracy: 0.5132\n",
      "Epoch 511/1000\n",
      "177/177 [==============================] - 0s 104us/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 2.6980 - val_accuracy: 0.5132\n",
      "Epoch 512/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 2.7035 - val_accuracy: 0.5132\n",
      "Epoch 513/1000\n",
      "177/177 [==============================] - 0s 169us/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 2.7008 - val_accuracy: 0.5132\n",
      "Epoch 514/1000\n",
      "177/177 [==============================] - 0s 160us/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 2.6948 - val_accuracy: 0.5132\n",
      "Epoch 515/1000\n",
      "177/177 [==============================] - 0s 146us/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 2.6997 - val_accuracy: 0.5132\n",
      "Epoch 516/1000\n",
      "177/177 [==============================] - 0s 171us/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 2.7085 - val_accuracy: 0.5132\n",
      "Epoch 517/1000\n",
      "177/177 [==============================] - 0s 97us/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 2.7047 - val_accuracy: 0.5132\n",
      "Epoch 518/1000\n",
      "177/177 [==============================] - 0s 112us/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 2.6950 - val_accuracy: 0.5132\n",
      "Epoch 519/1000\n",
      "177/177 [==============================] - 0s 87us/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 2.7030 - val_accuracy: 0.5132\n",
      "Epoch 520/1000\n",
      "177/177 [==============================] - 0s 79us/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 2.7237 - val_accuracy: 0.5000\n",
      "Epoch 521/1000\n",
      "177/177 [==============================] - 0s 121us/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 2.7015 - val_accuracy: 0.5132\n",
      "Epoch 522/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 2.7080 - val_accuracy: 0.5132\n",
      "Epoch 523/1000\n",
      "177/177 [==============================] - 0s 77us/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 2.7316 - val_accuracy: 0.5000\n",
      "Epoch 524/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.0163 - accuracy: 0.9944 - val_loss: 2.7009 - val_accuracy: 0.5132\n",
      "Epoch 525/1000\n",
      "177/177 [==============================] - 0s 57us/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 2.6963 - val_accuracy: 0.5132\n",
      "Epoch 526/1000\n",
      "177/177 [==============================] - 0s 63us/step - loss: 0.0204 - accuracy: 0.9944 - val_loss: 2.7486 - val_accuracy: 0.5000\n",
      "Epoch 527/1000\n",
      "177/177 [==============================] - 0s 56us/step - loss: 0.0327 - accuracy: 0.9944 - val_loss: 2.7142 - val_accuracy: 0.5132\n",
      "Epoch 528/1000\n",
      "177/177 [==============================] - 0s 55us/step - loss: 0.0256 - accuracy: 0.9944 - val_loss: 2.7132 - val_accuracy: 0.5132\n",
      "Epoch 529/1000\n",
      "177/177 [==============================] - 0s 55us/step - loss: 0.0497 - accuracy: 0.9944 - val_loss: 2.7371 - val_accuracy: 0.5132\n",
      "Epoch 530/1000\n",
      "177/177 [==============================] - 0s 63us/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 2.6865 - val_accuracy: 0.5132\n",
      "Epoch 531/1000\n",
      "177/177 [==============================] - 0s 57us/step - loss: 0.0441 - accuracy: 0.9944 - val_loss: 2.7197 - val_accuracy: 0.5132\n",
      "Epoch 532/1000\n",
      "177/177 [==============================] - 0s 70us/step - loss: 0.0240 - accuracy: 0.9944 - val_loss: 2.7218 - val_accuracy: 0.5132\n",
      "Epoch 533/1000\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.0205 - accuracy: 0.9944 - val_loss: 2.7104 - val_accuracy: 0.5132\n",
      "Epoch 534/1000\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 2.7218 - val_accuracy: 0.5132\n",
      "Epoch 535/1000\n",
      "177/177 [==============================] - 0s 139us/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 2.7462 - val_accuracy: 0.5132\n",
      "Epoch 536/1000\n",
      "177/177 [==============================] - 0s 84us/step - loss: 0.0224 - accuracy: 0.9944 - val_loss: 2.6994 - val_accuracy: 0.5132\n",
      "Epoch 537/1000\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.0412 - accuracy: 0.9944 - val_loss: 2.7219 - val_accuracy: 0.5132\n",
      "Epoch 538/1000\n",
      "177/177 [==============================] - 0s 131us/step - loss: 0.0288 - accuracy: 0.9944 - val_loss: 2.7338 - val_accuracy: 0.5132\n",
      "Epoch 539/1000\n",
      "177/177 [==============================] - 0s 63us/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 2.7022 - val_accuracy: 0.5000\n",
      "Epoch 540/1000\n",
      "177/177 [==============================] - 0s 68us/step - loss: 0.0794 - accuracy: 0.9944 - val_loss: 2.6988 - val_accuracy: 0.5132\n",
      "Epoch 541/1000\n",
      "177/177 [==============================] - 0s 96us/step - loss: 0.0492 - accuracy: 0.9887 - val_loss: 2.8333 - val_accuracy: 0.4868\n",
      "Epoch 542/1000\n",
      "177/177 [==============================] - 0s 89us/step - loss: 0.1034 - accuracy: 0.9887 - val_loss: 2.7560 - val_accuracy: 0.5132\n",
      "Epoch 543/1000\n",
      "177/177 [==============================] - 0s 75us/step - loss: 0.0402 - accuracy: 0.9887 - val_loss: 2.8744 - val_accuracy: 0.5000\n",
      "Epoch 544/1000\n",
      "177/177 [==============================] - 0s 111us/step - loss: 0.1412 - accuracy: 0.9831 - val_loss: 3.0771 - val_accuracy: 0.5132\n",
      "Epoch 545/1000\n",
      "177/177 [==============================] - 0s 69us/step - loss: 0.1348 - accuracy: 0.9774 - val_loss: 2.7132 - val_accuracy: 0.5132\n",
      "Epoch 546/1000\n",
      "177/177 [==============================] - 0s 70us/step - loss: 0.0319 - accuracy: 0.9944 - val_loss: 2.7116 - val_accuracy: 0.5132\n",
      "Epoch 547/1000\n",
      "177/177 [==============================] - 0s 82us/step - loss: 0.0168 - accuracy: 1.0000 - val_loss: 2.7771 - val_accuracy: 0.5000\n",
      "Epoch 548/1000\n",
      "177/177 [==============================] - 0s 99us/step - loss: 0.0207 - accuracy: 0.9944 - val_loss: 2.7590 - val_accuracy: 0.5000\n",
      "Epoch 549/1000\n",
      "177/177 [==============================] - 0s 85us/step - loss: 0.0222 - accuracy: 0.9944 - val_loss: 2.7064 - val_accuracy: 0.5132\n",
      "Epoch 550/1000\n",
      "177/177 [==============================] - 0s 77us/step - loss: 0.0215 - accuracy: 0.9944 - val_loss: 2.7337 - val_accuracy: 0.5132\n",
      "Epoch 551/1000\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.0260 - accuracy: 0.9944 - val_loss: 2.7325 - val_accuracy: 0.5132\n",
      "Epoch 552/1000\n",
      "177/177 [==============================] - 0s 97us/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 2.7230 - val_accuracy: 0.5132\n",
      "Epoch 553/1000\n",
      "177/177 [==============================] - 0s 129us/step - loss: 0.0205 - accuracy: 0.9944 - val_loss: 2.7702 - val_accuracy: 0.5000\n",
      "Epoch 554/1000\n",
      "177/177 [==============================] - 0s 81us/step - loss: 0.0267 - accuracy: 0.9944 - val_loss: 2.7549 - val_accuracy: 0.5132\n",
      "Epoch 555/1000\n",
      "177/177 [==============================] - 0s 75us/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 2.7478 - val_accuracy: 0.5000\n",
      "Epoch 556/1000\n",
      "177/177 [==============================] - 0s 100us/step - loss: 0.0302 - accuracy: 0.9944 - val_loss: 2.7967 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 557/1000\n",
      "177/177 [==============================] - 0s 95us/step - loss: 0.0383 - accuracy: 0.9831 - val_loss: 2.7438 - val_accuracy: 0.5132\n",
      "Epoch 558/1000\n",
      "177/177 [==============================] - 0s 56us/step - loss: 0.0545 - accuracy: 0.9887 - val_loss: 2.7115 - val_accuracy: 0.5132\n",
      "Epoch 559/1000\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.0645 - accuracy: 0.9887 - val_loss: 2.8187 - val_accuracy: 0.5000\n",
      "Epoch 560/1000\n",
      "177/177 [==============================] - 0s 107us/step - loss: 0.0654 - accuracy: 0.9831 - val_loss: 2.7716 - val_accuracy: 0.5132\n",
      "Epoch 561/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.0784 - accuracy: 0.9944 - val_loss: 2.7242 - val_accuracy: 0.5132\n",
      "Epoch 562/1000\n",
      "177/177 [==============================] - 0s 57us/step - loss: 0.0582 - accuracy: 0.9887 - val_loss: 2.7843 - val_accuracy: 0.5000\n",
      "Epoch 563/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.0924 - accuracy: 0.9831 - val_loss: 2.9375 - val_accuracy: 0.4868\n",
      "Epoch 564/1000\n",
      "177/177 [==============================] - 0s 58us/step - loss: 0.0395 - accuracy: 0.9831 - val_loss: 2.7960 - val_accuracy: 0.5000\n",
      "Epoch 565/1000\n",
      "177/177 [==============================] - 0s 50us/step - loss: 0.1107 - accuracy: 0.9887 - val_loss: 2.7219 - val_accuracy: 0.5132\n",
      "Epoch 566/1000\n",
      "177/177 [==============================] - 0s 49us/step - loss: 0.0692 - accuracy: 0.9887 - val_loss: 2.7705 - val_accuracy: 0.5132\n",
      "Epoch 567/1000\n",
      "177/177 [==============================] - 0s 51us/step - loss: 0.0233 - accuracy: 0.9944 - val_loss: 3.0838 - val_accuracy: 0.5000\n",
      "Epoch 568/1000\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.2938 - accuracy: 0.9605 - val_loss: 2.8008 - val_accuracy: 0.5132\n",
      "Epoch 569/1000\n",
      "177/177 [==============================] - 0s 58us/step - loss: 0.2918 - accuracy: 0.9661 - val_loss: 2.7196 - val_accuracy: 0.5263\n",
      "Epoch 570/1000\n",
      "177/177 [==============================] - 0s 94us/step - loss: 0.1605 - accuracy: 0.9831 - val_loss: 3.0394 - val_accuracy: 0.5263\n",
      "Epoch 571/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.1679 - accuracy: 0.9774 - val_loss: 3.1639 - val_accuracy: 0.5000\n",
      "Epoch 572/1000\n",
      "177/177 [==============================] - 0s 132us/step - loss: 0.2259 - accuracy: 0.9774 - val_loss: 2.7943 - val_accuracy: 0.5132\n",
      "Epoch 573/1000\n",
      "177/177 [==============================] - 0s 284us/step - loss: 0.1200 - accuracy: 0.9718 - val_loss: 2.7487 - val_accuracy: 0.5132\n",
      "Epoch 574/1000\n",
      "177/177 [==============================] - 0s 274us/step - loss: 0.0175 - accuracy: 0.9944 - val_loss: 2.9786 - val_accuracy: 0.5132\n",
      "Epoch 575/1000\n",
      "177/177 [==============================] - 0s 132us/step - loss: 0.0993 - accuracy: 0.9831 - val_loss: 3.0324 - val_accuracy: 0.5000\n",
      "Epoch 576/1000\n",
      "177/177 [==============================] - 0s 81us/step - loss: 0.1386 - accuracy: 0.9831 - val_loss: 2.7320 - val_accuracy: 0.5263\n",
      "Epoch 577/1000\n",
      "177/177 [==============================] - 0s 270us/step - loss: 0.0214 - accuracy: 0.9944 - val_loss: 2.7041 - val_accuracy: 0.5263\n",
      "Epoch 578/1000\n",
      "177/177 [==============================] - 0s 121us/step - loss: 0.1057 - accuracy: 0.9831 - val_loss: 2.7490 - val_accuracy: 0.5132\n",
      "Epoch 579/1000\n",
      "177/177 [==============================] - 0s 57us/step - loss: 0.0125 - accuracy: 0.9944 - val_loss: 2.9916 - val_accuracy: 0.4868\n",
      "Epoch 580/1000\n",
      "177/177 [==============================] - 0s 129us/step - loss: 0.1113 - accuracy: 0.9831 - val_loss: 2.8679 - val_accuracy: 0.5000\n",
      "Epoch 581/1000\n",
      "177/177 [==============================] - 0s 769us/step - loss: 0.0381 - accuracy: 0.9831 - val_loss: 2.7561 - val_accuracy: 0.5132\n",
      "Epoch 582/1000\n",
      "177/177 [==============================] - 0s 283us/step - loss: 0.0697 - accuracy: 0.9831 - val_loss: 2.8009 - val_accuracy: 0.5132\n",
      "Epoch 583/1000\n",
      "177/177 [==============================] - 0s 102us/step - loss: 0.0645 - accuracy: 0.9887 - val_loss: 2.8838 - val_accuracy: 0.5000\n",
      "Epoch 584/1000\n",
      "177/177 [==============================] - 0s 107us/step - loss: 0.0300 - accuracy: 0.9887 - val_loss: 2.7734 - val_accuracy: 0.5132\n",
      "Epoch 585/1000\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.0319 - accuracy: 0.9944 - val_loss: 2.7999 - val_accuracy: 0.5132\n",
      "Epoch 586/1000\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.0206 - accuracy: 0.9887 - val_loss: 2.7749 - val_accuracy: 0.5132\n",
      "Epoch 587/1000\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.0312 - accuracy: 0.9887 - val_loss: 2.8063 - val_accuracy: 0.5000\n",
      "Epoch 588/1000\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.0141 - accuracy: 0.9944 - val_loss: 2.9112 - val_accuracy: 0.5000\n",
      "Epoch 589/1000\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.0306 - accuracy: 0.9831 - val_loss: 2.7722 - val_accuracy: 0.5132\n",
      "Epoch 590/1000\n",
      "177/177 [==============================] - 0s 69us/step - loss: 0.0268 - accuracy: 0.9887 - val_loss: 2.7805 - val_accuracy: 0.5132\n",
      "Epoch 591/1000\n",
      "177/177 [==============================] - 0s 173us/step - loss: 0.0204 - accuracy: 0.9944 - val_loss: 2.8049 - val_accuracy: 0.5132\n",
      "Epoch 592/1000\n",
      "177/177 [==============================] - 0s 162us/step - loss: 0.0133 - accuracy: 0.9944 - val_loss: 2.9032 - val_accuracy: 0.5132\n",
      "Epoch 593/1000\n",
      "177/177 [==============================] - 0s 117us/step - loss: 0.0302 - accuracy: 0.9887 - val_loss: 2.8547 - val_accuracy: 0.5132\n",
      "Epoch 594/1000\n",
      "177/177 [==============================] - 0s 100us/step - loss: 0.0558 - accuracy: 0.9831 - val_loss: 2.8010 - val_accuracy: 0.5132\n",
      "Epoch 595/1000\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.0598 - accuracy: 0.9887 - val_loss: 2.8496 - val_accuracy: 0.5132\n",
      "Epoch 596/1000\n",
      "177/177 [==============================] - 0s 63us/step - loss: 0.0634 - accuracy: 0.9944 - val_loss: 2.8074 - val_accuracy: 0.5132\n",
      "Epoch 597/1000\n",
      "177/177 [==============================] - 0s 54us/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 2.8292 - val_accuracy: 0.5132\n",
      "Epoch 598/1000\n",
      "177/177 [==============================] - 0s 68us/step - loss: 0.0371 - accuracy: 0.9887 - val_loss: 2.8965 - val_accuracy: 0.5000\n",
      "Epoch 599/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.0325 - accuracy: 0.9831 - val_loss: 2.8515 - val_accuracy: 0.5132\n",
      "Epoch 600/1000\n",
      "177/177 [==============================] - 0s 69us/step - loss: 0.0403 - accuracy: 0.9887 - val_loss: 2.8071 - val_accuracy: 0.5132\n",
      "Epoch 601/1000\n",
      "177/177 [==============================] - 0s 59us/step - loss: 0.0354 - accuracy: 0.9887 - val_loss: 2.8131 - val_accuracy: 0.5000\n",
      "Epoch 602/1000\n",
      "177/177 [==============================] - 0s 70us/step - loss: 0.0317 - accuracy: 0.9831 - val_loss: 2.9950 - val_accuracy: 0.5000\n",
      "Epoch 603/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.0569 - accuracy: 0.9831 - val_loss: 2.7974 - val_accuracy: 0.5132\n",
      "Epoch 604/1000\n",
      "177/177 [==============================] - 0s 63us/step - loss: 0.0468 - accuracy: 0.9887 - val_loss: 2.7934 - val_accuracy: 0.5132\n",
      "Epoch 605/1000\n",
      "177/177 [==============================] - 0s 136us/step - loss: 0.0251 - accuracy: 0.9887 - val_loss: 2.8665 - val_accuracy: 0.5132\n",
      "Epoch 606/1000\n",
      "177/177 [==============================] - 0s 94us/step - loss: 0.0299 - accuracy: 0.9831 - val_loss: 2.8577 - val_accuracy: 0.5132\n",
      "Epoch 607/1000\n",
      "177/177 [==============================] - 0s 94us/step - loss: 0.0351 - accuracy: 0.9887 - val_loss: 2.8193 - val_accuracy: 0.5263\n",
      "Epoch 608/1000\n",
      "177/177 [==============================] - 0s 121us/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 2.8610 - val_accuracy: 0.5263\n",
      "Epoch 609/1000\n",
      "177/177 [==============================] - 0s 87us/step - loss: 0.0483 - accuracy: 0.9887 - val_loss: 2.8486 - val_accuracy: 0.5263\n",
      "Epoch 610/1000\n",
      "177/177 [==============================] - 0s 76us/step - loss: 0.0234 - accuracy: 0.9944 - val_loss: 2.8137 - val_accuracy: 0.5263\n",
      "Epoch 611/1000\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.0614 - accuracy: 0.9944 - val_loss: 2.8921 - val_accuracy: 0.5132\n",
      "Epoch 612/1000\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.0420 - accuracy: 0.9831 - val_loss: 2.9846 - val_accuracy: 0.5000\n",
      "Epoch 613/1000\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.0936 - accuracy: 0.9831 - val_loss: 2.8557 - val_accuracy: 0.5132\n",
      "Epoch 614/1000\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.0975 - accuracy: 0.9774 - val_loss: 2.8609 - val_accuracy: 0.5000\n",
      "Epoch 615/1000\n",
      "177/177 [==============================] - 0s 79us/step - loss: 0.0227 - accuracy: 0.9887 - val_loss: 2.9736 - val_accuracy: 0.5000\n",
      "Epoch 616/1000\n",
      "177/177 [==============================] - 0s 68us/step - loss: 0.0574 - accuracy: 0.9831 - val_loss: 2.8379 - val_accuracy: 0.5132\n",
      "Epoch 617/1000\n",
      "177/177 [==============================] - 0s 82us/step - loss: 0.0198 - accuracy: 0.9887 - val_loss: 2.8471 - val_accuracy: 0.5132\n",
      "Epoch 618/1000\n",
      "177/177 [==============================] - 0s 84us/step - loss: 0.0545 - accuracy: 0.9831 - val_loss: 2.8590 - val_accuracy: 0.5132\n",
      "Epoch 619/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.0820 - accuracy: 0.9831 - val_loss: 3.0269 - val_accuracy: 0.5132\n",
      "Epoch 620/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.0653 - accuracy: 0.9831 - val_loss: 2.9039 - val_accuracy: 0.5000\n",
      "Epoch 621/1000\n",
      "177/177 [==============================] - 0s 100us/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 2.8437 - val_accuracy: 0.5132\n",
      "Epoch 622/1000\n",
      "177/177 [==============================] - 0s 75us/step - loss: 0.0519 - accuracy: 0.9887 - val_loss: 2.8466 - val_accuracy: 0.5132\n",
      "Epoch 623/1000\n",
      "177/177 [==============================] - 0s 63us/step - loss: 0.0431 - accuracy: 0.9887 - val_loss: 2.8434 - val_accuracy: 0.5132\n",
      "Epoch 624/1000\n",
      "177/177 [==============================] - 0s 59us/step - loss: 0.0204 - accuracy: 0.9944 - val_loss: 2.8467 - val_accuracy: 0.5000\n",
      "Epoch 625/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.0855 - accuracy: 0.9887 - val_loss: 2.8116 - val_accuracy: 0.5132\n",
      "Epoch 626/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.0200 - accuracy: 0.9944 - val_loss: 2.8599 - val_accuracy: 0.5132\n",
      "Epoch 627/1000\n",
      "177/177 [==============================] - 0s 151us/step - loss: 0.0192 - accuracy: 0.9887 - val_loss: 2.9013 - val_accuracy: 0.5000\n",
      "Epoch 628/1000\n",
      "177/177 [==============================] - 0s 119us/step - loss: 0.0292 - accuracy: 0.9887 - val_loss: 2.8761 - val_accuracy: 0.5132\n",
      "Epoch 629/1000\n",
      "177/177 [==============================] - 0s 143us/step - loss: 0.0286 - accuracy: 0.9887 - val_loss: 2.8809 - val_accuracy: 0.5132\n",
      "Epoch 630/1000\n",
      "177/177 [==============================] - 0s 141us/step - loss: 0.0137 - accuracy: 0.9944 - val_loss: 2.9134 - val_accuracy: 0.5000\n",
      "Epoch 631/1000\n",
      "177/177 [==============================] - 0s 127us/step - loss: 0.0248 - accuracy: 0.9944 - val_loss: 2.8516 - val_accuracy: 0.5132\n",
      "Epoch 632/1000\n",
      "177/177 [==============================] - 0s 134us/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 2.8362 - val_accuracy: 0.5132\n",
      "Epoch 633/1000\n",
      "177/177 [==============================] - 0s 177us/step - loss: 0.0242 - accuracy: 0.9944 - val_loss: 2.8522 - val_accuracy: 0.5132\n",
      "Epoch 634/1000\n",
      "177/177 [==============================] - 0s 123us/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 2.9490 - val_accuracy: 0.5000\n",
      "Epoch 635/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.0687 - accuracy: 0.9831 - val_loss: 2.8813 - val_accuracy: 0.5132\n",
      "Epoch 636/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.0217 - accuracy: 0.9944 - val_loss: 2.8269 - val_accuracy: 0.5132\n",
      "Epoch 637/1000\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.0555 - accuracy: 0.9944 - val_loss: 2.8474 - val_accuracy: 0.5132\n",
      "Epoch 638/1000\n",
      "177/177 [==============================] - 0s 54us/step - loss: 0.0193 - accuracy: 0.9944 - val_loss: 2.9471 - val_accuracy: 0.5000\n",
      "Epoch 639/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.0214 - accuracy: 0.9887 - val_loss: 2.9116 - val_accuracy: 0.5000\n",
      "Epoch 640/1000\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.0130 - accuracy: 0.9944 - val_loss: 2.8635 - val_accuracy: 0.5132\n",
      "Epoch 641/1000\n",
      "177/177 [==============================] - 0s 60us/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 2.8425 - val_accuracy: 0.5132\n",
      "Epoch 642/1000\n",
      "177/177 [==============================] - 0s 56us/step - loss: 0.0156 - accuracy: 0.9944 - val_loss: 2.8646 - val_accuracy: 0.5132\n",
      "Epoch 643/1000\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 2.8985 - val_accuracy: 0.5000\n",
      "Epoch 644/1000\n",
      "177/177 [==============================] - 0s 68us/step - loss: 0.0187 - accuracy: 0.9944 - val_loss: 2.8534 - val_accuracy: 0.5132\n",
      "Epoch 645/1000\n",
      "177/177 [==============================] - 0s 154us/step - loss: 0.0281 - accuracy: 0.9944 - val_loss: 2.8635 - val_accuracy: 0.5132\n",
      "Epoch 646/1000\n",
      "177/177 [==============================] - 0s 217us/step - loss: 0.0257 - accuracy: 0.9944 - val_loss: 2.9074 - val_accuracy: 0.5000\n",
      "Epoch 647/1000\n",
      "177/177 [==============================] - 0s 153us/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 2.8569 - val_accuracy: 0.5132\n",
      "Epoch 648/1000\n",
      "177/177 [==============================] - 0s 86us/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 2.8638 - val_accuracy: 0.5132\n",
      "Epoch 649/1000\n",
      "177/177 [==============================] - 0s 130us/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 2.8888 - val_accuracy: 0.5000\n",
      "Epoch 650/1000\n",
      "177/177 [==============================] - 0s 136us/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 2.9030 - val_accuracy: 0.5000\n",
      "Epoch 651/1000\n",
      "177/177 [==============================] - 0s 149us/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 2.8853 - val_accuracy: 0.5000\n",
      "Epoch 652/1000\n",
      "177/177 [==============================] - 0s 68us/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 2.8567 - val_accuracy: 0.5132\n",
      "Epoch 653/1000\n",
      "177/177 [==============================] - 0s 59us/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 2.8648 - val_accuracy: 0.5132\n",
      "Epoch 654/1000\n",
      "177/177 [==============================] - 0s 82us/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 2.8812 - val_accuracy: 0.5000\n",
      "Epoch 655/1000\n",
      "177/177 [==============================] - 0s 68us/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 2.8980 - val_accuracy: 0.5000\n",
      "Epoch 656/1000\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 2.8969 - val_accuracy: 0.5000\n",
      "Epoch 657/1000\n",
      "177/177 [==============================] - 0s 63us/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 2.8765 - val_accuracy: 0.5132\n",
      "Epoch 658/1000\n",
      "177/177 [==============================] - 0s 53us/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 2.8768 - val_accuracy: 0.5132\n",
      "Epoch 659/1000\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 2.8858 - val_accuracy: 0.5000\n",
      "Epoch 660/1000\n",
      "177/177 [==============================] - 0s 60us/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 2.8909 - val_accuracy: 0.5000\n",
      "Epoch 661/1000\n",
      "177/177 [==============================] - 0s 57us/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 2.8935 - val_accuracy: 0.5000\n",
      "Epoch 662/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 2.8914 - val_accuracy: 0.5000\n",
      "Epoch 663/1000\n",
      "177/177 [==============================] - 0s 54us/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 2.8916 - val_accuracy: 0.5000\n",
      "Epoch 664/1000\n",
      "177/177 [==============================] - 0s 132us/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 2.8892 - val_accuracy: 0.5000\n",
      "Epoch 665/1000\n",
      "177/177 [==============================] - 0s 140us/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 2.8942 - val_accuracy: 0.5000\n",
      "Epoch 666/1000\n",
      "177/177 [==============================] - 0s 79us/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 2.8959 - val_accuracy: 0.5000\n",
      "Epoch 667/1000\n",
      "177/177 [==============================] - 0s 174us/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 2.9126 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 668/1000\n",
      "177/177 [==============================] - 0s 106us/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 2.9035 - val_accuracy: 0.5000\n",
      "Epoch 669/1000\n",
      "177/177 [==============================] - 0s 105us/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 2.8924 - val_accuracy: 0.5132\n",
      "Epoch 670/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 2.8930 - val_accuracy: 0.5132\n",
      "Epoch 671/1000\n",
      "177/177 [==============================] - 0s 56us/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 2.8907 - val_accuracy: 0.5132\n",
      "Epoch 672/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 2.8936 - val_accuracy: 0.5132\n",
      "Epoch 673/1000\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 2.8966 - val_accuracy: 0.5132\n",
      "Epoch 674/1000\n",
      "177/177 [==============================] - 0s 58us/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 2.9035 - val_accuracy: 0.5000\n",
      "Epoch 675/1000\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 2.9018 - val_accuracy: 0.5000\n",
      "Epoch 676/1000\n",
      "177/177 [==============================] - 0s 141us/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 2.9001 - val_accuracy: 0.5000\n",
      "Epoch 677/1000\n",
      "177/177 [==============================] - 0s 99us/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 2.8988 - val_accuracy: 0.5000\n",
      "Epoch 678/1000\n",
      "177/177 [==============================] - 0s 84us/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 2.9048 - val_accuracy: 0.5000\n",
      "Epoch 679/1000\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 2.9094 - val_accuracy: 0.5000\n",
      "Epoch 680/1000\n",
      "177/177 [==============================] - 0s 76us/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 2.9009 - val_accuracy: 0.5000\n",
      "Epoch 681/1000\n",
      "177/177 [==============================] - 0s 89us/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 2.9075 - val_accuracy: 0.5000\n",
      "Epoch 682/1000\n",
      "177/177 [==============================] - 0s 93us/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 2.9055 - val_accuracy: 0.5000\n",
      "Epoch 683/1000\n",
      "177/177 [==============================] - 0s 159us/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 2.9094 - val_accuracy: 0.5000\n",
      "Epoch 684/1000\n",
      "177/177 [==============================] - 0s 91us/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 2.9113 - val_accuracy: 0.5000\n",
      "Epoch 685/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 2.9105 - val_accuracy: 0.5000\n",
      "Epoch 686/1000\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 2.9128 - val_accuracy: 0.5000\n",
      "Epoch 687/1000\n",
      "177/177 [==============================] - 0s 56us/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 2.9125 - val_accuracy: 0.5000\n",
      "Epoch 688/1000\n",
      "177/177 [==============================] - 0s 97us/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 2.9147 - val_accuracy: 0.5000\n",
      "Epoch 689/1000\n",
      "177/177 [==============================] - 0s 150us/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 2.9075 - val_accuracy: 0.5132\n",
      "Epoch 690/1000\n",
      "177/177 [==============================] - 0s 110us/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 2.9055 - val_accuracy: 0.5132\n",
      "Epoch 691/1000\n",
      "177/177 [==============================] - 0s 106us/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 2.9096 - val_accuracy: 0.5132\n",
      "Epoch 692/1000\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 2.9104 - val_accuracy: 0.5000\n",
      "Epoch 693/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 2.9137 - val_accuracy: 0.5000\n",
      "Epoch 694/1000\n",
      "177/177 [==============================] - 0s 81us/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 2.9179 - val_accuracy: 0.5000\n",
      "Epoch 695/1000\n",
      "177/177 [==============================] - 0s 132us/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 2.9130 - val_accuracy: 0.5000\n",
      "Epoch 696/1000\n",
      "177/177 [==============================] - 0s 94us/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 2.9092 - val_accuracy: 0.5132\n",
      "Epoch 697/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 2.9105 - val_accuracy: 0.5132\n",
      "Epoch 698/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 2.9128 - val_accuracy: 0.5000\n",
      "Epoch 699/1000\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 2.9183 - val_accuracy: 0.5000\n",
      "Epoch 700/1000\n",
      "177/177 [==============================] - 0s 82us/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 2.9179 - val_accuracy: 0.5000\n",
      "Epoch 701/1000\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 2.9212 - val_accuracy: 0.5000\n",
      "Epoch 702/1000\n",
      "177/177 [==============================] - 0s 151us/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 2.9177 - val_accuracy: 0.5000\n",
      "Epoch 703/1000\n",
      "177/177 [==============================] - 0s 76us/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 2.9188 - val_accuracy: 0.5000\n",
      "Epoch 704/1000\n",
      "177/177 [==============================] - 0s 100us/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 2.9165 - val_accuracy: 0.5132\n",
      "Epoch 705/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 2.9232 - val_accuracy: 0.5000\n",
      "Epoch 706/1000\n",
      "177/177 [==============================] - 0s 58us/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 2.9231 - val_accuracy: 0.5000\n",
      "Epoch 707/1000\n",
      "177/177 [==============================] - 0s 74us/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 2.9191 - val_accuracy: 0.5132\n",
      "Epoch 708/1000\n",
      "177/177 [==============================] - 0s 77us/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 2.9184 - val_accuracy: 0.5132\n",
      "Epoch 709/1000\n",
      "177/177 [==============================] - 0s 56us/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 2.9163 - val_accuracy: 0.5132\n",
      "Epoch 710/1000\n",
      "177/177 [==============================] - 0s 76us/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 2.9200 - val_accuracy: 0.5132\n",
      "Epoch 711/1000\n",
      "177/177 [==============================] - 0s 56us/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 2.9292 - val_accuracy: 0.5000\n",
      "Epoch 712/1000\n",
      "177/177 [==============================] - 0s 69us/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 2.9290 - val_accuracy: 0.5000\n",
      "Epoch 713/1000\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 2.9239 - val_accuracy: 0.5132\n",
      "Epoch 714/1000\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 2.9282 - val_accuracy: 0.5000\n",
      "Epoch 715/1000\n",
      "177/177 [==============================] - 0s 63us/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 2.9312 - val_accuracy: 0.5000\n",
      "Epoch 716/1000\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 2.9334 - val_accuracy: 0.5000\n",
      "Epoch 717/1000\n",
      "177/177 [==============================] - 0s 105us/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 2.9336 - val_accuracy: 0.5000\n",
      "Epoch 718/1000\n",
      "177/177 [==============================] - 0s 82us/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 2.9340 - val_accuracy: 0.5000\n",
      "Epoch 719/1000\n",
      "177/177 [==============================] - 0s 84us/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 2.9268 - val_accuracy: 0.5132\n",
      "Epoch 720/1000\n",
      "177/177 [==============================] - 0s 59us/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 2.9262 - val_accuracy: 0.5132\n",
      "Epoch 721/1000\n",
      "177/177 [==============================] - 0s 60us/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 2.9271 - val_accuracy: 0.5132\n",
      "Epoch 722/1000\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 2.9314 - val_accuracy: 0.5132\n",
      "Epoch 723/1000\n",
      "177/177 [==============================] - 0s 139us/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 2.9321 - val_accuracy: 0.5132\n",
      "Epoch 724/1000\n",
      "177/177 [==============================] - 0s 69us/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 2.9300 - val_accuracy: 0.5132\n",
      "Epoch 725/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 2.9298 - val_accuracy: 0.5132\n",
      "Epoch 726/1000\n",
      "177/177 [==============================] - 0s 63us/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 2.9324 - val_accuracy: 0.5263\n",
      "Epoch 727/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 2.9323 - val_accuracy: 0.5263\n",
      "Epoch 728/1000\n",
      "177/177 [==============================] - 0s 59us/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 2.9355 - val_accuracy: 0.5132\n",
      "Epoch 729/1000\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 2.9399 - val_accuracy: 0.5132\n",
      "Epoch 730/1000\n",
      "177/177 [==============================] - 0s 68us/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 2.9347 - val_accuracy: 0.5263\n",
      "Epoch 731/1000\n",
      "177/177 [==============================] - 0s 94us/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 2.9376 - val_accuracy: 0.5132\n",
      "Epoch 732/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 2.9395 - val_accuracy: 0.5132\n",
      "Epoch 733/1000\n",
      "177/177 [==============================] - 0s 110us/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 2.9380 - val_accuracy: 0.5132\n",
      "Epoch 734/1000\n",
      "177/177 [==============================] - 0s 225us/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 2.9404 - val_accuracy: 0.5000\n",
      "Epoch 735/1000\n",
      "177/177 [==============================] - 0s 170us/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 2.9457 - val_accuracy: 0.5000\n",
      "Epoch 736/1000\n",
      "177/177 [==============================] - 0s 122us/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 2.9428 - val_accuracy: 0.5132\n",
      "Epoch 737/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 2.9392 - val_accuracy: 0.5263\n",
      "Epoch 738/1000\n",
      "177/177 [==============================] - 0s 87us/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 2.9391 - val_accuracy: 0.5263\n",
      "Epoch 739/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 2.9393 - val_accuracy: 0.5263\n",
      "Epoch 740/1000\n",
      "177/177 [==============================] - 0s 84us/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 2.9455 - val_accuracy: 0.5000\n",
      "Epoch 741/1000\n",
      "177/177 [==============================] - 0s 93us/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 2.9407 - val_accuracy: 0.5132\n",
      "Epoch 742/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 2.9441 - val_accuracy: 0.5000\n",
      "Epoch 743/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 2.9441 - val_accuracy: 0.5000\n",
      "Epoch 744/1000\n",
      "177/177 [==============================] - 0s 138us/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 2.9475 - val_accuracy: 0.5000\n",
      "Epoch 745/1000\n",
      "177/177 [==============================] - 0s 193us/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 2.9431 - val_accuracy: 0.5132\n",
      "Epoch 746/1000\n",
      "177/177 [==============================] - 0s 109us/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 2.9448 - val_accuracy: 0.5132\n",
      "Epoch 747/1000\n",
      "177/177 [==============================] - 0s 100us/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 2.9479 - val_accuracy: 0.5000\n",
      "Epoch 748/1000\n",
      "177/177 [==============================] - 0s 107us/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 2.9463 - val_accuracy: 0.5132\n",
      "Epoch 749/1000\n",
      "177/177 [==============================] - 0s 148us/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 2.9508 - val_accuracy: 0.5000\n",
      "Epoch 750/1000\n",
      "177/177 [==============================] - 0s 100us/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 2.9508 - val_accuracy: 0.5132\n",
      "Epoch 751/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 2.9500 - val_accuracy: 0.5132\n",
      "Epoch 752/1000\n",
      "177/177 [==============================] - 0s 54us/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 2.9502 - val_accuracy: 0.5263\n",
      "Epoch 753/1000\n",
      "177/177 [==============================] - 0s 59us/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 2.9455 - val_accuracy: 0.5263\n",
      "Epoch 754/1000\n",
      "177/177 [==============================] - 0s 58us/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 2.9472 - val_accuracy: 0.5263\n",
      "Epoch 755/1000\n",
      "177/177 [==============================] - 0s 102us/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 2.9539 - val_accuracy: 0.5263\n",
      "Epoch 756/1000\n",
      "177/177 [==============================] - 0s 60us/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 2.9520 - val_accuracy: 0.5263\n",
      "Epoch 757/1000\n",
      "177/177 [==============================] - 0s 63us/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 2.9551 - val_accuracy: 0.5263\n",
      "Epoch 758/1000\n",
      "177/177 [==============================] - 0s 55us/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 2.9575 - val_accuracy: 0.5263\n",
      "Epoch 759/1000\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 2.9612 - val_accuracy: 0.5132\n",
      "Epoch 760/1000\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 2.9658 - val_accuracy: 0.5132\n",
      "Epoch 761/1000\n",
      "177/177 [==============================] - 0s 74us/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 2.9580 - val_accuracy: 0.5132\n",
      "Epoch 762/1000\n",
      "177/177 [==============================] - 0s 63us/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 2.9514 - val_accuracy: 0.5263\n",
      "Epoch 763/1000\n",
      "177/177 [==============================] - 0s 63us/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 2.9570 - val_accuracy: 0.5263\n",
      "Epoch 764/1000\n",
      "177/177 [==============================] - 0s 110us/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 2.9651 - val_accuracy: 0.5132\n",
      "Epoch 765/1000\n",
      "177/177 [==============================] - 0s 161us/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 2.9646 - val_accuracy: 0.5132\n",
      "Epoch 766/1000\n",
      "177/177 [==============================] - 0s 119us/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 2.9627 - val_accuracy: 0.5263\n",
      "Epoch 767/1000\n",
      "177/177 [==============================] - 0s 103us/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 2.9596 - val_accuracy: 0.5263\n",
      "Epoch 768/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 2.9626 - val_accuracy: 0.5263\n",
      "Epoch 769/1000\n",
      "177/177 [==============================] - 0s 133us/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 2.9602 - val_accuracy: 0.5263\n",
      "Epoch 770/1000\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 2.9670 - val_accuracy: 0.5132\n",
      "Epoch 771/1000\n",
      "177/177 [==============================] - 0s 56us/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 2.9681 - val_accuracy: 0.5132\n",
      "Epoch 772/1000\n",
      "177/177 [==============================] - 0s 60us/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 2.9615 - val_accuracy: 0.5263\n",
      "Epoch 773/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 2.9648 - val_accuracy: 0.5263\n",
      "Epoch 774/1000\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 2.9636 - val_accuracy: 0.5263\n",
      "Epoch 775/1000\n",
      "177/177 [==============================] - 0s 59us/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 2.9668 - val_accuracy: 0.5263\n",
      "Epoch 776/1000\n",
      "177/177 [==============================] - 0s 59us/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 2.9718 - val_accuracy: 0.5132\n",
      "Epoch 777/1000\n",
      "177/177 [==============================] - 0s 83us/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 2.9737 - val_accuracy: 0.5132\n",
      "Epoch 778/1000\n",
      "177/177 [==============================] - 0s 60us/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 2.9720 - val_accuracy: 0.5132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 779/1000\n",
      "177/177 [==============================] - 0s 81us/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 2.9755 - val_accuracy: 0.5132\n",
      "Epoch 780/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 2.9737 - val_accuracy: 0.5132\n",
      "Epoch 781/1000\n",
      "177/177 [==============================] - 0s 87us/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 2.9727 - val_accuracy: 0.5263\n",
      "Epoch 782/1000\n",
      "177/177 [==============================] - 0s 77us/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 2.9709 - val_accuracy: 0.5263\n",
      "Epoch 783/1000\n",
      "177/177 [==============================] - 0s 87us/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 2.9655 - val_accuracy: 0.5263\n",
      "Epoch 784/1000\n",
      "177/177 [==============================] - 0s 130us/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 2.9619 - val_accuracy: 0.5263\n",
      "Epoch 785/1000\n",
      "177/177 [==============================] - 0s 166us/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 2.9661 - val_accuracy: 0.5263\n",
      "Epoch 786/1000\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 2.9789 - val_accuracy: 0.5132\n",
      "Epoch 787/1000\n",
      "177/177 [==============================] - 0s 134us/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 2.9811 - val_accuracy: 0.5132\n",
      "Epoch 788/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 2.9780 - val_accuracy: 0.5132\n",
      "Epoch 789/1000\n",
      "177/177 [==============================] - 0s 63us/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 2.9707 - val_accuracy: 0.5263\n",
      "Epoch 790/1000\n",
      "177/177 [==============================] - 0s 111us/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 2.9755 - val_accuracy: 0.5263\n",
      "Epoch 791/1000\n",
      "177/177 [==============================] - 0s 119us/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 2.9824 - val_accuracy: 0.5132\n",
      "Epoch 792/1000\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 2.9776 - val_accuracy: 0.5263\n",
      "Epoch 793/1000\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 2.9705 - val_accuracy: 0.5263\n",
      "Epoch 794/1000\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 2.9748 - val_accuracy: 0.5263\n",
      "Epoch 795/1000\n",
      "177/177 [==============================] - 0s 75us/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 2.9830 - val_accuracy: 0.5263\n",
      "Epoch 796/1000\n",
      "177/177 [==============================] - 0s 56us/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 2.9846 - val_accuracy: 0.5132\n",
      "Epoch 797/1000\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 2.9862 - val_accuracy: 0.5132\n",
      "Epoch 798/1000\n",
      "177/177 [==============================] - 0s 84us/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 2.9889 - val_accuracy: 0.5132\n",
      "Epoch 799/1000\n",
      "177/177 [==============================] - 0s 60us/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 2.9845 - val_accuracy: 0.5263\n",
      "Epoch 800/1000\n",
      "177/177 [==============================] - 0s 60us/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 2.9795 - val_accuracy: 0.5263\n",
      "Epoch 801/1000\n",
      "177/177 [==============================] - 0s 68us/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 2.9809 - val_accuracy: 0.5263\n",
      "Epoch 802/1000\n",
      "177/177 [==============================] - 0s 74us/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 2.9777 - val_accuracy: 0.5263\n",
      "Epoch 803/1000\n",
      "177/177 [==============================] - 0s 59us/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 2.9798 - val_accuracy: 0.5263\n",
      "Epoch 804/1000\n",
      "177/177 [==============================] - 0s 63us/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 2.9823 - val_accuracy: 0.5263\n",
      "Epoch 805/1000\n",
      "177/177 [==============================] - 0s 60us/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 2.9788 - val_accuracy: 0.5263\n",
      "Epoch 806/1000\n",
      "177/177 [==============================] - 0s 108us/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 2.9874 - val_accuracy: 0.5263\n",
      "Epoch 807/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 2.9951 - val_accuracy: 0.5132\n",
      "Epoch 808/1000\n",
      "177/177 [==============================] - 0s 56us/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 2.9937 - val_accuracy: 0.5132\n",
      "Epoch 809/1000\n",
      "177/177 [==============================] - 0s 99us/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 2.9867 - val_accuracy: 0.5263\n",
      "Epoch 810/1000\n",
      "177/177 [==============================] - 0s 59us/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 2.9835 - val_accuracy: 0.5263\n",
      "Epoch 811/1000\n",
      "177/177 [==============================] - 0s 81us/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 2.9946 - val_accuracy: 0.5132\n",
      "Epoch 812/1000\n",
      "177/177 [==============================] - 0s 58us/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 3.0020 - val_accuracy: 0.5132\n",
      "Epoch 813/1000\n",
      "177/177 [==============================] - 0s 76us/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 3.0025 - val_accuracy: 0.5132\n",
      "Epoch 814/1000\n",
      "177/177 [==============================] - 0s 117us/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 2.9934 - val_accuracy: 0.5263\n",
      "Epoch 815/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 2.9887 - val_accuracy: 0.5263\n",
      "Epoch 816/1000\n",
      "177/177 [==============================] - 0s 81us/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 2.9899 - val_accuracy: 0.5263\n",
      "Epoch 817/1000\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 2.9943 - val_accuracy: 0.5263\n",
      "Epoch 818/1000\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 3.0015 - val_accuracy: 0.5132\n",
      "Epoch 819/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 3.0043 - val_accuracy: 0.5132\n",
      "Epoch 820/1000\n",
      "177/177 [==============================] - 0s 75us/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 2.9938 - val_accuracy: 0.5263\n",
      "Epoch 821/1000\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 2.9931 - val_accuracy: 0.5263\n",
      "Epoch 822/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 2.9978 - val_accuracy: 0.5263\n",
      "Epoch 823/1000\n",
      "177/177 [==============================] - 0s 92us/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 3.0083 - val_accuracy: 0.5132\n",
      "Epoch 824/1000\n",
      "177/177 [==============================] - 0s 68us/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 3.0137 - val_accuracy: 0.5132\n",
      "Epoch 825/1000\n",
      "177/177 [==============================] - 0s 69us/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 3.0024 - val_accuracy: 0.5263\n",
      "Epoch 826/1000\n",
      "177/177 [==============================] - 0s 91us/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 2.9963 - val_accuracy: 0.5263\n",
      "Epoch 827/1000\n",
      "177/177 [==============================] - 0s 78us/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 2.9985 - val_accuracy: 0.5263\n",
      "Epoch 828/1000\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 2.9986 - val_accuracy: 0.5263\n",
      "Epoch 829/1000\n",
      "177/177 [==============================] - 0s 89us/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 3.0031 - val_accuracy: 0.5263\n",
      "Epoch 830/1000\n",
      "177/177 [==============================] - 0s 85us/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 3.0066 - val_accuracy: 0.5263\n",
      "Epoch 831/1000\n",
      "177/177 [==============================] - 0s 76us/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 3.0095 - val_accuracy: 0.5132\n",
      "Epoch 832/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 3.0085 - val_accuracy: 0.5263\n",
      "Epoch 833/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 3.0088 - val_accuracy: 0.5263\n",
      "Epoch 834/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 3.0021 - val_accuracy: 0.5263\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 835/1000\n",
      "177/177 [==============================] - 0s 78us/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 3.0045 - val_accuracy: 0.5263\n",
      "Epoch 836/1000\n",
      "177/177 [==============================] - 0s 130us/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 3.0055 - val_accuracy: 0.5263\n",
      "Epoch 837/1000\n",
      "177/177 [==============================] - 0s 134us/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 3.0149 - val_accuracy: 0.5132\n",
      "Epoch 838/1000\n",
      "177/177 [==============================] - 0s 181us/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 3.0219 - val_accuracy: 0.5132\n",
      "Epoch 839/1000\n",
      "177/177 [==============================] - 0s 138us/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 3.0150 - val_accuracy: 0.5263\n",
      "Epoch 840/1000\n",
      "177/177 [==============================] - 0s 104us/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 3.0082 - val_accuracy: 0.5263\n",
      "Epoch 841/1000\n",
      "177/177 [==============================] - 0s 105us/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 3.0135 - val_accuracy: 0.5263\n",
      "Epoch 842/1000\n",
      "177/177 [==============================] - 0s 169us/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 3.0132 - val_accuracy: 0.5263\n",
      "Epoch 843/1000\n",
      "177/177 [==============================] - 0s 120us/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 3.0120 - val_accuracy: 0.5263\n",
      "Epoch 844/1000\n",
      "177/177 [==============================] - 0s 114us/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 3.0061 - val_accuracy: 0.5263\n",
      "Epoch 845/1000\n",
      "177/177 [==============================] - 0s 118us/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 3.0096 - val_accuracy: 0.5263\n",
      "Epoch 846/1000\n",
      "177/177 [==============================] - 0s 118us/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 3.0149 - val_accuracy: 0.5263\n",
      "Epoch 847/1000\n",
      "177/177 [==============================] - 0s 115us/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 3.0186 - val_accuracy: 0.5263\n",
      "Epoch 848/1000\n",
      "177/177 [==============================] - 0s 140us/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 3.0200 - val_accuracy: 0.5263\n",
      "Epoch 849/1000\n",
      "177/177 [==============================] - 0s 223us/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 3.0186 - val_accuracy: 0.5263\n",
      "Epoch 850/1000\n",
      "177/177 [==============================] - 0s 149us/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 3.0170 - val_accuracy: 0.5263\n",
      "Epoch 851/1000\n",
      "177/177 [==============================] - 0s 158us/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 3.0203 - val_accuracy: 0.5263\n",
      "Epoch 852/1000\n",
      "177/177 [==============================] - 0s 122us/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 3.0194 - val_accuracy: 0.5263\n",
      "Epoch 853/1000\n",
      "177/177 [==============================] - 0s 204us/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 3.0254 - val_accuracy: 0.5132\n",
      "Epoch 854/1000\n",
      "177/177 [==============================] - 0s 79us/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 3.0191 - val_accuracy: 0.5263\n",
      "Epoch 855/1000\n",
      "177/177 [==============================] - 0s 82us/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 3.0216 - val_accuracy: 0.5263\n",
      "Epoch 856/1000\n",
      "177/177 [==============================] - 0s 76us/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 3.0218 - val_accuracy: 0.5263\n",
      "Epoch 857/1000\n",
      "177/177 [==============================] - 0s 74us/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 3.0267 - val_accuracy: 0.5263\n",
      "Epoch 858/1000\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 3.0229 - val_accuracy: 0.5263\n",
      "Epoch 859/1000\n",
      "177/177 [==============================] - 0s 76us/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 3.0204 - val_accuracy: 0.5263\n",
      "Epoch 860/1000\n",
      "177/177 [==============================] - 0s 185us/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 3.0247 - val_accuracy: 0.5263\n",
      "Epoch 861/1000\n",
      "177/177 [==============================] - 0s 130us/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 3.0280 - val_accuracy: 0.5263\n",
      "Epoch 862/1000\n",
      "177/177 [==============================] - 0s 118us/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 3.0304 - val_accuracy: 0.5132\n",
      "Epoch 863/1000\n",
      "177/177 [==============================] - 0s 103us/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 3.0240 - val_accuracy: 0.5263\n",
      "Epoch 864/1000\n",
      "177/177 [==============================] - 0s 114us/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 3.0257 - val_accuracy: 0.5263\n",
      "Epoch 865/1000\n",
      "177/177 [==============================] - 0s 237us/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 3.0246 - val_accuracy: 0.5263\n",
      "Epoch 866/1000\n",
      "177/177 [==============================] - 0s 176us/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 3.0284 - val_accuracy: 0.5263\n",
      "Epoch 867/1000\n",
      "177/177 [==============================] - 0s 296us/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 3.0285 - val_accuracy: 0.5263\n",
      "Epoch 868/1000\n",
      "177/177 [==============================] - 0s 259us/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 3.0286 - val_accuracy: 0.5263\n",
      "Epoch 869/1000\n",
      "177/177 [==============================] - 0s 272us/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 3.0278 - val_accuracy: 0.5263\n",
      "Epoch 870/1000\n",
      "177/177 [==============================] - 0s 116us/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 3.0306 - val_accuracy: 0.5263\n",
      "Epoch 871/1000\n",
      "177/177 [==============================] - 0s 99us/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 3.0373 - val_accuracy: 0.5132\n",
      "Epoch 872/1000\n",
      "177/177 [==============================] - 0s 70us/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 3.0388 - val_accuracy: 0.5132\n",
      "Epoch 873/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 3.0417 - val_accuracy: 0.5132\n",
      "Epoch 874/1000\n",
      "177/177 [==============================] - 0s 69us/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 3.0393 - val_accuracy: 0.5263\n",
      "Epoch 875/1000\n",
      "177/177 [==============================] - 0s 86us/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 3.0331 - val_accuracy: 0.5263\n",
      "Epoch 876/1000\n",
      "177/177 [==============================] - 0s 186us/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 3.0352 - val_accuracy: 0.5263\n",
      "Epoch 877/1000\n",
      "177/177 [==============================] - 0s 149us/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 3.0380 - val_accuracy: 0.5263\n",
      "Epoch 878/1000\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 3.0380 - val_accuracy: 0.5263\n",
      "Epoch 879/1000\n",
      "177/177 [==============================] - 0s 103us/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 3.0355 - val_accuracy: 0.5263\n",
      "Epoch 880/1000\n",
      "177/177 [==============================] - 0s 83us/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 3.0321 - val_accuracy: 0.5263\n",
      "Epoch 881/1000\n",
      "177/177 [==============================] - 0s 316us/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 3.0415 - val_accuracy: 0.5263\n",
      "Epoch 882/1000\n",
      "177/177 [==============================] - 0s 163us/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 3.0490 - val_accuracy: 0.5132\n",
      "Epoch 883/1000\n",
      "177/177 [==============================] - 0s 104us/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 3.0499 - val_accuracy: 0.5132\n",
      "Epoch 884/1000\n",
      "177/177 [==============================] - 0s 120us/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 3.0458 - val_accuracy: 0.5263\n",
      "Epoch 885/1000\n",
      "177/177 [==============================] - 0s 99us/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 3.0444 - val_accuracy: 0.5263\n",
      "Epoch 886/1000\n",
      "177/177 [==============================] - 0s 130us/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 3.0459 - val_accuracy: 0.5263\n",
      "Epoch 887/1000\n",
      "177/177 [==============================] - 0s 93us/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 3.0444 - val_accuracy: 0.5263\n",
      "Epoch 888/1000\n",
      "177/177 [==============================] - 0s 83us/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 3.0531 - val_accuracy: 0.5132\n",
      "Epoch 889/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 3.0487 - val_accuracy: 0.5263\n",
      "Epoch 890/1000\n",
      "177/177 [==============================] - 0s 76us/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 3.0483 - val_accuracy: 0.5263\n",
      "Epoch 891/1000\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 3.0475 - val_accuracy: 0.5263\n",
      "Epoch 892/1000\n",
      "177/177 [==============================] - 0s 111us/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 3.0456 - val_accuracy: 0.5263\n",
      "Epoch 893/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 3.0518 - val_accuracy: 0.5263\n",
      "Epoch 894/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 3.0508 - val_accuracy: 0.5263\n",
      "Epoch 895/1000\n",
      "177/177 [==============================] - 0s 68us/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 3.0508 - val_accuracy: 0.5263\n",
      "Epoch 896/1000\n",
      "177/177 [==============================] - 0s 92us/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 3.0540 - val_accuracy: 0.5263\n",
      "Epoch 897/1000\n",
      "177/177 [==============================] - 0s 77us/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 3.0571 - val_accuracy: 0.5263\n",
      "Epoch 898/1000\n",
      "177/177 [==============================] - 0s 95us/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 3.0545 - val_accuracy: 0.5263\n",
      "Epoch 899/1000\n",
      "177/177 [==============================] - 0s 127us/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 3.0479 - val_accuracy: 0.5263\n",
      "Epoch 900/1000\n",
      "177/177 [==============================] - 0s 79us/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 3.0502 - val_accuracy: 0.5263\n",
      "Epoch 901/1000\n",
      "177/177 [==============================] - 0s 87us/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 3.0610 - val_accuracy: 0.5132\n",
      "Epoch 902/1000\n",
      "177/177 [==============================] - 0s 91us/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 3.0534 - val_accuracy: 0.5263\n",
      "Epoch 903/1000\n",
      "177/177 [==============================] - 0s 77us/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 3.0567 - val_accuracy: 0.5263\n",
      "Epoch 904/1000\n",
      "177/177 [==============================] - 0s 376us/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 3.0612 - val_accuracy: 0.5263\n",
      "Epoch 905/1000\n",
      "177/177 [==============================] - 0s 138us/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 3.0615 - val_accuracy: 0.5263\n",
      "Epoch 906/1000\n",
      "177/177 [==============================] - 0s 115us/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 3.0618 - val_accuracy: 0.5263\n",
      "Epoch 907/1000\n",
      "177/177 [==============================] - 0s 105us/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 3.0606 - val_accuracy: 0.5263\n",
      "Epoch 908/1000\n",
      "177/177 [==============================] - 0s 138us/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 3.0570 - val_accuracy: 0.5263\n",
      "Epoch 909/1000\n",
      "177/177 [==============================] - 0s 150us/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 3.0603 - val_accuracy: 0.5263\n",
      "Epoch 910/1000\n",
      "177/177 [==============================] - 0s 185us/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 3.0583 - val_accuracy: 0.5263\n",
      "Epoch 911/1000\n",
      "177/177 [==============================] - 0s 57us/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 3.0613 - val_accuracy: 0.5263\n",
      "Epoch 912/1000\n",
      "177/177 [==============================] - 0s 55us/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 3.0605 - val_accuracy: 0.5263\n",
      "Epoch 913/1000\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 3.0650 - val_accuracy: 0.5263\n",
      "Epoch 914/1000\n",
      "177/177 [==============================] - 0s 53us/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 3.0654 - val_accuracy: 0.5263\n",
      "Epoch 915/1000\n",
      "177/177 [==============================] - 0s 55us/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 3.0678 - val_accuracy: 0.5132\n",
      "Epoch 916/1000\n",
      "177/177 [==============================] - 0s 53us/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 3.0708 - val_accuracy: 0.5132\n",
      "Epoch 917/1000\n",
      "177/177 [==============================] - 0s 56us/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 3.0620 - val_accuracy: 0.5263\n",
      "Epoch 918/1000\n",
      "177/177 [==============================] - 0s 57us/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 3.0631 - val_accuracy: 0.5263\n",
      "Epoch 919/1000\n",
      "177/177 [==============================] - 0s 58us/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 3.0740 - val_accuracy: 0.5263\n",
      "Epoch 920/1000\n",
      "177/177 [==============================] - 0s 59us/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 3.0755 - val_accuracy: 0.5263\n",
      "Epoch 921/1000\n",
      "177/177 [==============================] - 0s 87us/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 3.0730 - val_accuracy: 0.5263\n",
      "Epoch 922/1000\n",
      "177/177 [==============================] - 0s 68us/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 3.0668 - val_accuracy: 0.5263\n",
      "Epoch 923/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 3.0669 - val_accuracy: 0.5263\n",
      "Epoch 924/1000\n",
      "177/177 [==============================] - 0s 69us/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 3.0725 - val_accuracy: 0.5263\n",
      "Epoch 925/1000\n",
      "177/177 [==============================] - 0s 58us/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 3.0796 - val_accuracy: 0.5132\n",
      "Epoch 926/1000\n",
      "177/177 [==============================] - 0s 57us/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 3.0792 - val_accuracy: 0.5132\n",
      "Epoch 927/1000\n",
      "177/177 [==============================] - 0s 56us/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 3.0785 - val_accuracy: 0.5132\n",
      "Epoch 928/1000\n",
      "177/177 [==============================] - 0s 54us/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 3.0727 - val_accuracy: 0.5263\n",
      "Epoch 929/1000\n",
      "177/177 [==============================] - 0s 55us/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 3.0725 - val_accuracy: 0.5263\n",
      "Epoch 930/1000\n",
      "177/177 [==============================] - 0s 56us/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 3.0688 - val_accuracy: 0.5263\n",
      "Epoch 931/1000\n",
      "177/177 [==============================] - 0s 57us/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 3.0690 - val_accuracy: 0.5263\n",
      "Epoch 932/1000\n",
      "177/177 [==============================] - 0s 60us/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 3.0716 - val_accuracy: 0.5263\n",
      "Epoch 933/1000\n",
      "177/177 [==============================] - 0s 55us/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 3.0710 - val_accuracy: 0.5263\n",
      "Epoch 934/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 3.0714 - val_accuracy: 0.5263\n",
      "Epoch 935/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 3.0703 - val_accuracy: 0.5263\n",
      "Epoch 936/1000\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 3.0744 - val_accuracy: 0.5263\n",
      "Epoch 937/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 3.0842 - val_accuracy: 0.5132\n",
      "Epoch 938/1000\n",
      "177/177 [==============================] - 0s 50us/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 3.0818 - val_accuracy: 0.5263\n",
      "Epoch 939/1000\n",
      "177/177 [==============================] - 0s 84us/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 3.0776 - val_accuracy: 0.5263\n",
      "Epoch 940/1000\n",
      "177/177 [==============================] - 0s 74us/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 3.0820 - val_accuracy: 0.5263\n",
      "Epoch 941/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 3.0777 - val_accuracy: 0.5263\n",
      "Epoch 942/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 3.0803 - val_accuracy: 0.5263\n",
      "Epoch 943/1000\n",
      "177/177 [==============================] - 0s 91us/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 3.0836 - val_accuracy: 0.5263\n",
      "Epoch 944/1000\n",
      "177/177 [==============================] - 0s 83us/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 3.0906 - val_accuracy: 0.5132\n",
      "Epoch 945/1000\n",
      "177/177 [==============================] - 0s 69us/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 3.0832 - val_accuracy: 0.5263\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 946/1000\n",
      "177/177 [==============================] - 0s 68us/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 3.0808 - val_accuracy: 0.5263\n",
      "Epoch 947/1000\n",
      "177/177 [==============================] - 0s 68us/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 3.0829 - val_accuracy: 0.5263\n",
      "Epoch 948/1000\n",
      "177/177 [==============================] - 0s 94us/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 3.0861 - val_accuracy: 0.5263\n",
      "Epoch 949/1000\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 3.0892 - val_accuracy: 0.5263\n",
      "Epoch 950/1000\n",
      "177/177 [==============================] - 0s 112us/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 3.0942 - val_accuracy: 0.5132\n",
      "Epoch 951/1000\n",
      "177/177 [==============================] - 0s 133us/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 3.0896 - val_accuracy: 0.5263\n",
      "Epoch 952/1000\n",
      "177/177 [==============================] - 0s 84us/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 3.0811 - val_accuracy: 0.5263\n",
      "Epoch 953/1000\n",
      "177/177 [==============================] - 0s 155us/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 3.0783 - val_accuracy: 0.5263\n",
      "Epoch 954/1000\n",
      "177/177 [==============================] - 0s 200us/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 3.0828 - val_accuracy: 0.5263\n",
      "Epoch 955/1000\n",
      "177/177 [==============================] - 0s 110us/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 3.0930 - val_accuracy: 0.5263\n",
      "Epoch 956/1000\n",
      "177/177 [==============================] - 0s 115us/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 3.0894 - val_accuracy: 0.5263\n",
      "Epoch 957/1000\n",
      "177/177 [==============================] - 0s 149us/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 3.0916 - val_accuracy: 0.5263\n",
      "Epoch 958/1000\n",
      "177/177 [==============================] - 0s 396us/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 3.0931 - val_accuracy: 0.5263\n",
      "Epoch 959/1000\n",
      "177/177 [==============================] - 0s 99us/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 3.0921 - val_accuracy: 0.5263\n",
      "Epoch 960/1000\n",
      "177/177 [==============================] - 0s 129us/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 3.0969 - val_accuracy: 0.5263\n",
      "Epoch 961/1000\n",
      "177/177 [==============================] - 0s 236us/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 3.0959 - val_accuracy: 0.5263\n",
      "Epoch 962/1000\n",
      "177/177 [==============================] - 0s 140us/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 3.1039 - val_accuracy: 0.5132\n",
      "Epoch 963/1000\n",
      "177/177 [==============================] - 0s 157us/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 3.0956 - val_accuracy: 0.5263\n",
      "Epoch 964/1000\n",
      "177/177 [==============================] - 0s 75us/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 3.0939 - val_accuracy: 0.5263\n",
      "Epoch 965/1000\n",
      "177/177 [==============================] - 0s 95us/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 3.1008 - val_accuracy: 0.5263\n",
      "Epoch 966/1000\n",
      "177/177 [==============================] - 0s 70us/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 3.1085 - val_accuracy: 0.5132\n",
      "Epoch 967/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 3.1082 - val_accuracy: 0.5132\n",
      "Epoch 968/1000\n",
      "177/177 [==============================] - 0s 84us/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 3.1022 - val_accuracy: 0.5263\n",
      "Epoch 969/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 3.1048 - val_accuracy: 0.5263\n",
      "Epoch 970/1000\n",
      "177/177 [==============================] - 0s 75us/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 3.1011 - val_accuracy: 0.5263\n",
      "Epoch 971/1000\n",
      "177/177 [==============================] - 0s 113us/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 3.1011 - val_accuracy: 0.5263\n",
      "Epoch 972/1000\n",
      "177/177 [==============================] - 0s 78us/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 3.0992 - val_accuracy: 0.5263\n",
      "Epoch 973/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 3.1054 - val_accuracy: 0.5263\n",
      "Epoch 974/1000\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 3.1115 - val_accuracy: 0.5132\n",
      "Epoch 975/1000\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 3.1098 - val_accuracy: 0.5263\n",
      "Epoch 976/1000\n",
      "177/177 [==============================] - 0s 79us/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 3.1109 - val_accuracy: 0.5263\n",
      "Epoch 977/1000\n",
      "177/177 [==============================] - 0s 68us/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 3.1109 - val_accuracy: 0.5263\n",
      "Epoch 978/1000\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 3.1045 - val_accuracy: 0.5263\n",
      "Epoch 979/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 3.1031 - val_accuracy: 0.5263\n",
      "Epoch 980/1000\n",
      "177/177 [==============================] - 0s 78us/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 3.1089 - val_accuracy: 0.5263\n",
      "Epoch 981/1000\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 3.1189 - val_accuracy: 0.5132\n",
      "Epoch 982/1000\n",
      "177/177 [==============================] - 0s 76us/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 3.1154 - val_accuracy: 0.5263\n",
      "Epoch 983/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 3.1158 - val_accuracy: 0.5263\n",
      "Epoch 984/1000\n",
      "177/177 [==============================] - 0s 60us/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 3.1104 - val_accuracy: 0.5263\n",
      "Epoch 985/1000\n",
      "177/177 [==============================] - 0s 63us/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 3.1133 - val_accuracy: 0.5263\n",
      "Epoch 986/1000\n",
      "177/177 [==============================] - 0s 209us/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 3.1242 - val_accuracy: 0.5132\n",
      "Epoch 987/1000\n",
      "177/177 [==============================] - 0s 101us/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 3.1240 - val_accuracy: 0.5132\n",
      "Epoch 988/1000\n",
      "177/177 [==============================] - 0s 105us/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 3.1116 - val_accuracy: 0.5263\n",
      "Epoch 989/1000\n",
      "177/177 [==============================] - 0s 115us/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 3.1119 - val_accuracy: 0.5263\n",
      "Epoch 990/1000\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 3.1206 - val_accuracy: 0.5263\n",
      "Epoch 991/1000\n",
      "177/177 [==============================] - 0s 126us/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 3.1274 - val_accuracy: 0.5132\n",
      "Epoch 992/1000\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 3.1243 - val_accuracy: 0.5263\n",
      "Epoch 993/1000\n",
      "177/177 [==============================] - 0s 168us/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 3.1146 - val_accuracy: 0.5263\n",
      "Epoch 994/1000\n",
      "177/177 [==============================] - 0s 89us/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 3.1174 - val_accuracy: 0.5263\n",
      "Epoch 995/1000\n",
      "177/177 [==============================] - 0s 114us/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 3.1162 - val_accuracy: 0.5263\n",
      "Epoch 996/1000\n",
      "177/177 [==============================] - 0s 189us/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 3.1196 - val_accuracy: 0.5263\n",
      "Epoch 997/1000\n",
      "177/177 [==============================] - 0s 76us/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 3.1328 - val_accuracy: 0.5132\n",
      "Epoch 998/1000\n",
      "177/177 [==============================] - 0s 75us/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 3.1274 - val_accuracy: 0.5263\n",
      "Epoch 999/1000\n",
      "177/177 [==============================] - 0s 89us/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 3.1237 - val_accuracy: 0.5263\n",
      "Epoch 1000/1000\n",
      "177/177 [==============================] - 0s 96us/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 3.1269 - val_accuracy: 0.5263\n"
     ]
    }
   ],
   "source": [
    "hist_sel = model_sel.fit(X_sel_train, y_sel_train,\n",
    "          batch_size=64, epochs=1000,\n",
    "          validation_data=(X_sel_test, y_sel_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 99.59%\n"
     ]
    }
   ],
   "source": [
    "print('train accuracy: %.2f%%' % (np.mean(hist_sel.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba5 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_lasso_2.xlsx\",\n",
    "                        sheet_name=0,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NY360</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.848032e-03</td>\n",
       "      <td>0.996096</td>\n",
       "      <td>0.000056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NRS113</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.441349e-01</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.155850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>120337</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.466081e-02</td>\n",
       "      <td>0.005713</td>\n",
       "      <td>0.979626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>CFBREBSa127</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9.985392e-01</td>\n",
       "      <td>0.000350</td>\n",
       "      <td>0.001111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>GA27</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.665667e-08</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.999995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>CFBREBSa131</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6.617341e-03</td>\n",
       "      <td>0.565843</td>\n",
       "      <td>0.427540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>NRS112</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.055758e-03</td>\n",
       "      <td>0.045611</td>\n",
       "      <td>0.953333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>BCH-SA-06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.747076e-01</td>\n",
       "      <td>0.071162</td>\n",
       "      <td>0.054130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>834N</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.593112e-06</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.999985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>CA9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.838999e-01</td>\n",
       "      <td>0.142659</td>\n",
       "      <td>0.473441</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>608 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     phage       strain  phenotype  prediction             0  \\\n",
       "0       p0017kpresabs_qual        NY360          2           1  3.848032e-03   \n",
       "1       p0017kpresabs_qual       NRS113          0           0  8.441349e-01   \n",
       "2       p0017kpresabs_qual       120337          2           2  1.466081e-02   \n",
       "3       p0017kpresabs_qual  CFBREBSa127          1           0  9.985392e-01   \n",
       "4       p0017kpresabs_qual         GA27          2           2  1.665667e-08   \n",
       "..                     ...          ...        ...         ...           ...   \n",
       "603  p0040presabsSTCC_qual  CFBREBSa131          2           1  6.617341e-03   \n",
       "604  p0040presabsSTCC_qual       NRS112          2           2  1.055758e-03   \n",
       "605  p0040presabsSTCC_qual    BCH-SA-06          0           0  8.747076e-01   \n",
       "606  p0040presabsSTCC_qual         834N          2           2  2.593112e-06   \n",
       "607  p0040presabsSTCC_qual          CA9          1           2  3.838999e-01   \n",
       "\n",
       "            1         2  \n",
       "0    0.996096  0.000056  \n",
       "1    0.000015  0.155850  \n",
       "2    0.005713  0.979626  \n",
       "3    0.000350  0.001111  \n",
       "4    0.000005  0.999995  \n",
       "..        ...       ...  \n",
       "603  0.565843  0.427540  \n",
       "604  0.045611  0.953333  \n",
       "605  0.071162  0.054130  \n",
       "606  0.000013  0.999985  \n",
       "607  0.142659  0.473441  \n",
       "\n",
       "[608 rows x 7 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.51718800e-04, 2.74742440e-03, 9.96500850e-01],\n",
       "       [8.97230000e-01, 6.08902950e-02, 4.18796280e-02],\n",
       "       [7.03720650e-05, 4.70860500e-02, 9.52843550e-01],\n",
       "       [2.88527600e-01, 5.36827740e-01, 1.74644660e-01],\n",
       "       [1.56823560e-02, 5.86308730e-03, 9.78454600e-01],\n",
       "       [1.56823560e-02, 5.86308730e-03, 9.78454600e-01],\n",
       "       [1.36831460e-04, 2.30222500e-02, 9.76841000e-01],\n",
       "       [2.20663850e-04, 3.77053430e-02, 9.62074000e-01],\n",
       "       [2.82139740e-06, 1.99340170e-05, 9.99977230e-01],\n",
       "       [2.77909400e-04, 9.99516370e-01, 2.05717790e-04],\n",
       "       [3.33344770e-04, 9.94445150e-01, 5.22156530e-03],\n",
       "       [9.08604400e-03, 3.01494360e-02, 9.60764500e-01],\n",
       "       [5.34160700e-03, 1.60996360e-01, 8.33662100e-01],\n",
       "       [2.50591040e-01, 6.41792540e-01, 1.07616420e-01],\n",
       "       [2.28065280e-06, 5.25360700e-01, 4.74636970e-01],\n",
       "       [2.56176800e-01, 6.57620650e-02, 6.78061100e-01],\n",
       "       [9.99708600e-01, 2.64059600e-04, 2.72949020e-05],\n",
       "       [1.34376030e-01, 9.95259800e-02, 7.66098000e-01],\n",
       "       [9.88253360e-01, 4.61882180e-04, 1.12847110e-02],\n",
       "       [8.65499750e-05, 3.27547680e-02, 9.67158700e-01],\n",
       "       [2.88527600e-01, 5.36827740e-01, 1.74644660e-01],\n",
       "       [8.16356300e-03, 4.05958180e-01, 5.85878250e-01],\n",
       "       [1.72923400e-01, 1.43129100e-02, 8.12763700e-01],\n",
       "       [9.94496760e-01, 5.49632900e-03, 6.93117140e-06],\n",
       "       [6.55311640e-01, 1.19715850e-03, 3.43491230e-01],\n",
       "       [8.40285200e-05, 9.99832500e-01, 8.34299640e-05],\n",
       "       [9.98652040e-01, 1.20860290e-03, 1.39405090e-04],\n",
       "       [1.29242020e-01, 8.68939040e-01, 1.81892060e-03],\n",
       "       [2.56972820e-02, 1.49816480e-01, 8.24486200e-01],\n",
       "       [9.76098500e-01, 2.38772440e-02, 2.42741730e-05],\n",
       "       [7.93878850e-01, 2.06012250e-01, 1.08881046e-04],\n",
       "       [1.95083160e-07, 2.15402640e-03, 9.97845770e-01],\n",
       "       [6.24014500e-03, 5.36524430e-02, 9.40107460e-01],\n",
       "       [2.10317500e-01, 7.74605150e-01, 1.50774070e-02],\n",
       "       [4.68628080e-01, 4.88096330e-01, 4.32755100e-02],\n",
       "       [9.98687300e-01, 1.17514030e-03, 1.37495750e-04],\n",
       "       [1.23311780e-01, 7.31262100e-01, 1.45426120e-01],\n",
       "       [5.22019400e-04, 2.14394390e-01, 7.85083600e-01],\n",
       "       [1.56823560e-02, 5.86308730e-03, 9.78454600e-01],\n",
       "       [9.62282900e-03, 9.90377000e-01, 2.23230510e-07],\n",
       "       [7.53282600e-01, 3.13198850e-03, 2.43585440e-01],\n",
       "       [9.13684900e-01, 8.61868900e-02, 1.28219780e-04],\n",
       "       [1.50745810e-02, 3.09893400e-01, 6.75032000e-01],\n",
       "       [2.08428740e-02, 1.14926050e-04, 9.79042230e-01],\n",
       "       [1.29159410e-03, 9.96993540e-01, 1.71490040e-03],\n",
       "       [1.55879860e-05, 1.16651530e-03, 9.98817860e-01],\n",
       "       [6.07233000e-03, 8.61256850e-03, 9.85315100e-01],\n",
       "       [9.91947950e-01, 1.12287344e-04, 7.93974700e-03],\n",
       "       [3.24751360e-02, 1.00173560e-01, 8.67351300e-01],\n",
       "       [3.68456650e-02, 9.54297900e-01, 8.85645200e-03],\n",
       "       [4.50809200e-02, 9.30923340e-01, 2.39956830e-02],\n",
       "       [1.08398590e-03, 3.87937250e-01, 6.10978800e-01],\n",
       "       [7.76119950e-01, 2.11404340e-01, 1.24756480e-02],\n",
       "       [7.55715900e-02, 9.02180900e-01, 2.22474950e-02],\n",
       "       [8.21575800e-03, 9.91760730e-01, 2.34984900e-05],\n",
       "       [1.53022720e-02, 8.48054100e-01, 1.36643590e-01],\n",
       "       [9.82312700e-05, 9.83287600e-01, 1.66142360e-02],\n",
       "       [3.79594240e-08, 9.93685800e-01, 6.31418200e-03],\n",
       "       [7.44800600e-04, 9.39740540e-01, 5.95147100e-02],\n",
       "       [8.45771300e-02, 4.45112880e-01, 4.70310000e-01],\n",
       "       [1.98745990e-02, 2.93704540e-01, 6.86420860e-01],\n",
       "       [7.55715900e-02, 9.02180900e-01, 2.22474950e-02],\n",
       "       [9.98982600e-01, 2.41643240e-04, 7.75714300e-04],\n",
       "       [8.97230000e-01, 6.08902950e-02, 4.18796280e-02],\n",
       "       [4.89882300e-07, 1.78074170e-02, 9.82192100e-01],\n",
       "       [8.36710000e-03, 9.91613270e-01, 1.95757300e-05],\n",
       "       [3.61386900e-01, 3.36794050e-01, 3.01819060e-01],\n",
       "       [1.28557110e-03, 5.22821800e-01, 4.75892570e-01],\n",
       "       [8.58783350e-02, 2.04445440e-01, 7.09676150e-01],\n",
       "       [1.34868020e-03, 1.33814960e-02, 9.85269840e-01],\n",
       "       [7.96117800e-03, 9.91693100e-01, 3.45713580e-04],\n",
       "       [6.61734070e-03, 5.65843050e-01, 4.27539650e-01],\n",
       "       [1.05575820e-03, 4.56111840e-02, 9.53333000e-01],\n",
       "       [8.74707640e-01, 7.11623060e-02, 5.41300200e-02],\n",
       "       [2.59311240e-06, 1.25718925e-05, 9.99984860e-01],\n",
       "       [3.83899870e-01, 1.42659130e-01, 4.73440970e-01]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob5 = df_proba5[df_proba5['phage']=='p0040presabsSTCC_qual'].iloc[:,-3:]\n",
    "y_prob5 = y_prob5.to_numpy()\n",
    "y_prob5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6868501362427706"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo5 = rocauc_ovo(y_sel_test, y_prob5, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6868501362427706"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr5 = rocauc_ovr(y_sel_test, y_prob5, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_sel_train, X_sel_test, y_sel_train, y_sel_test = train_test_split(X_sel, y_sel,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=678,\n",
    "                                                    stratify=y_sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat6 = pd.DataFrame(X_sel_test.iloc[:,-1])\n",
    "dat6['test'] = y_sel_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strain</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>NRS169</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>NRS249</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>NRS262</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>SR1746</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>NRS029</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>GA27</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>GA231</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>SR1287</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>506</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>NRS001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     strain  test\n",
       "152  NRS169     1\n",
       "210  NRS249     2\n",
       "218  NRS262     2\n",
       "238  SR1746     1\n",
       "113  NRS029     1\n",
       "..      ...   ...\n",
       "96     GA27     2\n",
       "95    GA231     2\n",
       "237  SR1287     0\n",
       "14      506     2\n",
       "107  NRS001     1\n",
       "\n",
       "[76 rows x 2 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sel_train = X_sel_train.drop(['strain'], axis=1)\n",
    "X_sel_test = X_sel_test.drop(['strain'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sel2 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_sel_train.shape[1],)),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sel2.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 177 samples, validate on 76 samples\n",
      "Epoch 1/1000\n",
      "177/177 [==============================] - 0s 693us/step - loss: 11.0636 - accuracy: 0.3672 - val_loss: 7.6774 - val_accuracy: 0.4211\n",
      "Epoch 2/1000\n",
      "177/177 [==============================] - 0s 145us/step - loss: 6.2336 - accuracy: 0.4011 - val_loss: 3.9471 - val_accuracy: 0.3684\n",
      "Epoch 3/1000\n",
      "177/177 [==============================] - 0s 195us/step - loss: 2.7264 - accuracy: 0.3785 - val_loss: 1.9062 - val_accuracy: 0.3026\n",
      "Epoch 4/1000\n",
      "177/177 [==============================] - 0s 171us/step - loss: 1.3789 - accuracy: 0.4689 - val_loss: 1.1360 - val_accuracy: 0.4474\n",
      "Epoch 5/1000\n",
      "177/177 [==============================] - 0s 197us/step - loss: 1.2389 - accuracy: 0.5198 - val_loss: 1.0760 - val_accuracy: 0.4737\n",
      "Epoch 6/1000\n",
      "177/177 [==============================] - 0s 157us/step - loss: 1.2594 - accuracy: 0.4802 - val_loss: 1.1577 - val_accuracy: 0.4474\n",
      "Epoch 7/1000\n",
      "177/177 [==============================] - 0s 166us/step - loss: 1.2218 - accuracy: 0.5480 - val_loss: 1.1606 - val_accuracy: 0.5132\n",
      "Epoch 8/1000\n",
      "177/177 [==============================] - 0s 190us/step - loss: 1.2612 - accuracy: 0.5311 - val_loss: 1.1264 - val_accuracy: 0.3816\n",
      "Epoch 9/1000\n",
      "177/177 [==============================] - 0s 171us/step - loss: 1.1879 - accuracy: 0.5650 - val_loss: 1.1100 - val_accuracy: 0.4079\n",
      "Epoch 10/1000\n",
      "177/177 [==============================] - 0s 199us/step - loss: 0.9778 - accuracy: 0.5763 - val_loss: 1.0326 - val_accuracy: 0.5000\n",
      "Epoch 11/1000\n",
      "177/177 [==============================] - 0s 164us/step - loss: 1.1069 - accuracy: 0.5876 - val_loss: 1.0551 - val_accuracy: 0.4342\n",
      "Epoch 12/1000\n",
      "177/177 [==============================] - 0s 212us/step - loss: 1.1295 - accuracy: 0.6158 - val_loss: 1.0773 - val_accuracy: 0.4605\n",
      "Epoch 13/1000\n",
      "177/177 [==============================] - 0s 219us/step - loss: 1.0269 - accuracy: 0.6384 - val_loss: 1.0075 - val_accuracy: 0.4079\n",
      "Epoch 14/1000\n",
      "177/177 [==============================] - 0s 197us/step - loss: 1.2446 - accuracy: 0.6045 - val_loss: 1.1455 - val_accuracy: 0.4474\n",
      "Epoch 15/1000\n",
      "177/177 [==============================] - 0s 244us/step - loss: 1.1203 - accuracy: 0.5876 - val_loss: 1.0417 - val_accuracy: 0.4342\n",
      "Epoch 16/1000\n",
      "177/177 [==============================] - 0s 254us/step - loss: 0.8442 - accuracy: 0.6384 - val_loss: 1.0387 - val_accuracy: 0.4079\n",
      "Epoch 17/1000\n",
      "177/177 [==============================] - 0s 190us/step - loss: 0.8636 - accuracy: 0.6554 - val_loss: 1.0150 - val_accuracy: 0.4737\n",
      "Epoch 18/1000\n",
      "177/177 [==============================] - 0s 273us/step - loss: 0.9027 - accuracy: 0.6723 - val_loss: 0.9871 - val_accuracy: 0.4474\n",
      "Epoch 19/1000\n",
      "177/177 [==============================] - 0s 243us/step - loss: 0.8568 - accuracy: 0.6836 - val_loss: 0.9779 - val_accuracy: 0.4605\n",
      "Epoch 20/1000\n",
      "177/177 [==============================] - 0s 232us/step - loss: 0.8501 - accuracy: 0.6723 - val_loss: 0.9713 - val_accuracy: 0.4342\n",
      "Epoch 21/1000\n",
      "177/177 [==============================] - 0s 196us/step - loss: 0.8260 - accuracy: 0.6667 - val_loss: 1.0929 - val_accuracy: 0.4474\n",
      "Epoch 22/1000\n",
      "177/177 [==============================] - 0s 235us/step - loss: 0.9387 - accuracy: 0.6554 - val_loss: 0.9618 - val_accuracy: 0.4474\n",
      "Epoch 23/1000\n",
      "177/177 [==============================] - 0s 183us/step - loss: 0.8484 - accuracy: 0.6723 - val_loss: 1.0939 - val_accuracy: 0.4474\n",
      "Epoch 24/1000\n",
      "177/177 [==============================] - 0s 255us/step - loss: 1.0250 - accuracy: 0.6667 - val_loss: 0.9794 - val_accuracy: 0.4342\n",
      "Epoch 25/1000\n",
      "177/177 [==============================] - 0s 376us/step - loss: 0.8401 - accuracy: 0.7119 - val_loss: 0.9838 - val_accuracy: 0.4474\n",
      "Epoch 26/1000\n",
      "177/177 [==============================] - 0s 480us/step - loss: 0.7572 - accuracy: 0.7232 - val_loss: 1.3045 - val_accuracy: 0.4342\n",
      "Epoch 27/1000\n",
      "177/177 [==============================] - 0s 294us/step - loss: 0.8324 - accuracy: 0.7119 - val_loss: 1.0055 - val_accuracy: 0.4474\n",
      "Epoch 28/1000\n",
      "177/177 [==============================] - 0s 210us/step - loss: 0.7617 - accuracy: 0.7062 - val_loss: 1.1366 - val_accuracy: 0.4079\n",
      "Epoch 29/1000\n",
      "177/177 [==============================] - 0s 202us/step - loss: 0.9712 - accuracy: 0.7175 - val_loss: 0.9782 - val_accuracy: 0.4605\n",
      "Epoch 30/1000\n",
      "177/177 [==============================] - 0s 154us/step - loss: 0.8321 - accuracy: 0.7175 - val_loss: 1.2675 - val_accuracy: 0.4605\n",
      "Epoch 31/1000\n",
      "177/177 [==============================] - 0s 167us/step - loss: 1.3136 - accuracy: 0.6610 - val_loss: 1.5822 - val_accuracy: 0.4079\n",
      "Epoch 32/1000\n",
      "177/177 [==============================] - 0s 192us/step - loss: 1.0214 - accuracy: 0.7458 - val_loss: 1.1183 - val_accuracy: 0.5000\n",
      "Epoch 33/1000\n",
      "177/177 [==============================] - 0s 162us/step - loss: 0.7567 - accuracy: 0.7119 - val_loss: 1.3871 - val_accuracy: 0.4211\n",
      "Epoch 34/1000\n",
      "177/177 [==============================] - 0s 245us/step - loss: 1.0271 - accuracy: 0.6949 - val_loss: 1.0649 - val_accuracy: 0.4605\n",
      "Epoch 35/1000\n",
      "177/177 [==============================] - 0s 154us/step - loss: 0.8748 - accuracy: 0.7119 - val_loss: 1.0826 - val_accuracy: 0.4474\n",
      "Epoch 36/1000\n",
      "177/177 [==============================] - 0s 189us/step - loss: 0.8428 - accuracy: 0.7797 - val_loss: 1.0203 - val_accuracy: 0.5000\n",
      "Epoch 37/1000\n",
      "177/177 [==============================] - 0s 132us/step - loss: 0.8429 - accuracy: 0.7119 - val_loss: 1.0013 - val_accuracy: 0.4605\n",
      "Epoch 38/1000\n",
      "177/177 [==============================] - 0s 315us/step - loss: 0.6522 - accuracy: 0.8192 - val_loss: 1.1061 - val_accuracy: 0.4079\n",
      "Epoch 39/1000\n",
      "177/177 [==============================] - 0s 172us/step - loss: 0.7745 - accuracy: 0.7797 - val_loss: 1.1402 - val_accuracy: 0.4737\n",
      "Epoch 40/1000\n",
      "177/177 [==============================] - 0s 210us/step - loss: 1.0094 - accuracy: 0.7627 - val_loss: 1.0858 - val_accuracy: 0.4737\n",
      "Epoch 41/1000\n",
      "177/177 [==============================] - 0s 193us/step - loss: 0.6899 - accuracy: 0.7627 - val_loss: 0.9661 - val_accuracy: 0.4605\n",
      "Epoch 42/1000\n",
      "177/177 [==============================] - 0s 191us/step - loss: 0.6701 - accuracy: 0.7966 - val_loss: 1.0623 - val_accuracy: 0.5132\n",
      "Epoch 43/1000\n",
      "177/177 [==============================] - 0s 244us/step - loss: 0.6514 - accuracy: 0.8249 - val_loss: 1.0047 - val_accuracy: 0.5000\n",
      "Epoch 44/1000\n",
      "177/177 [==============================] - 0s 253us/step - loss: 0.6778 - accuracy: 0.8136 - val_loss: 0.9793 - val_accuracy: 0.5000\n",
      "Epoch 45/1000\n",
      "177/177 [==============================] - 0s 208us/step - loss: 0.5966 - accuracy: 0.8023 - val_loss: 0.9897 - val_accuracy: 0.4868\n",
      "Epoch 46/1000\n",
      "177/177 [==============================] - 0s 181us/step - loss: 0.8417 - accuracy: 0.7684 - val_loss: 1.0483 - val_accuracy: 0.4868\n",
      "Epoch 47/1000\n",
      "177/177 [==============================] - 0s 401us/step - loss: 1.0404 - accuracy: 0.7232 - val_loss: 1.3048 - val_accuracy: 0.4342\n",
      "Epoch 48/1000\n",
      "177/177 [==============================] - 0s 176us/step - loss: 0.9692 - accuracy: 0.7288 - val_loss: 1.1527 - val_accuracy: 0.4737\n",
      "Epoch 49/1000\n",
      "177/177 [==============================] - 0s 198us/step - loss: 0.6727 - accuracy: 0.7853 - val_loss: 1.1249 - val_accuracy: 0.5000\n",
      "Epoch 50/1000\n",
      "177/177 [==============================] - 0s 223us/step - loss: 0.7507 - accuracy: 0.7966 - val_loss: 1.0625 - val_accuracy: 0.5000\n",
      "Epoch 51/1000\n",
      "177/177 [==============================] - 0s 142us/step - loss: 0.9078 - accuracy: 0.8023 - val_loss: 1.0775 - val_accuracy: 0.5132\n",
      "Epoch 52/1000\n",
      "177/177 [==============================] - 0s 155us/step - loss: 4.0508 - accuracy: 0.7571 - val_loss: 3.0807 - val_accuracy: 0.4737\n",
      "Epoch 53/1000\n",
      "177/177 [==============================] - 0s 127us/step - loss: 4.4394 - accuracy: 0.7684 - val_loss: 2.7677 - val_accuracy: 0.5000\n",
      "Epoch 54/1000\n",
      "177/177 [==============================] - 0s 123us/step - loss: 3.8045 - accuracy: 0.7966 - val_loss: 2.5287 - val_accuracy: 0.4868\n",
      "Epoch 55/1000\n",
      "177/177 [==============================] - 0s 118us/step - loss: 3.2315 - accuracy: 0.7797 - val_loss: 2.0874 - val_accuracy: 0.4868\n",
      "Epoch 56/1000\n",
      "177/177 [==============================] - 0s 146us/step - loss: 2.5438 - accuracy: 0.8023 - val_loss: 1.4649 - val_accuracy: 0.4737\n",
      "Epoch 57/1000\n",
      "177/177 [==============================] - 0s 123us/step - loss: 1.4712 - accuracy: 0.8079 - val_loss: 1.2166 - val_accuracy: 0.4605\n",
      "Epoch 58/1000\n",
      "177/177 [==============================] - 0s 238us/step - loss: 0.7734 - accuracy: 0.7966 - val_loss: 1.1618 - val_accuracy: 0.4868\n",
      "Epoch 59/1000\n",
      "177/177 [==============================] - 0s 363us/step - loss: 0.6345 - accuracy: 0.7797 - val_loss: 1.0861 - val_accuracy: 0.4737\n",
      "Epoch 60/1000\n",
      "177/177 [==============================] - 0s 331us/step - loss: 0.6654 - accuracy: 0.8418 - val_loss: 1.1547 - val_accuracy: 0.3947\n",
      "Epoch 61/1000\n",
      "177/177 [==============================] - 0s 282us/step - loss: 0.5778 - accuracy: 0.8192 - val_loss: 1.1403 - val_accuracy: 0.4737\n",
      "Epoch 62/1000\n",
      "177/177 [==============================] - 0s 321us/step - loss: 0.5803 - accuracy: 0.8136 - val_loss: 1.0528 - val_accuracy: 0.4737\n",
      "Epoch 63/1000\n",
      "177/177 [==============================] - 0s 243us/step - loss: 0.8924 - accuracy: 0.8136 - val_loss: 1.1763 - val_accuracy: 0.4605\n",
      "Epoch 64/1000\n",
      "177/177 [==============================] - ETA: 0s - loss: 0.4811 - accuracy: 0.87 - 0s 280us/step - loss: 0.6639 - accuracy: 0.8249 - val_loss: 1.0639 - val_accuracy: 0.4737\n",
      "Epoch 65/1000\n",
      "177/177 [==============================] - 0s 268us/step - loss: 0.6002 - accuracy: 0.8192 - val_loss: 1.3464 - val_accuracy: 0.4605\n",
      "Epoch 66/1000\n",
      "177/177 [==============================] - 0s 169us/step - loss: 3.1028 - accuracy: 0.7345 - val_loss: 3.6532 - val_accuracy: 0.4079\n",
      "Epoch 67/1000\n",
      "177/177 [==============================] - 0s 279us/step - loss: 4.3376 - accuracy: 0.7401 - val_loss: 2.1490 - val_accuracy: 0.4342\n",
      "Epoch 68/1000\n",
      "177/177 [==============================] - 0s 259us/step - loss: 2.5453 - accuracy: 0.7458 - val_loss: 1.6145 - val_accuracy: 0.5132\n",
      "Epoch 69/1000\n",
      "177/177 [==============================] - 0s 326us/step - loss: 1.6478 - accuracy: 0.7458 - val_loss: 1.3786 - val_accuracy: 0.4342\n",
      "Epoch 70/1000\n",
      "177/177 [==============================] - 0s 299us/step - loss: 0.8374 - accuracy: 0.7345 - val_loss: 1.2382 - val_accuracy: 0.5000\n",
      "Epoch 71/1000\n",
      "177/177 [==============================] - 0s 236us/step - loss: 0.8712 - accuracy: 0.8023 - val_loss: 1.5386 - val_accuracy: 0.5000\n",
      "Epoch 72/1000\n",
      "177/177 [==============================] - 0s 269us/step - loss: 0.6055 - accuracy: 0.8418 - val_loss: 1.1337 - val_accuracy: 0.5263\n",
      "Epoch 73/1000\n",
      "177/177 [==============================] - 0s 291us/step - loss: 0.6350 - accuracy: 0.8362 - val_loss: 1.1468 - val_accuracy: 0.5263\n",
      "Epoch 74/1000\n",
      "177/177 [==============================] - 0s 229us/step - loss: 0.4957 - accuracy: 0.8531 - val_loss: 1.1657 - val_accuracy: 0.5263\n",
      "Epoch 75/1000\n",
      "177/177 [==============================] - 0s 289us/step - loss: 0.4708 - accuracy: 0.8362 - val_loss: 1.1449 - val_accuracy: 0.4868\n",
      "Epoch 76/1000\n",
      "177/177 [==============================] - 0s 237us/step - loss: 0.6672 - accuracy: 0.8588 - val_loss: 1.1139 - val_accuracy: 0.5000\n",
      "Epoch 77/1000\n",
      "177/177 [==============================] - 0s 262us/step - loss: 0.4941 - accuracy: 0.8757 - val_loss: 1.1457 - val_accuracy: 0.5263\n",
      "Epoch 78/1000\n",
      "177/177 [==============================] - 0s 205us/step - loss: 0.4878 - accuracy: 0.8588 - val_loss: 1.1212 - val_accuracy: 0.5395\n",
      "Epoch 79/1000\n",
      "177/177 [==============================] - 0s 239us/step - loss: 0.4213 - accuracy: 0.8701 - val_loss: 1.1190 - val_accuracy: 0.5132\n",
      "Epoch 80/1000\n",
      "177/177 [==============================] - 0s 264us/step - loss: 0.5746 - accuracy: 0.8588 - val_loss: 1.2148 - val_accuracy: 0.5132\n",
      "Epoch 81/1000\n",
      "177/177 [==============================] - 0s 179us/step - loss: 0.4895 - accuracy: 0.8701 - val_loss: 1.1711 - val_accuracy: 0.5132\n",
      "Epoch 82/1000\n",
      "177/177 [==============================] - 0s 256us/step - loss: 0.4381 - accuracy: 0.8814 - val_loss: 1.1815 - val_accuracy: 0.5395\n",
      "Epoch 83/1000\n",
      "177/177 [==============================] - 0s 271us/step - loss: 0.4571 - accuracy: 0.8757 - val_loss: 1.1505 - val_accuracy: 0.5526\n",
      "Epoch 84/1000\n",
      "177/177 [==============================] - 0s 296us/step - loss: 0.4686 - accuracy: 0.8870 - val_loss: 1.1293 - val_accuracy: 0.4868\n",
      "Epoch 85/1000\n",
      "177/177 [==============================] - 0s 314us/step - loss: 0.5003 - accuracy: 0.8531 - val_loss: 1.1498 - val_accuracy: 0.5395\n",
      "Epoch 86/1000\n",
      "177/177 [==============================] - 0s 242us/step - loss: 0.4135 - accuracy: 0.8757 - val_loss: 1.1606 - val_accuracy: 0.5132\n",
      "Epoch 87/1000\n",
      "177/177 [==============================] - 0s 287us/step - loss: 0.4372 - accuracy: 0.8870 - val_loss: 1.1867 - val_accuracy: 0.5526\n",
      "Epoch 88/1000\n",
      "177/177 [==============================] - 0s 187us/step - loss: 0.4681 - accuracy: 0.8644 - val_loss: 1.2199 - val_accuracy: 0.5658\n",
      "Epoch 89/1000\n",
      "177/177 [==============================] - 0s 328us/step - loss: 0.4282 - accuracy: 0.8644 - val_loss: 1.1232 - val_accuracy: 0.5132\n",
      "Epoch 90/1000\n",
      "177/177 [==============================] - 0s 290us/step - loss: 0.5017 - accuracy: 0.8757 - val_loss: 1.1674 - val_accuracy: 0.5263\n",
      "Epoch 91/1000\n",
      "177/177 [==============================] - 0s 320us/step - loss: 0.4050 - accuracy: 0.9153 - val_loss: 1.3307 - val_accuracy: 0.5000\n",
      "Epoch 92/1000\n",
      "177/177 [==============================] - 0s 286us/step - loss: 0.5152 - accuracy: 0.8814 - val_loss: 1.2257 - val_accuracy: 0.4868\n",
      "Epoch 93/1000\n",
      "177/177 [==============================] - 0s 272us/step - loss: 0.4449 - accuracy: 0.8531 - val_loss: 1.1952 - val_accuracy: 0.5132\n",
      "Epoch 94/1000\n",
      "177/177 [==============================] - 0s 206us/step - loss: 0.4685 - accuracy: 0.8814 - val_loss: 1.2584 - val_accuracy: 0.5000\n",
      "Epoch 95/1000\n",
      "177/177 [==============================] - 0s 166us/step - loss: 0.4887 - accuracy: 0.8757 - val_loss: 1.2537 - val_accuracy: 0.4868\n",
      "Epoch 96/1000\n",
      "177/177 [==============================] - 0s 137us/step - loss: 0.5135 - accuracy: 0.8870 - val_loss: 1.3306 - val_accuracy: 0.4737\n",
      "Epoch 97/1000\n",
      "177/177 [==============================] - 0s 121us/step - loss: 0.8957 - accuracy: 0.8644 - val_loss: 1.3537 - val_accuracy: 0.5263\n",
      "Epoch 98/1000\n",
      "177/177 [==============================] - 0s 144us/step - loss: 0.6831 - accuracy: 0.8644 - val_loss: 1.3164 - val_accuracy: 0.4737\n",
      "Epoch 99/1000\n",
      "177/177 [==============================] - 0s 116us/step - loss: 0.6417 - accuracy: 0.8701 - val_loss: 1.3488 - val_accuracy: 0.5132\n",
      "Epoch 100/1000\n",
      "177/177 [==============================] - 0s 119us/step - loss: 0.6001 - accuracy: 0.8418 - val_loss: 1.3734 - val_accuracy: 0.5132\n",
      "Epoch 101/1000\n",
      "177/177 [==============================] - 0s 141us/step - loss: 0.5514 - accuracy: 0.8588 - val_loss: 1.4834 - val_accuracy: 0.5132\n",
      "Epoch 102/1000\n",
      "177/177 [==============================] - 0s 118us/step - loss: 0.4124 - accuracy: 0.8870 - val_loss: 1.2216 - val_accuracy: 0.5526\n",
      "Epoch 103/1000\n",
      "177/177 [==============================] - 0s 126us/step - loss: 0.3601 - accuracy: 0.8927 - val_loss: 1.2087 - val_accuracy: 0.5395\n",
      "Epoch 104/1000\n",
      "177/177 [==============================] - 0s 130us/step - loss: 0.3513 - accuracy: 0.9040 - val_loss: 1.1949 - val_accuracy: 0.5395\n",
      "Epoch 105/1000\n",
      "177/177 [==============================] - 0s 129us/step - loss: 0.4260 - accuracy: 0.8983 - val_loss: 1.1825 - val_accuracy: 0.5526\n",
      "Epoch 106/1000\n",
      "177/177 [==============================] - 0s 118us/step - loss: 0.4548 - accuracy: 0.8870 - val_loss: 1.3010 - val_accuracy: 0.5000\n",
      "Epoch 107/1000\n",
      "177/177 [==============================] - 0s 117us/step - loss: 0.4007 - accuracy: 0.8644 - val_loss: 1.2408 - val_accuracy: 0.5263\n",
      "Epoch 108/1000\n",
      "177/177 [==============================] - 0s 139us/step - loss: 0.3510 - accuracy: 0.8983 - val_loss: 1.4474 - val_accuracy: 0.5000\n",
      "Epoch 109/1000\n",
      "177/177 [==============================] - 0s 118us/step - loss: 0.5233 - accuracy: 0.8757 - val_loss: 1.2745 - val_accuracy: 0.5526\n",
      "Epoch 110/1000\n",
      "177/177 [==============================] - 0s 119us/step - loss: 0.3783 - accuracy: 0.9096 - val_loss: 1.2293 - val_accuracy: 0.4868\n",
      "Epoch 111/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177/177 [==============================] - 0s 119us/step - loss: 0.4583 - accuracy: 0.8927 - val_loss: 1.2551 - val_accuracy: 0.5263\n",
      "Epoch 112/1000\n",
      "177/177 [==============================] - 0s 135us/step - loss: 0.4491 - accuracy: 0.8983 - val_loss: 1.2316 - val_accuracy: 0.5132\n",
      "Epoch 113/1000\n",
      "177/177 [==============================] - 0s 112us/step - loss: 0.3863 - accuracy: 0.8983 - val_loss: 1.2906 - val_accuracy: 0.5132\n",
      "Epoch 114/1000\n",
      "177/177 [==============================] - 0s 118us/step - loss: 0.3729 - accuracy: 0.9040 - val_loss: 1.2399 - val_accuracy: 0.5526\n",
      "Epoch 115/1000\n",
      "177/177 [==============================] - 0s 120us/step - loss: 0.2952 - accuracy: 0.9209 - val_loss: 1.2554 - val_accuracy: 0.4737\n",
      "Epoch 116/1000\n",
      "177/177 [==============================] - 0s 139us/step - loss: 0.4063 - accuracy: 0.8983 - val_loss: 1.3251 - val_accuracy: 0.4737\n",
      "Epoch 117/1000\n",
      "177/177 [==============================] - 0s 212us/step - loss: 0.4822 - accuracy: 0.8757 - val_loss: 1.3190 - val_accuracy: 0.5132\n",
      "Epoch 118/1000\n",
      "177/177 [==============================] - 0s 184us/step - loss: 0.4381 - accuracy: 0.9096 - val_loss: 1.3204 - val_accuracy: 0.5000\n",
      "Epoch 119/1000\n",
      "177/177 [==============================] - 0s 175us/step - loss: 0.3663 - accuracy: 0.9096 - val_loss: 1.3454 - val_accuracy: 0.5132\n",
      "Epoch 120/1000\n",
      "177/177 [==============================] - 0s 178us/step - loss: 0.3436 - accuracy: 0.9266 - val_loss: 1.3529 - val_accuracy: 0.5395\n",
      "Epoch 121/1000\n",
      "177/177 [==============================] - 0s 165us/step - loss: 0.3546 - accuracy: 0.9153 - val_loss: 1.3175 - val_accuracy: 0.5132\n",
      "Epoch 122/1000\n",
      "177/177 [==============================] - 0s 173us/step - loss: 0.3095 - accuracy: 0.9153 - val_loss: 1.2705 - val_accuracy: 0.5526\n",
      "Epoch 123/1000\n",
      "177/177 [==============================] - 0s 177us/step - loss: 0.3738 - accuracy: 0.9153 - val_loss: 1.3761 - val_accuracy: 0.5263\n",
      "Epoch 124/1000\n",
      "177/177 [==============================] - 0s 143us/step - loss: 0.3745 - accuracy: 0.9266 - val_loss: 1.3028 - val_accuracy: 0.5395\n",
      "Epoch 125/1000\n",
      "177/177 [==============================] - 0s 137us/step - loss: 0.3502 - accuracy: 0.9040 - val_loss: 1.3881 - val_accuracy: 0.5000\n",
      "Epoch 126/1000\n",
      "177/177 [==============================] - 0s 151us/step - loss: 0.4512 - accuracy: 0.9153 - val_loss: 1.4245 - val_accuracy: 0.5395\n",
      "Epoch 127/1000\n",
      "177/177 [==============================] - 0s 125us/step - loss: 0.3757 - accuracy: 0.9209 - val_loss: 1.3551 - val_accuracy: 0.5395\n",
      "Epoch 128/1000\n",
      "177/177 [==============================] - 0s 132us/step - loss: 0.3438 - accuracy: 0.9266 - val_loss: 1.3440 - val_accuracy: 0.5263\n",
      "Epoch 129/1000\n",
      "177/177 [==============================] - 0s 132us/step - loss: 0.3174 - accuracy: 0.9266 - val_loss: 1.3494 - val_accuracy: 0.5395\n",
      "Epoch 130/1000\n",
      "177/177 [==============================] - 0s 139us/step - loss: 0.3573 - accuracy: 0.9153 - val_loss: 1.2855 - val_accuracy: 0.5658\n",
      "Epoch 131/1000\n",
      "177/177 [==============================] - 0s 165us/step - loss: 0.4091 - accuracy: 0.8983 - val_loss: 1.2581 - val_accuracy: 0.5395\n",
      "Epoch 132/1000\n",
      "177/177 [==============================] - 0s 282us/step - loss: 0.2603 - accuracy: 0.9322 - val_loss: 1.3758 - val_accuracy: 0.5132\n",
      "Epoch 133/1000\n",
      "177/177 [==============================] - 0s 362us/step - loss: 0.2976 - accuracy: 0.9096 - val_loss: 1.3217 - val_accuracy: 0.5395\n",
      "Epoch 134/1000\n",
      "177/177 [==============================] - 0s 412us/step - loss: 0.3735 - accuracy: 0.9096 - val_loss: 1.5442 - val_accuracy: 0.5000\n",
      "Epoch 135/1000\n",
      "177/177 [==============================] - ETA: 0s - loss: 1.7026 - accuracy: 0.87 - 0s 238us/step - loss: 0.3966 - accuracy: 0.9209 - val_loss: 1.3313 - val_accuracy: 0.5263\n",
      "Epoch 136/1000\n",
      "177/177 [==============================] - 0s 277us/step - loss: 0.3515 - accuracy: 0.9153 - val_loss: 1.3425 - val_accuracy: 0.5132\n",
      "Epoch 137/1000\n",
      "177/177 [==============================] - 0s 286us/step - loss: 0.4621 - accuracy: 0.9040 - val_loss: 1.3571 - val_accuracy: 0.5263\n",
      "Epoch 138/1000\n",
      "177/177 [==============================] - 0s 226us/step - loss: 0.5528 - accuracy: 0.9153 - val_loss: 1.4707 - val_accuracy: 0.5263\n",
      "Epoch 139/1000\n",
      "177/177 [==============================] - 0s 266us/step - loss: 0.4502 - accuracy: 0.8927 - val_loss: 1.3907 - val_accuracy: 0.5263\n",
      "Epoch 140/1000\n",
      "177/177 [==============================] - 0s 242us/step - loss: 0.2530 - accuracy: 0.9153 - val_loss: 1.3674 - val_accuracy: 0.5395\n",
      "Epoch 141/1000\n",
      "177/177 [==============================] - 0s 197us/step - loss: 0.3333 - accuracy: 0.9266 - val_loss: 1.2727 - val_accuracy: 0.5263\n",
      "Epoch 142/1000\n",
      "177/177 [==============================] - 0s 246us/step - loss: 0.5275 - accuracy: 0.8814 - val_loss: 1.4044 - val_accuracy: 0.5000\n",
      "Epoch 143/1000\n",
      "177/177 [==============================] - 0s 141us/step - loss: 0.4659 - accuracy: 0.9040 - val_loss: 1.4426 - val_accuracy: 0.5000\n",
      "Epoch 144/1000\n",
      "177/177 [==============================] - 0s 130us/step - loss: 0.3164 - accuracy: 0.9153 - val_loss: 1.3490 - val_accuracy: 0.5395\n",
      "Epoch 145/1000\n",
      "177/177 [==============================] - 0s 128us/step - loss: 0.3949 - accuracy: 0.9096 - val_loss: 1.4377 - val_accuracy: 0.5263\n",
      "Epoch 146/1000\n",
      "177/177 [==============================] - 0s 147us/step - loss: 0.3198 - accuracy: 0.8983 - val_loss: 1.4593 - val_accuracy: 0.5263\n",
      "Epoch 147/1000\n",
      "177/177 [==============================] - 0s 129us/step - loss: 0.3199 - accuracy: 0.9096 - val_loss: 1.4181 - val_accuracy: 0.5526\n",
      "Epoch 148/1000\n",
      "177/177 [==============================] - 0s 113us/step - loss: 0.2834 - accuracy: 0.9040 - val_loss: 1.3636 - val_accuracy: 0.5263\n",
      "Epoch 149/1000\n",
      "177/177 [==============================] - 0s 137us/step - loss: 0.2758 - accuracy: 0.9153 - val_loss: 1.5813 - val_accuracy: 0.5526\n",
      "Epoch 150/1000\n",
      "177/177 [==============================] - 0s 117us/step - loss: 0.2781 - accuracy: 0.9153 - val_loss: 1.5124 - val_accuracy: 0.5526\n",
      "Epoch 151/1000\n",
      "177/177 [==============================] - 0s 138us/step - loss: 0.2810 - accuracy: 0.9209 - val_loss: 1.4169 - val_accuracy: 0.5526\n",
      "Epoch 152/1000\n",
      "177/177 [==============================] - 0s 189us/step - loss: 0.2560 - accuracy: 0.9153 - val_loss: 1.4290 - val_accuracy: 0.5395\n",
      "Epoch 153/1000\n",
      "177/177 [==============================] - 0s 180us/step - loss: 0.2887 - accuracy: 0.9209 - val_loss: 1.4103 - val_accuracy: 0.5395\n",
      "Epoch 154/1000\n",
      "177/177 [==============================] - 0s 217us/step - loss: 0.2484 - accuracy: 0.9153 - val_loss: 1.4367 - val_accuracy: 0.5526\n",
      "Epoch 155/1000\n",
      "177/177 [==============================] - 0s 188us/step - loss: 0.3432 - accuracy: 0.9266 - val_loss: 1.4775 - val_accuracy: 0.5132\n",
      "Epoch 156/1000\n",
      "177/177 [==============================] - 0s 245us/step - loss: 0.4916 - accuracy: 0.8983 - val_loss: 1.4569 - val_accuracy: 0.5132\n",
      "Epoch 157/1000\n",
      "177/177 [==============================] - 0s 202us/step - loss: 0.8354 - accuracy: 0.8701 - val_loss: 1.4014 - val_accuracy: 0.5132\n",
      "Epoch 158/1000\n",
      "177/177 [==============================] - 0s 152us/step - loss: 0.5188 - accuracy: 0.8870 - val_loss: 1.4936 - val_accuracy: 0.5263\n",
      "Epoch 159/1000\n",
      "177/177 [==============================] - 0s 175us/step - loss: 0.5290 - accuracy: 0.9153 - val_loss: 1.5409 - val_accuracy: 0.5132\n",
      "Epoch 160/1000\n",
      "177/177 [==============================] - 0s 220us/step - loss: 0.4759 - accuracy: 0.8983 - val_loss: 1.7591 - val_accuracy: 0.5000\n",
      "Epoch 161/1000\n",
      "177/177 [==============================] - 0s 234us/step - loss: 0.4227 - accuracy: 0.9209 - val_loss: 1.5136 - val_accuracy: 0.5132\n",
      "Epoch 162/1000\n",
      "177/177 [==============================] - 0s 192us/step - loss: 0.3003 - accuracy: 0.9266 - val_loss: 1.7501 - val_accuracy: 0.5000\n",
      "Epoch 163/1000\n",
      "177/177 [==============================] - 0s 243us/step - loss: 0.4434 - accuracy: 0.9040 - val_loss: 1.4832 - val_accuracy: 0.5395\n",
      "Epoch 164/1000\n",
      "177/177 [==============================] - 0s 146us/step - loss: 0.3461 - accuracy: 0.9322 - val_loss: 1.4470 - val_accuracy: 0.5526\n",
      "Epoch 165/1000\n",
      "177/177 [==============================] - 0s 156us/step - loss: 0.2983 - accuracy: 0.9209 - val_loss: 1.4495 - val_accuracy: 0.5395\n",
      "Epoch 166/1000\n",
      "177/177 [==============================] - 0s 119us/step - loss: 0.3221 - accuracy: 0.9153 - val_loss: 1.4934 - val_accuracy: 0.5658\n",
      "Epoch 167/1000\n",
      "177/177 [==============================] - 0s 139us/step - loss: 0.2605 - accuracy: 0.9209 - val_loss: 1.4580 - val_accuracy: 0.5658\n",
      "Epoch 168/1000\n",
      "177/177 [==============================] - 0s 151us/step - loss: 0.2461 - accuracy: 0.9379 - val_loss: 1.4221 - val_accuracy: 0.5789\n",
      "Epoch 169/1000\n",
      "177/177 [==============================] - 0s 134us/step - loss: 0.2296 - accuracy: 0.9266 - val_loss: 1.4817 - val_accuracy: 0.5263\n",
      "Epoch 170/1000\n",
      "177/177 [==============================] - 0s 200us/step - loss: 0.3069 - accuracy: 0.9266 - val_loss: 1.4934 - val_accuracy: 0.5526\n",
      "Epoch 171/1000\n",
      "177/177 [==============================] - 0s 304us/step - loss: 0.2095 - accuracy: 0.9492 - val_loss: 1.5693 - val_accuracy: 0.5395\n",
      "Epoch 172/1000\n",
      "177/177 [==============================] - 0s 296us/step - loss: 0.3017 - accuracy: 0.9153 - val_loss: 1.5957 - val_accuracy: 0.5263\n",
      "Epoch 173/1000\n",
      "177/177 [==============================] - 0s 232us/step - loss: 0.4928 - accuracy: 0.8983 - val_loss: 1.6528 - val_accuracy: 0.5263\n",
      "Epoch 174/1000\n",
      "177/177 [==============================] - 0s 275us/step - loss: 0.2141 - accuracy: 0.9322 - val_loss: 1.4807 - val_accuracy: 0.5263\n",
      "Epoch 175/1000\n",
      "177/177 [==============================] - 0s 290us/step - loss: 0.5162 - accuracy: 0.9040 - val_loss: 1.6278 - val_accuracy: 0.4868\n",
      "Epoch 176/1000\n",
      "177/177 [==============================] - 0s 271us/step - loss: 0.3506 - accuracy: 0.9322 - val_loss: 1.4811 - val_accuracy: 0.5395\n",
      "Epoch 177/1000\n",
      "177/177 [==============================] - 0s 229us/step - loss: 0.4836 - accuracy: 0.8814 - val_loss: 1.5021 - val_accuracy: 0.5395\n",
      "Epoch 178/1000\n",
      "177/177 [==============================] - 0s 176us/step - loss: 0.4494 - accuracy: 0.9266 - val_loss: 1.6009 - val_accuracy: 0.5395\n",
      "Epoch 179/1000\n",
      "177/177 [==============================] - 0s 252us/step - loss: 0.3388 - accuracy: 0.9322 - val_loss: 1.5110 - val_accuracy: 0.5132\n",
      "Epoch 180/1000\n",
      "177/177 [==============================] - 0s 168us/step - loss: 0.3356 - accuracy: 0.9096 - val_loss: 1.5241 - val_accuracy: 0.5132\n",
      "Epoch 181/1000\n",
      "177/177 [==============================] - 0s 203us/step - loss: 0.2579 - accuracy: 0.9379 - val_loss: 1.4934 - val_accuracy: 0.5526\n",
      "Epoch 182/1000\n",
      "177/177 [==============================] - 0s 221us/step - loss: 0.3856 - accuracy: 0.9322 - val_loss: 1.6055 - val_accuracy: 0.5132\n",
      "Epoch 183/1000\n",
      "177/177 [==============================] - 0s 198us/step - loss: 0.3105 - accuracy: 0.9266 - val_loss: 1.5214 - val_accuracy: 0.5395\n",
      "Epoch 184/1000\n",
      "177/177 [==============================] - 0s 179us/step - loss: 0.2597 - accuracy: 0.9096 - val_loss: 1.7070 - val_accuracy: 0.5132\n",
      "Epoch 185/1000\n",
      "177/177 [==============================] - 0s 187us/step - loss: 0.3546 - accuracy: 0.9379 - val_loss: 1.5064 - val_accuracy: 0.5658\n",
      "Epoch 186/1000\n",
      "177/177 [==============================] - 0s 208us/step - loss: 0.2501 - accuracy: 0.9379 - val_loss: 1.5077 - val_accuracy: 0.5658\n",
      "Epoch 187/1000\n",
      "177/177 [==============================] - 0s 169us/step - loss: 0.1980 - accuracy: 0.9492 - val_loss: 1.5090 - val_accuracy: 0.5526\n",
      "Epoch 188/1000\n",
      "177/177 [==============================] - 0s 178us/step - loss: 0.2897 - accuracy: 0.9266 - val_loss: 1.7251 - val_accuracy: 0.5263\n",
      "Epoch 189/1000\n",
      "177/177 [==============================] - 0s 128us/step - loss: 0.3136 - accuracy: 0.9379 - val_loss: 1.5577 - val_accuracy: 0.5658\n",
      "Epoch 190/1000\n",
      "177/177 [==============================] - 0s 132us/step - loss: 0.6981 - accuracy: 0.9322 - val_loss: 1.7456 - val_accuracy: 0.5263\n",
      "Epoch 191/1000\n",
      "177/177 [==============================] - 0s 156us/step - loss: 0.3960 - accuracy: 0.8927 - val_loss: 2.4997 - val_accuracy: 0.5395\n",
      "Epoch 192/1000\n",
      "177/177 [==============================] - 0s 146us/step - loss: 1.4675 - accuracy: 0.8249 - val_loss: 2.2166 - val_accuracy: 0.4868\n",
      "Epoch 193/1000\n",
      "177/177 [==============================] - 0s 145us/step - loss: 0.9790 - accuracy: 0.9096 - val_loss: 1.8191 - val_accuracy: 0.5000\n",
      "Epoch 194/1000\n",
      "177/177 [==============================] - 0s 190us/step - loss: 0.6493 - accuracy: 0.8701 - val_loss: 1.7027 - val_accuracy: 0.5132\n",
      "Epoch 195/1000\n",
      "177/177 [==============================] - 0s 158us/step - loss: 0.4634 - accuracy: 0.9266 - val_loss: 1.9071 - val_accuracy: 0.5132\n",
      "Epoch 196/1000\n",
      "177/177 [==============================] - 0s 187us/step - loss: 3.3803 - accuracy: 0.8192 - val_loss: 5.9115 - val_accuracy: 0.5132\n",
      "Epoch 197/1000\n",
      "177/177 [==============================] - 0s 147us/step - loss: 4.1796 - accuracy: 0.8305 - val_loss: 6.0399 - val_accuracy: 0.5132\n",
      "Epoch 198/1000\n",
      "177/177 [==============================] - 0s 164us/step - loss: 3.6894 - accuracy: 0.8079 - val_loss: 4.7761 - val_accuracy: 0.4605\n",
      "Epoch 199/1000\n",
      "177/177 [==============================] - 0s 174us/step - loss: 2.3943 - accuracy: 0.8192 - val_loss: 3.5502 - val_accuracy: 0.5000\n",
      "Epoch 200/1000\n",
      "177/177 [==============================] - 0s 133us/step - loss: 1.6215 - accuracy: 0.8757 - val_loss: 2.2273 - val_accuracy: 0.4605\n",
      "Epoch 201/1000\n",
      "177/177 [==============================] - 0s 125us/step - loss: 0.7660 - accuracy: 0.8870 - val_loss: 1.5689 - val_accuracy: 0.5658\n",
      "Epoch 202/1000\n",
      "177/177 [==============================] - 0s 169us/step - loss: 0.3480 - accuracy: 0.8644 - val_loss: 1.5094 - val_accuracy: 0.5789\n",
      "Epoch 203/1000\n",
      "177/177 [==============================] - 0s 159us/step - loss: 0.3396 - accuracy: 0.8588 - val_loss: 1.4409 - val_accuracy: 0.4868\n",
      "Epoch 204/1000\n",
      "177/177 [==============================] - 0s 175us/step - loss: 0.2881 - accuracy: 0.9209 - val_loss: 1.4888 - val_accuracy: 0.5526\n",
      "Epoch 205/1000\n",
      "177/177 [==============================] - 0s 138us/step - loss: 0.2627 - accuracy: 0.8927 - val_loss: 1.5262 - val_accuracy: 0.5526\n",
      "Epoch 206/1000\n",
      "177/177 [==============================] - 0s 116us/step - loss: 0.2707 - accuracy: 0.9322 - val_loss: 1.5299 - val_accuracy: 0.5395\n",
      "Epoch 207/1000\n",
      "177/177 [==============================] - 0s 124us/step - loss: 0.2667 - accuracy: 0.9266 - val_loss: 1.6215 - val_accuracy: 0.5395\n",
      "Epoch 208/1000\n",
      "177/177 [==============================] - 0s 141us/step - loss: 0.6252 - accuracy: 0.9153 - val_loss: 1.5882 - val_accuracy: 0.5395\n",
      "Epoch 209/1000\n",
      "177/177 [==============================] - 0s 121us/step - loss: 0.3024 - accuracy: 0.9209 - val_loss: 1.5900 - val_accuracy: 0.5526\n",
      "Epoch 210/1000\n",
      "177/177 [==============================] - 0s 126us/step - loss: 0.2269 - accuracy: 0.9096 - val_loss: 1.5218 - val_accuracy: 0.5658\n",
      "Epoch 211/1000\n",
      "177/177 [==============================] - 0s 144us/step - loss: 0.2531 - accuracy: 0.9322 - val_loss: 1.5544 - val_accuracy: 0.5395\n",
      "Epoch 212/1000\n",
      "177/177 [==============================] - 0s 122us/step - loss: 0.2809 - accuracy: 0.9096 - val_loss: 1.5774 - val_accuracy: 0.5395\n",
      "Epoch 213/1000\n",
      "177/177 [==============================] - 0s 121us/step - loss: 0.3054 - accuracy: 0.9266 - val_loss: 1.6077 - val_accuracy: 0.5395\n",
      "Epoch 214/1000\n",
      "177/177 [==============================] - 0s 119us/step - loss: 0.2771 - accuracy: 0.9266 - val_loss: 1.5815 - val_accuracy: 0.5526\n",
      "Epoch 215/1000\n",
      "177/177 [==============================] - 0s 136us/step - loss: 0.1909 - accuracy: 0.9266 - val_loss: 1.6697 - val_accuracy: 0.5263\n",
      "Epoch 216/1000\n",
      "177/177 [==============================] - 0s 134us/step - loss: 0.2692 - accuracy: 0.9379 - val_loss: 1.5658 - val_accuracy: 0.5526\n",
      "Epoch 217/1000\n",
      "177/177 [==============================] - 0s 144us/step - loss: 0.2355 - accuracy: 0.9153 - val_loss: 1.4988 - val_accuracy: 0.5789\n",
      "Epoch 218/1000\n",
      "177/177 [==============================] - 0s 325us/step - loss: 0.2045 - accuracy: 0.9435 - val_loss: 1.5473 - val_accuracy: 0.5658\n",
      "Epoch 219/1000\n",
      "177/177 [==============================] - 0s 159us/step - loss: 0.1909 - accuracy: 0.9379 - val_loss: 1.5788 - val_accuracy: 0.5526\n",
      "Epoch 220/1000\n",
      "177/177 [==============================] - 0s 136us/step - loss: 0.2045 - accuracy: 0.9379 - val_loss: 1.5726 - val_accuracy: 0.5789\n",
      "Epoch 221/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177/177 [==============================] - 0s 128us/step - loss: 0.1967 - accuracy: 0.9435 - val_loss: 1.6162 - val_accuracy: 0.5789\n",
      "Epoch 222/1000\n",
      "177/177 [==============================] - 0s 127us/step - loss: 0.2557 - accuracy: 0.9435 - val_loss: 1.6286 - val_accuracy: 0.5658\n",
      "Epoch 223/1000\n",
      "177/177 [==============================] - 0s 156us/step - loss: 0.2644 - accuracy: 0.9153 - val_loss: 1.7422 - val_accuracy: 0.5000\n",
      "Epoch 224/1000\n",
      "177/177 [==============================] - 0s 149us/step - loss: 0.4041 - accuracy: 0.9266 - val_loss: 1.7942 - val_accuracy: 0.5263\n",
      "Epoch 225/1000\n",
      "177/177 [==============================] - 0s 172us/step - loss: 0.4156 - accuracy: 0.9266 - val_loss: 1.6383 - val_accuracy: 0.5658\n",
      "Epoch 226/1000\n",
      "177/177 [==============================] - 0s 182us/step - loss: 0.2547 - accuracy: 0.9322 - val_loss: 1.8455 - val_accuracy: 0.5132\n",
      "Epoch 227/1000\n",
      "177/177 [==============================] - 0s 139us/step - loss: 0.3220 - accuracy: 0.9322 - val_loss: 1.6368 - val_accuracy: 0.5526\n",
      "Epoch 228/1000\n",
      "177/177 [==============================] - 0s 133us/step - loss: 0.3735 - accuracy: 0.8870 - val_loss: 1.6225 - val_accuracy: 0.5658\n",
      "Epoch 229/1000\n",
      "177/177 [==============================] - 0s 124us/step - loss: 0.1936 - accuracy: 0.9379 - val_loss: 1.7670 - val_accuracy: 0.5263\n",
      "Epoch 230/1000\n",
      "177/177 [==============================] - 0s 141us/step - loss: 0.2722 - accuracy: 0.9322 - val_loss: 1.7290 - val_accuracy: 0.5263\n",
      "Epoch 231/1000\n",
      "177/177 [==============================] - 0s 160us/step - loss: 1.5545 - accuracy: 0.9266 - val_loss: 2.3671 - val_accuracy: 0.5526\n",
      "Epoch 232/1000\n",
      "177/177 [==============================] - 0s 177us/step - loss: 1.5196 - accuracy: 0.9040 - val_loss: 1.9841 - val_accuracy: 0.5395\n",
      "Epoch 233/1000\n",
      "177/177 [==============================] - 0s 136us/step - loss: 0.8153 - accuracy: 0.9209 - val_loss: 1.6441 - val_accuracy: 0.5526\n",
      "Epoch 234/1000\n",
      "177/177 [==============================] - 0s 124us/step - loss: 0.3169 - accuracy: 0.9096 - val_loss: 1.8531 - val_accuracy: 0.5395\n",
      "Epoch 235/1000\n",
      "177/177 [==============================] - 0s 135us/step - loss: 0.8210 - accuracy: 0.9209 - val_loss: 1.9131 - val_accuracy: 0.5526\n",
      "Epoch 236/1000\n",
      "177/177 [==============================] - 0s 143us/step - loss: 0.5633 - accuracy: 0.9266 - val_loss: 1.6918 - val_accuracy: 0.5395\n",
      "Epoch 237/1000\n",
      "177/177 [==============================] - 0s 132us/step - loss: 0.3477 - accuracy: 0.8983 - val_loss: 1.6738 - val_accuracy: 0.5395\n",
      "Epoch 238/1000\n",
      "177/177 [==============================] - 0s 243us/step - loss: 0.2736 - accuracy: 0.9209 - val_loss: 1.7465 - val_accuracy: 0.5395\n",
      "Epoch 239/1000\n",
      "177/177 [==============================] - 0s 146us/step - loss: 0.6392 - accuracy: 0.9266 - val_loss: 2.2095 - val_accuracy: 0.5658\n",
      "Epoch 240/1000\n",
      "177/177 [==============================] - 0s 148us/step - loss: 0.8190 - accuracy: 0.9153 - val_loss: 1.7281 - val_accuracy: 0.5658\n",
      "Epoch 241/1000\n",
      "177/177 [==============================] - 0s 124us/step - loss: 0.5052 - accuracy: 0.9096 - val_loss: 1.6689 - val_accuracy: 0.5395\n",
      "Epoch 242/1000\n",
      "177/177 [==============================] - 0s 141us/step - loss: 0.1847 - accuracy: 0.9379 - val_loss: 1.7896 - val_accuracy: 0.5263\n",
      "Epoch 243/1000\n",
      "177/177 [==============================] - 0s 215us/step - loss: 0.3049 - accuracy: 0.9492 - val_loss: 1.7279 - val_accuracy: 0.5395\n",
      "Epoch 244/1000\n",
      "177/177 [==============================] - 0s 223us/step - loss: 0.1875 - accuracy: 0.9266 - val_loss: 1.7747 - val_accuracy: 0.5263\n",
      "Epoch 245/1000\n",
      "177/177 [==============================] - 0s 208us/step - loss: 0.2098 - accuracy: 0.9379 - val_loss: 1.8448 - val_accuracy: 0.5132\n",
      "Epoch 246/1000\n",
      "177/177 [==============================] - 0s 192us/step - loss: 0.2688 - accuracy: 0.9266 - val_loss: 1.7986 - val_accuracy: 0.5395\n",
      "Epoch 247/1000\n",
      "177/177 [==============================] - 0s 171us/step - loss: 0.1994 - accuracy: 0.9435 - val_loss: 1.7136 - val_accuracy: 0.5395\n",
      "Epoch 248/1000\n",
      "177/177 [==============================] - 0s 394us/step - loss: 0.1880 - accuracy: 0.9379 - val_loss: 1.7190 - val_accuracy: 0.5658\n",
      "Epoch 249/1000\n",
      "177/177 [==============================] - 0s 191us/step - loss: 0.2020 - accuracy: 0.9322 - val_loss: 1.8110 - val_accuracy: 0.4868\n",
      "Epoch 250/1000\n",
      "177/177 [==============================] - 0s 147us/step - loss: 0.2250 - accuracy: 0.9266 - val_loss: 1.6146 - val_accuracy: 0.5789\n",
      "Epoch 251/1000\n",
      "177/177 [==============================] - 0s 147us/step - loss: 0.1690 - accuracy: 0.9379 - val_loss: 1.6887 - val_accuracy: 0.5395\n",
      "Epoch 252/1000\n",
      "177/177 [==============================] - 0s 137us/step - loss: 0.1616 - accuracy: 0.9492 - val_loss: 1.8322 - val_accuracy: 0.5132\n",
      "Epoch 253/1000\n",
      "177/177 [==============================] - 0s 131us/step - loss: 0.2446 - accuracy: 0.9548 - val_loss: 1.7311 - val_accuracy: 0.5658\n",
      "Epoch 254/1000\n",
      "177/177 [==============================] - 0s 158us/step - loss: 0.1515 - accuracy: 0.9435 - val_loss: 1.7411 - val_accuracy: 0.5658\n",
      "Epoch 255/1000\n",
      "177/177 [==============================] - 0s 171us/step - loss: 0.1792 - accuracy: 0.9492 - val_loss: 1.7307 - val_accuracy: 0.5921\n",
      "Epoch 256/1000\n",
      "177/177 [==============================] - 0s 146us/step - loss: 0.1717 - accuracy: 0.9379 - val_loss: 1.7677 - val_accuracy: 0.5526\n",
      "Epoch 257/1000\n",
      "177/177 [==============================] - 0s 169us/step - loss: 0.1805 - accuracy: 0.9322 - val_loss: 1.7573 - val_accuracy: 0.5395\n",
      "Epoch 258/1000\n",
      "177/177 [==============================] - 0s 133us/step - loss: 0.1679 - accuracy: 0.9492 - val_loss: 1.7869 - val_accuracy: 0.5395\n",
      "Epoch 259/1000\n",
      "177/177 [==============================] - 0s 148us/step - loss: 0.1887 - accuracy: 0.9492 - val_loss: 1.7565 - val_accuracy: 0.5395\n",
      "Epoch 260/1000\n",
      "177/177 [==============================] - 0s 199us/step - loss: 0.1505 - accuracy: 0.9435 - val_loss: 1.7801 - val_accuracy: 0.5526\n",
      "Epoch 261/1000\n",
      "177/177 [==============================] - 0s 196us/step - loss: 0.2237 - accuracy: 0.9435 - val_loss: 2.0347 - val_accuracy: 0.5132\n",
      "Epoch 262/1000\n",
      "177/177 [==============================] - 0s 233us/step - loss: 0.4520 - accuracy: 0.9266 - val_loss: 1.8998 - val_accuracy: 0.5263\n",
      "Epoch 263/1000\n",
      "177/177 [==============================] - 0s 202us/step - loss: 0.2204 - accuracy: 0.9435 - val_loss: 1.8307 - val_accuracy: 0.5263\n",
      "Epoch 264/1000\n",
      "177/177 [==============================] - 0s 180us/step - loss: 0.1849 - accuracy: 0.9379 - val_loss: 1.8644 - val_accuracy: 0.5395\n",
      "Epoch 265/1000\n",
      "177/177 [==============================] - 0s 167us/step - loss: 0.3737 - accuracy: 0.9435 - val_loss: 1.7835 - val_accuracy: 0.5526\n",
      "Epoch 266/1000\n",
      "177/177 [==============================] - 0s 165us/step - loss: 0.3048 - accuracy: 0.9209 - val_loss: 1.7444 - val_accuracy: 0.5526\n",
      "Epoch 267/1000\n",
      "177/177 [==============================] - 0s 186us/step - loss: 0.2070 - accuracy: 0.9379 - val_loss: 1.6888 - val_accuracy: 0.5263\n",
      "Epoch 268/1000\n",
      "177/177 [==============================] - 0s 161us/step - loss: 0.2164 - accuracy: 0.9266 - val_loss: 1.8055 - val_accuracy: 0.5789\n",
      "Epoch 269/1000\n",
      "177/177 [==============================] - 0s 203us/step - loss: 0.1862 - accuracy: 0.9322 - val_loss: 1.9477 - val_accuracy: 0.5395\n",
      "Epoch 270/1000\n",
      "177/177 [==============================] - 0s 152us/step - loss: 0.3250 - accuracy: 0.9266 - val_loss: 1.9024 - val_accuracy: 0.5658\n",
      "Epoch 271/1000\n",
      "177/177 [==============================] - 0s 169us/step - loss: 0.3893 - accuracy: 0.9435 - val_loss: 1.8219 - val_accuracy: 0.5526\n",
      "Epoch 272/1000\n",
      "177/177 [==============================] - 0s 203us/step - loss: 0.3584 - accuracy: 0.9266 - val_loss: 1.8295 - val_accuracy: 0.5395\n",
      "Epoch 273/1000\n",
      "177/177 [==============================] - 0s 143us/step - loss: 0.1993 - accuracy: 0.9492 - val_loss: 1.7432 - val_accuracy: 0.5526\n",
      "Epoch 274/1000\n",
      "177/177 [==============================] - 0s 173us/step - loss: 0.2520 - accuracy: 0.9040 - val_loss: 1.7310 - val_accuracy: 0.5658\n",
      "Epoch 275/1000\n",
      "177/177 [==============================] - 0s 201us/step - loss: 0.2817 - accuracy: 0.9492 - val_loss: 1.7704 - val_accuracy: 0.5526\n",
      "Epoch 276/1000\n",
      "177/177 [==============================] - 0s 187us/step - loss: 0.1436 - accuracy: 0.9548 - val_loss: 1.7928 - val_accuracy: 0.5658\n",
      "Epoch 277/1000\n",
      "177/177 [==============================] - 0s 181us/step - loss: 0.5949 - accuracy: 0.9379 - val_loss: 1.9162 - val_accuracy: 0.5658\n",
      "Epoch 278/1000\n",
      "177/177 [==============================] - 0s 146us/step - loss: 0.2395 - accuracy: 0.9266 - val_loss: 1.8358 - val_accuracy: 0.5526\n",
      "Epoch 279/1000\n",
      "177/177 [==============================] - 0s 137us/step - loss: 0.2937 - accuracy: 0.9266 - val_loss: 1.8370 - val_accuracy: 0.5658\n",
      "Epoch 280/1000\n",
      "177/177 [==============================] - 0s 136us/step - loss: 0.1935 - accuracy: 0.9435 - val_loss: 1.8816 - val_accuracy: 0.5395\n",
      "Epoch 281/1000\n",
      "177/177 [==============================] - 0s 139us/step - loss: 0.3152 - accuracy: 0.9435 - val_loss: 1.8132 - val_accuracy: 0.5789\n",
      "Epoch 282/1000\n",
      "177/177 [==============================] - 0s 140us/step - loss: 0.1518 - accuracy: 0.9548 - val_loss: 1.7834 - val_accuracy: 0.5395\n",
      "Epoch 283/1000\n",
      "177/177 [==============================] - 0s 164us/step - loss: 0.2466 - accuracy: 0.9209 - val_loss: 1.7909 - val_accuracy: 0.5789\n",
      "Epoch 284/1000\n",
      "177/177 [==============================] - 0s 150us/step - loss: 0.2094 - accuracy: 0.9435 - val_loss: 1.8454 - val_accuracy: 0.5526\n",
      "Epoch 285/1000\n",
      "177/177 [==============================] - 0s 292us/step - loss: 0.2902 - accuracy: 0.9209 - val_loss: 2.0235 - val_accuracy: 0.5132\n",
      "Epoch 286/1000\n",
      "177/177 [==============================] - 0s 254us/step - loss: 0.4265 - accuracy: 0.9209 - val_loss: 2.0027 - val_accuracy: 0.5526\n",
      "Epoch 287/1000\n",
      "177/177 [==============================] - 0s 280us/step - loss: 0.1406 - accuracy: 0.9548 - val_loss: 1.8365 - val_accuracy: 0.5395\n",
      "Epoch 288/1000\n",
      "177/177 [==============================] - 0s 159us/step - loss: 0.1755 - accuracy: 0.9435 - val_loss: 1.7822 - val_accuracy: 0.5789\n",
      "Epoch 289/1000\n",
      "177/177 [==============================] - 0s 185us/step - loss: 0.1631 - accuracy: 0.9492 - val_loss: 1.7631 - val_accuracy: 0.5658\n",
      "Epoch 290/1000\n",
      "177/177 [==============================] - 0s 150us/step - loss: 0.1549 - accuracy: 0.9435 - val_loss: 1.8107 - val_accuracy: 0.5658\n",
      "Epoch 291/1000\n",
      "177/177 [==============================] - 0s 210us/step - loss: 0.1658 - accuracy: 0.9548 - val_loss: 1.8325 - val_accuracy: 0.5263\n",
      "Epoch 292/1000\n",
      "177/177 [==============================] - 0s 142us/step - loss: 0.2440 - accuracy: 0.9492 - val_loss: 1.8113 - val_accuracy: 0.5658\n",
      "Epoch 293/1000\n",
      "177/177 [==============================] - 0s 194us/step - loss: 0.2564 - accuracy: 0.9492 - val_loss: 1.7780 - val_accuracy: 0.5132\n",
      "Epoch 294/1000\n",
      "177/177 [==============================] - 0s 232us/step - loss: 0.2907 - accuracy: 0.9435 - val_loss: 1.8023 - val_accuracy: 0.5789\n",
      "Epoch 295/1000\n",
      "177/177 [==============================] - 0s 270us/step - loss: 0.1546 - accuracy: 0.9548 - val_loss: 1.9871 - val_accuracy: 0.5789\n",
      "Epoch 296/1000\n",
      "177/177 [==============================] - 0s 214us/step - loss: 0.2936 - accuracy: 0.9379 - val_loss: 1.8564 - val_accuracy: 0.5658\n",
      "Epoch 297/1000\n",
      "177/177 [==============================] - 0s 236us/step - loss: 0.1735 - accuracy: 0.9435 - val_loss: 1.8030 - val_accuracy: 0.5263\n",
      "Epoch 298/1000\n",
      "177/177 [==============================] - 0s 144us/step - loss: 0.2083 - accuracy: 0.9605 - val_loss: 1.7679 - val_accuracy: 0.5658\n",
      "Epoch 299/1000\n",
      "177/177 [==============================] - 0s 181us/step - loss: 0.1603 - accuracy: 0.9435 - val_loss: 1.9421 - val_accuracy: 0.5263\n",
      "Epoch 300/1000\n",
      "177/177 [==============================] - 0s 182us/step - loss: 0.3569 - accuracy: 0.9379 - val_loss: 1.9905 - val_accuracy: 0.5263\n",
      "Epoch 301/1000\n",
      "177/177 [==============================] - 0s 170us/step - loss: 0.4287 - accuracy: 0.9209 - val_loss: 1.8825 - val_accuracy: 0.5263\n",
      "Epoch 302/1000\n",
      "177/177 [==============================] - 0s 199us/step - loss: 0.3126 - accuracy: 0.9379 - val_loss: 1.9939 - val_accuracy: 0.5263\n",
      "Epoch 303/1000\n",
      "177/177 [==============================] - 0s 157us/step - loss: 0.4478 - accuracy: 0.9209 - val_loss: 1.7996 - val_accuracy: 0.5526\n",
      "Epoch 304/1000\n",
      "177/177 [==============================] - 0s 179us/step - loss: 0.2311 - accuracy: 0.9379 - val_loss: 1.8370 - val_accuracy: 0.5789\n",
      "Epoch 305/1000\n",
      "177/177 [==============================] - 0s 155us/step - loss: 0.2107 - accuracy: 0.9492 - val_loss: 1.8491 - val_accuracy: 0.5395\n",
      "Epoch 306/1000\n",
      "177/177 [==============================] - 0s 172us/step - loss: 0.2011 - accuracy: 0.9492 - val_loss: 1.8916 - val_accuracy: 0.5526\n",
      "Epoch 307/1000\n",
      "177/177 [==============================] - 0s 213us/step - loss: 0.1429 - accuracy: 0.9435 - val_loss: 1.8359 - val_accuracy: 0.5395\n",
      "Epoch 308/1000\n",
      "177/177 [==============================] - 0s 192us/step - loss: 0.1770 - accuracy: 0.9605 - val_loss: 1.8258 - val_accuracy: 0.5526\n",
      "Epoch 309/1000\n",
      "177/177 [==============================] - 0s 228us/step - loss: 0.2033 - accuracy: 0.9322 - val_loss: 1.9537 - val_accuracy: 0.5263\n",
      "Epoch 310/1000\n",
      "177/177 [==============================] - 0s 186us/step - loss: 0.2301 - accuracy: 0.9492 - val_loss: 1.8740 - val_accuracy: 0.5789\n",
      "Epoch 311/1000\n",
      "177/177 [==============================] - 0s 241us/step - loss: 0.1353 - accuracy: 0.9548 - val_loss: 1.9087 - val_accuracy: 0.5395\n",
      "Epoch 312/1000\n",
      "177/177 [==============================] - 0s 203us/step - loss: 0.2317 - accuracy: 0.9435 - val_loss: 1.8995 - val_accuracy: 0.5395\n",
      "Epoch 313/1000\n",
      "177/177 [==============================] - 0s 235us/step - loss: 0.2063 - accuracy: 0.9266 - val_loss: 1.8546 - val_accuracy: 0.5395\n",
      "Epoch 314/1000\n",
      "177/177 [==============================] - 0s 177us/step - loss: 0.2628 - accuracy: 0.9492 - val_loss: 1.8933 - val_accuracy: 0.5658\n",
      "Epoch 315/1000\n",
      "177/177 [==============================] - 0s 232us/step - loss: 0.2778 - accuracy: 0.9322 - val_loss: 2.0813 - val_accuracy: 0.5526\n",
      "Epoch 316/1000\n",
      "177/177 [==============================] - 0s 183us/step - loss: 0.5449 - accuracy: 0.9266 - val_loss: 2.0988 - val_accuracy: 0.5263\n",
      "Epoch 317/1000\n",
      "177/177 [==============================] - 0s 201us/step - loss: 0.5108 - accuracy: 0.9492 - val_loss: 1.9286 - val_accuracy: 0.5263\n",
      "Epoch 318/1000\n",
      "177/177 [==============================] - 0s 177us/step - loss: 0.1840 - accuracy: 0.9153 - val_loss: 2.4327 - val_accuracy: 0.5263\n",
      "Epoch 319/1000\n",
      "177/177 [==============================] - 0s 203us/step - loss: 0.5968 - accuracy: 0.9209 - val_loss: 2.2729 - val_accuracy: 0.5132\n",
      "Epoch 320/1000\n",
      "177/177 [==============================] - 0s 158us/step - loss: 0.3988 - accuracy: 0.9153 - val_loss: 1.8619 - val_accuracy: 0.5263\n",
      "Epoch 321/1000\n",
      "177/177 [==============================] - 0s 150us/step - loss: 0.2644 - accuracy: 0.9322 - val_loss: 1.7526 - val_accuracy: 0.5526\n",
      "Epoch 322/1000\n",
      "177/177 [==============================] - 0s 200us/step - loss: 0.2162 - accuracy: 0.9435 - val_loss: 1.7731 - val_accuracy: 0.5395\n",
      "Epoch 323/1000\n",
      "177/177 [==============================] - 0s 159us/step - loss: 0.2097 - accuracy: 0.9379 - val_loss: 1.8472 - val_accuracy: 0.5395\n",
      "Epoch 324/1000\n",
      "177/177 [==============================] - 0s 183us/step - loss: 0.1819 - accuracy: 0.9548 - val_loss: 1.8962 - val_accuracy: 0.5789\n",
      "Epoch 325/1000\n",
      "177/177 [==============================] - 0s 144us/step - loss: 0.1463 - accuracy: 0.9548 - val_loss: 1.9020 - val_accuracy: 0.5658\n",
      "Epoch 326/1000\n",
      "177/177 [==============================] - 0s 142us/step - loss: 0.1449 - accuracy: 0.9548 - val_loss: 1.9591 - val_accuracy: 0.5263\n",
      "Epoch 327/1000\n",
      "177/177 [==============================] - 0s 182us/step - loss: 0.2610 - accuracy: 0.9435 - val_loss: 1.9612 - val_accuracy: 0.5263\n",
      "Epoch 328/1000\n",
      "177/177 [==============================] - 0s 157us/step - loss: 0.2292 - accuracy: 0.9322 - val_loss: 2.0494 - val_accuracy: 0.5395\n",
      "Epoch 329/1000\n",
      "177/177 [==============================] - 0s 195us/step - loss: 0.4981 - accuracy: 0.9153 - val_loss: 1.9155 - val_accuracy: 0.5395\n",
      "Epoch 330/1000\n",
      "177/177 [==============================] - 0s 189us/step - loss: 0.2197 - accuracy: 0.9379 - val_loss: 1.7723 - val_accuracy: 0.5526\n",
      "Epoch 331/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177/177 [==============================] - 0s 303us/step - loss: 0.2204 - accuracy: 0.9492 - val_loss: 1.7964 - val_accuracy: 0.5526\n",
      "Epoch 332/1000\n",
      "177/177 [==============================] - 0s 232us/step - loss: 0.1843 - accuracy: 0.9548 - val_loss: 1.8708 - val_accuracy: 0.5395\n",
      "Epoch 333/1000\n",
      "177/177 [==============================] - 0s 366us/step - loss: 0.3672 - accuracy: 0.9096 - val_loss: 1.9051 - val_accuracy: 0.5658\n",
      "Epoch 334/1000\n",
      "177/177 [==============================] - 0s 323us/step - loss: 0.1522 - accuracy: 0.9661 - val_loss: 1.9382 - val_accuracy: 0.5263\n",
      "Epoch 335/1000\n",
      "177/177 [==============================] - 0s 284us/step - loss: 0.1827 - accuracy: 0.9548 - val_loss: 1.9061 - val_accuracy: 0.5526\n",
      "Epoch 336/1000\n",
      "177/177 [==============================] - 0s 184us/step - loss: 0.2201 - accuracy: 0.9379 - val_loss: 1.9701 - val_accuracy: 0.5000\n",
      "Epoch 337/1000\n",
      "177/177 [==============================] - 0s 131us/step - loss: 0.1625 - accuracy: 0.9605 - val_loss: 1.9307 - val_accuracy: 0.5395\n",
      "Epoch 338/1000\n",
      "177/177 [==============================] - 0s 164us/step - loss: 0.1467 - accuracy: 0.9548 - val_loss: 1.9560 - val_accuracy: 0.5526\n",
      "Epoch 339/1000\n",
      "177/177 [==============================] - 0s 180us/step - loss: 0.1444 - accuracy: 0.9492 - val_loss: 1.9792 - val_accuracy: 0.5263\n",
      "Epoch 340/1000\n",
      "177/177 [==============================] - 0s 164us/step - loss: 0.1899 - accuracy: 0.9605 - val_loss: 1.9722 - val_accuracy: 0.5658\n",
      "Epoch 341/1000\n",
      "177/177 [==============================] - 0s 196us/step - loss: 0.1883 - accuracy: 0.9492 - val_loss: 2.1759 - val_accuracy: 0.5263\n",
      "Epoch 342/1000\n",
      "177/177 [==============================] - 0s 160us/step - loss: 0.4474 - accuracy: 0.9379 - val_loss: 2.0968 - val_accuracy: 0.5395\n",
      "Epoch 343/1000\n",
      "177/177 [==============================] - 0s 153us/step - loss: 0.1690 - accuracy: 0.9379 - val_loss: 1.9623 - val_accuracy: 0.5526\n",
      "Epoch 344/1000\n",
      "177/177 [==============================] - 0s 196us/step - loss: 0.3223 - accuracy: 0.9209 - val_loss: 1.9441 - val_accuracy: 0.5658\n",
      "Epoch 345/1000\n",
      "177/177 [==============================] - 0s 145us/step - loss: 0.2712 - accuracy: 0.9435 - val_loss: 2.0742 - val_accuracy: 0.5395\n",
      "Epoch 346/1000\n",
      "177/177 [==============================] - 0s 181us/step - loss: 0.4838 - accuracy: 0.9266 - val_loss: 2.0261 - val_accuracy: 0.5658\n",
      "Epoch 347/1000\n",
      "177/177 [==============================] - 0s 143us/step - loss: 0.1800 - accuracy: 0.9548 - val_loss: 1.9886 - val_accuracy: 0.5526\n",
      "Epoch 348/1000\n",
      "177/177 [==============================] - 0s 148us/step - loss: 0.5717 - accuracy: 0.9040 - val_loss: 2.1650 - val_accuracy: 0.5526\n",
      "Epoch 349/1000\n",
      "177/177 [==============================] - 0s 180us/step - loss: 0.5114 - accuracy: 0.9322 - val_loss: 2.1204 - val_accuracy: 0.5395\n",
      "Epoch 350/1000\n",
      "177/177 [==============================] - 0s 145us/step - loss: 0.1349 - accuracy: 0.9548 - val_loss: 1.9208 - val_accuracy: 0.5658\n",
      "Epoch 351/1000\n",
      "177/177 [==============================] - 0s 184us/step - loss: 0.2209 - accuracy: 0.9548 - val_loss: 1.8776 - val_accuracy: 0.5658\n",
      "Epoch 352/1000\n",
      "177/177 [==============================] - 0s 146us/step - loss: 0.4385 - accuracy: 0.9153 - val_loss: 1.9669 - val_accuracy: 0.5526\n",
      "Epoch 353/1000\n",
      "177/177 [==============================] - 0s 200us/step - loss: 0.4406 - accuracy: 0.9322 - val_loss: 2.1147 - val_accuracy: 0.5526\n",
      "Epoch 354/1000\n",
      "177/177 [==============================] - 0s 224us/step - loss: 0.2475 - accuracy: 0.9492 - val_loss: 1.9978 - val_accuracy: 0.5789\n",
      "Epoch 355/1000\n",
      "177/177 [==============================] - 0s 170us/step - loss: 0.1874 - accuracy: 0.9548 - val_loss: 2.0160 - val_accuracy: 0.5395\n",
      "Epoch 356/1000\n",
      "177/177 [==============================] - 0s 195us/step - loss: 0.1450 - accuracy: 0.9492 - val_loss: 1.9681 - val_accuracy: 0.6053\n",
      "Epoch 357/1000\n",
      "177/177 [==============================] - 0s 156us/step - loss: 0.1148 - accuracy: 0.9605 - val_loss: 1.9975 - val_accuracy: 0.5658\n",
      "Epoch 358/1000\n",
      "177/177 [==============================] - 0s 162us/step - loss: 0.1375 - accuracy: 0.9605 - val_loss: 2.0271 - val_accuracy: 0.5658\n",
      "Epoch 359/1000\n",
      "177/177 [==============================] - 0s 181us/step - loss: 0.2097 - accuracy: 0.9379 - val_loss: 2.3767 - val_accuracy: 0.5395\n",
      "Epoch 360/1000\n",
      "177/177 [==============================] - 0s 170us/step - loss: 0.4802 - accuracy: 0.9209 - val_loss: 2.1043 - val_accuracy: 0.5526\n",
      "Epoch 361/1000\n",
      "177/177 [==============================] - 0s 185us/step - loss: 0.1267 - accuracy: 0.9605 - val_loss: 1.9925 - val_accuracy: 0.5658\n",
      "Epoch 362/1000\n",
      "177/177 [==============================] - 0s 126us/step - loss: 0.1917 - accuracy: 0.9548 - val_loss: 2.0192 - val_accuracy: 0.5658\n",
      "Epoch 363/1000\n",
      "177/177 [==============================] - 0s 124us/step - loss: 0.3138 - accuracy: 0.9322 - val_loss: 2.0130 - val_accuracy: 0.5526\n",
      "Epoch 364/1000\n",
      "177/177 [==============================] - 0s 157us/step - loss: 0.3377 - accuracy: 0.9379 - val_loss: 2.0699 - val_accuracy: 0.5395\n",
      "Epoch 365/1000\n",
      "177/177 [==============================] - 0s 148us/step - loss: 0.1319 - accuracy: 0.9605 - val_loss: 2.0213 - val_accuracy: 0.5395\n",
      "Epoch 366/1000\n",
      "177/177 [==============================] - 0s 158us/step - loss: 0.1637 - accuracy: 0.9605 - val_loss: 2.0182 - val_accuracy: 0.5658\n",
      "Epoch 367/1000\n",
      "177/177 [==============================] - 0s 182us/step - loss: 0.1290 - accuracy: 0.9661 - val_loss: 2.2902 - val_accuracy: 0.5263\n",
      "Epoch 368/1000\n",
      "177/177 [==============================] - 0s 139us/step - loss: 0.4286 - accuracy: 0.9322 - val_loss: 2.0579 - val_accuracy: 0.5526\n",
      "Epoch 369/1000\n",
      "177/177 [==============================] - 0s 182us/step - loss: 0.1988 - accuracy: 0.9435 - val_loss: 2.0115 - val_accuracy: 0.5658\n",
      "Epoch 370/1000\n",
      "177/177 [==============================] - 0s 149us/step - loss: 0.5079 - accuracy: 0.9209 - val_loss: 2.0110 - val_accuracy: 0.5658\n",
      "Epoch 371/1000\n",
      "177/177 [==============================] - 0s 161us/step - loss: 0.4469 - accuracy: 0.9435 - val_loss: 2.0817 - val_accuracy: 0.5526\n",
      "Epoch 372/1000\n",
      "177/177 [==============================] - 0s 188us/step - loss: 0.1578 - accuracy: 0.9661 - val_loss: 2.0409 - val_accuracy: 0.5658\n",
      "Epoch 373/1000\n",
      "177/177 [==============================] - 0s 143us/step - loss: 0.1492 - accuracy: 0.9492 - val_loss: 2.1886 - val_accuracy: 0.5395\n",
      "Epoch 374/1000\n",
      "177/177 [==============================] - 0s 160us/step - loss: 0.3266 - accuracy: 0.9379 - val_loss: 2.0764 - val_accuracy: 0.5526\n",
      "Epoch 375/1000\n",
      "177/177 [==============================] - 0s 176us/step - loss: 0.2220 - accuracy: 0.9379 - val_loss: 2.0615 - val_accuracy: 0.5263\n",
      "Epoch 376/1000\n",
      "177/177 [==============================] - 0s 157us/step - loss: 0.1848 - accuracy: 0.9661 - val_loss: 1.9847 - val_accuracy: 0.5526\n",
      "Epoch 377/1000\n",
      "177/177 [==============================] - 0s 146us/step - loss: 0.2007 - accuracy: 0.9548 - val_loss: 2.1482 - val_accuracy: 0.5132\n",
      "Epoch 378/1000\n",
      "177/177 [==============================] - 0s 141us/step - loss: 0.2498 - accuracy: 0.9548 - val_loss: 2.1640 - val_accuracy: 0.5132\n",
      "Epoch 379/1000\n",
      "177/177 [==============================] - 0s 169us/step - loss: 0.3356 - accuracy: 0.9153 - val_loss: 2.1441 - val_accuracy: 0.5526\n",
      "Epoch 380/1000\n",
      "177/177 [==============================] - 0s 176us/step - loss: 0.1512 - accuracy: 0.9548 - val_loss: 2.1138 - val_accuracy: 0.5789\n",
      "Epoch 381/1000\n",
      "177/177 [==============================] - 0s 183us/step - loss: 0.1795 - accuracy: 0.9548 - val_loss: 2.1419 - val_accuracy: 0.5526\n",
      "Epoch 382/1000\n",
      "177/177 [==============================] - 0s 226us/step - loss: 0.1245 - accuracy: 0.9605 - val_loss: 2.1787 - val_accuracy: 0.5526\n",
      "Epoch 383/1000\n",
      "177/177 [==============================] - 0s 148us/step - loss: 0.1228 - accuracy: 0.9661 - val_loss: 2.1652 - val_accuracy: 0.5526\n",
      "Epoch 384/1000\n",
      "177/177 [==============================] - 0s 180us/step - loss: 0.1513 - accuracy: 0.9548 - val_loss: 2.0973 - val_accuracy: 0.5263\n",
      "Epoch 385/1000\n",
      "177/177 [==============================] - 0s 175us/step - loss: 0.2073 - accuracy: 0.9548 - val_loss: 1.9881 - val_accuracy: 0.5789\n",
      "Epoch 386/1000\n",
      "177/177 [==============================] - 0s 144us/step - loss: 0.1420 - accuracy: 0.9548 - val_loss: 2.1310 - val_accuracy: 0.5526\n",
      "Epoch 387/1000\n",
      "177/177 [==============================] - 0s 157us/step - loss: 0.2557 - accuracy: 0.9435 - val_loss: 2.0723 - val_accuracy: 0.5132\n",
      "Epoch 388/1000\n",
      "177/177 [==============================] - 0s 185us/step - loss: 0.2235 - accuracy: 0.9435 - val_loss: 2.1240 - val_accuracy: 0.5000\n",
      "Epoch 389/1000\n",
      "177/177 [==============================] - 0s 156us/step - loss: 0.4184 - accuracy: 0.9492 - val_loss: 2.1169 - val_accuracy: 0.5395\n",
      "Epoch 390/1000\n",
      "177/177 [==============================] - 0s 213us/step - loss: 0.1589 - accuracy: 0.9492 - val_loss: 2.1004 - val_accuracy: 0.5263\n",
      "Epoch 391/1000\n",
      "177/177 [==============================] - 0s 136us/step - loss: 0.1465 - accuracy: 0.9548 - val_loss: 2.4692 - val_accuracy: 0.5000\n",
      "Epoch 392/1000\n",
      "177/177 [==============================] - 0s 148us/step - loss: 2.2898 - accuracy: 0.8475 - val_loss: 5.5579 - val_accuracy: 0.5263\n",
      "Epoch 393/1000\n",
      "177/177 [==============================] - 0s 188us/step - loss: 3.0748 - accuracy: 0.8475 - val_loss: 5.4327 - val_accuracy: 0.5000\n",
      "Epoch 394/1000\n",
      "177/177 [==============================] - 0s 122us/step - loss: 2.3512 - accuracy: 0.8531 - val_loss: 4.0107 - val_accuracy: 0.4868\n",
      "Epoch 395/1000\n",
      "177/177 [==============================] - 0s 142us/step - loss: 1.1891 - accuracy: 0.9322 - val_loss: 2.7619 - val_accuracy: 0.4868\n",
      "Epoch 396/1000\n",
      "177/177 [==============================] - 0s 145us/step - loss: 0.6431 - accuracy: 0.9153 - val_loss: 1.9853 - val_accuracy: 0.5263\n",
      "Epoch 397/1000\n",
      "177/177 [==============================] - 0s 111us/step - loss: 0.2267 - accuracy: 0.8757 - val_loss: 1.8199 - val_accuracy: 0.5000\n",
      "Epoch 398/1000\n",
      "177/177 [==============================] - 0s 115us/step - loss: 0.2108 - accuracy: 0.9322 - val_loss: 1.8716 - val_accuracy: 0.5658\n",
      "Epoch 399/1000\n",
      "177/177 [==============================] - 0s 117us/step - loss: 0.1231 - accuracy: 0.9548 - val_loss: 2.0793 - val_accuracy: 0.5395\n",
      "Epoch 400/1000\n",
      "177/177 [==============================] - 0s 113us/step - loss: 0.5979 - accuracy: 0.8927 - val_loss: 2.0992 - val_accuracy: 0.5263\n",
      "Epoch 401/1000\n",
      "177/177 [==============================] - 0s 109us/step - loss: 0.2020 - accuracy: 0.9435 - val_loss: 2.2685 - val_accuracy: 0.5395\n",
      "Epoch 402/1000\n",
      "177/177 [==============================] - 0s 117us/step - loss: 0.5016 - accuracy: 0.9435 - val_loss: 2.3083 - val_accuracy: 0.5395\n",
      "Epoch 403/1000\n",
      "177/177 [==============================] - 0s 134us/step - loss: 0.3635 - accuracy: 0.8983 - val_loss: 2.0647 - val_accuracy: 0.5658\n",
      "Epoch 404/1000\n",
      "177/177 [==============================] - 0s 110us/step - loss: 0.2447 - accuracy: 0.9435 - val_loss: 1.9989 - val_accuracy: 0.5526\n",
      "Epoch 405/1000\n",
      "177/177 [==============================] - 0s 115us/step - loss: 0.1867 - accuracy: 0.9548 - val_loss: 1.9837 - val_accuracy: 0.5658\n",
      "Epoch 406/1000\n",
      "177/177 [==============================] - 0s 112us/step - loss: 0.1768 - accuracy: 0.9379 - val_loss: 2.0706 - val_accuracy: 0.5658\n",
      "Epoch 407/1000\n",
      "177/177 [==============================] - 0s 127us/step - loss: 0.1841 - accuracy: 0.9661 - val_loss: 2.0370 - val_accuracy: 0.5658\n",
      "Epoch 408/1000\n",
      "177/177 [==============================] - 0s 119us/step - loss: 0.1343 - accuracy: 0.9492 - val_loss: 2.0575 - val_accuracy: 0.5395\n",
      "Epoch 409/1000\n",
      "177/177 [==============================] - 0s 110us/step - loss: 0.1470 - accuracy: 0.9435 - val_loss: 2.1096 - val_accuracy: 0.5658\n",
      "Epoch 410/1000\n",
      "177/177 [==============================] - 0s 112us/step - loss: 0.1338 - accuracy: 0.9548 - val_loss: 2.0426 - val_accuracy: 0.5658\n",
      "Epoch 411/1000\n",
      "177/177 [==============================] - 0s 123us/step - loss: 0.2003 - accuracy: 0.9435 - val_loss: 2.0936 - val_accuracy: 0.5395\n",
      "Epoch 412/1000\n",
      "177/177 [==============================] - 0s 102us/step - loss: 0.2047 - accuracy: 0.9379 - val_loss: 2.1246 - val_accuracy: 0.5395\n",
      "Epoch 413/1000\n",
      "177/177 [==============================] - 0s 110us/step - loss: 0.1178 - accuracy: 0.9435 - val_loss: 2.1076 - val_accuracy: 0.5526\n",
      "Epoch 414/1000\n",
      "177/177 [==============================] - 0s 133us/step - loss: 0.1605 - accuracy: 0.9492 - val_loss: 2.0946 - val_accuracy: 0.5658\n",
      "Epoch 415/1000\n",
      "177/177 [==============================] - 0s 114us/step - loss: 0.1516 - accuracy: 0.9548 - val_loss: 2.1182 - val_accuracy: 0.5658\n",
      "Epoch 416/1000\n",
      "177/177 [==============================] - 0s 106us/step - loss: 0.1078 - accuracy: 0.9548 - val_loss: 2.1481 - val_accuracy: 0.5526\n",
      "Epoch 417/1000\n",
      "177/177 [==============================] - 0s 114us/step - loss: 0.1958 - accuracy: 0.9548 - val_loss: 2.3695 - val_accuracy: 0.5263\n",
      "Epoch 418/1000\n",
      "177/177 [==============================] - 0s 264us/step - loss: 2.6986 - accuracy: 0.9040 - val_loss: 4.2438 - val_accuracy: 0.5263\n",
      "Epoch 419/1000\n",
      "177/177 [==============================] - 0s 106us/step - loss: 4.2321 - accuracy: 0.9040 - val_loss: 3.8678 - val_accuracy: 0.5921\n",
      "Epoch 420/1000\n",
      "177/177 [==============================] - 0s 110us/step - loss: 3.7127 - accuracy: 0.9266 - val_loss: 3.3906 - val_accuracy: 0.5789\n",
      "Epoch 421/1000\n",
      "177/177 [==============================] - 0s 150us/step - loss: 2.8082 - accuracy: 0.9209 - val_loss: 2.8941 - val_accuracy: 0.5658\n",
      "Epoch 422/1000\n",
      "177/177 [==============================] - 0s 123us/step - loss: 1.5483 - accuracy: 0.9435 - val_loss: 2.6866 - val_accuracy: 0.5132\n",
      "Epoch 423/1000\n",
      "177/177 [==============================] - 0s 149us/step - loss: 0.7629 - accuracy: 0.9492 - val_loss: 2.5726 - val_accuracy: 0.5000\n",
      "Epoch 424/1000\n",
      "177/177 [==============================] - 0s 220us/step - loss: 0.5124 - accuracy: 0.8757 - val_loss: 2.7505 - val_accuracy: 0.4737\n",
      "Epoch 425/1000\n",
      "177/177 [==============================] - 0s 193us/step - loss: 0.4036 - accuracy: 0.9322 - val_loss: 2.4128 - val_accuracy: 0.5000\n",
      "Epoch 426/1000\n",
      "177/177 [==============================] - 0s 159us/step - loss: 0.1747 - accuracy: 0.9492 - val_loss: 2.3475 - val_accuracy: 0.5000\n",
      "Epoch 427/1000\n",
      "177/177 [==============================] - 0s 142us/step - loss: 0.1883 - accuracy: 0.9548 - val_loss: 2.2235 - val_accuracy: 0.5395\n",
      "Epoch 428/1000\n",
      "177/177 [==============================] - 0s 142us/step - loss: 0.1973 - accuracy: 0.9548 - val_loss: 2.2382 - val_accuracy: 0.5395\n",
      "Epoch 429/1000\n",
      "177/177 [==============================] - 0s 153us/step - loss: 0.1455 - accuracy: 0.9605 - val_loss: 2.2901 - val_accuracy: 0.5526\n",
      "Epoch 430/1000\n",
      "177/177 [==============================] - 0s 131us/step - loss: 0.1450 - accuracy: 0.9605 - val_loss: 2.2610 - val_accuracy: 0.5395\n",
      "Epoch 431/1000\n",
      "177/177 [==============================] - 0s 131us/step - loss: 0.1510 - accuracy: 0.9548 - val_loss: 2.2418 - val_accuracy: 0.5526\n",
      "Epoch 432/1000\n",
      "177/177 [==============================] - 0s 155us/step - loss: 0.2140 - accuracy: 0.9548 - val_loss: 2.3045 - val_accuracy: 0.5395\n",
      "Epoch 433/1000\n",
      "177/177 [==============================] - 0s 134us/step - loss: 0.1792 - accuracy: 0.9435 - val_loss: 2.2194 - val_accuracy: 0.5395\n",
      "Epoch 434/1000\n",
      "177/177 [==============================] - 0s 142us/step - loss: 0.1351 - accuracy: 0.9548 - val_loss: 2.1930 - val_accuracy: 0.5395\n",
      "Epoch 435/1000\n",
      "177/177 [==============================] - 0s 153us/step - loss: 0.1349 - accuracy: 0.9605 - val_loss: 2.2596 - val_accuracy: 0.5263\n",
      "Epoch 436/1000\n",
      "177/177 [==============================] - 0s 159us/step - loss: 0.1765 - accuracy: 0.9605 - val_loss: 2.2424 - val_accuracy: 0.5395\n",
      "Epoch 437/1000\n",
      "177/177 [==============================] - 0s 221us/step - loss: 0.1469 - accuracy: 0.9605 - val_loss: 2.2347 - val_accuracy: 0.5526\n",
      "Epoch 438/1000\n",
      "177/177 [==============================] - 0s 147us/step - loss: 0.1562 - accuracy: 0.9492 - val_loss: 2.2160 - val_accuracy: 0.5526\n",
      "Epoch 439/1000\n",
      "177/177 [==============================] - 0s 148us/step - loss: 0.1379 - accuracy: 0.9548 - val_loss: 2.2742 - val_accuracy: 0.5395\n",
      "Epoch 440/1000\n",
      "177/177 [==============================] - 0s 214us/step - loss: 0.1697 - accuracy: 0.9661 - val_loss: 2.2197 - val_accuracy: 0.5526\n",
      "Epoch 441/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177/177 [==============================] - 0s 167us/step - loss: 0.1816 - accuracy: 0.9492 - val_loss: 2.3142 - val_accuracy: 0.5263\n",
      "Epoch 442/1000\n",
      "177/177 [==============================] - 0s 149us/step - loss: 0.0970 - accuracy: 0.9605 - val_loss: 2.2613 - val_accuracy: 0.5395\n",
      "Epoch 443/1000\n",
      "177/177 [==============================] - 0s 143us/step - loss: 0.2004 - accuracy: 0.9548 - val_loss: 2.3064 - val_accuracy: 0.5263\n",
      "Epoch 444/1000\n",
      "177/177 [==============================] - 0s 151us/step - loss: 0.0992 - accuracy: 0.9605 - val_loss: 2.2690 - val_accuracy: 0.5526\n",
      "Epoch 445/1000\n",
      "177/177 [==============================] - 0s 157us/step - loss: 0.1551 - accuracy: 0.9548 - val_loss: 2.2855 - val_accuracy: 0.5263\n",
      "Epoch 446/1000\n",
      "177/177 [==============================] - 0s 138us/step - loss: 0.2295 - accuracy: 0.9492 - val_loss: 2.2720 - val_accuracy: 0.5395\n",
      "Epoch 447/1000\n",
      "177/177 [==============================] - 0s 129us/step - loss: 0.1112 - accuracy: 0.9605 - val_loss: 2.2215 - val_accuracy: 0.5526\n",
      "Epoch 448/1000\n",
      "177/177 [==============================] - 0s 199us/step - loss: 0.1377 - accuracy: 0.9605 - val_loss: 2.2096 - val_accuracy: 0.5526\n",
      "Epoch 449/1000\n",
      "177/177 [==============================] - 0s 153us/step - loss: 0.1094 - accuracy: 0.9605 - val_loss: 2.2111 - val_accuracy: 0.5658\n",
      "Epoch 450/1000\n",
      "177/177 [==============================] - 0s 161us/step - loss: 0.1636 - accuracy: 0.9548 - val_loss: 2.2665 - val_accuracy: 0.5395\n",
      "Epoch 451/1000\n",
      "177/177 [==============================] - 0s 186us/step - loss: 0.1022 - accuracy: 0.9492 - val_loss: 2.2253 - val_accuracy: 0.5526\n",
      "Epoch 452/1000\n",
      "177/177 [==============================] - 0s 172us/step - loss: 0.1401 - accuracy: 0.9379 - val_loss: 2.2998 - val_accuracy: 0.5263\n",
      "Epoch 453/1000\n",
      "177/177 [==============================] - 0s 193us/step - loss: 0.2114 - accuracy: 0.9492 - val_loss: 2.2443 - val_accuracy: 0.5263\n",
      "Epoch 454/1000\n",
      "177/177 [==============================] - 0s 142us/step - loss: 0.1232 - accuracy: 0.9661 - val_loss: 2.2657 - val_accuracy: 0.5395\n",
      "Epoch 455/1000\n",
      "177/177 [==============================] - 0s 129us/step - loss: 0.1560 - accuracy: 0.9548 - val_loss: 2.2319 - val_accuracy: 0.5789\n",
      "Epoch 456/1000\n",
      "177/177 [==============================] - 0s 183us/step - loss: 0.1046 - accuracy: 0.9548 - val_loss: 2.2914 - val_accuracy: 0.5132\n",
      "Epoch 457/1000\n",
      "177/177 [==============================] - 0s 155us/step - loss: 0.1546 - accuracy: 0.9718 - val_loss: 2.2080 - val_accuracy: 0.5789\n",
      "Epoch 458/1000\n",
      "177/177 [==============================] - 0s 197us/step - loss: 0.1011 - accuracy: 0.9605 - val_loss: 2.2548 - val_accuracy: 0.5395\n",
      "Epoch 459/1000\n",
      "177/177 [==============================] - 0s 165us/step - loss: 0.1993 - accuracy: 0.9548 - val_loss: 2.3198 - val_accuracy: 0.5395\n",
      "Epoch 460/1000\n",
      "177/177 [==============================] - 0s 142us/step - loss: 0.2009 - accuracy: 0.9548 - val_loss: 2.2467 - val_accuracy: 0.5658\n",
      "Epoch 461/1000\n",
      "177/177 [==============================] - 0s 195us/step - loss: 0.1255 - accuracy: 0.9661 - val_loss: 2.5058 - val_accuracy: 0.5263\n",
      "Epoch 462/1000\n",
      "177/177 [==============================] - 0s 141us/step - loss: 0.2721 - accuracy: 0.9492 - val_loss: 2.3176 - val_accuracy: 0.5263\n",
      "Epoch 463/1000\n",
      "177/177 [==============================] - 0s 119us/step - loss: 0.1065 - accuracy: 0.9548 - val_loss: 2.2740 - val_accuracy: 0.5526\n",
      "Epoch 464/1000\n",
      "177/177 [==============================] - 0s 132us/step - loss: 0.1522 - accuracy: 0.9661 - val_loss: 2.2646 - val_accuracy: 0.5526\n",
      "Epoch 465/1000\n",
      "177/177 [==============================] - 0s 106us/step - loss: 0.1652 - accuracy: 0.9548 - val_loss: 2.3155 - val_accuracy: 0.5526\n",
      "Epoch 466/1000\n",
      "177/177 [==============================] - 0s 116us/step - loss: 0.1638 - accuracy: 0.9605 - val_loss: 2.3354 - val_accuracy: 0.5921\n",
      "Epoch 467/1000\n",
      "177/177 [==============================] - 0s 107us/step - loss: 0.0976 - accuracy: 0.9718 - val_loss: 2.3215 - val_accuracy: 0.5395\n",
      "Epoch 468/1000\n",
      "177/177 [==============================] - 0s 132us/step - loss: 0.0917 - accuracy: 0.9718 - val_loss: 2.2256 - val_accuracy: 0.5658\n",
      "Epoch 469/1000\n",
      "177/177 [==============================] - 0s 103us/step - loss: 0.1299 - accuracy: 0.9548 - val_loss: 2.2013 - val_accuracy: 0.5526\n",
      "Epoch 470/1000\n",
      "177/177 [==============================] - 0s 105us/step - loss: 0.1311 - accuracy: 0.9661 - val_loss: 2.2537 - val_accuracy: 0.5526\n",
      "Epoch 471/1000\n",
      "177/177 [==============================] - ETA: 0s - loss: 0.0378 - accuracy: 1.00 - 0s 106us/step - loss: 0.1708 - accuracy: 0.9605 - val_loss: 2.2793 - val_accuracy: 0.5395\n",
      "Epoch 472/1000\n",
      "177/177 [==============================] - 0s 110us/step - loss: 0.1677 - accuracy: 0.9605 - val_loss: 2.3027 - val_accuracy: 0.5526\n",
      "Epoch 473/1000\n",
      "177/177 [==============================] - 0s 106us/step - loss: 0.1074 - accuracy: 0.9661 - val_loss: 2.3152 - val_accuracy: 0.5395\n",
      "Epoch 474/1000\n",
      "177/177 [==============================] - 0s 111us/step - loss: 0.1071 - accuracy: 0.9548 - val_loss: 2.2841 - val_accuracy: 0.5658\n",
      "Epoch 475/1000\n",
      "177/177 [==============================] - 0s 150us/step - loss: 0.0990 - accuracy: 0.9661 - val_loss: 2.3011 - val_accuracy: 0.5263\n",
      "Epoch 476/1000\n",
      "177/177 [==============================] - 0s 116us/step - loss: 0.1678 - accuracy: 0.9605 - val_loss: 2.3046 - val_accuracy: 0.5395\n",
      "Epoch 477/1000\n",
      "177/177 [==============================] - 0s 108us/step - loss: 0.1721 - accuracy: 0.9548 - val_loss: 2.2937 - val_accuracy: 0.5789\n",
      "Epoch 478/1000\n",
      "177/177 [==============================] - 0s 107us/step - loss: 0.0890 - accuracy: 0.9718 - val_loss: 2.3205 - val_accuracy: 0.5263\n",
      "Epoch 479/1000\n",
      "177/177 [==============================] - 0s 132us/step - loss: 0.1330 - accuracy: 0.9605 - val_loss: 2.3211 - val_accuracy: 0.5526\n",
      "Epoch 480/1000\n",
      "177/177 [==============================] - 0s 103us/step - loss: 0.1755 - accuracy: 0.9605 - val_loss: 2.3203 - val_accuracy: 0.5526\n",
      "Epoch 481/1000\n",
      "177/177 [==============================] - 0s 97us/step - loss: 0.1159 - accuracy: 0.9492 - val_loss: 2.1955 - val_accuracy: 0.5789\n",
      "Epoch 482/1000\n",
      "177/177 [==============================] - 0s 103us/step - loss: 0.1083 - accuracy: 0.9718 - val_loss: 2.1954 - val_accuracy: 0.5658\n",
      "Epoch 483/1000\n",
      "177/177 [==============================] - 0s 134us/step - loss: 0.1821 - accuracy: 0.9492 - val_loss: 2.2711 - val_accuracy: 0.5526\n",
      "Epoch 484/1000\n",
      "177/177 [==============================] - 0s 105us/step - loss: 0.1664 - accuracy: 0.9605 - val_loss: 2.2987 - val_accuracy: 0.5658\n",
      "Epoch 485/1000\n",
      "177/177 [==============================] - 0s 115us/step - loss: 0.0938 - accuracy: 0.9605 - val_loss: 2.3853 - val_accuracy: 0.5263\n",
      "Epoch 486/1000\n",
      "177/177 [==============================] - 0s 136us/step - loss: 0.1846 - accuracy: 0.9605 - val_loss: 2.3666 - val_accuracy: 0.5263\n",
      "Epoch 487/1000\n",
      "177/177 [==============================] - 0s 97us/step - loss: 0.3299 - accuracy: 0.9153 - val_loss: 2.3041 - val_accuracy: 0.5395\n",
      "Epoch 488/1000\n",
      "177/177 [==============================] - 0s 101us/step - loss: 0.2215 - accuracy: 0.9492 - val_loss: 2.3138 - val_accuracy: 0.5789\n",
      "Epoch 489/1000\n",
      "177/177 [==============================] - 0s 125us/step - loss: 0.2548 - accuracy: 0.9492 - val_loss: 2.2422 - val_accuracy: 0.5526\n",
      "Epoch 490/1000\n",
      "177/177 [==============================] - 0s 174us/step - loss: 0.1944 - accuracy: 0.9548 - val_loss: 2.2765 - val_accuracy: 0.5526\n",
      "Epoch 491/1000\n",
      "177/177 [==============================] - 0s 155us/step - loss: 0.1428 - accuracy: 0.9718 - val_loss: 2.3107 - val_accuracy: 0.5789\n",
      "Epoch 492/1000\n",
      "177/177 [==============================] - 0s 244us/step - loss: 0.1407 - accuracy: 0.9548 - val_loss: 2.3733 - val_accuracy: 0.5263\n",
      "Epoch 493/1000\n",
      "177/177 [==============================] - 0s 137us/step - loss: 0.2295 - accuracy: 0.9548 - val_loss: 2.3098 - val_accuracy: 0.5395\n",
      "Epoch 494/1000\n",
      "177/177 [==============================] - 0s 144us/step - loss: 0.1833 - accuracy: 0.9379 - val_loss: 2.2557 - val_accuracy: 0.5658\n",
      "Epoch 495/1000\n",
      "177/177 [==============================] - 0s 191us/step - loss: 0.1343 - accuracy: 0.9605 - val_loss: 2.3502 - val_accuracy: 0.5658\n",
      "Epoch 496/1000\n",
      "177/177 [==============================] - 0s 164us/step - loss: 0.1343 - accuracy: 0.9605 - val_loss: 2.3429 - val_accuracy: 0.5526\n",
      "Epoch 497/1000\n",
      "177/177 [==============================] - 0s 188us/step - loss: 0.1480 - accuracy: 0.9605 - val_loss: 2.3201 - val_accuracy: 0.5526\n",
      "Epoch 498/1000\n",
      "177/177 [==============================] - 0s 159us/step - loss: 0.0875 - accuracy: 0.9718 - val_loss: 2.3574 - val_accuracy: 0.5526\n",
      "Epoch 499/1000\n",
      "177/177 [==============================] - 0s 156us/step - loss: 0.0948 - accuracy: 0.9605 - val_loss: 2.3642 - val_accuracy: 0.5395\n",
      "Epoch 500/1000\n",
      "177/177 [==============================] - 0s 186us/step - loss: 0.1421 - accuracy: 0.9548 - val_loss: 2.3448 - val_accuracy: 0.5526\n",
      "Epoch 501/1000\n",
      "177/177 [==============================] - 0s 157us/step - loss: 0.0902 - accuracy: 0.9661 - val_loss: 2.3474 - val_accuracy: 0.5658\n",
      "Epoch 502/1000\n",
      "177/177 [==============================] - 0s 184us/step - loss: 0.1333 - accuracy: 0.9492 - val_loss: 2.3353 - val_accuracy: 0.5658\n",
      "Epoch 503/1000\n",
      "177/177 [==============================] - 0s 164us/step - loss: 0.1324 - accuracy: 0.9661 - val_loss: 2.3436 - val_accuracy: 0.5658\n",
      "Epoch 504/1000\n",
      "177/177 [==============================] - 0s 130us/step - loss: 0.1295 - accuracy: 0.9605 - val_loss: 2.3643 - val_accuracy: 0.5658\n",
      "Epoch 505/1000\n",
      "177/177 [==============================] - 0s 147us/step - loss: 0.1037 - accuracy: 0.9661 - val_loss: 2.3856 - val_accuracy: 0.5526\n",
      "Epoch 506/1000\n",
      "177/177 [==============================] - 0s 144us/step - loss: 0.1757 - accuracy: 0.9548 - val_loss: 2.4818 - val_accuracy: 0.5263\n",
      "Epoch 507/1000\n",
      "177/177 [==============================] - 0s 144us/step - loss: 0.2329 - accuracy: 0.9435 - val_loss: 2.4412 - val_accuracy: 0.5395\n",
      "Epoch 508/1000\n",
      "177/177 [==============================] - 0s 183us/step - loss: 0.2107 - accuracy: 0.9379 - val_loss: 2.4007 - val_accuracy: 0.5526\n",
      "Epoch 509/1000\n",
      "177/177 [==============================] - 0s 137us/step - loss: 0.2116 - accuracy: 0.9379 - val_loss: 2.4129 - val_accuracy: 0.5263\n",
      "Epoch 510/1000\n",
      "177/177 [==============================] - 0s 162us/step - loss: 4.7838 - accuracy: 0.8362 - val_loss: 4.2025 - val_accuracy: 0.5395\n",
      "Epoch 511/1000\n",
      "177/177 [==============================] - 0s 248us/step - loss: 5.2367 - accuracy: 0.8418 - val_loss: 3.2209 - val_accuracy: 0.4868\n",
      "Epoch 512/1000\n",
      "177/177 [==============================] - 0s 147us/step - loss: 2.9363 - accuracy: 0.8588 - val_loss: 3.5083 - val_accuracy: 0.4737\n",
      "Epoch 513/1000\n",
      "177/177 [==============================] - 0s 171us/step - loss: 1.9494 - accuracy: 0.8814 - val_loss: 2.9449 - val_accuracy: 0.5132\n",
      "Epoch 514/1000\n",
      "177/177 [==============================] - 0s 157us/step - loss: 1.2435 - accuracy: 0.9096 - val_loss: 2.4400 - val_accuracy: 0.5658\n",
      "Epoch 515/1000\n",
      "177/177 [==============================] - 0s 162us/step - loss: 0.3276 - accuracy: 0.9266 - val_loss: 2.4736 - val_accuracy: 0.5921\n",
      "Epoch 516/1000\n",
      "177/177 [==============================] - 0s 196us/step - loss: 0.2029 - accuracy: 0.9096 - val_loss: 2.5299 - val_accuracy: 0.5921\n",
      "Epoch 517/1000\n",
      "177/177 [==============================] - 0s 164us/step - loss: 0.1716 - accuracy: 0.9548 - val_loss: 2.5082 - val_accuracy: 0.5789\n",
      "Epoch 518/1000\n",
      "177/177 [==============================] - 0s 186us/step - loss: 0.1305 - accuracy: 0.9661 - val_loss: 2.4742 - val_accuracy: 0.5921\n",
      "Epoch 519/1000\n",
      "177/177 [==============================] - 0s 151us/step - loss: 0.1506 - accuracy: 0.9492 - val_loss: 2.4274 - val_accuracy: 0.5789\n",
      "Epoch 520/1000\n",
      "177/177 [==============================] - 0s 139us/step - loss: 0.1387 - accuracy: 0.9548 - val_loss: 2.4142 - val_accuracy: 0.5526\n",
      "Epoch 521/1000\n",
      "177/177 [==============================] - 0s 171us/step - loss: 0.1362 - accuracy: 0.9605 - val_loss: 2.4570 - val_accuracy: 0.5526\n",
      "Epoch 522/1000\n",
      "177/177 [==============================] - 0s 147us/step - loss: 0.1412 - accuracy: 0.9548 - val_loss: 2.4576 - val_accuracy: 0.5263\n",
      "Epoch 523/1000\n",
      "177/177 [==============================] - 0s 160us/step - loss: 0.1325 - accuracy: 0.9605 - val_loss: 2.5184 - val_accuracy: 0.5395\n",
      "Epoch 524/1000\n",
      "177/177 [==============================] - 0s 178us/step - loss: 0.0851 - accuracy: 0.9774 - val_loss: 2.4504 - val_accuracy: 0.5526\n",
      "Epoch 525/1000\n",
      "177/177 [==============================] - 0s 139us/step - loss: 0.1215 - accuracy: 0.9605 - val_loss: 2.4253 - val_accuracy: 0.5526\n",
      "Epoch 526/1000\n",
      "177/177 [==============================] - 0s 181us/step - loss: 0.0861 - accuracy: 0.9661 - val_loss: 2.4866 - val_accuracy: 0.5263\n",
      "Epoch 527/1000\n",
      "177/177 [==============================] - 0s 141us/step - loss: 0.1113 - accuracy: 0.9661 - val_loss: 2.4600 - val_accuracy: 0.5395\n",
      "Epoch 528/1000\n",
      "177/177 [==============================] - 0s 154us/step - loss: 0.0918 - accuracy: 0.9718 - val_loss: 2.4944 - val_accuracy: 0.5132\n",
      "Epoch 529/1000\n",
      "177/177 [==============================] - 0s 166us/step - loss: 0.1328 - accuracy: 0.9661 - val_loss: 2.4870 - val_accuracy: 0.5132\n",
      "Epoch 530/1000\n",
      "177/177 [==============================] - 0s 149us/step - loss: 0.0901 - accuracy: 0.9718 - val_loss: 2.4688 - val_accuracy: 0.5132\n",
      "Epoch 531/1000\n",
      "177/177 [==============================] - 0s 143us/step - loss: 0.1074 - accuracy: 0.9661 - val_loss: 2.5078 - val_accuracy: 0.5395\n",
      "Epoch 532/1000\n",
      "177/177 [==============================] - 0s 177us/step - loss: 0.1244 - accuracy: 0.9661 - val_loss: 2.7582 - val_accuracy: 0.5263\n",
      "Epoch 533/1000\n",
      "177/177 [==============================] - 0s 147us/step - loss: 0.1426 - accuracy: 0.9661 - val_loss: 2.4557 - val_accuracy: 0.5395\n",
      "Epoch 534/1000\n",
      "177/177 [==============================] - 0s 150us/step - loss: 0.1001 - accuracy: 0.9661 - val_loss: 2.2996 - val_accuracy: 0.5000\n",
      "Epoch 535/1000\n",
      "177/177 [==============================] - 0s 192us/step - loss: 0.1609 - accuracy: 0.9605 - val_loss: 2.3317 - val_accuracy: 0.5132\n",
      "Epoch 536/1000\n",
      "177/177 [==============================] - 0s 145us/step - loss: 0.1160 - accuracy: 0.9661 - val_loss: 2.6766 - val_accuracy: 0.5526\n",
      "Epoch 537/1000\n",
      "177/177 [==============================] - 0s 174us/step - loss: 0.1114 - accuracy: 0.9661 - val_loss: 2.6721 - val_accuracy: 0.5263\n",
      "Epoch 538/1000\n",
      "177/177 [==============================] - 0s 150us/step - loss: 0.1623 - accuracy: 0.9718 - val_loss: 2.4531 - val_accuracy: 0.5132\n",
      "Epoch 539/1000\n",
      "177/177 [==============================] - 0s 159us/step - loss: 0.0842 - accuracy: 0.9718 - val_loss: 2.3762 - val_accuracy: 0.5526\n",
      "Epoch 540/1000\n",
      "177/177 [==============================] - 0s 204us/step - loss: 0.1324 - accuracy: 0.9548 - val_loss: 2.4250 - val_accuracy: 0.5132\n",
      "Epoch 541/1000\n",
      "177/177 [==============================] - 0s 149us/step - loss: 0.1145 - accuracy: 0.9605 - val_loss: 2.4726 - val_accuracy: 0.5658\n",
      "Epoch 542/1000\n",
      "177/177 [==============================] - 0s 157us/step - loss: 0.0894 - accuracy: 0.9661 - val_loss: 2.5058 - val_accuracy: 0.5658\n",
      "Epoch 543/1000\n",
      "177/177 [==============================] - 0s 168us/step - loss: 0.0802 - accuracy: 0.9718 - val_loss: 2.5122 - val_accuracy: 0.5526\n",
      "Epoch 544/1000\n",
      "177/177 [==============================] - 0s 155us/step - loss: 0.1077 - accuracy: 0.9718 - val_loss: 2.5259 - val_accuracy: 0.5395\n",
      "Epoch 545/1000\n",
      "177/177 [==============================] - 0s 174us/step - loss: 0.0845 - accuracy: 0.9661 - val_loss: 2.5162 - val_accuracy: 0.5263\n",
      "Epoch 546/1000\n",
      "177/177 [==============================] - 0s 146us/step - loss: 0.0920 - accuracy: 0.9661 - val_loss: 2.5095 - val_accuracy: 0.5395\n",
      "Epoch 547/1000\n",
      "177/177 [==============================] - 0s 147us/step - loss: 0.1104 - accuracy: 0.9492 - val_loss: 2.5299 - val_accuracy: 0.5132\n",
      "Epoch 548/1000\n",
      "177/177 [==============================] - 0s 176us/step - loss: 0.1521 - accuracy: 0.9548 - val_loss: 2.5950 - val_accuracy: 0.5263\n",
      "Epoch 549/1000\n",
      "177/177 [==============================] - 0s 144us/step - loss: 0.1191 - accuracy: 0.9605 - val_loss: 2.4846 - val_accuracy: 0.5263\n",
      "Epoch 550/1000\n",
      "177/177 [==============================] - 0s 149us/step - loss: 0.1326 - accuracy: 0.9661 - val_loss: 2.4970 - val_accuracy: 0.5263\n",
      "Epoch 551/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177/177 [==============================] - 0s 166us/step - loss: 0.1107 - accuracy: 0.9661 - val_loss: 2.5432 - val_accuracy: 0.5132\n",
      "Epoch 552/1000\n",
      "177/177 [==============================] - 0s 152us/step - loss: 0.0862 - accuracy: 0.9661 - val_loss: 2.5078 - val_accuracy: 0.5395\n",
      "Epoch 553/1000\n",
      "177/177 [==============================] - 0s 186us/step - loss: 0.1415 - accuracy: 0.9492 - val_loss: 2.6672 - val_accuracy: 0.5000\n",
      "Epoch 554/1000\n",
      "177/177 [==============================] - 0s 171us/step - loss: 0.2555 - accuracy: 0.9492 - val_loss: 2.6552 - val_accuracy: 0.5132\n",
      "Epoch 555/1000\n",
      "177/177 [==============================] - 0s 151us/step - loss: 0.2439 - accuracy: 0.9548 - val_loss: 2.5189 - val_accuracy: 0.5395\n",
      "Epoch 556/1000\n",
      "177/177 [==============================] - 0s 184us/step - loss: 0.0940 - accuracy: 0.9661 - val_loss: 3.0090 - val_accuracy: 0.5000\n",
      "Epoch 557/1000\n",
      "177/177 [==============================] - 0s 163us/step - loss: 0.6340 - accuracy: 0.9322 - val_loss: 2.7732 - val_accuracy: 0.5263\n",
      "Epoch 558/1000\n",
      "177/177 [==============================] - 0s 172us/step - loss: 0.5500 - accuracy: 0.9548 - val_loss: 2.5239 - val_accuracy: 0.5132\n",
      "Epoch 559/1000\n",
      "177/177 [==============================] - 0s 171us/step - loss: 0.1897 - accuracy: 0.9548 - val_loss: 2.4751 - val_accuracy: 0.5263\n",
      "Epoch 560/1000\n",
      "177/177 [==============================] - 0s 182us/step - loss: 0.1406 - accuracy: 0.9605 - val_loss: 2.5435 - val_accuracy: 0.5526\n",
      "Epoch 561/1000\n",
      "177/177 [==============================] - 0s 196us/step - loss: 0.0918 - accuracy: 0.9548 - val_loss: 2.6077 - val_accuracy: 0.5132\n",
      "Epoch 562/1000\n",
      "177/177 [==============================] - 0s 154us/step - loss: 0.1383 - accuracy: 0.9605 - val_loss: 2.5504 - val_accuracy: 0.5395\n",
      "Epoch 563/1000\n",
      "177/177 [==============================] - 0s 197us/step - loss: 0.0831 - accuracy: 0.9605 - val_loss: 2.5260 - val_accuracy: 0.5395\n",
      "Epoch 564/1000\n",
      "177/177 [==============================] - 0s 160us/step - loss: 0.1334 - accuracy: 0.9605 - val_loss: 2.4852 - val_accuracy: 0.5395\n",
      "Epoch 565/1000\n",
      "177/177 [==============================] - 0s 164us/step - loss: 0.0846 - accuracy: 0.9661 - val_loss: 2.6145 - val_accuracy: 0.5263\n",
      "Epoch 566/1000\n",
      "177/177 [==============================] - 0s 203us/step - loss: 0.1459 - accuracy: 0.9605 - val_loss: 2.5428 - val_accuracy: 0.5000\n",
      "Epoch 567/1000\n",
      "177/177 [==============================] - 0s 157us/step - loss: 0.1114 - accuracy: 0.9548 - val_loss: 2.5433 - val_accuracy: 0.5263\n",
      "Epoch 568/1000\n",
      "177/177 [==============================] - 0s 178us/step - loss: 0.0990 - accuracy: 0.9718 - val_loss: 2.5428 - val_accuracy: 0.5263\n",
      "Epoch 569/1000\n",
      "177/177 [==============================] - 0s 155us/step - loss: 0.1766 - accuracy: 0.9661 - val_loss: 2.5998 - val_accuracy: 0.5000\n",
      "Epoch 570/1000\n",
      "177/177 [==============================] - 0s 156us/step - loss: 0.1885 - accuracy: 0.9548 - val_loss: 2.5761 - val_accuracy: 0.5263\n",
      "Epoch 571/1000\n",
      "177/177 [==============================] - 0s 175us/step - loss: 0.1310 - accuracy: 0.9548 - val_loss: 2.6908 - val_accuracy: 0.5000\n",
      "Epoch 572/1000\n",
      "177/177 [==============================] - 0s 155us/step - loss: 0.4991 - accuracy: 0.9322 - val_loss: 2.7018 - val_accuracy: 0.5000\n",
      "Epoch 573/1000\n",
      "177/177 [==============================] - 0s 149us/step - loss: 0.3848 - accuracy: 0.9548 - val_loss: 2.5546 - val_accuracy: 0.5395\n",
      "Epoch 574/1000\n",
      "177/177 [==============================] - 0s 180us/step - loss: 0.1503 - accuracy: 0.9661 - val_loss: 2.4914 - val_accuracy: 0.5395\n",
      "Epoch 575/1000\n",
      "177/177 [==============================] - 0s 143us/step - loss: 0.0787 - accuracy: 0.9661 - val_loss: 2.5039 - val_accuracy: 0.5395\n",
      "Epoch 576/1000\n",
      "177/177 [==============================] - 0s 148us/step - loss: 0.1683 - accuracy: 0.9605 - val_loss: 2.6178 - val_accuracy: 0.4868\n",
      "Epoch 577/1000\n",
      "177/177 [==============================] - 0s 164us/step - loss: 3.8414 - accuracy: 0.8475 - val_loss: 3.8630 - val_accuracy: 0.5263\n",
      "Epoch 578/1000\n",
      "177/177 [==============================] - 0s 156us/step - loss: 3.6064 - accuracy: 0.8757 - val_loss: 3.4754 - val_accuracy: 0.4474\n",
      "Epoch 579/1000\n",
      "177/177 [==============================] - 0s 185us/step - loss: 2.8740 - accuracy: 0.8192 - val_loss: 3.3980 - val_accuracy: 0.4868\n",
      "Epoch 580/1000\n",
      "177/177 [==============================] - 0s 145us/step - loss: 1.9243 - accuracy: 0.8927 - val_loss: 3.2304 - val_accuracy: 0.5000\n",
      "Epoch 581/1000\n",
      "177/177 [==============================] - 0s 147us/step - loss: 0.9514 - accuracy: 0.8870 - val_loss: 2.8794 - val_accuracy: 0.5658\n",
      "Epoch 582/1000\n",
      "177/177 [==============================] - 0s 192us/step - loss: 0.1722 - accuracy: 0.9322 - val_loss: 2.9877 - val_accuracy: 0.5658\n",
      "Epoch 583/1000\n",
      "177/177 [==============================] - 0s 145us/step - loss: 0.1988 - accuracy: 0.9096 - val_loss: 2.8325 - val_accuracy: 0.5526\n",
      "Epoch 584/1000\n",
      "177/177 [==============================] - 0s 171us/step - loss: 0.2585 - accuracy: 0.9492 - val_loss: 2.8270 - val_accuracy: 0.5526\n",
      "Epoch 585/1000\n",
      "177/177 [==============================] - 0s 168us/step - loss: 0.3279 - accuracy: 0.9209 - val_loss: 2.8192 - val_accuracy: 0.5526\n",
      "Epoch 586/1000\n",
      "177/177 [==============================] - 0s 145us/step - loss: 0.2056 - accuracy: 0.9492 - val_loss: 2.7632 - val_accuracy: 0.5395\n",
      "Epoch 587/1000\n",
      "177/177 [==============================] - 0s 187us/step - loss: 0.1238 - accuracy: 0.9548 - val_loss: 2.7028 - val_accuracy: 0.5526\n",
      "Epoch 588/1000\n",
      "177/177 [==============================] - 0s 146us/step - loss: 0.2358 - accuracy: 0.9435 - val_loss: 2.7360 - val_accuracy: 0.5395\n",
      "Epoch 589/1000\n",
      "177/177 [==============================] - 0s 155us/step - loss: 0.2468 - accuracy: 0.9379 - val_loss: 2.7014 - val_accuracy: 0.5395\n",
      "Epoch 590/1000\n",
      "177/177 [==============================] - 0s 176us/step - loss: 0.3527 - accuracy: 0.9605 - val_loss: 2.7315 - val_accuracy: 0.5263\n",
      "Epoch 591/1000\n",
      "177/177 [==============================] - 0s 147us/step - loss: 0.1021 - accuracy: 0.9605 - val_loss: 2.7282 - val_accuracy: 0.5132\n",
      "Epoch 592/1000\n",
      "177/177 [==============================] - 0s 136us/step - loss: 0.0833 - accuracy: 0.9718 - val_loss: 2.7160 - val_accuracy: 0.5132\n",
      "Epoch 593/1000\n",
      "177/177 [==============================] - 0s 164us/step - loss: 0.0802 - accuracy: 0.9661 - val_loss: 2.7089 - val_accuracy: 0.5132\n",
      "Epoch 594/1000\n",
      "177/177 [==============================] - 0s 154us/step - loss: 0.0931 - accuracy: 0.9661 - val_loss: 2.6921 - val_accuracy: 0.5132\n",
      "Epoch 595/1000\n",
      "177/177 [==============================] - 0s 188us/step - loss: 0.0913 - accuracy: 0.9718 - val_loss: 2.7237 - val_accuracy: 0.5000\n",
      "Epoch 596/1000\n",
      "177/177 [==============================] - 0s 144us/step - loss: 0.0967 - accuracy: 0.9661 - val_loss: 2.6918 - val_accuracy: 0.5132\n",
      "Epoch 597/1000\n",
      "177/177 [==============================] - 0s 158us/step - loss: 0.0778 - accuracy: 0.9718 - val_loss: 2.6723 - val_accuracy: 0.5263\n",
      "Epoch 598/1000\n",
      "177/177 [==============================] - 0s 183us/step - loss: 0.0765 - accuracy: 0.9718 - val_loss: 2.6911 - val_accuracy: 0.5263\n",
      "Epoch 599/1000\n",
      "177/177 [==============================] - 0s 184us/step - loss: 0.0735 - accuracy: 0.9718 - val_loss: 2.7091 - val_accuracy: 0.5132\n",
      "Epoch 600/1000\n",
      "177/177 [==============================] - 0s 148us/step - loss: 0.0810 - accuracy: 0.9661 - val_loss: 2.7052 - val_accuracy: 0.5132\n",
      "Epoch 601/1000\n",
      "177/177 [==============================] - 0s 154us/step - loss: 0.0972 - accuracy: 0.9718 - val_loss: 2.7198 - val_accuracy: 0.5000\n",
      "Epoch 602/1000\n",
      "177/177 [==============================] - 0s 157us/step - loss: 0.0802 - accuracy: 0.9661 - val_loss: 2.6602 - val_accuracy: 0.5263\n",
      "Epoch 603/1000\n",
      "177/177 [==============================] - 0s 214us/step - loss: 0.1266 - accuracy: 0.9661 - val_loss: 2.7092 - val_accuracy: 0.5132\n",
      "Epoch 604/1000\n",
      "177/177 [==============================] - 0s 168us/step - loss: 0.1525 - accuracy: 0.9548 - val_loss: 2.8610 - val_accuracy: 0.5132\n",
      "Epoch 605/1000\n",
      "177/177 [==============================] - 0s 149us/step - loss: 1.5058 - accuracy: 0.8475 - val_loss: 6.1290 - val_accuracy: 0.4737\n",
      "Epoch 606/1000\n",
      "177/177 [==============================] - 0s 197us/step - loss: 3.5831 - accuracy: 0.8192 - val_loss: 5.1002 - val_accuracy: 0.4737\n",
      "Epoch 607/1000\n",
      "177/177 [==============================] - 0s 161us/step - loss: 1.3321 - accuracy: 0.8983 - val_loss: 3.8830 - val_accuracy: 0.4737\n",
      "Epoch 608/1000\n",
      "177/177 [==============================] - 0s 203us/step - loss: 0.8587 - accuracy: 0.9153 - val_loss: 2.7637 - val_accuracy: 0.5000\n",
      "Epoch 609/1000\n",
      "177/177 [==============================] - 0s 151us/step - loss: 0.3249 - accuracy: 0.9266 - val_loss: 2.3763 - val_accuracy: 0.5263\n",
      "Epoch 610/1000\n",
      "177/177 [==============================] - 0s 157us/step - loss: 0.1830 - accuracy: 0.8983 - val_loss: 2.4350 - val_accuracy: 0.5658\n",
      "Epoch 611/1000\n",
      "177/177 [==============================] - 0s 166us/step - loss: 0.1600 - accuracy: 0.9548 - val_loss: 2.5390 - val_accuracy: 0.5526\n",
      "Epoch 612/1000\n",
      "177/177 [==============================] - 0s 160us/step - loss: 0.1270 - accuracy: 0.9435 - val_loss: 2.6549 - val_accuracy: 0.5395\n",
      "Epoch 613/1000\n",
      "177/177 [==============================] - 0s 188us/step - loss: 0.0980 - accuracy: 0.9661 - val_loss: 2.6464 - val_accuracy: 0.5263\n",
      "Epoch 614/1000\n",
      "177/177 [==============================] - 0s 150us/step - loss: 0.1380 - accuracy: 0.9605 - val_loss: 2.6049 - val_accuracy: 0.5526\n",
      "Epoch 615/1000\n",
      "177/177 [==============================] - 0s 155us/step - loss: 0.1435 - accuracy: 0.9605 - val_loss: 2.6120 - val_accuracy: 0.5395\n",
      "Epoch 616/1000\n",
      "177/177 [==============================] - 0s 307us/step - loss: 0.1147 - accuracy: 0.9661 - val_loss: 2.5649 - val_accuracy: 0.5789\n",
      "Epoch 617/1000\n",
      "177/177 [==============================] - 0s 170us/step - loss: 0.0840 - accuracy: 0.9605 - val_loss: 2.5776 - val_accuracy: 0.5526\n",
      "Epoch 618/1000\n",
      "177/177 [==============================] - 0s 176us/step - loss: 0.0800 - accuracy: 0.9605 - val_loss: 2.6043 - val_accuracy: 0.5658\n",
      "Epoch 619/1000\n",
      "177/177 [==============================] - 0s 150us/step - loss: 0.0926 - accuracy: 0.9605 - val_loss: 2.5845 - val_accuracy: 0.5789\n",
      "Epoch 620/1000\n",
      "177/177 [==============================] - 0s 224us/step - loss: 0.0811 - accuracy: 0.9605 - val_loss: 2.6173 - val_accuracy: 0.5921\n",
      "Epoch 621/1000\n",
      "177/177 [==============================] - 0s 225us/step - loss: 0.1151 - accuracy: 0.9605 - val_loss: 2.6473 - val_accuracy: 0.5789\n",
      "Epoch 622/1000\n",
      "177/177 [==============================] - 0s 254us/step - loss: 0.0862 - accuracy: 0.9605 - val_loss: 2.6260 - val_accuracy: 0.5921\n",
      "Epoch 623/1000\n",
      "177/177 [==============================] - 0s 256us/step - loss: 0.0689 - accuracy: 0.9718 - val_loss: 2.6641 - val_accuracy: 0.5789\n",
      "Epoch 624/1000\n",
      "177/177 [==============================] - 0s 245us/step - loss: 0.0820 - accuracy: 0.9605 - val_loss: 2.6781 - val_accuracy: 0.5658\n",
      "Epoch 625/1000\n",
      "177/177 [==============================] - 0s 195us/step - loss: 0.1047 - accuracy: 0.9605 - val_loss: 2.6787 - val_accuracy: 0.5789\n",
      "Epoch 626/1000\n",
      "177/177 [==============================] - 0s 224us/step - loss: 0.1358 - accuracy: 0.9661 - val_loss: 2.7346 - val_accuracy: 0.5658\n",
      "Epoch 627/1000\n",
      "177/177 [==============================] - 0s 218us/step - loss: 0.0737 - accuracy: 0.9605 - val_loss: 2.6734 - val_accuracy: 0.5789\n",
      "Epoch 628/1000\n",
      "177/177 [==============================] - 0s 199us/step - loss: 0.1284 - accuracy: 0.9661 - val_loss: 2.6780 - val_accuracy: 0.5921\n",
      "Epoch 629/1000\n",
      "177/177 [==============================] - 0s 214us/step - loss: 0.0653 - accuracy: 0.9774 - val_loss: 2.6692 - val_accuracy: 0.5789\n",
      "Epoch 630/1000\n",
      "177/177 [==============================] - 0s 217us/step - loss: 0.0862 - accuracy: 0.9661 - val_loss: 2.7123 - val_accuracy: 0.5658\n",
      "Epoch 631/1000\n",
      "177/177 [==============================] - 0s 229us/step - loss: 0.1440 - accuracy: 0.9605 - val_loss: 2.7597 - val_accuracy: 0.5263\n",
      "Epoch 632/1000\n",
      "177/177 [==============================] - 0s 225us/step - loss: 0.1858 - accuracy: 0.9605 - val_loss: 2.6754 - val_accuracy: 0.5526\n",
      "Epoch 633/1000\n",
      "177/177 [==============================] - 0s 201us/step - loss: 0.0990 - accuracy: 0.9605 - val_loss: 2.6761 - val_accuracy: 0.5658\n",
      "Epoch 634/1000\n",
      "177/177 [==============================] - 0s 210us/step - loss: 0.1076 - accuracy: 0.9605 - val_loss: 2.6895 - val_accuracy: 0.5658\n",
      "Epoch 635/1000\n",
      "177/177 [==============================] - 0s 154us/step - loss: 0.0667 - accuracy: 0.9661 - val_loss: 2.6902 - val_accuracy: 0.5921\n",
      "Epoch 636/1000\n",
      "177/177 [==============================] - 0s 179us/step - loss: 0.0713 - accuracy: 0.9661 - val_loss: 2.7621 - val_accuracy: 0.5395\n",
      "Epoch 637/1000\n",
      "177/177 [==============================] - 0s 145us/step - loss: 0.1079 - accuracy: 0.9605 - val_loss: 2.7914 - val_accuracy: 0.5395\n",
      "Epoch 638/1000\n",
      "177/177 [==============================] - 0s 153us/step - loss: 0.0640 - accuracy: 0.9774 - val_loss: 2.7461 - val_accuracy: 0.5526\n",
      "Epoch 639/1000\n",
      "177/177 [==============================] - 0s 183us/step - loss: 0.0790 - accuracy: 0.9718 - val_loss: 2.7290 - val_accuracy: 0.5658\n",
      "Epoch 640/1000\n",
      "177/177 [==============================] - 0s 165us/step - loss: 0.1082 - accuracy: 0.9661 - val_loss: 2.7767 - val_accuracy: 0.5658\n",
      "Epoch 641/1000\n",
      "177/177 [==============================] - 0s 163us/step - loss: 0.0629 - accuracy: 0.9661 - val_loss: 2.7577 - val_accuracy: 0.5658\n",
      "Epoch 642/1000\n",
      "177/177 [==============================] - 0s 189us/step - loss: 0.0644 - accuracy: 0.9774 - val_loss: 2.7390 - val_accuracy: 0.5789\n",
      "Epoch 643/1000\n",
      "177/177 [==============================] - 0s 166us/step - loss: 0.0801 - accuracy: 0.9661 - val_loss: 2.7307 - val_accuracy: 0.5526\n",
      "Epoch 644/1000\n",
      "177/177 [==============================] - 0s 182us/step - loss: 0.0942 - accuracy: 0.9718 - val_loss: 2.7505 - val_accuracy: 0.5263\n",
      "Epoch 645/1000\n",
      "177/177 [==============================] - 0s 140us/step - loss: 0.1096 - accuracy: 0.9661 - val_loss: 2.7105 - val_accuracy: 0.5658\n",
      "Epoch 646/1000\n",
      "177/177 [==============================] - 0s 124us/step - loss: 0.0930 - accuracy: 0.9605 - val_loss: 2.7109 - val_accuracy: 0.5789\n",
      "Epoch 647/1000\n",
      "177/177 [==============================] - 0s 168us/step - loss: 0.1180 - accuracy: 0.9718 - val_loss: 2.7489 - val_accuracy: 0.5395\n",
      "Epoch 648/1000\n",
      "177/177 [==============================] - 0s 149us/step - loss: 0.0680 - accuracy: 0.9661 - val_loss: 2.7535 - val_accuracy: 0.5526\n",
      "Epoch 649/1000\n",
      "177/177 [==============================] - 0s 145us/step - loss: 0.0908 - accuracy: 0.9718 - val_loss: 2.7449 - val_accuracy: 0.5395\n",
      "Epoch 650/1000\n",
      "177/177 [==============================] - 0s 187us/step - loss: 0.0699 - accuracy: 0.9605 - val_loss: 2.7833 - val_accuracy: 0.5132\n",
      "Epoch 651/1000\n",
      "177/177 [==============================] - 0s 170us/step - loss: 0.1358 - accuracy: 0.9661 - val_loss: 2.8935 - val_accuracy: 0.5263\n",
      "Epoch 652/1000\n",
      "177/177 [==============================] - 0s 185us/step - loss: 0.0982 - accuracy: 0.9718 - val_loss: 2.5744 - val_accuracy: 0.5658\n",
      "Epoch 653/1000\n",
      "177/177 [==============================] - 0s 149us/step - loss: 0.1508 - accuracy: 0.9661 - val_loss: 2.4892 - val_accuracy: 0.5263\n",
      "Epoch 654/1000\n",
      "177/177 [==============================] - 0s 148us/step - loss: 0.0747 - accuracy: 0.9718 - val_loss: 2.5037 - val_accuracy: 0.5658\n",
      "Epoch 655/1000\n",
      "177/177 [==============================] - 0s 200us/step - loss: 0.1013 - accuracy: 0.9605 - val_loss: 2.6065 - val_accuracy: 0.5658\n",
      "Epoch 656/1000\n",
      "177/177 [==============================] - 0s 154us/step - loss: 0.0821 - accuracy: 0.9661 - val_loss: 2.6452 - val_accuracy: 0.5526\n",
      "Epoch 657/1000\n",
      "177/177 [==============================] - 0s 190us/step - loss: 0.1260 - accuracy: 0.9718 - val_loss: 2.6617 - val_accuracy: 0.5395\n",
      "Epoch 658/1000\n",
      "177/177 [==============================] - 0s 151us/step - loss: 0.0693 - accuracy: 0.9718 - val_loss: 2.6450 - val_accuracy: 0.5789\n",
      "Epoch 659/1000\n",
      "177/177 [==============================] - 0s 168us/step - loss: 0.0888 - accuracy: 0.9718 - val_loss: 2.6513 - val_accuracy: 0.5789\n",
      "Epoch 660/1000\n",
      "177/177 [==============================] - 0s 199us/step - loss: 0.0748 - accuracy: 0.9718 - val_loss: 2.7439 - val_accuracy: 0.5263\n",
      "Epoch 661/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177/177 [==============================] - 0s 152us/step - loss: 0.1172 - accuracy: 0.9661 - val_loss: 2.7099 - val_accuracy: 0.5526\n",
      "Epoch 662/1000\n",
      "177/177 [==============================] - 0s 188us/step - loss: 0.1106 - accuracy: 0.9661 - val_loss: 2.7194 - val_accuracy: 0.5395\n",
      "Epoch 663/1000\n",
      "177/177 [==============================] - 0s 147us/step - loss: 0.1121 - accuracy: 0.9548 - val_loss: 2.6969 - val_accuracy: 0.5658\n",
      "Epoch 664/1000\n",
      "177/177 [==============================] - 0s 161us/step - loss: 0.1358 - accuracy: 0.9548 - val_loss: 2.7825 - val_accuracy: 0.5263\n",
      "Epoch 665/1000\n",
      "177/177 [==============================] - 0s 218us/step - loss: 0.0800 - accuracy: 0.9718 - val_loss: 2.7421 - val_accuracy: 0.5263\n",
      "Epoch 666/1000\n",
      "177/177 [==============================] - 0s 174us/step - loss: 0.1220 - accuracy: 0.9661 - val_loss: 2.6409 - val_accuracy: 0.5263\n",
      "Epoch 667/1000\n",
      "177/177 [==============================] - 0s 204us/step - loss: 0.0707 - accuracy: 0.9661 - val_loss: 2.5208 - val_accuracy: 0.5526\n",
      "Epoch 668/1000\n",
      "177/177 [==============================] - 0s 147us/step - loss: 0.0846 - accuracy: 0.9661 - val_loss: 2.5009 - val_accuracy: 0.5526\n",
      "Epoch 669/1000\n",
      "177/177 [==============================] - 0s 165us/step - loss: 0.0707 - accuracy: 0.9718 - val_loss: 2.5900 - val_accuracy: 0.5658\n",
      "Epoch 670/1000\n",
      "177/177 [==============================] - 0s 219us/step - loss: 0.0772 - accuracy: 0.9661 - val_loss: 2.6524 - val_accuracy: 0.5395\n",
      "Epoch 671/1000\n",
      "177/177 [==============================] - 0s 159us/step - loss: 0.0877 - accuracy: 0.9718 - val_loss: 2.7006 - val_accuracy: 0.5132\n",
      "Epoch 672/1000\n",
      "177/177 [==============================] - 0s 191us/step - loss: 0.1495 - accuracy: 0.9718 - val_loss: 2.6955 - val_accuracy: 0.5132\n",
      "Epoch 673/1000\n",
      "177/177 [==============================] - 0s 149us/step - loss: 0.1319 - accuracy: 0.9605 - val_loss: 2.5919 - val_accuracy: 0.5526\n",
      "Epoch 674/1000\n",
      "177/177 [==============================] - 0s 155us/step - loss: 0.0685 - accuracy: 0.9661 - val_loss: 2.6353 - val_accuracy: 0.5263\n",
      "Epoch 675/1000\n",
      "177/177 [==============================] - 0s 179us/step - loss: 0.1193 - accuracy: 0.9718 - val_loss: 2.6389 - val_accuracy: 0.5395\n",
      "Epoch 676/1000\n",
      "177/177 [==============================] - 0s 163us/step - loss: 0.0690 - accuracy: 0.9718 - val_loss: 2.6769 - val_accuracy: 0.5526\n",
      "Epoch 677/1000\n",
      "177/177 [==============================] - 0s 191us/step - loss: 0.2018 - accuracy: 0.9661 - val_loss: 2.9324 - val_accuracy: 0.5132\n",
      "Epoch 678/1000\n",
      "177/177 [==============================] - 0s 149us/step - loss: 0.1498 - accuracy: 0.9661 - val_loss: 2.6516 - val_accuracy: 0.5526\n",
      "Epoch 679/1000\n",
      "177/177 [==============================] - 0s 153us/step - loss: 0.0895 - accuracy: 0.9774 - val_loss: 2.5106 - val_accuracy: 0.5132\n",
      "Epoch 680/1000\n",
      "177/177 [==============================] - 0s 181us/step - loss: 0.1169 - accuracy: 0.9718 - val_loss: 2.4757 - val_accuracy: 0.5658\n",
      "Epoch 681/1000\n",
      "177/177 [==============================] - 0s 148us/step - loss: 0.0758 - accuracy: 0.9718 - val_loss: 2.5637 - val_accuracy: 0.5658\n",
      "Epoch 682/1000\n",
      "177/177 [==============================] - 0s 153us/step - loss: 0.0764 - accuracy: 0.9718 - val_loss: 2.5896 - val_accuracy: 0.5658\n",
      "Epoch 683/1000\n",
      "177/177 [==============================] - 0s 181us/step - loss: 0.1212 - accuracy: 0.9718 - val_loss: 2.6374 - val_accuracy: 0.5395\n",
      "Epoch 684/1000\n",
      "177/177 [==============================] - 0s 146us/step - loss: 0.1239 - accuracy: 0.9718 - val_loss: 2.6731 - val_accuracy: 0.5395\n",
      "Epoch 685/1000\n",
      "177/177 [==============================] - 0s 199us/step - loss: 0.0630 - accuracy: 0.9774 - val_loss: 2.7069 - val_accuracy: 0.5526\n",
      "Epoch 686/1000\n",
      "177/177 [==============================] - 0s 161us/step - loss: 0.0908 - accuracy: 0.9718 - val_loss: 2.7075 - val_accuracy: 0.5526\n",
      "Epoch 687/1000\n",
      "177/177 [==============================] - 0s 157us/step - loss: 0.0629 - accuracy: 0.9774 - val_loss: 2.7100 - val_accuracy: 0.5395\n",
      "Epoch 688/1000\n",
      "177/177 [==============================] - 0s 182us/step - loss: 0.0746 - accuracy: 0.9718 - val_loss: 2.7161 - val_accuracy: 0.5263\n",
      "Epoch 689/1000\n",
      "177/177 [==============================] - 0s 164us/step - loss: 0.1025 - accuracy: 0.9718 - val_loss: 2.7002 - val_accuracy: 0.5526\n",
      "Epoch 690/1000\n",
      "177/177 [==============================] - 0s 192us/step - loss: 0.0992 - accuracy: 0.9548 - val_loss: 2.6646 - val_accuracy: 0.5395\n",
      "Epoch 691/1000\n",
      "177/177 [==============================] - 0s 152us/step - loss: 0.0783 - accuracy: 0.9605 - val_loss: 2.8960 - val_accuracy: 0.5132\n",
      "Epoch 692/1000\n",
      "177/177 [==============================] - 0s 169us/step - loss: 1.9988 - accuracy: 0.8814 - val_loss: 5.7396 - val_accuracy: 0.5000\n",
      "Epoch 693/1000\n",
      "177/177 [==============================] - 0s 212us/step - loss: 2.6653 - accuracy: 0.8475 - val_loss: 5.3091 - val_accuracy: 0.4868\n",
      "Epoch 694/1000\n",
      "177/177 [==============================] - 0s 169us/step - loss: 2.0226 - accuracy: 0.8701 - val_loss: 4.2788 - val_accuracy: 0.4605\n",
      "Epoch 695/1000\n",
      "177/177 [==============================] - 0s 187us/step - loss: 3.7682 - accuracy: 0.8418 - val_loss: 6.5732 - val_accuracy: 0.4211\n",
      "Epoch 696/1000\n",
      "177/177 [==============================] - 0s 144us/step - loss: 5.7619 - accuracy: 0.8531 - val_loss: 4.9195 - val_accuracy: 0.4605\n",
      "Epoch 697/1000\n",
      "177/177 [==============================] - 0s 160us/step - loss: 3.7055 - accuracy: 0.8588 - val_loss: 3.1564 - val_accuracy: 0.5263\n",
      "Epoch 698/1000\n",
      "177/177 [==============================] - 0s 175us/step - loss: 1.8002 - accuracy: 0.8475 - val_loss: 2.6308 - val_accuracy: 0.5000\n",
      "Epoch 699/1000\n",
      "177/177 [==============================] - 0s 155us/step - loss: 0.6461 - accuracy: 0.8531 - val_loss: 2.6989 - val_accuracy: 0.5526\n",
      "Epoch 700/1000\n",
      "177/177 [==============================] - 0s 188us/step - loss: 0.3371 - accuracy: 0.9492 - val_loss: 2.8261 - val_accuracy: 0.5395\n",
      "Epoch 701/1000\n",
      "177/177 [==============================] - 0s 152us/step - loss: 0.2456 - accuracy: 0.9435 - val_loss: 2.8159 - val_accuracy: 0.5526\n",
      "Epoch 702/1000\n",
      "177/177 [==============================] - 0s 152us/step - loss: 0.1209 - accuracy: 0.9548 - val_loss: 2.7868 - val_accuracy: 0.5658\n",
      "Epoch 703/1000\n",
      "177/177 [==============================] - 0s 186us/step - loss: 0.1220 - accuracy: 0.9605 - val_loss: 2.7797 - val_accuracy: 0.5921\n",
      "Epoch 704/1000\n",
      "177/177 [==============================] - 0s 170us/step - loss: 0.1508 - accuracy: 0.9661 - val_loss: 2.8178 - val_accuracy: 0.5921\n",
      "Epoch 705/1000\n",
      "177/177 [==============================] - 0s 171us/step - loss: 0.0906 - accuracy: 0.9605 - val_loss: 2.5495 - val_accuracy: 0.5658\n",
      "Epoch 706/1000\n",
      "177/177 [==============================] - 0s 173us/step - loss: 0.1146 - accuracy: 0.9661 - val_loss: 2.5827 - val_accuracy: 0.5921\n",
      "Epoch 707/1000\n",
      "177/177 [==============================] - 0s 159us/step - loss: 0.1215 - accuracy: 0.9661 - val_loss: 2.6464 - val_accuracy: 0.5789\n",
      "Epoch 708/1000\n",
      "177/177 [==============================] - 0s 180us/step - loss: 0.0722 - accuracy: 0.9774 - val_loss: 2.7194 - val_accuracy: 0.5921\n",
      "Epoch 709/1000\n",
      "177/177 [==============================] - 0s 154us/step - loss: 0.0708 - accuracy: 0.9718 - val_loss: 2.7911 - val_accuracy: 0.6053\n",
      "Epoch 710/1000\n",
      "177/177 [==============================] - 0s 159us/step - loss: 0.0818 - accuracy: 0.9661 - val_loss: 2.8346 - val_accuracy: 0.6053\n",
      "Epoch 711/1000\n",
      "177/177 [==============================] - 0s 186us/step - loss: 0.0935 - accuracy: 0.9718 - val_loss: 2.8600 - val_accuracy: 0.5658\n",
      "Epoch 712/1000\n",
      "177/177 [==============================] - 0s 148us/step - loss: 0.0737 - accuracy: 0.9605 - val_loss: 2.8608 - val_accuracy: 0.5921\n",
      "Epoch 713/1000\n",
      "177/177 [==============================] - 0s 188us/step - loss: 0.0844 - accuracy: 0.9661 - val_loss: 2.8676 - val_accuracy: 0.5921\n",
      "Epoch 714/1000\n",
      "177/177 [==============================] - 0s 151us/step - loss: 0.0746 - accuracy: 0.9661 - val_loss: 2.9169 - val_accuracy: 0.5658\n",
      "Epoch 715/1000\n",
      "177/177 [==============================] - 0s 161us/step - loss: 0.1269 - accuracy: 0.9605 - val_loss: 2.8701 - val_accuracy: 0.5789\n",
      "Epoch 716/1000\n",
      "177/177 [==============================] - 0s 183us/step - loss: 0.1675 - accuracy: 0.9492 - val_loss: 2.8399 - val_accuracy: 0.5789\n",
      "Epoch 717/1000\n",
      "177/177 [==============================] - 0s 156us/step - loss: 0.0678 - accuracy: 0.9548 - val_loss: 2.8823 - val_accuracy: 0.5789\n",
      "Epoch 718/1000\n",
      "177/177 [==============================] - 0s 155us/step - loss: 0.0626 - accuracy: 0.9774 - val_loss: 2.9010 - val_accuracy: 0.5789\n",
      "Epoch 719/1000\n",
      "177/177 [==============================] - 0s 194us/step - loss: 0.0636 - accuracy: 0.9718 - val_loss: 2.9060 - val_accuracy: 0.5921\n",
      "Epoch 720/1000\n",
      "177/177 [==============================] - 0s 167us/step - loss: 0.0612 - accuracy: 0.9661 - val_loss: 2.9646 - val_accuracy: 0.5789\n",
      "Epoch 721/1000\n",
      "177/177 [==============================] - 0s 205us/step - loss: 0.0733 - accuracy: 0.9718 - val_loss: 2.9349 - val_accuracy: 0.5789\n",
      "Epoch 722/1000\n",
      "177/177 [==============================] - 0s 150us/step - loss: 0.0926 - accuracy: 0.9661 - val_loss: 2.9710 - val_accuracy: 0.5658\n",
      "Epoch 723/1000\n",
      "177/177 [==============================] - 0s 176us/step - loss: 0.1102 - accuracy: 0.9661 - val_loss: 2.9293 - val_accuracy: 0.5789\n",
      "Epoch 724/1000\n",
      "177/177 [==============================] - 0s 171us/step - loss: 0.1473 - accuracy: 0.9492 - val_loss: 3.0338 - val_accuracy: 0.5658\n",
      "Epoch 725/1000\n",
      "177/177 [==============================] - 0s 161us/step - loss: 2.0134 - accuracy: 0.8757 - val_loss: 5.9285 - val_accuracy: 0.5132\n",
      "Epoch 726/1000\n",
      "177/177 [==============================] - 0s 185us/step - loss: 2.6528 - accuracy: 0.8475 - val_loss: 6.0059 - val_accuracy: 0.4868\n",
      "Epoch 727/1000\n",
      "177/177 [==============================] - 0s 153us/step - loss: 2.2549 - accuracy: 0.8644 - val_loss: 5.0969 - val_accuracy: 0.4868\n",
      "Epoch 728/1000\n",
      "177/177 [==============================] - 0s 158us/step - loss: 1.5723 - accuracy: 0.9322 - val_loss: 3.9789 - val_accuracy: 0.5000\n",
      "Epoch 729/1000\n",
      "177/177 [==============================] - 0s 180us/step - loss: 0.9958 - accuracy: 0.9492 - val_loss: 3.2316 - val_accuracy: 0.5132\n",
      "Epoch 730/1000\n",
      "177/177 [==============================] - 0s 148us/step - loss: 0.6921 - accuracy: 0.9379 - val_loss: 2.6856 - val_accuracy: 0.5000\n",
      "Epoch 731/1000\n",
      "177/177 [==============================] - 0s 153us/step - loss: 0.2866 - accuracy: 0.9435 - val_loss: 2.6715 - val_accuracy: 0.5132\n",
      "Epoch 732/1000\n",
      "177/177 [==============================] - 0s 179us/step - loss: 0.1915 - accuracy: 0.9266 - val_loss: 2.6566 - val_accuracy: 0.5263\n",
      "Epoch 733/1000\n",
      "177/177 [==============================] - 0s 163us/step - loss: 0.1653 - accuracy: 0.9266 - val_loss: 2.6697 - val_accuracy: 0.5395\n",
      "Epoch 734/1000\n",
      "177/177 [==============================] - 0s 193us/step - loss: 0.1327 - accuracy: 0.9209 - val_loss: 2.6786 - val_accuracy: 0.5263\n",
      "Epoch 735/1000\n",
      "177/177 [==============================] - 0s 152us/step - loss: 0.1421 - accuracy: 0.9492 - val_loss: 2.7710 - val_accuracy: 0.5263\n",
      "Epoch 736/1000\n",
      "177/177 [==============================] - 0s 160us/step - loss: 0.1301 - accuracy: 0.9605 - val_loss: 2.8060 - val_accuracy: 0.5263\n",
      "Epoch 737/1000\n",
      "177/177 [==============================] - 0s 182us/step - loss: 0.0995 - accuracy: 0.9435 - val_loss: 2.7786 - val_accuracy: 0.5395\n",
      "Epoch 738/1000\n",
      "177/177 [==============================] - 0s 153us/step - loss: 0.0790 - accuracy: 0.9661 - val_loss: 2.7898 - val_accuracy: 0.5526\n",
      "Epoch 739/1000\n",
      "177/177 [==============================] - 0s 192us/step - loss: 0.0945 - accuracy: 0.9548 - val_loss: 2.8339 - val_accuracy: 0.5526\n",
      "Epoch 740/1000\n",
      "177/177 [==============================] - 0s 146us/step - loss: 0.0763 - accuracy: 0.9492 - val_loss: 2.8481 - val_accuracy: 0.5395\n",
      "Epoch 741/1000\n",
      "177/177 [==============================] - 0s 158us/step - loss: 0.0694 - accuracy: 0.9661 - val_loss: 2.8429 - val_accuracy: 0.5395\n",
      "Epoch 742/1000\n",
      "177/177 [==============================] - 0s 184us/step - loss: 0.0760 - accuracy: 0.9661 - val_loss: 2.8521 - val_accuracy: 0.5526\n",
      "Epoch 743/1000\n",
      "177/177 [==============================] - 0s 151us/step - loss: 0.0777 - accuracy: 0.9661 - val_loss: 2.8658 - val_accuracy: 0.5658\n",
      "Epoch 744/1000\n",
      "177/177 [==============================] - 0s 161us/step - loss: 0.1074 - accuracy: 0.9661 - val_loss: 2.9237 - val_accuracy: 0.5526\n",
      "Epoch 745/1000\n",
      "177/177 [==============================] - 0s 184us/step - loss: 0.0603 - accuracy: 0.9774 - val_loss: 2.9163 - val_accuracy: 0.5395\n",
      "Epoch 746/1000\n",
      "177/177 [==============================] - 0s 173us/step - loss: 0.0718 - accuracy: 0.9718 - val_loss: 2.9210 - val_accuracy: 0.5395\n",
      "Epoch 747/1000\n",
      "177/177 [==============================] - 0s 184us/step - loss: 0.0848 - accuracy: 0.9661 - val_loss: 2.9031 - val_accuracy: 0.5395\n",
      "Epoch 748/1000\n",
      "177/177 [==============================] - 0s 149us/step - loss: 0.0717 - accuracy: 0.9661 - val_loss: 2.8946 - val_accuracy: 0.5395\n",
      "Epoch 749/1000\n",
      "177/177 [==============================] - 0s 153us/step - loss: 0.0841 - accuracy: 0.9718 - val_loss: 2.8811 - val_accuracy: 0.5526\n",
      "Epoch 750/1000\n",
      "177/177 [==============================] - 0s 197us/step - loss: 0.0682 - accuracy: 0.9718 - val_loss: 2.8690 - val_accuracy: 0.5526\n",
      "Epoch 751/1000\n",
      "177/177 [==============================] - 0s 169us/step - loss: 0.0816 - accuracy: 0.9661 - val_loss: 2.9201 - val_accuracy: 0.5395\n",
      "Epoch 752/1000\n",
      "177/177 [==============================] - 0s 205us/step - loss: 0.0731 - accuracy: 0.9661 - val_loss: 2.9044 - val_accuracy: 0.5526\n",
      "Epoch 753/1000\n",
      "177/177 [==============================] - 0s 159us/step - loss: 0.0857 - accuracy: 0.9718 - val_loss: 2.9111 - val_accuracy: 0.5526\n",
      "Epoch 754/1000\n",
      "177/177 [==============================] - 0s 156us/step - loss: 0.0987 - accuracy: 0.9605 - val_loss: 2.9702 - val_accuracy: 0.5395\n",
      "Epoch 755/1000\n",
      "177/177 [==============================] - 0s 197us/step - loss: 0.0619 - accuracy: 0.9774 - val_loss: 2.9228 - val_accuracy: 0.5395\n",
      "Epoch 756/1000\n",
      "177/177 [==============================] - 0s 154us/step - loss: 0.0824 - accuracy: 0.9661 - val_loss: 2.9243 - val_accuracy: 0.5526\n",
      "Epoch 757/1000\n",
      "177/177 [==============================] - 0s 177us/step - loss: 0.0663 - accuracy: 0.9774 - val_loss: 2.9745 - val_accuracy: 0.5395\n",
      "Epoch 758/1000\n",
      "177/177 [==============================] - 0s 136us/step - loss: 0.1113 - accuracy: 0.9605 - val_loss: 2.9216 - val_accuracy: 0.5526\n",
      "Epoch 759/1000\n",
      "177/177 [==============================] - 0s 168us/step - loss: 0.0719 - accuracy: 0.9718 - val_loss: 2.9185 - val_accuracy: 0.5395\n",
      "Epoch 760/1000\n",
      "177/177 [==============================] - 0s 192us/step - loss: 0.1080 - accuracy: 0.9605 - val_loss: 2.9405 - val_accuracy: 0.5395\n",
      "Epoch 761/1000\n",
      "177/177 [==============================] - 0s 162us/step - loss: 0.1308 - accuracy: 0.9605 - val_loss: 2.9843 - val_accuracy: 0.5395\n",
      "Epoch 762/1000\n",
      "177/177 [==============================] - 0s 176us/step - loss: 0.0773 - accuracy: 0.9718 - val_loss: 2.9776 - val_accuracy: 0.5263\n",
      "Epoch 763/1000\n",
      "177/177 [==============================] - 0s 173us/step - loss: 0.0957 - accuracy: 0.9435 - val_loss: 2.9779 - val_accuracy: 0.5526\n",
      "Epoch 764/1000\n",
      "177/177 [==============================] - 0s 175us/step - loss: 0.1039 - accuracy: 0.9661 - val_loss: 2.9361 - val_accuracy: 0.5789\n",
      "Epoch 765/1000\n",
      "177/177 [==============================] - 0s 211us/step - loss: 0.0593 - accuracy: 0.9718 - val_loss: 2.9410 - val_accuracy: 0.5789\n",
      "Epoch 766/1000\n",
      "177/177 [==============================] - 0s 150us/step - loss: 0.0582 - accuracy: 0.9774 - val_loss: 3.0110 - val_accuracy: 0.5921\n",
      "Epoch 767/1000\n",
      "177/177 [==============================] - 0s 206us/step - loss: 0.0697 - accuracy: 0.9605 - val_loss: 3.0355 - val_accuracy: 0.5658\n",
      "Epoch 768/1000\n",
      "177/177 [==============================] - 0s 147us/step - loss: 0.0959 - accuracy: 0.9718 - val_loss: 2.9871 - val_accuracy: 0.5789\n",
      "Epoch 769/1000\n",
      "177/177 [==============================] - 0s 170us/step - loss: 0.0920 - accuracy: 0.9718 - val_loss: 3.0222 - val_accuracy: 0.5658\n",
      "Epoch 770/1000\n",
      "177/177 [==============================] - 0s 189us/step - loss: 0.1444 - accuracy: 0.9492 - val_loss: 3.0203 - val_accuracy: 0.5526\n",
      "Epoch 771/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177/177 [==============================] - 0s 151us/step - loss: 0.0723 - accuracy: 0.9548 - val_loss: 3.0074 - val_accuracy: 0.5395\n",
      "Epoch 772/1000\n",
      "177/177 [==============================] - 0s 155us/step - loss: 0.0903 - accuracy: 0.9605 - val_loss: 3.0203 - val_accuracy: 0.5658\n",
      "Epoch 773/1000\n",
      "177/177 [==============================] - 0s 163us/step - loss: 0.0868 - accuracy: 0.9718 - val_loss: 2.9400 - val_accuracy: 0.5658\n",
      "Epoch 774/1000\n",
      "177/177 [==============================] - 0s 147us/step - loss: 0.0656 - accuracy: 0.9605 - val_loss: 2.9180 - val_accuracy: 0.5526\n",
      "Epoch 775/1000\n",
      "177/177 [==============================] - 0s 183us/step - loss: 0.1094 - accuracy: 0.9605 - val_loss: 2.8933 - val_accuracy: 0.5658\n",
      "Epoch 776/1000\n",
      "177/177 [==============================] - 0s 145us/step - loss: 0.0606 - accuracy: 0.9718 - val_loss: 2.9928 - val_accuracy: 0.5658\n",
      "Epoch 777/1000\n",
      "177/177 [==============================] - 0s 165us/step - loss: 0.0920 - accuracy: 0.9718 - val_loss: 3.0330 - val_accuracy: 0.5395\n",
      "Epoch 778/1000\n",
      "177/177 [==============================] - 0s 199us/step - loss: 0.0933 - accuracy: 0.9605 - val_loss: 2.9689 - val_accuracy: 0.5658\n",
      "Epoch 779/1000\n",
      "177/177 [==============================] - 0s 148us/step - loss: 0.1181 - accuracy: 0.9661 - val_loss: 3.0030 - val_accuracy: 0.5526\n",
      "Epoch 780/1000\n",
      "177/177 [==============================] - 0s 148us/step - loss: 0.0903 - accuracy: 0.9718 - val_loss: 3.1307 - val_accuracy: 0.5526\n",
      "Epoch 781/1000\n",
      "177/177 [==============================] - 0s 153us/step - loss: 0.1527 - accuracy: 0.9548 - val_loss: 3.2443 - val_accuracy: 0.5000\n",
      "Epoch 782/1000\n",
      "177/177 [==============================] - 0s 151us/step - loss: 0.1508 - accuracy: 0.9718 - val_loss: 3.1983 - val_accuracy: 0.5132\n",
      "Epoch 783/1000\n",
      "177/177 [==============================] - 0s 191us/step - loss: 0.0701 - accuracy: 0.9774 - val_loss: 3.1485 - val_accuracy: 0.5658\n",
      "Epoch 784/1000\n",
      "177/177 [==============================] - 0s 153us/step - loss: 0.0677 - accuracy: 0.9718 - val_loss: 3.1334 - val_accuracy: 0.5395\n",
      "Epoch 785/1000\n",
      "177/177 [==============================] - 0s 154us/step - loss: 0.0760 - accuracy: 0.9605 - val_loss: 3.0853 - val_accuracy: 0.5658\n",
      "Epoch 786/1000\n",
      "177/177 [==============================] - 0s 204us/step - loss: 0.0613 - accuracy: 0.9718 - val_loss: 3.1317 - val_accuracy: 0.5658\n",
      "Epoch 787/1000\n",
      "177/177 [==============================] - 0s 158us/step - loss: 0.0569 - accuracy: 0.9774 - val_loss: 3.1107 - val_accuracy: 0.5395\n",
      "Epoch 788/1000\n",
      "177/177 [==============================] - 0s 169us/step - loss: 0.0619 - accuracy: 0.9661 - val_loss: 3.0562 - val_accuracy: 0.5526\n",
      "Epoch 789/1000\n",
      "177/177 [==============================] - 0s 162us/step - loss: 0.0580 - accuracy: 0.9774 - val_loss: 3.0930 - val_accuracy: 0.5395\n",
      "Epoch 790/1000\n",
      "177/177 [==============================] - 0s 168us/step - loss: 0.0598 - accuracy: 0.9661 - val_loss: 3.0649 - val_accuracy: 0.5395\n",
      "Epoch 791/1000\n",
      "177/177 [==============================] - 0s 200us/step - loss: 0.0814 - accuracy: 0.9661 - val_loss: 3.0360 - val_accuracy: 0.5658\n",
      "Epoch 792/1000\n",
      "177/177 [==============================] - 0s 177us/step - loss: 0.0639 - accuracy: 0.9718 - val_loss: 3.0739 - val_accuracy: 0.5526\n",
      "Epoch 793/1000\n",
      "177/177 [==============================] - 0s 199us/step - loss: 0.0551 - accuracy: 0.9774 - val_loss: 3.1166 - val_accuracy: 0.5526\n",
      "Epoch 794/1000\n",
      "177/177 [==============================] - 0s 173us/step - loss: 0.0551 - accuracy: 0.9718 - val_loss: 3.0796 - val_accuracy: 0.5526\n",
      "Epoch 795/1000\n",
      "177/177 [==============================] - 0s 147us/step - loss: 0.0564 - accuracy: 0.9661 - val_loss: 3.0247 - val_accuracy: 0.5526\n",
      "Epoch 796/1000\n",
      "177/177 [==============================] - 0s 251us/step - loss: 0.0553 - accuracy: 0.9774 - val_loss: 3.0444 - val_accuracy: 0.5658\n",
      "Epoch 797/1000\n",
      "177/177 [==============================] - 0s 174us/step - loss: 0.0720 - accuracy: 0.9661 - val_loss: 3.0499 - val_accuracy: 0.5658\n",
      "Epoch 798/1000\n",
      "177/177 [==============================] - 0s 174us/step - loss: 0.0964 - accuracy: 0.9661 - val_loss: 3.1105 - val_accuracy: 0.5395\n",
      "Epoch 799/1000\n",
      "177/177 [==============================] - 0s 162us/step - loss: 0.0959 - accuracy: 0.9718 - val_loss: 3.0670 - val_accuracy: 0.5526\n",
      "Epoch 800/1000\n",
      "177/177 [==============================] - 0s 170us/step - loss: 0.0536 - accuracy: 0.9718 - val_loss: 3.0627 - val_accuracy: 0.5395\n",
      "Epoch 801/1000\n",
      "177/177 [==============================] - 0s 146us/step - loss: 0.0582 - accuracy: 0.9718 - val_loss: 2.9804 - val_accuracy: 0.5526\n",
      "Epoch 802/1000\n",
      "177/177 [==============================] - 0s 147us/step - loss: 0.0872 - accuracy: 0.9605 - val_loss: 2.9796 - val_accuracy: 0.5395\n",
      "Epoch 803/1000\n",
      "177/177 [==============================] - 0s 166us/step - loss: 0.0580 - accuracy: 0.9661 - val_loss: 2.9623 - val_accuracy: 0.5658\n",
      "Epoch 804/1000\n",
      "177/177 [==============================] - 0s 164us/step - loss: 0.0759 - accuracy: 0.9718 - val_loss: 3.1696 - val_accuracy: 0.5263\n",
      "Epoch 805/1000\n",
      "177/177 [==============================] - 0s 155us/step - loss: 0.1109 - accuracy: 0.9718 - val_loss: 2.9206 - val_accuracy: 0.5526\n",
      "Epoch 806/1000\n",
      "177/177 [==============================] - 0s 164us/step - loss: 0.1144 - accuracy: 0.9661 - val_loss: 2.8807 - val_accuracy: 0.5263\n",
      "Epoch 807/1000\n",
      "177/177 [==============================] - 0s 133us/step - loss: 0.1344 - accuracy: 0.9718 - val_loss: 2.9263 - val_accuracy: 0.5000\n",
      "Epoch 808/1000\n",
      "177/177 [==============================] - 0s 150us/step - loss: 0.0663 - accuracy: 0.9774 - val_loss: 2.9463 - val_accuracy: 0.5789\n",
      "Epoch 809/1000\n",
      "177/177 [==============================] - 0s 175us/step - loss: 0.1510 - accuracy: 0.9605 - val_loss: 3.0296 - val_accuracy: 0.5263\n",
      "Epoch 810/1000\n",
      "177/177 [==============================] - 0s 146us/step - loss: 0.0609 - accuracy: 0.9718 - val_loss: 3.0106 - val_accuracy: 0.5658\n",
      "Epoch 811/1000\n",
      "177/177 [==============================] - 0s 176us/step - loss: 0.1102 - accuracy: 0.9718 - val_loss: 3.0057 - val_accuracy: 0.5395\n",
      "Epoch 812/1000\n",
      "177/177 [==============================] - 0s 147us/step - loss: 0.0959 - accuracy: 0.9718 - val_loss: 3.0075 - val_accuracy: 0.5395\n",
      "Epoch 813/1000\n",
      "177/177 [==============================] - 0s 170us/step - loss: 0.0528 - accuracy: 0.9774 - val_loss: 2.9688 - val_accuracy: 0.5526\n",
      "Epoch 814/1000\n",
      "177/177 [==============================] - 0s 184us/step - loss: 0.0551 - accuracy: 0.9774 - val_loss: 3.1461 - val_accuracy: 0.5132\n",
      "Epoch 815/1000\n",
      "177/177 [==============================] - 0s 154us/step - loss: 0.0748 - accuracy: 0.9661 - val_loss: 3.1733 - val_accuracy: 0.5526\n",
      "Epoch 816/1000\n",
      "177/177 [==============================] - 0s 160us/step - loss: 0.0886 - accuracy: 0.9661 - val_loss: 3.2018 - val_accuracy: 0.5000\n",
      "Epoch 817/1000\n",
      "177/177 [==============================] - 0s 156us/step - loss: 0.1402 - accuracy: 0.9661 - val_loss: 3.2428 - val_accuracy: 0.5132\n",
      "Epoch 818/1000\n",
      "177/177 [==============================] - 0s 153us/step - loss: 0.0517 - accuracy: 0.9774 - val_loss: 3.1710 - val_accuracy: 0.5526\n",
      "Epoch 819/1000\n",
      "177/177 [==============================] - 0s 186us/step - loss: 0.0905 - accuracy: 0.9718 - val_loss: 3.1874 - val_accuracy: 0.5132\n",
      "Epoch 820/1000\n",
      "177/177 [==============================] - 0s 151us/step - loss: 0.1155 - accuracy: 0.9605 - val_loss: 3.1479 - val_accuracy: 0.5395\n",
      "Epoch 821/1000\n",
      "177/177 [==============================] - 0s 177us/step - loss: 0.0875 - accuracy: 0.9605 - val_loss: 3.0787 - val_accuracy: 0.5658\n",
      "Epoch 822/1000\n",
      "177/177 [==============================] - 0s 191us/step - loss: 0.1156 - accuracy: 0.9492 - val_loss: 3.1397 - val_accuracy: 0.5526\n",
      "Epoch 823/1000\n",
      "177/177 [==============================] - 0s 162us/step - loss: 0.3153 - accuracy: 0.9435 - val_loss: 3.1549 - val_accuracy: 0.5263\n",
      "Epoch 824/1000\n",
      "177/177 [==============================] - 0s 200us/step - loss: 0.0936 - accuracy: 0.9605 - val_loss: 3.1251 - val_accuracy: 0.5658\n",
      "Epoch 825/1000\n",
      "177/177 [==============================] - 0s 165us/step - loss: 0.1635 - accuracy: 0.9605 - val_loss: 3.1295 - val_accuracy: 0.5526\n",
      "Epoch 826/1000\n",
      "177/177 [==============================] - 0s 175us/step - loss: 0.0848 - accuracy: 0.9605 - val_loss: 3.0949 - val_accuracy: 0.5526\n",
      "Epoch 827/1000\n",
      "177/177 [==============================] - 0s 225us/step - loss: 0.0605 - accuracy: 0.9718 - val_loss: 3.0963 - val_accuracy: 0.5789\n",
      "Epoch 828/1000\n",
      "177/177 [==============================] - 0s 367us/step - loss: 0.0654 - accuracy: 0.9661 - val_loss: 3.0605 - val_accuracy: 0.5789\n",
      "Epoch 829/1000\n",
      "177/177 [==============================] - 0s 292us/step - loss: 0.0746 - accuracy: 0.9718 - val_loss: 3.1344 - val_accuracy: 0.5658\n",
      "Epoch 830/1000\n",
      "177/177 [==============================] - 0s 318us/step - loss: 0.0540 - accuracy: 0.9718 - val_loss: 3.1636 - val_accuracy: 0.5658\n",
      "Epoch 831/1000\n",
      "177/177 [==============================] - 0s 344us/step - loss: 0.0934 - accuracy: 0.9718 - val_loss: 3.2010 - val_accuracy: 0.5263\n",
      "Epoch 832/1000\n",
      "177/177 [==============================] - 0s 353us/step - loss: 0.0611 - accuracy: 0.9718 - val_loss: 3.1960 - val_accuracy: 0.5263\n",
      "Epoch 833/1000\n",
      "177/177 [==============================] - 0s 236us/step - loss: 0.0847 - accuracy: 0.9661 - val_loss: 3.1593 - val_accuracy: 0.5526\n",
      "Epoch 834/1000\n",
      "177/177 [==============================] - 0s 249us/step - loss: 0.1071 - accuracy: 0.9661 - val_loss: 3.1800 - val_accuracy: 0.5263\n",
      "Epoch 835/1000\n",
      "177/177 [==============================] - 0s 219us/step - loss: 0.0564 - accuracy: 0.9774 - val_loss: 3.1342 - val_accuracy: 0.5658\n",
      "Epoch 836/1000\n",
      "177/177 [==============================] - 0s 184us/step - loss: 0.1090 - accuracy: 0.9661 - val_loss: 3.2212 - val_accuracy: 0.5263\n",
      "Epoch 837/1000\n",
      "177/177 [==============================] - 0s 167us/step - loss: 0.1430 - accuracy: 0.9718 - val_loss: 3.2277 - val_accuracy: 0.5132\n",
      "Epoch 838/1000\n",
      "177/177 [==============================] - 0s 204us/step - loss: 0.0580 - accuracy: 0.9661 - val_loss: 3.2224 - val_accuracy: 0.5395\n",
      "Epoch 839/1000\n",
      "177/177 [==============================] - 0s 159us/step - loss: 0.0893 - accuracy: 0.9661 - val_loss: 3.2022 - val_accuracy: 0.5526\n",
      "Epoch 840/1000\n",
      "177/177 [==============================] - 0s 153us/step - loss: 0.0753 - accuracy: 0.9661 - val_loss: 3.1997 - val_accuracy: 0.5263\n",
      "Epoch 841/1000\n",
      "177/177 [==============================] - 0s 161us/step - loss: 0.0536 - accuracy: 0.9718 - val_loss: 3.1584 - val_accuracy: 0.5395\n",
      "Epoch 842/1000\n",
      "177/177 [==============================] - 0s 147us/step - loss: 0.0534 - accuracy: 0.9774 - val_loss: 3.1971 - val_accuracy: 0.5395\n",
      "Epoch 843/1000\n",
      "177/177 [==============================] - 0s 157us/step - loss: 0.0674 - accuracy: 0.9661 - val_loss: 3.3004 - val_accuracy: 0.5132\n",
      "Epoch 844/1000\n",
      "177/177 [==============================] - 0s 129us/step - loss: 0.1371 - accuracy: 0.9661 - val_loss: 3.2563 - val_accuracy: 0.5132\n",
      "Epoch 845/1000\n",
      "177/177 [==============================] - 0s 159us/step - loss: 0.1016 - accuracy: 0.9548 - val_loss: 3.2016 - val_accuracy: 0.5263\n",
      "Epoch 846/1000\n",
      "177/177 [==============================] - 0s 185us/step - loss: 0.1909 - accuracy: 0.9322 - val_loss: 3.3606 - val_accuracy: 0.5263\n",
      "Epoch 847/1000\n",
      "177/177 [==============================] - 0s 139us/step - loss: 0.2612 - accuracy: 0.9548 - val_loss: 3.3532 - val_accuracy: 0.5263\n",
      "Epoch 848/1000\n",
      "177/177 [==============================] - 0s 148us/step - loss: 0.1507 - accuracy: 0.9605 - val_loss: 3.2241 - val_accuracy: 0.5526\n",
      "Epoch 849/1000\n",
      "177/177 [==============================] - 0s 176us/step - loss: 0.0708 - accuracy: 0.9661 - val_loss: 2.9969 - val_accuracy: 0.5263\n",
      "Epoch 850/1000\n",
      "177/177 [==============================] - 0s 140us/step - loss: 0.1764 - accuracy: 0.9661 - val_loss: 3.0491 - val_accuracy: 0.5658\n",
      "Epoch 851/1000\n",
      "177/177 [==============================] - 0s 149us/step - loss: 0.2248 - accuracy: 0.9548 - val_loss: 3.0598 - val_accuracy: 0.5263\n",
      "Epoch 852/1000\n",
      "177/177 [==============================] - 0s 171us/step - loss: 0.1693 - accuracy: 0.9718 - val_loss: 3.1783 - val_accuracy: 0.5000\n",
      "Epoch 853/1000\n",
      "177/177 [==============================] - 0s 154us/step - loss: 0.0831 - accuracy: 0.9661 - val_loss: 3.1136 - val_accuracy: 0.5395\n",
      "Epoch 854/1000\n",
      "177/177 [==============================] - 0s 205us/step - loss: 0.1587 - accuracy: 0.9435 - val_loss: 3.1306 - val_accuracy: 0.5395\n",
      "Epoch 855/1000\n",
      "177/177 [==============================] - 0s 154us/step - loss: 0.1062 - accuracy: 0.9718 - val_loss: 3.1685 - val_accuracy: 0.5000\n",
      "Epoch 856/1000\n",
      "177/177 [==============================] - 0s 155us/step - loss: 0.0503 - accuracy: 0.9718 - val_loss: 3.1488 - val_accuracy: 0.5395\n",
      "Epoch 857/1000\n",
      "177/177 [==============================] - 0s 203us/step - loss: 0.0514 - accuracy: 0.9718 - val_loss: 3.2146 - val_accuracy: 0.5132\n",
      "Epoch 858/1000\n",
      "177/177 [==============================] - 0s 165us/step - loss: 0.0871 - accuracy: 0.9605 - val_loss: 3.1714 - val_accuracy: 0.5526\n",
      "Epoch 859/1000\n",
      "177/177 [==============================] - 0s 197us/step - loss: 0.0499 - accuracy: 0.9718 - val_loss: 3.2479 - val_accuracy: 0.5263\n",
      "Epoch 860/1000\n",
      "177/177 [==============================] - 0s 154us/step - loss: 0.1107 - accuracy: 0.9718 - val_loss: 3.2452 - val_accuracy: 0.5000\n",
      "Epoch 861/1000\n",
      "177/177 [==============================] - 0s 156us/step - loss: 0.1421 - accuracy: 0.9266 - val_loss: 3.1610 - val_accuracy: 0.5263\n",
      "Epoch 862/1000\n",
      "177/177 [==============================] - 0s 180us/step - loss: 0.1029 - accuracy: 0.9492 - val_loss: 3.3235 - val_accuracy: 0.4868\n",
      "Epoch 863/1000\n",
      "177/177 [==============================] - 0s 148us/step - loss: 0.2008 - accuracy: 0.9661 - val_loss: 3.3804 - val_accuracy: 0.4868\n",
      "Epoch 864/1000\n",
      "177/177 [==============================] - 0s 150us/step - loss: 0.1640 - accuracy: 0.9605 - val_loss: 3.2324 - val_accuracy: 0.5395\n",
      "Epoch 865/1000\n",
      "177/177 [==============================] - 0s 169us/step - loss: 0.0527 - accuracy: 0.9774 - val_loss: 3.2529 - val_accuracy: 0.5000\n",
      "Epoch 866/1000\n",
      "177/177 [==============================] - 0s 148us/step - loss: 0.1113 - accuracy: 0.9718 - val_loss: 3.2408 - val_accuracy: 0.5263\n",
      "Epoch 867/1000\n",
      "177/177 [==============================] - 0s 149us/step - loss: 0.0630 - accuracy: 0.9661 - val_loss: 3.2588 - val_accuracy: 0.5132\n",
      "Epoch 868/1000\n",
      "177/177 [==============================] - 0s 157us/step - loss: 0.0844 - accuracy: 0.9718 - val_loss: 3.1757 - val_accuracy: 0.5263\n",
      "Epoch 869/1000\n",
      "177/177 [==============================] - 0s 134us/step - loss: 0.1091 - accuracy: 0.9661 - val_loss: 3.2067 - val_accuracy: 0.5132\n",
      "Epoch 870/1000\n",
      "177/177 [==============================] - 0s 184us/step - loss: 0.1394 - accuracy: 0.9661 - val_loss: 3.2674 - val_accuracy: 0.5000\n",
      "Epoch 871/1000\n",
      "177/177 [==============================] - 0s 155us/step - loss: 0.0475 - accuracy: 0.9774 - val_loss: 3.1902 - val_accuracy: 0.5395\n",
      "Epoch 872/1000\n",
      "177/177 [==============================] - 0s 151us/step - loss: 0.0791 - accuracy: 0.9661 - val_loss: 3.2608 - val_accuracy: 0.5132\n",
      "Epoch 873/1000\n",
      "177/177 [==============================] - 0s 184us/step - loss: 0.0959 - accuracy: 0.9661 - val_loss: 3.2581 - val_accuracy: 0.5395\n",
      "Epoch 874/1000\n",
      "177/177 [==============================] - 0s 146us/step - loss: 0.0490 - accuracy: 0.9774 - val_loss: 3.2293 - val_accuracy: 0.5395\n",
      "Epoch 875/1000\n",
      "177/177 [==============================] - 0s 144us/step - loss: 0.0519 - accuracy: 0.9774 - val_loss: 3.1846 - val_accuracy: 0.5395\n",
      "Epoch 876/1000\n",
      "177/177 [==============================] - 0s 172us/step - loss: 0.0950 - accuracy: 0.9605 - val_loss: 3.1532 - val_accuracy: 0.5526\n",
      "Epoch 877/1000\n",
      "177/177 [==============================] - 0s 141us/step - loss: 0.0459 - accuracy: 0.9774 - val_loss: 3.3089 - val_accuracy: 0.5000\n",
      "Epoch 878/1000\n",
      "177/177 [==============================] - 0s 150us/step - loss: 0.1441 - accuracy: 0.9661 - val_loss: 3.2236 - val_accuracy: 0.5395\n",
      "Epoch 879/1000\n",
      "177/177 [==============================] - 0s 167us/step - loss: 0.0746 - accuracy: 0.9661 - val_loss: 3.1796 - val_accuracy: 0.5526\n",
      "Epoch 880/1000\n",
      "177/177 [==============================] - 0s 146us/step - loss: 0.1224 - accuracy: 0.9661 - val_loss: 3.2451 - val_accuracy: 0.5132\n",
      "Epoch 881/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177/177 [==============================] - 0s 154us/step - loss: 0.0686 - accuracy: 0.9661 - val_loss: 3.1948 - val_accuracy: 0.5395\n",
      "Epoch 882/1000\n",
      "177/177 [==============================] - 0s 146us/step - loss: 0.1132 - accuracy: 0.9661 - val_loss: 3.2311 - val_accuracy: 0.5132\n",
      "Epoch 883/1000\n",
      "177/177 [==============================] - 0s 137us/step - loss: 0.0475 - accuracy: 0.9774 - val_loss: 3.1568 - val_accuracy: 0.5395\n",
      "Epoch 884/1000\n",
      "177/177 [==============================] - 0s 180us/step - loss: 0.0766 - accuracy: 0.9605 - val_loss: 3.1689 - val_accuracy: 0.5132\n",
      "Epoch 885/1000\n",
      "177/177 [==============================] - 0s 164us/step - loss: 0.1420 - accuracy: 0.9718 - val_loss: 3.2557 - val_accuracy: 0.5000\n",
      "Epoch 886/1000\n",
      "177/177 [==============================] - 0s 152us/step - loss: 0.1308 - accuracy: 0.9661 - val_loss: 3.2132 - val_accuracy: 0.5395\n",
      "Epoch 887/1000\n",
      "177/177 [==============================] - 0s 203us/step - loss: 0.1231 - accuracy: 0.9605 - val_loss: 3.2445 - val_accuracy: 0.5132\n",
      "Epoch 888/1000\n",
      "177/177 [==============================] - 0s 145us/step - loss: 0.0481 - accuracy: 0.9718 - val_loss: 3.2225 - val_accuracy: 0.5395\n",
      "Epoch 889/1000\n",
      "177/177 [==============================] - 0s 146us/step - loss: 0.0822 - accuracy: 0.9661 - val_loss: 3.2484 - val_accuracy: 0.5132\n",
      "Epoch 890/1000\n",
      "177/177 [==============================] - 0s 173us/step - loss: 0.1110 - accuracy: 0.9661 - val_loss: 3.2157 - val_accuracy: 0.5395\n",
      "Epoch 891/1000\n",
      "177/177 [==============================] - 0s 147us/step - loss: 0.0759 - accuracy: 0.9774 - val_loss: 3.1979 - val_accuracy: 0.5395\n",
      "Epoch 892/1000\n",
      "177/177 [==============================] - 0s 150us/step - loss: 0.1133 - accuracy: 0.9718 - val_loss: 3.4863 - val_accuracy: 0.4868\n",
      "Epoch 893/1000\n",
      "177/177 [==============================] - 0s 160us/step - loss: 0.1844 - accuracy: 0.9661 - val_loss: 3.4640 - val_accuracy: 0.5132\n",
      "Epoch 894/1000\n",
      "177/177 [==============================] - 0s 153us/step - loss: 0.0690 - accuracy: 0.9774 - val_loss: 3.3773 - val_accuracy: 0.5395\n",
      "Epoch 895/1000\n",
      "177/177 [==============================] - 0s 177us/step - loss: 0.0877 - accuracy: 0.9661 - val_loss: 3.6077 - val_accuracy: 0.5000\n",
      "Epoch 896/1000\n",
      "177/177 [==============================] - 0s 139us/step - loss: 1.8931 - accuracy: 0.8814 - val_loss: 7.1382 - val_accuracy: 0.5000\n",
      "Epoch 897/1000\n",
      "177/177 [==============================] - 0s 147us/step - loss: 3.2307 - accuracy: 0.8588 - val_loss: 7.2330 - val_accuracy: 0.4737\n",
      "Epoch 898/1000\n",
      "177/177 [==============================] - 0s 171us/step - loss: 2.7817 - accuracy: 0.8531 - val_loss: 6.0876 - val_accuracy: 0.4868\n",
      "Epoch 899/1000\n",
      "177/177 [==============================] - 0s 140us/step - loss: 2.0232 - accuracy: 0.9209 - val_loss: 4.6305 - val_accuracy: 0.4737\n",
      "Epoch 900/1000\n",
      "177/177 [==============================] - 0s 145us/step - loss: 1.4119 - accuracy: 0.9548 - val_loss: 3.6820 - val_accuracy: 0.5132\n",
      "Epoch 901/1000\n",
      "177/177 [==============================] - 0s 183us/step - loss: 0.7923 - accuracy: 0.9379 - val_loss: 3.1861 - val_accuracy: 0.5000\n",
      "Epoch 902/1000\n",
      "177/177 [==============================] - 0s 143us/step - loss: 0.4679 - accuracy: 0.9548 - val_loss: 2.9883 - val_accuracy: 0.5395\n",
      "Epoch 903/1000\n",
      "177/177 [==============================] - 0s 146us/step - loss: 0.1475 - accuracy: 0.9605 - val_loss: 2.8545 - val_accuracy: 0.5132\n",
      "Epoch 904/1000\n",
      "177/177 [==============================] - 0s 168us/step - loss: 0.2124 - accuracy: 0.9435 - val_loss: 2.8361 - val_accuracy: 0.5395\n",
      "Epoch 905/1000\n",
      "177/177 [==============================] - 0s 140us/step - loss: 0.0884 - accuracy: 0.9605 - val_loss: 3.1913 - val_accuracy: 0.5395\n",
      "Epoch 906/1000\n",
      "177/177 [==============================] - 0s 146us/step - loss: 0.3875 - accuracy: 0.9435 - val_loss: 2.9737 - val_accuracy: 0.5263\n",
      "Epoch 907/1000\n",
      "177/177 [==============================] - 0s 166us/step - loss: 0.3315 - accuracy: 0.9605 - val_loss: 3.1275 - val_accuracy: 0.5395\n",
      "Epoch 908/1000\n",
      "177/177 [==============================] - 0s 137us/step - loss: 0.4327 - accuracy: 0.9379 - val_loss: 2.9850 - val_accuracy: 0.5526\n",
      "Epoch 909/1000\n",
      "177/177 [==============================] - 0s 153us/step - loss: 0.1590 - accuracy: 0.9492 - val_loss: 2.9704 - val_accuracy: 0.5526\n",
      "Epoch 910/1000\n",
      "177/177 [==============================] - 0s 173us/step - loss: 0.1167 - accuracy: 0.9661 - val_loss: 2.9451 - val_accuracy: 0.5526\n",
      "Epoch 911/1000\n",
      "177/177 [==============================] - 0s 143us/step - loss: 0.1588 - accuracy: 0.9266 - val_loss: 2.8932 - val_accuracy: 0.5658\n",
      "Epoch 912/1000\n",
      "177/177 [==============================] - 0s 164us/step - loss: 0.1862 - accuracy: 0.9605 - val_loss: 2.9682 - val_accuracy: 0.5395\n",
      "Epoch 913/1000\n",
      "177/177 [==============================] - 0s 213us/step - loss: 0.0756 - accuracy: 0.9661 - val_loss: 2.9908 - val_accuracy: 0.5263\n",
      "Epoch 914/1000\n",
      "177/177 [==============================] - 0s 174us/step - loss: 0.1173 - accuracy: 0.9718 - val_loss: 3.0293 - val_accuracy: 0.5526\n",
      "Epoch 915/1000\n",
      "177/177 [==============================] - 0s 166us/step - loss: 0.0779 - accuracy: 0.9661 - val_loss: 2.9996 - val_accuracy: 0.5526\n",
      "Epoch 916/1000\n",
      "177/177 [==============================] - 0s 141us/step - loss: 0.1218 - accuracy: 0.9661 - val_loss: 2.9995 - val_accuracy: 0.5395\n",
      "Epoch 917/1000\n",
      "177/177 [==============================] - 0s 148us/step - loss: 0.0504 - accuracy: 0.9774 - val_loss: 3.1199 - val_accuracy: 0.5526\n",
      "Epoch 918/1000\n",
      "177/177 [==============================] - 0s 162us/step - loss: 0.0626 - accuracy: 0.9661 - val_loss: 3.1774 - val_accuracy: 0.5789\n",
      "Epoch 919/1000\n",
      "177/177 [==============================] - 0s 197us/step - loss: 0.1194 - accuracy: 0.9661 - val_loss: 3.2363 - val_accuracy: 0.5526\n",
      "Epoch 920/1000\n",
      "177/177 [==============================] - 0s 381us/step - loss: 0.1295 - accuracy: 0.9718 - val_loss: 3.2138 - val_accuracy: 0.5395\n",
      "Epoch 921/1000\n",
      "177/177 [==============================] - 0s 152us/step - loss: 0.1620 - accuracy: 0.9774 - val_loss: 3.1210 - val_accuracy: 0.5395\n",
      "Epoch 922/1000\n",
      "177/177 [==============================] - 0s 177us/step - loss: 0.0531 - accuracy: 0.9831 - val_loss: 3.0966 - val_accuracy: 0.5526\n",
      "Epoch 923/1000\n",
      "177/177 [==============================] - 0s 154us/step - loss: 0.0640 - accuracy: 0.9605 - val_loss: 3.1398 - val_accuracy: 0.5395\n",
      "Epoch 924/1000\n",
      "177/177 [==============================] - 0s 185us/step - loss: 0.1726 - accuracy: 0.9605 - val_loss: 3.0841 - val_accuracy: 0.5658\n",
      "Epoch 925/1000\n",
      "177/177 [==============================] - 0s 152us/step - loss: 0.1152 - accuracy: 0.9661 - val_loss: 3.0944 - val_accuracy: 0.5526\n",
      "Epoch 926/1000\n",
      "177/177 [==============================] - 0s 145us/step - loss: 0.1100 - accuracy: 0.9661 - val_loss: 3.0412 - val_accuracy: 0.5526\n",
      "Epoch 927/1000\n",
      "177/177 [==============================] - 0s 166us/step - loss: 0.0515 - accuracy: 0.9718 - val_loss: 3.0233 - val_accuracy: 0.5395\n",
      "Epoch 928/1000\n",
      "177/177 [==============================] - 0s 129us/step - loss: 0.0481 - accuracy: 0.9774 - val_loss: 3.0373 - val_accuracy: 0.5658\n",
      "Epoch 929/1000\n",
      "177/177 [==============================] - 0s 128us/step - loss: 0.0473 - accuracy: 0.9718 - val_loss: 3.0339 - val_accuracy: 0.5658\n",
      "Epoch 930/1000\n",
      "177/177 [==============================] - 0s 173us/step - loss: 0.0474 - accuracy: 0.9774 - val_loss: 3.0469 - val_accuracy: 0.5658\n",
      "Epoch 931/1000\n",
      "177/177 [==============================] - 0s 140us/step - loss: 0.0489 - accuracy: 0.9718 - val_loss: 3.0569 - val_accuracy: 0.5526\n",
      "Epoch 932/1000\n",
      "177/177 [==============================] - 0s 159us/step - loss: 0.0512 - accuracy: 0.9661 - val_loss: 3.0706 - val_accuracy: 0.5658\n",
      "Epoch 933/1000\n",
      "177/177 [==============================] - 0s 154us/step - loss: 0.0781 - accuracy: 0.9718 - val_loss: 3.0508 - val_accuracy: 0.5658\n",
      "Epoch 934/1000\n",
      "177/177 [==============================] - 0s 137us/step - loss: 0.1234 - accuracy: 0.9718 - val_loss: 3.0840 - val_accuracy: 0.5526\n",
      "Epoch 935/1000\n",
      "177/177 [==============================] - 0s 175us/step - loss: 0.1261 - accuracy: 0.9661 - val_loss: 3.1319 - val_accuracy: 0.5526\n",
      "Epoch 936/1000\n",
      "177/177 [==============================] - 0s 157us/step - loss: 0.0492 - accuracy: 0.9718 - val_loss: 3.0900 - val_accuracy: 0.5526\n",
      "Epoch 937/1000\n",
      "177/177 [==============================] - 0s 159us/step - loss: 0.0474 - accuracy: 0.9774 - val_loss: 3.0824 - val_accuracy: 0.5526\n",
      "Epoch 938/1000\n",
      "177/177 [==============================] - 0s 172us/step - loss: 0.0489 - accuracy: 0.9718 - val_loss: 3.0415 - val_accuracy: 0.5526\n",
      "Epoch 939/1000\n",
      "177/177 [==============================] - 0s 141us/step - loss: 0.0663 - accuracy: 0.9661 - val_loss: 3.0824 - val_accuracy: 0.5395\n",
      "Epoch 940/1000\n",
      "177/177 [==============================] - 0s 141us/step - loss: 0.0879 - accuracy: 0.9661 - val_loss: 3.1182 - val_accuracy: 0.5395\n",
      "Epoch 941/1000\n",
      "177/177 [==============================] - 0s 176us/step - loss: 0.0478 - accuracy: 0.9718 - val_loss: 3.1156 - val_accuracy: 0.5395\n",
      "Epoch 942/1000\n",
      "177/177 [==============================] - 0s 140us/step - loss: 0.0837 - accuracy: 0.9661 - val_loss: 3.1175 - val_accuracy: 0.5789\n",
      "Epoch 943/1000\n",
      "177/177 [==============================] - 0s 144us/step - loss: 0.0602 - accuracy: 0.9661 - val_loss: 3.1503 - val_accuracy: 0.5526\n",
      "Epoch 944/1000\n",
      "177/177 [==============================] - 0s 186us/step - loss: 0.1525 - accuracy: 0.9605 - val_loss: 3.1827 - val_accuracy: 0.5263\n",
      "Epoch 945/1000\n",
      "177/177 [==============================] - 0s 146us/step - loss: 0.0449 - accuracy: 0.9774 - val_loss: 3.1187 - val_accuracy: 0.5395\n",
      "Epoch 946/1000\n",
      "177/177 [==============================] - 0s 146us/step - loss: 0.0633 - accuracy: 0.9718 - val_loss: 3.2170 - val_accuracy: 0.5263\n",
      "Epoch 947/1000\n",
      "177/177 [==============================] - 0s 179us/step - loss: 0.1636 - accuracy: 0.9718 - val_loss: 3.1731 - val_accuracy: 0.5526\n",
      "Epoch 948/1000\n",
      "177/177 [==============================] - 0s 141us/step - loss: 0.1493 - accuracy: 0.9435 - val_loss: 3.1856 - val_accuracy: 0.5395\n",
      "Epoch 949/1000\n",
      "177/177 [==============================] - 0s 168us/step - loss: 0.2089 - accuracy: 0.9605 - val_loss: 3.2549 - val_accuracy: 0.5132\n",
      "Epoch 950/1000\n",
      "177/177 [==============================] - 0s 159us/step - loss: 0.1067 - accuracy: 0.9718 - val_loss: 3.1300 - val_accuracy: 0.5395\n",
      "Epoch 951/1000\n",
      "177/177 [==============================] - 0s 141us/step - loss: 0.0960 - accuracy: 0.9718 - val_loss: 3.0793 - val_accuracy: 0.5526\n",
      "Epoch 952/1000\n",
      "177/177 [==============================] - 0s 153us/step - loss: 0.0932 - accuracy: 0.9661 - val_loss: 3.1177 - val_accuracy: 0.5395\n",
      "Epoch 953/1000\n",
      "177/177 [==============================] - 0s 159us/step - loss: 0.0695 - accuracy: 0.9718 - val_loss: 3.0897 - val_accuracy: 0.5526\n",
      "Epoch 954/1000\n",
      "177/177 [==============================] - 0s 157us/step - loss: 0.0628 - accuracy: 0.9661 - val_loss: 3.1856 - val_accuracy: 0.5395\n",
      "Epoch 955/1000\n",
      "177/177 [==============================] - 0s 172us/step - loss: 0.0619 - accuracy: 0.9661 - val_loss: 3.2103 - val_accuracy: 0.5263\n",
      "Epoch 956/1000\n",
      "177/177 [==============================] - 0s 135us/step - loss: 0.1533 - accuracy: 0.9661 - val_loss: 3.1924 - val_accuracy: 0.5263\n",
      "Epoch 957/1000\n",
      "177/177 [==============================] - 0s 137us/step - loss: 0.0469 - accuracy: 0.9718 - val_loss: 3.1893 - val_accuracy: 0.5526\n",
      "Epoch 958/1000\n",
      "177/177 [==============================] - 0s 178us/step - loss: 0.0502 - accuracy: 0.9718 - val_loss: 3.1521 - val_accuracy: 0.5526\n",
      "Epoch 959/1000\n",
      "177/177 [==============================] - 0s 141us/step - loss: 0.1082 - accuracy: 0.9661 - val_loss: 3.1883 - val_accuracy: 0.5526\n",
      "Epoch 960/1000\n",
      "177/177 [==============================] - 0s 139us/step - loss: 0.0489 - accuracy: 0.9661 - val_loss: 3.1094 - val_accuracy: 0.5658\n",
      "Epoch 961/1000\n",
      "177/177 [==============================] - 0s 188us/step - loss: 0.0663 - accuracy: 0.9661 - val_loss: 3.1697 - val_accuracy: 0.5263\n",
      "Epoch 962/1000\n",
      "177/177 [==============================] - 0s 148us/step - loss: 0.0989 - accuracy: 0.9605 - val_loss: 3.1198 - val_accuracy: 0.5263\n",
      "Epoch 963/1000\n",
      "177/177 [==============================] - 0s 148us/step - loss: 0.0481 - accuracy: 0.9718 - val_loss: 3.1367 - val_accuracy: 0.5263\n",
      "Epoch 964/1000\n",
      "177/177 [==============================] - 0s 188us/step - loss: 0.0953 - accuracy: 0.9661 - val_loss: 3.0404 - val_accuracy: 0.5395\n",
      "Epoch 965/1000\n",
      "177/177 [==============================] - 0s 140us/step - loss: 0.0563 - accuracy: 0.9774 - val_loss: 3.0601 - val_accuracy: 0.5526\n",
      "Epoch 966/1000\n",
      "177/177 [==============================] - 0s 150us/step - loss: 0.0686 - accuracy: 0.9661 - val_loss: 3.1046 - val_accuracy: 0.5395\n",
      "Epoch 967/1000\n",
      "177/177 [==============================] - 0s 156us/step - loss: 0.0944 - accuracy: 0.9718 - val_loss: 3.2261 - val_accuracy: 0.5395\n",
      "Epoch 968/1000\n",
      "177/177 [==============================] - 0s 138us/step - loss: 0.3331 - accuracy: 0.9492 - val_loss: 3.1563 - val_accuracy: 0.5132\n",
      "Epoch 969/1000\n",
      "177/177 [==============================] - 0s 156us/step - loss: 0.5320 - accuracy: 0.9266 - val_loss: 3.1790 - val_accuracy: 0.5132\n",
      "Epoch 970/1000\n",
      "177/177 [==============================] - 0s 153us/step - loss: 0.2419 - accuracy: 0.9661 - val_loss: 3.3196 - val_accuracy: 0.5000\n",
      "Epoch 971/1000\n",
      "177/177 [==============================] - 0s 142us/step - loss: 0.1180 - accuracy: 0.9718 - val_loss: 3.2148 - val_accuracy: 0.5263\n",
      "Epoch 972/1000\n",
      "177/177 [==============================] - 0s 178us/step - loss: 0.1266 - accuracy: 0.9774 - val_loss: 3.1421 - val_accuracy: 0.5263\n",
      "Epoch 973/1000\n",
      "177/177 [==============================] - 0s 138us/step - loss: 0.0655 - accuracy: 0.9718 - val_loss: 3.1519 - val_accuracy: 0.5395\n",
      "Epoch 974/1000\n",
      "177/177 [==============================] - 0s 147us/step - loss: 0.0444 - accuracy: 0.9774 - val_loss: 3.1717 - val_accuracy: 0.5132\n",
      "Epoch 975/1000\n",
      "177/177 [==============================] - 0s 180us/step - loss: 0.0506 - accuracy: 0.9718 - val_loss: 3.1773 - val_accuracy: 0.5263\n",
      "Epoch 976/1000\n",
      "177/177 [==============================] - 0s 144us/step - loss: 0.0784 - accuracy: 0.9718 - val_loss: 3.1832 - val_accuracy: 0.5395\n",
      "Epoch 977/1000\n",
      "177/177 [==============================] - 0s 132us/step - loss: 0.1171 - accuracy: 0.9718 - val_loss: 3.2458 - val_accuracy: 0.4868\n",
      "Epoch 978/1000\n",
      "177/177 [==============================] - 0s 172us/step - loss: 0.1670 - accuracy: 0.9718 - val_loss: 3.3096 - val_accuracy: 0.4868\n",
      "Epoch 979/1000\n",
      "177/177 [==============================] - 0s 137us/step - loss: 0.1225 - accuracy: 0.9661 - val_loss: 3.2467 - val_accuracy: 0.5263\n",
      "Epoch 980/1000\n",
      "177/177 [==============================] - 0s 146us/step - loss: 0.2982 - accuracy: 0.9379 - val_loss: 3.4811 - val_accuracy: 0.5132\n",
      "Epoch 981/1000\n",
      "177/177 [==============================] - 0s 180us/step - loss: 0.4949 - accuracy: 0.9435 - val_loss: 3.5643 - val_accuracy: 0.5000\n",
      "Epoch 982/1000\n",
      "177/177 [==============================] - 0s 142us/step - loss: 0.1008 - accuracy: 0.9718 - val_loss: 3.3163 - val_accuracy: 0.5263\n",
      "Epoch 983/1000\n",
      "177/177 [==============================] - 0s 148us/step - loss: 0.1166 - accuracy: 0.9661 - val_loss: 3.2357 - val_accuracy: 0.5132\n",
      "Epoch 984/1000\n",
      "177/177 [==============================] - 0s 277us/step - loss: 0.1165 - accuracy: 0.9322 - val_loss: 3.0912 - val_accuracy: 0.5395\n",
      "Epoch 985/1000\n",
      "177/177 [==============================] - 0s 184us/step - loss: 0.2452 - accuracy: 0.9661 - val_loss: 3.2324 - val_accuracy: 0.5132\n",
      "Epoch 986/1000\n",
      "177/177 [==============================] - 0s 186us/step - loss: 0.1615 - accuracy: 0.9661 - val_loss: 3.2477 - val_accuracy: 0.5263\n",
      "Epoch 987/1000\n",
      "177/177 [==============================] - 0s 144us/step - loss: 0.0501 - accuracy: 0.9718 - val_loss: 3.2710 - val_accuracy: 0.5132\n",
      "Epoch 988/1000\n",
      "177/177 [==============================] - 0s 161us/step - loss: 0.1176 - accuracy: 0.9605 - val_loss: 3.2211 - val_accuracy: 0.5395\n",
      "Epoch 989/1000\n",
      "177/177 [==============================] - 0s 149us/step - loss: 0.0558 - accuracy: 0.9605 - val_loss: 3.2588 - val_accuracy: 0.5263\n",
      "Epoch 990/1000\n",
      "177/177 [==============================] - 0s 153us/step - loss: 0.1148 - accuracy: 0.9605 - val_loss: 3.3278 - val_accuracy: 0.5395\n",
      "Epoch 991/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177/177 [==============================] - 0s 179us/step - loss: 0.0560 - accuracy: 0.9718 - val_loss: 3.3077 - val_accuracy: 0.5132\n",
      "Epoch 992/1000\n",
      "177/177 [==============================] - 0s 143us/step - loss: 0.0531 - accuracy: 0.9661 - val_loss: 3.3043 - val_accuracy: 0.5395\n",
      "Epoch 993/1000\n",
      "177/177 [==============================] - 0s 151us/step - loss: 0.1384 - accuracy: 0.9605 - val_loss: 3.2311 - val_accuracy: 0.5526\n",
      "Epoch 994/1000\n",
      "177/177 [==============================] - 0s 167us/step - loss: 0.0602 - accuracy: 0.9661 - val_loss: 3.2882 - val_accuracy: 0.5395\n",
      "Epoch 995/1000\n",
      "177/177 [==============================] - 0s 142us/step - loss: 0.1372 - accuracy: 0.9605 - val_loss: 3.3018 - val_accuracy: 0.5263\n",
      "Epoch 996/1000\n",
      "177/177 [==============================] - 0s 143us/step - loss: 0.0731 - accuracy: 0.9661 - val_loss: 3.2685 - val_accuracy: 0.5132\n",
      "Epoch 997/1000\n",
      "177/177 [==============================] - 0s 181us/step - loss: 0.1528 - accuracy: 0.9661 - val_loss: 3.3994 - val_accuracy: 0.5132\n",
      "Epoch 998/1000\n",
      "177/177 [==============================] - 0s 152us/step - loss: 0.2477 - accuracy: 0.9379 - val_loss: 3.2478 - val_accuracy: 0.5395\n",
      "Epoch 999/1000\n",
      "177/177 [==============================] - 0s 146us/step - loss: 0.0520 - accuracy: 0.9774 - val_loss: 3.2863 - val_accuracy: 0.5263\n",
      "Epoch 1000/1000\n",
      "177/177 [==============================] - 0s 173us/step - loss: 0.1010 - accuracy: 0.9718 - val_loss: 3.3423 - val_accuracy: 0.5395\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a40fa7fd0>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sel2.fit(X_sel_train, y_sel_train,\n",
    "          batch_size=16, epochs=1000,\n",
    "          validation_data=(X_sel_test, y_sel_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 0s 88us/step\n",
      "test accuracy: 57.89%\n"
     ]
    }
   ],
   "source": [
    "acc_test_sel2 = model_sel2.evaluate(X_sel_test, y_sel_test)[1]\n",
    "print('test accuracy: %.2f%%' % (acc_test_sel2*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 2, 2, 1, 1, 1, 1, 2, 2, 1, 1, 2, 2,\n",
       "       2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 1, 2, 2, 1, 0, 2, 0, 0, 2, 1, 2, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 2, 1, 2, 1, 2, 1, 1, 1, 0, 2, 1, 0,\n",
       "       1, 1, 0, 2, 1, 1, 1, 1, 0, 1])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred6 = model_sel2.predict_classes(X_sel_test)\n",
    "pred6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strain</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>NRS169</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>NRS249</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>NRS262</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>SR1746</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>NRS029</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>GA27</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>GA231</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>SR1287</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>506</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>NRS001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     strain  test  pred\n",
       "152  NRS169     1     1\n",
       "210  NRS249     2     1\n",
       "218  NRS262     2     2\n",
       "238  SR1746     1     1\n",
       "113  NRS029     1     1\n",
       "..      ...   ...   ...\n",
       "96     GA27     2     1\n",
       "95    GA231     2     1\n",
       "237  SR1287     0     1\n",
       "14      506     2     0\n",
       "107  NRS001     1     1\n",
       "\n",
       "[76 rows x 3 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat6['pred'] = pred6\n",
    "dat6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba6 = model_sel2.predict_proba(X_sel_test)\n",
    "dat_proba6 = pd.DataFrame(proba6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.419365e-09</td>\n",
       "      <td>0.968961</td>\n",
       "      <td>3.103886e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.290029e-08</td>\n",
       "      <td>0.999955</td>\n",
       "      <td>4.508791e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.233680e-02</td>\n",
       "      <td>0.133059</td>\n",
       "      <td>8.346044e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.945794e-10</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>7.537894e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.306629e-05</td>\n",
       "      <td>0.999977</td>\n",
       "      <td>3.929847e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>3.964591e-03</td>\n",
       "      <td>0.995929</td>\n",
       "      <td>1.068284e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>3.309226e-04</td>\n",
       "      <td>0.999669</td>\n",
       "      <td>6.232397e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>8.445997e-06</td>\n",
       "      <td>0.999992</td>\n",
       "      <td>1.182947e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>6.516150e-01</td>\n",
       "      <td>0.014809</td>\n",
       "      <td>3.335762e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>5.841915e-04</td>\n",
       "      <td>0.999416</td>\n",
       "      <td>6.525528e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0         1             2\n",
       "0   3.419365e-09  0.968961  3.103886e-02\n",
       "1   8.290029e-08  0.999955  4.508791e-05\n",
       "2   3.233680e-02  0.133059  8.346044e-01\n",
       "3   1.945794e-10  0.999999  7.537894e-07\n",
       "4   2.306629e-05  0.999977  3.929847e-08\n",
       "..           ...       ...           ...\n",
       "71  3.964591e-03  0.995929  1.068284e-04\n",
       "72  3.309226e-04  0.999669  6.232397e-10\n",
       "73  8.445997e-06  0.999992  1.182947e-13\n",
       "74  6.516150e-01  0.014809  3.335762e-01\n",
       "75  5.841915e-04  0.999416  6.525528e-08\n",
       "\n",
       "[76 rows x 3 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba6.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba6.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat6.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/6p40pST.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 177 samples, validate on 76 samples\n",
      "Epoch 1/1000\n",
      "177/177 [==============================] - 0s 220us/step - loss: 0.0498 - accuracy: 0.9774 - val_loss: 3.3403 - val_accuracy: 0.5658\n",
      "Epoch 2/1000\n",
      "177/177 [==============================] - 0s 298us/step - loss: 0.0748 - accuracy: 0.9661 - val_loss: 3.2625 - val_accuracy: 0.5921\n",
      "Epoch 3/1000\n",
      "177/177 [==============================] - 0s 237us/step - loss: 0.0803 - accuracy: 0.9661 - val_loss: 3.2721 - val_accuracy: 0.5921\n",
      "Epoch 4/1000\n",
      "177/177 [==============================] - 0s 189us/step - loss: 0.1154 - accuracy: 0.9605 - val_loss: 3.3236 - val_accuracy: 0.5658\n",
      "Epoch 5/1000\n",
      "177/177 [==============================] - 0s 182us/step - loss: 0.0495 - accuracy: 0.9661 - val_loss: 3.3043 - val_accuracy: 0.5921\n",
      "Epoch 6/1000\n",
      "177/177 [==============================] - 0s 175us/step - loss: 0.0489 - accuracy: 0.9661 - val_loss: 3.2807 - val_accuracy: 0.6053\n",
      "Epoch 7/1000\n",
      "177/177 [==============================] - 0s 187us/step - loss: 0.0485 - accuracy: 0.9774 - val_loss: 3.2393 - val_accuracy: 0.5921\n",
      "Epoch 8/1000\n",
      "177/177 [==============================] - 0s 193us/step - loss: 0.3056 - accuracy: 0.9153 - val_loss: 3.3535 - val_accuracy: 0.5921\n",
      "Epoch 9/1000\n",
      "177/177 [==============================] - 0s 184us/step - loss: 0.2239 - accuracy: 0.9548 - val_loss: 3.5001 - val_accuracy: 0.5526\n",
      "Epoch 10/1000\n",
      "177/177 [==============================] - 0s 180us/step - loss: 0.1289 - accuracy: 0.9605 - val_loss: 3.2619 - val_accuracy: 0.6053\n",
      "Epoch 11/1000\n",
      "177/177 [==============================] - 0s 186us/step - loss: 0.2039 - accuracy: 0.9605 - val_loss: 3.2563 - val_accuracy: 0.5395\n",
      "Epoch 12/1000\n",
      "177/177 [==============================] - 0s 176us/step - loss: 0.0874 - accuracy: 0.9605 - val_loss: 3.2260 - val_accuracy: 0.6053\n",
      "Epoch 13/1000\n",
      "177/177 [==============================] - 0s 182us/step - loss: 0.2500 - accuracy: 0.9492 - val_loss: 3.5614 - val_accuracy: 0.5526\n",
      "Epoch 14/1000\n",
      "177/177 [==============================] - 0s 175us/step - loss: 0.1997 - accuracy: 0.9492 - val_loss: 3.5341 - val_accuracy: 0.5658\n",
      "Epoch 15/1000\n",
      "177/177 [==============================] - 0s 210us/step - loss: 0.1300 - accuracy: 0.9718 - val_loss: 3.2287 - val_accuracy: 0.6184\n",
      "Epoch 16/1000\n",
      "177/177 [==============================] - 0s 251us/step - loss: 0.0826 - accuracy: 0.9718 - val_loss: 3.2879 - val_accuracy: 0.5789\n",
      "Epoch 17/1000\n",
      "177/177 [==============================] - 0s 200us/step - loss: 0.0702 - accuracy: 0.9661 - val_loss: 3.2844 - val_accuracy: 0.5921\n",
      "Epoch 18/1000\n",
      "177/177 [==============================] - 0s 204us/step - loss: 0.0502 - accuracy: 0.9774 - val_loss: 3.3294 - val_accuracy: 0.5789\n",
      "Epoch 19/1000\n",
      "177/177 [==============================] - 0s 173us/step - loss: 0.0539 - accuracy: 0.9718 - val_loss: 3.2994 - val_accuracy: 0.6053\n",
      "Epoch 20/1000\n",
      "177/177 [==============================] - 0s 177us/step - loss: 0.1035 - accuracy: 0.9661 - val_loss: 3.3299 - val_accuracy: 0.5921\n",
      "Epoch 21/1000\n",
      "177/177 [==============================] - 0s 175us/step - loss: 0.0551 - accuracy: 0.9661 - val_loss: 3.4104 - val_accuracy: 0.5658\n",
      "Epoch 22/1000\n",
      "177/177 [==============================] - 0s 168us/step - loss: 0.1308 - accuracy: 0.9661 - val_loss: 3.3286 - val_accuracy: 0.5789\n",
      "Epoch 23/1000\n",
      "177/177 [==============================] - 0s 170us/step - loss: 0.1805 - accuracy: 0.9492 - val_loss: 3.3053 - val_accuracy: 0.5789\n",
      "Epoch 24/1000\n",
      "177/177 [==============================] - 0s 153us/step - loss: 0.1189 - accuracy: 0.9605 - val_loss: 3.2717 - val_accuracy: 0.5921\n",
      "Epoch 25/1000\n",
      "177/177 [==============================] - 0s 220us/step - loss: 0.1236 - accuracy: 0.9435 - val_loss: 3.2798 - val_accuracy: 0.5921\n",
      "Epoch 26/1000\n",
      "177/177 [==============================] - 0s 162us/step - loss: 0.0869 - accuracy: 0.9661 - val_loss: 3.4810 - val_accuracy: 0.5526\n",
      "Epoch 27/1000\n",
      "177/177 [==============================] - 0s 200us/step - loss: 0.1565 - accuracy: 0.9435 - val_loss: 3.3154 - val_accuracy: 0.5789\n",
      "Epoch 28/1000\n",
      "177/177 [==============================] - 0s 157us/step - loss: 0.1958 - accuracy: 0.9605 - val_loss: 3.4494 - val_accuracy: 0.5526\n",
      "Epoch 29/1000\n",
      "177/177 [==============================] - 0s 184us/step - loss: 0.1957 - accuracy: 0.9548 - val_loss: 3.2993 - val_accuracy: 0.5789\n",
      "Epoch 30/1000\n",
      "177/177 [==============================] - 0s 226us/step - loss: 0.1900 - accuracy: 0.9492 - val_loss: 3.3538 - val_accuracy: 0.5658\n",
      "Epoch 31/1000\n",
      "177/177 [==============================] - 0s 461us/step - loss: 0.1021 - accuracy: 0.9661 - val_loss: 3.3908 - val_accuracy: 0.5658\n",
      "Epoch 32/1000\n",
      "177/177 [==============================] - 0s 271us/step - loss: 0.1207 - accuracy: 0.9661 - val_loss: 3.2501 - val_accuracy: 0.5658\n",
      "Epoch 33/1000\n",
      "177/177 [==============================] - 0s 377us/step - loss: 0.1009 - accuracy: 0.9605 - val_loss: 3.3833 - val_accuracy: 0.5395\n",
      "Epoch 34/1000\n",
      "177/177 [==============================] - 0s 612us/step - loss: 0.1486 - accuracy: 0.9661 - val_loss: 3.4473 - val_accuracy: 0.5526\n",
      "Epoch 35/1000\n",
      "177/177 [==============================] - 0s 631us/step - loss: 0.3126 - accuracy: 0.9266 - val_loss: 3.3841 - val_accuracy: 0.5789\n",
      "Epoch 36/1000\n",
      "177/177 [==============================] - 0s 526us/step - loss: 0.0872 - accuracy: 0.9605 - val_loss: 3.5869 - val_accuracy: 0.5526\n",
      "Epoch 37/1000\n",
      "177/177 [==============================] - 0s 301us/step - loss: 0.0941 - accuracy: 0.9492 - val_loss: 3.3404 - val_accuracy: 0.5921\n",
      "Epoch 38/1000\n",
      "177/177 [==============================] - 0s 285us/step - loss: 0.1146 - accuracy: 0.9661 - val_loss: 3.4432 - val_accuracy: 0.5789\n",
      "Epoch 39/1000\n",
      "177/177 [==============================] - 0s 209us/step - loss: 0.1007 - accuracy: 0.9661 - val_loss: 3.5030 - val_accuracy: 0.5658\n",
      "Epoch 40/1000\n",
      "177/177 [==============================] - 0s 236us/step - loss: 0.0973 - accuracy: 0.9605 - val_loss: 3.3520 - val_accuracy: 0.5921\n",
      "Epoch 41/1000\n",
      "177/177 [==============================] - 0s 961us/step - loss: 0.1061 - accuracy: 0.9661 - val_loss: 3.5504 - val_accuracy: 0.5526\n",
      "Epoch 42/1000\n",
      "177/177 [==============================] - 0s 246us/step - loss: 0.0861 - accuracy: 0.9605 - val_loss: 3.4161 - val_accuracy: 0.5921\n",
      "Epoch 43/1000\n",
      "177/177 [==============================] - 0s 206us/step - loss: 0.1848 - accuracy: 0.9605 - val_loss: 3.3461 - val_accuracy: 0.5921\n",
      "Epoch 44/1000\n",
      "177/177 [==============================] - 0s 160us/step - loss: 0.0572 - accuracy: 0.9661 - val_loss: 3.4689 - val_accuracy: 0.5526\n",
      "Epoch 45/1000\n",
      "177/177 [==============================] - 0s 184us/step - loss: 0.1496 - accuracy: 0.9605 - val_loss: 3.4758 - val_accuracy: 0.5526\n",
      "Epoch 46/1000\n",
      "177/177 [==============================] - 0s 331us/step - loss: 0.1235 - accuracy: 0.9492 - val_loss: 3.4151 - val_accuracy: 0.5658\n",
      "Epoch 47/1000\n",
      "177/177 [==============================] - 0s 212us/step - loss: 0.1763 - accuracy: 0.9605 - val_loss: 3.5064 - val_accuracy: 0.5658\n",
      "Epoch 48/1000\n",
      "177/177 [==============================] - 0s 283us/step - loss: 1.7599 - accuracy: 0.8701 - val_loss: 7.1219 - val_accuracy: 0.5395\n",
      "Epoch 49/1000\n",
      "177/177 [==============================] - 0s 281us/step - loss: 3.6602 - accuracy: 0.8531 - val_loss: 6.4742 - val_accuracy: 0.5263\n",
      "Epoch 50/1000\n",
      "177/177 [==============================] - 0s 224us/step - loss: 2.3108 - accuracy: 0.8870 - val_loss: 5.0541 - val_accuracy: 0.5263\n",
      "Epoch 51/1000\n",
      "177/177 [==============================] - 0s 251us/step - loss: 1.5348 - accuracy: 0.9379 - val_loss: 3.9082 - val_accuracy: 0.5658\n",
      "Epoch 52/1000\n",
      "177/177 [==============================] - 0s 257us/step - loss: 0.7644 - accuracy: 0.9153 - val_loss: 3.2997 - val_accuracy: 0.6184\n",
      "Epoch 53/1000\n",
      "177/177 [==============================] - 0s 187us/step - loss: 0.5129 - accuracy: 0.8927 - val_loss: 3.0059 - val_accuracy: 0.6184\n",
      "Epoch 54/1000\n",
      "177/177 [==============================] - 0s 215us/step - loss: 0.2626 - accuracy: 0.9322 - val_loss: 3.5934 - val_accuracy: 0.5526\n",
      "Epoch 55/1000\n",
      "177/177 [==============================] - 0s 219us/step - loss: 0.1577 - accuracy: 0.9605 - val_loss: 3.6478 - val_accuracy: 0.5789\n",
      "Epoch 56/1000\n",
      "177/177 [==============================] - 0s 152us/step - loss: 0.1545 - accuracy: 0.9718 - val_loss: 3.7177 - val_accuracy: 0.5789\n",
      "Epoch 57/1000\n",
      "177/177 [==============================] - 0s 160us/step - loss: 0.1071 - accuracy: 0.9661 - val_loss: 3.6224 - val_accuracy: 0.6053\n",
      "Epoch 58/1000\n",
      "177/177 [==============================] - 0s 159us/step - loss: 0.1518 - accuracy: 0.9548 - val_loss: 3.6750 - val_accuracy: 0.5789\n",
      "Epoch 59/1000\n",
      "177/177 [==============================] - 0s 165us/step - loss: 0.1529 - accuracy: 0.9718 - val_loss: 3.4559 - val_accuracy: 0.6184\n",
      "Epoch 60/1000\n",
      "177/177 [==============================] - 0s 199us/step - loss: 0.0829 - accuracy: 0.9718 - val_loss: 3.4992 - val_accuracy: 0.5921\n",
      "Epoch 61/1000\n",
      "177/177 [==============================] - 0s 173us/step - loss: 0.1627 - accuracy: 0.9718 - val_loss: 3.4039 - val_accuracy: 0.6053\n",
      "Epoch 62/1000\n",
      "177/177 [==============================] - 0s 175us/step - loss: 0.0574 - accuracy: 0.9718 - val_loss: 3.3557 - val_accuracy: 0.6184\n",
      "Epoch 63/1000\n",
      "177/177 [==============================] - 0s 159us/step - loss: 0.0578 - accuracy: 0.9718 - val_loss: 3.3497 - val_accuracy: 0.6053\n",
      "Epoch 64/1000\n",
      "177/177 [==============================] - 0s 151us/step - loss: 0.0852 - accuracy: 0.9605 - val_loss: 3.4220 - val_accuracy: 0.5789\n",
      "Epoch 65/1000\n",
      "177/177 [==============================] - 0s 157us/step - loss: 0.1897 - accuracy: 0.9605 - val_loss: 3.4923 - val_accuracy: 0.5789\n",
      "Epoch 66/1000\n",
      "177/177 [==============================] - 0s 142us/step - loss: 0.1609 - accuracy: 0.9322 - val_loss: 3.3485 - val_accuracy: 0.5658\n",
      "Epoch 67/1000\n",
      "177/177 [==============================] - 0s 141us/step - loss: 0.2902 - accuracy: 0.9548 - val_loss: 3.5978 - val_accuracy: 0.5526\n",
      "Epoch 68/1000\n",
      "177/177 [==============================] - 0s 140us/step - loss: 0.1425 - accuracy: 0.9605 - val_loss: 3.4269 - val_accuracy: 0.5921\n",
      "Epoch 69/1000\n",
      "177/177 [==============================] - 0s 154us/step - loss: 0.1347 - accuracy: 0.9379 - val_loss: 3.5088 - val_accuracy: 0.5395\n",
      "Epoch 70/1000\n",
      "177/177 [==============================] - 0s 153us/step - loss: 0.0919 - accuracy: 0.9661 - val_loss: 3.4947 - val_accuracy: 0.5526\n",
      "Epoch 71/1000\n",
      "177/177 [==============================] - 0s 155us/step - loss: 0.0692 - accuracy: 0.9661 - val_loss: 3.4059 - val_accuracy: 0.5921\n",
      "Epoch 72/1000\n",
      "177/177 [==============================] - 0s 147us/step - loss: 0.1453 - accuracy: 0.9435 - val_loss: 3.4462 - val_accuracy: 0.5526\n",
      "Epoch 73/1000\n",
      "177/177 [==============================] - 0s 143us/step - loss: 0.1542 - accuracy: 0.9661 - val_loss: 3.4490 - val_accuracy: 0.5395\n",
      "Epoch 74/1000\n",
      "177/177 [==============================] - 0s 153us/step - loss: 0.0679 - accuracy: 0.9661 - val_loss: 3.3435 - val_accuracy: 0.5789\n",
      "Epoch 75/1000\n",
      "177/177 [==============================] - 0s 158us/step - loss: 0.2056 - accuracy: 0.9435 - val_loss: 3.3922 - val_accuracy: 0.5526\n",
      "Epoch 76/1000\n",
      "177/177 [==============================] - 0s 171us/step - loss: 0.0677 - accuracy: 0.9661 - val_loss: 3.4074 - val_accuracy: 0.5658\n",
      "Epoch 77/1000\n",
      "177/177 [==============================] - 0s 158us/step - loss: 0.0858 - accuracy: 0.9661 - val_loss: 3.3553 - val_accuracy: 0.5921\n",
      "Epoch 78/1000\n",
      "177/177 [==============================] - 0s 155us/step - loss: 0.1773 - accuracy: 0.9492 - val_loss: 3.4099 - val_accuracy: 0.5658\n",
      "Epoch 79/1000\n",
      "177/177 [==============================] - 0s 156us/step - loss: 0.1560 - accuracy: 0.9605 - val_loss: 3.4109 - val_accuracy: 0.5921\n",
      "Epoch 80/1000\n",
      "177/177 [==============================] - 0s 152us/step - loss: 0.2187 - accuracy: 0.9435 - val_loss: 3.4528 - val_accuracy: 0.5921\n",
      "Epoch 81/1000\n",
      "177/177 [==============================] - 0s 137us/step - loss: 0.3038 - accuracy: 0.9322 - val_loss: 3.4787 - val_accuracy: 0.5921\n",
      "Epoch 82/1000\n",
      "177/177 [==============================] - 0s 147us/step - loss: 0.3502 - accuracy: 0.9605 - val_loss: 3.4460 - val_accuracy: 0.5526\n",
      "Epoch 83/1000\n",
      "177/177 [==============================] - 0s 163us/step - loss: 0.0981 - accuracy: 0.9605 - val_loss: 3.3781 - val_accuracy: 0.5658\n",
      "Epoch 84/1000\n",
      "177/177 [==============================] - 0s 154us/step - loss: 0.0478 - accuracy: 0.9718 - val_loss: 3.3339 - val_accuracy: 0.5658\n",
      "Epoch 85/1000\n",
      "177/177 [==============================] - 0s 159us/step - loss: 0.0534 - accuracy: 0.9661 - val_loss: 3.2703 - val_accuracy: 0.5789\n",
      "Epoch 86/1000\n",
      "177/177 [==============================] - 0s 161us/step - loss: 0.0832 - accuracy: 0.9718 - val_loss: 3.3677 - val_accuracy: 0.5658\n",
      "Epoch 87/1000\n",
      "177/177 [==============================] - 0s 157us/step - loss: 0.0766 - accuracy: 0.9718 - val_loss: 3.3961 - val_accuracy: 0.5658\n",
      "Epoch 88/1000\n",
      "177/177 [==============================] - 0s 166us/step - loss: 0.0613 - accuracy: 0.9661 - val_loss: 3.8146 - val_accuracy: 0.5526\n",
      "Epoch 89/1000\n",
      "177/177 [==============================] - 0s 159us/step - loss: 3.6179 - accuracy: 0.8531 - val_loss: 8.0296 - val_accuracy: 0.5658\n",
      "Epoch 90/1000\n",
      "177/177 [==============================] - 0s 164us/step - loss: 3.9590 - accuracy: 0.8701 - val_loss: 6.9100 - val_accuracy: 0.5000\n",
      "Epoch 91/1000\n",
      "177/177 [==============================] - 0s 203us/step - loss: 2.4751 - accuracy: 0.8870 - val_loss: 5.7923 - val_accuracy: 0.5263\n",
      "Epoch 92/1000\n",
      "177/177 [==============================] - 0s 142us/step - loss: 1.7387 - accuracy: 0.9266 - val_loss: 4.6044 - val_accuracy: 0.5526\n",
      "Epoch 93/1000\n",
      "177/177 [==============================] - 0s 135us/step - loss: 1.1014 - accuracy: 0.9209 - val_loss: 4.0631 - val_accuracy: 0.5132\n",
      "Epoch 94/1000\n",
      "177/177 [==============================] - 0s 132us/step - loss: 0.7358 - accuracy: 0.9322 - val_loss: 3.7565 - val_accuracy: 0.6053\n",
      "Epoch 95/1000\n",
      "177/177 [==============================] - 0s 138us/step - loss: 0.3783 - accuracy: 0.9266 - val_loss: 3.3516 - val_accuracy: 0.5789\n",
      "Epoch 96/1000\n",
      "177/177 [==============================] - 0s 131us/step - loss: 0.2838 - accuracy: 0.9209 - val_loss: 3.2623 - val_accuracy: 0.5921\n",
      "Epoch 97/1000\n",
      "177/177 [==============================] - 0s 147us/step - loss: 0.1652 - accuracy: 0.9322 - val_loss: 3.5973 - val_accuracy: 0.5921\n",
      "Epoch 98/1000\n",
      "177/177 [==============================] - 0s 154us/step - loss: 0.1389 - accuracy: 0.9718 - val_loss: 3.6468 - val_accuracy: 0.6053\n",
      "Epoch 99/1000\n",
      "177/177 [==============================] - 0s 170us/step - loss: 0.0766 - accuracy: 0.9774 - val_loss: 3.5372 - val_accuracy: 0.5921\n",
      "Epoch 100/1000\n",
      "177/177 [==============================] - 0s 157us/step - loss: 0.1171 - accuracy: 0.9492 - val_loss: 3.5175 - val_accuracy: 0.6184\n",
      "Epoch 101/1000\n",
      "177/177 [==============================] - 0s 279us/step - loss: 0.1702 - accuracy: 0.9661 - val_loss: 3.4268 - val_accuracy: 0.6053\n",
      "Epoch 102/1000\n",
      "177/177 [==============================] - 0s 562us/step - loss: 0.1122 - accuracy: 0.9492 - val_loss: 3.4941 - val_accuracy: 0.6184\n",
      "Epoch 103/1000\n",
      "177/177 [==============================] - 0s 232us/step - loss: 0.1707 - accuracy: 0.9548 - val_loss: 3.5316 - val_accuracy: 0.6053\n",
      "Epoch 104/1000\n",
      "177/177 [==============================] - 0s 301us/step - loss: 0.1557 - accuracy: 0.9548 - val_loss: 3.5814 - val_accuracy: 0.5658\n",
      "Epoch 105/1000\n",
      "177/177 [==============================] - 0s 450us/step - loss: 0.2572 - accuracy: 0.9548 - val_loss: 3.5063 - val_accuracy: 0.5921\n",
      "Epoch 106/1000\n",
      "177/177 [==============================] - 0s 276us/step - loss: 0.0894 - accuracy: 0.9661 - val_loss: 3.4581 - val_accuracy: 0.5789\n",
      "Epoch 107/1000\n",
      "177/177 [==============================] - 0s 1ms/step - loss: 0.1006 - accuracy: 0.9661 - val_loss: 3.4208 - val_accuracy: 0.5789\n",
      "Epoch 108/1000\n",
      "177/177 [==============================] - 0s 262us/step - loss: 0.0507 - accuracy: 0.9718 - val_loss: 3.4015 - val_accuracy: 0.5921\n",
      "Epoch 109/1000\n",
      "177/177 [==============================] - 0s 284us/step - loss: 0.0471 - accuracy: 0.9774 - val_loss: 3.3929 - val_accuracy: 0.5789\n",
      "Epoch 110/1000\n",
      " 16/177 [=>............................] - ETA: 0s - loss: 0.0030 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/keras/callbacks/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.120453). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177/177 [==============================] - 0s 347us/step - loss: 0.0478 - accuracy: 0.9774 - val_loss: 3.3345 - val_accuracy: 0.6053\n",
      "Epoch 111/1000\n",
      "177/177 [==============================] - 0s 245us/step - loss: 0.0484 - accuracy: 0.9661 - val_loss: 3.3098 - val_accuracy: 0.6053\n",
      "Epoch 112/1000\n",
      "177/177 [==============================] - 0s 235us/step - loss: 0.0470 - accuracy: 0.9718 - val_loss: 3.3175 - val_accuracy: 0.5921\n",
      "Epoch 113/1000\n",
      "177/177 [==============================] - 0s 248us/step - loss: 0.0464 - accuracy: 0.9774 - val_loss: 3.3320 - val_accuracy: 0.5921\n",
      "Epoch 114/1000\n",
      "177/177 [==============================] - 0s 246us/step - loss: 0.0462 - accuracy: 0.9774 - val_loss: 3.3336 - val_accuracy: 0.5789\n",
      "Epoch 115/1000\n",
      "177/177 [==============================] - 0s 190us/step - loss: 0.0456 - accuracy: 0.9718 - val_loss: 3.3391 - val_accuracy: 0.5921\n",
      "Epoch 116/1000\n",
      "177/177 [==============================] - 0s 206us/step - loss: 0.0470 - accuracy: 0.9774 - val_loss: 3.3331 - val_accuracy: 0.6053\n",
      "Epoch 117/1000\n",
      "177/177 [==============================] - 0s 565us/step - loss: 0.0458 - accuracy: 0.9718 - val_loss: 3.3640 - val_accuracy: 0.5789\n",
      "Epoch 118/1000\n",
      "177/177 [==============================] - 0s 203us/step - loss: 0.0452 - accuracy: 0.9774 - val_loss: 3.3669 - val_accuracy: 0.5789\n",
      "Epoch 119/1000\n",
      "177/177 [==============================] - 0s 325us/step - loss: 0.0441 - accuracy: 0.9774 - val_loss: 3.3372 - val_accuracy: 0.5921\n",
      "Epoch 120/1000\n",
      "177/177 [==============================] - 0s 243us/step - loss: 0.0451 - accuracy: 0.9774 - val_loss: 3.3366 - val_accuracy: 0.5921\n",
      "Epoch 121/1000\n",
      "177/177 [==============================] - ETA: 0s - loss: 0.0520 - accuracy: 0.97 - 0s 844us/step - loss: 0.0445 - accuracy: 0.9774 - val_loss: 3.3399 - val_accuracy: 0.5921\n",
      "Epoch 122/1000\n",
      "177/177 [==============================] - 0s 271us/step - loss: 0.0447 - accuracy: 0.9774 - val_loss: 3.3382 - val_accuracy: 0.5921\n",
      "Epoch 123/1000\n",
      "177/177 [==============================] - 0s 321us/step - loss: 0.0438 - accuracy: 0.9774 - val_loss: 3.3576 - val_accuracy: 0.5789\n",
      "Epoch 124/1000\n",
      "177/177 [==============================] - 0s 322us/step - loss: 0.0455 - accuracy: 0.9661 - val_loss: 3.3638 - val_accuracy: 0.5789\n",
      "Epoch 125/1000\n",
      "177/177 [==============================] - 0s 336us/step - loss: 0.0429 - accuracy: 0.9774 - val_loss: 3.3645 - val_accuracy: 0.5658\n",
      "Epoch 126/1000\n",
      "177/177 [==============================] - 0s 256us/step - loss: 0.0439 - accuracy: 0.9718 - val_loss: 3.3572 - val_accuracy: 0.5789\n",
      "Epoch 127/1000\n",
      "177/177 [==============================] - 0s 188us/step - loss: 0.0428 - accuracy: 0.9774 - val_loss: 3.3656 - val_accuracy: 0.5789\n",
      "Epoch 128/1000\n",
      "177/177 [==============================] - 0s 264us/step - loss: 0.0434 - accuracy: 0.9661 - val_loss: 3.3744 - val_accuracy: 0.5658\n",
      "Epoch 129/1000\n",
      "177/177 [==============================] - 0s 286us/step - loss: 0.0431 - accuracy: 0.9661 - val_loss: 3.3670 - val_accuracy: 0.5789\n",
      "Epoch 130/1000\n",
      "177/177 [==============================] - 0s 399us/step - loss: 0.0433 - accuracy: 0.9718 - val_loss: 3.3860 - val_accuracy: 0.5789\n",
      "Epoch 131/1000\n",
      "177/177 [==============================] - 0s 237us/step - loss: 0.0425 - accuracy: 0.9718 - val_loss: 3.3923 - val_accuracy: 0.5658\n",
      "Epoch 132/1000\n",
      "177/177 [==============================] - 0s 181us/step - loss: 0.0428 - accuracy: 0.9718 - val_loss: 3.4031 - val_accuracy: 0.5658\n",
      "Epoch 133/1000\n",
      "177/177 [==============================] - 0s 225us/step - loss: 0.0429 - accuracy: 0.9661 - val_loss: 3.3771 - val_accuracy: 0.5789\n",
      "Epoch 134/1000\n",
      "177/177 [==============================] - 0s 193us/step - loss: 0.0429 - accuracy: 0.9774 - val_loss: 3.3857 - val_accuracy: 0.5789\n",
      "Epoch 135/1000\n",
      "177/177 [==============================] - 0s 210us/step - loss: 0.0431 - accuracy: 0.9718 - val_loss: 3.3785 - val_accuracy: 0.5526\n",
      "Epoch 136/1000\n",
      "177/177 [==============================] - 0s 237us/step - loss: 0.0431 - accuracy: 0.9718 - val_loss: 3.3808 - val_accuracy: 0.5658\n",
      "Epoch 137/1000\n",
      "177/177 [==============================] - 0s 363us/step - loss: 0.0418 - accuracy: 0.9774 - val_loss: 3.3564 - val_accuracy: 0.5658\n",
      "Epoch 138/1000\n",
      "177/177 [==============================] - 0s 367us/step - loss: 0.0425 - accuracy: 0.9661 - val_loss: 3.3635 - val_accuracy: 0.5658\n",
      "Epoch 139/1000\n",
      "177/177 [==============================] - 0s 330us/step - loss: 0.0429 - accuracy: 0.9718 - val_loss: 3.3762 - val_accuracy: 0.5658\n",
      "Epoch 140/1000\n",
      "177/177 [==============================] - 0s 323us/step - loss: 0.0421 - accuracy: 0.9774 - val_loss: 3.3828 - val_accuracy: 0.5658\n",
      "Epoch 141/1000\n",
      "177/177 [==============================] - 0s 670us/step - loss: 0.0419 - accuracy: 0.9718 - val_loss: 3.3860 - val_accuracy: 0.5658\n",
      "Epoch 142/1000\n",
      "177/177 [==============================] - 0s 362us/step - loss: 0.0426 - accuracy: 0.9774 - val_loss: 3.3831 - val_accuracy: 0.5789\n",
      "Epoch 143/1000\n",
      "177/177 [==============================] - 0s 324us/step - loss: 0.0425 - accuracy: 0.9774 - val_loss: 3.4155 - val_accuracy: 0.5526\n",
      "Epoch 144/1000\n",
      "177/177 [==============================] - 0s 238us/step - loss: 0.0446 - accuracy: 0.9774 - val_loss: 3.3862 - val_accuracy: 0.5921\n",
      "Epoch 145/1000\n",
      "177/177 [==============================] - 0s 235us/step - loss: 0.0639 - accuracy: 0.9718 - val_loss: 3.4699 - val_accuracy: 0.5526\n",
      "Epoch 146/1000\n",
      "177/177 [==============================] - 0s 265us/step - loss: 0.0860 - accuracy: 0.9718 - val_loss: 3.3883 - val_accuracy: 0.5789\n",
      "Epoch 147/1000\n",
      "177/177 [==============================] - 0s 379us/step - loss: 0.1108 - accuracy: 0.9774 - val_loss: 3.4200 - val_accuracy: 0.5658\n",
      "Epoch 148/1000\n",
      "177/177 [==============================] - 0s 309us/step - loss: 0.0889 - accuracy: 0.9605 - val_loss: 3.4023 - val_accuracy: 0.6053\n",
      "Epoch 149/1000\n",
      "177/177 [==============================] - 0s 271us/step - loss: 0.0663 - accuracy: 0.9661 - val_loss: 3.4997 - val_accuracy: 0.5658\n",
      "Epoch 150/1000\n",
      "177/177 [==============================] - 0s 357us/step - loss: 0.0930 - accuracy: 0.9718 - val_loss: 3.3926 - val_accuracy: 0.5921\n",
      "Epoch 151/1000\n",
      "177/177 [==============================] - 0s 288us/step - loss: 0.0746 - accuracy: 0.9718 - val_loss: 3.5034 - val_accuracy: 0.5789\n",
      "Epoch 152/1000\n",
      "177/177 [==============================] - 0s 200us/step - loss: 0.1154 - accuracy: 0.9718 - val_loss: 3.3814 - val_accuracy: 0.5921\n",
      "Epoch 153/1000\n",
      "177/177 [==============================] - 0s 247us/step - loss: 0.1025 - accuracy: 0.9605 - val_loss: 3.4390 - val_accuracy: 0.5789\n",
      "Epoch 154/1000\n",
      "177/177 [==============================] - 0s 232us/step - loss: 0.1332 - accuracy: 0.9661 - val_loss: 3.4685 - val_accuracy: 0.5921\n",
      "Epoch 155/1000\n",
      "177/177 [==============================] - 0s 190us/step - loss: 0.0541 - accuracy: 0.9718 - val_loss: 3.4473 - val_accuracy: 0.5789\n",
      "Epoch 156/1000\n",
      "177/177 [==============================] - 0s 242us/step - loss: 0.0943 - accuracy: 0.9718 - val_loss: 3.4541 - val_accuracy: 0.5789\n",
      "Epoch 157/1000\n",
      "177/177 [==============================] - 0s 174us/step - loss: 0.0498 - accuracy: 0.9661 - val_loss: 3.5250 - val_accuracy: 0.5658\n",
      "Epoch 158/1000\n",
      "177/177 [==============================] - 0s 202us/step - loss: 1.5730 - accuracy: 0.8701 - val_loss: 6.2278 - val_accuracy: 0.5132\n",
      "Epoch 159/1000\n",
      "177/177 [==============================] - 0s 241us/step - loss: 2.5918 - accuracy: 0.8814 - val_loss: 5.8710 - val_accuracy: 0.5526\n",
      "Epoch 160/1000\n",
      "177/177 [==============================] - 0s 213us/step - loss: 1.8646 - accuracy: 0.9153 - val_loss: 5.0542 - val_accuracy: 0.5395\n",
      "Epoch 161/1000\n",
      "177/177 [==============================] - 0s 185us/step - loss: 1.0489 - accuracy: 0.9322 - val_loss: 3.8121 - val_accuracy: 0.5526\n",
      "Epoch 162/1000\n",
      "177/177 [==============================] - 0s 208us/step - loss: 0.4510 - accuracy: 0.9605 - val_loss: 3.3693 - val_accuracy: 0.6184\n",
      "Epoch 163/1000\n",
      "177/177 [==============================] - 0s 197us/step - loss: 0.2166 - accuracy: 0.9435 - val_loss: 3.2040 - val_accuracy: 0.6579\n",
      "Epoch 164/1000\n",
      "177/177 [==============================] - 0s 213us/step - loss: 0.1011 - accuracy: 0.9718 - val_loss: 3.1599 - val_accuracy: 0.5658\n",
      "Epoch 165/1000\n",
      "177/177 [==============================] - 0s 326us/step - loss: 0.0873 - accuracy: 0.9661 - val_loss: 3.2796 - val_accuracy: 0.5921\n",
      "Epoch 166/1000\n",
      "177/177 [==============================] - 0s 239us/step - loss: 0.1301 - accuracy: 0.9661 - val_loss: 3.3925 - val_accuracy: 0.6316\n",
      "Epoch 167/1000\n",
      "177/177 [==============================] - 0s 218us/step - loss: 0.1703 - accuracy: 0.9548 - val_loss: 3.4613 - val_accuracy: 0.6053\n",
      "Epoch 168/1000\n",
      "177/177 [==============================] - 0s 218us/step - loss: 0.1061 - accuracy: 0.9718 - val_loss: 3.5850 - val_accuracy: 0.5921\n",
      "Epoch 169/1000\n",
      "177/177 [==============================] - 0s 293us/step - loss: 0.1749 - accuracy: 0.9661 - val_loss: 3.4448 - val_accuracy: 0.6053\n",
      "Epoch 170/1000\n",
      "177/177 [==============================] - 0s 202us/step - loss: 0.2442 - accuracy: 0.9379 - val_loss: 3.4137 - val_accuracy: 0.6184\n",
      "Epoch 171/1000\n",
      "177/177 [==============================] - 0s 249us/step - loss: 0.0589 - accuracy: 0.9718 - val_loss: 3.4579 - val_accuracy: 0.5789\n",
      "Epoch 172/1000\n",
      "177/177 [==============================] - 0s 255us/step - loss: 0.0586 - accuracy: 0.9661 - val_loss: 3.4634 - val_accuracy: 0.5921\n",
      "Epoch 173/1000\n",
      "177/177 [==============================] - 0s 244us/step - loss: 0.0515 - accuracy: 0.9718 - val_loss: 3.5310 - val_accuracy: 0.5789\n",
      "Epoch 174/1000\n",
      "177/177 [==============================] - 0s 245us/step - loss: 0.0716 - accuracy: 0.9718 - val_loss: 3.4971 - val_accuracy: 0.6184\n",
      "Epoch 175/1000\n",
      "177/177 [==============================] - 0s 218us/step - loss: 0.1442 - accuracy: 0.9548 - val_loss: 3.4644 - val_accuracy: 0.6053\n",
      "Epoch 176/1000\n",
      "177/177 [==============================] - 0s 235us/step - loss: 0.0461 - accuracy: 0.9774 - val_loss: 3.6344 - val_accuracy: 0.5526\n",
      "Epoch 177/1000\n",
      "177/177 [==============================] - 0s 238us/step - loss: 0.1640 - accuracy: 0.9718 - val_loss: 3.4640 - val_accuracy: 0.5921\n",
      "Epoch 178/1000\n",
      "177/177 [==============================] - 0s 229us/step - loss: 0.0563 - accuracy: 0.9718 - val_loss: 3.5507 - val_accuracy: 0.5921\n",
      "Epoch 179/1000\n",
      "177/177 [==============================] - 0s 267us/step - loss: 0.1382 - accuracy: 0.9661 - val_loss: 3.5148 - val_accuracy: 0.6053\n",
      "Epoch 180/1000\n",
      "177/177 [==============================] - 0s 238us/step - loss: 0.0432 - accuracy: 0.9718 - val_loss: 3.4454 - val_accuracy: 0.6053\n",
      "Epoch 181/1000\n",
      "177/177 [==============================] - 0s 221us/step - loss: 0.0449 - accuracy: 0.9774 - val_loss: 3.5451 - val_accuracy: 0.5921\n",
      "Epoch 182/1000\n",
      "177/177 [==============================] - 0s 209us/step - loss: 0.1132 - accuracy: 0.9661 - val_loss: 3.7408 - val_accuracy: 0.5921\n",
      "Epoch 183/1000\n",
      "177/177 [==============================] - 0s 243us/step - loss: 0.0788 - accuracy: 0.9718 - val_loss: 3.4368 - val_accuracy: 0.6053\n",
      "Epoch 184/1000\n",
      "177/177 [==============================] - 0s 244us/step - loss: 0.1050 - accuracy: 0.9718 - val_loss: 3.3489 - val_accuracy: 0.5658\n",
      "Epoch 185/1000\n",
      "177/177 [==============================] - 0s 217us/step - loss: 0.1631 - accuracy: 0.9661 - val_loss: 3.3907 - val_accuracy: 0.5526\n",
      "Epoch 186/1000\n",
      "177/177 [==============================] - 0s 188us/step - loss: 0.1227 - accuracy: 0.9548 - val_loss: 3.4184 - val_accuracy: 0.5921\n",
      "Epoch 187/1000\n",
      "177/177 [==============================] - 0s 220us/step - loss: 0.0575 - accuracy: 0.9718 - val_loss: 3.4334 - val_accuracy: 0.5526\n",
      "Epoch 188/1000\n",
      "177/177 [==============================] - 0s 280us/step - loss: 0.1040 - accuracy: 0.9718 - val_loss: 3.4475 - val_accuracy: 0.5789\n",
      "Epoch 189/1000\n",
      "177/177 [==============================] - 0s 241us/step - loss: 0.0444 - accuracy: 0.9718 - val_loss: 3.4097 - val_accuracy: 0.6184\n",
      "Epoch 190/1000\n",
      "177/177 [==============================] - 0s 269us/step - loss: 0.0992 - accuracy: 0.9718 - val_loss: 3.5271 - val_accuracy: 0.5526\n",
      "Epoch 191/1000\n",
      "177/177 [==============================] - 0s 378us/step - loss: 0.1329 - accuracy: 0.9605 - val_loss: 3.4946 - val_accuracy: 0.5789\n",
      "Epoch 192/1000\n",
      "177/177 [==============================] - 0s 299us/step - loss: 0.0420 - accuracy: 0.9661 - val_loss: 3.4450 - val_accuracy: 0.6053\n",
      "Epoch 193/1000\n",
      "177/177 [==============================] - 0s 291us/step - loss: 0.0571 - accuracy: 0.9718 - val_loss: 3.6543 - val_accuracy: 0.5526\n",
      "Epoch 194/1000\n",
      "177/177 [==============================] - 0s 473us/step - loss: 0.1560 - accuracy: 0.9605 - val_loss: 3.5675 - val_accuracy: 0.5789\n",
      "Epoch 195/1000\n",
      "177/177 [==============================] - 0s 329us/step - loss: 0.2128 - accuracy: 0.9548 - val_loss: 3.5772 - val_accuracy: 0.5921\n",
      "Epoch 196/1000\n",
      "177/177 [==============================] - 0s 319us/step - loss: 0.1785 - accuracy: 0.9661 - val_loss: 3.6058 - val_accuracy: 0.5789\n",
      "Epoch 197/1000\n",
      "177/177 [==============================] - 0s 211us/step - loss: 0.1669 - accuracy: 0.9605 - val_loss: 3.4921 - val_accuracy: 0.5921\n",
      "Epoch 198/1000\n",
      "177/177 [==============================] - 0s 189us/step - loss: 0.0821 - accuracy: 0.9661 - val_loss: 3.7710 - val_accuracy: 0.5395\n",
      "Epoch 199/1000\n",
      "177/177 [==============================] - 0s 203us/step - loss: 0.1715 - accuracy: 0.9718 - val_loss: 3.5550 - val_accuracy: 0.5921\n",
      "Epoch 200/1000\n",
      "177/177 [==============================] - 0s 197us/step - loss: 0.0720 - accuracy: 0.9661 - val_loss: 3.5299 - val_accuracy: 0.5921\n",
      "Epoch 201/1000\n",
      "177/177 [==============================] - 0s 234us/step - loss: 0.0668 - accuracy: 0.9718 - val_loss: 3.4863 - val_accuracy: 0.6184\n",
      "Epoch 202/1000\n",
      "177/177 [==============================] - 0s 234us/step - loss: 0.0603 - accuracy: 0.9661 - val_loss: 3.5744 - val_accuracy: 0.5658\n",
      "Epoch 203/1000\n",
      "177/177 [==============================] - 0s 196us/step - loss: 0.1772 - accuracy: 0.9605 - val_loss: 3.6041 - val_accuracy: 0.5658\n",
      "Epoch 204/1000\n",
      "177/177 [==============================] - 0s 179us/step - loss: 0.2090 - accuracy: 0.9548 - val_loss: 3.3305 - val_accuracy: 0.6053\n",
      "Epoch 205/1000\n",
      "177/177 [==============================] - 0s 264us/step - loss: 0.0590 - accuracy: 0.9718 - val_loss: 3.5246 - val_accuracy: 0.5789\n",
      "Epoch 206/1000\n",
      "177/177 [==============================] - 0s 214us/step - loss: 0.0880 - accuracy: 0.9492 - val_loss: 3.6160 - val_accuracy: 0.5658\n",
      "Epoch 207/1000\n",
      "177/177 [==============================] - 0s 199us/step - loss: 0.1244 - accuracy: 0.9548 - val_loss: 3.7167 - val_accuracy: 0.5789\n",
      "Epoch 208/1000\n",
      "177/177 [==============================] - 0s 309us/step - loss: 0.0512 - accuracy: 0.9774 - val_loss: 3.7110 - val_accuracy: 0.5921\n",
      "Epoch 209/1000\n",
      "177/177 [==============================] - 0s 347us/step - loss: 0.0496 - accuracy: 0.9718 - val_loss: 3.6081 - val_accuracy: 0.5921\n",
      "Epoch 210/1000\n",
      "177/177 [==============================] - 0s 280us/step - loss: 0.0454 - accuracy: 0.9661 - val_loss: 3.6212 - val_accuracy: 0.5789\n",
      "Epoch 211/1000\n",
      "177/177 [==============================] - 0s 238us/step - loss: 0.0564 - accuracy: 0.9661 - val_loss: 3.5855 - val_accuracy: 0.6184\n",
      "Epoch 212/1000\n",
      "177/177 [==============================] - 0s 229us/step - loss: 0.1174 - accuracy: 0.9661 - val_loss: 3.7145 - val_accuracy: 0.5921\n",
      "Epoch 213/1000\n",
      "177/177 [==============================] - 0s 218us/step - loss: 0.0420 - accuracy: 0.9774 - val_loss: 3.6473 - val_accuracy: 0.5921\n",
      "Epoch 214/1000\n",
      "177/177 [==============================] - 0s 189us/step - loss: 0.0421 - accuracy: 0.9774 - val_loss: 3.6734 - val_accuracy: 0.5921\n",
      "Epoch 215/1000\n",
      "177/177 [==============================] - 0s 191us/step - loss: 0.0507 - accuracy: 0.9661 - val_loss: 3.5611 - val_accuracy: 0.6053\n",
      "Epoch 216/1000\n",
      "177/177 [==============================] - 0s 163us/step - loss: 0.1076 - accuracy: 0.9605 - val_loss: 3.7744 - val_accuracy: 0.5658\n",
      "Epoch 217/1000\n",
      "177/177 [==============================] - 0s 150us/step - loss: 0.1323 - accuracy: 0.9718 - val_loss: 3.5822 - val_accuracy: 0.5921\n",
      "Epoch 218/1000\n",
      "177/177 [==============================] - 0s 172us/step - loss: 0.0890 - accuracy: 0.9774 - val_loss: 3.6882 - val_accuracy: 0.5789\n",
      "Epoch 219/1000\n",
      "177/177 [==============================] - 0s 237us/step - loss: 0.0722 - accuracy: 0.9718 - val_loss: 3.5687 - val_accuracy: 0.5789\n",
      "Epoch 220/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177/177 [==============================] - 0s 238us/step - loss: 0.0695 - accuracy: 0.9774 - val_loss: 3.8298 - val_accuracy: 0.5526\n",
      "Epoch 221/1000\n",
      "177/177 [==============================] - 0s 257us/step - loss: 0.1713 - accuracy: 0.9605 - val_loss: 3.7148 - val_accuracy: 0.5658\n",
      "Epoch 222/1000\n",
      "177/177 [==============================] - 0s 496us/step - loss: 0.1295 - accuracy: 0.9548 - val_loss: 3.7496 - val_accuracy: 0.5789\n",
      "Epoch 223/1000\n",
      "177/177 [==============================] - 0s 394us/step - loss: 0.0629 - accuracy: 0.9718 - val_loss: 3.6574 - val_accuracy: 0.5921\n",
      "Epoch 224/1000\n",
      "177/177 [==============================] - 0s 284us/step - loss: 0.2829 - accuracy: 0.9322 - val_loss: 3.7138 - val_accuracy: 0.5658\n",
      "Epoch 225/1000\n",
      "177/177 [==============================] - 0s 202us/step - loss: 0.0770 - accuracy: 0.9774 - val_loss: 3.6706 - val_accuracy: 0.5789\n",
      "Epoch 226/1000\n",
      "177/177 [==============================] - 0s 181us/step - loss: 0.0449 - accuracy: 0.9774 - val_loss: 3.6204 - val_accuracy: 0.5789\n",
      "Epoch 227/1000\n",
      "177/177 [==============================] - 0s 250us/step - loss: 0.1108 - accuracy: 0.9548 - val_loss: 3.6484 - val_accuracy: 0.5789\n",
      "Epoch 228/1000\n",
      "177/177 [==============================] - 0s 241us/step - loss: 0.1168 - accuracy: 0.9718 - val_loss: 3.7246 - val_accuracy: 0.5789\n",
      "Epoch 229/1000\n",
      "177/177 [==============================] - 0s 300us/step - loss: 0.1867 - accuracy: 0.9548 - val_loss: 3.5962 - val_accuracy: 0.6053\n",
      "Epoch 230/1000\n",
      "177/177 [==============================] - 0s 218us/step - loss: 0.1808 - accuracy: 0.9661 - val_loss: 3.7105 - val_accuracy: 0.5789\n",
      "Epoch 231/1000\n",
      "177/177 [==============================] - 0s 208us/step - loss: 0.1090 - accuracy: 0.9605 - val_loss: 3.8001 - val_accuracy: 0.5921\n",
      "Epoch 232/1000\n",
      "177/177 [==============================] - 0s 188us/step - loss: 0.2482 - accuracy: 0.9661 - val_loss: 3.6567 - val_accuracy: 0.5789\n",
      "Epoch 233/1000\n",
      "177/177 [==============================] - 0s 267us/step - loss: 0.0921 - accuracy: 0.9718 - val_loss: 3.6315 - val_accuracy: 0.5789\n",
      "Epoch 234/1000\n",
      "177/177 [==============================] - 0s 370us/step - loss: 0.0480 - accuracy: 0.9718 - val_loss: 3.7016 - val_accuracy: 0.5789\n",
      "Epoch 235/1000\n",
      "177/177 [==============================] - 0s 189us/step - loss: 0.0768 - accuracy: 0.9661 - val_loss: 3.6025 - val_accuracy: 0.5789\n",
      "Epoch 236/1000\n",
      "177/177 [==============================] - 0s 236us/step - loss: 0.1094 - accuracy: 0.9661 - val_loss: 3.6500 - val_accuracy: 0.5658\n",
      "Epoch 237/1000\n",
      "177/177 [==============================] - 0s 199us/step - loss: 0.0399 - accuracy: 0.9774 - val_loss: 3.6475 - val_accuracy: 0.5658\n",
      "Epoch 238/1000\n",
      "177/177 [==============================] - 0s 481us/step - loss: 0.0396 - accuracy: 0.9718 - val_loss: 3.6641 - val_accuracy: 0.5789\n",
      "Epoch 239/1000\n",
      "177/177 [==============================] - 0s 275us/step - loss: 0.0385 - accuracy: 0.9831 - val_loss: 3.6980 - val_accuracy: 0.5789\n",
      "Epoch 240/1000\n",
      "177/177 [==============================] - 0s 196us/step - loss: 0.0385 - accuracy: 0.9774 - val_loss: 3.6951 - val_accuracy: 0.5789\n",
      "Epoch 241/1000\n",
      "177/177 [==============================] - 0s 192us/step - loss: 0.0382 - accuracy: 0.9774 - val_loss: 3.6844 - val_accuracy: 0.5658\n",
      "Epoch 242/1000\n",
      "177/177 [==============================] - 0s 224us/step - loss: 0.0384 - accuracy: 0.9774 - val_loss: 3.6855 - val_accuracy: 0.5658\n",
      "Epoch 243/1000\n",
      "177/177 [==============================] - 0s 311us/step - loss: 0.0389 - accuracy: 0.9774 - val_loss: 3.7119 - val_accuracy: 0.5658\n",
      "Epoch 244/1000\n",
      "177/177 [==============================] - 0s 266us/step - loss: 0.0380 - accuracy: 0.9831 - val_loss: 3.7571 - val_accuracy: 0.5658\n",
      "Epoch 245/1000\n",
      "177/177 [==============================] - 0s 261us/step - loss: 0.0383 - accuracy: 0.9774 - val_loss: 3.7516 - val_accuracy: 0.5526\n",
      "Epoch 246/1000\n",
      "177/177 [==============================] - 0s 281us/step - loss: 0.0386 - accuracy: 0.9831 - val_loss: 3.7459 - val_accuracy: 0.5526\n",
      "Epoch 247/1000\n",
      "177/177 [==============================] - 0s 219us/step - loss: 0.0379 - accuracy: 0.9831 - val_loss: 3.7676 - val_accuracy: 0.5526\n",
      "Epoch 248/1000\n",
      "177/177 [==============================] - 0s 212us/step - loss: 0.0382 - accuracy: 0.9774 - val_loss: 3.7490 - val_accuracy: 0.5526\n",
      "Epoch 249/1000\n",
      "177/177 [==============================] - 0s 176us/step - loss: 0.0382 - accuracy: 0.9774 - val_loss: 3.7776 - val_accuracy: 0.5526\n",
      "Epoch 250/1000\n",
      "177/177 [==============================] - 0s 173us/step - loss: 0.0378 - accuracy: 0.9831 - val_loss: 3.7262 - val_accuracy: 0.5526\n",
      "Epoch 251/1000\n",
      "177/177 [==============================] - 0s 203us/step - loss: 0.0770 - accuracy: 0.9718 - val_loss: 3.7096 - val_accuracy: 0.5789\n",
      "Epoch 252/1000\n",
      "177/177 [==============================] - 0s 182us/step - loss: 0.0695 - accuracy: 0.9661 - val_loss: 3.8090 - val_accuracy: 0.5658\n",
      "Epoch 253/1000\n",
      "177/177 [==============================] - 0s 201us/step - loss: 0.0615 - accuracy: 0.9661 - val_loss: 3.7661 - val_accuracy: 0.5921\n",
      "Epoch 254/1000\n",
      "177/177 [==============================] - 0s 189us/step - loss: 0.0983 - accuracy: 0.9661 - val_loss: 3.9424 - val_accuracy: 0.5526\n",
      "Epoch 255/1000\n",
      "177/177 [==============================] - 0s 221us/step - loss: 0.1238 - accuracy: 0.9718 - val_loss: 3.6951 - val_accuracy: 0.5658\n",
      "Epoch 256/1000\n",
      "177/177 [==============================] - 0s 240us/step - loss: 0.0852 - accuracy: 0.9774 - val_loss: 3.8420 - val_accuracy: 0.5526\n",
      "Epoch 257/1000\n",
      "177/177 [==============================] - 0s 313us/step - loss: 0.1292 - accuracy: 0.9718 - val_loss: 3.7124 - val_accuracy: 0.5526\n",
      "Epoch 258/1000\n",
      "177/177 [==============================] - 0s 201us/step - loss: 0.0912 - accuracy: 0.9718 - val_loss: 3.7538 - val_accuracy: 0.5526\n",
      "Epoch 259/1000\n",
      "177/177 [==============================] - 0s 238us/step - loss: 0.0843 - accuracy: 0.9774 - val_loss: 3.6792 - val_accuracy: 0.5658\n",
      "Epoch 260/1000\n",
      "177/177 [==============================] - 0s 188us/step - loss: 0.0603 - accuracy: 0.9831 - val_loss: 3.7850 - val_accuracy: 0.5658\n",
      "Epoch 261/1000\n",
      "177/177 [==============================] - 0s 224us/step - loss: 0.0858 - accuracy: 0.9718 - val_loss: 3.6788 - val_accuracy: 0.5526\n",
      "Epoch 262/1000\n",
      "177/177 [==============================] - 0s 165us/step - loss: 0.0388 - accuracy: 0.9774 - val_loss: 3.6932 - val_accuracy: 0.5658\n",
      "Epoch 263/1000\n",
      "177/177 [==============================] - 0s 195us/step - loss: 0.0381 - accuracy: 0.9774 - val_loss: 3.6933 - val_accuracy: 0.5658\n",
      "Epoch 264/1000\n",
      "177/177 [==============================] - 0s 182us/step - loss: 0.0377 - accuracy: 0.9718 - val_loss: 3.6753 - val_accuracy: 0.5658\n",
      "Epoch 265/1000\n",
      "177/177 [==============================] - 0s 311us/step - loss: 0.0376 - accuracy: 0.9661 - val_loss: 3.6629 - val_accuracy: 0.5789\n",
      "Epoch 266/1000\n",
      "177/177 [==============================] - 0s 365us/step - loss: 0.0365 - accuracy: 0.9718 - val_loss: 3.6798 - val_accuracy: 0.5789\n",
      "Epoch 267/1000\n",
      "177/177 [==============================] - 0s 363us/step - loss: 0.0370 - accuracy: 0.9718 - val_loss: 3.7151 - val_accuracy: 0.5658\n",
      "Epoch 268/1000\n",
      "177/177 [==============================] - 0s 432us/step - loss: 0.0362 - accuracy: 0.9774 - val_loss: 3.7131 - val_accuracy: 0.5658\n",
      "Epoch 269/1000\n",
      "177/177 [==============================] - 0s 262us/step - loss: 0.0367 - accuracy: 0.9718 - val_loss: 3.6661 - val_accuracy: 0.5789\n",
      "Epoch 270/1000\n",
      "177/177 [==============================] - 0s 232us/step - loss: 0.0361 - accuracy: 0.9718 - val_loss: 3.7165 - val_accuracy: 0.5526\n",
      "Epoch 271/1000\n",
      "177/177 [==============================] - 0s 243us/step - loss: 0.0366 - accuracy: 0.9718 - val_loss: 3.7500 - val_accuracy: 0.5658\n",
      "Epoch 272/1000\n",
      "177/177 [==============================] - 0s 231us/step - loss: 0.0365 - accuracy: 0.9831 - val_loss: 3.7662 - val_accuracy: 0.5658\n",
      "Epoch 273/1000\n",
      "177/177 [==============================] - 0s 241us/step - loss: 0.0356 - accuracy: 0.9774 - val_loss: 3.7784 - val_accuracy: 0.5658\n",
      "Epoch 274/1000\n",
      "177/177 [==============================] - 0s 310us/step - loss: 0.0358 - accuracy: 0.9774 - val_loss: 3.7763 - val_accuracy: 0.5658\n",
      "Epoch 275/1000\n",
      "177/177 [==============================] - 0s 293us/step - loss: 0.0368 - accuracy: 0.9831 - val_loss: 3.7788 - val_accuracy: 0.5526\n",
      "Epoch 276/1000\n",
      "177/177 [==============================] - 0s 251us/step - loss: 0.0360 - accuracy: 0.9774 - val_loss: 3.7636 - val_accuracy: 0.5526\n",
      "Epoch 277/1000\n",
      "177/177 [==============================] - 0s 246us/step - loss: 0.0363 - accuracy: 0.9718 - val_loss: 3.7855 - val_accuracy: 0.5658\n",
      "Epoch 278/1000\n",
      "177/177 [==============================] - 0s 299us/step - loss: 0.0355 - accuracy: 0.9831 - val_loss: 3.7915 - val_accuracy: 0.5526\n",
      "Epoch 279/1000\n",
      "177/177 [==============================] - 0s 335us/step - loss: 0.0359 - accuracy: 0.9718 - val_loss: 3.7818 - val_accuracy: 0.5658\n",
      "Epoch 280/1000\n",
      "177/177 [==============================] - 0s 277us/step - loss: 0.0362 - accuracy: 0.9774 - val_loss: 3.7903 - val_accuracy: 0.5526\n",
      "Epoch 281/1000\n",
      "177/177 [==============================] - 0s 269us/step - loss: 0.0361 - accuracy: 0.9831 - val_loss: 3.8049 - val_accuracy: 0.5526\n",
      "Epoch 282/1000\n",
      "177/177 [==============================] - 0s 180us/step - loss: 0.0359 - accuracy: 0.9831 - val_loss: 3.7669 - val_accuracy: 0.5658\n",
      "Epoch 283/1000\n",
      "177/177 [==============================] - 0s 232us/step - loss: 0.0359 - accuracy: 0.9774 - val_loss: 3.7841 - val_accuracy: 0.5658\n",
      "Epoch 284/1000\n",
      "177/177 [==============================] - 0s 207us/step - loss: 0.0364 - accuracy: 0.9831 - val_loss: 3.7700 - val_accuracy: 0.5658\n",
      "Epoch 285/1000\n",
      "177/177 [==============================] - 0s 175us/step - loss: 0.0361 - accuracy: 0.9831 - val_loss: 3.8034 - val_accuracy: 0.5658\n",
      "Epoch 286/1000\n",
      "177/177 [==============================] - 0s 151us/step - loss: 0.0364 - accuracy: 0.9774 - val_loss: 3.8346 - val_accuracy: 0.5658\n",
      "Epoch 287/1000\n",
      "177/177 [==============================] - 0s 178us/step - loss: 0.0368 - accuracy: 0.9831 - val_loss: 3.8244 - val_accuracy: 0.5658\n",
      "Epoch 288/1000\n",
      "177/177 [==============================] - 0s 147us/step - loss: 0.0361 - accuracy: 0.9831 - val_loss: 3.7822 - val_accuracy: 0.5658\n",
      "Epoch 289/1000\n",
      "177/177 [==============================] - 0s 161us/step - loss: 0.0596 - accuracy: 0.9661 - val_loss: 3.8158 - val_accuracy: 0.5789\n",
      "Epoch 290/1000\n",
      "177/177 [==============================] - 0s 333us/step - loss: 0.1282 - accuracy: 0.9661 - val_loss: 3.7984 - val_accuracy: 0.5921\n",
      "Epoch 291/1000\n",
      "177/177 [==============================] - 0s 235us/step - loss: 0.1236 - accuracy: 0.9605 - val_loss: 3.8239 - val_accuracy: 0.5789\n",
      "Epoch 292/1000\n",
      "177/177 [==============================] - 0s 162us/step - loss: 0.1696 - accuracy: 0.9492 - val_loss: 3.8105 - val_accuracy: 0.5526\n",
      "Epoch 293/1000\n",
      "177/177 [==============================] - 0s 160us/step - loss: 0.1498 - accuracy: 0.9718 - val_loss: 3.9872 - val_accuracy: 0.5658\n",
      "Epoch 294/1000\n",
      "177/177 [==============================] - 0s 170us/step - loss: 0.0962 - accuracy: 0.9548 - val_loss: 3.7863 - val_accuracy: 0.5658\n",
      "Epoch 295/1000\n",
      "177/177 [==============================] - 0s 148us/step - loss: 0.1455 - accuracy: 0.9435 - val_loss: 3.9179 - val_accuracy: 0.5658\n",
      "Epoch 296/1000\n",
      "177/177 [==============================] - 0s 142us/step - loss: 0.2005 - accuracy: 0.9605 - val_loss: 3.7995 - val_accuracy: 0.5789\n",
      "Epoch 297/1000\n",
      "177/177 [==============================] - 0s 166us/step - loss: 0.1656 - accuracy: 0.9548 - val_loss: 3.8996 - val_accuracy: 0.5658\n",
      "Epoch 298/1000\n",
      "177/177 [==============================] - 0s 146us/step - loss: 0.1405 - accuracy: 0.9605 - val_loss: 3.7983 - val_accuracy: 0.5789\n",
      "Epoch 299/1000\n",
      "177/177 [==============================] - 0s 209us/step - loss: 0.1482 - accuracy: 0.9605 - val_loss: 4.0132 - val_accuracy: 0.5526\n",
      "Epoch 300/1000\n",
      "177/177 [==============================] - 0s 220us/step - loss: 0.0660 - accuracy: 0.9605 - val_loss: 3.7012 - val_accuracy: 0.5921\n",
      "Epoch 301/1000\n",
      "177/177 [==============================] - 0s 268us/step - loss: 0.1768 - accuracy: 0.9605 - val_loss: 3.8584 - val_accuracy: 0.5526\n",
      "Epoch 302/1000\n",
      "177/177 [==============================] - 0s 160us/step - loss: 0.1820 - accuracy: 0.9605 - val_loss: 3.8814 - val_accuracy: 0.5526\n",
      "Epoch 303/1000\n",
      "177/177 [==============================] - 0s 155us/step - loss: 0.0479 - accuracy: 0.9774 - val_loss: 3.8308 - val_accuracy: 0.5789\n",
      "Epoch 304/1000\n",
      "177/177 [==============================] - 0s 182us/step - loss: 0.0528 - accuracy: 0.9718 - val_loss: 3.7426 - val_accuracy: 0.5921\n",
      "Epoch 305/1000\n",
      "177/177 [==============================] - 0s 249us/step - loss: 0.1944 - accuracy: 0.9718 - val_loss: 3.9387 - val_accuracy: 0.5526\n",
      "Epoch 306/1000\n",
      "177/177 [==============================] - 0s 206us/step - loss: 0.1859 - accuracy: 0.9661 - val_loss: 3.8450 - val_accuracy: 0.5921\n",
      "Epoch 307/1000\n",
      "177/177 [==============================] - 0s 247us/step - loss: 0.3462 - accuracy: 0.9435 - val_loss: 3.8967 - val_accuracy: 0.5789\n",
      "Epoch 308/1000\n",
      "177/177 [==============================] - 0s 247us/step - loss: 0.6708 - accuracy: 0.9548 - val_loss: 3.8559 - val_accuracy: 0.5789\n",
      "Epoch 309/1000\n",
      "177/177 [==============================] - 0s 148us/step - loss: 0.1414 - accuracy: 0.9605 - val_loss: 3.8415 - val_accuracy: 0.5789\n",
      "Epoch 310/1000\n",
      "177/177 [==============================] - 0s 179us/step - loss: 0.1191 - accuracy: 0.9718 - val_loss: 3.8915 - val_accuracy: 0.5658\n",
      "Epoch 311/1000\n",
      "177/177 [==============================] - 0s 143us/step - loss: 0.1499 - accuracy: 0.9492 - val_loss: 4.0049 - val_accuracy: 0.5658\n",
      "Epoch 312/1000\n",
      "177/177 [==============================] - 0s 151us/step - loss: 0.2392 - accuracy: 0.9605 - val_loss: 4.1502 - val_accuracy: 0.5658\n",
      "Epoch 313/1000\n",
      "177/177 [==============================] - 0s 173us/step - loss: 0.2321 - accuracy: 0.9661 - val_loss: 3.8951 - val_accuracy: 0.5789\n",
      "Epoch 314/1000\n",
      "177/177 [==============================] - 0s 132us/step - loss: 0.0727 - accuracy: 0.9718 - val_loss: 3.9704 - val_accuracy: 0.5658\n",
      "Epoch 315/1000\n",
      "177/177 [==============================] - 0s 124us/step - loss: 0.3690 - accuracy: 0.9322 - val_loss: 3.7486 - val_accuracy: 0.5921\n",
      "Epoch 316/1000\n",
      "177/177 [==============================] - 0s 176us/step - loss: 0.0428 - accuracy: 0.9774 - val_loss: 4.0428 - val_accuracy: 0.5526\n",
      "Epoch 317/1000\n",
      "177/177 [==============================] - 0s 157us/step - loss: 0.1691 - accuracy: 0.9661 - val_loss: 3.9949 - val_accuracy: 0.5921\n",
      "Epoch 318/1000\n",
      "177/177 [==============================] - 0s 468us/step - loss: 0.2356 - accuracy: 0.9548 - val_loss: 3.7836 - val_accuracy: 0.5921\n",
      "Epoch 319/1000\n",
      "177/177 [==============================] - 0s 226us/step - loss: 0.0629 - accuracy: 0.9661 - val_loss: 4.2265 - val_accuracy: 0.5526\n",
      "Epoch 320/1000\n",
      "177/177 [==============================] - 0s 320us/step - loss: 0.4107 - accuracy: 0.9435 - val_loss: 4.0408 - val_accuracy: 0.5789\n",
      "Epoch 321/1000\n",
      "177/177 [==============================] - 0s 297us/step - loss: 0.6606 - accuracy: 0.9492 - val_loss: 4.0044 - val_accuracy: 0.5658\n",
      "Epoch 322/1000\n",
      "177/177 [==============================] - 0s 254us/step - loss: 0.2868 - accuracy: 0.9266 - val_loss: 3.8693 - val_accuracy: 0.5921\n",
      "Epoch 323/1000\n",
      "177/177 [==============================] - 0s 253us/step - loss: 0.1215 - accuracy: 0.9548 - val_loss: 4.2216 - val_accuracy: 0.5395\n",
      "Epoch 324/1000\n",
      "177/177 [==============================] - 0s 229us/step - loss: 0.4101 - accuracy: 0.9605 - val_loss: 3.7879 - val_accuracy: 0.5789\n",
      "Epoch 325/1000\n",
      "177/177 [==============================] - 0s 229us/step - loss: 0.6177 - accuracy: 0.9153 - val_loss: 3.8360 - val_accuracy: 0.5921\n",
      "Epoch 326/1000\n",
      "177/177 [==============================] - 0s 197us/step - loss: 1.5684 - accuracy: 0.9209 - val_loss: 6.4304 - val_accuracy: 0.5132\n",
      "Epoch 327/1000\n",
      "177/177 [==============================] - 0s 165us/step - loss: 3.0437 - accuracy: 0.8927 - val_loss: 4.2917 - val_accuracy: 0.5789\n",
      "Epoch 328/1000\n",
      "177/177 [==============================] - 0s 142us/step - loss: 1.0795 - accuracy: 0.9209 - val_loss: 3.7265 - val_accuracy: 0.6053\n",
      "Epoch 329/1000\n",
      "177/177 [==============================] - 0s 211us/step - loss: 0.0460 - accuracy: 0.9774 - val_loss: 4.3768 - val_accuracy: 0.5526\n",
      "Epoch 330/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177/177 [==============================] - 0s 175us/step - loss: 0.4372 - accuracy: 0.9605 - val_loss: 4.5272 - val_accuracy: 0.5526\n",
      "Epoch 331/1000\n",
      "177/177 [==============================] - 0s 234us/step - loss: 0.2533 - accuracy: 0.9661 - val_loss: 3.9415 - val_accuracy: 0.5921\n",
      "Epoch 332/1000\n",
      "177/177 [==============================] - 0s 239us/step - loss: 0.0945 - accuracy: 0.9661 - val_loss: 3.7753 - val_accuracy: 0.5789\n",
      "Epoch 333/1000\n",
      "177/177 [==============================] - 0s 245us/step - loss: 0.0684 - accuracy: 0.9718 - val_loss: 3.8203 - val_accuracy: 0.5658\n",
      "Epoch 334/1000\n",
      "177/177 [==============================] - 0s 275us/step - loss: 0.1179 - accuracy: 0.9605 - val_loss: 3.8042 - val_accuracy: 0.5789\n",
      "Epoch 335/1000\n",
      "177/177 [==============================] - 0s 213us/step - loss: 0.0606 - accuracy: 0.9605 - val_loss: 3.8185 - val_accuracy: 0.5526\n",
      "Epoch 336/1000\n",
      "177/177 [==============================] - 0s 214us/step - loss: 0.0503 - accuracy: 0.9718 - val_loss: 4.0390 - val_accuracy: 0.5395\n",
      "Epoch 337/1000\n",
      "177/177 [==============================] - 0s 228us/step - loss: 0.1430 - accuracy: 0.9661 - val_loss: 3.8091 - val_accuracy: 0.5658\n",
      "Epoch 338/1000\n",
      "177/177 [==============================] - 0s 237us/step - loss: 0.1271 - accuracy: 0.9661 - val_loss: 3.9369 - val_accuracy: 0.5526\n",
      "Epoch 339/1000\n",
      "177/177 [==============================] - 0s 302us/step - loss: 0.0634 - accuracy: 0.9718 - val_loss: 3.8235 - val_accuracy: 0.5658\n",
      "Epoch 340/1000\n",
      "177/177 [==============================] - 0s 533us/step - loss: 0.1021 - accuracy: 0.9718 - val_loss: 3.8601 - val_accuracy: 0.5526\n",
      "Epoch 341/1000\n",
      "177/177 [==============================] - 0s 598us/step - loss: 0.0464 - accuracy: 0.9718 - val_loss: 3.9096 - val_accuracy: 0.5526\n",
      "Epoch 342/1000\n",
      "177/177 [==============================] - 0s 189us/step - loss: 0.0364 - accuracy: 0.9831 - val_loss: 3.8863 - val_accuracy: 0.5658\n",
      "Epoch 343/1000\n",
      "177/177 [==============================] - 0s 191us/step - loss: 0.0417 - accuracy: 0.9831 - val_loss: 3.9967 - val_accuracy: 0.5526\n",
      "Epoch 344/1000\n",
      "177/177 [==============================] - 0s 197us/step - loss: 0.0894 - accuracy: 0.9661 - val_loss: 3.9768 - val_accuracy: 0.5395\n",
      "Epoch 345/1000\n",
      "177/177 [==============================] - 0s 255us/step - loss: 0.0407 - accuracy: 0.9718 - val_loss: 4.0126 - val_accuracy: 0.5658\n",
      "Epoch 346/1000\n",
      "177/177 [==============================] - 0s 240us/step - loss: 0.0864 - accuracy: 0.9718 - val_loss: 3.8341 - val_accuracy: 0.5789\n",
      "Epoch 347/1000\n",
      "177/177 [==============================] - 0s 170us/step - loss: 0.1795 - accuracy: 0.9661 - val_loss: 3.8726 - val_accuracy: 0.5658\n",
      "Epoch 348/1000\n",
      "177/177 [==============================] - 0s 185us/step - loss: 0.0989 - accuracy: 0.9718 - val_loss: 3.9743 - val_accuracy: 0.5526\n",
      "Epoch 349/1000\n",
      "177/177 [==============================] - 0s 162us/step - loss: 0.0653 - accuracy: 0.9718 - val_loss: 4.0556 - val_accuracy: 0.5658\n",
      "Epoch 350/1000\n",
      "177/177 [==============================] - 0s 175us/step - loss: 0.1463 - accuracy: 0.9718 - val_loss: 4.0973 - val_accuracy: 0.5526\n",
      "Epoch 351/1000\n",
      "177/177 [==============================] - 0s 149us/step - loss: 0.0421 - accuracy: 0.9774 - val_loss: 3.9663 - val_accuracy: 0.5526\n",
      "Epoch 352/1000\n",
      "177/177 [==============================] - 0s 159us/step - loss: 0.0374 - accuracy: 0.9831 - val_loss: 3.9317 - val_accuracy: 0.5526\n",
      "Epoch 353/1000\n",
      "177/177 [==============================] - 0s 173us/step - loss: 0.0482 - accuracy: 0.9774 - val_loss: 3.9555 - val_accuracy: 0.5526\n",
      "Epoch 354/1000\n",
      "177/177 [==============================] - 0s 144us/step - loss: 0.0842 - accuracy: 0.9774 - val_loss: 3.9876 - val_accuracy: 0.5395\n",
      "Epoch 355/1000\n",
      "177/177 [==============================] - 0s 151us/step - loss: 0.0397 - accuracy: 0.9774 - val_loss: 4.0571 - val_accuracy: 0.5395\n",
      "Epoch 356/1000\n",
      "177/177 [==============================] - 0s 250us/step - loss: 0.0667 - accuracy: 0.9774 - val_loss: 3.8800 - val_accuracy: 0.5658\n",
      "Epoch 357/1000\n",
      "177/177 [==============================] - 0s 158us/step - loss: 0.1157 - accuracy: 0.9774 - val_loss: 3.8867 - val_accuracy: 0.5658\n",
      "Epoch 358/1000\n",
      "177/177 [==============================] - 0s 170us/step - loss: 0.0354 - accuracy: 0.9774 - val_loss: 3.9771 - val_accuracy: 0.5526\n",
      "Epoch 359/1000\n",
      "177/177 [==============================] - 0s 157us/step - loss: 0.0724 - accuracy: 0.9718 - val_loss: 3.8109 - val_accuracy: 0.5789\n",
      "Epoch 360/1000\n",
      "177/177 [==============================] - 0s 157us/step - loss: 0.1412 - accuracy: 0.9661 - val_loss: 3.9689 - val_accuracy: 0.5658\n",
      "Epoch 361/1000\n",
      "177/177 [==============================] - 0s 170us/step - loss: 0.0878 - accuracy: 0.9718 - val_loss: 3.8695 - val_accuracy: 0.5658\n",
      "Epoch 362/1000\n",
      "177/177 [==============================] - 0s 203us/step - loss: 0.1512 - accuracy: 0.9774 - val_loss: 3.8857 - val_accuracy: 0.5658\n",
      "Epoch 363/1000\n",
      "177/177 [==============================] - 0s 183us/step - loss: 0.0383 - accuracy: 0.9661 - val_loss: 4.0871 - val_accuracy: 0.5526\n",
      "Epoch 364/1000\n",
      "177/177 [==============================] - 0s 189us/step - loss: 0.1193 - accuracy: 0.9718 - val_loss: 3.8841 - val_accuracy: 0.5789\n",
      "Epoch 365/1000\n",
      "177/177 [==============================] - 0s 180us/step - loss: 0.1443 - accuracy: 0.9774 - val_loss: 3.8839 - val_accuracy: 0.5658\n",
      "Epoch 366/1000\n",
      "177/177 [==============================] - 0s 189us/step - loss: 0.0369 - accuracy: 0.9718 - val_loss: 4.2106 - val_accuracy: 0.5395\n",
      "Epoch 367/1000\n",
      "177/177 [==============================] - 0s 178us/step - loss: 0.1496 - accuracy: 0.9605 - val_loss: 4.0478 - val_accuracy: 0.5789\n",
      "Epoch 368/1000\n",
      "177/177 [==============================] - 0s 189us/step - loss: 0.1222 - accuracy: 0.9718 - val_loss: 3.9809 - val_accuracy: 0.5789\n",
      "Epoch 369/1000\n",
      "177/177 [==============================] - 0s 247us/step - loss: 0.2606 - accuracy: 0.9548 - val_loss: 3.9355 - val_accuracy: 0.5789\n",
      "Epoch 370/1000\n",
      "177/177 [==============================] - 0s 250us/step - loss: 0.2509 - accuracy: 0.9718 - val_loss: 3.8546 - val_accuracy: 0.5789\n",
      "Epoch 371/1000\n",
      "177/177 [==============================] - 0s 248us/step - loss: 0.0720 - accuracy: 0.9661 - val_loss: 3.9959 - val_accuracy: 0.5658\n",
      "Epoch 372/1000\n",
      "177/177 [==============================] - 0s 184us/step - loss: 0.1546 - accuracy: 0.9605 - val_loss: 4.0401 - val_accuracy: 0.5789\n",
      "Epoch 373/1000\n",
      "177/177 [==============================] - 0s 194us/step - loss: 0.0475 - accuracy: 0.9774 - val_loss: 3.9430 - val_accuracy: 0.5658\n",
      "Epoch 374/1000\n",
      "177/177 [==============================] - 0s 197us/step - loss: 0.1232 - accuracy: 0.9718 - val_loss: 4.0883 - val_accuracy: 0.5789\n",
      "Epoch 375/1000\n",
      "177/177 [==============================] - 0s 201us/step - loss: 0.1351 - accuracy: 0.9661 - val_loss: 3.8936 - val_accuracy: 0.5789\n",
      "Epoch 376/1000\n",
      "177/177 [==============================] - 0s 170us/step - loss: 0.0355 - accuracy: 0.9831 - val_loss: 4.0184 - val_accuracy: 0.5658\n",
      "Epoch 377/1000\n",
      "177/177 [==============================] - 0s 169us/step - loss: 0.0851 - accuracy: 0.9661 - val_loss: 3.9544 - val_accuracy: 0.5789\n",
      "Epoch 378/1000\n",
      "177/177 [==============================] - 0s 171us/step - loss: 0.0396 - accuracy: 0.9831 - val_loss: 4.2057 - val_accuracy: 0.5658\n",
      "Epoch 379/1000\n",
      "177/177 [==============================] - 0s 165us/step - loss: 0.2234 - accuracy: 0.9718 - val_loss: 4.0201 - val_accuracy: 0.5395\n",
      "Epoch 380/1000\n",
      "177/177 [==============================] - 0s 177us/step - loss: 0.1696 - accuracy: 0.9718 - val_loss: 4.1607 - val_accuracy: 0.5526\n",
      "Epoch 381/1000\n",
      "177/177 [==============================] - 0s 246us/step - loss: 0.1727 - accuracy: 0.9661 - val_loss: 4.0910 - val_accuracy: 0.5658\n",
      "Epoch 382/1000\n",
      "177/177 [==============================] - 0s 222us/step - loss: 0.2060 - accuracy: 0.9718 - val_loss: 4.2203 - val_accuracy: 0.5526\n",
      "Epoch 383/1000\n",
      "177/177 [==============================] - 0s 229us/step - loss: 0.0544 - accuracy: 0.9831 - val_loss: 4.0686 - val_accuracy: 0.5526\n",
      "Epoch 384/1000\n",
      "177/177 [==============================] - 0s 219us/step - loss: 0.1465 - accuracy: 0.9718 - val_loss: 4.2242 - val_accuracy: 0.5526\n",
      "Epoch 385/1000\n",
      "177/177 [==============================] - 0s 258us/step - loss: 0.1821 - accuracy: 0.9718 - val_loss: 4.3850 - val_accuracy: 0.5526\n",
      "Epoch 386/1000\n",
      "177/177 [==============================] - 0s 197us/step - loss: 0.1740 - accuracy: 0.9774 - val_loss: 4.2689 - val_accuracy: 0.5526\n",
      "Epoch 387/1000\n",
      "177/177 [==============================] - 0s 243us/step - loss: 0.0827 - accuracy: 0.9718 - val_loss: 4.1415 - val_accuracy: 0.5658\n",
      "Epoch 388/1000\n",
      "177/177 [==============================] - 0s 191us/step - loss: 0.1415 - accuracy: 0.9718 - val_loss: 4.1281 - val_accuracy: 0.5526\n",
      "Epoch 389/1000\n",
      "177/177 [==============================] - 0s 217us/step - loss: 0.0396 - accuracy: 0.9831 - val_loss: 3.9094 - val_accuracy: 0.5789\n",
      "Epoch 390/1000\n",
      "177/177 [==============================] - 0s 223us/step - loss: 0.1299 - accuracy: 0.9661 - val_loss: 3.9650 - val_accuracy: 0.5526\n",
      "Epoch 391/1000\n",
      "177/177 [==============================] - 0s 266us/step - loss: 0.0364 - accuracy: 0.9718 - val_loss: 3.9452 - val_accuracy: 0.5658\n",
      "Epoch 392/1000\n",
      "177/177 [==============================] - 0s 208us/step - loss: 0.0336 - accuracy: 0.9774 - val_loss: 4.0080 - val_accuracy: 0.5526\n",
      "Epoch 393/1000\n",
      "177/177 [==============================] - 0s 207us/step - loss: 0.0350 - accuracy: 0.9831 - val_loss: 4.0050 - val_accuracy: 0.5526\n",
      "Epoch 394/1000\n",
      "177/177 [==============================] - 0s 224us/step - loss: 0.0371 - accuracy: 0.9718 - val_loss: 3.9601 - val_accuracy: 0.5658\n",
      "Epoch 395/1000\n",
      "177/177 [==============================] - 0s 366us/step - loss: 0.0344 - accuracy: 0.9831 - val_loss: 3.9648 - val_accuracy: 0.5658\n",
      "Epoch 396/1000\n",
      "177/177 [==============================] - 0s 354us/step - loss: 0.0339 - accuracy: 0.9718 - val_loss: 3.9578 - val_accuracy: 0.5658\n",
      "Epoch 397/1000\n",
      "177/177 [==============================] - 0s 420us/step - loss: 0.0339 - accuracy: 0.9774 - val_loss: 3.9389 - val_accuracy: 0.5658\n",
      "Epoch 398/1000\n",
      "177/177 [==============================] - 0s 226us/step - loss: 0.0332 - accuracy: 0.9774 - val_loss: 3.9730 - val_accuracy: 0.5526\n",
      "Epoch 399/1000\n",
      "177/177 [==============================] - 0s 287us/step - loss: 0.0328 - accuracy: 0.9774 - val_loss: 3.9621 - val_accuracy: 0.5526\n",
      "Epoch 400/1000\n",
      "177/177 [==============================] - 0s 265us/step - loss: 0.0325 - accuracy: 0.9831 - val_loss: 3.9583 - val_accuracy: 0.5526\n",
      "Epoch 401/1000\n",
      "177/177 [==============================] - 0s 181us/step - loss: 0.0333 - accuracy: 0.9718 - val_loss: 3.9691 - val_accuracy: 0.5526\n",
      "Epoch 402/1000\n",
      "177/177 [==============================] - 0s 190us/step - loss: 0.0322 - accuracy: 0.9831 - val_loss: 3.9859 - val_accuracy: 0.5526\n",
      "Epoch 403/1000\n",
      "177/177 [==============================] - 0s 224us/step - loss: 0.0333 - accuracy: 0.9831 - val_loss: 3.9966 - val_accuracy: 0.5526\n",
      "Epoch 404/1000\n",
      "177/177 [==============================] - 0s 200us/step - loss: 0.0325 - accuracy: 0.9831 - val_loss: 3.9839 - val_accuracy: 0.5526\n",
      "Epoch 405/1000\n",
      "177/177 [==============================] - 0s 277us/step - loss: 0.0323 - accuracy: 0.9831 - val_loss: 3.9832 - val_accuracy: 0.5526\n",
      "Epoch 406/1000\n",
      "177/177 [==============================] - 0s 240us/step - loss: 0.0327 - accuracy: 0.9831 - val_loss: 3.9918 - val_accuracy: 0.5526\n",
      "Epoch 407/1000\n",
      "177/177 [==============================] - 0s 179us/step - loss: 0.0329 - accuracy: 0.9831 - val_loss: 3.9848 - val_accuracy: 0.5658\n",
      "Epoch 408/1000\n",
      "177/177 [==============================] - 0s 173us/step - loss: 0.0323 - accuracy: 0.9774 - val_loss: 4.0055 - val_accuracy: 0.5658\n",
      "Epoch 409/1000\n",
      "177/177 [==============================] - 0s 177us/step - loss: 0.0328 - accuracy: 0.9831 - val_loss: 4.0590 - val_accuracy: 0.5526\n",
      "Epoch 410/1000\n",
      "177/177 [==============================] - 0s 148us/step - loss: 0.0328 - accuracy: 0.9774 - val_loss: 4.0432 - val_accuracy: 0.5526\n",
      "Epoch 411/1000\n",
      "177/177 [==============================] - 0s 174us/step - loss: 0.0331 - accuracy: 0.9774 - val_loss: 3.9838 - val_accuracy: 0.5526\n",
      "Epoch 412/1000\n",
      "177/177 [==============================] - 0s 165us/step - loss: 0.0329 - accuracy: 0.9718 - val_loss: 3.9994 - val_accuracy: 0.5526\n",
      "Epoch 413/1000\n",
      "177/177 [==============================] - 0s 160us/step - loss: 0.0331 - accuracy: 0.9774 - val_loss: 3.9679 - val_accuracy: 0.5658\n",
      "Epoch 414/1000\n",
      "177/177 [==============================] - 0s 151us/step - loss: 0.0327 - accuracy: 0.9774 - val_loss: 3.9786 - val_accuracy: 0.5526\n",
      "Epoch 415/1000\n",
      "177/177 [==============================] - 0s 174us/step - loss: 0.0321 - accuracy: 0.9831 - val_loss: 4.0046 - val_accuracy: 0.5526\n",
      "Epoch 416/1000\n",
      "177/177 [==============================] - 0s 229us/step - loss: 0.0316 - accuracy: 0.9774 - val_loss: 4.0076 - val_accuracy: 0.5526\n",
      "Epoch 417/1000\n",
      "177/177 [==============================] - 0s 253us/step - loss: 0.0326 - accuracy: 0.9774 - val_loss: 3.9990 - val_accuracy: 0.5658\n",
      "Epoch 418/1000\n",
      "177/177 [==============================] - 0s 171us/step - loss: 0.0318 - accuracy: 0.9774 - val_loss: 4.0262 - val_accuracy: 0.5526\n",
      "Epoch 419/1000\n",
      "177/177 [==============================] - 0s 183us/step - loss: 0.0330 - accuracy: 0.9718 - val_loss: 4.0492 - val_accuracy: 0.5658\n",
      "Epoch 420/1000\n",
      "177/177 [==============================] - 0s 143us/step - loss: 0.0324 - accuracy: 0.9831 - val_loss: 4.0460 - val_accuracy: 0.5526\n",
      "Epoch 421/1000\n",
      "177/177 [==============================] - 0s 154us/step - loss: 0.0325 - accuracy: 0.9774 - val_loss: 4.0438 - val_accuracy: 0.5526\n",
      "Epoch 422/1000\n",
      "177/177 [==============================] - 0s 187us/step - loss: 0.0321 - accuracy: 0.9718 - val_loss: 4.0100 - val_accuracy: 0.5658\n",
      "Epoch 423/1000\n",
      "177/177 [==============================] - 0s 139us/step - loss: 0.0317 - accuracy: 0.9831 - val_loss: 4.0186 - val_accuracy: 0.5526\n",
      "Epoch 424/1000\n",
      "177/177 [==============================] - 0s 148us/step - loss: 0.0318 - accuracy: 0.9774 - val_loss: 4.0153 - val_accuracy: 0.5526\n",
      "Epoch 425/1000\n",
      "177/177 [==============================] - 0s 162us/step - loss: 0.0331 - accuracy: 0.9718 - val_loss: 4.0335 - val_accuracy: 0.5658\n",
      "Epoch 426/1000\n",
      "177/177 [==============================] - 0s 214us/step - loss: 0.0314 - accuracy: 0.9831 - val_loss: 4.0341 - val_accuracy: 0.5526\n",
      "Epoch 427/1000\n",
      "177/177 [==============================] - 0s 298us/step - loss: 0.0328 - accuracy: 0.9831 - val_loss: 4.0184 - val_accuracy: 0.5526\n",
      "Epoch 428/1000\n",
      "177/177 [==============================] - 0s 234us/step - loss: 0.0315 - accuracy: 0.9831 - val_loss: 4.0052 - val_accuracy: 0.5658\n",
      "Epoch 429/1000\n",
      "177/177 [==============================] - 0s 196us/step - loss: 0.0320 - accuracy: 0.9774 - val_loss: 4.0110 - val_accuracy: 0.5526\n",
      "Epoch 430/1000\n",
      "177/177 [==============================] - 0s 233us/step - loss: 0.0314 - accuracy: 0.9831 - val_loss: 3.8962 - val_accuracy: 0.5658\n",
      "Epoch 431/1000\n",
      "177/177 [==============================] - 0s 262us/step - loss: 0.0317 - accuracy: 0.9831 - val_loss: 3.9834 - val_accuracy: 0.5658\n",
      "Epoch 432/1000\n",
      "177/177 [==============================] - 0s 204us/step - loss: 0.0330 - accuracy: 0.9774 - val_loss: 4.0604 - val_accuracy: 0.5658\n",
      "Epoch 433/1000\n",
      "177/177 [==============================] - 0s 205us/step - loss: 0.0334 - accuracy: 0.9718 - val_loss: 4.1100 - val_accuracy: 0.5526\n",
      "Epoch 434/1000\n",
      "177/177 [==============================] - 0s 193us/step - loss: 0.0319 - accuracy: 0.9774 - val_loss: 4.0611 - val_accuracy: 0.5526\n",
      "Epoch 435/1000\n",
      "177/177 [==============================] - 0s 209us/step - loss: 0.0318 - accuracy: 0.9831 - val_loss: 4.0597 - val_accuracy: 0.5526\n",
      "Epoch 436/1000\n",
      "177/177 [==============================] - 0s 204us/step - loss: 0.0312 - accuracy: 0.9831 - val_loss: 4.0410 - val_accuracy: 0.5658\n",
      "Epoch 437/1000\n",
      "177/177 [==============================] - 0s 179us/step - loss: 0.0311 - accuracy: 0.9831 - val_loss: 4.0441 - val_accuracy: 0.5526\n",
      "Epoch 438/1000\n",
      "177/177 [==============================] - 0s 173us/step - loss: 0.0306 - accuracy: 0.9831 - val_loss: 4.0430 - val_accuracy: 0.5658\n",
      "Epoch 439/1000\n",
      "177/177 [==============================] - 0s 219us/step - loss: 0.0322 - accuracy: 0.9887 - val_loss: 4.0165 - val_accuracy: 0.5789\n",
      "Epoch 440/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177/177 [==============================] - 0s 262us/step - loss: 0.0313 - accuracy: 0.9887 - val_loss: 4.0696 - val_accuracy: 0.5789\n",
      "Epoch 441/1000\n",
      "177/177 [==============================] - 0s 188us/step - loss: 0.0316 - accuracy: 0.9774 - val_loss: 4.1099 - val_accuracy: 0.5658\n",
      "Epoch 442/1000\n",
      "177/177 [==============================] - 0s 167us/step - loss: 0.0307 - accuracy: 0.9887 - val_loss: 4.1012 - val_accuracy: 0.5658\n",
      "Epoch 443/1000\n",
      "177/177 [==============================] - 0s 195us/step - loss: 0.0309 - accuracy: 0.9887 - val_loss: 4.0809 - val_accuracy: 0.5658\n",
      "Epoch 444/1000\n",
      "177/177 [==============================] - 0s 190us/step - loss: 0.0308 - accuracy: 0.9831 - val_loss: 4.1209 - val_accuracy: 0.5658\n",
      "Epoch 445/1000\n",
      "177/177 [==============================] - 0s 170us/step - loss: 0.0316 - accuracy: 0.9774 - val_loss: 4.0618 - val_accuracy: 0.5658\n",
      "Epoch 446/1000\n",
      "177/177 [==============================] - 0s 174us/step - loss: 0.0311 - accuracy: 0.9774 - val_loss: 4.0220 - val_accuracy: 0.5789\n",
      "Epoch 447/1000\n",
      "177/177 [==============================] - 0s 168us/step - loss: 0.0313 - accuracy: 0.9831 - val_loss: 4.0081 - val_accuracy: 0.5658\n",
      "Epoch 448/1000\n",
      "177/177 [==============================] - 0s 174us/step - loss: 0.0309 - accuracy: 0.9774 - val_loss: 4.0329 - val_accuracy: 0.5789\n",
      "Epoch 449/1000\n",
      "177/177 [==============================] - 0s 167us/step - loss: 0.0305 - accuracy: 0.9831 - val_loss: 4.0565 - val_accuracy: 0.5658\n",
      "Epoch 450/1000\n",
      "177/177 [==============================] - 0s 140us/step - loss: 0.0307 - accuracy: 0.9774 - val_loss: 4.0586 - val_accuracy: 0.5789\n",
      "Epoch 451/1000\n",
      "177/177 [==============================] - 0s 158us/step - loss: 0.0322 - accuracy: 0.9831 - val_loss: 4.0999 - val_accuracy: 0.5658\n",
      "Epoch 452/1000\n",
      "177/177 [==============================] - 0s 161us/step - loss: 0.0305 - accuracy: 0.9887 - val_loss: 4.0891 - val_accuracy: 0.5658\n",
      "Epoch 453/1000\n",
      "177/177 [==============================] - 0s 130us/step - loss: 0.0308 - accuracy: 0.9831 - val_loss: 4.0470 - val_accuracy: 0.5658\n",
      "Epoch 454/1000\n",
      "177/177 [==============================] - 0s 139us/step - loss: 0.0316 - accuracy: 0.9887 - val_loss: 4.0606 - val_accuracy: 0.5789\n",
      "Epoch 455/1000\n",
      "177/177 [==============================] - 0s 172us/step - loss: 0.0307 - accuracy: 0.9831 - val_loss: 4.0915 - val_accuracy: 0.5789\n",
      "Epoch 456/1000\n",
      "177/177 [==============================] - 0s 161us/step - loss: 0.0302 - accuracy: 0.9887 - val_loss: 4.1028 - val_accuracy: 0.5789\n",
      "Epoch 457/1000\n",
      "177/177 [==============================] - 0s 215us/step - loss: 0.0305 - accuracy: 0.9887 - val_loss: 4.1114 - val_accuracy: 0.5658\n",
      "Epoch 458/1000\n",
      "177/177 [==============================] - 0s 274us/step - loss: 0.0301 - accuracy: 0.9774 - val_loss: 4.0845 - val_accuracy: 0.5263\n",
      "Epoch 459/1000\n",
      "177/177 [==============================] - 0s 160us/step - loss: 0.0663 - accuracy: 0.9831 - val_loss: 4.2770 - val_accuracy: 0.5526\n",
      "Epoch 460/1000\n",
      "177/177 [==============================] - 0s 191us/step - loss: 0.0617 - accuracy: 0.9887 - val_loss: 4.3735 - val_accuracy: 0.5526\n",
      "Epoch 461/1000\n",
      "177/177 [==============================] - 0s 305us/step - loss: 0.0556 - accuracy: 0.9887 - val_loss: 4.3666 - val_accuracy: 0.5526\n",
      "Epoch 462/1000\n",
      "177/177 [==============================] - 0s 266us/step - loss: 0.0565 - accuracy: 0.9774 - val_loss: 4.4251 - val_accuracy: 0.5526\n",
      "Epoch 463/1000\n",
      "177/177 [==============================] - 0s 151us/step - loss: 0.1247 - accuracy: 0.9718 - val_loss: 4.1970 - val_accuracy: 0.5658\n",
      "Epoch 464/1000\n",
      "177/177 [==============================] - 0s 150us/step - loss: 0.2169 - accuracy: 0.9605 - val_loss: 4.3810 - val_accuracy: 0.5526\n",
      "Epoch 465/1000\n",
      "177/177 [==============================] - 0s 156us/step - loss: 0.3374 - accuracy: 0.9605 - val_loss: 4.3744 - val_accuracy: 0.5789\n",
      "Epoch 466/1000\n",
      "177/177 [==============================] - 0s 145us/step - loss: 0.3934 - accuracy: 0.9605 - val_loss: 4.4058 - val_accuracy: 0.5789\n",
      "Epoch 467/1000\n",
      "177/177 [==============================] - 0s 148us/step - loss: 1.0643 - accuracy: 0.9605 - val_loss: 4.3142 - val_accuracy: 0.5921\n",
      "Epoch 468/1000\n",
      "177/177 [==============================] - 0s 149us/step - loss: 0.0463 - accuracy: 0.9718 - val_loss: 4.2263 - val_accuracy: 0.5789\n",
      "Epoch 469/1000\n",
      "177/177 [==============================] - 0s 154us/step - loss: 0.3032 - accuracy: 0.9661 - val_loss: 4.6356 - val_accuracy: 0.5658\n",
      "Epoch 470/1000\n",
      "177/177 [==============================] - 0s 158us/step - loss: 0.9232 - accuracy: 0.9605 - val_loss: 4.3832 - val_accuracy: 0.5921\n",
      "Epoch 471/1000\n",
      "177/177 [==============================] - 0s 163us/step - loss: 0.1421 - accuracy: 0.9718 - val_loss: 4.1511 - val_accuracy: 0.6053\n",
      "Epoch 472/1000\n",
      "177/177 [==============================] - 0s 199us/step - loss: 0.1024 - accuracy: 0.9831 - val_loss: 4.0700 - val_accuracy: 0.6053\n",
      "Epoch 473/1000\n",
      "177/177 [==============================] - 0s 276us/step - loss: 0.1329 - accuracy: 0.9718 - val_loss: 4.2055 - val_accuracy: 0.5658\n",
      "Epoch 474/1000\n",
      "177/177 [==============================] - 0s 215us/step - loss: 0.1590 - accuracy: 0.9661 - val_loss: 4.1669 - val_accuracy: 0.5658\n",
      "Epoch 475/1000\n",
      "177/177 [==============================] - 0s 175us/step - loss: 0.0992 - accuracy: 0.9774 - val_loss: 4.2576 - val_accuracy: 0.5526\n",
      "Epoch 476/1000\n",
      "177/177 [==============================] - 0s 152us/step - loss: 0.1870 - accuracy: 0.9774 - val_loss: 4.1481 - val_accuracy: 0.5658\n",
      "Epoch 477/1000\n",
      "177/177 [==============================] - 0s 172us/step - loss: 0.0463 - accuracy: 0.9718 - val_loss: 4.3063 - val_accuracy: 0.5789\n",
      "Epoch 478/1000\n",
      "177/177 [==============================] - 0s 147us/step - loss: 0.0761 - accuracy: 0.9718 - val_loss: 4.0814 - val_accuracy: 0.5921\n",
      "Epoch 479/1000\n",
      "177/177 [==============================] - 0s 155us/step - loss: 0.3014 - accuracy: 0.9435 - val_loss: 4.0931 - val_accuracy: 0.5789\n",
      "Epoch 480/1000\n",
      "177/177 [==============================] - 0s 150us/step - loss: 0.1578 - accuracy: 0.9718 - val_loss: 4.2848 - val_accuracy: 0.5658\n",
      "Epoch 481/1000\n",
      "177/177 [==============================] - 0s 164us/step - loss: 0.0715 - accuracy: 0.9718 - val_loss: 4.2379 - val_accuracy: 0.5789\n",
      "Epoch 482/1000\n",
      "177/177 [==============================] - 0s 211us/step - loss: 0.1438 - accuracy: 0.9774 - val_loss: 4.1387 - val_accuracy: 0.5789\n",
      "Epoch 483/1000\n",
      "177/177 [==============================] - 0s 260us/step - loss: 0.0386 - accuracy: 0.9774 - val_loss: 4.1928 - val_accuracy: 0.5789\n",
      "Epoch 484/1000\n",
      "177/177 [==============================] - 0s 153us/step - loss: 0.0981 - accuracy: 0.9718 - val_loss: 4.1252 - val_accuracy: 0.5789\n",
      "Epoch 485/1000\n",
      "177/177 [==============================] - 0s 164us/step - loss: 0.1697 - accuracy: 0.9774 - val_loss: 4.0905 - val_accuracy: 0.5789\n",
      "Epoch 486/1000\n",
      "177/177 [==============================] - 0s 161us/step - loss: 0.0840 - accuracy: 0.9774 - val_loss: 4.0674 - val_accuracy: 0.5921\n",
      "Epoch 487/1000\n",
      "177/177 [==============================] - 0s 143us/step - loss: 0.1834 - accuracy: 0.9774 - val_loss: 4.1064 - val_accuracy: 0.6053\n",
      "Epoch 488/1000\n",
      "177/177 [==============================] - 0s 142us/step - loss: 0.1637 - accuracy: 0.9661 - val_loss: 4.3323 - val_accuracy: 0.5658\n",
      "Epoch 489/1000\n",
      "177/177 [==============================] - 0s 154us/step - loss: 0.0315 - accuracy: 0.9718 - val_loss: 4.1337 - val_accuracy: 0.5921\n",
      "Epoch 490/1000\n",
      "177/177 [==============================] - 0s 150us/step - loss: 0.1082 - accuracy: 0.9774 - val_loss: 4.2643 - val_accuracy: 0.5658\n",
      "Epoch 491/1000\n",
      "177/177 [==============================] - 0s 149us/step - loss: 0.1702 - accuracy: 0.9718 - val_loss: 4.1685 - val_accuracy: 0.5658\n",
      "Epoch 492/1000\n",
      "177/177 [==============================] - 0s 221us/step - loss: 0.0313 - accuracy: 0.9887 - val_loss: 4.0651 - val_accuracy: 0.5921\n",
      "Epoch 493/1000\n",
      "177/177 [==============================] - 0s 220us/step - loss: 0.1418 - accuracy: 0.9718 - val_loss: 4.2289 - val_accuracy: 0.5789\n",
      "Epoch 494/1000\n",
      "177/177 [==============================] - 0s 174us/step - loss: 0.0307 - accuracy: 0.9831 - val_loss: 4.1207 - val_accuracy: 0.5789\n",
      "Epoch 495/1000\n",
      "177/177 [==============================] - 0s 167us/step - loss: 0.0687 - accuracy: 0.9774 - val_loss: 4.4983 - val_accuracy: 0.5526\n",
      "Epoch 496/1000\n",
      "177/177 [==============================] - 0s 181us/step - loss: 0.2333 - accuracy: 0.9718 - val_loss: 4.2467 - val_accuracy: 0.5658\n",
      "Epoch 497/1000\n",
      "177/177 [==============================] - 0s 151us/step - loss: 0.0493 - accuracy: 0.9774 - val_loss: 4.3026 - val_accuracy: 0.5526\n",
      "Epoch 498/1000\n",
      "177/177 [==============================] - 0s 146us/step - loss: 0.1935 - accuracy: 0.9718 - val_loss: 4.2630 - val_accuracy: 0.5658\n",
      "Epoch 499/1000\n",
      "177/177 [==============================] - 0s 156us/step - loss: 0.0404 - accuracy: 0.9831 - val_loss: 4.1940 - val_accuracy: 0.5658\n",
      "Epoch 500/1000\n",
      "177/177 [==============================] - 0s 142us/step - loss: 0.0688 - accuracy: 0.9831 - val_loss: 4.0812 - val_accuracy: 0.5921\n",
      "Epoch 501/1000\n",
      "177/177 [==============================] - 0s 153us/step - loss: 0.2032 - accuracy: 0.9774 - val_loss: 4.1196 - val_accuracy: 0.5921\n",
      "Epoch 502/1000\n",
      "177/177 [==============================] - 0s 162us/step - loss: 0.0343 - accuracy: 0.9774 - val_loss: 4.4907 - val_accuracy: 0.5526\n",
      "Epoch 503/1000\n",
      "177/177 [==============================] - 0s 195us/step - loss: 0.3272 - accuracy: 0.9661 - val_loss: 4.1181 - val_accuracy: 0.5921\n",
      "Epoch 504/1000\n",
      "177/177 [==============================] - 0s 313us/step - loss: 0.1487 - accuracy: 0.9718 - val_loss: 4.2460 - val_accuracy: 0.5789\n",
      "Epoch 505/1000\n",
      "177/177 [==============================] - 0s 320us/step - loss: 0.1414 - accuracy: 0.9605 - val_loss: 4.1898 - val_accuracy: 0.5789\n",
      "Epoch 506/1000\n",
      "177/177 [==============================] - 0s 338us/step - loss: 0.3302 - accuracy: 0.9605 - val_loss: 4.2150 - val_accuracy: 0.5658\n",
      "Epoch 507/1000\n",
      "177/177 [==============================] - 0s 366us/step - loss: 0.2852 - accuracy: 0.9661 - val_loss: 4.6516 - val_accuracy: 0.5526\n",
      "Epoch 508/1000\n",
      "177/177 [==============================] - 0s 201us/step - loss: 0.3168 - accuracy: 0.9605 - val_loss: 4.1770 - val_accuracy: 0.6053\n",
      "Epoch 509/1000\n",
      "177/177 [==============================] - 0s 176us/step - loss: 0.2723 - accuracy: 0.9661 - val_loss: 4.2793 - val_accuracy: 0.5658\n",
      "Epoch 510/1000\n",
      "177/177 [==============================] - 0s 154us/step - loss: 0.1444 - accuracy: 0.9774 - val_loss: 4.4544 - val_accuracy: 0.5789\n",
      "Epoch 511/1000\n",
      "177/177 [==============================] - 0s 164us/step - loss: 0.1273 - accuracy: 0.9718 - val_loss: 4.1502 - val_accuracy: 0.6053\n",
      "Epoch 512/1000\n",
      "177/177 [==============================] - 0s 172us/step - loss: 0.1515 - accuracy: 0.9831 - val_loss: 4.1922 - val_accuracy: 0.5789\n",
      "Epoch 513/1000\n",
      "177/177 [==============================] - 0s 157us/step - loss: 0.1099 - accuracy: 0.9718 - val_loss: 4.1720 - val_accuracy: 0.5789\n",
      "Epoch 514/1000\n",
      "177/177 [==============================] - 0s 154us/step - loss: 0.0960 - accuracy: 0.9774 - val_loss: 4.2012 - val_accuracy: 0.5789\n",
      "Epoch 515/1000\n",
      "177/177 [==============================] - 0s 169us/step - loss: 0.0341 - accuracy: 0.9831 - val_loss: 4.3024 - val_accuracy: 0.5789\n",
      "Epoch 516/1000\n",
      "177/177 [==============================] - 0s 169us/step - loss: 0.0355 - accuracy: 0.9774 - val_loss: 4.2703 - val_accuracy: 0.5789\n",
      "Epoch 517/1000\n",
      "177/177 [==============================] - 0s 229us/step - loss: 0.0439 - accuracy: 0.9718 - val_loss: 4.2252 - val_accuracy: 0.5921\n",
      "Epoch 518/1000\n",
      "177/177 [==============================] - 0s 274us/step - loss: 0.1320 - accuracy: 0.9718 - val_loss: 4.3203 - val_accuracy: 0.5789\n",
      "Epoch 519/1000\n",
      "177/177 [==============================] - 0s 185us/step - loss: 0.0577 - accuracy: 0.9718 - val_loss: 4.2280 - val_accuracy: 0.5921\n",
      "Epoch 520/1000\n",
      "177/177 [==============================] - 0s 182us/step - loss: 0.1240 - accuracy: 0.9774 - val_loss: 4.3626 - val_accuracy: 0.5658\n",
      "Epoch 521/1000\n",
      "177/177 [==============================] - 0s 176us/step - loss: 0.1374 - accuracy: 0.9661 - val_loss: 4.2348 - val_accuracy: 0.5789\n",
      "Epoch 522/1000\n",
      "177/177 [==============================] - 0s 163us/step - loss: 0.0315 - accuracy: 0.9831 - val_loss: 4.3767 - val_accuracy: 0.5658\n",
      "Epoch 523/1000\n",
      "177/177 [==============================] - 0s 155us/step - loss: 0.1684 - accuracy: 0.9718 - val_loss: 4.2531 - val_accuracy: 0.5658\n",
      "Epoch 524/1000\n",
      "177/177 [==============================] - 0s 150us/step - loss: 0.0595 - accuracy: 0.9661 - val_loss: 4.2955 - val_accuracy: 0.5789\n",
      "Epoch 525/1000\n",
      "177/177 [==============================] - 0s 152us/step - loss: 0.0527 - accuracy: 0.9831 - val_loss: 4.2062 - val_accuracy: 0.5921\n",
      "Epoch 526/1000\n",
      "177/177 [==============================] - 0s 226us/step - loss: 0.1443 - accuracy: 0.9831 - val_loss: 4.4072 - val_accuracy: 0.5658\n",
      "Epoch 527/1000\n",
      "177/177 [==============================] - 0s 227us/step - loss: 0.0755 - accuracy: 0.9774 - val_loss: 4.2171 - val_accuracy: 0.5789\n",
      "Epoch 528/1000\n",
      "177/177 [==============================] - 0s 226us/step - loss: 0.1204 - accuracy: 0.9718 - val_loss: 4.2694 - val_accuracy: 0.5789\n",
      "Epoch 529/1000\n",
      "177/177 [==============================] - 0s 219us/step - loss: 0.1245 - accuracy: 0.9718 - val_loss: 4.3084 - val_accuracy: 0.5658\n",
      "Epoch 530/1000\n",
      "177/177 [==============================] - 0s 225us/step - loss: 0.0994 - accuracy: 0.9718 - val_loss: 4.2257 - val_accuracy: 0.5921\n",
      "Epoch 531/1000\n",
      "177/177 [==============================] - 0s 147us/step - loss: 0.0466 - accuracy: 0.9831 - val_loss: 4.2530 - val_accuracy: 0.5789\n",
      "Epoch 532/1000\n",
      "177/177 [==============================] - 0s 140us/step - loss: 0.0396 - accuracy: 0.9831 - val_loss: 4.3980 - val_accuracy: 0.5658\n",
      "Epoch 533/1000\n",
      "177/177 [==============================] - 0s 167us/step - loss: 0.2114 - accuracy: 0.9605 - val_loss: 4.4224 - val_accuracy: 0.5658\n",
      "Epoch 534/1000\n",
      "177/177 [==============================] - 0s 149us/step - loss: 0.0992 - accuracy: 0.9661 - val_loss: 4.2610 - val_accuracy: 0.5789\n",
      "Epoch 535/1000\n",
      "177/177 [==============================] - 0s 150us/step - loss: 0.0505 - accuracy: 0.9774 - val_loss: 4.3561 - val_accuracy: 0.5658\n",
      "Epoch 536/1000\n",
      "177/177 [==============================] - 0s 173us/step - loss: 0.1661 - accuracy: 0.9718 - val_loss: 4.3580 - val_accuracy: 0.5921\n",
      "Epoch 537/1000\n",
      "177/177 [==============================] - 0s 176us/step - loss: 0.1430 - accuracy: 0.9774 - val_loss: 4.3634 - val_accuracy: 0.5658\n",
      "Epoch 538/1000\n",
      "177/177 [==============================] - 0s 279us/step - loss: 0.1131 - accuracy: 0.9661 - val_loss: 4.2160 - val_accuracy: 0.5789\n",
      "Epoch 539/1000\n",
      "177/177 [==============================] - 0s 226us/step - loss: 0.0503 - accuracy: 0.9718 - val_loss: 4.3863 - val_accuracy: 0.5789\n",
      "Epoch 540/1000\n",
      "177/177 [==============================] - 0s 238us/step - loss: 0.1380 - accuracy: 0.9661 - val_loss: 4.2598 - val_accuracy: 0.6053\n",
      "Epoch 541/1000\n",
      "177/177 [==============================] - 0s 226us/step - loss: 0.2088 - accuracy: 0.9605 - val_loss: 4.4511 - val_accuracy: 0.5789\n",
      "Epoch 542/1000\n",
      "177/177 [==============================] - 0s 202us/step - loss: 0.1255 - accuracy: 0.9718 - val_loss: 4.3884 - val_accuracy: 0.5789\n",
      "Epoch 543/1000\n",
      "177/177 [==============================] - 0s 186us/step - loss: 0.0367 - accuracy: 0.9774 - val_loss: 4.2540 - val_accuracy: 0.5921\n",
      "Epoch 544/1000\n",
      "177/177 [==============================] - 0s 171us/step - loss: 0.1293 - accuracy: 0.9774 - val_loss: 4.4574 - val_accuracy: 0.5658\n",
      "Epoch 545/1000\n",
      "177/177 [==============================] - 0s 171us/step - loss: 0.1569 - accuracy: 0.9718 - val_loss: 4.4156 - val_accuracy: 0.5658\n",
      "Epoch 546/1000\n",
      "177/177 [==============================] - 0s 158us/step - loss: 0.1047 - accuracy: 0.9774 - val_loss: 4.2521 - val_accuracy: 0.5921\n",
      "Epoch 547/1000\n",
      "177/177 [==============================] - 0s 156us/step - loss: 0.0345 - accuracy: 0.9718 - val_loss: 4.5332 - val_accuracy: 0.5526\n",
      "Epoch 548/1000\n",
      "177/177 [==============================] - 0s 152us/step - loss: 0.1718 - accuracy: 0.9718 - val_loss: 4.3898 - val_accuracy: 0.5526\n",
      "Epoch 549/1000\n",
      "177/177 [==============================] - 0s 149us/step - loss: 0.1036 - accuracy: 0.9831 - val_loss: 4.5928 - val_accuracy: 0.5789\n",
      "Epoch 550/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177/177 [==============================] - 0s 144us/step - loss: 0.1287 - accuracy: 0.9718 - val_loss: 4.5564 - val_accuracy: 0.5526\n",
      "Epoch 551/1000\n",
      "177/177 [==============================] - 0s 167us/step - loss: 0.1621 - accuracy: 0.9718 - val_loss: 4.5741 - val_accuracy: 0.5526\n",
      "Epoch 552/1000\n",
      "177/177 [==============================] - 0s 162us/step - loss: 0.0820 - accuracy: 0.9774 - val_loss: 4.4573 - val_accuracy: 0.5789\n",
      "Epoch 553/1000\n",
      "177/177 [==============================] - 0s 179us/step - loss: 0.1233 - accuracy: 0.9774 - val_loss: 4.6517 - val_accuracy: 0.5395\n",
      "Epoch 554/1000\n",
      "177/177 [==============================] - 0s 198us/step - loss: 0.2046 - accuracy: 0.9831 - val_loss: 4.6234 - val_accuracy: 0.5395\n",
      "Epoch 555/1000\n",
      "177/177 [==============================] - 0s 204us/step - loss: 0.0941 - accuracy: 0.9774 - val_loss: 4.2745 - val_accuracy: 0.5395\n",
      "Epoch 556/1000\n",
      "177/177 [==============================] - 0s 186us/step - loss: 0.2927 - accuracy: 0.9435 - val_loss: 4.2999 - val_accuracy: 0.6053\n",
      "Epoch 557/1000\n",
      "177/177 [==============================] - 0s 161us/step - loss: 0.1271 - accuracy: 0.9718 - val_loss: 4.5391 - val_accuracy: 0.5658\n",
      "Epoch 558/1000\n",
      "177/177 [==============================] - 0s 160us/step - loss: 0.1145 - accuracy: 0.9831 - val_loss: 4.4399 - val_accuracy: 0.5921\n",
      "Epoch 559/1000\n",
      "177/177 [==============================] - 0s 147us/step - loss: 0.0375 - accuracy: 0.9831 - val_loss: 4.5012 - val_accuracy: 0.5658\n",
      "Epoch 560/1000\n",
      "177/177 [==============================] - 0s 162us/step - loss: 0.0810 - accuracy: 0.9774 - val_loss: 4.2223 - val_accuracy: 0.5658\n",
      "Epoch 561/1000\n",
      "177/177 [==============================] - 0s 157us/step - loss: 0.1451 - accuracy: 0.9774 - val_loss: 4.1399 - val_accuracy: 0.5789\n",
      "Epoch 562/1000\n",
      "177/177 [==============================] - 0s 152us/step - loss: 0.0372 - accuracy: 0.9774 - val_loss: 4.3259 - val_accuracy: 0.5658\n",
      "Epoch 563/1000\n",
      "177/177 [==============================] - 0s 159us/step - loss: 0.0552 - accuracy: 0.9661 - val_loss: 4.1575 - val_accuracy: 0.6053\n",
      "Epoch 564/1000\n",
      "177/177 [==============================] - 0s 141us/step - loss: 0.1455 - accuracy: 0.9774 - val_loss: 4.4265 - val_accuracy: 0.5526\n",
      "Epoch 565/1000\n",
      "177/177 [==============================] - 0s 150us/step - loss: 0.1003 - accuracy: 0.9718 - val_loss: 4.3821 - val_accuracy: 0.5658\n",
      "Epoch 566/1000\n",
      "177/177 [==============================] - 0s 169us/step - loss: 0.1059 - accuracy: 0.9718 - val_loss: 4.2896 - val_accuracy: 0.5658\n",
      "Epoch 567/1000\n",
      "177/177 [==============================] - 0s 149us/step - loss: 0.0713 - accuracy: 0.9718 - val_loss: 4.3081 - val_accuracy: 0.5658\n",
      "Epoch 568/1000\n",
      "177/177 [==============================] - 0s 283us/step - loss: 0.0626 - accuracy: 0.9774 - val_loss: 4.2158 - val_accuracy: 0.5921\n",
      "Epoch 569/1000\n",
      "177/177 [==============================] - 0s 220us/step - loss: 0.1208 - accuracy: 0.9831 - val_loss: 4.3757 - val_accuracy: 0.5789\n",
      "Epoch 570/1000\n",
      "177/177 [==============================] - 0s 318us/step - loss: 0.0565 - accuracy: 0.9661 - val_loss: 4.2756 - val_accuracy: 0.5789\n",
      "Epoch 571/1000\n",
      "177/177 [==============================] - 0s 210us/step - loss: 0.0283 - accuracy: 0.9887 - val_loss: 4.3413 - val_accuracy: 0.5789\n",
      "Epoch 572/1000\n",
      "177/177 [==============================] - 0s 258us/step - loss: 0.0284 - accuracy: 0.9831 - val_loss: 4.4548 - val_accuracy: 0.5658\n",
      "Epoch 573/1000\n",
      "177/177 [==============================] - 0s 221us/step - loss: 0.0278 - accuracy: 0.9887 - val_loss: 4.4166 - val_accuracy: 0.5658\n",
      "Epoch 574/1000\n",
      "177/177 [==============================] - 0s 212us/step - loss: 0.0293 - accuracy: 0.9774 - val_loss: 4.3551 - val_accuracy: 0.5789\n",
      "Epoch 575/1000\n",
      "177/177 [==============================] - 0s 221us/step - loss: 0.0277 - accuracy: 0.9887 - val_loss: 4.3760 - val_accuracy: 0.5658\n",
      "Epoch 576/1000\n",
      "177/177 [==============================] - 0s 317us/step - loss: 0.0280 - accuracy: 0.9887 - val_loss: 4.3598 - val_accuracy: 0.5658\n",
      "Epoch 577/1000\n",
      "177/177 [==============================] - 0s 481us/step - loss: 0.0276 - accuracy: 0.9887 - val_loss: 4.3415 - val_accuracy: 0.5658\n",
      "Epoch 578/1000\n",
      "177/177 [==============================] - 0s 244us/step - loss: 0.0284 - accuracy: 0.9887 - val_loss: 4.3230 - val_accuracy: 0.5789\n",
      "Epoch 579/1000\n",
      "177/177 [==============================] - 0s 262us/step - loss: 0.0970 - accuracy: 0.9718 - val_loss: 4.3587 - val_accuracy: 0.5789\n",
      "Epoch 580/1000\n",
      "177/177 [==============================] - 0s 261us/step - loss: 0.1436 - accuracy: 0.9605 - val_loss: 4.3626 - val_accuracy: 0.5789\n",
      "Epoch 581/1000\n",
      "177/177 [==============================] - 0s 243us/step - loss: 0.1134 - accuracy: 0.9605 - val_loss: 4.5114 - val_accuracy: 0.5658\n",
      "Epoch 582/1000\n",
      "177/177 [==============================] - 0s 190us/step - loss: 0.0354 - accuracy: 0.9831 - val_loss: 4.3879 - val_accuracy: 0.5658\n",
      "Epoch 583/1000\n",
      "177/177 [==============================] - 0s 157us/step - loss: 0.0451 - accuracy: 0.9774 - val_loss: 4.3719 - val_accuracy: 0.5658\n",
      "Epoch 584/1000\n",
      "177/177 [==============================] - 0s 165us/step - loss: 0.0283 - accuracy: 0.9831 - val_loss: 4.3027 - val_accuracy: 0.5658\n",
      "Epoch 585/1000\n",
      "177/177 [==============================] - 0s 181us/step - loss: 0.0421 - accuracy: 0.9774 - val_loss: 4.2669 - val_accuracy: 0.5789\n",
      "Epoch 586/1000\n",
      "177/177 [==============================] - 0s 250us/step - loss: 0.1468 - accuracy: 0.9774 - val_loss: 4.3422 - val_accuracy: 0.5789\n",
      "Epoch 587/1000\n",
      "177/177 [==============================] - 0s 311us/step - loss: 0.0284 - accuracy: 0.9831 - val_loss: 4.6373 - val_accuracy: 0.5658\n",
      "Epoch 588/1000\n",
      "177/177 [==============================] - 0s 515us/step - loss: 0.1092 - accuracy: 0.9774 - val_loss: 4.4095 - val_accuracy: 0.5658\n",
      "Epoch 589/1000\n",
      "177/177 [==============================] - 0s 103us/step - loss: 0.1682 - accuracy: 0.9774 - val_loss: 4.5387 - val_accuracy: 0.5789\n",
      "Epoch 590/1000\n",
      "177/177 [==============================] - 0s 133us/step - loss: 0.0609 - accuracy: 0.9718 - val_loss: 4.4621 - val_accuracy: 0.5789\n",
      "Epoch 591/1000\n",
      "177/177 [==============================] - 0s 240us/step - loss: 0.0901 - accuracy: 0.9774 - val_loss: 4.6010 - val_accuracy: 0.5526\n",
      "Epoch 592/1000\n",
      "177/177 [==============================] - 0s 611us/step - loss: 0.1219 - accuracy: 0.9774 - val_loss: 4.2762 - val_accuracy: 0.5789\n",
      "Epoch 593/1000\n",
      "177/177 [==============================] - 0s 264us/step - loss: 0.1062 - accuracy: 0.9831 - val_loss: 4.5040 - val_accuracy: 0.5526\n",
      "Epoch 594/1000\n",
      "177/177 [==============================] - 0s 233us/step - loss: 0.1489 - accuracy: 0.9831 - val_loss: 4.4513 - val_accuracy: 0.5526\n",
      "Epoch 595/1000\n",
      "177/177 [==============================] - 0s 293us/step - loss: 0.0716 - accuracy: 0.9774 - val_loss: 4.4878 - val_accuracy: 0.5658\n",
      "Epoch 596/1000\n",
      "177/177 [==============================] - 0s 221us/step - loss: 0.1673 - accuracy: 0.9718 - val_loss: 4.6200 - val_accuracy: 0.5395\n",
      "Epoch 597/1000\n",
      "177/177 [==============================] - 0s 252us/step - loss: 0.0392 - accuracy: 0.9831 - val_loss: 4.4537 - val_accuracy: 0.5526\n",
      "Epoch 598/1000\n",
      "177/177 [==============================] - 0s 1ms/step - loss: 0.0573 - accuracy: 0.9831 - val_loss: 4.3387 - val_accuracy: 0.5789\n",
      "Epoch 599/1000\n",
      "177/177 [==============================] - 0s 276us/step - loss: 0.1659 - accuracy: 0.9774 - val_loss: 4.4557 - val_accuracy: 0.5658\n",
      "Epoch 600/1000\n",
      "177/177 [==============================] - 0s 286us/step - loss: 0.0378 - accuracy: 0.9831 - val_loss: 4.4199 - val_accuracy: 0.5789\n",
      "Epoch 601/1000\n",
      " 16/177 [=>............................] - ETA: 0s - loss: 0.0496 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/keras/callbacks/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.140514). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177/177 [==============================] - 0s 634us/step - loss: 0.1169 - accuracy: 0.9774 - val_loss: 4.4344 - val_accuracy: 0.5789\n",
      "Epoch 602/1000\n",
      "177/177 [==============================] - 0s 201us/step - loss: 0.1257 - accuracy: 0.9774 - val_loss: 4.5802 - val_accuracy: 0.5789\n",
      "Epoch 603/1000\n",
      "177/177 [==============================] - 0s 288us/step - loss: 0.0289 - accuracy: 0.9774 - val_loss: 4.4825 - val_accuracy: 0.5658\n",
      "Epoch 604/1000\n",
      "177/177 [==============================] - 0s 285us/step - loss: 0.1082 - accuracy: 0.9774 - val_loss: 4.5922 - val_accuracy: 0.5658\n",
      "Epoch 605/1000\n",
      "177/177 [==============================] - 0s 172us/step - loss: 0.1058 - accuracy: 0.9831 - val_loss: 4.4435 - val_accuracy: 0.5658\n",
      "Epoch 606/1000\n",
      "177/177 [==============================] - 0s 146us/step - loss: 0.0814 - accuracy: 0.9774 - val_loss: 4.5428 - val_accuracy: 0.5658\n",
      "Epoch 607/1000\n",
      "177/177 [==============================] - 0s 152us/step - loss: 0.1558 - accuracy: 0.9718 - val_loss: 4.6099 - val_accuracy: 0.5658\n",
      "Epoch 608/1000\n",
      "177/177 [==============================] - 0s 249us/step - loss: 0.0394 - accuracy: 0.9831 - val_loss: 4.5521 - val_accuracy: 0.5526\n",
      "Epoch 609/1000\n",
      "177/177 [==============================] - 0s 158us/step - loss: 0.0663 - accuracy: 0.9774 - val_loss: 4.3912 - val_accuracy: 0.5921\n",
      "Epoch 610/1000\n",
      "177/177 [==============================] - 0s 134us/step - loss: 0.1252 - accuracy: 0.9774 - val_loss: 4.4542 - val_accuracy: 0.5789\n",
      "Epoch 611/1000\n",
      "177/177 [==============================] - 0s 148us/step - loss: 0.0283 - accuracy: 0.9831 - val_loss: 4.7711 - val_accuracy: 0.5658\n",
      "Epoch 612/1000\n",
      "177/177 [==============================] - 0s 137us/step - loss: 0.1420 - accuracy: 0.9831 - val_loss: 4.3715 - val_accuracy: 0.5921\n",
      "Epoch 613/1000\n",
      "177/177 [==============================] - 0s 143us/step - loss: 0.1694 - accuracy: 0.9661 - val_loss: 4.4408 - val_accuracy: 0.5789\n",
      "Epoch 614/1000\n",
      "177/177 [==============================] - 0s 140us/step - loss: 0.0373 - accuracy: 0.9831 - val_loss: 4.7730 - val_accuracy: 0.5658\n",
      "Epoch 615/1000\n",
      "177/177 [==============================] - 0s 147us/step - loss: 0.1526 - accuracy: 0.9774 - val_loss: 4.4260 - val_accuracy: 0.5789\n",
      "Epoch 616/1000\n",
      "177/177 [==============================] - 0s 168us/step - loss: 0.1586 - accuracy: 0.9548 - val_loss: 4.6812 - val_accuracy: 0.6053\n",
      "Epoch 617/1000\n",
      "177/177 [==============================] - 0s 144us/step - loss: 0.6955 - accuracy: 0.9548 - val_loss: 4.8610 - val_accuracy: 0.5658\n",
      "Epoch 618/1000\n",
      "177/177 [==============================] - 0s 224us/step - loss: 0.1808 - accuracy: 0.9774 - val_loss: 4.6698 - val_accuracy: 0.5789\n",
      "Epoch 619/1000\n",
      "177/177 [==============================] - 0s 334us/step - loss: 0.3436 - accuracy: 0.9605 - val_loss: 4.6618 - val_accuracy: 0.5789\n",
      "Epoch 620/1000\n",
      "177/177 [==============================] - 0s 246us/step - loss: 0.1416 - accuracy: 0.9718 - val_loss: 4.5332 - val_accuracy: 0.5789\n",
      "Epoch 621/1000\n",
      "177/177 [==============================] - 0s 294us/step - loss: 0.1379 - accuracy: 0.9718 - val_loss: 4.8442 - val_accuracy: 0.5658\n",
      "Epoch 622/1000\n",
      "177/177 [==============================] - 0s 224us/step - loss: 0.5484 - accuracy: 0.9661 - val_loss: 4.4008 - val_accuracy: 0.5395\n",
      "Epoch 623/1000\n",
      "177/177 [==============================] - 0s 252us/step - loss: 0.4180 - accuracy: 0.9492 - val_loss: 4.6158 - val_accuracy: 0.5658\n",
      "Epoch 624/1000\n",
      "177/177 [==============================] - 0s 320us/step - loss: 0.1871 - accuracy: 0.9605 - val_loss: 5.0534 - val_accuracy: 0.5789\n",
      "Epoch 625/1000\n",
      "177/177 [==============================] - 0s 210us/step - loss: 0.6810 - accuracy: 0.9492 - val_loss: 4.6077 - val_accuracy: 0.5658\n",
      "Epoch 626/1000\n",
      "177/177 [==============================] - 0s 197us/step - loss: 0.0884 - accuracy: 0.9831 - val_loss: 4.4110 - val_accuracy: 0.5921\n",
      "Epoch 627/1000\n",
      "177/177 [==============================] - 0s 223us/step - loss: 0.0336 - accuracy: 0.9774 - val_loss: 4.4916 - val_accuracy: 0.5658\n",
      "Epoch 628/1000\n",
      "177/177 [==============================] - 0s 184us/step - loss: 0.0314 - accuracy: 0.9774 - val_loss: 4.6107 - val_accuracy: 0.5789\n",
      "Epoch 629/1000\n",
      "177/177 [==============================] - ETA: 0s - loss: 0.0460 - accuracy: 0.93 - 0s 229us/step - loss: 0.1254 - accuracy: 0.9774 - val_loss: 4.7384 - val_accuracy: 0.5658\n",
      "Epoch 630/1000\n",
      "177/177 [==============================] - 0s 225us/step - loss: 0.0667 - accuracy: 0.9831 - val_loss: 4.4748 - val_accuracy: 0.6053\n",
      "Epoch 631/1000\n",
      "177/177 [==============================] - 0s 223us/step - loss: 0.1870 - accuracy: 0.9718 - val_loss: 4.5523 - val_accuracy: 0.5789\n",
      "Epoch 632/1000\n",
      "177/177 [==============================] - 0s 181us/step - loss: 0.0380 - accuracy: 0.9831 - val_loss: 4.5833 - val_accuracy: 0.5789\n",
      "Epoch 633/1000\n",
      "177/177 [==============================] - 0s 204us/step - loss: 0.0936 - accuracy: 0.9718 - val_loss: 4.5019 - val_accuracy: 0.5789\n",
      "Epoch 634/1000\n",
      "177/177 [==============================] - 0s 223us/step - loss: 2.3246 - accuracy: 0.9040 - val_loss: 4.9895 - val_accuracy: 0.5526\n",
      "Epoch 635/1000\n",
      "177/177 [==============================] - 0s 264us/step - loss: 2.4622 - accuracy: 0.8983 - val_loss: 4.8675 - val_accuracy: 0.5526\n",
      "Epoch 636/1000\n",
      "177/177 [==============================] - 0s 303us/step - loss: 0.9583 - accuracy: 0.9040 - val_loss: 4.9187 - val_accuracy: 0.5921\n",
      "Epoch 637/1000\n",
      "177/177 [==============================] - 0s 272us/step - loss: 0.8105 - accuracy: 0.8644 - val_loss: 4.5396 - val_accuracy: 0.4868\n",
      "Epoch 638/1000\n",
      "177/177 [==============================] - 0s 250us/step - loss: 0.4791 - accuracy: 0.9379 - val_loss: 5.4421 - val_accuracy: 0.5395\n",
      "Epoch 639/1000\n",
      "177/177 [==============================] - 0s 240us/step - loss: 0.4645 - accuracy: 0.9322 - val_loss: 4.1687 - val_accuracy: 0.5526\n",
      "Epoch 640/1000\n",
      "177/177 [==============================] - 0s 249us/step - loss: 0.3395 - accuracy: 0.9492 - val_loss: 4.5860 - val_accuracy: 0.5263\n",
      "Epoch 641/1000\n",
      "177/177 [==============================] - 0s 263us/step - loss: 0.2956 - accuracy: 0.9435 - val_loss: 5.6244 - val_accuracy: 0.5526\n",
      "Epoch 642/1000\n",
      "177/177 [==============================] - 0s 185us/step - loss: 0.3618 - accuracy: 0.9492 - val_loss: 4.1819 - val_accuracy: 0.5526\n",
      "Epoch 643/1000\n",
      "177/177 [==============================] - 0s 157us/step - loss: 0.4000 - accuracy: 0.9548 - val_loss: 4.9115 - val_accuracy: 0.5658\n",
      "Epoch 644/1000\n",
      "177/177 [==============================] - 0s 172us/step - loss: 0.4373 - accuracy: 0.9435 - val_loss: 5.2000 - val_accuracy: 0.5526\n",
      "Epoch 645/1000\n",
      "177/177 [==============================] - 0s 177us/step - loss: 0.2202 - accuracy: 0.9548 - val_loss: 4.5970 - val_accuracy: 0.5658\n",
      "Epoch 646/1000\n",
      "177/177 [==============================] - 0s 178us/step - loss: 0.2552 - accuracy: 0.9661 - val_loss: 4.1705 - val_accuracy: 0.5921\n",
      "Epoch 647/1000\n",
      "177/177 [==============================] - 0s 173us/step - loss: 0.1694 - accuracy: 0.9774 - val_loss: 4.2539 - val_accuracy: 0.5658\n",
      "Epoch 648/1000\n",
      "177/177 [==============================] - 0s 233us/step - loss: 0.0733 - accuracy: 0.9774 - val_loss: 4.2905 - val_accuracy: 0.5789\n",
      "Epoch 649/1000\n",
      "177/177 [==============================] - 0s 233us/step - loss: 0.2173 - accuracy: 0.9718 - val_loss: 4.5433 - val_accuracy: 0.5526\n",
      "Epoch 650/1000\n",
      "177/177 [==============================] - 0s 172us/step - loss: 0.0880 - accuracy: 0.9718 - val_loss: 4.5026 - val_accuracy: 0.5395\n",
      "Epoch 651/1000\n",
      "177/177 [==============================] - 0s 142us/step - loss: 0.2203 - accuracy: 0.9661 - val_loss: 4.5687 - val_accuracy: 0.5395\n",
      "Epoch 652/1000\n",
      "177/177 [==============================] - 0s 133us/step - loss: 0.0996 - accuracy: 0.9718 - val_loss: 4.6344 - val_accuracy: 0.5526\n",
      "Epoch 653/1000\n",
      "177/177 [==============================] - 0s 182us/step - loss: 0.1317 - accuracy: 0.9774 - val_loss: 4.6778 - val_accuracy: 0.5263\n",
      "Epoch 654/1000\n",
      "177/177 [==============================] - 0s 240us/step - loss: 0.4850 - accuracy: 0.9548 - val_loss: 4.4983 - val_accuracy: 0.5658\n",
      "Epoch 655/1000\n",
      "177/177 [==============================] - 0s 213us/step - loss: 0.2359 - accuracy: 0.9661 - val_loss: 4.0778 - val_accuracy: 0.5658\n",
      "Epoch 656/1000\n",
      "177/177 [==============================] - 0s 203us/step - loss: 0.3016 - accuracy: 0.9492 - val_loss: 4.0545 - val_accuracy: 0.5789\n",
      "Epoch 657/1000\n",
      "177/177 [==============================] - 0s 216us/step - loss: 0.0810 - accuracy: 0.9718 - val_loss: 4.4537 - val_accuracy: 0.5789\n",
      "Epoch 658/1000\n",
      "177/177 [==============================] - 0s 222us/step - loss: 0.1377 - accuracy: 0.9718 - val_loss: 4.2946 - val_accuracy: 0.5921\n",
      "Epoch 659/1000\n",
      "177/177 [==============================] - 0s 184us/step - loss: 0.1530 - accuracy: 0.9718 - val_loss: 4.5984 - val_accuracy: 0.5789\n",
      "Epoch 660/1000\n",
      "177/177 [==============================] - 0s 164us/step - loss: 0.1384 - accuracy: 0.9605 - val_loss: 4.3936 - val_accuracy: 0.6053\n",
      "Epoch 661/1000\n",
      "177/177 [==============================] - 0s 187us/step - loss: 0.0677 - accuracy: 0.9718 - val_loss: 4.5455 - val_accuracy: 0.5789\n",
      "Epoch 662/1000\n",
      "177/177 [==============================] - 0s 143us/step - loss: 0.2888 - accuracy: 0.9492 - val_loss: 4.5242 - val_accuracy: 0.6053\n",
      "Epoch 663/1000\n",
      "177/177 [==============================] - 0s 133us/step - loss: 0.2642 - accuracy: 0.9605 - val_loss: 4.6540 - val_accuracy: 0.5789\n",
      "Epoch 664/1000\n",
      "177/177 [==============================] - 0s 126us/step - loss: 0.1026 - accuracy: 0.9718 - val_loss: 4.5657 - val_accuracy: 0.5921\n",
      "Epoch 665/1000\n",
      "177/177 [==============================] - 0s 110us/step - loss: 0.1821 - accuracy: 0.9718 - val_loss: 4.5070 - val_accuracy: 0.5789\n",
      "Epoch 666/1000\n",
      "177/177 [==============================] - 0s 109us/step - loss: 0.0505 - accuracy: 0.9774 - val_loss: 4.5397 - val_accuracy: 0.5526\n",
      "Epoch 667/1000\n",
      "177/177 [==============================] - 0s 140us/step - loss: 0.1467 - accuracy: 0.9774 - val_loss: 4.3453 - val_accuracy: 0.6053\n",
      "Epoch 668/1000\n",
      "177/177 [==============================] - 0s 119us/step - loss: 0.1118 - accuracy: 0.9661 - val_loss: 4.3456 - val_accuracy: 0.6184\n",
      "Epoch 669/1000\n",
      "177/177 [==============================] - 0s 205us/step - loss: 0.1118 - accuracy: 0.9774 - val_loss: 4.5828 - val_accuracy: 0.5658\n",
      "Epoch 670/1000\n",
      "177/177 [==============================] - 0s 664us/step - loss: 0.1386 - accuracy: 0.9774 - val_loss: 4.3753 - val_accuracy: 0.5921\n",
      "Epoch 671/1000\n",
      "177/177 [==============================] - 0s 378us/step - loss: 0.0416 - accuracy: 0.9718 - val_loss: 4.3737 - val_accuracy: 0.5921\n",
      "Epoch 672/1000\n",
      "177/177 [==============================] - 0s 404us/step - loss: 0.0934 - accuracy: 0.9831 - val_loss: 4.6827 - val_accuracy: 0.5526\n",
      "Epoch 673/1000\n",
      "177/177 [==============================] - 0s 285us/step - loss: 0.2123 - accuracy: 0.9774 - val_loss: 4.4107 - val_accuracy: 0.5789\n",
      "Epoch 674/1000\n",
      "177/177 [==============================] - 0s 260us/step - loss: 0.0400 - accuracy: 0.9774 - val_loss: 4.4372 - val_accuracy: 0.5921\n",
      "Epoch 675/1000\n",
      "177/177 [==============================] - 0s 198us/step - loss: 0.1064 - accuracy: 0.9774 - val_loss: 4.6875 - val_accuracy: 0.5526\n",
      "Epoch 676/1000\n",
      "177/177 [==============================] - 0s 132us/step - loss: 0.1601 - accuracy: 0.9661 - val_loss: 4.4864 - val_accuracy: 0.5658\n",
      "Epoch 677/1000\n",
      "177/177 [==============================] - 0s 170us/step - loss: 0.0949 - accuracy: 0.9774 - val_loss: 4.7800 - val_accuracy: 0.5526\n",
      "Epoch 678/1000\n",
      "177/177 [==============================] - 0s 236us/step - loss: 0.1657 - accuracy: 0.9774 - val_loss: 4.5225 - val_accuracy: 0.5789\n",
      "Epoch 679/1000\n",
      "177/177 [==============================] - 0s 186us/step - loss: 0.1628 - accuracy: 0.9774 - val_loss: 4.6114 - val_accuracy: 0.5526\n",
      "Epoch 680/1000\n",
      "177/177 [==============================] - 0s 155us/step - loss: 0.1495 - accuracy: 0.9718 - val_loss: 4.5984 - val_accuracy: 0.5526\n",
      "Epoch 681/1000\n",
      "177/177 [==============================] - 0s 220us/step - loss: 0.0856 - accuracy: 0.9774 - val_loss: 4.7138 - val_accuracy: 0.5395\n",
      "Epoch 682/1000\n",
      "177/177 [==============================] - 0s 177us/step - loss: 0.1406 - accuracy: 0.9774 - val_loss: 4.5809 - val_accuracy: 0.5526\n",
      "Epoch 683/1000\n",
      "177/177 [==============================] - 0s 172us/step - loss: 0.0950 - accuracy: 0.9774 - val_loss: 4.7241 - val_accuracy: 0.5526\n",
      "Epoch 684/1000\n",
      "177/177 [==============================] - 0s 181us/step - loss: 0.1132 - accuracy: 0.9661 - val_loss: 4.6235 - val_accuracy: 0.5395\n",
      "Epoch 685/1000\n",
      "177/177 [==============================] - 0s 168us/step - loss: 0.0287 - accuracy: 0.9774 - val_loss: 4.6625 - val_accuracy: 0.5395\n",
      "Epoch 686/1000\n",
      "177/177 [==============================] - 0s 167us/step - loss: 0.0293 - accuracy: 0.9774 - val_loss: 4.6362 - val_accuracy: 0.5395\n",
      "Epoch 687/1000\n",
      "177/177 [==============================] - 0s 131us/step - loss: 0.0289 - accuracy: 0.9831 - val_loss: 4.5732 - val_accuracy: 0.5658\n",
      "Epoch 688/1000\n",
      "177/177 [==============================] - 0s 128us/step - loss: 0.0515 - accuracy: 0.9831 - val_loss: 4.9103 - val_accuracy: 0.5395\n",
      "Epoch 689/1000\n",
      "177/177 [==============================] - 0s 115us/step - loss: 0.2326 - accuracy: 0.9605 - val_loss: 4.7573 - val_accuracy: 0.5526\n",
      "Epoch 690/1000\n",
      "177/177 [==============================] - 0s 118us/step - loss: 0.1199 - accuracy: 0.9831 - val_loss: 4.6762 - val_accuracy: 0.5395\n",
      "Epoch 691/1000\n",
      "177/177 [==============================] - 0s 146us/step - loss: 0.0989 - accuracy: 0.9831 - val_loss: 4.5866 - val_accuracy: 0.5789\n",
      "Epoch 692/1000\n",
      "177/177 [==============================] - 0s 157us/step - loss: 0.1526 - accuracy: 0.9774 - val_loss: 4.5757 - val_accuracy: 0.5658\n",
      "Epoch 693/1000\n",
      "177/177 [==============================] - 0s 176us/step - loss: 0.1214 - accuracy: 0.9831 - val_loss: 4.6160 - val_accuracy: 0.5526\n",
      "Epoch 694/1000\n",
      "177/177 [==============================] - 0s 184us/step - loss: 0.0329 - accuracy: 0.9831 - val_loss: 4.7087 - val_accuracy: 0.5395\n",
      "Epoch 695/1000\n",
      "177/177 [==============================] - 0s 143us/step - loss: 0.1236 - accuracy: 0.9661 - val_loss: 4.6300 - val_accuracy: 0.5526\n",
      "Epoch 696/1000\n",
      "177/177 [==============================] - 0s 162us/step - loss: 0.0292 - accuracy: 0.9774 - val_loss: 4.8627 - val_accuracy: 0.5526\n",
      "Epoch 697/1000\n",
      "177/177 [==============================] - 0s 192us/step - loss: 0.1428 - accuracy: 0.9774 - val_loss: 4.6114 - val_accuracy: 0.5921\n",
      "Epoch 698/1000\n",
      "177/177 [==============================] - 0s 184us/step - loss: 0.1483 - accuracy: 0.9718 - val_loss: 4.9526 - val_accuracy: 0.5526\n",
      "Epoch 699/1000\n",
      "177/177 [==============================] - 0s 133us/step - loss: 0.2503 - accuracy: 0.9548 - val_loss: 4.9853 - val_accuracy: 0.5395\n",
      "Epoch 700/1000\n",
      "177/177 [==============================] - 0s 132us/step - loss: 0.0510 - accuracy: 0.9774 - val_loss: 4.8109 - val_accuracy: 0.5658\n",
      "Epoch 701/1000\n",
      "177/177 [==============================] - 0s 118us/step - loss: 0.1515 - accuracy: 0.9661 - val_loss: 4.7926 - val_accuracy: 0.5395\n",
      "Epoch 702/1000\n",
      "177/177 [==============================] - 0s 130us/step - loss: 0.0317 - accuracy: 0.9887 - val_loss: 4.6502 - val_accuracy: 0.5658\n",
      "Epoch 703/1000\n",
      "177/177 [==============================] - 0s 117us/step - loss: 0.0541 - accuracy: 0.9774 - val_loss: 4.8329 - val_accuracy: 0.5395\n",
      "Epoch 704/1000\n",
      "177/177 [==============================] - 0s 118us/step - loss: 0.1534 - accuracy: 0.9774 - val_loss: 4.5964 - val_accuracy: 0.5658\n",
      "Epoch 705/1000\n",
      "177/177 [==============================] - 0s 129us/step - loss: 0.0792 - accuracy: 0.9831 - val_loss: 4.7351 - val_accuracy: 0.5395\n",
      "Epoch 706/1000\n",
      "177/177 [==============================] - 0s 123us/step - loss: 0.1829 - accuracy: 0.9718 - val_loss: 4.6518 - val_accuracy: 0.5526\n",
      "Epoch 707/1000\n",
      "177/177 [==============================] - 0s 138us/step - loss: 0.0590 - accuracy: 0.9774 - val_loss: 4.8017 - val_accuracy: 0.5526\n",
      "Epoch 708/1000\n",
      "177/177 [==============================] - 0s 122us/step - loss: 0.1661 - accuracy: 0.9831 - val_loss: 4.6339 - val_accuracy: 0.5789\n",
      "Epoch 709/1000\n",
      "177/177 [==============================] - 0s 130us/step - loss: 0.1209 - accuracy: 0.9831 - val_loss: 5.0263 - val_accuracy: 0.4868\n",
      "Epoch 710/1000\n",
      "177/177 [==============================] - 0s 115us/step - loss: 0.1825 - accuracy: 0.9774 - val_loss: 4.9321 - val_accuracy: 0.4868\n",
      "Epoch 711/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177/177 [==============================] - 0s 127us/step - loss: 0.1319 - accuracy: 0.9831 - val_loss: 4.6996 - val_accuracy: 0.5395\n",
      "Epoch 712/1000\n",
      "177/177 [==============================] - 0s 118us/step - loss: 0.1627 - accuracy: 0.9661 - val_loss: 4.6157 - val_accuracy: 0.5526\n",
      "Epoch 713/1000\n",
      "177/177 [==============================] - 0s 122us/step - loss: 0.0448 - accuracy: 0.9831 - val_loss: 4.4909 - val_accuracy: 0.5526\n",
      "Epoch 714/1000\n",
      "177/177 [==============================] - 0s 124us/step - loss: 0.0380 - accuracy: 0.9887 - val_loss: 4.4822 - val_accuracy: 0.5658\n",
      "Epoch 715/1000\n",
      "177/177 [==============================] - 0s 129us/step - loss: 0.0322 - accuracy: 0.9831 - val_loss: 4.5131 - val_accuracy: 0.5526\n",
      "Epoch 716/1000\n",
      "177/177 [==============================] - 0s 120us/step - loss: 0.0292 - accuracy: 0.9831 - val_loss: 4.5208 - val_accuracy: 0.5526\n",
      "Epoch 717/1000\n",
      "177/177 [==============================] - 0s 118us/step - loss: 0.0291 - accuracy: 0.9887 - val_loss: 4.5321 - val_accuracy: 0.5526\n",
      "Epoch 718/1000\n",
      "177/177 [==============================] - 0s 117us/step - loss: 0.0274 - accuracy: 0.9887 - val_loss: 4.5375 - val_accuracy: 0.5526\n",
      "Epoch 719/1000\n",
      "177/177 [==============================] - 0s 145us/step - loss: 0.0279 - accuracy: 0.9774 - val_loss: 4.5436 - val_accuracy: 0.5658\n",
      "Epoch 720/1000\n",
      "177/177 [==============================] - 0s 168us/step - loss: 0.0271 - accuracy: 0.9831 - val_loss: 4.5668 - val_accuracy: 0.5526\n",
      "Epoch 721/1000\n",
      "177/177 [==============================] - 0s 166us/step - loss: 0.0280 - accuracy: 0.9831 - val_loss: 4.6037 - val_accuracy: 0.5395\n",
      "Epoch 722/1000\n",
      "177/177 [==============================] - 0s 135us/step - loss: 0.0267 - accuracy: 0.9887 - val_loss: 4.6061 - val_accuracy: 0.5395\n",
      "Epoch 723/1000\n",
      "177/177 [==============================] - 0s 127us/step - loss: 0.0268 - accuracy: 0.9831 - val_loss: 4.6135 - val_accuracy: 0.5526\n",
      "Epoch 724/1000\n",
      "177/177 [==============================] - 0s 120us/step - loss: 0.0271 - accuracy: 0.9831 - val_loss: 4.6177 - val_accuracy: 0.5395\n",
      "Epoch 725/1000\n",
      "177/177 [==============================] - 0s 130us/step - loss: 0.0282 - accuracy: 0.9831 - val_loss: 4.6110 - val_accuracy: 0.5526\n",
      "Epoch 726/1000\n",
      "177/177 [==============================] - 0s 117us/step - loss: 0.0266 - accuracy: 0.9887 - val_loss: 4.6266 - val_accuracy: 0.5526\n",
      "Epoch 727/1000\n",
      "177/177 [==============================] - 0s 115us/step - loss: 0.0269 - accuracy: 0.9831 - val_loss: 4.6398 - val_accuracy: 0.5526\n",
      "Epoch 728/1000\n",
      "177/177 [==============================] - 0s 123us/step - loss: 0.0269 - accuracy: 0.9831 - val_loss: 4.6579 - val_accuracy: 0.5395\n",
      "Epoch 729/1000\n",
      "177/177 [==============================] - 0s 122us/step - loss: 0.0279 - accuracy: 0.9831 - val_loss: 4.6671 - val_accuracy: 0.5395\n",
      "Epoch 730/1000\n",
      "177/177 [==============================] - 0s 116us/step - loss: 0.0280 - accuracy: 0.9831 - val_loss: 4.6750 - val_accuracy: 0.5395\n",
      "Epoch 731/1000\n",
      "177/177 [==============================] - 0s 121us/step - loss: 0.0275 - accuracy: 0.9774 - val_loss: 4.6595 - val_accuracy: 0.5526\n",
      "Epoch 732/1000\n",
      "177/177 [==============================] - 0s 115us/step - loss: 0.0267 - accuracy: 0.9831 - val_loss: 4.6789 - val_accuracy: 0.5395\n",
      "Epoch 733/1000\n",
      "177/177 [==============================] - 0s 182us/step - loss: 0.0272 - accuracy: 0.9831 - val_loss: 4.6650 - val_accuracy: 0.5526\n",
      "Epoch 734/1000\n",
      "177/177 [==============================] - 0s 178us/step - loss: 0.0267 - accuracy: 0.9887 - val_loss: 4.6819 - val_accuracy: 0.5526\n",
      "Epoch 735/1000\n",
      "177/177 [==============================] - 0s 163us/step - loss: 0.0274 - accuracy: 0.9887 - val_loss: 4.6559 - val_accuracy: 0.5526\n",
      "Epoch 736/1000\n",
      "177/177 [==============================] - 0s 132us/step - loss: 0.0313 - accuracy: 0.9831 - val_loss: 4.6935 - val_accuracy: 0.5789\n",
      "Epoch 737/1000\n",
      "177/177 [==============================] - 0s 123us/step - loss: 0.0320 - accuracy: 0.9831 - val_loss: 4.7308 - val_accuracy: 0.5526\n",
      "Epoch 738/1000\n",
      "177/177 [==============================] - 0s 113us/step - loss: 0.0370 - accuracy: 0.9718 - val_loss: 4.6052 - val_accuracy: 0.5789\n",
      "Epoch 739/1000\n",
      "177/177 [==============================] - 0s 111us/step - loss: 0.1464 - accuracy: 0.9718 - val_loss: 4.7234 - val_accuracy: 0.5526\n",
      "Epoch 740/1000\n",
      "177/177 [==============================] - 0s 112us/step - loss: 0.1112 - accuracy: 0.9718 - val_loss: 4.7048 - val_accuracy: 0.5526\n",
      "Epoch 741/1000\n",
      "177/177 [==============================] - 0s 110us/step - loss: 0.1026 - accuracy: 0.9774 - val_loss: 4.5719 - val_accuracy: 0.5789\n",
      "Epoch 742/1000\n",
      "177/177 [==============================] - 0s 124us/step - loss: 0.1348 - accuracy: 0.9435 - val_loss: 4.6833 - val_accuracy: 0.5526\n",
      "Epoch 743/1000\n",
      "177/177 [==============================] - 0s 120us/step - loss: 0.0407 - accuracy: 0.9774 - val_loss: 5.2363 - val_accuracy: 0.5263\n",
      "Epoch 744/1000\n",
      "177/177 [==============================] - 0s 134us/step - loss: 0.2872 - accuracy: 0.9718 - val_loss: 4.6055 - val_accuracy: 0.5921\n",
      "Epoch 745/1000\n",
      "177/177 [==============================] - 0s 193us/step - loss: 0.2211 - accuracy: 0.9605 - val_loss: 4.8168 - val_accuracy: 0.5395\n",
      "Epoch 746/1000\n",
      "177/177 [==============================] - 0s 181us/step - loss: 0.3813 - accuracy: 0.9492 - val_loss: 5.1305 - val_accuracy: 0.5263\n",
      "Epoch 747/1000\n",
      "177/177 [==============================] - 0s 144us/step - loss: 0.1025 - accuracy: 0.9661 - val_loss: 4.7406 - val_accuracy: 0.5526\n",
      "Epoch 748/1000\n",
      "177/177 [==============================] - 0s 132us/step - loss: 0.2698 - accuracy: 0.9605 - val_loss: 4.6790 - val_accuracy: 0.5658\n",
      "Epoch 749/1000\n",
      "177/177 [==============================] - 0s 126us/step - loss: 0.0983 - accuracy: 0.9661 - val_loss: 4.6704 - val_accuracy: 0.5658\n",
      "Epoch 750/1000\n",
      "177/177 [==============================] - 0s 147us/step - loss: 0.1187 - accuracy: 0.9774 - val_loss: 4.9372 - val_accuracy: 0.5526\n",
      "Epoch 751/1000\n",
      "177/177 [==============================] - 0s 133us/step - loss: 0.1742 - accuracy: 0.9718 - val_loss: 4.7274 - val_accuracy: 0.5526\n",
      "Epoch 752/1000\n",
      "177/177 [==============================] - 0s 146us/step - loss: 0.1729 - accuracy: 0.9831 - val_loss: 4.7051 - val_accuracy: 0.5789\n",
      "Epoch 753/1000\n",
      "177/177 [==============================] - 0s 159us/step - loss: 0.1635 - accuracy: 0.9661 - val_loss: 4.8654 - val_accuracy: 0.5526\n",
      "Epoch 754/1000\n",
      "177/177 [==============================] - 0s 141us/step - loss: 0.0292 - accuracy: 0.9774 - val_loss: 4.7182 - val_accuracy: 0.5658\n",
      "Epoch 755/1000\n",
      "177/177 [==============================] - 0s 126us/step - loss: 0.1851 - accuracy: 0.9661 - val_loss: 4.9208 - val_accuracy: 0.5526\n",
      "Epoch 756/1000\n",
      "177/177 [==============================] - 0s 121us/step - loss: 0.0293 - accuracy: 0.9831 - val_loss: 4.7162 - val_accuracy: 0.5789\n",
      "Epoch 757/1000\n",
      "177/177 [==============================] - 0s 160us/step - loss: 0.1185 - accuracy: 0.9774 - val_loss: 4.8343 - val_accuracy: 0.5658\n",
      "Epoch 758/1000\n",
      "177/177 [==============================] - 0s 184us/step - loss: 0.1429 - accuracy: 0.9718 - val_loss: 4.7757 - val_accuracy: 0.5526\n",
      "Epoch 759/1000\n",
      "177/177 [==============================] - 0s 195us/step - loss: 0.0335 - accuracy: 0.9831 - val_loss: 4.9994 - val_accuracy: 0.5395\n",
      "Epoch 760/1000\n",
      "177/177 [==============================] - 0s 137us/step - loss: 0.2319 - accuracy: 0.9661 - val_loss: 4.7882 - val_accuracy: 0.5658\n",
      "Epoch 761/1000\n",
      "177/177 [==============================] - 0s 130us/step - loss: 0.3111 - accuracy: 0.9718 - val_loss: 5.3282 - val_accuracy: 0.5132\n",
      "Epoch 762/1000\n",
      "177/177 [==============================] - 0s 160us/step - loss: 0.2686 - accuracy: 0.9661 - val_loss: 4.7715 - val_accuracy: 0.5789\n",
      "Epoch 763/1000\n",
      "177/177 [==============================] - 0s 128us/step - loss: 0.0337 - accuracy: 0.9774 - val_loss: 4.8765 - val_accuracy: 0.5526\n",
      "Epoch 764/1000\n",
      "177/177 [==============================] - 0s 128us/step - loss: 0.0995 - accuracy: 0.9718 - val_loss: 4.6997 - val_accuracy: 0.5789\n",
      "Epoch 765/1000\n",
      "177/177 [==============================] - 0s 144us/step - loss: 0.1307 - accuracy: 0.9774 - val_loss: 4.9270 - val_accuracy: 0.5395\n",
      "Epoch 766/1000\n",
      "177/177 [==============================] - 0s 154us/step - loss: 0.2062 - accuracy: 0.9605 - val_loss: 4.6842 - val_accuracy: 0.5921\n",
      "Epoch 767/1000\n",
      "177/177 [==============================] - 0s 172us/step - loss: 0.1081 - accuracy: 0.9718 - val_loss: 4.7968 - val_accuracy: 0.5526\n",
      "Epoch 768/1000\n",
      "177/177 [==============================] - 0s 179us/step - loss: 0.0469 - accuracy: 0.9774 - val_loss: 4.8678 - val_accuracy: 0.5395\n",
      "Epoch 769/1000\n",
      "177/177 [==============================] - 0s 170us/step - loss: 0.0832 - accuracy: 0.9774 - val_loss: 4.6966 - val_accuracy: 0.5921\n",
      "Epoch 770/1000\n",
      "177/177 [==============================] - 0s 181us/step - loss: 0.1653 - accuracy: 0.9718 - val_loss: 4.9055 - val_accuracy: 0.5526\n",
      "Epoch 771/1000\n",
      "177/177 [==============================] - 0s 178us/step - loss: 0.0264 - accuracy: 0.9831 - val_loss: 4.6890 - val_accuracy: 0.5789\n",
      "Epoch 772/1000\n",
      "177/177 [==============================] - 0s 176us/step - loss: 0.0661 - accuracy: 0.9831 - val_loss: 4.9949 - val_accuracy: 0.5395\n",
      "Epoch 773/1000\n",
      "177/177 [==============================] - 0s 205us/step - loss: 0.2873 - accuracy: 0.9605 - val_loss: 4.9296 - val_accuracy: 0.5526\n",
      "Epoch 774/1000\n",
      "177/177 [==============================] - 0s 170us/step - loss: 0.0314 - accuracy: 0.9887 - val_loss: 4.7458 - val_accuracy: 0.5789\n",
      "Epoch 775/1000\n",
      "177/177 [==============================] - 0s 172us/step - loss: 0.0430 - accuracy: 0.9774 - val_loss: 5.2072 - val_accuracy: 0.5263\n",
      "Epoch 776/1000\n",
      "177/177 [==============================] - 0s 178us/step - loss: 0.2686 - accuracy: 0.9661 - val_loss: 4.8810 - val_accuracy: 0.5526\n",
      "Epoch 777/1000\n",
      "177/177 [==============================] - 0s 165us/step - loss: 0.0968 - accuracy: 0.9718 - val_loss: 4.8341 - val_accuracy: 0.5395\n",
      "Epoch 778/1000\n",
      "177/177 [==============================] - 0s 153us/step - loss: 6.3475 - accuracy: 0.8588 - val_loss: 6.8399 - val_accuracy: 0.5658\n",
      "Epoch 779/1000\n",
      "177/177 [==============================] - 0s 162us/step - loss: 6.9567 - accuracy: 0.8757 - val_loss: 5.0304 - val_accuracy: 0.5658\n",
      "Epoch 780/1000\n",
      "177/177 [==============================] - 0s 147us/step - loss: 2.3000 - accuracy: 0.7514 - val_loss: 9.9505 - val_accuracy: 0.5263\n",
      "Epoch 781/1000\n",
      "177/177 [==============================] - 0s 164us/step - loss: 2.7742 - accuracy: 0.8023 - val_loss: 6.0276 - val_accuracy: 0.5000\n",
      "Epoch 782/1000\n",
      "177/177 [==============================] - 0s 159us/step - loss: 1.1404 - accuracy: 0.8757 - val_loss: 4.9132 - val_accuracy: 0.5263\n",
      "Epoch 783/1000\n",
      "177/177 [==============================] - 0s 163us/step - loss: 0.3934 - accuracy: 0.9435 - val_loss: 5.2082 - val_accuracy: 0.5263\n",
      "Epoch 784/1000\n",
      "177/177 [==============================] - 0s 157us/step - loss: 0.1014 - accuracy: 0.9718 - val_loss: 5.9452 - val_accuracy: 0.4737\n",
      "Epoch 785/1000\n",
      "177/177 [==============================] - 0s 158us/step - loss: 0.1295 - accuracy: 0.9661 - val_loss: 4.6864 - val_accuracy: 0.5526\n",
      "Epoch 786/1000\n",
      "177/177 [==============================] - 0s 194us/step - loss: 0.2646 - accuracy: 0.9492 - val_loss: 4.4970 - val_accuracy: 0.5658\n",
      "Epoch 787/1000\n",
      "177/177 [==============================] - 0s 180us/step - loss: 0.3051 - accuracy: 0.9492 - val_loss: 4.9754 - val_accuracy: 0.5395\n",
      "Epoch 788/1000\n",
      "177/177 [==============================] - 0s 185us/step - loss: 0.2073 - accuracy: 0.9548 - val_loss: 5.3566 - val_accuracy: 0.5526\n",
      "Epoch 789/1000\n",
      "177/177 [==============================] - 0s 197us/step - loss: 0.1712 - accuracy: 0.9661 - val_loss: 5.3893 - val_accuracy: 0.5395\n",
      "Epoch 790/1000\n",
      "177/177 [==============================] - 0s 183us/step - loss: 0.0958 - accuracy: 0.9774 - val_loss: 5.1242 - val_accuracy: 0.5658\n",
      "Epoch 791/1000\n",
      "177/177 [==============================] - 0s 145us/step - loss: 0.1562 - accuracy: 0.9718 - val_loss: 5.0768 - val_accuracy: 0.5658\n",
      "Epoch 792/1000\n",
      "177/177 [==============================] - 0s 126us/step - loss: 0.2154 - accuracy: 0.9661 - val_loss: 5.1045 - val_accuracy: 0.5526\n",
      "Epoch 793/1000\n",
      "177/177 [==============================] - 0s 137us/step - loss: 0.2432 - accuracy: 0.9492 - val_loss: 4.8797 - val_accuracy: 0.5789\n",
      "Epoch 794/1000\n",
      "177/177 [==============================] - 0s 121us/step - loss: 0.2404 - accuracy: 0.9605 - val_loss: 4.9493 - val_accuracy: 0.5789\n",
      "Epoch 795/1000\n",
      "177/177 [==============================] - 0s 117us/step - loss: 0.2564 - accuracy: 0.9435 - val_loss: 5.0906 - val_accuracy: 0.5658\n",
      "Epoch 796/1000\n",
      "177/177 [==============================] - 0s 121us/step - loss: 0.3151 - accuracy: 0.9605 - val_loss: 5.0527 - val_accuracy: 0.5789\n",
      "Epoch 797/1000\n",
      "177/177 [==============================] - 0s 123us/step - loss: 0.1092 - accuracy: 0.9605 - val_loss: 5.3649 - val_accuracy: 0.5526\n",
      "Epoch 798/1000\n",
      "177/177 [==============================] - 0s 142us/step - loss: 0.6607 - accuracy: 0.9435 - val_loss: 5.0250 - val_accuracy: 0.5789\n",
      "Epoch 799/1000\n",
      "177/177 [==============================] - 0s 197us/step - loss: 0.3588 - accuracy: 0.9379 - val_loss: 5.2139 - val_accuracy: 0.5395\n",
      "Epoch 800/1000\n",
      "177/177 [==============================] - 0s 162us/step - loss: 0.2267 - accuracy: 0.9492 - val_loss: 5.0556 - val_accuracy: 0.5395\n",
      "Epoch 801/1000\n",
      "177/177 [==============================] - 0s 201us/step - loss: 0.1449 - accuracy: 0.9718 - val_loss: 5.1108 - val_accuracy: 0.5526\n",
      "Epoch 802/1000\n",
      "177/177 [==============================] - 0s 274us/step - loss: 0.2485 - accuracy: 0.9605 - val_loss: 5.3337 - val_accuracy: 0.5526\n",
      "Epoch 803/1000\n",
      "177/177 [==============================] - 0s 165us/step - loss: 5.3462 - accuracy: 0.8531 - val_loss: 10.4166 - val_accuracy: 0.5395\n",
      "Epoch 804/1000\n",
      "177/177 [==============================] - 0s 159us/step - loss: 7.3802 - accuracy: 0.8588 - val_loss: 8.9175 - val_accuracy: 0.4737\n",
      "Epoch 805/1000\n",
      "177/177 [==============================] - 0s 174us/step - loss: 4.0903 - accuracy: 0.8927 - val_loss: 6.7632 - val_accuracy: 0.4737\n",
      "Epoch 806/1000\n",
      "177/177 [==============================] - 0s 220us/step - loss: 1.6848 - accuracy: 0.8249 - val_loss: 5.2197 - val_accuracy: 0.5789\n",
      "Epoch 807/1000\n",
      "177/177 [==============================] - 0s 189us/step - loss: 0.4571 - accuracy: 0.9153 - val_loss: 4.9256 - val_accuracy: 0.5395\n",
      "Epoch 808/1000\n",
      "177/177 [==============================] - 0s 192us/step - loss: 0.1673 - accuracy: 0.9661 - val_loss: 5.0509 - val_accuracy: 0.5789\n",
      "Epoch 809/1000\n",
      "177/177 [==============================] - 0s 216us/step - loss: 0.3476 - accuracy: 0.9661 - val_loss: 5.1586 - val_accuracy: 0.5789\n",
      "Epoch 810/1000\n",
      "177/177 [==============================] - 0s 166us/step - loss: 0.1974 - accuracy: 0.9605 - val_loss: 5.0285 - val_accuracy: 0.5658\n",
      "Epoch 811/1000\n",
      "177/177 [==============================] - 0s 149us/step - loss: 0.0585 - accuracy: 0.9831 - val_loss: 4.9570 - val_accuracy: 0.5658\n",
      "Epoch 812/1000\n",
      "177/177 [==============================] - 0s 141us/step - loss: 0.1872 - accuracy: 0.9661 - val_loss: 4.9630 - val_accuracy: 0.5658\n",
      "Epoch 813/1000\n",
      "177/177 [==============================] - 0s 167us/step - loss: 0.0871 - accuracy: 0.9718 - val_loss: 4.8838 - val_accuracy: 0.5658\n",
      "Epoch 814/1000\n",
      "177/177 [==============================] - 0s 159us/step - loss: 0.0771 - accuracy: 0.9718 - val_loss: 4.8445 - val_accuracy: 0.5658\n",
      "Epoch 815/1000\n",
      "177/177 [==============================] - 0s 197us/step - loss: 0.0462 - accuracy: 0.9887 - val_loss: 4.8588 - val_accuracy: 0.5658\n",
      "Epoch 816/1000\n",
      "177/177 [==============================] - 0s 208us/step - loss: 0.0426 - accuracy: 0.9887 - val_loss: 4.7855 - val_accuracy: 0.5658\n",
      "Epoch 817/1000\n",
      "177/177 [==============================] - 0s 210us/step - loss: 0.0384 - accuracy: 0.9887 - val_loss: 4.7936 - val_accuracy: 0.5658\n",
      "Epoch 818/1000\n",
      "177/177 [==============================] - 0s 210us/step - loss: 0.0369 - accuracy: 0.9887 - val_loss: 4.7573 - val_accuracy: 0.5658\n",
      "Epoch 819/1000\n",
      "177/177 [==============================] - 0s 215us/step - loss: 0.0355 - accuracy: 0.9887 - val_loss: 4.7347 - val_accuracy: 0.5658\n",
      "Epoch 820/1000\n",
      "177/177 [==============================] - 0s 206us/step - loss: 0.0407 - accuracy: 0.9831 - val_loss: 4.7892 - val_accuracy: 0.5658\n",
      "Epoch 821/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177/177 [==============================] - 0s 157us/step - loss: 0.0340 - accuracy: 0.9887 - val_loss: 4.8138 - val_accuracy: 0.5658\n",
      "Epoch 822/1000\n",
      "177/177 [==============================] - 0s 175us/step - loss: 0.0351 - accuracy: 0.9887 - val_loss: 4.7501 - val_accuracy: 0.5658\n",
      "Epoch 823/1000\n",
      "177/177 [==============================] - 0s 155us/step - loss: 0.0365 - accuracy: 0.9887 - val_loss: 4.7523 - val_accuracy: 0.5658\n",
      "Epoch 824/1000\n",
      "177/177 [==============================] - 0s 149us/step - loss: 0.0324 - accuracy: 0.9831 - val_loss: 4.7880 - val_accuracy: 0.5658\n",
      "Epoch 825/1000\n",
      "177/177 [==============================] - 0s 155us/step - loss: 0.0411 - accuracy: 0.9774 - val_loss: 4.7306 - val_accuracy: 0.5658\n",
      "Epoch 826/1000\n",
      "177/177 [==============================] - 0s 158us/step - loss: 0.0325 - accuracy: 0.9887 - val_loss: 4.8029 - val_accuracy: 0.5658\n",
      "Epoch 827/1000\n",
      "177/177 [==============================] - 0s 145us/step - loss: 0.0389 - accuracy: 0.9831 - val_loss: 4.7064 - val_accuracy: 0.5789\n",
      "Epoch 828/1000\n",
      "177/177 [==============================] - 0s 146us/step - loss: 0.1250 - accuracy: 0.9718 - val_loss: 4.8259 - val_accuracy: 0.5526\n",
      "Epoch 829/1000\n",
      "177/177 [==============================] - 0s 150us/step - loss: 0.0311 - accuracy: 0.9887 - val_loss: 4.7221 - val_accuracy: 0.5658\n",
      "Epoch 830/1000\n",
      "177/177 [==============================] - 0s 141us/step - loss: 0.0343 - accuracy: 0.9831 - val_loss: 4.7624 - val_accuracy: 0.5658\n",
      "Epoch 831/1000\n",
      "177/177 [==============================] - 0s 151us/step - loss: 0.0314 - accuracy: 0.9831 - val_loss: 4.7740 - val_accuracy: 0.5658\n",
      "Epoch 832/1000\n",
      "177/177 [==============================] - 0s 185us/step - loss: 0.0308 - accuracy: 0.9887 - val_loss: 4.7721 - val_accuracy: 0.5789\n",
      "Epoch 833/1000\n",
      "177/177 [==============================] - 0s 165us/step - loss: 0.0312 - accuracy: 0.9887 - val_loss: 4.7613 - val_accuracy: 0.5789\n",
      "Epoch 834/1000\n",
      "177/177 [==============================] - 0s 145us/step - loss: 0.0307 - accuracy: 0.9831 - val_loss: 4.7803 - val_accuracy: 0.5658\n",
      "Epoch 835/1000\n",
      "177/177 [==============================] - 0s 157us/step - loss: 0.0305 - accuracy: 0.9831 - val_loss: 4.7844 - val_accuracy: 0.5658\n",
      "Epoch 836/1000\n",
      "177/177 [==============================] - 0s 164us/step - loss: 0.0310 - accuracy: 0.9774 - val_loss: 4.7826 - val_accuracy: 0.5789\n",
      "Epoch 837/1000\n",
      "177/177 [==============================] - 0s 154us/step - loss: 0.0302 - accuracy: 0.9887 - val_loss: 4.7860 - val_accuracy: 0.5658\n",
      "Epoch 838/1000\n",
      "177/177 [==============================] - 0s 160us/step - loss: 0.0308 - accuracy: 0.9831 - val_loss: 4.7981 - val_accuracy: 0.5789\n",
      "Epoch 839/1000\n",
      "177/177 [==============================] - 0s 169us/step - loss: 0.0488 - accuracy: 0.9831 - val_loss: 4.7059 - val_accuracy: 0.5789\n",
      "Epoch 840/1000\n",
      "177/177 [==============================] - 0s 147us/step - loss: 0.1447 - accuracy: 0.9774 - val_loss: 5.0534 - val_accuracy: 0.5526\n",
      "Epoch 841/1000\n",
      "177/177 [==============================] - 0s 149us/step - loss: 0.2923 - accuracy: 0.9435 - val_loss: 4.8612 - val_accuracy: 0.5658\n",
      "Epoch 842/1000\n",
      "177/177 [==============================] - 0s 144us/step - loss: 0.1243 - accuracy: 0.9718 - val_loss: 4.8471 - val_accuracy: 0.5263\n",
      "Epoch 843/1000\n",
      "177/177 [==============================] - 0s 147us/step - loss: 0.0938 - accuracy: 0.9718 - val_loss: 4.7414 - val_accuracy: 0.5526\n",
      "Epoch 844/1000\n",
      "177/177 [==============================] - 0s 133us/step - loss: 0.0688 - accuracy: 0.9831 - val_loss: 4.8573 - val_accuracy: 0.5395\n",
      "Epoch 845/1000\n",
      "177/177 [==============================] - 0s 153us/step - loss: 0.1330 - accuracy: 0.9718 - val_loss: 4.7534 - val_accuracy: 0.5789\n",
      "Epoch 846/1000\n",
      "177/177 [==============================] - 0s 162us/step - loss: 0.2360 - accuracy: 0.9605 - val_loss: 4.7653 - val_accuracy: 0.5658\n",
      "Epoch 847/1000\n",
      "177/177 [==============================] - 0s 159us/step - loss: 0.0511 - accuracy: 0.9831 - val_loss: 4.7795 - val_accuracy: 0.5658\n",
      "Epoch 848/1000\n",
      "177/177 [==============================] - 0s 173us/step - loss: 0.0757 - accuracy: 0.9774 - val_loss: 4.9692 - val_accuracy: 0.5526\n",
      "Epoch 849/1000\n",
      "177/177 [==============================] - 0s 160us/step - loss: 0.1197 - accuracy: 0.9661 - val_loss: 4.8794 - val_accuracy: 0.5526\n",
      "Epoch 850/1000\n",
      "177/177 [==============================] - 0s 153us/step - loss: 0.0656 - accuracy: 0.9774 - val_loss: 4.8137 - val_accuracy: 0.5789\n",
      "Epoch 851/1000\n",
      "177/177 [==============================] - 0s 155us/step - loss: 0.1740 - accuracy: 0.9661 - val_loss: 4.8705 - val_accuracy: 0.5658\n",
      "Epoch 852/1000\n",
      "177/177 [==============================] - 0s 157us/step - loss: 0.1098 - accuracy: 0.9774 - val_loss: 4.7913 - val_accuracy: 0.5921\n",
      "Epoch 853/1000\n",
      "177/177 [==============================] - 0s 147us/step - loss: 0.1317 - accuracy: 0.9831 - val_loss: 4.9335 - val_accuracy: 0.5658\n",
      "Epoch 854/1000\n",
      "177/177 [==============================] - 0s 156us/step - loss: 0.1076 - accuracy: 0.9661 - val_loss: 4.8040 - val_accuracy: 0.5921\n",
      "Epoch 855/1000\n",
      "177/177 [==============================] - 0s 178us/step - loss: 0.2247 - accuracy: 0.9605 - val_loss: 4.8282 - val_accuracy: 0.5658\n",
      "Epoch 856/1000\n",
      "177/177 [==============================] - 0s 150us/step - loss: 0.1625 - accuracy: 0.9605 - val_loss: 4.8603 - val_accuracy: 0.5658\n",
      "Epoch 857/1000\n",
      "177/177 [==============================] - 0s 144us/step - loss: 0.1210 - accuracy: 0.9718 - val_loss: 4.8574 - val_accuracy: 0.5658\n",
      "Epoch 858/1000\n",
      "177/177 [==============================] - 0s 147us/step - loss: 0.0324 - accuracy: 0.9831 - val_loss: 4.9509 - val_accuracy: 0.5658\n",
      "Epoch 859/1000\n",
      "177/177 [==============================] - 0s 207us/step - loss: 0.0812 - accuracy: 0.9774 - val_loss: 4.8908 - val_accuracy: 0.5658\n",
      "Epoch 860/1000\n",
      "177/177 [==============================] - 0s 159us/step - loss: 0.0415 - accuracy: 0.9774 - val_loss: 4.8064 - val_accuracy: 0.5789\n",
      "Epoch 861/1000\n",
      "177/177 [==============================] - 0s 159us/step - loss: 0.1178 - accuracy: 0.9774 - val_loss: 4.9937 - val_accuracy: 0.5526\n",
      "Epoch 862/1000\n",
      "177/177 [==============================] - 0s 202us/step - loss: 0.1076 - accuracy: 0.9718 - val_loss: 4.8731 - val_accuracy: 0.5658\n",
      "Epoch 863/1000\n",
      "177/177 [==============================] - 0s 147us/step - loss: 0.0295 - accuracy: 0.9887 - val_loss: 4.9185 - val_accuracy: 0.5526\n",
      "Epoch 864/1000\n",
      "177/177 [==============================] - 0s 183us/step - loss: 0.0304 - accuracy: 0.9774 - val_loss: 4.8902 - val_accuracy: 0.5658\n",
      "Epoch 865/1000\n",
      "177/177 [==============================] - 0s 183us/step - loss: 0.0287 - accuracy: 0.9887 - val_loss: 4.8568 - val_accuracy: 0.5658\n",
      "Epoch 866/1000\n",
      "177/177 [==============================] - 0s 194us/step - loss: 0.0294 - accuracy: 0.9887 - val_loss: 4.8711 - val_accuracy: 0.5658\n",
      "Epoch 867/1000\n",
      "177/177 [==============================] - 0s 186us/step - loss: 0.0294 - accuracy: 0.9831 - val_loss: 4.8778 - val_accuracy: 0.5526\n",
      "Epoch 868/1000\n",
      "177/177 [==============================] - 0s 157us/step - loss: 0.0285 - accuracy: 0.9887 - val_loss: 4.8894 - val_accuracy: 0.5526\n",
      "Epoch 869/1000\n",
      "177/177 [==============================] - 0s 153us/step - loss: 0.0288 - accuracy: 0.9887 - val_loss: 4.8851 - val_accuracy: 0.5526\n",
      "Epoch 870/1000\n",
      "177/177 [==============================] - 0s 147us/step - loss: 0.0289 - accuracy: 0.9831 - val_loss: 4.9015 - val_accuracy: 0.5658\n",
      "Epoch 871/1000\n",
      "177/177 [==============================] - 0s 146us/step - loss: 0.0365 - accuracy: 0.9887 - val_loss: 4.9159 - val_accuracy: 0.5526\n",
      "Epoch 872/1000\n",
      "177/177 [==============================] - 0s 153us/step - loss: 0.0333 - accuracy: 0.9887 - val_loss: 4.9289 - val_accuracy: 0.5658\n",
      "Epoch 873/1000\n",
      "177/177 [==============================] - 0s 163us/step - loss: 0.0314 - accuracy: 0.9887 - val_loss: 4.8697 - val_accuracy: 0.5658\n",
      "Epoch 874/1000\n",
      "177/177 [==============================] - 0s 161us/step - loss: 0.0298 - accuracy: 0.9831 - val_loss: 4.8110 - val_accuracy: 0.5789\n",
      "Epoch 875/1000\n",
      "177/177 [==============================] - 0s 143us/step - loss: 0.0289 - accuracy: 0.9831 - val_loss: 4.8284 - val_accuracy: 0.5526\n",
      "Epoch 876/1000\n",
      "177/177 [==============================] - 0s 144us/step - loss: 0.0290 - accuracy: 0.9831 - val_loss: 4.8221 - val_accuracy: 0.5658\n",
      "Epoch 877/1000\n",
      "177/177 [==============================] - 0s 170us/step - loss: 0.0284 - accuracy: 0.9887 - val_loss: 4.8350 - val_accuracy: 0.5658\n",
      "Epoch 878/1000\n",
      "177/177 [==============================] - 0s 152us/step - loss: 0.0277 - accuracy: 0.9887 - val_loss: 4.8398 - val_accuracy: 0.5658\n",
      "Epoch 879/1000\n",
      "177/177 [==============================] - 0s 182us/step - loss: 0.0284 - accuracy: 0.9774 - val_loss: 4.8851 - val_accuracy: 0.5526\n",
      "Epoch 880/1000\n",
      "177/177 [==============================] - 0s 149us/step - loss: 0.0292 - accuracy: 0.9831 - val_loss: 4.8474 - val_accuracy: 0.5526\n",
      "Epoch 881/1000\n",
      "177/177 [==============================] - 0s 156us/step - loss: 0.0285 - accuracy: 0.9887 - val_loss: 4.8185 - val_accuracy: 0.5658\n",
      "Epoch 882/1000\n",
      "177/177 [==============================] - 0s 152us/step - loss: 0.0286 - accuracy: 0.9887 - val_loss: 4.8252 - val_accuracy: 0.5658\n",
      "Epoch 883/1000\n",
      "177/177 [==============================] - 0s 151us/step - loss: 0.0278 - accuracy: 0.9831 - val_loss: 4.8411 - val_accuracy: 0.5658\n",
      "Epoch 884/1000\n",
      "177/177 [==============================] - 0s 158us/step - loss: 0.0282 - accuracy: 0.9831 - val_loss: 4.8555 - val_accuracy: 0.5658\n",
      "Epoch 885/1000\n",
      "177/177 [==============================] - 0s 148us/step - loss: 0.0277 - accuracy: 0.9887 - val_loss: 4.8591 - val_accuracy: 0.5526\n",
      "Epoch 886/1000\n",
      "177/177 [==============================] - 0s 150us/step - loss: 0.0274 - accuracy: 0.9887 - val_loss: 4.8607 - val_accuracy: 0.5526\n",
      "Epoch 887/1000\n",
      "177/177 [==============================] - 0s 166us/step - loss: 0.0279 - accuracy: 0.9831 - val_loss: 4.8501 - val_accuracy: 0.5658\n",
      "Epoch 888/1000\n",
      "177/177 [==============================] - 0s 161us/step - loss: 0.0280 - accuracy: 0.9831 - val_loss: 4.8703 - val_accuracy: 0.5658\n",
      "Epoch 889/1000\n",
      "177/177 [==============================] - 0s 160us/step - loss: 0.0274 - accuracy: 0.9887 - val_loss: 4.8716 - val_accuracy: 0.5658\n",
      "Epoch 890/1000\n",
      "177/177 [==============================] - 0s 145us/step - loss: 0.0277 - accuracy: 0.9831 - val_loss: 4.8868 - val_accuracy: 0.5526\n",
      "Epoch 891/1000\n",
      "177/177 [==============================] - 0s 162us/step - loss: 0.0282 - accuracy: 0.9774 - val_loss: 4.8742 - val_accuracy: 0.5658\n",
      "Epoch 892/1000\n",
      "177/177 [==============================] - 0s 153us/step - loss: 0.0276 - accuracy: 0.9887 - val_loss: 4.8694 - val_accuracy: 0.5658\n",
      "Epoch 893/1000\n",
      "177/177 [==============================] - 0s 157us/step - loss: 0.0274 - accuracy: 0.9887 - val_loss: 4.8834 - val_accuracy: 0.5658\n",
      "Epoch 894/1000\n",
      "177/177 [==============================] - 0s 147us/step - loss: 0.0275 - accuracy: 0.9831 - val_loss: 4.8756 - val_accuracy: 0.5526\n",
      "Epoch 895/1000\n",
      "177/177 [==============================] - 0s 153us/step - loss: 0.0279 - accuracy: 0.9831 - val_loss: 4.8875 - val_accuracy: 0.5526\n",
      "Epoch 896/1000\n",
      "177/177 [==============================] - 0s 151us/step - loss: 0.0275 - accuracy: 0.9887 - val_loss: 4.8693 - val_accuracy: 0.5526\n",
      "Epoch 897/1000\n",
      "177/177 [==============================] - 0s 148us/step - loss: 0.0273 - accuracy: 0.9774 - val_loss: 4.8678 - val_accuracy: 0.5526\n",
      "Epoch 898/1000\n",
      "177/177 [==============================] - 0s 178us/step - loss: 0.0276 - accuracy: 0.9831 - val_loss: 4.8735 - val_accuracy: 0.5526\n",
      "Epoch 899/1000\n",
      "177/177 [==============================] - 0s 152us/step - loss: 0.0277 - accuracy: 0.9831 - val_loss: 4.8661 - val_accuracy: 0.5526\n",
      "Epoch 900/1000\n",
      "177/177 [==============================] - 0s 147us/step - loss: 0.0271 - accuracy: 0.9887 - val_loss: 4.8529 - val_accuracy: 0.5526\n",
      "Epoch 901/1000\n",
      "177/177 [==============================] - 0s 152us/step - loss: 0.0272 - accuracy: 0.9831 - val_loss: 4.8398 - val_accuracy: 0.5658\n",
      "Epoch 902/1000\n",
      "177/177 [==============================] - 0s 149us/step - loss: 0.0269 - accuracy: 0.9887 - val_loss: 4.8540 - val_accuracy: 0.5658\n",
      "Epoch 903/1000\n",
      "177/177 [==============================] - 0s 148us/step - loss: 0.0275 - accuracy: 0.9887 - val_loss: 4.8641 - val_accuracy: 0.5526\n",
      "Epoch 904/1000\n",
      "177/177 [==============================] - 0s 152us/step - loss: 0.0283 - accuracy: 0.9831 - val_loss: 4.8696 - val_accuracy: 0.5526\n",
      "Epoch 905/1000\n",
      "177/177 [==============================] - 0s 146us/step - loss: 0.0279 - accuracy: 0.9831 - val_loss: 4.8516 - val_accuracy: 0.5658\n",
      "Epoch 906/1000\n",
      "177/177 [==============================] - 0s 160us/step - loss: 0.0271 - accuracy: 0.9887 - val_loss: 4.8661 - val_accuracy: 0.5658\n",
      "Epoch 907/1000\n",
      "177/177 [==============================] - 0s 142us/step - loss: 0.0277 - accuracy: 0.9831 - val_loss: 4.8669 - val_accuracy: 0.5526\n",
      "Epoch 908/1000\n",
      "177/177 [==============================] - 0s 150us/step - loss: 0.0279 - accuracy: 0.9831 - val_loss: 4.8748 - val_accuracy: 0.5526\n",
      "Epoch 909/1000\n",
      "177/177 [==============================] - 0s 141us/step - loss: 0.0274 - accuracy: 0.9887 - val_loss: 4.8983 - val_accuracy: 0.5526\n",
      "Epoch 910/1000\n",
      "177/177 [==============================] - 0s 151us/step - loss: 0.0272 - accuracy: 0.9774 - val_loss: 4.8732 - val_accuracy: 0.5658\n",
      "Epoch 911/1000\n",
      "177/177 [==============================] - 0s 142us/step - loss: 0.0270 - accuracy: 0.9831 - val_loss: 4.8495 - val_accuracy: 0.5658\n",
      "Epoch 912/1000\n",
      "177/177 [==============================] - 0s 158us/step - loss: 0.0449 - accuracy: 0.9887 - val_loss: 4.7472 - val_accuracy: 0.5526\n",
      "Epoch 913/1000\n",
      "177/177 [==============================] - 0s 157us/step - loss: 0.0496 - accuracy: 0.9887 - val_loss: 4.7537 - val_accuracy: 0.5526\n",
      "Epoch 914/1000\n",
      "177/177 [==============================] - 0s 145us/step - loss: 0.0475 - accuracy: 0.9887 - val_loss: 4.7586 - val_accuracy: 0.5395\n",
      "Epoch 915/1000\n",
      "177/177 [==============================] - 0s 153us/step - loss: 0.0402 - accuracy: 0.9887 - val_loss: 4.7951 - val_accuracy: 0.5395\n",
      "Epoch 916/1000\n",
      "177/177 [==============================] - 0s 162us/step - loss: 0.0359 - accuracy: 0.9887 - val_loss: 4.8204 - val_accuracy: 0.5658\n",
      "Epoch 917/1000\n",
      "177/177 [==============================] - 0s 145us/step - loss: 0.0336 - accuracy: 0.9831 - val_loss: 4.8546 - val_accuracy: 0.5658\n",
      "Epoch 918/1000\n",
      "177/177 [==============================] - 0s 155us/step - loss: 0.0309 - accuracy: 0.9887 - val_loss: 4.8450 - val_accuracy: 0.5921\n",
      "Epoch 919/1000\n",
      "177/177 [==============================] - 0s 168us/step - loss: 0.0400 - accuracy: 0.9831 - val_loss: 4.9253 - val_accuracy: 0.5658\n",
      "Epoch 920/1000\n",
      "177/177 [==============================] - 0s 155us/step - loss: 0.0316 - accuracy: 0.9831 - val_loss: 4.9029 - val_accuracy: 0.5658\n",
      "Epoch 921/1000\n",
      "177/177 [==============================] - 0s 149us/step - loss: 0.0288 - accuracy: 0.9887 - val_loss: 4.8900 - val_accuracy: 0.5658\n",
      "Epoch 922/1000\n",
      "177/177 [==============================] - 0s 169us/step - loss: 0.0276 - accuracy: 0.9887 - val_loss: 4.8974 - val_accuracy: 0.5658\n",
      "Epoch 923/1000\n",
      "177/177 [==============================] - 0s 164us/step - loss: 0.0270 - accuracy: 0.9887 - val_loss: 4.9062 - val_accuracy: 0.5658\n",
      "Epoch 924/1000\n",
      "177/177 [==============================] - 0s 154us/step - loss: 0.0267 - accuracy: 0.9831 - val_loss: 4.9219 - val_accuracy: 0.5526\n",
      "Epoch 925/1000\n",
      "177/177 [==============================] - 0s 142us/step - loss: 0.0269 - accuracy: 0.9831 - val_loss: 4.9033 - val_accuracy: 0.5658\n",
      "Epoch 926/1000\n",
      "177/177 [==============================] - 0s 157us/step - loss: 0.0269 - accuracy: 0.9774 - val_loss: 4.9065 - val_accuracy: 0.5526\n",
      "Epoch 927/1000\n",
      "177/177 [==============================] - 0s 148us/step - loss: 0.0274 - accuracy: 0.9831 - val_loss: 4.9137 - val_accuracy: 0.5526\n",
      "Epoch 928/1000\n",
      "177/177 [==============================] - 0s 150us/step - loss: 0.0264 - accuracy: 0.9887 - val_loss: 4.9211 - val_accuracy: 0.5526\n",
      "Epoch 929/1000\n",
      "177/177 [==============================] - 0s 154us/step - loss: 0.0263 - accuracy: 0.9887 - val_loss: 4.9167 - val_accuracy: 0.5526\n",
      "Epoch 930/1000\n",
      "177/177 [==============================] - 0s 149us/step - loss: 0.0268 - accuracy: 0.9887 - val_loss: 4.9214 - val_accuracy: 0.5526\n",
      "Epoch 931/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177/177 [==============================] - 0s 149us/step - loss: 0.0273 - accuracy: 0.9774 - val_loss: 4.9022 - val_accuracy: 0.5658\n",
      "Epoch 932/1000\n",
      "177/177 [==============================] - 0s 156us/step - loss: 0.0269 - accuracy: 0.9831 - val_loss: 4.9295 - val_accuracy: 0.5526\n",
      "Epoch 933/1000\n",
      "177/177 [==============================] - ETA: 0s - loss: 0.0029 - accuracy: 1.00 - 0s 156us/step - loss: 0.0268 - accuracy: 0.9831 - val_loss: 4.9384 - val_accuracy: 0.5526\n",
      "Epoch 934/1000\n",
      "177/177 [==============================] - 0s 161us/step - loss: 0.0270 - accuracy: 0.9831 - val_loss: 4.9107 - val_accuracy: 0.5658\n",
      "Epoch 935/1000\n",
      "177/177 [==============================] - 0s 156us/step - loss: 0.0267 - accuracy: 0.9831 - val_loss: 4.9300 - val_accuracy: 0.5526\n",
      "Epoch 936/1000\n",
      "177/177 [==============================] - 0s 154us/step - loss: 0.0268 - accuracy: 0.9831 - val_loss: 4.9666 - val_accuracy: 0.5526\n",
      "Epoch 937/1000\n",
      "177/177 [==============================] - 0s 150us/step - loss: 0.0268 - accuracy: 0.9774 - val_loss: 4.9443 - val_accuracy: 0.5658\n",
      "Epoch 938/1000\n",
      "177/177 [==============================] - 0s 155us/step - loss: 0.0265 - accuracy: 0.9831 - val_loss: 4.9395 - val_accuracy: 0.5658\n",
      "Epoch 939/1000\n",
      "177/177 [==============================] - 0s 143us/step - loss: 0.0261 - accuracy: 0.9831 - val_loss: 4.9246 - val_accuracy: 0.5658\n",
      "Epoch 940/1000\n",
      "177/177 [==============================] - 0s 155us/step - loss: 0.0266 - accuracy: 0.9887 - val_loss: 4.9381 - val_accuracy: 0.5658\n",
      "Epoch 941/1000\n",
      "177/177 [==============================] - 0s 157us/step - loss: 0.0276 - accuracy: 0.9774 - val_loss: 4.9395 - val_accuracy: 0.5526\n",
      "Epoch 942/1000\n",
      "177/177 [==============================] - 0s 149us/step - loss: 0.0258 - accuracy: 0.9831 - val_loss: 4.9446 - val_accuracy: 0.5526\n",
      "Epoch 943/1000\n",
      "177/177 [==============================] - 0s 156us/step - loss: 0.0261 - accuracy: 0.9887 - val_loss: 4.9397 - val_accuracy: 0.5526\n",
      "Epoch 944/1000\n",
      "177/177 [==============================] - 0s 173us/step - loss: 0.0261 - accuracy: 0.9887 - val_loss: 4.9389 - val_accuracy: 0.5526\n",
      "Epoch 945/1000\n",
      "177/177 [==============================] - 0s 146us/step - loss: 0.0262 - accuracy: 0.9774 - val_loss: 4.9359 - val_accuracy: 0.5526\n",
      "Epoch 946/1000\n",
      "177/177 [==============================] - 0s 155us/step - loss: 0.0261 - accuracy: 0.9887 - val_loss: 4.9485 - val_accuracy: 0.5526\n",
      "Epoch 947/1000\n",
      "177/177 [==============================] - 0s 150us/step - loss: 0.0262 - accuracy: 0.9887 - val_loss: 4.9531 - val_accuracy: 0.5526\n",
      "Epoch 948/1000\n",
      "177/177 [==============================] - 0s 154us/step - loss: 0.0261 - accuracy: 0.9774 - val_loss: 4.9265 - val_accuracy: 0.5658\n",
      "Epoch 949/1000\n",
      "177/177 [==============================] - 0s 157us/step - loss: 0.0277 - accuracy: 0.9774 - val_loss: 4.9527 - val_accuracy: 0.5526\n",
      "Epoch 950/1000\n",
      "177/177 [==============================] - 0s 160us/step - loss: 0.0259 - accuracy: 0.9887 - val_loss: 4.9541 - val_accuracy: 0.5658\n",
      "Epoch 951/1000\n",
      "177/177 [==============================] - 0s 150us/step - loss: 0.0265 - accuracy: 0.9831 - val_loss: 4.9188 - val_accuracy: 0.5658\n",
      "Epoch 952/1000\n",
      "177/177 [==============================] - 0s 148us/step - loss: 0.0260 - accuracy: 0.9887 - val_loss: 4.9286 - val_accuracy: 0.5658\n",
      "Epoch 953/1000\n",
      "177/177 [==============================] - 0s 146us/step - loss: 0.0260 - accuracy: 0.9831 - val_loss: 4.9482 - val_accuracy: 0.5526\n",
      "Epoch 954/1000\n",
      "177/177 [==============================] - 0s 179us/step - loss: 0.0264 - accuracy: 0.9831 - val_loss: 4.9534 - val_accuracy: 0.5526\n",
      "Epoch 955/1000\n",
      "177/177 [==============================] - 0s 169us/step - loss: 0.0262 - accuracy: 0.9774 - val_loss: 4.9335 - val_accuracy: 0.5658\n",
      "Epoch 956/1000\n",
      "177/177 [==============================] - 0s 178us/step - loss: 0.0254 - accuracy: 0.9887 - val_loss: 4.9356 - val_accuracy: 0.5658\n",
      "Epoch 957/1000\n",
      "177/177 [==============================] - 0s 147us/step - loss: 0.0268 - accuracy: 0.9831 - val_loss: 4.9331 - val_accuracy: 0.5526\n",
      "Epoch 958/1000\n",
      "177/177 [==============================] - 0s 151us/step - loss: 0.0261 - accuracy: 0.9831 - val_loss: 4.9398 - val_accuracy: 0.5658\n",
      "Epoch 959/1000\n",
      "177/177 [==============================] - 0s 155us/step - loss: 0.0263 - accuracy: 0.9774 - val_loss: 4.9623 - val_accuracy: 0.5526\n",
      "Epoch 960/1000\n",
      "177/177 [==============================] - 0s 158us/step - loss: 0.0259 - accuracy: 0.9831 - val_loss: 4.9494 - val_accuracy: 0.5658\n",
      "Epoch 961/1000\n",
      "177/177 [==============================] - 0s 153us/step - loss: 0.0251 - accuracy: 0.9887 - val_loss: 4.9473 - val_accuracy: 0.5658\n",
      "Epoch 962/1000\n",
      "177/177 [==============================] - 0s 144us/step - loss: 0.0260 - accuracy: 0.9887 - val_loss: 4.9663 - val_accuracy: 0.5526\n",
      "Epoch 963/1000\n",
      "177/177 [==============================] - 0s 174us/step - loss: 0.0262 - accuracy: 0.9831 - val_loss: 4.9471 - val_accuracy: 0.5526\n",
      "Epoch 964/1000\n",
      "177/177 [==============================] - 0s 155us/step - loss: 0.0256 - accuracy: 0.9887 - val_loss: 4.9532 - val_accuracy: 0.5526\n",
      "Epoch 965/1000\n",
      "177/177 [==============================] - 0s 153us/step - loss: 0.0254 - accuracy: 0.9831 - val_loss: 4.9443 - val_accuracy: 0.5658\n",
      "Epoch 966/1000\n",
      "177/177 [==============================] - 0s 154us/step - loss: 0.0255 - accuracy: 0.9887 - val_loss: 4.9496 - val_accuracy: 0.5658\n",
      "Epoch 967/1000\n",
      "177/177 [==============================] - 0s 174us/step - loss: 0.0259 - accuracy: 0.9887 - val_loss: 4.9470 - val_accuracy: 0.5658\n",
      "Epoch 968/1000\n",
      "177/177 [==============================] - 0s 145us/step - loss: 0.0266 - accuracy: 0.9831 - val_loss: 4.9051 - val_accuracy: 0.5658\n",
      "Epoch 969/1000\n",
      "177/177 [==============================] - 0s 151us/step - loss: 0.0258 - accuracy: 0.9887 - val_loss: 4.9210 - val_accuracy: 0.5658\n",
      "Epoch 970/1000\n",
      "177/177 [==============================] - 0s 146us/step - loss: 0.0259 - accuracy: 0.9831 - val_loss: 4.9535 - val_accuracy: 0.5658\n",
      "Epoch 971/1000\n",
      "177/177 [==============================] - 0s 151us/step - loss: 0.0260 - accuracy: 0.9774 - val_loss: 4.9689 - val_accuracy: 0.5526\n",
      "Epoch 972/1000\n",
      "177/177 [==============================] - 0s 149us/step - loss: 0.0257 - accuracy: 0.9887 - val_loss: 4.9568 - val_accuracy: 0.5526\n",
      "Epoch 973/1000\n",
      "177/177 [==============================] - 0s 155us/step - loss: 0.0254 - accuracy: 0.9831 - val_loss: 4.9272 - val_accuracy: 0.5526\n",
      "Epoch 974/1000\n",
      "177/177 [==============================] - 0s 165us/step - loss: 0.0252 - accuracy: 0.9831 - val_loss: 4.9208 - val_accuracy: 0.5658\n",
      "Epoch 975/1000\n",
      "177/177 [==============================] - 0s 155us/step - loss: 0.0261 - accuracy: 0.9887 - val_loss: 4.9458 - val_accuracy: 0.5658\n",
      "Epoch 976/1000\n",
      "177/177 [==============================] - 0s 149us/step - loss: 0.0256 - accuracy: 0.9887 - val_loss: 4.9377 - val_accuracy: 0.5658\n",
      "Epoch 977/1000\n",
      "177/177 [==============================] - 0s 156us/step - loss: 0.0251 - accuracy: 0.9887 - val_loss: 4.9486 - val_accuracy: 0.5526\n",
      "Epoch 978/1000\n",
      "177/177 [==============================] - 0s 144us/step - loss: 0.0253 - accuracy: 0.9887 - val_loss: 4.9548 - val_accuracy: 0.5526\n",
      "Epoch 979/1000\n",
      "177/177 [==============================] - 0s 153us/step - loss: 0.0270 - accuracy: 0.9774 - val_loss: 4.9304 - val_accuracy: 0.5526\n",
      "Epoch 980/1000\n",
      "177/177 [==============================] - 0s 147us/step - loss: 0.0263 - accuracy: 0.9831 - val_loss: 4.9726 - val_accuracy: 0.5526\n",
      "Epoch 981/1000\n",
      "177/177 [==============================] - 0s 152us/step - loss: 0.0258 - accuracy: 0.9887 - val_loss: 4.9433 - val_accuracy: 0.5526\n",
      "Epoch 982/1000\n",
      "177/177 [==============================] - 0s 147us/step - loss: 0.0272 - accuracy: 0.9774 - val_loss: 4.9149 - val_accuracy: 0.5789\n",
      "Epoch 983/1000\n",
      "177/177 [==============================] - 0s 150us/step - loss: 0.0257 - accuracy: 0.9887 - val_loss: 4.9226 - val_accuracy: 0.5658\n",
      "Epoch 984/1000\n",
      "177/177 [==============================] - 0s 172us/step - loss: 0.0253 - accuracy: 0.9887 - val_loss: 4.9550 - val_accuracy: 0.5526\n",
      "Epoch 985/1000\n",
      "177/177 [==============================] - 0s 163us/step - loss: 0.0261 - accuracy: 0.9831 - val_loss: 4.9888 - val_accuracy: 0.5526\n",
      "Epoch 986/1000\n",
      "177/177 [==============================] - 0s 150us/step - loss: 0.0366 - accuracy: 0.9887 - val_loss: 5.2369 - val_accuracy: 0.5526\n",
      "Epoch 987/1000\n",
      "177/177 [==============================] - 0s 153us/step - loss: 0.0424 - accuracy: 0.9831 - val_loss: 5.2255 - val_accuracy: 0.5526\n",
      "Epoch 988/1000\n",
      "177/177 [==============================] - 0s 155us/step - loss: 0.0566 - accuracy: 0.9774 - val_loss: 5.2800 - val_accuracy: 0.5395\n",
      "Epoch 989/1000\n",
      "177/177 [==============================] - 0s 155us/step - loss: 0.2155 - accuracy: 0.9605 - val_loss: 5.0635 - val_accuracy: 0.5789\n",
      "Epoch 990/1000\n",
      "177/177 [==============================] - 0s 155us/step - loss: 0.0991 - accuracy: 0.9435 - val_loss: 5.1277 - val_accuracy: 0.5526\n",
      "Epoch 991/1000\n",
      "177/177 [==============================] - 0s 151us/step - loss: 0.0876 - accuracy: 0.9718 - val_loss: 4.7952 - val_accuracy: 0.5789\n",
      "Epoch 992/1000\n",
      "177/177 [==============================] - 0s 158us/step - loss: 0.1844 - accuracy: 0.9379 - val_loss: 5.0768 - val_accuracy: 0.5658\n",
      "Epoch 993/1000\n",
      "177/177 [==============================] - 0s 157us/step - loss: 0.3002 - accuracy: 0.9605 - val_loss: 4.8354 - val_accuracy: 0.5658\n",
      "Epoch 994/1000\n",
      "177/177 [==============================] - 0s 154us/step - loss: 0.2196 - accuracy: 0.9718 - val_loss: 4.7983 - val_accuracy: 0.5658\n",
      "Epoch 995/1000\n",
      "177/177 [==============================] - 0s 150us/step - loss: 0.3617 - accuracy: 0.9661 - val_loss: 5.0962 - val_accuracy: 0.5526\n",
      "Epoch 996/1000\n",
      "177/177 [==============================] - 0s 170us/step - loss: 0.1074 - accuracy: 0.9831 - val_loss: 5.0019 - val_accuracy: 0.5000\n",
      "Epoch 997/1000\n",
      "177/177 [==============================] - 0s 164us/step - loss: 0.2644 - accuracy: 0.9718 - val_loss: 4.9991 - val_accuracy: 0.5526\n",
      "Epoch 998/1000\n",
      "177/177 [==============================] - 0s 152us/step - loss: 0.4442 - accuracy: 0.9605 - val_loss: 4.8666 - val_accuracy: 0.5263\n",
      "Epoch 999/1000\n",
      "177/177 [==============================] - 0s 154us/step - loss: 0.2682 - accuracy: 0.9492 - val_loss: 5.0842 - val_accuracy: 0.5263\n",
      "Epoch 1000/1000\n",
      "177/177 [==============================] - 0s 151us/step - loss: 0.2665 - accuracy: 0.9605 - val_loss: 4.8597 - val_accuracy: 0.5395\n"
     ]
    }
   ],
   "source": [
    "hist_sel2 = model_sel2.fit(X_sel_train, y_sel_train,\n",
    "          batch_size=16, epochs=1000,\n",
    "          validation_data=(X_sel_test, y_sel_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 96.98%\n"
     ]
    }
   ],
   "source": [
    "print('train accuracy: %.2f%%' % (np.mean(hist_sel2.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba6 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_lasso_2.xlsx\",\n",
    "                        sheet_name=1,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>CFBREBSa104</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.290039e-09</td>\n",
       "      <td>1.567630e-07</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NRS199</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.856965e-05</td>\n",
       "      <td>2.843749e-03</td>\n",
       "      <td>9.971277e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NRS233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9.999446e-01</td>\n",
       "      <td>4.541289e-06</td>\n",
       "      <td>5.090974e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>SR1746</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6.282367e-02</td>\n",
       "      <td>7.075194e-04</td>\n",
       "      <td>9.364688e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NRS202</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8.229589e-03</td>\n",
       "      <td>2.163908e-05</td>\n",
       "      <td>9.917488e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>GA27</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.964591e-03</td>\n",
       "      <td>9.959286e-01</td>\n",
       "      <td>1.068284e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>GA231</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.309226e-04</td>\n",
       "      <td>9.996691e-01</td>\n",
       "      <td>6.232397e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>SR1287</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.445997e-06</td>\n",
       "      <td>9.999915e-01</td>\n",
       "      <td>1.182947e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>506</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6.516150e-01</td>\n",
       "      <td>1.480882e-02</td>\n",
       "      <td>3.335762e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>NRS001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.841915e-04</td>\n",
       "      <td>9.994158e-01</td>\n",
       "      <td>6.525528e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>608 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     phage       strain  phenotype  prediction             0  \\\n",
       "0       p0017kpresabs_qual  CFBREBSa104          1           2  1.290039e-09   \n",
       "1       p0017kpresabs_qual       NRS199          2           2  2.856965e-05   \n",
       "2       p0017kpresabs_qual       NRS233          1           0  9.999446e-01   \n",
       "3       p0017kpresabs_qual       SR1746          0           2  6.282367e-02   \n",
       "4       p0017kpresabs_qual       NRS202          2           2  8.229589e-03   \n",
       "..                     ...          ...        ...         ...           ...   \n",
       "603  p0040presabsSTCC_qual         GA27          2           1  3.964591e-03   \n",
       "604  p0040presabsSTCC_qual        GA231          2           1  3.309226e-04   \n",
       "605  p0040presabsSTCC_qual       SR1287          0           1  8.445997e-06   \n",
       "606  p0040presabsSTCC_qual          506          2           0  6.516150e-01   \n",
       "607  p0040presabsSTCC_qual       NRS001          1           1  5.841915e-04   \n",
       "\n",
       "                1             2  \n",
       "0    1.567630e-07  9.999999e-01  \n",
       "1    2.843749e-03  9.971277e-01  \n",
       "2    4.541289e-06  5.090974e-05  \n",
       "3    7.075194e-04  9.364688e-01  \n",
       "4    2.163908e-05  9.917488e-01  \n",
       "..            ...           ...  \n",
       "603  9.959286e-01  1.068284e-04  \n",
       "604  9.996691e-01  6.232397e-10  \n",
       "605  9.999915e-01  1.182947e-13  \n",
       "606  1.480882e-02  3.335762e-01  \n",
       "607  9.994158e-01  6.525528e-08  \n",
       "\n",
       "[608 rows x 7 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.41936480e-09, 9.68961200e-01, 3.10388560e-02],\n",
       "       [8.29002900e-08, 9.99954800e-01, 4.50879120e-05],\n",
       "       [3.23367980e-02, 1.33058830e-01, 8.34604400e-01],\n",
       "       [1.94579440e-10, 9.99999300e-01, 7.53789400e-07],\n",
       "       [2.30662860e-05, 9.99977000e-01, 3.92984670e-08],\n",
       "       [6.76289450e-12, 1.00000000e+00, 5.51817240e-21],\n",
       "       [1.69047770e-04, 9.34854450e-01, 6.49765000e-02],\n",
       "       [1.25273660e-06, 8.30723900e-01, 1.69274880e-01],\n",
       "       [1.48787900e-07, 9.72064440e-04, 9.99027850e-01],\n",
       "       [3.34367240e-04, 9.99656200e-01, 9.43186750e-06],\n",
       "       [4.58884960e-04, 1.02441110e-01, 8.97100000e-01],\n",
       "       [4.00466840e-03, 2.33040730e-03, 9.93665000e-01],\n",
       "       [7.96433900e-02, 9.20356630e-01, 1.69437230e-10],\n",
       "       [4.37546670e-01, 5.60030160e-01, 2.42317000e-03],\n",
       "       [6.14800700e-03, 9.93722500e-01, 1.29520080e-04],\n",
       "       [7.49776400e-05, 9.99783460e-01, 1.41584650e-04],\n",
       "       [6.26841700e-12, 3.48335700e-01, 6.51664260e-01],\n",
       "       [6.13096700e-05, 8.84887800e-02, 9.11449970e-01],\n",
       "       [1.57721490e-02, 9.84227800e-01, 4.58528150e-08],\n",
       "       [2.10485440e-03, 9.97864540e-01, 3.05356260e-05],\n",
       "       [1.44485730e-03, 6.22492200e-03, 9.92330250e-01],\n",
       "       [4.86775000e-10, 2.36629780e-05, 9.99976300e-01],\n",
       "       [4.55387550e-04, 1.60566370e-04, 9.99384050e-01],\n",
       "       [4.66993700e-04, 9.40142000e-03, 9.90131600e-01],\n",
       "       [6.58113100e-03, 3.30961270e-02, 9.60322700e-01],\n",
       "       [3.99107750e-04, 1.99691530e-03, 9.97603950e-01],\n",
       "       [3.16123500e-09, 7.74513500e-05, 9.99922500e-01],\n",
       "       [3.73369500e-01, 6.04312300e-01, 2.23182680e-02],\n",
       "       [4.90586460e-11, 8.96388100e-05, 9.99910350e-01],\n",
       "       [2.41457660e-06, 2.65676050e-01, 7.34321530e-01],\n",
       "       [9.69532200e-10, 1.12360840e-05, 9.99988800e-01],\n",
       "       [4.99674640e-05, 9.62895630e-01, 3.70544050e-02],\n",
       "       [4.39655420e-06, 9.39234550e-01, 6.07610640e-02],\n",
       "       [2.25552320e-01, 4.09973060e-04, 7.74037700e-01],\n",
       "       [4.86775000e-10, 2.36629780e-05, 9.99976300e-01],\n",
       "       [9.46049230e-04, 5.61958400e-01, 4.37095520e-01],\n",
       "       [9.99698160e-01, 2.73062670e-04, 2.88658360e-05],\n",
       "       [5.44615830e-03, 1.69889700e-03, 9.92855000e-01],\n",
       "       [9.94415300e-01, 5.57713700e-03, 7.55282370e-06],\n",
       "       [9.99850300e-01, 1.49724290e-04, 1.91958660e-08],\n",
       "       [9.63049800e-02, 5.30259880e-06, 9.03689700e-01],\n",
       "       [1.10405565e-11, 9.99998800e-01, 1.22035060e-06],\n",
       "       [3.22631600e-08, 9.33781100e-02, 9.06621900e-01],\n",
       "       [3.70973570e-02, 9.42757500e-01, 2.01451950e-02],\n",
       "       [3.01223900e-12, 1.00000000e+00, 2.00354040e-15],\n",
       "       [2.66902240e-03, 8.54237500e-01, 1.43093500e-01],\n",
       "       [4.12811700e-12, 9.99999900e-01, 1.35788110e-07],\n",
       "       [1.00567740e-04, 9.99899400e-01, 1.28607270e-15],\n",
       "       [1.28902640e-06, 6.09658300e-01, 3.90340400e-01],\n",
       "       [7.65407560e-01, 1.00346730e-02, 2.24557770e-01],\n",
       "       [6.48001600e-04, 9.99351900e-01, 1.21519300e-07],\n",
       "       [9.07328700e-03, 9.90926740e-01, 2.14232480e-10],\n",
       "       [6.14800700e-03, 9.93722500e-01, 1.29520080e-04],\n",
       "       [9.74653800e-01, 4.42510300e-03, 2.09211650e-02],\n",
       "       [1.87444870e-03, 4.19175420e-07, 9.98125140e-01],\n",
       "       [7.60370050e-04, 7.02279400e-01, 2.96960260e-01],\n",
       "       [6.21504200e-11, 2.70054280e-02, 9.72994500e-01],\n",
       "       [4.65140070e-01, 5.25998060e-01, 8.86183800e-03],\n",
       "       [2.23749840e-07, 3.34154580e-04, 9.99665600e-01],\n",
       "       [3.47280570e-03, 9.96194700e-01, 3.32490420e-04],\n",
       "       [6.80611200e-02, 7.76230340e-01, 1.55708490e-01],\n",
       "       [3.55673820e-01, 6.36951100e-01, 7.37501960e-03],\n",
       "       [9.95314240e-01, 1.13727205e-04, 4.57197240e-03],\n",
       "       [1.14150170e-06, 7.38279470e-03, 9.92616060e-01],\n",
       "       [8.92012300e-04, 9.99108000e-01, 5.85739400e-14],\n",
       "       [9.99999900e-01, 1.33978250e-07, 2.22405470e-14],\n",
       "       [1.25869920e-06, 9.99998330e-01, 3.15224130e-07],\n",
       "       [8.08435300e-02, 5.20408000e-01, 3.98748500e-01],\n",
       "       [9.62159900e-01, 3.72342100e-02, 6.05946700e-04],\n",
       "       [3.97865800e-02, 2.02914160e-02, 9.39922000e-01],\n",
       "       [1.51701180e-02, 9.76650800e-01, 8.17899100e-03],\n",
       "       [3.96459130e-03, 9.95928600e-01, 1.06828375e-04],\n",
       "       [3.30922570e-04, 9.99669100e-01, 6.23239740e-10],\n",
       "       [8.44599700e-06, 9.99991540e-01, 1.18294720e-13],\n",
       "       [6.51615000e-01, 1.48088215e-02, 3.33576170e-01],\n",
       "       [5.84191470e-04, 9.99415760e-01, 6.52552800e-08]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob6 = df_proba6[df_proba6['phage']=='p0040presabsSTCC_qual'].iloc[:,-3:]\n",
    "y_prob6 = y_prob6.to_numpy()\n",
    "y_prob6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6915930436913519"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo6 = rocauc_ovo(y_sel_test, y_prob6, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6915930436913519"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr6 = rocauc_ovr(y_sel_test, y_prob6, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_sel_train, X_sel_test, y_sel_train, y_sel_test = train_test_split(X_sel, y_sel,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=789,\n",
    "                                                    stratify=y_sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat7 = pd.DataFrame(X_sel_test.iloc[:,-1])\n",
    "dat7['test'] = y_sel_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strain</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>NRS063</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>NRS219</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>GA27</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>CFBREBSa119</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>NRS233</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>CFBREBSa110</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>CFBRSa05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>CFBREBSa123</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>NY360</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>CFBREBSa118</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          strain  test\n",
       "120       NRS063     1\n",
       "187       NRS219     2\n",
       "96          GA27     2\n",
       "53   CFBREBSa119     1\n",
       "197       NRS233     2\n",
       "..           ...   ...\n",
       "47   CFBREBSa110     2\n",
       "68      CFBRSa05     0\n",
       "56   CFBREBSa123     0\n",
       "231        NY360     1\n",
       "52   CFBREBSa118     2\n",
       "\n",
       "[76 rows x 2 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sel_train = X_sel_train.drop(['strain'], axis=1)\n",
    "X_sel_test = X_sel_test.drop(['strain'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sel3 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_sel_train.shape[1],)),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sel3.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 177 samples, validate on 76 samples\n",
      "Epoch 1/1000\n",
      "177/177 [==============================] - 0s 628us/step - loss: 18.3438 - accuracy: 0.3220 - val_loss: 23.4208 - val_accuracy: 0.3158\n",
      "Epoch 2/1000\n",
      "177/177 [==============================] - 0s 63us/step - loss: 16.2084 - accuracy: 0.3333 - val_loss: 21.2330 - val_accuracy: 0.3553\n",
      "Epoch 3/1000\n",
      "177/177 [==============================] - 0s 119us/step - loss: 14.1420 - accuracy: 0.3616 - val_loss: 19.1816 - val_accuracy: 0.3947\n",
      "Epoch 4/1000\n",
      "177/177 [==============================] - 0s 75us/step - loss: 12.4666 - accuracy: 0.3729 - val_loss: 17.1185 - val_accuracy: 0.3553\n",
      "Epoch 5/1000\n",
      "177/177 [==============================] - 0s 102us/step - loss: 10.5170 - accuracy: 0.3390 - val_loss: 15.1804 - val_accuracy: 0.4079\n",
      "Epoch 6/1000\n",
      "177/177 [==============================] - 0s 116us/step - loss: 8.9393 - accuracy: 0.3277 - val_loss: 14.0285 - val_accuracy: 0.3026\n",
      "Epoch 7/1000\n",
      "177/177 [==============================] - 0s 102us/step - loss: 8.4973 - accuracy: 0.3051 - val_loss: 13.1009 - val_accuracy: 0.3026\n",
      "Epoch 8/1000\n",
      "177/177 [==============================] - 0s 109us/step - loss: 7.8078 - accuracy: 0.3051 - val_loss: 11.6401 - val_accuracy: 0.3026\n",
      "Epoch 9/1000\n",
      "177/177 [==============================] - 0s 100us/step - loss: 6.6446 - accuracy: 0.3164 - val_loss: 10.3081 - val_accuracy: 0.3684\n",
      "Epoch 10/1000\n",
      "177/177 [==============================] - 0s 108us/step - loss: 5.9770 - accuracy: 0.3842 - val_loss: 9.5086 - val_accuracy: 0.3684\n",
      "Epoch 11/1000\n",
      "177/177 [==============================] - 0s 109us/step - loss: 5.4966 - accuracy: 0.4011 - val_loss: 8.4803 - val_accuracy: 0.3553\n",
      "Epoch 12/1000\n",
      "177/177 [==============================] - 0s 99us/step - loss: 4.8229 - accuracy: 0.4294 - val_loss: 7.2855 - val_accuracy: 0.3158\n",
      "Epoch 13/1000\n",
      "177/177 [==============================] - 0s 185us/step - loss: 4.0828 - accuracy: 0.4181 - val_loss: 6.4822 - val_accuracy: 0.2895\n",
      "Epoch 14/1000\n",
      "177/177 [==============================] - 0s 130us/step - loss: 3.5903 - accuracy: 0.4011 - val_loss: 5.4584 - val_accuracy: 0.3158\n",
      "Epoch 15/1000\n",
      "177/177 [==============================] - 0s 149us/step - loss: 2.8366 - accuracy: 0.4407 - val_loss: 4.4214 - val_accuracy: 0.3553\n",
      "Epoch 16/1000\n",
      "177/177 [==============================] - 0s 124us/step - loss: 2.3517 - accuracy: 0.4689 - val_loss: 3.5969 - val_accuracy: 0.3289\n",
      "Epoch 17/1000\n",
      "177/177 [==============================] - 0s 129us/step - loss: 1.8866 - accuracy: 0.4802 - val_loss: 2.6254 - val_accuracy: 0.3816\n",
      "Epoch 18/1000\n",
      "177/177 [==============================] - 0s 108us/step - loss: 1.3739 - accuracy: 0.5085 - val_loss: 2.0193 - val_accuracy: 0.3421\n",
      "Epoch 19/1000\n",
      "177/177 [==============================] - 0s 106us/step - loss: 1.1733 - accuracy: 0.5198 - val_loss: 1.4332 - val_accuracy: 0.3947\n",
      "Epoch 20/1000\n",
      "177/177 [==============================] - 0s 99us/step - loss: 1.0850 - accuracy: 0.5650 - val_loss: 1.3212 - val_accuracy: 0.3553\n",
      "Epoch 21/1000\n",
      "177/177 [==============================] - 0s 87us/step - loss: 1.2381 - accuracy: 0.5593 - val_loss: 1.3387 - val_accuracy: 0.4079\n",
      "Epoch 22/1000\n",
      "177/177 [==============================] - 0s 91us/step - loss: 1.1253 - accuracy: 0.5650 - val_loss: 1.3769 - val_accuracy: 0.4211\n",
      "Epoch 23/1000\n",
      "177/177 [==============================] - 0s 75us/step - loss: 0.9588 - accuracy: 0.5650 - val_loss: 1.5603 - val_accuracy: 0.4605\n",
      "Epoch 24/1000\n",
      "177/177 [==============================] - 0s 77us/step - loss: 0.9901 - accuracy: 0.5876 - val_loss: 1.5986 - val_accuracy: 0.4737\n",
      "Epoch 25/1000\n",
      "177/177 [==============================] - 0s 84us/step - loss: 0.9466 - accuracy: 0.6102 - val_loss: 1.5827 - val_accuracy: 0.4605\n",
      "Epoch 26/1000\n",
      "177/177 [==============================] - 0s 115us/step - loss: 0.9414 - accuracy: 0.6102 - val_loss: 1.4300 - val_accuracy: 0.4605\n",
      "Epoch 27/1000\n",
      "177/177 [==============================] - 0s 118us/step - loss: 0.8763 - accuracy: 0.6215 - val_loss: 1.2847 - val_accuracy: 0.4474\n",
      "Epoch 28/1000\n",
      "177/177 [==============================] - 0s 102us/step - loss: 0.8288 - accuracy: 0.6215 - val_loss: 1.2125 - val_accuracy: 0.3947\n",
      "Epoch 29/1000\n",
      "177/177 [==============================] - 0s 117us/step - loss: 0.8315 - accuracy: 0.6102 - val_loss: 1.1882 - val_accuracy: 0.4079\n",
      "Epoch 30/1000\n",
      "177/177 [==============================] - 0s 108us/step - loss: 0.8111 - accuracy: 0.6215 - val_loss: 1.2080 - val_accuracy: 0.4474\n",
      "Epoch 31/1000\n",
      "177/177 [==============================] - 0s 106us/step - loss: 0.7906 - accuracy: 0.6441 - val_loss: 1.2290 - val_accuracy: 0.4342\n",
      "Epoch 32/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.7809 - accuracy: 0.6384 - val_loss: 1.2265 - val_accuracy: 0.4474\n",
      "Epoch 33/1000\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.7852 - accuracy: 0.6441 - val_loss: 1.2182 - val_accuracy: 0.4605\n",
      "Epoch 34/1000\n",
      "177/177 [==============================] - 0s 68us/step - loss: 0.7586 - accuracy: 0.6836 - val_loss: 1.2122 - val_accuracy: 0.4605\n",
      "Epoch 35/1000\n",
      "177/177 [==============================] - 0s 68us/step - loss: 0.7624 - accuracy: 0.6780 - val_loss: 1.1650 - val_accuracy: 0.4474\n",
      "Epoch 36/1000\n",
      "177/177 [==============================] - 0s 56us/step - loss: 0.7509 - accuracy: 0.6836 - val_loss: 1.2015 - val_accuracy: 0.4211\n",
      "Epoch 37/1000\n",
      "177/177 [==============================] - 0s 59us/step - loss: 0.7930 - accuracy: 0.6610 - val_loss: 1.1422 - val_accuracy: 0.4211\n",
      "Epoch 38/1000\n",
      "177/177 [==============================] - 0s 69us/step - loss: 0.7476 - accuracy: 0.7119 - val_loss: 1.2128 - val_accuracy: 0.4211\n",
      "Epoch 39/1000\n",
      "177/177 [==============================] - 0s 59us/step - loss: 0.8205 - accuracy: 0.6836 - val_loss: 1.2464 - val_accuracy: 0.4211\n",
      "Epoch 40/1000\n",
      "177/177 [==============================] - 0s 76us/step - loss: 0.7821 - accuracy: 0.7175 - val_loss: 1.2350 - val_accuracy: 0.4211\n",
      "Epoch 41/1000\n",
      "177/177 [==============================] - 0s 95us/step - loss: 0.8020 - accuracy: 0.6949 - val_loss: 1.2127 - val_accuracy: 0.4211\n",
      "Epoch 42/1000\n",
      "177/177 [==============================] - 0s 112us/step - loss: 0.7898 - accuracy: 0.7062 - val_loss: 1.1138 - val_accuracy: 0.4605\n",
      "Epoch 43/1000\n",
      "177/177 [==============================] - 0s 125us/step - loss: 0.7040 - accuracy: 0.7175 - val_loss: 1.1695 - val_accuracy: 0.4211\n",
      "Epoch 44/1000\n",
      "177/177 [==============================] - 0s 92us/step - loss: 0.7127 - accuracy: 0.7119 - val_loss: 1.1710 - val_accuracy: 0.4342\n",
      "Epoch 45/1000\n",
      "177/177 [==============================] - 0s 97us/step - loss: 0.7072 - accuracy: 0.7401 - val_loss: 1.1911 - val_accuracy: 0.4342\n",
      "Epoch 46/1000\n",
      "177/177 [==============================] - 0s 112us/step - loss: 0.6942 - accuracy: 0.7514 - val_loss: 1.1844 - val_accuracy: 0.4211\n",
      "Epoch 47/1000\n",
      "177/177 [==============================] - 0s 83us/step - loss: 0.6907 - accuracy: 0.7458 - val_loss: 1.1375 - val_accuracy: 0.4211\n",
      "Epoch 48/1000\n",
      "177/177 [==============================] - 0s 96us/step - loss: 0.6784 - accuracy: 0.7740 - val_loss: 1.1471 - val_accuracy: 0.4211\n",
      "Epoch 49/1000\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.6833 - accuracy: 0.7571 - val_loss: 1.1698 - val_accuracy: 0.4342\n",
      "Epoch 50/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.7089 - accuracy: 0.7684 - val_loss: 1.2309 - val_accuracy: 0.4342\n",
      "Epoch 51/1000\n",
      "177/177 [==============================] - 0s 83us/step - loss: 0.6768 - accuracy: 0.7571 - val_loss: 1.1907 - val_accuracy: 0.4342\n",
      "Epoch 52/1000\n",
      "177/177 [==============================] - 0s 166us/step - loss: 0.6722 - accuracy: 0.7571 - val_loss: 1.2010 - val_accuracy: 0.4342\n",
      "Epoch 53/1000\n",
      "177/177 [==============================] - 0s 82us/step - loss: 0.6942 - accuracy: 0.7627 - val_loss: 1.1695 - val_accuracy: 0.4342\n",
      "Epoch 54/1000\n",
      "177/177 [==============================] - 0s 89us/step - loss: 0.7080 - accuracy: 0.7458 - val_loss: 1.1871 - val_accuracy: 0.4342\n",
      "Epoch 55/1000\n",
      "177/177 [==============================] - 0s 99us/step - loss: 0.6749 - accuracy: 0.7740 - val_loss: 1.2209 - val_accuracy: 0.4211\n",
      "Epoch 56/1000\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.7068 - accuracy: 0.7627 - val_loss: 1.2352 - val_accuracy: 0.4211\n",
      "Epoch 57/1000\n",
      "177/177 [==============================] - 0s 91us/step - loss: 0.6498 - accuracy: 0.7740 - val_loss: 1.2196 - val_accuracy: 0.4342\n",
      "Epoch 58/1000\n",
      "177/177 [==============================] - 0s 84us/step - loss: 0.7331 - accuracy: 0.7514 - val_loss: 1.2350 - val_accuracy: 0.3684\n",
      "Epoch 59/1000\n",
      "177/177 [==============================] - 0s 89us/step - loss: 0.7001 - accuracy: 0.7627 - val_loss: 1.1436 - val_accuracy: 0.4211\n",
      "Epoch 60/1000\n",
      "177/177 [==============================] - 0s 128us/step - loss: 0.6228 - accuracy: 0.7853 - val_loss: 1.2101 - val_accuracy: 0.4211\n",
      "Epoch 61/1000\n",
      "177/177 [==============================] - 0s 92us/step - loss: 0.6583 - accuracy: 0.7797 - val_loss: 1.1744 - val_accuracy: 0.4342\n",
      "Epoch 62/1000\n",
      "177/177 [==============================] - 0s 108us/step - loss: 0.6089 - accuracy: 0.8079 - val_loss: 1.1957 - val_accuracy: 0.4342\n",
      "Epoch 63/1000\n",
      "177/177 [==============================] - 0s 89us/step - loss: 0.6295 - accuracy: 0.7910 - val_loss: 1.1687 - val_accuracy: 0.4474\n",
      "Epoch 64/1000\n",
      "177/177 [==============================] - 0s 96us/step - loss: 0.6176 - accuracy: 0.7966 - val_loss: 1.1820 - val_accuracy: 0.4342\n",
      "Epoch 65/1000\n",
      "177/177 [==============================] - 0s 144us/step - loss: 0.6036 - accuracy: 0.7966 - val_loss: 1.1530 - val_accuracy: 0.4474\n",
      "Epoch 66/1000\n",
      "177/177 [==============================] - 0s 114us/step - loss: 0.6128 - accuracy: 0.8023 - val_loss: 1.1547 - val_accuracy: 0.4474\n",
      "Epoch 67/1000\n",
      "177/177 [==============================] - 0s 104us/step - loss: 0.6098 - accuracy: 0.8023 - val_loss: 1.2022 - val_accuracy: 0.4211\n",
      "Epoch 68/1000\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.5977 - accuracy: 0.8079 - val_loss: 1.1878 - val_accuracy: 0.4474\n",
      "Epoch 69/1000\n",
      "177/177 [==============================] - 0s 124us/step - loss: 0.5969 - accuracy: 0.8079 - val_loss: 1.1536 - val_accuracy: 0.4474\n",
      "Epoch 70/1000\n",
      "177/177 [==============================] - 0s 132us/step - loss: 0.5828 - accuracy: 0.7910 - val_loss: 1.1864 - val_accuracy: 0.4474\n",
      "Epoch 71/1000\n",
      "177/177 [==============================] - 0s 95us/step - loss: 0.6221 - accuracy: 0.8023 - val_loss: 1.1640 - val_accuracy: 0.4474\n",
      "Epoch 72/1000\n",
      "177/177 [==============================] - 0s 126us/step - loss: 0.6087 - accuracy: 0.7966 - val_loss: 1.2277 - val_accuracy: 0.4342\n",
      "Epoch 73/1000\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.6662 - accuracy: 0.7853 - val_loss: 1.1954 - val_accuracy: 0.4342\n",
      "Epoch 74/1000\n",
      "177/177 [==============================] - 0s 83us/step - loss: 0.6051 - accuracy: 0.7966 - val_loss: 1.2001 - val_accuracy: 0.4474\n",
      "Epoch 75/1000\n",
      "177/177 [==============================] - 0s 70us/step - loss: 0.6451 - accuracy: 0.7966 - val_loss: 1.2045 - val_accuracy: 0.4474\n",
      "Epoch 76/1000\n",
      "177/177 [==============================] - 0s 103us/step - loss: 0.5936 - accuracy: 0.7966 - val_loss: 1.1650 - val_accuracy: 0.4474\n",
      "Epoch 77/1000\n",
      "177/177 [==============================] - 0s 83us/step - loss: 0.5899 - accuracy: 0.7966 - val_loss: 1.1725 - val_accuracy: 0.4605\n",
      "Epoch 78/1000\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.5594 - accuracy: 0.8136 - val_loss: 1.2372 - val_accuracy: 0.4605\n",
      "Epoch 79/1000\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.5702 - accuracy: 0.7910 - val_loss: 1.1949 - val_accuracy: 0.4868\n",
      "Epoch 80/1000\n",
      "177/177 [==============================] - 0s 68us/step - loss: 0.5437 - accuracy: 0.8136 - val_loss: 1.1973 - val_accuracy: 0.4474\n",
      "Epoch 81/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.5790 - accuracy: 0.7966 - val_loss: 1.1397 - val_accuracy: 0.4737\n",
      "Epoch 82/1000\n",
      "177/177 [==============================] - 0s 69us/step - loss: 0.5464 - accuracy: 0.8079 - val_loss: 1.1639 - val_accuracy: 0.4605\n",
      "Epoch 83/1000\n",
      "177/177 [==============================] - 0s 92us/step - loss: 0.5384 - accuracy: 0.8023 - val_loss: 1.1609 - val_accuracy: 0.4868\n",
      "Epoch 84/1000\n",
      "177/177 [==============================] - 0s 76us/step - loss: 0.5387 - accuracy: 0.8305 - val_loss: 1.1871 - val_accuracy: 0.4605\n",
      "Epoch 85/1000\n",
      "177/177 [==============================] - 0s 60us/step - loss: 0.5282 - accuracy: 0.8305 - val_loss: 1.2053 - val_accuracy: 0.4868\n",
      "Epoch 86/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.5337 - accuracy: 0.8192 - val_loss: 1.1595 - val_accuracy: 0.4868\n",
      "Epoch 87/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.5274 - accuracy: 0.8192 - val_loss: 1.1650 - val_accuracy: 0.4868\n",
      "Epoch 88/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.5263 - accuracy: 0.8249 - val_loss: 1.1830 - val_accuracy: 0.5000\n",
      "Epoch 89/1000\n",
      "177/177 [==============================] - 0s 82us/step - loss: 0.5282 - accuracy: 0.8305 - val_loss: 1.1850 - val_accuracy: 0.4868\n",
      "Epoch 90/1000\n",
      "177/177 [==============================] - 0s 56us/step - loss: 0.5180 - accuracy: 0.8362 - val_loss: 1.2375 - val_accuracy: 0.5000\n",
      "Epoch 91/1000\n",
      "177/177 [==============================] - 0s 87us/step - loss: 0.5935 - accuracy: 0.8362 - val_loss: 1.1954 - val_accuracy: 0.5000\n",
      "Epoch 92/1000\n",
      "177/177 [==============================] - 0s 93us/step - loss: 0.5658 - accuracy: 0.8136 - val_loss: 1.2878 - val_accuracy: 0.4605\n",
      "Epoch 93/1000\n",
      "177/177 [==============================] - 0s 79us/step - loss: 0.7212 - accuracy: 0.7684 - val_loss: 1.3094 - val_accuracy: 0.4605\n",
      "Epoch 94/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.6767 - accuracy: 0.7910 - val_loss: 1.1678 - val_accuracy: 0.4868\n",
      "Epoch 95/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.5091 - accuracy: 0.8362 - val_loss: 1.2661 - val_accuracy: 0.4605\n",
      "Epoch 96/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.6231 - accuracy: 0.8192 - val_loss: 1.3221 - val_accuracy: 0.4737\n",
      "Epoch 97/1000\n",
      "177/177 [==============================] - 0s 74us/step - loss: 0.5963 - accuracy: 0.8079 - val_loss: 1.1508 - val_accuracy: 0.5132\n",
      "Epoch 98/1000\n",
      "177/177 [==============================] - 0s 74us/step - loss: 0.5181 - accuracy: 0.8362 - val_loss: 1.1983 - val_accuracy: 0.5000\n",
      "Epoch 99/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.5709 - accuracy: 0.8305 - val_loss: 1.1957 - val_accuracy: 0.5000\n",
      "Epoch 100/1000\n",
      "177/177 [==============================] - 0s 58us/step - loss: 0.5246 - accuracy: 0.8362 - val_loss: 1.2395 - val_accuracy: 0.5263\n",
      "Epoch 101/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.5153 - accuracy: 0.8362 - val_loss: 1.2660 - val_accuracy: 0.5263\n",
      "Epoch 102/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.4948 - accuracy: 0.8305 - val_loss: 1.1766 - val_accuracy: 0.5263\n",
      "Epoch 103/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.5012 - accuracy: 0.8362 - val_loss: 1.1690 - val_accuracy: 0.5132\n",
      "Epoch 104/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.4740 - accuracy: 0.8531 - val_loss: 1.2167 - val_accuracy: 0.5263\n",
      "Epoch 105/1000\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.4933 - accuracy: 0.8418 - val_loss: 1.1850 - val_accuracy: 0.5263\n",
      "Epoch 106/1000\n",
      "177/177 [==============================] - 0s 92us/step - loss: 0.4702 - accuracy: 0.8475 - val_loss: 1.1925 - val_accuracy: 0.5132\n",
      "Epoch 107/1000\n",
      "177/177 [==============================] - 0s 112us/step - loss: 0.4888 - accuracy: 0.8362 - val_loss: 1.1983 - val_accuracy: 0.5263\n",
      "Epoch 108/1000\n",
      "177/177 [==============================] - 0s 118us/step - loss: 0.4626 - accuracy: 0.8475 - val_loss: 1.2395 - val_accuracy: 0.5263\n",
      "Epoch 109/1000\n",
      "177/177 [==============================] - 0s 110us/step - loss: 0.4709 - accuracy: 0.8475 - val_loss: 1.1811 - val_accuracy: 0.5000\n",
      "Epoch 110/1000\n",
      "177/177 [==============================] - 0s 147us/step - loss: 0.4659 - accuracy: 0.8475 - val_loss: 1.1772 - val_accuracy: 0.5000\n",
      "Epoch 111/1000\n",
      "177/177 [==============================] - 0s 185us/step - loss: 0.4487 - accuracy: 0.8588 - val_loss: 1.2021 - val_accuracy: 0.5000\n",
      "Epoch 112/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177/177 [==============================] - 0s 128us/step - loss: 0.4577 - accuracy: 0.8418 - val_loss: 1.2041 - val_accuracy: 0.4868\n",
      "Epoch 113/1000\n",
      "177/177 [==============================] - 0s 135us/step - loss: 0.4550 - accuracy: 0.8588 - val_loss: 1.1937 - val_accuracy: 0.5000\n",
      "Epoch 114/1000\n",
      "177/177 [==============================] - 0s 77us/step - loss: 0.4420 - accuracy: 0.8644 - val_loss: 1.2214 - val_accuracy: 0.5000\n",
      "Epoch 115/1000\n",
      "177/177 [==============================] - 0s 81us/step - loss: 0.4527 - accuracy: 0.8644 - val_loss: 1.2199 - val_accuracy: 0.5000\n",
      "Epoch 116/1000\n",
      "177/177 [==============================] - 0s 85us/step - loss: 0.4386 - accuracy: 0.8757 - val_loss: 1.1762 - val_accuracy: 0.5000\n",
      "Epoch 117/1000\n",
      "177/177 [==============================] - 0s 87us/step - loss: 0.4486 - accuracy: 0.8531 - val_loss: 1.1669 - val_accuracy: 0.5132\n",
      "Epoch 118/1000\n",
      "177/177 [==============================] - 0s 77us/step - loss: 0.4408 - accuracy: 0.8531 - val_loss: 1.2104 - val_accuracy: 0.5000\n",
      "Epoch 119/1000\n",
      "177/177 [==============================] - 0s 76us/step - loss: 0.4338 - accuracy: 0.8588 - val_loss: 1.2097 - val_accuracy: 0.5263\n",
      "Epoch 120/1000\n",
      "177/177 [==============================] - 0s 85us/step - loss: 0.4328 - accuracy: 0.8644 - val_loss: 1.2110 - val_accuracy: 0.5132\n",
      "Epoch 121/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.4260 - accuracy: 0.8757 - val_loss: 1.2080 - val_accuracy: 0.5132\n",
      "Epoch 122/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.4266 - accuracy: 0.8757 - val_loss: 1.2099 - val_accuracy: 0.5263\n",
      "Epoch 123/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.4284 - accuracy: 0.8701 - val_loss: 1.2034 - val_accuracy: 0.5395\n",
      "Epoch 124/1000\n",
      "177/177 [==============================] - 0s 146us/step - loss: 0.4212 - accuracy: 0.8757 - val_loss: 1.2391 - val_accuracy: 0.5263\n",
      "Epoch 125/1000\n",
      "177/177 [==============================] - 0s 125us/step - loss: 0.4305 - accuracy: 0.8531 - val_loss: 1.2099 - val_accuracy: 0.5526\n",
      "Epoch 126/1000\n",
      "177/177 [==============================] - 0s 114us/step - loss: 0.4196 - accuracy: 0.8588 - val_loss: 1.1977 - val_accuracy: 0.5526\n",
      "Epoch 127/1000\n",
      "177/177 [==============================] - 0s 115us/step - loss: 0.4193 - accuracy: 0.8588 - val_loss: 1.2313 - val_accuracy: 0.5395\n",
      "Epoch 128/1000\n",
      "177/177 [==============================] - 0s 95us/step - loss: 0.4206 - accuracy: 0.8701 - val_loss: 1.2068 - val_accuracy: 0.5395\n",
      "Epoch 129/1000\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.4067 - accuracy: 0.8814 - val_loss: 1.1941 - val_accuracy: 0.5000\n",
      "Epoch 130/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.4070 - accuracy: 0.8870 - val_loss: 1.2119 - val_accuracy: 0.5000\n",
      "Epoch 131/1000\n",
      "177/177 [==============================] - 0s 53us/step - loss: 0.4018 - accuracy: 0.8870 - val_loss: 1.2352 - val_accuracy: 0.5000\n",
      "Epoch 132/1000\n",
      "177/177 [==============================] - 0s 74us/step - loss: 0.4038 - accuracy: 0.8870 - val_loss: 1.2170 - val_accuracy: 0.5263\n",
      "Epoch 133/1000\n",
      "177/177 [==============================] - 0s 84us/step - loss: 0.4004 - accuracy: 0.8814 - val_loss: 1.2252 - val_accuracy: 0.5395\n",
      "Epoch 134/1000\n",
      "177/177 [==============================] - 0s 148us/step - loss: 0.3956 - accuracy: 0.8870 - val_loss: 1.2446 - val_accuracy: 0.5395\n",
      "Epoch 135/1000\n",
      "177/177 [==============================] - 0s 122us/step - loss: 0.3985 - accuracy: 0.8814 - val_loss: 1.2154 - val_accuracy: 0.5395\n",
      "Epoch 136/1000\n",
      "177/177 [==============================] - 0s 92us/step - loss: 0.3975 - accuracy: 0.8757 - val_loss: 1.1999 - val_accuracy: 0.5395\n",
      "Epoch 137/1000\n",
      "177/177 [==============================] - 0s 95us/step - loss: 0.3919 - accuracy: 0.8870 - val_loss: 1.2432 - val_accuracy: 0.5263\n",
      "Epoch 138/1000\n",
      "177/177 [==============================] - 0s 138us/step - loss: 0.3919 - accuracy: 0.8814 - val_loss: 1.2341 - val_accuracy: 0.5000\n",
      "Epoch 139/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.3879 - accuracy: 0.8927 - val_loss: 1.2143 - val_accuracy: 0.5000\n",
      "Epoch 140/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.3843 - accuracy: 0.8870 - val_loss: 1.2084 - val_accuracy: 0.5000\n",
      "Epoch 141/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.3819 - accuracy: 0.8870 - val_loss: 1.2252 - val_accuracy: 0.5132\n",
      "Epoch 142/1000\n",
      "177/177 [==============================] - 0s 74us/step - loss: 0.4049 - accuracy: 0.8757 - val_loss: 1.2205 - val_accuracy: 0.5263\n",
      "Epoch 143/1000\n",
      "177/177 [==============================] - 0s 89us/step - loss: 0.3858 - accuracy: 0.8870 - val_loss: 1.2907 - val_accuracy: 0.5263\n",
      "Epoch 144/1000\n",
      "177/177 [==============================] - 0s 79us/step - loss: 0.4432 - accuracy: 0.8757 - val_loss: 1.2091 - val_accuracy: 0.5132\n",
      "Epoch 145/1000\n",
      "177/177 [==============================] - 0s 87us/step - loss: 0.4266 - accuracy: 0.8757 - val_loss: 1.2844 - val_accuracy: 0.5132\n",
      "Epoch 146/1000\n",
      "177/177 [==============================] - 0s 70us/step - loss: 0.4093 - accuracy: 0.8757 - val_loss: 1.2211 - val_accuracy: 0.5000\n",
      "Epoch 147/1000\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.3995 - accuracy: 0.8814 - val_loss: 1.2377 - val_accuracy: 0.5000\n",
      "Epoch 148/1000\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.3893 - accuracy: 0.8927 - val_loss: 1.2963 - val_accuracy: 0.5000\n",
      "Epoch 149/1000\n",
      "177/177 [==============================] - 0s 94us/step - loss: 0.4405 - accuracy: 0.8814 - val_loss: 1.2438 - val_accuracy: 0.5263\n",
      "Epoch 150/1000\n",
      "177/177 [==============================] - 0s 97us/step - loss: 0.3680 - accuracy: 0.8870 - val_loss: 1.2321 - val_accuracy: 0.5395\n",
      "Epoch 151/1000\n",
      "177/177 [==============================] - 0s 102us/step - loss: 0.3870 - accuracy: 0.8870 - val_loss: 1.2499 - val_accuracy: 0.5263\n",
      "Epoch 152/1000\n",
      "177/177 [==============================] - 0s 126us/step - loss: 0.3769 - accuracy: 0.8927 - val_loss: 1.2795 - val_accuracy: 0.5263\n",
      "Epoch 153/1000\n",
      "177/177 [==============================] - 0s 106us/step - loss: 0.3701 - accuracy: 0.8983 - val_loss: 1.2303 - val_accuracy: 0.5132\n",
      "Epoch 154/1000\n",
      "177/177 [==============================] - 0s 103us/step - loss: 0.3781 - accuracy: 0.8870 - val_loss: 1.2231 - val_accuracy: 0.5132\n",
      "Epoch 155/1000\n",
      "177/177 [==============================] - 0s 105us/step - loss: 0.3595 - accuracy: 0.8983 - val_loss: 1.2694 - val_accuracy: 0.5132\n",
      "Epoch 156/1000\n",
      "177/177 [==============================] - 0s 99us/step - loss: 0.3536 - accuracy: 0.9040 - val_loss: 1.2735 - val_accuracy: 0.5132\n",
      "Epoch 157/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.3512 - accuracy: 0.9040 - val_loss: 1.2885 - val_accuracy: 0.5132\n",
      "Epoch 158/1000\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.3525 - accuracy: 0.9040 - val_loss: 1.2958 - val_accuracy: 0.5000\n",
      "Epoch 159/1000\n",
      "177/177 [==============================] - 0s 58us/step - loss: 0.3430 - accuracy: 0.9040 - val_loss: 1.2655 - val_accuracy: 0.5132\n",
      "Epoch 160/1000\n",
      "177/177 [==============================] - 0s 60us/step - loss: 0.3460 - accuracy: 0.8983 - val_loss: 1.2465 - val_accuracy: 0.5000\n",
      "Epoch 161/1000\n",
      "177/177 [==============================] - 0s 63us/step - loss: 0.3435 - accuracy: 0.9040 - val_loss: 1.2646 - val_accuracy: 0.5000\n",
      "Epoch 162/1000\n",
      "177/177 [==============================] - 0s 57us/step - loss: 0.3390 - accuracy: 0.9096 - val_loss: 1.2733 - val_accuracy: 0.5000\n",
      "Epoch 163/1000\n",
      "177/177 [==============================] - 0s 59us/step - loss: 0.3380 - accuracy: 0.9096 - val_loss: 1.3079 - val_accuracy: 0.5000\n",
      "Epoch 164/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.3377 - accuracy: 0.9209 - val_loss: 1.3299 - val_accuracy: 0.5000\n",
      "Epoch 165/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.3363 - accuracy: 0.9096 - val_loss: 1.3137 - val_accuracy: 0.5132\n",
      "Epoch 166/1000\n",
      "177/177 [==============================] - 0s 78us/step - loss: 0.3302 - accuracy: 0.9153 - val_loss: 1.2810 - val_accuracy: 0.5000\n",
      "Epoch 167/1000\n",
      "177/177 [==============================] - 0s 691us/step - loss: 0.3445 - accuracy: 0.8983 - val_loss: 1.2894 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 168/1000\n",
      "177/177 [==============================] - 0s 385us/step - loss: 0.3301 - accuracy: 0.9040 - val_loss: 1.3034 - val_accuracy: 0.5000\n",
      "Epoch 169/1000\n",
      "177/177 [==============================] - 0s 443us/step - loss: 0.3277 - accuracy: 0.8983 - val_loss: 1.3379 - val_accuracy: 0.5132\n",
      "Epoch 170/1000\n",
      "177/177 [==============================] - 0s 154us/step - loss: 0.3326 - accuracy: 0.9040 - val_loss: 1.3273 - val_accuracy: 0.5132\n",
      "Epoch 171/1000\n",
      "177/177 [==============================] - 0s 107us/step - loss: 0.3233 - accuracy: 0.9096 - val_loss: 1.3190 - val_accuracy: 0.5000\n",
      "Epoch 172/1000\n",
      "177/177 [==============================] - 0s 79us/step - loss: 0.3221 - accuracy: 0.9153 - val_loss: 1.3352 - val_accuracy: 0.5000\n",
      "Epoch 173/1000\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.3211 - accuracy: 0.9153 - val_loss: 1.3086 - val_accuracy: 0.4868\n",
      "Epoch 174/1000\n",
      "177/177 [==============================] - 0s 63us/step - loss: 0.3165 - accuracy: 0.9153 - val_loss: 1.3175 - val_accuracy: 0.4868\n",
      "Epoch 175/1000\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.3160 - accuracy: 0.9153 - val_loss: 1.3451 - val_accuracy: 0.4868\n",
      "Epoch 176/1000\n",
      "177/177 [==============================] - 0s 69us/step - loss: 0.3141 - accuracy: 0.9209 - val_loss: 1.3377 - val_accuracy: 0.4868\n",
      "Epoch 177/1000\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.3126 - accuracy: 0.9153 - val_loss: 1.3556 - val_accuracy: 0.5263\n",
      "Epoch 178/1000\n",
      "177/177 [==============================] - 0s 58us/step - loss: 0.3100 - accuracy: 0.9266 - val_loss: 1.3503 - val_accuracy: 0.4868\n",
      "Epoch 179/1000\n",
      "177/177 [==============================] - 0s 134us/step - loss: 0.3117 - accuracy: 0.9096 - val_loss: 1.3481 - val_accuracy: 0.5000\n",
      "Epoch 180/1000\n",
      "177/177 [==============================] - 0s 156us/step - loss: 0.3141 - accuracy: 0.9153 - val_loss: 1.3418 - val_accuracy: 0.5000\n",
      "Epoch 181/1000\n",
      "177/177 [==============================] - 0s 120us/step - loss: 0.3036 - accuracy: 0.9096 - val_loss: 1.3343 - val_accuracy: 0.5000\n",
      "Epoch 182/1000\n",
      "177/177 [==============================] - 0s 123us/step - loss: 0.3173 - accuracy: 0.9040 - val_loss: 1.3624 - val_accuracy: 0.5000\n",
      "Epoch 183/1000\n",
      "177/177 [==============================] - 0s 79us/step - loss: 0.3045 - accuracy: 0.9209 - val_loss: 1.3360 - val_accuracy: 0.5000\n",
      "Epoch 184/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.3022 - accuracy: 0.9153 - val_loss: 1.3709 - val_accuracy: 0.5000\n",
      "Epoch 185/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.2996 - accuracy: 0.9153 - val_loss: 1.3748 - val_accuracy: 0.5000\n",
      "Epoch 186/1000\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.2989 - accuracy: 0.9153 - val_loss: 1.3558 - val_accuracy: 0.5000\n",
      "Epoch 187/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.2963 - accuracy: 0.9153 - val_loss: 1.3585 - val_accuracy: 0.5000\n",
      "Epoch 188/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.2949 - accuracy: 0.9153 - val_loss: 1.3781 - val_accuracy: 0.5000\n",
      "Epoch 189/1000\n",
      "177/177 [==============================] - 0s 59us/step - loss: 0.2956 - accuracy: 0.9209 - val_loss: 1.3764 - val_accuracy: 0.5000\n",
      "Epoch 190/1000\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.2910 - accuracy: 0.9153 - val_loss: 1.3690 - val_accuracy: 0.5000\n",
      "Epoch 191/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.2935 - accuracy: 0.9209 - val_loss: 1.3836 - val_accuracy: 0.5132\n",
      "Epoch 192/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.2927 - accuracy: 0.9209 - val_loss: 1.3612 - val_accuracy: 0.5132\n",
      "Epoch 193/1000\n",
      "177/177 [==============================] - 0s 74us/step - loss: 0.2879 - accuracy: 0.9153 - val_loss: 1.3566 - val_accuracy: 0.5000\n",
      "Epoch 194/1000\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.2900 - accuracy: 0.9096 - val_loss: 1.3906 - val_accuracy: 0.5000\n",
      "Epoch 195/1000\n",
      "177/177 [==============================] - 0s 78us/step - loss: 0.2970 - accuracy: 0.9209 - val_loss: 1.3804 - val_accuracy: 0.5000\n",
      "Epoch 196/1000\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.2971 - accuracy: 0.9153 - val_loss: 1.4245 - val_accuracy: 0.5132\n",
      "Epoch 197/1000\n",
      "177/177 [==============================] - 0s 69us/step - loss: 0.3353 - accuracy: 0.9153 - val_loss: 1.3812 - val_accuracy: 0.5132\n",
      "Epoch 198/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.3019 - accuracy: 0.9153 - val_loss: 1.4153 - val_accuracy: 0.5132\n",
      "Epoch 199/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.2892 - accuracy: 0.9209 - val_loss: 1.3703 - val_accuracy: 0.5132\n",
      "Epoch 200/1000\n",
      "177/177 [==============================] - 0s 82us/step - loss: 0.3131 - accuracy: 0.9040 - val_loss: 1.3889 - val_accuracy: 0.5132\n",
      "Epoch 201/1000\n",
      "177/177 [==============================] - 0s 106us/step - loss: 0.2898 - accuracy: 0.9379 - val_loss: 1.4265 - val_accuracy: 0.4868\n",
      "Epoch 202/1000\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.2832 - accuracy: 0.9322 - val_loss: 1.3938 - val_accuracy: 0.5132\n",
      "Epoch 203/1000\n",
      "177/177 [==============================] - 0s 93us/step - loss: 0.2833 - accuracy: 0.9096 - val_loss: 1.3908 - val_accuracy: 0.5132\n",
      "Epoch 204/1000\n",
      "177/177 [==============================] - 0s 99us/step - loss: 0.2780 - accuracy: 0.9096 - val_loss: 1.4279 - val_accuracy: 0.5132\n",
      "Epoch 205/1000\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.2927 - accuracy: 0.9153 - val_loss: 1.4088 - val_accuracy: 0.5132\n",
      "Epoch 206/1000\n",
      "177/177 [==============================] - 0s 92us/step - loss: 0.2849 - accuracy: 0.9209 - val_loss: 1.4100 - val_accuracy: 0.5132\n",
      "Epoch 207/1000\n",
      "177/177 [==============================] - 0s 83us/step - loss: 0.2877 - accuracy: 0.9209 - val_loss: 1.4641 - val_accuracy: 0.5132\n",
      "Epoch 208/1000\n",
      "177/177 [==============================] - 0s 81us/step - loss: 0.3135 - accuracy: 0.9379 - val_loss: 1.4195 - val_accuracy: 0.5132\n",
      "Epoch 209/1000\n",
      "177/177 [==============================] - 0s 78us/step - loss: 0.2955 - accuracy: 0.9266 - val_loss: 1.4108 - val_accuracy: 0.5132\n",
      "Epoch 210/1000\n",
      "177/177 [==============================] - 0s 79us/step - loss: 0.2672 - accuracy: 0.9435 - val_loss: 1.5332 - val_accuracy: 0.5000\n",
      "Epoch 211/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.3979 - accuracy: 0.9153 - val_loss: 1.4992 - val_accuracy: 0.5132\n",
      "Epoch 212/1000\n",
      "177/177 [==============================] - 0s 78us/step - loss: 0.3134 - accuracy: 0.9096 - val_loss: 1.4172 - val_accuracy: 0.4868\n",
      "Epoch 213/1000\n",
      "177/177 [==============================] - 0s 92us/step - loss: 0.4069 - accuracy: 0.8814 - val_loss: 1.4608 - val_accuracy: 0.4868\n",
      "Epoch 214/1000\n",
      "177/177 [==============================] - 0s 265us/step - loss: 0.3305 - accuracy: 0.8983 - val_loss: 1.4159 - val_accuracy: 0.5132\n",
      "Epoch 215/1000\n",
      "177/177 [==============================] - 0s 128us/step - loss: 0.2889 - accuracy: 0.9266 - val_loss: 1.6399 - val_accuracy: 0.5000\n",
      "Epoch 216/1000\n",
      "177/177 [==============================] - 0s 125us/step - loss: 0.4310 - accuracy: 0.9040 - val_loss: 1.5161 - val_accuracy: 0.4737\n",
      "Epoch 217/1000\n",
      "177/177 [==============================] - 0s 103us/step - loss: 0.2976 - accuracy: 0.9322 - val_loss: 1.4282 - val_accuracy: 0.4868\n",
      "Epoch 218/1000\n",
      "177/177 [==============================] - 0s 123us/step - loss: 0.3787 - accuracy: 0.8814 - val_loss: 1.4898 - val_accuracy: 0.4868\n",
      "Epoch 219/1000\n",
      "177/177 [==============================] - 0s 114us/step - loss: 0.3764 - accuracy: 0.9096 - val_loss: 1.4196 - val_accuracy: 0.5132\n",
      "Epoch 220/1000\n",
      "177/177 [==============================] - 0s 131us/step - loss: 0.3007 - accuracy: 0.9209 - val_loss: 1.6125 - val_accuracy: 0.5132\n",
      "Epoch 221/1000\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.3469 - accuracy: 0.9096 - val_loss: 1.4743 - val_accuracy: 0.5132\n",
      "Epoch 222/1000\n",
      "177/177 [==============================] - 0s 125us/step - loss: 0.2818 - accuracy: 0.9266 - val_loss: 1.4556 - val_accuracy: 0.5132\n",
      "Epoch 223/1000\n",
      "177/177 [==============================] - 0s 107us/step - loss: 0.2956 - accuracy: 0.9153 - val_loss: 1.4123 - val_accuracy: 0.5132\n",
      "Epoch 224/1000\n",
      "177/177 [==============================] - 0s 105us/step - loss: 0.2606 - accuracy: 0.9266 - val_loss: 1.4679 - val_accuracy: 0.5132\n",
      "Epoch 225/1000\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.2597 - accuracy: 0.9266 - val_loss: 1.4369 - val_accuracy: 0.5132\n",
      "Epoch 226/1000\n",
      "177/177 [==============================] - 0s 91us/step - loss: 0.2634 - accuracy: 0.9266 - val_loss: 1.4889 - val_accuracy: 0.5132\n",
      "Epoch 227/1000\n",
      "177/177 [==============================] - 0s 95us/step - loss: 0.2480 - accuracy: 0.9492 - val_loss: 1.5227 - val_accuracy: 0.5132\n",
      "Epoch 228/1000\n",
      "177/177 [==============================] - 0s 92us/step - loss: 0.2486 - accuracy: 0.9548 - val_loss: 1.4621 - val_accuracy: 0.5132\n",
      "Epoch 229/1000\n",
      "177/177 [==============================] - 0s 141us/step - loss: 0.2459 - accuracy: 0.9379 - val_loss: 1.4547 - val_accuracy: 0.5132\n",
      "Epoch 230/1000\n",
      "177/177 [==============================] - 0s 102us/step - loss: 0.2440 - accuracy: 0.9379 - val_loss: 1.4778 - val_accuracy: 0.5132\n",
      "Epoch 231/1000\n",
      "177/177 [==============================] - 0s 168us/step - loss: 0.2422 - accuracy: 0.9435 - val_loss: 1.5039 - val_accuracy: 0.5132\n",
      "Epoch 232/1000\n",
      "177/177 [==============================] - 0s 143us/step - loss: 0.2431 - accuracy: 0.9322 - val_loss: 1.5159 - val_accuracy: 0.5132\n",
      "Epoch 233/1000\n",
      "177/177 [==============================] - 0s 112us/step - loss: 0.2424 - accuracy: 0.9435 - val_loss: 1.5330 - val_accuracy: 0.5132\n",
      "Epoch 234/1000\n",
      "177/177 [==============================] - 0s 116us/step - loss: 0.2414 - accuracy: 0.9548 - val_loss: 1.5103 - val_accuracy: 0.5132\n",
      "Epoch 235/1000\n",
      "177/177 [==============================] - 0s 109us/step - loss: 0.2390 - accuracy: 0.9379 - val_loss: 1.4667 - val_accuracy: 0.5132\n",
      "Epoch 236/1000\n",
      "177/177 [==============================] - 0s 110us/step - loss: 0.2380 - accuracy: 0.9435 - val_loss: 1.4857 - val_accuracy: 0.5132\n",
      "Epoch 237/1000\n",
      "177/177 [==============================] - 0s 145us/step - loss: 0.2372 - accuracy: 0.9435 - val_loss: 1.5011 - val_accuracy: 0.5132\n",
      "Epoch 238/1000\n",
      "177/177 [==============================] - 0s 121us/step - loss: 0.2355 - accuracy: 0.9548 - val_loss: 1.5185 - val_accuracy: 0.5132\n",
      "Epoch 239/1000\n",
      "177/177 [==============================] - 0s 101us/step - loss: 0.2359 - accuracy: 0.9435 - val_loss: 1.5195 - val_accuracy: 0.5132\n",
      "Epoch 240/1000\n",
      "177/177 [==============================] - 0s 82us/step - loss: 0.2365 - accuracy: 0.9435 - val_loss: 1.5502 - val_accuracy: 0.5132\n",
      "Epoch 241/1000\n",
      "177/177 [==============================] - 0s 104us/step - loss: 0.2348 - accuracy: 0.9492 - val_loss: 1.5384 - val_accuracy: 0.5132\n",
      "Epoch 242/1000\n",
      "177/177 [==============================] - 0s 79us/step - loss: 0.2321 - accuracy: 0.9435 - val_loss: 1.5058 - val_accuracy: 0.5132\n",
      "Epoch 243/1000\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.2357 - accuracy: 0.9266 - val_loss: 1.5126 - val_accuracy: 0.5132\n",
      "Epoch 244/1000\n",
      "177/177 [==============================] - 0s 95us/step - loss: 0.2264 - accuracy: 0.9435 - val_loss: 1.5799 - val_accuracy: 0.5132\n",
      "Epoch 245/1000\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.2489 - accuracy: 0.9435 - val_loss: 1.5311 - val_accuracy: 0.5132\n",
      "Epoch 246/1000\n",
      "177/177 [==============================] - 0s 70us/step - loss: 0.2505 - accuracy: 0.9266 - val_loss: 1.5190 - val_accuracy: 0.5132\n",
      "Epoch 247/1000\n",
      "177/177 [==============================] - 0s 79us/step - loss: 0.2707 - accuracy: 0.9322 - val_loss: 1.5251 - val_accuracy: 0.5132\n",
      "Epoch 248/1000\n",
      "177/177 [==============================] - 0s 92us/step - loss: 0.2236 - accuracy: 0.9379 - val_loss: 1.5175 - val_accuracy: 0.5132\n",
      "Epoch 249/1000\n",
      "177/177 [==============================] - 0s 109us/step - loss: 0.2317 - accuracy: 0.9322 - val_loss: 1.5742 - val_accuracy: 0.5132\n",
      "Epoch 250/1000\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.2318 - accuracy: 0.9322 - val_loss: 1.5356 - val_accuracy: 0.5132\n",
      "Epoch 251/1000\n",
      "177/177 [==============================] - 0s 92us/step - loss: 0.2259 - accuracy: 0.9322 - val_loss: 1.5435 - val_accuracy: 0.5132\n",
      "Epoch 252/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.2202 - accuracy: 0.9435 - val_loss: 1.5849 - val_accuracy: 0.5132\n",
      "Epoch 253/1000\n",
      "177/177 [==============================] - 0s 68us/step - loss: 0.2324 - accuracy: 0.9435 - val_loss: 1.5593 - val_accuracy: 0.5132\n",
      "Epoch 254/1000\n",
      "177/177 [==============================] - 0s 82us/step - loss: 0.2452 - accuracy: 0.9266 - val_loss: 1.5546 - val_accuracy: 0.5132\n",
      "Epoch 255/1000\n",
      "177/177 [==============================] - 0s 77us/step - loss: 0.2181 - accuracy: 0.9435 - val_loss: 1.5871 - val_accuracy: 0.5395\n",
      "Epoch 256/1000\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.2779 - accuracy: 0.9435 - val_loss: 1.5395 - val_accuracy: 0.5263\n",
      "Epoch 257/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.2270 - accuracy: 0.9379 - val_loss: 1.6380 - val_accuracy: 0.5000\n",
      "Epoch 258/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.3341 - accuracy: 0.9096 - val_loss: 1.5742 - val_accuracy: 0.5263\n",
      "Epoch 259/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.2504 - accuracy: 0.9266 - val_loss: 1.6147 - val_accuracy: 0.5395\n",
      "Epoch 260/1000\n",
      "177/177 [==============================] - 0s 193us/step - loss: 0.2848 - accuracy: 0.9492 - val_loss: 1.6309 - val_accuracy: 0.5395\n",
      "Epoch 261/1000\n",
      "177/177 [==============================] - 0s 142us/step - loss: 0.2530 - accuracy: 0.9492 - val_loss: 1.5872 - val_accuracy: 0.5395\n",
      "Epoch 262/1000\n",
      "177/177 [==============================] - 0s 109us/step - loss: 0.2732 - accuracy: 0.9209 - val_loss: 1.5949 - val_accuracy: 0.5395\n",
      "Epoch 263/1000\n",
      "177/177 [==============================] - 0s 85us/step - loss: 0.2446 - accuracy: 0.9435 - val_loss: 1.6345 - val_accuracy: 0.5395\n",
      "Epoch 264/1000\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.2341 - accuracy: 0.9492 - val_loss: 1.6066 - val_accuracy: 0.5395\n",
      "Epoch 265/1000\n",
      "177/177 [==============================] - 0s 99us/step - loss: 0.2123 - accuracy: 0.9605 - val_loss: 1.5739 - val_accuracy: 0.5395\n",
      "Epoch 266/1000\n",
      "177/177 [==============================] - 0s 91us/step - loss: 0.2260 - accuracy: 0.9379 - val_loss: 1.5711 - val_accuracy: 0.5395\n",
      "Epoch 267/1000\n",
      "177/177 [==============================] - 0s 87us/step - loss: 0.2199 - accuracy: 0.9492 - val_loss: 1.5910 - val_accuracy: 0.5395\n",
      "Epoch 268/1000\n",
      "177/177 [==============================] - 0s 83us/step - loss: 0.2116 - accuracy: 0.9548 - val_loss: 1.5665 - val_accuracy: 0.5263\n",
      "Epoch 269/1000\n",
      "177/177 [==============================] - 0s 78us/step - loss: 0.2100 - accuracy: 0.9435 - val_loss: 1.5930 - val_accuracy: 0.5263\n",
      "Epoch 270/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.2053 - accuracy: 0.9548 - val_loss: 1.6121 - val_accuracy: 0.5395\n",
      "Epoch 271/1000\n",
      "177/177 [==============================] - 0s 70us/step - loss: 0.2055 - accuracy: 0.9548 - val_loss: 1.6130 - val_accuracy: 0.5263\n",
      "Epoch 272/1000\n",
      "177/177 [==============================] - 0s 77us/step - loss: 0.2053 - accuracy: 0.9435 - val_loss: 1.6193 - val_accuracy: 0.5395\n",
      "Epoch 273/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.2017 - accuracy: 0.9548 - val_loss: 1.6415 - val_accuracy: 0.5395\n",
      "Epoch 274/1000\n",
      "177/177 [==============================] - 0s 52us/step - loss: 0.2052 - accuracy: 0.9548 - val_loss: 1.6027 - val_accuracy: 0.5395\n",
      "Epoch 275/1000\n",
      "177/177 [==============================] - 0s 56us/step - loss: 0.2038 - accuracy: 0.9379 - val_loss: 1.6065 - val_accuracy: 0.5395\n",
      "Epoch 276/1000\n",
      "177/177 [==============================] - 0s 53us/step - loss: 0.2015 - accuracy: 0.9548 - val_loss: 1.6214 - val_accuracy: 0.5395\n",
      "Epoch 277/1000\n",
      "177/177 [==============================] - 0s 53us/step - loss: 0.1994 - accuracy: 0.9548 - val_loss: 1.6234 - val_accuracy: 0.5395\n",
      "Epoch 278/1000\n",
      "177/177 [==============================] - 0s 75us/step - loss: 0.1985 - accuracy: 0.9492 - val_loss: 1.6350 - val_accuracy: 0.5395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 279/1000\n",
      "177/177 [==============================] - 0s 59us/step - loss: 0.2009 - accuracy: 0.9548 - val_loss: 1.6249 - val_accuracy: 0.5395\n",
      "Epoch 280/1000\n",
      "177/177 [==============================] - 0s 50us/step - loss: 0.1949 - accuracy: 0.9605 - val_loss: 1.5999 - val_accuracy: 0.5395\n",
      "Epoch 281/1000\n",
      "177/177 [==============================] - 0s 53us/step - loss: 0.1985 - accuracy: 0.9379 - val_loss: 1.6116 - val_accuracy: 0.5395\n",
      "Epoch 282/1000\n",
      "177/177 [==============================] - 0s 57us/step - loss: 0.2075 - accuracy: 0.9435 - val_loss: 1.6169 - val_accuracy: 0.5395\n",
      "Epoch 283/1000\n",
      "177/177 [==============================] - 0s 49us/step - loss: 0.2024 - accuracy: 0.9379 - val_loss: 1.6540 - val_accuracy: 0.5395\n",
      "Epoch 284/1000\n",
      "177/177 [==============================] - 0s 55us/step - loss: 0.2427 - accuracy: 0.9266 - val_loss: 1.6179 - val_accuracy: 0.5395\n",
      "Epoch 285/1000\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.1967 - accuracy: 0.9548 - val_loss: 1.7546 - val_accuracy: 0.5263\n",
      "Epoch 286/1000\n",
      "177/177 [==============================] - 0s 50us/step - loss: 0.2840 - accuracy: 0.9492 - val_loss: 1.6496 - val_accuracy: 0.5395\n",
      "Epoch 287/1000\n",
      "177/177 [==============================] - 0s 58us/step - loss: 0.2229 - accuracy: 0.9379 - val_loss: 1.7830 - val_accuracy: 0.5000\n",
      "Epoch 288/1000\n",
      "177/177 [==============================] - 0s 57us/step - loss: 0.4270 - accuracy: 0.8983 - val_loss: 1.7650 - val_accuracy: 0.5000\n",
      "Epoch 289/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.3446 - accuracy: 0.9153 - val_loss: 1.5596 - val_accuracy: 0.5395\n",
      "Epoch 290/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.1974 - accuracy: 0.9492 - val_loss: 1.8343 - val_accuracy: 0.5263\n",
      "Epoch 291/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.3710 - accuracy: 0.9153 - val_loss: 1.8041 - val_accuracy: 0.5263\n",
      "Epoch 292/1000\n",
      "177/177 [==============================] - 0s 68us/step - loss: 0.2845 - accuracy: 0.9435 - val_loss: 1.6453 - val_accuracy: 0.5395\n",
      "Epoch 293/1000\n",
      "177/177 [==============================] - 0s 76us/step - loss: 0.2711 - accuracy: 0.9209 - val_loss: 1.7372 - val_accuracy: 0.5132\n",
      "Epoch 294/1000\n",
      "177/177 [==============================] - 0s 68us/step - loss: 0.3281 - accuracy: 0.9153 - val_loss: 1.6344 - val_accuracy: 0.5395\n",
      "Epoch 295/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.1971 - accuracy: 0.9379 - val_loss: 1.7716 - val_accuracy: 0.5263\n",
      "Epoch 296/1000\n",
      "177/177 [==============================] - 0s 69us/step - loss: 0.2871 - accuracy: 0.9379 - val_loss: 1.7540 - val_accuracy: 0.5263\n",
      "Epoch 297/1000\n",
      "177/177 [==============================] - 0s 63us/step - loss: 0.2570 - accuracy: 0.9435 - val_loss: 1.7085 - val_accuracy: 0.5395\n",
      "Epoch 298/1000\n",
      "177/177 [==============================] - 0s 70us/step - loss: 0.3156 - accuracy: 0.9266 - val_loss: 1.7055 - val_accuracy: 0.5263\n",
      "Epoch 299/1000\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.2536 - accuracy: 0.9266 - val_loss: 1.6022 - val_accuracy: 0.5395\n",
      "Epoch 300/1000\n",
      "177/177 [==============================] - 0s 75us/step - loss: 0.2031 - accuracy: 0.9492 - val_loss: 1.7877 - val_accuracy: 0.5263\n",
      "Epoch 301/1000\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.3220 - accuracy: 0.9379 - val_loss: 1.6947 - val_accuracy: 0.5395\n",
      "Epoch 302/1000\n",
      "177/177 [==============================] - 0s 78us/step - loss: 0.1820 - accuracy: 0.9548 - val_loss: 1.6562 - val_accuracy: 0.5395\n",
      "Epoch 303/1000\n",
      "177/177 [==============================] - 0s 84us/step - loss: 0.2267 - accuracy: 0.9322 - val_loss: 1.6591 - val_accuracy: 0.5395\n",
      "Epoch 304/1000\n",
      "177/177 [==============================] - 0s 78us/step - loss: 0.1914 - accuracy: 0.9548 - val_loss: 1.7780 - val_accuracy: 0.5263\n",
      "Epoch 305/1000\n",
      "177/177 [==============================] - 0s 94us/step - loss: 0.2476 - accuracy: 0.9435 - val_loss: 1.6866 - val_accuracy: 0.5395\n",
      "Epoch 306/1000\n",
      "177/177 [==============================] - 0s 113us/step - loss: 0.1760 - accuracy: 0.9605 - val_loss: 1.6322 - val_accuracy: 0.5395\n",
      "Epoch 307/1000\n",
      "177/177 [==============================] - 0s 119us/step - loss: 0.1957 - accuracy: 0.9379 - val_loss: 1.6390 - val_accuracy: 0.5395\n",
      "Epoch 308/1000\n",
      "177/177 [==============================] - 0s 96us/step - loss: 0.1745 - accuracy: 0.9661 - val_loss: 1.7227 - val_accuracy: 0.5395\n",
      "Epoch 309/1000\n",
      "177/177 [==============================] - 0s 92us/step - loss: 0.2517 - accuracy: 0.9548 - val_loss: 1.6928 - val_accuracy: 0.5395\n",
      "Epoch 310/1000\n",
      "177/177 [==============================] - 0s 87us/step - loss: 0.2428 - accuracy: 0.9435 - val_loss: 1.7329 - val_accuracy: 0.5395\n",
      "Epoch 311/1000\n",
      "177/177 [==============================] - 0s 100us/step - loss: 0.2454 - accuracy: 0.9266 - val_loss: 1.6991 - val_accuracy: 0.5395\n",
      "Epoch 312/1000\n",
      "177/177 [==============================] - 0s 108us/step - loss: 0.2498 - accuracy: 0.9492 - val_loss: 1.7433 - val_accuracy: 0.5395\n",
      "Epoch 313/1000\n",
      "177/177 [==============================] - 0s 146us/step - loss: 0.1693 - accuracy: 0.9661 - val_loss: 1.6961 - val_accuracy: 0.5395\n",
      "Epoch 314/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.2392 - accuracy: 0.9379 - val_loss: 1.6922 - val_accuracy: 0.5395\n",
      "Epoch 315/1000\n",
      "177/177 [==============================] - 0s 75us/step - loss: 0.1950 - accuracy: 0.9379 - val_loss: 1.7642 - val_accuracy: 0.5395\n",
      "Epoch 316/1000\n",
      "177/177 [==============================] - 0s 104us/step - loss: 0.2133 - accuracy: 0.9548 - val_loss: 1.7314 - val_accuracy: 0.5395\n",
      "Epoch 317/1000\n",
      "177/177 [==============================] - 0s 69us/step - loss: 0.1684 - accuracy: 0.9605 - val_loss: 1.7045 - val_accuracy: 0.5395\n",
      "Epoch 318/1000\n",
      "177/177 [==============================] - 0s 93us/step - loss: 0.2143 - accuracy: 0.9435 - val_loss: 1.6959 - val_accuracy: 0.5395\n",
      "Epoch 319/1000\n",
      "177/177 [==============================] - 0s 81us/step - loss: 0.1848 - accuracy: 0.9548 - val_loss: 1.7571 - val_accuracy: 0.5395\n",
      "Epoch 320/1000\n",
      "177/177 [==============================] - 0s 68us/step - loss: 0.1808 - accuracy: 0.9661 - val_loss: 1.6961 - val_accuracy: 0.5395\n",
      "Epoch 321/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.2040 - accuracy: 0.9379 - val_loss: 1.6976 - val_accuracy: 0.5395\n",
      "Epoch 322/1000\n",
      "177/177 [==============================] - 0s 54us/step - loss: 0.1816 - accuracy: 0.9435 - val_loss: 1.7346 - val_accuracy: 0.5395\n",
      "Epoch 323/1000\n",
      "177/177 [==============================] - 0s 60us/step - loss: 0.1702 - accuracy: 0.9605 - val_loss: 1.7306 - val_accuracy: 0.5395\n",
      "Epoch 324/1000\n",
      "177/177 [==============================] - 0s 59us/step - loss: 0.1876 - accuracy: 0.9492 - val_loss: 1.7789 - val_accuracy: 0.5395\n",
      "Epoch 325/1000\n",
      "177/177 [==============================] - 0s 54us/step - loss: 0.1970 - accuracy: 0.9605 - val_loss: 1.7418 - val_accuracy: 0.5395\n",
      "Epoch 326/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.2199 - accuracy: 0.9492 - val_loss: 1.7670 - val_accuracy: 0.5395\n",
      "Epoch 327/1000\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.2057 - accuracy: 0.9605 - val_loss: 1.7635 - val_accuracy: 0.5395\n",
      "Epoch 328/1000\n",
      "177/177 [==============================] - 0s 52us/step - loss: 0.1788 - accuracy: 0.9548 - val_loss: 1.7400 - val_accuracy: 0.5395\n",
      "Epoch 329/1000\n",
      "177/177 [==============================] - 0s 57us/step - loss: 0.1635 - accuracy: 0.9661 - val_loss: 1.7209 - val_accuracy: 0.5395\n",
      "Epoch 330/1000\n",
      "177/177 [==============================] - 0s 53us/step - loss: 0.1626 - accuracy: 0.9718 - val_loss: 1.7418 - val_accuracy: 0.5395\n",
      "Epoch 331/1000\n",
      "177/177 [==============================] - 0s 63us/step - loss: 0.1619 - accuracy: 0.9718 - val_loss: 1.7608 - val_accuracy: 0.5395\n",
      "Epoch 332/1000\n",
      "177/177 [==============================] - 0s 48us/step - loss: 0.1623 - accuracy: 0.9718 - val_loss: 1.7715 - val_accuracy: 0.5395\n",
      "Epoch 333/1000\n",
      "177/177 [==============================] - 0s 60us/step - loss: 0.1603 - accuracy: 0.9661 - val_loss: 1.7484 - val_accuracy: 0.5395\n",
      "Epoch 334/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.1619 - accuracy: 0.9661 - val_loss: 1.7464 - val_accuracy: 0.5395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 335/1000\n",
      "177/177 [==============================] - 0s 53us/step - loss: 0.1613 - accuracy: 0.9718 - val_loss: 1.7715 - val_accuracy: 0.5395\n",
      "Epoch 336/1000\n",
      "177/177 [==============================] - 0s 53us/step - loss: 0.1596 - accuracy: 0.9718 - val_loss: 1.7357 - val_accuracy: 0.5395\n",
      "Epoch 337/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.1600 - accuracy: 0.9661 - val_loss: 1.7391 - val_accuracy: 0.5395\n",
      "Epoch 338/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.1580 - accuracy: 0.9661 - val_loss: 1.7749 - val_accuracy: 0.5395\n",
      "Epoch 339/1000\n",
      "177/177 [==============================] - 0s 60us/step - loss: 0.1607 - accuracy: 0.9661 - val_loss: 1.7957 - val_accuracy: 0.5395\n",
      "Epoch 340/1000\n",
      "177/177 [==============================] - 0s 58us/step - loss: 0.1586 - accuracy: 0.9605 - val_loss: 1.7919 - val_accuracy: 0.5395\n",
      "Epoch 341/1000\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.1682 - accuracy: 0.9548 - val_loss: 1.7930 - val_accuracy: 0.5395\n",
      "Epoch 342/1000\n",
      "177/177 [==============================] - 0s 79us/step - loss: 0.1526 - accuracy: 0.9661 - val_loss: 1.8297 - val_accuracy: 0.5395\n",
      "Epoch 343/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.2000 - accuracy: 0.9605 - val_loss: 1.7431 - val_accuracy: 0.5395\n",
      "Epoch 344/1000\n",
      "177/177 [==============================] - 0s 92us/step - loss: 0.1631 - accuracy: 0.9492 - val_loss: 1.7822 - val_accuracy: 0.5395\n",
      "Epoch 345/1000\n",
      "177/177 [==============================] - 0s 84us/step - loss: 0.1929 - accuracy: 0.9435 - val_loss: 1.7874 - val_accuracy: 0.5395\n",
      "Epoch 346/1000\n",
      "177/177 [==============================] - 0s 105us/step - loss: 0.2088 - accuracy: 0.9605 - val_loss: 1.8389 - val_accuracy: 0.5395\n",
      "Epoch 347/1000\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.1607 - accuracy: 0.9605 - val_loss: 1.8729 - val_accuracy: 0.5263\n",
      "Epoch 348/1000\n",
      "177/177 [==============================] - 0s 116us/step - loss: 0.2434 - accuracy: 0.9435 - val_loss: 1.8138 - val_accuracy: 0.5395\n",
      "Epoch 349/1000\n",
      "177/177 [==============================] - 0s 107us/step - loss: 0.1932 - accuracy: 0.9605 - val_loss: 1.8353 - val_accuracy: 0.5395\n",
      "Epoch 350/1000\n",
      "177/177 [==============================] - 0s 101us/step - loss: 0.1963 - accuracy: 0.9605 - val_loss: 1.8258 - val_accuracy: 0.5395\n",
      "Epoch 351/1000\n",
      "177/177 [==============================] - 0s 109us/step - loss: 0.1481 - accuracy: 0.9718 - val_loss: 1.7585 - val_accuracy: 0.5395\n",
      "Epoch 352/1000\n",
      "177/177 [==============================] - 0s 77us/step - loss: 0.1677 - accuracy: 0.9548 - val_loss: 1.7805 - val_accuracy: 0.5395\n",
      "Epoch 353/1000\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.1506 - accuracy: 0.9718 - val_loss: 1.8344 - val_accuracy: 0.5395\n",
      "Epoch 354/1000\n",
      "177/177 [==============================] - 0s 83us/step - loss: 0.1549 - accuracy: 0.9661 - val_loss: 1.8196 - val_accuracy: 0.5395\n",
      "Epoch 355/1000\n",
      "177/177 [==============================] - 0s 101us/step - loss: 0.1503 - accuracy: 0.9661 - val_loss: 1.8105 - val_accuracy: 0.5395\n",
      "Epoch 356/1000\n",
      "177/177 [==============================] - 0s 83us/step - loss: 0.1569 - accuracy: 0.9548 - val_loss: 1.8270 - val_accuracy: 0.5395\n",
      "Epoch 357/1000\n",
      "177/177 [==============================] - 0s 89us/step - loss: 0.1664 - accuracy: 0.9605 - val_loss: 1.8348 - val_accuracy: 0.5395\n",
      "Epoch 358/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.1486 - accuracy: 0.9718 - val_loss: 1.7913 - val_accuracy: 0.5395\n",
      "Epoch 359/1000\n",
      "177/177 [==============================] - 0s 87us/step - loss: 0.1552 - accuracy: 0.9605 - val_loss: 1.8295 - val_accuracy: 0.5395\n",
      "Epoch 360/1000\n",
      "177/177 [==============================] - 0s 76us/step - loss: 0.1453 - accuracy: 0.9718 - val_loss: 1.8387 - val_accuracy: 0.5395\n",
      "Epoch 361/1000\n",
      "177/177 [==============================] - 0s 84us/step - loss: 0.1478 - accuracy: 0.9718 - val_loss: 1.8043 - val_accuracy: 0.5395\n",
      "Epoch 362/1000\n",
      "177/177 [==============================] - 0s 76us/step - loss: 0.1470 - accuracy: 0.9661 - val_loss: 1.8032 - val_accuracy: 0.5395\n",
      "Epoch 363/1000\n",
      "177/177 [==============================] - 0s 63us/step - loss: 0.1451 - accuracy: 0.9718 - val_loss: 1.8333 - val_accuracy: 0.5395\n",
      "Epoch 364/1000\n",
      "177/177 [==============================] - 0s 69us/step - loss: 0.1454 - accuracy: 0.9718 - val_loss: 1.8601 - val_accuracy: 0.5395\n",
      "Epoch 365/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.1452 - accuracy: 0.9718 - val_loss: 1.8485 - val_accuracy: 0.5395\n",
      "Epoch 366/1000\n",
      "177/177 [==============================] - 0s 81us/step - loss: 0.1447 - accuracy: 0.9661 - val_loss: 1.8407 - val_accuracy: 0.5395\n",
      "Epoch 367/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.1429 - accuracy: 0.9718 - val_loss: 1.8628 - val_accuracy: 0.5395\n",
      "Epoch 368/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.1442 - accuracy: 0.9718 - val_loss: 1.8407 - val_accuracy: 0.5395\n",
      "Epoch 369/1000\n",
      "177/177 [==============================] - 0s 70us/step - loss: 0.1423 - accuracy: 0.9718 - val_loss: 1.8535 - val_accuracy: 0.5395\n",
      "Epoch 370/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.1414 - accuracy: 0.9718 - val_loss: 1.8680 - val_accuracy: 0.5395\n",
      "Epoch 371/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.1402 - accuracy: 0.9718 - val_loss: 1.8659 - val_accuracy: 0.5395\n",
      "Epoch 372/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.1411 - accuracy: 0.9718 - val_loss: 1.8429 - val_accuracy: 0.5395\n",
      "Epoch 373/1000\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.1404 - accuracy: 0.9718 - val_loss: 1.8473 - val_accuracy: 0.5395\n",
      "Epoch 374/1000\n",
      "177/177 [==============================] - 0s 68us/step - loss: 0.1394 - accuracy: 0.9718 - val_loss: 1.8727 - val_accuracy: 0.5395\n",
      "Epoch 375/1000\n",
      "177/177 [==============================] - 0s 69us/step - loss: 0.1419 - accuracy: 0.9718 - val_loss: 1.8651 - val_accuracy: 0.5395\n",
      "Epoch 376/1000\n",
      "177/177 [==============================] - 0s 56us/step - loss: 0.1431 - accuracy: 0.9661 - val_loss: 1.8592 - val_accuracy: 0.5395\n",
      "Epoch 377/1000\n",
      "177/177 [==============================] - 0s 82us/step - loss: 0.1541 - accuracy: 0.9548 - val_loss: 1.8800 - val_accuracy: 0.5395\n",
      "Epoch 378/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.1504 - accuracy: 0.9661 - val_loss: 1.9044 - val_accuracy: 0.5395\n",
      "Epoch 379/1000\n",
      "177/177 [==============================] - 0s 109us/step - loss: 0.1392 - accuracy: 0.9661 - val_loss: 1.8610 - val_accuracy: 0.5395\n",
      "Epoch 380/1000\n",
      "177/177 [==============================] - 0s 81us/step - loss: 0.1542 - accuracy: 0.9605 - val_loss: 1.8686 - val_accuracy: 0.5395\n",
      "Epoch 381/1000\n",
      "177/177 [==============================] - 0s 132us/step - loss: 0.1463 - accuracy: 0.9605 - val_loss: 1.9222 - val_accuracy: 0.5395\n",
      "Epoch 382/1000\n",
      "177/177 [==============================] - 0s 108us/step - loss: 0.1496 - accuracy: 0.9605 - val_loss: 1.8719 - val_accuracy: 0.5395\n",
      "Epoch 383/1000\n",
      "177/177 [==============================] - 0s 70us/step - loss: 0.1403 - accuracy: 0.9661 - val_loss: 1.9030 - val_accuracy: 0.5395\n",
      "Epoch 384/1000\n",
      "177/177 [==============================] - 0s 77us/step - loss: 0.1370 - accuracy: 0.9718 - val_loss: 1.9282 - val_accuracy: 0.5395\n",
      "Epoch 385/1000\n",
      "177/177 [==============================] - 0s 100us/step - loss: 0.1379 - accuracy: 0.9718 - val_loss: 1.8861 - val_accuracy: 0.5395\n",
      "Epoch 386/1000\n",
      "177/177 [==============================] - 0s 121us/step - loss: 0.1396 - accuracy: 0.9661 - val_loss: 1.8655 - val_accuracy: 0.5395\n",
      "Epoch 387/1000\n",
      "177/177 [==============================] - 0s 138us/step - loss: 0.1388 - accuracy: 0.9718 - val_loss: 1.9160 - val_accuracy: 0.5395\n",
      "Epoch 388/1000\n",
      "177/177 [==============================] - 0s 108us/step - loss: 0.1396 - accuracy: 0.9661 - val_loss: 1.8782 - val_accuracy: 0.5395\n",
      "Epoch 389/1000\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.1348 - accuracy: 0.9718 - val_loss: 1.8894 - val_accuracy: 0.5395\n",
      "Epoch 390/1000\n",
      "177/177 [==============================] - 0s 109us/step - loss: 0.1371 - accuracy: 0.9718 - val_loss: 1.9340 - val_accuracy: 0.5395\n",
      "Epoch 391/1000\n",
      "177/177 [==============================] - 0s 55us/step - loss: 0.1396 - accuracy: 0.9661 - val_loss: 1.9220 - val_accuracy: 0.5395\n",
      "Epoch 392/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.1308 - accuracy: 0.9718 - val_loss: 1.9144 - val_accuracy: 0.5395\n",
      "Epoch 393/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.1471 - accuracy: 0.9605 - val_loss: 1.9302 - val_accuracy: 0.5395\n",
      "Epoch 394/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.1523 - accuracy: 0.9661 - val_loss: 1.9799 - val_accuracy: 0.5395\n",
      "Epoch 395/1000\n",
      "177/177 [==============================] - 0s 58us/step - loss: 0.1318 - accuracy: 0.9718 - val_loss: 1.9149 - val_accuracy: 0.5395\n",
      "Epoch 396/1000\n",
      "177/177 [==============================] - 0s 56us/step - loss: 0.1527 - accuracy: 0.9548 - val_loss: 1.9040 - val_accuracy: 0.5395\n",
      "Epoch 397/1000\n",
      "177/177 [==============================] - 0s 56us/step - loss: 0.1609 - accuracy: 0.9605 - val_loss: 1.9092 - val_accuracy: 0.5395\n",
      "Epoch 398/1000\n",
      "177/177 [==============================] - 0s 59us/step - loss: 0.1419 - accuracy: 0.9605 - val_loss: 1.8980 - val_accuracy: 0.5395\n",
      "Epoch 399/1000\n",
      "177/177 [==============================] - 0s 51us/step - loss: 0.1521 - accuracy: 0.9492 - val_loss: 1.9667 - val_accuracy: 0.5395\n",
      "Epoch 400/1000\n",
      "177/177 [==============================] - 0s 55us/step - loss: 0.1712 - accuracy: 0.9605 - val_loss: 1.9562 - val_accuracy: 0.5395\n",
      "Epoch 401/1000\n",
      "177/177 [==============================] - 0s 59us/step - loss: 0.1343 - accuracy: 0.9661 - val_loss: 1.9980 - val_accuracy: 0.5395\n",
      "Epoch 402/1000\n",
      "177/177 [==============================] - 0s 59us/step - loss: 0.1929 - accuracy: 0.9548 - val_loss: 1.9401 - val_accuracy: 0.5395\n",
      "Epoch 403/1000\n",
      "177/177 [==============================] - 0s 57us/step - loss: 0.1438 - accuracy: 0.9548 - val_loss: 2.0965 - val_accuracy: 0.5263\n",
      "Epoch 404/1000\n",
      "177/177 [==============================] - 0s 59us/step - loss: 0.2436 - accuracy: 0.9548 - val_loss: 2.0184 - val_accuracy: 0.5263\n",
      "Epoch 405/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.1409 - accuracy: 0.9605 - val_loss: 1.8859 - val_accuracy: 0.5395\n",
      "Epoch 406/1000\n",
      "177/177 [==============================] - 0s 53us/step - loss: 0.2004 - accuracy: 0.9492 - val_loss: 1.9108 - val_accuracy: 0.5395\n",
      "Epoch 407/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.1687 - accuracy: 0.9492 - val_loss: 2.0031 - val_accuracy: 0.5395\n",
      "Epoch 408/1000\n",
      "177/177 [==============================] - 0s 59us/step - loss: 0.1793 - accuracy: 0.9605 - val_loss: 1.9862 - val_accuracy: 0.5395\n",
      "Epoch 409/1000\n",
      "177/177 [==============================] - 0s 57us/step - loss: 0.1826 - accuracy: 0.9605 - val_loss: 1.9898 - val_accuracy: 0.5395\n",
      "Epoch 410/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.1602 - accuracy: 0.9548 - val_loss: 1.9909 - val_accuracy: 0.5395\n",
      "Epoch 411/1000\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.1266 - accuracy: 0.9718 - val_loss: 2.0672 - val_accuracy: 0.5263\n",
      "Epoch 412/1000\n",
      "177/177 [==============================] - 0s 92us/step - loss: 0.2117 - accuracy: 0.9605 - val_loss: 1.9317 - val_accuracy: 0.5395\n",
      "Epoch 413/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.1375 - accuracy: 0.9548 - val_loss: 1.9140 - val_accuracy: 0.5395\n",
      "Epoch 414/1000\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.1466 - accuracy: 0.9548 - val_loss: 1.9955 - val_accuracy: 0.5395\n",
      "Epoch 415/1000\n",
      "177/177 [==============================] - 0s 77us/step - loss: 0.1450 - accuracy: 0.9605 - val_loss: 1.9923 - val_accuracy: 0.5395\n",
      "Epoch 416/1000\n",
      "177/177 [==============================] - 0s 60us/step - loss: 0.1269 - accuracy: 0.9661 - val_loss: 2.0054 - val_accuracy: 0.5395\n",
      "Epoch 417/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.2194 - accuracy: 0.9379 - val_loss: 1.9796 - val_accuracy: 0.5395\n",
      "Epoch 418/1000\n",
      "177/177 [==============================] - 0s 58us/step - loss: 0.1360 - accuracy: 0.9605 - val_loss: 2.0656 - val_accuracy: 0.5263\n",
      "Epoch 419/1000\n",
      "177/177 [==============================] - 0s 59us/step - loss: 0.1960 - accuracy: 0.9605 - val_loss: 2.0329 - val_accuracy: 0.5395\n",
      "Epoch 420/1000\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.1375 - accuracy: 0.9661 - val_loss: 1.9237 - val_accuracy: 0.5395\n",
      "Epoch 421/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.1536 - accuracy: 0.9548 - val_loss: 1.9462 - val_accuracy: 0.5395\n",
      "Epoch 422/1000\n",
      "177/177 [==============================] - 0s 77us/step - loss: 0.1314 - accuracy: 0.9661 - val_loss: 2.0231 - val_accuracy: 0.5395\n",
      "Epoch 423/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.1344 - accuracy: 0.9605 - val_loss: 2.0114 - val_accuracy: 0.5395\n",
      "Epoch 424/1000\n",
      "177/177 [==============================] - 0s 76us/step - loss: 0.1203 - accuracy: 0.9661 - val_loss: 1.9900 - val_accuracy: 0.5395\n",
      "Epoch 425/1000\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.1240 - accuracy: 0.9661 - val_loss: 1.9956 - val_accuracy: 0.5395\n",
      "Epoch 426/1000\n",
      "177/177 [==============================] - 0s 74us/step - loss: 0.1208 - accuracy: 0.9718 - val_loss: 2.0076 - val_accuracy: 0.5395\n",
      "Epoch 427/1000\n",
      "177/177 [==============================] - 0s 147us/step - loss: 0.1278 - accuracy: 0.9661 - val_loss: 1.9882 - val_accuracy: 0.5395\n",
      "Epoch 428/1000\n",
      "177/177 [==============================] - 0s 162us/step - loss: 0.1360 - accuracy: 0.9718 - val_loss: 1.9591 - val_accuracy: 0.5395\n",
      "Epoch 429/1000\n",
      "177/177 [==============================] - 0s 136us/step - loss: 0.1249 - accuracy: 0.9718 - val_loss: 2.0609 - val_accuracy: 0.5395\n",
      "Epoch 430/1000\n",
      "177/177 [==============================] - 0s 96us/step - loss: 0.1615 - accuracy: 0.9605 - val_loss: 1.9653 - val_accuracy: 0.5395\n",
      "Epoch 431/1000\n",
      "177/177 [==============================] - 0s 93us/step - loss: 0.1249 - accuracy: 0.9718 - val_loss: 1.9812 - val_accuracy: 0.5395\n",
      "Epoch 432/1000\n",
      "177/177 [==============================] - 0s 102us/step - loss: 0.1211 - accuracy: 0.9718 - val_loss: 2.0218 - val_accuracy: 0.5395\n",
      "Epoch 433/1000\n",
      "177/177 [==============================] - 0s 193us/step - loss: 0.1175 - accuracy: 0.9774 - val_loss: 2.0713 - val_accuracy: 0.5395\n",
      "Epoch 434/1000\n",
      "177/177 [==============================] - 0s 91us/step - loss: 0.1258 - accuracy: 0.9605 - val_loss: 2.0017 - val_accuracy: 0.5395\n",
      "Epoch 435/1000\n",
      "177/177 [==============================] - 0s 109us/step - loss: 0.1229 - accuracy: 0.9718 - val_loss: 1.9892 - val_accuracy: 0.5395\n",
      "Epoch 436/1000\n",
      "177/177 [==============================] - 0s 126us/step - loss: 0.1201 - accuracy: 0.9718 - val_loss: 2.0300 - val_accuracy: 0.5395\n",
      "Epoch 437/1000\n",
      "177/177 [==============================] - 0s 121us/step - loss: 0.1224 - accuracy: 0.9718 - val_loss: 2.0361 - val_accuracy: 0.5395\n",
      "Epoch 438/1000\n",
      "177/177 [==============================] - 0s 142us/step - loss: 0.1171 - accuracy: 0.9718 - val_loss: 2.0161 - val_accuracy: 0.5395\n",
      "Epoch 439/1000\n",
      "177/177 [==============================] - 0s 128us/step - loss: 0.1226 - accuracy: 0.9718 - val_loss: 2.0375 - val_accuracy: 0.5395\n",
      "Epoch 440/1000\n",
      "177/177 [==============================] - 0s 122us/step - loss: 0.1155 - accuracy: 0.9774 - val_loss: 2.0704 - val_accuracy: 0.5395\n",
      "Epoch 441/1000\n",
      "177/177 [==============================] - 0s 114us/step - loss: 0.1231 - accuracy: 0.9718 - val_loss: 2.0365 - val_accuracy: 0.5395\n",
      "Epoch 442/1000\n",
      "177/177 [==============================] - 0s 125us/step - loss: 0.1201 - accuracy: 0.9774 - val_loss: 2.0270 - val_accuracy: 0.5395\n",
      "Epoch 443/1000\n",
      "177/177 [==============================] - 0s 123us/step - loss: 0.1196 - accuracy: 0.9718 - val_loss: 2.0467 - val_accuracy: 0.5395\n",
      "Epoch 444/1000\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.1158 - accuracy: 0.9774 - val_loss: 2.0695 - val_accuracy: 0.5395\n",
      "Epoch 445/1000\n",
      "177/177 [==============================] - 0s 112us/step - loss: 0.1244 - accuracy: 0.9661 - val_loss: 2.0226 - val_accuracy: 0.5395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 446/1000\n",
      "177/177 [==============================] - 0s 112us/step - loss: 0.1249 - accuracy: 0.9661 - val_loss: 2.0203 - val_accuracy: 0.5395\n",
      "Epoch 447/1000\n",
      "177/177 [==============================] - ETA: 0s - loss: 0.1149 - accuracy: 0.96 - 0s 196us/step - loss: 0.1177 - accuracy: 0.9718 - val_loss: 2.1237 - val_accuracy: 0.5395\n",
      "Epoch 448/1000\n",
      "177/177 [==============================] - 0s 179us/step - loss: 0.1722 - accuracy: 0.9605 - val_loss: 2.0641 - val_accuracy: 0.5395\n",
      "Epoch 449/1000\n",
      "177/177 [==============================] - 0s 142us/step - loss: 0.1151 - accuracy: 0.9718 - val_loss: 2.0887 - val_accuracy: 0.5395\n",
      "Epoch 450/1000\n",
      "177/177 [==============================] - 0s 206us/step - loss: 0.1928 - accuracy: 0.9492 - val_loss: 2.0552 - val_accuracy: 0.5395\n",
      "Epoch 451/1000\n",
      "177/177 [==============================] - 0s 215us/step - loss: 0.1473 - accuracy: 0.9605 - val_loss: 2.2188 - val_accuracy: 0.5263\n",
      "Epoch 452/1000\n",
      "177/177 [==============================] - 0s 131us/step - loss: 0.3606 - accuracy: 0.9492 - val_loss: 2.2353 - val_accuracy: 0.5263\n",
      "Epoch 453/1000\n",
      "177/177 [==============================] - 0s 167us/step - loss: 0.2280 - accuracy: 0.9605 - val_loss: 1.9341 - val_accuracy: 0.5395\n",
      "Epoch 454/1000\n",
      "177/177 [==============================] - 0s 104us/step - loss: 0.2431 - accuracy: 0.9492 - val_loss: 2.1117 - val_accuracy: 0.5000\n",
      "Epoch 455/1000\n",
      "177/177 [==============================] - 0s 117us/step - loss: 0.2868 - accuracy: 0.9435 - val_loss: 2.0613 - val_accuracy: 0.5395\n",
      "Epoch 456/1000\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.1268 - accuracy: 0.9605 - val_loss: 2.2539 - val_accuracy: 0.5263\n",
      "Epoch 457/1000\n",
      "177/177 [==============================] - 0s 100us/step - loss: 0.1916 - accuracy: 0.9548 - val_loss: 2.1904 - val_accuracy: 0.5395\n",
      "Epoch 458/1000\n",
      "177/177 [==============================] - 0s 111us/step - loss: 0.1128 - accuracy: 0.9718 - val_loss: 2.0290 - val_accuracy: 0.5395\n",
      "Epoch 459/1000\n",
      "177/177 [==============================] - 0s 130us/step - loss: 0.1339 - accuracy: 0.9548 - val_loss: 1.9917 - val_accuracy: 0.5395\n",
      "Epoch 460/1000\n",
      "177/177 [==============================] - 0s 113us/step - loss: 0.1202 - accuracy: 0.9661 - val_loss: 2.0172 - val_accuracy: 0.5395\n",
      "Epoch 461/1000\n",
      "177/177 [==============================] - 0s 105us/step - loss: 0.1154 - accuracy: 0.9718 - val_loss: 2.0851 - val_accuracy: 0.5395\n",
      "Epoch 462/1000\n",
      "177/177 [==============================] - 0s 119us/step - loss: 0.1180 - accuracy: 0.9718 - val_loss: 2.0563 - val_accuracy: 0.5395\n",
      "Epoch 463/1000\n",
      "177/177 [==============================] - 0s 109us/step - loss: 0.1150 - accuracy: 0.9661 - val_loss: 2.0662 - val_accuracy: 0.5395\n",
      "Epoch 464/1000\n",
      "177/177 [==============================] - 0s 112us/step - loss: 0.1158 - accuracy: 0.9718 - val_loss: 2.0973 - val_accuracy: 0.5395\n",
      "Epoch 465/1000\n",
      "177/177 [==============================] - 0s 97us/step - loss: 0.1110 - accuracy: 0.9718 - val_loss: 2.1326 - val_accuracy: 0.5395\n",
      "Epoch 466/1000\n",
      "177/177 [==============================] - 0s 110us/step - loss: 0.1186 - accuracy: 0.9605 - val_loss: 2.1019 - val_accuracy: 0.5395\n",
      "Epoch 467/1000\n",
      "177/177 [==============================] - 0s 109us/step - loss: 0.1170 - accuracy: 0.9718 - val_loss: 2.0774 - val_accuracy: 0.5395\n",
      "Epoch 468/1000\n",
      "177/177 [==============================] - 0s 139us/step - loss: 0.1240 - accuracy: 0.9661 - val_loss: 2.1073 - val_accuracy: 0.5395\n",
      "Epoch 469/1000\n",
      "177/177 [==============================] - 0s 97us/step - loss: 0.1285 - accuracy: 0.9661 - val_loss: 2.0964 - val_accuracy: 0.5395\n",
      "Epoch 470/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.1132 - accuracy: 0.9718 - val_loss: 2.0940 - val_accuracy: 0.5395\n",
      "Epoch 471/1000\n",
      "177/177 [==============================] - 0s 82us/step - loss: 0.1143 - accuracy: 0.9718 - val_loss: 2.1282 - val_accuracy: 0.5395\n",
      "Epoch 472/1000\n",
      "177/177 [==============================] - 0s 94us/step - loss: 0.1099 - accuracy: 0.9774 - val_loss: 2.1357 - val_accuracy: 0.5395\n",
      "Epoch 473/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.1094 - accuracy: 0.9774 - val_loss: 2.0841 - val_accuracy: 0.5395\n",
      "Epoch 474/1000\n",
      "177/177 [==============================] - 0s 74us/step - loss: 0.1110 - accuracy: 0.9718 - val_loss: 2.0845 - val_accuracy: 0.5395\n",
      "Epoch 475/1000\n",
      "177/177 [==============================] - 0s 100us/step - loss: 0.1104 - accuracy: 0.9718 - val_loss: 2.1312 - val_accuracy: 0.5395\n",
      "Epoch 476/1000\n",
      "177/177 [==============================] - 0s 91us/step - loss: 0.1077 - accuracy: 0.9774 - val_loss: 2.1395 - val_accuracy: 0.5395\n",
      "Epoch 477/1000\n",
      "177/177 [==============================] - 0s 78us/step - loss: 0.1063 - accuracy: 0.9774 - val_loss: 2.1364 - val_accuracy: 0.5395\n",
      "Epoch 478/1000\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.1056 - accuracy: 0.9774 - val_loss: 2.1408 - val_accuracy: 0.5395\n",
      "Epoch 479/1000\n",
      "177/177 [==============================] - 0s 93us/step - loss: 0.1050 - accuracy: 0.9774 - val_loss: 2.1469 - val_accuracy: 0.5395\n",
      "Epoch 480/1000\n",
      "177/177 [==============================] - 0s 124us/step - loss: 0.1048 - accuracy: 0.9774 - val_loss: 2.1499 - val_accuracy: 0.5395\n",
      "Epoch 481/1000\n",
      "177/177 [==============================] - 0s 104us/step - loss: 0.1043 - accuracy: 0.9774 - val_loss: 2.1279 - val_accuracy: 0.5395\n",
      "Epoch 482/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.1036 - accuracy: 0.9774 - val_loss: 2.1259 - val_accuracy: 0.5395\n",
      "Epoch 483/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.1034 - accuracy: 0.9774 - val_loss: 2.1328 - val_accuracy: 0.5395\n",
      "Epoch 484/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.1033 - accuracy: 0.9774 - val_loss: 2.1427 - val_accuracy: 0.5395\n",
      "Epoch 485/1000\n",
      "177/177 [==============================] - 0s 59us/step - loss: 0.1031 - accuracy: 0.9774 - val_loss: 2.1316 - val_accuracy: 0.5395\n",
      "Epoch 486/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.1030 - accuracy: 0.9774 - val_loss: 2.1405 - val_accuracy: 0.5395\n",
      "Epoch 487/1000\n",
      "177/177 [==============================] - 0s 70us/step - loss: 0.1056 - accuracy: 0.9774 - val_loss: 2.1412 - val_accuracy: 0.5395\n",
      "Epoch 488/1000\n",
      "177/177 [==============================] - 0s 83us/step - loss: 0.1058 - accuracy: 0.9774 - val_loss: 2.1215 - val_accuracy: 0.5395\n",
      "Epoch 489/1000\n",
      "177/177 [==============================] - 0s 69us/step - loss: 0.1095 - accuracy: 0.9718 - val_loss: 2.1801 - val_accuracy: 0.5395\n",
      "Epoch 490/1000\n",
      "177/177 [==============================] - 0s 68us/step - loss: 0.1081 - accuracy: 0.9718 - val_loss: 2.1652 - val_accuracy: 0.5395\n",
      "Epoch 491/1000\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.1017 - accuracy: 0.9774 - val_loss: 2.1281 - val_accuracy: 0.5395\n",
      "Epoch 492/1000\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.1085 - accuracy: 0.9774 - val_loss: 2.1389 - val_accuracy: 0.5395\n",
      "Epoch 493/1000\n",
      "177/177 [==============================] - 0s 60us/step - loss: 0.1039 - accuracy: 0.9774 - val_loss: 2.1845 - val_accuracy: 0.5395\n",
      "Epoch 494/1000\n",
      "177/177 [==============================] - 0s 56us/step - loss: 0.1048 - accuracy: 0.9774 - val_loss: 2.1236 - val_accuracy: 0.5395\n",
      "Epoch 495/1000\n",
      "177/177 [==============================] - 0s 63us/step - loss: 0.1076 - accuracy: 0.9661 - val_loss: 2.1342 - val_accuracy: 0.5395\n",
      "Epoch 496/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.1025 - accuracy: 0.9774 - val_loss: 2.1953 - val_accuracy: 0.5395\n",
      "Epoch 497/1000\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.1303 - accuracy: 0.9661 - val_loss: 2.1615 - val_accuracy: 0.5395\n",
      "Epoch 498/1000\n",
      "177/177 [==============================] - 0s 63us/step - loss: 0.1322 - accuracy: 0.9661 - val_loss: 2.1920 - val_accuracy: 0.5395\n",
      "Epoch 499/1000\n",
      "177/177 [==============================] - 0s 97us/step - loss: 0.1410 - accuracy: 0.9548 - val_loss: 2.1735 - val_accuracy: 0.5395\n",
      "Epoch 500/1000\n",
      "177/177 [==============================] - 0s 70us/step - loss: 0.0997 - accuracy: 0.9774 - val_loss: 2.3153 - val_accuracy: 0.5263\n",
      "Epoch 501/1000\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.1637 - accuracy: 0.9661 - val_loss: 2.2067 - val_accuracy: 0.5395\n",
      "Epoch 502/1000\n",
      "177/177 [==============================] - 0s 147us/step - loss: 0.1275 - accuracy: 0.9661 - val_loss: 2.1380 - val_accuracy: 0.5395\n",
      "Epoch 503/1000\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.1168 - accuracy: 0.9661 - val_loss: 2.2461 - val_accuracy: 0.5263\n",
      "Epoch 504/1000\n",
      "177/177 [==============================] - 0s 115us/step - loss: 0.1633 - accuracy: 0.9661 - val_loss: 2.1686 - val_accuracy: 0.5395\n",
      "Epoch 505/1000\n",
      "177/177 [==============================] - 0s 141us/step - loss: 0.1008 - accuracy: 0.9774 - val_loss: 2.1258 - val_accuracy: 0.5395\n",
      "Epoch 506/1000\n",
      "177/177 [==============================] - 0s 124us/step - loss: 0.1354 - accuracy: 0.9548 - val_loss: 2.1493 - val_accuracy: 0.5395\n",
      "Epoch 507/1000\n",
      "177/177 [==============================] - 0s 83us/step - loss: 0.1161 - accuracy: 0.9718 - val_loss: 2.2353 - val_accuracy: 0.5395\n",
      "Epoch 508/1000\n",
      "177/177 [==============================] - 0s 75us/step - loss: 0.1210 - accuracy: 0.9605 - val_loss: 2.1934 - val_accuracy: 0.5395\n",
      "Epoch 509/1000\n",
      "177/177 [==============================] - 0s 99us/step - loss: 0.1060 - accuracy: 0.9718 - val_loss: 2.2281 - val_accuracy: 0.5395\n",
      "Epoch 510/1000\n",
      "177/177 [==============================] - 0s 100us/step - loss: 0.1062 - accuracy: 0.9718 - val_loss: 2.2219 - val_accuracy: 0.5395\n",
      "Epoch 511/1000\n",
      "177/177 [==============================] - 0s 109us/step - loss: 0.0984 - accuracy: 0.9774 - val_loss: 2.1860 - val_accuracy: 0.5395\n",
      "Epoch 512/1000\n",
      "177/177 [==============================] - 0s 100us/step - loss: 0.1021 - accuracy: 0.9718 - val_loss: 2.1813 - val_accuracy: 0.5395\n",
      "Epoch 513/1000\n",
      "177/177 [==============================] - 0s 122us/step - loss: 0.1003 - accuracy: 0.9718 - val_loss: 2.2258 - val_accuracy: 0.5395\n",
      "Epoch 514/1000\n",
      "177/177 [==============================] - 0s 105us/step - loss: 0.1003 - accuracy: 0.9774 - val_loss: 2.2206 - val_accuracy: 0.5395\n",
      "Epoch 515/1000\n",
      "177/177 [==============================] - 0s 101us/step - loss: 0.0984 - accuracy: 0.9774 - val_loss: 2.2054 - val_accuracy: 0.5395\n",
      "Epoch 516/1000\n",
      "177/177 [==============================] - 0s 92us/step - loss: 0.0968 - accuracy: 0.9774 - val_loss: 2.2135 - val_accuracy: 0.5395\n",
      "Epoch 517/1000\n",
      "177/177 [==============================] - 0s 105us/step - loss: 0.0961 - accuracy: 0.9774 - val_loss: 2.2305 - val_accuracy: 0.5395\n",
      "Epoch 518/1000\n",
      "177/177 [==============================] - 0s 99us/step - loss: 0.0959 - accuracy: 0.9774 - val_loss: 2.2126 - val_accuracy: 0.5395\n",
      "Epoch 519/1000\n",
      "177/177 [==============================] - 0s 100us/step - loss: 0.0956 - accuracy: 0.9774 - val_loss: 2.2030 - val_accuracy: 0.5395\n",
      "Epoch 520/1000\n",
      "177/177 [==============================] - 0s 84us/step - loss: 0.0959 - accuracy: 0.9774 - val_loss: 2.2041 - val_accuracy: 0.5395\n",
      "Epoch 521/1000\n",
      "177/177 [==============================] - 0s 95us/step - loss: 0.0949 - accuracy: 0.9774 - val_loss: 2.2137 - val_accuracy: 0.5395\n",
      "Epoch 522/1000\n",
      "177/177 [==============================] - 0s 81us/step - loss: 0.0952 - accuracy: 0.9774 - val_loss: 2.2209 - val_accuracy: 0.5395\n",
      "Epoch 523/1000\n",
      "177/177 [==============================] - 0s 92us/step - loss: 0.0948 - accuracy: 0.9774 - val_loss: 2.2451 - val_accuracy: 0.5395\n",
      "Epoch 524/1000\n",
      "177/177 [==============================] - 0s 92us/step - loss: 0.0942 - accuracy: 0.9774 - val_loss: 2.2620 - val_accuracy: 0.5395\n",
      "Epoch 525/1000\n",
      "177/177 [==============================] - 0s 78us/step - loss: 0.0956 - accuracy: 0.9774 - val_loss: 2.2600 - val_accuracy: 0.5395\n",
      "Epoch 526/1000\n",
      "177/177 [==============================] - 0s 75us/step - loss: 0.0938 - accuracy: 0.9774 - val_loss: 2.2373 - val_accuracy: 0.5395\n",
      "Epoch 527/1000\n",
      "177/177 [==============================] - 0s 147us/step - loss: 0.0968 - accuracy: 0.9774 - val_loss: 2.2343 - val_accuracy: 0.5395\n",
      "Epoch 528/1000\n",
      "177/177 [==============================] - 0s 97us/step - loss: 0.0935 - accuracy: 0.9774 - val_loss: 2.2483 - val_accuracy: 0.5395\n",
      "Epoch 529/1000\n",
      "177/177 [==============================] - 0s 115us/step - loss: 0.1072 - accuracy: 0.9661 - val_loss: 2.2387 - val_accuracy: 0.5395\n",
      "Epoch 530/1000\n",
      "177/177 [==============================] - 0s 83us/step - loss: 0.1124 - accuracy: 0.9605 - val_loss: 2.2337 - val_accuracy: 0.5395\n",
      "Epoch 531/1000\n",
      "177/177 [==============================] - 0s 103us/step - loss: 0.1117 - accuracy: 0.9605 - val_loss: 2.2638 - val_accuracy: 0.5395\n",
      "Epoch 532/1000\n",
      "177/177 [==============================] - 0s 89us/step - loss: 0.1114 - accuracy: 0.9718 - val_loss: 2.3013 - val_accuracy: 0.5395\n",
      "Epoch 533/1000\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.1041 - accuracy: 0.9718 - val_loss: 2.2249 - val_accuracy: 0.5395\n",
      "Epoch 534/1000\n",
      "177/177 [==============================] - 0s 75us/step - loss: 0.1056 - accuracy: 0.9605 - val_loss: 2.2329 - val_accuracy: 0.5395\n",
      "Epoch 535/1000\n",
      "177/177 [==============================] - 0s 85us/step - loss: 0.0955 - accuracy: 0.9774 - val_loss: 2.2782 - val_accuracy: 0.5395\n",
      "Epoch 536/1000\n",
      "177/177 [==============================] - 0s 83us/step - loss: 0.0971 - accuracy: 0.9774 - val_loss: 2.2665 - val_accuracy: 0.5395\n",
      "Epoch 537/1000\n",
      "177/177 [==============================] - 0s 74us/step - loss: 0.0936 - accuracy: 0.9774 - val_loss: 2.2505 - val_accuracy: 0.5395\n",
      "Epoch 538/1000\n",
      "177/177 [==============================] - 0s 75us/step - loss: 0.0925 - accuracy: 0.9774 - val_loss: 2.2707 - val_accuracy: 0.5395\n",
      "Epoch 539/1000\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.0909 - accuracy: 0.9774 - val_loss: 2.2895 - val_accuracy: 0.5395\n",
      "Epoch 540/1000\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.0947 - accuracy: 0.9774 - val_loss: 2.2752 - val_accuracy: 0.5395\n",
      "Epoch 541/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.0913 - accuracy: 0.9774 - val_loss: 2.2540 - val_accuracy: 0.5395\n",
      "Epoch 542/1000\n",
      "177/177 [==============================] - 0s 74us/step - loss: 0.0940 - accuracy: 0.9774 - val_loss: 2.2604 - val_accuracy: 0.5395\n",
      "Epoch 543/1000\n",
      "177/177 [==============================] - 0s 297us/step - loss: 0.0900 - accuracy: 0.9774 - val_loss: 2.2978 - val_accuracy: 0.5395\n",
      "Epoch 544/1000\n",
      "177/177 [==============================] - 0s 99us/step - loss: 0.0934 - accuracy: 0.9718 - val_loss: 2.2668 - val_accuracy: 0.5395\n",
      "Epoch 545/1000\n",
      "177/177 [==============================] - 0s 138us/step - loss: 0.0910 - accuracy: 0.9774 - val_loss: 2.2514 - val_accuracy: 0.5395\n",
      "Epoch 546/1000\n",
      "177/177 [==============================] - 0s 120us/step - loss: 0.0922 - accuracy: 0.9774 - val_loss: 2.2711 - val_accuracy: 0.5395\n",
      "Epoch 547/1000\n",
      "177/177 [==============================] - 0s 115us/step - loss: 0.0898 - accuracy: 0.9774 - val_loss: 2.2958 - val_accuracy: 0.5395\n",
      "Epoch 548/1000\n",
      "177/177 [==============================] - 0s 135us/step - loss: 0.0936 - accuracy: 0.9718 - val_loss: 2.2753 - val_accuracy: 0.5395\n",
      "Epoch 549/1000\n",
      "177/177 [==============================] - 0s 119us/step - loss: 0.0906 - accuracy: 0.9774 - val_loss: 2.2629 - val_accuracy: 0.5395\n",
      "Epoch 550/1000\n",
      "177/177 [==============================] - 0s 117us/step - loss: 0.0927 - accuracy: 0.9774 - val_loss: 2.2863 - val_accuracy: 0.5395\n",
      "Epoch 551/1000\n",
      "177/177 [==============================] - 0s 106us/step - loss: 0.0891 - accuracy: 0.9774 - val_loss: 2.3210 - val_accuracy: 0.5395\n",
      "Epoch 552/1000\n",
      "177/177 [==============================] - 0s 123us/step - loss: 0.0968 - accuracy: 0.9718 - val_loss: 2.2879 - val_accuracy: 0.5395\n",
      "Epoch 553/1000\n",
      "177/177 [==============================] - 0s 114us/step - loss: 0.0906 - accuracy: 0.9774 - val_loss: 2.2712 - val_accuracy: 0.5395\n",
      "Epoch 554/1000\n",
      "177/177 [==============================] - 0s 97us/step - loss: 0.0990 - accuracy: 0.9605 - val_loss: 2.2890 - val_accuracy: 0.5395\n",
      "Epoch 555/1000\n",
      "177/177 [==============================] - 0s 116us/step - loss: 0.0991 - accuracy: 0.9718 - val_loss: 2.2946 - val_accuracy: 0.5395\n",
      "Epoch 556/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177/177 [==============================] - 0s 94us/step - loss: 0.0933 - accuracy: 0.9718 - val_loss: 2.2608 - val_accuracy: 0.5395\n",
      "Epoch 557/1000\n",
      "177/177 [==============================] - ETA: 0s - loss: 0.1293 - accuracy: 0.93 - 0s 68us/step - loss: 0.0949 - accuracy: 0.9661 - val_loss: 2.3259 - val_accuracy: 0.5395\n",
      "Epoch 558/1000\n",
      "177/177 [==============================] - 0s 74us/step - loss: 0.0931 - accuracy: 0.9774 - val_loss: 2.3324 - val_accuracy: 0.5395\n",
      "Epoch 559/1000\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.0886 - accuracy: 0.9774 - val_loss: 2.3128 - val_accuracy: 0.5395\n",
      "Epoch 560/1000\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.0920 - accuracy: 0.9718 - val_loss: 2.3126 - val_accuracy: 0.5395\n",
      "Epoch 561/1000\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.0914 - accuracy: 0.9718 - val_loss: 2.3457 - val_accuracy: 0.5395\n",
      "Epoch 562/1000\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.0906 - accuracy: 0.9774 - val_loss: 2.3261 - val_accuracy: 0.5395\n",
      "Epoch 563/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.0880 - accuracy: 0.9774 - val_loss: 2.3066 - val_accuracy: 0.5395\n",
      "Epoch 564/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.0880 - accuracy: 0.9774 - val_loss: 2.3075 - val_accuracy: 0.5395\n",
      "Epoch 565/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.0876 - accuracy: 0.9774 - val_loss: 2.3104 - val_accuracy: 0.5395\n",
      "Epoch 566/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.0867 - accuracy: 0.9774 - val_loss: 2.3168 - val_accuracy: 0.5395\n",
      "Epoch 567/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.0865 - accuracy: 0.9774 - val_loss: 2.3177 - val_accuracy: 0.5395\n",
      "Epoch 568/1000\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.0860 - accuracy: 0.9774 - val_loss: 2.3183 - val_accuracy: 0.5395\n",
      "Epoch 569/1000\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.0862 - accuracy: 0.9774 - val_loss: 2.3290 - val_accuracy: 0.5395\n",
      "Epoch 570/1000\n",
      "177/177 [==============================] - 0s 86us/step - loss: 0.0860 - accuracy: 0.9774 - val_loss: 2.3339 - val_accuracy: 0.5395\n",
      "Epoch 571/1000\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.0857 - accuracy: 0.9774 - val_loss: 2.3273 - val_accuracy: 0.5395\n",
      "Epoch 572/1000\n",
      "177/177 [==============================] - 0s 69us/step - loss: 0.0854 - accuracy: 0.9774 - val_loss: 2.3155 - val_accuracy: 0.5395\n",
      "Epoch 573/1000\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.0855 - accuracy: 0.9774 - val_loss: 2.3206 - val_accuracy: 0.5395\n",
      "Epoch 574/1000\n",
      "177/177 [==============================] - 0s 89us/step - loss: 0.0851 - accuracy: 0.9774 - val_loss: 2.3268 - val_accuracy: 0.5395\n",
      "Epoch 575/1000\n",
      "177/177 [==============================] - 0s 83us/step - loss: 0.0858 - accuracy: 0.9774 - val_loss: 2.3325 - val_accuracy: 0.5395\n",
      "Epoch 576/1000\n",
      "177/177 [==============================] - 0s 75us/step - loss: 0.0847 - accuracy: 0.9774 - val_loss: 2.3354 - val_accuracy: 0.5395\n",
      "Epoch 577/1000\n",
      "177/177 [==============================] - 0s 75us/step - loss: 0.0846 - accuracy: 0.9774 - val_loss: 2.3344 - val_accuracy: 0.5395\n",
      "Epoch 578/1000\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.0847 - accuracy: 0.9774 - val_loss: 2.3447 - val_accuracy: 0.5395\n",
      "Epoch 579/1000\n",
      "177/177 [==============================] - ETA: 0s - loss: 0.0698 - accuracy: 0.98 - 0s 91us/step - loss: 0.0842 - accuracy: 0.9774 - val_loss: 2.3478 - val_accuracy: 0.5395\n",
      "Epoch 580/1000\n",
      "177/177 [==============================] - 0s 76us/step - loss: 0.0839 - accuracy: 0.9774 - val_loss: 2.3478 - val_accuracy: 0.5395\n",
      "Epoch 581/1000\n",
      "177/177 [==============================] - 0s 85us/step - loss: 0.0841 - accuracy: 0.9774 - val_loss: 2.3403 - val_accuracy: 0.5395\n",
      "Epoch 582/1000\n",
      "177/177 [==============================] - 0s 79us/step - loss: 0.0847 - accuracy: 0.9774 - val_loss: 2.3449 - val_accuracy: 0.5395\n",
      "Epoch 583/1000\n",
      "177/177 [==============================] - 0s 93us/step - loss: 0.0840 - accuracy: 0.9774 - val_loss: 2.3699 - val_accuracy: 0.5395\n",
      "Epoch 584/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.0834 - accuracy: 0.9774 - val_loss: 2.3725 - val_accuracy: 0.5395\n",
      "Epoch 585/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.0837 - accuracy: 0.9774 - val_loss: 2.3631 - val_accuracy: 0.5395\n",
      "Epoch 586/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.0836 - accuracy: 0.9774 - val_loss: 2.3572 - val_accuracy: 0.5395\n",
      "Epoch 587/1000\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.0831 - accuracy: 0.9774 - val_loss: 2.3513 - val_accuracy: 0.5395\n",
      "Epoch 588/1000\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.0826 - accuracy: 0.9774 - val_loss: 2.3470 - val_accuracy: 0.5395\n",
      "Epoch 589/1000\n",
      "177/177 [==============================] - 0s 79us/step - loss: 0.0834 - accuracy: 0.9774 - val_loss: 2.3651 - val_accuracy: 0.5395\n",
      "Epoch 590/1000\n",
      "177/177 [==============================] - 0s 81us/step - loss: 0.0827 - accuracy: 0.9774 - val_loss: 2.3630 - val_accuracy: 0.5395\n",
      "Epoch 591/1000\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.0825 - accuracy: 0.9774 - val_loss: 2.3783 - val_accuracy: 0.5395\n",
      "Epoch 592/1000\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.0820 - accuracy: 0.9774 - val_loss: 2.3821 - val_accuracy: 0.5395\n",
      "Epoch 593/1000\n",
      "177/177 [==============================] - 0s 86us/step - loss: 0.0825 - accuracy: 0.9774 - val_loss: 2.3659 - val_accuracy: 0.5395\n",
      "Epoch 594/1000\n",
      "177/177 [==============================] - 0s 75us/step - loss: 0.0827 - accuracy: 0.9774 - val_loss: 2.3700 - val_accuracy: 0.5395\n",
      "Epoch 595/1000\n",
      "177/177 [==============================] - 0s 82us/step - loss: 0.0830 - accuracy: 0.9774 - val_loss: 2.3812 - val_accuracy: 0.5395\n",
      "Epoch 596/1000\n",
      "177/177 [==============================] - 0s 78us/step - loss: 0.0816 - accuracy: 0.9774 - val_loss: 2.3617 - val_accuracy: 0.5395\n",
      "Epoch 597/1000\n",
      "177/177 [==============================] - 0s 74us/step - loss: 0.0818 - accuracy: 0.9774 - val_loss: 2.3757 - val_accuracy: 0.5395\n",
      "Epoch 598/1000\n",
      "177/177 [==============================] - 0s 78us/step - loss: 0.0815 - accuracy: 0.9774 - val_loss: 2.3899 - val_accuracy: 0.5395\n",
      "Epoch 599/1000\n",
      "177/177 [==============================] - 0s 104us/step - loss: 0.0833 - accuracy: 0.9774 - val_loss: 2.4004 - val_accuracy: 0.5395\n",
      "Epoch 600/1000\n",
      "177/177 [==============================] - 0s 83us/step - loss: 0.0821 - accuracy: 0.9774 - val_loss: 2.3721 - val_accuracy: 0.5395\n",
      "Epoch 601/1000\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.0863 - accuracy: 0.9718 - val_loss: 2.3852 - val_accuracy: 0.5395\n",
      "Epoch 602/1000\n",
      "177/177 [==============================] - 0s 83us/step - loss: 0.0818 - accuracy: 0.9774 - val_loss: 2.4149 - val_accuracy: 0.5395\n",
      "Epoch 603/1000\n",
      "177/177 [==============================] - 0s 97us/step - loss: 0.0927 - accuracy: 0.9661 - val_loss: 2.3521 - val_accuracy: 0.5395\n",
      "Epoch 604/1000\n",
      "177/177 [==============================] - 0s 77us/step - loss: 0.1184 - accuracy: 0.9548 - val_loss: 2.3584 - val_accuracy: 0.5395\n",
      "Epoch 605/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.0870 - accuracy: 0.9718 - val_loss: 2.4411 - val_accuracy: 0.5395\n",
      "Epoch 606/1000\n",
      "177/177 [==============================] - 0s 89us/step - loss: 0.0853 - accuracy: 0.9718 - val_loss: 2.3872 - val_accuracy: 0.5395\n",
      "Epoch 607/1000\n",
      "177/177 [==============================] - 0s 83us/step - loss: 0.0889 - accuracy: 0.9718 - val_loss: 2.3936 - val_accuracy: 0.5395\n",
      "Epoch 608/1000\n",
      "177/177 [==============================] - 0s 59us/step - loss: 0.0814 - accuracy: 0.9774 - val_loss: 2.4511 - val_accuracy: 0.5395\n",
      "Epoch 609/1000\n",
      "177/177 [==============================] - 0s 78us/step - loss: 0.0914 - accuracy: 0.9718 - val_loss: 2.3856 - val_accuracy: 0.5395\n",
      "Epoch 610/1000\n",
      "177/177 [==============================] - 0s 78us/step - loss: 0.0896 - accuracy: 0.9661 - val_loss: 2.3964 - val_accuracy: 0.5395\n",
      "Epoch 611/1000\n",
      "177/177 [==============================] - 0s 76us/step - loss: 0.1150 - accuracy: 0.9548 - val_loss: 2.4005 - val_accuracy: 0.5395\n",
      "Epoch 612/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.1204 - accuracy: 0.9718 - val_loss: 2.5356 - val_accuracy: 0.5263\n",
      "Epoch 613/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.1233 - accuracy: 0.9661 - val_loss: 2.4051 - val_accuracy: 0.5395\n",
      "Epoch 614/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.1539 - accuracy: 0.9492 - val_loss: 2.4099 - val_accuracy: 0.5395\n",
      "Epoch 615/1000\n",
      "177/177 [==============================] - 0s 74us/step - loss: 0.1060 - accuracy: 0.9605 - val_loss: 2.5159 - val_accuracy: 0.5263\n",
      "Epoch 616/1000\n",
      "177/177 [==============================] - 0s 96us/step - loss: 0.1356 - accuracy: 0.9661 - val_loss: 2.4866 - val_accuracy: 0.5395\n",
      "Epoch 617/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.0797 - accuracy: 0.9774 - val_loss: 2.3949 - val_accuracy: 0.5395\n",
      "Epoch 618/1000\n",
      "177/177 [==============================] - 0s 79us/step - loss: 0.0941 - accuracy: 0.9661 - val_loss: 2.3900 - val_accuracy: 0.5395\n",
      "Epoch 619/1000\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.0813 - accuracy: 0.9774 - val_loss: 2.4357 - val_accuracy: 0.5395\n",
      "Epoch 620/1000\n",
      "177/177 [==============================] - 0s 63us/step - loss: 0.0813 - accuracy: 0.9774 - val_loss: 2.4443 - val_accuracy: 0.5395\n",
      "Epoch 621/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.0798 - accuracy: 0.9774 - val_loss: 2.3882 - val_accuracy: 0.5395\n",
      "Epoch 622/1000\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.0831 - accuracy: 0.9774 - val_loss: 2.3971 - val_accuracy: 0.5395\n",
      "Epoch 623/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.0806 - accuracy: 0.9774 - val_loss: 2.4551 - val_accuracy: 0.5395\n",
      "Epoch 624/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.0852 - accuracy: 0.9718 - val_loss: 2.4179 - val_accuracy: 0.5395\n",
      "Epoch 625/1000\n",
      "177/177 [==============================] - 0s 69us/step - loss: 0.0821 - accuracy: 0.9774 - val_loss: 2.3997 - val_accuracy: 0.5395\n",
      "Epoch 626/1000\n",
      "177/177 [==============================] - 0s 55us/step - loss: 0.0826 - accuracy: 0.9774 - val_loss: 2.4379 - val_accuracy: 0.5395\n",
      "Epoch 627/1000\n",
      "177/177 [==============================] - 0s 86us/step - loss: 0.0775 - accuracy: 0.9774 - val_loss: 2.4716 - val_accuracy: 0.5395\n",
      "Epoch 628/1000\n",
      "177/177 [==============================] - 0s 91us/step - loss: 0.0843 - accuracy: 0.9718 - val_loss: 2.4099 - val_accuracy: 0.5395\n",
      "Epoch 629/1000\n",
      "177/177 [==============================] - 0s 59us/step - loss: 0.0801 - accuracy: 0.9774 - val_loss: 2.4198 - val_accuracy: 0.5395\n",
      "Epoch 630/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.0791 - accuracy: 0.9774 - val_loss: 2.4520 - val_accuracy: 0.5395\n",
      "Epoch 631/1000\n",
      "177/177 [==============================] - 0s 91us/step - loss: 0.0773 - accuracy: 0.9774 - val_loss: 2.4623 - val_accuracy: 0.5395\n",
      "Epoch 632/1000\n",
      "177/177 [==============================] - 0s 83us/step - loss: 0.0769 - accuracy: 0.9774 - val_loss: 2.4265 - val_accuracy: 0.5395\n",
      "Epoch 633/1000\n",
      "177/177 [==============================] - 0s 77us/step - loss: 0.0765 - accuracy: 0.9774 - val_loss: 2.4307 - val_accuracy: 0.5395\n",
      "Epoch 634/1000\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.0781 - accuracy: 0.9774 - val_loss: 2.4381 - val_accuracy: 0.5395\n",
      "Epoch 635/1000\n",
      "177/177 [==============================] - 0s 85us/step - loss: 0.0783 - accuracy: 0.9774 - val_loss: 2.4639 - val_accuracy: 0.5395\n",
      "Epoch 636/1000\n",
      "177/177 [==============================] - 0s 82us/step - loss: 0.0760 - accuracy: 0.9774 - val_loss: 2.4456 - val_accuracy: 0.5395\n",
      "Epoch 637/1000\n",
      "177/177 [==============================] - 0s 82us/step - loss: 0.0767 - accuracy: 0.9774 - val_loss: 2.4481 - val_accuracy: 0.5526\n",
      "Epoch 638/1000\n",
      "177/177 [==============================] - 0s 117us/step - loss: 0.0765 - accuracy: 0.9774 - val_loss: 2.4723 - val_accuracy: 0.5526\n",
      "Epoch 639/1000\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.0759 - accuracy: 0.9774 - val_loss: 2.4935 - val_accuracy: 0.5395\n",
      "Epoch 640/1000\n",
      "177/177 [==============================] - 0s 84us/step - loss: 0.0769 - accuracy: 0.9774 - val_loss: 2.4774 - val_accuracy: 0.5395\n",
      "Epoch 641/1000\n",
      "177/177 [==============================] - 0s 79us/step - loss: 0.0762 - accuracy: 0.9774 - val_loss: 2.4559 - val_accuracy: 0.5395\n",
      "Epoch 642/1000\n",
      "177/177 [==============================] - 0s 103us/step - loss: 0.0761 - accuracy: 0.9774 - val_loss: 2.4631 - val_accuracy: 0.5395\n",
      "Epoch 643/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.0759 - accuracy: 0.9774 - val_loss: 2.4714 - val_accuracy: 0.5395\n",
      "Epoch 644/1000\n",
      "177/177 [==============================] - 0s 84us/step - loss: 0.0746 - accuracy: 0.9774 - val_loss: 2.4614 - val_accuracy: 0.5395\n",
      "Epoch 645/1000\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.0755 - accuracy: 0.9718 - val_loss: 2.4686 - val_accuracy: 0.5395\n",
      "Epoch 646/1000\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.0753 - accuracy: 0.9718 - val_loss: 2.4732 - val_accuracy: 0.5395\n",
      "Epoch 647/1000\n",
      "177/177 [==============================] - 0s 63us/step - loss: 0.0750 - accuracy: 0.9774 - val_loss: 2.4527 - val_accuracy: 0.5395\n",
      "Epoch 648/1000\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.0741 - accuracy: 0.9774 - val_loss: 2.4360 - val_accuracy: 0.5526\n",
      "Epoch 649/1000\n",
      "177/177 [==============================] - 0s 60us/step - loss: 0.0745 - accuracy: 0.9774 - val_loss: 2.4423 - val_accuracy: 0.5395\n",
      "Epoch 650/1000\n",
      "177/177 [==============================] - 0s 56us/step - loss: 0.0745 - accuracy: 0.9774 - val_loss: 2.4733 - val_accuracy: 0.5395\n",
      "Epoch 651/1000\n",
      "177/177 [==============================] - 0s 69us/step - loss: 0.0777 - accuracy: 0.9774 - val_loss: 2.4659 - val_accuracy: 0.5395\n",
      "Epoch 652/1000\n",
      "177/177 [==============================] - 0s 56us/step - loss: 0.0843 - accuracy: 0.9718 - val_loss: 2.4651 - val_accuracy: 0.5395\n",
      "Epoch 653/1000\n",
      "177/177 [==============================] - 0s 53us/step - loss: 0.0819 - accuracy: 0.9718 - val_loss: 2.5145 - val_accuracy: 0.5395\n",
      "Epoch 654/1000\n",
      "177/177 [==============================] - 0s 51us/step - loss: 0.0745 - accuracy: 0.9774 - val_loss: 2.4748 - val_accuracy: 0.5395\n",
      "Epoch 655/1000\n",
      "177/177 [==============================] - 0s 56us/step - loss: 0.0770 - accuracy: 0.9774 - val_loss: 2.4762 - val_accuracy: 0.5526\n",
      "Epoch 656/1000\n",
      "177/177 [==============================] - 0s 54us/step - loss: 0.0760 - accuracy: 0.9774 - val_loss: 2.5213 - val_accuracy: 0.5395\n",
      "Epoch 657/1000\n",
      "177/177 [==============================] - 0s 49us/step - loss: 0.0784 - accuracy: 0.9718 - val_loss: 2.5099 - val_accuracy: 0.5395\n",
      "Epoch 658/1000\n",
      "177/177 [==============================] - 0s 54us/step - loss: 0.0754 - accuracy: 0.9774 - val_loss: 2.4882 - val_accuracy: 0.5395\n",
      "Epoch 659/1000\n",
      "177/177 [==============================] - 0s 48us/step - loss: 0.0784 - accuracy: 0.9718 - val_loss: 2.4909 - val_accuracy: 0.5395\n",
      "Epoch 660/1000\n",
      "177/177 [==============================] - 0s 55us/step - loss: 0.0747 - accuracy: 0.9774 - val_loss: 2.5249 - val_accuracy: 0.5395\n",
      "Epoch 661/1000\n",
      "177/177 [==============================] - 0s 50us/step - loss: 0.0801 - accuracy: 0.9661 - val_loss: 2.4659 - val_accuracy: 0.5395\n",
      "Epoch 662/1000\n",
      "177/177 [==============================] - 0s 49us/step - loss: 0.0748 - accuracy: 0.9774 - val_loss: 2.4641 - val_accuracy: 0.5395\n",
      "Epoch 663/1000\n",
      "177/177 [==============================] - 0s 51us/step - loss: 0.0749 - accuracy: 0.9774 - val_loss: 2.4697 - val_accuracy: 0.5395\n",
      "Epoch 664/1000\n",
      "177/177 [==============================] - 0s 49us/step - loss: 0.0736 - accuracy: 0.9774 - val_loss: 2.5089 - val_accuracy: 0.5395\n",
      "Epoch 665/1000\n",
      "177/177 [==============================] - 0s 49us/step - loss: 0.0792 - accuracy: 0.9718 - val_loss: 2.4717 - val_accuracy: 0.5395\n",
      "Epoch 666/1000\n",
      "177/177 [==============================] - 0s 51us/step - loss: 0.0777 - accuracy: 0.9774 - val_loss: 2.4776 - val_accuracy: 0.5395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 667/1000\n",
      "177/177 [==============================] - 0s 50us/step - loss: 0.0794 - accuracy: 0.9718 - val_loss: 2.5189 - val_accuracy: 0.5395\n",
      "Epoch 668/1000\n",
      "177/177 [==============================] - 0s 53us/step - loss: 0.0742 - accuracy: 0.9774 - val_loss: 2.6036 - val_accuracy: 0.5395\n",
      "Epoch 669/1000\n",
      "177/177 [==============================] - 0s 50us/step - loss: 0.0909 - accuracy: 0.9718 - val_loss: 2.5252 - val_accuracy: 0.5395\n",
      "Epoch 670/1000\n",
      "177/177 [==============================] - 0s 54us/step - loss: 0.0943 - accuracy: 0.9605 - val_loss: 2.4972 - val_accuracy: 0.5526\n",
      "Epoch 671/1000\n",
      "177/177 [==============================] - 0s 57us/step - loss: 0.0730 - accuracy: 0.9774 - val_loss: 2.6004 - val_accuracy: 0.5395\n",
      "Epoch 672/1000\n",
      "177/177 [==============================] - 0s 52us/step - loss: 0.1299 - accuracy: 0.9661 - val_loss: 2.5091 - val_accuracy: 0.5526\n",
      "Epoch 673/1000\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.1323 - accuracy: 0.9492 - val_loss: 2.5096 - val_accuracy: 0.5263\n",
      "Epoch 674/1000\n",
      "177/177 [==============================] - 0s 55us/step - loss: 0.1184 - accuracy: 0.9548 - val_loss: 2.5399 - val_accuracy: 0.5395\n",
      "Epoch 675/1000\n",
      "177/177 [==============================] - 0s 58us/step - loss: 0.0737 - accuracy: 0.9774 - val_loss: 2.4912 - val_accuracy: 0.5395\n",
      "Epoch 676/1000\n",
      "177/177 [==============================] - 0s 58us/step - loss: 0.0790 - accuracy: 0.9718 - val_loss: 2.5146 - val_accuracy: 0.5395\n",
      "Epoch 677/1000\n",
      "177/177 [==============================] - 0s 59us/step - loss: 0.0735 - accuracy: 0.9774 - val_loss: 2.5562 - val_accuracy: 0.5395\n",
      "Epoch 678/1000\n",
      "177/177 [==============================] - 0s 56us/step - loss: 0.0740 - accuracy: 0.9774 - val_loss: 2.5519 - val_accuracy: 0.5395\n",
      "Epoch 679/1000\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.0767 - accuracy: 0.9774 - val_loss: 2.5132 - val_accuracy: 0.5395\n",
      "Epoch 680/1000\n",
      "177/177 [==============================] - 0s 47us/step - loss: 0.0735 - accuracy: 0.9774 - val_loss: 2.4773 - val_accuracy: 0.5526\n",
      "Epoch 681/1000\n",
      "177/177 [==============================] - 0s 50us/step - loss: 0.0977 - accuracy: 0.9605 - val_loss: 2.5123 - val_accuracy: 0.5526\n",
      "Epoch 682/1000\n",
      "177/177 [==============================] - 0s 48us/step - loss: 0.1175 - accuracy: 0.9661 - val_loss: 2.5271 - val_accuracy: 0.5526\n",
      "Epoch 683/1000\n",
      "177/177 [==============================] - 0s 43us/step - loss: 0.0778 - accuracy: 0.9661 - val_loss: 2.6199 - val_accuracy: 0.5132\n",
      "Epoch 684/1000\n",
      "177/177 [==============================] - 0s 43us/step - loss: 0.1764 - accuracy: 0.9435 - val_loss: 2.5477 - val_accuracy: 0.5395\n",
      "Epoch 685/1000\n",
      "177/177 [==============================] - 0s 42us/step - loss: 0.0791 - accuracy: 0.9661 - val_loss: 2.6238 - val_accuracy: 0.5395\n",
      "Epoch 686/1000\n",
      "177/177 [==============================] - 0s 46us/step - loss: 0.0859 - accuracy: 0.9718 - val_loss: 2.5669 - val_accuracy: 0.5395\n",
      "Epoch 687/1000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 0.0734 - accuracy: 0.9774 - val_loss: 2.4996 - val_accuracy: 0.5395\n",
      "Epoch 688/1000\n",
      "177/177 [==============================] - 0s 43us/step - loss: 0.0755 - accuracy: 0.9774 - val_loss: 2.5155 - val_accuracy: 0.5395\n",
      "Epoch 689/1000\n",
      "177/177 [==============================] - 0s 58us/step - loss: 0.0722 - accuracy: 0.9774 - val_loss: 2.5520 - val_accuracy: 0.5395\n",
      "Epoch 690/1000\n",
      "177/177 [==============================] - 0s 55us/step - loss: 0.0767 - accuracy: 0.9718 - val_loss: 2.4982 - val_accuracy: 0.5526\n",
      "Epoch 691/1000\n",
      "177/177 [==============================] - 0s 54us/step - loss: 0.0754 - accuracy: 0.9774 - val_loss: 2.5023 - val_accuracy: 0.5526\n",
      "Epoch 692/1000\n",
      "177/177 [==============================] - 0s 54us/step - loss: 0.0734 - accuracy: 0.9774 - val_loss: 2.5818 - val_accuracy: 0.5395\n",
      "Epoch 693/1000\n",
      "177/177 [==============================] - 0s 58us/step - loss: 0.0725 - accuracy: 0.9774 - val_loss: 2.5866 - val_accuracy: 0.5395\n",
      "Epoch 694/1000\n",
      "177/177 [==============================] - 0s 54us/step - loss: 0.0713 - accuracy: 0.9774 - val_loss: 2.5693 - val_accuracy: 0.5395\n",
      "Epoch 695/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.0721 - accuracy: 0.9774 - val_loss: 2.5573 - val_accuracy: 0.5395\n",
      "Epoch 696/1000\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.0707 - accuracy: 0.9774 - val_loss: 2.5656 - val_accuracy: 0.5395\n",
      "Epoch 697/1000\n",
      "177/177 [==============================] - 0s 51us/step - loss: 0.0708 - accuracy: 0.9774 - val_loss: 2.5750 - val_accuracy: 0.5395\n",
      "Epoch 698/1000\n",
      "177/177 [==============================] - 0s 50us/step - loss: 0.0700 - accuracy: 0.9774 - val_loss: 2.5458 - val_accuracy: 0.5395\n",
      "Epoch 699/1000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 0.0696 - accuracy: 0.9774 - val_loss: 2.5387 - val_accuracy: 0.5395\n",
      "Epoch 700/1000\n",
      "177/177 [==============================] - 0s 46us/step - loss: 0.0703 - accuracy: 0.9718 - val_loss: 2.5605 - val_accuracy: 0.5395\n",
      "Epoch 701/1000\n",
      "177/177 [==============================] - 0s 55us/step - loss: 0.0687 - accuracy: 0.9718 - val_loss: 2.5907 - val_accuracy: 0.5395\n",
      "Epoch 702/1000\n",
      "177/177 [==============================] - 0s 54us/step - loss: 0.0687 - accuracy: 0.9774 - val_loss: 2.5864 - val_accuracy: 0.5526\n",
      "Epoch 703/1000\n",
      "177/177 [==============================] - 0s 52us/step - loss: 0.0688 - accuracy: 0.9774 - val_loss: 2.5690 - val_accuracy: 0.5526\n",
      "Epoch 704/1000\n",
      "177/177 [==============================] - 0s 54us/step - loss: 0.0684 - accuracy: 0.9774 - val_loss: 2.5773 - val_accuracy: 0.5526\n",
      "Epoch 705/1000\n",
      "177/177 [==============================] - 0s 52us/step - loss: 0.0686 - accuracy: 0.9774 - val_loss: 2.5941 - val_accuracy: 0.5526\n",
      "Epoch 706/1000\n",
      "177/177 [==============================] - 0s 53us/step - loss: 0.0683 - accuracy: 0.9774 - val_loss: 2.5966 - val_accuracy: 0.5526\n",
      "Epoch 707/1000\n",
      "177/177 [==============================] - 0s 52us/step - loss: 0.0682 - accuracy: 0.9774 - val_loss: 2.5933 - val_accuracy: 0.5395\n",
      "Epoch 708/1000\n",
      "177/177 [==============================] - 0s 57us/step - loss: 0.0674 - accuracy: 0.9774 - val_loss: 2.5829 - val_accuracy: 0.5395\n",
      "Epoch 709/1000\n",
      "177/177 [==============================] - 0s 52us/step - loss: 0.0682 - accuracy: 0.9774 - val_loss: 2.5914 - val_accuracy: 0.5526\n",
      "Epoch 710/1000\n",
      "177/177 [==============================] - 0s 49us/step - loss: 0.0673 - accuracy: 0.9774 - val_loss: 2.6006 - val_accuracy: 0.5395\n",
      "Epoch 711/1000\n",
      "177/177 [==============================] - 0s 68us/step - loss: 0.0681 - accuracy: 0.9774 - val_loss: 2.5918 - val_accuracy: 0.5395\n",
      "Epoch 712/1000\n",
      "177/177 [==============================] - 0s 56us/step - loss: 0.0675 - accuracy: 0.9774 - val_loss: 2.5803 - val_accuracy: 0.5395\n",
      "Epoch 713/1000\n",
      "177/177 [==============================] - 0s 78us/step - loss: 0.0674 - accuracy: 0.9774 - val_loss: 2.5719 - val_accuracy: 0.5395\n",
      "Epoch 714/1000\n",
      "177/177 [==============================] - 0s 59us/step - loss: 0.0684 - accuracy: 0.9774 - val_loss: 2.5982 - val_accuracy: 0.5395\n",
      "Epoch 715/1000\n",
      "177/177 [==============================] - 0s 69us/step - loss: 0.0674 - accuracy: 0.9774 - val_loss: 2.6108 - val_accuracy: 0.5395\n",
      "Epoch 716/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.0670 - accuracy: 0.9774 - val_loss: 2.6015 - val_accuracy: 0.5526\n",
      "Epoch 717/1000\n",
      "177/177 [==============================] - 0s 69us/step - loss: 0.0668 - accuracy: 0.9774 - val_loss: 2.5812 - val_accuracy: 0.5526\n",
      "Epoch 718/1000\n",
      "177/177 [==============================] - 0s 57us/step - loss: 0.0668 - accuracy: 0.9774 - val_loss: 2.5852 - val_accuracy: 0.5526\n",
      "Epoch 719/1000\n",
      "177/177 [==============================] - 0s 55us/step - loss: 0.0665 - accuracy: 0.9774 - val_loss: 2.6090 - val_accuracy: 0.5395\n",
      "Epoch 720/1000\n",
      "177/177 [==============================] - 0s 54us/step - loss: 0.0670 - accuracy: 0.9718 - val_loss: 2.6052 - val_accuracy: 0.5395\n",
      "Epoch 721/1000\n",
      "177/177 [==============================] - 0s 103us/step - loss: 0.0672 - accuracy: 0.9774 - val_loss: 2.6028 - val_accuracy: 0.5395\n",
      "Epoch 722/1000\n",
      "177/177 [==============================] - 0s 85us/step - loss: 0.0659 - accuracy: 0.9774 - val_loss: 2.6134 - val_accuracy: 0.5526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 723/1000\n",
      "177/177 [==============================] - 0s 76us/step - loss: 0.0665 - accuracy: 0.9774 - val_loss: 2.6117 - val_accuracy: 0.5526\n",
      "Epoch 724/1000\n",
      "177/177 [==============================] - 0s 74us/step - loss: 0.0668 - accuracy: 0.9774 - val_loss: 2.6072 - val_accuracy: 0.5526\n",
      "Epoch 725/1000\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.0676 - accuracy: 0.9774 - val_loss: 2.6052 - val_accuracy: 0.5526\n",
      "Epoch 726/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.0656 - accuracy: 0.9774 - val_loss: 2.6437 - val_accuracy: 0.5395\n",
      "Epoch 727/1000\n",
      "177/177 [==============================] - 0s 56us/step - loss: 0.0672 - accuracy: 0.9774 - val_loss: 2.6336 - val_accuracy: 0.5395\n",
      "Epoch 728/1000\n",
      "177/177 [==============================] - 0s 68us/step - loss: 0.0666 - accuracy: 0.9774 - val_loss: 2.6155 - val_accuracy: 0.5395\n",
      "Epoch 729/1000\n",
      "177/177 [==============================] - 0s 74us/step - loss: 0.0664 - accuracy: 0.9774 - val_loss: 2.6159 - val_accuracy: 0.5395\n",
      "Epoch 730/1000\n",
      "177/177 [==============================] - 0s 63us/step - loss: 0.0653 - accuracy: 0.9774 - val_loss: 2.6325 - val_accuracy: 0.5526\n",
      "Epoch 731/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.0663 - accuracy: 0.9774 - val_loss: 2.6498 - val_accuracy: 0.5526\n",
      "Epoch 732/1000\n",
      "177/177 [==============================] - 0s 70us/step - loss: 0.0658 - accuracy: 0.9774 - val_loss: 2.6359 - val_accuracy: 0.5526\n",
      "Epoch 733/1000\n",
      "177/177 [==============================] - 0s 85us/step - loss: 0.0648 - accuracy: 0.9774 - val_loss: 2.6357 - val_accuracy: 0.5526\n",
      "Epoch 734/1000\n",
      "177/177 [==============================] - 0s 86us/step - loss: 0.0658 - accuracy: 0.9718 - val_loss: 2.6418 - val_accuracy: 0.5395\n",
      "Epoch 735/1000\n",
      "177/177 [==============================] - 0s 74us/step - loss: 0.0660 - accuracy: 0.9774 - val_loss: 2.6377 - val_accuracy: 0.5395\n",
      "Epoch 736/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.0649 - accuracy: 0.9774 - val_loss: 2.6293 - val_accuracy: 0.5395\n",
      "Epoch 737/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.0643 - accuracy: 0.9774 - val_loss: 2.6350 - val_accuracy: 0.5526\n",
      "Epoch 738/1000\n",
      "177/177 [==============================] - 0s 77us/step - loss: 0.0659 - accuracy: 0.9774 - val_loss: 2.6467 - val_accuracy: 0.5526\n",
      "Epoch 739/1000\n",
      "177/177 [==============================] - 0s 76us/step - loss: 0.0646 - accuracy: 0.9774 - val_loss: 2.6402 - val_accuracy: 0.5526\n",
      "Epoch 740/1000\n",
      "177/177 [==============================] - 0s 75us/step - loss: 0.0646 - accuracy: 0.9774 - val_loss: 2.6272 - val_accuracy: 0.5526\n",
      "Epoch 741/1000\n",
      "177/177 [==============================] - 0s 79us/step - loss: 0.0643 - accuracy: 0.9774 - val_loss: 2.6450 - val_accuracy: 0.5526\n",
      "Epoch 742/1000\n",
      "177/177 [==============================] - 0s 79us/step - loss: 0.0646 - accuracy: 0.9718 - val_loss: 2.6554 - val_accuracy: 0.5395\n",
      "Epoch 743/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.0649 - accuracy: 0.9774 - val_loss: 2.6422 - val_accuracy: 0.5526\n",
      "Epoch 744/1000\n",
      "177/177 [==============================] - 0s 83us/step - loss: 0.0638 - accuracy: 0.9774 - val_loss: 2.6521 - val_accuracy: 0.5526\n",
      "Epoch 745/1000\n",
      "177/177 [==============================] - 0s 81us/step - loss: 0.0637 - accuracy: 0.9774 - val_loss: 2.6568 - val_accuracy: 0.5395\n",
      "Epoch 746/1000\n",
      "177/177 [==============================] - 0s 70us/step - loss: 0.0640 - accuracy: 0.9774 - val_loss: 2.6570 - val_accuracy: 0.5395\n",
      "Epoch 747/1000\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.0636 - accuracy: 0.9774 - val_loss: 2.6464 - val_accuracy: 0.5526\n",
      "Epoch 748/1000\n",
      "177/177 [==============================] - 0s 83us/step - loss: 0.0645 - accuracy: 0.9774 - val_loss: 2.6426 - val_accuracy: 0.5526\n",
      "Epoch 749/1000\n",
      "177/177 [==============================] - 0s 75us/step - loss: 0.0640 - accuracy: 0.9774 - val_loss: 2.6692 - val_accuracy: 0.5526\n",
      "Epoch 750/1000\n",
      "177/177 [==============================] - 0s 70us/step - loss: 0.0643 - accuracy: 0.9774 - val_loss: 2.6549 - val_accuracy: 0.5526\n",
      "Epoch 751/1000\n",
      "177/177 [==============================] - 0s 96us/step - loss: 0.0639 - accuracy: 0.9774 - val_loss: 2.6588 - val_accuracy: 0.5526\n",
      "Epoch 752/1000\n",
      "177/177 [==============================] - 0s 87us/step - loss: 0.0637 - accuracy: 0.9774 - val_loss: 2.6636 - val_accuracy: 0.5526\n",
      "Epoch 753/1000\n",
      "177/177 [==============================] - 0s 81us/step - loss: 0.0653 - accuracy: 0.9774 - val_loss: 2.6792 - val_accuracy: 0.5395\n",
      "Epoch 754/1000\n",
      "177/177 [==============================] - 0s 83us/step - loss: 0.0633 - accuracy: 0.9774 - val_loss: 2.6538 - val_accuracy: 0.5395\n",
      "Epoch 755/1000\n",
      "177/177 [==============================] - 0s 76us/step - loss: 0.0636 - accuracy: 0.9718 - val_loss: 2.6516 - val_accuracy: 0.5395\n",
      "Epoch 756/1000\n",
      "177/177 [==============================] - 0s 85us/step - loss: 0.0643 - accuracy: 0.9774 - val_loss: 2.6737 - val_accuracy: 0.5395\n",
      "Epoch 757/1000\n",
      "177/177 [==============================] - 0s 77us/step - loss: 0.0629 - accuracy: 0.9774 - val_loss: 2.6857 - val_accuracy: 0.5395\n",
      "Epoch 758/1000\n",
      "177/177 [==============================] - 0s 83us/step - loss: 0.0632 - accuracy: 0.9774 - val_loss: 2.6655 - val_accuracy: 0.5395\n",
      "Epoch 759/1000\n",
      "177/177 [==============================] - 0s 87us/step - loss: 0.0630 - accuracy: 0.9774 - val_loss: 2.6532 - val_accuracy: 0.5395\n",
      "Epoch 760/1000\n",
      "177/177 [==============================] - 0s 81us/step - loss: 0.0624 - accuracy: 0.9774 - val_loss: 2.6613 - val_accuracy: 0.5526\n",
      "Epoch 761/1000\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.0627 - accuracy: 0.9774 - val_loss: 2.6693 - val_accuracy: 0.5526\n",
      "Epoch 762/1000\n",
      "177/177 [==============================] - 0s 74us/step - loss: 0.0631 - accuracy: 0.9774 - val_loss: 2.6633 - val_accuracy: 0.5526\n",
      "Epoch 763/1000\n",
      "177/177 [==============================] - 0s 75us/step - loss: 0.0622 - accuracy: 0.9774 - val_loss: 2.6777 - val_accuracy: 0.5526\n",
      "Epoch 764/1000\n",
      "177/177 [==============================] - 0s 84us/step - loss: 0.0619 - accuracy: 0.9774 - val_loss: 2.6884 - val_accuracy: 0.5526\n",
      "Epoch 765/1000\n",
      "177/177 [==============================] - 0s 76us/step - loss: 0.0632 - accuracy: 0.9774 - val_loss: 2.6728 - val_accuracy: 0.5526\n",
      "Epoch 766/1000\n",
      "177/177 [==============================] - 0s 69us/step - loss: 0.0626 - accuracy: 0.9774 - val_loss: 2.6745 - val_accuracy: 0.5526\n",
      "Epoch 767/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.0627 - accuracy: 0.9774 - val_loss: 2.6921 - val_accuracy: 0.5526\n",
      "Epoch 768/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.0623 - accuracy: 0.9774 - val_loss: 2.7050 - val_accuracy: 0.5526\n",
      "Epoch 769/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.0625 - accuracy: 0.9774 - val_loss: 2.7001 - val_accuracy: 0.5526\n",
      "Epoch 770/1000\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.0615 - accuracy: 0.9774 - val_loss: 2.7049 - val_accuracy: 0.5526\n",
      "Epoch 771/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.0615 - accuracy: 0.9774 - val_loss: 2.7043 - val_accuracy: 0.5395\n",
      "Epoch 772/1000\n",
      "177/177 [==============================] - 0s 96us/step - loss: 0.0612 - accuracy: 0.9774 - val_loss: 2.7081 - val_accuracy: 0.5395\n",
      "Epoch 773/1000\n",
      "177/177 [==============================] - 0s 123us/step - loss: 0.0617 - accuracy: 0.9774 - val_loss: 2.6987 - val_accuracy: 0.5395\n",
      "Epoch 774/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.0614 - accuracy: 0.9774 - val_loss: 2.6743 - val_accuracy: 0.5395\n",
      "Epoch 775/1000\n",
      "177/177 [==============================] - 0s 59us/step - loss: 0.0617 - accuracy: 0.9774 - val_loss: 2.6926 - val_accuracy: 0.5526\n",
      "Epoch 776/1000\n",
      "177/177 [==============================] - 0s 86us/step - loss: 0.0609 - accuracy: 0.9774 - val_loss: 2.7081 - val_accuracy: 0.5526\n",
      "Epoch 777/1000\n",
      "177/177 [==============================] - 0s 78us/step - loss: 0.0626 - accuracy: 0.9774 - val_loss: 2.7092 - val_accuracy: 0.5526\n",
      "Epoch 778/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.0603 - accuracy: 0.9774 - val_loss: 2.6904 - val_accuracy: 0.5526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 779/1000\n",
      "177/177 [==============================] - 0s 51us/step - loss: 0.0619 - accuracy: 0.9774 - val_loss: 2.6935 - val_accuracy: 0.5526\n",
      "Epoch 780/1000\n",
      "177/177 [==============================] - 0s 58us/step - loss: 0.0610 - accuracy: 0.9774 - val_loss: 2.7086 - val_accuracy: 0.5526\n",
      "Epoch 781/1000\n",
      "177/177 [==============================] - 0s 59us/step - loss: 0.0615 - accuracy: 0.9774 - val_loss: 2.7109 - val_accuracy: 0.5526\n",
      "Epoch 782/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.0605 - accuracy: 0.9774 - val_loss: 2.7176 - val_accuracy: 0.5526\n",
      "Epoch 783/1000\n",
      "177/177 [==============================] - 0s 68us/step - loss: 0.0611 - accuracy: 0.9774 - val_loss: 2.7215 - val_accuracy: 0.5526\n",
      "Epoch 784/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.0607 - accuracy: 0.9718 - val_loss: 2.7287 - val_accuracy: 0.5395\n",
      "Epoch 785/1000\n",
      "177/177 [==============================] - 0s 74us/step - loss: 0.0660 - accuracy: 0.9718 - val_loss: 2.6894 - val_accuracy: 0.5526\n",
      "Epoch 786/1000\n",
      "177/177 [==============================] - 0s 84us/step - loss: 0.0887 - accuracy: 0.9661 - val_loss: 2.6708 - val_accuracy: 0.5395\n",
      "Epoch 787/1000\n",
      "177/177 [==============================] - 0s 84us/step - loss: 0.0680 - accuracy: 0.9661 - val_loss: 2.7505 - val_accuracy: 0.5526\n",
      "Epoch 788/1000\n",
      "177/177 [==============================] - 0s 79us/step - loss: 0.0625 - accuracy: 0.9774 - val_loss: 2.6931 - val_accuracy: 0.5526\n",
      "Epoch 789/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.0625 - accuracy: 0.9774 - val_loss: 2.6861 - val_accuracy: 0.5395\n",
      "Epoch 790/1000\n",
      "177/177 [==============================] - 0s 70us/step - loss: 0.0846 - accuracy: 0.9718 - val_loss: 2.7195 - val_accuracy: 0.5395\n",
      "Epoch 791/1000\n",
      "177/177 [==============================] - 0s 69us/step - loss: 0.0754 - accuracy: 0.9718 - val_loss: 2.8472 - val_accuracy: 0.5263\n",
      "Epoch 792/1000\n",
      "177/177 [==============================] - 0s 68us/step - loss: 0.1361 - accuracy: 0.9661 - val_loss: 2.6914 - val_accuracy: 0.5395\n",
      "Epoch 793/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.1313 - accuracy: 0.9661 - val_loss: 2.7905 - val_accuracy: 0.5263\n",
      "Epoch 794/1000\n",
      "177/177 [==============================] - 0s 91us/step - loss: 0.1842 - accuracy: 0.9548 - val_loss: 2.6774 - val_accuracy: 0.5395\n",
      "Epoch 795/1000\n",
      "177/177 [==============================] - 0s 69us/step - loss: 0.0630 - accuracy: 0.9718 - val_loss: 2.9412 - val_accuracy: 0.5263\n",
      "Epoch 796/1000\n",
      "177/177 [==============================] - 0s 83us/step - loss: 0.2572 - accuracy: 0.9661 - val_loss: 2.7478 - val_accuracy: 0.5395\n",
      "Epoch 797/1000\n",
      "177/177 [==============================] - 0s 55us/step - loss: 0.0940 - accuracy: 0.9661 - val_loss: 2.7127 - val_accuracy: 0.5263\n",
      "Epoch 798/1000\n",
      "177/177 [==============================] - 0s 55us/step - loss: 0.2581 - accuracy: 0.9492 - val_loss: 2.7449 - val_accuracy: 0.5263\n",
      "Epoch 799/1000\n",
      "177/177 [==============================] - 0s 52us/step - loss: 0.1133 - accuracy: 0.9492 - val_loss: 2.7752 - val_accuracy: 0.5395\n",
      "Epoch 800/1000\n",
      "177/177 [==============================] - 0s 68us/step - loss: 0.1576 - accuracy: 0.9774 - val_loss: 2.9992 - val_accuracy: 0.5263\n",
      "Epoch 801/1000\n",
      "177/177 [==============================] - 0s 53us/step - loss: 0.1563 - accuracy: 0.9661 - val_loss: 2.6589 - val_accuracy: 0.5526\n",
      "Epoch 802/1000\n",
      "177/177 [==============================] - 0s 58us/step - loss: 0.1127 - accuracy: 0.9605 - val_loss: 2.6951 - val_accuracy: 0.5526\n",
      "Epoch 803/1000\n",
      "177/177 [==============================] - 0s 49us/step - loss: 0.1474 - accuracy: 0.9548 - val_loss: 2.6479 - val_accuracy: 0.5526\n",
      "Epoch 804/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.0786 - accuracy: 0.9661 - val_loss: 2.6850 - val_accuracy: 0.5526\n",
      "Epoch 805/1000\n",
      "177/177 [==============================] - 0s 56us/step - loss: 0.0654 - accuracy: 0.9774 - val_loss: 2.6387 - val_accuracy: 0.5526\n",
      "Epoch 806/1000\n",
      "177/177 [==============================] - 0s 58us/step - loss: 0.0792 - accuracy: 0.9718 - val_loss: 2.7101 - val_accuracy: 0.5395\n",
      "Epoch 807/1000\n",
      "177/177 [==============================] - 0s 54us/step - loss: 0.0654 - accuracy: 0.9718 - val_loss: 2.7958 - val_accuracy: 0.5395\n",
      "Epoch 808/1000\n",
      "177/177 [==============================] - 0s 51us/step - loss: 0.0619 - accuracy: 0.9774 - val_loss: 2.7691 - val_accuracy: 0.5395\n",
      "Epoch 809/1000\n",
      "177/177 [==============================] - 0s 55us/step - loss: 0.0614 - accuracy: 0.9774 - val_loss: 2.7397 - val_accuracy: 0.5395\n",
      "Epoch 810/1000\n",
      "177/177 [==============================] - 0s 56us/step - loss: 0.0626 - accuracy: 0.9774 - val_loss: 2.7370 - val_accuracy: 0.5526\n",
      "Epoch 811/1000\n",
      "177/177 [==============================] - 0s 51us/step - loss: 0.0610 - accuracy: 0.9774 - val_loss: 2.7375 - val_accuracy: 0.5526\n",
      "Epoch 812/1000\n",
      "177/177 [==============================] - 0s 52us/step - loss: 0.0612 - accuracy: 0.9774 - val_loss: 2.7491 - val_accuracy: 0.5526\n",
      "Epoch 813/1000\n",
      "177/177 [==============================] - 0s 55us/step - loss: 0.0594 - accuracy: 0.9774 - val_loss: 2.7252 - val_accuracy: 0.5526\n",
      "Epoch 814/1000\n",
      "177/177 [==============================] - 0s 51us/step - loss: 0.0597 - accuracy: 0.9718 - val_loss: 2.7278 - val_accuracy: 0.5526\n",
      "Epoch 815/1000\n",
      "177/177 [==============================] - 0s 50us/step - loss: 0.0597 - accuracy: 0.9718 - val_loss: 2.7354 - val_accuracy: 0.5526\n",
      "Epoch 816/1000\n",
      "177/177 [==============================] - 0s 52us/step - loss: 0.0591 - accuracy: 0.9774 - val_loss: 2.7550 - val_accuracy: 0.5526\n",
      "Epoch 817/1000\n",
      "177/177 [==============================] - 0s 52us/step - loss: 0.0585 - accuracy: 0.9774 - val_loss: 2.7530 - val_accuracy: 0.5526\n",
      "Epoch 818/1000\n",
      "177/177 [==============================] - 0s 56us/step - loss: 0.0579 - accuracy: 0.9774 - val_loss: 2.7527 - val_accuracy: 0.5526\n",
      "Epoch 819/1000\n",
      "177/177 [==============================] - 0s 52us/step - loss: 0.0577 - accuracy: 0.9774 - val_loss: 2.7543 - val_accuracy: 0.5526\n",
      "Epoch 820/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.0583 - accuracy: 0.9718 - val_loss: 2.7662 - val_accuracy: 0.5526\n",
      "Epoch 821/1000\n",
      "177/177 [==============================] - 0s 54us/step - loss: 0.0582 - accuracy: 0.9774 - val_loss: 2.7579 - val_accuracy: 0.5526\n",
      "Epoch 822/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.0585 - accuracy: 0.9774 - val_loss: 2.7525 - val_accuracy: 0.5526\n",
      "Epoch 823/1000\n",
      "177/177 [==============================] - 0s 53us/step - loss: 0.0582 - accuracy: 0.9774 - val_loss: 2.7694 - val_accuracy: 0.5526\n",
      "Epoch 824/1000\n",
      "177/177 [==============================] - 0s 52us/step - loss: 0.0574 - accuracy: 0.9774 - val_loss: 2.7725 - val_accuracy: 0.5526\n",
      "Epoch 825/1000\n",
      "177/177 [==============================] - 0s 58us/step - loss: 0.0585 - accuracy: 0.9774 - val_loss: 2.7697 - val_accuracy: 0.5526\n",
      "Epoch 826/1000\n",
      "177/177 [==============================] - 0s 57us/step - loss: 0.0574 - accuracy: 0.9774 - val_loss: 2.8046 - val_accuracy: 0.5395\n",
      "Epoch 827/1000\n",
      "177/177 [==============================] - 0s 57us/step - loss: 0.0583 - accuracy: 0.9774 - val_loss: 2.8048 - val_accuracy: 0.5526\n",
      "Epoch 828/1000\n",
      "177/177 [==============================] - 0s 57us/step - loss: 0.0577 - accuracy: 0.9774 - val_loss: 2.7839 - val_accuracy: 0.5526\n",
      "Epoch 829/1000\n",
      "177/177 [==============================] - 0s 52us/step - loss: 0.0575 - accuracy: 0.9774 - val_loss: 2.7878 - val_accuracy: 0.5526\n",
      "Epoch 830/1000\n",
      "177/177 [==============================] - 0s 52us/step - loss: 0.0572 - accuracy: 0.9774 - val_loss: 2.8079 - val_accuracy: 0.5526\n",
      "Epoch 831/1000\n",
      "177/177 [==============================] - 0s 47us/step - loss: 0.0570 - accuracy: 0.9774 - val_loss: 2.7833 - val_accuracy: 0.5526\n",
      "Epoch 832/1000\n",
      "177/177 [==============================] - 0s 51us/step - loss: 0.0566 - accuracy: 0.9774 - val_loss: 2.7635 - val_accuracy: 0.5526\n",
      "Epoch 833/1000\n",
      "177/177 [==============================] - 0s 47us/step - loss: 0.0569 - accuracy: 0.9831 - val_loss: 2.7832 - val_accuracy: 0.5526\n",
      "Epoch 834/1000\n",
      "177/177 [==============================] - 0s 46us/step - loss: 0.0574 - accuracy: 0.9774 - val_loss: 2.8131 - val_accuracy: 0.5526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 835/1000\n",
      "177/177 [==============================] - 0s 51us/step - loss: 0.0584 - accuracy: 0.9774 - val_loss: 2.7957 - val_accuracy: 0.5526\n",
      "Epoch 836/1000\n",
      "177/177 [==============================] - 0s 46us/step - loss: 0.0571 - accuracy: 0.9774 - val_loss: 2.7826 - val_accuracy: 0.5526\n",
      "Epoch 837/1000\n",
      "177/177 [==============================] - 0s 51us/step - loss: 0.0586 - accuracy: 0.9774 - val_loss: 2.7776 - val_accuracy: 0.5526\n",
      "Epoch 838/1000\n",
      "177/177 [==============================] - 0s 59us/step - loss: 0.0581 - accuracy: 0.9774 - val_loss: 2.8032 - val_accuracy: 0.5526\n",
      "Epoch 839/1000\n",
      "177/177 [==============================] - 0s 47us/step - loss: 0.0578 - accuracy: 0.9774 - val_loss: 2.8351 - val_accuracy: 0.5395\n",
      "Epoch 840/1000\n",
      "177/177 [==============================] - 0s 46us/step - loss: 0.0597 - accuracy: 0.9774 - val_loss: 2.7988 - val_accuracy: 0.5526\n",
      "Epoch 841/1000\n",
      "177/177 [==============================] - 0s 57us/step - loss: 0.0579 - accuracy: 0.9831 - val_loss: 2.7722 - val_accuracy: 0.5395\n",
      "Epoch 842/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.0643 - accuracy: 0.9774 - val_loss: 2.8048 - val_accuracy: 0.5526\n",
      "Epoch 843/1000\n",
      "177/177 [==============================] - 0s 51us/step - loss: 0.0583 - accuracy: 0.9774 - val_loss: 2.8434 - val_accuracy: 0.5526\n",
      "Epoch 844/1000\n",
      "177/177 [==============================] - 0s 52us/step - loss: 0.0572 - accuracy: 0.9774 - val_loss: 2.7846 - val_accuracy: 0.5526\n",
      "Epoch 845/1000\n",
      "177/177 [==============================] - 0s 53us/step - loss: 0.0594 - accuracy: 0.9774 - val_loss: 2.7727 - val_accuracy: 0.5395\n",
      "Epoch 846/1000\n",
      "177/177 [==============================] - 0s 54us/step - loss: 0.0607 - accuracy: 0.9831 - val_loss: 2.8214 - val_accuracy: 0.5526\n",
      "Epoch 847/1000\n",
      "177/177 [==============================] - 0s 60us/step - loss: 0.0564 - accuracy: 0.9774 - val_loss: 2.8506 - val_accuracy: 0.5526\n",
      "Epoch 848/1000\n",
      "177/177 [==============================] - 0s 53us/step - loss: 0.0564 - accuracy: 0.9774 - val_loss: 2.8182 - val_accuracy: 0.5526\n",
      "Epoch 849/1000\n",
      "177/177 [==============================] - 0s 52us/step - loss: 0.0558 - accuracy: 0.9774 - val_loss: 2.8262 - val_accuracy: 0.5526\n",
      "Epoch 850/1000\n",
      "177/177 [==============================] - 0s 53us/step - loss: 0.0553 - accuracy: 0.9774 - val_loss: 2.8384 - val_accuracy: 0.5526\n",
      "Epoch 851/1000\n",
      "177/177 [==============================] - 0s 52us/step - loss: 0.0563 - accuracy: 0.9774 - val_loss: 2.8366 - val_accuracy: 0.5526\n",
      "Epoch 852/1000\n",
      "177/177 [==============================] - 0s 51us/step - loss: 0.0554 - accuracy: 0.9774 - val_loss: 2.8266 - val_accuracy: 0.5526\n",
      "Epoch 853/1000\n",
      "177/177 [==============================] - 0s 54us/step - loss: 0.0558 - accuracy: 0.9774 - val_loss: 2.8289 - val_accuracy: 0.5526\n",
      "Epoch 854/1000\n",
      "177/177 [==============================] - 0s 52us/step - loss: 0.0553 - accuracy: 0.9718 - val_loss: 2.8312 - val_accuracy: 0.5526\n",
      "Epoch 855/1000\n",
      "177/177 [==============================] - 0s 49us/step - loss: 0.0554 - accuracy: 0.9774 - val_loss: 2.8372 - val_accuracy: 0.5526\n",
      "Epoch 856/1000\n",
      "177/177 [==============================] - 0s 54us/step - loss: 0.0546 - accuracy: 0.9774 - val_loss: 2.8205 - val_accuracy: 0.5395\n",
      "Epoch 857/1000\n",
      "177/177 [==============================] - 0s 56us/step - loss: 0.0560 - accuracy: 0.9774 - val_loss: 2.8147 - val_accuracy: 0.5395\n",
      "Epoch 858/1000\n",
      "177/177 [==============================] - 0s 58us/step - loss: 0.0549 - accuracy: 0.9831 - val_loss: 2.8308 - val_accuracy: 0.5395\n",
      "Epoch 859/1000\n",
      "177/177 [==============================] - 0s 63us/step - loss: 0.0551 - accuracy: 0.9774 - val_loss: 2.8444 - val_accuracy: 0.5395\n",
      "Epoch 860/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.0549 - accuracy: 0.9774 - val_loss: 2.8371 - val_accuracy: 0.5395\n",
      "Epoch 861/1000\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.0546 - accuracy: 0.9774 - val_loss: 2.8388 - val_accuracy: 0.5395\n",
      "Epoch 862/1000\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.0542 - accuracy: 0.9774 - val_loss: 2.8420 - val_accuracy: 0.5395\n",
      "Epoch 863/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.0550 - accuracy: 0.9718 - val_loss: 2.8274 - val_accuracy: 0.5395\n",
      "Epoch 864/1000\n",
      "177/177 [==============================] - 0s 63us/step - loss: 0.0545 - accuracy: 0.9774 - val_loss: 2.8342 - val_accuracy: 0.5395\n",
      "Epoch 865/1000\n",
      "177/177 [==============================] - 0s 57us/step - loss: 0.0539 - accuracy: 0.9774 - val_loss: 2.8573 - val_accuracy: 0.5526\n",
      "Epoch 866/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.0558 - accuracy: 0.9774 - val_loss: 2.8326 - val_accuracy: 0.5395\n",
      "Epoch 867/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.0555 - accuracy: 0.9831 - val_loss: 2.8221 - val_accuracy: 0.5395\n",
      "Epoch 868/1000\n",
      "177/177 [==============================] - 0s 58us/step - loss: 0.0561 - accuracy: 0.9774 - val_loss: 2.8609 - val_accuracy: 0.5526\n",
      "Epoch 869/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.0542 - accuracy: 0.9774 - val_loss: 2.8784 - val_accuracy: 0.5526\n",
      "Epoch 870/1000\n",
      "177/177 [==============================] - 0s 101us/step - loss: 0.0548 - accuracy: 0.9774 - val_loss: 2.8560 - val_accuracy: 0.5526\n",
      "Epoch 871/1000\n",
      "177/177 [==============================] - 0s 79us/step - loss: 0.0547 - accuracy: 0.9774 - val_loss: 2.8655 - val_accuracy: 0.5526\n",
      "Epoch 872/1000\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.0533 - accuracy: 0.9774 - val_loss: 2.8729 - val_accuracy: 0.5526\n",
      "Epoch 873/1000\n",
      "177/177 [==============================] - 0s 81us/step - loss: 0.0535 - accuracy: 0.9774 - val_loss: 2.8584 - val_accuracy: 0.5526\n",
      "Epoch 874/1000\n",
      "177/177 [==============================] - 0s 74us/step - loss: 0.0537 - accuracy: 0.9774 - val_loss: 2.8543 - val_accuracy: 0.5526\n",
      "Epoch 875/1000\n",
      "177/177 [==============================] - 0s 82us/step - loss: 0.0536 - accuracy: 0.9774 - val_loss: 2.8421 - val_accuracy: 0.5526\n",
      "Epoch 876/1000\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.0537 - accuracy: 0.9774 - val_loss: 2.8404 - val_accuracy: 0.5526\n",
      "Epoch 877/1000\n",
      "177/177 [==============================] - 0s 69us/step - loss: 0.0537 - accuracy: 0.9774 - val_loss: 2.8625 - val_accuracy: 0.5526\n",
      "Epoch 878/1000\n",
      "177/177 [==============================] - 0s 59us/step - loss: 0.0538 - accuracy: 0.9774 - val_loss: 2.8653 - val_accuracy: 0.5526\n",
      "Epoch 879/1000\n",
      "177/177 [==============================] - 0s 84us/step - loss: 0.0540 - accuracy: 0.9774 - val_loss: 2.8416 - val_accuracy: 0.5395\n",
      "Epoch 880/1000\n",
      "177/177 [==============================] - 0s 55us/step - loss: 0.0552 - accuracy: 0.9831 - val_loss: 2.8590 - val_accuracy: 0.5395\n",
      "Epoch 881/1000\n",
      "177/177 [==============================] - 0s 59us/step - loss: 0.0534 - accuracy: 0.9774 - val_loss: 2.8949 - val_accuracy: 0.5526\n",
      "Epoch 882/1000\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.0566 - accuracy: 0.9718 - val_loss: 2.8560 - val_accuracy: 0.5526\n",
      "Epoch 883/1000\n",
      "177/177 [==============================] - 0s 74us/step - loss: 0.0556 - accuracy: 0.9831 - val_loss: 2.8329 - val_accuracy: 0.5395\n",
      "Epoch 884/1000\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.0557 - accuracy: 0.9831 - val_loss: 2.8454 - val_accuracy: 0.5526\n",
      "Epoch 885/1000\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.0522 - accuracy: 0.9774 - val_loss: 2.9068 - val_accuracy: 0.5395\n",
      "Epoch 886/1000\n",
      "177/177 [==============================] - 0s 77us/step - loss: 0.0585 - accuracy: 0.9661 - val_loss: 2.8231 - val_accuracy: 0.5395\n",
      "Epoch 887/1000\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.0644 - accuracy: 0.9718 - val_loss: 2.8609 - val_accuracy: 0.5526\n",
      "Epoch 888/1000\n",
      "177/177 [==============================] - 0s 78us/step - loss: 0.0530 - accuracy: 0.9718 - val_loss: 2.9349 - val_accuracy: 0.5526\n",
      "Epoch 889/1000\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.0828 - accuracy: 0.9661 - val_loss: 2.8537 - val_accuracy: 0.5395\n",
      "Epoch 890/1000\n",
      "177/177 [==============================] - 0s 79us/step - loss: 0.0937 - accuracy: 0.9605 - val_loss: 2.8495 - val_accuracy: 0.5395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 891/1000\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.0681 - accuracy: 0.9661 - val_loss: 3.0103 - val_accuracy: 0.5395\n",
      "Epoch 892/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.1194 - accuracy: 0.9661 - val_loss: 2.8470 - val_accuracy: 0.5526\n",
      "Epoch 893/1000\n",
      "177/177 [==============================] - 0s 74us/step - loss: 0.0667 - accuracy: 0.9661 - val_loss: 2.8499 - val_accuracy: 0.5395\n",
      "Epoch 894/1000\n",
      "177/177 [==============================] - 0s 81us/step - loss: 0.0557 - accuracy: 0.9718 - val_loss: 2.8941 - val_accuracy: 0.5263\n",
      "Epoch 895/1000\n",
      "177/177 [==============================] - 0s 110us/step - loss: 0.0600 - accuracy: 0.9718 - val_loss: 2.8901 - val_accuracy: 0.5395\n",
      "Epoch 896/1000\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.0553 - accuracy: 0.9718 - val_loss: 2.8290 - val_accuracy: 0.5526\n",
      "Epoch 897/1000\n",
      "177/177 [==============================] - 0s 105us/step - loss: 0.0588 - accuracy: 0.9774 - val_loss: 2.8784 - val_accuracy: 0.5395\n",
      "Epoch 898/1000\n",
      "177/177 [==============================] - 0s 463us/step - loss: 0.0530 - accuracy: 0.9774 - val_loss: 2.9486 - val_accuracy: 0.5395\n",
      "Epoch 899/1000\n",
      "177/177 [==============================] - 0s 175us/step - loss: 0.0595 - accuracy: 0.9718 - val_loss: 2.8486 - val_accuracy: 0.5526\n",
      "Epoch 900/1000\n",
      "177/177 [==============================] - 0s 107us/step - loss: 0.0590 - accuracy: 0.9774 - val_loss: 2.8376 - val_accuracy: 0.5526\n",
      "Epoch 901/1000\n",
      "177/177 [==============================] - 0s 91us/step - loss: 0.0555 - accuracy: 0.9774 - val_loss: 2.9209 - val_accuracy: 0.5526\n",
      "Epoch 902/1000\n",
      "177/177 [==============================] - 0s 93us/step - loss: 0.0557 - accuracy: 0.9774 - val_loss: 2.9065 - val_accuracy: 0.5526\n",
      "Epoch 903/1000\n",
      "177/177 [==============================] - 0s 119us/step - loss: 0.0554 - accuracy: 0.9831 - val_loss: 2.8850 - val_accuracy: 0.5526\n",
      "Epoch 904/1000\n",
      "177/177 [==============================] - 0s 70us/step - loss: 0.0547 - accuracy: 0.9831 - val_loss: 2.9063 - val_accuracy: 0.5526\n",
      "Epoch 905/1000\n",
      "177/177 [==============================] - 0s 100us/step - loss: 0.0536 - accuracy: 0.9774 - val_loss: 2.9471 - val_accuracy: 0.5526\n",
      "Epoch 906/1000\n",
      "177/177 [==============================] - 0s 136us/step - loss: 0.0531 - accuracy: 0.9774 - val_loss: 2.9523 - val_accuracy: 0.5526\n",
      "Epoch 907/1000\n",
      "177/177 [==============================] - 0s 105us/step - loss: 0.0531 - accuracy: 0.9718 - val_loss: 2.9382 - val_accuracy: 0.5526\n",
      "Epoch 908/1000\n",
      "177/177 [==============================] - 0s 160us/step - loss: 0.0522 - accuracy: 0.9774 - val_loss: 2.8989 - val_accuracy: 0.5526\n",
      "Epoch 909/1000\n",
      "177/177 [==============================] - 0s 112us/step - loss: 0.0525 - accuracy: 0.9831 - val_loss: 2.9016 - val_accuracy: 0.5526\n",
      "Epoch 910/1000\n",
      "177/177 [==============================] - 0s 182us/step - loss: 0.0514 - accuracy: 0.9831 - val_loss: 2.9149 - val_accuracy: 0.5526\n",
      "Epoch 911/1000\n",
      "177/177 [==============================] - 0s 136us/step - loss: 0.0515 - accuracy: 0.9831 - val_loss: 2.9274 - val_accuracy: 0.5526\n",
      "Epoch 912/1000\n",
      "177/177 [==============================] - 0s 126us/step - loss: 0.0516 - accuracy: 0.9831 - val_loss: 2.9150 - val_accuracy: 0.5526\n",
      "Epoch 913/1000\n",
      "177/177 [==============================] - 0s 141us/step - loss: 0.0511 - accuracy: 0.9831 - val_loss: 2.9198 - val_accuracy: 0.5526\n",
      "Epoch 914/1000\n",
      "177/177 [==============================] - 0s 104us/step - loss: 0.0508 - accuracy: 0.9831 - val_loss: 2.9329 - val_accuracy: 0.5526\n",
      "Epoch 915/1000\n",
      "177/177 [==============================] - 0s 171us/step - loss: 0.0512 - accuracy: 0.9718 - val_loss: 2.9264 - val_accuracy: 0.5526\n",
      "Epoch 916/1000\n",
      "177/177 [==============================] - 0s 129us/step - loss: 0.0508 - accuracy: 0.9774 - val_loss: 2.9099 - val_accuracy: 0.5526\n",
      "Epoch 917/1000\n",
      "177/177 [==============================] - 0s 120us/step - loss: 0.0508 - accuracy: 0.9718 - val_loss: 2.9038 - val_accuracy: 0.5526\n",
      "Epoch 918/1000\n",
      "177/177 [==============================] - 0s 879us/step - loss: 0.0503 - accuracy: 0.9831 - val_loss: 2.9159 - val_accuracy: 0.5526\n",
      "Epoch 919/1000\n",
      "177/177 [==============================] - 0s 134us/step - loss: 0.0512 - accuracy: 0.9831 - val_loss: 2.9205 - val_accuracy: 0.5526\n",
      "Epoch 920/1000\n",
      "177/177 [==============================] - 0s 176us/step - loss: 0.0501 - accuracy: 0.9831 - val_loss: 2.9118 - val_accuracy: 0.5395\n",
      "Epoch 921/1000\n",
      "177/177 [==============================] - 0s 102us/step - loss: 0.0519 - accuracy: 0.9887 - val_loss: 2.9389 - val_accuracy: 0.5395\n",
      "Epoch 922/1000\n",
      "177/177 [==============================] - 0s 230us/step - loss: 0.0503 - accuracy: 0.9831 - val_loss: 2.9871 - val_accuracy: 0.5526\n",
      "Epoch 923/1000\n",
      "177/177 [==============================] - 0s 373us/step - loss: 0.0504 - accuracy: 0.9774 - val_loss: 3.0090 - val_accuracy: 0.5526\n",
      "Epoch 924/1000\n",
      "177/177 [==============================] - 0s 158us/step - loss: 0.0505 - accuracy: 0.9774 - val_loss: 2.9864 - val_accuracy: 0.5526\n",
      "Epoch 925/1000\n",
      "177/177 [==============================] - 0s 86us/step - loss: 0.0500 - accuracy: 0.9831 - val_loss: 2.9580 - val_accuracy: 0.5395\n",
      "Epoch 926/1000\n",
      "177/177 [==============================] - 0s 99us/step - loss: 0.0520 - accuracy: 0.9831 - val_loss: 2.9520 - val_accuracy: 0.5395\n",
      "Epoch 927/1000\n",
      "177/177 [==============================] - 0s 76us/step - loss: 0.0500 - accuracy: 0.9831 - val_loss: 2.9886 - val_accuracy: 0.5526\n",
      "Epoch 928/1000\n",
      "177/177 [==============================] - 0s 86us/step - loss: 0.0495 - accuracy: 0.9774 - val_loss: 3.0034 - val_accuracy: 0.5526\n",
      "Epoch 929/1000\n",
      "177/177 [==============================] - 0s 75us/step - loss: 0.0510 - accuracy: 0.9831 - val_loss: 2.9646 - val_accuracy: 0.5526\n",
      "Epoch 930/1000\n",
      "177/177 [==============================] - 0s 187us/step - loss: 0.0506 - accuracy: 0.9887 - val_loss: 2.9255 - val_accuracy: 0.5395\n",
      "Epoch 931/1000\n",
      "177/177 [==============================] - 0s 125us/step - loss: 0.0541 - accuracy: 0.9831 - val_loss: 2.9519 - val_accuracy: 0.5395\n",
      "Epoch 932/1000\n",
      "177/177 [==============================] - 0s 91us/step - loss: 0.0498 - accuracy: 0.9887 - val_loss: 3.0158 - val_accuracy: 0.5526\n",
      "Epoch 933/1000\n",
      "177/177 [==============================] - 0s 127us/step - loss: 0.0519 - accuracy: 0.9774 - val_loss: 2.9936 - val_accuracy: 0.5526\n",
      "Epoch 934/1000\n",
      "177/177 [==============================] - 0s 95us/step - loss: 0.0503 - accuracy: 0.9774 - val_loss: 2.9731 - val_accuracy: 0.5395\n",
      "Epoch 935/1000\n",
      "177/177 [==============================] - 0s 99us/step - loss: 0.0516 - accuracy: 0.9774 - val_loss: 2.9789 - val_accuracy: 0.5526\n",
      "Epoch 936/1000\n",
      "177/177 [==============================] - 0s 95us/step - loss: 0.0494 - accuracy: 0.9774 - val_loss: 3.0108 - val_accuracy: 0.5526\n",
      "Epoch 937/1000\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.0492 - accuracy: 0.9774 - val_loss: 3.0316 - val_accuracy: 0.5526\n",
      "Epoch 938/1000\n",
      "177/177 [==============================] - 0s 92us/step - loss: 0.0583 - accuracy: 0.9718 - val_loss: 2.9751 - val_accuracy: 0.5395\n",
      "Epoch 939/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.0833 - accuracy: 0.9718 - val_loss: 2.9657 - val_accuracy: 0.5395\n",
      "Epoch 940/1000\n",
      "177/177 [==============================] - 0s 60us/step - loss: 0.0565 - accuracy: 0.9718 - val_loss: 3.0456 - val_accuracy: 0.5526\n",
      "Epoch 941/1000\n",
      "177/177 [==============================] - 0s 58us/step - loss: 0.0605 - accuracy: 0.9718 - val_loss: 3.0304 - val_accuracy: 0.5526\n",
      "Epoch 942/1000\n",
      "177/177 [==============================] - 0s 104us/step - loss: 0.0493 - accuracy: 0.9774 - val_loss: 2.9748 - val_accuracy: 0.5526\n",
      "Epoch 943/1000\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.0520 - accuracy: 0.9831 - val_loss: 2.9760 - val_accuracy: 0.5526\n",
      "Epoch 944/1000\n",
      "177/177 [==============================] - 0s 77us/step - loss: 0.0512 - accuracy: 0.9831 - val_loss: 3.0180 - val_accuracy: 0.5526\n",
      "Epoch 945/1000\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.0499 - accuracy: 0.9831 - val_loss: 3.0375 - val_accuracy: 0.5526\n",
      "Epoch 946/1000\n",
      "177/177 [==============================] - 0s 76us/step - loss: 0.0494 - accuracy: 0.9831 - val_loss: 3.0029 - val_accuracy: 0.5526\n",
      "Epoch 947/1000\n",
      "177/177 [==============================] - 0s 77us/step - loss: 0.0488 - accuracy: 0.9831 - val_loss: 2.9999 - val_accuracy: 0.5526\n",
      "Epoch 948/1000\n",
      "177/177 [==============================] - 0s 78us/step - loss: 0.0492 - accuracy: 0.9831 - val_loss: 3.0079 - val_accuracy: 0.5526\n",
      "Epoch 949/1000\n",
      "177/177 [==============================] - 0s 63us/step - loss: 0.0491 - accuracy: 0.9831 - val_loss: 3.0505 - val_accuracy: 0.5526\n",
      "Epoch 950/1000\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.0488 - accuracy: 0.9831 - val_loss: 3.0527 - val_accuracy: 0.5526\n",
      "Epoch 951/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.0482 - accuracy: 0.9831 - val_loss: 3.0392 - val_accuracy: 0.5526\n",
      "Epoch 952/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.0480 - accuracy: 0.9831 - val_loss: 3.0306 - val_accuracy: 0.5395\n",
      "Epoch 953/1000\n",
      "177/177 [==============================] - 0s 86us/step - loss: 0.0479 - accuracy: 0.9831 - val_loss: 3.0439 - val_accuracy: 0.5526\n",
      "Epoch 954/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.0474 - accuracy: 0.9831 - val_loss: 3.0449 - val_accuracy: 0.5526\n",
      "Epoch 955/1000\n",
      "177/177 [==============================] - 0s 59us/step - loss: 0.0477 - accuracy: 0.9831 - val_loss: 3.0428 - val_accuracy: 0.5526\n",
      "Epoch 956/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.0477 - accuracy: 0.9887 - val_loss: 3.0311 - val_accuracy: 0.5395\n",
      "Epoch 957/1000\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.0475 - accuracy: 0.9887 - val_loss: 3.0402 - val_accuracy: 0.5395\n",
      "Epoch 958/1000\n",
      "177/177 [==============================] - 0s 230us/step - loss: 0.0473 - accuracy: 0.9887 - val_loss: 3.0565 - val_accuracy: 0.5395\n",
      "Epoch 959/1000\n",
      "177/177 [==============================] - 0s 140us/step - loss: 0.0474 - accuracy: 0.9887 - val_loss: 3.0534 - val_accuracy: 0.5263\n",
      "Epoch 960/1000\n",
      "177/177 [==============================] - 0s 141us/step - loss: 0.0472 - accuracy: 0.9831 - val_loss: 3.0650 - val_accuracy: 0.5263\n",
      "Epoch 961/1000\n",
      "177/177 [==============================] - 0s 261us/step - loss: 0.0479 - accuracy: 0.9774 - val_loss: 3.0321 - val_accuracy: 0.5263\n",
      "Epoch 962/1000\n",
      "177/177 [==============================] - 0s 137us/step - loss: 0.0478 - accuracy: 0.9887 - val_loss: 3.0139 - val_accuracy: 0.5395\n",
      "Epoch 963/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.0476 - accuracy: 0.9887 - val_loss: 3.0465 - val_accuracy: 0.5395\n",
      "Epoch 964/1000\n",
      "177/177 [==============================] - 0s 154us/step - loss: 0.0470 - accuracy: 0.9887 - val_loss: 3.0597 - val_accuracy: 0.5526\n",
      "Epoch 965/1000\n",
      "177/177 [==============================] - 0s 157us/step - loss: 0.0478 - accuracy: 0.9887 - val_loss: 3.0392 - val_accuracy: 0.5395\n",
      "Epoch 966/1000\n",
      "177/177 [==============================] - 0s 146us/step - loss: 0.0476 - accuracy: 0.9887 - val_loss: 3.0578 - val_accuracy: 0.5395\n",
      "Epoch 967/1000\n",
      "177/177 [==============================] - 0s 105us/step - loss: 0.0467 - accuracy: 0.9887 - val_loss: 3.0832 - val_accuracy: 0.5526\n",
      "Epoch 968/1000\n",
      "177/177 [==============================] - 0s 78us/step - loss: 0.0473 - accuracy: 0.9831 - val_loss: 3.0867 - val_accuracy: 0.5526\n",
      "Epoch 969/1000\n",
      "177/177 [==============================] - 0s 57us/step - loss: 0.0461 - accuracy: 0.9887 - val_loss: 3.0756 - val_accuracy: 0.5395\n",
      "Epoch 970/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.0466 - accuracy: 0.9887 - val_loss: 3.0729 - val_accuracy: 0.5395\n",
      "Epoch 971/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.0470 - accuracy: 0.9887 - val_loss: 3.0808 - val_accuracy: 0.5395\n",
      "Epoch 972/1000\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.0462 - accuracy: 0.9887 - val_loss: 3.0884 - val_accuracy: 0.5526\n",
      "Epoch 973/1000\n",
      "177/177 [==============================] - 0s 60us/step - loss: 0.0467 - accuracy: 0.9774 - val_loss: 3.0783 - val_accuracy: 0.5395\n",
      "Epoch 974/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.0462 - accuracy: 0.9831 - val_loss: 3.0709 - val_accuracy: 0.5395\n",
      "Epoch 975/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.0472 - accuracy: 0.9831 - val_loss: 3.0579 - val_accuracy: 0.5395\n",
      "Epoch 976/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.0479 - accuracy: 0.9887 - val_loss: 3.0250 - val_accuracy: 0.5395\n",
      "Epoch 977/1000\n",
      "177/177 [==============================] - 0s 78us/step - loss: 0.0478 - accuracy: 0.9887 - val_loss: 3.0420 - val_accuracy: 0.5395\n",
      "Epoch 978/1000\n",
      "177/177 [==============================] - 0s 143us/step - loss: 0.0464 - accuracy: 0.9831 - val_loss: 3.0825 - val_accuracy: 0.5526\n",
      "Epoch 979/1000\n",
      "177/177 [==============================] - 0s 158us/step - loss: 0.0491 - accuracy: 0.9774 - val_loss: 3.0441 - val_accuracy: 0.5395\n",
      "Epoch 980/1000\n",
      "177/177 [==============================] - 0s 200us/step - loss: 0.0513 - accuracy: 0.9831 - val_loss: 3.0148 - val_accuracy: 0.5395\n",
      "Epoch 981/1000\n",
      "177/177 [==============================] - 0s 97us/step - loss: 0.0498 - accuracy: 0.9887 - val_loss: 3.0806 - val_accuracy: 0.5526\n",
      "Epoch 982/1000\n",
      "177/177 [==============================] - 0s 82us/step - loss: 0.0692 - accuracy: 0.9605 - val_loss: 3.0186 - val_accuracy: 0.5395\n",
      "Epoch 983/1000\n",
      "177/177 [==============================] - 0s 108us/step - loss: 0.0850 - accuracy: 0.9718 - val_loss: 3.1859 - val_accuracy: 0.5132\n",
      "Epoch 984/1000\n",
      "177/177 [==============================] - 0s 104us/step - loss: 0.2035 - accuracy: 0.9548 - val_loss: 2.9843 - val_accuracy: 0.5395\n",
      "Epoch 985/1000\n",
      "177/177 [==============================] - 0s 91us/step - loss: 0.1160 - accuracy: 0.9661 - val_loss: 3.2438 - val_accuracy: 0.5395\n",
      "Epoch 986/1000\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.2011 - accuracy: 0.9661 - val_loss: 3.0216 - val_accuracy: 0.5526\n",
      "Epoch 987/1000\n",
      "177/177 [==============================] - 0s 543us/step - loss: 0.1690 - accuracy: 0.9661 - val_loss: 3.0955 - val_accuracy: 0.5263\n",
      "Epoch 988/1000\n",
      "177/177 [==============================] - 0s 139us/step - loss: 0.1666 - accuracy: 0.9548 - val_loss: 3.0250 - val_accuracy: 0.5395\n",
      "Epoch 989/1000\n",
      "177/177 [==============================] - 0s 146us/step - loss: 0.0849 - accuracy: 0.9661 - val_loss: 3.0364 - val_accuracy: 0.5526\n",
      "Epoch 990/1000\n",
      "177/177 [==============================] - 0s 101us/step - loss: 0.0512 - accuracy: 0.9774 - val_loss: 3.0000 - val_accuracy: 0.5526\n",
      "Epoch 991/1000\n",
      "177/177 [==============================] - 0s 114us/step - loss: 0.0703 - accuracy: 0.9718 - val_loss: 3.0373 - val_accuracy: 0.5395\n",
      "Epoch 992/1000\n",
      "177/177 [==============================] - 0s 148us/step - loss: 0.0791 - accuracy: 0.9718 - val_loss: 3.1359 - val_accuracy: 0.5395\n",
      "Epoch 993/1000\n",
      "177/177 [==============================] - 0s 77us/step - loss: 0.0572 - accuracy: 0.9718 - val_loss: 3.1114 - val_accuracy: 0.5132\n",
      "Epoch 994/1000\n",
      "177/177 [==============================] - 0s 118us/step - loss: 0.1941 - accuracy: 0.9548 - val_loss: 3.0752 - val_accuracy: 0.5395\n",
      "Epoch 995/1000\n",
      "177/177 [==============================] - 0s 274us/step - loss: 0.0633 - accuracy: 0.9718 - val_loss: 3.0202 - val_accuracy: 0.5395\n",
      "Epoch 996/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.0557 - accuracy: 0.9774 - val_loss: 3.2223 - val_accuracy: 0.5263\n",
      "Epoch 997/1000\n",
      "177/177 [==============================] - 0s 56us/step - loss: 0.2041 - accuracy: 0.9661 - val_loss: 2.9156 - val_accuracy: 0.5395\n",
      "Epoch 998/1000\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.0639 - accuracy: 0.9774 - val_loss: 2.9088 - val_accuracy: 0.5395\n",
      "Epoch 999/1000\n",
      "177/177 [==============================] - 0s 51us/step - loss: 0.0598 - accuracy: 0.9718 - val_loss: 3.0526 - val_accuracy: 0.5395\n",
      "Epoch 1000/1000\n",
      "177/177 [==============================] - 0s 52us/step - loss: 0.0745 - accuracy: 0.9718 - val_loss: 3.0059 - val_accuracy: 0.5395\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a4149b550>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sel3.fit(X_sel_train, y_sel_train,\n",
    "          batch_size=64, epochs=1000,\n",
    "          validation_data=(X_sel_test, y_sel_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 0s 64us/step\n",
      "test accuracy: 53.95%\n"
     ]
    }
   ],
   "source": [
    "acc_test_sel3 = model_sel3.evaluate(X_sel_test, y_sel_test)[1]\n",
    "print('test accuracy: %.2f%%' % (acc_test_sel3*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 1, 2, 2, 0, 1, 2, 2, 2, 0, 2, 2, 1, 1, 1, 0, 0, 1, 1, 1, 1,\n",
       "       1, 1, 0, 0, 0, 1, 2, 1, 1, 2, 1, 2, 1, 1, 0, 1, 0, 2, 0, 2, 2, 1,\n",
       "       0, 0, 1, 1, 1, 2, 2, 2, 1, 1, 0, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       1, 1, 0, 1, 0, 2, 2, 0, 1, 1])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred7 = model_sel3.predict_classes(X_sel_test)\n",
    "pred7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strain</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>NRS063</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>NRS219</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>GA27</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>CFBREBSa119</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>NRS233</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>CFBREBSa110</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>CFBRSa05</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>CFBREBSa123</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>NY360</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>CFBREBSa118</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          strain  test  pred\n",
       "120       NRS063     1     1\n",
       "187       NRS219     2     2\n",
       "96          GA27     2     1\n",
       "53   CFBREBSa119     1     2\n",
       "197       NRS233     2     2\n",
       "..           ...   ...   ...\n",
       "47   CFBREBSa110     2     2\n",
       "68      CFBRSa05     0     2\n",
       "56   CFBREBSa123     0     0\n",
       "231        NY360     1     1\n",
       "52   CFBREBSa118     2     1\n",
       "\n",
       "[76 rows x 3 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat7['pred'] = pred7\n",
    "dat7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba7 = model_sel3.predict_proba(X_sel_test)\n",
    "dat_proba7 = pd.DataFrame(proba7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.997123</td>\n",
       "      <td>0.001210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.999929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.209421</td>\n",
       "      <td>0.790520</td>\n",
       "      <td>0.000060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.001453</td>\n",
       "      <td>0.998545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.412327</td>\n",
       "      <td>0.004981</td>\n",
       "      <td>0.582692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.044135</td>\n",
       "      <td>0.010244</td>\n",
       "      <td>0.945621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.145032</td>\n",
       "      <td>0.408530</td>\n",
       "      <td>0.446438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.994623</td>\n",
       "      <td>0.004152</td>\n",
       "      <td>0.001224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.000795</td>\n",
       "      <td>0.948566</td>\n",
       "      <td>0.050639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.999037</td>\n",
       "      <td>0.000934</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2\n",
       "0   0.001667  0.997123  0.001210\n",
       "1   0.000003  0.000068  0.999929\n",
       "2   0.209421  0.790520  0.000060\n",
       "3   0.000002  0.001453  0.998545\n",
       "4   0.412327  0.004981  0.582692\n",
       "..       ...       ...       ...\n",
       "71  0.044135  0.010244  0.945621\n",
       "72  0.145032  0.408530  0.446438\n",
       "73  0.994623  0.004152  0.001224\n",
       "74  0.000795  0.948566  0.050639\n",
       "75  0.000029  0.999037  0.000934\n",
       "\n",
       "[76 rows x 3 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba7.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba7.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat7.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/7p40pST.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 177 samples, validate on 76 samples\n",
      "Epoch 1/1000\n",
      "177/177 [==============================] - 0s 77us/step - loss: 0.0491 - accuracy: 0.9774 - val_loss: 2.9670 - val_accuracy: 0.5395\n",
      "Epoch 2/1000\n",
      "177/177 [==============================] - 0s 70us/step - loss: 0.0491 - accuracy: 0.9831 - val_loss: 2.9832 - val_accuracy: 0.5395\n",
      "Epoch 3/1000\n",
      "177/177 [==============================] - 0s 58us/step - loss: 0.0496 - accuracy: 0.9831 - val_loss: 2.9822 - val_accuracy: 0.5395\n",
      "Epoch 4/1000\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.0495 - accuracy: 0.9831 - val_loss: 2.9811 - val_accuracy: 0.5395\n",
      "Epoch 5/1000\n",
      "177/177 [==============================] - 0s 107us/step - loss: 0.0489 - accuracy: 0.9831 - val_loss: 2.9873 - val_accuracy: 0.5395\n",
      "Epoch 6/1000\n",
      "177/177 [==============================] - 0s 83us/step - loss: 0.0493 - accuracy: 0.9831 - val_loss: 2.9726 - val_accuracy: 0.5395\n",
      "Epoch 7/1000\n",
      "177/177 [==============================] - 0s 114us/step - loss: 0.0492 - accuracy: 0.9774 - val_loss: 2.9720 - val_accuracy: 0.5395\n",
      "Epoch 8/1000\n",
      "177/177 [==============================] - 0s 108us/step - loss: 0.0503 - accuracy: 0.9831 - val_loss: 2.9480 - val_accuracy: 0.5395\n",
      "Epoch 9/1000\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.0492 - accuracy: 0.9831 - val_loss: 2.9673 - val_accuracy: 0.5395\n",
      "Epoch 10/1000\n",
      "177/177 [==============================] - 0s 285us/step - loss: 0.0485 - accuracy: 0.9831 - val_loss: 2.9780 - val_accuracy: 0.5395\n",
      "Epoch 11/1000\n",
      "177/177 [==============================] - 0s 104us/step - loss: 0.0492 - accuracy: 0.9831 - val_loss: 2.9853 - val_accuracy: 0.5395\n",
      "Epoch 12/1000\n",
      "177/177 [==============================] - 0s 95us/step - loss: 0.0492 - accuracy: 0.9774 - val_loss: 2.9884 - val_accuracy: 0.5395\n",
      "Epoch 13/1000\n",
      "177/177 [==============================] - 0s 125us/step - loss: 0.0485 - accuracy: 0.9831 - val_loss: 2.9771 - val_accuracy: 0.5395\n",
      "Epoch 14/1000\n",
      "177/177 [==============================] - 0s 79us/step - loss: 0.0484 - accuracy: 0.9831 - val_loss: 2.9833 - val_accuracy: 0.5395\n",
      "Epoch 15/1000\n",
      "177/177 [==============================] - 0s 93us/step - loss: 0.0486 - accuracy: 0.9831 - val_loss: 2.9859 - val_accuracy: 0.5395\n",
      "Epoch 16/1000\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.0493 - accuracy: 0.9831 - val_loss: 2.9958 - val_accuracy: 0.5395\n",
      "Epoch 17/1000\n",
      "177/177 [==============================] - 0s 86us/step - loss: 0.0490 - accuracy: 0.9831 - val_loss: 2.9964 - val_accuracy: 0.5395\n",
      "Epoch 18/1000\n",
      "177/177 [==============================] - 0s 94us/step - loss: 0.0485 - accuracy: 0.9831 - val_loss: 3.0010 - val_accuracy: 0.5395\n",
      "Epoch 19/1000\n",
      "177/177 [==============================] - 0s 77us/step - loss: 0.0485 - accuracy: 0.9831 - val_loss: 2.9977 - val_accuracy: 0.5395\n",
      "Epoch 20/1000\n",
      "177/177 [==============================] - 0s 78us/step - loss: 0.0489 - accuracy: 0.9831 - val_loss: 2.9842 - val_accuracy: 0.5395\n",
      "Epoch 21/1000\n",
      "177/177 [==============================] - 0s 78us/step - loss: 0.0483 - accuracy: 0.9831 - val_loss: 2.9739 - val_accuracy: 0.5395\n",
      "Epoch 22/1000\n",
      "177/177 [==============================] - 0s 82us/step - loss: 0.0489 - accuracy: 0.9774 - val_loss: 2.9762 - val_accuracy: 0.5395\n",
      "Epoch 23/1000\n",
      "177/177 [==============================] - 0s 83us/step - loss: 0.0483 - accuracy: 0.9831 - val_loss: 2.9788 - val_accuracy: 0.5395\n",
      "Epoch 24/1000\n",
      "177/177 [==============================] - 0s 83us/step - loss: 0.0491 - accuracy: 0.9774 - val_loss: 2.9793 - val_accuracy: 0.5395\n",
      "Epoch 25/1000\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.0486 - accuracy: 0.9831 - val_loss: 2.9788 - val_accuracy: 0.5395\n",
      "Epoch 26/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.0485 - accuracy: 0.9831 - val_loss: 2.9884 - val_accuracy: 0.5395\n",
      "Epoch 27/1000\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.0480 - accuracy: 0.9831 - val_loss: 2.9944 - val_accuracy: 0.5395\n",
      "Epoch 28/1000\n",
      "177/177 [==============================] - 0s 74us/step - loss: 0.0481 - accuracy: 0.9831 - val_loss: 3.0045 - val_accuracy: 0.5395\n",
      "Epoch 29/1000\n",
      "177/177 [==============================] - 0s 69us/step - loss: 0.0501 - accuracy: 0.9774 - val_loss: 2.9991 - val_accuracy: 0.5395\n",
      "Epoch 30/1000\n",
      "177/177 [==============================] - 0s 81us/step - loss: 0.0488 - accuracy: 0.9831 - val_loss: 2.9966 - val_accuracy: 0.5395\n",
      "Epoch 31/1000\n",
      "177/177 [==============================] - 0s 85us/step - loss: 0.0486 - accuracy: 0.9831 - val_loss: 2.9894 - val_accuracy: 0.5395\n",
      "Epoch 32/1000\n",
      "177/177 [==============================] - 0s 99us/step - loss: 0.0495 - accuracy: 0.9831 - val_loss: 2.9760 - val_accuracy: 0.5263\n",
      "Epoch 33/1000\n",
      "177/177 [==============================] - 0s 84us/step - loss: 0.0490 - accuracy: 0.9831 - val_loss: 2.9609 - val_accuracy: 0.5263\n",
      "Epoch 34/1000\n",
      "177/177 [==============================] - 0s 77us/step - loss: 0.0493 - accuracy: 0.9831 - val_loss: 2.9808 - val_accuracy: 0.5263\n",
      "Epoch 35/1000\n",
      "177/177 [==============================] - 0s 104us/step - loss: 0.0478 - accuracy: 0.9831 - val_loss: 2.9965 - val_accuracy: 0.5263\n",
      "Epoch 36/1000\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.0481 - accuracy: 0.9774 - val_loss: 3.0144 - val_accuracy: 0.5263\n",
      "Epoch 37/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.0487 - accuracy: 0.9831 - val_loss: 3.0075 - val_accuracy: 0.5263\n",
      "Epoch 38/1000\n",
      "177/177 [==============================] - 0s 85us/step - loss: 0.0489 - accuracy: 0.9774 - val_loss: 3.0220 - val_accuracy: 0.5263\n",
      "Epoch 39/1000\n",
      "177/177 [==============================] - 0s 108us/step - loss: 0.0483 - accuracy: 0.9831 - val_loss: 3.0073 - val_accuracy: 0.5263\n",
      "Epoch 40/1000\n",
      "177/177 [==============================] - 0s 97us/step - loss: 0.0480 - accuracy: 0.9831 - val_loss: 2.9766 - val_accuracy: 0.5395\n",
      "Epoch 41/1000\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.0479 - accuracy: 0.9831 - val_loss: 2.9618 - val_accuracy: 0.5395\n",
      "Epoch 42/1000\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.0474 - accuracy: 0.9831 - val_loss: 2.9596 - val_accuracy: 0.5395\n",
      "Epoch 43/1000\n",
      "177/177 [==============================] - 0s 99us/step - loss: 0.0478 - accuracy: 0.9774 - val_loss: 2.9540 - val_accuracy: 0.5395\n",
      "Epoch 44/1000\n",
      "177/177 [==============================] - 0s 101us/step - loss: 0.0485 - accuracy: 0.9831 - val_loss: 2.9529 - val_accuracy: 0.5395\n",
      "Epoch 45/1000\n",
      "177/177 [==============================] - 0s 89us/step - loss: 0.0482 - accuracy: 0.9831 - val_loss: 2.9341 - val_accuracy: 0.5132\n",
      "Epoch 46/1000\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.0497 - accuracy: 0.9887 - val_loss: 2.9659 - val_accuracy: 0.5263\n",
      "Epoch 47/1000\n",
      "177/177 [==============================] - 0s 63us/step - loss: 0.0485 - accuracy: 0.9831 - val_loss: 3.0048 - val_accuracy: 0.5395\n",
      "Epoch 48/1000\n",
      "177/177 [==============================] - 0s 92us/step - loss: 0.0472 - accuracy: 0.9831 - val_loss: 3.0192 - val_accuracy: 0.5395\n",
      "Epoch 49/1000\n",
      "177/177 [==============================] - 0s 63us/step - loss: 0.0493 - accuracy: 0.9831 - val_loss: 3.0008 - val_accuracy: 0.5395\n",
      "Epoch 50/1000\n",
      "177/177 [==============================] - 0s 83us/step - loss: 0.0482 - accuracy: 0.9774 - val_loss: 2.9701 - val_accuracy: 0.5395\n",
      "Epoch 51/1000\n",
      "177/177 [==============================] - 0s 74us/step - loss: 0.0484 - accuracy: 0.9831 - val_loss: 2.9708 - val_accuracy: 0.5395\n",
      "Epoch 52/1000\n",
      "177/177 [==============================] - 0s 69us/step - loss: 0.0473 - accuracy: 0.9831 - val_loss: 2.9884 - val_accuracy: 0.5395\n",
      "Epoch 53/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.0474 - accuracy: 0.9831 - val_loss: 3.0056 - val_accuracy: 0.5395\n",
      "Epoch 54/1000\n",
      "177/177 [==============================] - 0s 82us/step - loss: 0.0503 - accuracy: 0.9831 - val_loss: 2.9722 - val_accuracy: 0.5395\n",
      "Epoch 55/1000\n",
      "177/177 [==============================] - 0s 87us/step - loss: 0.0506 - accuracy: 0.9774 - val_loss: 2.9535 - val_accuracy: 0.5132\n",
      "Epoch 56/1000\n",
      "177/177 [==============================] - 0s 76us/step - loss: 0.0600 - accuracy: 0.9774 - val_loss: 3.0184 - val_accuracy: 0.5395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/1000\n",
      "177/177 [==============================] - 0s 56us/step - loss: 0.1064 - accuracy: 0.9605 - val_loss: 2.9470 - val_accuracy: 0.5395\n",
      "Epoch 58/1000\n",
      "177/177 [==============================] - 0s 97us/step - loss: 0.1253 - accuracy: 0.9548 - val_loss: 3.0617 - val_accuracy: 0.5000\n",
      "Epoch 59/1000\n",
      "177/177 [==============================] - 0s 54us/step - loss: 0.1477 - accuracy: 0.9548 - val_loss: 2.9082 - val_accuracy: 0.5395\n",
      "Epoch 60/1000\n",
      "177/177 [==============================] - 0s 70us/step - loss: 0.0927 - accuracy: 0.9718 - val_loss: 2.9422 - val_accuracy: 0.5263\n",
      "Epoch 61/1000\n",
      "177/177 [==============================] - 0s 76us/step - loss: 0.0618 - accuracy: 0.9718 - val_loss: 2.8213 - val_accuracy: 0.5395\n",
      "Epoch 62/1000\n",
      "177/177 [==============================] - 0s 76us/step - loss: 0.0782 - accuracy: 0.9774 - val_loss: 2.9084 - val_accuracy: 0.5395\n",
      "Epoch 63/1000\n",
      "177/177 [==============================] - 0s 75us/step - loss: 0.0518 - accuracy: 0.9774 - val_loss: 3.0510 - val_accuracy: 0.5395\n",
      "Epoch 64/1000\n",
      "177/177 [==============================] - 0s 75us/step - loss: 0.0554 - accuracy: 0.9661 - val_loss: 3.0389 - val_accuracy: 0.5395\n",
      "Epoch 65/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.0492 - accuracy: 0.9774 - val_loss: 3.0021 - val_accuracy: 0.5395\n",
      "Epoch 66/1000\n",
      "177/177 [==============================] - 0s 69us/step - loss: 0.0563 - accuracy: 0.9718 - val_loss: 3.0061 - val_accuracy: 0.5395\n",
      "Epoch 67/1000\n",
      "177/177 [==============================] - 0s 68us/step - loss: 0.0493 - accuracy: 0.9831 - val_loss: 3.0136 - val_accuracy: 0.5395\n",
      "Epoch 68/1000\n",
      "177/177 [==============================] - 0s 57us/step - loss: 0.0497 - accuracy: 0.9831 - val_loss: 2.9711 - val_accuracy: 0.5395\n",
      "Epoch 69/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.0476 - accuracy: 0.9831 - val_loss: 2.9677 - val_accuracy: 0.5395\n",
      "Epoch 70/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.0480 - accuracy: 0.9831 - val_loss: 2.9691 - val_accuracy: 0.5395\n",
      "Epoch 71/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.0480 - accuracy: 0.9831 - val_loss: 2.9951 - val_accuracy: 0.5395\n",
      "Epoch 72/1000\n",
      "177/177 [==============================] - 0s 56us/step - loss: 0.0471 - accuracy: 0.9831 - val_loss: 3.0159 - val_accuracy: 0.5395\n",
      "Epoch 73/1000\n",
      "177/177 [==============================] - 0s 58us/step - loss: 0.0466 - accuracy: 0.9831 - val_loss: 3.0422 - val_accuracy: 0.5395\n",
      "Epoch 74/1000\n",
      "177/177 [==============================] - 0s 57us/step - loss: 0.0469 - accuracy: 0.9831 - val_loss: 3.0329 - val_accuracy: 0.5395\n",
      "Epoch 75/1000\n",
      "177/177 [==============================] - 0s 74us/step - loss: 0.0471 - accuracy: 0.9831 - val_loss: 3.0334 - val_accuracy: 0.5395\n",
      "Epoch 76/1000\n",
      "177/177 [==============================] - 0s 63us/step - loss: 0.0468 - accuracy: 0.9831 - val_loss: 3.0324 - val_accuracy: 0.5395\n",
      "Epoch 77/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.0478 - accuracy: 0.9831 - val_loss: 3.0454 - val_accuracy: 0.5395\n",
      "Epoch 78/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.0463 - accuracy: 0.9831 - val_loss: 3.0427 - val_accuracy: 0.5395\n",
      "Epoch 79/1000\n",
      "177/177 [==============================] - 0s 59us/step - loss: 0.0463 - accuracy: 0.9831 - val_loss: 3.0437 - val_accuracy: 0.5263\n",
      "Epoch 80/1000\n",
      "177/177 [==============================] - 0s 74us/step - loss: 0.0455 - accuracy: 0.9831 - val_loss: 3.0398 - val_accuracy: 0.5132\n",
      "Epoch 81/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.0465 - accuracy: 0.9831 - val_loss: 3.0513 - val_accuracy: 0.5132\n",
      "Epoch 82/1000\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.0459 - accuracy: 0.9831 - val_loss: 3.0764 - val_accuracy: 0.5132\n",
      "Epoch 83/1000\n",
      "177/177 [==============================] - ETA: 0s - loss: 0.0563 - accuracy: 0.98 - 0s 112us/step - loss: 0.0465 - accuracy: 0.9831 - val_loss: 3.0944 - val_accuracy: 0.5263\n",
      "Epoch 84/1000\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.0460 - accuracy: 0.9831 - val_loss: 3.0720 - val_accuracy: 0.5263\n",
      "Epoch 85/1000\n",
      "177/177 [==============================] - 0s 77us/step - loss: 0.0458 - accuracy: 0.9831 - val_loss: 3.0548 - val_accuracy: 0.5132\n",
      "Epoch 86/1000\n",
      "177/177 [==============================] - 0s 69us/step - loss: 0.0459 - accuracy: 0.9831 - val_loss: 3.0530 - val_accuracy: 0.5132\n",
      "Epoch 87/1000\n",
      "177/177 [==============================] - 0s 89us/step - loss: 0.0457 - accuracy: 0.9831 - val_loss: 3.0796 - val_accuracy: 0.5263\n",
      "Epoch 88/1000\n",
      "177/177 [==============================] - 0s 78us/step - loss: 0.0465 - accuracy: 0.9831 - val_loss: 3.0756 - val_accuracy: 0.5263\n",
      "Epoch 89/1000\n",
      "177/177 [==============================] - 0s 68us/step - loss: 0.0453 - accuracy: 0.9831 - val_loss: 3.0530 - val_accuracy: 0.5000\n",
      "Epoch 90/1000\n",
      "177/177 [==============================] - 0s 116us/step - loss: 0.0479 - accuracy: 0.9774 - val_loss: 3.0513 - val_accuracy: 0.5000\n",
      "Epoch 91/1000\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.0467 - accuracy: 0.9831 - val_loss: 3.0585 - val_accuracy: 0.5263\n",
      "Epoch 92/1000\n",
      "177/177 [==============================] - 0s 119us/step - loss: 0.0473 - accuracy: 0.9831 - val_loss: 3.0810 - val_accuracy: 0.5263\n",
      "Epoch 93/1000\n",
      "177/177 [==============================] - 0s 81us/step - loss: 0.0459 - accuracy: 0.9831 - val_loss: 3.0569 - val_accuracy: 0.5263\n",
      "Epoch 94/1000\n",
      "177/177 [==============================] - 0s 84us/step - loss: 0.0454 - accuracy: 0.9831 - val_loss: 3.0586 - val_accuracy: 0.5263\n",
      "Epoch 95/1000\n",
      "177/177 [==============================] - 0s 74us/step - loss: 0.0460 - accuracy: 0.9774 - val_loss: 3.0504 - val_accuracy: 0.5263\n",
      "Epoch 96/1000\n",
      "177/177 [==============================] - 0s 86us/step - loss: 0.0461 - accuracy: 0.9831 - val_loss: 3.0797 - val_accuracy: 0.5263\n",
      "Epoch 97/1000\n",
      "177/177 [==============================] - 0s 93us/step - loss: 0.0454 - accuracy: 0.9831 - val_loss: 3.0997 - val_accuracy: 0.5263\n",
      "Epoch 98/1000\n",
      "177/177 [==============================] - 0s 110us/step - loss: 0.0454 - accuracy: 0.9831 - val_loss: 3.0949 - val_accuracy: 0.5263\n",
      "Epoch 99/1000\n",
      "177/177 [==============================] - 0s 105us/step - loss: 0.0450 - accuracy: 0.9831 - val_loss: 3.0994 - val_accuracy: 0.5263\n",
      "Epoch 100/1000\n",
      "177/177 [==============================] - 0s 81us/step - loss: 0.0448 - accuracy: 0.9831 - val_loss: 3.0983 - val_accuracy: 0.5263\n",
      "Epoch 101/1000\n",
      "177/177 [==============================] - 0s 104us/step - loss: 0.0455 - accuracy: 0.9831 - val_loss: 3.1144 - val_accuracy: 0.5263\n",
      "Epoch 102/1000\n",
      "177/177 [==============================] - 0s 109us/step - loss: 0.0464 - accuracy: 0.9831 - val_loss: 3.0901 - val_accuracy: 0.5263\n",
      "Epoch 103/1000\n",
      "177/177 [==============================] - 0s 95us/step - loss: 0.0455 - accuracy: 0.9831 - val_loss: 3.0827 - val_accuracy: 0.5132\n",
      "Epoch 104/1000\n",
      "177/177 [==============================] - 0s 89us/step - loss: 0.0453 - accuracy: 0.9831 - val_loss: 3.0954 - val_accuracy: 0.5263\n",
      "Epoch 105/1000\n",
      "177/177 [==============================] - 0s 113us/step - loss: 0.0451 - accuracy: 0.9831 - val_loss: 3.0830 - val_accuracy: 0.5263\n",
      "Epoch 106/1000\n",
      "177/177 [==============================] - 0s 81us/step - loss: 0.0456 - accuracy: 0.9831 - val_loss: 3.0938 - val_accuracy: 0.5000\n",
      "Epoch 107/1000\n",
      "177/177 [==============================] - 0s 93us/step - loss: 0.0450 - accuracy: 0.9831 - val_loss: 3.1220 - val_accuracy: 0.5132\n",
      "Epoch 108/1000\n",
      "177/177 [==============================] - 0s 82us/step - loss: 0.0447 - accuracy: 0.9831 - val_loss: 3.1181 - val_accuracy: 0.5132\n",
      "Epoch 109/1000\n",
      "177/177 [==============================] - 0s 93us/step - loss: 0.0456 - accuracy: 0.9831 - val_loss: 3.1076 - val_accuracy: 0.5263\n",
      "Epoch 110/1000\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.0449 - accuracy: 0.9831 - val_loss: 3.0870 - val_accuracy: 0.5263\n",
      "Epoch 111/1000\n",
      "177/177 [==============================] - 0s 82us/step - loss: 0.0446 - accuracy: 0.9831 - val_loss: 3.0865 - val_accuracy: 0.5395\n",
      "Epoch 112/1000\n",
      "177/177 [==============================] - 0s 79us/step - loss: 0.0445 - accuracy: 0.9831 - val_loss: 3.1024 - val_accuracy: 0.5395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.0445 - accuracy: 0.9831 - val_loss: 3.1149 - val_accuracy: 0.5395\n",
      "Epoch 114/1000\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.0446 - accuracy: 0.9831 - val_loss: 3.1067 - val_accuracy: 0.5263\n",
      "Epoch 115/1000\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.0445 - accuracy: 0.9831 - val_loss: 3.0999 - val_accuracy: 0.5263\n",
      "Epoch 116/1000\n",
      "177/177 [==============================] - 0s 96us/step - loss: 0.0457 - accuracy: 0.9831 - val_loss: 3.1132 - val_accuracy: 0.5263\n",
      "Epoch 117/1000\n",
      "177/177 [==============================] - 0s 84us/step - loss: 0.0445 - accuracy: 0.9831 - val_loss: 3.1085 - val_accuracy: 0.5263\n",
      "Epoch 118/1000\n",
      "177/177 [==============================] - 0s 81us/step - loss: 0.0445 - accuracy: 0.9831 - val_loss: 3.1144 - val_accuracy: 0.5132\n",
      "Epoch 119/1000\n",
      "177/177 [==============================] - 0s 75us/step - loss: 0.0444 - accuracy: 0.9831 - val_loss: 3.1216 - val_accuracy: 0.5263\n",
      "Epoch 120/1000\n",
      "177/177 [==============================] - 0s 75us/step - loss: 0.0444 - accuracy: 0.9831 - val_loss: 3.1430 - val_accuracy: 0.5263\n",
      "Epoch 121/1000\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.0440 - accuracy: 0.9831 - val_loss: 3.1343 - val_accuracy: 0.5132\n",
      "Epoch 122/1000\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.0446 - accuracy: 0.9774 - val_loss: 3.1255 - val_accuracy: 0.5000\n",
      "Epoch 123/1000\n",
      "177/177 [==============================] - 0s 104us/step - loss: 0.0446 - accuracy: 0.9831 - val_loss: 3.1378 - val_accuracy: 0.5263\n",
      "Epoch 124/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.0447 - accuracy: 0.9831 - val_loss: 3.1259 - val_accuracy: 0.5132\n",
      "Epoch 125/1000\n",
      "177/177 [==============================] - 0s 79us/step - loss: 0.0441 - accuracy: 0.9831 - val_loss: 3.1117 - val_accuracy: 0.5000\n",
      "Epoch 126/1000\n",
      "177/177 [==============================] - 0s 74us/step - loss: 0.0440 - accuracy: 0.9831 - val_loss: 3.1198 - val_accuracy: 0.5000\n",
      "Epoch 127/1000\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.0457 - accuracy: 0.9831 - val_loss: 3.1587 - val_accuracy: 0.5263\n",
      "Epoch 128/1000\n",
      "177/177 [==============================] - 0s 76us/step - loss: 0.0440 - accuracy: 0.9831 - val_loss: 3.1379 - val_accuracy: 0.5132\n",
      "Epoch 129/1000\n",
      "177/177 [==============================] - 0s 76us/step - loss: 0.0442 - accuracy: 0.9831 - val_loss: 3.1263 - val_accuracy: 0.5000\n",
      "Epoch 130/1000\n",
      "177/177 [==============================] - 0s 96us/step - loss: 0.0447 - accuracy: 0.9887 - val_loss: 3.1175 - val_accuracy: 0.5000\n",
      "Epoch 131/1000\n",
      "177/177 [==============================] - 0s 93us/step - loss: 0.0438 - accuracy: 0.9831 - val_loss: 3.1319 - val_accuracy: 0.5263\n",
      "Epoch 132/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.0449 - accuracy: 0.9831 - val_loss: 3.1253 - val_accuracy: 0.5263\n",
      "Epoch 133/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.0450 - accuracy: 0.9774 - val_loss: 3.1170 - val_accuracy: 0.5000\n",
      "Epoch 134/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.0445 - accuracy: 0.9774 - val_loss: 3.1320 - val_accuracy: 0.5132\n",
      "Epoch 135/1000\n",
      "177/177 [==============================] - 0s 69us/step - loss: 0.0440 - accuracy: 0.9831 - val_loss: 3.1688 - val_accuracy: 0.5263\n",
      "Epoch 136/1000\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.0457 - accuracy: 0.9774 - val_loss: 3.1598 - val_accuracy: 0.5263\n",
      "Epoch 137/1000\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.0444 - accuracy: 0.9887 - val_loss: 3.1180 - val_accuracy: 0.5000\n",
      "Epoch 138/1000\n",
      "177/177 [==============================] - 0s 83us/step - loss: 0.0516 - accuracy: 0.9887 - val_loss: 3.1105 - val_accuracy: 0.5132\n",
      "Epoch 139/1000\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.0452 - accuracy: 0.9774 - val_loss: 3.1743 - val_accuracy: 0.5132\n",
      "Epoch 140/1000\n",
      "177/177 [==============================] - 0s 83us/step - loss: 0.0470 - accuracy: 0.9831 - val_loss: 3.0860 - val_accuracy: 0.5263\n",
      "Epoch 141/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.0463 - accuracy: 0.9831 - val_loss: 3.0660 - val_accuracy: 0.5000\n",
      "Epoch 142/1000\n",
      "177/177 [==============================] - 0s 78us/step - loss: 0.0544 - accuracy: 0.9831 - val_loss: 3.1239 - val_accuracy: 0.5263\n",
      "Epoch 143/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.0416 - accuracy: 0.9831 - val_loss: 3.3042 - val_accuracy: 0.5132\n",
      "Epoch 144/1000\n",
      "177/177 [==============================] - 0s 54us/step - loss: 0.1329 - accuracy: 0.9718 - val_loss: 3.1740 - val_accuracy: 0.5000\n",
      "Epoch 145/1000\n",
      "177/177 [==============================] - 0s 69us/step - loss: 0.1062 - accuracy: 0.9661 - val_loss: 3.0709 - val_accuracy: 0.5132\n",
      "Epoch 146/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.0456 - accuracy: 0.9831 - val_loss: 3.1118 - val_accuracy: 0.5263\n",
      "Epoch 147/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.0508 - accuracy: 0.9774 - val_loss: 3.0563 - val_accuracy: 0.5263\n",
      "Epoch 148/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.0453 - accuracy: 0.9831 - val_loss: 3.0495 - val_accuracy: 0.5263\n",
      "Epoch 149/1000\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.0456 - accuracy: 0.9831 - val_loss: 3.0908 - val_accuracy: 0.5263\n",
      "Epoch 150/1000\n",
      "177/177 [==============================] - 0s 84us/step - loss: 0.0453 - accuracy: 0.9831 - val_loss: 3.1282 - val_accuracy: 0.5263\n",
      "Epoch 151/1000\n",
      "177/177 [==============================] - 0s 96us/step - loss: 0.0442 - accuracy: 0.9831 - val_loss: 3.1802 - val_accuracy: 0.5263\n",
      "Epoch 152/1000\n",
      "177/177 [==============================] - 0s 101us/step - loss: 0.0438 - accuracy: 0.9831 - val_loss: 3.2071 - val_accuracy: 0.5263\n",
      "Epoch 153/1000\n",
      "177/177 [==============================] - 0s 323us/step - loss: 0.0452 - accuracy: 0.9831 - val_loss: 3.1776 - val_accuracy: 0.5263\n",
      "Epoch 154/1000\n",
      "177/177 [==============================] - 0s 76us/step - loss: 0.0441 - accuracy: 0.9831 - val_loss: 3.1485 - val_accuracy: 0.5263\n",
      "Epoch 155/1000\n",
      "177/177 [==============================] - 0s 68us/step - loss: 0.0434 - accuracy: 0.9831 - val_loss: 3.1289 - val_accuracy: 0.5263\n",
      "Epoch 156/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.0437 - accuracy: 0.9831 - val_loss: 3.1337 - val_accuracy: 0.5263\n",
      "Epoch 157/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.0431 - accuracy: 0.9831 - val_loss: 3.1518 - val_accuracy: 0.5263\n",
      "Epoch 158/1000\n",
      "177/177 [==============================] - 0s 201us/step - loss: 0.0436 - accuracy: 0.9831 - val_loss: 3.1686 - val_accuracy: 0.5263\n",
      "Epoch 159/1000\n",
      "177/177 [==============================] - 0s 58us/step - loss: 0.0435 - accuracy: 0.9831 - val_loss: 3.1659 - val_accuracy: 0.5132\n",
      "Epoch 160/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.0428 - accuracy: 0.9831 - val_loss: 3.1695 - val_accuracy: 0.5000\n",
      "Epoch 161/1000\n",
      "177/177 [==============================] - 0s 59us/step - loss: 0.0425 - accuracy: 0.9831 - val_loss: 3.1804 - val_accuracy: 0.5132\n",
      "Epoch 162/1000\n",
      "177/177 [==============================] - 0s 55us/step - loss: 0.0434 - accuracy: 0.9831 - val_loss: 3.1758 - val_accuracy: 0.5132\n",
      "Epoch 163/1000\n",
      "177/177 [==============================] - 0s 63us/step - loss: 0.0429 - accuracy: 0.9831 - val_loss: 3.1385 - val_accuracy: 0.5000\n",
      "Epoch 164/1000\n",
      "177/177 [==============================] - 0s 75us/step - loss: 0.0434 - accuracy: 0.9887 - val_loss: 3.1422 - val_accuracy: 0.5000\n",
      "Epoch 165/1000\n",
      "177/177 [==============================] - 0s 285us/step - loss: 0.0433 - accuracy: 0.9887 - val_loss: 3.1640 - val_accuracy: 0.5132\n",
      "Epoch 166/1000\n",
      "177/177 [==============================] - 0s 323us/step - loss: 0.0439 - accuracy: 0.9774 - val_loss: 3.1912 - val_accuracy: 0.5263\n",
      "Epoch 167/1000\n",
      "177/177 [==============================] - 0s 417us/step - loss: 0.0430 - accuracy: 0.9831 - val_loss: 3.1740 - val_accuracy: 0.5132\n",
      "Epoch 168/1000\n",
      "177/177 [==============================] - 0s 373us/step - loss: 0.0434 - accuracy: 0.9831 - val_loss: 3.1625 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/1000\n",
      "177/177 [==============================] - 0s 180us/step - loss: 0.0433 - accuracy: 0.9831 - val_loss: 3.1766 - val_accuracy: 0.5263\n",
      "Epoch 170/1000\n",
      "177/177 [==============================] - 0s 119us/step - loss: 0.0425 - accuracy: 0.9831 - val_loss: 3.1882 - val_accuracy: 0.5263\n",
      "Epoch 171/1000\n",
      "177/177 [==============================] - 0s 118us/step - loss: 0.0426 - accuracy: 0.9831 - val_loss: 3.1697 - val_accuracy: 0.5263\n",
      "Epoch 172/1000\n",
      "177/177 [==============================] - 0s 394us/step - loss: 0.0425 - accuracy: 0.9831 - val_loss: 3.1530 - val_accuracy: 0.5132\n",
      "Epoch 173/1000\n",
      "177/177 [==============================] - 0s 425us/step - loss: 0.0423 - accuracy: 0.9774 - val_loss: 3.1692 - val_accuracy: 0.5132\n",
      "Epoch 174/1000\n",
      "177/177 [==============================] - 0s 82us/step - loss: 0.0423 - accuracy: 0.9831 - val_loss: 3.1977 - val_accuracy: 0.5132\n",
      "Epoch 175/1000\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.0421 - accuracy: 0.9831 - val_loss: 3.2113 - val_accuracy: 0.5132\n",
      "Epoch 176/1000\n",
      "177/177 [==============================] - 0s 70us/step - loss: 0.0426 - accuracy: 0.9774 - val_loss: 3.2122 - val_accuracy: 0.5132\n",
      "Epoch 177/1000\n",
      "177/177 [==============================] - 0s 68us/step - loss: 0.0425 - accuracy: 0.9831 - val_loss: 3.2052 - val_accuracy: 0.5132\n",
      "Epoch 178/1000\n",
      "177/177 [==============================] - 0s 60us/step - loss: 0.0422 - accuracy: 0.9831 - val_loss: 3.1840 - val_accuracy: 0.5000\n",
      "Epoch 179/1000\n",
      "177/177 [==============================] - 0s 68us/step - loss: 0.0425 - accuracy: 0.9887 - val_loss: 3.1820 - val_accuracy: 0.5000\n",
      "Epoch 180/1000\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.0420 - accuracy: 0.9887 - val_loss: 3.1955 - val_accuracy: 0.5000\n",
      "Epoch 181/1000\n",
      "177/177 [==============================] - 0s 104us/step - loss: 0.0422 - accuracy: 0.9831 - val_loss: 3.2198 - val_accuracy: 0.5132\n",
      "Epoch 182/1000\n",
      "177/177 [==============================] - 0s 125us/step - loss: 0.0428 - accuracy: 0.9831 - val_loss: 3.2103 - val_accuracy: 0.5000\n",
      "Epoch 183/1000\n",
      "177/177 [==============================] - 0s 140us/step - loss: 0.0426 - accuracy: 0.9831 - val_loss: 3.2003 - val_accuracy: 0.5000\n",
      "Epoch 184/1000\n",
      "177/177 [==============================] - 0s 95us/step - loss: 0.0419 - accuracy: 0.9887 - val_loss: 3.2158 - val_accuracy: 0.5132\n",
      "Epoch 185/1000\n",
      "177/177 [==============================] - 0s 237us/step - loss: 0.0420 - accuracy: 0.9831 - val_loss: 3.2262 - val_accuracy: 0.5132\n",
      "Epoch 186/1000\n",
      "177/177 [==============================] - 0s 555us/step - loss: 0.0423 - accuracy: 0.9831 - val_loss: 3.2180 - val_accuracy: 0.5132\n",
      "Epoch 187/1000\n",
      "177/177 [==============================] - 0s 516us/step - loss: 0.0419 - accuracy: 0.9887 - val_loss: 3.2178 - val_accuracy: 0.5000\n",
      "Epoch 188/1000\n",
      "177/177 [==============================] - 0s 163us/step - loss: 0.0418 - accuracy: 0.9887 - val_loss: 3.2286 - val_accuracy: 0.5132\n",
      "Epoch 189/1000\n",
      "177/177 [==============================] - 0s 110us/step - loss: 0.0423 - accuracy: 0.9831 - val_loss: 3.2338 - val_accuracy: 0.5132\n",
      "Epoch 190/1000\n",
      "177/177 [==============================] - 0s 139us/step - loss: 0.0430 - accuracy: 0.9774 - val_loss: 3.2130 - val_accuracy: 0.5000\n",
      "Epoch 191/1000\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.0417 - accuracy: 0.9887 - val_loss: 3.2151 - val_accuracy: 0.5132\n",
      "Epoch 192/1000\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.0419 - accuracy: 0.9831 - val_loss: 3.2263 - val_accuracy: 0.5263\n",
      "Epoch 193/1000\n",
      "177/177 [==============================] - 0s 619us/step - loss: 0.0420 - accuracy: 0.9831 - val_loss: 3.2186 - val_accuracy: 0.5132\n",
      "Epoch 194/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.0424 - accuracy: 0.9887 - val_loss: 3.2175 - val_accuracy: 0.5263\n",
      "Epoch 195/1000\n",
      "177/177 [==============================] - 0s 85us/step - loss: 0.0425 - accuracy: 0.9831 - val_loss: 3.2278 - val_accuracy: 0.5263\n",
      "Epoch 196/1000\n",
      "177/177 [==============================] - 0s 85us/step - loss: 0.0414 - accuracy: 0.9774 - val_loss: 3.2064 - val_accuracy: 0.5132\n",
      "Epoch 197/1000\n",
      "177/177 [==============================] - 0s 94us/step - loss: 0.0419 - accuracy: 0.9831 - val_loss: 3.2151 - val_accuracy: 0.5132\n",
      "Epoch 198/1000\n",
      "177/177 [==============================] - 0s 84us/step - loss: 0.0418 - accuracy: 0.9774 - val_loss: 3.2300 - val_accuracy: 0.5132\n",
      "Epoch 199/1000\n",
      "177/177 [==============================] - 0s 91us/step - loss: 0.0413 - accuracy: 0.9831 - val_loss: 3.2486 - val_accuracy: 0.5132\n",
      "Epoch 200/1000\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.0411 - accuracy: 0.9831 - val_loss: 3.2490 - val_accuracy: 0.5132\n",
      "Epoch 201/1000\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.0418 - accuracy: 0.9887 - val_loss: 3.2524 - val_accuracy: 0.5000\n",
      "Epoch 202/1000\n",
      "177/177 [==============================] - 0s 115us/step - loss: 0.0420 - accuracy: 0.9887 - val_loss: 3.2541 - val_accuracy: 0.5132\n",
      "Epoch 203/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.0414 - accuracy: 0.9887 - val_loss: 3.2504 - val_accuracy: 0.5132\n",
      "Epoch 204/1000\n",
      "177/177 [==============================] - 0s 82us/step - loss: 0.0415 - accuracy: 0.9831 - val_loss: 3.2480 - val_accuracy: 0.5132\n",
      "Epoch 205/1000\n",
      "177/177 [==============================] - 0s 85us/step - loss: 0.0411 - accuracy: 0.9887 - val_loss: 3.2155 - val_accuracy: 0.5000\n",
      "Epoch 206/1000\n",
      "177/177 [==============================] - 0s 81us/step - loss: 0.0426 - accuracy: 0.9887 - val_loss: 3.2077 - val_accuracy: 0.5132\n",
      "Epoch 207/1000\n",
      "177/177 [==============================] - 0s 83us/step - loss: 0.0418 - accuracy: 0.9887 - val_loss: 3.2029 - val_accuracy: 0.5132\n",
      "Epoch 208/1000\n",
      "177/177 [==============================] - 0s 91us/step - loss: 0.0411 - accuracy: 0.9831 - val_loss: 3.2287 - val_accuracy: 0.5263\n",
      "Epoch 209/1000\n",
      "177/177 [==============================] - 0s 103us/step - loss: 0.0425 - accuracy: 0.9774 - val_loss: 3.2314 - val_accuracy: 0.5263\n",
      "Epoch 210/1000\n",
      "177/177 [==============================] - 0s 114us/step - loss: 0.0411 - accuracy: 0.9887 - val_loss: 3.2389 - val_accuracy: 0.5132\n",
      "Epoch 211/1000\n",
      "177/177 [==============================] - 0s 87us/step - loss: 0.0413 - accuracy: 0.9887 - val_loss: 3.2302 - val_accuracy: 0.5132\n",
      "Epoch 212/1000\n",
      "177/177 [==============================] - 0s 81us/step - loss: 0.0411 - accuracy: 0.9887 - val_loss: 3.2254 - val_accuracy: 0.5132\n",
      "Epoch 213/1000\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.0418 - accuracy: 0.9887 - val_loss: 3.2121 - val_accuracy: 0.5132\n",
      "Epoch 214/1000\n",
      "177/177 [==============================] - 0s 87us/step - loss: 0.0412 - accuracy: 0.9887 - val_loss: 3.2038 - val_accuracy: 0.5132\n",
      "Epoch 215/1000\n",
      "177/177 [==============================] - 0s 565us/step - loss: 0.0413 - accuracy: 0.9831 - val_loss: 3.2086 - val_accuracy: 0.5132\n",
      "Epoch 216/1000\n",
      "177/177 [==============================] - 0s 113us/step - loss: 0.0406 - accuracy: 0.9887 - val_loss: 3.2221 - val_accuracy: 0.5132\n",
      "Epoch 217/1000\n",
      "177/177 [==============================] - 0s 154us/step - loss: 0.0410 - accuracy: 0.9831 - val_loss: 3.2467 - val_accuracy: 0.5132\n",
      "Epoch 218/1000\n",
      "177/177 [==============================] - 0s 93us/step - loss: 0.0427 - accuracy: 0.9887 - val_loss: 3.2612 - val_accuracy: 0.5000\n",
      "Epoch 219/1000\n",
      "177/177 [==============================] - 0s 76us/step - loss: 0.0412 - accuracy: 0.9887 - val_loss: 3.2653 - val_accuracy: 0.5132\n",
      "Epoch 220/1000\n",
      "177/177 [==============================] - 0s 115us/step - loss: 0.0409 - accuracy: 0.9887 - val_loss: 3.2637 - val_accuracy: 0.5132\n",
      "Epoch 221/1000\n",
      "177/177 [==============================] - 0s 229us/step - loss: 0.0410 - accuracy: 0.9887 - val_loss: 3.2565 - val_accuracy: 0.5132\n",
      "Epoch 222/1000\n",
      "177/177 [==============================] - 0s 931us/step - loss: 0.0407 - accuracy: 0.9887 - val_loss: 3.2564 - val_accuracy: 0.5263\n",
      "Epoch 223/1000\n",
      "177/177 [==============================] - 0s 155us/step - loss: 0.0408 - accuracy: 0.9887 - val_loss: 3.2414 - val_accuracy: 0.5132\n",
      "Epoch 224/1000\n",
      "177/177 [==============================] - 0s 134us/step - loss: 0.0407 - accuracy: 0.9831 - val_loss: 3.2403 - val_accuracy: 0.5132\n",
      "Epoch 225/1000\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.0404 - accuracy: 0.9887 - val_loss: 3.2525 - val_accuracy: 0.5132\n",
      "Epoch 226/1000\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.0411 - accuracy: 0.9887 - val_loss: 3.2474 - val_accuracy: 0.5000\n",
      "Epoch 227/1000\n",
      "177/177 [==============================] - 0s 106us/step - loss: 0.0406 - accuracy: 0.9887 - val_loss: 3.2741 - val_accuracy: 0.5132\n",
      "Epoch 228/1000\n",
      "177/177 [==============================] - 0s 126us/step - loss: 0.0407 - accuracy: 0.9887 - val_loss: 3.2691 - val_accuracy: 0.5132\n",
      "Epoch 229/1000\n",
      "177/177 [==============================] - 0s 222us/step - loss: 0.0404 - accuracy: 0.9887 - val_loss: 3.2590 - val_accuracy: 0.5000\n",
      "Epoch 230/1000\n",
      "177/177 [==============================] - 0s 144us/step - loss: 0.0403 - accuracy: 0.9887 - val_loss: 3.2547 - val_accuracy: 0.5000\n",
      "Epoch 231/1000\n",
      "177/177 [==============================] - 0s 107us/step - loss: 0.0413 - accuracy: 0.9887 - val_loss: 3.2534 - val_accuracy: 0.5000\n",
      "Epoch 232/1000\n",
      "177/177 [==============================] - 0s 189us/step - loss: 0.0401 - accuracy: 0.9887 - val_loss: 3.2441 - val_accuracy: 0.5000\n",
      "Epoch 233/1000\n",
      "177/177 [==============================] - 0s 81us/step - loss: 0.0411 - accuracy: 0.9887 - val_loss: 3.2559 - val_accuracy: 0.5000\n",
      "Epoch 234/1000\n",
      "177/177 [==============================] - 0s 87us/step - loss: 0.0410 - accuracy: 0.9887 - val_loss: 3.2787 - val_accuracy: 0.5000\n",
      "Epoch 235/1000\n",
      "177/177 [==============================] - 0s 92us/step - loss: 0.0408 - accuracy: 0.9887 - val_loss: 3.2911 - val_accuracy: 0.5132\n",
      "Epoch 236/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.0406 - accuracy: 0.9887 - val_loss: 3.2876 - val_accuracy: 0.5000\n",
      "Epoch 237/1000\n",
      "177/177 [==============================] - 0s 59us/step - loss: 0.0404 - accuracy: 0.9887 - val_loss: 3.2706 - val_accuracy: 0.5000\n",
      "Epoch 238/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.0412 - accuracy: 0.9887 - val_loss: 3.2721 - val_accuracy: 0.5000\n",
      "Epoch 239/1000\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.0401 - accuracy: 0.9887 - val_loss: 3.2814 - val_accuracy: 0.5132\n",
      "Epoch 240/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.0404 - accuracy: 0.9887 - val_loss: 3.2905 - val_accuracy: 0.5132\n",
      "Epoch 241/1000\n",
      "177/177 [==============================] - 0s 60us/step - loss: 0.0401 - accuracy: 0.9887 - val_loss: 3.2751 - val_accuracy: 0.5000\n",
      "Epoch 242/1000\n",
      "177/177 [==============================] - 0s 63us/step - loss: 0.0400 - accuracy: 0.9887 - val_loss: 3.2735 - val_accuracy: 0.5132\n",
      "Epoch 243/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.0405 - accuracy: 0.9887 - val_loss: 3.2762 - val_accuracy: 0.5000\n",
      "Epoch 244/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.0418 - accuracy: 0.9887 - val_loss: 3.2815 - val_accuracy: 0.5132\n",
      "Epoch 245/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.0400 - accuracy: 0.9887 - val_loss: 3.2653 - val_accuracy: 0.5000\n",
      "Epoch 246/1000\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.0402 - accuracy: 0.9887 - val_loss: 3.2653 - val_accuracy: 0.5000\n",
      "Epoch 247/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.0404 - accuracy: 0.9887 - val_loss: 3.2805 - val_accuracy: 0.5000\n",
      "Epoch 248/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.0415 - accuracy: 0.9887 - val_loss: 3.3022 - val_accuracy: 0.5132\n",
      "Epoch 249/1000\n",
      "177/177 [==============================] - 0s 76us/step - loss: 0.0426 - accuracy: 0.9887 - val_loss: 3.2727 - val_accuracy: 0.5000\n",
      "Epoch 250/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.0413 - accuracy: 0.9887 - val_loss: 3.2522 - val_accuracy: 0.5000\n",
      "Epoch 251/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.0484 - accuracy: 0.9831 - val_loss: 3.3157 - val_accuracy: 0.5132\n",
      "Epoch 252/1000\n",
      "177/177 [==============================] - 0s 70us/step - loss: 0.0534 - accuracy: 0.9774 - val_loss: 3.2015 - val_accuracy: 0.5000\n",
      "Epoch 253/1000\n",
      "177/177 [==============================] - 0s 99us/step - loss: 0.0449 - accuracy: 0.9887 - val_loss: 3.2022 - val_accuracy: 0.5000\n",
      "Epoch 254/1000\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.0425 - accuracy: 0.9887 - val_loss: 3.2842 - val_accuracy: 0.5263\n",
      "Epoch 255/1000\n",
      "177/177 [==============================] - 0s 110us/step - loss: 0.0398 - accuracy: 0.9831 - val_loss: 3.3245 - val_accuracy: 0.5132\n",
      "Epoch 256/1000\n",
      "177/177 [==============================] - 0s 97us/step - loss: 0.0446 - accuracy: 0.9774 - val_loss: 3.2673 - val_accuracy: 0.5000\n",
      "Epoch 257/1000\n",
      "177/177 [==============================] - 0s 78us/step - loss: 0.0546 - accuracy: 0.9831 - val_loss: 3.3058 - val_accuracy: 0.5263\n",
      "Epoch 258/1000\n",
      "177/177 [==============================] - 0s 79us/step - loss: 0.0731 - accuracy: 0.9718 - val_loss: 3.2456 - val_accuracy: 0.5132\n",
      "Epoch 259/1000\n",
      "177/177 [==============================] - 0s 84us/step - loss: 0.0707 - accuracy: 0.9831 - val_loss: 3.2082 - val_accuracy: 0.5263\n",
      "Epoch 260/1000\n",
      "177/177 [==============================] - 0s 175us/step - loss: 0.0478 - accuracy: 0.9774 - val_loss: 3.2206 - val_accuracy: 0.5263\n",
      "Epoch 261/1000\n",
      "177/177 [==============================] - 0s 175us/step - loss: 0.0411 - accuracy: 0.9831 - val_loss: 3.1947 - val_accuracy: 0.5132\n",
      "Epoch 262/1000\n",
      "177/177 [==============================] - 0s 99us/step - loss: 0.0638 - accuracy: 0.9831 - val_loss: 3.2889 - val_accuracy: 0.5263\n",
      "Epoch 263/1000\n",
      "177/177 [==============================] - 0s 107us/step - loss: 0.0848 - accuracy: 0.9718 - val_loss: 3.2285 - val_accuracy: 0.5132\n",
      "Epoch 264/1000\n",
      "177/177 [==============================] - 0s 74us/step - loss: 0.1175 - accuracy: 0.9661 - val_loss: 3.1829 - val_accuracy: 0.5263\n",
      "Epoch 265/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.0433 - accuracy: 0.9831 - val_loss: 3.2525 - val_accuracy: 0.5263\n",
      "Epoch 266/1000\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.0859 - accuracy: 0.9718 - val_loss: 3.1489 - val_accuracy: 0.5395\n",
      "Epoch 267/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.1454 - accuracy: 0.9718 - val_loss: 3.3663 - val_accuracy: 0.4868\n",
      "Epoch 268/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.1823 - accuracy: 0.9661 - val_loss: 3.1953 - val_accuracy: 0.5263\n",
      "Epoch 269/1000\n",
      "177/177 [==============================] - 0s 60us/step - loss: 0.0749 - accuracy: 0.9718 - val_loss: 3.2016 - val_accuracy: 0.5263\n",
      "Epoch 270/1000\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.0463 - accuracy: 0.9831 - val_loss: 3.2202 - val_accuracy: 0.5263\n",
      "Epoch 271/1000\n",
      "177/177 [==============================] - 0s 174us/step - loss: 0.0623 - accuracy: 0.9774 - val_loss: 3.3098 - val_accuracy: 0.5263\n",
      "Epoch 272/1000\n",
      "177/177 [==============================] - 0s 124us/step - loss: 0.0549 - accuracy: 0.9774 - val_loss: 3.2985 - val_accuracy: 0.5263\n",
      "Epoch 273/1000\n",
      "177/177 [==============================] - 0s 137us/step - loss: 0.0443 - accuracy: 0.9831 - val_loss: 3.2397 - val_accuracy: 0.5263\n",
      "Epoch 274/1000\n",
      "177/177 [==============================] - 0s 375us/step - loss: 0.0530 - accuracy: 0.9774 - val_loss: 3.2937 - val_accuracy: 0.5263\n",
      "Epoch 275/1000\n",
      "177/177 [==============================] - 0s 410us/step - loss: 0.0580 - accuracy: 0.9774 - val_loss: 3.3097 - val_accuracy: 0.5263\n",
      "Epoch 276/1000\n",
      "177/177 [==============================] - 0s 344us/step - loss: 0.0436 - accuracy: 0.9831 - val_loss: 3.2877 - val_accuracy: 0.5263\n",
      "Epoch 277/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.0739 - accuracy: 0.9774 - val_loss: 3.3337 - val_accuracy: 0.5263\n",
      "Epoch 278/1000\n",
      "177/177 [==============================] - 0s 78us/step - loss: 0.0603 - accuracy: 0.9718 - val_loss: 3.3180 - val_accuracy: 0.5263\n",
      "Epoch 279/1000\n",
      "177/177 [==============================] - 0s 79us/step - loss: 0.0431 - accuracy: 0.9831 - val_loss: 3.2979 - val_accuracy: 0.5132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 280/1000\n",
      "177/177 [==============================] - 0s 69us/step - loss: 0.1051 - accuracy: 0.9605 - val_loss: 3.2020 - val_accuracy: 0.5263\n",
      "Epoch 281/1000\n",
      "177/177 [==============================] - 0s 144us/step - loss: 0.0425 - accuracy: 0.9831 - val_loss: 3.4626 - val_accuracy: 0.5132\n",
      "Epoch 282/1000\n",
      "177/177 [==============================] - 0s 93us/step - loss: 0.1638 - accuracy: 0.9718 - val_loss: 3.2858 - val_accuracy: 0.5132\n",
      "Epoch 283/1000\n",
      "177/177 [==============================] - 0s 74us/step - loss: 0.0857 - accuracy: 0.9661 - val_loss: 3.2233 - val_accuracy: 0.5263\n",
      "Epoch 284/1000\n",
      "177/177 [==============================] - 0s 75us/step - loss: 0.0626 - accuracy: 0.9718 - val_loss: 3.5001 - val_accuracy: 0.5132\n",
      "Epoch 285/1000\n",
      "177/177 [==============================] - 0s 60us/step - loss: 0.2644 - accuracy: 0.9718 - val_loss: 3.3905 - val_accuracy: 0.5132\n",
      "Epoch 286/1000\n",
      "177/177 [==============================] - 0s 81us/step - loss: 0.0398 - accuracy: 0.9831 - val_loss: 3.2066 - val_accuracy: 0.5263\n",
      "Epoch 287/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.0858 - accuracy: 0.9718 - val_loss: 3.2251 - val_accuracy: 0.5263\n",
      "Epoch 288/1000\n",
      "177/177 [==============================] - 0s 112us/step - loss: 0.0397 - accuracy: 0.9831 - val_loss: 3.3841 - val_accuracy: 0.5132\n",
      "Epoch 289/1000\n",
      "177/177 [==============================] - 0s 79us/step - loss: 0.0834 - accuracy: 0.9718 - val_loss: 3.2592 - val_accuracy: 0.5132\n",
      "Epoch 290/1000\n",
      "177/177 [==============================] - 0s 100us/step - loss: 0.0899 - accuracy: 0.9718 - val_loss: 3.2473 - val_accuracy: 0.5263\n",
      "Epoch 291/1000\n",
      "177/177 [==============================] - 0s 104us/step - loss: 0.0402 - accuracy: 0.9831 - val_loss: 3.3381 - val_accuracy: 0.5263\n",
      "Epoch 292/1000\n",
      "177/177 [==============================] - 0s 63us/step - loss: 0.0465 - accuracy: 0.9774 - val_loss: 3.2998 - val_accuracy: 0.5263\n",
      "Epoch 293/1000\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.0402 - accuracy: 0.9831 - val_loss: 3.2889 - val_accuracy: 0.5263\n",
      "Epoch 294/1000\n",
      "177/177 [==============================] - 0s 143us/step - loss: 0.0408 - accuracy: 0.9831 - val_loss: 3.2791 - val_accuracy: 0.5263\n",
      "Epoch 295/1000\n",
      "177/177 [==============================] - 0s 82us/step - loss: 0.0408 - accuracy: 0.9831 - val_loss: 3.2853 - val_accuracy: 0.5263\n",
      "Epoch 296/1000\n",
      "177/177 [==============================] - 0s 68us/step - loss: 0.0407 - accuracy: 0.9831 - val_loss: 3.3109 - val_accuracy: 0.5263\n",
      "Epoch 297/1000\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.0399 - accuracy: 0.9774 - val_loss: 3.3299 - val_accuracy: 0.5263\n",
      "Epoch 298/1000\n",
      "177/177 [==============================] - 0s 92us/step - loss: 0.0400 - accuracy: 0.9831 - val_loss: 3.3466 - val_accuracy: 0.5263\n",
      "Epoch 299/1000\n",
      "177/177 [==============================] - 0s 68us/step - loss: 0.0398 - accuracy: 0.9831 - val_loss: 3.3331 - val_accuracy: 0.5263\n",
      "Epoch 300/1000\n",
      "177/177 [==============================] - 0s 79us/step - loss: 0.0397 - accuracy: 0.9774 - val_loss: 3.3273 - val_accuracy: 0.5263\n",
      "Epoch 301/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.0392 - accuracy: 0.9774 - val_loss: 3.3243 - val_accuracy: 0.5132\n",
      "Epoch 302/1000\n",
      "177/177 [==============================] - 0s 69us/step - loss: 0.0388 - accuracy: 0.9774 - val_loss: 3.3381 - val_accuracy: 0.5132\n",
      "Epoch 303/1000\n",
      "177/177 [==============================] - 0s 55us/step - loss: 0.0391 - accuracy: 0.9831 - val_loss: 3.3595 - val_accuracy: 0.5132\n",
      "Epoch 304/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.0388 - accuracy: 0.9831 - val_loss: 3.3691 - val_accuracy: 0.5132\n",
      "Epoch 305/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.0389 - accuracy: 0.9831 - val_loss: 3.3540 - val_accuracy: 0.5000\n",
      "Epoch 306/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.0389 - accuracy: 0.9831 - val_loss: 3.3452 - val_accuracy: 0.5000\n",
      "Epoch 307/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.0383 - accuracy: 0.9887 - val_loss: 3.3474 - val_accuracy: 0.5000\n",
      "Epoch 308/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.0388 - accuracy: 0.9887 - val_loss: 3.3571 - val_accuracy: 0.5132\n",
      "Epoch 309/1000\n",
      "177/177 [==============================] - 0s 70us/step - loss: 0.0383 - accuracy: 0.9887 - val_loss: 3.3489 - val_accuracy: 0.5000\n",
      "Epoch 310/1000\n",
      "177/177 [==============================] - 0s 75us/step - loss: 0.0383 - accuracy: 0.9887 - val_loss: 3.3482 - val_accuracy: 0.5000\n",
      "Epoch 311/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.0389 - accuracy: 0.9887 - val_loss: 3.3772 - val_accuracy: 0.5000\n",
      "Epoch 312/1000\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.0382 - accuracy: 0.9887 - val_loss: 3.3830 - val_accuracy: 0.5000\n",
      "Epoch 313/1000\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.0380 - accuracy: 0.9887 - val_loss: 3.3942 - val_accuracy: 0.5000\n",
      "Epoch 314/1000\n",
      "177/177 [==============================] - 0s 63us/step - loss: 0.0387 - accuracy: 0.9887 - val_loss: 3.3969 - val_accuracy: 0.5000\n",
      "Epoch 315/1000\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.0382 - accuracy: 0.9887 - val_loss: 3.3703 - val_accuracy: 0.5000\n",
      "Epoch 316/1000\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.0384 - accuracy: 0.9887 - val_loss: 3.3625 - val_accuracy: 0.5000\n",
      "Epoch 317/1000\n",
      "177/177 [==============================] - 0s 59us/step - loss: 0.0384 - accuracy: 0.9831 - val_loss: 3.3897 - val_accuracy: 0.5000\n",
      "Epoch 318/1000\n",
      "177/177 [==============================] - 0s 397us/step - loss: 0.0385 - accuracy: 0.9887 - val_loss: 3.4013 - val_accuracy: 0.5000\n",
      "Epoch 319/1000\n",
      "177/177 [==============================] - 0s 124us/step - loss: 0.0378 - accuracy: 0.9887 - val_loss: 3.4064 - val_accuracy: 0.5000\n",
      "Epoch 320/1000\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.0377 - accuracy: 0.9887 - val_loss: 3.4003 - val_accuracy: 0.5000\n",
      "Epoch 321/1000\n",
      "177/177 [==============================] - 0s 76us/step - loss: 0.0380 - accuracy: 0.9887 - val_loss: 3.4015 - val_accuracy: 0.5000\n",
      "Epoch 322/1000\n",
      "177/177 [==============================] - 0s 74us/step - loss: 0.0382 - accuracy: 0.9831 - val_loss: 3.4073 - val_accuracy: 0.5000\n",
      "Epoch 323/1000\n",
      "177/177 [==============================] - 0s 75us/step - loss: 0.0376 - accuracy: 0.9831 - val_loss: 3.4131 - val_accuracy: 0.5000\n",
      "Epoch 324/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.0378 - accuracy: 0.9887 - val_loss: 3.3992 - val_accuracy: 0.5000\n",
      "Epoch 325/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.0381 - accuracy: 0.9887 - val_loss: 3.3859 - val_accuracy: 0.5000\n",
      "Epoch 326/1000\n",
      "177/177 [==============================] - 0s 78us/step - loss: 0.0383 - accuracy: 0.9887 - val_loss: 3.3910 - val_accuracy: 0.5000\n",
      "Epoch 327/1000\n",
      "177/177 [==============================] - 0s 75us/step - loss: 0.0384 - accuracy: 0.9887 - val_loss: 3.4217 - val_accuracy: 0.5000\n",
      "Epoch 328/1000\n",
      "177/177 [==============================] - 0s 82us/step - loss: 0.0378 - accuracy: 0.9887 - val_loss: 3.4387 - val_accuracy: 0.5000\n",
      "Epoch 329/1000\n",
      "177/177 [==============================] - 0s 86us/step - loss: 0.0377 - accuracy: 0.9887 - val_loss: 3.4244 - val_accuracy: 0.5000\n",
      "Epoch 330/1000\n",
      "177/177 [==============================] - 0s 230us/step - loss: 0.0383 - accuracy: 0.9887 - val_loss: 3.4108 - val_accuracy: 0.5000\n",
      "Epoch 331/1000\n",
      "177/177 [==============================] - 0s 183us/step - loss: 0.0383 - accuracy: 0.9887 - val_loss: 3.4001 - val_accuracy: 0.5000\n",
      "Epoch 332/1000\n",
      "177/177 [==============================] - 0s 103us/step - loss: 0.0373 - accuracy: 0.9887 - val_loss: 3.4123 - val_accuracy: 0.5000\n",
      "Epoch 333/1000\n",
      "177/177 [==============================] - 0s 141us/step - loss: 0.0377 - accuracy: 0.9887 - val_loss: 3.4122 - val_accuracy: 0.5000\n",
      "Epoch 334/1000\n",
      "177/177 [==============================] - 0s 134us/step - loss: 0.0385 - accuracy: 0.9831 - val_loss: 3.3929 - val_accuracy: 0.5000\n",
      "Epoch 335/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.0377 - accuracy: 0.9887 - val_loss: 3.3990 - val_accuracy: 0.5000\n",
      "Epoch 336/1000\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.0372 - accuracy: 0.9887 - val_loss: 3.4266 - val_accuracy: 0.5000\n",
      "Epoch 337/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.0375 - accuracy: 0.9887 - val_loss: 3.4523 - val_accuracy: 0.5000\n",
      "Epoch 338/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.0371 - accuracy: 0.9887 - val_loss: 3.4530 - val_accuracy: 0.5000\n",
      "Epoch 339/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.0378 - accuracy: 0.9887 - val_loss: 3.4392 - val_accuracy: 0.5000\n",
      "Epoch 340/1000\n",
      "177/177 [==============================] - 0s 124us/step - loss: 0.0385 - accuracy: 0.9887 - val_loss: 3.4420 - val_accuracy: 0.5000\n",
      "Epoch 341/1000\n",
      "177/177 [==============================] - 0s 97us/step - loss: 0.0375 - accuracy: 0.9887 - val_loss: 3.4307 - val_accuracy: 0.5000\n",
      "Epoch 342/1000\n",
      "177/177 [==============================] - 0s 69us/step - loss: 0.0377 - accuracy: 0.9887 - val_loss: 3.4294 - val_accuracy: 0.5000\n",
      "Epoch 343/1000\n",
      "177/177 [==============================] - 0s 96us/step - loss: 0.0375 - accuracy: 0.9887 - val_loss: 3.4328 - val_accuracy: 0.5000\n",
      "Epoch 344/1000\n",
      "177/177 [==============================] - 0s 117us/step - loss: 0.0376 - accuracy: 0.9887 - val_loss: 3.4451 - val_accuracy: 0.5000\n",
      "Epoch 345/1000\n",
      "177/177 [==============================] - 0s 100us/step - loss: 0.0375 - accuracy: 0.9887 - val_loss: 3.4700 - val_accuracy: 0.5000\n",
      "Epoch 346/1000\n",
      "177/177 [==============================] - 0s 126us/step - loss: 0.0371 - accuracy: 0.9887 - val_loss: 3.4613 - val_accuracy: 0.5000\n",
      "Epoch 347/1000\n",
      "177/177 [==============================] - 0s 91us/step - loss: 0.0369 - accuracy: 0.9887 - val_loss: 3.4446 - val_accuracy: 0.5000\n",
      "Epoch 348/1000\n",
      "177/177 [==============================] - 0s 134us/step - loss: 0.0373 - accuracy: 0.9887 - val_loss: 3.4394 - val_accuracy: 0.5000\n",
      "Epoch 349/1000\n",
      "177/177 [==============================] - 0s 79us/step - loss: 0.0386 - accuracy: 0.9887 - val_loss: 3.4306 - val_accuracy: 0.5000\n",
      "Epoch 350/1000\n",
      "177/177 [==============================] - 0s 108us/step - loss: 0.0371 - accuracy: 0.9887 - val_loss: 3.4055 - val_accuracy: 0.5000\n",
      "Epoch 351/1000\n",
      "177/177 [==============================] - 0s 91us/step - loss: 0.0379 - accuracy: 0.9887 - val_loss: 3.4048 - val_accuracy: 0.5132\n",
      "Epoch 352/1000\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.0377 - accuracy: 0.9887 - val_loss: 3.4211 - val_accuracy: 0.5132\n",
      "Epoch 353/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.0390 - accuracy: 0.9887 - val_loss: 3.4353 - val_accuracy: 0.5000\n",
      "Epoch 354/1000\n",
      "177/177 [==============================] - 0s 78us/step - loss: 0.0381 - accuracy: 0.9887 - val_loss: 3.4081 - val_accuracy: 0.5000\n",
      "Epoch 355/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.0376 - accuracy: 0.9887 - val_loss: 3.4093 - val_accuracy: 0.5000\n",
      "Epoch 356/1000\n",
      "177/177 [==============================] - 0s 74us/step - loss: 0.0380 - accuracy: 0.9887 - val_loss: 3.4202 - val_accuracy: 0.5132\n",
      "Epoch 357/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.0374 - accuracy: 0.9831 - val_loss: 3.4353 - val_accuracy: 0.5132\n",
      "Epoch 358/1000\n",
      "177/177 [==============================] - 0s 69us/step - loss: 0.0370 - accuracy: 0.9831 - val_loss: 3.4267 - val_accuracy: 0.5132\n",
      "Epoch 359/1000\n",
      "177/177 [==============================] - 0s 75us/step - loss: 0.0370 - accuracy: 0.9887 - val_loss: 3.4327 - val_accuracy: 0.5132\n",
      "Epoch 360/1000\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.0368 - accuracy: 0.9887 - val_loss: 3.4521 - val_accuracy: 0.5132\n",
      "Epoch 361/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.0370 - accuracy: 0.9887 - val_loss: 3.4567 - val_accuracy: 0.5132\n",
      "Epoch 362/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.0370 - accuracy: 0.9831 - val_loss: 3.4460 - val_accuracy: 0.5000\n",
      "Epoch 363/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.0371 - accuracy: 0.9887 - val_loss: 3.4325 - val_accuracy: 0.5000\n",
      "Epoch 364/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.0367 - accuracy: 0.9887 - val_loss: 3.4399 - val_accuracy: 0.5000\n",
      "Epoch 365/1000\n",
      "177/177 [==============================] - 0s 81us/step - loss: 0.0376 - accuracy: 0.9887 - val_loss: 3.4727 - val_accuracy: 0.5000\n",
      "Epoch 366/1000\n",
      "177/177 [==============================] - 0s 114us/step - loss: 0.0367 - accuracy: 0.9887 - val_loss: 3.4642 - val_accuracy: 0.5132\n",
      "Epoch 367/1000\n",
      "177/177 [==============================] - 0s 143us/step - loss: 0.0371 - accuracy: 0.9831 - val_loss: 3.4522 - val_accuracy: 0.5132\n",
      "Epoch 368/1000\n",
      "177/177 [==============================] - 0s 100us/step - loss: 0.0364 - accuracy: 0.9887 - val_loss: 3.4469 - val_accuracy: 0.5132\n",
      "Epoch 369/1000\n",
      "177/177 [==============================] - 0s 96us/step - loss: 0.0369 - accuracy: 0.9887 - val_loss: 3.4532 - val_accuracy: 0.5132\n",
      "Epoch 370/1000\n",
      "177/177 [==============================] - 0s 107us/step - loss: 0.0367 - accuracy: 0.9887 - val_loss: 3.4537 - val_accuracy: 0.5000\n",
      "Epoch 371/1000\n",
      "177/177 [==============================] - 0s 120us/step - loss: 0.0363 - accuracy: 0.9887 - val_loss: 3.4437 - val_accuracy: 0.5132\n",
      "Epoch 372/1000\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.0363 - accuracy: 0.9887 - val_loss: 3.4332 - val_accuracy: 0.5132\n",
      "Epoch 373/1000\n",
      "177/177 [==============================] - 0s 92us/step - loss: 0.0365 - accuracy: 0.9887 - val_loss: 3.4440 - val_accuracy: 0.5132\n",
      "Epoch 374/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.0365 - accuracy: 0.9887 - val_loss: 3.4656 - val_accuracy: 0.5132\n",
      "Epoch 375/1000\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.0376 - accuracy: 0.9887 - val_loss: 3.4693 - val_accuracy: 0.5132\n",
      "Epoch 376/1000\n",
      "177/177 [==============================] - 0s 83us/step - loss: 0.0365 - accuracy: 0.9887 - val_loss: 3.4452 - val_accuracy: 0.5000\n",
      "Epoch 377/1000\n",
      "177/177 [==============================] - 0s 341us/step - loss: 0.0373 - accuracy: 0.9831 - val_loss: 3.4440 - val_accuracy: 0.5000\n",
      "Epoch 378/1000\n",
      "177/177 [==============================] - 0s 117us/step - loss: 0.0364 - accuracy: 0.9887 - val_loss: 3.4683 - val_accuracy: 0.5000\n",
      "Epoch 379/1000\n",
      "177/177 [==============================] - 0s 78us/step - loss: 0.0364 - accuracy: 0.9887 - val_loss: 3.4987 - val_accuracy: 0.5000\n",
      "Epoch 380/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.0366 - accuracy: 0.9887 - val_loss: 3.4878 - val_accuracy: 0.5000\n",
      "Epoch 381/1000\n",
      "177/177 [==============================] - 0s 58us/step - loss: 0.0362 - accuracy: 0.9887 - val_loss: 3.4780 - val_accuracy: 0.5000\n",
      "Epoch 382/1000\n",
      "177/177 [==============================] - 0s 63us/step - loss: 0.0366 - accuracy: 0.9831 - val_loss: 3.4707 - val_accuracy: 0.5000\n",
      "Epoch 383/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.0362 - accuracy: 0.9887 - val_loss: 3.4805 - val_accuracy: 0.5132\n",
      "Epoch 384/1000\n",
      "177/177 [==============================] - 0s 68us/step - loss: 0.0371 - accuracy: 0.9831 - val_loss: 3.4729 - val_accuracy: 0.5132\n",
      "Epoch 385/1000\n",
      "177/177 [==============================] - 0s 85us/step - loss: 0.0363 - accuracy: 0.9887 - val_loss: 3.4588 - val_accuracy: 0.5132\n",
      "Epoch 386/1000\n",
      "177/177 [==============================] - 0s 79us/step - loss: 0.0366 - accuracy: 0.9887 - val_loss: 3.4433 - val_accuracy: 0.5132\n",
      "Epoch 387/1000\n",
      "177/177 [==============================] - 0s 82us/step - loss: 0.0373 - accuracy: 0.9887 - val_loss: 3.4510 - val_accuracy: 0.5132\n",
      "Epoch 388/1000\n",
      "177/177 [==============================] - 0s 75us/step - loss: 0.0361 - accuracy: 0.9887 - val_loss: 3.4793 - val_accuracy: 0.5132\n",
      "Epoch 389/1000\n",
      "177/177 [==============================] - 0s 459us/step - loss: 0.0370 - accuracy: 0.9831 - val_loss: 3.4723 - val_accuracy: 0.5132\n",
      "Epoch 390/1000\n",
      "177/177 [==============================] - 0s 223us/step - loss: 0.0363 - accuracy: 0.9887 - val_loss: 3.4706 - val_accuracy: 0.5132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 391/1000\n",
      "177/177 [==============================] - 0s 367us/step - loss: 0.0358 - accuracy: 0.9887 - val_loss: 3.4789 - val_accuracy: 0.5132\n",
      "Epoch 392/1000\n",
      "177/177 [==============================] - 0s 70us/step - loss: 0.0360 - accuracy: 0.9887 - val_loss: 3.4826 - val_accuracy: 0.5132\n",
      "Epoch 393/1000\n",
      "177/177 [==============================] - 0s 63us/step - loss: 0.0362 - accuracy: 0.9887 - val_loss: 3.4840 - val_accuracy: 0.5132\n",
      "Epoch 394/1000\n",
      "177/177 [==============================] - 0s 69us/step - loss: 0.0366 - accuracy: 0.9831 - val_loss: 3.4859 - val_accuracy: 0.5000\n",
      "Epoch 395/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.0361 - accuracy: 0.9831 - val_loss: 3.4857 - val_accuracy: 0.5000\n",
      "Epoch 396/1000\n",
      "177/177 [==============================] - 0s 84us/step - loss: 0.0362 - accuracy: 0.9887 - val_loss: 3.4884 - val_accuracy: 0.5000\n",
      "Epoch 397/1000\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.0358 - accuracy: 0.9887 - val_loss: 3.5100 - val_accuracy: 0.5000\n",
      "Epoch 398/1000\n",
      "177/177 [==============================] - 0s 92us/step - loss: 0.0359 - accuracy: 0.9887 - val_loss: 3.5093 - val_accuracy: 0.5000\n",
      "Epoch 399/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.0357 - accuracy: 0.9887 - val_loss: 3.5060 - val_accuracy: 0.5000\n",
      "Epoch 400/1000\n",
      "177/177 [==============================] - 0s 77us/step - loss: 0.0356 - accuracy: 0.9887 - val_loss: 3.5059 - val_accuracy: 0.5000\n",
      "Epoch 401/1000\n",
      "177/177 [==============================] - 0s 78us/step - loss: 0.0358 - accuracy: 0.9887 - val_loss: 3.5073 - val_accuracy: 0.5000\n",
      "Epoch 402/1000\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.0355 - accuracy: 0.9887 - val_loss: 3.5042 - val_accuracy: 0.5000\n",
      "Epoch 403/1000\n",
      "177/177 [==============================] - 0s 54us/step - loss: 0.0363 - accuracy: 0.9887 - val_loss: 3.5281 - val_accuracy: 0.5000\n",
      "Epoch 404/1000\n",
      "177/177 [==============================] - 0s 235us/step - loss: 0.0357 - accuracy: 0.9887 - val_loss: 3.5198 - val_accuracy: 0.5000\n",
      "Epoch 405/1000\n",
      "177/177 [==============================] - 0s 241us/step - loss: 0.0356 - accuracy: 0.9887 - val_loss: 3.4971 - val_accuracy: 0.5000\n",
      "Epoch 406/1000\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.0364 - accuracy: 0.9831 - val_loss: 3.5018 - val_accuracy: 0.5000\n",
      "Epoch 407/1000\n",
      "177/177 [==============================] - 0s 83us/step - loss: 0.0353 - accuracy: 0.9887 - val_loss: 3.5183 - val_accuracy: 0.5000\n",
      "Epoch 408/1000\n",
      "177/177 [==============================] - 0s 216us/step - loss: 0.0360 - accuracy: 0.9831 - val_loss: 3.5278 - val_accuracy: 0.5000\n",
      "Epoch 409/1000\n",
      "177/177 [==============================] - 0s 145us/step - loss: 0.0355 - accuracy: 0.9887 - val_loss: 3.5168 - val_accuracy: 0.5000\n",
      "Epoch 410/1000\n",
      "177/177 [==============================] - 0s 63us/step - loss: 0.0360 - accuracy: 0.9887 - val_loss: 3.5016 - val_accuracy: 0.5000\n",
      "Epoch 411/1000\n",
      "177/177 [==============================] - 0s 114us/step - loss: 0.0356 - accuracy: 0.9887 - val_loss: 3.5282 - val_accuracy: 0.5000\n",
      "Epoch 412/1000\n",
      "177/177 [==============================] - 0s 149us/step - loss: 0.0355 - accuracy: 0.9887 - val_loss: 3.5413 - val_accuracy: 0.5132\n",
      "Epoch 413/1000\n",
      "177/177 [==============================] - 0s 78us/step - loss: 0.0360 - accuracy: 0.9831 - val_loss: 3.5320 - val_accuracy: 0.5000\n",
      "Epoch 414/1000\n",
      "177/177 [==============================] - 0s 68us/step - loss: 0.0351 - accuracy: 0.9887 - val_loss: 3.5155 - val_accuracy: 0.5000\n",
      "Epoch 415/1000\n",
      "177/177 [==============================] - 0s 76us/step - loss: 0.0360 - accuracy: 0.9887 - val_loss: 3.5049 - val_accuracy: 0.5000\n",
      "Epoch 416/1000\n",
      "177/177 [==============================] - 0s 74us/step - loss: 0.0356 - accuracy: 0.9887 - val_loss: 3.5207 - val_accuracy: 0.5000\n",
      "Epoch 417/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.0357 - accuracy: 0.9887 - val_loss: 3.5194 - val_accuracy: 0.5000\n",
      "Epoch 418/1000\n",
      "177/177 [==============================] - 0s 102us/step - loss: 0.0357 - accuracy: 0.9831 - val_loss: 3.5096 - val_accuracy: 0.5000\n",
      "Epoch 419/1000\n",
      "177/177 [==============================] - 0s 85us/step - loss: 0.0352 - accuracy: 0.9831 - val_loss: 3.5318 - val_accuracy: 0.5000\n",
      "Epoch 420/1000\n",
      "177/177 [==============================] - 0s 99us/step - loss: 0.0350 - accuracy: 0.9887 - val_loss: 3.5499 - val_accuracy: 0.5000\n",
      "Epoch 421/1000\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.0357 - accuracy: 0.9887 - val_loss: 3.5487 - val_accuracy: 0.5000\n",
      "Epoch 422/1000\n",
      "177/177 [==============================] - 0s 106us/step - loss: 0.0359 - accuracy: 0.9887 - val_loss: 3.5308 - val_accuracy: 0.5000\n",
      "Epoch 423/1000\n",
      "177/177 [==============================] - 0s 170us/step - loss: 0.0364 - accuracy: 0.9831 - val_loss: 3.5440 - val_accuracy: 0.5000\n",
      "Epoch 424/1000\n",
      "177/177 [==============================] - 0s 150us/step - loss: 0.0354 - accuracy: 0.9887 - val_loss: 3.5482 - val_accuracy: 0.5000\n",
      "Epoch 425/1000\n",
      "177/177 [==============================] - 0s 75us/step - loss: 0.0354 - accuracy: 0.9831 - val_loss: 3.5429 - val_accuracy: 0.5000\n",
      "Epoch 426/1000\n",
      "177/177 [==============================] - 0s 93us/step - loss: 0.0354 - accuracy: 0.9887 - val_loss: 3.5370 - val_accuracy: 0.5000\n",
      "Epoch 427/1000\n",
      "177/177 [==============================] - 0s 100us/step - loss: 0.0355 - accuracy: 0.9831 - val_loss: 3.5315 - val_accuracy: 0.5000\n",
      "Epoch 428/1000\n",
      "177/177 [==============================] - 0s 104us/step - loss: 0.0352 - accuracy: 0.9831 - val_loss: 3.5221 - val_accuracy: 0.5000\n",
      "Epoch 429/1000\n",
      "177/177 [==============================] - 0s 105us/step - loss: 0.0358 - accuracy: 0.9887 - val_loss: 3.5285 - val_accuracy: 0.5000\n",
      "Epoch 430/1000\n",
      "177/177 [==============================] - 0s 78us/step - loss: 0.0351 - accuracy: 0.9887 - val_loss: 3.5245 - val_accuracy: 0.5000\n",
      "Epoch 431/1000\n",
      "177/177 [==============================] - 0s 85us/step - loss: 0.0351 - accuracy: 0.9887 - val_loss: 3.5432 - val_accuracy: 0.5000\n",
      "Epoch 432/1000\n",
      "177/177 [==============================] - 0s 74us/step - loss: 0.0353 - accuracy: 0.9887 - val_loss: 3.5376 - val_accuracy: 0.5000\n",
      "Epoch 433/1000\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.0348 - accuracy: 0.9887 - val_loss: 3.5326 - val_accuracy: 0.5000\n",
      "Epoch 434/1000\n",
      "177/177 [==============================] - 0s 149us/step - loss: 0.0350 - accuracy: 0.9831 - val_loss: 3.5411 - val_accuracy: 0.5000\n",
      "Epoch 435/1000\n",
      "177/177 [==============================] - 0s 60us/step - loss: 0.0360 - accuracy: 0.9887 - val_loss: 3.5560 - val_accuracy: 0.5000\n",
      "Epoch 436/1000\n",
      "177/177 [==============================] - 0s 76us/step - loss: 0.0358 - accuracy: 0.9887 - val_loss: 3.5329 - val_accuracy: 0.5000\n",
      "Epoch 437/1000\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.0355 - accuracy: 0.9887 - val_loss: 3.5307 - val_accuracy: 0.5000\n",
      "Epoch 438/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.0350 - accuracy: 0.9887 - val_loss: 3.5567 - val_accuracy: 0.5000\n",
      "Epoch 439/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.0367 - accuracy: 0.9887 - val_loss: 3.5593 - val_accuracy: 0.5000\n",
      "Epoch 440/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.0363 - accuracy: 0.9887 - val_loss: 3.5150 - val_accuracy: 0.5000\n",
      "Epoch 441/1000\n",
      "177/177 [==============================] - 0s 63us/step - loss: 0.0381 - accuracy: 0.9831 - val_loss: 3.5200 - val_accuracy: 0.5000\n",
      "Epoch 442/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.0356 - accuracy: 0.9887 - val_loss: 3.5537 - val_accuracy: 0.5000\n",
      "Epoch 443/1000\n",
      "177/177 [==============================] - 0s 74us/step - loss: 0.0347 - accuracy: 0.9887 - val_loss: 3.5837 - val_accuracy: 0.5132\n",
      "Epoch 444/1000\n",
      "177/177 [==============================] - 0s 76us/step - loss: 0.0385 - accuracy: 0.9887 - val_loss: 3.5004 - val_accuracy: 0.5000\n",
      "Epoch 445/1000\n",
      "177/177 [==============================] - 0s 77us/step - loss: 0.0432 - accuracy: 0.9831 - val_loss: 3.5286 - val_accuracy: 0.5000\n",
      "Epoch 446/1000\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.0614 - accuracy: 0.9774 - val_loss: 3.5554 - val_accuracy: 0.5132\n",
      "Epoch 447/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.0639 - accuracy: 0.9774 - val_loss: 3.5008 - val_accuracy: 0.5000\n",
      "Epoch 448/1000\n",
      "177/177 [==============================] - 0s 63us/step - loss: 0.0689 - accuracy: 0.9718 - val_loss: 3.5854 - val_accuracy: 0.5132\n",
      "Epoch 449/1000\n",
      "177/177 [==============================] - 0s 178us/step - loss: 0.0367 - accuracy: 0.9774 - val_loss: 3.4889 - val_accuracy: 0.5000\n",
      "Epoch 450/1000\n",
      "177/177 [==============================] - 0s 155us/step - loss: 0.0652 - accuracy: 0.9831 - val_loss: 3.4961 - val_accuracy: 0.5395\n",
      "Epoch 451/1000\n",
      "177/177 [==============================] - 0s 107us/step - loss: 0.0393 - accuracy: 0.9774 - val_loss: 3.7502 - val_accuracy: 0.5263\n",
      "Epoch 452/1000\n",
      "177/177 [==============================] - 0s 74us/step - loss: 0.2105 - accuracy: 0.9718 - val_loss: 3.4021 - val_accuracy: 0.5263\n",
      "Epoch 453/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.0427 - accuracy: 0.9774 - val_loss: 3.4804 - val_accuracy: 0.4868\n",
      "Epoch 454/1000\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.1364 - accuracy: 0.9605 - val_loss: 3.4215 - val_accuracy: 0.5263\n",
      "Epoch 455/1000\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.0402 - accuracy: 0.9831 - val_loss: 3.7480 - val_accuracy: 0.5263\n",
      "Epoch 456/1000\n",
      "177/177 [==============================] - 0s 77us/step - loss: 0.1391 - accuracy: 0.9718 - val_loss: 3.5016 - val_accuracy: 0.5395\n",
      "Epoch 457/1000\n",
      "177/177 [==============================] - 0s 77us/step - loss: 0.0818 - accuracy: 0.9774 - val_loss: 3.4493 - val_accuracy: 0.5132\n",
      "Epoch 458/1000\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.0476 - accuracy: 0.9774 - val_loss: 3.5089 - val_accuracy: 0.5132\n",
      "Epoch 459/1000\n",
      "177/177 [==============================] - 0s 76us/step - loss: 0.1046 - accuracy: 0.9774 - val_loss: 3.5006 - val_accuracy: 0.5132\n",
      "Epoch 460/1000\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.0354 - accuracy: 0.9831 - val_loss: 3.3659 - val_accuracy: 0.5263\n",
      "Epoch 461/1000\n",
      "177/177 [==============================] - 0s 91us/step - loss: 0.1028 - accuracy: 0.9774 - val_loss: 3.4135 - val_accuracy: 0.5263\n",
      "Epoch 462/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.0380 - accuracy: 0.9831 - val_loss: 3.6540 - val_accuracy: 0.5263\n",
      "Epoch 463/1000\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.0813 - accuracy: 0.9774 - val_loss: 3.5012 - val_accuracy: 0.5263\n",
      "Epoch 464/1000\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.0478 - accuracy: 0.9774 - val_loss: 3.5100 - val_accuracy: 0.5263\n",
      "Epoch 465/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.0362 - accuracy: 0.9831 - val_loss: 3.5325 - val_accuracy: 0.5263\n",
      "Epoch 466/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.0366 - accuracy: 0.9774 - val_loss: 3.5357 - val_accuracy: 0.5263\n",
      "Epoch 467/1000\n",
      "177/177 [==============================] - 0s 68us/step - loss: 0.0369 - accuracy: 0.9831 - val_loss: 3.4935 - val_accuracy: 0.5263\n",
      "Epoch 468/1000\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.0360 - accuracy: 0.9831 - val_loss: 3.4777 - val_accuracy: 0.5263\n",
      "Epoch 469/1000\n",
      "177/177 [==============================] - 0s 138us/step - loss: 0.0359 - accuracy: 0.9831 - val_loss: 3.4993 - val_accuracy: 0.5263\n",
      "Epoch 470/1000\n",
      "177/177 [==============================] - 0s 136us/step - loss: 0.0356 - accuracy: 0.9887 - val_loss: 3.5324 - val_accuracy: 0.5263\n",
      "Epoch 471/1000\n",
      "177/177 [==============================] - 0s 93us/step - loss: 0.0360 - accuracy: 0.9831 - val_loss: 3.5654 - val_accuracy: 0.5263\n",
      "Epoch 472/1000\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.0349 - accuracy: 0.9831 - val_loss: 3.5960 - val_accuracy: 0.5263\n",
      "Epoch 473/1000\n",
      "177/177 [==============================] - 0s 108us/step - loss: 0.0350 - accuracy: 0.9831 - val_loss: 3.6024 - val_accuracy: 0.5132\n",
      "Epoch 474/1000\n",
      "177/177 [==============================] - 0s 131us/step - loss: 0.0347 - accuracy: 0.9887 - val_loss: 3.5764 - val_accuracy: 0.5000\n",
      "Epoch 475/1000\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.0353 - accuracy: 0.9831 - val_loss: 3.5683 - val_accuracy: 0.5000\n",
      "Epoch 476/1000\n",
      "177/177 [==============================] - 0s 69us/step - loss: 0.0346 - accuracy: 0.9887 - val_loss: 3.5759 - val_accuracy: 0.5000\n",
      "Epoch 477/1000\n",
      "177/177 [==============================] - 0s 123us/step - loss: 0.0351 - accuracy: 0.9831 - val_loss: 3.5894 - val_accuracy: 0.5000\n",
      "Epoch 478/1000\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.0350 - accuracy: 0.9831 - val_loss: 3.5822 - val_accuracy: 0.5000\n",
      "Epoch 479/1000\n",
      "177/177 [==============================] - 0s 122us/step - loss: 0.0347 - accuracy: 0.9887 - val_loss: 3.5686 - val_accuracy: 0.5132\n",
      "Epoch 480/1000\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.0339 - accuracy: 0.9887 - val_loss: 3.5611 - val_accuracy: 0.5132\n",
      "Epoch 481/1000\n",
      "177/177 [==============================] - 0s 100us/step - loss: 0.0344 - accuracy: 0.9887 - val_loss: 3.5565 - val_accuracy: 0.5132\n",
      "Epoch 482/1000\n",
      "177/177 [==============================] - 0s 93us/step - loss: 0.0341 - accuracy: 0.9887 - val_loss: 3.5726 - val_accuracy: 0.5132\n",
      "Epoch 483/1000\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.0348 - accuracy: 0.9887 - val_loss: 3.5871 - val_accuracy: 0.5132\n",
      "Epoch 484/1000\n",
      "177/177 [==============================] - 0s 75us/step - loss: 0.0356 - accuracy: 0.9887 - val_loss: 3.5894 - val_accuracy: 0.5132\n",
      "Epoch 485/1000\n",
      "177/177 [==============================] - 0s 128us/step - loss: 0.0341 - accuracy: 0.9887 - val_loss: 3.5720 - val_accuracy: 0.5132\n",
      "Epoch 486/1000\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.0341 - accuracy: 0.9887 - val_loss: 3.5672 - val_accuracy: 0.5132\n",
      "Epoch 487/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.0337 - accuracy: 0.9887 - val_loss: 3.5751 - val_accuracy: 0.5000\n",
      "Epoch 488/1000\n",
      "177/177 [==============================] - 0s 68us/step - loss: 0.0339 - accuracy: 0.9887 - val_loss: 3.6045 - val_accuracy: 0.5000\n",
      "Epoch 489/1000\n",
      "177/177 [==============================] - 0s 68us/step - loss: 0.0338 - accuracy: 0.9887 - val_loss: 3.6012 - val_accuracy: 0.5000\n",
      "Epoch 490/1000\n",
      "177/177 [==============================] - 0s 81us/step - loss: 0.0341 - accuracy: 0.9887 - val_loss: 3.6062 - val_accuracy: 0.5000\n",
      "Epoch 491/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.0340 - accuracy: 0.9887 - val_loss: 3.6202 - val_accuracy: 0.5000\n",
      "Epoch 492/1000\n",
      "177/177 [==============================] - 0s 256us/step - loss: 0.0342 - accuracy: 0.9831 - val_loss: 3.6147 - val_accuracy: 0.5000\n",
      "Epoch 493/1000\n",
      "177/177 [==============================] - 0s 109us/step - loss: 0.0339 - accuracy: 0.9887 - val_loss: 3.6252 - val_accuracy: 0.5000\n",
      "Epoch 494/1000\n",
      "177/177 [==============================] - 0s 68us/step - loss: 0.0336 - accuracy: 0.9887 - val_loss: 3.6197 - val_accuracy: 0.5000\n",
      "Epoch 495/1000\n",
      "177/177 [==============================] - 0s 84us/step - loss: 0.0335 - accuracy: 0.9887 - val_loss: 3.6270 - val_accuracy: 0.5000\n",
      "Epoch 496/1000\n",
      "177/177 [==============================] - 0s 81us/step - loss: 0.0340 - accuracy: 0.9887 - val_loss: 3.6289 - val_accuracy: 0.5000\n",
      "Epoch 497/1000\n",
      "177/177 [==============================] - 0s 79us/step - loss: 0.0339 - accuracy: 0.9831 - val_loss: 3.6232 - val_accuracy: 0.5000\n",
      "Epoch 498/1000\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.0337 - accuracy: 0.9887 - val_loss: 3.6354 - val_accuracy: 0.5000\n",
      "Epoch 499/1000\n",
      "177/177 [==============================] - 0s 68us/step - loss: 0.0342 - accuracy: 0.9887 - val_loss: 3.6424 - val_accuracy: 0.5000\n",
      "Epoch 500/1000\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.0333 - accuracy: 0.9887 - val_loss: 3.6560 - val_accuracy: 0.5000\n",
      "Epoch 501/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.0347 - accuracy: 0.9831 - val_loss: 3.6584 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 502/1000\n",
      "177/177 [==============================] - 0s 68us/step - loss: 0.0341 - accuracy: 0.9887 - val_loss: 3.6496 - val_accuracy: 0.5000\n",
      "Epoch 503/1000\n",
      "177/177 [==============================] - 0s 94us/step - loss: 0.0339 - accuracy: 0.9887 - val_loss: 3.6217 - val_accuracy: 0.5000\n",
      "Epoch 504/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.0340 - accuracy: 0.9887 - val_loss: 3.6208 - val_accuracy: 0.5000\n",
      "Epoch 505/1000\n",
      "177/177 [==============================] - 0s 204us/step - loss: 0.0338 - accuracy: 0.9831 - val_loss: 3.6115 - val_accuracy: 0.5000\n",
      "Epoch 506/1000\n",
      "177/177 [==============================] - 0s 130us/step - loss: 0.0342 - accuracy: 0.9887 - val_loss: 3.6232 - val_accuracy: 0.5000\n",
      "Epoch 507/1000\n",
      "177/177 [==============================] - 0s 105us/step - loss: 0.0338 - accuracy: 0.9887 - val_loss: 3.6436 - val_accuracy: 0.5000\n",
      "Epoch 508/1000\n",
      "177/177 [==============================] - 0s 74us/step - loss: 0.0341 - accuracy: 0.9887 - val_loss: 3.6681 - val_accuracy: 0.5000\n",
      "Epoch 509/1000\n",
      "177/177 [==============================] - 0s 177us/step - loss: 0.0338 - accuracy: 0.9887 - val_loss: 3.6573 - val_accuracy: 0.5000\n",
      "Epoch 510/1000\n",
      "177/177 [==============================] - 0s 110us/step - loss: 0.0342 - accuracy: 0.9887 - val_loss: 3.6509 - val_accuracy: 0.5000\n",
      "Epoch 511/1000\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.0335 - accuracy: 0.9887 - val_loss: 3.6696 - val_accuracy: 0.5000\n",
      "Epoch 512/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.0338 - accuracy: 0.9831 - val_loss: 3.6551 - val_accuracy: 0.5000\n",
      "Epoch 513/1000\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.0334 - accuracy: 0.9887 - val_loss: 3.6515 - val_accuracy: 0.5000\n",
      "Epoch 514/1000\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.0345 - accuracy: 0.9831 - val_loss: 3.6541 - val_accuracy: 0.5000\n",
      "Epoch 515/1000\n",
      "177/177 [==============================] - 0s 76us/step - loss: 0.0334 - accuracy: 0.9887 - val_loss: 3.6563 - val_accuracy: 0.5000\n",
      "Epoch 516/1000\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.0330 - accuracy: 0.9887 - val_loss: 3.6774 - val_accuracy: 0.5000\n",
      "Epoch 517/1000\n",
      "177/177 [==============================] - 0s 82us/step - loss: 0.0330 - accuracy: 0.9887 - val_loss: 3.6918 - val_accuracy: 0.5000\n",
      "Epoch 518/1000\n",
      "177/177 [==============================] - 0s 75us/step - loss: 0.0332 - accuracy: 0.9887 - val_loss: 3.6884 - val_accuracy: 0.5000\n",
      "Epoch 519/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.0335 - accuracy: 0.9887 - val_loss: 3.6887 - val_accuracy: 0.5000\n",
      "Epoch 520/1000\n",
      "177/177 [==============================] - 0s 81us/step - loss: 0.0334 - accuracy: 0.9887 - val_loss: 3.6769 - val_accuracy: 0.5000\n",
      "Epoch 521/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.0335 - accuracy: 0.9887 - val_loss: 3.6799 - val_accuracy: 0.5000\n",
      "Epoch 522/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.0330 - accuracy: 0.9887 - val_loss: 3.6509 - val_accuracy: 0.5000\n",
      "Epoch 523/1000\n",
      "177/177 [==============================] - 0s 137us/step - loss: 0.0341 - accuracy: 0.9887 - val_loss: 3.6263 - val_accuracy: 0.5000\n",
      "Epoch 524/1000\n",
      "177/177 [==============================] - 0s 145us/step - loss: 0.0341 - accuracy: 0.9831 - val_loss: 3.6388 - val_accuracy: 0.5000\n",
      "Epoch 525/1000\n",
      "177/177 [==============================] - 0s 107us/step - loss: 0.0331 - accuracy: 0.9831 - val_loss: 3.6640 - val_accuracy: 0.5000\n",
      "Epoch 526/1000\n",
      "177/177 [==============================] - 0s 74us/step - loss: 0.0341 - accuracy: 0.9887 - val_loss: 3.6586 - val_accuracy: 0.5000\n",
      "Epoch 527/1000\n",
      "177/177 [==============================] - 0s 113us/step - loss: 0.0331 - accuracy: 0.9887 - val_loss: 3.6569 - val_accuracy: 0.5000\n",
      "Epoch 528/1000\n",
      "177/177 [==============================] - 0s 91us/step - loss: 0.0347 - accuracy: 0.9887 - val_loss: 3.6746 - val_accuracy: 0.5000\n",
      "Epoch 529/1000\n",
      "177/177 [==============================] - 0s 83us/step - loss: 0.0338 - accuracy: 0.9887 - val_loss: 3.7037 - val_accuracy: 0.5000\n",
      "Epoch 530/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.0331 - accuracy: 0.9887 - val_loss: 3.7206 - val_accuracy: 0.5000\n",
      "Epoch 531/1000\n",
      "177/177 [==============================] - 0s 75us/step - loss: 0.0351 - accuracy: 0.9887 - val_loss: 3.7045 - val_accuracy: 0.5000\n",
      "Epoch 532/1000\n",
      "177/177 [==============================] - 0s 63us/step - loss: 0.0332 - accuracy: 0.9887 - val_loss: 3.6294 - val_accuracy: 0.5000\n",
      "Epoch 533/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.0349 - accuracy: 0.9887 - val_loss: 3.6107 - val_accuracy: 0.5000\n",
      "Epoch 534/1000\n",
      "177/177 [==============================] - 0s 70us/step - loss: 0.0355 - accuracy: 0.9887 - val_loss: 3.6201 - val_accuracy: 0.5132\n",
      "Epoch 535/1000\n",
      "177/177 [==============================] - 0s 87us/step - loss: 0.0338 - accuracy: 0.9887 - val_loss: 3.6449 - val_accuracy: 0.5132\n",
      "Epoch 536/1000\n",
      "177/177 [==============================] - 0s 74us/step - loss: 0.0331 - accuracy: 0.9887 - val_loss: 3.6810 - val_accuracy: 0.5000\n",
      "Epoch 537/1000\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.0353 - accuracy: 0.9887 - val_loss: 3.6592 - val_accuracy: 0.5000\n",
      "Epoch 538/1000\n",
      "177/177 [==============================] - 0s 82us/step - loss: 0.0344 - accuracy: 0.9887 - val_loss: 3.6494 - val_accuracy: 0.5000\n",
      "Epoch 539/1000\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.0336 - accuracy: 0.9887 - val_loss: 3.6531 - val_accuracy: 0.5132\n",
      "Epoch 540/1000\n",
      "177/177 [==============================] - 0s 78us/step - loss: 0.0333 - accuracy: 0.9887 - val_loss: 3.6447 - val_accuracy: 0.5132\n",
      "Epoch 541/1000\n",
      "177/177 [==============================] - 0s 104us/step - loss: 0.0330 - accuracy: 0.9887 - val_loss: 3.6605 - val_accuracy: 0.5132\n",
      "Epoch 542/1000\n",
      "177/177 [==============================] - 0s 156us/step - loss: 0.0334 - accuracy: 0.9887 - val_loss: 3.6568 - val_accuracy: 0.5000\n",
      "Epoch 543/1000\n",
      "177/177 [==============================] - 0s 172us/step - loss: 0.0340 - accuracy: 0.9887 - val_loss: 3.6445 - val_accuracy: 0.5000\n",
      "Epoch 544/1000\n",
      "177/177 [==============================] - 0s 99us/step - loss: 0.0345 - accuracy: 0.9887 - val_loss: 3.6096 - val_accuracy: 0.5000\n",
      "Epoch 545/1000\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.0349 - accuracy: 0.9887 - val_loss: 3.6531 - val_accuracy: 0.5000\n",
      "Epoch 546/1000\n",
      "177/177 [==============================] - 0s 149us/step - loss: 0.0343 - accuracy: 0.9887 - val_loss: 3.7013 - val_accuracy: 0.5000\n",
      "Epoch 547/1000\n",
      "177/177 [==============================] - 0s 144us/step - loss: 0.0332 - accuracy: 0.9887 - val_loss: 3.7425 - val_accuracy: 0.5000\n",
      "Epoch 548/1000\n",
      "177/177 [==============================] - 0s 115us/step - loss: 0.0353 - accuracy: 0.9887 - val_loss: 3.7084 - val_accuracy: 0.5000\n",
      "Epoch 549/1000\n",
      "177/177 [==============================] - 0s 94us/step - loss: 0.0336 - accuracy: 0.9887 - val_loss: 3.6308 - val_accuracy: 0.5000\n",
      "Epoch 550/1000\n",
      "177/177 [==============================] - 0s 95us/step - loss: 0.0364 - accuracy: 0.9831 - val_loss: 3.6320 - val_accuracy: 0.5000\n",
      "Epoch 551/1000\n",
      "177/177 [==============================] - 0s 86us/step - loss: 0.0342 - accuracy: 0.9887 - val_loss: 3.6655 - val_accuracy: 0.5000\n",
      "Epoch 552/1000\n",
      "177/177 [==============================] - 0s 84us/step - loss: 0.0331 - accuracy: 0.9831 - val_loss: 3.7184 - val_accuracy: 0.5132\n",
      "Epoch 553/1000\n",
      "177/177 [==============================] - 0s 87us/step - loss: 0.0341 - accuracy: 0.9887 - val_loss: 3.7126 - val_accuracy: 0.5132\n",
      "Epoch 554/1000\n",
      "177/177 [==============================] - 0s 81us/step - loss: 0.0336 - accuracy: 0.9831 - val_loss: 3.6564 - val_accuracy: 0.5000\n",
      "Epoch 555/1000\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.0357 - accuracy: 0.9887 - val_loss: 3.6493 - val_accuracy: 0.5000\n",
      "Epoch 556/1000\n",
      "177/177 [==============================] - 0s 296us/step - loss: 0.0343 - accuracy: 0.9887 - val_loss: 3.6822 - val_accuracy: 0.5000\n",
      "Epoch 557/1000\n",
      "177/177 [==============================] - 0s 406us/step - loss: 0.0331 - accuracy: 0.9887 - val_loss: 3.7178 - val_accuracy: 0.5132\n",
      "Epoch 558/1000\n",
      "177/177 [==============================] - 0s 447us/step - loss: 0.0327 - accuracy: 0.9887 - val_loss: 3.7138 - val_accuracy: 0.5263\n",
      "Epoch 559/1000\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.0325 - accuracy: 0.9887 - val_loss: 3.7155 - val_accuracy: 0.5000\n",
      "Epoch 560/1000\n",
      "177/177 [==============================] - 0s 87us/step - loss: 0.0324 - accuracy: 0.9887 - val_loss: 3.7296 - val_accuracy: 0.5000\n",
      "Epoch 561/1000\n",
      "177/177 [==============================] - 0s 329us/step - loss: 0.0325 - accuracy: 0.9887 - val_loss: 3.7339 - val_accuracy: 0.5000\n",
      "Epoch 562/1000\n",
      "177/177 [==============================] - 0s 462us/step - loss: 0.0323 - accuracy: 0.9887 - val_loss: 3.7438 - val_accuracy: 0.5000\n",
      "Epoch 563/1000\n",
      "177/177 [==============================] - 0s 79us/step - loss: 0.0329 - accuracy: 0.9887 - val_loss: 3.7180 - val_accuracy: 0.5000\n",
      "Epoch 564/1000\n",
      "177/177 [==============================] - 0s 82us/step - loss: 0.0333 - accuracy: 0.9831 - val_loss: 3.7165 - val_accuracy: 0.5000\n",
      "Epoch 565/1000\n",
      "177/177 [==============================] - 0s 76us/step - loss: 0.0332 - accuracy: 0.9887 - val_loss: 3.7349 - val_accuracy: 0.5000\n",
      "Epoch 566/1000\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.0322 - accuracy: 0.9887 - val_loss: 3.7474 - val_accuracy: 0.5000\n",
      "Epoch 567/1000\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.0321 - accuracy: 0.9887 - val_loss: 3.7399 - val_accuracy: 0.5000\n",
      "Epoch 568/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.0325 - accuracy: 0.9887 - val_loss: 3.7275 - val_accuracy: 0.5000\n",
      "Epoch 569/1000\n",
      "177/177 [==============================] - 0s 75us/step - loss: 0.0327 - accuracy: 0.9887 - val_loss: 3.7378 - val_accuracy: 0.5000\n",
      "Epoch 570/1000\n",
      "177/177 [==============================] - 0s 63us/step - loss: 0.0328 - accuracy: 0.9887 - val_loss: 3.7321 - val_accuracy: 0.5000\n",
      "Epoch 571/1000\n",
      "177/177 [==============================] - 0s 68us/step - loss: 0.0321 - accuracy: 0.9887 - val_loss: 3.7439 - val_accuracy: 0.5000\n",
      "Epoch 572/1000\n",
      "177/177 [==============================] - 0s 77us/step - loss: 0.0321 - accuracy: 0.9887 - val_loss: 3.7475 - val_accuracy: 0.5000\n",
      "Epoch 573/1000\n",
      "177/177 [==============================] - 0s 84us/step - loss: 0.0326 - accuracy: 0.9887 - val_loss: 3.7382 - val_accuracy: 0.5000\n",
      "Epoch 574/1000\n",
      "177/177 [==============================] - 0s 70us/step - loss: 0.0324 - accuracy: 0.9887 - val_loss: 3.7556 - val_accuracy: 0.5000\n",
      "Epoch 575/1000\n",
      "177/177 [==============================] - 0s 69us/step - loss: 0.0319 - accuracy: 0.9887 - val_loss: 3.7680 - val_accuracy: 0.5000\n",
      "Epoch 576/1000\n",
      "177/177 [==============================] - 0s 79us/step - loss: 0.0321 - accuracy: 0.9887 - val_loss: 3.7766 - val_accuracy: 0.5000\n",
      "Epoch 577/1000\n",
      "177/177 [==============================] - 0s 157us/step - loss: 0.0324 - accuracy: 0.9887 - val_loss: 3.7538 - val_accuracy: 0.5000\n",
      "Epoch 578/1000\n",
      "177/177 [==============================] - 0s 83us/step - loss: 0.0321 - accuracy: 0.9887 - val_loss: 3.7408 - val_accuracy: 0.5000\n",
      "Epoch 579/1000\n",
      "177/177 [==============================] - 0s 82us/step - loss: 0.0319 - accuracy: 0.9887 - val_loss: 3.7291 - val_accuracy: 0.5000\n",
      "Epoch 580/1000\n",
      "177/177 [==============================] - 0s 110us/step - loss: 0.0322 - accuracy: 0.9831 - val_loss: 3.7296 - val_accuracy: 0.5000\n",
      "Epoch 581/1000\n",
      "177/177 [==============================] - 0s 74us/step - loss: 0.0326 - accuracy: 0.9887 - val_loss: 3.7311 - val_accuracy: 0.4868\n",
      "Epoch 582/1000\n",
      "177/177 [==============================] - 0s 96us/step - loss: 0.0316 - accuracy: 0.9887 - val_loss: 3.7197 - val_accuracy: 0.5000\n",
      "Epoch 583/1000\n",
      "177/177 [==============================] - 0s 83us/step - loss: 0.0321 - accuracy: 0.9887 - val_loss: 3.7204 - val_accuracy: 0.5000\n",
      "Epoch 584/1000\n",
      "177/177 [==============================] - 0s 82us/step - loss: 0.0326 - accuracy: 0.9831 - val_loss: 3.7385 - val_accuracy: 0.5000\n",
      "Epoch 585/1000\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.0321 - accuracy: 0.9887 - val_loss: 3.7643 - val_accuracy: 0.4868\n",
      "Epoch 586/1000\n",
      "177/177 [==============================] - 0s 89us/step - loss: 0.0321 - accuracy: 0.9887 - val_loss: 3.7737 - val_accuracy: 0.4868\n",
      "Epoch 587/1000\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.0315 - accuracy: 0.9887 - val_loss: 3.7484 - val_accuracy: 0.5000\n",
      "Epoch 588/1000\n",
      "177/177 [==============================] - 0s 70us/step - loss: 0.0322 - accuracy: 0.9887 - val_loss: 3.7393 - val_accuracy: 0.5000\n",
      "Epoch 589/1000\n",
      "177/177 [==============================] - 0s 74us/step - loss: 0.0325 - accuracy: 0.9831 - val_loss: 3.7540 - val_accuracy: 0.5000\n",
      "Epoch 590/1000\n",
      "177/177 [==============================] - 0s 142us/step - loss: 0.0318 - accuracy: 0.9831 - val_loss: 3.7649 - val_accuracy: 0.4868\n",
      "Epoch 591/1000\n",
      "177/177 [==============================] - 0s 96us/step - loss: 0.0321 - accuracy: 0.9887 - val_loss: 3.7745 - val_accuracy: 0.5000\n",
      "Epoch 592/1000\n",
      "177/177 [==============================] - 0s 101us/step - loss: 0.0322 - accuracy: 0.9887 - val_loss: 3.7848 - val_accuracy: 0.5000\n",
      "Epoch 593/1000\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.0322 - accuracy: 0.9887 - val_loss: 3.7765 - val_accuracy: 0.5000\n",
      "Epoch 594/1000\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.0322 - accuracy: 0.9887 - val_loss: 3.7808 - val_accuracy: 0.5000\n",
      "Epoch 595/1000\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.0323 - accuracy: 0.9887 - val_loss: 3.7777 - val_accuracy: 0.5000\n",
      "Epoch 596/1000\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.0315 - accuracy: 0.9887 - val_loss: 3.7766 - val_accuracy: 0.5000\n",
      "Epoch 597/1000\n",
      "177/177 [==============================] - 0s 92us/step - loss: 0.0321 - accuracy: 0.9831 - val_loss: 3.7753 - val_accuracy: 0.5000\n",
      "Epoch 598/1000\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.0318 - accuracy: 0.9887 - val_loss: 3.7596 - val_accuracy: 0.5000\n",
      "Epoch 599/1000\n",
      "177/177 [==============================] - 0s 93us/step - loss: 0.0317 - accuracy: 0.9887 - val_loss: 3.7639 - val_accuracy: 0.5000\n",
      "Epoch 600/1000\n",
      "177/177 [==============================] - 0s 89us/step - loss: 0.0317 - accuracy: 0.9887 - val_loss: 3.7859 - val_accuracy: 0.4868\n",
      "Epoch 601/1000\n",
      "177/177 [==============================] - 0s 76us/step - loss: 0.0316 - accuracy: 0.9887 - val_loss: 3.7918 - val_accuracy: 0.4868\n",
      "Epoch 602/1000\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.0317 - accuracy: 0.9831 - val_loss: 3.7607 - val_accuracy: 0.5000\n",
      "Epoch 603/1000\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.0320 - accuracy: 0.9887 - val_loss: 3.7577 - val_accuracy: 0.5000\n",
      "Epoch 604/1000\n",
      "177/177 [==============================] - 0s 77us/step - loss: 0.0316 - accuracy: 0.9887 - val_loss: 3.7605 - val_accuracy: 0.5000\n",
      "Epoch 605/1000\n",
      "177/177 [==============================] - 0s 68us/step - loss: 0.0314 - accuracy: 0.9887 - val_loss: 3.7827 - val_accuracy: 0.5000\n",
      "Epoch 606/1000\n",
      "177/177 [==============================] - 0s 91us/step - loss: 0.0315 - accuracy: 0.9887 - val_loss: 3.7866 - val_accuracy: 0.5000\n",
      "Epoch 607/1000\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.0321 - accuracy: 0.9831 - val_loss: 3.7820 - val_accuracy: 0.5000\n",
      "Epoch 608/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.0320 - accuracy: 0.9887 - val_loss: 3.7772 - val_accuracy: 0.5000\n",
      "Epoch 609/1000\n",
      "177/177 [==============================] - 0s 69us/step - loss: 0.0317 - accuracy: 0.9887 - val_loss: 3.7927 - val_accuracy: 0.5000\n",
      "Epoch 610/1000\n",
      "177/177 [==============================] - 0s 230us/step - loss: 0.0317 - accuracy: 0.9887 - val_loss: 3.7937 - val_accuracy: 0.5000\n",
      "Epoch 611/1000\n",
      "177/177 [==============================] - 0s 533us/step - loss: 0.0316 - accuracy: 0.9887 - val_loss: 3.7792 - val_accuracy: 0.5000\n",
      "Epoch 612/1000\n",
      "177/177 [==============================] - 0s 56us/step - loss: 0.0313 - accuracy: 0.9887 - val_loss: 3.7735 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 613/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.0328 - accuracy: 0.9887 - val_loss: 3.7964 - val_accuracy: 0.5000\n",
      "Epoch 614/1000\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.0319 - accuracy: 0.9887 - val_loss: 3.7882 - val_accuracy: 0.5000\n",
      "Epoch 615/1000\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.0321 - accuracy: 0.9887 - val_loss: 3.7780 - val_accuracy: 0.5132\n",
      "Epoch 616/1000\n",
      "177/177 [==============================] - 0s 78us/step - loss: 0.0320 - accuracy: 0.9887 - val_loss: 3.7601 - val_accuracy: 0.5132\n",
      "Epoch 617/1000\n",
      "177/177 [==============================] - 0s 78us/step - loss: 0.0323 - accuracy: 0.9887 - val_loss: 3.7529 - val_accuracy: 0.5000\n",
      "Epoch 618/1000\n",
      "177/177 [==============================] - 0s 74us/step - loss: 0.0318 - accuracy: 0.9887 - val_loss: 3.7588 - val_accuracy: 0.5000\n",
      "Epoch 619/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.0314 - accuracy: 0.9887 - val_loss: 3.7913 - val_accuracy: 0.5000\n",
      "Epoch 620/1000\n",
      "177/177 [==============================] - 0s 191us/step - loss: 0.0319 - accuracy: 0.9887 - val_loss: 3.7946 - val_accuracy: 0.5000\n",
      "Epoch 621/1000\n",
      "177/177 [==============================] - 0s 107us/step - loss: 0.0311 - accuracy: 0.9887 - val_loss: 3.7810 - val_accuracy: 0.5132\n",
      "Epoch 622/1000\n",
      "177/177 [==============================] - 0s 120us/step - loss: 0.0312 - accuracy: 0.9887 - val_loss: 3.7816 - val_accuracy: 0.5132\n",
      "Epoch 623/1000\n",
      "177/177 [==============================] - 0s 93us/step - loss: 0.0325 - accuracy: 0.9831 - val_loss: 3.7759 - val_accuracy: 0.5000\n",
      "Epoch 624/1000\n",
      "177/177 [==============================] - 0s 193us/step - loss: 0.0311 - accuracy: 0.9887 - val_loss: 3.7533 - val_accuracy: 0.5132\n",
      "Epoch 625/1000\n",
      "177/177 [==============================] - 0s 142us/step - loss: 0.0319 - accuracy: 0.9887 - val_loss: 3.7516 - val_accuracy: 0.5000\n",
      "Epoch 626/1000\n",
      "177/177 [==============================] - 0s 113us/step - loss: 0.0324 - accuracy: 0.9887 - val_loss: 3.7668 - val_accuracy: 0.5000\n",
      "Epoch 627/1000\n",
      "177/177 [==============================] - 0s 149us/step - loss: 0.0315 - accuracy: 0.9887 - val_loss: 3.8045 - val_accuracy: 0.5000\n",
      "Epoch 628/1000\n",
      "177/177 [==============================] - 0s 102us/step - loss: 0.0312 - accuracy: 0.9887 - val_loss: 3.8164 - val_accuracy: 0.5000\n",
      "Epoch 629/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.0318 - accuracy: 0.9831 - val_loss: 3.8122 - val_accuracy: 0.5132\n",
      "Epoch 630/1000\n",
      "177/177 [==============================] - 0s 97us/step - loss: 0.0325 - accuracy: 0.9887 - val_loss: 3.7940 - val_accuracy: 0.5132\n",
      "Epoch 631/1000\n",
      "177/177 [==============================] - 0s 57us/step - loss: 0.0317 - accuracy: 0.9887 - val_loss: 3.7710 - val_accuracy: 0.5000\n",
      "Epoch 632/1000\n",
      "177/177 [==============================] - 0s 63us/step - loss: 0.0311 - accuracy: 0.9887 - val_loss: 3.7823 - val_accuracy: 0.5000\n",
      "Epoch 633/1000\n",
      "177/177 [==============================] - 0s 57us/step - loss: 0.0313 - accuracy: 0.9887 - val_loss: 3.8104 - val_accuracy: 0.4868\n",
      "Epoch 634/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.0315 - accuracy: 0.9887 - val_loss: 3.8286 - val_accuracy: 0.4868\n",
      "Epoch 635/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.0317 - accuracy: 0.9887 - val_loss: 3.8294 - val_accuracy: 0.5000\n",
      "Epoch 636/1000\n",
      "177/177 [==============================] - 0s 75us/step - loss: 0.0317 - accuracy: 0.9887 - val_loss: 3.8439 - val_accuracy: 0.5000\n",
      "Epoch 637/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.0308 - accuracy: 0.9887 - val_loss: 3.8160 - val_accuracy: 0.5000\n",
      "Epoch 638/1000\n",
      "177/177 [==============================] - 0s 74us/step - loss: 0.0316 - accuracy: 0.9887 - val_loss: 3.7992 - val_accuracy: 0.5000\n",
      "Epoch 639/1000\n",
      "177/177 [==============================] - 0s 74us/step - loss: 0.0309 - accuracy: 0.9887 - val_loss: 3.7765 - val_accuracy: 0.5000\n",
      "Epoch 640/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.0309 - accuracy: 0.9887 - val_loss: 3.7679 - val_accuracy: 0.5000\n",
      "Epoch 641/1000\n",
      "177/177 [==============================] - 0s 75us/step - loss: 0.0312 - accuracy: 0.9831 - val_loss: 3.8060 - val_accuracy: 0.5000\n",
      "Epoch 642/1000\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.0309 - accuracy: 0.9887 - val_loss: 3.8160 - val_accuracy: 0.5000\n",
      "Epoch 643/1000\n",
      "177/177 [==============================] - 0s 78us/step - loss: 0.0309 - accuracy: 0.9887 - val_loss: 3.8158 - val_accuracy: 0.5000\n",
      "Epoch 644/1000\n",
      "177/177 [==============================] - 0s 59us/step - loss: 0.0325 - accuracy: 0.9887 - val_loss: 3.8224 - val_accuracy: 0.5000\n",
      "Epoch 645/1000\n",
      "177/177 [==============================] - 0s 94us/step - loss: 0.0309 - accuracy: 0.9887 - val_loss: 3.8270 - val_accuracy: 0.5000\n",
      "Epoch 646/1000\n",
      "177/177 [==============================] - 0s 131us/step - loss: 0.0313 - accuracy: 0.9887 - val_loss: 3.8280 - val_accuracy: 0.4868\n",
      "Epoch 647/1000\n",
      "177/177 [==============================] - 0s 115us/step - loss: 0.0311 - accuracy: 0.9887 - val_loss: 3.7926 - val_accuracy: 0.5132\n",
      "Epoch 648/1000\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.0312 - accuracy: 0.9887 - val_loss: 3.7829 - val_accuracy: 0.5132\n",
      "Epoch 649/1000\n",
      "177/177 [==============================] - 0s 87us/step - loss: 0.0313 - accuracy: 0.9887 - val_loss: 3.7940 - val_accuracy: 0.5132\n",
      "Epoch 650/1000\n",
      "177/177 [==============================] - 0s 101us/step - loss: 0.0311 - accuracy: 0.9887 - val_loss: 3.7943 - val_accuracy: 0.4868\n",
      "Epoch 651/1000\n",
      "177/177 [==============================] - 0s 131us/step - loss: 0.0310 - accuracy: 0.9887 - val_loss: 3.7904 - val_accuracy: 0.4868\n",
      "Epoch 652/1000\n",
      "177/177 [==============================] - 0s 108us/step - loss: 0.0305 - accuracy: 0.9887 - val_loss: 3.7899 - val_accuracy: 0.5000\n",
      "Epoch 653/1000\n",
      "177/177 [==============================] - 0s 174us/step - loss: 0.0312 - accuracy: 0.9887 - val_loss: 3.7979 - val_accuracy: 0.5000\n",
      "Epoch 654/1000\n",
      "177/177 [==============================] - 0s 135us/step - loss: 0.0316 - accuracy: 0.9887 - val_loss: 3.8265 - val_accuracy: 0.5000\n",
      "Epoch 655/1000\n",
      "177/177 [==============================] - 0s 187us/step - loss: 0.0314 - accuracy: 0.9887 - val_loss: 3.8454 - val_accuracy: 0.5000\n",
      "Epoch 656/1000\n",
      "177/177 [==============================] - 0s 129us/step - loss: 0.0306 - accuracy: 0.9887 - val_loss: 3.8457 - val_accuracy: 0.5000\n",
      "Epoch 657/1000\n",
      "177/177 [==============================] - 0s 101us/step - loss: 0.0314 - accuracy: 0.9887 - val_loss: 3.8348 - val_accuracy: 0.5000\n",
      "Epoch 658/1000\n",
      "177/177 [==============================] - 0s 81us/step - loss: 0.0307 - accuracy: 0.9887 - val_loss: 3.8338 - val_accuracy: 0.5000\n",
      "Epoch 659/1000\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.0310 - accuracy: 0.9887 - val_loss: 3.8176 - val_accuracy: 0.5000\n",
      "Epoch 660/1000\n",
      "177/177 [==============================] - 0s 74us/step - loss: 0.0307 - accuracy: 0.9887 - val_loss: 3.8082 - val_accuracy: 0.5000\n",
      "Epoch 661/1000\n",
      "177/177 [==============================] - 0s 58us/step - loss: 0.0312 - accuracy: 0.9887 - val_loss: 3.8129 - val_accuracy: 0.5000\n",
      "Epoch 662/1000\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.0305 - accuracy: 0.9887 - val_loss: 3.8523 - val_accuracy: 0.4868\n",
      "Epoch 663/1000\n",
      "177/177 [==============================] - 0s 60us/step - loss: 0.0307 - accuracy: 0.9887 - val_loss: 3.8805 - val_accuracy: 0.4868\n",
      "Epoch 664/1000\n",
      "177/177 [==============================] - 0s 63us/step - loss: 0.0307 - accuracy: 0.9887 - val_loss: 3.8518 - val_accuracy: 0.5000\n",
      "Epoch 665/1000\n",
      "177/177 [==============================] - 0s 68us/step - loss: 0.0312 - accuracy: 0.9887 - val_loss: 3.8259 - val_accuracy: 0.5000\n",
      "Epoch 666/1000\n",
      "177/177 [==============================] - 0s 69us/step - loss: 0.0306 - accuracy: 0.9887 - val_loss: 3.8346 - val_accuracy: 0.5000\n",
      "Epoch 667/1000\n",
      "177/177 [==============================] - 0s 54us/step - loss: 0.0311 - accuracy: 0.9887 - val_loss: 3.8417 - val_accuracy: 0.4868\n",
      "Epoch 668/1000\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.0302 - accuracy: 0.9887 - val_loss: 3.8207 - val_accuracy: 0.5000\n",
      "Epoch 669/1000\n",
      "177/177 [==============================] - 0s 85us/step - loss: 0.0311 - accuracy: 0.9831 - val_loss: 3.8173 - val_accuracy: 0.5000\n",
      "Epoch 670/1000\n",
      "177/177 [==============================] - 0s 345us/step - loss: 0.0306 - accuracy: 0.9831 - val_loss: 3.8215 - val_accuracy: 0.5000\n",
      "Epoch 671/1000\n",
      "177/177 [==============================] - 0s 195us/step - loss: 0.0307 - accuracy: 0.9831 - val_loss: 3.8514 - val_accuracy: 0.4868\n",
      "Epoch 672/1000\n",
      "177/177 [==============================] - 0s 116us/step - loss: 0.0301 - accuracy: 0.9887 - val_loss: 3.8641 - val_accuracy: 0.4868\n",
      "Epoch 673/1000\n",
      "177/177 [==============================] - 0s 121us/step - loss: 0.0309 - accuracy: 0.9887 - val_loss: 3.8776 - val_accuracy: 0.5000\n",
      "Epoch 674/1000\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.0305 - accuracy: 0.9887 - val_loss: 3.8703 - val_accuracy: 0.5000\n",
      "Epoch 675/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.0299 - accuracy: 0.9887 - val_loss: 3.8733 - val_accuracy: 0.4868\n",
      "Epoch 676/1000\n",
      "177/177 [==============================] - 0s 76us/step - loss: 0.0304 - accuracy: 0.9887 - val_loss: 3.8573 - val_accuracy: 0.4868\n",
      "Epoch 677/1000\n",
      "177/177 [==============================] - 0s 291us/step - loss: 0.0308 - accuracy: 0.9887 - val_loss: 3.8384 - val_accuracy: 0.5000\n",
      "Epoch 678/1000\n",
      "177/177 [==============================] - 0s 169us/step - loss: 0.0313 - accuracy: 0.9887 - val_loss: 3.8513 - val_accuracy: 0.5000\n",
      "Epoch 679/1000\n",
      "177/177 [==============================] - 0s 120us/step - loss: 0.0307 - accuracy: 0.9887 - val_loss: 3.8567 - val_accuracy: 0.4868\n",
      "Epoch 680/1000\n",
      "177/177 [==============================] - 0s 119us/step - loss: 0.0313 - accuracy: 0.9831 - val_loss: 3.8624 - val_accuracy: 0.5000\n",
      "Epoch 681/1000\n",
      "177/177 [==============================] - 0s 101us/step - loss: 0.0307 - accuracy: 0.9887 - val_loss: 3.8715 - val_accuracy: 0.5000\n",
      "Epoch 682/1000\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.0312 - accuracy: 0.9887 - val_loss: 3.8972 - val_accuracy: 0.5000\n",
      "Epoch 683/1000\n",
      "177/177 [==============================] - 0s 69us/step - loss: 0.0316 - accuracy: 0.9887 - val_loss: 3.9178 - val_accuracy: 0.4868\n",
      "Epoch 684/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.0302 - accuracy: 0.9887 - val_loss: 3.9025 - val_accuracy: 0.5000\n",
      "Epoch 685/1000\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.0310 - accuracy: 0.9831 - val_loss: 3.8667 - val_accuracy: 0.5000\n",
      "Epoch 686/1000\n",
      "177/177 [==============================] - 0s 95us/step - loss: 0.0307 - accuracy: 0.9831 - val_loss: 3.8730 - val_accuracy: 0.5000\n",
      "Epoch 687/1000\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.0308 - accuracy: 0.9887 - val_loss: 3.8836 - val_accuracy: 0.4868\n",
      "Epoch 688/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.0311 - accuracy: 0.9887 - val_loss: 3.8583 - val_accuracy: 0.4868\n",
      "Epoch 689/1000\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.0301 - accuracy: 0.9831 - val_loss: 3.8554 - val_accuracy: 0.5132\n",
      "Epoch 690/1000\n",
      "177/177 [==============================] - 0s 229us/step - loss: 0.0312 - accuracy: 0.9887 - val_loss: 3.8376 - val_accuracy: 0.5132\n",
      "Epoch 691/1000\n",
      "177/177 [==============================] - 0s 139us/step - loss: 0.0306 - accuracy: 0.9887 - val_loss: 3.8367 - val_accuracy: 0.5000\n",
      "Epoch 692/1000\n",
      "177/177 [==============================] - 0s 133us/step - loss: 0.0304 - accuracy: 0.9831 - val_loss: 3.8398 - val_accuracy: 0.5000\n",
      "Epoch 693/1000\n",
      "177/177 [==============================] - 0s 86us/step - loss: 0.0301 - accuracy: 0.9887 - val_loss: 3.8535 - val_accuracy: 0.5000\n",
      "Epoch 694/1000\n",
      "177/177 [==============================] - 0s 91us/step - loss: 0.0302 - accuracy: 0.9887 - val_loss: 3.8558 - val_accuracy: 0.5132\n",
      "Epoch 695/1000\n",
      "177/177 [==============================] - 0s 130us/step - loss: 0.0305 - accuracy: 0.9887 - val_loss: 3.8665 - val_accuracy: 0.5132\n",
      "Epoch 696/1000\n",
      "177/177 [==============================] - 0s 97us/step - loss: 0.0299 - accuracy: 0.9887 - val_loss: 3.8743 - val_accuracy: 0.5000\n",
      "Epoch 697/1000\n",
      "177/177 [==============================] - 0s 78us/step - loss: 0.0298 - accuracy: 0.9887 - val_loss: 3.8686 - val_accuracy: 0.5000\n",
      "Epoch 698/1000\n",
      "177/177 [==============================] - 0s 89us/step - loss: 0.0303 - accuracy: 0.9831 - val_loss: 3.8611 - val_accuracy: 0.5000\n",
      "Epoch 699/1000\n",
      "177/177 [==============================] - 0s 104us/step - loss: 0.0302 - accuracy: 0.9887 - val_loss: 3.8525 - val_accuracy: 0.5000\n",
      "Epoch 700/1000\n",
      "177/177 [==============================] - 0s 130us/step - loss: 0.0308 - accuracy: 0.9887 - val_loss: 3.8597 - val_accuracy: 0.5000\n",
      "Epoch 701/1000\n",
      "177/177 [==============================] - 0s 130us/step - loss: 0.0302 - accuracy: 0.9887 - val_loss: 3.8502 - val_accuracy: 0.5132\n",
      "Epoch 702/1000\n",
      "177/177 [==============================] - 0s 139us/step - loss: 0.0298 - accuracy: 0.9887 - val_loss: 3.8686 - val_accuracy: 0.5132\n",
      "Epoch 703/1000\n",
      "177/177 [==============================] - 0s 108us/step - loss: 0.0297 - accuracy: 0.9887 - val_loss: 3.8707 - val_accuracy: 0.5000\n",
      "Epoch 704/1000\n",
      "177/177 [==============================] - 0s 411us/step - loss: 0.0297 - accuracy: 0.9887 - val_loss: 3.8662 - val_accuracy: 0.5000\n",
      "Epoch 705/1000\n",
      "177/177 [==============================] - 0s 84us/step - loss: 0.0297 - accuracy: 0.9887 - val_loss: 3.8842 - val_accuracy: 0.5000\n",
      "Epoch 706/1000\n",
      "177/177 [==============================] - 0s 82us/step - loss: 0.0297 - accuracy: 0.9887 - val_loss: 3.8824 - val_accuracy: 0.5000\n",
      "Epoch 707/1000\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.0300 - accuracy: 0.9887 - val_loss: 3.8771 - val_accuracy: 0.5132\n",
      "Epoch 708/1000\n",
      "177/177 [==============================] - 0s 74us/step - loss: 0.0300 - accuracy: 0.9887 - val_loss: 3.8646 - val_accuracy: 0.5132\n",
      "Epoch 709/1000\n",
      "177/177 [==============================] - 0s 89us/step - loss: 0.0303 - accuracy: 0.9887 - val_loss: 3.8804 - val_accuracy: 0.5132\n",
      "Epoch 710/1000\n",
      "177/177 [==============================] - 0s 87us/step - loss: 0.0298 - accuracy: 0.9887 - val_loss: 3.8894 - val_accuracy: 0.4868\n",
      "Epoch 711/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.0299 - accuracy: 0.9887 - val_loss: 3.8932 - val_accuracy: 0.4868\n",
      "Epoch 712/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.0306 - accuracy: 0.9887 - val_loss: 3.8601 - val_accuracy: 0.5132\n",
      "Epoch 713/1000\n",
      "177/177 [==============================] - 0s 76us/step - loss: 0.0306 - accuracy: 0.9887 - val_loss: 3.8762 - val_accuracy: 0.5132\n",
      "Epoch 714/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.0305 - accuracy: 0.9887 - val_loss: 3.8867 - val_accuracy: 0.5132\n",
      "Epoch 715/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.0298 - accuracy: 0.9887 - val_loss: 3.9086 - val_accuracy: 0.5000\n",
      "Epoch 716/1000\n",
      "177/177 [==============================] - 0s 69us/step - loss: 0.0303 - accuracy: 0.9887 - val_loss: 3.8943 - val_accuracy: 0.5000\n",
      "Epoch 717/1000\n",
      "177/177 [==============================] - 0s 91us/step - loss: 0.0298 - accuracy: 0.9887 - val_loss: 3.8928 - val_accuracy: 0.5000\n",
      "Epoch 718/1000\n",
      "177/177 [==============================] - ETA: 0s - loss: 0.0461 - accuracy: 0.98 - 0s 201us/step - loss: 0.0309 - accuracy: 0.9887 - val_loss: 3.8969 - val_accuracy: 0.5000\n",
      "Epoch 719/1000\n",
      "177/177 [==============================] - 0s 141us/step - loss: 0.0301 - accuracy: 0.9887 - val_loss: 3.9049 - val_accuracy: 0.5000\n",
      "Epoch 720/1000\n",
      "177/177 [==============================] - 0s 110us/step - loss: 0.0297 - accuracy: 0.9887 - val_loss: 3.9190 - val_accuracy: 0.4868\n",
      "Epoch 721/1000\n",
      "177/177 [==============================] - 0s 106us/step - loss: 0.0304 - accuracy: 0.9887 - val_loss: 3.9186 - val_accuracy: 0.4868\n",
      "Epoch 722/1000\n",
      "177/177 [==============================] - 0s 92us/step - loss: 0.0297 - accuracy: 0.9887 - val_loss: 3.8733 - val_accuracy: 0.5000\n",
      "Epoch 723/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177/177 [==============================] - 0s 77us/step - loss: 0.0317 - accuracy: 0.9887 - val_loss: 3.8484 - val_accuracy: 0.5000\n",
      "Epoch 724/1000\n",
      "177/177 [==============================] - 0s 96us/step - loss: 0.0303 - accuracy: 0.9887 - val_loss: 3.8826 - val_accuracy: 0.5132\n",
      "Epoch 725/1000\n",
      "177/177 [==============================] - 0s 78us/step - loss: 0.0306 - accuracy: 0.9831 - val_loss: 3.9140 - val_accuracy: 0.5000\n",
      "Epoch 726/1000\n",
      "177/177 [==============================] - 0s 91us/step - loss: 0.0361 - accuracy: 0.9774 - val_loss: 3.8274 - val_accuracy: 0.5132\n",
      "Epoch 727/1000\n",
      "177/177 [==============================] - 0s 84us/step - loss: 0.0741 - accuracy: 0.9774 - val_loss: 3.8109 - val_accuracy: 0.5000\n",
      "Epoch 728/1000\n",
      "177/177 [==============================] - 0s 74us/step - loss: 0.0308 - accuracy: 0.9887 - val_loss: 3.9447 - val_accuracy: 0.5263\n",
      "Epoch 729/1000\n",
      "177/177 [==============================] - 0s 123us/step - loss: 0.0622 - accuracy: 0.9774 - val_loss: 3.7550 - val_accuracy: 0.5000\n",
      "Epoch 730/1000\n",
      "177/177 [==============================] - 0s 87us/step - loss: 0.1305 - accuracy: 0.9548 - val_loss: 3.7897 - val_accuracy: 0.5000\n",
      "Epoch 731/1000\n",
      "177/177 [==============================] - 0s 333us/step - loss: 0.0456 - accuracy: 0.9831 - val_loss: 3.9634 - val_accuracy: 0.5263\n",
      "Epoch 732/1000\n",
      "177/177 [==============================] - 0s 107us/step - loss: 0.0301 - accuracy: 0.9887 - val_loss: 3.8583 - val_accuracy: 0.5132\n",
      "Epoch 733/1000\n",
      "177/177 [==============================] - 0s 82us/step - loss: 0.0399 - accuracy: 0.9774 - val_loss: 3.9290 - val_accuracy: 0.5263\n",
      "Epoch 734/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.0400 - accuracy: 0.9774 - val_loss: 3.8194 - val_accuracy: 0.5263\n",
      "Epoch 735/1000\n",
      "177/177 [==============================] - 0s 79us/step - loss: 0.0353 - accuracy: 0.9887 - val_loss: 3.8327 - val_accuracy: 0.5132\n",
      "Epoch 736/1000\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.0786 - accuracy: 0.9831 - val_loss: 3.9908 - val_accuracy: 0.5132\n",
      "Epoch 737/1000\n",
      "177/177 [==============================] - 0s 77us/step - loss: 0.0893 - accuracy: 0.9718 - val_loss: 3.9162 - val_accuracy: 0.5263\n",
      "Epoch 738/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.0365 - accuracy: 0.9831 - val_loss: 3.8647 - val_accuracy: 0.5263\n",
      "Epoch 739/1000\n",
      "177/177 [==============================] - 0s 68us/step - loss: 0.0330 - accuracy: 0.9831 - val_loss: 3.9622 - val_accuracy: 0.5132\n",
      "Epoch 740/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.0538 - accuracy: 0.9774 - val_loss: 3.8353 - val_accuracy: 0.5132\n",
      "Epoch 741/1000\n",
      "177/177 [==============================] - 0s 132us/step - loss: 0.1148 - accuracy: 0.9774 - val_loss: 3.7642 - val_accuracy: 0.5132\n",
      "Epoch 742/1000\n",
      "177/177 [==============================] - 0s 76us/step - loss: 0.0342 - accuracy: 0.9887 - val_loss: 3.8698 - val_accuracy: 0.5132\n",
      "Epoch 743/1000\n",
      "177/177 [==============================] - 0s 74us/step - loss: 0.0468 - accuracy: 0.9718 - val_loss: 3.7025 - val_accuracy: 0.5263\n",
      "Epoch 744/1000\n",
      "177/177 [==============================] - 0s 76us/step - loss: 0.0426 - accuracy: 0.9887 - val_loss: 3.9214 - val_accuracy: 0.4868\n",
      "Epoch 745/1000\n",
      "177/177 [==============================] - 0s 99us/step - loss: 0.1627 - accuracy: 0.9661 - val_loss: 3.9093 - val_accuracy: 0.5132\n",
      "Epoch 746/1000\n",
      "177/177 [==============================] - 0s 92us/step - loss: 0.0719 - accuracy: 0.9774 - val_loss: 4.0100 - val_accuracy: 0.5132\n",
      "Epoch 747/1000\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.0355 - accuracy: 0.9774 - val_loss: 3.8609 - val_accuracy: 0.5263\n",
      "Epoch 748/1000\n",
      "177/177 [==============================] - 0s 125us/step - loss: 0.0905 - accuracy: 0.9718 - val_loss: 3.8898 - val_accuracy: 0.5263\n",
      "Epoch 749/1000\n",
      "177/177 [==============================] - 0s 112us/step - loss: 0.0547 - accuracy: 0.9774 - val_loss: 3.9026 - val_accuracy: 0.5132\n",
      "Epoch 750/1000\n",
      "177/177 [==============================] - 0s 124us/step - loss: 0.0513 - accuracy: 0.9774 - val_loss: 3.8042 - val_accuracy: 0.5263\n",
      "Epoch 751/1000\n",
      "177/177 [==============================] - 0s 177us/step - loss: 0.0505 - accuracy: 0.9774 - val_loss: 3.8793 - val_accuracy: 0.5132\n",
      "Epoch 752/1000\n",
      "177/177 [==============================] - 0s 135us/step - loss: 0.0366 - accuracy: 0.9774 - val_loss: 3.8421 - val_accuracy: 0.5132\n",
      "Epoch 753/1000\n",
      "177/177 [==============================] - 0s 138us/step - loss: 0.0886 - accuracy: 0.9774 - val_loss: 3.8285 - val_accuracy: 0.5263\n",
      "Epoch 754/1000\n",
      "177/177 [==============================] - 0s 69us/step - loss: 0.0342 - accuracy: 0.9831 - val_loss: 4.1605 - val_accuracy: 0.5263\n",
      "Epoch 755/1000\n",
      "177/177 [==============================] - 0s 221us/step - loss: 0.2181 - accuracy: 0.9718 - val_loss: 3.7391 - val_accuracy: 0.5263\n",
      "Epoch 756/1000\n",
      "177/177 [==============================] - 0s 208us/step - loss: 0.0390 - accuracy: 0.9887 - val_loss: 3.8268 - val_accuracy: 0.5000\n",
      "Epoch 757/1000\n",
      "177/177 [==============================] - 0s 152us/step - loss: 0.0951 - accuracy: 0.9774 - val_loss: 3.9269 - val_accuracy: 0.5132\n",
      "Epoch 758/1000\n",
      "177/177 [==============================] - 0s 143us/step - loss: 0.0573 - accuracy: 0.9774 - val_loss: 3.9772 - val_accuracy: 0.5132\n",
      "Epoch 759/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.0319 - accuracy: 0.9831 - val_loss: 3.9152 - val_accuracy: 0.5263\n",
      "Epoch 760/1000\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.0348 - accuracy: 0.9887 - val_loss: 3.8985 - val_accuracy: 0.5263\n",
      "Epoch 761/1000\n",
      "177/177 [==============================] - 0s 77us/step - loss: 0.0324 - accuracy: 0.9831 - val_loss: 3.9061 - val_accuracy: 0.5263\n",
      "Epoch 762/1000\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.0313 - accuracy: 0.9831 - val_loss: 3.9197 - val_accuracy: 0.5263\n",
      "Epoch 763/1000\n",
      "177/177 [==============================] - 0s 120us/step - loss: 0.0307 - accuracy: 0.9831 - val_loss: 3.9401 - val_accuracy: 0.5263\n",
      "Epoch 764/1000\n",
      "177/177 [==============================] - 0s 89us/step - loss: 0.0314 - accuracy: 0.9831 - val_loss: 3.9336 - val_accuracy: 0.5263\n",
      "Epoch 765/1000\n",
      "177/177 [==============================] - 0s 388us/step - loss: 0.0310 - accuracy: 0.9774 - val_loss: 3.9320 - val_accuracy: 0.5263\n",
      "Epoch 766/1000\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.0300 - accuracy: 0.9887 - val_loss: 3.9296 - val_accuracy: 0.5132\n",
      "Epoch 767/1000\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.0299 - accuracy: 0.9887 - val_loss: 3.9398 - val_accuracy: 0.5000\n",
      "Epoch 768/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.0297 - accuracy: 0.9887 - val_loss: 3.9334 - val_accuracy: 0.5000\n",
      "Epoch 769/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.0292 - accuracy: 0.9887 - val_loss: 3.9422 - val_accuracy: 0.5000\n",
      "Epoch 770/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.0294 - accuracy: 0.9887 - val_loss: 3.9645 - val_accuracy: 0.5000\n",
      "Epoch 771/1000\n",
      "177/177 [==============================] - 0s 83us/step - loss: 0.0299 - accuracy: 0.9887 - val_loss: 3.9900 - val_accuracy: 0.5000\n",
      "Epoch 772/1000\n",
      "177/177 [==============================] - 0s 59us/step - loss: 0.0297 - accuracy: 0.9887 - val_loss: 3.9926 - val_accuracy: 0.5000\n",
      "Epoch 773/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.0297 - accuracy: 0.9887 - val_loss: 3.9955 - val_accuracy: 0.5000\n",
      "Epoch 774/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.0290 - accuracy: 0.9887 - val_loss: 3.9871 - val_accuracy: 0.5000\n",
      "Epoch 775/1000\n",
      "177/177 [==============================] - 0s 68us/step - loss: 0.0288 - accuracy: 0.9887 - val_loss: 3.9901 - val_accuracy: 0.5000\n",
      "Epoch 776/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.0306 - accuracy: 0.9887 - val_loss: 3.9780 - val_accuracy: 0.5132\n",
      "Epoch 777/1000\n",
      "177/177 [==============================] - 0s 371us/step - loss: 0.0297 - accuracy: 0.9887 - val_loss: 3.9695 - val_accuracy: 0.5000\n",
      "Epoch 778/1000\n",
      "177/177 [==============================] - 0s 103us/step - loss: 0.0293 - accuracy: 0.9887 - val_loss: 3.9704 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 779/1000\n",
      "177/177 [==============================] - 0s 70us/step - loss: 0.0289 - accuracy: 0.9887 - val_loss: 3.9623 - val_accuracy: 0.5000\n",
      "Epoch 780/1000\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.0292 - accuracy: 0.9887 - val_loss: 3.9731 - val_accuracy: 0.5000\n",
      "Epoch 781/1000\n",
      "177/177 [==============================] - 0s 84us/step - loss: 0.0294 - accuracy: 0.9887 - val_loss: 3.9936 - val_accuracy: 0.5000\n",
      "Epoch 782/1000\n",
      "177/177 [==============================] - 0s 140us/step - loss: 0.0293 - accuracy: 0.9887 - val_loss: 4.0254 - val_accuracy: 0.5000\n",
      "Epoch 783/1000\n",
      "177/177 [==============================] - 0s 113us/step - loss: 0.0293 - accuracy: 0.9887 - val_loss: 4.0228 - val_accuracy: 0.5000\n",
      "Epoch 784/1000\n",
      "177/177 [==============================] - 0s 97us/step - loss: 0.0289 - accuracy: 0.9887 - val_loss: 4.0168 - val_accuracy: 0.5000\n",
      "Epoch 785/1000\n",
      "177/177 [==============================] - 0s 79us/step - loss: 0.0290 - accuracy: 0.9887 - val_loss: 4.0166 - val_accuracy: 0.5000\n",
      "Epoch 786/1000\n",
      "177/177 [==============================] - 0s 128us/step - loss: 0.0289 - accuracy: 0.9887 - val_loss: 4.0257 - val_accuracy: 0.5000\n",
      "Epoch 787/1000\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.0294 - accuracy: 0.9887 - val_loss: 4.0187 - val_accuracy: 0.5000\n",
      "Epoch 788/1000\n",
      "177/177 [==============================] - 0s 112us/step - loss: 0.0297 - accuracy: 0.9887 - val_loss: 4.0038 - val_accuracy: 0.5000\n",
      "Epoch 789/1000\n",
      "177/177 [==============================] - 0s 79us/step - loss: 0.0287 - accuracy: 0.9887 - val_loss: 4.0128 - val_accuracy: 0.5000\n",
      "Epoch 790/1000\n",
      "177/177 [==============================] - 0s 104us/step - loss: 0.0294 - accuracy: 0.9887 - val_loss: 4.0177 - val_accuracy: 0.5000\n",
      "Epoch 791/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.0297 - accuracy: 0.9887 - val_loss: 4.0449 - val_accuracy: 0.5000\n",
      "Epoch 792/1000\n",
      "177/177 [==============================] - 0s 63us/step - loss: 0.0290 - accuracy: 0.9887 - val_loss: 4.0473 - val_accuracy: 0.5000\n",
      "Epoch 793/1000\n",
      "177/177 [==============================] - 0s 76us/step - loss: 0.0297 - accuracy: 0.9887 - val_loss: 4.0300 - val_accuracy: 0.5000\n",
      "Epoch 794/1000\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.0284 - accuracy: 0.9887 - val_loss: 4.0133 - val_accuracy: 0.5000\n",
      "Epoch 795/1000\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.0286 - accuracy: 0.9887 - val_loss: 4.0085 - val_accuracy: 0.5000\n",
      "Epoch 796/1000\n",
      "177/177 [==============================] - 0s 121us/step - loss: 0.0291 - accuracy: 0.9887 - val_loss: 4.0042 - val_accuracy: 0.5000\n",
      "Epoch 797/1000\n",
      "177/177 [==============================] - 0s 95us/step - loss: 0.0288 - accuracy: 0.9887 - val_loss: 4.0147 - val_accuracy: 0.5000\n",
      "Epoch 798/1000\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.0284 - accuracy: 0.9887 - val_loss: 4.0301 - val_accuracy: 0.5000\n",
      "Epoch 799/1000\n",
      "177/177 [==============================] - 0s 96us/step - loss: 0.0288 - accuracy: 0.9887 - val_loss: 4.0490 - val_accuracy: 0.4868\n",
      "Epoch 800/1000\n",
      "177/177 [==============================] - 0s 89us/step - loss: 0.0285 - accuracy: 0.9887 - val_loss: 4.0570 - val_accuracy: 0.5000\n",
      "Epoch 801/1000\n",
      "177/177 [==============================] - 0s 102us/step - loss: 0.0285 - accuracy: 0.9887 - val_loss: 4.0559 - val_accuracy: 0.5000\n",
      "Epoch 802/1000\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.0288 - accuracy: 0.9887 - val_loss: 4.0571 - val_accuracy: 0.5000\n",
      "Epoch 803/1000\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.0292 - accuracy: 0.9887 - val_loss: 4.0613 - val_accuracy: 0.4868\n",
      "Epoch 804/1000\n",
      "177/177 [==============================] - 0s 93us/step - loss: 0.0291 - accuracy: 0.9887 - val_loss: 4.0416 - val_accuracy: 0.5000\n",
      "Epoch 805/1000\n",
      "177/177 [==============================] - 0s 86us/step - loss: 0.0283 - accuracy: 0.9887 - val_loss: 4.0280 - val_accuracy: 0.5000\n",
      "Epoch 806/1000\n",
      "177/177 [==============================] - 0s 70us/step - loss: 0.0285 - accuracy: 0.9887 - val_loss: 4.0256 - val_accuracy: 0.5000\n",
      "Epoch 807/1000\n",
      "177/177 [==============================] - 0s 96us/step - loss: 0.0287 - accuracy: 0.9831 - val_loss: 4.0393 - val_accuracy: 0.5000\n",
      "Epoch 808/1000\n",
      "177/177 [==============================] - 0s 100us/step - loss: 0.0285 - accuracy: 0.9831 - val_loss: 4.0415 - val_accuracy: 0.4868\n",
      "Epoch 809/1000\n",
      "177/177 [==============================] - 0s 78us/step - loss: 0.0285 - accuracy: 0.9887 - val_loss: 4.0461 - val_accuracy: 0.4868\n",
      "Epoch 810/1000\n",
      "177/177 [==============================] - 0s 77us/step - loss: 0.0292 - accuracy: 0.9831 - val_loss: 4.0561 - val_accuracy: 0.4868\n",
      "Epoch 811/1000\n",
      "177/177 [==============================] - 0s 97us/step - loss: 0.0284 - accuracy: 0.9887 - val_loss: 4.0464 - val_accuracy: 0.5000\n",
      "Epoch 812/1000\n",
      "177/177 [==============================] - 0s 133us/step - loss: 0.0285 - accuracy: 0.9887 - val_loss: 4.0403 - val_accuracy: 0.5000\n",
      "Epoch 813/1000\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.0285 - accuracy: 0.9887 - val_loss: 4.0663 - val_accuracy: 0.5000\n",
      "Epoch 814/1000\n",
      "177/177 [==============================] - 0s 86us/step - loss: 0.0287 - accuracy: 0.9887 - val_loss: 4.0831 - val_accuracy: 0.4868\n",
      "Epoch 815/1000\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.0288 - accuracy: 0.9887 - val_loss: 4.0802 - val_accuracy: 0.4868\n",
      "Epoch 816/1000\n",
      "177/177 [==============================] - 0s 83us/step - loss: 0.0286 - accuracy: 0.9887 - val_loss: 4.0679 - val_accuracy: 0.5000\n",
      "Epoch 817/1000\n",
      "177/177 [==============================] - 0s 94us/step - loss: 0.0289 - accuracy: 0.9887 - val_loss: 4.0714 - val_accuracy: 0.5000\n",
      "Epoch 818/1000\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.0287 - accuracy: 0.9831 - val_loss: 4.0680 - val_accuracy: 0.5000\n",
      "Epoch 819/1000\n",
      "177/177 [==============================] - 0s 83us/step - loss: 0.0281 - accuracy: 0.9887 - val_loss: 4.0730 - val_accuracy: 0.4868\n",
      "Epoch 820/1000\n",
      "177/177 [==============================] - 0s 82us/step - loss: 0.0285 - accuracy: 0.9887 - val_loss: 4.0830 - val_accuracy: 0.4868\n",
      "Epoch 821/1000\n",
      "177/177 [==============================] - 0s 118us/step - loss: 0.0288 - accuracy: 0.9887 - val_loss: 4.0830 - val_accuracy: 0.4868\n",
      "Epoch 822/1000\n",
      "177/177 [==============================] - 0s 70us/step - loss: 0.0290 - accuracy: 0.9831 - val_loss: 4.0759 - val_accuracy: 0.5000\n",
      "Epoch 823/1000\n",
      "177/177 [==============================] - 0s 69us/step - loss: 0.0285 - accuracy: 0.9887 - val_loss: 4.0752 - val_accuracy: 0.5000\n",
      "Epoch 824/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.0280 - accuracy: 0.9887 - val_loss: 4.0696 - val_accuracy: 0.5000\n",
      "Epoch 825/1000\n",
      "177/177 [==============================] - 0s 87us/step - loss: 0.0282 - accuracy: 0.9887 - val_loss: 4.0656 - val_accuracy: 0.4868\n",
      "Epoch 826/1000\n",
      "177/177 [==============================] - 0s 70us/step - loss: 0.0284 - accuracy: 0.9887 - val_loss: 4.0878 - val_accuracy: 0.4868\n",
      "Epoch 827/1000\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.0284 - accuracy: 0.9887 - val_loss: 4.0901 - val_accuracy: 0.5000\n",
      "Epoch 828/1000\n",
      "177/177 [==============================] - 0s 82us/step - loss: 0.0280 - accuracy: 0.9887 - val_loss: 4.0936 - val_accuracy: 0.5000\n",
      "Epoch 829/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.0281 - accuracy: 0.9887 - val_loss: 4.1012 - val_accuracy: 0.4868\n",
      "Epoch 830/1000\n",
      "177/177 [==============================] - 0s 130us/step - loss: 0.0286 - accuracy: 0.9887 - val_loss: 4.1112 - val_accuracy: 0.4868\n",
      "Epoch 831/1000\n",
      "177/177 [==============================] - 0s 85us/step - loss: 0.0289 - accuracy: 0.9831 - val_loss: 4.0856 - val_accuracy: 0.4868\n",
      "Epoch 832/1000\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.0283 - accuracy: 0.9887 - val_loss: 4.0893 - val_accuracy: 0.4868\n",
      "Epoch 833/1000\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.0287 - accuracy: 0.9831 - val_loss: 4.0907 - val_accuracy: 0.4868\n",
      "Epoch 834/1000\n",
      "177/177 [==============================] - 0s 119us/step - loss: 0.0284 - accuracy: 0.9887 - val_loss: 4.0903 - val_accuracy: 0.5000\n",
      "Epoch 835/1000\n",
      "177/177 [==============================] - 0s 118us/step - loss: 0.0279 - accuracy: 0.9887 - val_loss: 4.0739 - val_accuracy: 0.5000\n",
      "Epoch 836/1000\n",
      "177/177 [==============================] - 0s 81us/step - loss: 0.0285 - accuracy: 0.9887 - val_loss: 4.0722 - val_accuracy: 0.4868\n",
      "Epoch 837/1000\n",
      "177/177 [==============================] - 0s 157us/step - loss: 0.0292 - accuracy: 0.9831 - val_loss: 4.0765 - val_accuracy: 0.4868\n",
      "Epoch 838/1000\n",
      "177/177 [==============================] - 0s 95us/step - loss: 0.0286 - accuracy: 0.9887 - val_loss: 4.0978 - val_accuracy: 0.4868\n",
      "Epoch 839/1000\n",
      "177/177 [==============================] - 0s 117us/step - loss: 0.0279 - accuracy: 0.9887 - val_loss: 4.1086 - val_accuracy: 0.4868\n",
      "Epoch 840/1000\n",
      "177/177 [==============================] - 0s 78us/step - loss: 0.0281 - accuracy: 0.9887 - val_loss: 4.1025 - val_accuracy: 0.4868\n",
      "Epoch 841/1000\n",
      "177/177 [==============================] - 0s 85us/step - loss: 0.0285 - accuracy: 0.9887 - val_loss: 4.1003 - val_accuracy: 0.4868\n",
      "Epoch 842/1000\n",
      "177/177 [==============================] - 0s 70us/step - loss: 0.0278 - accuracy: 0.9887 - val_loss: 4.0920 - val_accuracy: 0.5000\n",
      "Epoch 843/1000\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.0278 - accuracy: 0.9887 - val_loss: 4.0939 - val_accuracy: 0.5000\n",
      "Epoch 844/1000\n",
      "177/177 [==============================] - 0s 99us/step - loss: 0.0280 - accuracy: 0.9887 - val_loss: 4.1005 - val_accuracy: 0.4868\n",
      "Epoch 845/1000\n",
      "177/177 [==============================] - 0s 135us/step - loss: 0.0278 - accuracy: 0.9887 - val_loss: 4.1058 - val_accuracy: 0.4868\n",
      "Epoch 846/1000\n",
      "177/177 [==============================] - 0s 84us/step - loss: 0.0286 - accuracy: 0.9887 - val_loss: 4.0988 - val_accuracy: 0.4868\n",
      "Epoch 847/1000\n",
      "177/177 [==============================] - 0s 99us/step - loss: 0.0290 - accuracy: 0.9831 - val_loss: 4.0754 - val_accuracy: 0.4868\n",
      "Epoch 848/1000\n",
      "177/177 [==============================] - 0s 85us/step - loss: 0.0276 - accuracy: 0.9887 - val_loss: 4.0847 - val_accuracy: 0.4868\n",
      "Epoch 849/1000\n",
      "177/177 [==============================] - 0s 151us/step - loss: 0.0276 - accuracy: 0.9887 - val_loss: 4.1015 - val_accuracy: 0.4868\n",
      "Epoch 850/1000\n",
      "177/177 [==============================] - 0s 95us/step - loss: 0.0282 - accuracy: 0.9887 - val_loss: 4.0977 - val_accuracy: 0.4868\n",
      "Epoch 851/1000\n",
      "177/177 [==============================] - 0s 99us/step - loss: 0.0283 - accuracy: 0.9831 - val_loss: 4.0875 - val_accuracy: 0.4868\n",
      "Epoch 852/1000\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.0283 - accuracy: 0.9887 - val_loss: 4.0824 - val_accuracy: 0.5000\n",
      "Epoch 853/1000\n",
      "177/177 [==============================] - 0s 104us/step - loss: 0.0281 - accuracy: 0.9887 - val_loss: 4.1048 - val_accuracy: 0.4868\n",
      "Epoch 854/1000\n",
      "177/177 [==============================] - 0s 81us/step - loss: 0.0290 - accuracy: 0.9831 - val_loss: 4.1139 - val_accuracy: 0.4868\n",
      "Epoch 855/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.0286 - accuracy: 0.9887 - val_loss: 4.1020 - val_accuracy: 0.4868\n",
      "Epoch 856/1000\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.0296 - accuracy: 0.9831 - val_loss: 4.0941 - val_accuracy: 0.4868\n",
      "Epoch 857/1000\n",
      "177/177 [==============================] - 0s 136us/step - loss: 0.0277 - accuracy: 0.9887 - val_loss: 4.0925 - val_accuracy: 0.5000\n",
      "Epoch 858/1000\n",
      "177/177 [==============================] - 0s 77us/step - loss: 0.0280 - accuracy: 0.9887 - val_loss: 4.0983 - val_accuracy: 0.5000\n",
      "Epoch 859/1000\n",
      "177/177 [==============================] - 0s 92us/step - loss: 0.0277 - accuracy: 0.9887 - val_loss: 4.1003 - val_accuracy: 0.4868\n",
      "Epoch 860/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.0283 - accuracy: 0.9831 - val_loss: 4.1177 - val_accuracy: 0.4868\n",
      "Epoch 861/1000\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.0279 - accuracy: 0.9887 - val_loss: 4.1135 - val_accuracy: 0.4868\n",
      "Epoch 862/1000\n",
      "177/177 [==============================] - 0s 127us/step - loss: 0.0275 - accuracy: 0.9887 - val_loss: 4.1145 - val_accuracy: 0.4868\n",
      "Epoch 863/1000\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.0284 - accuracy: 0.9887 - val_loss: 4.1228 - val_accuracy: 0.5000\n",
      "Epoch 864/1000\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.0280 - accuracy: 0.9887 - val_loss: 4.1379 - val_accuracy: 0.4868\n",
      "Epoch 865/1000\n",
      "177/177 [==============================] - 0s 78us/step - loss: 0.0280 - accuracy: 0.9887 - val_loss: 4.1455 - val_accuracy: 0.4868\n",
      "Epoch 866/1000\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.0275 - accuracy: 0.9887 - val_loss: 4.1439 - val_accuracy: 0.4868\n",
      "Epoch 867/1000\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.0282 - accuracy: 0.9887 - val_loss: 4.1421 - val_accuracy: 0.5000\n",
      "Epoch 868/1000\n",
      "177/177 [==============================] - 0s 68us/step - loss: 0.0278 - accuracy: 0.9887 - val_loss: 4.1402 - val_accuracy: 0.4868\n",
      "Epoch 869/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.0284 - accuracy: 0.9831 - val_loss: 4.1292 - val_accuracy: 0.4868\n",
      "Epoch 870/1000\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.0289 - accuracy: 0.9887 - val_loss: 4.1252 - val_accuracy: 0.4868\n",
      "Epoch 871/1000\n",
      "177/177 [==============================] - 0s 84us/step - loss: 0.0280 - accuracy: 0.9887 - val_loss: 4.1223 - val_accuracy: 0.4868\n",
      "Epoch 872/1000\n",
      "177/177 [==============================] - 0s 68us/step - loss: 0.0277 - accuracy: 0.9887 - val_loss: 4.1117 - val_accuracy: 0.4868\n",
      "Epoch 873/1000\n",
      "177/177 [==============================] - 0s 91us/step - loss: 0.0277 - accuracy: 0.9887 - val_loss: 4.1103 - val_accuracy: 0.4868\n",
      "Epoch 874/1000\n",
      "177/177 [==============================] - 0s 75us/step - loss: 0.0281 - accuracy: 0.9887 - val_loss: 4.1314 - val_accuracy: 0.4868\n",
      "Epoch 875/1000\n",
      "177/177 [==============================] - 0s 78us/step - loss: 0.0282 - accuracy: 0.9887 - val_loss: 4.1115 - val_accuracy: 0.5000\n",
      "Epoch 876/1000\n",
      "177/177 [==============================] - 0s 74us/step - loss: 0.0277 - accuracy: 0.9887 - val_loss: 4.1131 - val_accuracy: 0.5000\n",
      "Epoch 877/1000\n",
      "177/177 [==============================] - 0s 76us/step - loss: 0.0277 - accuracy: 0.9887 - val_loss: 4.1124 - val_accuracy: 0.4868\n",
      "Epoch 878/1000\n",
      "177/177 [==============================] - 0s 78us/step - loss: 0.0276 - accuracy: 0.9887 - val_loss: 4.1353 - val_accuracy: 0.4868\n",
      "Epoch 879/1000\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.0279 - accuracy: 0.9887 - val_loss: 4.1285 - val_accuracy: 0.4868\n",
      "Epoch 880/1000\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.0280 - accuracy: 0.9887 - val_loss: 4.1131 - val_accuracy: 0.4868\n",
      "Epoch 881/1000\n",
      "177/177 [==============================] - 0s 81us/step - loss: 0.0282 - accuracy: 0.9887 - val_loss: 4.1162 - val_accuracy: 0.5000\n",
      "Epoch 882/1000\n",
      "177/177 [==============================] - 0s 96us/step - loss: 0.0276 - accuracy: 0.9887 - val_loss: 4.1277 - val_accuracy: 0.4868\n",
      "Epoch 883/1000\n",
      "177/177 [==============================] - 0s 96us/step - loss: 0.0279 - accuracy: 0.9831 - val_loss: 4.1525 - val_accuracy: 0.4868\n",
      "Epoch 884/1000\n",
      "177/177 [==============================] - 0s 177us/step - loss: 0.0274 - accuracy: 0.9887 - val_loss: 4.1607 - val_accuracy: 0.4868\n",
      "Epoch 885/1000\n",
      "177/177 [==============================] - 0s 241us/step - loss: 0.0280 - accuracy: 0.9831 - val_loss: 4.1452 - val_accuracy: 0.4868\n",
      "Epoch 886/1000\n",
      "177/177 [==============================] - 0s 237us/step - loss: 0.0276 - accuracy: 0.9887 - val_loss: 4.1165 - val_accuracy: 0.4868\n",
      "Epoch 887/1000\n",
      "177/177 [==============================] - 0s 150us/step - loss: 0.0276 - accuracy: 0.9887 - val_loss: 4.0980 - val_accuracy: 0.5000\n",
      "Epoch 888/1000\n",
      "177/177 [==============================] - ETA: 0s - loss: 0.0153 - accuracy: 1.00 - 0s 156us/step - loss: 0.0281 - accuracy: 0.9887 - val_loss: 4.1274 - val_accuracy: 0.4868\n",
      "Epoch 889/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177/177 [==============================] - 0s 142us/step - loss: 0.0276 - accuracy: 0.9887 - val_loss: 4.1553 - val_accuracy: 0.4868\n",
      "Epoch 890/1000\n",
      "177/177 [==============================] - 0s 100us/step - loss: 0.0274 - accuracy: 0.9887 - val_loss: 4.1906 - val_accuracy: 0.4868\n",
      "Epoch 891/1000\n",
      "177/177 [==============================] - 0s 135us/step - loss: 0.0281 - accuracy: 0.9887 - val_loss: 4.2048 - val_accuracy: 0.4868\n",
      "Epoch 892/1000\n",
      "177/177 [==============================] - 0s 85us/step - loss: 0.0286 - accuracy: 0.9831 - val_loss: 4.1749 - val_accuracy: 0.5000\n",
      "Epoch 893/1000\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.0278 - accuracy: 0.9831 - val_loss: 4.1481 - val_accuracy: 0.5000\n",
      "Epoch 894/1000\n",
      "177/177 [==============================] - 0s 75us/step - loss: 0.0273 - accuracy: 0.9887 - val_loss: 4.1521 - val_accuracy: 0.4868\n",
      "Epoch 895/1000\n",
      "177/177 [==============================] - 0s 104us/step - loss: 0.0275 - accuracy: 0.9887 - val_loss: 4.1469 - val_accuracy: 0.4868\n",
      "Epoch 896/1000\n",
      "177/177 [==============================] - 0s 108us/step - loss: 0.0272 - accuracy: 0.9887 - val_loss: 4.1442 - val_accuracy: 0.4868\n",
      "Epoch 897/1000\n",
      "177/177 [==============================] - 0s 151us/step - loss: 0.0280 - accuracy: 0.9887 - val_loss: 4.1453 - val_accuracy: 0.4868\n",
      "Epoch 898/1000\n",
      "177/177 [==============================] - 0s 160us/step - loss: 0.0274 - accuracy: 0.9887 - val_loss: 4.1540 - val_accuracy: 0.4868\n",
      "Epoch 899/1000\n",
      "177/177 [==============================] - 0s 94us/step - loss: 0.0277 - accuracy: 0.9831 - val_loss: 4.1461 - val_accuracy: 0.4868\n",
      "Epoch 900/1000\n",
      "177/177 [==============================] - 0s 76us/step - loss: 0.0278 - accuracy: 0.9887 - val_loss: 4.1509 - val_accuracy: 0.4868\n",
      "Epoch 901/1000\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.0274 - accuracy: 0.9887 - val_loss: 4.1674 - val_accuracy: 0.4868\n",
      "Epoch 902/1000\n",
      "177/177 [==============================] - 0s 92us/step - loss: 0.0272 - accuracy: 0.9887 - val_loss: 4.1738 - val_accuracy: 0.4868\n",
      "Epoch 903/1000\n",
      "177/177 [==============================] - 0s 103us/step - loss: 0.0272 - accuracy: 0.9887 - val_loss: 4.1736 - val_accuracy: 0.4868\n",
      "Epoch 904/1000\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.0275 - accuracy: 0.9887 - val_loss: 4.1682 - val_accuracy: 0.4868\n",
      "Epoch 905/1000\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.0274 - accuracy: 0.9887 - val_loss: 4.1590 - val_accuracy: 0.4868\n",
      "Epoch 906/1000\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.0284 - accuracy: 0.9887 - val_loss: 4.1447 - val_accuracy: 0.5000\n",
      "Epoch 907/1000\n",
      "177/177 [==============================] - 0s 87us/step - loss: 0.0278 - accuracy: 0.9887 - val_loss: 4.1490 - val_accuracy: 0.4868\n",
      "Epoch 908/1000\n",
      "177/177 [==============================] - 0s 104us/step - loss: 0.0270 - accuracy: 0.9887 - val_loss: 4.1685 - val_accuracy: 0.4868\n",
      "Epoch 909/1000\n",
      "177/177 [==============================] - ETA: 0s - loss: 0.0257 - accuracy: 1.00 - 0s 75us/step - loss: 0.0282 - accuracy: 0.9887 - val_loss: 4.1647 - val_accuracy: 0.4868\n",
      "Epoch 910/1000\n",
      "177/177 [==============================] - 0s 111us/step - loss: 0.0276 - accuracy: 0.9887 - val_loss: 4.1229 - val_accuracy: 0.5000\n",
      "Epoch 911/1000\n",
      "177/177 [==============================] - 0s 89us/step - loss: 0.0288 - accuracy: 0.9831 - val_loss: 4.1214 - val_accuracy: 0.5000\n",
      "Epoch 912/1000\n",
      "177/177 [==============================] - 0s 191us/step - loss: 0.0282 - accuracy: 0.9887 - val_loss: 4.1514 - val_accuracy: 0.5000\n",
      "Epoch 913/1000\n",
      "177/177 [==============================] - 0s 253us/step - loss: 0.0272 - accuracy: 0.9887 - val_loss: 4.1870 - val_accuracy: 0.4868\n",
      "Epoch 914/1000\n",
      "177/177 [==============================] - 0s 117us/step - loss: 0.0303 - accuracy: 0.9831 - val_loss: 4.1484 - val_accuracy: 0.4868\n",
      "Epoch 915/1000\n",
      "177/177 [==============================] - 0s 270us/step - loss: 0.0284 - accuracy: 0.9831 - val_loss: 4.0756 - val_accuracy: 0.5000\n",
      "Epoch 916/1000\n",
      "177/177 [==============================] - 0s 153us/step - loss: 0.0628 - accuracy: 0.9831 - val_loss: 4.2061 - val_accuracy: 0.5132\n",
      "Epoch 917/1000\n",
      "177/177 [==============================] - 0s 204us/step - loss: 0.0605 - accuracy: 0.9774 - val_loss: 4.0303 - val_accuracy: 0.5000\n",
      "Epoch 918/1000\n",
      "177/177 [==============================] - 0s 315us/step - loss: 0.0948 - accuracy: 0.9774 - val_loss: 4.0648 - val_accuracy: 0.5132\n",
      "Epoch 919/1000\n",
      "177/177 [==============================] - 0s 77us/step - loss: 0.1099 - accuracy: 0.9774 - val_loss: 4.3306 - val_accuracy: 0.5132\n",
      "Epoch 920/1000\n",
      "177/177 [==============================] - 0s 92us/step - loss: 0.0688 - accuracy: 0.9774 - val_loss: 4.1762 - val_accuracy: 0.5000\n",
      "Epoch 921/1000\n",
      "177/177 [==============================] - 0s 102us/step - loss: 0.1820 - accuracy: 0.9605 - val_loss: 3.8962 - val_accuracy: 0.5263\n",
      "Epoch 922/1000\n",
      "177/177 [==============================] - 0s 325us/step - loss: 0.0347 - accuracy: 0.9831 - val_loss: 4.0478 - val_accuracy: 0.5263\n",
      "Epoch 923/1000\n",
      "177/177 [==============================] - 0s 265us/step - loss: 0.0579 - accuracy: 0.9718 - val_loss: 3.8890 - val_accuracy: 0.5395\n",
      "Epoch 924/1000\n",
      "177/177 [==============================] - 0s 252us/step - loss: 0.1409 - accuracy: 0.9774 - val_loss: 4.0644 - val_accuracy: 0.5263\n",
      "Epoch 925/1000\n",
      "177/177 [==============================] - 0s 472us/step - loss: 0.0936 - accuracy: 0.9831 - val_loss: 4.4974 - val_accuracy: 0.5263\n",
      "Epoch 926/1000\n",
      "177/177 [==============================] - 0s 433us/step - loss: 0.2593 - accuracy: 0.9718 - val_loss: 4.2138 - val_accuracy: 0.5132\n",
      "Epoch 927/1000\n",
      "177/177 [==============================] - 0s 168us/step - loss: 0.0667 - accuracy: 0.9718 - val_loss: 4.1625 - val_accuracy: 0.5000\n",
      "Epoch 928/1000\n",
      "177/177 [==============================] - 0s 204us/step - loss: 0.2629 - accuracy: 0.9548 - val_loss: 3.9585 - val_accuracy: 0.5132\n",
      "Epoch 929/1000\n",
      "177/177 [==============================] - 0s 231us/step - loss: 0.0450 - accuracy: 0.9718 - val_loss: 4.2233 - val_accuracy: 0.5132\n",
      "Epoch 930/1000\n",
      "177/177 [==============================] - 0s 453us/step - loss: 0.1265 - accuracy: 0.9718 - val_loss: 4.0261 - val_accuracy: 0.5263\n",
      "Epoch 931/1000\n",
      "177/177 [==============================] - 0s 189us/step - loss: 0.1028 - accuracy: 0.9774 - val_loss: 4.0661 - val_accuracy: 0.5263\n",
      "Epoch 932/1000\n",
      "177/177 [==============================] - 0s 79us/step - loss: 0.0654 - accuracy: 0.9718 - val_loss: 4.4755 - val_accuracy: 0.5132\n",
      "Epoch 933/1000\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.3436 - accuracy: 0.9718 - val_loss: 4.2966 - val_accuracy: 0.5132\n",
      "Epoch 934/1000\n",
      "177/177 [==============================] - 0s 125us/step - loss: 0.0519 - accuracy: 0.9718 - val_loss: 3.9108 - val_accuracy: 0.5263\n",
      "Epoch 935/1000\n",
      "177/177 [==============================] - 0s 122us/step - loss: 0.1378 - accuracy: 0.9718 - val_loss: 3.9314 - val_accuracy: 0.5263\n",
      "Epoch 936/1000\n",
      "177/177 [==============================] - 0s 103us/step - loss: 0.0925 - accuracy: 0.9718 - val_loss: 4.2840 - val_accuracy: 0.5132\n",
      "Epoch 937/1000\n",
      "177/177 [==============================] - 0s 120us/step - loss: 0.0495 - accuracy: 0.9774 - val_loss: 4.0881 - val_accuracy: 0.5263\n",
      "Epoch 938/1000\n",
      "177/177 [==============================] - 0s 162us/step - loss: 0.0658 - accuracy: 0.9774 - val_loss: 4.0789 - val_accuracy: 0.5263\n",
      "Epoch 939/1000\n",
      "177/177 [==============================] - 0s 197us/step - loss: 0.0325 - accuracy: 0.9831 - val_loss: 4.1616 - val_accuracy: 0.5132\n",
      "Epoch 940/1000\n",
      "177/177 [==============================] - 0s 220us/step - loss: 0.0338 - accuracy: 0.9831 - val_loss: 4.1830 - val_accuracy: 0.5132\n",
      "Epoch 941/1000\n",
      "177/177 [==============================] - 0s 79us/step - loss: 0.0600 - accuracy: 0.9774 - val_loss: 4.0061 - val_accuracy: 0.5132\n",
      "Epoch 942/1000\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.0620 - accuracy: 0.9774 - val_loss: 4.0124 - val_accuracy: 0.5263\n",
      "Epoch 943/1000\n",
      "177/177 [==============================] - 0s 70us/step - loss: 0.0293 - accuracy: 0.9887 - val_loss: 4.1284 - val_accuracy: 0.5263\n",
      "Epoch 944/1000\n",
      "177/177 [==============================] - 0s 78us/step - loss: 0.0303 - accuracy: 0.9831 - val_loss: 4.2227 - val_accuracy: 0.5132\n",
      "Epoch 945/1000\n",
      "177/177 [==============================] - 0s 103us/step - loss: 0.0385 - accuracy: 0.9774 - val_loss: 4.1403 - val_accuracy: 0.5395\n",
      "Epoch 946/1000\n",
      "177/177 [==============================] - 0s 68us/step - loss: 0.0348 - accuracy: 0.9887 - val_loss: 4.0722 - val_accuracy: 0.5263\n",
      "Epoch 947/1000\n",
      "177/177 [==============================] - 0s 59us/step - loss: 0.0297 - accuracy: 0.9887 - val_loss: 4.0912 - val_accuracy: 0.5263\n",
      "Epoch 948/1000\n",
      "177/177 [==============================] - 0s 76us/step - loss: 0.0295 - accuracy: 0.9831 - val_loss: 4.1457 - val_accuracy: 0.5132\n",
      "Epoch 949/1000\n",
      "177/177 [==============================] - 0s 76us/step - loss: 0.0315 - accuracy: 0.9831 - val_loss: 4.1218 - val_accuracy: 0.5132\n",
      "Epoch 950/1000\n",
      "177/177 [==============================] - 0s 91us/step - loss: 0.0291 - accuracy: 0.9887 - val_loss: 4.1053 - val_accuracy: 0.5000\n",
      "Epoch 951/1000\n",
      "177/177 [==============================] - 0s 74us/step - loss: 0.0290 - accuracy: 0.9887 - val_loss: 4.1328 - val_accuracy: 0.5000\n",
      "Epoch 952/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.0295 - accuracy: 0.9887 - val_loss: 4.1561 - val_accuracy: 0.5000\n",
      "Epoch 953/1000\n",
      "177/177 [==============================] - 0s 58us/step - loss: 0.0301 - accuracy: 0.9831 - val_loss: 4.1858 - val_accuracy: 0.5132\n",
      "Epoch 954/1000\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.0284 - accuracy: 0.9887 - val_loss: 4.1963 - val_accuracy: 0.5000\n",
      "Epoch 955/1000\n",
      "177/177 [==============================] - 0s 92us/step - loss: 0.0274 - accuracy: 0.9887 - val_loss: 4.2005 - val_accuracy: 0.5000\n",
      "Epoch 956/1000\n",
      "177/177 [==============================] - 0s 68us/step - loss: 0.0282 - accuracy: 0.9887 - val_loss: 4.1890 - val_accuracy: 0.5000\n",
      "Epoch 957/1000\n",
      "177/177 [==============================] - 0s 68us/step - loss: 0.0279 - accuracy: 0.9831 - val_loss: 4.1512 - val_accuracy: 0.5000\n",
      "Epoch 958/1000\n",
      "177/177 [==============================] - 0s 92us/step - loss: 0.0281 - accuracy: 0.9887 - val_loss: 4.1431 - val_accuracy: 0.5000\n",
      "Epoch 959/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.0283 - accuracy: 0.9887 - val_loss: 4.1444 - val_accuracy: 0.5000\n",
      "Epoch 960/1000\n",
      "177/177 [==============================] - 0s 75us/step - loss: 0.0286 - accuracy: 0.9831 - val_loss: 4.1564 - val_accuracy: 0.5000\n",
      "Epoch 961/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.0281 - accuracy: 0.9887 - val_loss: 4.1748 - val_accuracy: 0.5000\n",
      "Epoch 962/1000\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.0275 - accuracy: 0.9887 - val_loss: 4.1997 - val_accuracy: 0.5000\n",
      "Epoch 963/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.0284 - accuracy: 0.9831 - val_loss: 4.2080 - val_accuracy: 0.5000\n",
      "Epoch 964/1000\n",
      "177/177 [==============================] - 0s 63us/step - loss: 0.0274 - accuracy: 0.9887 - val_loss: 4.2081 - val_accuracy: 0.5000\n",
      "Epoch 965/1000\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.0281 - accuracy: 0.9831 - val_loss: 4.2076 - val_accuracy: 0.5000\n",
      "Epoch 966/1000\n",
      "177/177 [==============================] - 0s 83us/step - loss: 0.0275 - accuracy: 0.9887 - val_loss: 4.2057 - val_accuracy: 0.5000\n",
      "Epoch 967/1000\n",
      "177/177 [==============================] - 0s 84us/step - loss: 0.0275 - accuracy: 0.9887 - val_loss: 4.2091 - val_accuracy: 0.5000\n",
      "Epoch 968/1000\n",
      "177/177 [==============================] - 0s 85us/step - loss: 0.0272 - accuracy: 0.9887 - val_loss: 4.2352 - val_accuracy: 0.5000\n",
      "Epoch 969/1000\n",
      "177/177 [==============================] - 0s 104us/step - loss: 0.0270 - accuracy: 0.9887 - val_loss: 4.2413 - val_accuracy: 0.5000\n",
      "Epoch 970/1000\n",
      "177/177 [==============================] - 0s 95us/step - loss: 0.0272 - accuracy: 0.9887 - val_loss: 4.2455 - val_accuracy: 0.5000\n",
      "Epoch 971/1000\n",
      "177/177 [==============================] - 0s 96us/step - loss: 0.0274 - accuracy: 0.9887 - val_loss: 4.2466 - val_accuracy: 0.5000\n",
      "Epoch 972/1000\n",
      "177/177 [==============================] - ETA: 0s - loss: 0.0343 - accuracy: 0.96 - 0s 87us/step - loss: 0.0284 - accuracy: 0.9831 - val_loss: 4.2620 - val_accuracy: 0.5000\n",
      "Epoch 973/1000\n",
      "177/177 [==============================] - 0s 87us/step - loss: 0.0280 - accuracy: 0.9887 - val_loss: 4.2599 - val_accuracy: 0.5132\n",
      "Epoch 974/1000\n",
      "177/177 [==============================] - 0s 77us/step - loss: 0.0270 - accuracy: 0.9887 - val_loss: 4.2384 - val_accuracy: 0.5132\n",
      "Epoch 975/1000\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.0285 - accuracy: 0.9831 - val_loss: 4.2143 - val_accuracy: 0.5000\n",
      "Epoch 976/1000\n",
      "177/177 [==============================] - 0s 94us/step - loss: 0.0272 - accuracy: 0.9887 - val_loss: 4.2262 - val_accuracy: 0.5000\n",
      "Epoch 977/1000\n",
      "177/177 [==============================] - 0s 95us/step - loss: 0.0269 - accuracy: 0.9887 - val_loss: 4.2366 - val_accuracy: 0.5000\n",
      "Epoch 978/1000\n",
      "177/177 [==============================] - 0s 128us/step - loss: 0.0271 - accuracy: 0.9831 - val_loss: 4.2494 - val_accuracy: 0.5000\n",
      "Epoch 979/1000\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.0273 - accuracy: 0.9887 - val_loss: 4.2498 - val_accuracy: 0.5132\n",
      "Epoch 980/1000\n",
      "177/177 [==============================] - 0s 69us/step - loss: 0.0270 - accuracy: 0.9887 - val_loss: 4.2551 - val_accuracy: 0.5000\n",
      "Epoch 981/1000\n",
      "177/177 [==============================] - 0s 116us/step - loss: 0.0264 - accuracy: 0.9887 - val_loss: 4.2710 - val_accuracy: 0.5000\n",
      "Epoch 982/1000\n",
      "177/177 [==============================] - 0s 81us/step - loss: 0.0265 - accuracy: 0.9887 - val_loss: 4.2774 - val_accuracy: 0.4868\n",
      "Epoch 983/1000\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.0271 - accuracy: 0.9887 - val_loss: 4.2838 - val_accuracy: 0.4868\n",
      "Epoch 984/1000\n",
      "177/177 [==============================] - 0s 84us/step - loss: 0.0274 - accuracy: 0.9887 - val_loss: 4.2858 - val_accuracy: 0.5000\n",
      "Epoch 985/1000\n",
      "177/177 [==============================] - 0s 96us/step - loss: 0.0272 - accuracy: 0.9887 - val_loss: 4.2896 - val_accuracy: 0.5000\n",
      "Epoch 986/1000\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.0280 - accuracy: 0.9887 - val_loss: 4.2896 - val_accuracy: 0.5000\n",
      "Epoch 987/1000\n",
      "177/177 [==============================] - 0s 85us/step - loss: 0.0268 - accuracy: 0.9831 - val_loss: 4.2998 - val_accuracy: 0.5000\n",
      "Epoch 988/1000\n",
      "177/177 [==============================] - 0s 87us/step - loss: 0.0265 - accuracy: 0.9887 - val_loss: 4.3024 - val_accuracy: 0.5000\n",
      "Epoch 989/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.0274 - accuracy: 0.9887 - val_loss: 4.2962 - val_accuracy: 0.5000\n",
      "Epoch 990/1000\n",
      "177/177 [==============================] - 0s 92us/step - loss: 0.0270 - accuracy: 0.9887 - val_loss: 4.2994 - val_accuracy: 0.5000\n",
      "Epoch 991/1000\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.0274 - accuracy: 0.9887 - val_loss: 4.2982 - val_accuracy: 0.4868\n",
      "Epoch 992/1000\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.0267 - accuracy: 0.9887 - val_loss: 4.3082 - val_accuracy: 0.4868\n",
      "Epoch 993/1000\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.0267 - accuracy: 0.9887 - val_loss: 4.3336 - val_accuracy: 0.4868\n",
      "Epoch 994/1000\n",
      "177/177 [==============================] - 0s 86us/step - loss: 0.0268 - accuracy: 0.9831 - val_loss: 4.3164 - val_accuracy: 0.5000\n",
      "Epoch 995/1000\n",
      "177/177 [==============================] - 0s 112us/step - loss: 0.0270 - accuracy: 0.9831 - val_loss: 4.3065 - val_accuracy: 0.5000\n",
      "Epoch 996/1000\n",
      "177/177 [==============================] - 0s 228us/step - loss: 0.0276 - accuracy: 0.9831 - val_loss: 4.2956 - val_accuracy: 0.5132\n",
      "Epoch 997/1000\n",
      "177/177 [==============================] - 0s 216us/step - loss: 0.0267 - accuracy: 0.9887 - val_loss: 4.2917 - val_accuracy: 0.5000\n",
      "Epoch 998/1000\n",
      "177/177 [==============================] - 0s 115us/step - loss: 0.0267 - accuracy: 0.9887 - val_loss: 4.3009 - val_accuracy: 0.4868\n",
      "Epoch 999/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177/177 [==============================] - 0s 85us/step - loss: 0.0265 - accuracy: 0.9831 - val_loss: 4.3014 - val_accuracy: 0.4868\n",
      "Epoch 1000/1000\n",
      "177/177 [==============================] - 0s 120us/step - loss: 0.0275 - accuracy: 0.9887 - val_loss: 4.3074 - val_accuracy: 0.4868\n"
     ]
    }
   ],
   "source": [
    "hist_sel3 = model_sel3.fit(X_sel_train, y_sel_train,\n",
    "          batch_size=64, epochs=1000,\n",
    "          validation_data=(X_sel_test, y_sel_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 98.51%\n"
     ]
    }
   ],
   "source": [
    "print('train accuracy: %.2f%%' % (np.mean(hist_sel3.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba7 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_lasso_2.xlsx\",\n",
    "                        sheet_name=2,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NRS271</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.854929</td>\n",
       "      <td>0.144940</td>\n",
       "      <td>0.000130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>SR2852</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.999923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>CA39</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.959992</td>\n",
       "      <td>0.013406</td>\n",
       "      <td>0.026602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NRS266</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.999980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NY356</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.009156</td>\n",
       "      <td>0.411991</td>\n",
       "      <td>0.578852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>CFBREBSa110</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.044135</td>\n",
       "      <td>0.010244</td>\n",
       "      <td>0.945621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>CFBRSa05</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.145032</td>\n",
       "      <td>0.408530</td>\n",
       "      <td>0.446439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>CFBREBSa123</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.994623</td>\n",
       "      <td>0.004152</td>\n",
       "      <td>0.001224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>NY360</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000795</td>\n",
       "      <td>0.948566</td>\n",
       "      <td>0.050639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>CFBREBSa118</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.999037</td>\n",
       "      <td>0.000934</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>608 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     phage       strain  phenotype  prediction         0  \\\n",
       "0       p0017kpresabs_qual       NRS271          1           0  0.854929   \n",
       "1       p0017kpresabs_qual       SR2852          2           2  0.000001   \n",
       "2       p0017kpresabs_qual         CA39          2           0  0.959992   \n",
       "3       p0017kpresabs_qual       NRS266          1           2  0.000018   \n",
       "4       p0017kpresabs_qual        NY356          2           2  0.009156   \n",
       "..                     ...          ...        ...         ...       ...   \n",
       "603  p0040presabsSTCC_qual  CFBREBSa110          2           2  0.044135   \n",
       "604  p0040presabsSTCC_qual     CFBRSa05          0           2  0.145032   \n",
       "605  p0040presabsSTCC_qual  CFBREBSa123          0           0  0.994623   \n",
       "606  p0040presabsSTCC_qual        NY360          1           1  0.000795   \n",
       "607  p0040presabsSTCC_qual  CFBREBSa118          2           1  0.000029   \n",
       "\n",
       "            1         2  \n",
       "0    0.144940  0.000130  \n",
       "1    0.000075  0.999923  \n",
       "2    0.013406  0.026602  \n",
       "3    0.000003  0.999980  \n",
       "4    0.411991  0.578852  \n",
       "..        ...       ...  \n",
       "603  0.010244  0.945621  \n",
       "604  0.408530  0.446439  \n",
       "605  0.004152  0.001224  \n",
       "606  0.948566  0.050639  \n",
       "607  0.999037  0.000934  \n",
       "\n",
       "[608 rows x 7 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.66690190e-03, 9.97123200e-01, 1.20998790e-03],\n",
       "       [3.49782390e-06, 6.78205000e-05, 9.99928700e-01],\n",
       "       [2.09420860e-01, 7.90519650e-01, 5.95099200e-05],\n",
       "       [1.96571390e-06, 1.45322250e-03, 9.98544800e-01],\n",
       "       [4.12326540e-01, 4.98116340e-03, 5.82692270e-01],\n",
       "       [7.72617500e-01, 4.32880400e-02, 1.84094460e-01],\n",
       "       [1.71254470e-01, 4.99478640e-01, 3.29266900e-01],\n",
       "       [3.80232800e-03, 3.76772940e-01, 6.19424760e-01],\n",
       "       [2.21669350e-01, 1.51685240e-01, 6.26645450e-01],\n",
       "       [4.41352540e-02, 1.02438750e-02, 9.45620830e-01],\n",
       "       [9.92457750e-01, 7.54223900e-03, 2.72427330e-09],\n",
       "       [9.40488530e-04, 6.44437250e-13, 9.99059500e-01],\n",
       "       [1.02810030e-09, 1.55061130e-05, 9.99984500e-01],\n",
       "       [5.64978700e-07, 9.91509100e-01, 8.49027800e-03],\n",
       "       [8.51652300e-06, 9.92857340e-01, 7.13409670e-03],\n",
       "       [3.38913600e-06, 9.99820650e-01, 1.75997020e-04],\n",
       "       [9.99552400e-01, 4.43265980e-04, 4.26081500e-06],\n",
       "       [8.34376300e-01, 1.75572990e-04, 1.65448130e-01],\n",
       "       [2.26120170e-01, 7.59064730e-01, 1.48150990e-02],\n",
       "       [1.20082930e-03, 9.94843000e-01, 3.95613260e-03],\n",
       "       [3.95731210e-04, 5.44048250e-01, 4.55555950e-01],\n",
       "       [2.10178570e-05, 9.21685700e-01, 7.82933460e-02],\n",
       "       [1.72875080e-04, 9.99259900e-01, 5.67258450e-04],\n",
       "       [3.93147800e-03, 9.93331730e-01, 2.73675730e-03],\n",
       "       [6.26399930e-01, 3.73483900e-01, 1.16177440e-04],\n",
       "       [9.99999050e-01, 1.00679870e-06, 8.42128000e-10],\n",
       "       [9.89466500e-01, 1.05335090e-02, 7.61488600e-09],\n",
       "       [1.45170700e-08, 9.99348460e-01, 6.51543550e-04],\n",
       "       [1.96670110e-07, 1.19873720e-04, 9.99879960e-01],\n",
       "       [5.57804000e-04, 9.90874650e-01, 8.56761300e-03],\n",
       "       [5.79305780e-05, 9.92665100e-01, 7.27689600e-03],\n",
       "       [5.31238270e-03, 3.77388820e-02, 9.56948760e-01],\n",
       "       [3.26029060e-01, 6.42787900e-01, 3.11830980e-02],\n",
       "       [8.51805700e-07, 5.93079500e-05, 9.99939800e-01],\n",
       "       [1.73795990e-02, 9.81459600e-01, 1.16073720e-03],\n",
       "       [2.10452170e-02, 5.60768600e-01, 4.18186130e-01],\n",
       "       [9.99978660e-01, 8.63896550e-06, 1.27464670e-05],\n",
       "       [4.94157500e-03, 8.42702900e-01, 1.52355550e-01],\n",
       "       [6.89345660e-01, 2.92857320e-01, 1.77970320e-02],\n",
       "       [2.03806700e-04, 1.98481340e-04, 9.99597700e-01],\n",
       "       [9.97475900e-01, 2.54360540e-07, 2.52377400e-03],\n",
       "       [1.96041200e-01, 1.03316806e-01, 7.00641930e-01],\n",
       "       [2.18923670e-03, 1.04725990e-02, 9.87338200e-01],\n",
       "       [7.94895800e-04, 9.48566400e-01, 5.06386530e-02],\n",
       "       [6.98894300e-01, 2.98118530e-01, 2.98705770e-03],\n",
       "       [9.99973650e-01, 2.15523600e-05, 4.80563500e-06],\n",
       "       [8.07088400e-03, 9.85879600e-01, 6.04953900e-03],\n",
       "       [1.84155390e-01, 7.92559300e-01, 2.32853070e-02],\n",
       "       [2.28428830e-05, 8.64149300e-01, 1.35827810e-01],\n",
       "       [9.90863300e-05, 5.36421340e-06, 9.99895600e-01],\n",
       "       [4.78743550e-08, 4.10201860e-05, 9.99958900e-01],\n",
       "       [4.41352540e-02, 1.02438750e-02, 9.45620830e-01],\n",
       "       [4.83231800e-05, 9.96065300e-01, 3.88638540e-03],\n",
       "       [1.44575470e-07, 9.95495300e-01, 4.50455700e-03],\n",
       "       [9.99487500e-01, 5.06525000e-04, 5.93522550e-06],\n",
       "       [2.73414220e-02, 2.68462900e-01, 7.04195700e-01],\n",
       "       [9.40060560e-01, 5.99229560e-02, 1.65137400e-05],\n",
       "       [9.99491600e-01, 1.04116380e-04, 4.04238560e-04],\n",
       "       [3.35872080e-03, 2.70950590e-02, 9.69546200e-01],\n",
       "       [2.65413560e-06, 2.86865800e-10, 9.99997400e-01],\n",
       "       [1.80761050e-03, 4.85514350e-04, 9.97706900e-01],\n",
       "       [2.42095520e-01, 1.36666280e-04, 7.57767800e-01],\n",
       "       [1.41594720e-03, 1.11474740e-03, 9.97469300e-01],\n",
       "       [6.69437000e-06, 2.32701000e-02, 9.76723250e-01],\n",
       "       [1.08702265e-01, 1.53056170e-03, 8.89767100e-01],\n",
       "       [5.53343200e-10, 6.01148670e-06, 9.99994040e-01],\n",
       "       [4.60150740e-03, 9.95397870e-01, 5.95391200e-07],\n",
       "       [1.94136080e-03, 9.94733900e-01, 3.32471050e-03],\n",
       "       [9.99433200e-01, 5.66526300e-04, 2.18869390e-07],\n",
       "       [9.46874200e-06, 9.99681500e-01, 3.09078280e-04],\n",
       "       [9.99837160e-01, 1.62845360e-04, 1.24419370e-08],\n",
       "       [4.41352540e-02, 1.02438750e-02, 9.45620830e-01],\n",
       "       [1.45031780e-01, 4.08529700e-01, 4.46438500e-01],\n",
       "       [9.94623400e-01, 4.15215040e-03, 1.22448440e-03],\n",
       "       [7.94895800e-04, 9.48566400e-01, 5.06386530e-02],\n",
       "       [2.88040760e-05, 9.99036800e-01, 9.34390200e-04]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob7 = df_proba7[df_proba7['phage']=='p0040presabsSTCC_qual'].iloc[:,-3:]\n",
    "y_prob7 = y_prob7.to_numpy()\n",
    "y_prob7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.704575980285179"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo7 = rocauc_ovo(y_sel_test, y_prob7, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.704575980285179"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr7 = rocauc_ovr(y_sel_test, y_prob7, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_sel_train, X_sel_test, y_sel_train, y_sel_test = train_test_split(X_sel, y_sel,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=890,\n",
    "                                                    stratify=y_sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat8 = pd.DataFrame(X_sel_test.iloc[:,-1])\n",
    "dat8['test'] = y_sel_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strain</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>NRS103</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>EUH25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>NRS001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>NRS192</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>NRS113</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>BCH-SA-09</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>NRS106</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>CFBREBSa131</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>GA51254</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          strain  test\n",
       "130       NRS103     2\n",
       "92         EUH25     0\n",
       "143       NRS148     2\n",
       "107       NRS001     1\n",
       "166       NRS192     0\n",
       "..           ...   ...\n",
       "139       NRS113     1\n",
       "24     BCH-SA-09     2\n",
       "133       NRS106     2\n",
       "62   CFBREBSa131     2\n",
       "100      GA51254     0\n",
       "\n",
       "[76 rows x 2 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sel_train = X_sel_train.drop(['strain'], axis=1)\n",
    "X_sel_test = X_sel_test.drop(['strain'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sel4 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_sel_train.shape[1],)),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sel4.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 177 samples, validate on 76 samples\n",
      "Epoch 1/1000\n",
      "177/177 [==============================] - 0s 708us/step - loss: 20.2238 - accuracy: 0.2712 - val_loss: 15.0039 - val_accuracy: 0.2105\n",
      "Epoch 2/1000\n",
      "177/177 [==============================] - 0s 100us/step - loss: 13.7926 - accuracy: 0.3051 - val_loss: 10.3115 - val_accuracy: 0.1842\n",
      "Epoch 3/1000\n",
      "177/177 [==============================] - 0s 156us/step - loss: 8.7917 - accuracy: 0.3107 - val_loss: 6.2796 - val_accuracy: 0.3026\n",
      "Epoch 4/1000\n",
      "177/177 [==============================] - 0s 126us/step - loss: 5.4862 - accuracy: 0.4181 - val_loss: 5.0898 - val_accuracy: 0.4079\n",
      "Epoch 5/1000\n",
      "177/177 [==============================] - 0s 214us/step - loss: 5.1095 - accuracy: 0.4576 - val_loss: 3.2619 - val_accuracy: 0.3816\n",
      "Epoch 6/1000\n",
      "177/177 [==============================] - 0s 176us/step - loss: 2.9017 - accuracy: 0.4407 - val_loss: 1.8542 - val_accuracy: 0.3684\n",
      "Epoch 7/1000\n",
      "177/177 [==============================] - 0s 158us/step - loss: 1.9712 - accuracy: 0.4689 - val_loss: 1.7821 - val_accuracy: 0.4474\n",
      "Epoch 8/1000\n",
      "177/177 [==============================] - 0s 177us/step - loss: 1.6109 - accuracy: 0.4746 - val_loss: 1.1592 - val_accuracy: 0.3684\n",
      "Epoch 9/1000\n",
      "177/177 [==============================] - 0s 182us/step - loss: 1.2537 - accuracy: 0.4859 - val_loss: 1.1357 - val_accuracy: 0.3289\n",
      "Epoch 10/1000\n",
      "177/177 [==============================] - 0s 181us/step - loss: 1.0244 - accuracy: 0.4576 - val_loss: 1.2001 - val_accuracy: 0.3553\n",
      "Epoch 11/1000\n",
      "177/177 [==============================] - 0s 145us/step - loss: 1.1873 - accuracy: 0.5028 - val_loss: 1.1366 - val_accuracy: 0.3684\n",
      "Epoch 12/1000\n",
      "177/177 [==============================] - 0s 204us/step - loss: 0.9482 - accuracy: 0.5311 - val_loss: 1.0955 - val_accuracy: 0.3816\n",
      "Epoch 13/1000\n",
      "177/177 [==============================] - 0s 138us/step - loss: 1.0132 - accuracy: 0.5593 - val_loss: 1.1326 - val_accuracy: 0.3684\n",
      "Epoch 14/1000\n",
      "177/177 [==============================] - 0s 161us/step - loss: 0.9809 - accuracy: 0.5706 - val_loss: 1.0846 - val_accuracy: 0.3947\n",
      "Epoch 15/1000\n",
      "177/177 [==============================] - 0s 326us/step - loss: 1.0315 - accuracy: 0.5819 - val_loss: 1.1579 - val_accuracy: 0.3947\n",
      "Epoch 16/1000\n",
      "177/177 [==============================] - 0s 134us/step - loss: 1.0099 - accuracy: 0.6102 - val_loss: 1.1016 - val_accuracy: 0.3816\n",
      "Epoch 17/1000\n",
      "177/177 [==============================] - 0s 188us/step - loss: 0.8708 - accuracy: 0.6215 - val_loss: 1.0679 - val_accuracy: 0.3816\n",
      "Epoch 18/1000\n",
      "177/177 [==============================] - 0s 142us/step - loss: 0.9093 - accuracy: 0.6328 - val_loss: 1.2667 - val_accuracy: 0.3684\n",
      "Epoch 19/1000\n",
      "177/177 [==============================] - 0s 180us/step - loss: 1.0133 - accuracy: 0.6554 - val_loss: 1.0922 - val_accuracy: 0.3684\n",
      "Epoch 20/1000\n",
      "177/177 [==============================] - 0s 157us/step - loss: 0.9069 - accuracy: 0.5932 - val_loss: 1.0495 - val_accuracy: 0.3947\n",
      "Epoch 21/1000\n",
      "177/177 [==============================] - 0s 144us/step - loss: 0.8274 - accuracy: 0.6610 - val_loss: 1.0551 - val_accuracy: 0.3947\n",
      "Epoch 22/1000\n",
      "177/177 [==============================] - 0s 202us/step - loss: 0.9165 - accuracy: 0.6610 - val_loss: 1.0248 - val_accuracy: 0.4211\n",
      "Epoch 23/1000\n",
      "177/177 [==============================] - 0s 177us/step - loss: 0.9897 - accuracy: 0.6441 - val_loss: 1.0362 - val_accuracy: 0.4079\n",
      "Epoch 24/1000\n",
      "177/177 [==============================] - 0s 203us/step - loss: 0.8284 - accuracy: 0.7119 - val_loss: 1.0499 - val_accuracy: 0.3816\n",
      "Epoch 25/1000\n",
      "177/177 [==============================] - 0s 165us/step - loss: 0.8259 - accuracy: 0.7006 - val_loss: 1.0450 - val_accuracy: 0.3816\n",
      "Epoch 26/1000\n",
      "177/177 [==============================] - 0s 140us/step - loss: 0.7819 - accuracy: 0.7062 - val_loss: 1.0271 - val_accuracy: 0.4342\n",
      "Epoch 27/1000\n",
      "177/177 [==============================] - 0s 156us/step - loss: 0.7532 - accuracy: 0.7345 - val_loss: 1.0132 - val_accuracy: 0.4211\n",
      "Epoch 28/1000\n",
      "177/177 [==============================] - 0s 100us/step - loss: 0.9004 - accuracy: 0.6780 - val_loss: 1.0864 - val_accuracy: 0.4079\n",
      "Epoch 29/1000\n",
      "177/177 [==============================] - 0s 109us/step - loss: 0.7603 - accuracy: 0.7345 - val_loss: 1.0155 - val_accuracy: 0.4211\n",
      "Epoch 30/1000\n",
      "177/177 [==============================] - 0s 146us/step - loss: 0.7524 - accuracy: 0.7458 - val_loss: 1.0183 - val_accuracy: 0.4605\n",
      "Epoch 31/1000\n",
      "177/177 [==============================] - 0s 114us/step - loss: 0.7096 - accuracy: 0.7627 - val_loss: 0.9998 - val_accuracy: 0.4211\n",
      "Epoch 32/1000\n",
      "177/177 [==============================] - 0s 107us/step - loss: 0.8060 - accuracy: 0.7514 - val_loss: 1.0184 - val_accuracy: 0.4211\n",
      "Epoch 33/1000\n",
      "177/177 [==============================] - 0s 121us/step - loss: 0.9652 - accuracy: 0.7797 - val_loss: 1.0622 - val_accuracy: 0.4342\n",
      "Epoch 34/1000\n",
      "177/177 [==============================] - 0s 127us/step - loss: 0.9300 - accuracy: 0.7401 - val_loss: 1.0387 - val_accuracy: 0.4342\n",
      "Epoch 35/1000\n",
      "177/177 [==============================] - 0s 221us/step - loss: 0.8065 - accuracy: 0.7458 - val_loss: 0.9953 - val_accuracy: 0.4474\n",
      "Epoch 36/1000\n",
      "177/177 [==============================] - 0s 148us/step - loss: 0.6735 - accuracy: 0.7458 - val_loss: 1.0382 - val_accuracy: 0.4737\n",
      "Epoch 37/1000\n",
      "177/177 [==============================] - 0s 99us/step - loss: 0.6827 - accuracy: 0.7627 - val_loss: 0.9960 - val_accuracy: 0.4474\n",
      "Epoch 38/1000\n",
      "177/177 [==============================] - 0s 123us/step - loss: 0.7180 - accuracy: 0.7684 - val_loss: 1.0621 - val_accuracy: 0.4079\n",
      "Epoch 39/1000\n",
      "177/177 [==============================] - 0s 197us/step - loss: 0.7248 - accuracy: 0.7797 - val_loss: 0.9777 - val_accuracy: 0.4211\n",
      "Epoch 40/1000\n",
      "177/177 [==============================] - 0s 109us/step - loss: 0.7990 - accuracy: 0.7853 - val_loss: 1.0211 - val_accuracy: 0.4342\n",
      "Epoch 41/1000\n",
      "177/177 [==============================] - 0s 143us/step - loss: 0.7775 - accuracy: 0.7797 - val_loss: 1.0075 - val_accuracy: 0.4079\n",
      "Epoch 42/1000\n",
      "177/177 [==============================] - 0s 196us/step - loss: 0.6732 - accuracy: 0.8249 - val_loss: 1.0137 - val_accuracy: 0.4211\n",
      "Epoch 43/1000\n",
      "177/177 [==============================] - 0s 132us/step - loss: 0.6503 - accuracy: 0.8136 - val_loss: 1.0332 - val_accuracy: 0.4079\n",
      "Epoch 44/1000\n",
      "177/177 [==============================] - 0s 155us/step - loss: 0.7454 - accuracy: 0.7797 - val_loss: 1.0172 - val_accuracy: 0.4211\n",
      "Epoch 45/1000\n",
      "177/177 [==============================] - 0s 120us/step - loss: 0.5876 - accuracy: 0.8362 - val_loss: 0.9780 - val_accuracy: 0.4474\n",
      "Epoch 46/1000\n",
      "177/177 [==============================] - 0s 97us/step - loss: 0.6031 - accuracy: 0.8418 - val_loss: 1.0123 - val_accuracy: 0.4605\n",
      "Epoch 47/1000\n",
      "177/177 [==============================] - 0s 128us/step - loss: 0.7337 - accuracy: 0.8192 - val_loss: 1.0696 - val_accuracy: 0.4211\n",
      "Epoch 48/1000\n",
      "177/177 [==============================] - 0s 162us/step - loss: 0.7763 - accuracy: 0.7627 - val_loss: 1.0140 - val_accuracy: 0.4605\n",
      "Epoch 49/1000\n",
      "177/177 [==============================] - 0s 148us/step - loss: 0.8943 - accuracy: 0.7853 - val_loss: 1.1042 - val_accuracy: 0.4079\n",
      "Epoch 50/1000\n",
      "177/177 [==============================] - 0s 136us/step - loss: 0.6537 - accuracy: 0.8079 - val_loss: 0.9755 - val_accuracy: 0.3947\n",
      "Epoch 51/1000\n",
      "177/177 [==============================] - 0s 155us/step - loss: 0.5975 - accuracy: 0.8475 - val_loss: 1.0424 - val_accuracy: 0.4211\n",
      "Epoch 52/1000\n",
      "177/177 [==============================] - 0s 132us/step - loss: 0.5933 - accuracy: 0.8588 - val_loss: 0.9622 - val_accuracy: 0.4474\n",
      "Epoch 53/1000\n",
      "177/177 [==============================] - 0s 155us/step - loss: 0.6917 - accuracy: 0.8475 - val_loss: 1.0302 - val_accuracy: 0.4079\n",
      "Epoch 54/1000\n",
      "177/177 [==============================] - 0s 189us/step - loss: 0.7539 - accuracy: 0.8192 - val_loss: 1.0213 - val_accuracy: 0.4474\n",
      "Epoch 55/1000\n",
      "177/177 [==============================] - 0s 166us/step - loss: 0.6565 - accuracy: 0.8475 - val_loss: 0.9737 - val_accuracy: 0.4342\n",
      "Epoch 56/1000\n",
      "177/177 [==============================] - 0s 225us/step - loss: 0.6432 - accuracy: 0.8305 - val_loss: 1.2986 - val_accuracy: 0.3553\n",
      "Epoch 57/1000\n",
      "177/177 [==============================] - 0s 151us/step - loss: 1.0497 - accuracy: 0.7910 - val_loss: 1.0138 - val_accuracy: 0.4474\n",
      "Epoch 58/1000\n",
      "177/177 [==============================] - ETA: 0s - loss: 0.7011 - accuracy: 0.87 - 0s 148us/step - loss: 0.7824 - accuracy: 0.7966 - val_loss: 1.3804 - val_accuracy: 0.4605\n",
      "Epoch 59/1000\n",
      "177/177 [==============================] - 0s 141us/step - loss: 0.9904 - accuracy: 0.7797 - val_loss: 1.2411 - val_accuracy: 0.4605\n",
      "Epoch 60/1000\n",
      "177/177 [==============================] - 0s 120us/step - loss: 0.8441 - accuracy: 0.7740 - val_loss: 1.1653 - val_accuracy: 0.4737\n",
      "Epoch 61/1000\n",
      "177/177 [==============================] - 0s 118us/step - loss: 0.7788 - accuracy: 0.7684 - val_loss: 1.1240 - val_accuracy: 0.4342\n",
      "Epoch 62/1000\n",
      "177/177 [==============================] - 0s 158us/step - loss: 0.6783 - accuracy: 0.8475 - val_loss: 1.0026 - val_accuracy: 0.4211\n",
      "Epoch 63/1000\n",
      "177/177 [==============================] - 0s 129us/step - loss: 0.5284 - accuracy: 0.8475 - val_loss: 1.0569 - val_accuracy: 0.4211\n",
      "Epoch 64/1000\n",
      "177/177 [==============================] - 0s 120us/step - loss: 0.5872 - accuracy: 0.8475 - val_loss: 1.0174 - val_accuracy: 0.4605\n",
      "Epoch 65/1000\n",
      "177/177 [==============================] - 0s 126us/step - loss: 0.6895 - accuracy: 0.8418 - val_loss: 1.0109 - val_accuracy: 0.4605\n",
      "Epoch 66/1000\n",
      "177/177 [==============================] - 0s 117us/step - loss: 0.6569 - accuracy: 0.8305 - val_loss: 1.1296 - val_accuracy: 0.4605\n",
      "Epoch 67/1000\n",
      "177/177 [==============================] - 0s 101us/step - loss: 0.5767 - accuracy: 0.8644 - val_loss: 0.9783 - val_accuracy: 0.4605\n",
      "Epoch 68/1000\n",
      "177/177 [==============================] - 0s 114us/step - loss: 0.7609 - accuracy: 0.8249 - val_loss: 1.0079 - val_accuracy: 0.4211\n",
      "Epoch 69/1000\n",
      "177/177 [==============================] - 0s 117us/step - loss: 0.6294 - accuracy: 0.8531 - val_loss: 1.0774 - val_accuracy: 0.4605\n",
      "Epoch 70/1000\n",
      "177/177 [==============================] - 0s 101us/step - loss: 0.7196 - accuracy: 0.8362 - val_loss: 1.1328 - val_accuracy: 0.4342\n",
      "Epoch 71/1000\n",
      "177/177 [==============================] - 0s 87us/step - loss: 0.8045 - accuracy: 0.8305 - val_loss: 1.3147 - val_accuracy: 0.4474\n",
      "Epoch 72/1000\n",
      "177/177 [==============================] - 0s 105us/step - loss: 0.5268 - accuracy: 0.8475 - val_loss: 1.0748 - val_accuracy: 0.4868\n",
      "Epoch 73/1000\n",
      "177/177 [==============================] - 0s 91us/step - loss: 0.7803 - accuracy: 0.8192 - val_loss: 1.2145 - val_accuracy: 0.4474\n",
      "Epoch 74/1000\n",
      "177/177 [==============================] - 0s 87us/step - loss: 0.8558 - accuracy: 0.8192 - val_loss: 1.3361 - val_accuracy: 0.4211\n",
      "Epoch 75/1000\n",
      "177/177 [==============================] - 0s 94us/step - loss: 0.6955 - accuracy: 0.8418 - val_loss: 1.0015 - val_accuracy: 0.4605\n",
      "Epoch 76/1000\n",
      "177/177 [==============================] - 0s 143us/step - loss: 0.6167 - accuracy: 0.8418 - val_loss: 1.0389 - val_accuracy: 0.4079\n",
      "Epoch 77/1000\n",
      "177/177 [==============================] - 0s 114us/step - loss: 0.6479 - accuracy: 0.8531 - val_loss: 1.0382 - val_accuracy: 0.4211\n",
      "Epoch 78/1000\n",
      "177/177 [==============================] - 0s 117us/step - loss: 0.7247 - accuracy: 0.8588 - val_loss: 0.9780 - val_accuracy: 0.4737\n",
      "Epoch 79/1000\n",
      "177/177 [==============================] - 0s 108us/step - loss: 0.8163 - accuracy: 0.8475 - val_loss: 1.1069 - val_accuracy: 0.4737\n",
      "Epoch 80/1000\n",
      "177/177 [==============================] - 0s 124us/step - loss: 0.6070 - accuracy: 0.8475 - val_loss: 1.0426 - val_accuracy: 0.4737\n",
      "Epoch 81/1000\n",
      "177/177 [==============================] - 0s 86us/step - loss: 0.6938 - accuracy: 0.8475 - val_loss: 0.9991 - val_accuracy: 0.5000\n",
      "Epoch 82/1000\n",
      "177/177 [==============================] - 0s 82us/step - loss: 0.5503 - accuracy: 0.8588 - val_loss: 1.0333 - val_accuracy: 0.4868\n",
      "Epoch 83/1000\n",
      "177/177 [==============================] - 0s 75us/step - loss: 0.5437 - accuracy: 0.8644 - val_loss: 0.9849 - val_accuracy: 0.5000\n",
      "Epoch 84/1000\n",
      "177/177 [==============================] - 0s 96us/step - loss: 0.5537 - accuracy: 0.8757 - val_loss: 1.0137 - val_accuracy: 0.5000\n",
      "Epoch 85/1000\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.4457 - accuracy: 0.8870 - val_loss: 0.9836 - val_accuracy: 0.5000\n",
      "Epoch 86/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.5056 - accuracy: 0.8757 - val_loss: 1.0042 - val_accuracy: 0.4868\n",
      "Epoch 87/1000\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.4511 - accuracy: 0.8418 - val_loss: 1.0433 - val_accuracy: 0.5132\n",
      "Epoch 88/1000\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.6399 - accuracy: 0.8531 - val_loss: 0.9869 - val_accuracy: 0.5132\n",
      "Epoch 89/1000\n",
      "177/177 [==============================] - 0s 125us/step - loss: 0.8502 - accuracy: 0.8305 - val_loss: 1.3296 - val_accuracy: 0.4868\n",
      "Epoch 90/1000\n",
      "177/177 [==============================] - 0s 84us/step - loss: 0.7030 - accuracy: 0.8475 - val_loss: 0.9948 - val_accuracy: 0.5132\n",
      "Epoch 91/1000\n",
      "177/177 [==============================] - 0s 100us/step - loss: 0.7860 - accuracy: 0.8475 - val_loss: 1.0225 - val_accuracy: 0.5000\n",
      "Epoch 92/1000\n",
      "177/177 [==============================] - 0s 104us/step - loss: 0.4928 - accuracy: 0.8757 - val_loss: 1.0464 - val_accuracy: 0.5000\n",
      "Epoch 93/1000\n",
      "177/177 [==============================] - 0s 232us/step - loss: 0.6130 - accuracy: 0.8531 - val_loss: 1.0030 - val_accuracy: 0.5000\n",
      "Epoch 94/1000\n",
      "177/177 [==============================] - 0s 227us/step - loss: 0.4424 - accuracy: 0.8814 - val_loss: 1.0848 - val_accuracy: 0.5000\n",
      "Epoch 95/1000\n",
      "177/177 [==============================] - 0s 270us/step - loss: 0.7729 - accuracy: 0.8644 - val_loss: 1.0043 - val_accuracy: 0.5132\n",
      "Epoch 96/1000\n",
      "177/177 [==============================] - 0s 323us/step - loss: 0.5188 - accuracy: 0.8757 - val_loss: 1.1105 - val_accuracy: 0.5000\n",
      "Epoch 97/1000\n",
      "177/177 [==============================] - 0s 137us/step - loss: 0.4948 - accuracy: 0.8814 - val_loss: 0.9827 - val_accuracy: 0.5132\n",
      "Epoch 98/1000\n",
      "177/177 [==============================] - 0s 184us/step - loss: 0.5040 - accuracy: 0.8870 - val_loss: 0.9922 - val_accuracy: 0.5263\n",
      "Epoch 99/1000\n",
      "177/177 [==============================] - 0s 199us/step - loss: 0.5855 - accuracy: 0.8983 - val_loss: 1.0972 - val_accuracy: 0.4605\n",
      "Epoch 100/1000\n",
      "177/177 [==============================] - 0s 264us/step - loss: 0.6680 - accuracy: 0.8644 - val_loss: 1.0739 - val_accuracy: 0.4868\n",
      "Epoch 101/1000\n",
      "177/177 [==============================] - 0s 158us/step - loss: 0.7919 - accuracy: 0.8588 - val_loss: 1.0624 - val_accuracy: 0.5132\n",
      "Epoch 102/1000\n",
      "177/177 [==============================] - 0s 215us/step - loss: 1.2033 - accuracy: 0.8362 - val_loss: 1.1254 - val_accuracy: 0.4868\n",
      "Epoch 103/1000\n",
      "177/177 [==============================] - 0s 155us/step - loss: 1.0312 - accuracy: 0.8305 - val_loss: 1.8215 - val_accuracy: 0.4868\n",
      "Epoch 104/1000\n",
      "177/177 [==============================] - 0s 153us/step - loss: 1.3515 - accuracy: 0.8136 - val_loss: 1.4590 - val_accuracy: 0.4737\n",
      "Epoch 105/1000\n",
      "177/177 [==============================] - 0s 96us/step - loss: 0.6310 - accuracy: 0.8531 - val_loss: 1.0751 - val_accuracy: 0.5263\n",
      "Epoch 106/1000\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.6650 - accuracy: 0.8531 - val_loss: 1.0628 - val_accuracy: 0.4868\n",
      "Epoch 107/1000\n",
      "177/177 [==============================] - 0s 116us/step - loss: 0.5503 - accuracy: 0.8983 - val_loss: 1.3032 - val_accuracy: 0.4474\n",
      "Epoch 108/1000\n",
      "177/177 [==============================] - 0s 182us/step - loss: 0.6533 - accuracy: 0.8588 - val_loss: 1.0325 - val_accuracy: 0.5000\n",
      "Epoch 109/1000\n",
      "177/177 [==============================] - 0s 166us/step - loss: 0.4589 - accuracy: 0.8983 - val_loss: 1.0134 - val_accuracy: 0.5263\n",
      "Epoch 110/1000\n",
      "177/177 [==============================] - 0s 175us/step - loss: 0.4596 - accuracy: 0.9096 - val_loss: 1.1257 - val_accuracy: 0.4737\n",
      "Epoch 111/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177/177 [==============================] - 0s 140us/step - loss: 0.4236 - accuracy: 0.8983 - val_loss: 1.0144 - val_accuracy: 0.5000\n",
      "Epoch 112/1000\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.5159 - accuracy: 0.8814 - val_loss: 1.0408 - val_accuracy: 0.5395\n",
      "Epoch 113/1000\n",
      "177/177 [==============================] - 0s 125us/step - loss: 0.5242 - accuracy: 0.8814 - val_loss: 1.0234 - val_accuracy: 0.5132\n",
      "Epoch 114/1000\n",
      "177/177 [==============================] - 0s 130us/step - loss: 0.3964 - accuracy: 0.8983 - val_loss: 1.0202 - val_accuracy: 0.5000\n",
      "Epoch 115/1000\n",
      "177/177 [==============================] - 0s 157us/step - loss: 0.3627 - accuracy: 0.9040 - val_loss: 1.0655 - val_accuracy: 0.5395\n",
      "Epoch 116/1000\n",
      "177/177 [==============================] - 0s 139us/step - loss: 0.4097 - accuracy: 0.9096 - val_loss: 1.0737 - val_accuracy: 0.5132\n",
      "Epoch 117/1000\n",
      "177/177 [==============================] - 0s 227us/step - loss: 0.3589 - accuracy: 0.9040 - val_loss: 1.0830 - val_accuracy: 0.5000\n",
      "Epoch 118/1000\n",
      "177/177 [==============================] - 0s 140us/step - loss: 0.6579 - accuracy: 0.8644 - val_loss: 1.1562 - val_accuracy: 0.4342\n",
      "Epoch 119/1000\n",
      "177/177 [==============================] - 0s 213us/step - loss: 0.4589 - accuracy: 0.8983 - val_loss: 1.0607 - val_accuracy: 0.5000\n",
      "Epoch 120/1000\n",
      "177/177 [==============================] - 0s 130us/step - loss: 0.6684 - accuracy: 0.8983 - val_loss: 1.0064 - val_accuracy: 0.4868\n",
      "Epoch 121/1000\n",
      "177/177 [==============================] - 0s 124us/step - loss: 0.6095 - accuracy: 0.8870 - val_loss: 1.3444 - val_accuracy: 0.4474\n",
      "Epoch 122/1000\n",
      "177/177 [==============================] - 0s 169us/step - loss: 0.5254 - accuracy: 0.8927 - val_loss: 1.0663 - val_accuracy: 0.5132\n",
      "Epoch 123/1000\n",
      "177/177 [==============================] - 0s 108us/step - loss: 0.6222 - accuracy: 0.8814 - val_loss: 1.1209 - val_accuracy: 0.4737\n",
      "Epoch 124/1000\n",
      "177/177 [==============================] - 0s 101us/step - loss: 0.5717 - accuracy: 0.8870 - val_loss: 1.1292 - val_accuracy: 0.4868\n",
      "Epoch 125/1000\n",
      "177/177 [==============================] - 0s 148us/step - loss: 0.3746 - accuracy: 0.8927 - val_loss: 1.0402 - val_accuracy: 0.4868\n",
      "Epoch 126/1000\n",
      "177/177 [==============================] - 0s 149us/step - loss: 0.3820 - accuracy: 0.9322 - val_loss: 1.0511 - val_accuracy: 0.4868\n",
      "Epoch 127/1000\n",
      "177/177 [==============================] - 0s 148us/step - loss: 0.3326 - accuracy: 0.9322 - val_loss: 1.0878 - val_accuracy: 0.4868\n",
      "Epoch 128/1000\n",
      "177/177 [==============================] - 0s 124us/step - loss: 0.3198 - accuracy: 0.9153 - val_loss: 1.0470 - val_accuracy: 0.5132\n",
      "Epoch 129/1000\n",
      "177/177 [==============================] - 0s 134us/step - loss: 0.3603 - accuracy: 0.8870 - val_loss: 1.1493 - val_accuracy: 0.5000\n",
      "Epoch 130/1000\n",
      "177/177 [==============================] - 0s 208us/step - loss: 0.3244 - accuracy: 0.9266 - val_loss: 1.0453 - val_accuracy: 0.4868\n",
      "Epoch 131/1000\n",
      "177/177 [==============================] - 0s 155us/step - loss: 0.3290 - accuracy: 0.9153 - val_loss: 1.1595 - val_accuracy: 0.5000\n",
      "Epoch 132/1000\n",
      "177/177 [==============================] - 0s 133us/step - loss: 0.3693 - accuracy: 0.9096 - val_loss: 1.1035 - val_accuracy: 0.4737\n",
      "Epoch 133/1000\n",
      "177/177 [==============================] - 0s 157us/step - loss: 0.3789 - accuracy: 0.9435 - val_loss: 1.0529 - val_accuracy: 0.5000\n",
      "Epoch 134/1000\n",
      "177/177 [==============================] - 0s 144us/step - loss: 0.3795 - accuracy: 0.9153 - val_loss: 1.1689 - val_accuracy: 0.4868\n",
      "Epoch 135/1000\n",
      "177/177 [==============================] - 0s 208us/step - loss: 0.3647 - accuracy: 0.9153 - val_loss: 1.0618 - val_accuracy: 0.5000\n",
      "Epoch 136/1000\n",
      "177/177 [==============================] - 0s 199us/step - loss: 0.3200 - accuracy: 0.9322 - val_loss: 1.0854 - val_accuracy: 0.4868\n",
      "Epoch 137/1000\n",
      "177/177 [==============================] - 0s 160us/step - loss: 0.3193 - accuracy: 0.9322 - val_loss: 1.1138 - val_accuracy: 0.5000\n",
      "Epoch 138/1000\n",
      "177/177 [==============================] - 0s 129us/step - loss: 0.4079 - accuracy: 0.9153 - val_loss: 1.2812 - val_accuracy: 0.5000\n",
      "Epoch 139/1000\n",
      "177/177 [==============================] - 0s 143us/step - loss: 0.4193 - accuracy: 0.9266 - val_loss: 1.0695 - val_accuracy: 0.4868\n",
      "Epoch 140/1000\n",
      "177/177 [==============================] - 0s 163us/step - loss: 0.3932 - accuracy: 0.9322 - val_loss: 1.1970 - val_accuracy: 0.4737\n",
      "Epoch 141/1000\n",
      "177/177 [==============================] - 0s 115us/step - loss: 0.5279 - accuracy: 0.9153 - val_loss: 1.3225 - val_accuracy: 0.4868\n",
      "Epoch 142/1000\n",
      "177/177 [==============================] - 0s 111us/step - loss: 0.4575 - accuracy: 0.9209 - val_loss: 1.1248 - val_accuracy: 0.5000\n",
      "Epoch 143/1000\n",
      "177/177 [==============================] - 0s 144us/step - loss: 0.4695 - accuracy: 0.9153 - val_loss: 1.1863 - val_accuracy: 0.4868\n",
      "Epoch 144/1000\n",
      "177/177 [==============================] - 0s 144us/step - loss: 0.4766 - accuracy: 0.8983 - val_loss: 1.1303 - val_accuracy: 0.4737\n",
      "Epoch 145/1000\n",
      "177/177 [==============================] - 0s 169us/step - loss: 0.6327 - accuracy: 0.8983 - val_loss: 1.3162 - val_accuracy: 0.4342\n",
      "Epoch 146/1000\n",
      "177/177 [==============================] - 0s 224us/step - loss: 0.7815 - accuracy: 0.8983 - val_loss: 1.0974 - val_accuracy: 0.4737\n",
      "Epoch 147/1000\n",
      "177/177 [==============================] - 0s 161us/step - loss: 0.3380 - accuracy: 0.8983 - val_loss: 1.3281 - val_accuracy: 0.4868\n",
      "Epoch 148/1000\n",
      "177/177 [==============================] - 0s 179us/step - loss: 0.4971 - accuracy: 0.8983 - val_loss: 1.1646 - val_accuracy: 0.4737\n",
      "Epoch 149/1000\n",
      "177/177 [==============================] - 0s 128us/step - loss: 0.4559 - accuracy: 0.9209 - val_loss: 1.1123 - val_accuracy: 0.5000\n",
      "Epoch 150/1000\n",
      "177/177 [==============================] - 0s 118us/step - loss: 0.3746 - accuracy: 0.9153 - val_loss: 1.3526 - val_accuracy: 0.4868\n",
      "Epoch 151/1000\n",
      "177/177 [==============================] - 0s 186us/step - loss: 0.5959 - accuracy: 0.8870 - val_loss: 1.3675 - val_accuracy: 0.4868\n",
      "Epoch 152/1000\n",
      "177/177 [==============================] - 0s 196us/step - loss: 0.4714 - accuracy: 0.8983 - val_loss: 1.1212 - val_accuracy: 0.5132\n",
      "Epoch 153/1000\n",
      "177/177 [==============================] - 0s 227us/step - loss: 0.3421 - accuracy: 0.9322 - val_loss: 1.1976 - val_accuracy: 0.5000\n",
      "Epoch 154/1000\n",
      "177/177 [==============================] - 0s 137us/step - loss: 0.2869 - accuracy: 0.9379 - val_loss: 1.1111 - val_accuracy: 0.5132\n",
      "Epoch 155/1000\n",
      "177/177 [==============================] - 0s 201us/step - loss: 0.2969 - accuracy: 0.9322 - val_loss: 1.1663 - val_accuracy: 0.5132\n",
      "Epoch 156/1000\n",
      "177/177 [==============================] - 0s 108us/step - loss: 0.3764 - accuracy: 0.9096 - val_loss: 1.1976 - val_accuracy: 0.5132\n",
      "Epoch 157/1000\n",
      "177/177 [==============================] - 0s 99us/step - loss: 0.2719 - accuracy: 0.9379 - val_loss: 1.1311 - val_accuracy: 0.5000\n",
      "Epoch 158/1000\n",
      "177/177 [==============================] - 0s 97us/step - loss: 0.3284 - accuracy: 0.9266 - val_loss: 1.1853 - val_accuracy: 0.5132\n",
      "Epoch 159/1000\n",
      "177/177 [==============================] - 0s 119us/step - loss: 0.2650 - accuracy: 0.9379 - val_loss: 1.1297 - val_accuracy: 0.5000\n",
      "Epoch 160/1000\n",
      "177/177 [==============================] - 0s 117us/step - loss: 0.3478 - accuracy: 0.9266 - val_loss: 1.2402 - val_accuracy: 0.5000\n",
      "Epoch 161/1000\n",
      "177/177 [==============================] - 0s 133us/step - loss: 0.5446 - accuracy: 0.9153 - val_loss: 1.3843 - val_accuracy: 0.5132\n",
      "Epoch 162/1000\n",
      "177/177 [==============================] - 0s 173us/step - loss: 0.3993 - accuracy: 0.9322 - val_loss: 1.1461 - val_accuracy: 0.5132\n",
      "Epoch 163/1000\n",
      "177/177 [==============================] - 0s 142us/step - loss: 0.5149 - accuracy: 0.9209 - val_loss: 1.2307 - val_accuracy: 0.5000\n",
      "Epoch 164/1000\n",
      "177/177 [==============================] - 0s 206us/step - loss: 0.5517 - accuracy: 0.9322 - val_loss: 1.5048 - val_accuracy: 0.4868\n",
      "Epoch 165/1000\n",
      "177/177 [==============================] - 0s 192us/step - loss: 0.5749 - accuracy: 0.9040 - val_loss: 1.1999 - val_accuracy: 0.4868\n",
      "Epoch 166/1000\n",
      "177/177 [==============================] - 0s 188us/step - loss: 0.4239 - accuracy: 0.9322 - val_loss: 1.1814 - val_accuracy: 0.4868\n",
      "Epoch 167/1000\n",
      "177/177 [==============================] - 0s 111us/step - loss: 0.6052 - accuracy: 0.9266 - val_loss: 1.4894 - val_accuracy: 0.5000\n",
      "Epoch 168/1000\n",
      "177/177 [==============================] - 0s 128us/step - loss: 0.5854 - accuracy: 0.9040 - val_loss: 1.1583 - val_accuracy: 0.4868\n",
      "Epoch 169/1000\n",
      "177/177 [==============================] - 0s 107us/step - loss: 0.4155 - accuracy: 0.9379 - val_loss: 1.1898 - val_accuracy: 0.5000\n",
      "Epoch 170/1000\n",
      "177/177 [==============================] - 0s 143us/step - loss: 0.3539 - accuracy: 0.9209 - val_loss: 1.2707 - val_accuracy: 0.4868\n",
      "Epoch 171/1000\n",
      "177/177 [==============================] - 0s 83us/step - loss: 0.3434 - accuracy: 0.9379 - val_loss: 1.1745 - val_accuracy: 0.5000\n",
      "Epoch 172/1000\n",
      "177/177 [==============================] - 0s 89us/step - loss: 0.2732 - accuracy: 0.9379 - val_loss: 1.2654 - val_accuracy: 0.4868\n",
      "Epoch 173/1000\n",
      "177/177 [==============================] - 0s 92us/step - loss: 0.2784 - accuracy: 0.9266 - val_loss: 1.1797 - val_accuracy: 0.5132\n",
      "Epoch 174/1000\n",
      "177/177 [==============================] - 0s 123us/step - loss: 0.3018 - accuracy: 0.9492 - val_loss: 1.1717 - val_accuracy: 0.5395\n",
      "Epoch 175/1000\n",
      "177/177 [==============================] - 0s 89us/step - loss: 0.2730 - accuracy: 0.9266 - val_loss: 1.2872 - val_accuracy: 0.5000\n",
      "Epoch 176/1000\n",
      "177/177 [==============================] - ETA: 0s - loss: 0.1880 - accuracy: 0.93 - 0s 121us/step - loss: 0.2796 - accuracy: 0.9322 - val_loss: 1.1813 - val_accuracy: 0.5132\n",
      "Epoch 177/1000\n",
      "177/177 [==============================] - 0s 141us/step - loss: 0.3269 - accuracy: 0.9379 - val_loss: 1.1734 - val_accuracy: 0.5263\n",
      "Epoch 178/1000\n",
      "177/177 [==============================] - 0s 110us/step - loss: 0.4780 - accuracy: 0.9266 - val_loss: 1.2364 - val_accuracy: 0.5263\n",
      "Epoch 179/1000\n",
      "177/177 [==============================] - 0s 109us/step - loss: 0.3729 - accuracy: 0.9266 - val_loss: 1.6730 - val_accuracy: 0.4737\n",
      "Epoch 180/1000\n",
      "177/177 [==============================] - 0s 158us/step - loss: 0.6510 - accuracy: 0.9322 - val_loss: 1.3990 - val_accuracy: 0.4737\n",
      "Epoch 181/1000\n",
      "177/177 [==============================] - 0s 100us/step - loss: 0.3013 - accuracy: 0.9322 - val_loss: 1.2079 - val_accuracy: 0.5263\n",
      "Epoch 182/1000\n",
      "177/177 [==============================] - 0s 97us/step - loss: 0.3485 - accuracy: 0.9379 - val_loss: 1.2682 - val_accuracy: 0.4737\n",
      "Epoch 183/1000\n",
      "177/177 [==============================] - 0s 82us/step - loss: 0.3640 - accuracy: 0.9379 - val_loss: 1.2634 - val_accuracy: 0.5000\n",
      "Epoch 184/1000\n",
      "177/177 [==============================] - 0s 127us/step - loss: 0.4753 - accuracy: 0.9209 - val_loss: 1.1809 - val_accuracy: 0.5263\n",
      "Epoch 185/1000\n",
      "177/177 [==============================] - 0s 91us/step - loss: 0.3915 - accuracy: 0.9266 - val_loss: 1.5488 - val_accuracy: 0.4737\n",
      "Epoch 186/1000\n",
      "177/177 [==============================] - 0s 86us/step - loss: 0.7758 - accuracy: 0.8870 - val_loss: 1.4186 - val_accuracy: 0.5132\n",
      "Epoch 187/1000\n",
      "177/177 [==============================] - 0s 93us/step - loss: 0.4263 - accuracy: 0.9209 - val_loss: 1.2823 - val_accuracy: 0.5132\n",
      "Epoch 188/1000\n",
      "177/177 [==============================] - 0s 123us/step - loss: 0.6176 - accuracy: 0.9209 - val_loss: 1.2347 - val_accuracy: 0.4868\n",
      "Epoch 189/1000\n",
      "177/177 [==============================] - 0s 99us/step - loss: 0.5536 - accuracy: 0.9040 - val_loss: 1.5060 - val_accuracy: 0.4737\n",
      "Epoch 190/1000\n",
      "177/177 [==============================] - 0s 109us/step - loss: 0.3759 - accuracy: 0.9322 - val_loss: 1.1866 - val_accuracy: 0.5132\n",
      "Epoch 191/1000\n",
      "177/177 [==============================] - 0s 173us/step - loss: 0.3203 - accuracy: 0.9379 - val_loss: 1.2113 - val_accuracy: 0.5000\n",
      "Epoch 192/1000\n",
      "177/177 [==============================] - 0s 163us/step - loss: 0.3714 - accuracy: 0.9379 - val_loss: 1.2557 - val_accuracy: 0.5000\n",
      "Epoch 193/1000\n",
      "177/177 [==============================] - 0s 144us/step - loss: 0.2679 - accuracy: 0.9209 - val_loss: 1.2533 - val_accuracy: 0.5000\n",
      "Epoch 194/1000\n",
      "177/177 [==============================] - 0s 252us/step - loss: 0.4915 - accuracy: 0.9209 - val_loss: 1.1950 - val_accuracy: 0.5526\n",
      "Epoch 195/1000\n",
      "177/177 [==============================] - 0s 182us/step - loss: 0.4171 - accuracy: 0.9096 - val_loss: 1.4093 - val_accuracy: 0.4868\n",
      "Epoch 196/1000\n",
      "177/177 [==============================] - 0s 199us/step - loss: 0.4239 - accuracy: 0.9379 - val_loss: 1.2301 - val_accuracy: 0.5263\n",
      "Epoch 197/1000\n",
      "177/177 [==============================] - 0s 142us/step - loss: 0.3638 - accuracy: 0.9322 - val_loss: 1.2995 - val_accuracy: 0.5132\n",
      "Epoch 198/1000\n",
      "177/177 [==============================] - 0s 175us/step - loss: 0.2737 - accuracy: 0.9379 - val_loss: 1.3148 - val_accuracy: 0.4868\n",
      "Epoch 199/1000\n",
      "177/177 [==============================] - 0s 191us/step - loss: 0.3852 - accuracy: 0.9322 - val_loss: 1.2135 - val_accuracy: 0.5263\n",
      "Epoch 200/1000\n",
      "177/177 [==============================] - 0s 143us/step - loss: 0.3099 - accuracy: 0.9435 - val_loss: 1.3327 - val_accuracy: 0.5132\n",
      "Epoch 201/1000\n",
      "177/177 [==============================] - 0s 199us/step - loss: 0.2826 - accuracy: 0.9322 - val_loss: 1.2520 - val_accuracy: 0.5526\n",
      "Epoch 202/1000\n",
      "177/177 [==============================] - 0s 134us/step - loss: 0.2690 - accuracy: 0.9379 - val_loss: 1.3290 - val_accuracy: 0.5395\n",
      "Epoch 203/1000\n",
      "177/177 [==============================] - 0s 185us/step - loss: 0.4146 - accuracy: 0.9322 - val_loss: 1.7279 - val_accuracy: 0.4868\n",
      "Epoch 204/1000\n",
      "177/177 [==============================] - 0s 123us/step - loss: 0.5606 - accuracy: 0.9322 - val_loss: 1.4727 - val_accuracy: 0.4868\n",
      "Epoch 205/1000\n",
      "177/177 [==============================] - 0s 147us/step - loss: 0.3154 - accuracy: 0.9435 - val_loss: 1.2707 - val_accuracy: 0.5395\n",
      "Epoch 206/1000\n",
      "177/177 [==============================] - 0s 149us/step - loss: 0.4854 - accuracy: 0.9322 - val_loss: 1.2713 - val_accuracy: 0.4868\n",
      "Epoch 207/1000\n",
      "177/177 [==============================] - 0s 118us/step - loss: 0.3632 - accuracy: 0.9322 - val_loss: 1.4497 - val_accuracy: 0.4605\n",
      "Epoch 208/1000\n",
      "177/177 [==============================] - 0s 116us/step - loss: 0.4842 - accuracy: 0.9153 - val_loss: 1.2279 - val_accuracy: 0.5263\n",
      "Epoch 209/1000\n",
      "177/177 [==============================] - 0s 118us/step - loss: 0.4064 - accuracy: 0.9266 - val_loss: 1.4040 - val_accuracy: 0.5000\n",
      "Epoch 210/1000\n",
      "177/177 [==============================] - 0s 133us/step - loss: 0.4736 - accuracy: 0.9096 - val_loss: 1.3755 - val_accuracy: 0.5000\n",
      "Epoch 211/1000\n",
      "177/177 [==============================] - 0s 100us/step - loss: 0.3081 - accuracy: 0.9379 - val_loss: 1.2654 - val_accuracy: 0.5263\n",
      "Epoch 212/1000\n",
      "177/177 [==============================] - 0s 83us/step - loss: 0.3572 - accuracy: 0.9548 - val_loss: 1.4227 - val_accuracy: 0.4868\n",
      "Epoch 213/1000\n",
      "177/177 [==============================] - 0s 91us/step - loss: 0.2999 - accuracy: 0.9322 - val_loss: 1.3491 - val_accuracy: 0.5132\n",
      "Epoch 214/1000\n",
      "177/177 [==============================] - 0s 93us/step - loss: 0.3061 - accuracy: 0.9492 - val_loss: 1.2596 - val_accuracy: 0.5263\n",
      "Epoch 215/1000\n",
      "177/177 [==============================] - 0s 93us/step - loss: 0.4132 - accuracy: 0.9379 - val_loss: 1.3163 - val_accuracy: 0.5000\n",
      "Epoch 216/1000\n",
      "177/177 [==============================] - 0s 76us/step - loss: 0.2404 - accuracy: 0.9435 - val_loss: 1.3652 - val_accuracy: 0.5132\n",
      "Epoch 217/1000\n",
      "177/177 [==============================] - 0s 76us/step - loss: 0.5511 - accuracy: 0.9153 - val_loss: 1.3123 - val_accuracy: 0.4605\n",
      "Epoch 218/1000\n",
      "177/177 [==============================] - 0s 75us/step - loss: 0.2954 - accuracy: 0.9548 - val_loss: 1.2933 - val_accuracy: 0.5395\n",
      "Epoch 219/1000\n",
      "177/177 [==============================] - 0s 87us/step - loss: 0.2500 - accuracy: 0.9492 - val_loss: 1.2553 - val_accuracy: 0.5395\n",
      "Epoch 220/1000\n",
      "177/177 [==============================] - 0s 81us/step - loss: 0.2669 - accuracy: 0.9492 - val_loss: 1.3353 - val_accuracy: 0.5526\n",
      "Epoch 221/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177/177 [==============================] - 0s 88us/step - loss: 0.2415 - accuracy: 0.9605 - val_loss: 1.2845 - val_accuracy: 0.5526\n",
      "Epoch 222/1000\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.4238 - accuracy: 0.9435 - val_loss: 1.3582 - val_accuracy: 0.5263\n",
      "Epoch 223/1000\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.4267 - accuracy: 0.9322 - val_loss: 1.4924 - val_accuracy: 0.5000\n",
      "Epoch 224/1000\n",
      "177/177 [==============================] - 0s 107us/step - loss: 0.2647 - accuracy: 0.9266 - val_loss: 1.2915 - val_accuracy: 0.5395\n",
      "Epoch 225/1000\n",
      "177/177 [==============================] - 0s 115us/step - loss: 0.2102 - accuracy: 0.9435 - val_loss: 1.3150 - val_accuracy: 0.5395\n",
      "Epoch 226/1000\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.1825 - accuracy: 0.9492 - val_loss: 1.2966 - val_accuracy: 0.5132\n",
      "Epoch 227/1000\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.2354 - accuracy: 0.9492 - val_loss: 1.3194 - val_accuracy: 0.5263\n",
      "Epoch 228/1000\n",
      "177/177 [==============================] - 0s 117us/step - loss: 0.2045 - accuracy: 0.9548 - val_loss: 1.3157 - val_accuracy: 0.5263\n",
      "Epoch 229/1000\n",
      "177/177 [==============================] - 0s 235us/step - loss: 0.1832 - accuracy: 0.9548 - val_loss: 1.3054 - val_accuracy: 0.5263\n",
      "Epoch 230/1000\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.2559 - accuracy: 0.9492 - val_loss: 1.3161 - val_accuracy: 0.5395\n",
      "Epoch 231/1000\n",
      "177/177 [==============================] - 0s 137us/step - loss: 0.2128 - accuracy: 0.9492 - val_loss: 1.3021 - val_accuracy: 0.5395\n",
      "Epoch 232/1000\n",
      "177/177 [==============================] - 0s 145us/step - loss: 0.1911 - accuracy: 0.9435 - val_loss: 1.4364 - val_accuracy: 0.4737\n",
      "Epoch 233/1000\n",
      "177/177 [==============================] - 0s 112us/step - loss: 0.5021 - accuracy: 0.9266 - val_loss: 1.2912 - val_accuracy: 0.5000\n",
      "Epoch 234/1000\n",
      "177/177 [==============================] - 0s 133us/step - loss: 0.3144 - accuracy: 0.9379 - val_loss: 1.4653 - val_accuracy: 0.5132\n",
      "Epoch 235/1000\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.4644 - accuracy: 0.9153 - val_loss: 1.4797 - val_accuracy: 0.5132\n",
      "Epoch 236/1000\n",
      "177/177 [==============================] - 0s 76us/step - loss: 0.3542 - accuracy: 0.9379 - val_loss: 1.3107 - val_accuracy: 0.5526\n",
      "Epoch 237/1000\n",
      "177/177 [==============================] - 0s 94us/step - loss: 0.4828 - accuracy: 0.9322 - val_loss: 1.3589 - val_accuracy: 0.5000\n",
      "Epoch 238/1000\n",
      "177/177 [==============================] - 0s 132us/step - loss: 0.4176 - accuracy: 0.9379 - val_loss: 1.5096 - val_accuracy: 0.5000\n",
      "Epoch 239/1000\n",
      "177/177 [==============================] - 0s 86us/step - loss: 0.3145 - accuracy: 0.9548 - val_loss: 1.3076 - val_accuracy: 0.5526\n",
      "Epoch 240/1000\n",
      "177/177 [==============================] - 0s 86us/step - loss: 0.1534 - accuracy: 0.9605 - val_loss: 1.3744 - val_accuracy: 0.5132\n",
      "Epoch 241/1000\n",
      "177/177 [==============================] - 0s 107us/step - loss: 0.1985 - accuracy: 0.9492 - val_loss: 1.3535 - val_accuracy: 0.5395\n",
      "Epoch 242/1000\n",
      "177/177 [==============================] - 0s 115us/step - loss: 0.2437 - accuracy: 0.9492 - val_loss: 1.3901 - val_accuracy: 0.5263\n",
      "Epoch 243/1000\n",
      "177/177 [==============================] - 0s 86us/step - loss: 0.2179 - accuracy: 0.9492 - val_loss: 1.3139 - val_accuracy: 0.5263\n",
      "Epoch 244/1000\n",
      "177/177 [==============================] - 0s 82us/step - loss: 0.3258 - accuracy: 0.9492 - val_loss: 1.4539 - val_accuracy: 0.4868\n",
      "Epoch 245/1000\n",
      "177/177 [==============================] - 0s 94us/step - loss: 0.2532 - accuracy: 0.9379 - val_loss: 1.3911 - val_accuracy: 0.5000\n",
      "Epoch 246/1000\n",
      "177/177 [==============================] - 0s 86us/step - loss: 0.3459 - accuracy: 0.9435 - val_loss: 1.3377 - val_accuracy: 0.5263\n",
      "Epoch 247/1000\n",
      "177/177 [==============================] - 0s 107us/step - loss: 0.4502 - accuracy: 0.9379 - val_loss: 1.6696 - val_accuracy: 0.4737\n",
      "Epoch 248/1000\n",
      "177/177 [==============================] - 0s 92us/step - loss: 0.3340 - accuracy: 0.9322 - val_loss: 1.3762 - val_accuracy: 0.5000\n",
      "Epoch 249/1000\n",
      "177/177 [==============================] - 0s 83us/step - loss: 0.4745 - accuracy: 0.9322 - val_loss: 1.3478 - val_accuracy: 0.5526\n",
      "Epoch 250/1000\n",
      "177/177 [==============================] - 0s 95us/step - loss: 0.4636 - accuracy: 0.9322 - val_loss: 1.7641 - val_accuracy: 0.4868\n",
      "Epoch 251/1000\n",
      "177/177 [==============================] - 0s 125us/step - loss: 0.5503 - accuracy: 0.9322 - val_loss: 1.4798 - val_accuracy: 0.4868\n",
      "Epoch 252/1000\n",
      "177/177 [==============================] - 0s 147us/step - loss: 0.2344 - accuracy: 0.9266 - val_loss: 1.4183 - val_accuracy: 0.5395\n",
      "Epoch 253/1000\n",
      "177/177 [==============================] - 0s 94us/step - loss: 0.4679 - accuracy: 0.9379 - val_loss: 1.3953 - val_accuracy: 0.5132\n",
      "Epoch 254/1000\n",
      "177/177 [==============================] - 0s 241us/step - loss: 0.3988 - accuracy: 0.9379 - val_loss: 1.5541 - val_accuracy: 0.5000\n",
      "Epoch 255/1000\n",
      "177/177 [==============================] - 0s 91us/step - loss: 0.2636 - accuracy: 0.9379 - val_loss: 1.3576 - val_accuracy: 0.4868\n",
      "Epoch 256/1000\n",
      "177/177 [==============================] - 0s 129us/step - loss: 0.3089 - accuracy: 0.9435 - val_loss: 1.3592 - val_accuracy: 0.4868\n",
      "Epoch 257/1000\n",
      "177/177 [==============================] - 0s 139us/step - loss: 0.1772 - accuracy: 0.9548 - val_loss: 1.7045 - val_accuracy: 0.4737\n",
      "Epoch 258/1000\n",
      "177/177 [==============================] - 0s 122us/step - loss: 0.4283 - accuracy: 0.9379 - val_loss: 1.5521 - val_accuracy: 0.5000\n",
      "Epoch 259/1000\n",
      "177/177 [==============================] - 0s 103us/step - loss: 0.1763 - accuracy: 0.9548 - val_loss: 1.3749 - val_accuracy: 0.5395\n",
      "Epoch 260/1000\n",
      "177/177 [==============================] - 0s 107us/step - loss: 0.2246 - accuracy: 0.9435 - val_loss: 1.5060 - val_accuracy: 0.5000\n",
      "Epoch 261/1000\n",
      "177/177 [==============================] - 0s 167us/step - loss: 0.3042 - accuracy: 0.9435 - val_loss: 1.4828 - val_accuracy: 0.5000\n",
      "Epoch 262/1000\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.1709 - accuracy: 0.9492 - val_loss: 1.3948 - val_accuracy: 0.5132\n",
      "Epoch 263/1000\n",
      "177/177 [==============================] - 0s 96us/step - loss: 0.1798 - accuracy: 0.9605 - val_loss: 1.4265 - val_accuracy: 0.5132\n",
      "Epoch 264/1000\n",
      "177/177 [==============================] - 0s 148us/step - loss: 0.2941 - accuracy: 0.9492 - val_loss: 1.5854 - val_accuracy: 0.5000\n",
      "Epoch 265/1000\n",
      "177/177 [==============================] - 0s 107us/step - loss: 0.2070 - accuracy: 0.9435 - val_loss: 1.4009 - val_accuracy: 0.5263\n",
      "Epoch 266/1000\n",
      "177/177 [==============================] - 0s 122us/step - loss: 0.3339 - accuracy: 0.9322 - val_loss: 1.4173 - val_accuracy: 0.5132\n",
      "Epoch 267/1000\n",
      "177/177 [==============================] - 0s 168us/step - loss: 0.3077 - accuracy: 0.9492 - val_loss: 1.6048 - val_accuracy: 0.4868\n",
      "Epoch 268/1000\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.2054 - accuracy: 0.9435 - val_loss: 1.4011 - val_accuracy: 0.5263\n",
      "Epoch 269/1000\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.3799 - accuracy: 0.9379 - val_loss: 1.3920 - val_accuracy: 0.5395\n",
      "Epoch 270/1000\n",
      "177/177 [==============================] - 0s 126us/step - loss: 0.2354 - accuracy: 0.9435 - val_loss: 1.6000 - val_accuracy: 0.4868\n",
      "Epoch 271/1000\n",
      "177/177 [==============================] - 0s 82us/step - loss: 0.3103 - accuracy: 0.9435 - val_loss: 1.4218 - val_accuracy: 0.5263\n",
      "Epoch 272/1000\n",
      "177/177 [==============================] - 0s 107us/step - loss: 0.1319 - accuracy: 0.9548 - val_loss: 1.4225 - val_accuracy: 0.5132\n",
      "Epoch 273/1000\n",
      "177/177 [==============================] - 0s 82us/step - loss: 0.1484 - accuracy: 0.9548 - val_loss: 1.4186 - val_accuracy: 0.5395\n",
      "Epoch 274/1000\n",
      "177/177 [==============================] - 0s 102us/step - loss: 0.1402 - accuracy: 0.9661 - val_loss: 1.4161 - val_accuracy: 0.5263\n",
      "Epoch 275/1000\n",
      "177/177 [==============================] - 0s 135us/step - loss: 0.1983 - accuracy: 0.9548 - val_loss: 1.4212 - val_accuracy: 0.5132\n",
      "Epoch 276/1000\n",
      "177/177 [==============================] - 0s 83us/step - loss: 0.1637 - accuracy: 0.9661 - val_loss: 1.4290 - val_accuracy: 0.5395\n",
      "Epoch 277/1000\n",
      "177/177 [==============================] - 0s 104us/step - loss: 0.5113 - accuracy: 0.9266 - val_loss: 1.4907 - val_accuracy: 0.5263\n",
      "Epoch 278/1000\n",
      "177/177 [==============================] - 0s 115us/step - loss: 0.2270 - accuracy: 0.9435 - val_loss: 1.4181 - val_accuracy: 0.5395\n",
      "Epoch 279/1000\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.2551 - accuracy: 0.9435 - val_loss: 1.4887 - val_accuracy: 0.5132\n",
      "Epoch 280/1000\n",
      "177/177 [==============================] - 0s 92us/step - loss: 0.3684 - accuracy: 0.9492 - val_loss: 1.7097 - val_accuracy: 0.5000\n",
      "Epoch 281/1000\n",
      "177/177 [==============================] - 0s 96us/step - loss: 0.2718 - accuracy: 0.9605 - val_loss: 1.4272 - val_accuracy: 0.5395\n",
      "Epoch 282/1000\n",
      "177/177 [==============================] - 0s 110us/step - loss: 0.1760 - accuracy: 0.9548 - val_loss: 1.4350 - val_accuracy: 0.5263\n",
      "Epoch 283/1000\n",
      "177/177 [==============================] - 0s 82us/step - loss: 0.1333 - accuracy: 0.9548 - val_loss: 1.4689 - val_accuracy: 0.5132\n",
      "Epoch 284/1000\n",
      "177/177 [==============================] - 0s 137us/step - loss: 0.1422 - accuracy: 0.9661 - val_loss: 1.4345 - val_accuracy: 0.5263\n",
      "Epoch 285/1000\n",
      "177/177 [==============================] - 0s 140us/step - loss: 0.1879 - accuracy: 0.9548 - val_loss: 1.4521 - val_accuracy: 0.5263\n",
      "Epoch 286/1000\n",
      "177/177 [==============================] - 0s 134us/step - loss: 0.1951 - accuracy: 0.9661 - val_loss: 1.4448 - val_accuracy: 0.5132\n",
      "Epoch 287/1000\n",
      "177/177 [==============================] - 0s 99us/step - loss: 0.1344 - accuracy: 0.9718 - val_loss: 1.4433 - val_accuracy: 0.5658\n",
      "Epoch 288/1000\n",
      "177/177 [==============================] - 0s 109us/step - loss: 0.1709 - accuracy: 0.9605 - val_loss: 1.4885 - val_accuracy: 0.5395\n",
      "Epoch 289/1000\n",
      "177/177 [==============================] - 0s 139us/step - loss: 0.1349 - accuracy: 0.9661 - val_loss: 1.4630 - val_accuracy: 0.5395\n",
      "Epoch 290/1000\n",
      "177/177 [==============================] - 0s 107us/step - loss: 0.1361 - accuracy: 0.9605 - val_loss: 1.4304 - val_accuracy: 0.5132\n",
      "Epoch 291/1000\n",
      "177/177 [==============================] - 0s 128us/step - loss: 0.1431 - accuracy: 0.9661 - val_loss: 1.4814 - val_accuracy: 0.5395\n",
      "Epoch 292/1000\n",
      "177/177 [==============================] - 0s 115us/step - loss: 0.1857 - accuracy: 0.9661 - val_loss: 1.4572 - val_accuracy: 0.5263\n",
      "Epoch 293/1000\n",
      "177/177 [==============================] - 0s 149us/step - loss: 0.1721 - accuracy: 0.9605 - val_loss: 1.4716 - val_accuracy: 0.5263\n",
      "Epoch 294/1000\n",
      "177/177 [==============================] - 0s 85us/step - loss: 0.1575 - accuracy: 0.9661 - val_loss: 1.4559 - val_accuracy: 0.5263\n",
      "Epoch 295/1000\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.1270 - accuracy: 0.9718 - val_loss: 1.4659 - val_accuracy: 0.5000\n",
      "Epoch 296/1000\n",
      "177/177 [==============================] - 0s 75us/step - loss: 0.1246 - accuracy: 0.9718 - val_loss: 1.4793 - val_accuracy: 0.5132\n",
      "Epoch 297/1000\n",
      "177/177 [==============================] - 0s 99us/step - loss: 0.1729 - accuracy: 0.9661 - val_loss: 1.4724 - val_accuracy: 0.5263\n",
      "Epoch 298/1000\n",
      "177/177 [==============================] - 0s 107us/step - loss: 0.1867 - accuracy: 0.9661 - val_loss: 1.4733 - val_accuracy: 0.5263\n",
      "Epoch 299/1000\n",
      "177/177 [==============================] - 0s 92us/step - loss: 0.2117 - accuracy: 0.9661 - val_loss: 1.5036 - val_accuracy: 0.5395\n",
      "Epoch 300/1000\n",
      "177/177 [==============================] - 0s 89us/step - loss: 0.2047 - accuracy: 0.9661 - val_loss: 1.4817 - val_accuracy: 0.5526\n",
      "Epoch 301/1000\n",
      "177/177 [==============================] - 0s 127us/step - loss: 0.2795 - accuracy: 0.9492 - val_loss: 1.5773 - val_accuracy: 0.5132\n",
      "Epoch 302/1000\n",
      "177/177 [==============================] - 0s 85us/step - loss: 0.2007 - accuracy: 0.9661 - val_loss: 1.4864 - val_accuracy: 0.5395\n",
      "Epoch 303/1000\n",
      "177/177 [==============================] - 0s 105us/step - loss: 0.1707 - accuracy: 0.9718 - val_loss: 1.4941 - val_accuracy: 0.5395\n",
      "Epoch 304/1000\n",
      "177/177 [==============================] - 0s 107us/step - loss: 0.1644 - accuracy: 0.9661 - val_loss: 1.4944 - val_accuracy: 0.5395\n",
      "Epoch 305/1000\n",
      "177/177 [==============================] - 0s 145us/step - loss: 0.1198 - accuracy: 0.9718 - val_loss: 1.4852 - val_accuracy: 0.5395\n",
      "Epoch 306/1000\n",
      "177/177 [==============================] - 0s 117us/step - loss: 0.1252 - accuracy: 0.9718 - val_loss: 1.5848 - val_accuracy: 0.5263\n",
      "Epoch 307/1000\n",
      "177/177 [==============================] - 0s 114us/step - loss: 0.1972 - accuracy: 0.9605 - val_loss: 1.5156 - val_accuracy: 0.5395\n",
      "Epoch 308/1000\n",
      "177/177 [==============================] - 0s 120us/step - loss: 0.2244 - accuracy: 0.9492 - val_loss: 1.4859 - val_accuracy: 0.5395\n",
      "Epoch 309/1000\n",
      "177/177 [==============================] - 0s 119us/step - loss: 0.1369 - accuracy: 0.9774 - val_loss: 1.6813 - val_accuracy: 0.5000\n",
      "Epoch 310/1000\n",
      "177/177 [==============================] - 0s 103us/step - loss: 0.2916 - accuracy: 0.9548 - val_loss: 1.5493 - val_accuracy: 0.5132\n",
      "Epoch 311/1000\n",
      "177/177 [==============================] - 0s 97us/step - loss: 0.1616 - accuracy: 0.9605 - val_loss: 1.5070 - val_accuracy: 0.5658\n",
      "Epoch 312/1000\n",
      "177/177 [==============================] - 0s 120us/step - loss: 0.4003 - accuracy: 0.9492 - val_loss: 1.6236 - val_accuracy: 0.4737\n",
      "Epoch 313/1000\n",
      "177/177 [==============================] - 0s 118us/step - loss: 0.2391 - accuracy: 0.9661 - val_loss: 1.5137 - val_accuracy: 0.5263\n",
      "Epoch 314/1000\n",
      "177/177 [==============================] - 0s 94us/step - loss: 0.1408 - accuracy: 0.9605 - val_loss: 1.5343 - val_accuracy: 0.5132\n",
      "Epoch 315/1000\n",
      "177/177 [==============================] - 0s 127us/step - loss: 0.1631 - accuracy: 0.9605 - val_loss: 1.5196 - val_accuracy: 0.5395\n",
      "Epoch 316/1000\n",
      "177/177 [==============================] - 0s 149us/step - loss: 0.2244 - accuracy: 0.9661 - val_loss: 1.5105 - val_accuracy: 0.5395\n",
      "Epoch 317/1000\n",
      "177/177 [==============================] - 0s 99us/step - loss: 0.1676 - accuracy: 0.9605 - val_loss: 1.5122 - val_accuracy: 0.5395\n",
      "Epoch 318/1000\n",
      "177/177 [==============================] - 0s 96us/step - loss: 0.1297 - accuracy: 0.9774 - val_loss: 1.5566 - val_accuracy: 0.5395\n",
      "Epoch 319/1000\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.1952 - accuracy: 0.9661 - val_loss: 1.5715 - val_accuracy: 0.5263\n",
      "Epoch 320/1000\n",
      "177/177 [==============================] - 0s 124us/step - loss: 0.2306 - accuracy: 0.9548 - val_loss: 1.5096 - val_accuracy: 0.5526\n",
      "Epoch 321/1000\n",
      "177/177 [==============================] - 0s 85us/step - loss: 0.2784 - accuracy: 0.9605 - val_loss: 1.7449 - val_accuracy: 0.4868\n",
      "Epoch 322/1000\n",
      "177/177 [==============================] - 0s 83us/step - loss: 0.3717 - accuracy: 0.9492 - val_loss: 1.7116 - val_accuracy: 0.5000\n",
      "Epoch 323/1000\n",
      "177/177 [==============================] - 0s 79us/step - loss: 0.3194 - accuracy: 0.9435 - val_loss: 1.5435 - val_accuracy: 0.5526\n",
      "Epoch 324/1000\n",
      "177/177 [==============================] - 0s 107us/step - loss: 0.2136 - accuracy: 0.9605 - val_loss: 1.6078 - val_accuracy: 0.5132\n",
      "Epoch 325/1000\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.1843 - accuracy: 0.9605 - val_loss: 1.5531 - val_accuracy: 0.5132\n",
      "Epoch 326/1000\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.1511 - accuracy: 0.9605 - val_loss: 1.5359 - val_accuracy: 0.5395\n",
      "Epoch 327/1000\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.3480 - accuracy: 0.9605 - val_loss: 1.5226 - val_accuracy: 0.5263\n",
      "Epoch 328/1000\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.1347 - accuracy: 0.9718 - val_loss: 1.5647 - val_accuracy: 0.5000\n",
      "Epoch 329/1000\n",
      "177/177 [==============================] - 0s 122us/step - loss: 0.2821 - accuracy: 0.9492 - val_loss: 1.5736 - val_accuracy: 0.5132\n",
      "Epoch 330/1000\n",
      "177/177 [==============================] - 0s 86us/step - loss: 0.1525 - accuracy: 0.9605 - val_loss: 1.6769 - val_accuracy: 0.4737\n",
      "Epoch 331/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177/177 [==============================] - 0s 87us/step - loss: 0.1798 - accuracy: 0.9718 - val_loss: 1.5670 - val_accuracy: 0.5263\n",
      "Epoch 332/1000\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.1504 - accuracy: 0.9661 - val_loss: 1.5880 - val_accuracy: 0.5263\n",
      "Epoch 333/1000\n",
      "177/177 [==============================] - 0s 83us/step - loss: 0.2408 - accuracy: 0.9548 - val_loss: 1.7152 - val_accuracy: 0.5000\n",
      "Epoch 334/1000\n",
      "177/177 [==============================] - 0s 99us/step - loss: 0.2043 - accuracy: 0.9718 - val_loss: 1.5551 - val_accuracy: 0.5526\n",
      "Epoch 335/1000\n",
      "177/177 [==============================] - 0s 84us/step - loss: 0.2463 - accuracy: 0.9548 - val_loss: 1.6085 - val_accuracy: 0.5132\n",
      "Epoch 336/1000\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.1725 - accuracy: 0.9605 - val_loss: 1.5931 - val_accuracy: 0.5263\n",
      "Epoch 337/1000\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.2603 - accuracy: 0.9492 - val_loss: 1.5958 - val_accuracy: 0.5395\n",
      "Epoch 338/1000\n",
      "177/177 [==============================] - 0s 125us/step - loss: 0.1542 - accuracy: 0.9661 - val_loss: 1.7822 - val_accuracy: 0.5000\n",
      "Epoch 339/1000\n",
      "177/177 [==============================] - 0s 105us/step - loss: 0.3149 - accuracy: 0.9379 - val_loss: 1.6037 - val_accuracy: 0.5263\n",
      "Epoch 340/1000\n",
      "177/177 [==============================] - 0s 159us/step - loss: 0.3658 - accuracy: 0.9605 - val_loss: 1.6611 - val_accuracy: 0.5395\n",
      "Epoch 341/1000\n",
      "177/177 [==============================] - 0s 234us/step - loss: 0.3592 - accuracy: 0.9435 - val_loss: 1.6052 - val_accuracy: 0.5132\n",
      "Epoch 342/1000\n",
      "177/177 [==============================] - 0s 109us/step - loss: 0.1324 - accuracy: 0.9718 - val_loss: 1.5745 - val_accuracy: 0.5526\n",
      "Epoch 343/1000\n",
      "177/177 [==============================] - 0s 110us/step - loss: 0.1294 - accuracy: 0.9718 - val_loss: 1.5935 - val_accuracy: 0.5395\n",
      "Epoch 344/1000\n",
      "177/177 [==============================] - ETA: 0s - loss: 0.0743 - accuracy: 1.00 - 0s 105us/step - loss: 0.1198 - accuracy: 0.9774 - val_loss: 1.5779 - val_accuracy: 0.5000\n",
      "Epoch 345/1000\n",
      "177/177 [==============================] - 0s 116us/step - loss: 0.1830 - accuracy: 0.9718 - val_loss: 1.6019 - val_accuracy: 0.5263\n",
      "Epoch 346/1000\n",
      "177/177 [==============================] - 0s 116us/step - loss: 0.1483 - accuracy: 0.9661 - val_loss: 1.6204 - val_accuracy: 0.5526\n",
      "Epoch 347/1000\n",
      "177/177 [==============================] - 0s 99us/step - loss: 0.1069 - accuracy: 0.9774 - val_loss: 1.5774 - val_accuracy: 0.5526\n",
      "Epoch 348/1000\n",
      "177/177 [==============================] - 0s 89us/step - loss: 0.1518 - accuracy: 0.9661 - val_loss: 1.6822 - val_accuracy: 0.5263\n",
      "Epoch 349/1000\n",
      "177/177 [==============================] - 0s 118us/step - loss: 0.2212 - accuracy: 0.9661 - val_loss: 1.6071 - val_accuracy: 0.5263\n",
      "Epoch 350/1000\n",
      "177/177 [==============================] - 0s 100us/step - loss: 0.2035 - accuracy: 0.9605 - val_loss: 1.6276 - val_accuracy: 0.5000\n",
      "Epoch 351/1000\n",
      "177/177 [==============================] - 0s 121us/step - loss: 0.2720 - accuracy: 0.9435 - val_loss: 1.7023 - val_accuracy: 0.5263\n",
      "Epoch 352/1000\n",
      "177/177 [==============================] - 0s 240us/step - loss: 0.2202 - accuracy: 0.9548 - val_loss: 1.6225 - val_accuracy: 0.5263\n",
      "Epoch 353/1000\n",
      "177/177 [==============================] - 0s 96us/step - loss: 0.1482 - accuracy: 0.9661 - val_loss: 1.6156 - val_accuracy: 0.5000\n",
      "Epoch 354/1000\n",
      "177/177 [==============================] - 0s 108us/step - loss: 0.1684 - accuracy: 0.9605 - val_loss: 1.6123 - val_accuracy: 0.4868\n",
      "Epoch 355/1000\n",
      "177/177 [==============================] - 0s 105us/step - loss: 0.1903 - accuracy: 0.9661 - val_loss: 1.7304 - val_accuracy: 0.5000\n",
      "Epoch 356/1000\n",
      "177/177 [==============================] - 0s 102us/step - loss: 0.1711 - accuracy: 0.9661 - val_loss: 1.6258 - val_accuracy: 0.5395\n",
      "Epoch 357/1000\n",
      "177/177 [==============================] - 0s 110us/step - loss: 0.1603 - accuracy: 0.9492 - val_loss: 1.7178 - val_accuracy: 0.5000\n",
      "Epoch 358/1000\n",
      "177/177 [==============================] - 0s 113us/step - loss: 0.3017 - accuracy: 0.9492 - val_loss: 1.7607 - val_accuracy: 0.5000\n",
      "Epoch 359/1000\n",
      "177/177 [==============================] - 0s 114us/step - loss: 0.2359 - accuracy: 0.9379 - val_loss: 1.6230 - val_accuracy: 0.5263\n",
      "Epoch 360/1000\n",
      "177/177 [==============================] - 0s 103us/step - loss: 0.2423 - accuracy: 0.9661 - val_loss: 1.6945 - val_accuracy: 0.5000\n",
      "Epoch 361/1000\n",
      "177/177 [==============================] - 0s 106us/step - loss: 0.1393 - accuracy: 0.9718 - val_loss: 1.6187 - val_accuracy: 0.5263\n",
      "Epoch 362/1000\n",
      "177/177 [==============================] - 0s 107us/step - loss: 0.2541 - accuracy: 0.9605 - val_loss: 1.7775 - val_accuracy: 0.5132\n",
      "Epoch 363/1000\n",
      "177/177 [==============================] - 0s 102us/step - loss: 0.3486 - accuracy: 0.9435 - val_loss: 1.8344 - val_accuracy: 0.4737\n",
      "Epoch 364/1000\n",
      "177/177 [==============================] - 0s 85us/step - loss: 0.2339 - accuracy: 0.9492 - val_loss: 1.6295 - val_accuracy: 0.5263\n",
      "Epoch 365/1000\n",
      "177/177 [==============================] - 0s 168us/step - loss: 0.2824 - accuracy: 0.9435 - val_loss: 1.7334 - val_accuracy: 0.5000\n",
      "Epoch 366/1000\n",
      "177/177 [==============================] - 0s 281us/step - loss: 0.2745 - accuracy: 0.9661 - val_loss: 1.6890 - val_accuracy: 0.5263\n",
      "Epoch 367/1000\n",
      "177/177 [==============================] - 0s 145us/step - loss: 0.2246 - accuracy: 0.9492 - val_loss: 1.6456 - val_accuracy: 0.5132\n",
      "Epoch 368/1000\n",
      "177/177 [==============================] - 0s 102us/step - loss: 0.1485 - accuracy: 0.9661 - val_loss: 1.6562 - val_accuracy: 0.4868\n",
      "Epoch 369/1000\n",
      "177/177 [==============================] - 0s 99us/step - loss: 0.1288 - accuracy: 0.9661 - val_loss: 1.6432 - val_accuracy: 0.5000\n",
      "Epoch 370/1000\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.1516 - accuracy: 0.9661 - val_loss: 1.6627 - val_accuracy: 0.5000\n",
      "Epoch 371/1000\n",
      "177/177 [==============================] - 0s 96us/step - loss: 0.1233 - accuracy: 0.9718 - val_loss: 1.6489 - val_accuracy: 0.5526\n",
      "Epoch 372/1000\n",
      "177/177 [==============================] - 0s 102us/step - loss: 0.1110 - accuracy: 0.9661 - val_loss: 1.6793 - val_accuracy: 0.5395\n",
      "Epoch 373/1000\n",
      "177/177 [==============================] - 0s 89us/step - loss: 0.1342 - accuracy: 0.9661 - val_loss: 1.6840 - val_accuracy: 0.5395\n",
      "Epoch 374/1000\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.1028 - accuracy: 0.9661 - val_loss: 1.7062 - val_accuracy: 0.5395\n",
      "Epoch 375/1000\n",
      "177/177 [==============================] - 0s 86us/step - loss: 0.1811 - accuracy: 0.9661 - val_loss: 1.6788 - val_accuracy: 0.5132\n",
      "Epoch 376/1000\n",
      "177/177 [==============================] - 0s 96us/step - loss: 0.2645 - accuracy: 0.9379 - val_loss: 1.7933 - val_accuracy: 0.5132\n",
      "Epoch 377/1000\n",
      "177/177 [==============================] - 0s 101us/step - loss: 0.1207 - accuracy: 0.9661 - val_loss: 1.6652 - val_accuracy: 0.5263\n",
      "Epoch 378/1000\n",
      "177/177 [==============================] - 0s 108us/step - loss: 0.3493 - accuracy: 0.9435 - val_loss: 1.7166 - val_accuracy: 0.5263\n",
      "Epoch 379/1000\n",
      "177/177 [==============================] - 0s 94us/step - loss: 0.1690 - accuracy: 0.9718 - val_loss: 1.6589 - val_accuracy: 0.5132\n",
      "Epoch 380/1000\n",
      "177/177 [==============================] - 0s 95us/step - loss: 0.1396 - accuracy: 0.9718 - val_loss: 2.0083 - val_accuracy: 0.4868\n",
      "Epoch 381/1000\n",
      "177/177 [==============================] - 0s 96us/step - loss: 0.3424 - accuracy: 0.9605 - val_loss: 1.7596 - val_accuracy: 0.5000\n",
      "Epoch 382/1000\n",
      "177/177 [==============================] - 0s 89us/step - loss: 0.1050 - accuracy: 0.9605 - val_loss: 1.6935 - val_accuracy: 0.5263\n",
      "Epoch 383/1000\n",
      "177/177 [==============================] - 0s 89us/step - loss: 0.1045 - accuracy: 0.9661 - val_loss: 1.7019 - val_accuracy: 0.5263\n",
      "Epoch 384/1000\n",
      "177/177 [==============================] - ETA: 0s - loss: 0.0752 - accuracy: 0.96 - 0s 88us/step - loss: 0.1317 - accuracy: 0.9605 - val_loss: 1.7331 - val_accuracy: 0.4868\n",
      "Epoch 385/1000\n",
      "177/177 [==============================] - 0s 89us/step - loss: 0.1208 - accuracy: 0.9774 - val_loss: 1.6937 - val_accuracy: 0.5132\n",
      "Epoch 386/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177/177 [==============================] - 0s 97us/step - loss: 0.0931 - accuracy: 0.9831 - val_loss: 1.7106 - val_accuracy: 0.4868\n",
      "Epoch 387/1000\n",
      "177/177 [==============================] - 0s 99us/step - loss: 0.0891 - accuracy: 0.9718 - val_loss: 1.6976 - val_accuracy: 0.4868\n",
      "Epoch 388/1000\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.1351 - accuracy: 0.9718 - val_loss: 1.7242 - val_accuracy: 0.5000\n",
      "Epoch 389/1000\n",
      "177/177 [==============================] - 0s 141us/step - loss: 0.1083 - accuracy: 0.9718 - val_loss: 1.7052 - val_accuracy: 0.5263\n",
      "Epoch 390/1000\n",
      "177/177 [==============================] - 0s 105us/step - loss: 0.1164 - accuracy: 0.9774 - val_loss: 1.7290 - val_accuracy: 0.5263\n",
      "Epoch 391/1000\n",
      "177/177 [==============================] - 0s 99us/step - loss: 0.0982 - accuracy: 0.9718 - val_loss: 1.6986 - val_accuracy: 0.4868\n",
      "Epoch 392/1000\n",
      "177/177 [==============================] - 0s 108us/step - loss: 0.1648 - accuracy: 0.9661 - val_loss: 1.7067 - val_accuracy: 0.5000\n",
      "Epoch 393/1000\n",
      "177/177 [==============================] - 0s 99us/step - loss: 0.1051 - accuracy: 0.9718 - val_loss: 1.7341 - val_accuracy: 0.5132\n",
      "Epoch 394/1000\n",
      "177/177 [==============================] - 0s 107us/step - loss: 0.0802 - accuracy: 0.9831 - val_loss: 1.7228 - val_accuracy: 0.5132\n",
      "Epoch 395/1000\n",
      "177/177 [==============================] - 0s 100us/step - loss: 0.0837 - accuracy: 0.9774 - val_loss: 1.7376 - val_accuracy: 0.5000\n",
      "Epoch 396/1000\n",
      "177/177 [==============================] - 0s 100us/step - loss: 0.1362 - accuracy: 0.9718 - val_loss: 1.7346 - val_accuracy: 0.5263\n",
      "Epoch 397/1000\n",
      "177/177 [==============================] - 0s 109us/step - loss: 0.0867 - accuracy: 0.9774 - val_loss: 1.7138 - val_accuracy: 0.5000\n",
      "Epoch 398/1000\n",
      "177/177 [==============================] - 0s 109us/step - loss: 0.0938 - accuracy: 0.9774 - val_loss: 1.7900 - val_accuracy: 0.5132\n",
      "Epoch 399/1000\n",
      "177/177 [==============================] - 0s 123us/step - loss: 0.1377 - accuracy: 0.9661 - val_loss: 1.7288 - val_accuracy: 0.5000\n",
      "Epoch 400/1000\n",
      "177/177 [==============================] - 0s 108us/step - loss: 0.0897 - accuracy: 0.9831 - val_loss: 1.7194 - val_accuracy: 0.5263\n",
      "Epoch 401/1000\n",
      "177/177 [==============================] - 0s 111us/step - loss: 0.1287 - accuracy: 0.9718 - val_loss: 1.8291 - val_accuracy: 0.5000\n",
      "Epoch 402/1000\n",
      "177/177 [==============================] - 0s 134us/step - loss: 0.1917 - accuracy: 0.9605 - val_loss: 1.7517 - val_accuracy: 0.5132\n",
      "Epoch 403/1000\n",
      "177/177 [==============================] - 0s 116us/step - loss: 0.1116 - accuracy: 0.9774 - val_loss: 1.7308 - val_accuracy: 0.5263\n",
      "Epoch 404/1000\n",
      "177/177 [==============================] - 0s 109us/step - loss: 0.3335 - accuracy: 0.9435 - val_loss: 1.7806 - val_accuracy: 0.5000\n",
      "Epoch 405/1000\n",
      "177/177 [==============================] - 0s 123us/step - loss: 0.2214 - accuracy: 0.9435 - val_loss: 1.7191 - val_accuracy: 0.5263\n",
      "Epoch 406/1000\n",
      "177/177 [==============================] - 0s 118us/step - loss: 0.4183 - accuracy: 0.9492 - val_loss: 1.7625 - val_accuracy: 0.5263\n",
      "Epoch 407/1000\n",
      "177/177 [==============================] - 0s 114us/step - loss: 0.1652 - accuracy: 0.9492 - val_loss: 1.7891 - val_accuracy: 0.4737\n",
      "Epoch 408/1000\n",
      "177/177 [==============================] - 0s 134us/step - loss: 0.1381 - accuracy: 0.9718 - val_loss: 1.7483 - val_accuracy: 0.5263\n",
      "Epoch 409/1000\n",
      "177/177 [==============================] - 0s 94us/step - loss: 0.1462 - accuracy: 0.9718 - val_loss: 1.7989 - val_accuracy: 0.5000\n",
      "Epoch 410/1000\n",
      "177/177 [==============================] - 0s 83us/step - loss: 0.2502 - accuracy: 0.9605 - val_loss: 1.7398 - val_accuracy: 0.5395\n",
      "Epoch 411/1000\n",
      "177/177 [==============================] - 0s 81us/step - loss: 0.2249 - accuracy: 0.9548 - val_loss: 1.7529 - val_accuracy: 0.5263\n",
      "Epoch 412/1000\n",
      "177/177 [==============================] - 0s 95us/step - loss: 0.4848 - accuracy: 0.9492 - val_loss: 1.7187 - val_accuracy: 0.5132\n",
      "Epoch 413/1000\n",
      "177/177 [==============================] - 0s 97us/step - loss: 0.2300 - accuracy: 0.9492 - val_loss: 1.7966 - val_accuracy: 0.4868\n",
      "Epoch 414/1000\n",
      "177/177 [==============================] - 0s 91us/step - loss: 0.1342 - accuracy: 0.9718 - val_loss: 1.7638 - val_accuracy: 0.5263\n",
      "Epoch 415/1000\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.0896 - accuracy: 0.9718 - val_loss: 1.7414 - val_accuracy: 0.5395\n",
      "Epoch 416/1000\n",
      "177/177 [==============================] - 0s 101us/step - loss: 0.1723 - accuracy: 0.9661 - val_loss: 1.7815 - val_accuracy: 0.5263\n",
      "Epoch 417/1000\n",
      "177/177 [==============================] - 0s 95us/step - loss: 0.1410 - accuracy: 0.9718 - val_loss: 1.8149 - val_accuracy: 0.5395\n",
      "Epoch 418/1000\n",
      "177/177 [==============================] - 0s 97us/step - loss: 0.1673 - accuracy: 0.9605 - val_loss: 1.8152 - val_accuracy: 0.4868\n",
      "Epoch 419/1000\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.2162 - accuracy: 0.9605 - val_loss: 1.7395 - val_accuracy: 0.5132\n",
      "Epoch 420/1000\n",
      "177/177 [==============================] - 0s 102us/step - loss: 0.1736 - accuracy: 0.9605 - val_loss: 1.8696 - val_accuracy: 0.5000\n",
      "Epoch 421/1000\n",
      "177/177 [==============================] - 0s 115us/step - loss: 0.2226 - accuracy: 0.9435 - val_loss: 1.7902 - val_accuracy: 0.5395\n",
      "Epoch 422/1000\n",
      "177/177 [==============================] - 0s 112us/step - loss: 0.2020 - accuracy: 0.9661 - val_loss: 1.7965 - val_accuracy: 0.5263\n",
      "Epoch 423/1000\n",
      "177/177 [==============================] - 0s 112us/step - loss: 0.3533 - accuracy: 0.9435 - val_loss: 2.0390 - val_accuracy: 0.4605\n",
      "Epoch 424/1000\n",
      "177/177 [==============================] - 0s 101us/step - loss: 0.5108 - accuracy: 0.9492 - val_loss: 1.8078 - val_accuracy: 0.5000\n",
      "Epoch 425/1000\n",
      "177/177 [==============================] - 0s 115us/step - loss: 0.2529 - accuracy: 0.9548 - val_loss: 1.7897 - val_accuracy: 0.5263\n",
      "Epoch 426/1000\n",
      "177/177 [==============================] - 0s 115us/step - loss: 0.4231 - accuracy: 0.9548 - val_loss: 1.7753 - val_accuracy: 0.5263\n",
      "Epoch 427/1000\n",
      "177/177 [==============================] - 0s 122us/step - loss: 0.1540 - accuracy: 0.9661 - val_loss: 1.9376 - val_accuracy: 0.4605\n",
      "Epoch 428/1000\n",
      "177/177 [==============================] - 0s 108us/step - loss: 0.3900 - accuracy: 0.9492 - val_loss: 1.7661 - val_accuracy: 0.5132\n",
      "Epoch 429/1000\n",
      "177/177 [==============================] - 0s 92us/step - loss: 0.2931 - accuracy: 0.9548 - val_loss: 1.7764 - val_accuracy: 0.5263\n",
      "Epoch 430/1000\n",
      "177/177 [==============================] - 0s 83us/step - loss: 0.1333 - accuracy: 0.9718 - val_loss: 1.8591 - val_accuracy: 0.5000\n",
      "Epoch 431/1000\n",
      "177/177 [==============================] - 0s 93us/step - loss: 0.2187 - accuracy: 0.9605 - val_loss: 1.8085 - val_accuracy: 0.5263\n",
      "Epoch 432/1000\n",
      "177/177 [==============================] - 0s 108us/step - loss: 0.1469 - accuracy: 0.9774 - val_loss: 1.8204 - val_accuracy: 0.5132\n",
      "Epoch 433/1000\n",
      "177/177 [==============================] - 0s 87us/step - loss: 0.2679 - accuracy: 0.9605 - val_loss: 1.9828 - val_accuracy: 0.4605\n",
      "Epoch 434/1000\n",
      "177/177 [==============================] - 0s 92us/step - loss: 0.1690 - accuracy: 0.9492 - val_loss: 1.8008 - val_accuracy: 0.5132\n",
      "Epoch 435/1000\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.5089 - accuracy: 0.9322 - val_loss: 1.8399 - val_accuracy: 0.5000\n",
      "Epoch 436/1000\n",
      "177/177 [==============================] - 0s 84us/step - loss: 0.3815 - accuracy: 0.9435 - val_loss: 2.2622 - val_accuracy: 0.4737\n",
      "Epoch 437/1000\n",
      "177/177 [==============================] - 0s 93us/step - loss: 0.5344 - accuracy: 0.9266 - val_loss: 1.8557 - val_accuracy: 0.4868\n",
      "Epoch 438/1000\n",
      "177/177 [==============================] - 0s 86us/step - loss: 0.2017 - accuracy: 0.9548 - val_loss: 1.8547 - val_accuracy: 0.5132\n",
      "Epoch 439/1000\n",
      "177/177 [==============================] - 0s 86us/step - loss: 0.2310 - accuracy: 0.9435 - val_loss: 1.8523 - val_accuracy: 0.4868\n",
      "Epoch 440/1000\n",
      "177/177 [==============================] - 0s 97us/step - loss: 0.2049 - accuracy: 0.9718 - val_loss: 1.8033 - val_accuracy: 0.5263\n",
      "Epoch 441/1000\n",
      "177/177 [==============================] - 0s 100us/step - loss: 0.0995 - accuracy: 0.9774 - val_loss: 1.8684 - val_accuracy: 0.4868\n",
      "Epoch 442/1000\n",
      "177/177 [==============================] - 0s 103us/step - loss: 0.1363 - accuracy: 0.9605 - val_loss: 1.8111 - val_accuracy: 0.5000\n",
      "Epoch 443/1000\n",
      "177/177 [==============================] - 0s 115us/step - loss: 0.1244 - accuracy: 0.9774 - val_loss: 1.8635 - val_accuracy: 0.5000\n",
      "Epoch 444/1000\n",
      "177/177 [==============================] - 0s 113us/step - loss: 0.2040 - accuracy: 0.9605 - val_loss: 1.8999 - val_accuracy: 0.4868\n",
      "Epoch 445/1000\n",
      "177/177 [==============================] - 0s 131us/step - loss: 0.1680 - accuracy: 0.9661 - val_loss: 1.8646 - val_accuracy: 0.5000\n",
      "Epoch 446/1000\n",
      "177/177 [==============================] - 0s 121us/step - loss: 0.1374 - accuracy: 0.9661 - val_loss: 1.8440 - val_accuracy: 0.5000\n",
      "Epoch 447/1000\n",
      "177/177 [==============================] - 0s 112us/step - loss: 0.1003 - accuracy: 0.9718 - val_loss: 1.8049 - val_accuracy: 0.5000\n",
      "Epoch 448/1000\n",
      "177/177 [==============================] - 0s 118us/step - loss: 0.0891 - accuracy: 0.9718 - val_loss: 1.9101 - val_accuracy: 0.4868\n",
      "Epoch 449/1000\n",
      "177/177 [==============================] - 0s 122us/step - loss: 0.1809 - accuracy: 0.9605 - val_loss: 1.8687 - val_accuracy: 0.4868\n",
      "Epoch 450/1000\n",
      "177/177 [==============================] - 0s 96us/step - loss: 0.1159 - accuracy: 0.9661 - val_loss: 1.8191 - val_accuracy: 0.5263\n",
      "Epoch 451/1000\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.0897 - accuracy: 0.9718 - val_loss: 1.9367 - val_accuracy: 0.5000\n",
      "Epoch 452/1000\n",
      "177/177 [==============================] - 0s 93us/step - loss: 0.2004 - accuracy: 0.9605 - val_loss: 1.9000 - val_accuracy: 0.4737\n",
      "Epoch 453/1000\n",
      "177/177 [==============================] - 0s 101us/step - loss: 0.1449 - accuracy: 0.9605 - val_loss: 1.8451 - val_accuracy: 0.5395\n",
      "Epoch 454/1000\n",
      "177/177 [==============================] - 0s 100us/step - loss: 0.1021 - accuracy: 0.9774 - val_loss: 1.8733 - val_accuracy: 0.5000\n",
      "Epoch 455/1000\n",
      "177/177 [==============================] - 0s 87us/step - loss: 0.1585 - accuracy: 0.9718 - val_loss: 1.8979 - val_accuracy: 0.4605\n",
      "Epoch 456/1000\n",
      "177/177 [==============================] - 0s 86us/step - loss: 0.3328 - accuracy: 0.9548 - val_loss: 1.8197 - val_accuracy: 0.5132\n",
      "Epoch 457/1000\n",
      "177/177 [==============================] - 0s 86us/step - loss: 0.3452 - accuracy: 0.9548 - val_loss: 1.9016 - val_accuracy: 0.4868\n",
      "Epoch 458/1000\n",
      "177/177 [==============================] - 0s 97us/step - loss: 0.3109 - accuracy: 0.9492 - val_loss: 1.8980 - val_accuracy: 0.4605\n",
      "Epoch 459/1000\n",
      "177/177 [==============================] - 0s 95us/step - loss: 0.2855 - accuracy: 0.9605 - val_loss: 1.9099 - val_accuracy: 0.5000\n",
      "Epoch 460/1000\n",
      "177/177 [==============================] - 0s 93us/step - loss: 0.1829 - accuracy: 0.9548 - val_loss: 1.8817 - val_accuracy: 0.5395\n",
      "Epoch 461/1000\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.1683 - accuracy: 0.9718 - val_loss: 1.8523 - val_accuracy: 0.4868\n",
      "Epoch 462/1000\n",
      "177/177 [==============================] - 0s 94us/step - loss: 0.0888 - accuracy: 0.9661 - val_loss: 2.2539 - val_accuracy: 0.4605\n",
      "Epoch 463/1000\n",
      "177/177 [==============================] - 0s 83us/step - loss: 0.4701 - accuracy: 0.9435 - val_loss: 2.0545 - val_accuracy: 0.4605\n",
      "Epoch 464/1000\n",
      "177/177 [==============================] - 0s 104us/step - loss: 0.1876 - accuracy: 0.9661 - val_loss: 1.8992 - val_accuracy: 0.5263\n",
      "Epoch 465/1000\n",
      "177/177 [==============================] - 0s 121us/step - loss: 0.1053 - accuracy: 0.9605 - val_loss: 1.9396 - val_accuracy: 0.5132\n",
      "Epoch 466/1000\n",
      "177/177 [==============================] - 0s 107us/step - loss: 0.2090 - accuracy: 0.9661 - val_loss: 1.9730 - val_accuracy: 0.5000\n",
      "Epoch 467/1000\n",
      "177/177 [==============================] - 0s 115us/step - loss: 0.1986 - accuracy: 0.9605 - val_loss: 1.8911 - val_accuracy: 0.5395\n",
      "Epoch 468/1000\n",
      "177/177 [==============================] - 0s 117us/step - loss: 0.1043 - accuracy: 0.9718 - val_loss: 1.9193 - val_accuracy: 0.4868\n",
      "Epoch 469/1000\n",
      "177/177 [==============================] - 0s 137us/step - loss: 0.2137 - accuracy: 0.9548 - val_loss: 1.9602 - val_accuracy: 0.4474\n",
      "Epoch 470/1000\n",
      "177/177 [==============================] - 0s 114us/step - loss: 0.2238 - accuracy: 0.9661 - val_loss: 1.8777 - val_accuracy: 0.5132\n",
      "Epoch 471/1000\n",
      "177/177 [==============================] - 0s 112us/step - loss: 0.1157 - accuracy: 0.9718 - val_loss: 2.0061 - val_accuracy: 0.4868\n",
      "Epoch 472/1000\n",
      "177/177 [==============================] - 0s 132us/step - loss: 0.2255 - accuracy: 0.9718 - val_loss: 1.9184 - val_accuracy: 0.4737\n",
      "Epoch 473/1000\n",
      "177/177 [==============================] - 0s 118us/step - loss: 0.1735 - accuracy: 0.9718 - val_loss: 1.9184 - val_accuracy: 0.4737\n",
      "Epoch 474/1000\n",
      "177/177 [==============================] - 0s 133us/step - loss: 0.0682 - accuracy: 0.9831 - val_loss: 1.9444 - val_accuracy: 0.4868\n",
      "Epoch 475/1000\n",
      "177/177 [==============================] - 0s 138us/step - loss: 0.1264 - accuracy: 0.9774 - val_loss: 1.8924 - val_accuracy: 0.5000\n",
      "Epoch 476/1000\n",
      "177/177 [==============================] - 0s 123us/step - loss: 0.1334 - accuracy: 0.9774 - val_loss: 1.9052 - val_accuracy: 0.4737\n",
      "Epoch 477/1000\n",
      "177/177 [==============================] - 0s 125us/step - loss: 0.1453 - accuracy: 0.9661 - val_loss: 2.0105 - val_accuracy: 0.4737\n",
      "Epoch 478/1000\n",
      "177/177 [==============================] - 0s 120us/step - loss: 0.1221 - accuracy: 0.9605 - val_loss: 1.9292 - val_accuracy: 0.5132\n",
      "Epoch 479/1000\n",
      "177/177 [==============================] - 0s 107us/step - loss: 0.1029 - accuracy: 0.9774 - val_loss: 1.9287 - val_accuracy: 0.5132\n",
      "Epoch 480/1000\n",
      "177/177 [==============================] - 0s 114us/step - loss: 0.0736 - accuracy: 0.9774 - val_loss: 1.9685 - val_accuracy: 0.4737\n",
      "Epoch 481/1000\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.0977 - accuracy: 0.9774 - val_loss: 1.9074 - val_accuracy: 0.5000\n",
      "Epoch 482/1000\n",
      "177/177 [==============================] - 0s 89us/step - loss: 0.1241 - accuracy: 0.9774 - val_loss: 1.9374 - val_accuracy: 0.4605\n",
      "Epoch 483/1000\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.1021 - accuracy: 0.9718 - val_loss: 1.9122 - val_accuracy: 0.4868\n",
      "Epoch 484/1000\n",
      "177/177 [==============================] - 0s 120us/step - loss: 0.1137 - accuracy: 0.9774 - val_loss: 1.9590 - val_accuracy: 0.4605\n",
      "Epoch 485/1000\n",
      "177/177 [==============================] - 0s 104us/step - loss: 0.0934 - accuracy: 0.9831 - val_loss: 1.9260 - val_accuracy: 0.5000\n",
      "Epoch 486/1000\n",
      "177/177 [==============================] - 0s 83us/step - loss: 0.1007 - accuracy: 0.9718 - val_loss: 1.9578 - val_accuracy: 0.4868\n",
      "Epoch 487/1000\n",
      "177/177 [==============================] - 0s 91us/step - loss: 0.1891 - accuracy: 0.9492 - val_loss: 2.2457 - val_accuracy: 0.4605\n",
      "Epoch 488/1000\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.3183 - accuracy: 0.9435 - val_loss: 1.9661 - val_accuracy: 0.5000\n",
      "Epoch 489/1000\n",
      "177/177 [==============================] - 0s 89us/step - loss: 0.1218 - accuracy: 0.9661 - val_loss: 1.9681 - val_accuracy: 0.5000\n",
      "Epoch 490/1000\n",
      "177/177 [==============================] - 0s 122us/step - loss: 0.1028 - accuracy: 0.9718 - val_loss: 1.9503 - val_accuracy: 0.5263\n",
      "Epoch 491/1000\n",
      "177/177 [==============================] - 0s 131us/step - loss: 0.0730 - accuracy: 0.9831 - val_loss: 1.9351 - val_accuracy: 0.5000\n",
      "Epoch 492/1000\n",
      "177/177 [==============================] - 0s 127us/step - loss: 0.0696 - accuracy: 0.9774 - val_loss: 2.0132 - val_accuracy: 0.5000\n",
      "Epoch 493/1000\n",
      "177/177 [==============================] - 0s 124us/step - loss: 0.1454 - accuracy: 0.9774 - val_loss: 1.9469 - val_accuracy: 0.4605\n",
      "Epoch 494/1000\n",
      "177/177 [==============================] - 0s 125us/step - loss: 0.1241 - accuracy: 0.9774 - val_loss: 1.9495 - val_accuracy: 0.4605\n",
      "Epoch 495/1000\n",
      "177/177 [==============================] - 0s 147us/step - loss: 0.2029 - accuracy: 0.9718 - val_loss: 2.0764 - val_accuracy: 0.4737\n",
      "Epoch 496/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177/177 [==============================] - 0s 107us/step - loss: 0.1650 - accuracy: 0.9718 - val_loss: 1.9406 - val_accuracy: 0.5132\n",
      "Epoch 497/1000\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.1316 - accuracy: 0.9774 - val_loss: 1.9702 - val_accuracy: 0.4868\n",
      "Epoch 498/1000\n",
      "177/177 [==============================] - 0s 79us/step - loss: 0.0941 - accuracy: 0.9774 - val_loss: 1.9586 - val_accuracy: 0.5395\n",
      "Epoch 499/1000\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.2830 - accuracy: 0.9435 - val_loss: 2.0399 - val_accuracy: 0.4474\n",
      "Epoch 500/1000\n",
      "177/177 [==============================] - 0s 77us/step - loss: 0.1382 - accuracy: 0.9718 - val_loss: 1.9334 - val_accuracy: 0.5132\n",
      "Epoch 501/1000\n",
      "177/177 [==============================] - 0s 77us/step - loss: 0.4043 - accuracy: 0.9548 - val_loss: 1.9177 - val_accuracy: 0.5132\n",
      "Epoch 502/1000\n",
      "177/177 [==============================] - 0s 92us/step - loss: 0.3721 - accuracy: 0.9492 - val_loss: 2.3813 - val_accuracy: 0.4211\n",
      "Epoch 503/1000\n",
      "177/177 [==============================] - 0s 85us/step - loss: 0.5396 - accuracy: 0.9435 - val_loss: 1.9777 - val_accuracy: 0.5395\n",
      "Epoch 504/1000\n",
      "177/177 [==============================] - 0s 205us/step - loss: 0.5589 - accuracy: 0.9548 - val_loss: 2.1416 - val_accuracy: 0.4868\n",
      "Epoch 505/1000\n",
      "177/177 [==============================] - 0s 95us/step - loss: 0.2869 - accuracy: 0.9435 - val_loss: 2.1072 - val_accuracy: 0.4868\n",
      "Epoch 506/1000\n",
      "177/177 [==============================] - 0s 128us/step - loss: 0.2549 - accuracy: 0.9548 - val_loss: 1.9765 - val_accuracy: 0.4868\n",
      "Epoch 507/1000\n",
      "177/177 [==============================] - 0s 131us/step - loss: 0.1631 - accuracy: 0.9605 - val_loss: 1.9745 - val_accuracy: 0.5263\n",
      "Epoch 508/1000\n",
      "177/177 [==============================] - 0s 103us/step - loss: 0.5228 - accuracy: 0.9492 - val_loss: 1.9611 - val_accuracy: 0.4868\n",
      "Epoch 509/1000\n",
      "177/177 [==============================] - 0s 140us/step - loss: 0.1666 - accuracy: 0.9492 - val_loss: 2.0943 - val_accuracy: 0.4474\n",
      "Epoch 510/1000\n",
      "177/177 [==============================] - 0s 108us/step - loss: 0.3653 - accuracy: 0.9548 - val_loss: 1.9783 - val_accuracy: 0.5132\n",
      "Epoch 511/1000\n",
      "177/177 [==============================] - 0s 95us/step - loss: 0.3566 - accuracy: 0.9605 - val_loss: 2.1904 - val_accuracy: 0.4737\n",
      "Epoch 512/1000\n",
      "177/177 [==============================] - 0s 93us/step - loss: 0.3434 - accuracy: 0.9435 - val_loss: 2.2364 - val_accuracy: 0.4737\n",
      "Epoch 513/1000\n",
      "177/177 [==============================] - 0s 166us/step - loss: 0.2534 - accuracy: 0.9605 - val_loss: 2.0056 - val_accuracy: 0.4868\n",
      "Epoch 514/1000\n",
      "177/177 [==============================] - 0s 138us/step - loss: 0.4144 - accuracy: 0.9605 - val_loss: 1.9758 - val_accuracy: 0.5000\n",
      "Epoch 515/1000\n",
      "177/177 [==============================] - 0s 163us/step - loss: 0.2565 - accuracy: 0.9548 - val_loss: 2.1117 - val_accuracy: 0.4868\n",
      "Epoch 516/1000\n",
      "177/177 [==============================] - 0s 126us/step - loss: 0.1373 - accuracy: 0.9774 - val_loss: 1.9962 - val_accuracy: 0.5000\n",
      "Epoch 517/1000\n",
      "177/177 [==============================] - 0s 154us/step - loss: 0.1439 - accuracy: 0.9661 - val_loss: 2.0209 - val_accuracy: 0.4737\n",
      "Epoch 518/1000\n",
      "177/177 [==============================] - 0s 114us/step - loss: 0.1558 - accuracy: 0.9661 - val_loss: 2.0523 - val_accuracy: 0.4868\n",
      "Epoch 519/1000\n",
      "177/177 [==============================] - 0s 116us/step - loss: 0.0678 - accuracy: 0.9718 - val_loss: 1.9958 - val_accuracy: 0.5000\n",
      "Epoch 520/1000\n",
      "177/177 [==============================] - 0s 121us/step - loss: 0.0987 - accuracy: 0.9774 - val_loss: 2.0300 - val_accuracy: 0.4868\n",
      "Epoch 521/1000\n",
      "177/177 [==============================] - 0s 116us/step - loss: 0.0953 - accuracy: 0.9774 - val_loss: 2.0125 - val_accuracy: 0.4737\n",
      "Epoch 522/1000\n",
      "177/177 [==============================] - 0s 118us/step - loss: 0.1229 - accuracy: 0.9774 - val_loss: 2.0550 - val_accuracy: 0.4605\n",
      "Epoch 523/1000\n",
      "177/177 [==============================] - 0s 134us/step - loss: 0.0879 - accuracy: 0.9774 - val_loss: 2.0056 - val_accuracy: 0.5000\n",
      "Epoch 524/1000\n",
      "177/177 [==============================] - 0s 148us/step - loss: 0.1077 - accuracy: 0.9661 - val_loss: 2.0254 - val_accuracy: 0.4868\n",
      "Epoch 525/1000\n",
      "177/177 [==============================] - 0s 154us/step - loss: 0.1358 - accuracy: 0.9661 - val_loss: 2.0736 - val_accuracy: 0.4868\n",
      "Epoch 526/1000\n",
      "177/177 [==============================] - 0s 173us/step - loss: 0.2353 - accuracy: 0.9605 - val_loss: 1.9926 - val_accuracy: 0.5000\n",
      "Epoch 527/1000\n",
      "177/177 [==============================] - 0s 177us/step - loss: 0.2492 - accuracy: 0.9718 - val_loss: 2.1968 - val_accuracy: 0.4737\n",
      "Epoch 528/1000\n",
      "177/177 [==============================] - 0s 228us/step - loss: 0.2113 - accuracy: 0.9492 - val_loss: 2.0585 - val_accuracy: 0.4737\n",
      "Epoch 529/1000\n",
      "177/177 [==============================] - 0s 203us/step - loss: 0.1357 - accuracy: 0.9718 - val_loss: 2.0097 - val_accuracy: 0.5000\n",
      "Epoch 530/1000\n",
      "177/177 [==============================] - 0s 157us/step - loss: 0.0778 - accuracy: 0.9774 - val_loss: 2.1276 - val_accuracy: 0.4868\n",
      "Epoch 531/1000\n",
      "177/177 [==============================] - 0s 140us/step - loss: 0.1640 - accuracy: 0.9661 - val_loss: 2.0982 - val_accuracy: 0.4868\n",
      "Epoch 532/1000\n",
      "177/177 [==============================] - 0s 96us/step - loss: 0.0938 - accuracy: 0.9774 - val_loss: 2.0306 - val_accuracy: 0.5000\n",
      "Epoch 533/1000\n",
      "177/177 [==============================] - 0s 123us/step - loss: 0.2296 - accuracy: 0.9548 - val_loss: 2.1066 - val_accuracy: 0.4605\n",
      "Epoch 534/1000\n",
      "177/177 [==============================] - 0s 119us/step - loss: 0.1610 - accuracy: 0.9605 - val_loss: 2.0967 - val_accuracy: 0.4868\n",
      "Epoch 535/1000\n",
      "177/177 [==============================] - 0s 120us/step - loss: 0.2077 - accuracy: 0.9661 - val_loss: 2.0538 - val_accuracy: 0.4868\n",
      "Epoch 536/1000\n",
      "177/177 [==============================] - 0s 120us/step - loss: 0.0907 - accuracy: 0.9605 - val_loss: 2.3551 - val_accuracy: 0.4737\n",
      "Epoch 537/1000\n",
      "177/177 [==============================] - 0s 134us/step - loss: 0.2977 - accuracy: 0.9548 - val_loss: 2.0991 - val_accuracy: 0.4737\n",
      "Epoch 538/1000\n",
      "177/177 [==============================] - 0s 130us/step - loss: 0.0734 - accuracy: 0.9831 - val_loss: 2.0573 - val_accuracy: 0.4868\n",
      "Epoch 539/1000\n",
      "177/177 [==============================] - 0s 121us/step - loss: 0.1181 - accuracy: 0.9774 - val_loss: 2.1320 - val_accuracy: 0.4737\n",
      "Epoch 540/1000\n",
      "177/177 [==============================] - 0s 127us/step - loss: 0.1741 - accuracy: 0.9718 - val_loss: 2.1010 - val_accuracy: 0.4868\n",
      "Epoch 541/1000\n",
      "177/177 [==============================] - 0s 135us/step - loss: 0.1131 - accuracy: 0.9774 - val_loss: 2.0419 - val_accuracy: 0.5132\n",
      "Epoch 542/1000\n",
      "177/177 [==============================] - 0s 107us/step - loss: 0.1274 - accuracy: 0.9718 - val_loss: 2.1361 - val_accuracy: 0.4868\n",
      "Epoch 543/1000\n",
      "177/177 [==============================] - 0s 91us/step - loss: 0.2290 - accuracy: 0.9605 - val_loss: 2.2068 - val_accuracy: 0.4737\n",
      "Epoch 544/1000\n",
      "177/177 [==============================] - 0s 89us/step - loss: 0.0704 - accuracy: 0.9661 - val_loss: 2.0484 - val_accuracy: 0.5132\n",
      "Epoch 545/1000\n",
      "177/177 [==============================] - 0s 107us/step - loss: 0.2318 - accuracy: 0.9605 - val_loss: 2.1214 - val_accuracy: 0.4737\n",
      "Epoch 546/1000\n",
      "177/177 [==============================] - 0s 97us/step - loss: 0.2735 - accuracy: 0.9492 - val_loss: 2.1627 - val_accuracy: 0.4737\n",
      "Epoch 547/1000\n",
      "177/177 [==============================] - 0s 92us/step - loss: 0.1570 - accuracy: 0.9718 - val_loss: 2.0762 - val_accuracy: 0.5263\n",
      "Epoch 548/1000\n",
      "177/177 [==============================] - 0s 109us/step - loss: 0.4666 - accuracy: 0.9435 - val_loss: 2.0869 - val_accuracy: 0.4737\n",
      "Epoch 549/1000\n",
      "177/177 [==============================] - 0s 108us/step - loss: 0.1882 - accuracy: 0.9605 - val_loss: 2.2208 - val_accuracy: 0.4868\n",
      "Epoch 550/1000\n",
      "177/177 [==============================] - 0s 99us/step - loss: 0.2775 - accuracy: 0.9548 - val_loss: 2.0653 - val_accuracy: 0.4737\n",
      "Epoch 551/1000\n",
      "177/177 [==============================] - 0s 116us/step - loss: 0.2252 - accuracy: 0.9718 - val_loss: 2.1131 - val_accuracy: 0.4605\n",
      "Epoch 552/1000\n",
      "177/177 [==============================] - 0s 110us/step - loss: 0.1895 - accuracy: 0.9718 - val_loss: 2.0599 - val_accuracy: 0.4737\n",
      "Epoch 553/1000\n",
      "177/177 [==============================] - 0s 112us/step - loss: 0.1415 - accuracy: 0.9661 - val_loss: 2.0519 - val_accuracy: 0.5000\n",
      "Epoch 554/1000\n",
      "177/177 [==============================] - 0s 157us/step - loss: 0.1091 - accuracy: 0.9718 - val_loss: 2.1366 - val_accuracy: 0.4605\n",
      "Epoch 555/1000\n",
      "177/177 [==============================] - 0s 157us/step - loss: 0.2346 - accuracy: 0.9661 - val_loss: 2.0706 - val_accuracy: 0.5000\n",
      "Epoch 556/1000\n",
      "177/177 [==============================] - 0s 160us/step - loss: 0.0692 - accuracy: 0.9774 - val_loss: 2.1180 - val_accuracy: 0.5000\n",
      "Epoch 557/1000\n",
      "177/177 [==============================] - 0s 175us/step - loss: 0.0593 - accuracy: 0.9831 - val_loss: 2.0925 - val_accuracy: 0.4737\n",
      "Epoch 558/1000\n",
      "177/177 [==============================] - 0s 196us/step - loss: 0.0639 - accuracy: 0.9774 - val_loss: 2.1852 - val_accuracy: 0.4868\n",
      "Epoch 559/1000\n",
      "177/177 [==============================] - 0s 192us/step - loss: 0.1456 - accuracy: 0.9774 - val_loss: 2.1279 - val_accuracy: 0.4868\n",
      "Epoch 560/1000\n",
      "177/177 [==============================] - 0s 151us/step - loss: 0.2145 - accuracy: 0.9718 - val_loss: 2.0970 - val_accuracy: 0.4737\n",
      "Epoch 561/1000\n",
      "177/177 [==============================] - 0s 177us/step - loss: 0.3003 - accuracy: 0.9548 - val_loss: 2.4036 - val_accuracy: 0.4605\n",
      "Epoch 562/1000\n",
      "177/177 [==============================] - 0s 173us/step - loss: 0.3745 - accuracy: 0.9492 - val_loss: 2.1791 - val_accuracy: 0.4737\n",
      "Epoch 563/1000\n",
      "177/177 [==============================] - 0s 135us/step - loss: 0.1976 - accuracy: 0.9661 - val_loss: 2.1052 - val_accuracy: 0.5263\n",
      "Epoch 564/1000\n",
      "177/177 [==============================] - ETA: 0s - loss: 0.1023 - accuracy: 0.96 - 0s 132us/step - loss: 0.2251 - accuracy: 0.9605 - val_loss: 2.1477 - val_accuracy: 0.4737\n",
      "Epoch 565/1000\n",
      "177/177 [==============================] - 0s 93us/step - loss: 0.2293 - accuracy: 0.9718 - val_loss: 2.1372 - val_accuracy: 0.4737\n",
      "Epoch 566/1000\n",
      "177/177 [==============================] - 0s 87us/step - loss: 0.1883 - accuracy: 0.9718 - val_loss: 2.0915 - val_accuracy: 0.5132\n",
      "Epoch 567/1000\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.1720 - accuracy: 0.9661 - val_loss: 2.2198 - val_accuracy: 0.4474\n",
      "Epoch 568/1000\n",
      "177/177 [==============================] - 0s 119us/step - loss: 0.2463 - accuracy: 0.9548 - val_loss: 2.1418 - val_accuracy: 0.5000\n",
      "Epoch 569/1000\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.2538 - accuracy: 0.9661 - val_loss: 2.0887 - val_accuracy: 0.5000\n",
      "Epoch 570/1000\n",
      "177/177 [==============================] - 0s 116us/step - loss: 0.4195 - accuracy: 0.9435 - val_loss: 2.2227 - val_accuracy: 0.5000\n",
      "Epoch 571/1000\n",
      "177/177 [==============================] - 0s 129us/step - loss: 0.4433 - accuracy: 0.9435 - val_loss: 2.5087 - val_accuracy: 0.4737\n",
      "Epoch 572/1000\n",
      "177/177 [==============================] - 0s 127us/step - loss: 0.3024 - accuracy: 0.9605 - val_loss: 2.1233 - val_accuracy: 0.4868\n",
      "Epoch 573/1000\n",
      "177/177 [==============================] - 0s 127us/step - loss: 0.1337 - accuracy: 0.9774 - val_loss: 2.1392 - val_accuracy: 0.5132\n",
      "Epoch 574/1000\n",
      "177/177 [==============================] - 0s 139us/step - loss: 0.0671 - accuracy: 0.9831 - val_loss: 2.2480 - val_accuracy: 0.4474\n",
      "Epoch 575/1000\n",
      "177/177 [==============================] - 0s 118us/step - loss: 0.1561 - accuracy: 0.9661 - val_loss: 2.1600 - val_accuracy: 0.4737\n",
      "Epoch 576/1000\n",
      "177/177 [==============================] - 0s 139us/step - loss: 0.0801 - accuracy: 0.9718 - val_loss: 2.1500 - val_accuracy: 0.4737\n",
      "Epoch 577/1000\n",
      "177/177 [==============================] - 0s 137us/step - loss: 0.1020 - accuracy: 0.9774 - val_loss: 2.1536 - val_accuracy: 0.4737\n",
      "Epoch 578/1000\n",
      "177/177 [==============================] - 0s 122us/step - loss: 0.0589 - accuracy: 0.9831 - val_loss: 2.1436 - val_accuracy: 0.4737\n",
      "Epoch 579/1000\n",
      "177/177 [==============================] - 0s 137us/step - loss: 0.1002 - accuracy: 0.9774 - val_loss: 2.1629 - val_accuracy: 0.4605\n",
      "Epoch 580/1000\n",
      "177/177 [==============================] - 0s 125us/step - loss: 0.1264 - accuracy: 0.9718 - val_loss: 2.1563 - val_accuracy: 0.4605\n",
      "Epoch 581/1000\n",
      "177/177 [==============================] - 0s 123us/step - loss: 0.1806 - accuracy: 0.9718 - val_loss: 2.1162 - val_accuracy: 0.4868\n",
      "Epoch 582/1000\n",
      "177/177 [==============================] - 0s 138us/step - loss: 0.0874 - accuracy: 0.9718 - val_loss: 2.2923 - val_accuracy: 0.4737\n",
      "Epoch 583/1000\n",
      "177/177 [==============================] - 0s 96us/step - loss: 0.2234 - accuracy: 0.9605 - val_loss: 2.1782 - val_accuracy: 0.4605\n",
      "Epoch 584/1000\n",
      "177/177 [==============================] - 0s 108us/step - loss: 0.0887 - accuracy: 0.9718 - val_loss: 2.1614 - val_accuracy: 0.5132\n",
      "Epoch 585/1000\n",
      "177/177 [==============================] - 0s 93us/step - loss: 0.3921 - accuracy: 0.9435 - val_loss: 2.3636 - val_accuracy: 0.4342\n",
      "Epoch 586/1000\n",
      "177/177 [==============================] - 0s 108us/step - loss: 0.2192 - accuracy: 0.9548 - val_loss: 2.1870 - val_accuracy: 0.5000\n",
      "Epoch 587/1000\n",
      "177/177 [==============================] - 0s 137us/step - loss: 0.5118 - accuracy: 0.9379 - val_loss: 2.1396 - val_accuracy: 0.5132\n",
      "Epoch 588/1000\n",
      "177/177 [==============================] - 0s 125us/step - loss: 0.2320 - accuracy: 0.9661 - val_loss: 2.3481 - val_accuracy: 0.4737\n",
      "Epoch 589/1000\n",
      "177/177 [==============================] - 0s 123us/step - loss: 0.2736 - accuracy: 0.9548 - val_loss: 2.2948 - val_accuracy: 0.4474\n",
      "Epoch 590/1000\n",
      "177/177 [==============================] - 0s 121us/step - loss: 0.1673 - accuracy: 0.9661 - val_loss: 2.1656 - val_accuracy: 0.5132\n",
      "Epoch 591/1000\n",
      "177/177 [==============================] - 0s 89us/step - loss: 0.1654 - accuracy: 0.9492 - val_loss: 2.2122 - val_accuracy: 0.4737\n",
      "Epoch 592/1000\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.1267 - accuracy: 0.9718 - val_loss: 2.1793 - val_accuracy: 0.4737\n",
      "Epoch 593/1000\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.1844 - accuracy: 0.9718 - val_loss: 2.1637 - val_accuracy: 0.4737\n",
      "Epoch 594/1000\n",
      "177/177 [==============================] - 0s 107us/step - loss: 0.2490 - accuracy: 0.9661 - val_loss: 2.3398 - val_accuracy: 0.4605\n",
      "Epoch 595/1000\n",
      "177/177 [==============================] - 0s 103us/step - loss: 0.2460 - accuracy: 0.9661 - val_loss: 2.2115 - val_accuracy: 0.4737\n",
      "Epoch 596/1000\n",
      "177/177 [==============================] - 0s 102us/step - loss: 0.2135 - accuracy: 0.9718 - val_loss: 2.1818 - val_accuracy: 0.5132\n",
      "Epoch 597/1000\n",
      "177/177 [==============================] - 0s 111us/step - loss: 0.2026 - accuracy: 0.9774 - val_loss: 2.2404 - val_accuracy: 0.4868\n",
      "Epoch 598/1000\n",
      "177/177 [==============================] - 0s 117us/step - loss: 0.1310 - accuracy: 0.9774 - val_loss: 2.2134 - val_accuracy: 0.4868\n",
      "Epoch 599/1000\n",
      "177/177 [==============================] - 0s 102us/step - loss: 0.0627 - accuracy: 0.9831 - val_loss: 2.1637 - val_accuracy: 0.5000\n",
      "Epoch 600/1000\n",
      "177/177 [==============================] - 0s 100us/step - loss: 0.1329 - accuracy: 0.9774 - val_loss: 2.2185 - val_accuracy: 0.4737\n",
      "Epoch 601/1000\n",
      "177/177 [==============================] - 0s 104us/step - loss: 0.0648 - accuracy: 0.9774 - val_loss: 2.2114 - val_accuracy: 0.4868\n",
      "Epoch 602/1000\n",
      "177/177 [==============================] - 0s 109us/step - loss: 0.0990 - accuracy: 0.9718 - val_loss: 2.1982 - val_accuracy: 0.4868\n",
      "Epoch 603/1000\n",
      "177/177 [==============================] - 0s 101us/step - loss: 0.0855 - accuracy: 0.9774 - val_loss: 2.2191 - val_accuracy: 0.4737\n",
      "Epoch 604/1000\n",
      "177/177 [==============================] - 0s 108us/step - loss: 0.0556 - accuracy: 0.9774 - val_loss: 2.2380 - val_accuracy: 0.4737\n",
      "Epoch 605/1000\n",
      "177/177 [==============================] - 0s 118us/step - loss: 0.0860 - accuracy: 0.9831 - val_loss: 2.1972 - val_accuracy: 0.4605\n",
      "Epoch 606/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177/177 [==============================] - 0s 107us/step - loss: 0.0765 - accuracy: 0.9774 - val_loss: 2.2523 - val_accuracy: 0.4868\n",
      "Epoch 607/1000\n",
      "177/177 [==============================] - 0s 115us/step - loss: 0.0938 - accuracy: 0.9774 - val_loss: 2.2065 - val_accuracy: 0.4605\n",
      "Epoch 608/1000\n",
      "177/177 [==============================] - 0s 118us/step - loss: 0.0632 - accuracy: 0.9831 - val_loss: 2.2616 - val_accuracy: 0.4868\n",
      "Epoch 609/1000\n",
      "177/177 [==============================] - 0s 129us/step - loss: 0.0796 - accuracy: 0.9831 - val_loss: 2.2112 - val_accuracy: 0.5000\n",
      "Epoch 610/1000\n",
      "177/177 [==============================] - 0s 106us/step - loss: 0.1185 - accuracy: 0.9718 - val_loss: 2.2123 - val_accuracy: 0.4737\n",
      "Epoch 611/1000\n",
      "177/177 [==============================] - 0s 109us/step - loss: 0.0841 - accuracy: 0.9831 - val_loss: 2.2527 - val_accuracy: 0.4605\n",
      "Epoch 612/1000\n",
      "177/177 [==============================] - 0s 133us/step - loss: 0.0749 - accuracy: 0.9774 - val_loss: 2.2259 - val_accuracy: 0.4737\n",
      "Epoch 613/1000\n",
      "177/177 [==============================] - 0s 131us/step - loss: 0.1128 - accuracy: 0.9831 - val_loss: 2.2396 - val_accuracy: 0.4737\n",
      "Epoch 614/1000\n",
      "177/177 [==============================] - 0s 116us/step - loss: 0.0569 - accuracy: 0.9887 - val_loss: 2.1907 - val_accuracy: 0.5132\n",
      "Epoch 615/1000\n",
      "177/177 [==============================] - 0s 117us/step - loss: 0.1814 - accuracy: 0.9718 - val_loss: 2.2152 - val_accuracy: 0.4737\n",
      "Epoch 616/1000\n",
      "177/177 [==============================] - 0s 105us/step - loss: 0.0934 - accuracy: 0.9774 - val_loss: 2.2510 - val_accuracy: 0.5132\n",
      "Epoch 617/1000\n",
      "177/177 [==============================] - 0s 101us/step - loss: 0.2001 - accuracy: 0.9718 - val_loss: 2.2135 - val_accuracy: 0.4868\n",
      "Epoch 618/1000\n",
      "177/177 [==============================] - 0s 94us/step - loss: 0.0581 - accuracy: 0.9831 - val_loss: 2.2158 - val_accuracy: 0.4868\n",
      "Epoch 619/1000\n",
      "177/177 [==============================] - 0s 178us/step - loss: 0.1843 - accuracy: 0.9718 - val_loss: 2.2771 - val_accuracy: 0.4605\n",
      "Epoch 620/1000\n",
      "177/177 [==============================] - 0s 120us/step - loss: 0.0879 - accuracy: 0.9774 - val_loss: 2.2181 - val_accuracy: 0.5132\n",
      "Epoch 621/1000\n",
      "177/177 [==============================] - 0s 122us/step - loss: 0.1307 - accuracy: 0.9718 - val_loss: 2.1951 - val_accuracy: 0.5132\n",
      "Epoch 622/1000\n",
      "177/177 [==============================] - 0s 173us/step - loss: 0.1058 - accuracy: 0.9605 - val_loss: 2.3548 - val_accuracy: 0.4868\n",
      "Epoch 623/1000\n",
      "177/177 [==============================] - 0s 101us/step - loss: 0.2309 - accuracy: 0.9605 - val_loss: 2.2442 - val_accuracy: 0.5132\n",
      "Epoch 624/1000\n",
      "177/177 [==============================] - 0s 101us/step - loss: 0.0614 - accuracy: 0.9774 - val_loss: 2.2721 - val_accuracy: 0.4737\n",
      "Epoch 625/1000\n",
      "177/177 [==============================] - 0s 91us/step - loss: 0.1928 - accuracy: 0.9661 - val_loss: 2.2314 - val_accuracy: 0.5132\n",
      "Epoch 626/1000\n",
      "177/177 [==============================] - 0s 82us/step - loss: 0.0684 - accuracy: 0.9774 - val_loss: 2.2794 - val_accuracy: 0.4868\n",
      "Epoch 627/1000\n",
      "177/177 [==============================] - 0s 108us/step - loss: 0.1136 - accuracy: 0.9831 - val_loss: 2.2494 - val_accuracy: 0.4605\n",
      "Epoch 628/1000\n",
      "177/177 [==============================] - 0s 93us/step - loss: 0.1523 - accuracy: 0.9718 - val_loss: 2.2196 - val_accuracy: 0.4868\n",
      "Epoch 629/1000\n",
      "177/177 [==============================] - 0s 110us/step - loss: 0.1588 - accuracy: 0.9605 - val_loss: 2.2997 - val_accuracy: 0.5000\n",
      "Epoch 630/1000\n",
      "177/177 [==============================] - 0s 124us/step - loss: 0.1200 - accuracy: 0.9774 - val_loss: 2.2117 - val_accuracy: 0.5000\n",
      "Epoch 631/1000\n",
      "177/177 [==============================] - 0s 120us/step - loss: 0.0849 - accuracy: 0.9718 - val_loss: 2.3502 - val_accuracy: 0.4737\n",
      "Epoch 632/1000\n",
      "177/177 [==============================] - 0s 121us/step - loss: 0.1285 - accuracy: 0.9661 - val_loss: 2.2514 - val_accuracy: 0.5132\n",
      "Epoch 633/1000\n",
      "177/177 [==============================] - 0s 84us/step - loss: 0.1519 - accuracy: 0.9718 - val_loss: 2.2670 - val_accuracy: 0.4737\n",
      "Epoch 634/1000\n",
      "177/177 [==============================] - 0s 87us/step - loss: 0.1442 - accuracy: 0.9661 - val_loss: 2.2472 - val_accuracy: 0.5263\n",
      "Epoch 635/1000\n",
      "177/177 [==============================] - 0s 83us/step - loss: 0.1785 - accuracy: 0.9718 - val_loss: 2.3039 - val_accuracy: 0.5263\n",
      "Epoch 636/1000\n",
      "177/177 [==============================] - 0s 76us/step - loss: 0.1729 - accuracy: 0.9774 - val_loss: 2.3438 - val_accuracy: 0.4474\n",
      "Epoch 637/1000\n",
      "177/177 [==============================] - 0s 94us/step - loss: 0.1499 - accuracy: 0.9661 - val_loss: 2.2368 - val_accuracy: 0.5132\n",
      "Epoch 638/1000\n",
      "177/177 [==============================] - 0s 85us/step - loss: 0.2653 - accuracy: 0.9492 - val_loss: 2.3163 - val_accuracy: 0.5000\n",
      "Epoch 639/1000\n",
      "177/177 [==============================] - 0s 103us/step - loss: 0.4314 - accuracy: 0.9548 - val_loss: 2.6019 - val_accuracy: 0.4737\n",
      "Epoch 640/1000\n",
      "177/177 [==============================] - 0s 92us/step - loss: 0.2911 - accuracy: 0.9435 - val_loss: 2.2466 - val_accuracy: 0.5132\n",
      "Epoch 641/1000\n",
      "177/177 [==============================] - 0s 78us/step - loss: 0.3992 - accuracy: 0.9548 - val_loss: 2.2701 - val_accuracy: 0.5000\n",
      "Epoch 642/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.2110 - accuracy: 0.9774 - val_loss: 2.4287 - val_accuracy: 0.4605\n",
      "Epoch 643/1000\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.3181 - accuracy: 0.9548 - val_loss: 2.2603 - val_accuracy: 0.5132\n",
      "Epoch 644/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.1826 - accuracy: 0.9661 - val_loss: 2.6595 - val_accuracy: 0.4737\n",
      "Epoch 645/1000\n",
      "177/177 [==============================] - 0s 70us/step - loss: 0.5438 - accuracy: 0.9435 - val_loss: 2.6779 - val_accuracy: 0.4605\n",
      "Epoch 646/1000\n",
      "177/177 [==============================] - 0s 77us/step - loss: 0.2971 - accuracy: 0.9661 - val_loss: 2.3124 - val_accuracy: 0.5263\n",
      "Epoch 647/1000\n",
      "177/177 [==============================] - 0s 84us/step - loss: 0.1734 - accuracy: 0.9661 - val_loss: 2.2951 - val_accuracy: 0.5132\n",
      "Epoch 648/1000\n",
      "177/177 [==============================] - 0s 69us/step - loss: 0.0659 - accuracy: 0.9831 - val_loss: 2.3837 - val_accuracy: 0.4605\n",
      "Epoch 649/1000\n",
      "177/177 [==============================] - 0s 77us/step - loss: 0.1804 - accuracy: 0.9774 - val_loss: 2.3315 - val_accuracy: 0.4605\n",
      "Epoch 650/1000\n",
      "177/177 [==============================] - 0s 74us/step - loss: 0.0580 - accuracy: 0.9831 - val_loss: 2.2911 - val_accuracy: 0.4737\n",
      "Epoch 651/1000\n",
      "177/177 [==============================] - 0s 87us/step - loss: 0.1219 - accuracy: 0.9774 - val_loss: 2.3031 - val_accuracy: 0.4605\n",
      "Epoch 652/1000\n",
      "177/177 [==============================] - 0s 77us/step - loss: 0.0991 - accuracy: 0.9774 - val_loss: 2.2997 - val_accuracy: 0.4605\n",
      "Epoch 653/1000\n",
      "177/177 [==============================] - 0s 78us/step - loss: 0.0498 - accuracy: 0.9831 - val_loss: 2.3072 - val_accuracy: 0.4605\n",
      "Epoch 654/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.0620 - accuracy: 0.9774 - val_loss: 2.3596 - val_accuracy: 0.4868\n",
      "Epoch 655/1000\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.1415 - accuracy: 0.9831 - val_loss: 2.3157 - val_accuracy: 0.4605\n",
      "Epoch 656/1000\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.1016 - accuracy: 0.9774 - val_loss: 2.2937 - val_accuracy: 0.4605\n",
      "Epoch 657/1000\n",
      "177/177 [==============================] - 0s 77us/step - loss: 0.0472 - accuracy: 0.9831 - val_loss: 2.3774 - val_accuracy: 0.4737\n",
      "Epoch 658/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.1063 - accuracy: 0.9831 - val_loss: 2.3230 - val_accuracy: 0.4868\n",
      "Epoch 659/1000\n",
      "177/177 [==============================] - 0s 76us/step - loss: 0.1429 - accuracy: 0.9774 - val_loss: 2.3212 - val_accuracy: 0.4737\n",
      "Epoch 660/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.1141 - accuracy: 0.9774 - val_loss: 2.4384 - val_accuracy: 0.4737\n",
      "Epoch 661/1000\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.1424 - accuracy: 0.9831 - val_loss: 2.2795 - val_accuracy: 0.5000\n",
      "Epoch 662/1000\n",
      "177/177 [==============================] - 0s 76us/step - loss: 0.1390 - accuracy: 0.9718 - val_loss: 2.3886 - val_accuracy: 0.4605\n",
      "Epoch 663/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.1255 - accuracy: 0.9661 - val_loss: 2.3790 - val_accuracy: 0.5000\n",
      "Epoch 664/1000\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.2922 - accuracy: 0.9661 - val_loss: 2.3152 - val_accuracy: 0.5000\n",
      "Epoch 665/1000\n",
      "177/177 [==============================] - 0s 84us/step - loss: 0.2693 - accuracy: 0.9661 - val_loss: 2.4217 - val_accuracy: 0.4474\n",
      "Epoch 666/1000\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.3164 - accuracy: 0.9605 - val_loss: 2.3331 - val_accuracy: 0.4868\n",
      "Epoch 667/1000\n",
      "177/177 [==============================] - 0s 84us/step - loss: 0.1932 - accuracy: 0.9718 - val_loss: 2.4415 - val_accuracy: 0.4605\n",
      "Epoch 668/1000\n",
      "177/177 [==============================] - 0s 76us/step - loss: 0.1634 - accuracy: 0.9605 - val_loss: 2.2991 - val_accuracy: 0.5132\n",
      "Epoch 669/1000\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.1256 - accuracy: 0.9718 - val_loss: 2.3616 - val_accuracy: 0.4605\n",
      "Epoch 670/1000\n",
      "177/177 [==============================] - 0s 69us/step - loss: 0.0971 - accuracy: 0.9774 - val_loss: 2.3520 - val_accuracy: 0.4605\n",
      "Epoch 671/1000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.0808 - accuracy: 0.9774 - val_loss: 2.3697 - val_accuracy: 0.4605\n",
      "Epoch 672/1000\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.0663 - accuracy: 0.9831 - val_loss: 2.3332 - val_accuracy: 0.4605\n",
      "Epoch 673/1000\n",
      "177/177 [==============================] - 0s 75us/step - loss: 0.0800 - accuracy: 0.9774 - val_loss: 2.3543 - val_accuracy: 0.4605\n",
      "Epoch 674/1000\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.1045 - accuracy: 0.9718 - val_loss: 2.3933 - val_accuracy: 0.4605\n",
      "Epoch 675/1000\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.0981 - accuracy: 0.9831 - val_loss: 2.3571 - val_accuracy: 0.4605\n",
      "Epoch 676/1000\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.0863 - accuracy: 0.9774 - val_loss: 2.3555 - val_accuracy: 0.5000\n",
      "Epoch 677/1000\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.1158 - accuracy: 0.9605 - val_loss: 2.3517 - val_accuracy: 0.4605\n",
      "Epoch 678/1000\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.1201 - accuracy: 0.9661 - val_loss: 2.3831 - val_accuracy: 0.4868\n",
      "Epoch 679/1000\n",
      "177/177 [==============================] - 0s 69us/step - loss: 0.1073 - accuracy: 0.9774 - val_loss: 2.3160 - val_accuracy: 0.5000\n",
      "Epoch 680/1000\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.1993 - accuracy: 0.9661 - val_loss: 2.5352 - val_accuracy: 0.4737\n",
      "Epoch 681/1000\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.1443 - accuracy: 0.9718 - val_loss: 2.3460 - val_accuracy: 0.4737\n",
      "Epoch 682/1000\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.1161 - accuracy: 0.9774 - val_loss: 2.3295 - val_accuracy: 0.5132\n",
      "Epoch 683/1000\n",
      "177/177 [==============================] - 0s 70us/step - loss: 0.2494 - accuracy: 0.9718 - val_loss: 2.4378 - val_accuracy: 0.4605\n",
      "Epoch 684/1000\n",
      "177/177 [==============================] - 0s 101us/step - loss: 0.0965 - accuracy: 0.9774 - val_loss: 2.3520 - val_accuracy: 0.4868\n",
      "Epoch 685/1000\n",
      "177/177 [==============================] - 0s 81us/step - loss: 0.0901 - accuracy: 0.9661 - val_loss: 2.4030 - val_accuracy: 0.4474\n",
      "Epoch 686/1000\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.1123 - accuracy: 0.9718 - val_loss: 2.4036 - val_accuracy: 0.4605\n",
      "Epoch 687/1000\n",
      "177/177 [==============================] - 0s 74us/step - loss: 0.2099 - accuracy: 0.9718 - val_loss: 2.3124 - val_accuracy: 0.5000\n",
      "Epoch 688/1000\n",
      "177/177 [==============================] - 0s 78us/step - loss: 0.0547 - accuracy: 0.9831 - val_loss: 2.4218 - val_accuracy: 0.4737\n",
      "Epoch 689/1000\n",
      "177/177 [==============================] - 0s 82us/step - loss: 0.1269 - accuracy: 0.9831 - val_loss: 2.4138 - val_accuracy: 0.4474\n",
      "Epoch 690/1000\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.1035 - accuracy: 0.9774 - val_loss: 2.4002 - val_accuracy: 0.4474\n",
      "Epoch 691/1000\n",
      "177/177 [==============================] - 0s 111us/step - loss: 0.0727 - accuracy: 0.9831 - val_loss: 2.4953 - val_accuracy: 0.4737\n",
      "Epoch 692/1000\n",
      "177/177 [==============================] - 0s 120us/step - loss: 0.1883 - accuracy: 0.9718 - val_loss: 2.3733 - val_accuracy: 0.5000\n",
      "Epoch 693/1000\n",
      "177/177 [==============================] - 0s 105us/step - loss: 0.0728 - accuracy: 0.9718 - val_loss: 2.3971 - val_accuracy: 0.4474\n",
      "Epoch 694/1000\n",
      "177/177 [==============================] - 0s 91us/step - loss: 0.0703 - accuracy: 0.9774 - val_loss: 2.4061 - val_accuracy: 0.4474\n",
      "Epoch 695/1000\n",
      "177/177 [==============================] - 0s 124us/step - loss: 0.2522 - accuracy: 0.9661 - val_loss: 2.5546 - val_accuracy: 0.4605\n",
      "Epoch 696/1000\n",
      "177/177 [==============================] - 0s 123us/step - loss: 0.1217 - accuracy: 0.9661 - val_loss: 2.3941 - val_accuracy: 0.4605\n",
      "Epoch 697/1000\n",
      "177/177 [==============================] - 0s 109us/step - loss: 0.3031 - accuracy: 0.9492 - val_loss: 2.4160 - val_accuracy: 0.4605\n",
      "Epoch 698/1000\n",
      "177/177 [==============================] - 0s 113us/step - loss: 0.1351 - accuracy: 0.9661 - val_loss: 2.7886 - val_accuracy: 0.4605\n",
      "Epoch 699/1000\n",
      "177/177 [==============================] - 0s 110us/step - loss: 0.4488 - accuracy: 0.9548 - val_loss: 2.6584 - val_accuracy: 0.4605\n",
      "Epoch 700/1000\n",
      "177/177 [==============================] - 0s 111us/step - loss: 0.3956 - accuracy: 0.9605 - val_loss: 2.4430 - val_accuracy: 0.5263\n",
      "Epoch 701/1000\n",
      "177/177 [==============================] - 0s 109us/step - loss: 0.1997 - accuracy: 0.9435 - val_loss: 2.6003 - val_accuracy: 0.4342\n",
      "Epoch 702/1000\n",
      "177/177 [==============================] - 0s 104us/step - loss: 0.4612 - accuracy: 0.9548 - val_loss: 2.7358 - val_accuracy: 0.4211\n",
      "Epoch 703/1000\n",
      "177/177 [==============================] - 0s 109us/step - loss: 0.3083 - accuracy: 0.9661 - val_loss: 2.4341 - val_accuracy: 0.5000\n",
      "Epoch 704/1000\n",
      "177/177 [==============================] - 0s 117us/step - loss: 0.3472 - accuracy: 0.9435 - val_loss: 2.4295 - val_accuracy: 0.4605\n",
      "Epoch 705/1000\n",
      "177/177 [==============================] - 0s 115us/step - loss: 0.3779 - accuracy: 0.9661 - val_loss: 2.9243 - val_accuracy: 0.4605\n",
      "Epoch 706/1000\n",
      "177/177 [==============================] - 0s 119us/step - loss: 0.6267 - accuracy: 0.9435 - val_loss: 2.3926 - val_accuracy: 0.4868\n",
      "Epoch 707/1000\n",
      "177/177 [==============================] - 0s 129us/step - loss: 0.1832 - accuracy: 0.9661 - val_loss: 2.4119 - val_accuracy: 0.5000\n",
      "Epoch 708/1000\n",
      "177/177 [==============================] - 0s 137us/step - loss: 0.1302 - accuracy: 0.9774 - val_loss: 2.5569 - val_accuracy: 0.4342\n",
      "Epoch 709/1000\n",
      "177/177 [==============================] - 0s 97us/step - loss: 0.1712 - accuracy: 0.9548 - val_loss: 2.4821 - val_accuracy: 0.4605\n",
      "Epoch 710/1000\n",
      "177/177 [==============================] - 0s 108us/step - loss: 0.0587 - accuracy: 0.9831 - val_loss: 2.4423 - val_accuracy: 0.5000\n",
      "Epoch 711/1000\n",
      "177/177 [==============================] - 0s 104us/step - loss: 0.1202 - accuracy: 0.9718 - val_loss: 2.4860 - val_accuracy: 0.4605\n",
      "Epoch 712/1000\n",
      "177/177 [==============================] - 0s 127us/step - loss: 0.1231 - accuracy: 0.9774 - val_loss: 2.4555 - val_accuracy: 0.4605\n",
      "Epoch 713/1000\n",
      "177/177 [==============================] - 0s 113us/step - loss: 0.0469 - accuracy: 0.9774 - val_loss: 2.4267 - val_accuracy: 0.4737\n",
      "Epoch 714/1000\n",
      "177/177 [==============================] - 0s 115us/step - loss: 0.1041 - accuracy: 0.9718 - val_loss: 2.4696 - val_accuracy: 0.4342\n",
      "Epoch 715/1000\n",
      "177/177 [==============================] - 0s 96us/step - loss: 0.0960 - accuracy: 0.9718 - val_loss: 2.4344 - val_accuracy: 0.4605\n",
      "Epoch 716/1000\n",
      "177/177 [==============================] - 0s 121us/step - loss: 0.0448 - accuracy: 0.9774 - val_loss: 2.4871 - val_accuracy: 0.4737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 717/1000\n",
      "177/177 [==============================] - 0s 94us/step - loss: 0.1179 - accuracy: 0.9831 - val_loss: 2.4659 - val_accuracy: 0.4605\n",
      "Epoch 718/1000\n",
      "177/177 [==============================] - 0s 106us/step - loss: 0.2229 - accuracy: 0.9661 - val_loss: 2.3983 - val_accuracy: 0.4868\n",
      "Epoch 719/1000\n",
      "177/177 [==============================] - 0s 104us/step - loss: 0.1762 - accuracy: 0.9605 - val_loss: 2.5798 - val_accuracy: 0.4737\n",
      "Epoch 720/1000\n",
      "177/177 [==============================] - 0s 97us/step - loss: 0.2222 - accuracy: 0.9718 - val_loss: 2.4627 - val_accuracy: 0.4605\n",
      "Epoch 721/1000\n",
      "177/177 [==============================] - 0s 102us/step - loss: 0.1184 - accuracy: 0.9774 - val_loss: 2.4496 - val_accuracy: 0.5132\n",
      "Epoch 722/1000\n",
      "177/177 [==============================] - 0s 113us/step - loss: 0.1196 - accuracy: 0.9774 - val_loss: 2.5457 - val_accuracy: 0.4605\n",
      "Epoch 723/1000\n",
      "177/177 [==============================] - 0s 102us/step - loss: 0.1306 - accuracy: 0.9774 - val_loss: 2.4836 - val_accuracy: 0.4605\n",
      "Epoch 724/1000\n",
      "177/177 [==============================] - 0s 104us/step - loss: 0.0561 - accuracy: 0.9774 - val_loss: 2.4506 - val_accuracy: 0.5000\n",
      "Epoch 725/1000\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.0574 - accuracy: 0.9718 - val_loss: 2.4368 - val_accuracy: 0.4868\n",
      "Epoch 726/1000\n",
      "177/177 [==============================] - 0s 118us/step - loss: 0.2074 - accuracy: 0.9661 - val_loss: 2.5001 - val_accuracy: 0.4605\n",
      "Epoch 727/1000\n",
      "177/177 [==============================] - 0s 106us/step - loss: 0.2246 - accuracy: 0.9492 - val_loss: 3.0379 - val_accuracy: 0.4474\n",
      "Epoch 728/1000\n",
      "177/177 [==============================] - 0s 96us/step - loss: 0.5579 - accuracy: 0.9379 - val_loss: 2.7729 - val_accuracy: 0.4737\n",
      "Epoch 729/1000\n",
      "177/177 [==============================] - 0s 105us/step - loss: 0.1330 - accuracy: 0.9718 - val_loss: 2.4918 - val_accuracy: 0.4868\n",
      "Epoch 730/1000\n",
      "177/177 [==============================] - 0s 100us/step - loss: 0.3355 - accuracy: 0.9548 - val_loss: 2.4617 - val_accuracy: 0.5000\n",
      "Epoch 731/1000\n",
      "177/177 [==============================] - 0s 110us/step - loss: 0.1990 - accuracy: 0.9548 - val_loss: 2.6423 - val_accuracy: 0.4211\n",
      "Epoch 732/1000\n",
      "177/177 [==============================] - 0s 107us/step - loss: 0.1207 - accuracy: 0.9774 - val_loss: 2.5619 - val_accuracy: 0.4605\n",
      "Epoch 733/1000\n",
      "177/177 [==============================] - 0s 123us/step - loss: 0.0712 - accuracy: 0.9831 - val_loss: 2.4951 - val_accuracy: 0.5000\n",
      "Epoch 734/1000\n",
      "177/177 [==============================] - 0s 125us/step - loss: 0.1291 - accuracy: 0.9774 - val_loss: 2.4434 - val_accuracy: 0.4737\n",
      "Epoch 735/1000\n",
      "177/177 [==============================] - 0s 97us/step - loss: 0.0702 - accuracy: 0.9774 - val_loss: 2.4489 - val_accuracy: 0.4605\n",
      "Epoch 736/1000\n",
      "177/177 [==============================] - 0s 103us/step - loss: 0.0719 - accuracy: 0.9718 - val_loss: 2.4191 - val_accuracy: 0.4737\n",
      "Epoch 737/1000\n",
      "177/177 [==============================] - 0s 105us/step - loss: 0.0739 - accuracy: 0.9774 - val_loss: 2.4635 - val_accuracy: 0.4605\n",
      "Epoch 738/1000\n",
      "177/177 [==============================] - 0s 117us/step - loss: 0.0595 - accuracy: 0.9831 - val_loss: 2.4318 - val_accuracy: 0.4474\n",
      "Epoch 739/1000\n",
      "177/177 [==============================] - 0s 105us/step - loss: 0.0912 - accuracy: 0.9831 - val_loss: 2.4850 - val_accuracy: 0.4737\n",
      "Epoch 740/1000\n",
      "177/177 [==============================] - 0s 124us/step - loss: 0.0992 - accuracy: 0.9831 - val_loss: 2.4458 - val_accuracy: 0.4605\n",
      "Epoch 741/1000\n",
      "177/177 [==============================] - 0s 100us/step - loss: 0.2518 - accuracy: 0.9605 - val_loss: 2.4982 - val_accuracy: 0.4737\n",
      "Epoch 742/1000\n",
      "177/177 [==============================] - 0s 141us/step - loss: 0.2683 - accuracy: 0.9435 - val_loss: 2.5227 - val_accuracy: 0.4737\n",
      "Epoch 743/1000\n",
      "177/177 [==============================] - 0s 129us/step - loss: 0.1127 - accuracy: 0.9718 - val_loss: 2.4329 - val_accuracy: 0.5000\n",
      "Epoch 744/1000\n",
      "177/177 [==============================] - 0s 91us/step - loss: 0.1819 - accuracy: 0.9718 - val_loss: 2.5133 - val_accuracy: 0.4605\n",
      "Epoch 745/1000\n",
      "177/177 [==============================] - 0s 101us/step - loss: 0.2680 - accuracy: 0.9661 - val_loss: 2.4665 - val_accuracy: 0.5000\n",
      "Epoch 746/1000\n",
      "177/177 [==============================] - 0s 93us/step - loss: 0.1583 - accuracy: 0.9774 - val_loss: 2.5396 - val_accuracy: 0.5000\n",
      "Epoch 747/1000\n",
      "177/177 [==============================] - 0s 119us/step - loss: 0.1107 - accuracy: 0.9718 - val_loss: 2.4586 - val_accuracy: 0.4737\n",
      "Epoch 748/1000\n",
      "177/177 [==============================] - 0s 107us/step - loss: 0.1927 - accuracy: 0.9774 - val_loss: 2.4805 - val_accuracy: 0.4605\n",
      "Epoch 749/1000\n",
      "177/177 [==============================] - 0s 100us/step - loss: 0.2400 - accuracy: 0.9605 - val_loss: 2.4485 - val_accuracy: 0.5000\n",
      "Epoch 750/1000\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.2269 - accuracy: 0.9718 - val_loss: 2.4655 - val_accuracy: 0.5263\n",
      "Epoch 751/1000\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.1560 - accuracy: 0.9661 - val_loss: 2.5301 - val_accuracy: 0.4474\n",
      "Epoch 752/1000\n",
      "177/177 [==============================] - 0s 94us/step - loss: 0.3260 - accuracy: 0.9661 - val_loss: 2.4828 - val_accuracy: 0.4737\n",
      "Epoch 753/1000\n",
      "177/177 [==============================] - 0s 94us/step - loss: 0.1814 - accuracy: 0.9718 - val_loss: 2.4866 - val_accuracy: 0.4868\n",
      "Epoch 754/1000\n",
      "177/177 [==============================] - 0s 83us/step - loss: 0.0690 - accuracy: 0.9831 - val_loss: 2.5257 - val_accuracy: 0.5132\n",
      "Epoch 755/1000\n",
      "177/177 [==============================] - 0s 89us/step - loss: 0.0930 - accuracy: 0.9774 - val_loss: 2.4147 - val_accuracy: 0.5263\n",
      "Epoch 756/1000\n",
      "177/177 [==============================] - 0s 86us/step - loss: 0.1633 - accuracy: 0.9718 - val_loss: 2.4335 - val_accuracy: 0.4737\n",
      "Epoch 757/1000\n",
      "177/177 [==============================] - 0s 87us/step - loss: 0.1621 - accuracy: 0.9718 - val_loss: 2.5794 - val_accuracy: 0.4737\n",
      "Epoch 758/1000\n",
      "177/177 [==============================] - 0s 83us/step - loss: 0.1028 - accuracy: 0.9718 - val_loss: 2.4928 - val_accuracy: 0.5000\n",
      "Epoch 759/1000\n",
      "177/177 [==============================] - 0s 87us/step - loss: 0.0660 - accuracy: 0.9831 - val_loss: 2.4769 - val_accuracy: 0.5132\n",
      "Epoch 760/1000\n",
      "177/177 [==============================] - 0s 97us/step - loss: 0.1473 - accuracy: 0.9718 - val_loss: 2.5250 - val_accuracy: 0.4737\n",
      "Epoch 761/1000\n",
      "177/177 [==============================] - 0s 92us/step - loss: 0.0589 - accuracy: 0.9831 - val_loss: 2.4977 - val_accuracy: 0.5000\n",
      "Epoch 762/1000\n",
      "177/177 [==============================] - 0s 95us/step - loss: 0.1076 - accuracy: 0.9774 - val_loss: 2.4864 - val_accuracy: 0.4605\n",
      "Epoch 763/1000\n",
      "177/177 [==============================] - 0s 89us/step - loss: 0.1276 - accuracy: 0.9774 - val_loss: 2.4762 - val_accuracy: 0.4737\n",
      "Epoch 764/1000\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.1091 - accuracy: 0.9831 - val_loss: 2.5914 - val_accuracy: 0.4868\n",
      "Epoch 765/1000\n",
      "177/177 [==============================] - 0s 106us/step - loss: 0.2036 - accuracy: 0.9774 - val_loss: 2.5285 - val_accuracy: 0.4868\n",
      "Epoch 766/1000\n",
      "177/177 [==============================] - 0s 103us/step - loss: 0.0949 - accuracy: 0.9831 - val_loss: 2.4533 - val_accuracy: 0.5000\n",
      "Epoch 767/1000\n",
      "177/177 [==============================] - 0s 100us/step - loss: 0.1049 - accuracy: 0.9774 - val_loss: 2.4920 - val_accuracy: 0.5000\n",
      "Epoch 768/1000\n",
      "177/177 [==============================] - 0s 99us/step - loss: 0.1232 - accuracy: 0.9718 - val_loss: 2.5435 - val_accuracy: 0.4737\n",
      "Epoch 769/1000\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.0753 - accuracy: 0.9774 - val_loss: 2.4837 - val_accuracy: 0.5132\n",
      "Epoch 770/1000\n",
      "177/177 [==============================] - 0s 95us/step - loss: 0.0934 - accuracy: 0.9774 - val_loss: 2.4811 - val_accuracy: 0.5000\n",
      "Epoch 771/1000\n",
      "177/177 [==============================] - 0s 100us/step - loss: 0.1505 - accuracy: 0.9774 - val_loss: 2.4894 - val_accuracy: 0.4605\n",
      "Epoch 772/1000\n",
      "177/177 [==============================] - 0s 95us/step - loss: 0.1481 - accuracy: 0.9831 - val_loss: 2.5148 - val_accuracy: 0.4737\n",
      "Epoch 773/1000\n",
      "177/177 [==============================] - 0s 93us/step - loss: 0.1123 - accuracy: 0.9887 - val_loss: 2.6443 - val_accuracy: 0.4737\n",
      "Epoch 774/1000\n",
      "177/177 [==============================] - 0s 105us/step - loss: 0.3901 - accuracy: 0.9492 - val_loss: 2.5846 - val_accuracy: 0.4737\n",
      "Epoch 775/1000\n",
      "177/177 [==============================] - 0s 119us/step - loss: 0.1433 - accuracy: 0.9661 - val_loss: 2.4955 - val_accuracy: 0.5132\n",
      "Epoch 776/1000\n",
      "177/177 [==============================] - 0s 122us/step - loss: 0.2264 - accuracy: 0.9718 - val_loss: 2.5891 - val_accuracy: 0.4474\n",
      "Epoch 777/1000\n",
      "177/177 [==============================] - 0s 101us/step - loss: 0.1890 - accuracy: 0.9661 - val_loss: 2.6218 - val_accuracy: 0.4605\n",
      "Epoch 778/1000\n",
      "177/177 [==============================] - 0s 111us/step - loss: 0.1533 - accuracy: 0.9718 - val_loss: 2.5252 - val_accuracy: 0.5263\n",
      "Epoch 779/1000\n",
      "177/177 [==============================] - 0s 236us/step - loss: 0.1804 - accuracy: 0.9605 - val_loss: 2.6181 - val_accuracy: 0.4737\n",
      "Epoch 780/1000\n",
      "177/177 [==============================] - 0s 101us/step - loss: 0.2736 - accuracy: 0.9605 - val_loss: 2.6135 - val_accuracy: 0.5132\n",
      "Epoch 781/1000\n",
      "177/177 [==============================] - 0s 119us/step - loss: 0.1108 - accuracy: 0.9661 - val_loss: 2.4804 - val_accuracy: 0.5000\n",
      "Epoch 782/1000\n",
      "177/177 [==============================] - 0s 108us/step - loss: 0.2414 - accuracy: 0.9718 - val_loss: 2.5749 - val_accuracy: 0.4605\n",
      "Epoch 783/1000\n",
      "177/177 [==============================] - 0s 121us/step - loss: 0.2504 - accuracy: 0.9661 - val_loss: 2.5122 - val_accuracy: 0.5000\n",
      "Epoch 784/1000\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.1737 - accuracy: 0.9605 - val_loss: 2.4837 - val_accuracy: 0.5000\n",
      "Epoch 785/1000\n",
      "177/177 [==============================] - 0s 115us/step - loss: 0.2206 - accuracy: 0.9718 - val_loss: 2.5993 - val_accuracy: 0.4737\n",
      "Epoch 786/1000\n",
      "177/177 [==============================] - 0s 102us/step - loss: 0.2670 - accuracy: 0.9605 - val_loss: 2.6025 - val_accuracy: 0.4737\n",
      "Epoch 787/1000\n",
      "177/177 [==============================] - 0s 93us/step - loss: 0.1824 - accuracy: 0.9718 - val_loss: 2.5276 - val_accuracy: 0.5132\n",
      "Epoch 788/1000\n",
      "177/177 [==============================] - 0s 97us/step - loss: 0.0615 - accuracy: 0.9774 - val_loss: 2.6814 - val_accuracy: 0.4605\n",
      "Epoch 789/1000\n",
      "177/177 [==============================] - 0s 102us/step - loss: 0.3633 - accuracy: 0.9492 - val_loss: 2.5079 - val_accuracy: 0.5132\n",
      "Epoch 790/1000\n",
      "177/177 [==============================] - 0s 106us/step - loss: 0.1458 - accuracy: 0.9718 - val_loss: 2.5305 - val_accuracy: 0.5000\n",
      "Epoch 791/1000\n",
      "177/177 [==============================] - 0s 119us/step - loss: 0.0815 - accuracy: 0.9774 - val_loss: 2.5644 - val_accuracy: 0.4737\n",
      "Epoch 792/1000\n",
      "177/177 [==============================] - 0s 114us/step - loss: 0.2064 - accuracy: 0.9605 - val_loss: 2.5645 - val_accuracy: 0.4868\n",
      "Epoch 793/1000\n",
      "177/177 [==============================] - 0s 112us/step - loss: 0.5852 - accuracy: 0.9605 - val_loss: 2.5086 - val_accuracy: 0.4868\n",
      "Epoch 794/1000\n",
      "177/177 [==============================] - 0s 116us/step - loss: 0.2673 - accuracy: 0.9605 - val_loss: 2.5738 - val_accuracy: 0.4868\n",
      "Epoch 795/1000\n",
      "177/177 [==============================] - 0s 110us/step - loss: 0.4995 - accuracy: 0.9492 - val_loss: 2.7956 - val_accuracy: 0.4737\n",
      "Epoch 796/1000\n",
      "177/177 [==============================] - 0s 122us/step - loss: 0.1811 - accuracy: 0.9718 - val_loss: 2.5655 - val_accuracy: 0.4605\n",
      "Epoch 797/1000\n",
      "177/177 [==============================] - 0s 106us/step - loss: 0.1195 - accuracy: 0.9774 - val_loss: 2.5564 - val_accuracy: 0.4605\n",
      "Epoch 798/1000\n",
      "177/177 [==============================] - 0s 107us/step - loss: 0.0569 - accuracy: 0.9774 - val_loss: 2.6901 - val_accuracy: 0.4474\n",
      "Epoch 799/1000\n",
      "177/177 [==============================] - 0s 112us/step - loss: 0.2027 - accuracy: 0.9661 - val_loss: 2.6642 - val_accuracy: 0.4737\n",
      "Epoch 800/1000\n",
      "177/177 [==============================] - 0s 115us/step - loss: 0.0548 - accuracy: 0.9831 - val_loss: 2.5786 - val_accuracy: 0.4868\n",
      "Epoch 801/1000\n",
      "177/177 [==============================] - 0s 122us/step - loss: 0.0676 - accuracy: 0.9774 - val_loss: 2.6018 - val_accuracy: 0.4605\n",
      "Epoch 802/1000\n",
      "177/177 [==============================] - 0s 95us/step - loss: 0.0795 - accuracy: 0.9774 - val_loss: 2.5925 - val_accuracy: 0.4605\n",
      "Epoch 803/1000\n",
      "177/177 [==============================] - 0s 94us/step - loss: 0.0480 - accuracy: 0.9831 - val_loss: 2.5672 - val_accuracy: 0.4605\n",
      "Epoch 804/1000\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.0486 - accuracy: 0.9831 - val_loss: 2.5624 - val_accuracy: 0.4605\n",
      "Epoch 805/1000\n",
      "177/177 [==============================] - 0s 96us/step - loss: 0.0481 - accuracy: 0.9774 - val_loss: 2.5959 - val_accuracy: 0.4737\n",
      "Epoch 806/1000\n",
      "177/177 [==============================] - 0s 103us/step - loss: 0.0474 - accuracy: 0.9831 - val_loss: 2.5443 - val_accuracy: 0.4868\n",
      "Epoch 807/1000\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.0488 - accuracy: 0.9831 - val_loss: 2.5550 - val_accuracy: 0.4868\n",
      "Epoch 808/1000\n",
      "177/177 [==============================] - 0s 108us/step - loss: 0.0503 - accuracy: 0.9831 - val_loss: 2.5698 - val_accuracy: 0.4868\n",
      "Epoch 809/1000\n",
      "177/177 [==============================] - 0s 91us/step - loss: 0.0470 - accuracy: 0.9887 - val_loss: 2.5694 - val_accuracy: 0.4737\n",
      "Epoch 810/1000\n",
      "177/177 [==============================] - 0s 107us/step - loss: 0.0447 - accuracy: 0.9887 - val_loss: 2.5876 - val_accuracy: 0.4737\n",
      "Epoch 811/1000\n",
      "177/177 [==============================] - 0s 105us/step - loss: 0.0430 - accuracy: 0.9887 - val_loss: 2.5933 - val_accuracy: 0.4737\n",
      "Epoch 812/1000\n",
      "177/177 [==============================] - 0s 95us/step - loss: 0.0455 - accuracy: 0.9887 - val_loss: 2.5698 - val_accuracy: 0.4605\n",
      "Epoch 813/1000\n",
      "177/177 [==============================] - 0s 91us/step - loss: 0.0442 - accuracy: 0.9887 - val_loss: 2.5743 - val_accuracy: 0.4737\n",
      "Epoch 814/1000\n",
      "177/177 [==============================] - 0s 139us/step - loss: 0.0419 - accuracy: 0.9887 - val_loss: 2.5975 - val_accuracy: 0.4737\n",
      "Epoch 815/1000\n",
      "177/177 [==============================] - 0s 110us/step - loss: 0.0422 - accuracy: 0.9831 - val_loss: 2.5950 - val_accuracy: 0.4605\n",
      "Epoch 816/1000\n",
      "177/177 [==============================] - 0s 92us/step - loss: 0.0415 - accuracy: 0.9887 - val_loss: 2.6197 - val_accuracy: 0.4474\n",
      "Epoch 817/1000\n",
      "177/177 [==============================] - 0s 106us/step - loss: 0.0426 - accuracy: 0.9887 - val_loss: 2.6155 - val_accuracy: 0.4474\n",
      "Epoch 818/1000\n",
      "177/177 [==============================] - 0s 120us/step - loss: 0.0442 - accuracy: 0.9831 - val_loss: 2.5790 - val_accuracy: 0.4737\n",
      "Epoch 819/1000\n",
      "177/177 [==============================] - 0s 106us/step - loss: 0.0434 - accuracy: 0.9887 - val_loss: 2.6336 - val_accuracy: 0.4737\n",
      "Epoch 820/1000\n",
      "177/177 [==============================] - 0s 111us/step - loss: 0.0574 - accuracy: 0.9831 - val_loss: 2.5962 - val_accuracy: 0.4737\n",
      "Epoch 821/1000\n",
      "177/177 [==============================] - 0s 107us/step - loss: 0.1131 - accuracy: 0.9831 - val_loss: 2.5954 - val_accuracy: 0.4605\n",
      "Epoch 822/1000\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.0653 - accuracy: 0.9831 - val_loss: 2.5744 - val_accuracy: 0.4737\n",
      "Epoch 823/1000\n",
      "177/177 [==============================] - 0s 99us/step - loss: 0.1577 - accuracy: 0.9661 - val_loss: 2.5615 - val_accuracy: 0.5000\n",
      "Epoch 824/1000\n",
      "177/177 [==============================] - 0s 106us/step - loss: 0.1322 - accuracy: 0.9774 - val_loss: 2.7814 - val_accuracy: 0.4342\n",
      "Epoch 825/1000\n",
      "177/177 [==============================] - 0s 110us/step - loss: 0.3283 - accuracy: 0.9605 - val_loss: 2.6194 - val_accuracy: 0.4737\n",
      "Epoch 826/1000\n",
      "177/177 [==============================] - 0s 107us/step - loss: 0.2791 - accuracy: 0.9548 - val_loss: 2.6404 - val_accuracy: 0.4868\n",
      "Epoch 827/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177/177 [==============================] - 0s 110us/step - loss: 0.0763 - accuracy: 0.9774 - val_loss: 2.6467 - val_accuracy: 0.4737\n",
      "Epoch 828/1000\n",
      "177/177 [==============================] - 0s 112us/step - loss: 0.1181 - accuracy: 0.9718 - val_loss: 2.6737 - val_accuracy: 0.5132\n",
      "Epoch 829/1000\n",
      "177/177 [==============================] - 0s 116us/step - loss: 0.1142 - accuracy: 0.9774 - val_loss: 2.5844 - val_accuracy: 0.4868\n",
      "Epoch 830/1000\n",
      "177/177 [==============================] - 0s 110us/step - loss: 0.0824 - accuracy: 0.9774 - val_loss: 2.6378 - val_accuracy: 0.4474\n",
      "Epoch 831/1000\n",
      "177/177 [==============================] - 0s 97us/step - loss: 0.1308 - accuracy: 0.9774 - val_loss: 2.6500 - val_accuracy: 0.4868\n",
      "Epoch 832/1000\n",
      "177/177 [==============================] - 0s 104us/step - loss: 0.0502 - accuracy: 0.9831 - val_loss: 2.5781 - val_accuracy: 0.4737\n",
      "Epoch 833/1000\n",
      "177/177 [==============================] - 0s 118us/step - loss: 0.1361 - accuracy: 0.9774 - val_loss: 2.6564 - val_accuracy: 0.4605\n",
      "Epoch 834/1000\n",
      "177/177 [==============================] - 0s 107us/step - loss: 0.1361 - accuracy: 0.9774 - val_loss: 2.6833 - val_accuracy: 0.4868\n",
      "Epoch 835/1000\n",
      "177/177 [==============================] - 0s 108us/step - loss: 0.0955 - accuracy: 0.9718 - val_loss: 2.6018 - val_accuracy: 0.4868\n",
      "Epoch 836/1000\n",
      "177/177 [==============================] - 0s 115us/step - loss: 0.1017 - accuracy: 0.9831 - val_loss: 3.0021 - val_accuracy: 0.4605\n",
      "Epoch 837/1000\n",
      "177/177 [==============================] - 0s 108us/step - loss: 0.4284 - accuracy: 0.9548 - val_loss: 2.7428 - val_accuracy: 0.4605\n",
      "Epoch 838/1000\n",
      "177/177 [==============================] - 0s 113us/step - loss: 0.1172 - accuracy: 0.9774 - val_loss: 2.6158 - val_accuracy: 0.5000\n",
      "Epoch 839/1000\n",
      "177/177 [==============================] - 0s 146us/step - loss: 0.2130 - accuracy: 0.9661 - val_loss: 2.6198 - val_accuracy: 0.4868\n",
      "Epoch 840/1000\n",
      "177/177 [==============================] - 0s 96us/step - loss: 0.0835 - accuracy: 0.9661 - val_loss: 2.6978 - val_accuracy: 0.4342\n",
      "Epoch 841/1000\n",
      "177/177 [==============================] - 0s 106us/step - loss: 0.1048 - accuracy: 0.9661 - val_loss: 2.6113 - val_accuracy: 0.4737\n",
      "Epoch 842/1000\n",
      "177/177 [==============================] - 0s 110us/step - loss: 0.1728 - accuracy: 0.9661 - val_loss: 2.6135 - val_accuracy: 0.4737\n",
      "Epoch 843/1000\n",
      "177/177 [==============================] - 0s 111us/step - loss: 0.0402 - accuracy: 0.9831 - val_loss: 2.6720 - val_accuracy: 0.4474\n",
      "Epoch 844/1000\n",
      "177/177 [==============================] - 0s 94us/step - loss: 0.0695 - accuracy: 0.9718 - val_loss: 2.6092 - val_accuracy: 0.4605\n",
      "Epoch 845/1000\n",
      "177/177 [==============================] - 0s 100us/step - loss: 0.0871 - accuracy: 0.9718 - val_loss: 2.6385 - val_accuracy: 0.4737\n",
      "Epoch 846/1000\n",
      "177/177 [==============================] - 0s 116us/step - loss: 0.1189 - accuracy: 0.9774 - val_loss: 2.6687 - val_accuracy: 0.4737\n",
      "Epoch 847/1000\n",
      "177/177 [==============================] - 0s 104us/step - loss: 0.1210 - accuracy: 0.9661 - val_loss: 2.6126 - val_accuracy: 0.4737\n",
      "Epoch 848/1000\n",
      "177/177 [==============================] - 0s 111us/step - loss: 0.1025 - accuracy: 0.9718 - val_loss: 2.7216 - val_accuracy: 0.4605\n",
      "Epoch 849/1000\n",
      "177/177 [==============================] - 0s 104us/step - loss: 0.1279 - accuracy: 0.9774 - val_loss: 2.6695 - val_accuracy: 0.4737\n",
      "Epoch 850/1000\n",
      "177/177 [==============================] - 0s 131us/step - loss: 0.0387 - accuracy: 0.9887 - val_loss: 2.6997 - val_accuracy: 0.4474\n",
      "Epoch 851/1000\n",
      "177/177 [==============================] - 0s 129us/step - loss: 0.2368 - accuracy: 0.9718 - val_loss: 2.6418 - val_accuracy: 0.4605\n",
      "Epoch 852/1000\n",
      "177/177 [==============================] - 0s 100us/step - loss: 0.1521 - accuracy: 0.9831 - val_loss: 2.7312 - val_accuracy: 0.4737\n",
      "Epoch 853/1000\n",
      "177/177 [==============================] - 0s 125us/step - loss: 0.1794 - accuracy: 0.9831 - val_loss: 2.7122 - val_accuracy: 0.4737\n",
      "Epoch 854/1000\n",
      "177/177 [==============================] - 0s 104us/step - loss: 0.3343 - accuracy: 0.9661 - val_loss: 2.6438 - val_accuracy: 0.4868\n",
      "Epoch 855/1000\n",
      "177/177 [==============================] - 0s 95us/step - loss: 0.2611 - accuracy: 0.9661 - val_loss: 2.7600 - val_accuracy: 0.4474\n",
      "Epoch 856/1000\n",
      "177/177 [==============================] - 0s 116us/step - loss: 0.1403 - accuracy: 0.9718 - val_loss: 2.6923 - val_accuracy: 0.4737\n",
      "Epoch 857/1000\n",
      "177/177 [==============================] - 0s 96us/step - loss: 0.1250 - accuracy: 0.9661 - val_loss: 2.6186 - val_accuracy: 0.5000\n",
      "Epoch 858/1000\n",
      "177/177 [==============================] - 0s 107us/step - loss: 0.1578 - accuracy: 0.9774 - val_loss: 2.8278 - val_accuracy: 0.4605\n",
      "Epoch 859/1000\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.2305 - accuracy: 0.9661 - val_loss: 2.7667 - val_accuracy: 0.4605\n",
      "Epoch 860/1000\n",
      "177/177 [==============================] - 0s 83us/step - loss: 0.0411 - accuracy: 0.9831 - val_loss: 2.6760 - val_accuracy: 0.4737\n",
      "Epoch 861/1000\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.1386 - accuracy: 0.9718 - val_loss: 2.6778 - val_accuracy: 0.4868\n",
      "Epoch 862/1000\n",
      "177/177 [==============================] - 0s 83us/step - loss: 0.0484 - accuracy: 0.9774 - val_loss: 2.8057 - val_accuracy: 0.4342\n",
      "Epoch 863/1000\n",
      "177/177 [==============================] - 0s 110us/step - loss: 0.1642 - accuracy: 0.9718 - val_loss: 2.7574 - val_accuracy: 0.4474\n",
      "Epoch 864/1000\n",
      "177/177 [==============================] - 0s 95us/step - loss: 0.1204 - accuracy: 0.9718 - val_loss: 2.6953 - val_accuracy: 0.4868\n",
      "Epoch 865/1000\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.0915 - accuracy: 0.9774 - val_loss: 2.7260 - val_accuracy: 0.4342\n",
      "Epoch 866/1000\n",
      "177/177 [==============================] - 0s 121us/step - loss: 0.1127 - accuracy: 0.9831 - val_loss: 2.7603 - val_accuracy: 0.4474\n",
      "Epoch 867/1000\n",
      "177/177 [==============================] - 0s 114us/step - loss: 0.0697 - accuracy: 0.9774 - val_loss: 2.6694 - val_accuracy: 0.4737\n",
      "Epoch 868/1000\n",
      "177/177 [==============================] - 0s 114us/step - loss: 0.1447 - accuracy: 0.9718 - val_loss: 2.6709 - val_accuracy: 0.4605\n",
      "Epoch 869/1000\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.1202 - accuracy: 0.9831 - val_loss: 2.7966 - val_accuracy: 0.4211\n",
      "Epoch 870/1000\n",
      "177/177 [==============================] - 0s 85us/step - loss: 0.0490 - accuracy: 0.9718 - val_loss: 2.7118 - val_accuracy: 0.4342\n",
      "Epoch 871/1000\n",
      "177/177 [==============================] - 0s 89us/step - loss: 0.0674 - accuracy: 0.9718 - val_loss: 2.6564 - val_accuracy: 0.4868\n",
      "Epoch 872/1000\n",
      "177/177 [==============================] - 0s 84us/step - loss: 0.1218 - accuracy: 0.9774 - val_loss: 2.7242 - val_accuracy: 0.4474\n",
      "Epoch 873/1000\n",
      "177/177 [==============================] - 0s 84us/step - loss: 0.0480 - accuracy: 0.9831 - val_loss: 2.7163 - val_accuracy: 0.4474\n",
      "Epoch 874/1000\n",
      "177/177 [==============================] - 0s 85us/step - loss: 0.1169 - accuracy: 0.9774 - val_loss: 2.7441 - val_accuracy: 0.4342\n",
      "Epoch 875/1000\n",
      "177/177 [==============================] - 0s 84us/step - loss: 0.0384 - accuracy: 0.9887 - val_loss: 2.7318 - val_accuracy: 0.4474\n",
      "Epoch 876/1000\n",
      "177/177 [==============================] - 0s 94us/step - loss: 0.0480 - accuracy: 0.9831 - val_loss: 2.6959 - val_accuracy: 0.4605\n",
      "Epoch 877/1000\n",
      "177/177 [==============================] - 0s 86us/step - loss: 0.0461 - accuracy: 0.9831 - val_loss: 2.6991 - val_accuracy: 0.4474\n",
      "Epoch 878/1000\n",
      "177/177 [==============================] - 0s 103us/step - loss: 0.0921 - accuracy: 0.9831 - val_loss: 2.8336 - val_accuracy: 0.4474\n",
      "Epoch 879/1000\n",
      "177/177 [==============================] - 0s 94us/step - loss: 0.1291 - accuracy: 0.9718 - val_loss: 2.7572 - val_accuracy: 0.4342\n",
      "Epoch 880/1000\n",
      "177/177 [==============================] - 0s 99us/step - loss: 0.0910 - accuracy: 0.9831 - val_loss: 2.6978 - val_accuracy: 0.4605\n",
      "Epoch 881/1000\n",
      "177/177 [==============================] - 0s 95us/step - loss: 0.0449 - accuracy: 0.9887 - val_loss: 2.7555 - val_accuracy: 0.4474\n",
      "Epoch 882/1000\n",
      "177/177 [==============================] - 0s 84us/step - loss: 0.1100 - accuracy: 0.9831 - val_loss: 2.7411 - val_accuracy: 0.4342\n",
      "Epoch 883/1000\n",
      "177/177 [==============================] - 0s 102us/step - loss: 0.0584 - accuracy: 0.9661 - val_loss: 2.7026 - val_accuracy: 0.4737\n",
      "Epoch 884/1000\n",
      "177/177 [==============================] - 0s 104us/step - loss: 0.2435 - accuracy: 0.9661 - val_loss: 2.8312 - val_accuracy: 0.4079\n",
      "Epoch 885/1000\n",
      "177/177 [==============================] - 0s 113us/step - loss: 0.1384 - accuracy: 0.9661 - val_loss: 2.7885 - val_accuracy: 0.4868\n",
      "Epoch 886/1000\n",
      "177/177 [==============================] - 0s 121us/step - loss: 0.5037 - accuracy: 0.9492 - val_loss: 2.6695 - val_accuracy: 0.4737\n",
      "Epoch 887/1000\n",
      "177/177 [==============================] - 0s 109us/step - loss: 0.2740 - accuracy: 0.9548 - val_loss: 2.8887 - val_accuracy: 0.4474\n",
      "Epoch 888/1000\n",
      "177/177 [==============================] - 0s 100us/step - loss: 0.3023 - accuracy: 0.9548 - val_loss: 2.6887 - val_accuracy: 0.4868\n",
      "Epoch 889/1000\n",
      "177/177 [==============================] - 0s 112us/step - loss: 0.2688 - accuracy: 0.9661 - val_loss: 2.9010 - val_accuracy: 0.4474\n",
      "Epoch 890/1000\n",
      "177/177 [==============================] - 0s 103us/step - loss: 0.2809 - accuracy: 0.9605 - val_loss: 2.8606 - val_accuracy: 0.4342\n",
      "Epoch 891/1000\n",
      "177/177 [==============================] - 0s 115us/step - loss: 0.1292 - accuracy: 0.9831 - val_loss: 2.7515 - val_accuracy: 0.4737\n",
      "Epoch 892/1000\n",
      "177/177 [==============================] - 0s 123us/step - loss: 0.0556 - accuracy: 0.9774 - val_loss: 2.7569 - val_accuracy: 0.4605\n",
      "Epoch 893/1000\n",
      "177/177 [==============================] - 0s 89us/step - loss: 0.0919 - accuracy: 0.9774 - val_loss: 2.7901 - val_accuracy: 0.4342\n",
      "Epoch 894/1000\n",
      "177/177 [==============================] - 0s 110us/step - loss: 0.0465 - accuracy: 0.9774 - val_loss: 2.7714 - val_accuracy: 0.4342\n",
      "Epoch 895/1000\n",
      "177/177 [==============================] - 0s 104us/step - loss: 0.1089 - accuracy: 0.9774 - val_loss: 2.7519 - val_accuracy: 0.4474\n",
      "Epoch 896/1000\n",
      "177/177 [==============================] - 0s 77us/step - loss: 0.0661 - accuracy: 0.9774 - val_loss: 2.7375 - val_accuracy: 0.4474\n",
      "Epoch 897/1000\n",
      "177/177 [==============================] - 0s 83us/step - loss: 0.0656 - accuracy: 0.9718 - val_loss: 2.7347 - val_accuracy: 0.4474\n",
      "Epoch 898/1000\n",
      "177/177 [==============================] - 0s 81us/step - loss: 0.0484 - accuracy: 0.9887 - val_loss: 2.7784 - val_accuracy: 0.4474\n",
      "Epoch 899/1000\n",
      "177/177 [==============================] - 0s 82us/step - loss: 0.0380 - accuracy: 0.9887 - val_loss: 2.8079 - val_accuracy: 0.4474\n",
      "Epoch 900/1000\n",
      "177/177 [==============================] - 0s 100us/step - loss: 0.0484 - accuracy: 0.9887 - val_loss: 2.7699 - val_accuracy: 0.4342\n",
      "Epoch 901/1000\n",
      "177/177 [==============================] - 0s 95us/step - loss: 0.0396 - accuracy: 0.9887 - val_loss: 2.7800 - val_accuracy: 0.4342\n",
      "Epoch 902/1000\n",
      "177/177 [==============================] - 0s 112us/step - loss: 0.0399 - accuracy: 0.9887 - val_loss: 2.7884 - val_accuracy: 0.4342\n",
      "Epoch 903/1000\n",
      "177/177 [==============================] - 0s 101us/step - loss: 0.0380 - accuracy: 0.9887 - val_loss: 2.7930 - val_accuracy: 0.4342\n",
      "Epoch 904/1000\n",
      "177/177 [==============================] - 0s 109us/step - loss: 0.0403 - accuracy: 0.9887 - val_loss: 2.7760 - val_accuracy: 0.4342\n",
      "Epoch 905/1000\n",
      "177/177 [==============================] - 0s 102us/step - loss: 0.0739 - accuracy: 0.9831 - val_loss: 2.7763 - val_accuracy: 0.4342\n",
      "Epoch 906/1000\n",
      "177/177 [==============================] - 0s 115us/step - loss: 0.0658 - accuracy: 0.9774 - val_loss: 2.7877 - val_accuracy: 0.4474\n",
      "Epoch 907/1000\n",
      "177/177 [==============================] - 0s 118us/step - loss: 0.0893 - accuracy: 0.9831 - val_loss: 2.8018 - val_accuracy: 0.4474\n",
      "Epoch 908/1000\n",
      "177/177 [==============================] - 0s 117us/step - loss: 0.0400 - accuracy: 0.9887 - val_loss: 2.7688 - val_accuracy: 0.4474\n",
      "Epoch 909/1000\n",
      "177/177 [==============================] - 0s 99us/step - loss: 0.0742 - accuracy: 0.9831 - val_loss: 2.8407 - val_accuracy: 0.4342\n",
      "Epoch 910/1000\n",
      "177/177 [==============================] - 0s 99us/step - loss: 0.1481 - accuracy: 0.9661 - val_loss: 2.8016 - val_accuracy: 0.4342\n",
      "Epoch 911/1000\n",
      "177/177 [==============================] - 0s 115us/step - loss: 0.0379 - accuracy: 0.9887 - val_loss: 2.7760 - val_accuracy: 0.4474\n",
      "Epoch 912/1000\n",
      "177/177 [==============================] - 0s 105us/step - loss: 0.0796 - accuracy: 0.9774 - val_loss: 2.8231 - val_accuracy: 0.4342\n",
      "Epoch 913/1000\n",
      "177/177 [==============================] - 0s 119us/step - loss: 0.1441 - accuracy: 0.9661 - val_loss: 2.8525 - val_accuracy: 0.4342\n",
      "Epoch 914/1000\n",
      "177/177 [==============================] - 0s 126us/step - loss: 0.1055 - accuracy: 0.9774 - val_loss: 2.7921 - val_accuracy: 0.4605\n",
      "Epoch 915/1000\n",
      "177/177 [==============================] - 0s 86us/step - loss: 0.1005 - accuracy: 0.9831 - val_loss: 2.8965 - val_accuracy: 0.4342\n",
      "Epoch 916/1000\n",
      "177/177 [==============================] - 0s 93us/step - loss: 0.1521 - accuracy: 0.9774 - val_loss: 2.8227 - val_accuracy: 0.4342\n",
      "Epoch 917/1000\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.0401 - accuracy: 0.9774 - val_loss: 2.7608 - val_accuracy: 0.5000\n",
      "Epoch 918/1000\n",
      "177/177 [==============================] - 0s 102us/step - loss: 0.0984 - accuracy: 0.9718 - val_loss: 2.8282 - val_accuracy: 0.4342\n",
      "Epoch 919/1000\n",
      "177/177 [==============================] - 0s 108us/step - loss: 0.2450 - accuracy: 0.9661 - val_loss: 3.0291 - val_accuracy: 0.4474\n",
      "Epoch 920/1000\n",
      "177/177 [==============================] - 0s 102us/step - loss: 0.1272 - accuracy: 0.9774 - val_loss: 2.7920 - val_accuracy: 0.4737\n",
      "Epoch 921/1000\n",
      "177/177 [==============================] - 0s 97us/step - loss: 0.4301 - accuracy: 0.9605 - val_loss: 2.7793 - val_accuracy: 0.5000\n",
      "Epoch 922/1000\n",
      "177/177 [==============================] - 0s 102us/step - loss: 0.1295 - accuracy: 0.9605 - val_loss: 3.0722 - val_accuracy: 0.4605\n",
      "Epoch 923/1000\n",
      "177/177 [==============================] - 0s 105us/step - loss: 0.5950 - accuracy: 0.9548 - val_loss: 3.0712 - val_accuracy: 0.4211\n",
      "Epoch 924/1000\n",
      "177/177 [==============================] - 0s 119us/step - loss: 0.4068 - accuracy: 0.9435 - val_loss: 2.9479 - val_accuracy: 0.5000\n",
      "Epoch 925/1000\n",
      "177/177 [==============================] - 0s 92us/step - loss: 0.6716 - accuracy: 0.9209 - val_loss: 2.9347 - val_accuracy: 0.4342\n",
      "Epoch 926/1000\n",
      "177/177 [==============================] - 0s 101us/step - loss: 0.2963 - accuracy: 0.9661 - val_loss: 2.8659 - val_accuracy: 0.4342\n",
      "Epoch 927/1000\n",
      "177/177 [==============================] - 0s 99us/step - loss: 0.1125 - accuracy: 0.9831 - val_loss: 2.8776 - val_accuracy: 0.4737\n",
      "Epoch 928/1000\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.0465 - accuracy: 0.9831 - val_loss: 2.8040 - val_accuracy: 0.4737\n",
      "Epoch 929/1000\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.0457 - accuracy: 0.9831 - val_loss: 2.8137 - val_accuracy: 0.4737\n",
      "Epoch 930/1000\n",
      "177/177 [==============================] - 0s 99us/step - loss: 0.0416 - accuracy: 0.9887 - val_loss: 2.8393 - val_accuracy: 0.4737\n",
      "Epoch 931/1000\n",
      "177/177 [==============================] - 0s 123us/step - loss: 0.0432 - accuracy: 0.9831 - val_loss: 2.8378 - val_accuracy: 0.4605\n",
      "Epoch 932/1000\n",
      "177/177 [==============================] - 0s 110us/step - loss: 0.0383 - accuracy: 0.9887 - val_loss: 2.8451 - val_accuracy: 0.4605\n",
      "Epoch 933/1000\n",
      "177/177 [==============================] - 0s 113us/step - loss: 0.0583 - accuracy: 0.9831 - val_loss: 2.8311 - val_accuracy: 0.4737\n",
      "Epoch 934/1000\n",
      "177/177 [==============================] - 0s 110us/step - loss: 0.2900 - accuracy: 0.9605 - val_loss: 2.7519 - val_accuracy: 0.4737\n",
      "Epoch 935/1000\n",
      "177/177 [==============================] - 0s 95us/step - loss: 0.0599 - accuracy: 0.9774 - val_loss: 2.9717 - val_accuracy: 0.4605\n",
      "Epoch 936/1000\n",
      "177/177 [==============================] - 0s 105us/step - loss: 0.1773 - accuracy: 0.9718 - val_loss: 2.7832 - val_accuracy: 0.4737\n",
      "Epoch 937/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177/177 [==============================] - 0s 100us/step - loss: 0.0996 - accuracy: 0.9718 - val_loss: 2.9069 - val_accuracy: 0.4605\n",
      "Epoch 938/1000\n",
      "177/177 [==============================] - 0s 100us/step - loss: 0.1865 - accuracy: 0.9718 - val_loss: 2.8834 - val_accuracy: 0.4474\n",
      "Epoch 939/1000\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.0712 - accuracy: 0.9774 - val_loss: 2.8178 - val_accuracy: 0.4868\n",
      "Epoch 940/1000\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.1889 - accuracy: 0.9718 - val_loss: 2.8454 - val_accuracy: 0.4342\n",
      "Epoch 941/1000\n",
      "177/177 [==============================] - 0s 110us/step - loss: 0.0587 - accuracy: 0.9774 - val_loss: 3.0989 - val_accuracy: 0.4474\n",
      "Epoch 942/1000\n",
      "177/177 [==============================] - 0s 113us/step - loss: 0.3579 - accuracy: 0.9492 - val_loss: 2.9297 - val_accuracy: 0.4474\n",
      "Epoch 943/1000\n",
      "177/177 [==============================] - 0s 117us/step - loss: 0.0408 - accuracy: 0.9774 - val_loss: 2.8460 - val_accuracy: 0.4474\n",
      "Epoch 944/1000\n",
      "177/177 [==============================] - 0s 129us/step - loss: 0.0781 - accuracy: 0.9774 - val_loss: 2.8930 - val_accuracy: 0.4342\n",
      "Epoch 945/1000\n",
      "177/177 [==============================] - 0s 118us/step - loss: 0.0639 - accuracy: 0.9774 - val_loss: 2.8563 - val_accuracy: 0.4605\n",
      "Epoch 946/1000\n",
      "177/177 [==============================] - 0s 126us/step - loss: 0.0583 - accuracy: 0.9774 - val_loss: 2.8450 - val_accuracy: 0.4342\n",
      "Epoch 947/1000\n",
      "177/177 [==============================] - 0s 96us/step - loss: 0.0769 - accuracy: 0.9831 - val_loss: 2.9349 - val_accuracy: 0.3947\n",
      "Epoch 948/1000\n",
      "177/177 [==============================] - 0s 113us/step - loss: 0.1119 - accuracy: 0.9718 - val_loss: 2.8626 - val_accuracy: 0.4474\n",
      "Epoch 949/1000\n",
      "177/177 [==============================] - 0s 105us/step - loss: 0.0591 - accuracy: 0.9774 - val_loss: 2.7865 - val_accuracy: 0.4737\n",
      "Epoch 950/1000\n",
      "177/177 [==============================] - 0s 111us/step - loss: 0.0570 - accuracy: 0.9774 - val_loss: 2.8455 - val_accuracy: 0.4474\n",
      "Epoch 951/1000\n",
      "177/177 [==============================] - 0s 120us/step - loss: 0.0505 - accuracy: 0.9774 - val_loss: 2.9743 - val_accuracy: 0.4474\n",
      "Epoch 952/1000\n",
      "177/177 [==============================] - 0s 111us/step - loss: 0.0992 - accuracy: 0.9718 - val_loss: 2.8440 - val_accuracy: 0.4737\n",
      "Epoch 953/1000\n",
      "177/177 [==============================] - 0s 109us/step - loss: 0.0843 - accuracy: 0.9774 - val_loss: 2.8714 - val_accuracy: 0.4605\n",
      "Epoch 954/1000\n",
      "177/177 [==============================] - 0s 123us/step - loss: 0.1440 - accuracy: 0.9718 - val_loss: 2.8605 - val_accuracy: 0.4342\n",
      "Epoch 955/1000\n",
      "177/177 [==============================] - 0s 103us/step - loss: 0.0482 - accuracy: 0.9831 - val_loss: 2.8672 - val_accuracy: 0.4342\n",
      "Epoch 956/1000\n",
      "177/177 [==============================] - 0s 119us/step - loss: 0.1213 - accuracy: 0.9774 - val_loss: 2.8692 - val_accuracy: 0.4342\n",
      "Epoch 957/1000\n",
      "177/177 [==============================] - 0s 125us/step - loss: 0.0707 - accuracy: 0.9831 - val_loss: 2.9157 - val_accuracy: 0.4342\n",
      "Epoch 958/1000\n",
      "177/177 [==============================] - 0s 103us/step - loss: 0.0397 - accuracy: 0.9887 - val_loss: 2.8310 - val_accuracy: 0.4474\n",
      "Epoch 959/1000\n",
      "177/177 [==============================] - 0s 118us/step - loss: 0.1287 - accuracy: 0.9831 - val_loss: 2.8657 - val_accuracy: 0.4342\n",
      "Epoch 960/1000\n",
      "177/177 [==============================] - 0s 107us/step - loss: 0.0825 - accuracy: 0.9774 - val_loss: 2.8913 - val_accuracy: 0.4474\n",
      "Epoch 961/1000\n",
      "177/177 [==============================] - 0s 112us/step - loss: 0.0365 - accuracy: 0.9887 - val_loss: 2.8821 - val_accuracy: 0.4342\n",
      "Epoch 962/1000\n",
      "177/177 [==============================] - 0s 99us/step - loss: 0.0673 - accuracy: 0.9774 - val_loss: 2.9116 - val_accuracy: 0.4474\n",
      "Epoch 963/1000\n",
      "177/177 [==============================] - 0s 105us/step - loss: 0.1046 - accuracy: 0.9661 - val_loss: 2.9294 - val_accuracy: 0.4474\n",
      "Epoch 964/1000\n",
      "177/177 [==============================] - 0s 141us/step - loss: 0.0380 - accuracy: 0.9887 - val_loss: 2.8688 - val_accuracy: 0.4474\n",
      "Epoch 965/1000\n",
      "177/177 [==============================] - 0s 101us/step - loss: 0.0710 - accuracy: 0.9831 - val_loss: 2.9700 - val_accuracy: 0.4605\n",
      "Epoch 966/1000\n",
      "177/177 [==============================] - 0s 108us/step - loss: 0.1159 - accuracy: 0.9831 - val_loss: 2.9112 - val_accuracy: 0.4342\n",
      "Epoch 967/1000\n",
      "177/177 [==============================] - 0s 124us/step - loss: 0.0480 - accuracy: 0.9831 - val_loss: 2.8578 - val_accuracy: 0.4474\n",
      "Epoch 968/1000\n",
      "177/177 [==============================] - 0s 114us/step - loss: 0.0418 - accuracy: 0.9887 - val_loss: 2.9163 - val_accuracy: 0.4474\n",
      "Epoch 969/1000\n",
      "177/177 [==============================] - 0s 105us/step - loss: 0.0783 - accuracy: 0.9831 - val_loss: 2.8725 - val_accuracy: 0.4342\n",
      "Epoch 970/1000\n",
      "177/177 [==============================] - 0s 134us/step - loss: 0.0532 - accuracy: 0.9831 - val_loss: 2.9207 - val_accuracy: 0.4342\n",
      "Epoch 971/1000\n",
      "177/177 [==============================] - 0s 99us/step - loss: 0.1068 - accuracy: 0.9774 - val_loss: 2.9610 - val_accuracy: 0.4474\n",
      "Epoch 972/1000\n",
      "177/177 [==============================] - 0s 112us/step - loss: 0.0395 - accuracy: 0.9887 - val_loss: 2.8961 - val_accuracy: 0.4474\n",
      "Epoch 973/1000\n",
      "177/177 [==============================] - 0s 121us/step - loss: 0.0799 - accuracy: 0.9831 - val_loss: 2.8905 - val_accuracy: 0.4342\n",
      "Epoch 974/1000\n",
      "177/177 [==============================] - 0s 105us/step - loss: 0.2574 - accuracy: 0.9661 - val_loss: 3.1016 - val_accuracy: 0.4342\n",
      "Epoch 975/1000\n",
      "177/177 [==============================] - 0s 108us/step - loss: 0.1655 - accuracy: 0.9718 - val_loss: 2.8795 - val_accuracy: 0.4737\n",
      "Epoch 976/1000\n",
      "177/177 [==============================] - 0s 114us/step - loss: 0.1421 - accuracy: 0.9718 - val_loss: 2.9217 - val_accuracy: 0.4474\n",
      "Epoch 977/1000\n",
      "177/177 [==============================] - 0s 97us/step - loss: 0.2451 - accuracy: 0.9661 - val_loss: 3.1422 - val_accuracy: 0.4211\n",
      "Epoch 978/1000\n",
      "177/177 [==============================] - 0s 97us/step - loss: 0.1788 - accuracy: 0.9718 - val_loss: 2.9203 - val_accuracy: 0.4605\n",
      "Epoch 979/1000\n",
      "177/177 [==============================] - 0s 108us/step - loss: 0.1527 - accuracy: 0.9718 - val_loss: 2.8670 - val_accuracy: 0.4737\n",
      "Epoch 980/1000\n",
      "177/177 [==============================] - 0s 109us/step - loss: 0.0436 - accuracy: 0.9831 - val_loss: 2.8993 - val_accuracy: 0.4474\n",
      "Epoch 981/1000\n",
      "177/177 [==============================] - 0s 106us/step - loss: 0.0711 - accuracy: 0.9831 - val_loss: 2.9109 - val_accuracy: 0.4342\n",
      "Epoch 982/1000\n",
      "177/177 [==============================] - 0s 106us/step - loss: 0.0503 - accuracy: 0.9831 - val_loss: 2.9176 - val_accuracy: 0.4342\n",
      "Epoch 983/1000\n",
      "177/177 [==============================] - 0s 103us/step - loss: 0.0502 - accuracy: 0.9831 - val_loss: 2.8984 - val_accuracy: 0.4342\n",
      "Epoch 984/1000\n",
      "177/177 [==============================] - 0s 97us/step - loss: 0.0751 - accuracy: 0.9718 - val_loss: 2.8846 - val_accuracy: 0.4474\n",
      "Epoch 985/1000\n",
      "177/177 [==============================] - 0s 97us/step - loss: 0.0402 - accuracy: 0.9887 - val_loss: 2.9619 - val_accuracy: 0.4211\n",
      "Epoch 986/1000\n",
      "177/177 [==============================] - 0s 105us/step - loss: 0.0949 - accuracy: 0.9661 - val_loss: 2.8791 - val_accuracy: 0.4605\n",
      "Epoch 987/1000\n",
      "177/177 [==============================] - 0s 110us/step - loss: 0.0644 - accuracy: 0.9831 - val_loss: 2.9997 - val_accuracy: 0.4737\n",
      "Epoch 988/1000\n",
      "177/177 [==============================] - 0s 97us/step - loss: 0.1597 - accuracy: 0.9718 - val_loss: 2.9902 - val_accuracy: 0.4211\n",
      "Epoch 989/1000\n",
      "177/177 [==============================] - 0s 117us/step - loss: 0.1538 - accuracy: 0.9605 - val_loss: 2.9162 - val_accuracy: 0.4868\n",
      "Epoch 990/1000\n",
      "177/177 [==============================] - 0s 87us/step - loss: 0.4373 - accuracy: 0.9661 - val_loss: 3.1895 - val_accuracy: 0.4342\n",
      "Epoch 991/1000\n",
      "177/177 [==============================] - 0s 92us/step - loss: 0.4164 - accuracy: 0.9605 - val_loss: 3.1274 - val_accuracy: 0.4474\n",
      "Epoch 992/1000\n",
      "177/177 [==============================] - 0s 93us/step - loss: 0.1727 - accuracy: 0.9831 - val_loss: 2.9014 - val_accuracy: 0.5000\n",
      "Epoch 993/1000\n",
      "177/177 [==============================] - 0s 107us/step - loss: 0.1661 - accuracy: 0.9661 - val_loss: 2.9996 - val_accuracy: 0.4211\n",
      "Epoch 994/1000\n",
      "177/177 [==============================] - 0s 97us/step - loss: 0.1903 - accuracy: 0.9661 - val_loss: 2.9687 - val_accuracy: 0.4474\n",
      "Epoch 995/1000\n",
      "177/177 [==============================] - 0s 96us/step - loss: 0.2001 - accuracy: 0.9605 - val_loss: 2.9150 - val_accuracy: 0.4605\n",
      "Epoch 996/1000\n",
      "177/177 [==============================] - 0s 119us/step - loss: 0.1052 - accuracy: 0.9661 - val_loss: 2.9259 - val_accuracy: 0.4342\n",
      "Epoch 997/1000\n",
      "177/177 [==============================] - 0s 120us/step - loss: 0.0486 - accuracy: 0.9774 - val_loss: 2.9007 - val_accuracy: 0.4605\n",
      "Epoch 998/1000\n",
      "177/177 [==============================] - 0s 111us/step - loss: 0.0599 - accuracy: 0.9774 - val_loss: 2.9026 - val_accuracy: 0.4474\n",
      "Epoch 999/1000\n",
      "177/177 [==============================] - 0s 105us/step - loss: 0.0445 - accuracy: 0.9887 - val_loss: 2.9524 - val_accuracy: 0.4474\n",
      "Epoch 1000/1000\n",
      "177/177 [==============================] - 0s 115us/step - loss: 0.0669 - accuracy: 0.9774 - val_loss: 2.9470 - val_accuracy: 0.4342\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a4197f080>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sel4.fit(X_sel_train, y_sel_train,\n",
    "          batch_size=32, epochs=1000,\n",
    "          validation_data=(X_sel_test, y_sel_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 0s 139us/step\n",
      "over-sampling test accuracy: 53.95%\n"
     ]
    }
   ],
   "source": [
    "acc_test_sel4 = model_sel4.evaluate(X_sel_test, y_sel_test)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_sel4*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 1, 0, 2, 1, 0, 1, 0, 2, 1, 1, 0, 2, 2, 1, 1, 2, 0, 2, 0,\n",
       "       2, 2, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 2, 0,\n",
       "       0, 0, 2, 1, 0, 2, 1, 1, 1, 0, 0, 2, 0, 0, 1, 2, 2, 1, 0, 2, 0, 2,\n",
       "       1, 2, 2, 1, 0, 2, 1, 1, 2, 0])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred8 = model_sel4.predict_classes(X_sel_test)\n",
    "pred8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strain</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>NRS103</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>EUH25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>NRS001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>NRS192</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>NRS113</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>BCH-SA-09</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>NRS106</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>CFBREBSa131</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>GA51254</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          strain  test  pred\n",
       "130       NRS103     2     1\n",
       "92         EUH25     0     0\n",
       "143       NRS148     2     2\n",
       "107       NRS001     1     1\n",
       "166       NRS192     0     0\n",
       "..           ...   ...   ...\n",
       "139       NRS113     1     2\n",
       "24     BCH-SA-09     2     1\n",
       "133       NRS106     2     1\n",
       "62   CFBREBSa131     2     2\n",
       "100      GA51254     0     0\n",
       "\n",
       "[76 rows x 3 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat8['pred'] = pred8\n",
    "dat8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba8 = model_sel4.predict_proba(X_sel_test)\n",
    "dat_proba8 = pd.DataFrame(proba8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.431225e-07</td>\n",
       "      <td>9.923463e-01</td>\n",
       "      <td>7.653485e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>7.584864e-09</td>\n",
       "      <td>1.752051e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.180629e-07</td>\n",
       "      <td>2.044864e-03</td>\n",
       "      <td>9.979544e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.535082e-04</td>\n",
       "      <td>9.996251e-01</td>\n",
       "      <td>2.135907e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.998932e-01</td>\n",
       "      <td>5.361687e-05</td>\n",
       "      <td>5.318268e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>2.686909e-07</td>\n",
       "      <td>9.312122e-02</td>\n",
       "      <td>9.068785e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>5.529492e-07</td>\n",
       "      <td>9.999899e-01</td>\n",
       "      <td>9.559324e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>1.115902e-03</td>\n",
       "      <td>9.988155e-01</td>\n",
       "      <td>6.852559e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>2.708040e-07</td>\n",
       "      <td>1.567682e-01</td>\n",
       "      <td>8.432316e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>9.993569e-01</td>\n",
       "      <td>6.431147e-04</td>\n",
       "      <td>1.816008e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0             1             2\n",
       "0   2.431225e-07  9.923463e-01  7.653485e-03\n",
       "1   1.000000e+00  7.584864e-09  1.752051e-11\n",
       "2   7.180629e-07  2.044864e-03  9.979544e-01\n",
       "3   3.535082e-04  9.996251e-01  2.135907e-05\n",
       "4   9.998932e-01  5.361687e-05  5.318268e-05\n",
       "..           ...           ...           ...\n",
       "71  2.686909e-07  9.312122e-02  9.068785e-01\n",
       "72  5.529492e-07  9.999899e-01  9.559324e-06\n",
       "73  1.115902e-03  9.988155e-01  6.852559e-05\n",
       "74  2.708040e-07  1.567682e-01  8.432316e-01\n",
       "75  9.993569e-01  6.431147e-04  1.816008e-08\n",
       "\n",
       "[76 rows x 3 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba8.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba8.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat8.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/8p40pST.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 177 samples, validate on 76 samples\n",
      "Epoch 1/1000\n",
      "177/177 [==============================] - 0s 99us/step - loss: 0.0315 - accuracy: 0.9887 - val_loss: 2.7908 - val_accuracy: 0.5395\n",
      "Epoch 2/1000\n",
      "177/177 [==============================] - 0s 106us/step - loss: 0.0321 - accuracy: 0.9887 - val_loss: 2.7835 - val_accuracy: 0.5395\n",
      "Epoch 3/1000\n",
      "177/177 [==============================] - 0s 124us/step - loss: 0.0344 - accuracy: 0.9831 - val_loss: 2.7820 - val_accuracy: 0.5526\n",
      "Epoch 4/1000\n",
      "177/177 [==============================] - 0s 142us/step - loss: 0.0326 - accuracy: 0.9887 - val_loss: 2.7963 - val_accuracy: 0.5526\n",
      "Epoch 5/1000\n",
      "177/177 [==============================] - 0s 152us/step - loss: 0.0312 - accuracy: 0.9887 - val_loss: 2.8002 - val_accuracy: 0.5395\n",
      "Epoch 6/1000\n",
      "177/177 [==============================] - 0s 131us/step - loss: 0.0303 - accuracy: 0.9887 - val_loss: 2.7866 - val_accuracy: 0.5395\n",
      "Epoch 7/1000\n",
      "177/177 [==============================] - 0s 127us/step - loss: 0.0363 - accuracy: 0.9887 - val_loss: 2.7911 - val_accuracy: 0.5395\n",
      "Epoch 8/1000\n",
      "177/177 [==============================] - 0s 136us/step - loss: 0.0323 - accuracy: 0.9887 - val_loss: 2.8127 - val_accuracy: 0.5263\n",
      "Epoch 9/1000\n",
      "177/177 [==============================] - 0s 142us/step - loss: 0.0319 - accuracy: 0.9887 - val_loss: 2.8148 - val_accuracy: 0.5263\n",
      "Epoch 10/1000\n",
      "177/177 [==============================] - 0s 148us/step - loss: 0.0322 - accuracy: 0.9887 - val_loss: 2.8157 - val_accuracy: 0.5395\n",
      "Epoch 11/1000\n",
      "177/177 [==============================] - 0s 131us/step - loss: 0.0312 - accuracy: 0.9887 - val_loss: 2.8266 - val_accuracy: 0.5395\n",
      "Epoch 12/1000\n",
      "177/177 [==============================] - 0s 89us/step - loss: 0.0309 - accuracy: 0.9887 - val_loss: 2.8179 - val_accuracy: 0.5395\n",
      "Epoch 13/1000\n",
      "177/177 [==============================] - 0s 151us/step - loss: 0.0333 - accuracy: 0.9831 - val_loss: 2.8045 - val_accuracy: 0.5395\n",
      "Epoch 14/1000\n",
      "177/177 [==============================] - 0s 163us/step - loss: 0.0311 - accuracy: 0.9887 - val_loss: 2.8289 - val_accuracy: 0.5395\n",
      "Epoch 15/1000\n",
      "177/177 [==============================] - 0s 413us/step - loss: 0.0321 - accuracy: 0.9887 - val_loss: 2.8229 - val_accuracy: 0.5395\n",
      "Epoch 16/1000\n",
      "177/177 [==============================] - 0s 157us/step - loss: 0.0291 - accuracy: 0.9887 - val_loss: 2.8106 - val_accuracy: 0.5395\n",
      "Epoch 17/1000\n",
      "177/177 [==============================] - 0s 115us/step - loss: 0.0331 - accuracy: 0.9887 - val_loss: 2.8038 - val_accuracy: 0.5395\n",
      "Epoch 18/1000\n",
      "177/177 [==============================] - 0s 167us/step - loss: 0.0311 - accuracy: 0.9887 - val_loss: 2.8143 - val_accuracy: 0.5395\n",
      "Epoch 19/1000\n",
      "177/177 [==============================] - 0s 105us/step - loss: 0.0319 - accuracy: 0.9887 - val_loss: 2.8237 - val_accuracy: 0.5395\n",
      "Epoch 20/1000\n",
      "177/177 [==============================] - 0s 121us/step - loss: 0.0331 - accuracy: 0.9831 - val_loss: 2.8124 - val_accuracy: 0.5526\n",
      "Epoch 21/1000\n",
      "177/177 [==============================] - 0s 137us/step - loss: 0.0320 - accuracy: 0.9887 - val_loss: 2.8133 - val_accuracy: 0.5395\n",
      "Epoch 22/1000\n",
      "177/177 [==============================] - 0s 85us/step - loss: 0.0313 - accuracy: 0.9887 - val_loss: 2.8064 - val_accuracy: 0.5395\n",
      "Epoch 23/1000\n",
      "177/177 [==============================] - 0s 102us/step - loss: 0.0303 - accuracy: 0.9887 - val_loss: 2.8113 - val_accuracy: 0.5395\n",
      "Epoch 24/1000\n",
      "177/177 [==============================] - 0s 93us/step - loss: 0.0300 - accuracy: 0.9887 - val_loss: 2.8171 - val_accuracy: 0.5263\n",
      "Epoch 25/1000\n",
      "177/177 [==============================] - 0s 129us/step - loss: 0.0317 - accuracy: 0.9887 - val_loss: 2.8247 - val_accuracy: 0.5395\n",
      "Epoch 26/1000\n",
      "177/177 [==============================] - 0s 106us/step - loss: 0.0299 - accuracy: 0.9887 - val_loss: 2.8206 - val_accuracy: 0.5395\n",
      "Epoch 27/1000\n",
      "177/177 [==============================] - 0s 110us/step - loss: 0.0307 - accuracy: 0.9887 - val_loss: 2.8189 - val_accuracy: 0.5526\n",
      "Epoch 28/1000\n",
      "177/177 [==============================] - 0s 119us/step - loss: 0.0306 - accuracy: 0.9887 - val_loss: 2.8277 - val_accuracy: 0.5526\n",
      "Epoch 29/1000\n",
      "177/177 [==============================] - 0s 115us/step - loss: 0.0305 - accuracy: 0.9887 - val_loss: 2.8271 - val_accuracy: 0.5395\n",
      "Epoch 30/1000\n",
      "177/177 [==============================] - 0s 112us/step - loss: 0.0309 - accuracy: 0.9887 - val_loss: 2.8268 - val_accuracy: 0.5395\n",
      "Epoch 31/1000\n",
      "177/177 [==============================] - 0s 101us/step - loss: 0.0369 - accuracy: 0.9887 - val_loss: 2.8370 - val_accuracy: 0.5263\n",
      "Epoch 32/1000\n",
      "177/177 [==============================] - 0s 108us/step - loss: 0.0300 - accuracy: 0.9887 - val_loss: 2.8348 - val_accuracy: 0.5395\n",
      "Epoch 33/1000\n",
      "177/177 [==============================] - 0s 130us/step - loss: 0.0344 - accuracy: 0.9887 - val_loss: 2.8315 - val_accuracy: 0.5395\n",
      "Epoch 34/1000\n",
      "177/177 [==============================] - 0s 104us/step - loss: 0.0569 - accuracy: 0.9831 - val_loss: 2.8435 - val_accuracy: 0.5395\n",
      "Epoch 35/1000\n",
      "177/177 [==============================] - 0s 103us/step - loss: 0.1087 - accuracy: 0.9831 - val_loss: 2.8374 - val_accuracy: 0.5395\n",
      "Epoch 36/1000\n",
      "177/177 [==============================] - 0s 109us/step - loss: 0.0276 - accuracy: 0.9887 - val_loss: 2.8527 - val_accuracy: 0.5395\n",
      "Epoch 37/1000\n",
      "177/177 [==============================] - 0s 123us/step - loss: 0.0611 - accuracy: 0.9831 - val_loss: 2.8381 - val_accuracy: 0.5395\n",
      "Epoch 38/1000\n",
      "177/177 [==============================] - 0s 104us/step - loss: 0.0326 - accuracy: 0.9887 - val_loss: 2.8217 - val_accuracy: 0.5263\n",
      "Epoch 39/1000\n",
      "177/177 [==============================] - 0s 103us/step - loss: 0.1140 - accuracy: 0.9831 - val_loss: 2.8583 - val_accuracy: 0.5395\n",
      "Epoch 40/1000\n",
      "177/177 [==============================] - 0s 100us/step - loss: 0.0699 - accuracy: 0.9718 - val_loss: 2.8455 - val_accuracy: 0.5263\n",
      "Epoch 41/1000\n",
      "177/177 [==============================] - 0s 139us/step - loss: 0.1089 - accuracy: 0.9831 - val_loss: 2.8366 - val_accuracy: 0.5263\n",
      "Epoch 42/1000\n",
      "177/177 [==============================] - 0s 123us/step - loss: 0.0727 - accuracy: 0.9774 - val_loss: 2.8406 - val_accuracy: 0.5395\n",
      "Epoch 43/1000\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.0688 - accuracy: 0.9774 - val_loss: 2.8702 - val_accuracy: 0.5132\n",
      "Epoch 44/1000\n",
      "177/177 [==============================] - 0s 116us/step - loss: 0.3306 - accuracy: 0.9548 - val_loss: 2.8464 - val_accuracy: 0.5132\n",
      "Epoch 45/1000\n",
      "177/177 [==============================] - 0s 102us/step - loss: 0.2634 - accuracy: 0.9718 - val_loss: 2.8605 - val_accuracy: 0.5263\n",
      "Epoch 46/1000\n",
      "177/177 [==============================] - 0s 97us/step - loss: 0.1913 - accuracy: 0.9718 - val_loss: 3.1172 - val_accuracy: 0.4868\n",
      "Epoch 47/1000\n",
      "177/177 [==============================] - 0s 96us/step - loss: 0.2448 - accuracy: 0.9718 - val_loss: 2.8666 - val_accuracy: 0.5395\n",
      "Epoch 48/1000\n",
      "177/177 [==============================] - 0s 95us/step - loss: 0.0445 - accuracy: 0.9887 - val_loss: 2.7838 - val_accuracy: 0.5132\n",
      "Epoch 49/1000\n",
      "177/177 [==============================] - 0s 93us/step - loss: 0.0880 - accuracy: 0.9718 - val_loss: 2.8127 - val_accuracy: 0.5263\n",
      "Epoch 50/1000\n",
      "177/177 [==============================] - 0s 114us/step - loss: 0.3038 - accuracy: 0.9605 - val_loss: 3.0175 - val_accuracy: 0.4737\n",
      "Epoch 51/1000\n",
      "177/177 [==============================] - 0s 111us/step - loss: 0.1746 - accuracy: 0.9661 - val_loss: 2.8478 - val_accuracy: 0.5263\n",
      "Epoch 52/1000\n",
      "177/177 [==============================] - 0s 93us/step - loss: 0.5117 - accuracy: 0.9435 - val_loss: 2.8862 - val_accuracy: 0.5263\n",
      "Epoch 53/1000\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.1894 - accuracy: 0.9661 - val_loss: 3.0489 - val_accuracy: 0.5000\n",
      "Epoch 54/1000\n",
      "177/177 [==============================] - 0s 92us/step - loss: 0.2430 - accuracy: 0.9605 - val_loss: 2.8821 - val_accuracy: 0.5395\n",
      "Epoch 55/1000\n",
      "177/177 [==============================] - 0s 94us/step - loss: 0.1054 - accuracy: 0.9774 - val_loss: 2.8761 - val_accuracy: 0.5395\n",
      "Epoch 56/1000\n",
      "177/177 [==============================] - 0s 94us/step - loss: 0.1566 - accuracy: 0.9831 - val_loss: 2.9356 - val_accuracy: 0.5000\n",
      "Epoch 57/1000\n",
      "177/177 [==============================] - 0s 87us/step - loss: 0.0309 - accuracy: 0.9887 - val_loss: 2.8745 - val_accuracy: 0.5132\n",
      "Epoch 58/1000\n",
      "177/177 [==============================] - 0s 78us/step - loss: 0.0804 - accuracy: 0.9774 - val_loss: 2.8869 - val_accuracy: 0.5263\n",
      "Epoch 59/1000\n",
      "177/177 [==============================] - 0s 124us/step - loss: 0.0363 - accuracy: 0.9831 - val_loss: 2.8896 - val_accuracy: 0.5263\n",
      "Epoch 60/1000\n",
      "177/177 [==============================] - 0s 119us/step - loss: 0.0343 - accuracy: 0.9887 - val_loss: 2.8856 - val_accuracy: 0.5263\n",
      "Epoch 61/1000\n",
      "177/177 [==============================] - 0s 113us/step - loss: 0.0355 - accuracy: 0.9887 - val_loss: 2.8884 - val_accuracy: 0.5263\n",
      "Epoch 62/1000\n",
      "177/177 [==============================] - 0s 101us/step - loss: 0.0419 - accuracy: 0.9887 - val_loss: 2.8634 - val_accuracy: 0.5263\n",
      "Epoch 63/1000\n",
      "177/177 [==============================] - 0s 89us/step - loss: 0.0392 - accuracy: 0.9831 - val_loss: 2.8876 - val_accuracy: 0.5263\n",
      "Epoch 64/1000\n",
      "177/177 [==============================] - 0s 89us/step - loss: 0.0356 - accuracy: 0.9831 - val_loss: 2.8891 - val_accuracy: 0.5000\n",
      "Epoch 65/1000\n",
      "177/177 [==============================] - 0s 100us/step - loss: 0.1683 - accuracy: 0.9661 - val_loss: 2.9684 - val_accuracy: 0.5000\n",
      "Epoch 66/1000\n",
      "177/177 [==============================] - 0s 93us/step - loss: 0.0828 - accuracy: 0.9718 - val_loss: 2.8723 - val_accuracy: 0.5263\n",
      "Epoch 67/1000\n",
      "177/177 [==============================] - 0s 82us/step - loss: 0.0824 - accuracy: 0.9831 - val_loss: 2.8638 - val_accuracy: 0.5526\n",
      "Epoch 68/1000\n",
      "177/177 [==============================] - 0s 101us/step - loss: 0.0560 - accuracy: 0.9774 - val_loss: 2.8733 - val_accuracy: 0.5395\n",
      "Epoch 69/1000\n",
      "177/177 [==============================] - 0s 94us/step - loss: 0.0323 - accuracy: 0.9887 - val_loss: 2.8452 - val_accuracy: 0.5395\n",
      "Epoch 70/1000\n",
      "177/177 [==============================] - 0s 89us/step - loss: 0.0345 - accuracy: 0.9887 - val_loss: 2.8644 - val_accuracy: 0.5395\n",
      "Epoch 71/1000\n",
      "177/177 [==============================] - 0s 114us/step - loss: 0.0352 - accuracy: 0.9887 - val_loss: 2.8595 - val_accuracy: 0.5263\n",
      "Epoch 72/1000\n",
      "177/177 [==============================] - 0s 96us/step - loss: 0.0316 - accuracy: 0.9887 - val_loss: 2.8741 - val_accuracy: 0.5263\n",
      "Epoch 73/1000\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.0340 - accuracy: 0.9887 - val_loss: 2.8837 - val_accuracy: 0.5395\n",
      "Epoch 74/1000\n",
      "177/177 [==============================] - 0s 144us/step - loss: 0.0315 - accuracy: 0.9887 - val_loss: 2.8812 - val_accuracy: 0.5263\n",
      "Epoch 75/1000\n",
      "177/177 [==============================] - 0s 105us/step - loss: 0.0323 - accuracy: 0.9887 - val_loss: 2.8863 - val_accuracy: 0.5263\n",
      "Epoch 76/1000\n",
      "177/177 [==============================] - 0s 127us/step - loss: 0.0321 - accuracy: 0.9831 - val_loss: 2.8773 - val_accuracy: 0.5526\n",
      "Epoch 77/1000\n",
      "177/177 [==============================] - 0s 114us/step - loss: 0.0308 - accuracy: 0.9887 - val_loss: 2.8832 - val_accuracy: 0.5526\n",
      "Epoch 78/1000\n",
      "177/177 [==============================] - 0s 106us/step - loss: 0.0323 - accuracy: 0.9887 - val_loss: 2.8892 - val_accuracy: 0.5526\n",
      "Epoch 79/1000\n",
      "177/177 [==============================] - 0s 103us/step - loss: 0.0328 - accuracy: 0.9831 - val_loss: 2.8978 - val_accuracy: 0.5263\n",
      "Epoch 80/1000\n",
      "177/177 [==============================] - 0s 92us/step - loss: 0.0316 - accuracy: 0.9831 - val_loss: 2.8920 - val_accuracy: 0.5395\n",
      "Epoch 81/1000\n",
      "177/177 [==============================] - 0s 97us/step - loss: 0.0304 - accuracy: 0.9887 - val_loss: 2.9029 - val_accuracy: 0.5263\n",
      "Epoch 82/1000\n",
      "177/177 [==============================] - 0s 94us/step - loss: 0.0299 - accuracy: 0.9831 - val_loss: 2.8994 - val_accuracy: 0.5263\n",
      "Epoch 83/1000\n",
      "177/177 [==============================] - 0s 108us/step - loss: 0.0297 - accuracy: 0.9831 - val_loss: 2.8952 - val_accuracy: 0.5395\n",
      "Epoch 84/1000\n",
      "177/177 [==============================] - 0s 119us/step - loss: 0.0323 - accuracy: 0.9831 - val_loss: 2.9014 - val_accuracy: 0.5263\n",
      "Epoch 85/1000\n",
      "177/177 [==============================] - 0s 104us/step - loss: 0.0295 - accuracy: 0.9887 - val_loss: 2.9206 - val_accuracy: 0.5263\n",
      "Epoch 86/1000\n",
      "177/177 [==============================] - 0s 94us/step - loss: 0.0316 - accuracy: 0.9831 - val_loss: 2.9146 - val_accuracy: 0.5395\n",
      "Epoch 87/1000\n",
      "177/177 [==============================] - 0s 107us/step - loss: 0.0434 - accuracy: 0.9831 - val_loss: 2.8961 - val_accuracy: 0.5395\n",
      "Epoch 88/1000\n",
      "177/177 [==============================] - 0s 111us/step - loss: 0.0919 - accuracy: 0.9831 - val_loss: 2.9013 - val_accuracy: 0.5395\n",
      "Epoch 89/1000\n",
      "177/177 [==============================] - 0s 93us/step - loss: 0.0687 - accuracy: 0.9774 - val_loss: 2.9257 - val_accuracy: 0.5395\n",
      "Epoch 90/1000\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.0989 - accuracy: 0.9774 - val_loss: 2.8918 - val_accuracy: 0.5395\n",
      "Epoch 91/1000\n",
      "177/177 [==============================] - 0s 116us/step - loss: 0.0529 - accuracy: 0.9774 - val_loss: 2.9122 - val_accuracy: 0.5395\n",
      "Epoch 92/1000\n",
      "177/177 [==============================] - 0s 95us/step - loss: 0.0778 - accuracy: 0.9718 - val_loss: 2.9160 - val_accuracy: 0.5263\n",
      "Epoch 93/1000\n",
      "177/177 [==============================] - 0s 112us/step - loss: 0.1608 - accuracy: 0.9774 - val_loss: 2.9693 - val_accuracy: 0.5132\n",
      "Epoch 94/1000\n",
      "177/177 [==============================] - 0s 89us/step - loss: 0.0816 - accuracy: 0.9605 - val_loss: 2.9034 - val_accuracy: 0.5263\n",
      "Epoch 95/1000\n",
      "177/177 [==============================] - 0s 94us/step - loss: 0.0858 - accuracy: 0.9774 - val_loss: 2.8936 - val_accuracy: 0.5395\n",
      "Epoch 96/1000\n",
      "177/177 [==============================] - 0s 86us/step - loss: 0.1696 - accuracy: 0.9605 - val_loss: 2.9683 - val_accuracy: 0.5263\n",
      "Epoch 97/1000\n",
      "177/177 [==============================] - 0s 82us/step - loss: 0.3080 - accuracy: 0.9605 - val_loss: 2.8964 - val_accuracy: 0.5526\n",
      "Epoch 98/1000\n",
      "177/177 [==============================] - 0s 104us/step - loss: 0.1574 - accuracy: 0.9718 - val_loss: 3.2524 - val_accuracy: 0.4868\n",
      "Epoch 99/1000\n",
      "177/177 [==============================] - 0s 99us/step - loss: 0.3501 - accuracy: 0.9605 - val_loss: 3.0160 - val_accuracy: 0.4868\n",
      "Epoch 100/1000\n",
      "177/177 [==============================] - 0s 107us/step - loss: 0.1055 - accuracy: 0.9718 - val_loss: 2.9155 - val_accuracy: 0.5000\n",
      "Epoch 101/1000\n",
      "177/177 [==============================] - 0s 85us/step - loss: 0.0828 - accuracy: 0.9831 - val_loss: 2.9370 - val_accuracy: 0.5263\n",
      "Epoch 102/1000\n",
      "177/177 [==============================] - ETA: 0s - loss: 0.0326 - accuracy: 1.00 - 0s 128us/step - loss: 0.1490 - accuracy: 0.9718 - val_loss: 2.9600 - val_accuracy: 0.5000\n",
      "Epoch 103/1000\n",
      "177/177 [==============================] - 0s 106us/step - loss: 0.0691 - accuracy: 0.9831 - val_loss: 2.9150 - val_accuracy: 0.5000\n",
      "Epoch 104/1000\n",
      "177/177 [==============================] - 0s 116us/step - loss: 0.1090 - accuracy: 0.9831 - val_loss: 2.8932 - val_accuracy: 0.5132\n",
      "Epoch 105/1000\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.0349 - accuracy: 0.9944 - val_loss: 2.9497 - val_accuracy: 0.5000\n",
      "Epoch 106/1000\n",
      "177/177 [==============================] - 0s 95us/step - loss: 0.1598 - accuracy: 0.9774 - val_loss: 2.9529 - val_accuracy: 0.5132\n",
      "Epoch 107/1000\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.0570 - accuracy: 0.9831 - val_loss: 2.9614 - val_accuracy: 0.5000\n",
      "Epoch 108/1000\n",
      "177/177 [==============================] - 0s 120us/step - loss: 0.3364 - accuracy: 0.9718 - val_loss: 2.9623 - val_accuracy: 0.4868\n",
      "Epoch 109/1000\n",
      "177/177 [==============================] - 0s 108us/step - loss: 0.1726 - accuracy: 0.9605 - val_loss: 2.9103 - val_accuracy: 0.5395\n",
      "Epoch 110/1000\n",
      "177/177 [==============================] - 0s 87us/step - loss: 0.0700 - accuracy: 0.9718 - val_loss: 2.8791 - val_accuracy: 0.5395\n",
      "Epoch 111/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177/177 [==============================] - 0s 97us/step - loss: 0.0800 - accuracy: 0.9718 - val_loss: 3.0188 - val_accuracy: 0.5132\n",
      "Epoch 112/1000\n",
      "177/177 [==============================] - 0s 78us/step - loss: 0.1799 - accuracy: 0.9661 - val_loss: 3.0012 - val_accuracy: 0.5263\n",
      "Epoch 113/1000\n",
      "177/177 [==============================] - 0s 75us/step - loss: 0.1043 - accuracy: 0.9774 - val_loss: 2.8950 - val_accuracy: 0.5526\n",
      "Epoch 114/1000\n",
      "177/177 [==============================] - 0s 84us/step - loss: 0.2027 - accuracy: 0.9605 - val_loss: 2.9772 - val_accuracy: 0.5132\n",
      "Epoch 115/1000\n",
      "177/177 [==============================] - 0s 89us/step - loss: 0.1265 - accuracy: 0.9661 - val_loss: 2.9960 - val_accuracy: 0.5263\n",
      "Epoch 116/1000\n",
      "177/177 [==============================] - 0s 82us/step - loss: 0.0613 - accuracy: 0.9774 - val_loss: 2.9307 - val_accuracy: 0.5526\n",
      "Epoch 117/1000\n",
      "177/177 [==============================] - 0s 96us/step - loss: 0.0724 - accuracy: 0.9887 - val_loss: 2.9680 - val_accuracy: 0.5263\n",
      "Epoch 118/1000\n",
      "177/177 [==============================] - 0s 103us/step - loss: 0.0712 - accuracy: 0.9831 - val_loss: 2.9782 - val_accuracy: 0.5263\n",
      "Epoch 119/1000\n",
      "177/177 [==============================] - 0s 92us/step - loss: 0.0537 - accuracy: 0.9831 - val_loss: 2.9989 - val_accuracy: 0.5263\n",
      "Epoch 120/1000\n",
      "177/177 [==============================] - 0s 102us/step - loss: 0.1098 - accuracy: 0.9831 - val_loss: 2.9732 - val_accuracy: 0.5263\n",
      "Epoch 121/1000\n",
      "177/177 [==============================] - 0s 103us/step - loss: 0.1740 - accuracy: 0.9774 - val_loss: 2.9540 - val_accuracy: 0.5263\n",
      "Epoch 122/1000\n",
      "177/177 [==============================] - 0s 101us/step - loss: 0.1105 - accuracy: 0.9718 - val_loss: 3.0166 - val_accuracy: 0.5000\n",
      "Epoch 123/1000\n",
      "177/177 [==============================] - 0s 103us/step - loss: 0.1282 - accuracy: 0.9718 - val_loss: 2.9753 - val_accuracy: 0.5263\n",
      "Epoch 124/1000\n",
      "177/177 [==============================] - 0s 124us/step - loss: 0.0395 - accuracy: 0.9887 - val_loss: 2.9238 - val_accuracy: 0.5526\n",
      "Epoch 125/1000\n",
      "177/177 [==============================] - 0s 100us/step - loss: 0.0588 - accuracy: 0.9831 - val_loss: 2.9402 - val_accuracy: 0.5263\n",
      "Epoch 126/1000\n",
      "177/177 [==============================] - 0s 106us/step - loss: 0.0800 - accuracy: 0.9831 - val_loss: 2.9617 - val_accuracy: 0.5132\n",
      "Epoch 127/1000\n",
      "177/177 [==============================] - 0s 137us/step - loss: 0.0442 - accuracy: 0.9831 - val_loss: 2.9589 - val_accuracy: 0.5132\n",
      "Epoch 128/1000\n",
      "177/177 [==============================] - 0s 120us/step - loss: 0.0396 - accuracy: 0.9774 - val_loss: 3.0960 - val_accuracy: 0.5132\n",
      "Epoch 129/1000\n",
      "177/177 [==============================] - 0s 117us/step - loss: 0.1767 - accuracy: 0.9774 - val_loss: 2.9779 - val_accuracy: 0.5263\n",
      "Epoch 130/1000\n",
      "177/177 [==============================] - 0s 94us/step - loss: 0.0308 - accuracy: 0.9831 - val_loss: 2.9542 - val_accuracy: 0.5132\n",
      "Epoch 131/1000\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.0574 - accuracy: 0.9831 - val_loss: 2.9495 - val_accuracy: 0.5132\n",
      "Epoch 132/1000\n",
      "177/177 [==============================] - 0s 105us/step - loss: 0.0822 - accuracy: 0.9831 - val_loss: 2.9772 - val_accuracy: 0.5132\n",
      "Epoch 133/1000\n",
      "177/177 [==============================] - 0s 87us/step - loss: 0.0347 - accuracy: 0.9887 - val_loss: 2.9577 - val_accuracy: 0.5132\n",
      "Epoch 134/1000\n",
      "177/177 [==============================] - 0s 104us/step - loss: 0.0352 - accuracy: 0.9887 - val_loss: 2.9299 - val_accuracy: 0.5132\n",
      "Epoch 135/1000\n",
      "177/177 [==============================] - 0s 94us/step - loss: 0.2007 - accuracy: 0.9661 - val_loss: 3.0464 - val_accuracy: 0.5132\n",
      "Epoch 136/1000\n",
      "177/177 [==============================] - 0s 106us/step - loss: 0.0547 - accuracy: 0.9718 - val_loss: 2.9781 - val_accuracy: 0.5132\n",
      "Epoch 137/1000\n",
      "177/177 [==============================] - 0s 97us/step - loss: 0.2387 - accuracy: 0.9661 - val_loss: 3.0136 - val_accuracy: 0.5000\n",
      "Epoch 138/1000\n",
      "177/177 [==============================] - 0s 85us/step - loss: 0.0455 - accuracy: 0.9831 - val_loss: 3.2369 - val_accuracy: 0.5132\n",
      "Epoch 139/1000\n",
      "177/177 [==============================] - 0s 95us/step - loss: 0.3702 - accuracy: 0.9548 - val_loss: 3.1642 - val_accuracy: 0.5000\n",
      "Epoch 140/1000\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.1911 - accuracy: 0.9605 - val_loss: 3.0085 - val_accuracy: 0.5000\n",
      "Epoch 141/1000\n",
      "177/177 [==============================] - 0s 95us/step - loss: 0.1258 - accuracy: 0.9718 - val_loss: 2.9770 - val_accuracy: 0.5395\n",
      "Epoch 142/1000\n",
      "177/177 [==============================] - 0s 96us/step - loss: 0.3155 - accuracy: 0.9661 - val_loss: 3.0254 - val_accuracy: 0.5000\n",
      "Epoch 143/1000\n",
      "177/177 [==============================] - 0s 100us/step - loss: 0.2159 - accuracy: 0.9661 - val_loss: 3.1205 - val_accuracy: 0.4868\n",
      "Epoch 144/1000\n",
      "177/177 [==============================] - 0s 87us/step - loss: 0.0938 - accuracy: 0.9661 - val_loss: 2.9864 - val_accuracy: 0.5263\n",
      "Epoch 145/1000\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.0627 - accuracy: 0.9774 - val_loss: 2.9663 - val_accuracy: 0.5395\n",
      "Epoch 146/1000\n",
      "177/177 [==============================] - 0s 114us/step - loss: 0.0469 - accuracy: 0.9831 - val_loss: 2.9867 - val_accuracy: 0.5132\n",
      "Epoch 147/1000\n",
      "177/177 [==============================] - 0s 109us/step - loss: 0.0825 - accuracy: 0.9774 - val_loss: 3.0222 - val_accuracy: 0.5000\n",
      "Epoch 148/1000\n",
      "177/177 [==============================] - 0s 105us/step - loss: 0.0314 - accuracy: 0.9887 - val_loss: 3.0130 - val_accuracy: 0.4868\n",
      "Epoch 149/1000\n",
      "177/177 [==============================] - 0s 93us/step - loss: 0.0823 - accuracy: 0.9831 - val_loss: 3.0208 - val_accuracy: 0.5000\n",
      "Epoch 150/1000\n",
      "177/177 [==============================] - 0s 106us/step - loss: 0.0602 - accuracy: 0.9831 - val_loss: 3.0102 - val_accuracy: 0.5000\n",
      "Epoch 151/1000\n",
      "177/177 [==============================] - 0s 103us/step - loss: 0.1633 - accuracy: 0.9718 - val_loss: 3.0069 - val_accuracy: 0.5000\n",
      "Epoch 152/1000\n",
      "177/177 [==============================] - 0s 254us/step - loss: 0.0646 - accuracy: 0.9831 - val_loss: 3.0415 - val_accuracy: 0.5000\n",
      "Epoch 153/1000\n",
      "177/177 [==============================] - 0s 339us/step - loss: 0.0635 - accuracy: 0.9831 - val_loss: 3.0064 - val_accuracy: 0.5263\n",
      "Epoch 154/1000\n",
      "177/177 [==============================] - 0s 89us/step - loss: 0.0354 - accuracy: 0.9831 - val_loss: 2.9880 - val_accuracy: 0.5132\n",
      "Epoch 155/1000\n",
      "177/177 [==============================] - 0s 195us/step - loss: 0.0366 - accuracy: 0.9887 - val_loss: 2.9890 - val_accuracy: 0.5263\n",
      "Epoch 156/1000\n",
      "177/177 [==============================] - 0s 201us/step - loss: 0.0327 - accuracy: 0.9887 - val_loss: 3.0303 - val_accuracy: 0.5132\n",
      "Epoch 157/1000\n",
      "177/177 [==============================] - 0s 120us/step - loss: 0.0340 - accuracy: 0.9887 - val_loss: 3.0267 - val_accuracy: 0.5000\n",
      "Epoch 158/1000\n",
      "177/177 [==============================] - 0s 105us/step - loss: 0.0307 - accuracy: 0.9887 - val_loss: 3.0195 - val_accuracy: 0.5000\n",
      "Epoch 159/1000\n",
      "177/177 [==============================] - 0s 82us/step - loss: 0.0324 - accuracy: 0.9887 - val_loss: 3.0236 - val_accuracy: 0.5000\n",
      "Epoch 160/1000\n",
      "177/177 [==============================] - 0s 74us/step - loss: 0.0317 - accuracy: 0.9887 - val_loss: 3.0293 - val_accuracy: 0.5132\n",
      "Epoch 161/1000\n",
      "177/177 [==============================] - 0s 94us/step - loss: 0.0611 - accuracy: 0.9774 - val_loss: 3.0129 - val_accuracy: 0.5132\n",
      "Epoch 162/1000\n",
      "177/177 [==============================] - 0s 85us/step - loss: 0.1687 - accuracy: 0.9774 - val_loss: 2.9909 - val_accuracy: 0.5132\n",
      "Epoch 163/1000\n",
      "177/177 [==============================] - 0s 74us/step - loss: 0.1243 - accuracy: 0.9774 - val_loss: 3.0568 - val_accuracy: 0.5132\n",
      "Epoch 164/1000\n",
      "177/177 [==============================] - 0s 184us/step - loss: 0.1261 - accuracy: 0.9718 - val_loss: 3.0565 - val_accuracy: 0.5263\n",
      "Epoch 165/1000\n",
      "177/177 [==============================] - 0s 240us/step - loss: 0.1317 - accuracy: 0.9774 - val_loss: 3.0115 - val_accuracy: 0.5000\n",
      "Epoch 166/1000\n",
      "177/177 [==============================] - 0s 170us/step - loss: 0.0380 - accuracy: 0.9831 - val_loss: 3.0547 - val_accuracy: 0.5132\n",
      "Epoch 167/1000\n",
      "177/177 [==============================] - 0s 187us/step - loss: 0.0928 - accuracy: 0.9661 - val_loss: 3.0177 - val_accuracy: 0.5263\n",
      "Epoch 168/1000\n",
      "177/177 [==============================] - 0s 193us/step - loss: 0.0880 - accuracy: 0.9774 - val_loss: 2.9821 - val_accuracy: 0.5263\n",
      "Epoch 169/1000\n",
      "177/177 [==============================] - 0s 141us/step - loss: 0.0636 - accuracy: 0.9831 - val_loss: 3.0540 - val_accuracy: 0.5263\n",
      "Epoch 170/1000\n",
      "177/177 [==============================] - 0s 147us/step - loss: 0.0986 - accuracy: 0.9718 - val_loss: 3.0410 - val_accuracy: 0.5132\n",
      "Epoch 171/1000\n",
      "177/177 [==============================] - 0s 128us/step - loss: 0.0341 - accuracy: 0.9887 - val_loss: 3.0200 - val_accuracy: 0.5263\n",
      "Epoch 172/1000\n",
      "177/177 [==============================] - 0s 124us/step - loss: 0.0374 - accuracy: 0.9887 - val_loss: 3.0202 - val_accuracy: 0.5263\n",
      "Epoch 173/1000\n",
      "177/177 [==============================] - 0s 148us/step - loss: 0.0360 - accuracy: 0.9887 - val_loss: 3.0174 - val_accuracy: 0.5395\n",
      "Epoch 174/1000\n",
      "177/177 [==============================] - 0s 145us/step - loss: 0.0309 - accuracy: 0.9887 - val_loss: 3.0118 - val_accuracy: 0.5263\n",
      "Epoch 175/1000\n",
      "177/177 [==============================] - 0s 136us/step - loss: 0.0312 - accuracy: 0.9887 - val_loss: 3.0267 - val_accuracy: 0.5395\n",
      "Epoch 176/1000\n",
      "177/177 [==============================] - 0s 130us/step - loss: 0.0301 - accuracy: 0.9887 - val_loss: 3.0270 - val_accuracy: 0.5395\n",
      "Epoch 177/1000\n",
      "177/177 [==============================] - 0s 167us/step - loss: 0.0311 - accuracy: 0.9831 - val_loss: 3.0454 - val_accuracy: 0.5263\n",
      "Epoch 178/1000\n",
      "177/177 [==============================] - 0s 284us/step - loss: 0.0295 - accuracy: 0.9887 - val_loss: 3.0271 - val_accuracy: 0.5395\n",
      "Epoch 179/1000\n",
      "177/177 [==============================] - 0s 822us/step - loss: 0.0299 - accuracy: 0.9887 - val_loss: 3.0318 - val_accuracy: 0.5395\n",
      "Epoch 180/1000\n",
      "177/177 [==============================] - 0s 451us/step - loss: 0.0307 - accuracy: 0.9887 - val_loss: 3.0258 - val_accuracy: 0.5395\n",
      "Epoch 181/1000\n",
      "177/177 [==============================] - 0s 152us/step - loss: 0.0287 - accuracy: 0.9887 - val_loss: 3.0291 - val_accuracy: 0.5395\n",
      "Epoch 182/1000\n",
      "177/177 [==============================] - 0s 180us/step - loss: 0.0296 - accuracy: 0.9887 - val_loss: 3.0294 - val_accuracy: 0.5395\n",
      "Epoch 183/1000\n",
      "177/177 [==============================] - 0s 841us/step - loss: 0.0289 - accuracy: 0.9887 - val_loss: 3.0425 - val_accuracy: 0.5395\n",
      "Epoch 184/1000\n",
      "177/177 [==============================] - 0s 262us/step - loss: 0.0288 - accuracy: 0.9887 - val_loss: 3.0437 - val_accuracy: 0.5395\n",
      "Epoch 185/1000\n",
      "177/177 [==============================] - 0s 769us/step - loss: 0.0281 - accuracy: 0.9887 - val_loss: 3.0392 - val_accuracy: 0.5395\n",
      "Epoch 186/1000\n",
      "177/177 [==============================] - 0s 284us/step - loss: 0.0291 - accuracy: 0.9887 - val_loss: 3.0395 - val_accuracy: 0.5395\n",
      "Epoch 187/1000\n",
      "177/177 [==============================] - 0s 305us/step - loss: 0.0296 - accuracy: 0.9831 - val_loss: 3.0349 - val_accuracy: 0.5395\n",
      "Epoch 188/1000\n",
      "177/177 [==============================] - 0s 120us/step - loss: 0.0322 - accuracy: 0.9831 - val_loss: 3.0197 - val_accuracy: 0.5395\n",
      "Epoch 189/1000\n",
      "177/177 [==============================] - 0s 142us/step - loss: 0.0313 - accuracy: 0.9887 - val_loss: 3.0201 - val_accuracy: 0.5395\n",
      "Epoch 190/1000\n",
      "177/177 [==============================] - 0s 158us/step - loss: 0.0291 - accuracy: 0.9887 - val_loss: 3.0222 - val_accuracy: 0.5395\n",
      "Epoch 191/1000\n",
      "177/177 [==============================] - 0s 109us/step - loss: 0.0284 - accuracy: 0.9887 - val_loss: 3.0290 - val_accuracy: 0.5263\n",
      "Epoch 192/1000\n",
      "177/177 [==============================] - 0s 462us/step - loss: 0.0304 - accuracy: 0.9887 - val_loss: 3.0466 - val_accuracy: 0.5263\n",
      "Epoch 193/1000\n",
      "177/177 [==============================] - 0s 158us/step - loss: 0.0280 - accuracy: 0.9887 - val_loss: 3.0402 - val_accuracy: 0.5395\n",
      "Epoch 194/1000\n",
      "177/177 [==============================] - ETA: 0s - loss: 0.0862 - accuracy: 0.93 - 0s 121us/step - loss: 0.0274 - accuracy: 0.9887 - val_loss: 3.0363 - val_accuracy: 0.5395\n",
      "Epoch 195/1000\n",
      "177/177 [==============================] - 0s 136us/step - loss: 0.0291 - accuracy: 0.9887 - val_loss: 3.0353 - val_accuracy: 0.5395\n",
      "Epoch 196/1000\n",
      "177/177 [==============================] - 0s 110us/step - loss: 0.0302 - accuracy: 0.9887 - val_loss: 3.0497 - val_accuracy: 0.5395\n",
      "Epoch 197/1000\n",
      "177/177 [==============================] - 0s 141us/step - loss: 0.0283 - accuracy: 0.9831 - val_loss: 3.0592 - val_accuracy: 0.5395\n",
      "Epoch 198/1000\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.0278 - accuracy: 0.9887 - val_loss: 3.0620 - val_accuracy: 0.5395\n",
      "Epoch 199/1000\n",
      "177/177 [==============================] - 0s 97us/step - loss: 0.0280 - accuracy: 0.9887 - val_loss: 3.0618 - val_accuracy: 0.5395\n",
      "Epoch 200/1000\n",
      "177/177 [==============================] - 0s 144us/step - loss: 0.0286 - accuracy: 0.9887 - val_loss: 3.0531 - val_accuracy: 0.5395\n",
      "Epoch 201/1000\n",
      "177/177 [==============================] - 0s 133us/step - loss: 0.0291 - accuracy: 0.9887 - val_loss: 3.0592 - val_accuracy: 0.5395\n",
      "Epoch 202/1000\n",
      "177/177 [==============================] - 0s 155us/step - loss: 0.0305 - accuracy: 0.9831 - val_loss: 3.0681 - val_accuracy: 0.5395\n",
      "Epoch 203/1000\n",
      "177/177 [==============================] - 0s 124us/step - loss: 0.0285 - accuracy: 0.9887 - val_loss: 3.0471 - val_accuracy: 0.5395\n",
      "Epoch 204/1000\n",
      "177/177 [==============================] - 0s 138us/step - loss: 0.0310 - accuracy: 0.9887 - val_loss: 3.0453 - val_accuracy: 0.5526\n",
      "Epoch 205/1000\n",
      "177/177 [==============================] - 0s 131us/step - loss: 0.0291 - accuracy: 0.9887 - val_loss: 3.0448 - val_accuracy: 0.5395\n",
      "Epoch 206/1000\n",
      "177/177 [==============================] - 0s 141us/step - loss: 0.0290 - accuracy: 0.9831 - val_loss: 3.0489 - val_accuracy: 0.5263\n",
      "Epoch 207/1000\n",
      "177/177 [==============================] - 0s 119us/step - loss: 0.0292 - accuracy: 0.9887 - val_loss: 3.0470 - val_accuracy: 0.5263\n",
      "Epoch 208/1000\n",
      "177/177 [==============================] - 0s 132us/step - loss: 0.0289 - accuracy: 0.9887 - val_loss: 3.0668 - val_accuracy: 0.5395\n",
      "Epoch 209/1000\n",
      "177/177 [==============================] - 0s 124us/step - loss: 0.0297 - accuracy: 0.9887 - val_loss: 3.0585 - val_accuracy: 0.5395\n",
      "Epoch 210/1000\n",
      "177/177 [==============================] - 0s 132us/step - loss: 0.0291 - accuracy: 0.9887 - val_loss: 3.0617 - val_accuracy: 0.5395\n",
      "Epoch 211/1000\n",
      "177/177 [==============================] - 0s 127us/step - loss: 0.0291 - accuracy: 0.9887 - val_loss: 3.0527 - val_accuracy: 0.5395\n",
      "Epoch 212/1000\n",
      "177/177 [==============================] - 0s 143us/step - loss: 0.0297 - accuracy: 0.9887 - val_loss: 3.0578 - val_accuracy: 0.5395\n",
      "Epoch 213/1000\n",
      "177/177 [==============================] - 0s 317us/step - loss: 0.0277 - accuracy: 0.9887 - val_loss: 3.0715 - val_accuracy: 0.5395\n",
      "Epoch 214/1000\n",
      "177/177 [==============================] - 0s 388us/step - loss: 0.0284 - accuracy: 0.9887 - val_loss: 3.0828 - val_accuracy: 0.5395\n",
      "Epoch 215/1000\n",
      "177/177 [==============================] - 0s 101us/step - loss: 0.0288 - accuracy: 0.9887 - val_loss: 3.0846 - val_accuracy: 0.5395\n",
      "Epoch 216/1000\n",
      "177/177 [==============================] - 0s 123us/step - loss: 0.0271 - accuracy: 0.9887 - val_loss: 3.0917 - val_accuracy: 0.5395\n",
      "Epoch 217/1000\n",
      "177/177 [==============================] - 0s 122us/step - loss: 0.0337 - accuracy: 0.9887 - val_loss: 3.0912 - val_accuracy: 0.5395\n",
      "Epoch 218/1000\n",
      "177/177 [==============================] - 0s 129us/step - loss: 0.0311 - accuracy: 0.9887 - val_loss: 3.0735 - val_accuracy: 0.5395\n",
      "Epoch 219/1000\n",
      "177/177 [==============================] - 0s 109us/step - loss: 0.0311 - accuracy: 0.9887 - val_loss: 3.0823 - val_accuracy: 0.5395\n",
      "Epoch 220/1000\n",
      "177/177 [==============================] - 0s 284us/step - loss: 0.0305 - accuracy: 0.9887 - val_loss: 3.0844 - val_accuracy: 0.5395\n",
      "Epoch 221/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177/177 [==============================] - 0s 108us/step - loss: 0.0295 - accuracy: 0.9887 - val_loss: 3.0927 - val_accuracy: 0.5395\n",
      "Epoch 222/1000\n",
      "177/177 [==============================] - 0s 136us/step - loss: 0.0293 - accuracy: 0.9887 - val_loss: 3.1107 - val_accuracy: 0.5395\n",
      "Epoch 223/1000\n",
      "177/177 [==============================] - 0s 179us/step - loss: 0.0304 - accuracy: 0.9887 - val_loss: 3.0911 - val_accuracy: 0.5395\n",
      "Epoch 224/1000\n",
      "177/177 [==============================] - 0s 280us/step - loss: 0.0282 - accuracy: 0.9831 - val_loss: 3.0850 - val_accuracy: 0.5395\n",
      "Epoch 225/1000\n",
      "177/177 [==============================] - 0s 168us/step - loss: 0.0294 - accuracy: 0.9831 - val_loss: 3.0860 - val_accuracy: 0.5395\n",
      "Epoch 226/1000\n",
      "177/177 [==============================] - 0s 134us/step - loss: 0.0274 - accuracy: 0.9944 - val_loss: 3.0941 - val_accuracy: 0.5395\n",
      "Epoch 227/1000\n",
      "177/177 [==============================] - 0s 126us/step - loss: 0.0317 - accuracy: 0.9887 - val_loss: 3.0945 - val_accuracy: 0.5395\n",
      "Epoch 228/1000\n",
      "177/177 [==============================] - 0s 128us/step - loss: 0.0308 - accuracy: 0.9887 - val_loss: 3.0925 - val_accuracy: 0.5395\n",
      "Epoch 229/1000\n",
      "177/177 [==============================] - 0s 128us/step - loss: 0.0385 - accuracy: 0.9831 - val_loss: 3.1199 - val_accuracy: 0.5395\n",
      "Epoch 230/1000\n",
      "177/177 [==============================] - 0s 110us/step - loss: 0.0445 - accuracy: 0.9774 - val_loss: 3.1048 - val_accuracy: 0.5395\n",
      "Epoch 231/1000\n",
      "177/177 [==============================] - 0s 105us/step - loss: 0.0355 - accuracy: 0.9831 - val_loss: 3.1019 - val_accuracy: 0.5395\n",
      "Epoch 232/1000\n",
      "177/177 [==============================] - 0s 101us/step - loss: 0.0511 - accuracy: 0.9831 - val_loss: 3.0956 - val_accuracy: 0.5395\n",
      "Epoch 233/1000\n",
      "177/177 [==============================] - 0s 94us/step - loss: 0.0727 - accuracy: 0.9831 - val_loss: 3.1103 - val_accuracy: 0.5395\n",
      "Epoch 234/1000\n",
      "177/177 [==============================] - 0s 372us/step - loss: 0.0404 - accuracy: 0.9831 - val_loss: 3.1212 - val_accuracy: 0.5395\n",
      "Epoch 235/1000\n",
      "177/177 [==============================] - 0s 241us/step - loss: 0.0344 - accuracy: 0.9831 - val_loss: 3.1241 - val_accuracy: 0.5395\n",
      "Epoch 236/1000\n",
      "177/177 [==============================] - 0s 150us/step - loss: 0.0392 - accuracy: 0.9831 - val_loss: 3.1099 - val_accuracy: 0.5395\n",
      "Epoch 237/1000\n",
      "177/177 [==============================] - 0s 119us/step - loss: 0.0387 - accuracy: 0.9831 - val_loss: 3.1074 - val_accuracy: 0.5395\n",
      "Epoch 238/1000\n",
      "177/177 [==============================] - 0s 107us/step - loss: 0.0318 - accuracy: 0.9831 - val_loss: 3.1012 - val_accuracy: 0.5395\n",
      "Epoch 239/1000\n",
      "177/177 [==============================] - 0s 120us/step - loss: 0.0455 - accuracy: 0.9831 - val_loss: 3.1231 - val_accuracy: 0.5395\n",
      "Epoch 240/1000\n",
      "177/177 [==============================] - 0s 117us/step - loss: 0.0789 - accuracy: 0.9831 - val_loss: 3.1190 - val_accuracy: 0.5395\n",
      "Epoch 241/1000\n",
      "177/177 [==============================] - 0s 127us/step - loss: 0.0513 - accuracy: 0.9774 - val_loss: 3.1201 - val_accuracy: 0.5395\n",
      "Epoch 242/1000\n",
      "177/177 [==============================] - 0s 266us/step - loss: 0.0317 - accuracy: 0.9831 - val_loss: 3.1600 - val_accuracy: 0.5395\n",
      "Epoch 243/1000\n",
      "177/177 [==============================] - 0s 205us/step - loss: 0.0859 - accuracy: 0.9831 - val_loss: 3.1120 - val_accuracy: 0.5263\n",
      "Epoch 244/1000\n",
      "177/177 [==============================] - 0s 185us/step - loss: 0.0804 - accuracy: 0.9718 - val_loss: 3.1666 - val_accuracy: 0.5395\n",
      "Epoch 245/1000\n",
      "177/177 [==============================] - 0s 167us/step - loss: 0.0800 - accuracy: 0.9831 - val_loss: 3.1742 - val_accuracy: 0.5395\n",
      "Epoch 246/1000\n",
      "177/177 [==============================] - 0s 150us/step - loss: 0.0245 - accuracy: 0.9887 - val_loss: 3.1261 - val_accuracy: 0.5263\n",
      "Epoch 247/1000\n",
      "177/177 [==============================] - 0s 110us/step - loss: 0.0394 - accuracy: 0.9831 - val_loss: 3.1433 - val_accuracy: 0.5395\n",
      "Epoch 248/1000\n",
      "177/177 [==============================] - 0s 236us/step - loss: 0.0334 - accuracy: 0.9887 - val_loss: 3.1415 - val_accuracy: 0.5395\n",
      "Epoch 249/1000\n",
      "177/177 [==============================] - 0s 230us/step - loss: 0.0295 - accuracy: 0.9887 - val_loss: 3.1431 - val_accuracy: 0.5395\n",
      "Epoch 250/1000\n",
      "177/177 [==============================] - 0s 107us/step - loss: 0.0347 - accuracy: 0.9887 - val_loss: 3.1362 - val_accuracy: 0.5263\n",
      "Epoch 251/1000\n",
      "177/177 [==============================] - 0s 123us/step - loss: 0.0285 - accuracy: 0.9887 - val_loss: 3.1175 - val_accuracy: 0.5395\n",
      "Epoch 252/1000\n",
      "177/177 [==============================] - 0s 145us/step - loss: 0.0329 - accuracy: 0.9887 - val_loss: 3.1184 - val_accuracy: 0.5395\n",
      "Epoch 253/1000\n",
      "177/177 [==============================] - 0s 133us/step - loss: 0.0270 - accuracy: 0.9887 - val_loss: 3.1321 - val_accuracy: 0.5395\n",
      "Epoch 254/1000\n",
      "177/177 [==============================] - 0s 113us/step - loss: 0.0294 - accuracy: 0.9887 - val_loss: 3.1428 - val_accuracy: 0.5395\n",
      "Epoch 255/1000\n",
      "177/177 [==============================] - 0s 97us/step - loss: 0.0292 - accuracy: 0.9831 - val_loss: 3.1407 - val_accuracy: 0.5395\n",
      "Epoch 256/1000\n",
      "177/177 [==============================] - 0s 92us/step - loss: 0.0291 - accuracy: 0.9887 - val_loss: 3.1446 - val_accuracy: 0.5395\n",
      "Epoch 257/1000\n",
      "177/177 [==============================] - 0s 106us/step - loss: 0.0295 - accuracy: 0.9831 - val_loss: 3.1329 - val_accuracy: 0.5395\n",
      "Epoch 258/1000\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.0294 - accuracy: 0.9887 - val_loss: 3.1297 - val_accuracy: 0.5395\n",
      "Epoch 259/1000\n",
      "177/177 [==============================] - 0s 99us/step - loss: 0.0305 - accuracy: 0.9887 - val_loss: 3.1510 - val_accuracy: 0.5395\n",
      "Epoch 260/1000\n",
      "177/177 [==============================] - 0s 95us/step - loss: 0.0275 - accuracy: 0.9887 - val_loss: 3.1418 - val_accuracy: 0.5395\n",
      "Epoch 261/1000\n",
      "177/177 [==============================] - 0s 97us/step - loss: 0.0279 - accuracy: 0.9887 - val_loss: 3.1420 - val_accuracy: 0.5395\n",
      "Epoch 262/1000\n",
      "177/177 [==============================] - 0s 321us/step - loss: 0.0286 - accuracy: 0.9887 - val_loss: 3.1421 - val_accuracy: 0.5395\n",
      "Epoch 263/1000\n",
      "177/177 [==============================] - 0s 201us/step - loss: 0.0290 - accuracy: 0.9887 - val_loss: 3.1529 - val_accuracy: 0.5395\n",
      "Epoch 264/1000\n",
      "177/177 [==============================] - 0s 139us/step - loss: 0.0287 - accuracy: 0.9887 - val_loss: 3.1588 - val_accuracy: 0.5395\n",
      "Epoch 265/1000\n",
      "177/177 [==============================] - 0s 94us/step - loss: 0.0285 - accuracy: 0.9887 - val_loss: 3.1530 - val_accuracy: 0.5263\n",
      "Epoch 266/1000\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.0284 - accuracy: 0.9887 - val_loss: 3.1525 - val_accuracy: 0.5395\n",
      "Epoch 267/1000\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.0290 - accuracy: 0.9831 - val_loss: 3.1526 - val_accuracy: 0.5395\n",
      "Epoch 268/1000\n",
      "177/177 [==============================] - 0s 109us/step - loss: 0.0283 - accuracy: 0.9831 - val_loss: 3.1552 - val_accuracy: 0.5263\n",
      "Epoch 269/1000\n",
      "177/177 [==============================] - 0s 116us/step - loss: 0.0281 - accuracy: 0.9831 - val_loss: 3.1529 - val_accuracy: 0.5395\n",
      "Epoch 270/1000\n",
      "177/177 [==============================] - 0s 180us/step - loss: 0.0285 - accuracy: 0.9887 - val_loss: 3.1582 - val_accuracy: 0.5395\n",
      "Epoch 271/1000\n",
      "177/177 [==============================] - 0s 116us/step - loss: 0.0279 - accuracy: 0.9887 - val_loss: 3.1544 - val_accuracy: 0.5395\n",
      "Epoch 272/1000\n",
      "177/177 [==============================] - 0s 104us/step - loss: 0.0276 - accuracy: 0.9887 - val_loss: 3.1578 - val_accuracy: 0.5395\n",
      "Epoch 273/1000\n",
      "177/177 [==============================] - 0s 104us/step - loss: 0.0311 - accuracy: 0.9887 - val_loss: 3.1594 - val_accuracy: 0.5395\n",
      "Epoch 274/1000\n",
      "177/177 [==============================] - 0s 106us/step - loss: 0.0304 - accuracy: 0.9887 - val_loss: 3.1538 - val_accuracy: 0.5395\n",
      "Epoch 275/1000\n",
      "177/177 [==============================] - 0s 131us/step - loss: 0.0288 - accuracy: 0.9887 - val_loss: 3.1572 - val_accuracy: 0.5395\n",
      "Epoch 276/1000\n",
      "177/177 [==============================] - 0s 115us/step - loss: 0.0280 - accuracy: 0.9831 - val_loss: 3.1587 - val_accuracy: 0.5395\n",
      "Epoch 277/1000\n",
      "177/177 [==============================] - 0s 121us/step - loss: 0.0288 - accuracy: 0.9887 - val_loss: 3.1774 - val_accuracy: 0.5395\n",
      "Epoch 278/1000\n",
      "177/177 [==============================] - 0s 99us/step - loss: 0.0297 - accuracy: 0.9887 - val_loss: 3.1707 - val_accuracy: 0.5395\n",
      "Epoch 279/1000\n",
      "177/177 [==============================] - 0s 119us/step - loss: 0.0285 - accuracy: 0.9887 - val_loss: 3.1636 - val_accuracy: 0.5395\n",
      "Epoch 280/1000\n",
      "177/177 [==============================] - 0s 108us/step - loss: 0.0283 - accuracy: 0.9831 - val_loss: 3.1656 - val_accuracy: 0.5395\n",
      "Epoch 281/1000\n",
      "177/177 [==============================] - 0s 377us/step - loss: 0.0290 - accuracy: 0.9887 - val_loss: 3.1801 - val_accuracy: 0.5263\n",
      "Epoch 282/1000\n",
      "177/177 [==============================] - 0s 169us/step - loss: 0.0289 - accuracy: 0.9831 - val_loss: 3.1732 - val_accuracy: 0.5395\n",
      "Epoch 283/1000\n",
      "177/177 [==============================] - 0s 214us/step - loss: 0.0281 - accuracy: 0.9887 - val_loss: 3.1723 - val_accuracy: 0.5395\n",
      "Epoch 284/1000\n",
      "177/177 [==============================] - 0s 196us/step - loss: 0.0289 - accuracy: 0.9887 - val_loss: 3.1722 - val_accuracy: 0.5395\n",
      "Epoch 285/1000\n",
      "177/177 [==============================] - 0s 106us/step - loss: 0.0277 - accuracy: 0.9887 - val_loss: 3.1855 - val_accuracy: 0.5263\n",
      "Epoch 286/1000\n",
      "177/177 [==============================] - 0s 102us/step - loss: 0.0269 - accuracy: 0.9887 - val_loss: 3.1920 - val_accuracy: 0.5395\n",
      "Epoch 287/1000\n",
      "177/177 [==============================] - 0s 231us/step - loss: 0.0283 - accuracy: 0.9887 - val_loss: 3.1911 - val_accuracy: 0.5395\n",
      "Epoch 288/1000\n",
      "177/177 [==============================] - 0s 113us/step - loss: 0.0287 - accuracy: 0.9887 - val_loss: 3.1768 - val_accuracy: 0.5395\n",
      "Epoch 289/1000\n",
      "177/177 [==============================] - 0s 95us/step - loss: 0.0318 - accuracy: 0.9831 - val_loss: 3.1869 - val_accuracy: 0.5395\n",
      "Epoch 290/1000\n",
      "177/177 [==============================] - 0s 101us/step - loss: 0.0314 - accuracy: 0.9887 - val_loss: 3.2098 - val_accuracy: 0.5395\n",
      "Epoch 291/1000\n",
      "177/177 [==============================] - 0s 121us/step - loss: 0.0294 - accuracy: 0.9887 - val_loss: 3.1928 - val_accuracy: 0.5395\n",
      "Epoch 292/1000\n",
      "177/177 [==============================] - 0s 260us/step - loss: 0.0295 - accuracy: 0.9887 - val_loss: 3.1970 - val_accuracy: 0.5395\n",
      "Epoch 293/1000\n",
      "177/177 [==============================] - 0s 159us/step - loss: 0.0290 - accuracy: 0.9887 - val_loss: 3.2017 - val_accuracy: 0.5395\n",
      "Epoch 294/1000\n",
      "177/177 [==============================] - 0s 107us/step - loss: 0.0269 - accuracy: 0.9887 - val_loss: 3.1926 - val_accuracy: 0.5395\n",
      "Epoch 295/1000\n",
      "177/177 [==============================] - 0s 142us/step - loss: 0.0285 - accuracy: 0.9887 - val_loss: 3.1857 - val_accuracy: 0.5263\n",
      "Epoch 296/1000\n",
      "177/177 [==============================] - 0s 146us/step - loss: 0.0320 - accuracy: 0.9887 - val_loss: 3.2033 - val_accuracy: 0.5263\n",
      "Epoch 297/1000\n",
      "177/177 [==============================] - 0s 97us/step - loss: 0.0347 - accuracy: 0.9887 - val_loss: 3.1814 - val_accuracy: 0.5395\n",
      "Epoch 298/1000\n",
      "177/177 [==============================] - 0s 103us/step - loss: 0.0295 - accuracy: 0.9887 - val_loss: 3.1833 - val_accuracy: 0.5395\n",
      "Epoch 299/1000\n",
      "177/177 [==============================] - 0s 92us/step - loss: 0.0275 - accuracy: 0.9887 - val_loss: 3.1895 - val_accuracy: 0.5395\n",
      "Epoch 300/1000\n",
      "177/177 [==============================] - 0s 240us/step - loss: 0.0328 - accuracy: 0.9887 - val_loss: 3.2037 - val_accuracy: 0.5395\n",
      "Epoch 301/1000\n",
      "177/177 [==============================] - 0s 188us/step - loss: 0.0320 - accuracy: 0.9831 - val_loss: 3.2181 - val_accuracy: 0.5263\n",
      "Epoch 302/1000\n",
      "177/177 [==============================] - 0s 175us/step - loss: 0.0346 - accuracy: 0.9831 - val_loss: 3.1973 - val_accuracy: 0.5395\n",
      "Epoch 303/1000\n",
      "177/177 [==============================] - 0s 253us/step - loss: 0.0304 - accuracy: 0.9887 - val_loss: 3.2024 - val_accuracy: 0.5395\n",
      "Epoch 304/1000\n",
      "177/177 [==============================] - 0s 124us/step - loss: 0.0300 - accuracy: 0.9887 - val_loss: 3.2188 - val_accuracy: 0.5395\n",
      "Epoch 305/1000\n",
      "177/177 [==============================] - 0s 204us/step - loss: 0.0278 - accuracy: 0.9887 - val_loss: 3.2377 - val_accuracy: 0.5395\n",
      "Epoch 306/1000\n",
      "177/177 [==============================] - 0s 135us/step - loss: 0.0310 - accuracy: 0.9887 - val_loss: 3.2360 - val_accuracy: 0.5263\n",
      "Epoch 307/1000\n",
      "177/177 [==============================] - 0s 185us/step - loss: 0.0265 - accuracy: 0.9887 - val_loss: 3.2188 - val_accuracy: 0.5395\n",
      "Epoch 308/1000\n",
      "177/177 [==============================] - 0s 393us/step - loss: 0.0289 - accuracy: 0.9887 - val_loss: 3.2225 - val_accuracy: 0.5263\n",
      "Epoch 309/1000\n",
      "177/177 [==============================] - 0s 160us/step - loss: 0.0271 - accuracy: 0.9887 - val_loss: 3.2275 - val_accuracy: 0.5263\n",
      "Epoch 310/1000\n",
      "177/177 [==============================] - 0s 200us/step - loss: 0.0321 - accuracy: 0.9887 - val_loss: 3.2201 - val_accuracy: 0.5395\n",
      "Epoch 311/1000\n",
      "177/177 [==============================] - 0s 153us/step - loss: 0.0297 - accuracy: 0.9887 - val_loss: 3.2354 - val_accuracy: 0.5395\n",
      "Epoch 312/1000\n",
      "177/177 [==============================] - 0s 131us/step - loss: 0.0430 - accuracy: 0.9774 - val_loss: 3.2613 - val_accuracy: 0.5263\n",
      "Epoch 313/1000\n",
      "177/177 [==============================] - 0s 114us/step - loss: 0.0638 - accuracy: 0.9831 - val_loss: 3.2261 - val_accuracy: 0.5395\n",
      "Epoch 314/1000\n",
      "177/177 [==============================] - 0s 120us/step - loss: 0.0900 - accuracy: 0.9774 - val_loss: 3.2540 - val_accuracy: 0.5395\n",
      "Epoch 315/1000\n",
      "177/177 [==============================] - 0s 161us/step - loss: 0.0367 - accuracy: 0.9831 - val_loss: 3.2378 - val_accuracy: 0.5395\n",
      "Epoch 316/1000\n",
      "177/177 [==============================] - 0s 118us/step - loss: 0.0602 - accuracy: 0.9774 - val_loss: 3.2620 - val_accuracy: 0.5395\n",
      "Epoch 317/1000\n",
      "177/177 [==============================] - 0s 96us/step - loss: 0.0825 - accuracy: 0.9774 - val_loss: 3.2272 - val_accuracy: 0.5395\n",
      "Epoch 318/1000\n",
      "177/177 [==============================] - 0s 92us/step - loss: 0.0309 - accuracy: 0.9887 - val_loss: 3.2364 - val_accuracy: 0.5263\n",
      "Epoch 319/1000\n",
      "177/177 [==============================] - 0s 131us/step - loss: 0.0321 - accuracy: 0.9831 - val_loss: 3.2496 - val_accuracy: 0.5395\n",
      "Epoch 320/1000\n",
      "177/177 [==============================] - 0s 132us/step - loss: 0.0270 - accuracy: 0.9831 - val_loss: 3.2439 - val_accuracy: 0.5395\n",
      "Epoch 321/1000\n",
      "177/177 [==============================] - 0s 144us/step - loss: 0.0276 - accuracy: 0.9831 - val_loss: 3.2468 - val_accuracy: 0.5395\n",
      "Epoch 322/1000\n",
      "177/177 [==============================] - 0s 95us/step - loss: 0.0279 - accuracy: 0.9831 - val_loss: 3.2503 - val_accuracy: 0.5395\n",
      "Epoch 323/1000\n",
      "177/177 [==============================] - 0s 104us/step - loss: 0.0275 - accuracy: 0.9831 - val_loss: 3.2744 - val_accuracy: 0.5395\n",
      "Epoch 324/1000\n",
      "177/177 [==============================] - 0s 112us/step - loss: 0.0295 - accuracy: 0.9887 - val_loss: 3.2689 - val_accuracy: 0.5263\n",
      "Epoch 325/1000\n",
      "177/177 [==============================] - 0s 94us/step - loss: 0.0283 - accuracy: 0.9887 - val_loss: 3.2668 - val_accuracy: 0.5395\n",
      "Epoch 326/1000\n",
      "177/177 [==============================] - 0s 141us/step - loss: 0.0308 - accuracy: 0.9831 - val_loss: 3.2468 - val_accuracy: 0.5395\n",
      "Epoch 327/1000\n",
      "177/177 [==============================] - 0s 106us/step - loss: 0.0296 - accuracy: 0.9831 - val_loss: 3.2525 - val_accuracy: 0.5263\n",
      "Epoch 328/1000\n",
      "177/177 [==============================] - 0s 121us/step - loss: 0.0274 - accuracy: 0.9831 - val_loss: 3.2541 - val_accuracy: 0.5263\n",
      "Epoch 329/1000\n",
      "177/177 [==============================] - 0s 122us/step - loss: 0.0300 - accuracy: 0.9887 - val_loss: 3.2595 - val_accuracy: 0.5395\n",
      "Epoch 330/1000\n",
      "177/177 [==============================] - 0s 96us/step - loss: 0.0296 - accuracy: 0.9831 - val_loss: 3.2467 - val_accuracy: 0.5395\n",
      "Epoch 331/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177/177 [==============================] - 0s 244us/step - loss: 0.0291 - accuracy: 0.9831 - val_loss: 3.2546 - val_accuracy: 0.5263\n",
      "Epoch 332/1000\n",
      "177/177 [==============================] - 0s 250us/step - loss: 0.0263 - accuracy: 0.9887 - val_loss: 3.2676 - val_accuracy: 0.5263\n",
      "Epoch 333/1000\n",
      "177/177 [==============================] - 0s 115us/step - loss: 0.0279 - accuracy: 0.9831 - val_loss: 3.2630 - val_accuracy: 0.5395\n",
      "Epoch 334/1000\n",
      "177/177 [==============================] - 0s 117us/step - loss: 0.0269 - accuracy: 0.9887 - val_loss: 3.2602 - val_accuracy: 0.5263\n",
      "Epoch 335/1000\n",
      "177/177 [==============================] - 0s 109us/step - loss: 0.0270 - accuracy: 0.9887 - val_loss: 3.2577 - val_accuracy: 0.5263\n",
      "Epoch 336/1000\n",
      "177/177 [==============================] - 0s 119us/step - loss: 0.0280 - accuracy: 0.9887 - val_loss: 3.2625 - val_accuracy: 0.5263\n",
      "Epoch 337/1000\n",
      "177/177 [==============================] - 0s 118us/step - loss: 0.0269 - accuracy: 0.9887 - val_loss: 3.2606 - val_accuracy: 0.5263\n",
      "Epoch 338/1000\n",
      "177/177 [==============================] - 0s 91us/step - loss: 0.0288 - accuracy: 0.9831 - val_loss: 3.2584 - val_accuracy: 0.5395\n",
      "Epoch 339/1000\n",
      "177/177 [==============================] - 0s 94us/step - loss: 0.0287 - accuracy: 0.9831 - val_loss: 3.2623 - val_accuracy: 0.5263\n",
      "Epoch 340/1000\n",
      "177/177 [==============================] - 0s 201us/step - loss: 0.0284 - accuracy: 0.9887 - val_loss: 3.2583 - val_accuracy: 0.5395\n",
      "Epoch 341/1000\n",
      "177/177 [==============================] - 0s 204us/step - loss: 0.0280 - accuracy: 0.9887 - val_loss: 3.2564 - val_accuracy: 0.5263\n",
      "Epoch 342/1000\n",
      "177/177 [==============================] - 0s 244us/step - loss: 0.0269 - accuracy: 0.9887 - val_loss: 3.2575 - val_accuracy: 0.5263\n",
      "Epoch 343/1000\n",
      "177/177 [==============================] - 0s 124us/step - loss: 0.0286 - accuracy: 0.9887 - val_loss: 3.2571 - val_accuracy: 0.5395\n",
      "Epoch 344/1000\n",
      "177/177 [==============================] - 0s 114us/step - loss: 0.0262 - accuracy: 0.9887 - val_loss: 3.2518 - val_accuracy: 0.5395\n",
      "Epoch 345/1000\n",
      "177/177 [==============================] - 0s 134us/step - loss: 0.0279 - accuracy: 0.9887 - val_loss: 3.2517 - val_accuracy: 0.5395\n",
      "Epoch 346/1000\n",
      "177/177 [==============================] - 0s 97us/step - loss: 0.0261 - accuracy: 0.9831 - val_loss: 3.2718 - val_accuracy: 0.5395\n",
      "Epoch 347/1000\n",
      "177/177 [==============================] - 0s 114us/step - loss: 0.0275 - accuracy: 0.9887 - val_loss: 3.2766 - val_accuracy: 0.5395\n",
      "Epoch 348/1000\n",
      "177/177 [==============================] - 0s 229us/step - loss: 0.0274 - accuracy: 0.9887 - val_loss: 3.2692 - val_accuracy: 0.5395\n",
      "Epoch 349/1000\n",
      "177/177 [==============================] - 0s 185us/step - loss: 0.0288 - accuracy: 0.9887 - val_loss: 3.2669 - val_accuracy: 0.5395\n",
      "Epoch 350/1000\n",
      "177/177 [==============================] - 0s 151us/step - loss: 0.0270 - accuracy: 0.9887 - val_loss: 3.2769 - val_accuracy: 0.5395\n",
      "Epoch 351/1000\n",
      "177/177 [==============================] - 0s 141us/step - loss: 0.0273 - accuracy: 0.9887 - val_loss: 3.2746 - val_accuracy: 0.5395\n",
      "Epoch 352/1000\n",
      "177/177 [==============================] - 0s 218us/step - loss: 0.0295 - accuracy: 0.9887 - val_loss: 3.2917 - val_accuracy: 0.5263\n",
      "Epoch 353/1000\n",
      "177/177 [==============================] - 0s 218us/step - loss: 0.0302 - accuracy: 0.9887 - val_loss: 3.2755 - val_accuracy: 0.5395\n",
      "Epoch 354/1000\n",
      "177/177 [==============================] - 0s 156us/step - loss: 0.0267 - accuracy: 0.9887 - val_loss: 3.2800 - val_accuracy: 0.5395\n",
      "Epoch 355/1000\n",
      "177/177 [==============================] - 0s 99us/step - loss: 0.0265 - accuracy: 0.9887 - val_loss: 3.2803 - val_accuracy: 0.5395\n",
      "Epoch 356/1000\n",
      "177/177 [==============================] - 0s 94us/step - loss: 0.0269 - accuracy: 0.9887 - val_loss: 3.2841 - val_accuracy: 0.5263\n",
      "Epoch 357/1000\n",
      "177/177 [==============================] - 0s 102us/step - loss: 0.0283 - accuracy: 0.9887 - val_loss: 3.2803 - val_accuracy: 0.5395\n",
      "Epoch 358/1000\n",
      "177/177 [==============================] - 0s 93us/step - loss: 0.0269 - accuracy: 0.9887 - val_loss: 3.2935 - val_accuracy: 0.5395\n",
      "Epoch 359/1000\n",
      "177/177 [==============================] - 0s 117us/step - loss: 0.0267 - accuracy: 0.9887 - val_loss: 3.3160 - val_accuracy: 0.5263\n",
      "Epoch 360/1000\n",
      "177/177 [==============================] - 0s 103us/step - loss: 0.0277 - accuracy: 0.9887 - val_loss: 3.3218 - val_accuracy: 0.5263\n",
      "Epoch 361/1000\n",
      "177/177 [==============================] - 0s 196us/step - loss: 0.0278 - accuracy: 0.9887 - val_loss: 3.3445 - val_accuracy: 0.5263\n",
      "Epoch 362/1000\n",
      "177/177 [==============================] - 0s 201us/step - loss: 0.0293 - accuracy: 0.9887 - val_loss: 3.3197 - val_accuracy: 0.5263\n",
      "Epoch 363/1000\n",
      "177/177 [==============================] - 0s 132us/step - loss: 0.0284 - accuracy: 0.9887 - val_loss: 3.3314 - val_accuracy: 0.5263\n",
      "Epoch 364/1000\n",
      "177/177 [==============================] - 0s 131us/step - loss: 0.0303 - accuracy: 0.9831 - val_loss: 3.3143 - val_accuracy: 0.5395\n",
      "Epoch 365/1000\n",
      "177/177 [==============================] - 0s 111us/step - loss: 0.0267 - accuracy: 0.9944 - val_loss: 3.3354 - val_accuracy: 0.5263\n",
      "Epoch 366/1000\n",
      "177/177 [==============================] - 0s 99us/step - loss: 0.0261 - accuracy: 0.9887 - val_loss: 3.3387 - val_accuracy: 0.5263\n",
      "Epoch 367/1000\n",
      "177/177 [==============================] - 0s 132us/step - loss: 0.0306 - accuracy: 0.9887 - val_loss: 3.3320 - val_accuracy: 0.5263\n",
      "Epoch 368/1000\n",
      "177/177 [==============================] - 0s 107us/step - loss: 0.0271 - accuracy: 0.9887 - val_loss: 3.3291 - val_accuracy: 0.5263\n",
      "Epoch 369/1000\n",
      "177/177 [==============================] - 0s 332us/step - loss: 0.0301 - accuracy: 0.9831 - val_loss: 3.3160 - val_accuracy: 0.5263\n",
      "Epoch 370/1000\n",
      "177/177 [==============================] - 0s 269us/step - loss: 0.0302 - accuracy: 0.9887 - val_loss: 3.3222 - val_accuracy: 0.5395\n",
      "Epoch 371/1000\n",
      "177/177 [==============================] - 0s 270us/step - loss: 0.0258 - accuracy: 0.9887 - val_loss: 3.3492 - val_accuracy: 0.5263\n",
      "Epoch 372/1000\n",
      "177/177 [==============================] - 0s 120us/step - loss: 0.0345 - accuracy: 0.9887 - val_loss: 3.3633 - val_accuracy: 0.5395\n",
      "Epoch 373/1000\n",
      "177/177 [==============================] - 0s 91us/step - loss: 0.0271 - accuracy: 0.9887 - val_loss: 3.3261 - val_accuracy: 0.5395\n",
      "Epoch 374/1000\n",
      "177/177 [==============================] - 0s 102us/step - loss: 0.0298 - accuracy: 0.9887 - val_loss: 3.3146 - val_accuracy: 0.5263\n",
      "Epoch 375/1000\n",
      "177/177 [==============================] - 0s 114us/step - loss: 0.0297 - accuracy: 0.9887 - val_loss: 3.3014 - val_accuracy: 0.5395\n",
      "Epoch 376/1000\n",
      "177/177 [==============================] - 0s 237us/step - loss: 0.0287 - accuracy: 0.9887 - val_loss: 3.2965 - val_accuracy: 0.5263\n",
      "Epoch 377/1000\n",
      "177/177 [==============================] - 0s 204us/step - loss: 0.0265 - accuracy: 0.9887 - val_loss: 3.3173 - val_accuracy: 0.5263\n",
      "Epoch 378/1000\n",
      "177/177 [==============================] - 0s 187us/step - loss: 0.0285 - accuracy: 0.9887 - val_loss: 3.3025 - val_accuracy: 0.5395\n",
      "Epoch 379/1000\n",
      "177/177 [==============================] - 0s 129us/step - loss: 0.0267 - accuracy: 0.9887 - val_loss: 3.3002 - val_accuracy: 0.5395\n",
      "Epoch 380/1000\n",
      "177/177 [==============================] - 0s 110us/step - loss: 0.0278 - accuracy: 0.9887 - val_loss: 3.3032 - val_accuracy: 0.5395\n",
      "Epoch 381/1000\n",
      "177/177 [==============================] - 0s 167us/step - loss: 0.0269 - accuracy: 0.9887 - val_loss: 3.3067 - val_accuracy: 0.5263\n",
      "Epoch 382/1000\n",
      "177/177 [==============================] - 0s 101us/step - loss: 0.0286 - accuracy: 0.9887 - val_loss: 3.3263 - val_accuracy: 0.5395\n",
      "Epoch 383/1000\n",
      "177/177 [==============================] - 0s 97us/step - loss: 0.0283 - accuracy: 0.9887 - val_loss: 3.3297 - val_accuracy: 0.5395\n",
      "Epoch 384/1000\n",
      "177/177 [==============================] - 0s 152us/step - loss: 0.0285 - accuracy: 0.9887 - val_loss: 3.3176 - val_accuracy: 0.5395\n",
      "Epoch 385/1000\n",
      "177/177 [==============================] - 0s 122us/step - loss: 0.0285 - accuracy: 0.9887 - val_loss: 3.3297 - val_accuracy: 0.5395\n",
      "Epoch 386/1000\n",
      "177/177 [==============================] - 0s 250us/step - loss: 0.0290 - accuracy: 0.9831 - val_loss: 3.3496 - val_accuracy: 0.5263\n",
      "Epoch 387/1000\n",
      "177/177 [==============================] - 0s 127us/step - loss: 0.0282 - accuracy: 0.9887 - val_loss: 3.3349 - val_accuracy: 0.5395\n",
      "Epoch 388/1000\n",
      "177/177 [==============================] - ETA: 0s - loss: 0.0116 - accuracy: 1.00 - 0s 161us/step - loss: 0.0278 - accuracy: 0.9887 - val_loss: 3.3406 - val_accuracy: 0.5395\n",
      "Epoch 389/1000\n",
      "177/177 [==============================] - 0s 141us/step - loss: 0.0282 - accuracy: 0.9831 - val_loss: 3.3363 - val_accuracy: 0.5395\n",
      "Epoch 390/1000\n",
      "177/177 [==============================] - 0s 168us/step - loss: 0.0273 - accuracy: 0.9887 - val_loss: 3.3520 - val_accuracy: 0.5395\n",
      "Epoch 391/1000\n",
      "177/177 [==============================] - 0s 160us/step - loss: 0.0273 - accuracy: 0.9831 - val_loss: 3.3502 - val_accuracy: 0.5263\n",
      "Epoch 392/1000\n",
      "177/177 [==============================] - 0s 151us/step - loss: 0.0442 - accuracy: 0.9831 - val_loss: 3.3489 - val_accuracy: 0.5263\n",
      "Epoch 393/1000\n",
      "177/177 [==============================] - 0s 198us/step - loss: 0.1530 - accuracy: 0.9774 - val_loss: 3.3202 - val_accuracy: 0.5263\n",
      "Epoch 394/1000\n",
      "177/177 [==============================] - 0s 116us/step - loss: 0.0904 - accuracy: 0.9831 - val_loss: 3.4158 - val_accuracy: 0.5132\n",
      "Epoch 395/1000\n",
      "177/177 [==============================] - 0s 551us/step - loss: 0.1401 - accuracy: 0.9774 - val_loss: 3.3327 - val_accuracy: 0.5395\n",
      "Epoch 396/1000\n",
      "177/177 [==============================] - 0s 275us/step - loss: 0.0360 - accuracy: 0.9831 - val_loss: 3.4056 - val_accuracy: 0.5132\n",
      "Epoch 397/1000\n",
      "177/177 [==============================] - 0s 140us/step - loss: 0.2932 - accuracy: 0.9718 - val_loss: 3.3771 - val_accuracy: 0.5263\n",
      "Epoch 398/1000\n",
      "177/177 [==============================] - 0s 111us/step - loss: 0.0942 - accuracy: 0.9831 - val_loss: 3.4577 - val_accuracy: 0.5395\n",
      "Epoch 399/1000\n",
      "177/177 [==============================] - 0s 112us/step - loss: 0.2315 - accuracy: 0.9605 - val_loss: 3.4331 - val_accuracy: 0.5000\n",
      "Epoch 400/1000\n",
      "177/177 [==============================] - 0s 106us/step - loss: 0.4794 - accuracy: 0.9548 - val_loss: 3.3637 - val_accuracy: 0.5132\n",
      "Epoch 401/1000\n",
      "177/177 [==============================] - 0s 279us/step - loss: 0.1446 - accuracy: 0.9718 - val_loss: 3.4791 - val_accuracy: 0.5000\n",
      "Epoch 402/1000\n",
      "177/177 [==============================] - 0s 171us/step - loss: 0.4871 - accuracy: 0.9548 - val_loss: 3.2877 - val_accuracy: 0.5395\n",
      "Epoch 403/1000\n",
      "177/177 [==============================] - 0s 136us/step - loss: 0.2048 - accuracy: 0.9774 - val_loss: 3.3572 - val_accuracy: 0.5395\n",
      "Epoch 404/1000\n",
      "177/177 [==============================] - 0s 282us/step - loss: 0.1282 - accuracy: 0.9774 - val_loss: 3.4048 - val_accuracy: 0.5526\n",
      "Epoch 405/1000\n",
      "177/177 [==============================] - 0s 122us/step - loss: 0.0686 - accuracy: 0.9831 - val_loss: 3.3090 - val_accuracy: 0.5263\n",
      "Epoch 406/1000\n",
      "177/177 [==============================] - 0s 143us/step - loss: 0.0525 - accuracy: 0.9831 - val_loss: 3.4359 - val_accuracy: 0.5263\n",
      "Epoch 407/1000\n",
      "177/177 [==============================] - 0s 275us/step - loss: 0.1702 - accuracy: 0.9548 - val_loss: 3.2881 - val_accuracy: 0.5395\n",
      "Epoch 408/1000\n",
      "177/177 [==============================] - 0s 130us/step - loss: 0.2132 - accuracy: 0.9605 - val_loss: 3.3698 - val_accuracy: 0.5263\n",
      "Epoch 409/1000\n",
      "177/177 [==============================] - 0s 109us/step - loss: 0.0798 - accuracy: 0.9831 - val_loss: 3.3577 - val_accuracy: 0.5263\n",
      "Epoch 410/1000\n",
      "177/177 [==============================] - 0s 117us/step - loss: 0.0265 - accuracy: 0.9887 - val_loss: 3.3303 - val_accuracy: 0.5263\n",
      "Epoch 411/1000\n",
      "177/177 [==============================] - 0s 129us/step - loss: 0.0325 - accuracy: 0.9887 - val_loss: 3.3277 - val_accuracy: 0.5395\n",
      "Epoch 412/1000\n",
      "177/177 [==============================] - ETA: 0s - loss: 0.0342 - accuracy: 0.96 - 0s 111us/step - loss: 0.0931 - accuracy: 0.9718 - val_loss: 3.3311 - val_accuracy: 0.5263\n",
      "Epoch 413/1000\n",
      "177/177 [==============================] - 0s 104us/step - loss: 0.0737 - accuracy: 0.9831 - val_loss: 3.3875 - val_accuracy: 0.5132\n",
      "Epoch 414/1000\n",
      "177/177 [==============================] - 0s 110us/step - loss: 0.1275 - accuracy: 0.9774 - val_loss: 3.3407 - val_accuracy: 0.5263\n",
      "Epoch 415/1000\n",
      "177/177 [==============================] - 0s 105us/step - loss: 0.0315 - accuracy: 0.9887 - val_loss: 3.3905 - val_accuracy: 0.5000\n",
      "Epoch 416/1000\n",
      "177/177 [==============================] - 0s 179us/step - loss: 0.0415 - accuracy: 0.9831 - val_loss: 3.3347 - val_accuracy: 0.5263\n",
      "Epoch 417/1000\n",
      "177/177 [==============================] - 0s 129us/step - loss: 0.0900 - accuracy: 0.9774 - val_loss: 3.4054 - val_accuracy: 0.5000\n",
      "Epoch 418/1000\n",
      "177/177 [==============================] - 0s 178us/step - loss: 0.0509 - accuracy: 0.9774 - val_loss: 3.3568 - val_accuracy: 0.5395\n",
      "Epoch 419/1000\n",
      "177/177 [==============================] - 0s 142us/step - loss: 0.0861 - accuracy: 0.9774 - val_loss: 3.3506 - val_accuracy: 0.5132\n",
      "Epoch 420/1000\n",
      "177/177 [==============================] - 0s 259us/step - loss: 0.1206 - accuracy: 0.9774 - val_loss: 3.3774 - val_accuracy: 0.4868\n",
      "Epoch 421/1000\n",
      "177/177 [==============================] - 0s 109us/step - loss: 0.2167 - accuracy: 0.9718 - val_loss: 3.3998 - val_accuracy: 0.5000\n",
      "Epoch 422/1000\n",
      "177/177 [==============================] - 0s 97us/step - loss: 0.0396 - accuracy: 0.9718 - val_loss: 3.3275 - val_accuracy: 0.5263\n",
      "Epoch 423/1000\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.0616 - accuracy: 0.9831 - val_loss: 3.3275 - val_accuracy: 0.5395\n",
      "Epoch 424/1000\n",
      "177/177 [==============================] - 0s 105us/step - loss: 0.0437 - accuracy: 0.9774 - val_loss: 3.3739 - val_accuracy: 0.5395\n",
      "Epoch 425/1000\n",
      "177/177 [==============================] - 0s 92us/step - loss: 0.0782 - accuracy: 0.9774 - val_loss: 3.3299 - val_accuracy: 0.5263\n",
      "Epoch 426/1000\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.0430 - accuracy: 0.9887 - val_loss: 3.3026 - val_accuracy: 0.5263\n",
      "Epoch 427/1000\n",
      "177/177 [==============================] - 0s 119us/step - loss: 0.0747 - accuracy: 0.9831 - val_loss: 3.3564 - val_accuracy: 0.5263\n",
      "Epoch 428/1000\n",
      "177/177 [==============================] - 0s 102us/step - loss: 0.0615 - accuracy: 0.9718 - val_loss: 3.7222 - val_accuracy: 0.4868\n",
      "Epoch 429/1000\n",
      "177/177 [==============================] - 0s 99us/step - loss: 0.3246 - accuracy: 0.9661 - val_loss: 3.4255 - val_accuracy: 0.5000\n",
      "Epoch 430/1000\n",
      "177/177 [==============================] - 0s 219us/step - loss: 0.0252 - accuracy: 0.9887 - val_loss: 3.3906 - val_accuracy: 0.5000\n",
      "Epoch 431/1000\n",
      "177/177 [==============================] - 0s 209us/step - loss: 0.1177 - accuracy: 0.9831 - val_loss: 3.3902 - val_accuracy: 0.5000\n",
      "Epoch 432/1000\n",
      "177/177 [==============================] - 0s 181us/step - loss: 0.0257 - accuracy: 0.9831 - val_loss: 3.3944 - val_accuracy: 0.4868\n",
      "Epoch 433/1000\n",
      "177/177 [==============================] - 0s 208us/step - loss: 0.0922 - accuracy: 0.9831 - val_loss: 3.3331 - val_accuracy: 0.5132\n",
      "Epoch 434/1000\n",
      "177/177 [==============================] - 0s 125us/step - loss: 0.0287 - accuracy: 0.9887 - val_loss: 3.3285 - val_accuracy: 0.5132\n",
      "Epoch 435/1000\n",
      "177/177 [==============================] - 0s 100us/step - loss: 0.0812 - accuracy: 0.9831 - val_loss: 3.3839 - val_accuracy: 0.5132\n",
      "Epoch 436/1000\n",
      "177/177 [==============================] - 0s 105us/step - loss: 0.0809 - accuracy: 0.9774 - val_loss: 3.4190 - val_accuracy: 0.5263\n",
      "Epoch 437/1000\n",
      "177/177 [==============================] - 0s 110us/step - loss: 0.0306 - accuracy: 0.9887 - val_loss: 3.4179 - val_accuracy: 0.5132\n",
      "Epoch 438/1000\n",
      "177/177 [==============================] - 0s 91us/step - loss: 0.0285 - accuracy: 0.9887 - val_loss: 3.4102 - val_accuracy: 0.5000\n",
      "Epoch 439/1000\n",
      "177/177 [==============================] - 0s 121us/step - loss: 0.0281 - accuracy: 0.9887 - val_loss: 3.4071 - val_accuracy: 0.5132\n",
      "Epoch 440/1000\n",
      "177/177 [==============================] - 0s 108us/step - loss: 0.0279 - accuracy: 0.9887 - val_loss: 3.4045 - val_accuracy: 0.5132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 441/1000\n",
      "177/177 [==============================] - 0s 113us/step - loss: 0.0288 - accuracy: 0.9887 - val_loss: 3.4352 - val_accuracy: 0.5395\n",
      "Epoch 442/1000\n",
      "177/177 [==============================] - 0s 108us/step - loss: 0.0291 - accuracy: 0.9887 - val_loss: 3.4453 - val_accuracy: 0.5263\n",
      "Epoch 443/1000\n",
      "177/177 [==============================] - 0s 102us/step - loss: 0.0294 - accuracy: 0.9887 - val_loss: 3.4451 - val_accuracy: 0.5263\n",
      "Epoch 444/1000\n",
      "177/177 [==============================] - 0s 219us/step - loss: 0.0263 - accuracy: 0.9887 - val_loss: 3.4187 - val_accuracy: 0.5263\n",
      "Epoch 445/1000\n",
      "177/177 [==============================] - 0s 356us/step - loss: 0.0270 - accuracy: 0.9887 - val_loss: 3.4159 - val_accuracy: 0.5263\n",
      "Epoch 446/1000\n",
      "177/177 [==============================] - 0s 209us/step - loss: 0.0297 - accuracy: 0.9831 - val_loss: 3.4297 - val_accuracy: 0.5132\n",
      "Epoch 447/1000\n",
      "177/177 [==============================] - 0s 316us/step - loss: 0.0277 - accuracy: 0.9831 - val_loss: 3.4370 - val_accuracy: 0.5132\n",
      "Epoch 448/1000\n",
      "177/177 [==============================] - 0s 347us/step - loss: 0.0249 - accuracy: 0.9944 - val_loss: 3.4192 - val_accuracy: 0.5263\n",
      "Epoch 449/1000\n",
      "177/177 [==============================] - 0s 318us/step - loss: 0.0278 - accuracy: 0.9887 - val_loss: 3.4173 - val_accuracy: 0.5263\n",
      "Epoch 450/1000\n",
      "177/177 [==============================] - 0s 145us/step - loss: 0.0289 - accuracy: 0.9887 - val_loss: 3.4272 - val_accuracy: 0.5263\n",
      "Epoch 451/1000\n",
      "177/177 [==============================] - 0s 136us/step - loss: 0.0256 - accuracy: 0.9831 - val_loss: 3.4139 - val_accuracy: 0.5263\n",
      "Epoch 452/1000\n",
      "177/177 [==============================] - 0s 130us/step - loss: 0.0283 - accuracy: 0.9887 - val_loss: 3.4160 - val_accuracy: 0.5263\n",
      "Epoch 453/1000\n",
      "177/177 [==============================] - 0s 131us/step - loss: 0.0278 - accuracy: 0.9887 - val_loss: 3.4163 - val_accuracy: 0.5263\n",
      "Epoch 454/1000\n",
      "177/177 [==============================] - 0s 301us/step - loss: 0.0272 - accuracy: 0.9831 - val_loss: 3.4273 - val_accuracy: 0.5263\n",
      "Epoch 455/1000\n",
      "177/177 [==============================] - 0s 313us/step - loss: 0.0303 - accuracy: 0.9887 - val_loss: 3.4461 - val_accuracy: 0.5263\n",
      "Epoch 456/1000\n",
      "177/177 [==============================] - 0s 385us/step - loss: 0.0258 - accuracy: 0.9887 - val_loss: 3.4370 - val_accuracy: 0.5263\n",
      "Epoch 457/1000\n",
      "177/177 [==============================] - 0s 493us/step - loss: 0.0273 - accuracy: 0.9887 - val_loss: 3.4313 - val_accuracy: 0.5263\n",
      "Epoch 458/1000\n",
      "177/177 [==============================] - 0s 108us/step - loss: 0.0278 - accuracy: 0.9887 - val_loss: 3.4191 - val_accuracy: 0.5263\n",
      "Epoch 459/1000\n",
      "177/177 [==============================] - 0s 108us/step - loss: 0.0286 - accuracy: 0.9887 - val_loss: 3.4175 - val_accuracy: 0.5263\n",
      "Epoch 460/1000\n",
      "177/177 [==============================] - 0s 112us/step - loss: 0.0290 - accuracy: 0.9887 - val_loss: 3.4289 - val_accuracy: 0.5263\n",
      "Epoch 461/1000\n",
      "177/177 [==============================] - 0s 126us/step - loss: 0.0298 - accuracy: 0.9831 - val_loss: 3.4291 - val_accuracy: 0.5263\n",
      "Epoch 462/1000\n",
      "177/177 [==============================] - 0s 107us/step - loss: 0.0283 - accuracy: 0.9887 - val_loss: 3.4204 - val_accuracy: 0.5395\n",
      "Epoch 463/1000\n",
      "177/177 [==============================] - 0s 132us/step - loss: 0.0280 - accuracy: 0.9887 - val_loss: 3.4246 - val_accuracy: 0.5263\n",
      "Epoch 464/1000\n",
      "177/177 [==============================] - 0s 165us/step - loss: 0.0270 - accuracy: 0.9887 - val_loss: 3.4278 - val_accuracy: 0.5263\n",
      "Epoch 465/1000\n",
      "177/177 [==============================] - 0s 130us/step - loss: 0.0300 - accuracy: 0.9887 - val_loss: 3.4461 - val_accuracy: 0.5395\n",
      "Epoch 466/1000\n",
      "177/177 [==============================] - 0s 121us/step - loss: 0.0287 - accuracy: 0.9887 - val_loss: 3.4343 - val_accuracy: 0.5263\n",
      "Epoch 467/1000\n",
      "177/177 [==============================] - 0s 135us/step - loss: 0.0282 - accuracy: 0.9831 - val_loss: 3.4317 - val_accuracy: 0.5395\n",
      "Epoch 468/1000\n",
      "177/177 [==============================] - 0s 102us/step - loss: 0.0279 - accuracy: 0.9887 - val_loss: 3.4336 - val_accuracy: 0.5263\n",
      "Epoch 469/1000\n",
      "177/177 [==============================] - 0s 111us/step - loss: 0.0269 - accuracy: 0.9831 - val_loss: 3.4225 - val_accuracy: 0.5263\n",
      "Epoch 470/1000\n",
      "177/177 [==============================] - 0s 105us/step - loss: 0.0290 - accuracy: 0.9887 - val_loss: 3.4226 - val_accuracy: 0.5263\n",
      "Epoch 471/1000\n",
      "177/177 [==============================] - 0s 118us/step - loss: 0.0326 - accuracy: 0.9831 - val_loss: 3.4407 - val_accuracy: 0.5395\n",
      "Epoch 472/1000\n",
      "177/177 [==============================] - 0s 118us/step - loss: 0.0281 - accuracy: 0.9831 - val_loss: 3.4376 - val_accuracy: 0.5263\n",
      "Epoch 473/1000\n",
      "177/177 [==============================] - 0s 191us/step - loss: 0.0282 - accuracy: 0.9887 - val_loss: 3.4164 - val_accuracy: 0.5263\n",
      "Epoch 474/1000\n",
      "177/177 [==============================] - 0s 284us/step - loss: 0.0276 - accuracy: 0.9887 - val_loss: 3.4203 - val_accuracy: 0.5395\n",
      "Epoch 475/1000\n",
      "177/177 [==============================] - 0s 161us/step - loss: 0.0267 - accuracy: 0.9887 - val_loss: 3.4268 - val_accuracy: 0.5263\n",
      "Epoch 476/1000\n",
      "177/177 [==============================] - 0s 124us/step - loss: 0.0258 - accuracy: 0.9887 - val_loss: 3.4545 - val_accuracy: 0.5395\n",
      "Epoch 477/1000\n",
      "177/177 [==============================] - 0s 122us/step - loss: 0.0297 - accuracy: 0.9887 - val_loss: 3.4551 - val_accuracy: 0.5395\n",
      "Epoch 478/1000\n",
      "177/177 [==============================] - 0s 101us/step - loss: 0.0274 - accuracy: 0.9887 - val_loss: 3.4442 - val_accuracy: 0.5395\n",
      "Epoch 479/1000\n",
      "177/177 [==============================] - 0s 111us/step - loss: 0.0248 - accuracy: 0.9887 - val_loss: 3.4178 - val_accuracy: 0.5263\n",
      "Epoch 480/1000\n",
      "177/177 [==============================] - 0s 453us/step - loss: 0.0281 - accuracy: 0.9887 - val_loss: 3.4105 - val_accuracy: 0.5263\n",
      "Epoch 481/1000\n",
      "177/177 [==============================] - 0s 420us/step - loss: 0.0285 - accuracy: 0.9887 - val_loss: 3.4195 - val_accuracy: 0.5395\n",
      "Epoch 482/1000\n",
      "177/177 [==============================] - 0s 523us/step - loss: 0.0270 - accuracy: 0.9887 - val_loss: 3.4323 - val_accuracy: 0.5395\n",
      "Epoch 483/1000\n",
      "177/177 [==============================] - 0s 128us/step - loss: 0.0273 - accuracy: 0.9887 - val_loss: 3.4516 - val_accuracy: 0.5395\n",
      "Epoch 484/1000\n",
      "177/177 [==============================] - 0s 129us/step - loss: 0.0275 - accuracy: 0.9887 - val_loss: 3.4445 - val_accuracy: 0.5395\n",
      "Epoch 485/1000\n",
      "177/177 [==============================] - 0s 127us/step - loss: 0.0258 - accuracy: 0.9887 - val_loss: 3.4260 - val_accuracy: 0.5263\n",
      "Epoch 486/1000\n",
      "177/177 [==============================] - 0s 130us/step - loss: 0.0263 - accuracy: 0.9887 - val_loss: 3.4294 - val_accuracy: 0.5263\n",
      "Epoch 487/1000\n",
      "177/177 [==============================] - 0s 151us/step - loss: 0.0287 - accuracy: 0.9831 - val_loss: 3.4337 - val_accuracy: 0.5395\n",
      "Epoch 488/1000\n",
      "177/177 [==============================] - 0s 152us/step - loss: 0.0263 - accuracy: 0.9831 - val_loss: 3.4425 - val_accuracy: 0.5395\n",
      "Epoch 489/1000\n",
      "177/177 [==============================] - 0s 134us/step - loss: 0.0255 - accuracy: 0.9887 - val_loss: 3.4534 - val_accuracy: 0.5395\n",
      "Epoch 490/1000\n",
      "177/177 [==============================] - 0s 141us/step - loss: 0.0258 - accuracy: 0.9887 - val_loss: 3.4458 - val_accuracy: 0.5395\n",
      "Epoch 491/1000\n",
      "177/177 [==============================] - 0s 111us/step - loss: 0.0298 - accuracy: 0.9887 - val_loss: 3.4320 - val_accuracy: 0.5263\n",
      "Epoch 492/1000\n",
      "177/177 [==============================] - 0s 128us/step - loss: 0.0316 - accuracy: 0.9887 - val_loss: 3.4353 - val_accuracy: 0.5263\n",
      "Epoch 493/1000\n",
      "177/177 [==============================] - 0s 161us/step - loss: 0.0282 - accuracy: 0.9887 - val_loss: 3.4503 - val_accuracy: 0.5395\n",
      "Epoch 494/1000\n",
      "177/177 [==============================] - 0s 298us/step - loss: 0.0265 - accuracy: 0.9887 - val_loss: 3.4411 - val_accuracy: 0.5395\n",
      "Epoch 495/1000\n",
      "177/177 [==============================] - 0s 356us/step - loss: 0.0295 - accuracy: 0.9831 - val_loss: 3.4568 - val_accuracy: 0.5395\n",
      "Epoch 496/1000\n",
      "177/177 [==============================] - 0s 287us/step - loss: 0.0292 - accuracy: 0.9831 - val_loss: 3.4395 - val_accuracy: 0.5526\n",
      "Epoch 497/1000\n",
      "177/177 [==============================] - 0s 211us/step - loss: 0.0294 - accuracy: 0.9887 - val_loss: 3.4411 - val_accuracy: 0.5526\n",
      "Epoch 498/1000\n",
      "177/177 [==============================] - 0s 161us/step - loss: 0.0266 - accuracy: 0.9887 - val_loss: 3.4436 - val_accuracy: 0.5395\n",
      "Epoch 499/1000\n",
      "177/177 [==============================] - 0s 302us/step - loss: 0.0241 - accuracy: 0.9887 - val_loss: 3.4490 - val_accuracy: 0.5395\n",
      "Epoch 500/1000\n",
      "177/177 [==============================] - 0s 216us/step - loss: 0.0288 - accuracy: 0.9887 - val_loss: 3.4466 - val_accuracy: 0.5395\n",
      "Epoch 501/1000\n",
      "177/177 [==============================] - 0s 163us/step - loss: 0.0314 - accuracy: 0.9887 - val_loss: 3.4790 - val_accuracy: 0.5263\n",
      "Epoch 502/1000\n",
      "177/177 [==============================] - 0s 155us/step - loss: 0.0250 - accuracy: 0.9887 - val_loss: 3.4390 - val_accuracy: 0.5395\n",
      "Epoch 503/1000\n",
      "177/177 [==============================] - 0s 148us/step - loss: 0.0314 - accuracy: 0.9887 - val_loss: 3.4465 - val_accuracy: 0.5395\n",
      "Epoch 504/1000\n",
      "177/177 [==============================] - 0s 125us/step - loss: 0.0280 - accuracy: 0.9887 - val_loss: 3.4538 - val_accuracy: 0.5526\n",
      "Epoch 505/1000\n",
      "177/177 [==============================] - 0s 120us/step - loss: 0.0581 - accuracy: 0.9774 - val_loss: 3.4442 - val_accuracy: 0.5263\n",
      "Epoch 506/1000\n",
      "177/177 [==============================] - 0s 170us/step - loss: 0.0629 - accuracy: 0.9718 - val_loss: 3.5342 - val_accuracy: 0.5132\n",
      "Epoch 507/1000\n",
      "177/177 [==============================] - 0s 160us/step - loss: 0.1162 - accuracy: 0.9605 - val_loss: 3.4320 - val_accuracy: 0.5395\n",
      "Epoch 508/1000\n",
      "177/177 [==============================] - 0s 614us/step - loss: 0.0437 - accuracy: 0.9774 - val_loss: 3.5269 - val_accuracy: 0.4868\n",
      "Epoch 509/1000\n",
      "177/177 [==============================] - 0s 192us/step - loss: 0.0975 - accuracy: 0.9774 - val_loss: 3.4604 - val_accuracy: 0.5263\n",
      "Epoch 510/1000\n",
      "177/177 [==============================] - 0s 109us/step - loss: 0.0339 - accuracy: 0.9887 - val_loss: 3.4459 - val_accuracy: 0.5395\n",
      "Epoch 511/1000\n",
      "177/177 [==============================] - 0s 112us/step - loss: 0.0368 - accuracy: 0.9887 - val_loss: 3.4515 - val_accuracy: 0.5395\n",
      "Epoch 512/1000\n",
      "177/177 [==============================] - 0s 146us/step - loss: 0.0288 - accuracy: 0.9887 - val_loss: 3.4646 - val_accuracy: 0.5395\n",
      "Epoch 513/1000\n",
      "177/177 [==============================] - 0s 158us/step - loss: 0.0257 - accuracy: 0.9887 - val_loss: 3.4712 - val_accuracy: 0.5395\n",
      "Epoch 514/1000\n",
      "177/177 [==============================] - 0s 149us/step - loss: 0.0291 - accuracy: 0.9887 - val_loss: 3.4698 - val_accuracy: 0.5526\n",
      "Epoch 515/1000\n",
      "177/177 [==============================] - 0s 120us/step - loss: 0.0265 - accuracy: 0.9887 - val_loss: 3.4676 - val_accuracy: 0.5395\n",
      "Epoch 516/1000\n",
      "177/177 [==============================] - 0s 141us/step - loss: 0.0275 - accuracy: 0.9887 - val_loss: 3.4663 - val_accuracy: 0.5395\n",
      "Epoch 517/1000\n",
      "177/177 [==============================] - 0s 108us/step - loss: 0.0267 - accuracy: 0.9887 - val_loss: 3.4713 - val_accuracy: 0.5395\n",
      "Epoch 518/1000\n",
      "177/177 [==============================] - 0s 124us/step - loss: 0.0259 - accuracy: 0.9887 - val_loss: 3.4688 - val_accuracy: 0.5395\n",
      "Epoch 519/1000\n",
      "177/177 [==============================] - 0s 176us/step - loss: 0.0265 - accuracy: 0.9887 - val_loss: 3.4691 - val_accuracy: 0.5395\n",
      "Epoch 520/1000\n",
      "177/177 [==============================] - 0s 132us/step - loss: 0.0271 - accuracy: 0.9887 - val_loss: 3.4622 - val_accuracy: 0.5263\n",
      "Epoch 521/1000\n",
      "177/177 [==============================] - 0s 121us/step - loss: 0.0267 - accuracy: 0.9887 - val_loss: 3.4684 - val_accuracy: 0.5263\n",
      "Epoch 522/1000\n",
      "177/177 [==============================] - 0s 124us/step - loss: 0.0317 - accuracy: 0.9887 - val_loss: 3.4940 - val_accuracy: 0.5263\n",
      "Epoch 523/1000\n",
      "177/177 [==============================] - 0s 132us/step - loss: 0.0346 - accuracy: 0.9831 - val_loss: 3.4510 - val_accuracy: 0.5263\n",
      "Epoch 524/1000\n",
      "177/177 [==============================] - 0s 171us/step - loss: 0.0271 - accuracy: 0.9887 - val_loss: 3.4636 - val_accuracy: 0.5263\n",
      "Epoch 525/1000\n",
      "177/177 [==============================] - 0s 115us/step - loss: 0.0265 - accuracy: 0.9887 - val_loss: 3.4906 - val_accuracy: 0.5395\n",
      "Epoch 526/1000\n",
      "177/177 [==============================] - 0s 118us/step - loss: 0.0285 - accuracy: 0.9887 - val_loss: 3.4911 - val_accuracy: 0.5395\n",
      "Epoch 527/1000\n",
      "177/177 [==============================] - 0s 272us/step - loss: 0.0297 - accuracy: 0.9887 - val_loss: 3.4642 - val_accuracy: 0.5263\n",
      "Epoch 528/1000\n",
      "177/177 [==============================] - 0s 358us/step - loss: 0.0268 - accuracy: 0.9887 - val_loss: 3.4636 - val_accuracy: 0.5263\n",
      "Epoch 529/1000\n",
      "177/177 [==============================] - 0s 147us/step - loss: 0.0264 - accuracy: 0.9887 - val_loss: 3.4794 - val_accuracy: 0.5263\n",
      "Epoch 530/1000\n",
      "177/177 [==============================] - 0s 105us/step - loss: 0.0257 - accuracy: 0.9887 - val_loss: 3.4824 - val_accuracy: 0.5263\n",
      "Epoch 531/1000\n",
      "177/177 [==============================] - 0s 103us/step - loss: 0.0271 - accuracy: 0.9887 - val_loss: 3.4723 - val_accuracy: 0.5263\n",
      "Epoch 532/1000\n",
      "177/177 [==============================] - 0s 107us/step - loss: 0.0252 - accuracy: 0.9887 - val_loss: 3.4715 - val_accuracy: 0.5395\n",
      "Epoch 533/1000\n",
      "177/177 [==============================] - 0s 104us/step - loss: 0.0311 - accuracy: 0.9887 - val_loss: 3.4800 - val_accuracy: 0.5395\n",
      "Epoch 534/1000\n",
      "177/177 [==============================] - 0s 99us/step - loss: 0.0246 - accuracy: 0.9887 - val_loss: 3.4685 - val_accuracy: 0.5526\n",
      "Epoch 535/1000\n",
      "177/177 [==============================] - 0s 455us/step - loss: 0.0296 - accuracy: 0.9831 - val_loss: 3.4834 - val_accuracy: 0.5395\n",
      "Epoch 536/1000\n",
      "177/177 [==============================] - 0s 247us/step - loss: 0.0281 - accuracy: 0.9887 - val_loss: 3.4855 - val_accuracy: 0.5395\n",
      "Epoch 537/1000\n",
      "177/177 [==============================] - 0s 479us/step - loss: 0.0266 - accuracy: 0.9831 - val_loss: 3.4812 - val_accuracy: 0.5395\n",
      "Epoch 538/1000\n",
      "177/177 [==============================] - 0s 300us/step - loss: 0.0257 - accuracy: 0.9887 - val_loss: 3.4899 - val_accuracy: 0.5395\n",
      "Epoch 539/1000\n",
      "177/177 [==============================] - 0s 189us/step - loss: 0.0302 - accuracy: 0.9887 - val_loss: 3.5116 - val_accuracy: 0.5526\n",
      "Epoch 540/1000\n",
      "177/177 [==============================] - 0s 221us/step - loss: 0.0330 - accuracy: 0.9774 - val_loss: 3.5269 - val_accuracy: 0.5395\n",
      "Epoch 541/1000\n",
      "177/177 [==============================] - 0s 205us/step - loss: 0.0280 - accuracy: 0.9831 - val_loss: 3.4807 - val_accuracy: 0.5395\n",
      "Epoch 542/1000\n",
      "177/177 [==============================] - 0s 257us/step - loss: 0.0323 - accuracy: 0.9831 - val_loss: 3.4695 - val_accuracy: 0.5395\n",
      "Epoch 543/1000\n",
      "177/177 [==============================] - 0s 123us/step - loss: 0.0940 - accuracy: 0.9831 - val_loss: 3.4682 - val_accuracy: 0.5263\n",
      "Epoch 544/1000\n",
      "177/177 [==============================] - 0s 140us/step - loss: 0.0619 - accuracy: 0.9831 - val_loss: 3.5322 - val_accuracy: 0.5000\n",
      "Epoch 545/1000\n",
      "177/177 [==============================] - 0s 150us/step - loss: 0.0547 - accuracy: 0.9718 - val_loss: 3.4695 - val_accuracy: 0.5395\n",
      "Epoch 546/1000\n",
      "177/177 [==============================] - 0s 119us/step - loss: 0.0656 - accuracy: 0.9718 - val_loss: 3.5977 - val_accuracy: 0.5000\n",
      "Epoch 547/1000\n",
      "177/177 [==============================] - 0s 146us/step - loss: 0.1848 - accuracy: 0.9661 - val_loss: 3.5251 - val_accuracy: 0.5263\n",
      "Epoch 548/1000\n",
      "177/177 [==============================] - 0s 122us/step - loss: 0.1368 - accuracy: 0.9718 - val_loss: 3.4641 - val_accuracy: 0.5526\n",
      "Epoch 549/1000\n",
      "177/177 [==============================] - 0s 127us/step - loss: 0.1271 - accuracy: 0.9718 - val_loss: 3.5984 - val_accuracy: 0.4737\n",
      "Epoch 550/1000\n",
      "177/177 [==============================] - 0s 121us/step - loss: 0.4467 - accuracy: 0.9435 - val_loss: 3.5224 - val_accuracy: 0.5132\n",
      "Epoch 551/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177/177 [==============================] - 0s 157us/step - loss: 0.2640 - accuracy: 0.9718 - val_loss: 3.5392 - val_accuracy: 0.5263\n",
      "Epoch 552/1000\n",
      "177/177 [==============================] - 0s 134us/step - loss: 0.0720 - accuracy: 0.9774 - val_loss: 3.4923 - val_accuracy: 0.5395\n",
      "Epoch 553/1000\n",
      "177/177 [==============================] - 0s 247us/step - loss: 0.1415 - accuracy: 0.9774 - val_loss: 3.4437 - val_accuracy: 0.5526\n",
      "Epoch 554/1000\n",
      "177/177 [==============================] - 0s 391us/step - loss: 0.0355 - accuracy: 0.9831 - val_loss: 3.4980 - val_accuracy: 0.5395\n",
      "Epoch 555/1000\n",
      "177/177 [==============================] - 0s 127us/step - loss: 0.0577 - accuracy: 0.9831 - val_loss: 3.5169 - val_accuracy: 0.5395\n",
      "Epoch 556/1000\n",
      "177/177 [==============================] - 0s 127us/step - loss: 0.2164 - accuracy: 0.9774 - val_loss: 3.5363 - val_accuracy: 0.5395\n",
      "Epoch 557/1000\n",
      "177/177 [==============================] - 0s 222us/step - loss: 0.2389 - accuracy: 0.9548 - val_loss: 3.5145 - val_accuracy: 0.5395\n",
      "Epoch 558/1000\n",
      "177/177 [==============================] - 0s 202us/step - loss: 0.6219 - accuracy: 0.9661 - val_loss: 3.5102 - val_accuracy: 0.5526\n",
      "Epoch 559/1000\n",
      "177/177 [==============================] - 0s 203us/step - loss: 0.5796 - accuracy: 0.9548 - val_loss: 3.8694 - val_accuracy: 0.4868\n",
      "Epoch 560/1000\n",
      "177/177 [==============================] - 0s 130us/step - loss: 0.5100 - accuracy: 0.9492 - val_loss: 3.6146 - val_accuracy: 0.5000\n",
      "Epoch 561/1000\n",
      "177/177 [==============================] - 0s 106us/step - loss: 0.0664 - accuracy: 0.9718 - val_loss: 3.4864 - val_accuracy: 0.5526\n",
      "Epoch 562/1000\n",
      "177/177 [==============================] - 0s 127us/step - loss: 0.3537 - accuracy: 0.9661 - val_loss: 3.4659 - val_accuracy: 0.5263\n",
      "Epoch 563/1000\n",
      "177/177 [==============================] - 0s 108us/step - loss: 0.0932 - accuracy: 0.9774 - val_loss: 3.5153 - val_accuracy: 0.5395\n",
      "Epoch 564/1000\n",
      "177/177 [==============================] - 0s 113us/step - loss: 0.1053 - accuracy: 0.9774 - val_loss: 3.5130 - val_accuracy: 0.5263\n",
      "Epoch 565/1000\n",
      "177/177 [==============================] - 0s 127us/step - loss: 0.1456 - accuracy: 0.9661 - val_loss: 3.5037 - val_accuracy: 0.5263\n",
      "Epoch 566/1000\n",
      "177/177 [==============================] - 0s 124us/step - loss: 0.0300 - accuracy: 0.9887 - val_loss: 3.5974 - val_accuracy: 0.5132\n",
      "Epoch 567/1000\n",
      "177/177 [==============================] - 0s 126us/step - loss: 0.0477 - accuracy: 0.9774 - val_loss: 3.5542 - val_accuracy: 0.5263\n",
      "Epoch 568/1000\n",
      "177/177 [==============================] - 0s 157us/step - loss: 0.1526 - accuracy: 0.9718 - val_loss: 3.4967 - val_accuracy: 0.5263\n",
      "Epoch 569/1000\n",
      "177/177 [==============================] - 0s 135us/step - loss: 0.0719 - accuracy: 0.9661 - val_loss: 3.6430 - val_accuracy: 0.5132\n",
      "Epoch 570/1000\n",
      "177/177 [==============================] - 0s 100us/step - loss: 0.1536 - accuracy: 0.9661 - val_loss: 3.5732 - val_accuracy: 0.5132\n",
      "Epoch 571/1000\n",
      "177/177 [==============================] - 0s 108us/step - loss: 0.0714 - accuracy: 0.9774 - val_loss: 3.5243 - val_accuracy: 0.5263\n",
      "Epoch 572/1000\n",
      "177/177 [==============================] - 0s 128us/step - loss: 0.0321 - accuracy: 0.9831 - val_loss: 3.5509 - val_accuracy: 0.5263\n",
      "Epoch 573/1000\n",
      "177/177 [==============================] - 0s 105us/step - loss: 0.0889 - accuracy: 0.9718 - val_loss: 3.5612 - val_accuracy: 0.5132\n",
      "Epoch 574/1000\n",
      "177/177 [==============================] - 0s 128us/step - loss: 0.1003 - accuracy: 0.9831 - val_loss: 3.5722 - val_accuracy: 0.5132\n",
      "Epoch 575/1000\n",
      "177/177 [==============================] - 0s 154us/step - loss: 0.0779 - accuracy: 0.9831 - val_loss: 3.5503 - val_accuracy: 0.5263\n",
      "Epoch 576/1000\n",
      "177/177 [==============================] - 0s 124us/step - loss: 0.0289 - accuracy: 0.9887 - val_loss: 3.5667 - val_accuracy: 0.5263\n",
      "Epoch 577/1000\n",
      "177/177 [==============================] - 0s 118us/step - loss: 0.1817 - accuracy: 0.9774 - val_loss: 3.5443 - val_accuracy: 0.5263\n",
      "Epoch 578/1000\n",
      "177/177 [==============================] - 0s 125us/step - loss: 0.0788 - accuracy: 0.9831 - val_loss: 3.5951 - val_accuracy: 0.5132\n",
      "Epoch 579/1000\n",
      "177/177 [==============================] - 0s 134us/step - loss: 0.0983 - accuracy: 0.9774 - val_loss: 3.5270 - val_accuracy: 0.5263\n",
      "Epoch 580/1000\n",
      "177/177 [==============================] - 0s 127us/step - loss: 0.0720 - accuracy: 0.9831 - val_loss: 3.5069 - val_accuracy: 0.5263\n",
      "Epoch 581/1000\n",
      "177/177 [==============================] - 0s 141us/step - loss: 0.0559 - accuracy: 0.9774 - val_loss: 3.5467 - val_accuracy: 0.5263\n",
      "Epoch 582/1000\n",
      "177/177 [==============================] - 0s 120us/step - loss: 0.0331 - accuracy: 0.9887 - val_loss: 3.5640 - val_accuracy: 0.5132\n",
      "Epoch 583/1000\n",
      "177/177 [==============================] - 0s 183us/step - loss: 0.0528 - accuracy: 0.9831 - val_loss: 3.4974 - val_accuracy: 0.5263\n",
      "Epoch 584/1000\n",
      "177/177 [==============================] - 0s 129us/step - loss: 0.0657 - accuracy: 0.9774 - val_loss: 3.5077 - val_accuracy: 0.5263\n",
      "Epoch 585/1000\n",
      "177/177 [==============================] - 0s 149us/step - loss: 0.0373 - accuracy: 0.9887 - val_loss: 3.5775 - val_accuracy: 0.5000\n",
      "Epoch 586/1000\n",
      "177/177 [==============================] - 0s 199us/step - loss: 0.0808 - accuracy: 0.9774 - val_loss: 3.5201 - val_accuracy: 0.5263\n",
      "Epoch 587/1000\n",
      "177/177 [==============================] - 0s 140us/step - loss: 0.0519 - accuracy: 0.9831 - val_loss: 3.5081 - val_accuracy: 0.5263\n",
      "Epoch 588/1000\n",
      "177/177 [==============================] - 0s 123us/step - loss: 0.2110 - accuracy: 0.9718 - val_loss: 3.5426 - val_accuracy: 0.5263\n",
      "Epoch 589/1000\n",
      "177/177 [==============================] - 0s 131us/step - loss: 0.1296 - accuracy: 0.9718 - val_loss: 3.5595 - val_accuracy: 0.5132\n",
      "Epoch 590/1000\n",
      "177/177 [==============================] - 0s 127us/step - loss: 0.0695 - accuracy: 0.9774 - val_loss: 3.4976 - val_accuracy: 0.5263\n",
      "Epoch 591/1000\n",
      "177/177 [==============================] - 0s 133us/step - loss: 0.1014 - accuracy: 0.9774 - val_loss: 3.5561 - val_accuracy: 0.5263\n",
      "Epoch 592/1000\n",
      "177/177 [==============================] - 0s 161us/step - loss: 0.0313 - accuracy: 0.9887 - val_loss: 3.5925 - val_accuracy: 0.5395\n",
      "Epoch 593/1000\n",
      "177/177 [==============================] - 0s 126us/step - loss: 0.0805 - accuracy: 0.9831 - val_loss: 3.5614 - val_accuracy: 0.5132\n",
      "Epoch 594/1000\n",
      "177/177 [==============================] - 0s 140us/step - loss: 0.0283 - accuracy: 0.9887 - val_loss: 3.5334 - val_accuracy: 0.5263\n",
      "Epoch 595/1000\n",
      "177/177 [==============================] - 0s 132us/step - loss: 0.0294 - accuracy: 0.9887 - val_loss: 3.5265 - val_accuracy: 0.5263\n",
      "Epoch 596/1000\n",
      "177/177 [==============================] - 0s 93us/step - loss: 0.0303 - accuracy: 0.9887 - val_loss: 3.5381 - val_accuracy: 0.5263\n",
      "Epoch 597/1000\n",
      "177/177 [==============================] - 0s 89us/step - loss: 0.0286 - accuracy: 0.9887 - val_loss: 3.5501 - val_accuracy: 0.5263\n",
      "Epoch 598/1000\n",
      "177/177 [==============================] - 0s 118us/step - loss: 0.0278 - accuracy: 0.9831 - val_loss: 3.5689 - val_accuracy: 0.5263\n",
      "Epoch 599/1000\n",
      "177/177 [==============================] - 0s 119us/step - loss: 0.0275 - accuracy: 0.9887 - val_loss: 3.5772 - val_accuracy: 0.5132\n",
      "Epoch 600/1000\n",
      "177/177 [==============================] - 0s 100us/step - loss: 0.0289 - accuracy: 0.9887 - val_loss: 3.5625 - val_accuracy: 0.5395\n",
      "Epoch 601/1000\n",
      "177/177 [==============================] - 0s 107us/step - loss: 0.0288 - accuracy: 0.9887 - val_loss: 3.5628 - val_accuracy: 0.5263\n",
      "Epoch 602/1000\n",
      "177/177 [==============================] - 0s 124us/step - loss: 0.0275 - accuracy: 0.9831 - val_loss: 3.5754 - val_accuracy: 0.5263\n",
      "Epoch 603/1000\n",
      "177/177 [==============================] - 0s 162us/step - loss: 0.0290 - accuracy: 0.9887 - val_loss: 3.5865 - val_accuracy: 0.5263\n",
      "Epoch 604/1000\n",
      "177/177 [==============================] - 0s 118us/step - loss: 0.0276 - accuracy: 0.9887 - val_loss: 3.5674 - val_accuracy: 0.5263\n",
      "Epoch 605/1000\n",
      "177/177 [==============================] - 0s 131us/step - loss: 0.0272 - accuracy: 0.9831 - val_loss: 3.5738 - val_accuracy: 0.5263\n",
      "Epoch 606/1000\n",
      "177/177 [==============================] - 0s 109us/step - loss: 0.0260 - accuracy: 0.9887 - val_loss: 3.5741 - val_accuracy: 0.5263\n",
      "Epoch 607/1000\n",
      "177/177 [==============================] - 0s 124us/step - loss: 0.0263 - accuracy: 0.9887 - val_loss: 3.5734 - val_accuracy: 0.5263\n",
      "Epoch 608/1000\n",
      "177/177 [==============================] - ETA: 0s - loss: 0.0699 - accuracy: 0.96 - 0s 95us/step - loss: 0.0273 - accuracy: 0.9887 - val_loss: 3.5805 - val_accuracy: 0.5263\n",
      "Epoch 609/1000\n",
      "177/177 [==============================] - 0s 105us/step - loss: 0.0273 - accuracy: 0.9887 - val_loss: 3.5799 - val_accuracy: 0.5263\n",
      "Epoch 610/1000\n",
      "177/177 [==============================] - 0s 96us/step - loss: 0.0304 - accuracy: 0.9831 - val_loss: 3.5761 - val_accuracy: 0.5395\n",
      "Epoch 611/1000\n",
      "177/177 [==============================] - 0s 117us/step - loss: 0.0275 - accuracy: 0.9887 - val_loss: 3.5866 - val_accuracy: 0.5263\n",
      "Epoch 612/1000\n",
      "177/177 [==============================] - 0s 125us/step - loss: 0.0279 - accuracy: 0.9887 - val_loss: 3.5913 - val_accuracy: 0.5395\n",
      "Epoch 613/1000\n",
      "177/177 [==============================] - 0s 130us/step - loss: 0.0290 - accuracy: 0.9887 - val_loss: 3.6096 - val_accuracy: 0.5395\n",
      "Epoch 614/1000\n",
      "177/177 [==============================] - 0s 137us/step - loss: 0.0251 - accuracy: 0.9887 - val_loss: 3.5966 - val_accuracy: 0.5263\n",
      "Epoch 615/1000\n",
      "177/177 [==============================] - 0s 159us/step - loss: 0.0260 - accuracy: 0.9887 - val_loss: 3.5986 - val_accuracy: 0.5395\n",
      "Epoch 616/1000\n",
      "177/177 [==============================] - 0s 138us/step - loss: 0.0260 - accuracy: 0.9887 - val_loss: 3.5932 - val_accuracy: 0.5395\n",
      "Epoch 617/1000\n",
      "177/177 [==============================] - 0s 125us/step - loss: 0.0266 - accuracy: 0.9887 - val_loss: 3.5923 - val_accuracy: 0.5395\n",
      "Epoch 618/1000\n",
      "177/177 [==============================] - 0s 156us/step - loss: 0.0263 - accuracy: 0.9887 - val_loss: 3.6019 - val_accuracy: 0.5263\n",
      "Epoch 619/1000\n",
      "177/177 [==============================] - 0s 125us/step - loss: 0.0260 - accuracy: 0.9831 - val_loss: 3.6057 - val_accuracy: 0.5263\n",
      "Epoch 620/1000\n",
      "177/177 [==============================] - 0s 137us/step - loss: 0.0271 - accuracy: 0.9887 - val_loss: 3.6147 - val_accuracy: 0.5263\n",
      "Epoch 621/1000\n",
      "177/177 [==============================] - 0s 151us/step - loss: 0.0264 - accuracy: 0.9887 - val_loss: 3.5991 - val_accuracy: 0.5263\n",
      "Epoch 622/1000\n",
      "177/177 [==============================] - 0s 151us/step - loss: 0.0259 - accuracy: 0.9831 - val_loss: 3.5970 - val_accuracy: 0.5263\n",
      "Epoch 623/1000\n",
      "177/177 [==============================] - 0s 126us/step - loss: 0.0270 - accuracy: 0.9887 - val_loss: 3.5999 - val_accuracy: 0.5263\n",
      "Epoch 624/1000\n",
      "177/177 [==============================] - 0s 178us/step - loss: 0.0280 - accuracy: 0.9831 - val_loss: 3.6087 - val_accuracy: 0.5263\n",
      "Epoch 625/1000\n",
      "177/177 [==============================] - 0s 141us/step - loss: 0.0263 - accuracy: 0.9887 - val_loss: 3.6001 - val_accuracy: 0.5263\n",
      "Epoch 626/1000\n",
      "177/177 [==============================] - 0s 127us/step - loss: 0.0276 - accuracy: 0.9831 - val_loss: 3.5987 - val_accuracy: 0.5395\n",
      "Epoch 627/1000\n",
      "177/177 [==============================] - 0s 126us/step - loss: 0.0269 - accuracy: 0.9887 - val_loss: 3.6099 - val_accuracy: 0.5263\n",
      "Epoch 628/1000\n",
      "177/177 [==============================] - 0s 130us/step - loss: 0.0273 - accuracy: 0.9887 - val_loss: 3.6182 - val_accuracy: 0.5263\n",
      "Epoch 629/1000\n",
      "177/177 [==============================] - 0s 149us/step - loss: 0.0265 - accuracy: 0.9887 - val_loss: 3.6063 - val_accuracy: 0.5263\n",
      "Epoch 630/1000\n",
      "177/177 [==============================] - 0s 146us/step - loss: 0.0262 - accuracy: 0.9887 - val_loss: 3.6072 - val_accuracy: 0.5263\n",
      "Epoch 631/1000\n",
      "177/177 [==============================] - 0s 121us/step - loss: 0.0271 - accuracy: 0.9831 - val_loss: 3.6074 - val_accuracy: 0.5395\n",
      "Epoch 632/1000\n",
      "177/177 [==============================] - 0s 164us/step - loss: 0.0268 - accuracy: 0.9887 - val_loss: 3.6265 - val_accuracy: 0.5263\n",
      "Epoch 633/1000\n",
      "177/177 [==============================] - 0s 140us/step - loss: 0.0260 - accuracy: 0.9887 - val_loss: 3.6321 - val_accuracy: 0.5263\n",
      "Epoch 634/1000\n",
      "177/177 [==============================] - 0s 127us/step - loss: 0.0269 - accuracy: 0.9831 - val_loss: 3.6263 - val_accuracy: 0.5263\n",
      "Epoch 635/1000\n",
      "177/177 [==============================] - 0s 167us/step - loss: 0.0253 - accuracy: 0.9944 - val_loss: 3.6376 - val_accuracy: 0.5263\n",
      "Epoch 636/1000\n",
      "177/177 [==============================] - 0s 97us/step - loss: 0.0284 - accuracy: 0.9887 - val_loss: 3.6372 - val_accuracy: 0.5263\n",
      "Epoch 637/1000\n",
      "177/177 [==============================] - 0s 136us/step - loss: 0.0288 - accuracy: 0.9887 - val_loss: 3.6489 - val_accuracy: 0.5263\n",
      "Epoch 638/1000\n",
      "177/177 [==============================] - 0s 138us/step - loss: 0.0275 - accuracy: 0.9887 - val_loss: 3.6298 - val_accuracy: 0.5395\n",
      "Epoch 639/1000\n",
      "177/177 [==============================] - 0s 156us/step - loss: 0.0277 - accuracy: 0.9887 - val_loss: 3.6172 - val_accuracy: 0.5395\n",
      "Epoch 640/1000\n",
      "177/177 [==============================] - 0s 128us/step - loss: 0.0275 - accuracy: 0.9887 - val_loss: 3.6218 - val_accuracy: 0.5395\n",
      "Epoch 641/1000\n",
      "177/177 [==============================] - 0s 156us/step - loss: 0.0292 - accuracy: 0.9887 - val_loss: 3.6378 - val_accuracy: 0.5263\n",
      "Epoch 642/1000\n",
      "177/177 [==============================] - 0s 136us/step - loss: 0.0253 - accuracy: 0.9887 - val_loss: 3.6393 - val_accuracy: 0.5263\n",
      "Epoch 643/1000\n",
      "177/177 [==============================] - 0s 125us/step - loss: 0.0271 - accuracy: 0.9831 - val_loss: 3.6262 - val_accuracy: 0.5263\n",
      "Epoch 644/1000\n",
      "177/177 [==============================] - 0s 172us/step - loss: 0.0260 - accuracy: 0.9887 - val_loss: 3.6384 - val_accuracy: 0.5263\n",
      "Epoch 645/1000\n",
      "177/177 [==============================] - 0s 118us/step - loss: 0.0263 - accuracy: 0.9887 - val_loss: 3.6400 - val_accuracy: 0.5263\n",
      "Epoch 646/1000\n",
      "177/177 [==============================] - 0s 153us/step - loss: 0.0254 - accuracy: 0.9887 - val_loss: 3.6477 - val_accuracy: 0.5263\n",
      "Epoch 647/1000\n",
      "177/177 [==============================] - 0s 143us/step - loss: 0.0272 - accuracy: 0.9887 - val_loss: 3.6458 - val_accuracy: 0.5263\n",
      "Epoch 648/1000\n",
      "177/177 [==============================] - 0s 113us/step - loss: 0.0246 - accuracy: 0.9887 - val_loss: 3.6338 - val_accuracy: 0.5263\n",
      "Epoch 649/1000\n",
      "177/177 [==============================] - 0s 92us/step - loss: 0.0259 - accuracy: 0.9887 - val_loss: 3.6321 - val_accuracy: 0.5395\n",
      "Epoch 650/1000\n",
      "177/177 [==============================] - 0s 96us/step - loss: 0.0274 - accuracy: 0.9887 - val_loss: 3.6317 - val_accuracy: 0.5395\n",
      "Epoch 651/1000\n",
      "177/177 [==============================] - 0s 100us/step - loss: 0.0288 - accuracy: 0.9831 - val_loss: 3.6516 - val_accuracy: 0.5263\n",
      "Epoch 652/1000\n",
      "177/177 [==============================] - 0s 139us/step - loss: 0.0250 - accuracy: 0.9887 - val_loss: 3.6463 - val_accuracy: 0.5263\n",
      "Epoch 653/1000\n",
      "177/177 [==============================] - 0s 130us/step - loss: 0.0245 - accuracy: 0.9887 - val_loss: 3.6387 - val_accuracy: 0.5263\n",
      "Epoch 654/1000\n",
      "177/177 [==============================] - 0s 161us/step - loss: 0.0264 - accuracy: 0.9887 - val_loss: 3.6298 - val_accuracy: 0.5395\n",
      "Epoch 655/1000\n",
      "177/177 [==============================] - 0s 126us/step - loss: 0.0302 - accuracy: 0.9887 - val_loss: 3.6295 - val_accuracy: 0.5395\n",
      "Epoch 656/1000\n",
      "177/177 [==============================] - 0s 113us/step - loss: 0.0246 - accuracy: 0.9887 - val_loss: 3.6621 - val_accuracy: 0.5395\n",
      "Epoch 657/1000\n",
      "177/177 [==============================] - 0s 153us/step - loss: 0.0291 - accuracy: 0.9887 - val_loss: 3.6776 - val_accuracy: 0.5526\n",
      "Epoch 658/1000\n",
      "177/177 [==============================] - 0s 126us/step - loss: 0.0314 - accuracy: 0.9887 - val_loss: 3.6712 - val_accuracy: 0.5395\n",
      "Epoch 659/1000\n",
      "177/177 [==============================] - 0s 129us/step - loss: 0.0254 - accuracy: 0.9887 - val_loss: 3.6489 - val_accuracy: 0.5263\n",
      "Epoch 660/1000\n",
      "177/177 [==============================] - 0s 137us/step - loss: 0.0286 - accuracy: 0.9831 - val_loss: 3.6361 - val_accuracy: 0.5263\n",
      "Epoch 661/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177/177 [==============================] - 0s 128us/step - loss: 0.0291 - accuracy: 0.9887 - val_loss: 3.6429 - val_accuracy: 0.5395\n",
      "Epoch 662/1000\n",
      "177/177 [==============================] - 0s 110us/step - loss: 0.0278 - accuracy: 0.9887 - val_loss: 3.6466 - val_accuracy: 0.5263\n",
      "Epoch 663/1000\n",
      "177/177 [==============================] - 0s 114us/step - loss: 0.0264 - accuracy: 0.9831 - val_loss: 3.6505 - val_accuracy: 0.5263\n",
      "Epoch 664/1000\n",
      "177/177 [==============================] - 0s 115us/step - loss: 0.0269 - accuracy: 0.9831 - val_loss: 3.6490 - val_accuracy: 0.5263\n",
      "Epoch 665/1000\n",
      "177/177 [==============================] - 0s 127us/step - loss: 0.0246 - accuracy: 0.9887 - val_loss: 3.6484 - val_accuracy: 0.5263\n",
      "Epoch 666/1000\n",
      "177/177 [==============================] - 0s 114us/step - loss: 0.0271 - accuracy: 0.9887 - val_loss: 3.6555 - val_accuracy: 0.5263\n",
      "Epoch 667/1000\n",
      "177/177 [==============================] - 0s 129us/step - loss: 0.0257 - accuracy: 0.9887 - val_loss: 3.6527 - val_accuracy: 0.5263\n",
      "Epoch 668/1000\n",
      "177/177 [==============================] - 0s 138us/step - loss: 0.0248 - accuracy: 0.9887 - val_loss: 3.6448 - val_accuracy: 0.5263\n",
      "Epoch 669/1000\n",
      "177/177 [==============================] - 0s 119us/step - loss: 0.0274 - accuracy: 0.9831 - val_loss: 3.6554 - val_accuracy: 0.5263\n",
      "Epoch 670/1000\n",
      "177/177 [==============================] - 0s 137us/step - loss: 0.0262 - accuracy: 0.9831 - val_loss: 3.6728 - val_accuracy: 0.5263\n",
      "Epoch 671/1000\n",
      "177/177 [==============================] - 0s 109us/step - loss: 0.0251 - accuracy: 0.9887 - val_loss: 3.6723 - val_accuracy: 0.5263\n",
      "Epoch 672/1000\n",
      "177/177 [==============================] - 0s 130us/step - loss: 0.0256 - accuracy: 0.9831 - val_loss: 3.6765 - val_accuracy: 0.5263\n",
      "Epoch 673/1000\n",
      "177/177 [==============================] - 0s 143us/step - loss: 0.0263 - accuracy: 0.9831 - val_loss: 3.6709 - val_accuracy: 0.5263\n",
      "Epoch 674/1000\n",
      "177/177 [==============================] - 0s 108us/step - loss: 0.0264 - accuracy: 0.9887 - val_loss: 3.6768 - val_accuracy: 0.5263\n",
      "Epoch 675/1000\n",
      "177/177 [==============================] - 0s 107us/step - loss: 0.0262 - accuracy: 0.9887 - val_loss: 3.6712 - val_accuracy: 0.5395\n",
      "Epoch 676/1000\n",
      "177/177 [==============================] - 0s 131us/step - loss: 0.0277 - accuracy: 0.9887 - val_loss: 3.6695 - val_accuracy: 0.5263\n",
      "Epoch 677/1000\n",
      "177/177 [==============================] - 0s 147us/step - loss: 0.0266 - accuracy: 0.9887 - val_loss: 3.6682 - val_accuracy: 0.5395\n",
      "Epoch 678/1000\n",
      "177/177 [==============================] - 0s 148us/step - loss: 0.0267 - accuracy: 0.9831 - val_loss: 3.6875 - val_accuracy: 0.5263\n",
      "Epoch 679/1000\n",
      "177/177 [==============================] - 0s 124us/step - loss: 0.0277 - accuracy: 0.9887 - val_loss: 3.6943 - val_accuracy: 0.5263\n",
      "Epoch 680/1000\n",
      "177/177 [==============================] - 0s 109us/step - loss: 0.0262 - accuracy: 0.9887 - val_loss: 3.6716 - val_accuracy: 0.5395\n",
      "Epoch 681/1000\n",
      "177/177 [==============================] - 0s 133us/step - loss: 0.0303 - accuracy: 0.9887 - val_loss: 3.6707 - val_accuracy: 0.5395\n",
      "Epoch 682/1000\n",
      "177/177 [==============================] - 0s 128us/step - loss: 0.0250 - accuracy: 0.9887 - val_loss: 3.6892 - val_accuracy: 0.5263\n",
      "Epoch 683/1000\n",
      "177/177 [==============================] - 0s 133us/step - loss: 0.0228 - accuracy: 0.9944 - val_loss: 3.7101 - val_accuracy: 0.5395\n",
      "Epoch 684/1000\n",
      "177/177 [==============================] - 0s 162us/step - loss: 0.0303 - accuracy: 0.9887 - val_loss: 3.7202 - val_accuracy: 0.5395\n",
      "Epoch 685/1000\n",
      "177/177 [==============================] - 0s 114us/step - loss: 0.0300 - accuracy: 0.9887 - val_loss: 3.6851 - val_accuracy: 0.5263\n",
      "Epoch 686/1000\n",
      "177/177 [==============================] - 0s 144us/step - loss: 0.0273 - accuracy: 0.9831 - val_loss: 3.6804 - val_accuracy: 0.5395\n",
      "Epoch 687/1000\n",
      "177/177 [==============================] - 0s 108us/step - loss: 0.0288 - accuracy: 0.9887 - val_loss: 3.6778 - val_accuracy: 0.5395\n",
      "Epoch 688/1000\n",
      "177/177 [==============================] - 0s 133us/step - loss: 0.0242 - accuracy: 0.9887 - val_loss: 3.7080 - val_accuracy: 0.5263\n",
      "Epoch 689/1000\n",
      "177/177 [==============================] - 0s 125us/step - loss: 0.0330 - accuracy: 0.9887 - val_loss: 3.7040 - val_accuracy: 0.5395\n",
      "Epoch 690/1000\n",
      "177/177 [==============================] - 0s 140us/step - loss: 0.0273 - accuracy: 0.9887 - val_loss: 3.7060 - val_accuracy: 0.5263\n",
      "Epoch 691/1000\n",
      "177/177 [==============================] - 0s 119us/step - loss: 0.0288 - accuracy: 0.9887 - val_loss: 3.6932 - val_accuracy: 0.5395\n",
      "Epoch 692/1000\n",
      "177/177 [==============================] - 0s 117us/step - loss: 0.0262 - accuracy: 0.9887 - val_loss: 3.6860 - val_accuracy: 0.5395\n",
      "Epoch 693/1000\n",
      "177/177 [==============================] - 0s 129us/step - loss: 0.0276 - accuracy: 0.9831 - val_loss: 3.6931 - val_accuracy: 0.5263\n",
      "Epoch 694/1000\n",
      "177/177 [==============================] - 0s 106us/step - loss: 0.0262 - accuracy: 0.9887 - val_loss: 3.6943 - val_accuracy: 0.5263\n",
      "Epoch 695/1000\n",
      "177/177 [==============================] - 0s 156us/step - loss: 0.0270 - accuracy: 0.9887 - val_loss: 3.7033 - val_accuracy: 0.5263\n",
      "Epoch 696/1000\n",
      "177/177 [==============================] - 0s 153us/step - loss: 0.0248 - accuracy: 0.9887 - val_loss: 3.6935 - val_accuracy: 0.5263\n",
      "Epoch 697/1000\n",
      "177/177 [==============================] - 0s 124us/step - loss: 0.0244 - accuracy: 0.9887 - val_loss: 3.6901 - val_accuracy: 0.5395\n",
      "Epoch 698/1000\n",
      "177/177 [==============================] - 0s 135us/step - loss: 0.0259 - accuracy: 0.9887 - val_loss: 3.6897 - val_accuracy: 0.5263\n",
      "Epoch 699/1000\n",
      "177/177 [==============================] - 0s 111us/step - loss: 0.0261 - accuracy: 0.9831 - val_loss: 3.6964 - val_accuracy: 0.5263\n",
      "Epoch 700/1000\n",
      "177/177 [==============================] - 0s 129us/step - loss: 0.0260 - accuracy: 0.9887 - val_loss: 3.6951 - val_accuracy: 0.5395\n",
      "Epoch 701/1000\n",
      "177/177 [==============================] - 0s 144us/step - loss: 0.0255 - accuracy: 0.9887 - val_loss: 3.7013 - val_accuracy: 0.5395\n",
      "Epoch 702/1000\n",
      "177/177 [==============================] - 0s 105us/step - loss: 0.0267 - accuracy: 0.9887 - val_loss: 3.6972 - val_accuracy: 0.5263\n",
      "Epoch 703/1000\n",
      "177/177 [==============================] - 0s 143us/step - loss: 0.0254 - accuracy: 0.9887 - val_loss: 3.6999 - val_accuracy: 0.5263\n",
      "Epoch 704/1000\n",
      "177/177 [==============================] - 0s 120us/step - loss: 0.0270 - accuracy: 0.9887 - val_loss: 3.7055 - val_accuracy: 0.5263\n",
      "Epoch 705/1000\n",
      "177/177 [==============================] - 0s 96us/step - loss: 0.0272 - accuracy: 0.9887 - val_loss: 3.7019 - val_accuracy: 0.5263\n",
      "Epoch 706/1000\n",
      "177/177 [==============================] - 0s 104us/step - loss: 0.0326 - accuracy: 0.9831 - val_loss: 3.6907 - val_accuracy: 0.5395\n",
      "Epoch 707/1000\n",
      "177/177 [==============================] - 0s 124us/step - loss: 0.0257 - accuracy: 0.9887 - val_loss: 3.7049 - val_accuracy: 0.5263\n",
      "Epoch 708/1000\n",
      "177/177 [==============================] - 0s 104us/step - loss: 0.0249 - accuracy: 0.9887 - val_loss: 3.7327 - val_accuracy: 0.5263\n",
      "Epoch 709/1000\n",
      "177/177 [==============================] - 0s 160us/step - loss: 0.0257 - accuracy: 0.9887 - val_loss: 3.7244 - val_accuracy: 0.5263\n",
      "Epoch 710/1000\n",
      "177/177 [==============================] - 0s 156us/step - loss: 0.0249 - accuracy: 0.9887 - val_loss: 3.7139 - val_accuracy: 0.5263\n",
      "Epoch 711/1000\n",
      "177/177 [==============================] - 0s 108us/step - loss: 0.0262 - accuracy: 0.9887 - val_loss: 3.7155 - val_accuracy: 0.5263\n",
      "Epoch 712/1000\n",
      "177/177 [==============================] - 0s 123us/step - loss: 0.0235 - accuracy: 0.9887 - val_loss: 3.7458 - val_accuracy: 0.5263\n",
      "Epoch 713/1000\n",
      "177/177 [==============================] - 0s 145us/step - loss: 0.0267 - accuracy: 0.9887 - val_loss: 3.7347 - val_accuracy: 0.5263\n",
      "Epoch 714/1000\n",
      "177/177 [==============================] - 0s 128us/step - loss: 0.0296 - accuracy: 0.9887 - val_loss: 3.7179 - val_accuracy: 0.5263\n",
      "Epoch 715/1000\n",
      "177/177 [==============================] - 0s 117us/step - loss: 0.0262 - accuracy: 0.9831 - val_loss: 3.7421 - val_accuracy: 0.5263\n",
      "Epoch 716/1000\n",
      "177/177 [==============================] - 0s 112us/step - loss: 0.0252 - accuracy: 0.9831 - val_loss: 3.7280 - val_accuracy: 0.5263\n",
      "Epoch 717/1000\n",
      "177/177 [==============================] - 0s 121us/step - loss: 0.0293 - accuracy: 0.9887 - val_loss: 3.7187 - val_accuracy: 0.5395\n",
      "Epoch 718/1000\n",
      "177/177 [==============================] - 0s 106us/step - loss: 0.0233 - accuracy: 0.9887 - val_loss: 3.7523 - val_accuracy: 0.5263\n",
      "Epoch 719/1000\n",
      "177/177 [==============================] - 0s 142us/step - loss: 0.0289 - accuracy: 0.9774 - val_loss: 3.7348 - val_accuracy: 0.5263\n",
      "Epoch 720/1000\n",
      "177/177 [==============================] - 0s 164us/step - loss: 0.0295 - accuracy: 0.9887 - val_loss: 3.7239 - val_accuracy: 0.5263\n",
      "Epoch 721/1000\n",
      "177/177 [==============================] - 0s 113us/step - loss: 0.0254 - accuracy: 0.9887 - val_loss: 3.7239 - val_accuracy: 0.5263\n",
      "Epoch 722/1000\n",
      "177/177 [==============================] - 0s 115us/step - loss: 0.0549 - accuracy: 0.9831 - val_loss: 3.7201 - val_accuracy: 0.5263\n",
      "Epoch 723/1000\n",
      "177/177 [==============================] - 0s 125us/step - loss: 0.1344 - accuracy: 0.9831 - val_loss: 3.7739 - val_accuracy: 0.5000\n",
      "Epoch 724/1000\n",
      "177/177 [==============================] - 0s 101us/step - loss: 0.0455 - accuracy: 0.9718 - val_loss: 3.6895 - val_accuracy: 0.5263\n",
      "Epoch 725/1000\n",
      "177/177 [==============================] - 0s 107us/step - loss: 0.0499 - accuracy: 0.9831 - val_loss: 3.7531 - val_accuracy: 0.5263\n",
      "Epoch 726/1000\n",
      "177/177 [==============================] - 0s 140us/step - loss: 0.0341 - accuracy: 0.9774 - val_loss: 3.7453 - val_accuracy: 0.5263\n",
      "Epoch 727/1000\n",
      "177/177 [==============================] - 0s 214us/step - loss: 0.1005 - accuracy: 0.9831 - val_loss: 3.7116 - val_accuracy: 0.5263\n",
      "Epoch 728/1000\n",
      "177/177 [==============================] - 0s 171us/step - loss: 0.0420 - accuracy: 0.9831 - val_loss: 3.7057 - val_accuracy: 0.5395\n",
      "Epoch 729/1000\n",
      "177/177 [==============================] - 0s 173us/step - loss: 0.0373 - accuracy: 0.9831 - val_loss: 3.7314 - val_accuracy: 0.5263\n",
      "Epoch 730/1000\n",
      "177/177 [==============================] - 0s 147us/step - loss: 0.1875 - accuracy: 0.9605 - val_loss: 3.7709 - val_accuracy: 0.5395\n",
      "Epoch 731/1000\n",
      "177/177 [==============================] - 0s 156us/step - loss: 0.1184 - accuracy: 0.9831 - val_loss: 3.7303 - val_accuracy: 0.5263\n",
      "Epoch 732/1000\n",
      "177/177 [==============================] - 0s 111us/step - loss: 0.1007 - accuracy: 0.9831 - val_loss: 3.8049 - val_accuracy: 0.5000\n",
      "Epoch 733/1000\n",
      "177/177 [==============================] - 0s 134us/step - loss: 0.2259 - accuracy: 0.9718 - val_loss: 3.8120 - val_accuracy: 0.5000\n",
      "Epoch 734/1000\n",
      "177/177 [==============================] - 0s 148us/step - loss: 0.0511 - accuracy: 0.9774 - val_loss: 3.7273 - val_accuracy: 0.5395\n",
      "Epoch 735/1000\n",
      "177/177 [==============================] - 0s 125us/step - loss: 0.1149 - accuracy: 0.9718 - val_loss: 3.7746 - val_accuracy: 0.5395\n",
      "Epoch 736/1000\n",
      "177/177 [==============================] - 0s 109us/step - loss: 0.1009 - accuracy: 0.9718 - val_loss: 3.7676 - val_accuracy: 0.5132\n",
      "Epoch 737/1000\n",
      "177/177 [==============================] - 0s 119us/step - loss: 0.1265 - accuracy: 0.9831 - val_loss: 3.7430 - val_accuracy: 0.5263\n",
      "Epoch 738/1000\n",
      "177/177 [==============================] - 0s 112us/step - loss: 0.0301 - accuracy: 0.9887 - val_loss: 3.7913 - val_accuracy: 0.5132\n",
      "Epoch 739/1000\n",
      "177/177 [==============================] - 0s 123us/step - loss: 0.1401 - accuracy: 0.9774 - val_loss: 3.7804 - val_accuracy: 0.5263\n",
      "Epoch 740/1000\n",
      "177/177 [==============================] - 0s 138us/step - loss: 0.2246 - accuracy: 0.9774 - val_loss: 3.7963 - val_accuracy: 0.5000\n",
      "Epoch 741/1000\n",
      "177/177 [==============================] - 0s 145us/step - loss: 0.2555 - accuracy: 0.9492 - val_loss: 3.8349 - val_accuracy: 0.5263\n",
      "Epoch 742/1000\n",
      "177/177 [==============================] - 0s 121us/step - loss: 0.3319 - accuracy: 0.9661 - val_loss: 3.7244 - val_accuracy: 0.5000\n",
      "Epoch 743/1000\n",
      "177/177 [==============================] - 0s 109us/step - loss: 0.2231 - accuracy: 0.9605 - val_loss: 3.8183 - val_accuracy: 0.5000\n",
      "Epoch 744/1000\n",
      "177/177 [==============================] - 0s 189us/step - loss: 0.3180 - accuracy: 0.9605 - val_loss: 3.7287 - val_accuracy: 0.5132\n",
      "Epoch 745/1000\n",
      "177/177 [==============================] - 0s 123us/step - loss: 0.0428 - accuracy: 0.9831 - val_loss: 3.8469 - val_accuracy: 0.5263\n",
      "Epoch 746/1000\n",
      "177/177 [==============================] - 0s 111us/step - loss: 0.2761 - accuracy: 0.9718 - val_loss: 3.8365 - val_accuracy: 0.5000\n",
      "Epoch 747/1000\n",
      "177/177 [==============================] - 0s 165us/step - loss: 0.0436 - accuracy: 0.9718 - val_loss: 3.7822 - val_accuracy: 0.5263\n",
      "Epoch 748/1000\n",
      "177/177 [==============================] - 0s 133us/step - loss: 0.0486 - accuracy: 0.9831 - val_loss: 3.8050 - val_accuracy: 0.5263\n",
      "Epoch 749/1000\n",
      "177/177 [==============================] - 0s 128us/step - loss: 0.0970 - accuracy: 0.9831 - val_loss: 3.7708 - val_accuracy: 0.5263\n",
      "Epoch 750/1000\n",
      "177/177 [==============================] - 0s 123us/step - loss: 0.0285 - accuracy: 0.9887 - val_loss: 3.7705 - val_accuracy: 0.5263\n",
      "Epoch 751/1000\n",
      "177/177 [==============================] - 0s 111us/step - loss: 0.0346 - accuracy: 0.9831 - val_loss: 3.7872 - val_accuracy: 0.5263\n",
      "Epoch 752/1000\n",
      "177/177 [==============================] - 0s 201us/step - loss: 0.0646 - accuracy: 0.9831 - val_loss: 3.7793 - val_accuracy: 0.5263\n",
      "Epoch 753/1000\n",
      "177/177 [==============================] - 0s 110us/step - loss: 0.0267 - accuracy: 0.9887 - val_loss: 3.7793 - val_accuracy: 0.5263\n",
      "Epoch 754/1000\n",
      "177/177 [==============================] - 0s 122us/step - loss: 0.0835 - accuracy: 0.9831 - val_loss: 3.8206 - val_accuracy: 0.5000\n",
      "Epoch 755/1000\n",
      "177/177 [==============================] - 0s 163us/step - loss: 0.1095 - accuracy: 0.9718 - val_loss: 3.7846 - val_accuracy: 0.5263\n",
      "Epoch 756/1000\n",
      "177/177 [==============================] - 0s 123us/step - loss: 0.0296 - accuracy: 0.9944 - val_loss: 3.7537 - val_accuracy: 0.5132\n",
      "Epoch 757/1000\n",
      "177/177 [==============================] - 0s 121us/step - loss: 0.1046 - accuracy: 0.9718 - val_loss: 3.7952 - val_accuracy: 0.5132\n",
      "Epoch 758/1000\n",
      "177/177 [==============================] - 0s 125us/step - loss: 0.0285 - accuracy: 0.9887 - val_loss: 3.7743 - val_accuracy: 0.5263\n",
      "Epoch 759/1000\n",
      "177/177 [==============================] - 0s 171us/step - loss: 0.0369 - accuracy: 0.9887 - val_loss: 3.7690 - val_accuracy: 0.5263\n",
      "Epoch 760/1000\n",
      "177/177 [==============================] - 0s 116us/step - loss: 0.0839 - accuracy: 0.9831 - val_loss: 3.8019 - val_accuracy: 0.5263\n",
      "Epoch 761/1000\n",
      "177/177 [==============================] - 0s 114us/step - loss: 0.0501 - accuracy: 0.9774 - val_loss: 3.7854 - val_accuracy: 0.5263\n",
      "Epoch 762/1000\n",
      "177/177 [==============================] - 0s 135us/step - loss: 0.0698 - accuracy: 0.9774 - val_loss: 3.8081 - val_accuracy: 0.5132\n",
      "Epoch 763/1000\n",
      "177/177 [==============================] - 0s 106us/step - loss: 0.1032 - accuracy: 0.9661 - val_loss: 3.7957 - val_accuracy: 0.5263\n",
      "Epoch 764/1000\n",
      "177/177 [==============================] - 0s 115us/step - loss: 0.0273 - accuracy: 0.9887 - val_loss: 3.7839 - val_accuracy: 0.5263\n",
      "Epoch 765/1000\n",
      "177/177 [==============================] - 0s 139us/step - loss: 0.0386 - accuracy: 0.9774 - val_loss: 3.8242 - val_accuracy: 0.5132\n",
      "Epoch 766/1000\n",
      "177/177 [==============================] - 0s 116us/step - loss: 0.1261 - accuracy: 0.9774 - val_loss: 3.8053 - val_accuracy: 0.5263\n",
      "Epoch 767/1000\n",
      "177/177 [==============================] - 0s 130us/step - loss: 0.0420 - accuracy: 0.9831 - val_loss: 3.7884 - val_accuracy: 0.5263\n",
      "Epoch 768/1000\n",
      "177/177 [==============================] - 0s 128us/step - loss: 0.0303 - accuracy: 0.9887 - val_loss: 3.8021 - val_accuracy: 0.5263\n",
      "Epoch 769/1000\n",
      "177/177 [==============================] - 0s 110us/step - loss: 0.0265 - accuracy: 0.9831 - val_loss: 3.8103 - val_accuracy: 0.5263\n",
      "Epoch 770/1000\n",
      "177/177 [==============================] - 0s 121us/step - loss: 0.0254 - accuracy: 0.9887 - val_loss: 3.8082 - val_accuracy: 0.5263\n",
      "Epoch 771/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177/177 [==============================] - 0s 116us/step - loss: 0.0254 - accuracy: 0.9887 - val_loss: 3.8066 - val_accuracy: 0.5263\n",
      "Epoch 772/1000\n",
      "177/177 [==============================] - 0s 118us/step - loss: 0.0255 - accuracy: 0.9887 - val_loss: 3.8078 - val_accuracy: 0.5263\n",
      "Epoch 773/1000\n",
      "177/177 [==============================] - 0s 112us/step - loss: 0.0248 - accuracy: 0.9831 - val_loss: 3.8142 - val_accuracy: 0.5263\n",
      "Epoch 774/1000\n",
      "177/177 [==============================] - 0s 124us/step - loss: 0.0265 - accuracy: 0.9887 - val_loss: 3.8059 - val_accuracy: 0.5263\n",
      "Epoch 775/1000\n",
      "177/177 [==============================] - 0s 139us/step - loss: 0.0270 - accuracy: 0.9887 - val_loss: 3.8162 - val_accuracy: 0.5263\n",
      "Epoch 776/1000\n",
      "177/177 [==============================] - 0s 123us/step - loss: 0.0253 - accuracy: 0.9887 - val_loss: 3.8058 - val_accuracy: 0.5263\n",
      "Epoch 777/1000\n",
      "177/177 [==============================] - 0s 118us/step - loss: 0.0253 - accuracy: 0.9887 - val_loss: 3.8019 - val_accuracy: 0.5263\n",
      "Epoch 778/1000\n",
      "177/177 [==============================] - 0s 119us/step - loss: 0.0260 - accuracy: 0.9887 - val_loss: 3.8035 - val_accuracy: 0.5263\n",
      "Epoch 779/1000\n",
      "177/177 [==============================] - 0s 162us/step - loss: 0.0233 - accuracy: 0.9887 - val_loss: 3.8177 - val_accuracy: 0.5263\n",
      "Epoch 780/1000\n",
      "177/177 [==============================] - 0s 120us/step - loss: 0.0311 - accuracy: 0.9887 - val_loss: 3.8033 - val_accuracy: 0.5263\n",
      "Epoch 781/1000\n",
      "177/177 [==============================] - 0s 129us/step - loss: 0.0332 - accuracy: 0.9831 - val_loss: 3.7732 - val_accuracy: 0.5263\n",
      "Epoch 782/1000\n",
      "177/177 [==============================] - 0s 151us/step - loss: 0.0317 - accuracy: 0.9887 - val_loss: 3.7958 - val_accuracy: 0.5263\n",
      "Epoch 783/1000\n",
      "177/177 [==============================] - 0s 115us/step - loss: 0.0472 - accuracy: 0.9831 - val_loss: 3.7967 - val_accuracy: 0.5263\n",
      "Epoch 784/1000\n",
      "177/177 [==============================] - 0s 117us/step - loss: 0.0647 - accuracy: 0.9774 - val_loss: 3.8333 - val_accuracy: 0.5000\n",
      "Epoch 785/1000\n",
      "177/177 [==============================] - 0s 144us/step - loss: 0.3096 - accuracy: 0.9605 - val_loss: 3.8993 - val_accuracy: 0.5000\n",
      "Epoch 786/1000\n",
      "177/177 [==============================] - 0s 123us/step - loss: 0.0972 - accuracy: 0.9718 - val_loss: 3.7659 - val_accuracy: 0.5395\n",
      "Epoch 787/1000\n",
      "177/177 [==============================] - 0s 131us/step - loss: 0.3673 - accuracy: 0.9548 - val_loss: 3.9071 - val_accuracy: 0.5000\n",
      "Epoch 788/1000\n",
      "177/177 [==============================] - 0s 136us/step - loss: 0.1019 - accuracy: 0.9774 - val_loss: 3.7835 - val_accuracy: 0.5263\n",
      "Epoch 789/1000\n",
      "177/177 [==============================] - 0s 122us/step - loss: 0.1928 - accuracy: 0.9718 - val_loss: 3.7957 - val_accuracy: 0.5263\n",
      "Epoch 790/1000\n",
      "177/177 [==============================] - 0s 175us/step - loss: 0.0445 - accuracy: 0.9774 - val_loss: 3.8146 - val_accuracy: 0.5263\n",
      "Epoch 791/1000\n",
      "177/177 [==============================] - 0s 187us/step - loss: 0.0278 - accuracy: 0.9887 - val_loss: 3.7989 - val_accuracy: 0.5263\n",
      "Epoch 792/1000\n",
      "177/177 [==============================] - 0s 166us/step - loss: 0.0393 - accuracy: 0.9887 - val_loss: 3.8242 - val_accuracy: 0.5263\n",
      "Epoch 793/1000\n",
      "177/177 [==============================] - 0s 206us/step - loss: 0.0296 - accuracy: 0.9887 - val_loss: 3.8460 - val_accuracy: 0.5263\n",
      "Epoch 794/1000\n",
      "177/177 [==============================] - 0s 171us/step - loss: 0.0257 - accuracy: 0.9944 - val_loss: 3.8576 - val_accuracy: 0.5263\n",
      "Epoch 795/1000\n",
      "177/177 [==============================] - 0s 362us/step - loss: 0.0279 - accuracy: 0.9887 - val_loss: 3.8570 - val_accuracy: 0.5263\n",
      "Epoch 796/1000\n",
      "177/177 [==============================] - 0s 122us/step - loss: 0.0248 - accuracy: 0.9887 - val_loss: 3.8509 - val_accuracy: 0.5263\n",
      "Epoch 797/1000\n",
      "177/177 [==============================] - 0s 137us/step - loss: 0.0267 - accuracy: 0.9887 - val_loss: 3.8483 - val_accuracy: 0.5263\n",
      "Epoch 798/1000\n",
      "177/177 [==============================] - 0s 166us/step - loss: 0.0280 - accuracy: 0.9887 - val_loss: 3.8631 - val_accuracy: 0.5263\n",
      "Epoch 799/1000\n",
      "177/177 [==============================] - 0s 161us/step - loss: 0.0261 - accuracy: 0.9887 - val_loss: 3.8607 - val_accuracy: 0.5263\n",
      "Epoch 800/1000\n",
      "177/177 [==============================] - 0s 179us/step - loss: 0.0263 - accuracy: 0.9887 - val_loss: 3.8566 - val_accuracy: 0.5263\n",
      "Epoch 801/1000\n",
      "177/177 [==============================] - 0s 180us/step - loss: 0.0254 - accuracy: 0.9887 - val_loss: 3.8620 - val_accuracy: 0.5263\n",
      "Epoch 802/1000\n",
      "177/177 [==============================] - 0s 111us/step - loss: 0.0246 - accuracy: 0.9887 - val_loss: 3.8616 - val_accuracy: 0.5263\n",
      "Epoch 803/1000\n",
      "177/177 [==============================] - 0s 136us/step - loss: 0.0259 - accuracy: 0.9887 - val_loss: 3.8662 - val_accuracy: 0.5263\n",
      "Epoch 804/1000\n",
      "177/177 [==============================] - 0s 101us/step - loss: 0.0275 - accuracy: 0.9831 - val_loss: 3.8648 - val_accuracy: 0.5263\n",
      "Epoch 805/1000\n",
      "177/177 [==============================] - 0s 125us/step - loss: 0.0297 - accuracy: 0.9831 - val_loss: 3.8747 - val_accuracy: 0.5263\n",
      "Epoch 806/1000\n",
      "177/177 [==============================] - 0s 130us/step - loss: 0.0276 - accuracy: 0.9887 - val_loss: 3.8634 - val_accuracy: 0.5263\n",
      "Epoch 807/1000\n",
      "177/177 [==============================] - 0s 226us/step - loss: 0.0265 - accuracy: 0.9831 - val_loss: 3.8795 - val_accuracy: 0.5263\n",
      "Epoch 808/1000\n",
      "177/177 [==============================] - 0s 229us/step - loss: 0.0280 - accuracy: 0.9887 - val_loss: 3.8776 - val_accuracy: 0.5263\n",
      "Epoch 809/1000\n",
      "177/177 [==============================] - 0s 133us/step - loss: 0.0296 - accuracy: 0.9831 - val_loss: 3.8710 - val_accuracy: 0.5263\n",
      "Epoch 810/1000\n",
      "177/177 [==============================] - 0s 145us/step - loss: 0.0288 - accuracy: 0.9831 - val_loss: 3.8773 - val_accuracy: 0.5263\n",
      "Epoch 811/1000\n",
      "177/177 [==============================] - 0s 190us/step - loss: 0.0252 - accuracy: 0.9887 - val_loss: 3.8797 - val_accuracy: 0.5263\n",
      "Epoch 812/1000\n",
      "177/177 [==============================] - 0s 141us/step - loss: 0.0252 - accuracy: 0.9831 - val_loss: 3.8857 - val_accuracy: 0.5263\n",
      "Epoch 813/1000\n",
      "177/177 [==============================] - 0s 155us/step - loss: 0.0256 - accuracy: 0.9831 - val_loss: 3.8785 - val_accuracy: 0.5263\n",
      "Epoch 814/1000\n",
      "177/177 [==============================] - 0s 162us/step - loss: 0.0260 - accuracy: 0.9831 - val_loss: 3.8858 - val_accuracy: 0.5263\n",
      "Epoch 815/1000\n",
      "177/177 [==============================] - 0s 219us/step - loss: 0.0275 - accuracy: 0.9887 - val_loss: 3.8715 - val_accuracy: 0.5263\n",
      "Epoch 816/1000\n",
      "177/177 [==============================] - 0s 169us/step - loss: 0.0245 - accuracy: 0.9831 - val_loss: 3.8839 - val_accuracy: 0.5263\n",
      "Epoch 817/1000\n",
      "177/177 [==============================] - 0s 220us/step - loss: 0.0276 - accuracy: 0.9887 - val_loss: 3.8866 - val_accuracy: 0.5263\n",
      "Epoch 818/1000\n",
      "177/177 [==============================] - 0s 317us/step - loss: 0.0303 - accuracy: 0.9831 - val_loss: 3.8985 - val_accuracy: 0.5263\n",
      "Epoch 819/1000\n",
      "177/177 [==============================] - 0s 265us/step - loss: 0.0276 - accuracy: 0.9887 - val_loss: 3.8800 - val_accuracy: 0.5263\n",
      "Epoch 820/1000\n",
      "177/177 [==============================] - 0s 171us/step - loss: 0.0267 - accuracy: 0.9831 - val_loss: 3.8692 - val_accuracy: 0.5263\n",
      "Epoch 821/1000\n",
      "177/177 [==============================] - 0s 517us/step - loss: 0.0286 - accuracy: 0.9887 - val_loss: 3.8796 - val_accuracy: 0.5263\n",
      "Epoch 822/1000\n",
      "177/177 [==============================] - 0s 330us/step - loss: 0.0266 - accuracy: 0.9887 - val_loss: 3.8703 - val_accuracy: 0.5263\n",
      "Epoch 823/1000\n",
      "177/177 [==============================] - 0s 304us/step - loss: 0.0260 - accuracy: 0.9887 - val_loss: 3.8856 - val_accuracy: 0.5263\n",
      "Epoch 824/1000\n",
      "177/177 [==============================] - 0s 245us/step - loss: 0.0264 - accuracy: 0.9887 - val_loss: 3.8812 - val_accuracy: 0.5263\n",
      "Epoch 825/1000\n",
      "177/177 [==============================] - 0s 447us/step - loss: 0.0254 - accuracy: 0.9887 - val_loss: 3.8688 - val_accuracy: 0.5263\n",
      "Epoch 826/1000\n",
      "177/177 [==============================] - 0s 128us/step - loss: 0.0296 - accuracy: 0.9887 - val_loss: 3.8650 - val_accuracy: 0.5395\n",
      "Epoch 827/1000\n",
      "177/177 [==============================] - 0s 155us/step - loss: 0.0286 - accuracy: 0.9831 - val_loss: 3.9089 - val_accuracy: 0.5263\n",
      "Epoch 828/1000\n",
      "177/177 [==============================] - 0s 135us/step - loss: 0.0368 - accuracy: 0.9718 - val_loss: 3.8946 - val_accuracy: 0.5395\n",
      "Epoch 829/1000\n",
      "177/177 [==============================] - 0s 419us/step - loss: 0.0448 - accuracy: 0.9831 - val_loss: 3.8492 - val_accuracy: 0.5263\n",
      "Epoch 830/1000\n",
      "177/177 [==============================] - 0s 404us/step - loss: 0.0358 - accuracy: 0.9831 - val_loss: 3.8653 - val_accuracy: 0.5263\n",
      "Epoch 831/1000\n",
      "177/177 [==============================] - 0s 336us/step - loss: 0.0281 - accuracy: 0.9887 - val_loss: 3.8877 - val_accuracy: 0.5263\n",
      "Epoch 832/1000\n",
      "177/177 [==============================] - 0s 603us/step - loss: 0.0265 - accuracy: 0.9887 - val_loss: 3.8893 - val_accuracy: 0.5263\n",
      "Epoch 833/1000\n",
      "177/177 [==============================] - 0s 186us/step - loss: 0.0276 - accuracy: 0.9887 - val_loss: 3.8972 - val_accuracy: 0.5263\n",
      "Epoch 834/1000\n",
      "177/177 [==============================] - 0s 158us/step - loss: 0.0277 - accuracy: 0.9831 - val_loss: 3.8758 - val_accuracy: 0.5263\n",
      "Epoch 835/1000\n",
      "177/177 [==============================] - 0s 295us/step - loss: 0.0264 - accuracy: 0.9887 - val_loss: 3.8743 - val_accuracy: 0.5395\n",
      "Epoch 836/1000\n",
      "177/177 [==============================] - 0s 268us/step - loss: 0.0252 - accuracy: 0.9887 - val_loss: 3.8749 - val_accuracy: 0.5263\n",
      "Epoch 837/1000\n",
      "177/177 [==============================] - 0s 176us/step - loss: 0.0261 - accuracy: 0.9887 - val_loss: 3.8777 - val_accuracy: 0.5263\n",
      "Epoch 838/1000\n",
      "177/177 [==============================] - 0s 165us/step - loss: 0.0266 - accuracy: 0.9887 - val_loss: 3.8727 - val_accuracy: 0.5263\n",
      "Epoch 839/1000\n",
      "177/177 [==============================] - 0s 160us/step - loss: 0.0236 - accuracy: 0.9831 - val_loss: 3.8950 - val_accuracy: 0.5263\n",
      "Epoch 840/1000\n",
      "177/177 [==============================] - 0s 144us/step - loss: 0.0266 - accuracy: 0.9831 - val_loss: 3.8976 - val_accuracy: 0.5263\n",
      "Epoch 841/1000\n",
      "177/177 [==============================] - 0s 103us/step - loss: 0.0249 - accuracy: 0.9887 - val_loss: 3.8896 - val_accuracy: 0.5263\n",
      "Epoch 842/1000\n",
      "177/177 [==============================] - 0s 180us/step - loss: 0.0301 - accuracy: 0.9887 - val_loss: 3.8702 - val_accuracy: 0.5263\n",
      "Epoch 843/1000\n",
      "177/177 [==============================] - 0s 166us/step - loss: 0.0281 - accuracy: 0.9831 - val_loss: 3.8786 - val_accuracy: 0.5263\n",
      "Epoch 844/1000\n",
      "177/177 [==============================] - 0s 115us/step - loss: 0.0266 - accuracy: 0.9831 - val_loss: 3.8954 - val_accuracy: 0.5263\n",
      "Epoch 845/1000\n",
      "177/177 [==============================] - 0s 148us/step - loss: 0.0251 - accuracy: 0.9887 - val_loss: 3.8957 - val_accuracy: 0.5263\n",
      "Epoch 846/1000\n",
      "177/177 [==============================] - 0s 129us/step - loss: 0.0258 - accuracy: 0.9887 - val_loss: 3.8828 - val_accuracy: 0.5263\n",
      "Epoch 847/1000\n",
      "177/177 [==============================] - 0s 137us/step - loss: 0.0281 - accuracy: 0.9887 - val_loss: 3.8906 - val_accuracy: 0.5263\n",
      "Epoch 848/1000\n",
      "177/177 [==============================] - 0s 157us/step - loss: 0.0266 - accuracy: 0.9887 - val_loss: 3.9014 - val_accuracy: 0.5395\n",
      "Epoch 849/1000\n",
      "177/177 [==============================] - 0s 112us/step - loss: 0.0283 - accuracy: 0.9887 - val_loss: 3.9117 - val_accuracy: 0.5395\n",
      "Epoch 850/1000\n",
      "177/177 [==============================] - 0s 166us/step - loss: 0.0257 - accuracy: 0.9831 - val_loss: 3.9281 - val_accuracy: 0.5263\n",
      "Epoch 851/1000\n",
      "177/177 [==============================] - 0s 114us/step - loss: 0.0271 - accuracy: 0.9887 - val_loss: 3.9224 - val_accuracy: 0.5263\n",
      "Epoch 852/1000\n",
      "177/177 [==============================] - 0s 141us/step - loss: 0.0279 - accuracy: 0.9887 - val_loss: 3.9115 - val_accuracy: 0.5263\n",
      "Epoch 853/1000\n",
      "177/177 [==============================] - 0s 159us/step - loss: 0.0258 - accuracy: 0.9831 - val_loss: 3.9094 - val_accuracy: 0.5263\n",
      "Epoch 854/1000\n",
      "177/177 [==============================] - 0s 130us/step - loss: 0.0263 - accuracy: 0.9887 - val_loss: 3.9169 - val_accuracy: 0.5263\n",
      "Epoch 855/1000\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.0253 - accuracy: 0.9887 - val_loss: 3.9072 - val_accuracy: 0.5263\n",
      "Epoch 856/1000\n",
      "177/177 [==============================] - 0s 85us/step - loss: 0.0262 - accuracy: 0.9887 - val_loss: 3.9052 - val_accuracy: 0.5263\n",
      "Epoch 857/1000\n",
      "177/177 [==============================] - 0s 145us/step - loss: 0.0247 - accuracy: 0.9887 - val_loss: 3.9147 - val_accuracy: 0.5263\n",
      "Epoch 858/1000\n",
      "177/177 [==============================] - 0s 92us/step - loss: 0.0252 - accuracy: 0.9831 - val_loss: 3.9158 - val_accuracy: 0.5263\n",
      "Epoch 859/1000\n",
      "177/177 [==============================] - 0s 95us/step - loss: 0.0262 - accuracy: 0.9831 - val_loss: 3.9319 - val_accuracy: 0.5263\n",
      "Epoch 860/1000\n",
      "177/177 [==============================] - 0s 187us/step - loss: 0.0245 - accuracy: 0.9887 - val_loss: 3.9222 - val_accuracy: 0.5263\n",
      "Epoch 861/1000\n",
      "177/177 [==============================] - 0s 114us/step - loss: 0.0242 - accuracy: 0.9831 - val_loss: 3.9133 - val_accuracy: 0.5263\n",
      "Epoch 862/1000\n",
      "177/177 [==============================] - 0s 130us/step - loss: 0.0245 - accuracy: 0.9887 - val_loss: 3.9104 - val_accuracy: 0.5263\n",
      "Epoch 863/1000\n",
      "177/177 [==============================] - 0s 156us/step - loss: 0.0258 - accuracy: 0.9831 - val_loss: 3.9217 - val_accuracy: 0.5263\n",
      "Epoch 864/1000\n",
      "177/177 [==============================] - 0s 132us/step - loss: 0.0255 - accuracy: 0.9887 - val_loss: 3.9207 - val_accuracy: 0.5263\n",
      "Epoch 865/1000\n",
      "177/177 [==============================] - 0s 106us/step - loss: 0.0273 - accuracy: 0.9831 - val_loss: 3.9085 - val_accuracy: 0.5263\n",
      "Epoch 866/1000\n",
      "177/177 [==============================] - 0s 250us/step - loss: 0.0253 - accuracy: 0.9831 - val_loss: 3.9265 - val_accuracy: 0.5263\n",
      "Epoch 867/1000\n",
      "177/177 [==============================] - 0s 672us/step - loss: 0.0246 - accuracy: 0.9831 - val_loss: 3.9254 - val_accuracy: 0.5263\n",
      "Epoch 868/1000\n",
      "177/177 [==============================] - 0s 737us/step - loss: 0.0260 - accuracy: 0.9887 - val_loss: 3.9381 - val_accuracy: 0.5263\n",
      "Epoch 869/1000\n",
      "177/177 [==============================] - 0s 392us/step - loss: 0.0259 - accuracy: 0.9887 - val_loss: 3.9266 - val_accuracy: 0.5263\n",
      "Epoch 870/1000\n",
      "177/177 [==============================] - 0s 101us/step - loss: 0.0243 - accuracy: 0.9887 - val_loss: 3.9295 - val_accuracy: 0.5263\n",
      "Epoch 871/1000\n",
      "177/177 [==============================] - 0s 105us/step - loss: 0.0260 - accuracy: 0.9887 - val_loss: 3.9344 - val_accuracy: 0.5263\n",
      "Epoch 872/1000\n",
      "177/177 [==============================] - 0s 127us/step - loss: 0.0239 - accuracy: 0.9887 - val_loss: 3.9147 - val_accuracy: 0.5395\n",
      "Epoch 873/1000\n",
      "177/177 [==============================] - 0s 132us/step - loss: 0.0284 - accuracy: 0.9887 - val_loss: 3.9130 - val_accuracy: 0.5395\n",
      "Epoch 874/1000\n",
      "177/177 [==============================] - 0s 96us/step - loss: 0.0270 - accuracy: 0.9887 - val_loss: 3.9287 - val_accuracy: 0.5263\n",
      "Epoch 875/1000\n",
      "177/177 [==============================] - 0s 150us/step - loss: 0.0265 - accuracy: 0.9887 - val_loss: 3.9481 - val_accuracy: 0.5263\n",
      "Epoch 876/1000\n",
      "177/177 [==============================] - 0s 100us/step - loss: 0.0345 - accuracy: 0.9887 - val_loss: 3.9401 - val_accuracy: 0.5263\n",
      "Epoch 877/1000\n",
      "177/177 [==============================] - 0s 127us/step - loss: 0.0276 - accuracy: 0.9887 - val_loss: 3.9332 - val_accuracy: 0.5263\n",
      "Epoch 878/1000\n",
      "177/177 [==============================] - 0s 319us/step - loss: 0.0276 - accuracy: 0.9887 - val_loss: 3.9325 - val_accuracy: 0.5263\n",
      "Epoch 879/1000\n",
      "177/177 [==============================] - 0s 260us/step - loss: 0.0292 - accuracy: 0.9887 - val_loss: 3.9134 - val_accuracy: 0.5263\n",
      "Epoch 880/1000\n",
      "177/177 [==============================] - 0s 207us/step - loss: 0.0289 - accuracy: 0.9887 - val_loss: 3.9372 - val_accuracy: 0.5263\n",
      "Epoch 881/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177/177 [==============================] - 0s 220us/step - loss: 0.0287 - accuracy: 0.9831 - val_loss: 3.9587 - val_accuracy: 0.5263\n",
      "Epoch 882/1000\n",
      "177/177 [==============================] - 0s 132us/step - loss: 0.0265 - accuracy: 0.9887 - val_loss: 3.9494 - val_accuracy: 0.5263\n",
      "Epoch 883/1000\n",
      "177/177 [==============================] - 0s 195us/step - loss: 0.0255 - accuracy: 0.9887 - val_loss: 3.9303 - val_accuracy: 0.5263\n",
      "Epoch 884/1000\n",
      "177/177 [==============================] - 0s 148us/step - loss: 0.0242 - accuracy: 0.9887 - val_loss: 3.9283 - val_accuracy: 0.5263\n",
      "Epoch 885/1000\n",
      "177/177 [==============================] - 0s 132us/step - loss: 0.0263 - accuracy: 0.9887 - val_loss: 3.9401 - val_accuracy: 0.5263\n",
      "Epoch 886/1000\n",
      "177/177 [==============================] - 0s 120us/step - loss: 0.0246 - accuracy: 0.9887 - val_loss: 3.9308 - val_accuracy: 0.5263\n",
      "Epoch 887/1000\n",
      "177/177 [==============================] - 0s 116us/step - loss: 0.0255 - accuracy: 0.9887 - val_loss: 3.9383 - val_accuracy: 0.5263\n",
      "Epoch 888/1000\n",
      "177/177 [==============================] - 0s 142us/step - loss: 0.0263 - accuracy: 0.9887 - val_loss: 3.9336 - val_accuracy: 0.5263\n",
      "Epoch 889/1000\n",
      "177/177 [==============================] - 0s 137us/step - loss: 0.0263 - accuracy: 0.9887 - val_loss: 3.9487 - val_accuracy: 0.5263\n",
      "Epoch 890/1000\n",
      "177/177 [==============================] - 0s 116us/step - loss: 0.0271 - accuracy: 0.9887 - val_loss: 3.9498 - val_accuracy: 0.5263\n",
      "Epoch 891/1000\n",
      "177/177 [==============================] - 0s 125us/step - loss: 0.0232 - accuracy: 0.9944 - val_loss: 3.9789 - val_accuracy: 0.5263\n",
      "Epoch 892/1000\n",
      "177/177 [==============================] - 0s 161us/step - loss: 0.0248 - accuracy: 0.9887 - val_loss: 3.9935 - val_accuracy: 0.5395\n",
      "Epoch 893/1000\n",
      "177/177 [==============================] - 0s 121us/step - loss: 0.0373 - accuracy: 0.9718 - val_loss: 4.0162 - val_accuracy: 0.5395\n",
      "Epoch 894/1000\n",
      "177/177 [==============================] - 0s 132us/step - loss: 0.0264 - accuracy: 0.9887 - val_loss: 3.9680 - val_accuracy: 0.5263\n",
      "Epoch 895/1000\n",
      "177/177 [==============================] - 0s 163us/step - loss: 0.0256 - accuracy: 0.9831 - val_loss: 3.9507 - val_accuracy: 0.5263\n",
      "Epoch 896/1000\n",
      "177/177 [==============================] - 0s 109us/step - loss: 0.0276 - accuracy: 0.9887 - val_loss: 3.9436 - val_accuracy: 0.5263\n",
      "Epoch 897/1000\n",
      "177/177 [==============================] - 0s 109us/step - loss: 0.0271 - accuracy: 0.9887 - val_loss: 3.9666 - val_accuracy: 0.5263\n",
      "Epoch 898/1000\n",
      "177/177 [==============================] - 0s 135us/step - loss: 0.0278 - accuracy: 0.9887 - val_loss: 3.9615 - val_accuracy: 0.5263\n",
      "Epoch 899/1000\n",
      "177/177 [==============================] - 0s 132us/step - loss: 0.0284 - accuracy: 0.9887 - val_loss: 3.9551 - val_accuracy: 0.5263\n",
      "Epoch 900/1000\n",
      "177/177 [==============================] - 0s 153us/step - loss: 0.0240 - accuracy: 0.9887 - val_loss: 3.9792 - val_accuracy: 0.5263\n",
      "Epoch 901/1000\n",
      "177/177 [==============================] - 0s 161us/step - loss: 0.0300 - accuracy: 0.9831 - val_loss: 3.9523 - val_accuracy: 0.5263\n",
      "Epoch 902/1000\n",
      "177/177 [==============================] - 0s 116us/step - loss: 0.0250 - accuracy: 0.9887 - val_loss: 3.9462 - val_accuracy: 0.5263\n",
      "Epoch 903/1000\n",
      "177/177 [==============================] - 0s 129us/step - loss: 0.0260 - accuracy: 0.9887 - val_loss: 3.9560 - val_accuracy: 0.5263\n",
      "Epoch 904/1000\n",
      "177/177 [==============================] - 0s 136us/step - loss: 0.0276 - accuracy: 0.9887 - val_loss: 3.9630 - val_accuracy: 0.5263\n",
      "Epoch 905/1000\n",
      "177/177 [==============================] - 0s 374us/step - loss: 0.0259 - accuracy: 0.9887 - val_loss: 3.9640 - val_accuracy: 0.5263\n",
      "Epoch 906/1000\n",
      "177/177 [==============================] - 0s 117us/step - loss: 0.0252 - accuracy: 0.9887 - val_loss: 3.9652 - val_accuracy: 0.5263\n",
      "Epoch 907/1000\n",
      "177/177 [==============================] - 0s 158us/step - loss: 0.0277 - accuracy: 0.9887 - val_loss: 3.9822 - val_accuracy: 0.5263\n",
      "Epoch 908/1000\n",
      "177/177 [==============================] - 0s 124us/step - loss: 0.0250 - accuracy: 0.9887 - val_loss: 3.9596 - val_accuracy: 0.5263\n",
      "Epoch 909/1000\n",
      "177/177 [==============================] - 0s 154us/step - loss: 0.0264 - accuracy: 0.9887 - val_loss: 3.9538 - val_accuracy: 0.5263\n",
      "Epoch 910/1000\n",
      "177/177 [==============================] - 0s 146us/step - loss: 0.0247 - accuracy: 0.9887 - val_loss: 3.9645 - val_accuracy: 0.5263\n",
      "Epoch 911/1000\n",
      "177/177 [==============================] - 0s 136us/step - loss: 0.0249 - accuracy: 0.9887 - val_loss: 3.9743 - val_accuracy: 0.5263\n",
      "Epoch 912/1000\n",
      "177/177 [==============================] - 0s 170us/step - loss: 0.0249 - accuracy: 0.9887 - val_loss: 3.9823 - val_accuracy: 0.5263\n",
      "Epoch 913/1000\n",
      "177/177 [==============================] - 0s 165us/step - loss: 0.0277 - accuracy: 0.9831 - val_loss: 3.9928 - val_accuracy: 0.5132\n",
      "Epoch 914/1000\n",
      "177/177 [==============================] - 0s 178us/step - loss: 0.0270 - accuracy: 0.9831 - val_loss: 3.9644 - val_accuracy: 0.5263\n",
      "Epoch 915/1000\n",
      "177/177 [==============================] - 0s 173us/step - loss: 0.0278 - accuracy: 0.9887 - val_loss: 3.9526 - val_accuracy: 0.5263\n",
      "Epoch 916/1000\n",
      "177/177 [==============================] - 0s 228us/step - loss: 0.0395 - accuracy: 0.9774 - val_loss: 3.9619 - val_accuracy: 0.5263\n",
      "Epoch 917/1000\n",
      "177/177 [==============================] - 0s 296us/step - loss: 0.0414 - accuracy: 0.9831 - val_loss: 4.0019 - val_accuracy: 0.5263\n",
      "Epoch 918/1000\n",
      "177/177 [==============================] - 0s 472us/step - loss: 0.0838 - accuracy: 0.9831 - val_loss: 3.9685 - val_accuracy: 0.5263\n",
      "Epoch 919/1000\n",
      "177/177 [==============================] - 0s 323us/step - loss: 0.0637 - accuracy: 0.9774 - val_loss: 4.0015 - val_accuracy: 0.5263\n",
      "Epoch 920/1000\n",
      "177/177 [==============================] - 0s 162us/step - loss: 0.0550 - accuracy: 0.9718 - val_loss: 3.9809 - val_accuracy: 0.5263\n",
      "Epoch 921/1000\n",
      "177/177 [==============================] - 0s 193us/step - loss: 0.0740 - accuracy: 0.9831 - val_loss: 3.9752 - val_accuracy: 0.5263\n",
      "Epoch 922/1000\n",
      "177/177 [==============================] - 0s 136us/step - loss: 0.0254 - accuracy: 0.9831 - val_loss: 4.0126 - val_accuracy: 0.5395\n",
      "Epoch 923/1000\n",
      "177/177 [==============================] - 0s 155us/step - loss: 0.0957 - accuracy: 0.9718 - val_loss: 3.9682 - val_accuracy: 0.5263\n",
      "Epoch 924/1000\n",
      "177/177 [==============================] - 0s 114us/step - loss: 0.1448 - accuracy: 0.9774 - val_loss: 4.1052 - val_accuracy: 0.4868\n",
      "Epoch 925/1000\n",
      "177/177 [==============================] - 0s 138us/step - loss: 0.1320 - accuracy: 0.9718 - val_loss: 3.9734 - val_accuracy: 0.5263\n",
      "Epoch 926/1000\n",
      "177/177 [==============================] - 0s 150us/step - loss: 0.1036 - accuracy: 0.9774 - val_loss: 4.0012 - val_accuracy: 0.5263\n",
      "Epoch 927/1000\n",
      "177/177 [==============================] - 0s 123us/step - loss: 0.1971 - accuracy: 0.9605 - val_loss: 4.1944 - val_accuracy: 0.4737\n",
      "Epoch 928/1000\n",
      "177/177 [==============================] - 0s 118us/step - loss: 0.1183 - accuracy: 0.9887 - val_loss: 3.9532 - val_accuracy: 0.5263\n",
      "Epoch 929/1000\n",
      "177/177 [==============================] - 0s 164us/step - loss: 0.2809 - accuracy: 0.9718 - val_loss: 3.9689 - val_accuracy: 0.5263\n",
      "Epoch 930/1000\n",
      "177/177 [==============================] - 0s 296us/step - loss: 0.2161 - accuracy: 0.9718 - val_loss: 4.2167 - val_accuracy: 0.4868\n",
      "Epoch 931/1000\n",
      "177/177 [==============================] - 0s 228us/step - loss: 0.2609 - accuracy: 0.9605 - val_loss: 3.9744 - val_accuracy: 0.5263\n",
      "Epoch 932/1000\n",
      "177/177 [==============================] - 0s 221us/step - loss: 0.0735 - accuracy: 0.9718 - val_loss: 4.1497 - val_accuracy: 0.4868\n",
      "Epoch 933/1000\n",
      "177/177 [==============================] - 0s 221us/step - loss: 0.2573 - accuracy: 0.9548 - val_loss: 4.1572 - val_accuracy: 0.4868\n",
      "Epoch 934/1000\n",
      "177/177 [==============================] - 0s 226us/step - loss: 0.2032 - accuracy: 0.9605 - val_loss: 4.0168 - val_accuracy: 0.5132\n",
      "Epoch 935/1000\n",
      "177/177 [==============================] - 0s 266us/step - loss: 0.3924 - accuracy: 0.9492 - val_loss: 3.9556 - val_accuracy: 0.5263\n",
      "Epoch 936/1000\n",
      "177/177 [==============================] - 0s 125us/step - loss: 0.3821 - accuracy: 0.9492 - val_loss: 4.2084 - val_accuracy: 0.4737\n",
      "Epoch 937/1000\n",
      "177/177 [==============================] - 0s 117us/step - loss: 0.2916 - accuracy: 0.9718 - val_loss: 3.9576 - val_accuracy: 0.5263\n",
      "Epoch 938/1000\n",
      "177/177 [==============================] - 0s 207us/step - loss: 0.2462 - accuracy: 0.9718 - val_loss: 4.0095 - val_accuracy: 0.5000\n",
      "Epoch 939/1000\n",
      "177/177 [==============================] - 0s 186us/step - loss: 0.0639 - accuracy: 0.9605 - val_loss: 4.1003 - val_accuracy: 0.4868\n",
      "Epoch 940/1000\n",
      "177/177 [==============================] - 0s 142us/step - loss: 0.3820 - accuracy: 0.9492 - val_loss: 4.0355 - val_accuracy: 0.5000\n",
      "Epoch 941/1000\n",
      "177/177 [==============================] - 0s 183us/step - loss: 0.0314 - accuracy: 0.9831 - val_loss: 4.0400 - val_accuracy: 0.5132\n",
      "Epoch 942/1000\n",
      "177/177 [==============================] - 0s 201us/step - loss: 0.3753 - accuracy: 0.9605 - val_loss: 4.0473 - val_accuracy: 0.4868\n",
      "Epoch 943/1000\n",
      "177/177 [==============================] - 0s 89us/step - loss: 0.2549 - accuracy: 0.9774 - val_loss: 3.9623 - val_accuracy: 0.5000\n",
      "Epoch 944/1000\n",
      "177/177 [==============================] - 0s 91us/step - loss: 0.0611 - accuracy: 0.9774 - val_loss: 3.9379 - val_accuracy: 0.5263\n",
      "Epoch 945/1000\n",
      "177/177 [==============================] - 0s 101us/step - loss: 0.1077 - accuracy: 0.9718 - val_loss: 4.0029 - val_accuracy: 0.5132\n",
      "Epoch 946/1000\n",
      "177/177 [==============================] - 0s 105us/step - loss: 0.1207 - accuracy: 0.9774 - val_loss: 3.9191 - val_accuracy: 0.5132\n",
      "Epoch 947/1000\n",
      "177/177 [==============================] - 0s 103us/step - loss: 0.1071 - accuracy: 0.9774 - val_loss: 3.9277 - val_accuracy: 0.5000\n",
      "Epoch 948/1000\n",
      "177/177 [==============================] - 0s 99us/step - loss: 0.1152 - accuracy: 0.9831 - val_loss: 3.9687 - val_accuracy: 0.5132\n",
      "Epoch 949/1000\n",
      "177/177 [==============================] - 0s 113us/step - loss: 0.0467 - accuracy: 0.9831 - val_loss: 3.9845 - val_accuracy: 0.5263\n",
      "Epoch 950/1000\n",
      "177/177 [==============================] - 0s 108us/step - loss: 0.0805 - accuracy: 0.9831 - val_loss: 4.0069 - val_accuracy: 0.5263\n",
      "Epoch 951/1000\n",
      "177/177 [==============================] - 0s 121us/step - loss: 0.0318 - accuracy: 0.9887 - val_loss: 4.0760 - val_accuracy: 0.5395\n",
      "Epoch 952/1000\n",
      "177/177 [==============================] - 0s 188us/step - loss: 0.0888 - accuracy: 0.9831 - val_loss: 4.0799 - val_accuracy: 0.5395\n",
      "Epoch 953/1000\n",
      "177/177 [==============================] - 0s 191us/step - loss: 0.0696 - accuracy: 0.9831 - val_loss: 4.0672 - val_accuracy: 0.5263\n",
      "Epoch 954/1000\n",
      "177/177 [==============================] - 0s 145us/step - loss: 0.1116 - accuracy: 0.9774 - val_loss: 4.1008 - val_accuracy: 0.5132\n",
      "Epoch 955/1000\n",
      "177/177 [==============================] - 0s 145us/step - loss: 0.0326 - accuracy: 0.9831 - val_loss: 4.1462 - val_accuracy: 0.5132\n",
      "Epoch 956/1000\n",
      "177/177 [==============================] - 0s 167us/step - loss: 0.0936 - accuracy: 0.9661 - val_loss: 4.0673 - val_accuracy: 0.5263\n",
      "Epoch 957/1000\n",
      "177/177 [==============================] - 0s 155us/step - loss: 0.1225 - accuracy: 0.9774 - val_loss: 4.1004 - val_accuracy: 0.5132\n",
      "Epoch 958/1000\n",
      "177/177 [==============================] - 0s 165us/step - loss: 0.1052 - accuracy: 0.9661 - val_loss: 4.1405 - val_accuracy: 0.5132\n",
      "Epoch 959/1000\n",
      "177/177 [==============================] - 0s 134us/step - loss: 0.0717 - accuracy: 0.9831 - val_loss: 4.0796 - val_accuracy: 0.5263\n",
      "Epoch 960/1000\n",
      "177/177 [==============================] - 0s 103us/step - loss: 0.1448 - accuracy: 0.9774 - val_loss: 4.0817 - val_accuracy: 0.5132\n",
      "Epoch 961/1000\n",
      "177/177 [==============================] - 0s 106us/step - loss: 0.0717 - accuracy: 0.9718 - val_loss: 4.1410 - val_accuracy: 0.5000\n",
      "Epoch 962/1000\n",
      "177/177 [==============================] - 0s 110us/step - loss: 0.0502 - accuracy: 0.9887 - val_loss: 4.0406 - val_accuracy: 0.5263\n",
      "Epoch 963/1000\n",
      "177/177 [==============================] - 0s 124us/step - loss: 0.0997 - accuracy: 0.9774 - val_loss: 4.0789 - val_accuracy: 0.5263\n",
      "Epoch 964/1000\n",
      "177/177 [==============================] - 0s 144us/step - loss: 0.0368 - accuracy: 0.9831 - val_loss: 4.1481 - val_accuracy: 0.5132\n",
      "Epoch 965/1000\n",
      "177/177 [==============================] - 0s 180us/step - loss: 0.0874 - accuracy: 0.9605 - val_loss: 4.0944 - val_accuracy: 0.5132\n",
      "Epoch 966/1000\n",
      "177/177 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 1.00 - 0s 206us/step - loss: 0.0438 - accuracy: 0.9831 - val_loss: 4.0163 - val_accuracy: 0.5263\n",
      "Epoch 967/1000\n",
      "177/177 [==============================] - 0s 245us/step - loss: 0.3062 - accuracy: 0.9605 - val_loss: 4.0742 - val_accuracy: 0.5263\n",
      "Epoch 968/1000\n",
      "177/177 [==============================] - 0s 271us/step - loss: 0.0644 - accuracy: 0.9718 - val_loss: 4.2355 - val_accuracy: 0.5000\n",
      "Epoch 969/1000\n",
      "177/177 [==============================] - 0s 229us/step - loss: 0.1507 - accuracy: 0.9661 - val_loss: 4.1270 - val_accuracy: 0.5132\n",
      "Epoch 970/1000\n",
      "177/177 [==============================] - 0s 287us/step - loss: 0.2634 - accuracy: 0.9661 - val_loss: 4.0482 - val_accuracy: 0.5263\n",
      "Epoch 971/1000\n",
      "177/177 [==============================] - 0s 127us/step - loss: 0.0878 - accuracy: 0.9774 - val_loss: 4.2834 - val_accuracy: 0.5000\n",
      "Epoch 972/1000\n",
      "177/177 [==============================] - 0s 147us/step - loss: 0.2597 - accuracy: 0.9661 - val_loss: 4.2160 - val_accuracy: 0.4868\n",
      "Epoch 973/1000\n",
      "177/177 [==============================] - 0s 303us/step - loss: 0.0843 - accuracy: 0.9718 - val_loss: 4.0778 - val_accuracy: 0.5132\n",
      "Epoch 974/1000\n",
      "177/177 [==============================] - 0s 156us/step - loss: 0.1107 - accuracy: 0.9718 - val_loss: 4.0742 - val_accuracy: 0.5000\n",
      "Epoch 975/1000\n",
      "177/177 [==============================] - 0s 160us/step - loss: 0.0506 - accuracy: 0.9831 - val_loss: 4.1258 - val_accuracy: 0.5000\n",
      "Epoch 976/1000\n",
      "177/177 [==============================] - 0s 102us/step - loss: 0.1640 - accuracy: 0.9831 - val_loss: 4.1146 - val_accuracy: 0.5132\n",
      "Epoch 977/1000\n",
      "177/177 [==============================] - 0s 197us/step - loss: 0.0348 - accuracy: 0.9774 - val_loss: 4.0644 - val_accuracy: 0.5000\n",
      "Epoch 978/1000\n",
      "177/177 [==============================] - 0s 183us/step - loss: 0.1171 - accuracy: 0.9718 - val_loss: 4.0377 - val_accuracy: 0.5000\n",
      "Epoch 979/1000\n",
      "177/177 [==============================] - 0s 119us/step - loss: 0.0673 - accuracy: 0.9831 - val_loss: 4.0795 - val_accuracy: 0.5132\n",
      "Epoch 980/1000\n",
      "177/177 [==============================] - 0s 107us/step - loss: 0.0330 - accuracy: 0.9887 - val_loss: 4.1066 - val_accuracy: 0.5000\n",
      "Epoch 981/1000\n",
      "177/177 [==============================] - 0s 120us/step - loss: 0.0593 - accuracy: 0.9831 - val_loss: 4.0866 - val_accuracy: 0.5132\n",
      "Epoch 982/1000\n",
      "177/177 [==============================] - 0s 113us/step - loss: 0.0283 - accuracy: 0.9887 - val_loss: 4.0910 - val_accuracy: 0.5132\n",
      "Epoch 983/1000\n",
      "177/177 [==============================] - 0s 137us/step - loss: 0.0280 - accuracy: 0.9887 - val_loss: 4.0866 - val_accuracy: 0.5132\n",
      "Epoch 984/1000\n",
      "177/177 [==============================] - 0s 157us/step - loss: 0.0292 - accuracy: 0.9831 - val_loss: 4.1003 - val_accuracy: 0.5132\n",
      "Epoch 985/1000\n",
      "177/177 [==============================] - 0s 145us/step - loss: 0.0292 - accuracy: 0.9887 - val_loss: 4.0877 - val_accuracy: 0.5132\n",
      "Epoch 986/1000\n",
      "177/177 [==============================] - 0s 158us/step - loss: 0.0285 - accuracy: 0.9887 - val_loss: 4.1137 - val_accuracy: 0.5132\n",
      "Epoch 987/1000\n",
      "177/177 [==============================] - 0s 141us/step - loss: 0.0261 - accuracy: 0.9887 - val_loss: 4.1145 - val_accuracy: 0.5132\n",
      "Epoch 988/1000\n",
      "177/177 [==============================] - 0s 139us/step - loss: 0.0261 - accuracy: 0.9887 - val_loss: 4.1106 - val_accuracy: 0.5132\n",
      "Epoch 989/1000\n",
      "177/177 [==============================] - 0s 115us/step - loss: 0.0259 - accuracy: 0.9887 - val_loss: 4.1076 - val_accuracy: 0.5132\n",
      "Epoch 990/1000\n",
      "177/177 [==============================] - 0s 156us/step - loss: 0.0257 - accuracy: 0.9887 - val_loss: 4.1223 - val_accuracy: 0.5132\n",
      "Epoch 991/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177/177 [==============================] - 0s 193us/step - loss: 0.0268 - accuracy: 0.9831 - val_loss: 4.1355 - val_accuracy: 0.5132\n",
      "Epoch 992/1000\n",
      "177/177 [==============================] - 0s 156us/step - loss: 0.0255 - accuracy: 0.9887 - val_loss: 4.1392 - val_accuracy: 0.5132\n",
      "Epoch 993/1000\n",
      "177/177 [==============================] - 0s 154us/step - loss: 0.0261 - accuracy: 0.9887 - val_loss: 4.1475 - val_accuracy: 0.5132\n",
      "Epoch 994/1000\n",
      "177/177 [==============================] - 0s 119us/step - loss: 0.0261 - accuracy: 0.9831 - val_loss: 4.1588 - val_accuracy: 0.5132\n",
      "Epoch 995/1000\n",
      "177/177 [==============================] - 0s 150us/step - loss: 0.0289 - accuracy: 0.9887 - val_loss: 4.1549 - val_accuracy: 0.5263\n",
      "Epoch 996/1000\n",
      "177/177 [==============================] - 0s 199us/step - loss: 0.0281 - accuracy: 0.9887 - val_loss: 4.1430 - val_accuracy: 0.5132\n",
      "Epoch 997/1000\n",
      "177/177 [==============================] - 0s 139us/step - loss: 0.0254 - accuracy: 0.9887 - val_loss: 4.1259 - val_accuracy: 0.5263\n",
      "Epoch 998/1000\n",
      "177/177 [==============================] - 0s 154us/step - loss: 0.0272 - accuracy: 0.9887 - val_loss: 4.1289 - val_accuracy: 0.5132\n",
      "Epoch 999/1000\n",
      "177/177 [==============================] - 0s 131us/step - loss: 0.0284 - accuracy: 0.9831 - val_loss: 4.1552 - val_accuracy: 0.5132\n",
      "Epoch 1000/1000\n",
      "177/177 [==============================] - 0s 148us/step - loss: 0.0288 - accuracy: 0.9887 - val_loss: 4.1492 - val_accuracy: 0.5263\n"
     ]
    }
   ],
   "source": [
    "hist_sel4 = model_sel4.fit(X_sel_train, y_sel_train,\n",
    "          batch_size=32, epochs=1000,\n",
    "          validation_data=(X_sel_test, y_sel_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 98.35%\n"
     ]
    }
   ],
   "source": [
    "print('train accuracy: %.2f%%' % (np.mean(hist_sel4.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba8 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_lasso_2.xlsx\",\n",
    "                        sheet_name=3,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NRS104</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.210638e-02</td>\n",
       "      <td>0.917809</td>\n",
       "      <td>8.477923e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NRS071</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.015229e-02</td>\n",
       "      <td>0.255327</td>\n",
       "      <td>7.345203e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NRS072</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.642946e-03</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>9.963547e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>BCH-SA-12</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.809318e-03</td>\n",
       "      <td>0.099188</td>\n",
       "      <td>8.980029e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>CFBREBSa125</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4.875667e-01</td>\n",
       "      <td>0.088657</td>\n",
       "      <td>4.237761e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>NRS113</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.686909e-07</td>\n",
       "      <td>0.093121</td>\n",
       "      <td>9.068785e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>BCH-SA-09</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5.529492e-07</td>\n",
       "      <td>0.999990</td>\n",
       "      <td>9.559324e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>NRS106</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.115902e-03</td>\n",
       "      <td>0.998816</td>\n",
       "      <td>6.852559e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>CFBREBSa131</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.708040e-07</td>\n",
       "      <td>0.156768</td>\n",
       "      <td>8.432316e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>GA51254</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.993569e-01</td>\n",
       "      <td>0.000643</td>\n",
       "      <td>1.816008e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>608 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     phage       strain  phenotype  prediction             0  \\\n",
       "0       p0017kpresabs_qual       NRS104          0           1  8.210638e-02   \n",
       "1       p0017kpresabs_qual       NRS071          0           2  1.015229e-02   \n",
       "2       p0017kpresabs_qual       NRS072          1           2  3.642946e-03   \n",
       "3       p0017kpresabs_qual    BCH-SA-12          0           2  2.809318e-03   \n",
       "4       p0017kpresabs_qual  CFBREBSa125          2           0  4.875667e-01   \n",
       "..                     ...          ...        ...         ...           ...   \n",
       "603  p0040presabsSTCC_qual       NRS113          1           2  2.686909e-07   \n",
       "604  p0040presabsSTCC_qual    BCH-SA-09          2           1  5.529492e-07   \n",
       "605  p0040presabsSTCC_qual       NRS106          2           1  1.115902e-03   \n",
       "606  p0040presabsSTCC_qual  CFBREBSa131          2           2  2.708040e-07   \n",
       "607  p0040presabsSTCC_qual      GA51254          0           0  9.993569e-01   \n",
       "\n",
       "            1             2  \n",
       "0    0.917809  8.477923e-05  \n",
       "1    0.255327  7.345203e-01  \n",
       "2    0.000002  9.963547e-01  \n",
       "3    0.099188  8.980029e-01  \n",
       "4    0.088657  4.237761e-01  \n",
       "..        ...           ...  \n",
       "603  0.093121  9.068785e-01  \n",
       "604  0.999990  9.559324e-06  \n",
       "605  0.998816  6.852559e-05  \n",
       "606  0.156768  8.432316e-01  \n",
       "607  0.000643  1.816008e-08  \n",
       "\n",
       "[608 rows x 7 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.43122490e-07, 9.92346300e-01, 7.65348460e-03],\n",
       "       [1.00000000e+00, 7.58486400e-09, 1.75205150e-11],\n",
       "       [7.18062900e-07, 2.04486400e-03, 9.97954370e-01],\n",
       "       [3.53508200e-04, 9.99625100e-01, 2.13590670e-05],\n",
       "       [9.99893200e-01, 5.36168740e-05, 5.31826770e-05],\n",
       "       [1.06981310e-02, 2.92876200e-01, 6.96425600e-01],\n",
       "       [2.58759500e-06, 9.54899200e-01, 4.50981900e-02],\n",
       "       [9.07146800e-01, 2.17483380e-02, 7.11049140e-02],\n",
       "       [1.27781110e-05, 6.22910260e-01, 3.77076950e-01],\n",
       "       [8.01830950e-01, 1.69265790e-01, 2.89032240e-02],\n",
       "       [4.29922060e-03, 9.91900600e-03, 9.85781850e-01],\n",
       "       [2.15574220e-07, 9.99999760e-01, 7.08923960e-11],\n",
       "       [2.29871820e-05, 9.99974850e-01, 2.18163500e-06],\n",
       "       [9.99760700e-01, 9.99083400e-06, 2.29271700e-04],\n",
       "       [6.13850000e-04, 3.45332970e-03, 9.95932900e-01],\n",
       "       [3.76958470e-03, 8.33303100e-03, 9.87897400e-01],\n",
       "       [1.58768310e-04, 6.10627230e-01, 3.89213950e-01],\n",
       "       [1.28875790e-02, 9.86618000e-01, 4.94504400e-04],\n",
       "       [1.67557320e-03, 1.36974680e-01, 8.61349760e-01],\n",
       "       [6.82522360e-01, 2.96103120e-02, 2.87867370e-01],\n",
       "       [3.70425140e-09, 5.52345600e-02, 9.44765400e-01],\n",
       "       [9.96554000e-01, 1.21625130e-03, 2.22967400e-03],\n",
       "       [4.17411120e-01, 7.21938000e-05, 5.82516730e-01],\n",
       "       [4.08073500e-02, 2.45680500e-06, 9.59190130e-01],\n",
       "       [1.56943360e-03, 9.98203750e-01, 2.26748200e-04],\n",
       "       [2.72856880e-10, 9.99975200e-01, 2.47759640e-05],\n",
       "       [2.46113140e-04, 9.99753900e-01, 2.31356270e-08],\n",
       "       [3.14169750e-03, 9.15604200e-01, 8.12541000e-02],\n",
       "       [3.21991900e-10, 5.17730650e-01, 4.82269320e-01],\n",
       "       [2.45211800e-03, 3.25125520e-01, 6.72422350e-01],\n",
       "       [2.64196500e-07, 1.93478400e-05, 9.99980330e-01],\n",
       "       [3.21418540e-04, 9.52968240e-01, 4.67103300e-02],\n",
       "       [1.34228140e-06, 9.99998330e-01, 4.14585540e-07],\n",
       "       [3.40220300e-03, 9.51416500e-01, 4.51812450e-02],\n",
       "       [3.78662730e-05, 9.98701100e-01, 1.26106610e-03],\n",
       "       [1.74727890e-06, 9.81409670e-01, 1.85885880e-02],\n",
       "       [2.20142070e-03, 9.97798500e-01, 2.55051980e-08],\n",
       "       [7.06740700e-02, 9.29320160e-01, 5.75459200e-06],\n",
       "       [9.99954000e-01, 2.66412750e-05, 1.94239640e-05],\n",
       "       [1.73838470e-01, 6.56299650e-01, 1.69861910e-01],\n",
       "       [6.95743200e-04, 9.99304300e-01, 3.04195140e-08],\n",
       "       [3.15577500e-02, 9.67938360e-01, 5.03932650e-04],\n",
       "       [4.57590460e-07, 2.61160560e-06, 9.99996900e-01],\n",
       "       [8.25275800e-01, 1.74691170e-01, 3.30163640e-05],\n",
       "       [9.11282300e-01, 8.86771300e-02, 4.05195100e-05],\n",
       "       [9.93825550e-01, 3.83196630e-03, 2.34248300e-03],\n",
       "       [4.35196060e-08, 3.83850150e-06, 9.99996070e-01],\n",
       "       [1.57709830e-11, 9.99991540e-01, 8.41925100e-06],\n",
       "       [9.99980800e-01, 5.78212300e-06, 1.33331005e-05],\n",
       "       [1.00960170e-05, 3.66497900e-01, 6.33492000e-01],\n",
       "       [3.35994440e-02, 7.51756200e-01, 2.14644400e-01],\n",
       "       [7.24961700e-05, 9.99769150e-01, 1.58363110e-04],\n",
       "       [2.54512200e-01, 7.24410700e-01, 2.10770850e-02],\n",
       "       [9.96554000e-01, 1.21625130e-03, 2.22967400e-03],\n",
       "       [6.08706300e-01, 1.22151695e-01, 2.69141940e-01],\n",
       "       [1.91496820e-01, 3.71042580e-01, 4.37460660e-01],\n",
       "       [7.89694370e-01, 4.44616100e-02, 1.65844010e-01],\n",
       "       [9.99740300e-01, 2.50983020e-04, 8.73221700e-06],\n",
       "       [8.24607200e-06, 9.99991200e-01, 5.64660900e-07],\n",
       "       [2.89044500e-03, 2.01732750e-05, 9.97089450e-01],\n",
       "       [5.36529460e-04, 6.26953500e-03, 9.93193860e-01],\n",
       "       [5.10176000e-04, 9.85020900e-01, 1.44688890e-02],\n",
       "       [8.00722700e-01, 3.63622230e-03, 1.95641060e-01],\n",
       "       [2.23876090e-01, 1.16143115e-02, 7.64509560e-01],\n",
       "       [9.70835860e-01, 1.14980130e-02, 1.76661690e-02],\n",
       "       [7.47331160e-02, 3.47713640e-02, 8.90495500e-01],\n",
       "       [1.87164930e-04, 9.89158300e-01, 1.06546090e-02],\n",
       "       [3.74669900e-01, 1.71895040e-01, 4.53435030e-01],\n",
       "       [1.56955540e-01, 4.96275430e-04, 8.42548200e-01],\n",
       "       [2.50091670e-05, 9.81181700e-01, 1.87932380e-02],\n",
       "       [8.14656850e-01, 1.85338750e-01, 4.32367000e-06],\n",
       "       [2.68690850e-07, 9.31212200e-02, 9.06878530e-01],\n",
       "       [5.52949200e-07, 9.99989870e-01, 9.55932400e-06],\n",
       "       [1.11590160e-03, 9.98815540e-01, 6.85255900e-05],\n",
       "       [2.70804000e-07, 1.56768160e-01, 8.43231600e-01],\n",
       "       [9.99356900e-01, 6.43114730e-04, 1.81600810e-08]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob8 = df_proba8[df_proba8['phage']=='p0040presabsSTCC_qual'].iloc[:,-3:]\n",
    "y_prob8 = y_prob8.to_numpy()\n",
    "y_prob8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6741404257452303"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo8 = rocauc_ovo(y_sel_test, y_prob8, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6741404257452303"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr8 = rocauc_ovr(y_sel_test, y_prob8, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6892898964911329"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovos2 = [ovo5, ovo6, ovo7, ovo8]\n",
    "np.mean(ovos2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.010890681093656675"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(ovos2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6892898964911329"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovrs2 = [ovr5, ovr6, ovr7, ovr8]\n",
    "np.mean(ovrs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.010890681093656675"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(ovrs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs_l= [acc_test_sel, acc_test_sel2, acc_test_sel3, acc_test_sel4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy mean after lasso: 54.61%\n"
     ]
    }
   ],
   "source": [
    "mean_l = np.mean(accs_l)\n",
    "print('test accuracy mean after lasso: %.2f%%' % (mean_l*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy standard deviation after lasso: 0.019736831386885305\n"
     ]
    }
   ],
   "source": [
    "std_l = np.std(accs_l)\n",
    "print('test accuracy standard deviation after lasso:', std_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs_train_l = [np.mean(hist_sel.history['accuracy']), np.mean(hist_sel2.history['accuracy']), np.mean(hist_sel3.history['accuracy']),\n",
    "             np.mean(hist_sel4.history['accuracy'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy mean after lasso: 98.36%\n"
     ]
    }
   ],
   "source": [
    "mean_train_l = np.mean(accs_train_l)\n",
    "print('train accuracy mean after lasso: %.2f%%' % (mean_train_l*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy standard deviation after lasso: 0.009281495\n"
     ]
    }
   ],
   "source": [
    "std_train_l = np.std(accs_train_l)\n",
    "print('train accuracy standard deviation after lasso:', std_train_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
