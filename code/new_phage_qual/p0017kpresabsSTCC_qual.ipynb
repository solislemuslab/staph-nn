{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This file implements neural networks before and after lasso selection for p0017kpresabsSTCC_qual with four replicates.\n",
    "## We compute the mean and standarad deviation of training and test accuracies.\n",
    "## We also compute the mean and standard deviation of AUC ROC values for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "import numpy as np\n",
    "seed(100)\n",
    "import tensorflow\n",
    "tensorflow.random.set_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(253, 7082)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/p0017kpresabsSTCC_qual.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'Unnamed: 0':'id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      2\n",
       "1      0\n",
       "2      2\n",
       "3      2\n",
       "4      2\n",
       "      ..\n",
       "248    2\n",
       "249    1\n",
       "250    0\n",
       "251    2\n",
       "252    2\n",
       "Name: pheno, Length: 253, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pheno']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>TTTTTTTTATTTTACTCACCTCTAAAGCATAATTCCATATAAACTTGTTATTATCCGAAATTTTTGTATAATAGATTATTTTTGTTGGAGTAATTATTAG</th>\n",
       "      <th>TTTTTTTGTAAATCTTTTCCATTTATTTCTTCGCTTTTCTCGCTACAATTTACAAATGGACTTGTTATCAACGTTAGGGCAATAAATGAAAGTAGTATAA</th>\n",
       "      <th>TTTTTTTCTTATTATACGAAATTTTCATATCATAGTAAAGTTTTTTACGAAAAAAACGTATTTAATGTTGACAATACGAAAATTTCGTATTATATTAGGT</th>\n",
       "      <th>TTTTTTTCGTAAAAAACTTTACTATGATATGAAAATTTCGTATAATAAGAAAAAAAGGAGGTAAGTAATATGAACAAAGAAAGAAATATTATTATAGCCA</th>\n",
       "      <th>TTTTTTTATTTTGCAATTTTTTATTTTCATTATAAACTTCCTTTCAAACACTGCTGAAATAGACGTCTTTTTCAAATAAGCATGATTAATACTTCAATTC</th>\n",
       "      <th>TTTTTTTATTTTACTCACCTCTAAAGCATAATTCCATATAAACTTGTTATTATCCGAAATTTTTGTATAATAGATTATTTTTGTTGGAGTAATTATTAGT</th>\n",
       "      <th>TTTTTTTATGTTATTATAATTAAAGTTTTCCATTGTTTTCCTCCTATAATAGCTTATCTGCAATCATCACAGCTAATAAATCGTTTTGTCTTATTGCTTC</th>\n",
       "      <th>TTTTTTTATGTTATAATCTTTCTAGACGTATTCAAAGGACGTCTTTTTAGATTGTATGTTATAGCTAGCCTTCCGGTTAATTTTTTGTTATGATGTGTTA</th>\n",
       "      <th>TTTTTTTATAACATTCAAAGTCTCACCATTGTCATTTGAATGATCATCAATAATAATTAATTCGTAATCAGTACTCTTCATTGTTTGATTTAATACAGAA</th>\n",
       "      <th>...</th>\n",
       "      <th>AAATATCTACCTTTTAATTTATGTAACTACTATTAGTATGCATATTCATTAGTTTTACCAGGACCATTAATTACATAAGATGATTTAGACTCTCCTTTTT</th>\n",
       "      <th>AAATAAGTGTGTTAGCTATAAAAAGAGATGAATAAAAACAAATATATTATATTTGGAGGAAGCGCCATGCTCAAAAGAAGTTTATTATTTTTAACTGTTT</th>\n",
       "      <th>AAAGTAGTATAAATGTTGTTTTTTTTATTTTACTCACCTCTAAAGCATAATTCCATATAAACTTGTTATTATCCGAAATTTTTGTATAATAGATTATTTT</th>\n",
       "      <th>AAAGAGATGAATAAAAACAAATATATTATATTTGGAGGAAGCGCCATGCTCAAAAGAAGTTTATTATTTTTAACTGTTTTATTGTTATTATTCTCATTTT</th>\n",
       "      <th>AAACGACCATTCAAAAGAACACGCAAAAGAAACTATAAGAAAAACAAACGGTGCTATTCGGTCAGCTTTAGATGACGCATTATATGATGGACTTATTTTT</th>\n",
       "      <th>AAAATGGTTATAAGAGGGGGGTTATACATGGATTTTTAAAATTATCGCGAAGTCGAGCCCCTCCCCGTTCCCCAAGTATTTTGATCGCTTTTGATTTTTT</th>\n",
       "      <th>AAAAGATTAATTATTTTTAACTAAAAATTAAAGTTCAATTAGTGTTTTGATGAATTTGGTCTTGATAAATTGAAATGATCTAAAAAACGCTATAATTTTT</th>\n",
       "      <th>ST</th>\n",
       "      <th>CC</th>\n",
       "      <th>pheno</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>107</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>109</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>120335</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120337</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7082 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  \\\n",
       "0     107   \n",
       "1     109   \n",
       "2     115   \n",
       "3  120335   \n",
       "4  120337   \n",
       "\n",
       "   TTTTTTTTATTTTACTCACCTCTAAAGCATAATTCCATATAAACTTGTTATTATCCGAAATTTTTGTATAATAGATTATTTTTGTTGGAGTAATTATTAG  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   TTTTTTTGTAAATCTTTTCCATTTATTTCTTCGCTTTTCTCGCTACAATTTACAAATGGACTTGTTATCAACGTTAGGGCAATAAATGAAAGTAGTATAA  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   TTTTTTTCTTATTATACGAAATTTTCATATCATAGTAAAGTTTTTTACGAAAAAAACGTATTTAATGTTGACAATACGAAAATTTCGTATTATATTAGGT  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   TTTTTTTCGTAAAAAACTTTACTATGATATGAAAATTTCGTATAATAAGAAAAAAAGGAGGTAAGTAATATGAACAAAGAAAGAAATATTATTATAGCCA  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   TTTTTTTATTTTGCAATTTTTTATTTTCATTATAAACTTCCTTTCAAACACTGCTGAAATAGACGTCTTTTTCAAATAAGCATGATTAATACTTCAATTC  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   TTTTTTTATTTTACTCACCTCTAAAGCATAATTCCATATAAACTTGTTATTATCCGAAATTTTTGTATAATAGATTATTTTTGTTGGAGTAATTATTAGT  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   TTTTTTTATGTTATTATAATTAAAGTTTTCCATTGTTTTCCTCCTATAATAGCTTATCTGCAATCATCACAGCTAATAAATCGTTTTGTCTTATTGCTTC  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   TTTTTTTATGTTATAATCTTTCTAGACGTATTCAAAGGACGTCTTTTTAGATTGTATGTTATAGCTAGCCTTCCGGTTAATTTTTTGTTATGATGTGTTA  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   TTTTTTTATAACATTCAAAGTCTCACCATTGTCATTTGAATGATCATCAATAATAATTAATTCGTAATCAGTACTCTTCATTGTTTGATTTAATACAGAA  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   ...  \\\n",
       "0  ...   \n",
       "1  ...   \n",
       "2  ...   \n",
       "3  ...   \n",
       "4  ...   \n",
       "\n",
       "   AAATATCTACCTTTTAATTTATGTAACTACTATTAGTATGCATATTCATTAGTTTTACCAGGACCATTAATTACATAAGATGATTTAGACTCTCCTTTTT  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   AAATAAGTGTGTTAGCTATAAAAAGAGATGAATAAAAACAAATATATTATATTTGGAGGAAGCGCCATGCTCAAAAGAAGTTTATTATTTTTAACTGTTT  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   AAAGTAGTATAAATGTTGTTTTTTTTATTTTACTCACCTCTAAAGCATAATTCCATATAAACTTGTTATTATCCGAAATTTTTGTATAATAGATTATTTT  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   AAAGAGATGAATAAAAACAAATATATTATATTTGGAGGAAGCGCCATGCTCAAAAGAAGTTTATTATTTTTAACTGTTTTATTGTTATTATTCTCATTTT  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   AAACGACCATTCAAAAGAACACGCAAAAGAAACTATAAGAAAAACAAACGGTGCTATTCGGTCAGCTTTAGATGACGCATTATATGATGGACTTATTTTT  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   AAAATGGTTATAAGAGGGGGGTTATACATGGATTTTTAAAATTATCGCGAAGTCGAGCCCCTCCCCGTTCCCCAAGTATTTTGATCGCTTTTGATTTTTT  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   AAAAGATTAATTATTTTTAACTAAAAATTAAAGTTCAATTAGTGTTTTGATGAATTTGGTCTTGATAAATTGAAATGATCTAAAAAACGCTATAATTTTT  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   ST  CC  pheno  \n",
       "0   5   5      2  \n",
       "1   8   8      0  \n",
       "2   5   5      2  \n",
       "3   5   5      2  \n",
       "4   5   5      2  \n",
       "\n",
       "[5 rows x 7082 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    91\n",
       "0    88\n",
       "1    74\n",
       "Name: pheno, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pheno'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.drop(columns=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(253, 7081)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TTTTTTTTATTTTACTCACCTCTAAAGCATAATTCCATATAAACTTGTTATTATCCGAAATTTTTGTATAATAGATTATTTTTGTTGGAGTAATTATTAG</th>\n",
       "      <th>TTTTTTTGTAAATCTTTTCCATTTATTTCTTCGCTTTTCTCGCTACAATTTACAAATGGACTTGTTATCAACGTTAGGGCAATAAATGAAAGTAGTATAA</th>\n",
       "      <th>TTTTTTTCTTATTATACGAAATTTTCATATCATAGTAAAGTTTTTTACGAAAAAAACGTATTTAATGTTGACAATACGAAAATTTCGTATTATATTAGGT</th>\n",
       "      <th>TTTTTTTCGTAAAAAACTTTACTATGATATGAAAATTTCGTATAATAAGAAAAAAAGGAGGTAAGTAATATGAACAAAGAAAGAAATATTATTATAGCCA</th>\n",
       "      <th>TTTTTTTATTTTGCAATTTTTTATTTTCATTATAAACTTCCTTTCAAACACTGCTGAAATAGACGTCTTTTTCAAATAAGCATGATTAATACTTCAATTC</th>\n",
       "      <th>TTTTTTTATTTTACTCACCTCTAAAGCATAATTCCATATAAACTTGTTATTATCCGAAATTTTTGTATAATAGATTATTTTTGTTGGAGTAATTATTAGT</th>\n",
       "      <th>TTTTTTTATGTTATTATAATTAAAGTTTTCCATTGTTTTCCTCCTATAATAGCTTATCTGCAATCATCACAGCTAATAAATCGTTTTGTCTTATTGCTTC</th>\n",
       "      <th>TTTTTTTATGTTATAATCTTTCTAGACGTATTCAAAGGACGTCTTTTTAGATTGTATGTTATAGCTAGCCTTCCGGTTAATTTTTTGTTATGATGTGTTA</th>\n",
       "      <th>TTTTTTTATAACATTCAAAGTCTCACCATTGTCATTTGAATGATCATCAATAATAATTAATTCGTAATCAGTACTCTTCATTGTTTGATTTAATACAGAA</th>\n",
       "      <th>TTTTTTTAGGTAATGAATACGAAAATTTCGTATTTACGAACGATAAAAAGAAATCAATTATTTTAGCATTTAAAGAAAAACAAACATCTTAATAGGAGGA</th>\n",
       "      <th>...</th>\n",
       "      <th>AAATATCTACCTTTTAATTTATGTAACTACTATTAGTATGCATATTCATTAGTTTTACCAGGACCATTAATTACATAAGATGATTTAGACTCTCCTTTTT</th>\n",
       "      <th>AAATAAGTGTGTTAGCTATAAAAAGAGATGAATAAAAACAAATATATTATATTTGGAGGAAGCGCCATGCTCAAAAGAAGTTTATTATTTTTAACTGTTT</th>\n",
       "      <th>AAAGTAGTATAAATGTTGTTTTTTTTATTTTACTCACCTCTAAAGCATAATTCCATATAAACTTGTTATTATCCGAAATTTTTGTATAATAGATTATTTT</th>\n",
       "      <th>AAAGAGATGAATAAAAACAAATATATTATATTTGGAGGAAGCGCCATGCTCAAAAGAAGTTTATTATTTTTAACTGTTTTATTGTTATTATTCTCATTTT</th>\n",
       "      <th>AAACGACCATTCAAAAGAACACGCAAAAGAAACTATAAGAAAAACAAACGGTGCTATTCGGTCAGCTTTAGATGACGCATTATATGATGGACTTATTTTT</th>\n",
       "      <th>AAAATGGTTATAAGAGGGGGGTTATACATGGATTTTTAAAATTATCGCGAAGTCGAGCCCCTCCCCGTTCCCCAAGTATTTTGATCGCTTTTGATTTTTT</th>\n",
       "      <th>AAAAGATTAATTATTTTTAACTAAAAATTAAAGTTCAATTAGTGTTTTGATGAATTTGGTCTTGATAAATTGAAATGATCTAAAAAACGCTATAATTTTT</th>\n",
       "      <th>ST</th>\n",
       "      <th>CC</th>\n",
       "      <th>pheno</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7081 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TTTTTTTTATTTTACTCACCTCTAAAGCATAATTCCATATAAACTTGTTATTATCCGAAATTTTTGTATAATAGATTATTTTTGTTGGAGTAATTATTAG  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   TTTTTTTGTAAATCTTTTCCATTTATTTCTTCGCTTTTCTCGCTACAATTTACAAATGGACTTGTTATCAACGTTAGGGCAATAAATGAAAGTAGTATAA  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   TTTTTTTCTTATTATACGAAATTTTCATATCATAGTAAAGTTTTTTACGAAAAAAACGTATTTAATGTTGACAATACGAAAATTTCGTATTATATTAGGT  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   TTTTTTTCGTAAAAAACTTTACTATGATATGAAAATTTCGTATAATAAGAAAAAAAGGAGGTAAGTAATATGAACAAAGAAAGAAATATTATTATAGCCA  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   TTTTTTTATTTTGCAATTTTTTATTTTCATTATAAACTTCCTTTCAAACACTGCTGAAATAGACGTCTTTTTCAAATAAGCATGATTAATACTTCAATTC  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   TTTTTTTATTTTACTCACCTCTAAAGCATAATTCCATATAAACTTGTTATTATCCGAAATTTTTGTATAATAGATTATTTTTGTTGGAGTAATTATTAGT  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   TTTTTTTATGTTATTATAATTAAAGTTTTCCATTGTTTTCCTCCTATAATAGCTTATCTGCAATCATCACAGCTAATAAATCGTTTTGTCTTATTGCTTC  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   TTTTTTTATGTTATAATCTTTCTAGACGTATTCAAAGGACGTCTTTTTAGATTGTATGTTATAGCTAGCCTTCCGGTTAATTTTTTGTTATGATGTGTTA  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   TTTTTTTATAACATTCAAAGTCTCACCATTGTCATTTGAATGATCATCAATAATAATTAATTCGTAATCAGTACTCTTCATTGTTTGATTTAATACAGAA  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   TTTTTTTAGGTAATGAATACGAAAATTTCGTATTTACGAACGATAAAAAGAAATCAATTATTTTAGCATTTAAAGAAAAACAAACATCTTAATAGGAGGA  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   ...  \\\n",
       "0  ...   \n",
       "1  ...   \n",
       "2  ...   \n",
       "3  ...   \n",
       "4  ...   \n",
       "\n",
       "   AAATATCTACCTTTTAATTTATGTAACTACTATTAGTATGCATATTCATTAGTTTTACCAGGACCATTAATTACATAAGATGATTTAGACTCTCCTTTTT  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   AAATAAGTGTGTTAGCTATAAAAAGAGATGAATAAAAACAAATATATTATATTTGGAGGAAGCGCCATGCTCAAAAGAAGTTTATTATTTTTAACTGTTT  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   AAAGTAGTATAAATGTTGTTTTTTTTATTTTACTCACCTCTAAAGCATAATTCCATATAAACTTGTTATTATCCGAAATTTTTGTATAATAGATTATTTT  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   AAAGAGATGAATAAAAACAAATATATTATATTTGGAGGAAGCGCCATGCTCAAAAGAAGTTTATTATTTTTAACTGTTTTATTGTTATTATTCTCATTTT  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   AAACGACCATTCAAAAGAACACGCAAAAGAAACTATAAGAAAAACAAACGGTGCTATTCGGTCAGCTTTAGATGACGCATTATATGATGGACTTATTTTT  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   AAAATGGTTATAAGAGGGGGGTTATACATGGATTTTTAAAATTATCGCGAAGTCGAGCCCCTCCCCGTTCCCCAAGTATTTTGATCGCTTTTGATTTTTT  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   AAAAGATTAATTATTTTTAACTAAAAATTAAAGTTCAATTAGTGTTTTGATGAATTTGGTCTTGATAAATTGAAATGATCTAAAAAACGCTATAATTTTT  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   ST  CC  pheno  \n",
       "0   5   5      2  \n",
       "1   8   8      0  \n",
       "2   5   5      2  \n",
       "3   5   5      2  \n",
       "4   5   5      2  \n",
       "\n",
       "[5 rows x 7081 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(253, 7081) (253,)\n"
     ]
    }
   ],
   "source": [
    "X = df.loc[:, df.columns != 'pheno']\n",
    "y = df['pheno']\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# Fully-Connected Neural Network ################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.regularizers import l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=123,\n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = pd.DataFrame(X_test.iloc[:,0])\n",
    "dat['test'] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>NRS027</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>NRS246</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>NRS218</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>CFBRSa70</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>NRS177</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>SR3585</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>GA50819</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>NRS161</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>CFBREBSa114</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>NRS114</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  test\n",
       "112       NRS027     1\n",
       "207       NRS246     1\n",
       "186       NRS218     2\n",
       "88      CFBRSa70     2\n",
       "156       NRS177     1\n",
       "..           ...   ...\n",
       "244       SR3585     0\n",
       "99       GA50819     2\n",
       "147       NRS161     2\n",
       "49   CFBREBSa114     1\n",
       "140       NRS114     2\n",
       "\n",
       "[76 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(['id'], axis=1)\n",
    "X_test = X_test.drop(['id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### neural network on over-sampling data\n",
    "model1 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 177 samples, validate on 76 samples\n",
      "Epoch 1/100\n",
      "177/177 [==============================] - 0s 3ms/step - loss: 1.8286 - accuracy: 0.3955 - val_loss: 1.7507 - val_accuracy: 0.3947\n",
      "Epoch 2/100\n",
      "177/177 [==============================] - 0s 595us/step - loss: 1.3423 - accuracy: 0.3898 - val_loss: 2.0357 - val_accuracy: 0.3421\n",
      "Epoch 3/100\n",
      "177/177 [==============================] - 0s 469us/step - loss: 1.3016 - accuracy: 0.4237 - val_loss: 1.8341 - val_accuracy: 0.4474\n",
      "Epoch 4/100\n",
      "177/177 [==============================] - 0s 475us/step - loss: 1.1671 - accuracy: 0.4520 - val_loss: 1.5888 - val_accuracy: 0.4737\n",
      "Epoch 5/100\n",
      "177/177 [==============================] - 0s 542us/step - loss: 1.0002 - accuracy: 0.5537 - val_loss: 1.6090 - val_accuracy: 0.4474\n",
      "Epoch 6/100\n",
      "177/177 [==============================] - 0s 643us/step - loss: 0.9303 - accuracy: 0.5932 - val_loss: 1.4015 - val_accuracy: 0.4737\n",
      "Epoch 7/100\n",
      "177/177 [==============================] - 0s 558us/step - loss: 0.9054 - accuracy: 0.5989 - val_loss: 1.5397 - val_accuracy: 0.4605\n",
      "Epoch 8/100\n",
      "177/177 [==============================] - 0s 401us/step - loss: 0.8703 - accuracy: 0.6215 - val_loss: 1.5996 - val_accuracy: 0.5395\n",
      "Epoch 9/100\n",
      "177/177 [==============================] - 0s 440us/step - loss: 0.8259 - accuracy: 0.6554 - val_loss: 1.3922 - val_accuracy: 0.5263\n",
      "Epoch 10/100\n",
      "177/177 [==============================] - 0s 361us/step - loss: 0.7738 - accuracy: 0.6893 - val_loss: 1.5216 - val_accuracy: 0.5132\n",
      "Epoch 11/100\n",
      "177/177 [==============================] - 0s 341us/step - loss: 0.7504 - accuracy: 0.6893 - val_loss: 1.5636 - val_accuracy: 0.5132\n",
      "Epoch 12/100\n",
      "177/177 [==============================] - 0s 330us/step - loss: 0.7205 - accuracy: 0.7006 - val_loss: 1.6141 - val_accuracy: 0.4868\n",
      "Epoch 13/100\n",
      "177/177 [==============================] - 0s 355us/step - loss: 0.7030 - accuracy: 0.6949 - val_loss: 1.5575 - val_accuracy: 0.5000\n",
      "Epoch 14/100\n",
      "177/177 [==============================] - 0s 343us/step - loss: 0.7073 - accuracy: 0.7119 - val_loss: 1.6355 - val_accuracy: 0.4737\n",
      "Epoch 15/100\n",
      "177/177 [==============================] - 0s 373us/step - loss: 0.6581 - accuracy: 0.7571 - val_loss: 1.5109 - val_accuracy: 0.5132\n",
      "Epoch 16/100\n",
      "177/177 [==============================] - 0s 380us/step - loss: 0.6649 - accuracy: 0.7345 - val_loss: 1.6072 - val_accuracy: 0.4474\n",
      "Epoch 17/100\n",
      "177/177 [==============================] - 0s 377us/step - loss: 0.6385 - accuracy: 0.7740 - val_loss: 1.6506 - val_accuracy: 0.4211\n",
      "Epoch 18/100\n",
      "177/177 [==============================] - 0s 570us/step - loss: 0.6220 - accuracy: 0.7684 - val_loss: 1.6172 - val_accuracy: 0.4342\n",
      "Epoch 19/100\n",
      "177/177 [==============================] - 0s 561us/step - loss: 0.6136 - accuracy: 0.7458 - val_loss: 1.6092 - val_accuracy: 0.4342\n",
      "Epoch 20/100\n",
      "177/177 [==============================] - 0s 453us/step - loss: 0.6344 - accuracy: 0.7853 - val_loss: 1.7312 - val_accuracy: 0.4211\n",
      "Epoch 21/100\n",
      "177/177 [==============================] - 0s 558us/step - loss: 0.5680 - accuracy: 0.8023 - val_loss: 1.5919 - val_accuracy: 0.4868\n",
      "Epoch 22/100\n",
      "177/177 [==============================] - 0s 598us/step - loss: 0.5639 - accuracy: 0.8023 - val_loss: 1.6900 - val_accuracy: 0.4079\n",
      "Epoch 23/100\n",
      "177/177 [==============================] - 0s 454us/step - loss: 0.5296 - accuracy: 0.8362 - val_loss: 1.7666 - val_accuracy: 0.4474\n",
      "Epoch 24/100\n",
      "177/177 [==============================] - 0s 400us/step - loss: 0.5197 - accuracy: 0.8531 - val_loss: 1.7945 - val_accuracy: 0.5000\n",
      "Epoch 25/100\n",
      "177/177 [==============================] - 0s 357us/step - loss: 0.5220 - accuracy: 0.8136 - val_loss: 1.7825 - val_accuracy: 0.4211\n",
      "Epoch 26/100\n",
      "177/177 [==============================] - 0s 614us/step - loss: 0.5139 - accuracy: 0.8305 - val_loss: 1.7853 - val_accuracy: 0.4079\n",
      "Epoch 27/100\n",
      "177/177 [==============================] - 0s 1ms/step - loss: 0.5356 - accuracy: 0.8305 - val_loss: 1.8052 - val_accuracy: 0.3816\n",
      "Epoch 28/100\n",
      "177/177 [==============================] - 0s 411us/step - loss: 0.5068 - accuracy: 0.8305 - val_loss: 1.9380 - val_accuracy: 0.4211\n",
      "Epoch 29/100\n",
      "177/177 [==============================] - 0s 567us/step - loss: 0.4729 - accuracy: 0.8249 - val_loss: 1.7716 - val_accuracy: 0.4211\n",
      "Epoch 30/100\n",
      "177/177 [==============================] - 0s 541us/step - loss: 0.4752 - accuracy: 0.8475 - val_loss: 1.7961 - val_accuracy: 0.4605\n",
      "Epoch 31/100\n",
      "177/177 [==============================] - 0s 599us/step - loss: 0.4633 - accuracy: 0.8644 - val_loss: 1.8766 - val_accuracy: 0.4474\n",
      "Epoch 32/100\n",
      "177/177 [==============================] - 0s 384us/step - loss: 0.4175 - accuracy: 0.8814 - val_loss: 1.9389 - val_accuracy: 0.4079\n",
      "Epoch 33/100\n",
      "177/177 [==============================] - 0s 518us/step - loss: 0.4495 - accuracy: 0.8531 - val_loss: 1.8924 - val_accuracy: 0.4079\n",
      "Epoch 34/100\n",
      "177/177 [==============================] - 0s 556us/step - loss: 0.4493 - accuracy: 0.8588 - val_loss: 1.9409 - val_accuracy: 0.4342\n",
      "Epoch 35/100\n",
      "177/177 [==============================] - 0s 536us/step - loss: 0.4248 - accuracy: 0.8588 - val_loss: 2.0037 - val_accuracy: 0.4605\n",
      "Epoch 36/100\n",
      "177/177 [==============================] - 0s 621us/step - loss: 0.4683 - accuracy: 0.8249 - val_loss: 1.9606 - val_accuracy: 0.4605\n",
      "Epoch 37/100\n",
      "177/177 [==============================] - 0s 567us/step - loss: 0.3968 - accuracy: 0.8701 - val_loss: 1.9774 - val_accuracy: 0.4737\n",
      "Epoch 38/100\n",
      "177/177 [==============================] - 0s 398us/step - loss: 0.3776 - accuracy: 0.8814 - val_loss: 2.0974 - val_accuracy: 0.4342\n",
      "Epoch 39/100\n",
      "177/177 [==============================] - 0s 331us/step - loss: 0.3773 - accuracy: 0.8757 - val_loss: 2.0291 - val_accuracy: 0.4868\n",
      "Epoch 40/100\n",
      "177/177 [==============================] - 0s 341us/step - loss: 0.3775 - accuracy: 0.8644 - val_loss: 2.0522 - val_accuracy: 0.4211\n",
      "Epoch 41/100\n",
      "177/177 [==============================] - 0s 358us/step - loss: 0.3521 - accuracy: 0.9040 - val_loss: 2.1223 - val_accuracy: 0.4605\n",
      "Epoch 42/100\n",
      "177/177 [==============================] - 0s 347us/step - loss: 0.3653 - accuracy: 0.8983 - val_loss: 2.1376 - val_accuracy: 0.4605\n",
      "Epoch 43/100\n",
      "177/177 [==============================] - 0s 336us/step - loss: 0.3625 - accuracy: 0.8927 - val_loss: 2.1475 - val_accuracy: 0.4211\n",
      "Epoch 44/100\n",
      "177/177 [==============================] - 0s 319us/step - loss: 0.3652 - accuracy: 0.8701 - val_loss: 2.0899 - val_accuracy: 0.4211\n",
      "Epoch 45/100\n",
      "177/177 [==============================] - 0s 328us/step - loss: 0.3347 - accuracy: 0.8870 - val_loss: 2.1175 - val_accuracy: 0.4605\n",
      "Epoch 46/100\n",
      "177/177 [==============================] - 0s 322us/step - loss: 0.3144 - accuracy: 0.9209 - val_loss: 2.1529 - val_accuracy: 0.4605\n",
      "Epoch 47/100\n",
      "177/177 [==============================] - 0s 342us/step - loss: 0.3261 - accuracy: 0.9153 - val_loss: 2.1786 - val_accuracy: 0.4474\n",
      "Epoch 48/100\n",
      "177/177 [==============================] - 0s 338us/step - loss: 0.3221 - accuracy: 0.8814 - val_loss: 2.0719 - val_accuracy: 0.4474\n",
      "Epoch 49/100\n",
      "177/177 [==============================] - 0s 367us/step - loss: 0.3240 - accuracy: 0.8983 - val_loss: 2.4410 - val_accuracy: 0.3816\n",
      "Epoch 50/100\n",
      "177/177 [==============================] - 0s 480us/step - loss: 0.3210 - accuracy: 0.9040 - val_loss: 2.1871 - val_accuracy: 0.4211\n",
      "Epoch 51/100\n",
      "177/177 [==============================] - 0s 477us/step - loss: 0.3294 - accuracy: 0.8927 - val_loss: 2.0499 - val_accuracy: 0.5000\n",
      "Epoch 52/100\n",
      "177/177 [==============================] - 0s 396us/step - loss: 0.2914 - accuracy: 0.8927 - val_loss: 2.2030 - val_accuracy: 0.4211\n",
      "Epoch 53/100\n",
      "177/177 [==============================] - 0s 330us/step - loss: 0.3014 - accuracy: 0.9040 - val_loss: 2.2716 - val_accuracy: 0.4211\n",
      "Epoch 54/100\n",
      "177/177 [==============================] - 0s 427us/step - loss: 0.3085 - accuracy: 0.8814 - val_loss: 2.4035 - val_accuracy: 0.4211\n",
      "Epoch 55/100\n",
      "177/177 [==============================] - 0s 359us/step - loss: 0.3140 - accuracy: 0.8814 - val_loss: 2.2729 - val_accuracy: 0.4211\n",
      "Epoch 56/100\n",
      "177/177 [==============================] - 0s 331us/step - loss: 0.3218 - accuracy: 0.8757 - val_loss: 2.5584 - val_accuracy: 0.4474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "177/177 [==============================] - 0s 327us/step - loss: 0.3659 - accuracy: 0.8644 - val_loss: 2.1291 - val_accuracy: 0.5000\n",
      "Epoch 58/100\n",
      "177/177 [==============================] - 0s 353us/step - loss: 0.3278 - accuracy: 0.8927 - val_loss: 2.5510 - val_accuracy: 0.3947\n",
      "Epoch 59/100\n",
      "177/177 [==============================] - 0s 361us/step - loss: 0.3172 - accuracy: 0.8757 - val_loss: 2.4577 - val_accuracy: 0.4211\n",
      "Epoch 60/100\n",
      "177/177 [==============================] - 0s 643us/step - loss: 0.2883 - accuracy: 0.8701 - val_loss: 2.2560 - val_accuracy: 0.4342\n",
      "Epoch 61/100\n",
      "177/177 [==============================] - 0s 583us/step - loss: 0.2964 - accuracy: 0.8983 - val_loss: 2.6415 - val_accuracy: 0.4211\n",
      "Epoch 62/100\n",
      "177/177 [==============================] - 0s 404us/step - loss: 0.2803 - accuracy: 0.9096 - val_loss: 2.6270 - val_accuracy: 0.4079\n",
      "Epoch 63/100\n",
      "177/177 [==============================] - 0s 413us/step - loss: 0.2763 - accuracy: 0.9040 - val_loss: 2.3129 - val_accuracy: 0.4605\n",
      "Epoch 64/100\n",
      "177/177 [==============================] - 0s 610us/step - loss: 0.2637 - accuracy: 0.9040 - val_loss: 2.5245 - val_accuracy: 0.4079\n",
      "Epoch 65/100\n",
      "177/177 [==============================] - 0s 393us/step - loss: 0.2541 - accuracy: 0.9209 - val_loss: 2.3668 - val_accuracy: 0.4342\n",
      "Epoch 66/100\n",
      "177/177 [==============================] - 0s 339us/step - loss: 0.2400 - accuracy: 0.9266 - val_loss: 2.6700 - val_accuracy: 0.4211\n",
      "Epoch 67/100\n",
      "177/177 [==============================] - 0s 359us/step - loss: 0.2320 - accuracy: 0.9266 - val_loss: 2.6719 - val_accuracy: 0.4211\n",
      "Epoch 68/100\n",
      "177/177 [==============================] - 0s 348us/step - loss: 0.2220 - accuracy: 0.9379 - val_loss: 2.6506 - val_accuracy: 0.4079\n",
      "Epoch 69/100\n",
      "177/177 [==============================] - 0s 390us/step - loss: 0.2196 - accuracy: 0.9266 - val_loss: 2.7687 - val_accuracy: 0.4211\n",
      "Epoch 70/100\n",
      "177/177 [==============================] - 0s 322us/step - loss: 0.2078 - accuracy: 0.9435 - val_loss: 2.6354 - val_accuracy: 0.4079\n",
      "Epoch 71/100\n",
      "177/177 [==============================] - 0s 681us/step - loss: 0.2105 - accuracy: 0.9322 - val_loss: 2.6967 - val_accuracy: 0.4079\n",
      "Epoch 72/100\n",
      "177/177 [==============================] - 0s 532us/step - loss: 0.2063 - accuracy: 0.9379 - val_loss: 2.8089 - val_accuracy: 0.4342\n",
      "Epoch 73/100\n",
      "177/177 [==============================] - 0s 445us/step - loss: 0.1982 - accuracy: 0.9379 - val_loss: 2.5948 - val_accuracy: 0.4342\n",
      "Epoch 74/100\n",
      "177/177 [==============================] - 0s 391us/step - loss: 0.2211 - accuracy: 0.9322 - val_loss: 2.5865 - val_accuracy: 0.4211\n",
      "Epoch 75/100\n",
      "177/177 [==============================] - 0s 431us/step - loss: 0.2053 - accuracy: 0.9379 - val_loss: 2.8183 - val_accuracy: 0.4079\n",
      "Epoch 76/100\n",
      "177/177 [==============================] - 0s 422us/step - loss: 0.1774 - accuracy: 0.9492 - val_loss: 2.8037 - val_accuracy: 0.4079\n",
      "Epoch 77/100\n",
      "177/177 [==============================] - 0s 381us/step - loss: 0.2220 - accuracy: 0.9322 - val_loss: 2.9666 - val_accuracy: 0.4211\n",
      "Epoch 78/100\n",
      "177/177 [==============================] - 0s 382us/step - loss: 0.1909 - accuracy: 0.9548 - val_loss: 2.8803 - val_accuracy: 0.4079\n",
      "Epoch 79/100\n",
      "177/177 [==============================] - 0s 367us/step - loss: 0.1982 - accuracy: 0.9492 - val_loss: 2.9188 - val_accuracy: 0.3947\n",
      "Epoch 80/100\n",
      "177/177 [==============================] - 0s 338us/step - loss: 0.2188 - accuracy: 0.9266 - val_loss: 2.9241 - val_accuracy: 0.4211\n",
      "Epoch 81/100\n",
      "177/177 [==============================] - 0s 407us/step - loss: 0.2036 - accuracy: 0.9266 - val_loss: 3.2066 - val_accuracy: 0.3947\n",
      "Epoch 82/100\n",
      "177/177 [==============================] - 0s 443us/step - loss: 0.2362 - accuracy: 0.9209 - val_loss: 2.7773 - val_accuracy: 0.4211\n",
      "Epoch 83/100\n",
      "177/177 [==============================] - 0s 494us/step - loss: 0.2222 - accuracy: 0.9435 - val_loss: 3.4193 - val_accuracy: 0.4211\n",
      "Epoch 84/100\n",
      "177/177 [==============================] - 0s 352us/step - loss: 0.2070 - accuracy: 0.9153 - val_loss: 2.4975 - val_accuracy: 0.4868\n",
      "Epoch 85/100\n",
      "177/177 [==============================] - 0s 344us/step - loss: 0.2418 - accuracy: 0.9153 - val_loss: 2.6019 - val_accuracy: 0.4474\n",
      "Epoch 86/100\n",
      "177/177 [==============================] - 0s 358us/step - loss: 0.2388 - accuracy: 0.9266 - val_loss: 3.3824 - val_accuracy: 0.3816\n",
      "Epoch 87/100\n",
      "177/177 [==============================] - 0s 364us/step - loss: 0.2283 - accuracy: 0.9322 - val_loss: 2.8028 - val_accuracy: 0.3684\n",
      "Epoch 88/100\n",
      "177/177 [==============================] - 0s 374us/step - loss: 0.1908 - accuracy: 0.9435 - val_loss: 2.7463 - val_accuracy: 0.4211\n",
      "Epoch 89/100\n",
      "177/177 [==============================] - 0s 475us/step - loss: 0.1653 - accuracy: 0.9379 - val_loss: 2.9658 - val_accuracy: 0.3947\n",
      "Epoch 90/100\n",
      "177/177 [==============================] - 0s 524us/step - loss: 0.1906 - accuracy: 0.9492 - val_loss: 2.8986 - val_accuracy: 0.4211\n",
      "Epoch 91/100\n",
      "177/177 [==============================] - 0s 373us/step - loss: 0.1794 - accuracy: 0.9492 - val_loss: 2.7943 - val_accuracy: 0.4211\n",
      "Epoch 92/100\n",
      "177/177 [==============================] - 0s 341us/step - loss: 0.1767 - accuracy: 0.9379 - val_loss: 3.3642 - val_accuracy: 0.3947\n",
      "Epoch 93/100\n",
      "177/177 [==============================] - 0s 347us/step - loss: 0.1749 - accuracy: 0.9435 - val_loss: 2.9445 - val_accuracy: 0.3947\n",
      "Epoch 94/100\n",
      "177/177 [==============================] - 0s 531us/step - loss: 0.1734 - accuracy: 0.9379 - val_loss: 3.0579 - val_accuracy: 0.4211\n",
      "Epoch 95/100\n",
      "177/177 [==============================] - 0s 422us/step - loss: 0.1521 - accuracy: 0.9548 - val_loss: 3.0838 - val_accuracy: 0.4079\n",
      "Epoch 96/100\n",
      "177/177 [==============================] - 0s 538us/step - loss: 0.1622 - accuracy: 0.9492 - val_loss: 3.1245 - val_accuracy: 0.3947\n",
      "Epoch 97/100\n",
      "177/177 [==============================] - 0s 437us/step - loss: 0.1631 - accuracy: 0.9379 - val_loss: 3.1505 - val_accuracy: 0.3684\n",
      "Epoch 98/100\n",
      "177/177 [==============================] - 0s 584us/step - loss: 0.1535 - accuracy: 0.9661 - val_loss: 3.2044 - val_accuracy: 0.4211\n",
      "Epoch 99/100\n",
      "177/177 [==============================] - 0s 551us/step - loss: 0.1528 - accuracy: 0.9322 - val_loss: 3.2344 - val_accuracy: 0.3947\n",
      "Epoch 100/100\n",
      "177/177 [==============================] - 0s 419us/step - loss: 0.1415 - accuracy: 0.9548 - val_loss: 3.5213 - val_accuracy: 0.3684\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a37be11d0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(X_train, y_train,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 0s 146us/step\n",
      "test accuracy: 46.05%\n"
     ]
    }
   ],
   "source": [
    "acc_test1 = model1.evaluate(X_test, y_test)[1]\n",
    "print('test accuracy: %.2f%%' % (acc_test1*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 0, 0, 0, 0, 2, 0, 1, 2, 2, 2, 0, 1, 2, 2, 1, 0, 0,\n",
       "       2, 2, 1, 0, 0, 1, 1, 1, 1, 2, 1, 1, 2, 2, 0, 2, 0, 0, 1, 0, 0, 0,\n",
       "       2, 2, 1, 0, 1, 2, 2, 1, 0, 2, 1, 2, 0, 1, 1, 0, 0, 1, 0, 2, 1, 1,\n",
       "       0, 2, 1, 1, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model1.predict_classes(X_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>NRS027</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>NRS246</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>NRS218</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>CFBRSa70</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>NRS177</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>SR3585</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>GA50819</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>NRS161</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>CFBREBSa114</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>NRS114</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  test  pred\n",
       "112       NRS027     1     0\n",
       "207       NRS246     1     0\n",
       "186       NRS218     2     0\n",
       "88      CFBRSa70     2     0\n",
       "156       NRS177     1     1\n",
       "..           ...   ...   ...\n",
       "244       SR3585     0     0\n",
       "99       GA50819     2     0\n",
       "147       NRS161     2     0\n",
       "49   CFBREBSa114     1     0\n",
       "140       NRS114     2     0\n",
       "\n",
       "[76 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat['pred'] = pred\n",
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba1 = model1.predict_proba(X_test)\n",
    "dat_proba1 = pd.DataFrame(proba1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.984498</td>\n",
       "      <td>0.003820</td>\n",
       "      <td>0.011683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.788082</td>\n",
       "      <td>0.154701</td>\n",
       "      <td>0.057217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.737957</td>\n",
       "      <td>0.170649</td>\n",
       "      <td>0.091394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.675271</td>\n",
       "      <td>0.005887</td>\n",
       "      <td>0.318842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.020528</td>\n",
       "      <td>0.969990</td>\n",
       "      <td>0.009482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.543581</td>\n",
       "      <td>0.044045</td>\n",
       "      <td>0.412374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.980923</td>\n",
       "      <td>0.017977</td>\n",
       "      <td>0.001100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.999027</td>\n",
       "      <td>0.000967</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.838052</td>\n",
       "      <td>0.122710</td>\n",
       "      <td>0.039238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.790052</td>\n",
       "      <td>0.129668</td>\n",
       "      <td>0.080280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2\n",
       "0   0.984498  0.003820  0.011683\n",
       "1   0.788082  0.154701  0.057217\n",
       "2   0.737957  0.170649  0.091394\n",
       "3   0.675271  0.005887  0.318842\n",
       "4   0.020528  0.969990  0.009482\n",
       "..       ...       ...       ...\n",
       "71  0.543581  0.044045  0.412374\n",
       "72  0.980923  0.017977  0.001100\n",
       "73  0.999027  0.000967  0.000006\n",
       "74  0.838052  0.122710  0.039238\n",
       "75  0.790052  0.129668  0.080280\n",
       "\n",
       "[76 rows x 3 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba1.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba1.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/1p17ST.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 177 samples, validate on 76 samples\n",
      "Epoch 1/100\n",
      "177/177 [==============================] - 0s 505us/step - loss: 0.1900 - accuracy: 0.9322 - val_loss: 2.1362 - val_accuracy: 0.4342\n",
      "Epoch 2/100\n",
      "177/177 [==============================] - 0s 421us/step - loss: 0.2072 - accuracy: 0.9266 - val_loss: 2.3325 - val_accuracy: 0.4737\n",
      "Epoch 3/100\n",
      "177/177 [==============================] - 0s 457us/step - loss: 0.1913 - accuracy: 0.9209 - val_loss: 1.8385 - val_accuracy: 0.4342\n",
      "Epoch 4/100\n",
      "177/177 [==============================] - 0s 411us/step - loss: 0.2013 - accuracy: 0.9435 - val_loss: 2.1156 - val_accuracy: 0.4605\n",
      "Epoch 5/100\n",
      "177/177 [==============================] - 0s 378us/step - loss: 0.1875 - accuracy: 0.9266 - val_loss: 2.3817 - val_accuracy: 0.4868\n",
      "Epoch 6/100\n",
      "177/177 [==============================] - 0s 380us/step - loss: 0.2032 - accuracy: 0.9209 - val_loss: 2.2680 - val_accuracy: 0.5000\n",
      "Epoch 7/100\n",
      "177/177 [==============================] - 0s 351us/step - loss: 0.1810 - accuracy: 0.9379 - val_loss: 2.6080 - val_accuracy: 0.4737\n",
      "Epoch 8/100\n",
      "177/177 [==============================] - 0s 384us/step - loss: 0.1996 - accuracy: 0.9379 - val_loss: 2.4180 - val_accuracy: 0.4737\n",
      "Epoch 9/100\n",
      "177/177 [==============================] - 0s 384us/step - loss: 0.1827 - accuracy: 0.9209 - val_loss: 2.3451 - val_accuracy: 0.5000\n",
      "Epoch 10/100\n",
      "177/177 [==============================] - 0s 390us/step - loss: 0.1777 - accuracy: 0.9435 - val_loss: 2.3910 - val_accuracy: 0.5263\n",
      "Epoch 11/100\n",
      "177/177 [==============================] - 0s 379us/step - loss: 0.1728 - accuracy: 0.9492 - val_loss: 2.2033 - val_accuracy: 0.4868\n",
      "Epoch 12/100\n",
      "177/177 [==============================] - 0s 343us/step - loss: 0.1609 - accuracy: 0.9492 - val_loss: 2.1554 - val_accuracy: 0.4737\n",
      "Epoch 13/100\n",
      "177/177 [==============================] - 0s 377us/step - loss: 0.1698 - accuracy: 0.9266 - val_loss: 2.6651 - val_accuracy: 0.5000\n",
      "Epoch 14/100\n",
      "177/177 [==============================] - 0s 357us/step - loss: 0.1719 - accuracy: 0.9322 - val_loss: 2.4871 - val_accuracy: 0.4868\n",
      "Epoch 15/100\n",
      "177/177 [==============================] - 0s 360us/step - loss: 0.1563 - accuracy: 0.9605 - val_loss: 2.5839 - val_accuracy: 0.4868\n",
      "Epoch 16/100\n",
      "177/177 [==============================] - 0s 353us/step - loss: 0.1554 - accuracy: 0.9605 - val_loss: 2.5144 - val_accuracy: 0.4605\n",
      "Epoch 17/100\n",
      "177/177 [==============================] - 0s 345us/step - loss: 0.1548 - accuracy: 0.9435 - val_loss: 2.5352 - val_accuracy: 0.4605\n",
      "Epoch 18/100\n",
      "177/177 [==============================] - 0s 397us/step - loss: 0.1580 - accuracy: 0.9492 - val_loss: 2.3391 - val_accuracy: 0.4868\n",
      "Epoch 19/100\n",
      "177/177 [==============================] - 0s 354us/step - loss: 0.1399 - accuracy: 0.9718 - val_loss: 2.2921 - val_accuracy: 0.4868\n",
      "Epoch 20/100\n",
      "177/177 [==============================] - 0s 359us/step - loss: 0.1426 - accuracy: 0.9605 - val_loss: 2.4947 - val_accuracy: 0.4868\n",
      "Epoch 21/100\n",
      "177/177 [==============================] - 0s 368us/step - loss: 0.1360 - accuracy: 0.9548 - val_loss: 2.6137 - val_accuracy: 0.4868\n",
      "Epoch 22/100\n",
      "177/177 [==============================] - 0s 359us/step - loss: 0.1485 - accuracy: 0.9435 - val_loss: 2.4807 - val_accuracy: 0.4605\n",
      "Epoch 23/100\n",
      "177/177 [==============================] - 0s 357us/step - loss: 0.1447 - accuracy: 0.9548 - val_loss: 2.5468 - val_accuracy: 0.4737\n",
      "Epoch 24/100\n",
      "177/177 [==============================] - 0s 368us/step - loss: 0.1397 - accuracy: 0.9718 - val_loss: 2.6183 - val_accuracy: 0.5000\n",
      "Epoch 25/100\n",
      "177/177 [==============================] - 0s 362us/step - loss: 0.1401 - accuracy: 0.9605 - val_loss: 2.5396 - val_accuracy: 0.4474\n",
      "Epoch 26/100\n",
      "177/177 [==============================] - 0s 431us/step - loss: 0.1403 - accuracy: 0.9492 - val_loss: 2.5469 - val_accuracy: 0.5132\n",
      "Epoch 27/100\n",
      "177/177 [==============================] - 0s 410us/step - loss: 0.1427 - accuracy: 0.9548 - val_loss: 2.6695 - val_accuracy: 0.4737\n",
      "Epoch 28/100\n",
      "177/177 [==============================] - 0s 586us/step - loss: 0.1347 - accuracy: 0.9718 - val_loss: 2.5144 - val_accuracy: 0.4737\n",
      "Epoch 29/100\n",
      "177/177 [==============================] - 0s 406us/step - loss: 0.1521 - accuracy: 0.9548 - val_loss: 2.3386 - val_accuracy: 0.5132\n",
      "Epoch 30/100\n",
      "177/177 [==============================] - 0s 433us/step - loss: 0.1407 - accuracy: 0.9548 - val_loss: 2.7025 - val_accuracy: 0.4737\n",
      "Epoch 31/100\n",
      "177/177 [==============================] - 0s 461us/step - loss: 0.1372 - accuracy: 0.9718 - val_loss: 2.6777 - val_accuracy: 0.4605\n",
      "Epoch 32/100\n",
      "177/177 [==============================] - 0s 420us/step - loss: 0.1644 - accuracy: 0.9605 - val_loss: 2.5244 - val_accuracy: 0.4737\n",
      "Epoch 33/100\n",
      "177/177 [==============================] - 0s 372us/step - loss: 0.1451 - accuracy: 0.9492 - val_loss: 2.3380 - val_accuracy: 0.5000\n",
      "Epoch 34/100\n",
      "177/177 [==============================] - 0s 539us/step - loss: 0.1286 - accuracy: 0.9548 - val_loss: 2.3175 - val_accuracy: 0.4737\n",
      "Epoch 35/100\n",
      "177/177 [==============================] - 0s 646us/step - loss: 0.1211 - accuracy: 0.9661 - val_loss: 2.7360 - val_accuracy: 0.4737\n",
      "Epoch 36/100\n",
      "177/177 [==============================] - 0s 703us/step - loss: 0.1250 - accuracy: 0.9605 - val_loss: 2.7592 - val_accuracy: 0.4474\n",
      "Epoch 37/100\n",
      "177/177 [==============================] - 0s 429us/step - loss: 0.1287 - accuracy: 0.9492 - val_loss: 2.6046 - val_accuracy: 0.4868\n",
      "Epoch 38/100\n",
      "177/177 [==============================] - 0s 371us/step - loss: 0.1232 - accuracy: 0.9379 - val_loss: 2.6218 - val_accuracy: 0.4737\n",
      "Epoch 39/100\n",
      "177/177 [==============================] - 0s 421us/step - loss: 0.1214 - accuracy: 0.9548 - val_loss: 2.6930 - val_accuracy: 0.4737\n",
      "Epoch 40/100\n",
      "177/177 [==============================] - 0s 428us/step - loss: 0.1195 - accuracy: 0.9548 - val_loss: 2.6785 - val_accuracy: 0.4605\n",
      "Epoch 41/100\n",
      "177/177 [==============================] - 0s 374us/step - loss: 0.1225 - accuracy: 0.9605 - val_loss: 2.8647 - val_accuracy: 0.4737\n",
      "Epoch 42/100\n",
      "177/177 [==============================] - 0s 340us/step - loss: 0.1178 - accuracy: 0.9718 - val_loss: 2.7983 - val_accuracy: 0.4474\n",
      "Epoch 43/100\n",
      "177/177 [==============================] - 0s 336us/step - loss: 0.1122 - accuracy: 0.9661 - val_loss: 2.8625 - val_accuracy: 0.4737\n",
      "Epoch 44/100\n",
      "177/177 [==============================] - 0s 367us/step - loss: 0.1204 - accuracy: 0.9492 - val_loss: 2.6696 - val_accuracy: 0.4868\n",
      "Epoch 45/100\n",
      "177/177 [==============================] - 0s 475us/step - loss: 0.1124 - accuracy: 0.9605 - val_loss: 2.7602 - val_accuracy: 0.4474\n",
      "Epoch 46/100\n",
      "177/177 [==============================] - 0s 573us/step - loss: 0.1155 - accuracy: 0.9718 - val_loss: 2.8843 - val_accuracy: 0.5000\n",
      "Epoch 47/100\n",
      "177/177 [==============================] - 0s 345us/step - loss: 0.1040 - accuracy: 0.9718 - val_loss: 2.5649 - val_accuracy: 0.4737\n",
      "Epoch 48/100\n",
      "177/177 [==============================] - 0s 339us/step - loss: 0.1272 - accuracy: 0.9718 - val_loss: 2.7197 - val_accuracy: 0.4474\n",
      "Epoch 49/100\n",
      "177/177 [==============================] - 0s 338us/step - loss: 0.1064 - accuracy: 0.9661 - val_loss: 2.9313 - val_accuracy: 0.4737\n",
      "Epoch 50/100\n",
      "177/177 [==============================] - 0s 408us/step - loss: 0.1189 - accuracy: 0.9661 - val_loss: 2.9168 - val_accuracy: 0.4605\n",
      "Epoch 51/100\n",
      "177/177 [==============================] - 0s 491us/step - loss: 0.1043 - accuracy: 0.9718 - val_loss: 2.8938 - val_accuracy: 0.4474\n",
      "Epoch 52/100\n",
      "177/177 [==============================] - 0s 658us/step - loss: 0.1009 - accuracy: 0.9774 - val_loss: 2.9296 - val_accuracy: 0.4868\n",
      "Epoch 53/100\n",
      "177/177 [==============================] - 0s 442us/step - loss: 0.1109 - accuracy: 0.9548 - val_loss: 2.7793 - val_accuracy: 0.4474\n",
      "Epoch 54/100\n",
      "177/177 [==============================] - 0s 327us/step - loss: 0.1011 - accuracy: 0.9774 - val_loss: 2.7692 - val_accuracy: 0.4737\n",
      "Epoch 55/100\n",
      "177/177 [==============================] - 0s 400us/step - loss: 0.1120 - accuracy: 0.9718 - val_loss: 2.9148 - val_accuracy: 0.4737\n",
      "Epoch 56/100\n",
      "177/177 [==============================] - 0s 447us/step - loss: 0.1052 - accuracy: 0.9548 - val_loss: 2.9174 - val_accuracy: 0.4605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "177/177 [==============================] - 0s 446us/step - loss: 0.1094 - accuracy: 0.9661 - val_loss: 2.9556 - val_accuracy: 0.4737\n",
      "Epoch 58/100\n",
      "177/177 [==============================] - 0s 515us/step - loss: 0.0958 - accuracy: 0.9661 - val_loss: 2.7513 - val_accuracy: 0.4868\n",
      "Epoch 59/100\n",
      "177/177 [==============================] - 0s 462us/step - loss: 0.0925 - accuracy: 0.9718 - val_loss: 2.8178 - val_accuracy: 0.4737\n",
      "Epoch 60/100\n",
      "177/177 [==============================] - 0s 337us/step - loss: 0.0975 - accuracy: 0.9605 - val_loss: 3.0080 - val_accuracy: 0.4605\n",
      "Epoch 61/100\n",
      "177/177 [==============================] - 0s 336us/step - loss: 0.1086 - accuracy: 0.9379 - val_loss: 3.0334 - val_accuracy: 0.4737\n",
      "Epoch 62/100\n",
      "177/177 [==============================] - 0s 324us/step - loss: 0.1030 - accuracy: 0.9548 - val_loss: 2.9800 - val_accuracy: 0.5132\n",
      "Epoch 63/100\n",
      "177/177 [==============================] - 0s 319us/step - loss: 0.0961 - accuracy: 0.9605 - val_loss: 3.0126 - val_accuracy: 0.4868\n",
      "Epoch 64/100\n",
      "177/177 [==============================] - 0s 331us/step - loss: 0.0954 - accuracy: 0.9661 - val_loss: 3.0300 - val_accuracy: 0.4737\n",
      "Epoch 65/100\n",
      "177/177 [==============================] - 0s 323us/step - loss: 0.1084 - accuracy: 0.9605 - val_loss: 3.1646 - val_accuracy: 0.4737\n",
      "Epoch 66/100\n",
      "177/177 [==============================] - 0s 347us/step - loss: 0.0930 - accuracy: 0.9605 - val_loss: 2.8449 - val_accuracy: 0.4737\n",
      "Epoch 67/100\n",
      "177/177 [==============================] - 0s 360us/step - loss: 0.1123 - accuracy: 0.9605 - val_loss: 3.2027 - val_accuracy: 0.4605\n",
      "Epoch 68/100\n",
      "177/177 [==============================] - 0s 556us/step - loss: 0.1230 - accuracy: 0.9605 - val_loss: 2.7643 - val_accuracy: 0.4737\n",
      "Epoch 69/100\n",
      "177/177 [==============================] - 0s 817us/step - loss: 0.1000 - accuracy: 0.9718 - val_loss: 2.7139 - val_accuracy: 0.4737\n",
      "Epoch 70/100\n",
      "177/177 [==============================] - 0s 699us/step - loss: 0.1095 - accuracy: 0.9548 - val_loss: 3.1420 - val_accuracy: 0.4868\n",
      "Epoch 71/100\n",
      "177/177 [==============================] - 0s 561us/step - loss: 0.0881 - accuracy: 0.9605 - val_loss: 2.9845 - val_accuracy: 0.4868\n",
      "Epoch 72/100\n",
      "177/177 [==============================] - 0s 586us/step - loss: 0.0955 - accuracy: 0.9718 - val_loss: 3.1468 - val_accuracy: 0.5000\n",
      "Epoch 73/100\n",
      "177/177 [==============================] - 0s 439us/step - loss: 0.0973 - accuracy: 0.9774 - val_loss: 3.0208 - val_accuracy: 0.4737\n",
      "Epoch 74/100\n",
      "177/177 [==============================] - 0s 490us/step - loss: 0.1190 - accuracy: 0.9605 - val_loss: 2.8564 - val_accuracy: 0.4737\n",
      "Epoch 75/100\n",
      "177/177 [==============================] - 0s 327us/step - loss: 0.0937 - accuracy: 0.9718 - val_loss: 3.3383 - val_accuracy: 0.4605\n",
      "Epoch 76/100\n",
      "177/177 [==============================] - 0s 332us/step - loss: 0.0936 - accuracy: 0.9661 - val_loss: 3.0824 - val_accuracy: 0.4605\n",
      "Epoch 77/100\n",
      "177/177 [==============================] - 0s 515us/step - loss: 0.0891 - accuracy: 0.9661 - val_loss: 2.9053 - val_accuracy: 0.4737\n",
      "Epoch 78/100\n",
      "177/177 [==============================] - 0s 454us/step - loss: 0.0899 - accuracy: 0.9548 - val_loss: 3.0862 - val_accuracy: 0.4737\n",
      "Epoch 79/100\n",
      "177/177 [==============================] - 0s 337us/step - loss: 0.0878 - accuracy: 0.9661 - val_loss: 3.0916 - val_accuracy: 0.4868\n",
      "Epoch 80/100\n",
      "177/177 [==============================] - 0s 333us/step - loss: 0.0864 - accuracy: 0.9774 - val_loss: 3.1486 - val_accuracy: 0.4737\n",
      "Epoch 81/100\n",
      "177/177 [==============================] - 0s 350us/step - loss: 0.0769 - accuracy: 0.9774 - val_loss: 3.3476 - val_accuracy: 0.4737\n",
      "Epoch 82/100\n",
      "177/177 [==============================] - 0s 489us/step - loss: 0.0861 - accuracy: 0.9718 - val_loss: 3.2488 - val_accuracy: 0.4737\n",
      "Epoch 83/100\n",
      "177/177 [==============================] - 0s 399us/step - loss: 0.0858 - accuracy: 0.9661 - val_loss: 3.2562 - val_accuracy: 0.5000\n",
      "Epoch 84/100\n",
      "177/177 [==============================] - 0s 411us/step - loss: 0.1092 - accuracy: 0.9435 - val_loss: 3.1487 - val_accuracy: 0.5000\n",
      "Epoch 85/100\n",
      "177/177 [==============================] - 0s 350us/step - loss: 0.0981 - accuracy: 0.9774 - val_loss: 3.1674 - val_accuracy: 0.4737\n",
      "Epoch 86/100\n",
      "177/177 [==============================] - 0s 336us/step - loss: 0.0979 - accuracy: 0.9661 - val_loss: 3.2824 - val_accuracy: 0.4605\n",
      "Epoch 87/100\n",
      "177/177 [==============================] - 0s 333us/step - loss: 0.0987 - accuracy: 0.9605 - val_loss: 3.1661 - val_accuracy: 0.4474\n",
      "Epoch 88/100\n",
      "177/177 [==============================] - 0s 328us/step - loss: 0.0920 - accuracy: 0.9605 - val_loss: 3.4336 - val_accuracy: 0.4737\n",
      "Epoch 89/100\n",
      "177/177 [==============================] - 0s 329us/step - loss: 0.0846 - accuracy: 0.9774 - val_loss: 3.0996 - val_accuracy: 0.5000\n",
      "Epoch 90/100\n",
      "177/177 [==============================] - 0s 384us/step - loss: 0.0830 - accuracy: 0.9605 - val_loss: 3.0340 - val_accuracy: 0.4737\n",
      "Epoch 91/100\n",
      "177/177 [==============================] - 0s 357us/step - loss: 0.0854 - accuracy: 0.9605 - val_loss: 3.1721 - val_accuracy: 0.4737\n",
      "Epoch 92/100\n",
      "177/177 [==============================] - 0s 341us/step - loss: 0.0904 - accuracy: 0.9605 - val_loss: 3.1463 - val_accuracy: 0.4868\n",
      "Epoch 93/100\n",
      "177/177 [==============================] - 0s 324us/step - loss: 0.0847 - accuracy: 0.9774 - val_loss: 3.2591 - val_accuracy: 0.5000\n",
      "Epoch 94/100\n",
      "177/177 [==============================] - 0s 434us/step - loss: 0.0801 - accuracy: 0.9774 - val_loss: 2.9781 - val_accuracy: 0.4737\n",
      "Epoch 95/100\n",
      "177/177 [==============================] - 0s 367us/step - loss: 0.0964 - accuracy: 0.9661 - val_loss: 3.1817 - val_accuracy: 0.5000\n",
      "Epoch 96/100\n",
      "177/177 [==============================] - 0s 344us/step - loss: 0.0784 - accuracy: 0.9718 - val_loss: 3.3834 - val_accuracy: 0.5000\n",
      "Epoch 97/100\n",
      "177/177 [==============================] - 0s 334us/step - loss: 0.0777 - accuracy: 0.9718 - val_loss: 3.1460 - val_accuracy: 0.4868\n",
      "Epoch 98/100\n",
      "177/177 [==============================] - 0s 335us/step - loss: 0.0903 - accuracy: 0.9605 - val_loss: 3.3049 - val_accuracy: 0.5000\n",
      "Epoch 99/100\n",
      "177/177 [==============================] - 0s 413us/step - loss: 0.0775 - accuracy: 0.9661 - val_loss: 3.2130 - val_accuracy: 0.4868\n",
      "Epoch 100/100\n",
      "177/177 [==============================] - 0s 432us/step - loss: 0.0903 - accuracy: 0.9548 - val_loss: 3.3373 - val_accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "hist1 = model1.fit(X_train, y_train,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 95.86%\n"
     ]
    }
   ],
   "source": [
    "print('train accuracy: %.2f%%' % (np.mean(hist1.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_2.xlsx\",\n",
    "                        sheet_name=0,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NRS027</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.759813</td>\n",
       "      <td>0.001304</td>\n",
       "      <td>0.238883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NRS246</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.947819</td>\n",
       "      <td>0.009591</td>\n",
       "      <td>0.042591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NRS218</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.008693</td>\n",
       "      <td>0.989390</td>\n",
       "      <td>0.001916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>CFBRSa70</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.813774</td>\n",
       "      <td>0.001482</td>\n",
       "      <td>0.184744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NRS177</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000916</td>\n",
       "      <td>0.998926</td>\n",
       "      <td>0.000157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>NRS187</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.216843</td>\n",
       "      <td>0.568123</td>\n",
       "      <td>0.215034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>SR1287</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.418802</td>\n",
       "      <td>0.553160</td>\n",
       "      <td>0.028038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>CFBRSa50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.948100</td>\n",
       "      <td>0.035031</td>\n",
       "      <td>0.016869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>NRS196</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000964</td>\n",
       "      <td>0.039095</td>\n",
       "      <td>0.959940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>NRS072</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.795570</td>\n",
       "      <td>0.187358</td>\n",
       "      <td>0.017072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>608 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     phage    strain  phenotype  prediction         0  \\\n",
       "0       p0017kpresabs_qual    NRS027          1           0  0.759813   \n",
       "1       p0017kpresabs_qual    NRS246          1           0  0.947819   \n",
       "2       p0017kpresabs_qual    NRS218          2           1  0.008693   \n",
       "3       p0017kpresabs_qual  CFBRSa70          2           0  0.813774   \n",
       "4       p0017kpresabs_qual    NRS177          1           1  0.000916   \n",
       "..                     ...       ...        ...         ...       ...   \n",
       "603  p0040presabsSTCC_qual    NRS187          1           1  0.216843   \n",
       "604  p0040presabsSTCC_qual    SR1287          0           1  0.418802   \n",
       "605  p0040presabsSTCC_qual  CFBRSa50          0           0  0.948100   \n",
       "606  p0040presabsSTCC_qual    NRS196          2           2  0.000964   \n",
       "607  p0040presabsSTCC_qual    NRS072          0           0  0.795570   \n",
       "\n",
       "            1         2  \n",
       "0    0.001304  0.238883  \n",
       "1    0.009591  0.042591  \n",
       "2    0.989390  0.001916  \n",
       "3    0.001482  0.184744  \n",
       "4    0.998926  0.000157  \n",
       "..        ...       ...  \n",
       "603  0.568123  0.215034  \n",
       "604  0.553160  0.028038  \n",
       "605  0.035031  0.016869  \n",
       "606  0.039095  0.959940  \n",
       "607  0.187358  0.017072  \n",
       "\n",
       "[608 rows x 7 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.84497600e-01, 3.81966210e-03, 1.16827550e-02],\n",
       "       [7.88081700e-01, 1.54701190e-01, 5.72170700e-02],\n",
       "       [7.37956940e-01, 1.70648720e-01, 9.13943800e-02],\n",
       "       [6.75271030e-01, 5.88705530e-03, 3.18841900e-01],\n",
       "       [2.05277700e-02, 9.69990200e-01, 9.48202800e-03],\n",
       "       [9.52440260e-01, 4.55336050e-02, 2.02612440e-03],\n",
       "       [5.78992840e-01, 1.77872760e-03, 4.19228460e-01],\n",
       "       [9.89311300e-01, 1.86408400e-08, 1.06887035e-02],\n",
       "       [9.78816570e-01, 2.04767290e-02, 7.06694960e-04],\n",
       "       [4.48757670e-04, 6.23674170e-02, 9.37183860e-01],\n",
       "       [6.54357800e-01, 3.45035230e-01, 6.06996360e-04],\n",
       "       [9.21064600e-04, 7.28172360e-01, 2.70906630e-01],\n",
       "       [4.51788680e-02, 2.53711730e-02, 9.29449900e-01],\n",
       "       [4.47370170e-01, 9.34465450e-02, 4.59183280e-01],\n",
       "       [3.34240530e-01, 3.12528000e-01, 3.53231460e-01],\n",
       "       [9.80747300e-01, 1.92189630e-02, 3.38107460e-05],\n",
       "       [3.82750300e-03, 9.86360000e-01, 9.81258800e-03],\n",
       "       [2.04085500e-03, 6.69315800e-03, 9.91265950e-01],\n",
       "       [3.21129900e-01, 2.24861440e-01, 4.54008700e-01],\n",
       "       [2.45276520e-02, 5.83894000e-01, 3.91578380e-01],\n",
       "       [8.86389800e-01, 6.34516700e-02, 5.01585600e-02],\n",
       "       [8.99209440e-01, 7.14440350e-02, 2.93465610e-02],\n",
       "       [5.34757040e-03, 1.51145380e-01, 8.43507100e-01],\n",
       "       [3.46904660e-02, 3.68127520e-01, 5.97182000e-01],\n",
       "       [2.84220300e-02, 6.41673270e-01, 3.29904700e-01],\n",
       "       [8.87675940e-01, 7.62153700e-02, 3.61086840e-02],\n",
       "       [7.20647600e-01, 2.77458880e-01, 1.89356940e-03],\n",
       "       [3.16133160e-02, 9.38010040e-01, 3.03766750e-02],\n",
       "       [1.58078400e-02, 7.66719900e-01, 2.17472290e-01],\n",
       "       [6.40456160e-07, 9.99999400e-01, 3.75366030e-13],\n",
       "       [3.45855650e-02, 9.14924900e-01, 5.04895230e-02],\n",
       "       [2.01079500e-02, 9.38954900e-02, 8.85996500e-01],\n",
       "       [1.61497470e-01, 7.56822940e-01, 8.16796050e-02],\n",
       "       [9.62975200e-03, 8.57835900e-01, 1.32534440e-01],\n",
       "       [1.12602815e-01, 8.23222250e-02, 8.05075050e-01],\n",
       "       [2.60175470e-02, 2.51740520e-02, 9.48808430e-01],\n",
       "       [8.38052300e-01, 1.22709620e-01, 3.92381740e-02],\n",
       "       [1.18227460e-02, 4.10171000e-02, 9.47160100e-01],\n",
       "       [9.82982100e-01, 1.15993990e-02, 5.41858050e-03],\n",
       "       [5.83982170e-01, 1.82444910e-04, 4.15835380e-01],\n",
       "       [3.34522460e-01, 6.01484200e-01, 6.39934400e-02],\n",
       "       [9.72405850e-01, 7.88998900e-04, 2.68052300e-02],\n",
       "       [4.45651980e-01, 2.69708400e-01, 2.84639660e-01],\n",
       "       [5.21311500e-01, 3.13562780e-01, 1.65125650e-01],\n",
       "       [8.15910700e-03, 2.55666900e-01, 7.36173900e-01],\n",
       "       [8.22603800e-07, 7.58670000e-05, 9.99923350e-01],\n",
       "       [3.94851000e-02, 9.59658000e-01, 8.56853150e-04],\n",
       "       [6.75271030e-01, 5.88705530e-03, 3.18841900e-01],\n",
       "       [1.45406000e-01, 7.01804600e-01, 1.52789380e-01],\n",
       "       [9.48501800e-05, 1.20671480e-03, 9.98698350e-01],\n",
       "       [6.76049700e-07, 4.55716870e-05, 9.99953750e-01],\n",
       "       [4.59531550e-01, 5.32850000e-01, 7.61848100e-03],\n",
       "       [6.70857200e-01, 2.90271430e-01, 3.88713600e-02],\n",
       "       [1.49432870e-01, 9.14993400e-02, 7.59067830e-01],\n",
       "       [4.49424860e-01, 4.52814700e-01, 9.77603640e-02],\n",
       "       [5.54040300e-02, 5.70969800e-02, 8.87499030e-01],\n",
       "       [9.93390700e-01, 6.58798000e-03, 2.12603350e-05],\n",
       "       [7.27045300e-07, 9.99999300e-01, 1.67900940e-13],\n",
       "       [1.16542510e-01, 8.83410100e-01, 4.74163060e-05],\n",
       "       [8.48345460e-01, 1.45965890e-01, 5.68862200e-03],\n",
       "       [5.94026100e-01, 3.84935400e-01, 2.10385080e-02],\n",
       "       [1.29341890e-04, 9.99844800e-01, 2.58464550e-05],\n",
       "       [9.47888000e-01, 3.81541300e-02, 1.39578210e-02],\n",
       "       [1.81457810e-02, 3.74249630e-02, 9.44429300e-01],\n",
       "       [1.85637100e-04, 9.99696600e-01, 1.17751030e-04],\n",
       "       [8.49942500e-03, 7.71043060e-01, 2.20457520e-01],\n",
       "       [9.96285100e-01, 3.36110750e-03, 3.53861700e-04],\n",
       "       [2.88900700e-01, 3.28733920e-01, 3.82365440e-01],\n",
       "       [2.22388500e-22, 1.00000000e+00, 3.22270290e-28],\n",
       "       [1.66892410e-01, 5.53138500e-01, 2.79969070e-01],\n",
       "       [9.26526840e-01, 2.57111830e-03, 7.09020940e-02],\n",
       "       [5.43581250e-01, 4.40445060e-02, 4.12374260e-01],\n",
       "       [9.80923200e-01, 1.79772210e-02, 1.09952660e-03],\n",
       "       [9.99026900e-01, 9.67287630e-04, 5.81563200e-06],\n",
       "       [8.38052300e-01, 1.22709620e-01, 3.92381740e-02],\n",
       "       [7.90051700e-01, 1.29668070e-01, 8.02801850e-02]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob = df_proba[df_proba['phage']=='p0017kpresabsSTCC_qual'].iloc[:,-3:]\n",
    "y_prob = y_prob.to_numpy()\n",
    "y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Retrieved from https://github.com/scikit-learn/scikit-learn/issues/3298\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "def rocauc_ovo(truth, pred, average=\"macro\", multi_class=\"ovo\"):\n",
    "\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(truth)\n",
    "\n",
    "    truth = lb.transform(truth)   \n",
    "    \n",
    "    return roc_auc_score(truth, pred, average=average, multi_class=multi_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5648119517167135"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo1 = rocauc_ovo(y_test, y_prob, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rocauc_ovr(truth, pred, average=\"macro\", multi_class=\"ovr\"):\n",
    "\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(truth)\n",
    "\n",
    "    truth = lb.transform(truth)   \n",
    "\n",
    "    return roc_auc_score(truth, pred, average=average, multi_class=multi_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5648119517167135"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr1 = rocauc_ovr(y_test, y_prob, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=234,\n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat2 = pd.DataFrame(X_test.iloc[:,0])\n",
    "dat2['test'] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>NRS210</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>Grady1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>CFBRSa29</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>CFBRSa03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>217</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>BCH-SA-10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>GA15</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>SR3585</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>NRS387</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>NRS217</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  test\n",
       "178     NRS210     2\n",
       "104     Grady1     0\n",
       "79    CFBRSa29     2\n",
       "66    CFBRSa03     0\n",
       "9          217     1\n",
       "..         ...   ...\n",
       "25   BCH-SA-10     1\n",
       "94        GA15     2\n",
       "244     SR3585     0\n",
       "227     NRS387     2\n",
       "185     NRS217     0\n",
       "\n",
       "[76 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(['id'], axis=1)\n",
    "X_test = X_test.drop(['id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 177 samples, validate on 76 samples\n",
      "Epoch 1/100\n",
      "177/177 [==============================] - 0s 1ms/step - loss: 5.7287 - accuracy: 0.3446 - val_loss: 1.4654 - val_accuracy: 0.3816\n",
      "Epoch 2/100\n",
      "177/177 [==============================] - 0s 389us/step - loss: 3.0653 - accuracy: 0.4181 - val_loss: 1.2886 - val_accuracy: 0.3816\n",
      "Epoch 3/100\n",
      "177/177 [==============================] - 0s 384us/step - loss: 1.7815 - accuracy: 0.4972 - val_loss: 1.2566 - val_accuracy: 0.3816\n",
      "Epoch 4/100\n",
      "177/177 [==============================] - 0s 402us/step - loss: 1.4527 - accuracy: 0.4859 - val_loss: 1.2613 - val_accuracy: 0.3947\n",
      "Epoch 5/100\n",
      "177/177 [==============================] - 0s 420us/step - loss: 1.1768 - accuracy: 0.5311 - val_loss: 1.1635 - val_accuracy: 0.4868\n",
      "Epoch 6/100\n",
      "177/177 [==============================] - 0s 371us/step - loss: 0.9800 - accuracy: 0.5593 - val_loss: 1.1365 - val_accuracy: 0.4737\n",
      "Epoch 7/100\n",
      "177/177 [==============================] - 0s 355us/step - loss: 0.9622 - accuracy: 0.5819 - val_loss: 1.1249 - val_accuracy: 0.4737\n",
      "Epoch 8/100\n",
      "177/177 [==============================] - 0s 347us/step - loss: 0.9155 - accuracy: 0.6215 - val_loss: 1.1186 - val_accuracy: 0.4868\n",
      "Epoch 9/100\n",
      "177/177 [==============================] - 0s 384us/step - loss: 0.8721 - accuracy: 0.6158 - val_loss: 1.1214 - val_accuracy: 0.5263\n",
      "Epoch 10/100\n",
      "177/177 [==============================] - 0s 397us/step - loss: 0.9001 - accuracy: 0.6215 - val_loss: 1.1143 - val_accuracy: 0.5263\n",
      "Epoch 11/100\n",
      "177/177 [==============================] - 0s 406us/step - loss: 0.8458 - accuracy: 0.6271 - val_loss: 1.1408 - val_accuracy: 0.5132\n",
      "Epoch 12/100\n",
      "177/177 [==============================] - 0s 387us/step - loss: 0.8587 - accuracy: 0.6215 - val_loss: 1.2111 - val_accuracy: 0.4342\n",
      "Epoch 13/100\n",
      "177/177 [==============================] - 0s 449us/step - loss: 0.8633 - accuracy: 0.6441 - val_loss: 1.1373 - val_accuracy: 0.5000\n",
      "Epoch 14/100\n",
      "177/177 [==============================] - 0s 524us/step - loss: 0.7786 - accuracy: 0.6497 - val_loss: 1.1145 - val_accuracy: 0.5132\n",
      "Epoch 15/100\n",
      "177/177 [==============================] - 0s 656us/step - loss: 0.7923 - accuracy: 0.6667 - val_loss: 1.1635 - val_accuracy: 0.4868\n",
      "Epoch 16/100\n",
      "177/177 [==============================] - 0s 535us/step - loss: 0.7506 - accuracy: 0.6610 - val_loss: 1.2026 - val_accuracy: 0.4342\n",
      "Epoch 17/100\n",
      "177/177 [==============================] - 0s 494us/step - loss: 0.7593 - accuracy: 0.6723 - val_loss: 1.1213 - val_accuracy: 0.4737\n",
      "Epoch 18/100\n",
      "177/177 [==============================] - 0s 620us/step - loss: 0.7305 - accuracy: 0.6893 - val_loss: 1.1617 - val_accuracy: 0.4868\n",
      "Epoch 19/100\n",
      "177/177 [==============================] - 0s 659us/step - loss: 0.7593 - accuracy: 0.6949 - val_loss: 1.1698 - val_accuracy: 0.4605\n",
      "Epoch 20/100\n",
      "177/177 [==============================] - 0s 427us/step - loss: 0.8444 - accuracy: 0.6554 - val_loss: 1.2416 - val_accuracy: 0.4342\n",
      "Epoch 21/100\n",
      "177/177 [==============================] - 0s 428us/step - loss: 0.6863 - accuracy: 0.7288 - val_loss: 1.1618 - val_accuracy: 0.4605\n",
      "Epoch 22/100\n",
      "177/177 [==============================] - 0s 600us/step - loss: 0.8242 - accuracy: 0.6667 - val_loss: 1.1974 - val_accuracy: 0.4868\n",
      "Epoch 23/100\n",
      "177/177 [==============================] - 0s 486us/step - loss: 0.7136 - accuracy: 0.6667 - val_loss: 1.2949 - val_accuracy: 0.3816\n",
      "Epoch 24/100\n",
      "177/177 [==============================] - 0s 355us/step - loss: 0.7182 - accuracy: 0.7062 - val_loss: 1.2115 - val_accuracy: 0.4737\n",
      "Epoch 25/100\n",
      "177/177 [==============================] - 0s 518us/step - loss: 0.6742 - accuracy: 0.7232 - val_loss: 1.2391 - val_accuracy: 0.4474\n",
      "Epoch 26/100\n",
      "177/177 [==============================] - 0s 540us/step - loss: 0.6138 - accuracy: 0.7514 - val_loss: 1.2304 - val_accuracy: 0.4605\n",
      "Epoch 27/100\n",
      "177/177 [==============================] - 0s 597us/step - loss: 0.6870 - accuracy: 0.7458 - val_loss: 1.2477 - val_accuracy: 0.4737\n",
      "Epoch 28/100\n",
      "177/177 [==============================] - 0s 484us/step - loss: 0.6162 - accuracy: 0.7232 - val_loss: 1.2947 - val_accuracy: 0.4342\n",
      "Epoch 29/100\n",
      "177/177 [==============================] - 0s 452us/step - loss: 0.6367 - accuracy: 0.7514 - val_loss: 1.3309 - val_accuracy: 0.4079\n",
      "Epoch 30/100\n",
      "177/177 [==============================] - 0s 305us/step - loss: 0.6477 - accuracy: 0.7627 - val_loss: 1.3513 - val_accuracy: 0.4079\n",
      "Epoch 31/100\n",
      "177/177 [==============================] - 0s 329us/step - loss: 0.6043 - accuracy: 0.7627 - val_loss: 1.2595 - val_accuracy: 0.4868\n",
      "Epoch 32/100\n",
      "177/177 [==============================] - 0s 319us/step - loss: 0.5653 - accuracy: 0.7740 - val_loss: 1.2954 - val_accuracy: 0.4211\n",
      "Epoch 33/100\n",
      "177/177 [==============================] - 0s 298us/step - loss: 0.5876 - accuracy: 0.7345 - val_loss: 1.3444 - val_accuracy: 0.3947\n",
      "Epoch 34/100\n",
      "177/177 [==============================] - 0s 391us/step - loss: 0.5504 - accuracy: 0.7853 - val_loss: 1.3106 - val_accuracy: 0.4211\n",
      "Epoch 35/100\n",
      "177/177 [==============================] - 0s 759us/step - loss: 0.5933 - accuracy: 0.7740 - val_loss: 1.3548 - val_accuracy: 0.4342\n",
      "Epoch 36/100\n",
      "177/177 [==============================] - 0s 657us/step - loss: 0.5523 - accuracy: 0.7966 - val_loss: 1.3367 - val_accuracy: 0.4342\n",
      "Epoch 37/100\n",
      "177/177 [==============================] - 0s 677us/step - loss: 0.5518 - accuracy: 0.8079 - val_loss: 1.3181 - val_accuracy: 0.4474\n",
      "Epoch 38/100\n",
      "177/177 [==============================] - 0s 641us/step - loss: 0.5836 - accuracy: 0.7853 - val_loss: 1.4446 - val_accuracy: 0.3816\n",
      "Epoch 39/100\n",
      "177/177 [==============================] - 0s 447us/step - loss: 0.4964 - accuracy: 0.8023 - val_loss: 1.3748 - val_accuracy: 0.4211\n",
      "Epoch 40/100\n",
      "177/177 [==============================] - 0s 577us/step - loss: 0.5241 - accuracy: 0.7853 - val_loss: 1.4125 - val_accuracy: 0.4605\n",
      "Epoch 41/100\n",
      "177/177 [==============================] - 0s 670us/step - loss: 0.5121 - accuracy: 0.8136 - val_loss: 1.4420 - val_accuracy: 0.4342\n",
      "Epoch 42/100\n",
      "177/177 [==============================] - 0s 650us/step - loss: 0.5480 - accuracy: 0.8192 - val_loss: 1.3613 - val_accuracy: 0.4342\n",
      "Epoch 43/100\n",
      "177/177 [==============================] - 0s 740us/step - loss: 0.5199 - accuracy: 0.8023 - val_loss: 1.4095 - val_accuracy: 0.4474\n",
      "Epoch 44/100\n",
      "177/177 [==============================] - 0s 535us/step - loss: 0.5110 - accuracy: 0.8079 - val_loss: 1.4367 - val_accuracy: 0.4211\n",
      "Epoch 45/100\n",
      "177/177 [==============================] - 0s 509us/step - loss: 0.5156 - accuracy: 0.8192 - val_loss: 1.4348 - val_accuracy: 0.4474\n",
      "Epoch 46/100\n",
      "177/177 [==============================] - 0s 559us/step - loss: 0.4782 - accuracy: 0.8079 - val_loss: 1.4564 - val_accuracy: 0.4605\n",
      "Epoch 47/100\n",
      "177/177 [==============================] - 0s 389us/step - loss: 0.5291 - accuracy: 0.8192 - val_loss: 1.4745 - val_accuracy: 0.4342\n",
      "Epoch 48/100\n",
      "177/177 [==============================] - 0s 645us/step - loss: 0.4648 - accuracy: 0.8249 - val_loss: 1.4503 - val_accuracy: 0.4474\n",
      "Epoch 49/100\n",
      "177/177 [==============================] - 0s 668us/step - loss: 0.4939 - accuracy: 0.8249 - val_loss: 1.4869 - val_accuracy: 0.4342\n",
      "Epoch 50/100\n",
      "177/177 [==============================] - 0s 622us/step - loss: 0.4533 - accuracy: 0.8249 - val_loss: 1.5960 - val_accuracy: 0.4079\n",
      "Epoch 51/100\n",
      "177/177 [==============================] - 0s 525us/step - loss: 0.4951 - accuracy: 0.8249 - val_loss: 1.4394 - val_accuracy: 0.4868\n",
      "Epoch 52/100\n",
      "177/177 [==============================] - 0s 361us/step - loss: 0.5071 - accuracy: 0.8136 - val_loss: 1.4809 - val_accuracy: 0.4737\n",
      "Epoch 53/100\n",
      "177/177 [==============================] - 0s 336us/step - loss: 0.4834 - accuracy: 0.8192 - val_loss: 1.5591 - val_accuracy: 0.3421\n",
      "Epoch 54/100\n",
      "177/177 [==============================] - 0s 316us/step - loss: 0.4685 - accuracy: 0.8305 - val_loss: 1.5145 - val_accuracy: 0.4342\n",
      "Epoch 55/100\n",
      "177/177 [==============================] - 0s 308us/step - loss: 0.5173 - accuracy: 0.8305 - val_loss: 1.5393 - val_accuracy: 0.3816\n",
      "Epoch 56/100\n",
      "177/177 [==============================] - 0s 314us/step - loss: 0.4646 - accuracy: 0.8588 - val_loss: 1.5150 - val_accuracy: 0.4211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "177/177 [==============================] - 0s 377us/step - loss: 0.4099 - accuracy: 0.8475 - val_loss: 1.5894 - val_accuracy: 0.4211\n",
      "Epoch 58/100\n",
      "177/177 [==============================] - 0s 658us/step - loss: 0.4361 - accuracy: 0.8701 - val_loss: 1.5307 - val_accuracy: 0.4474\n",
      "Epoch 59/100\n",
      "177/177 [==============================] - 0s 689us/step - loss: 0.4507 - accuracy: 0.8475 - val_loss: 1.5307 - val_accuracy: 0.4605\n",
      "Epoch 60/100\n",
      "177/177 [==============================] - 0s 300us/step - loss: 0.4298 - accuracy: 0.8588 - val_loss: 1.6431 - val_accuracy: 0.4079\n",
      "Epoch 61/100\n",
      "177/177 [==============================] - 0s 325us/step - loss: 0.4461 - accuracy: 0.8418 - val_loss: 1.5611 - val_accuracy: 0.4079\n",
      "Epoch 62/100\n",
      "177/177 [==============================] - 0s 331us/step - loss: 0.4501 - accuracy: 0.7966 - val_loss: 1.5466 - val_accuracy: 0.4342\n",
      "Epoch 63/100\n",
      "177/177 [==============================] - 0s 422us/step - loss: 0.3723 - accuracy: 0.8757 - val_loss: 1.6251 - val_accuracy: 0.4079\n",
      "Epoch 64/100\n",
      "177/177 [==============================] - 0s 431us/step - loss: 0.4091 - accuracy: 0.8531 - val_loss: 1.5850 - val_accuracy: 0.4211\n",
      "Epoch 65/100\n",
      "177/177 [==============================] - 0s 309us/step - loss: 0.3970 - accuracy: 0.8531 - val_loss: 1.5743 - val_accuracy: 0.4342\n",
      "Epoch 66/100\n",
      "177/177 [==============================] - 0s 314us/step - loss: 0.3798 - accuracy: 0.8927 - val_loss: 1.6220 - val_accuracy: 0.4079\n",
      "Epoch 67/100\n",
      "177/177 [==============================] - 0s 421us/step - loss: 0.3737 - accuracy: 0.8757 - val_loss: 1.5968 - val_accuracy: 0.4211\n",
      "Epoch 68/100\n",
      "177/177 [==============================] - 0s 633us/step - loss: 0.3896 - accuracy: 0.8362 - val_loss: 1.5931 - val_accuracy: 0.4342\n",
      "Epoch 69/100\n",
      "177/177 [==============================] - 0s 573us/step - loss: 0.3735 - accuracy: 0.8701 - val_loss: 1.6570 - val_accuracy: 0.4079\n",
      "Epoch 70/100\n",
      "177/177 [==============================] - 0s 540us/step - loss: 0.3771 - accuracy: 0.8757 - val_loss: 1.6295 - val_accuracy: 0.3947\n",
      "Epoch 71/100\n",
      "177/177 [==============================] - 0s 357us/step - loss: 0.3618 - accuracy: 0.8701 - val_loss: 1.6989 - val_accuracy: 0.4474\n",
      "Epoch 72/100\n",
      "177/177 [==============================] - 0s 353us/step - loss: 0.3582 - accuracy: 0.8983 - val_loss: 1.7294 - val_accuracy: 0.4474\n",
      "Epoch 73/100\n",
      "177/177 [==============================] - 0s 316us/step - loss: 0.4497 - accuracy: 0.8531 - val_loss: 1.6460 - val_accuracy: 0.3947\n",
      "Epoch 74/100\n",
      "177/177 [==============================] - 0s 456us/step - loss: 0.4572 - accuracy: 0.8588 - val_loss: 1.6730 - val_accuracy: 0.4079\n",
      "Epoch 75/100\n",
      "177/177 [==============================] - 0s 512us/step - loss: 0.3524 - accuracy: 0.8814 - val_loss: 1.6909 - val_accuracy: 0.4342\n",
      "Epoch 76/100\n",
      "177/177 [==============================] - 0s 379us/step - loss: 0.4193 - accuracy: 0.8475 - val_loss: 1.6992 - val_accuracy: 0.3684\n",
      "Epoch 77/100\n",
      "177/177 [==============================] - 0s 396us/step - loss: 0.3493 - accuracy: 0.8757 - val_loss: 1.7866 - val_accuracy: 0.4079\n",
      "Epoch 78/100\n",
      "177/177 [==============================] - 0s 589us/step - loss: 0.3461 - accuracy: 0.8814 - val_loss: 1.7585 - val_accuracy: 0.4211\n",
      "Epoch 79/100\n",
      "177/177 [==============================] - 0s 392us/step - loss: 0.3547 - accuracy: 0.8588 - val_loss: 1.7215 - val_accuracy: 0.4211\n",
      "Epoch 80/100\n",
      "177/177 [==============================] - 0s 396us/step - loss: 0.3621 - accuracy: 0.8870 - val_loss: 1.8111 - val_accuracy: 0.4079\n",
      "Epoch 81/100\n",
      "177/177 [==============================] - 0s 468us/step - loss: 0.3651 - accuracy: 0.8757 - val_loss: 1.7385 - val_accuracy: 0.4605\n",
      "Epoch 82/100\n",
      "177/177 [==============================] - 0s 332us/step - loss: 0.3302 - accuracy: 0.8644 - val_loss: 1.7801 - val_accuracy: 0.4342\n",
      "Epoch 83/100\n",
      "177/177 [==============================] - 0s 328us/step - loss: 0.3661 - accuracy: 0.8757 - val_loss: 1.7661 - val_accuracy: 0.3947\n",
      "Epoch 84/100\n",
      "177/177 [==============================] - 0s 304us/step - loss: 0.3944 - accuracy: 0.8305 - val_loss: 1.7836 - val_accuracy: 0.4079\n",
      "Epoch 85/100\n",
      "177/177 [==============================] - 0s 340us/step - loss: 0.3274 - accuracy: 0.8757 - val_loss: 1.7651 - val_accuracy: 0.4474\n",
      "Epoch 86/100\n",
      "177/177 [==============================] - 0s 315us/step - loss: 0.3307 - accuracy: 0.8814 - val_loss: 1.8741 - val_accuracy: 0.4079\n",
      "Epoch 87/100\n",
      "177/177 [==============================] - 0s 310us/step - loss: 0.3348 - accuracy: 0.8814 - val_loss: 1.7683 - val_accuracy: 0.4079\n",
      "Epoch 88/100\n",
      "177/177 [==============================] - 0s 331us/step - loss: 0.3392 - accuracy: 0.8757 - val_loss: 1.7669 - val_accuracy: 0.4211\n",
      "Epoch 89/100\n",
      "177/177 [==============================] - 0s 308us/step - loss: 0.3097 - accuracy: 0.8757 - val_loss: 1.7897 - val_accuracy: 0.3947\n",
      "Epoch 90/100\n",
      "177/177 [==============================] - 0s 312us/step - loss: 0.3039 - accuracy: 0.8927 - val_loss: 1.8052 - val_accuracy: 0.3684\n",
      "Epoch 91/100\n",
      "177/177 [==============================] - 0s 303us/step - loss: 0.3171 - accuracy: 0.8814 - val_loss: 1.8400 - val_accuracy: 0.3553\n",
      "Epoch 92/100\n",
      "177/177 [==============================] - 0s 314us/step - loss: 0.3229 - accuracy: 0.8870 - val_loss: 1.8520 - val_accuracy: 0.4342\n",
      "Epoch 93/100\n",
      "177/177 [==============================] - 0s 321us/step - loss: 0.3382 - accuracy: 0.8814 - val_loss: 1.8208 - val_accuracy: 0.4211\n",
      "Epoch 94/100\n",
      "177/177 [==============================] - 0s 385us/step - loss: 0.3929 - accuracy: 0.8701 - val_loss: 1.8737 - val_accuracy: 0.3684\n",
      "Epoch 95/100\n",
      "177/177 [==============================] - 0s 372us/step - loss: 0.3044 - accuracy: 0.8983 - val_loss: 1.8764 - val_accuracy: 0.4342\n",
      "Epoch 96/100\n",
      "177/177 [==============================] - 0s 324us/step - loss: 0.3633 - accuracy: 0.8757 - val_loss: 1.8436 - val_accuracy: 0.4474\n",
      "Epoch 97/100\n",
      "177/177 [==============================] - 0s 309us/step - loss: 0.3059 - accuracy: 0.9266 - val_loss: 1.9132 - val_accuracy: 0.3684\n",
      "Epoch 98/100\n",
      "177/177 [==============================] - 0s 506us/step - loss: 0.3549 - accuracy: 0.9096 - val_loss: 1.9351 - val_accuracy: 0.3816\n",
      "Epoch 99/100\n",
      "177/177 [==============================] - 0s 411us/step - loss: 0.2997 - accuracy: 0.8701 - val_loss: 1.8999 - val_accuracy: 0.4737\n",
      "Epoch 100/100\n",
      "177/177 [==============================] - 0s 288us/step - loss: 0.3117 - accuracy: 0.8701 - val_loss: 1.8810 - val_accuracy: 0.4079\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x633782198>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(X_train, y_train,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 0s 153us/step\n",
      "test accuracy: 43.42%\n"
     ]
    }
   ],
   "source": [
    "acc_test2 = model2.evaluate(X_test, y_test)[1]\n",
    "print('test accuracy: %.2f%%' % (acc_test2*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 0, 2, 0, 1, 2, 0, 1, 2, 0, 1, 1, 0, 1, 1, 2, 0, 1, 1,\n",
       "       0, 1, 1, 0, 0, 1, 2, 2, 1, 2, 2, 0, 2, 0, 0, 0, 1, 0, 2, 1, 2, 1,\n",
       "       0, 1, 0, 1, 1, 1, 2, 1, 2, 2, 0, 0, 2, 0, 1, 0, 1, 2, 2, 0, 0, 0,\n",
       "       0, 1, 0, 2, 0, 1, 1, 0, 2, 1])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred2 = model2.predict_classes(X_test)\n",
    "pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>NRS210</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>Grady1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>CFBRSa29</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>CFBRSa03</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>217</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>BCH-SA-10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>GA15</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>SR3585</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>NRS387</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>NRS217</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  test  pred\n",
       "178     NRS210     2     0\n",
       "104     Grady1     0     0\n",
       "79    CFBRSa29     2     0\n",
       "66    CFBRSa03     0     1\n",
       "9          217     1     0\n",
       "..         ...   ...   ...\n",
       "25   BCH-SA-10     1     1\n",
       "94        GA15     2     1\n",
       "244     SR3585     0     0\n",
       "227     NRS387     2     2\n",
       "185     NRS217     0     1\n",
       "\n",
       "[76 rows x 3 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat2['pred'] = pred2\n",
    "dat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba2 = model2.predict_proba(X_test)\n",
    "dat_proba2 = pd.DataFrame(proba2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.424648</td>\n",
       "      <td>0.408826</td>\n",
       "      <td>0.166526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.718681</td>\n",
       "      <td>0.180438</td>\n",
       "      <td>0.100881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.947249</td>\n",
       "      <td>0.009377</td>\n",
       "      <td>0.043374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.107967</td>\n",
       "      <td>0.647848</td>\n",
       "      <td>0.244185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.529560</td>\n",
       "      <td>0.360273</td>\n",
       "      <td>0.110167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.332118</td>\n",
       "      <td>0.531638</td>\n",
       "      <td>0.136244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.289990</td>\n",
       "      <td>0.652280</td>\n",
       "      <td>0.057730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.615252</td>\n",
       "      <td>0.118302</td>\n",
       "      <td>0.266446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.427122</td>\n",
       "      <td>0.029366</td>\n",
       "      <td>0.543513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.001093</td>\n",
       "      <td>0.786404</td>\n",
       "      <td>0.212503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2\n",
       "0   0.424648  0.408826  0.166526\n",
       "1   0.718681  0.180438  0.100881\n",
       "2   0.947249  0.009377  0.043374\n",
       "3   0.107967  0.647848  0.244185\n",
       "4   0.529560  0.360273  0.110167\n",
       "..       ...       ...       ...\n",
       "71  0.332118  0.531638  0.136244\n",
       "72  0.289990  0.652280  0.057730\n",
       "73  0.615252  0.118302  0.266446\n",
       "74  0.427122  0.029366  0.543513\n",
       "75  0.001093  0.786404  0.212503\n",
       "\n",
       "[76 rows x 3 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba2.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba2.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat2.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/2p17ST.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 177 samples, validate on 76 samples\n",
      "Epoch 1/100\n",
      "177/177 [==============================] - 0s 458us/step - loss: 0.3917 - accuracy: 0.8418 - val_loss: 1.8322 - val_accuracy: 0.3947\n",
      "Epoch 2/100\n",
      "177/177 [==============================] - 0s 413us/step - loss: 0.5722 - accuracy: 0.8192 - val_loss: 1.8582 - val_accuracy: 0.4079\n",
      "Epoch 3/100\n",
      "177/177 [==============================] - 0s 363us/step - loss: 0.4528 - accuracy: 0.8475 - val_loss: 1.8289 - val_accuracy: 0.4342\n",
      "Epoch 4/100\n",
      "177/177 [==============================] - 0s 336us/step - loss: 0.4144 - accuracy: 0.8249 - val_loss: 1.7495 - val_accuracy: 0.4737\n",
      "Epoch 5/100\n",
      "177/177 [==============================] - 0s 410us/step - loss: 0.3830 - accuracy: 0.8588 - val_loss: 1.8195 - val_accuracy: 0.4474\n",
      "Epoch 6/100\n",
      "177/177 [==============================] - 0s 380us/step - loss: 0.4009 - accuracy: 0.8531 - val_loss: 1.8094 - val_accuracy: 0.4342\n",
      "Epoch 7/100\n",
      "177/177 [==============================] - 0s 361us/step - loss: 0.3751 - accuracy: 0.8475 - val_loss: 1.8277 - val_accuracy: 0.3947\n",
      "Epoch 8/100\n",
      "177/177 [==============================] - 0s 392us/step - loss: 0.4071 - accuracy: 0.8362 - val_loss: 1.8567 - val_accuracy: 0.3816\n",
      "Epoch 9/100\n",
      "177/177 [==============================] - 0s 373us/step - loss: 0.3784 - accuracy: 0.8531 - val_loss: 1.8652 - val_accuracy: 0.4079\n",
      "Epoch 10/100\n",
      "177/177 [==============================] - 0s 379us/step - loss: 0.3919 - accuracy: 0.8531 - val_loss: 1.8465 - val_accuracy: 0.4079\n",
      "Epoch 11/100\n",
      "177/177 [==============================] - 0s 368us/step - loss: 0.4053 - accuracy: 0.8418 - val_loss: 1.8611 - val_accuracy: 0.4211\n",
      "Epoch 12/100\n",
      "177/177 [==============================] - 0s 403us/step - loss: 0.3723 - accuracy: 0.8588 - val_loss: 1.8726 - val_accuracy: 0.4211\n",
      "Epoch 13/100\n",
      "177/177 [==============================] - 0s 361us/step - loss: 0.4134 - accuracy: 0.8644 - val_loss: 1.8582 - val_accuracy: 0.4211\n",
      "Epoch 14/100\n",
      "177/177 [==============================] - 0s 382us/step - loss: 0.3901 - accuracy: 0.8701 - val_loss: 1.8515 - val_accuracy: 0.3947\n",
      "Epoch 15/100\n",
      "177/177 [==============================] - 0s 394us/step - loss: 0.4417 - accuracy: 0.8531 - val_loss: 1.8414 - val_accuracy: 0.4079\n",
      "Epoch 16/100\n",
      "177/177 [==============================] - 0s 378us/step - loss: 0.4232 - accuracy: 0.8362 - val_loss: 1.8723 - val_accuracy: 0.4342\n",
      "Epoch 17/100\n",
      "177/177 [==============================] - 0s 341us/step - loss: 0.4108 - accuracy: 0.8701 - val_loss: 1.8493 - val_accuracy: 0.4474\n",
      "Epoch 18/100\n",
      "177/177 [==============================] - 0s 381us/step - loss: 0.3547 - accuracy: 0.8531 - val_loss: 1.8766 - val_accuracy: 0.4342\n",
      "Epoch 19/100\n",
      "177/177 [==============================] - 0s 339us/step - loss: 0.3612 - accuracy: 0.8531 - val_loss: 1.9563 - val_accuracy: 0.3816\n",
      "Epoch 20/100\n",
      "177/177 [==============================] - 0s 395us/step - loss: 0.3829 - accuracy: 0.8927 - val_loss: 1.8346 - val_accuracy: 0.4342\n",
      "Epoch 21/100\n",
      "177/177 [==============================] - 0s 427us/step - loss: 0.3679 - accuracy: 0.8757 - val_loss: 1.8864 - val_accuracy: 0.4474\n",
      "Epoch 22/100\n",
      "177/177 [==============================] - 0s 596us/step - loss: 0.4296 - accuracy: 0.8870 - val_loss: 1.9863 - val_accuracy: 0.4079\n",
      "Epoch 23/100\n",
      "177/177 [==============================] - 0s 434us/step - loss: 0.3941 - accuracy: 0.8531 - val_loss: 1.8874 - val_accuracy: 0.3947\n",
      "Epoch 24/100\n",
      "177/177 [==============================] - 0s 580us/step - loss: 0.4511 - accuracy: 0.8701 - val_loss: 1.8646 - val_accuracy: 0.4211\n",
      "Epoch 25/100\n",
      "177/177 [==============================] - 0s 440us/step - loss: 0.3978 - accuracy: 0.8701 - val_loss: 1.8718 - val_accuracy: 0.4211\n",
      "Epoch 26/100\n",
      "177/177 [==============================] - 0s 356us/step - loss: 0.4881 - accuracy: 0.8588 - val_loss: 1.8494 - val_accuracy: 0.4211\n",
      "Epoch 27/100\n",
      "177/177 [==============================] - 0s 356us/step - loss: 0.3635 - accuracy: 0.8644 - val_loss: 1.8956 - val_accuracy: 0.4342\n",
      "Epoch 28/100\n",
      "177/177 [==============================] - 0s 538us/step - loss: 0.4325 - accuracy: 0.8475 - val_loss: 1.9327 - val_accuracy: 0.4474\n",
      "Epoch 29/100\n",
      "177/177 [==============================] - 0s 515us/step - loss: 0.4334 - accuracy: 0.8531 - val_loss: 1.9408 - val_accuracy: 0.4079\n",
      "Epoch 30/100\n",
      "177/177 [==============================] - 0s 416us/step - loss: 0.3493 - accuracy: 0.8418 - val_loss: 1.8855 - val_accuracy: 0.4211\n",
      "Epoch 31/100\n",
      "177/177 [==============================] - 0s 352us/step - loss: 0.4268 - accuracy: 0.8418 - val_loss: 1.8780 - val_accuracy: 0.4342\n",
      "Epoch 32/100\n",
      "177/177 [==============================] - 0s 350us/step - loss: 0.3282 - accuracy: 0.8983 - val_loss: 1.9106 - val_accuracy: 0.3816\n",
      "Epoch 33/100\n",
      "177/177 [==============================] - 0s 352us/step - loss: 0.5022 - accuracy: 0.8814 - val_loss: 1.9107 - val_accuracy: 0.3816\n",
      "Epoch 34/100\n",
      "177/177 [==============================] - 0s 400us/step - loss: 0.4066 - accuracy: 0.8870 - val_loss: 1.9240 - val_accuracy: 0.4474\n",
      "Epoch 35/100\n",
      "177/177 [==============================] - 0s 353us/step - loss: 0.3813 - accuracy: 0.8531 - val_loss: 1.9660 - val_accuracy: 0.4079\n",
      "Epoch 36/100\n",
      "177/177 [==============================] - 0s 411us/step - loss: 0.3936 - accuracy: 0.8701 - val_loss: 2.0080 - val_accuracy: 0.3947\n",
      "Epoch 37/100\n",
      "177/177 [==============================] - 0s 343us/step - loss: 0.4255 - accuracy: 0.8757 - val_loss: 1.9354 - val_accuracy: 0.4474\n",
      "Epoch 38/100\n",
      "177/177 [==============================] - 0s 319us/step - loss: 0.4263 - accuracy: 0.8531 - val_loss: 1.8720 - val_accuracy: 0.4079\n",
      "Epoch 39/100\n",
      "177/177 [==============================] - 0s 340us/step - loss: 0.5441 - accuracy: 0.8588 - val_loss: 1.9242 - val_accuracy: 0.3816\n",
      "Epoch 40/100\n",
      "177/177 [==============================] - 0s 332us/step - loss: 0.5193 - accuracy: 0.8418 - val_loss: 1.9004 - val_accuracy: 0.3947\n",
      "Epoch 41/100\n",
      "177/177 [==============================] - 0s 314us/step - loss: 0.5554 - accuracy: 0.8362 - val_loss: 1.9418 - val_accuracy: 0.4737\n",
      "Epoch 42/100\n",
      "177/177 [==============================] - 0s 320us/step - loss: 0.3691 - accuracy: 0.8475 - val_loss: 1.8472 - val_accuracy: 0.4211\n",
      "Epoch 43/100\n",
      "177/177 [==============================] - 0s 325us/step - loss: 0.4778 - accuracy: 0.8701 - val_loss: 1.8672 - val_accuracy: 0.3947\n",
      "Epoch 44/100\n",
      "177/177 [==============================] - 0s 322us/step - loss: 0.4543 - accuracy: 0.8701 - val_loss: 1.8780 - val_accuracy: 0.3816\n",
      "Epoch 45/100\n",
      "177/177 [==============================] - 0s 328us/step - loss: 0.3341 - accuracy: 0.8814 - val_loss: 1.8443 - val_accuracy: 0.4211\n",
      "Epoch 46/100\n",
      "177/177 [==============================] - 0s 317us/step - loss: 0.3508 - accuracy: 0.8757 - val_loss: 1.9106 - val_accuracy: 0.4079\n",
      "Epoch 47/100\n",
      "177/177 [==============================] - 0s 409us/step - loss: 0.4101 - accuracy: 0.8814 - val_loss: 1.9299 - val_accuracy: 0.4211\n",
      "Epoch 48/100\n",
      "177/177 [==============================] - 0s 431us/step - loss: 0.3295 - accuracy: 0.8701 - val_loss: 1.8852 - val_accuracy: 0.4079\n",
      "Epoch 49/100\n",
      "177/177 [==============================] - 0s 331us/step - loss: 0.3479 - accuracy: 0.8927 - val_loss: 1.9277 - val_accuracy: 0.3816\n",
      "Epoch 50/100\n",
      "177/177 [==============================] - 0s 329us/step - loss: 0.3929 - accuracy: 0.9266 - val_loss: 1.9637 - val_accuracy: 0.4211\n",
      "Epoch 51/100\n",
      "177/177 [==============================] - 0s 365us/step - loss: 0.3667 - accuracy: 0.8870 - val_loss: 1.9280 - val_accuracy: 0.4079\n",
      "Epoch 52/100\n",
      "177/177 [==============================] - 0s 641us/step - loss: 0.3609 - accuracy: 0.8701 - val_loss: 1.8818 - val_accuracy: 0.4342\n",
      "Epoch 53/100\n",
      "177/177 [==============================] - 0s 665us/step - loss: 0.4310 - accuracy: 0.8870 - val_loss: 1.9193 - val_accuracy: 0.4211\n",
      "Epoch 54/100\n",
      "177/177 [==============================] - 0s 354us/step - loss: 0.3219 - accuracy: 0.8983 - val_loss: 1.9628 - val_accuracy: 0.4342\n",
      "Epoch 55/100\n",
      "177/177 [==============================] - 0s 374us/step - loss: 0.3526 - accuracy: 0.9040 - val_loss: 1.9292 - val_accuracy: 0.4211\n",
      "Epoch 56/100\n",
      "177/177 [==============================] - 0s 343us/step - loss: 0.3389 - accuracy: 0.8701 - val_loss: 1.9686 - val_accuracy: 0.3553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "177/177 [==============================] - 0s 431us/step - loss: 0.3562 - accuracy: 0.8588 - val_loss: 1.9866 - val_accuracy: 0.3553\n",
      "Epoch 58/100\n",
      "177/177 [==============================] - 0s 450us/step - loss: 0.4635 - accuracy: 0.8588 - val_loss: 1.9444 - val_accuracy: 0.3684\n",
      "Epoch 59/100\n",
      "177/177 [==============================] - 0s 429us/step - loss: 0.4262 - accuracy: 0.8814 - val_loss: 2.0161 - val_accuracy: 0.3816\n",
      "Epoch 60/100\n",
      "177/177 [==============================] - 0s 324us/step - loss: 0.3738 - accuracy: 0.8644 - val_loss: 2.0320 - val_accuracy: 0.3553\n",
      "Epoch 61/100\n",
      "177/177 [==============================] - 0s 360us/step - loss: 0.3831 - accuracy: 0.8418 - val_loss: 1.9790 - val_accuracy: 0.3684\n",
      "Epoch 62/100\n",
      "177/177 [==============================] - 0s 388us/step - loss: 0.4453 - accuracy: 0.8701 - val_loss: 1.9871 - val_accuracy: 0.3553\n",
      "Epoch 63/100\n",
      "177/177 [==============================] - 0s 419us/step - loss: 0.3711 - accuracy: 0.8757 - val_loss: 2.0691 - val_accuracy: 0.3553\n",
      "Epoch 64/100\n",
      "177/177 [==============================] - 0s 426us/step - loss: 0.4734 - accuracy: 0.8644 - val_loss: 2.0798 - val_accuracy: 0.3421\n",
      "Epoch 65/100\n",
      "177/177 [==============================] - 0s 355us/step - loss: 0.3972 - accuracy: 0.8588 - val_loss: 1.9795 - val_accuracy: 0.3553\n",
      "Epoch 66/100\n",
      "177/177 [==============================] - 0s 434us/step - loss: 0.4532 - accuracy: 0.8644 - val_loss: 1.9457 - val_accuracy: 0.3421\n",
      "Epoch 67/100\n",
      "177/177 [==============================] - 0s 507us/step - loss: 0.4533 - accuracy: 0.8644 - val_loss: 2.0155 - val_accuracy: 0.3421\n",
      "Epoch 68/100\n",
      "177/177 [==============================] - 0s 414us/step - loss: 0.3086 - accuracy: 0.8814 - val_loss: 2.0614 - val_accuracy: 0.3684\n",
      "Epoch 69/100\n",
      "177/177 [==============================] - 0s 408us/step - loss: 0.3517 - accuracy: 0.8927 - val_loss: 2.0475 - val_accuracy: 0.3553\n",
      "Epoch 70/100\n",
      "177/177 [==============================] - 0s 436us/step - loss: 0.3236 - accuracy: 0.8870 - val_loss: 1.9972 - val_accuracy: 0.3684\n",
      "Epoch 71/100\n",
      "177/177 [==============================] - 0s 441us/step - loss: 0.3220 - accuracy: 0.8983 - val_loss: 2.0355 - val_accuracy: 0.3553\n",
      "Epoch 72/100\n",
      "177/177 [==============================] - 0s 437us/step - loss: 0.3150 - accuracy: 0.8701 - val_loss: 2.0723 - val_accuracy: 0.3553\n",
      "Epoch 73/100\n",
      "177/177 [==============================] - 0s 344us/step - loss: 0.3536 - accuracy: 0.8870 - val_loss: 2.0309 - val_accuracy: 0.3684\n",
      "Epoch 74/100\n",
      "177/177 [==============================] - 0s 355us/step - loss: 0.3178 - accuracy: 0.8701 - val_loss: 2.0152 - val_accuracy: 0.3553\n",
      "Epoch 75/100\n",
      "177/177 [==============================] - 0s 447us/step - loss: 0.3073 - accuracy: 0.8927 - val_loss: 2.0644 - val_accuracy: 0.3553\n",
      "Epoch 76/100\n",
      "177/177 [==============================] - 0s 521us/step - loss: 0.3398 - accuracy: 0.8927 - val_loss: 2.0454 - val_accuracy: 0.3421\n",
      "Epoch 77/100\n",
      "177/177 [==============================] - 0s 384us/step - loss: 0.3222 - accuracy: 0.8814 - val_loss: 2.0651 - val_accuracy: 0.3684\n",
      "Epoch 78/100\n",
      "177/177 [==============================] - 0s 420us/step - loss: 0.3151 - accuracy: 0.8927 - val_loss: 2.0797 - val_accuracy: 0.3684\n",
      "Epoch 79/100\n",
      "177/177 [==============================] - 0s 476us/step - loss: 0.3144 - accuracy: 0.8927 - val_loss: 2.0776 - val_accuracy: 0.3684\n",
      "Epoch 80/100\n",
      "177/177 [==============================] - 0s 428us/step - loss: 0.4100 - accuracy: 0.8927 - val_loss: 2.1276 - val_accuracy: 0.3684\n",
      "Epoch 81/100\n",
      "177/177 [==============================] - 0s 306us/step - loss: 0.3969 - accuracy: 0.8701 - val_loss: 2.0710 - val_accuracy: 0.3421\n",
      "Epoch 82/100\n",
      "177/177 [==============================] - 0s 376us/step - loss: 0.3867 - accuracy: 0.8870 - val_loss: 2.0809 - val_accuracy: 0.3684\n",
      "Epoch 83/100\n",
      "177/177 [==============================] - 0s 324us/step - loss: 0.3415 - accuracy: 0.9040 - val_loss: 2.1154 - val_accuracy: 0.3684\n",
      "Epoch 84/100\n",
      "177/177 [==============================] - 0s 333us/step - loss: 0.3651 - accuracy: 0.8757 - val_loss: 2.1401 - val_accuracy: 0.3553\n",
      "Epoch 85/100\n",
      "177/177 [==============================] - 0s 770us/step - loss: 0.3693 - accuracy: 0.8814 - val_loss: 2.1178 - val_accuracy: 0.3553\n",
      "Epoch 86/100\n",
      "177/177 [==============================] - 0s 572us/step - loss: 0.3236 - accuracy: 0.8701 - val_loss: 2.0856 - val_accuracy: 0.3684\n",
      "Epoch 87/100\n",
      "177/177 [==============================] - 0s 551us/step - loss: 0.3629 - accuracy: 0.8757 - val_loss: 2.1123 - val_accuracy: 0.3553\n",
      "Epoch 88/100\n",
      "177/177 [==============================] - 0s 374us/step - loss: 0.3090 - accuracy: 0.8870 - val_loss: 2.1643 - val_accuracy: 0.3684\n",
      "Epoch 89/100\n",
      "177/177 [==============================] - 0s 366us/step - loss: 0.3821 - accuracy: 0.8870 - val_loss: 2.1337 - val_accuracy: 0.3684\n",
      "Epoch 90/100\n",
      "177/177 [==============================] - 0s 413us/step - loss: 0.3257 - accuracy: 0.8644 - val_loss: 2.0976 - val_accuracy: 0.3553\n",
      "Epoch 91/100\n",
      "177/177 [==============================] - 0s 354us/step - loss: 0.3114 - accuracy: 0.8870 - val_loss: 2.1124 - val_accuracy: 0.3421\n",
      "Epoch 92/100\n",
      "177/177 [==============================] - 0s 320us/step - loss: 0.3709 - accuracy: 0.8983 - val_loss: 2.1220 - val_accuracy: 0.3553\n",
      "Epoch 93/100\n",
      "177/177 [==============================] - 0s 297us/step - loss: 0.3091 - accuracy: 0.8983 - val_loss: 2.1269 - val_accuracy: 0.3553\n",
      "Epoch 94/100\n",
      "177/177 [==============================] - 0s 309us/step - loss: 0.3811 - accuracy: 0.8870 - val_loss: 2.1452 - val_accuracy: 0.3553\n",
      "Epoch 95/100\n",
      "177/177 [==============================] - 0s 422us/step - loss: 0.3352 - accuracy: 0.9040 - val_loss: 2.1199 - val_accuracy: 0.3421\n",
      "Epoch 96/100\n",
      "177/177 [==============================] - 0s 554us/step - loss: 0.3676 - accuracy: 0.8870 - val_loss: 2.1076 - val_accuracy: 0.3553\n",
      "Epoch 97/100\n",
      "177/177 [==============================] - 0s 371us/step - loss: 0.3675 - accuracy: 0.8757 - val_loss: 2.1589 - val_accuracy: 0.3421\n",
      "Epoch 98/100\n",
      "177/177 [==============================] - 0s 364us/step - loss: 0.2817 - accuracy: 0.8927 - val_loss: 2.1796 - val_accuracy: 0.3421\n",
      "Epoch 99/100\n",
      "177/177 [==============================] - 0s 320us/step - loss: 0.3033 - accuracy: 0.8870 - val_loss: 2.1454 - val_accuracy: 0.3421\n",
      "Epoch 100/100\n",
      "177/177 [==============================] - 0s 408us/step - loss: 0.2970 - accuracy: 0.8927 - val_loss: 2.1490 - val_accuracy: 0.3553\n"
     ]
    }
   ],
   "source": [
    "hist2 = model2.fit(X_train, y_train,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 87.12%\n"
     ]
    }
   ],
   "source": [
    "print('train accuracy: %.2f%%' % (np.mean(hist2.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba2 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_2.xlsx\",\n",
    "                        sheet_name=1,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NRS210</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999887</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>8.851192e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>Grady1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.625329</td>\n",
       "      <td>0.369782</td>\n",
       "      <td>4.889404e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>CFBRSa29</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999098</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>6.335156e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>CFBRSa03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.647338</td>\n",
       "      <td>0.331796</td>\n",
       "      <td>2.086646e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>217</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.613342</td>\n",
       "      <td>0.381903</td>\n",
       "      <td>4.754707e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>NRS265</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.025601</td>\n",
       "      <td>0.687962</td>\n",
       "      <td>2.864372e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>NY439</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.161947</td>\n",
       "      <td>0.266501</td>\n",
       "      <td>5.715521e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>CFBRSa05</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.652983</td>\n",
       "      <td>0.254172</td>\n",
       "      <td>9.284494e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>NRS205</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000927</td>\n",
       "      <td>0.033760</td>\n",
       "      <td>9.653131e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>CA105</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.736115</td>\n",
       "      <td>0.260109</td>\n",
       "      <td>3.775318e-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>608 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     phage    strain  phenotype  prediction         0  \\\n",
       "0       p0017kpresabs_qual    NRS210          2           0  0.999887   \n",
       "1       p0017kpresabs_qual    Grady1          0           0  0.625329   \n",
       "2       p0017kpresabs_qual  CFBRSa29          2           0  0.999098   \n",
       "3       p0017kpresabs_qual  CFBRSa03          0           0  0.647338   \n",
       "4       p0017kpresabs_qual       217          1           0  0.613342   \n",
       "..                     ...       ...        ...         ...       ...   \n",
       "603  p0040presabsSTCC_qual    NRS265          1           1  0.025601   \n",
       "604  p0040presabsSTCC_qual     NY439          2           2  0.161947   \n",
       "605  p0040presabsSTCC_qual  CFBRSa05          0           0  0.652983   \n",
       "606  p0040presabsSTCC_qual    NRS205          2           2  0.000927   \n",
       "607  p0040presabsSTCC_qual     CA105          1           0  0.736115   \n",
       "\n",
       "            1             2  \n",
       "0    0.000112  8.851192e-07  \n",
       "1    0.369782  4.889404e-03  \n",
       "2    0.000269  6.335156e-04  \n",
       "3    0.331796  2.086646e-02  \n",
       "4    0.381903  4.754707e-03  \n",
       "..        ...           ...  \n",
       "603  0.687962  2.864372e-01  \n",
       "604  0.266501  5.715521e-01  \n",
       "605  0.254172  9.284494e-02  \n",
       "606  0.033760  9.653131e-01  \n",
       "607  0.260109  3.775318e-03  \n",
       "\n",
       "[608 rows x 7 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.24647660e-01, 4.08826020e-01, 1.66526320e-01],\n",
       "       [7.18681100e-01, 1.80437520e-01, 1.00881360e-01],\n",
       "       [9.47249000e-01, 9.37690200e-03, 4.33740900e-02],\n",
       "       [1.07966706e-01, 6.47847830e-01, 2.44185400e-01],\n",
       "       [5.29560150e-01, 3.60272680e-01, 1.10167170e-01],\n",
       "       [5.15713060e-02, 8.18200100e-02, 8.66608700e-01],\n",
       "       [9.76539130e-01, 1.04538990e-02, 1.30070230e-02],\n",
       "       [4.20736760e-01, 4.39833020e-01, 1.39430120e-01],\n",
       "       [3.09566180e-04, 7.84324800e-02, 9.21257900e-01],\n",
       "       [9.53557250e-01, 3.84975000e-02, 7.94523000e-03],\n",
       "       [4.01180400e-01, 4.24578250e-01, 1.74241440e-01],\n",
       "       [9.39308850e-03, 2.11539610e-01, 7.79067300e-01],\n",
       "       [8.04686900e-01, 1.72121930e-01, 2.31912320e-02],\n",
       "       [2.61865760e-01, 7.31533000e-01, 6.60125860e-03],\n",
       "       [2.38813100e-01, 6.65672060e-01, 9.55148040e-02],\n",
       "       [6.25298260e-01, 2.95344740e-01, 7.93570300e-02],\n",
       "       [5.00576700e-04, 9.99377200e-01, 1.22274700e-04],\n",
       "       [3.22207180e-01, 6.70551240e-01, 7.24155600e-03],\n",
       "       [5.39691230e-03, 4.31195000e-02, 9.51483600e-01],\n",
       "       [9.13577740e-01, 3.16774320e-02, 5.47447880e-02],\n",
       "       [4.90678330e-02, 4.76643230e-01, 4.74289000e-01],\n",
       "       [1.56124000e-01, 5.74744000e-01, 2.69132050e-01],\n",
       "       [9.79327260e-01, 3.98195260e-03, 1.66907460e-02],\n",
       "       [6.27129700e-03, 6.63917840e-01, 3.29810860e-01],\n",
       "       [3.92572000e-03, 6.23155060e-01, 3.72919230e-01],\n",
       "       [9.73971100e-01, 1.73800180e-02, 8.64890000e-03],\n",
       "       [6.82426630e-01, 5.05749020e-02, 2.66998440e-01],\n",
       "       [3.21249750e-01, 5.88288800e-01, 9.04614900e-02],\n",
       "       [3.15500470e-01, 3.21895540e-01, 3.62603930e-01],\n",
       "       [2.96424180e-02, 5.06113130e-02, 9.19746200e-01],\n",
       "       [2.55101380e-03, 9.96964750e-01, 4.84238670e-04],\n",
       "       [1.33284380e-03, 1.42054050e-01, 8.56613100e-01],\n",
       "       [9.48983940e-04, 8.39014900e-02, 9.15149500e-01],\n",
       "       [9.63690000e-01, 6.03004820e-03, 3.02799680e-02],\n",
       "       [1.81610610e-01, 6.09451760e-02, 7.57444200e-01],\n",
       "       [6.78510100e-01, 4.56856200e-02, 2.75804220e-01],\n",
       "       [7.82338900e-01, 1.50615740e-01, 6.70453900e-02],\n",
       "       [9.51210000e-01, 2.48794410e-04, 4.85412200e-02],\n",
       "       [1.51025170e-02, 9.72754960e-01, 1.21425120e-02],\n",
       "       [9.01892900e-01, 8.49805700e-02, 1.31265380e-02],\n",
       "       [1.84142570e-02, 4.72467570e-01, 5.09118140e-01],\n",
       "       [1.14899170e-01, 6.44298500e-01, 2.40802360e-01],\n",
       "       [1.79033100e-02, 2.82550400e-04, 9.81814100e-01],\n",
       "       [1.66333960e-01, 6.09451400e-01, 2.24214630e-01],\n",
       "       [5.68737000e-01, 2.64147820e-01, 1.67115270e-01],\n",
       "       [1.57332080e-01, 6.90594000e-01, 1.52073900e-01],\n",
       "       [5.39311950e-01, 3.57414870e-01, 1.03273170e-01],\n",
       "       [1.40857190e-01, 5.26208600e-01, 3.32934230e-01],\n",
       "       [3.24629000e-01, 5.28689400e-01, 1.46681640e-01],\n",
       "       [2.63068280e-02, 5.18867300e-01, 4.54825880e-01],\n",
       "       [1.24443000e-01, 8.80462100e-03, 8.66752400e-01],\n",
       "       [2.06198150e-03, 9.96343550e-01, 1.59439420e-03],\n",
       "       [2.94346800e-01, 2.27459850e-01, 4.78193340e-01],\n",
       "       [1.58687270e-02, 4.35632350e-01, 5.48498900e-01],\n",
       "       [6.17662200e-01, 3.77981780e-01, 4.35601800e-03],\n",
       "       [8.06589840e-01, 1.53312040e-01, 4.00981400e-02],\n",
       "       [1.92536740e-01, 3.39964780e-01, 4.67498500e-01],\n",
       "       [9.42297640e-01, 1.44299180e-03, 5.62593530e-02],\n",
       "       [1.33844140e-01, 6.25205700e-01, 2.40950120e-01],\n",
       "       [6.28834000e-01, 1.82784570e-02, 3.52887480e-01],\n",
       "       [3.32408820e-01, 4.11966620e-01, 2.55624600e-01],\n",
       "       [3.32545260e-07, 9.03641100e-04, 9.99096040e-01],\n",
       "       [8.26974800e-03, 3.33629070e-01, 6.58101200e-01],\n",
       "       [4.84459550e-01, 3.59895640e-02, 4.79550870e-01],\n",
       "       [7.84116500e-01, 1.20179266e-01, 9.57041800e-02],\n",
       "       [6.84117100e-01, 2.91988500e-01, 2.38944440e-02],\n",
       "       [9.76149400e-01, 1.71036120e-04, 2.36795820e-02],\n",
       "       [5.00673950e-02, 6.82354330e-01, 2.67578300e-01],\n",
       "       [7.74967130e-01, 1.25616800e-01, 9.94160800e-02],\n",
       "       [8.75740800e-02, 1.21534660e-01, 7.90891300e-01],\n",
       "       [9.96743400e-01, 2.59773000e-04, 2.99687050e-03],\n",
       "       [3.32118270e-01, 5.31637800e-01, 1.36243910e-01],\n",
       "       [2.89990200e-01, 6.52280150e-01, 5.77296840e-02],\n",
       "       [6.15251960e-01, 1.18301970e-01, 2.66446020e-01],\n",
       "       [4.27121900e-01, 2.93655320e-02, 5.43512600e-01],\n",
       "       [1.09295130e-03, 7.86403950e-01, 2.12503080e-01]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob2 = df_proba2[df_proba2['phage']=='p0017kpresabsSTCC_qual'].iloc[:,-3:]\n",
    "y_prob2 = y_prob2.to_numpy()\n",
    "y_prob2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5709819281247853"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo2 = rocauc_ovo(y_test, y_prob2, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5709819281247853"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr2 = rocauc_ovr(y_test, y_prob2, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=345,\n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat3 = pd.DataFrame(X_test.iloc[:,0])\n",
    "dat3['test'] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>NY360</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>EUH25</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>EUH15</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>NRS241</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>SR2852</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>BCH-SA-11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>NRS022</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>GA27</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>NRS102</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>NRS192</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  test\n",
       "231      NY360     2\n",
       "92       EUH25     2\n",
       "91       EUH15     2\n",
       "203     NRS241     0\n",
       "242     SR2852     2\n",
       "..         ...   ...\n",
       "26   BCH-SA-11     0\n",
       "111     NRS022     1\n",
       "96        GA27     2\n",
       "129     NRS102     1\n",
       "166     NRS192     0\n",
       "\n",
       "[76 rows x 2 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(['id'], axis=1)\n",
    "X_test = X_test.drop(['id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 177 samples, validate on 76 samples\n",
      "Epoch 1/100\n",
      "177/177 [==============================] - 0s 1ms/step - loss: 2.3523 - accuracy: 0.2881 - val_loss: 3.2508 - val_accuracy: 0.4737\n",
      "Epoch 2/100\n",
      "177/177 [==============================] - 0s 400us/step - loss: 1.6915 - accuracy: 0.4633 - val_loss: 2.7861 - val_accuracy: 0.4474\n",
      "Epoch 3/100\n",
      "177/177 [==============================] - 0s 379us/step - loss: 1.3269 - accuracy: 0.5254 - val_loss: 2.2743 - val_accuracy: 0.3289\n",
      "Epoch 4/100\n",
      "177/177 [==============================] - 0s 360us/step - loss: 1.0844 - accuracy: 0.5141 - val_loss: 1.8620 - val_accuracy: 0.3026\n",
      "Epoch 5/100\n",
      "177/177 [==============================] - 0s 346us/step - loss: 1.0418 - accuracy: 0.5593 - val_loss: 1.5707 - val_accuracy: 0.3421\n",
      "Epoch 6/100\n",
      "177/177 [==============================] - 0s 378us/step - loss: 0.9628 - accuracy: 0.6384 - val_loss: 1.4432 - val_accuracy: 0.3947\n",
      "Epoch 7/100\n",
      "177/177 [==============================] - 0s 481us/step - loss: 0.8618 - accuracy: 0.6328 - val_loss: 1.4124 - val_accuracy: 0.3553\n",
      "Epoch 8/100\n",
      "177/177 [==============================] - 0s 392us/step - loss: 0.8463 - accuracy: 0.6497 - val_loss: 1.3838 - val_accuracy: 0.3684\n",
      "Epoch 9/100\n",
      "177/177 [==============================] - 0s 430us/step - loss: 0.7963 - accuracy: 0.6554 - val_loss: 1.4115 - val_accuracy: 0.3553\n",
      "Epoch 10/100\n",
      "177/177 [==============================] - 0s 413us/step - loss: 0.7520 - accuracy: 0.6836 - val_loss: 1.4882 - val_accuracy: 0.3553\n",
      "Epoch 11/100\n",
      "177/177 [==============================] - 0s 488us/step - loss: 0.7441 - accuracy: 0.6723 - val_loss: 1.4672 - val_accuracy: 0.3553\n",
      "Epoch 12/100\n",
      "177/177 [==============================] - 0s 605us/step - loss: 0.7085 - accuracy: 0.7006 - val_loss: 1.5175 - val_accuracy: 0.3421\n",
      "Epoch 13/100\n",
      "177/177 [==============================] - 0s 541us/step - loss: 0.7024 - accuracy: 0.7232 - val_loss: 1.5284 - val_accuracy: 0.3553\n",
      "Epoch 14/100\n",
      "177/177 [==============================] - 0s 390us/step - loss: 0.6957 - accuracy: 0.7006 - val_loss: 1.5355 - val_accuracy: 0.3421\n",
      "Epoch 15/100\n",
      "177/177 [==============================] - 0s 436us/step - loss: 0.6648 - accuracy: 0.7119 - val_loss: 1.5822 - val_accuracy: 0.3421\n",
      "Epoch 16/100\n",
      "177/177 [==============================] - 0s 549us/step - loss: 0.6759 - accuracy: 0.7232 - val_loss: 1.5258 - val_accuracy: 0.3421\n",
      "Epoch 17/100\n",
      "177/177 [==============================] - 0s 600us/step - loss: 0.6283 - accuracy: 0.7458 - val_loss: 1.5602 - val_accuracy: 0.3553\n",
      "Epoch 18/100\n",
      "177/177 [==============================] - 0s 500us/step - loss: 0.6415 - accuracy: 0.7458 - val_loss: 1.6013 - val_accuracy: 0.3684\n",
      "Epoch 19/100\n",
      "177/177 [==============================] - 0s 417us/step - loss: 0.6020 - accuracy: 0.7627 - val_loss: 1.6487 - val_accuracy: 0.3684\n",
      "Epoch 20/100\n",
      "177/177 [==============================] - 0s 432us/step - loss: 0.5900 - accuracy: 0.7684 - val_loss: 1.7053 - val_accuracy: 0.3289\n",
      "Epoch 21/100\n",
      "177/177 [==============================] - 0s 875us/step - loss: 0.5695 - accuracy: 0.7853 - val_loss: 1.7359 - val_accuracy: 0.3289\n",
      "Epoch 22/100\n",
      "177/177 [==============================] - 0s 361us/step - loss: 0.5795 - accuracy: 0.7966 - val_loss: 1.7179 - val_accuracy: 0.3816\n",
      "Epoch 23/100\n",
      "177/177 [==============================] - 0s 600us/step - loss: 0.5419 - accuracy: 0.7797 - val_loss: 1.7317 - val_accuracy: 0.3421\n",
      "Epoch 24/100\n",
      "177/177 [==============================] - 0s 782us/step - loss: 0.5450 - accuracy: 0.8192 - val_loss: 1.7974 - val_accuracy: 0.3684\n",
      "Epoch 25/100\n",
      "177/177 [==============================] - 0s 330us/step - loss: 0.5479 - accuracy: 0.8136 - val_loss: 2.0872 - val_accuracy: 0.3684\n",
      "Epoch 26/100\n",
      "177/177 [==============================] - 0s 412us/step - loss: 0.5533 - accuracy: 0.8023 - val_loss: 1.8970 - val_accuracy: 0.3553\n",
      "Epoch 27/100\n",
      "177/177 [==============================] - 0s 442us/step - loss: 0.5531 - accuracy: 0.8136 - val_loss: 1.8089 - val_accuracy: 0.4211\n",
      "Epoch 28/100\n",
      "177/177 [==============================] - 0s 315us/step - loss: 0.5368 - accuracy: 0.7966 - val_loss: 1.8381 - val_accuracy: 0.3553\n",
      "Epoch 29/100\n",
      "177/177 [==============================] - 0s 346us/step - loss: 0.5363 - accuracy: 0.8249 - val_loss: 1.9177 - val_accuracy: 0.3421\n",
      "Epoch 30/100\n",
      "177/177 [==============================] - 0s 341us/step - loss: 0.4849 - accuracy: 0.8305 - val_loss: 2.0348 - val_accuracy: 0.4079\n",
      "Epoch 31/100\n",
      "177/177 [==============================] - 0s 980us/step - loss: 0.5294 - accuracy: 0.8362 - val_loss: 2.0296 - val_accuracy: 0.3158\n",
      "Epoch 32/100\n",
      "177/177 [==============================] - 0s 674us/step - loss: 0.5307 - accuracy: 0.8362 - val_loss: 2.0498 - val_accuracy: 0.3816\n",
      "Epoch 33/100\n",
      "177/177 [==============================] - 0s 634us/step - loss: 0.5201 - accuracy: 0.8305 - val_loss: 2.2663 - val_accuracy: 0.3816\n",
      "Epoch 34/100\n",
      "177/177 [==============================] - 0s 560us/step - loss: 0.4841 - accuracy: 0.8362 - val_loss: 2.1086 - val_accuracy: 0.3158\n",
      "Epoch 35/100\n",
      "177/177 [==============================] - 0s 741us/step - loss: 0.4908 - accuracy: 0.8249 - val_loss: 1.9928 - val_accuracy: 0.3947\n",
      "Epoch 36/100\n",
      "177/177 [==============================] - 0s 519us/step - loss: 0.4439 - accuracy: 0.8362 - val_loss: 1.9866 - val_accuracy: 0.3816\n",
      "Epoch 37/100\n",
      "177/177 [==============================] - 0s 449us/step - loss: 0.4862 - accuracy: 0.8362 - val_loss: 1.9776 - val_accuracy: 0.3684\n",
      "Epoch 38/100\n",
      "177/177 [==============================] - 0s 402us/step - loss: 0.4783 - accuracy: 0.8531 - val_loss: 2.0687 - val_accuracy: 0.3684\n",
      "Epoch 39/100\n",
      "177/177 [==============================] - 0s 547us/step - loss: 0.4479 - accuracy: 0.8588 - val_loss: 2.1051 - val_accuracy: 0.3684\n",
      "Epoch 40/100\n",
      "177/177 [==============================] - 0s 2ms/step - loss: 0.4220 - accuracy: 0.8757 - val_loss: 2.1527 - val_accuracy: 0.3684\n",
      "Epoch 41/100\n",
      "177/177 [==============================] - 0s 615us/step - loss: 0.3891 - accuracy: 0.8701 - val_loss: 2.1755 - val_accuracy: 0.3947\n",
      "Epoch 42/100\n",
      "177/177 [==============================] - 0s 540us/step - loss: 0.3938 - accuracy: 0.8701 - val_loss: 2.1427 - val_accuracy: 0.3684\n",
      "Epoch 43/100\n",
      "177/177 [==============================] - 0s 535us/step - loss: 0.3814 - accuracy: 0.8757 - val_loss: 2.1518 - val_accuracy: 0.3421\n",
      "Epoch 44/100\n",
      "177/177 [==============================] - 0s 494us/step - loss: 0.3697 - accuracy: 0.8757 - val_loss: 2.1585 - val_accuracy: 0.3553\n",
      "Epoch 45/100\n",
      "177/177 [==============================] - 0s 382us/step - loss: 0.3692 - accuracy: 0.8814 - val_loss: 2.2682 - val_accuracy: 0.3684\n",
      "Epoch 46/100\n",
      "177/177 [==============================] - 0s 331us/step - loss: 0.3732 - accuracy: 0.8588 - val_loss: 2.2587 - val_accuracy: 0.4079\n",
      "Epoch 47/100\n",
      "177/177 [==============================] - 0s 346us/step - loss: 0.3535 - accuracy: 0.9040 - val_loss: 2.2857 - val_accuracy: 0.3289\n",
      "Epoch 48/100\n",
      "177/177 [==============================] - 0s 347us/step - loss: 0.3813 - accuracy: 0.8757 - val_loss: 2.3149 - val_accuracy: 0.4079\n",
      "Epoch 49/100\n",
      "177/177 [==============================] - 0s 311us/step - loss: 0.3373 - accuracy: 0.8757 - val_loss: 2.3295 - val_accuracy: 0.3816\n",
      "Epoch 50/100\n",
      "177/177 [==============================] - 0s 326us/step - loss: 0.3759 - accuracy: 0.8814 - val_loss: 2.3235 - val_accuracy: 0.4079\n",
      "Epoch 51/100\n",
      "177/177 [==============================] - 0s 618us/step - loss: 0.3397 - accuracy: 0.8757 - val_loss: 2.3177 - val_accuracy: 0.3947\n",
      "Epoch 52/100\n",
      "177/177 [==============================] - 0s 629us/step - loss: 0.3789 - accuracy: 0.8927 - val_loss: 2.3289 - val_accuracy: 0.4211\n",
      "Epoch 53/100\n",
      "177/177 [==============================] - 0s 602us/step - loss: 0.3509 - accuracy: 0.8983 - val_loss: 2.3923 - val_accuracy: 0.3947\n",
      "Epoch 54/100\n",
      "177/177 [==============================] - 0s 411us/step - loss: 0.3641 - accuracy: 0.8870 - val_loss: 2.4292 - val_accuracy: 0.3816\n",
      "Epoch 55/100\n",
      "177/177 [==============================] - 0s 331us/step - loss: 0.3275 - accuracy: 0.8870 - val_loss: 2.4420 - val_accuracy: 0.3816\n",
      "Epoch 56/100\n",
      "177/177 [==============================] - 0s 317us/step - loss: 0.3912 - accuracy: 0.8814 - val_loss: 2.4221 - val_accuracy: 0.3816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "177/177 [==============================] - 0s 366us/step - loss: 0.3773 - accuracy: 0.8870 - val_loss: 2.4871 - val_accuracy: 0.4079\n",
      "Epoch 58/100\n",
      "177/177 [==============================] - 0s 482us/step - loss: 0.3356 - accuracy: 0.8983 - val_loss: 2.6041 - val_accuracy: 0.4079\n",
      "Epoch 59/100\n",
      "177/177 [==============================] - 0s 532us/step - loss: 0.4069 - accuracy: 0.8870 - val_loss: 2.6427 - val_accuracy: 0.3553\n",
      "Epoch 60/100\n",
      "177/177 [==============================] - 0s 357us/step - loss: 0.3879 - accuracy: 0.8983 - val_loss: 2.3989 - val_accuracy: 0.3816\n",
      "Epoch 61/100\n",
      "177/177 [==============================] - 0s 561us/step - loss: 0.3260 - accuracy: 0.8927 - val_loss: 2.4294 - val_accuracy: 0.3947\n",
      "Epoch 62/100\n",
      "177/177 [==============================] - 0s 537us/step - loss: 0.3018 - accuracy: 0.8870 - val_loss: 2.5242 - val_accuracy: 0.3816\n",
      "Epoch 63/100\n",
      "177/177 [==============================] - 0s 446us/step - loss: 0.3151 - accuracy: 0.8927 - val_loss: 2.4605 - val_accuracy: 0.3947\n",
      "Epoch 64/100\n",
      "177/177 [==============================] - 0s 449us/step - loss: 0.3152 - accuracy: 0.9096 - val_loss: 2.4733 - val_accuracy: 0.4079\n",
      "Epoch 65/100\n",
      "177/177 [==============================] - 0s 447us/step - loss: 0.2752 - accuracy: 0.9153 - val_loss: 2.5698 - val_accuracy: 0.4211\n",
      "Epoch 66/100\n",
      "177/177 [==============================] - 0s 322us/step - loss: 0.3018 - accuracy: 0.9096 - val_loss: 2.6213 - val_accuracy: 0.3421\n",
      "Epoch 67/100\n",
      "177/177 [==============================] - 0s 303us/step - loss: 0.2678 - accuracy: 0.9096 - val_loss: 2.5912 - val_accuracy: 0.4079\n",
      "Epoch 68/100\n",
      "177/177 [==============================] - 0s 358us/step - loss: 0.3070 - accuracy: 0.9153 - val_loss: 2.5643 - val_accuracy: 0.3553\n",
      "Epoch 69/100\n",
      "177/177 [==============================] - 0s 367us/step - loss: 0.2847 - accuracy: 0.9096 - val_loss: 2.5249 - val_accuracy: 0.3816\n",
      "Epoch 70/100\n",
      "177/177 [==============================] - 0s 457us/step - loss: 0.2654 - accuracy: 0.9153 - val_loss: 2.5649 - val_accuracy: 0.3816\n",
      "Epoch 71/100\n",
      "177/177 [==============================] - 0s 312us/step - loss: 0.2645 - accuracy: 0.9209 - val_loss: 2.6002 - val_accuracy: 0.4079\n",
      "Epoch 72/100\n",
      "177/177 [==============================] - 0s 310us/step - loss: 0.2695 - accuracy: 0.9040 - val_loss: 2.6044 - val_accuracy: 0.4211\n",
      "Epoch 73/100\n",
      "177/177 [==============================] - 0s 408us/step - loss: 0.3060 - accuracy: 0.9209 - val_loss: 2.5860 - val_accuracy: 0.3421\n",
      "Epoch 74/100\n",
      "177/177 [==============================] - 0s 324us/step - loss: 0.2931 - accuracy: 0.9040 - val_loss: 2.4812 - val_accuracy: 0.3553\n",
      "Epoch 75/100\n",
      "177/177 [==============================] - 0s 340us/step - loss: 0.2949 - accuracy: 0.9096 - val_loss: 2.4408 - val_accuracy: 0.3684\n",
      "Epoch 76/100\n",
      "177/177 [==============================] - 0s 313us/step - loss: 0.2778 - accuracy: 0.9096 - val_loss: 2.4419 - val_accuracy: 0.3684\n",
      "Epoch 77/100\n",
      "177/177 [==============================] - 0s 322us/step - loss: 0.3118 - accuracy: 0.8927 - val_loss: 2.3025 - val_accuracy: 0.3816\n",
      "Epoch 78/100\n",
      "177/177 [==============================] - 0s 397us/step - loss: 0.2597 - accuracy: 0.9153 - val_loss: 2.4184 - val_accuracy: 0.3816\n",
      "Epoch 79/100\n",
      "177/177 [==============================] - 0s 389us/step - loss: 0.2623 - accuracy: 0.9153 - val_loss: 2.3977 - val_accuracy: 0.4342\n",
      "Epoch 80/100\n",
      "177/177 [==============================] - 0s 318us/step - loss: 0.2580 - accuracy: 0.9040 - val_loss: 2.4585 - val_accuracy: 0.3289\n",
      "Epoch 81/100\n",
      "177/177 [==============================] - 0s 312us/step - loss: 0.2510 - accuracy: 0.9209 - val_loss: 2.3938 - val_accuracy: 0.3947\n",
      "Epoch 82/100\n",
      "177/177 [==============================] - 0s 490us/step - loss: 0.2444 - accuracy: 0.9153 - val_loss: 2.3791 - val_accuracy: 0.3947\n",
      "Epoch 83/100\n",
      "177/177 [==============================] - 0s 338us/step - loss: 0.2398 - accuracy: 0.9322 - val_loss: 2.4407 - val_accuracy: 0.3684\n",
      "Epoch 84/100\n",
      "177/177 [==============================] - 0s 314us/step - loss: 0.2569 - accuracy: 0.9040 - val_loss: 2.4796 - val_accuracy: 0.3947\n",
      "Epoch 85/100\n",
      "177/177 [==============================] - 0s 353us/step - loss: 0.2113 - accuracy: 0.9322 - val_loss: 2.4731 - val_accuracy: 0.3684\n",
      "Epoch 86/100\n",
      "177/177 [==============================] - 0s 314us/step - loss: 0.2954 - accuracy: 0.9209 - val_loss: 2.4703 - val_accuracy: 0.3684\n",
      "Epoch 87/100\n",
      "177/177 [==============================] - 0s 328us/step - loss: 0.2682 - accuracy: 0.9209 - val_loss: 2.5346 - val_accuracy: 0.3684\n",
      "Epoch 88/100\n",
      "177/177 [==============================] - 0s 322us/step - loss: 0.2331 - accuracy: 0.9266 - val_loss: 2.5586 - val_accuracy: 0.3816\n",
      "Epoch 89/100\n",
      "177/177 [==============================] - 0s 312us/step - loss: 0.2344 - accuracy: 0.9209 - val_loss: 2.5253 - val_accuracy: 0.4079\n",
      "Epoch 90/100\n",
      "177/177 [==============================] - 0s 325us/step - loss: 0.2167 - accuracy: 0.9322 - val_loss: 2.5553 - val_accuracy: 0.3553\n",
      "Epoch 91/100\n",
      "177/177 [==============================] - 0s 317us/step - loss: 0.2297 - accuracy: 0.9153 - val_loss: 2.5544 - val_accuracy: 0.3684\n",
      "Epoch 92/100\n",
      "177/177 [==============================] - 0s 364us/step - loss: 0.2060 - accuracy: 0.9209 - val_loss: 2.5741 - val_accuracy: 0.3816\n",
      "Epoch 93/100\n",
      "177/177 [==============================] - 0s 320us/step - loss: 0.2145 - accuracy: 0.9040 - val_loss: 2.6229 - val_accuracy: 0.3553\n",
      "Epoch 94/100\n",
      "177/177 [==============================] - 0s 352us/step - loss: 0.2044 - accuracy: 0.9322 - val_loss: 2.5973 - val_accuracy: 0.3947\n",
      "Epoch 95/100\n",
      "177/177 [==============================] - 0s 379us/step - loss: 0.2092 - accuracy: 0.9209 - val_loss: 2.5692 - val_accuracy: 0.3947\n",
      "Epoch 96/100\n",
      "177/177 [==============================] - 0s 422us/step - loss: 0.2064 - accuracy: 0.9379 - val_loss: 2.5894 - val_accuracy: 0.3684\n",
      "Epoch 97/100\n",
      "177/177 [==============================] - 0s 561us/step - loss: 0.2068 - accuracy: 0.9266 - val_loss: 2.6039 - val_accuracy: 0.3816\n",
      "Epoch 98/100\n",
      "177/177 [==============================] - 0s 367us/step - loss: 0.1924 - accuracy: 0.9209 - val_loss: 2.6882 - val_accuracy: 0.3289\n",
      "Epoch 99/100\n",
      "177/177 [==============================] - 0s 360us/step - loss: 0.2019 - accuracy: 0.9153 - val_loss: 2.6498 - val_accuracy: 0.3816\n",
      "Epoch 100/100\n",
      "177/177 [==============================] - 0s 401us/step - loss: 0.2063 - accuracy: 0.9322 - val_loss: 2.6806 - val_accuracy: 0.3816\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x632a3b908>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.fit(X_train, y_train,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 0s 167us/step\n",
      "test accuracy: 40.79%\n"
     ]
    }
   ],
   "source": [
    "acc_test3 = model3.evaluate(X_test, y_test)[1]\n",
    "print('test accuracy: %.2f%%' % (acc_test3*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 0, 2, 2, 2, 2, 0, 0, 2, 0, 0, 0, 0, 1, 1, 2, 1, 0, 0, 2,\n",
       "       0, 2, 1, 2, 1, 0, 0, 0, 0, 0, 1, 2, 1, 1, 2, 2, 0, 1, 1, 1, 0, 2,\n",
       "       0, 0, 2, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 2, 2, 0, 1, 2,\n",
       "       2, 0, 2, 1, 1, 0, 2, 2, 0, 0])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred3 = model3.predict_classes(X_test)\n",
    "pred3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>NY360</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>EUH25</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>EUH15</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>NRS241</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>SR2852</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>BCH-SA-11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>NRS022</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>GA27</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>NRS102</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>NRS192</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  test  pred\n",
       "231      NY360     2     1\n",
       "92       EUH25     2     0\n",
       "91       EUH15     2     2\n",
       "203     NRS241     0     0\n",
       "242     SR2852     2     2\n",
       "..         ...   ...   ...\n",
       "26   BCH-SA-11     0     0\n",
       "111     NRS022     1     2\n",
       "96        GA27     2     2\n",
       "129     NRS102     1     0\n",
       "166     NRS192     0     0\n",
       "\n",
       "[76 rows x 3 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat3['pred'] = pred3\n",
    "dat3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba3 = model3.predict_proba(X_test)\n",
    "dat_proba3 = pd.DataFrame(proba3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.257059</td>\n",
       "      <td>0.641684</td>\n",
       "      <td>0.101257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.894516</td>\n",
       "      <td>0.081192</td>\n",
       "      <td>0.024292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.011563</td>\n",
       "      <td>0.120927</td>\n",
       "      <td>0.867510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.495871</td>\n",
       "      <td>0.477288</td>\n",
       "      <td>0.026841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.001606</td>\n",
       "      <td>0.996894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.724754</td>\n",
       "      <td>0.229334</td>\n",
       "      <td>0.045912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.011559</td>\n",
       "      <td>0.001357</td>\n",
       "      <td>0.987085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.002119</td>\n",
       "      <td>0.101259</td>\n",
       "      <td>0.896621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.943227</td>\n",
       "      <td>0.045022</td>\n",
       "      <td>0.011751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.982225</td>\n",
       "      <td>0.003353</td>\n",
       "      <td>0.014422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2\n",
       "0   0.257059  0.641684  0.101257\n",
       "1   0.894516  0.081192  0.024292\n",
       "2   0.011563  0.120927  0.867510\n",
       "3   0.495871  0.477288  0.026841\n",
       "4   0.001500  0.001606  0.996894\n",
       "..       ...       ...       ...\n",
       "71  0.724754  0.229334  0.045912\n",
       "72  0.011559  0.001357  0.987085\n",
       "73  0.002119  0.101259  0.896621\n",
       "74  0.943227  0.045022  0.011751\n",
       "75  0.982225  0.003353  0.014422\n",
       "\n",
       "[76 rows x 3 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba3.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba3.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat3.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/3p17ST.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 177 samples, validate on 76 samples\n",
      "Epoch 1/100\n",
      "177/177 [==============================] - 0s 410us/step - loss: 0.2053 - accuracy: 0.9322 - val_loss: 2.6494 - val_accuracy: 0.3816\n",
      "Epoch 2/100\n",
      "177/177 [==============================] - 0s 416us/step - loss: 0.2112 - accuracy: 0.9266 - val_loss: 2.6600 - val_accuracy: 0.3816\n",
      "Epoch 3/100\n",
      "177/177 [==============================] - 0s 408us/step - loss: 0.2328 - accuracy: 0.9322 - val_loss: 2.6248 - val_accuracy: 0.3947\n",
      "Epoch 4/100\n",
      "177/177 [==============================] - 0s 384us/step - loss: 0.2154 - accuracy: 0.9322 - val_loss: 2.7844 - val_accuracy: 0.3553\n",
      "Epoch 5/100\n",
      "177/177 [==============================] - 0s 383us/step - loss: 0.2131 - accuracy: 0.9153 - val_loss: 2.7444 - val_accuracy: 0.3816\n",
      "Epoch 6/100\n",
      "177/177 [==============================] - 0s 370us/step - loss: 0.2042 - accuracy: 0.9435 - val_loss: 2.6425 - val_accuracy: 0.3947\n",
      "Epoch 7/100\n",
      "177/177 [==============================] - 0s 388us/step - loss: 0.1881 - accuracy: 0.9322 - val_loss: 2.6521 - val_accuracy: 0.3684\n",
      "Epoch 8/100\n",
      "177/177 [==============================] - 0s 381us/step - loss: 0.2003 - accuracy: 0.9435 - val_loss: 2.7808 - val_accuracy: 0.3684\n",
      "Epoch 9/100\n",
      "177/177 [==============================] - 0s 398us/step - loss: 0.1948 - accuracy: 0.9548 - val_loss: 2.7571 - val_accuracy: 0.3421\n",
      "Epoch 10/100\n",
      "177/177 [==============================] - 0s 369us/step - loss: 0.2140 - accuracy: 0.9492 - val_loss: 2.7135 - val_accuracy: 0.3553\n",
      "Epoch 11/100\n",
      "177/177 [==============================] - 0s 392us/step - loss: 0.1888 - accuracy: 0.9548 - val_loss: 2.7307 - val_accuracy: 0.3816\n",
      "Epoch 12/100\n",
      "177/177 [==============================] - 0s 430us/step - loss: 0.1786 - accuracy: 0.9379 - val_loss: 2.7026 - val_accuracy: 0.3947\n",
      "Epoch 13/100\n",
      "177/177 [==============================] - 0s 452us/step - loss: 0.2250 - accuracy: 0.9266 - val_loss: 2.7846 - val_accuracy: 0.3816\n",
      "Epoch 14/100\n",
      "177/177 [==============================] - 0s 433us/step - loss: 0.1793 - accuracy: 0.9492 - val_loss: 2.7709 - val_accuracy: 0.3684\n",
      "Epoch 15/100\n",
      "177/177 [==============================] - 0s 383us/step - loss: 0.1909 - accuracy: 0.9548 - val_loss: 2.8374 - val_accuracy: 0.3684\n",
      "Epoch 16/100\n",
      "177/177 [==============================] - 0s 372us/step - loss: 0.2470 - accuracy: 0.9209 - val_loss: 2.8677 - val_accuracy: 0.3553\n",
      "Epoch 17/100\n",
      "177/177 [==============================] - 0s 399us/step - loss: 0.2094 - accuracy: 0.9492 - val_loss: 2.8012 - val_accuracy: 0.3684\n",
      "Epoch 18/100\n",
      "177/177 [==============================] - 0s 343us/step - loss: 0.2605 - accuracy: 0.9209 - val_loss: 2.9442 - val_accuracy: 0.3553\n",
      "Epoch 19/100\n",
      "177/177 [==============================] - 0s 379us/step - loss: 0.2303 - accuracy: 0.9492 - val_loss: 2.7917 - val_accuracy: 0.3947\n",
      "Epoch 20/100\n",
      "177/177 [==============================] - 0s 339us/step - loss: 0.1758 - accuracy: 0.9379 - val_loss: 2.9335 - val_accuracy: 0.3684\n",
      "Epoch 21/100\n",
      "177/177 [==============================] - 0s 439us/step - loss: 0.2890 - accuracy: 0.9379 - val_loss: 3.0159 - val_accuracy: 0.3553\n",
      "Epoch 22/100\n",
      "177/177 [==============================] - 0s 413us/step - loss: 0.2841 - accuracy: 0.9379 - val_loss: 2.7362 - val_accuracy: 0.3816\n",
      "Epoch 23/100\n",
      "177/177 [==============================] - 0s 455us/step - loss: 0.2222 - accuracy: 0.9266 - val_loss: 2.6675 - val_accuracy: 0.3553\n",
      "Epoch 24/100\n",
      "177/177 [==============================] - 0s 674us/step - loss: 0.2579 - accuracy: 0.9492 - val_loss: 2.7601 - val_accuracy: 0.3684\n",
      "Epoch 25/100\n",
      "177/177 [==============================] - 0s 793us/step - loss: 0.2035 - accuracy: 0.9605 - val_loss: 2.8697 - val_accuracy: 0.3816\n",
      "Epoch 26/100\n",
      "177/177 [==============================] - 0s 366us/step - loss: 0.2238 - accuracy: 0.9379 - val_loss: 2.7745 - val_accuracy: 0.3684\n",
      "Epoch 27/100\n",
      "177/177 [==============================] - 0s 685us/step - loss: 0.1656 - accuracy: 0.9379 - val_loss: 2.8353 - val_accuracy: 0.3553\n",
      "Epoch 28/100\n",
      "177/177 [==============================] - 0s 315us/step - loss: 0.1799 - accuracy: 0.9435 - val_loss: 2.8737 - val_accuracy: 0.3553\n",
      "Epoch 29/100\n",
      "177/177 [==============================] - 0s 1ms/step - loss: 0.1686 - accuracy: 0.9379 - val_loss: 2.8602 - val_accuracy: 0.4079\n",
      "Epoch 30/100\n",
      "177/177 [==============================] - 0s 710us/step - loss: 0.2396 - accuracy: 0.9322 - val_loss: 2.8712 - val_accuracy: 0.3816\n",
      "Epoch 31/100\n",
      "177/177 [==============================] - 0s 897us/step - loss: 0.2109 - accuracy: 0.9435 - val_loss: 2.8869 - val_accuracy: 0.3684\n",
      "Epoch 32/100\n",
      "177/177 [==============================] - 0s 1ms/step - loss: 0.2037 - accuracy: 0.9435 - val_loss: 2.9851 - val_accuracy: 0.3553\n",
      "Epoch 33/100\n",
      "177/177 [==============================] - 0s 616us/step - loss: 0.1896 - accuracy: 0.9379 - val_loss: 3.0850 - val_accuracy: 0.3684\n",
      "Epoch 34/100\n",
      "177/177 [==============================] - 0s 670us/step - loss: 0.2263 - accuracy: 0.9605 - val_loss: 2.9922 - val_accuracy: 0.3816\n",
      "Epoch 35/100\n",
      "177/177 [==============================] - 0s 1ms/step - loss: 0.1537 - accuracy: 0.9492 - val_loss: 2.8675 - val_accuracy: 0.3553\n",
      "Epoch 36/100\n",
      "177/177 [==============================] - 0s 891us/step - loss: 0.1933 - accuracy: 0.9605 - val_loss: 2.8763 - val_accuracy: 0.3421\n",
      "Epoch 37/100\n",
      "177/177 [==============================] - 0s 484us/step - loss: 0.1628 - accuracy: 0.9548 - val_loss: 3.0233 - val_accuracy: 0.3289\n",
      "Epoch 38/100\n",
      "177/177 [==============================] - 0s 432us/step - loss: 0.1648 - accuracy: 0.9548 - val_loss: 3.0352 - val_accuracy: 0.3553\n",
      "Epoch 39/100\n",
      "177/177 [==============================] - 0s 372us/step - loss: 0.1912 - accuracy: 0.9605 - val_loss: 3.0129 - val_accuracy: 0.3684\n",
      "Epoch 40/100\n",
      "177/177 [==============================] - 0s 369us/step - loss: 0.1849 - accuracy: 0.9379 - val_loss: 2.9756 - val_accuracy: 0.3816\n",
      "Epoch 41/100\n",
      "177/177 [==============================] - 0s 359us/step - loss: 0.1709 - accuracy: 0.9605 - val_loss: 2.9688 - val_accuracy: 0.3684\n",
      "Epoch 42/100\n",
      "177/177 [==============================] - 0s 392us/step - loss: 0.1744 - accuracy: 0.9548 - val_loss: 3.0534 - val_accuracy: 0.3553\n",
      "Epoch 43/100\n",
      "177/177 [==============================] - 0s 348us/step - loss: 0.1407 - accuracy: 0.9435 - val_loss: 3.0542 - val_accuracy: 0.3816\n",
      "Epoch 44/100\n",
      "177/177 [==============================] - 0s 335us/step - loss: 0.1822 - accuracy: 0.9605 - val_loss: 3.0164 - val_accuracy: 0.3947\n",
      "Epoch 45/100\n",
      "177/177 [==============================] - 0s 333us/step - loss: 0.1852 - accuracy: 0.9435 - val_loss: 3.0724 - val_accuracy: 0.3816\n",
      "Epoch 46/100\n",
      "177/177 [==============================] - 0s 336us/step - loss: 0.1908 - accuracy: 0.9322 - val_loss: 3.1233 - val_accuracy: 0.3684\n",
      "Epoch 47/100\n",
      "177/177 [==============================] - 0s 385us/step - loss: 0.1878 - accuracy: 0.9605 - val_loss: 3.1004 - val_accuracy: 0.3684\n",
      "Epoch 48/100\n",
      "177/177 [==============================] - 0s 698us/step - loss: 0.1337 - accuracy: 0.9605 - val_loss: 3.0379 - val_accuracy: 0.3421\n",
      "Epoch 49/100\n",
      "177/177 [==============================] - 0s 940us/step - loss: 0.2711 - accuracy: 0.9492 - val_loss: 2.9663 - val_accuracy: 0.3684\n",
      "Epoch 50/100\n",
      "177/177 [==============================] - 0s 848us/step - loss: 0.2225 - accuracy: 0.9548 - val_loss: 3.1818 - val_accuracy: 0.3421\n",
      "Epoch 51/100\n",
      "177/177 [==============================] - 0s 641us/step - loss: 0.1852 - accuracy: 0.9379 - val_loss: 3.2390 - val_accuracy: 0.3553\n",
      "Epoch 52/100\n",
      "177/177 [==============================] - 0s 566us/step - loss: 0.1644 - accuracy: 0.9605 - val_loss: 3.1980 - val_accuracy: 0.3684\n",
      "Epoch 53/100\n",
      "177/177 [==============================] - 0s 467us/step - loss: 0.1770 - accuracy: 0.9492 - val_loss: 3.1451 - val_accuracy: 0.3421\n",
      "Epoch 54/100\n",
      "177/177 [==============================] - 0s 469us/step - loss: 0.1388 - accuracy: 0.9435 - val_loss: 3.1159 - val_accuracy: 0.3684\n",
      "Epoch 55/100\n",
      "177/177 [==============================] - 0s 358us/step - loss: 0.2288 - accuracy: 0.9548 - val_loss: 3.1490 - val_accuracy: 0.3553\n",
      "Epoch 56/100\n",
      "177/177 [==============================] - 0s 396us/step - loss: 0.1838 - accuracy: 0.9322 - val_loss: 3.2790 - val_accuracy: 0.3553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "177/177 [==============================] - 0s 418us/step - loss: 0.2328 - accuracy: 0.9492 - val_loss: 3.3875 - val_accuracy: 0.3289\n",
      "Epoch 58/100\n",
      "177/177 [==============================] - 0s 352us/step - loss: 0.2115 - accuracy: 0.9266 - val_loss: 3.2435 - val_accuracy: 0.3684\n",
      "Epoch 59/100\n",
      "177/177 [==============================] - 0s 332us/step - loss: 0.2790 - accuracy: 0.9492 - val_loss: 3.2966 - val_accuracy: 0.3553\n",
      "Epoch 60/100\n",
      "177/177 [==============================] - 0s 362us/step - loss: 0.2474 - accuracy: 0.9548 - val_loss: 3.2845 - val_accuracy: 0.3553\n",
      "Epoch 61/100\n",
      "177/177 [==============================] - 0s 386us/step - loss: 0.1419 - accuracy: 0.9548 - val_loss: 3.2767 - val_accuracy: 0.3553\n",
      "Epoch 62/100\n",
      "177/177 [==============================] - 0s 396us/step - loss: 0.1996 - accuracy: 0.9548 - val_loss: 3.4239 - val_accuracy: 0.3553\n",
      "Epoch 63/100\n",
      "177/177 [==============================] - 0s 417us/step - loss: 0.1932 - accuracy: 0.9492 - val_loss: 3.2621 - val_accuracy: 0.3816\n",
      "Epoch 64/100\n",
      "177/177 [==============================] - 0s 410us/step - loss: 0.1695 - accuracy: 0.9548 - val_loss: 3.2021 - val_accuracy: 0.3553\n",
      "Epoch 65/100\n",
      "177/177 [==============================] - 0s 519us/step - loss: 0.1499 - accuracy: 0.9492 - val_loss: 3.2361 - val_accuracy: 0.3289\n",
      "Epoch 66/100\n",
      "177/177 [==============================] - 0s 369us/step - loss: 0.1604 - accuracy: 0.9492 - val_loss: 3.2096 - val_accuracy: 0.3684\n",
      "Epoch 67/100\n",
      "177/177 [==============================] - 0s 347us/step - loss: 0.1318 - accuracy: 0.9435 - val_loss: 3.3361 - val_accuracy: 0.3816\n",
      "Epoch 68/100\n",
      "177/177 [==============================] - 0s 336us/step - loss: 0.1587 - accuracy: 0.9718 - val_loss: 3.3089 - val_accuracy: 0.3553\n",
      "Epoch 69/100\n",
      "177/177 [==============================] - 0s 387us/step - loss: 0.1265 - accuracy: 0.9605 - val_loss: 3.3056 - val_accuracy: 0.3289\n",
      "Epoch 70/100\n",
      "177/177 [==============================] - 0s 392us/step - loss: 0.2004 - accuracy: 0.9548 - val_loss: 3.2901 - val_accuracy: 0.3421\n",
      "Epoch 71/100\n",
      "177/177 [==============================] - 0s 344us/step - loss: 0.1831 - accuracy: 0.9435 - val_loss: 3.4251 - val_accuracy: 0.3421\n",
      "Epoch 72/100\n",
      "177/177 [==============================] - 0s 405us/step - loss: 0.1677 - accuracy: 0.9605 - val_loss: 3.4056 - val_accuracy: 0.3553\n",
      "Epoch 73/100\n",
      "177/177 [==============================] - 0s 350us/step - loss: 0.1603 - accuracy: 0.9492 - val_loss: 3.5330 - val_accuracy: 0.3553\n",
      "Epoch 74/100\n",
      "177/177 [==============================] - 0s 308us/step - loss: 0.1949 - accuracy: 0.9492 - val_loss: 3.5468 - val_accuracy: 0.3684\n",
      "Epoch 75/100\n",
      "177/177 [==============================] - 0s 335us/step - loss: 0.1619 - accuracy: 0.9605 - val_loss: 3.3579 - val_accuracy: 0.3816\n",
      "Epoch 76/100\n",
      "177/177 [==============================] - 0s 321us/step - loss: 0.1388 - accuracy: 0.9605 - val_loss: 3.3650 - val_accuracy: 0.3553\n",
      "Epoch 77/100\n",
      "177/177 [==============================] - 0s 334us/step - loss: 0.1594 - accuracy: 0.9548 - val_loss: 3.4157 - val_accuracy: 0.3553\n",
      "Epoch 78/100\n",
      "177/177 [==============================] - 0s 372us/step - loss: 0.1567 - accuracy: 0.9492 - val_loss: 3.5316 - val_accuracy: 0.3684\n",
      "Epoch 79/100\n",
      "177/177 [==============================] - ETA: 0s - loss: 0.1356 - accuracy: 0.96 - 0s 721us/step - loss: 0.1342 - accuracy: 0.9661 - val_loss: 3.3776 - val_accuracy: 0.3553\n",
      "Epoch 80/100\n",
      "177/177 [==============================] - 0s 2ms/step - loss: 0.1211 - accuracy: 0.9548 - val_loss: 3.3216 - val_accuracy: 0.3684\n",
      "Epoch 81/100\n",
      "177/177 [==============================] - 0s 408us/step - loss: 0.1190 - accuracy: 0.9661 - val_loss: 3.4714 - val_accuracy: 0.3421\n",
      "Epoch 82/100\n",
      "177/177 [==============================] - 0s 631us/step - loss: 0.1363 - accuracy: 0.9661 - val_loss: 3.5181 - val_accuracy: 0.3553\n",
      "Epoch 83/100\n",
      "177/177 [==============================] - 0s 442us/step - loss: 0.1343 - accuracy: 0.9661 - val_loss: 3.3916 - val_accuracy: 0.3816\n",
      "Epoch 84/100\n",
      "177/177 [==============================] - 0s 351us/step - loss: 0.1481 - accuracy: 0.9605 - val_loss: 3.4300 - val_accuracy: 0.3553\n",
      "Epoch 85/100\n",
      "177/177 [==============================] - 0s 439us/step - loss: 0.1090 - accuracy: 0.9718 - val_loss: 3.5004 - val_accuracy: 0.3421\n",
      "Epoch 86/100\n",
      "177/177 [==============================] - 0s 389us/step - loss: 0.1400 - accuracy: 0.9605 - val_loss: 3.4630 - val_accuracy: 0.3816\n",
      "Epoch 87/100\n",
      "177/177 [==============================] - 0s 549us/step - loss: 0.1099 - accuracy: 0.9605 - val_loss: 3.5082 - val_accuracy: 0.3553\n",
      "Epoch 88/100\n",
      "177/177 [==============================] - 0s 721us/step - loss: 0.1457 - accuracy: 0.9718 - val_loss: 3.5380 - val_accuracy: 0.3421\n",
      "Epoch 89/100\n",
      "177/177 [==============================] - 0s 333us/step - loss: 0.1319 - accuracy: 0.9605 - val_loss: 3.4757 - val_accuracy: 0.3553\n",
      "Epoch 90/100\n",
      "177/177 [==============================] - 0s 347us/step - loss: 0.1214 - accuracy: 0.9548 - val_loss: 3.4630 - val_accuracy: 0.3684\n",
      "Epoch 91/100\n",
      "177/177 [==============================] - 0s 378us/step - loss: 0.1732 - accuracy: 0.9661 - val_loss: 3.4827 - val_accuracy: 0.3553\n",
      "Epoch 92/100\n",
      "177/177 [==============================] - 0s 471us/step - loss: 0.1352 - accuracy: 0.9492 - val_loss: 3.5098 - val_accuracy: 0.3684\n",
      "Epoch 93/100\n",
      "177/177 [==============================] - 0s 440us/step - loss: 0.1444 - accuracy: 0.9548 - val_loss: 3.5495 - val_accuracy: 0.3684\n",
      "Epoch 94/100\n",
      "177/177 [==============================] - 0s 550us/step - loss: 0.1537 - accuracy: 0.9548 - val_loss: 3.6555 - val_accuracy: 0.3553\n",
      "Epoch 95/100\n",
      "177/177 [==============================] - 0s 357us/step - loss: 0.1324 - accuracy: 0.9605 - val_loss: 3.5864 - val_accuracy: 0.3553\n",
      "Epoch 96/100\n",
      "177/177 [==============================] - 0s 329us/step - loss: 0.1053 - accuracy: 0.9718 - val_loss: 3.4752 - val_accuracy: 0.3684\n",
      "Epoch 97/100\n",
      "177/177 [==============================] - 0s 445us/step - loss: 0.1346 - accuracy: 0.9718 - val_loss: 3.5467 - val_accuracy: 0.3684\n",
      "Epoch 98/100\n",
      "177/177 [==============================] - 0s 512us/step - loss: 0.1156 - accuracy: 0.9661 - val_loss: 3.6133 - val_accuracy: 0.3684\n",
      "Epoch 99/100\n",
      "177/177 [==============================] - 0s 351us/step - loss: 0.1912 - accuracy: 0.9718 - val_loss: 3.4792 - val_accuracy: 0.3553\n",
      "Epoch 100/100\n",
      "177/177 [==============================] - 0s 439us/step - loss: 0.1652 - accuracy: 0.9661 - val_loss: 3.4742 - val_accuracy: 0.3553\n"
     ]
    }
   ],
   "source": [
    "hist3 = model3.fit(X_train, y_train,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 95.01%\n"
     ]
    }
   ],
   "source": [
    "print('train accuracy: %.2f%%' % (np.mean(hist3.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba3 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_2.xlsx\",\n",
    "                        sheet_name=2,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NY360</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.165526e-02</td>\n",
       "      <td>4.848140e-01</td>\n",
       "      <td>0.493531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>EUH25</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>9.986388e-01</td>\n",
       "      <td>1.245148e-03</td>\n",
       "      <td>0.000116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>EUH15</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9.227520e-04</td>\n",
       "      <td>1.424882e-02</td>\n",
       "      <td>0.984828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NRS241</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.374333e-01</td>\n",
       "      <td>1.614128e-01</td>\n",
       "      <td>0.001154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>SR2852</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.976981e-09</td>\n",
       "      <td>5.145955e-10</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>BCH-SA-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.305407e-01</td>\n",
       "      <td>6.356251e-02</td>\n",
       "      <td>0.005897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>504</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.476389e-02</td>\n",
       "      <td>8.577548e-01</td>\n",
       "      <td>0.097481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>GA27</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.779456e-01</td>\n",
       "      <td>5.384378e-01</td>\n",
       "      <td>0.183617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>NRS209</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.210180e-01</td>\n",
       "      <td>3.559393e-01</td>\n",
       "      <td>0.223043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>BCH-SA-13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.484084e-03</td>\n",
       "      <td>9.944786e-01</td>\n",
       "      <td>0.000037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>608 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     phage     strain  phenotype  prediction             0  \\\n",
       "0       p0017kpresabs_qual      NY360          2           2  2.165526e-02   \n",
       "1       p0017kpresabs_qual      EUH25          2           0  9.986388e-01   \n",
       "2       p0017kpresabs_qual      EUH15          2           2  9.227520e-04   \n",
       "3       p0017kpresabs_qual     NRS241          0           0  8.374333e-01   \n",
       "4       p0017kpresabs_qual     SR2852          2           2  3.976981e-09   \n",
       "..                     ...        ...        ...         ...           ...   \n",
       "603  p0040presabsSTCC_qual  BCH-SA-01          0           0  9.305407e-01   \n",
       "604  p0040presabsSTCC_qual        504          0           1  4.476389e-02   \n",
       "605  p0040presabsSTCC_qual       GA27          2           1  2.779456e-01   \n",
       "606  p0040presabsSTCC_qual     NRS209          1           0  4.210180e-01   \n",
       "607  p0040presabsSTCC_qual  BCH-SA-13          1           1  5.484084e-03   \n",
       "\n",
       "                1         2  \n",
       "0    4.848140e-01  0.493531  \n",
       "1    1.245148e-03  0.000116  \n",
       "2    1.424882e-02  0.984828  \n",
       "3    1.614128e-01  0.001154  \n",
       "4    5.145955e-10  1.000000  \n",
       "..            ...       ...  \n",
       "603  6.356251e-02  0.005897  \n",
       "604  8.577548e-01  0.097481  \n",
       "605  5.384378e-01  0.183617  \n",
       "606  3.559393e-01  0.223043  \n",
       "607  9.944786e-01  0.000037  \n",
       "\n",
       "[608 rows x 7 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.57059160e-01, 6.41683640e-01, 1.01257280e-01],\n",
       "       [8.94515500e-01, 8.11922100e-02, 2.42923310e-02],\n",
       "       [1.15627300e-02, 1.20926790e-01, 8.67510500e-01],\n",
       "       [4.95870600e-01, 4.77288220e-01, 2.68411770e-02],\n",
       "       [1.49988130e-03, 1.60604310e-03, 9.96894000e-01],\n",
       "       [2.25119780e-02, 1.68889820e-05, 9.77471100e-01],\n",
       "       [1.80777150e-01, 3.95467820e-01, 4.23755000e-01],\n",
       "       [5.77097000e-04, 6.26295500e-04, 9.98796600e-01],\n",
       "       [6.49840530e-01, 3.19829500e-02, 3.18176500e-01],\n",
       "       [9.98679460e-01, 4.78549370e-04, 8.41911650e-04],\n",
       "       [1.58170970e-01, 4.03310000e-01, 4.38519060e-01],\n",
       "       [5.33674600e-01, 3.87690720e-01, 7.86347500e-02],\n",
       "       [9.18829560e-01, 7.69565550e-02, 4.21389330e-03],\n",
       "       [7.33572840e-01, 7.72389700e-02, 1.89188150e-01],\n",
       "       [7.15747500e-01, 1.97265350e-02, 2.64526000e-01],\n",
       "       [9.06369800e-02, 5.53815400e-01, 3.55547580e-01],\n",
       "       [4.41347150e-01, 5.04651960e-01, 5.40008360e-02],\n",
       "       [3.40273860e-02, 2.42209000e-02, 9.41751700e-01],\n",
       "       [8.72841800e-03, 9.46853000e-01, 4.44186030e-02],\n",
       "       [9.87901200e-01, 9.05682700e-04, 1.11932220e-02],\n",
       "       [9.30615800e-01, 6.77685960e-02, 1.61556210e-03],\n",
       "       [4.87390500e-03, 3.32144550e-04, 9.94793950e-01],\n",
       "       [8.86135600e-01, 1.17963430e-02, 1.02068060e-01],\n",
       "       [1.88428780e-02, 2.61263250e-05, 9.81130960e-01],\n",
       "       [3.97555650e-01, 5.16302600e-01, 8.61416700e-02],\n",
       "       [2.73794720e-12, 6.76848650e-05, 9.99932300e-01],\n",
       "       [1.78820600e-01, 6.53080200e-01, 1.68099180e-01],\n",
       "       [5.55002500e-01, 4.44364820e-01, 6.32632200e-04],\n",
       "       [9.85638560e-01, 8.45594050e-03, 5.90557470e-03],\n",
       "       [6.12051960e-01, 3.83543520e-01, 4.40452400e-03],\n",
       "       [7.38423500e-01, 6.21407070e-02, 1.99435760e-01],\n",
       "       [7.33572840e-01, 7.72389700e-02, 1.89188150e-01],\n",
       "       [5.29468400e-02, 7.37429800e-01, 2.09623400e-01],\n",
       "       [3.72747900e-02, 4.27354200e-03, 9.58451700e-01],\n",
       "       [3.33895700e-01, 4.26376460e-01, 2.39727810e-01],\n",
       "       [6.31579500e-02, 7.35761760e-01, 2.01080320e-01],\n",
       "       [8.69664000e-03, 2.83647200e-01, 7.07656200e-01],\n",
       "       [2.45291250e-03, 7.60347680e-03, 9.89943600e-01],\n",
       "       [6.02820160e-01, 4.61793770e-02, 3.51000500e-01],\n",
       "       [5.14971900e-02, 9.48371230e-01, 1.31586940e-04],\n",
       "       [2.10053940e-02, 9.78218000e-01, 7.76487600e-04],\n",
       "       [3.94242730e-01, 5.36923900e-01, 6.88333960e-02],\n",
       "       [8.05182300e-01, 2.26062050e-02, 1.72211420e-01],\n",
       "       [7.23576640e-04, 1.95922600e-03, 9.97317140e-01],\n",
       "       [4.11129860e-01, 2.44306610e-01, 3.44563570e-01],\n",
       "       [9.61034700e-01, 1.23798640e-02, 2.65854350e-02],\n",
       "       [3.96006900e-01, 7.97779200e-05, 6.03913300e-01],\n",
       "       [2.90553630e-02, 9.70632850e-01, 3.11822900e-04],\n",
       "       [7.33572840e-01, 7.72389700e-02, 1.89188150e-01],\n",
       "       [3.28323960e-01, 4.72644720e-01, 1.99031380e-01],\n",
       "       [9.61034700e-01, 1.23798640e-02, 2.65854350e-02],\n",
       "       [2.88302360e-02, 9.25545930e-01, 4.56238000e-02],\n",
       "       [8.80931900e-01, 1.11938175e-02, 1.07874350e-01],\n",
       "       [4.10585970e-01, 3.65017770e-01, 2.24396330e-01],\n",
       "       [9.65038300e-01, 1.68799520e-05, 3.49447540e-02],\n",
       "       [2.31539800e-02, 9.76041730e-01, 8.04370500e-04],\n",
       "       [1.09315395e-01, 6.15246400e-01, 2.75438250e-01],\n",
       "       [3.15970840e-01, 6.78904650e-01, 5.12441850e-03],\n",
       "       [7.46258850e-01, 2.03332040e-01, 5.04090450e-02],\n",
       "       [9.88972600e-01, 1.19000900e-03, 9.83732700e-03],\n",
       "       [1.85644680e-04, 9.14604800e-01, 8.52094900e-02],\n",
       "       [5.74996360e-02, 9.02244450e-02, 8.52275970e-01],\n",
       "       [2.22019030e-01, 1.88882440e-02, 7.59092750e-01],\n",
       "       [5.16636200e-01, 2.07289010e-01, 2.76074830e-01],\n",
       "       [3.51870020e-02, 9.14250600e-01, 5.05622920e-02],\n",
       "       [2.28540900e-03, 6.69413550e-09, 9.97714640e-01],\n",
       "       [1.84943790e-02, 2.04377340e-01, 7.77128200e-01],\n",
       "       [9.94011000e-01, 8.61171050e-04, 5.12771800e-03],\n",
       "       [6.95325500e-04, 1.94841910e-06, 9.99302740e-01],\n",
       "       [3.19787000e-01, 5.01944100e-01, 1.78268820e-01],\n",
       "       [1.80086760e-01, 6.25546000e-01, 1.94367260e-01],\n",
       "       [7.24754040e-01, 2.29333730e-01, 4.59122800e-02],\n",
       "       [1.15585720e-02, 1.35671390e-03, 9.87084700e-01],\n",
       "       [2.11943200e-03, 1.01259340e-01, 8.96621200e-01],\n",
       "       [9.43227100e-01, 4.50221000e-02, 1.17508190e-02],\n",
       "       [9.82225100e-01, 3.35280670e-03, 1.44221130e-02]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob3 = df_proba3[df_proba3['phage']=='p0017kpresabsSTCC_qual'].iloc[:,-3:]\n",
    "y_prob3 = y_prob3.to_numpy()\n",
    "y_prob3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5330372889896698"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo3 = rocauc_ovo(y_test, y_prob3, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5330372889896698"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr3 = rocauc_ovr(y_test, y_prob3, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=456,\n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat4 = pd.DataFrame(X_test.iloc[:,0])\n",
    "dat4['test'] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>SR1129</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>CA105</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>NRS175</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>EUH25</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>NRS070</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>SR1065</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>BCH-SA-09</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>Grady1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>NRS254</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>CFBRSa66B</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  test\n",
       "236     SR1129     2\n",
       "31       CA105     2\n",
       "155     NRS175     1\n",
       "92       EUH25     2\n",
       "122     NRS070     2\n",
       "..         ...   ...\n",
       "235     SR1065     0\n",
       "24   BCH-SA-09     0\n",
       "104     Grady1     0\n",
       "213     NRS254     2\n",
       "87   CFBRSa66B     0\n",
       "\n",
       "[76 rows x 2 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(['id'], axis=1)\n",
    "X_test = X_test.drop(['id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 177 samples, validate on 76 samples\n",
      "Epoch 1/100\n",
      "177/177 [==============================] - 0s 1ms/step - loss: 1.5504 - accuracy: 0.3559 - val_loss: 1.3531 - val_accuracy: 0.3026\n",
      "Epoch 2/100\n",
      "177/177 [==============================] - 0s 441us/step - loss: 1.1503 - accuracy: 0.4520 - val_loss: 1.2867 - val_accuracy: 0.3421\n",
      "Epoch 3/100\n",
      "177/177 [==============================] - 0s 468us/step - loss: 0.9935 - accuracy: 0.5480 - val_loss: 1.2375 - val_accuracy: 0.3158\n",
      "Epoch 4/100\n",
      "177/177 [==============================] - 0s 471us/step - loss: 0.9298 - accuracy: 0.5819 - val_loss: 1.3074 - val_accuracy: 0.3026\n",
      "Epoch 5/100\n",
      "177/177 [==============================] - 0s 496us/step - loss: 0.8241 - accuracy: 0.6271 - val_loss: 1.3592 - val_accuracy: 0.3158\n",
      "Epoch 6/100\n",
      "177/177 [==============================] - 0s 461us/step - loss: 0.7915 - accuracy: 0.6893 - val_loss: 1.4034 - val_accuracy: 0.3553\n",
      "Epoch 7/100\n",
      "177/177 [==============================] - 0s 367us/step - loss: 0.7636 - accuracy: 0.6949 - val_loss: 1.4735 - val_accuracy: 0.3553\n",
      "Epoch 8/100\n",
      "177/177 [==============================] - 0s 356us/step - loss: 0.7182 - accuracy: 0.7006 - val_loss: 1.4562 - val_accuracy: 0.3553\n",
      "Epoch 9/100\n",
      "177/177 [==============================] - 0s 349us/step - loss: 0.7016 - accuracy: 0.7288 - val_loss: 1.4879 - val_accuracy: 0.3684\n",
      "Epoch 10/100\n",
      "177/177 [==============================] - 0s 351us/step - loss: 0.6534 - accuracy: 0.7175 - val_loss: 1.5830 - val_accuracy: 0.3684\n",
      "Epoch 11/100\n",
      "177/177 [==============================] - 0s 372us/step - loss: 0.6637 - accuracy: 0.7288 - val_loss: 1.6191 - val_accuracy: 0.3816\n",
      "Epoch 12/100\n",
      "177/177 [==============================] - 0s 365us/step - loss: 0.6211 - accuracy: 0.7288 - val_loss: 1.6437 - val_accuracy: 0.3816\n",
      "Epoch 13/100\n",
      "177/177 [==============================] - 0s 343us/step - loss: 0.5966 - accuracy: 0.7401 - val_loss: 1.6793 - val_accuracy: 0.3816\n",
      "Epoch 14/100\n",
      "177/177 [==============================] - 0s 355us/step - loss: 0.5884 - accuracy: 0.7514 - val_loss: 1.7378 - val_accuracy: 0.3816\n",
      "Epoch 15/100\n",
      "177/177 [==============================] - 0s 390us/step - loss: 0.5711 - accuracy: 0.7684 - val_loss: 1.7581 - val_accuracy: 0.3816\n",
      "Epoch 16/100\n",
      "177/177 [==============================] - 0s 396us/step - loss: 0.5563 - accuracy: 0.7740 - val_loss: 1.7923 - val_accuracy: 0.3816\n",
      "Epoch 17/100\n",
      "177/177 [==============================] - 0s 371us/step - loss: 0.5244 - accuracy: 0.8023 - val_loss: 1.8517 - val_accuracy: 0.3816\n",
      "Epoch 18/100\n",
      "177/177 [==============================] - 0s 396us/step - loss: 0.5242 - accuracy: 0.8023 - val_loss: 1.8659 - val_accuracy: 0.3947\n",
      "Epoch 19/100\n",
      "177/177 [==============================] - 0s 380us/step - loss: 0.5105 - accuracy: 0.8249 - val_loss: 1.8383 - val_accuracy: 0.3947\n",
      "Epoch 20/100\n",
      "177/177 [==============================] - 0s 382us/step - loss: 0.5171 - accuracy: 0.8136 - val_loss: 1.8887 - val_accuracy: 0.3816\n",
      "Epoch 21/100\n",
      "177/177 [==============================] - 0s 368us/step - loss: 0.5059 - accuracy: 0.8192 - val_loss: 2.0077 - val_accuracy: 0.3947\n",
      "Epoch 22/100\n",
      "177/177 [==============================] - 0s 382us/step - loss: 0.5089 - accuracy: 0.8023 - val_loss: 2.0447 - val_accuracy: 0.3947\n",
      "Epoch 23/100\n",
      "177/177 [==============================] - 0s 475us/step - loss: 0.4986 - accuracy: 0.8192 - val_loss: 1.9164 - val_accuracy: 0.4211\n",
      "Epoch 24/100\n",
      "177/177 [==============================] - 0s 438us/step - loss: 0.4720 - accuracy: 0.8136 - val_loss: 1.9667 - val_accuracy: 0.3947\n",
      "Epoch 25/100\n",
      "177/177 [==============================] - 0s 405us/step - loss: 0.4859 - accuracy: 0.8362 - val_loss: 2.0965 - val_accuracy: 0.4211\n",
      "Epoch 26/100\n",
      "177/177 [==============================] - 0s 388us/step - loss: 0.4472 - accuracy: 0.8305 - val_loss: 2.0978 - val_accuracy: 0.4079\n",
      "Epoch 27/100\n",
      "177/177 [==============================] - 0s 357us/step - loss: 0.4654 - accuracy: 0.8192 - val_loss: 2.0392 - val_accuracy: 0.4211\n",
      "Epoch 28/100\n",
      "177/177 [==============================] - 0s 360us/step - loss: 0.4375 - accuracy: 0.8362 - val_loss: 2.0372 - val_accuracy: 0.4342\n",
      "Epoch 29/100\n",
      "177/177 [==============================] - 0s 378us/step - loss: 0.4302 - accuracy: 0.8531 - val_loss: 2.1488 - val_accuracy: 0.4211\n",
      "Epoch 30/100\n",
      "177/177 [==============================] - 0s 372us/step - loss: 0.3990 - accuracy: 0.8475 - val_loss: 2.2136 - val_accuracy: 0.4211\n",
      "Epoch 31/100\n",
      "177/177 [==============================] - 0s 322us/step - loss: 0.3985 - accuracy: 0.8418 - val_loss: 2.1603 - val_accuracy: 0.4211\n",
      "Epoch 32/100\n",
      "177/177 [==============================] - 0s 353us/step - loss: 0.3932 - accuracy: 0.8531 - val_loss: 2.1252 - val_accuracy: 0.4211\n",
      "Epoch 33/100\n",
      "177/177 [==============================] - 0s 368us/step - loss: 0.3844 - accuracy: 0.8757 - val_loss: 2.1290 - val_accuracy: 0.4211\n",
      "Epoch 34/100\n",
      "177/177 [==============================] - 0s 374us/step - loss: 0.3730 - accuracy: 0.8588 - val_loss: 2.2980 - val_accuracy: 0.4211\n",
      "Epoch 35/100\n",
      "177/177 [==============================] - 0s 400us/step - loss: 0.3783 - accuracy: 0.8644 - val_loss: 2.3782 - val_accuracy: 0.4211\n",
      "Epoch 36/100\n",
      "177/177 [==============================] - 0s 401us/step - loss: 0.3623 - accuracy: 0.8701 - val_loss: 2.3530 - val_accuracy: 0.4079\n",
      "Epoch 37/100\n",
      "177/177 [==============================] - 0s 403us/step - loss: 0.3829 - accuracy: 0.8588 - val_loss: 2.2695 - val_accuracy: 0.4079\n",
      "Epoch 38/100\n",
      "177/177 [==============================] - 0s 347us/step - loss: 0.3997 - accuracy: 0.8814 - val_loss: 2.2346 - val_accuracy: 0.4342\n",
      "Epoch 39/100\n",
      "177/177 [==============================] - 0s 392us/step - loss: 0.3789 - accuracy: 0.8701 - val_loss: 2.3306 - val_accuracy: 0.4079\n",
      "Epoch 40/100\n",
      "177/177 [==============================] - 0s 411us/step - loss: 0.3693 - accuracy: 0.8644 - val_loss: 2.4311 - val_accuracy: 0.4342\n",
      "Epoch 41/100\n",
      "177/177 [==============================] - 0s 395us/step - loss: 0.3602 - accuracy: 0.8701 - val_loss: 2.3964 - val_accuracy: 0.4342\n",
      "Epoch 42/100\n",
      "177/177 [==============================] - 0s 390us/step - loss: 0.3570 - accuracy: 0.8814 - val_loss: 2.4252 - val_accuracy: 0.4211\n",
      "Epoch 43/100\n",
      "177/177 [==============================] - 0s 350us/step - loss: 0.3309 - accuracy: 0.8757 - val_loss: 2.5005 - val_accuracy: 0.4342\n",
      "Epoch 44/100\n",
      "177/177 [==============================] - 0s 404us/step - loss: 0.3251 - accuracy: 0.8814 - val_loss: 2.4325 - val_accuracy: 0.4342\n",
      "Epoch 45/100\n",
      "177/177 [==============================] - 0s 392us/step - loss: 0.3425 - accuracy: 0.8983 - val_loss: 2.3441 - val_accuracy: 0.4079\n",
      "Epoch 46/100\n",
      "177/177 [==============================] - 0s 390us/step - loss: 0.3187 - accuracy: 0.8870 - val_loss: 2.4616 - val_accuracy: 0.4079\n",
      "Epoch 47/100\n",
      "177/177 [==============================] - 0s 391us/step - loss: 0.3349 - accuracy: 0.8814 - val_loss: 2.5294 - val_accuracy: 0.4211\n",
      "Epoch 48/100\n",
      "177/177 [==============================] - 0s 382us/step - loss: 0.3248 - accuracy: 0.8870 - val_loss: 2.5391 - val_accuracy: 0.4342\n",
      "Epoch 49/100\n",
      "177/177 [==============================] - 0s 403us/step - loss: 0.2958 - accuracy: 0.9040 - val_loss: 2.4718 - val_accuracy: 0.4342\n",
      "Epoch 50/100\n",
      "177/177 [==============================] - 0s 382us/step - loss: 0.3275 - accuracy: 0.8927 - val_loss: 2.5077 - val_accuracy: 0.4211\n",
      "Epoch 51/100\n",
      "177/177 [==============================] - 0s 384us/step - loss: 0.3236 - accuracy: 0.8757 - val_loss: 2.5823 - val_accuracy: 0.4342\n",
      "Epoch 52/100\n",
      "177/177 [==============================] - 0s 354us/step - loss: 0.2862 - accuracy: 0.8814 - val_loss: 2.5361 - val_accuracy: 0.4211\n",
      "Epoch 53/100\n",
      "177/177 [==============================] - 0s 399us/step - loss: 0.3291 - accuracy: 0.8870 - val_loss: 2.5415 - val_accuracy: 0.4211\n",
      "Epoch 54/100\n",
      "177/177 [==============================] - 0s 410us/step - loss: 0.2970 - accuracy: 0.8870 - val_loss: 2.6084 - val_accuracy: 0.4079\n",
      "Epoch 55/100\n",
      "177/177 [==============================] - 0s 333us/step - loss: 0.2921 - accuracy: 0.8870 - val_loss: 2.6263 - val_accuracy: 0.4342\n",
      "Epoch 56/100\n",
      "177/177 [==============================] - 0s 381us/step - loss: 0.2916 - accuracy: 0.8927 - val_loss: 2.6465 - val_accuracy: 0.4342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "177/177 [==============================] - 0s 396us/step - loss: 0.2728 - accuracy: 0.8983 - val_loss: 2.6668 - val_accuracy: 0.4474\n",
      "Epoch 58/100\n",
      "177/177 [==============================] - 0s 363us/step - loss: 0.2667 - accuracy: 0.8870 - val_loss: 2.6968 - val_accuracy: 0.4342\n",
      "Epoch 59/100\n",
      "177/177 [==============================] - 0s 329us/step - loss: 0.2712 - accuracy: 0.8927 - val_loss: 2.7045 - val_accuracy: 0.4474\n",
      "Epoch 60/100\n",
      "177/177 [==============================] - 0s 344us/step - loss: 0.2566 - accuracy: 0.8870 - val_loss: 2.6801 - val_accuracy: 0.4342\n",
      "Epoch 61/100\n",
      "177/177 [==============================] - 0s 349us/step - loss: 0.2812 - accuracy: 0.9096 - val_loss: 2.7139 - val_accuracy: 0.4474\n",
      "Epoch 62/100\n",
      "177/177 [==============================] - 0s 400us/step - loss: 0.2451 - accuracy: 0.9096 - val_loss: 2.7718 - val_accuracy: 0.4342\n",
      "Epoch 63/100\n",
      "177/177 [==============================] - 0s 351us/step - loss: 0.2646 - accuracy: 0.9096 - val_loss: 2.7849 - val_accuracy: 0.4474\n",
      "Epoch 64/100\n",
      "177/177 [==============================] - 0s 346us/step - loss: 0.2601 - accuracy: 0.9040 - val_loss: 2.7540 - val_accuracy: 0.4211\n",
      "Epoch 65/100\n",
      "177/177 [==============================] - 0s 347us/step - loss: 0.2596 - accuracy: 0.8983 - val_loss: 2.7973 - val_accuracy: 0.4474\n",
      "Epoch 66/100\n",
      "177/177 [==============================] - 0s 346us/step - loss: 0.2377 - accuracy: 0.9040 - val_loss: 2.8429 - val_accuracy: 0.4474\n",
      "Epoch 67/100\n",
      "177/177 [==============================] - 0s 333us/step - loss: 0.2461 - accuracy: 0.9040 - val_loss: 2.8449 - val_accuracy: 0.4474\n",
      "Epoch 68/100\n",
      "177/177 [==============================] - 0s 368us/step - loss: 0.2428 - accuracy: 0.9153 - val_loss: 2.8477 - val_accuracy: 0.4474\n",
      "Epoch 69/100\n",
      "177/177 [==============================] - 0s 377us/step - loss: 0.2394 - accuracy: 0.9153 - val_loss: 2.8675 - val_accuracy: 0.4474\n",
      "Epoch 70/100\n",
      "177/177 [==============================] - 0s 371us/step - loss: 0.2296 - accuracy: 0.9096 - val_loss: 2.8604 - val_accuracy: 0.4474\n",
      "Epoch 71/100\n",
      "177/177 [==============================] - 0s 452us/step - loss: 0.2477 - accuracy: 0.9209 - val_loss: 2.8794 - val_accuracy: 0.4474\n",
      "Epoch 72/100\n",
      "177/177 [==============================] - 0s 534us/step - loss: 0.2448 - accuracy: 0.9153 - val_loss: 2.8914 - val_accuracy: 0.4474\n",
      "Epoch 73/100\n",
      "177/177 [==============================] - 0s 556us/step - loss: 0.2269 - accuracy: 0.9209 - val_loss: 2.8936 - val_accuracy: 0.4474\n",
      "Epoch 74/100\n",
      "177/177 [==============================] - 0s 463us/step - loss: 0.2700 - accuracy: 0.9322 - val_loss: 2.9189 - val_accuracy: 0.4342\n",
      "Epoch 75/100\n",
      "177/177 [==============================] - 0s 367us/step - loss: 0.2521 - accuracy: 0.9153 - val_loss: 3.0338 - val_accuracy: 0.4474\n",
      "Epoch 76/100\n",
      "177/177 [==============================] - 0s 323us/step - loss: 0.2271 - accuracy: 0.9153 - val_loss: 3.0596 - val_accuracy: 0.4474\n",
      "Epoch 77/100\n",
      "177/177 [==============================] - 0s 409us/step - loss: 0.2434 - accuracy: 0.9153 - val_loss: 3.0146 - val_accuracy: 0.4211\n",
      "Epoch 78/100\n",
      "177/177 [==============================] - 0s 419us/step - loss: 0.2469 - accuracy: 0.9322 - val_loss: 3.0456 - val_accuracy: 0.4474\n",
      "Epoch 79/100\n",
      "177/177 [==============================] - 0s 378us/step - loss: 0.2417 - accuracy: 0.9209 - val_loss: 3.0990 - val_accuracy: 0.4474\n",
      "Epoch 80/100\n",
      "177/177 [==============================] - 0s 386us/step - loss: 0.2127 - accuracy: 0.9153 - val_loss: 3.1118 - val_accuracy: 0.4474\n",
      "Epoch 81/100\n",
      "177/177 [==============================] - 0s 340us/step - loss: 0.2500 - accuracy: 0.9153 - val_loss: 3.1029 - val_accuracy: 0.4342\n",
      "Epoch 82/100\n",
      "177/177 [==============================] - 0s 344us/step - loss: 0.2065 - accuracy: 0.9266 - val_loss: 3.1208 - val_accuracy: 0.4474\n",
      "Epoch 83/100\n",
      "177/177 [==============================] - 0s 340us/step - loss: 0.2532 - accuracy: 0.9266 - val_loss: 3.1506 - val_accuracy: 0.4474\n",
      "Epoch 84/100\n",
      "177/177 [==============================] - 0s 355us/step - loss: 0.2091 - accuracy: 0.9322 - val_loss: 3.1733 - val_accuracy: 0.4474\n",
      "Epoch 85/100\n",
      "177/177 [==============================] - 0s 318us/step - loss: 0.2409 - accuracy: 0.9209 - val_loss: 3.1790 - val_accuracy: 0.4474\n",
      "Epoch 86/100\n",
      "177/177 [==============================] - 0s 382us/step - loss: 0.2423 - accuracy: 0.9266 - val_loss: 3.1444 - val_accuracy: 0.4342\n",
      "Epoch 87/100\n",
      "177/177 [==============================] - 0s 347us/step - loss: 0.2788 - accuracy: 0.9153 - val_loss: 3.1448 - val_accuracy: 0.4474\n",
      "Epoch 88/100\n",
      "177/177 [==============================] - 0s 358us/step - loss: 0.2560 - accuracy: 0.9435 - val_loss: 3.2427 - val_accuracy: 0.4474\n",
      "Epoch 89/100\n",
      "177/177 [==============================] - 0s 325us/step - loss: 0.1919 - accuracy: 0.9435 - val_loss: 3.2606 - val_accuracy: 0.4211\n",
      "Epoch 90/100\n",
      "177/177 [==============================] - 0s 369us/step - loss: 0.2335 - accuracy: 0.9096 - val_loss: 3.3102 - val_accuracy: 0.4211\n",
      "Epoch 91/100\n",
      "177/177 [==============================] - 0s 417us/step - loss: 0.2438 - accuracy: 0.8983 - val_loss: 3.3581 - val_accuracy: 0.4474\n",
      "Epoch 92/100\n",
      "177/177 [==============================] - 0s 386us/step - loss: 0.2602 - accuracy: 0.9379 - val_loss: 3.2990 - val_accuracy: 0.4605\n",
      "Epoch 93/100\n",
      "177/177 [==============================] - 0s 335us/step - loss: 0.2213 - accuracy: 0.9266 - val_loss: 3.2278 - val_accuracy: 0.4474\n",
      "Epoch 94/100\n",
      "177/177 [==============================] - 0s 314us/step - loss: 0.2541 - accuracy: 0.9153 - val_loss: 3.2867 - val_accuracy: 0.4211\n",
      "Epoch 95/100\n",
      "177/177 [==============================] - 0s 356us/step - loss: 0.2286 - accuracy: 0.9266 - val_loss: 3.3036 - val_accuracy: 0.4605\n",
      "Epoch 96/100\n",
      "177/177 [==============================] - 0s 377us/step - loss: 0.2097 - accuracy: 0.9322 - val_loss: 3.3094 - val_accuracy: 0.4474\n",
      "Epoch 97/100\n",
      "177/177 [==============================] - 0s 340us/step - loss: 0.2092 - accuracy: 0.9435 - val_loss: 3.2917 - val_accuracy: 0.4474\n",
      "Epoch 98/100\n",
      "177/177 [==============================] - 0s 268us/step - loss: 0.1873 - accuracy: 0.9379 - val_loss: 3.3113 - val_accuracy: 0.4605\n",
      "Epoch 99/100\n",
      "177/177 [==============================] - 0s 266us/step - loss: 0.1977 - accuracy: 0.9435 - val_loss: 3.3744 - val_accuracy: 0.4605\n",
      "Epoch 100/100\n",
      "177/177 [==============================] - 0s 269us/step - loss: 0.1948 - accuracy: 0.9266 - val_loss: 3.3967 - val_accuracy: 0.4474\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a38d41048>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.fit(X_train, y_train,\n",
    "          batch_size=64, epochs=100,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 0s 162us/step\n",
      "test accuracy: 43.42%\n"
     ]
    }
   ],
   "source": [
    "acc_test4 = model4.evaluate(X_test, y_test)[1]\n",
    "print('test accuracy: %.2f%%' % (acc_test4*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 0, 0, 2, 2, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 2,\n",
       "       1, 0, 2, 2, 2, 0, 2, 2, 0, 2, 1, 0, 2, 1, 1, 1, 0, 0, 2, 0, 1, 0,\n",
       "       1, 2, 0, 1, 1, 2, 2, 2, 0, 2, 0, 1, 0, 2, 1, 0, 0, 0, 0, 0, 2, 2,\n",
       "       0, 2, 2, 2, 2, 0, 2, 1, 2, 0])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred4 = model4.predict_classes(X_test)\n",
    "pred4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>SR1129</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>CA105</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>NRS175</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>EUH25</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>NRS070</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>SR1065</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>BCH-SA-09</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>Grady1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>NRS254</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>CFBRSa66B</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  test  pred\n",
       "236     SR1129     2     2\n",
       "31       CA105     2     2\n",
       "155     NRS175     1     0\n",
       "92       EUH25     2     0\n",
       "122     NRS070     2     2\n",
       "..         ...   ...   ...\n",
       "235     SR1065     0     0\n",
       "24   BCH-SA-09     0     2\n",
       "104     Grady1     0     1\n",
       "213     NRS254     2     2\n",
       "87   CFBRSa66B     0     0\n",
       "\n",
       "[76 rows x 3 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat4['pred'] = pred4\n",
    "dat4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba4 = model4.predict_proba(X_test)\n",
    "dat_proba4 = pd.DataFrame(proba4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.005313</td>\n",
       "      <td>5.045130e-03</td>\n",
       "      <td>0.989642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.317836</td>\n",
       "      <td>6.064754e-02</td>\n",
       "      <td>0.621516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.741557</td>\n",
       "      <td>2.228121e-01</td>\n",
       "      <td>0.035630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.999357</td>\n",
       "      <td>6.244136e-07</td>\n",
       "      <td>0.000643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000022</td>\n",
       "      <td>8.065955e-06</td>\n",
       "      <td>0.999970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.960508</td>\n",
       "      <td>4.693716e-07</td>\n",
       "      <td>0.039492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.009070</td>\n",
       "      <td>2.135354e-01</td>\n",
       "      <td>0.777394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.407448</td>\n",
       "      <td>5.212504e-01</td>\n",
       "      <td>0.071302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.029411</td>\n",
       "      <td>1.292708e-02</td>\n",
       "      <td>0.957662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.664336</td>\n",
       "      <td>4.924109e-02</td>\n",
       "      <td>0.286423</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0             1         2\n",
       "0   0.005313  5.045130e-03  0.989642\n",
       "1   0.317836  6.064754e-02  0.621516\n",
       "2   0.741557  2.228121e-01  0.035630\n",
       "3   0.999357  6.244136e-07  0.000643\n",
       "4   0.000022  8.065955e-06  0.999970\n",
       "..       ...           ...       ...\n",
       "71  0.960508  4.693716e-07  0.039492\n",
       "72  0.009070  2.135354e-01  0.777394\n",
       "73  0.407448  5.212504e-01  0.071302\n",
       "74  0.029411  1.292708e-02  0.957662\n",
       "75  0.664336  4.924109e-02  0.286423\n",
       "\n",
       "[76 rows x 3 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba4.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba4.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat4.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/4p17ST.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 177 samples, validate on 76 samples\n",
      "Epoch 1/100\n",
      "177/177 [==============================] - 0s 408us/step - loss: 0.1877 - accuracy: 0.9435 - val_loss: 3.1428 - val_accuracy: 0.3947\n",
      "Epoch 2/100\n",
      "177/177 [==============================] - 0s 390us/step - loss: 0.2036 - accuracy: 0.9322 - val_loss: 3.1284 - val_accuracy: 0.4342\n",
      "Epoch 3/100\n",
      "177/177 [==============================] - 0s 353us/step - loss: 0.1926 - accuracy: 0.9548 - val_loss: 3.1405 - val_accuracy: 0.4211\n",
      "Epoch 4/100\n",
      "177/177 [==============================] - 0s 341us/step - loss: 0.1933 - accuracy: 0.9322 - val_loss: 3.1627 - val_accuracy: 0.4211\n",
      "Epoch 5/100\n",
      "177/177 [==============================] - 0s 365us/step - loss: 0.1808 - accuracy: 0.9435 - val_loss: 3.1504 - val_accuracy: 0.4342\n",
      "Epoch 6/100\n",
      "177/177 [==============================] - 0s 344us/step - loss: 0.1809 - accuracy: 0.9605 - val_loss: 3.1611 - val_accuracy: 0.4342\n",
      "Epoch 7/100\n",
      "177/177 [==============================] - 0s 361us/step - loss: 0.1821 - accuracy: 0.9492 - val_loss: 3.1765 - val_accuracy: 0.4342\n",
      "Epoch 8/100\n",
      "177/177 [==============================] - 0s 353us/step - loss: 0.1861 - accuracy: 0.9492 - val_loss: 3.2098 - val_accuracy: 0.4211\n",
      "Epoch 9/100\n",
      "177/177 [==============================] - 0s 370us/step - loss: 0.1745 - accuracy: 0.9492 - val_loss: 3.1784 - val_accuracy: 0.4342\n",
      "Epoch 10/100\n",
      "177/177 [==============================] - 0s 336us/step - loss: 0.1800 - accuracy: 0.9492 - val_loss: 3.2340 - val_accuracy: 0.4342\n",
      "Epoch 11/100\n",
      "177/177 [==============================] - 0s 365us/step - loss: 0.1877 - accuracy: 0.9605 - val_loss: 3.2943 - val_accuracy: 0.4342\n",
      "Epoch 12/100\n",
      "177/177 [==============================] - 0s 362us/step - loss: 0.1851 - accuracy: 0.9548 - val_loss: 3.2316 - val_accuracy: 0.4211\n",
      "Epoch 13/100\n",
      "177/177 [==============================] - 0s 367us/step - loss: 0.1745 - accuracy: 0.9492 - val_loss: 3.2437 - val_accuracy: 0.4211\n",
      "Epoch 14/100\n",
      "177/177 [==============================] - 0s 359us/step - loss: 0.1818 - accuracy: 0.9548 - val_loss: 3.2695 - val_accuracy: 0.4211\n",
      "Epoch 15/100\n",
      "177/177 [==============================] - 0s 394us/step - loss: 0.1746 - accuracy: 0.9435 - val_loss: 3.2763 - val_accuracy: 0.4342\n",
      "Epoch 16/100\n",
      "177/177 [==============================] - 0s 379us/step - loss: 0.1778 - accuracy: 0.9379 - val_loss: 3.3080 - val_accuracy: 0.4342\n",
      "Epoch 17/100\n",
      "177/177 [==============================] - 0s 380us/step - loss: 0.1737 - accuracy: 0.9548 - val_loss: 3.2835 - val_accuracy: 0.4342\n",
      "Epoch 18/100\n",
      "177/177 [==============================] - 0s 359us/step - loss: 0.1728 - accuracy: 0.9548 - val_loss: 3.3082 - val_accuracy: 0.4342\n",
      "Epoch 19/100\n",
      "177/177 [==============================] - 0s 413us/step - loss: 0.1718 - accuracy: 0.9492 - val_loss: 3.3261 - val_accuracy: 0.4342\n",
      "Epoch 20/100\n",
      "177/177 [==============================] - 0s 351us/step - loss: 0.1624 - accuracy: 0.9605 - val_loss: 3.3453 - val_accuracy: 0.4342\n",
      "Epoch 21/100\n",
      "177/177 [==============================] - 0s 340us/step - loss: 0.1625 - accuracy: 0.9492 - val_loss: 3.3920 - val_accuracy: 0.4211\n",
      "Epoch 22/100\n",
      "177/177 [==============================] - 0s 366us/step - loss: 0.1755 - accuracy: 0.9379 - val_loss: 3.3780 - val_accuracy: 0.4211\n",
      "Epoch 23/100\n",
      "177/177 [==============================] - 0s 418us/step - loss: 0.1722 - accuracy: 0.9379 - val_loss: 3.3914 - val_accuracy: 0.4211\n",
      "Epoch 24/100\n",
      "177/177 [==============================] - 0s 419us/step - loss: 0.1571 - accuracy: 0.9548 - val_loss: 3.4126 - val_accuracy: 0.4211\n",
      "Epoch 25/100\n",
      "177/177 [==============================] - 0s 390us/step - loss: 0.1626 - accuracy: 0.9492 - val_loss: 3.4189 - val_accuracy: 0.4211\n",
      "Epoch 26/100\n",
      "177/177 [==============================] - 0s 382us/step - loss: 0.1589 - accuracy: 0.9492 - val_loss: 3.4156 - val_accuracy: 0.4211\n",
      "Epoch 27/100\n",
      "177/177 [==============================] - 0s 421us/step - loss: 0.1556 - accuracy: 0.9492 - val_loss: 3.3997 - val_accuracy: 0.4079\n",
      "Epoch 28/100\n",
      "177/177 [==============================] - 0s 373us/step - loss: 0.1523 - accuracy: 0.9435 - val_loss: 3.4201 - val_accuracy: 0.4211\n",
      "Epoch 29/100\n",
      "177/177 [==============================] - 0s 365us/step - loss: 0.1517 - accuracy: 0.9548 - val_loss: 3.4515 - val_accuracy: 0.4211\n",
      "Epoch 30/100\n",
      "177/177 [==============================] - 0s 371us/step - loss: 0.1561 - accuracy: 0.9548 - val_loss: 3.4781 - val_accuracy: 0.4211\n",
      "Epoch 31/100\n",
      "177/177 [==============================] - 0s 362us/step - loss: 0.1518 - accuracy: 0.9548 - val_loss: 3.4986 - val_accuracy: 0.4211\n",
      "Epoch 32/100\n",
      "177/177 [==============================] - 0s 361us/step - loss: 0.1557 - accuracy: 0.9435 - val_loss: 3.4867 - val_accuracy: 0.4079\n",
      "Epoch 33/100\n",
      "177/177 [==============================] - 0s 360us/step - loss: 0.1475 - accuracy: 0.9492 - val_loss: 3.4680 - val_accuracy: 0.4079\n",
      "Epoch 34/100\n",
      "177/177 [==============================] - 0s 377us/step - loss: 0.1587 - accuracy: 0.9492 - val_loss: 3.4865 - val_accuracy: 0.4079\n",
      "Epoch 35/100\n",
      "177/177 [==============================] - 0s 392us/step - loss: 0.1473 - accuracy: 0.9605 - val_loss: 3.5379 - val_accuracy: 0.4079\n",
      "Epoch 36/100\n",
      "177/177 [==============================] - 0s 358us/step - loss: 0.1770 - accuracy: 0.9379 - val_loss: 3.5999 - val_accuracy: 0.4079\n",
      "Epoch 37/100\n",
      "177/177 [==============================] - 0s 391us/step - loss: 0.1515 - accuracy: 0.9379 - val_loss: 3.5695 - val_accuracy: 0.4211\n",
      "Epoch 38/100\n",
      "177/177 [==============================] - 0s 347us/step - loss: 0.1465 - accuracy: 0.9548 - val_loss: 3.4907 - val_accuracy: 0.4079\n",
      "Epoch 39/100\n",
      "177/177 [==============================] - 0s 318us/step - loss: 0.1715 - accuracy: 0.9492 - val_loss: 3.5130 - val_accuracy: 0.4211\n",
      "Epoch 40/100\n",
      "177/177 [==============================] - 0s 329us/step - loss: 0.1620 - accuracy: 0.9379 - val_loss: 3.6854 - val_accuracy: 0.4079\n",
      "Epoch 41/100\n",
      "177/177 [==============================] - 0s 308us/step - loss: 0.1644 - accuracy: 0.9266 - val_loss: 3.6583 - val_accuracy: 0.4079\n",
      "Epoch 42/100\n",
      "177/177 [==============================] - 0s 313us/step - loss: 0.1621 - accuracy: 0.9492 - val_loss: 3.5689 - val_accuracy: 0.4211\n",
      "Epoch 43/100\n",
      "177/177 [==============================] - 0s 297us/step - loss: 0.1432 - accuracy: 0.9548 - val_loss: 3.6065 - val_accuracy: 0.4211\n",
      "Epoch 44/100\n",
      "177/177 [==============================] - 0s 308us/step - loss: 0.1702 - accuracy: 0.9548 - val_loss: 3.6407 - val_accuracy: 0.4211\n",
      "Epoch 45/100\n",
      "177/177 [==============================] - 0s 324us/step - loss: 0.1444 - accuracy: 0.9548 - val_loss: 3.6162 - val_accuracy: 0.4079\n",
      "Epoch 46/100\n",
      "177/177 [==============================] - 0s 344us/step - loss: 0.1440 - accuracy: 0.9492 - val_loss: 3.6565 - val_accuracy: 0.3947\n",
      "Epoch 47/100\n",
      "177/177 [==============================] - 0s 368us/step - loss: 0.1604 - accuracy: 0.9379 - val_loss: 3.7006 - val_accuracy: 0.4079\n",
      "Epoch 48/100\n",
      "177/177 [==============================] - 0s 427us/step - loss: 0.1421 - accuracy: 0.9605 - val_loss: 3.7266 - val_accuracy: 0.4211\n",
      "Epoch 49/100\n",
      "177/177 [==============================] - 0s 335us/step - loss: 0.1503 - accuracy: 0.9605 - val_loss: 3.6888 - val_accuracy: 0.4211\n",
      "Epoch 50/100\n",
      "177/177 [==============================] - 0s 338us/step - loss: 0.1499 - accuracy: 0.9492 - val_loss: 3.6725 - val_accuracy: 0.4211\n",
      "Epoch 51/100\n",
      "177/177 [==============================] - 0s 324us/step - loss: 0.1376 - accuracy: 0.9605 - val_loss: 3.7653 - val_accuracy: 0.4211\n",
      "Epoch 52/100\n",
      "177/177 [==============================] - 0s 359us/step - loss: 0.1492 - accuracy: 0.9435 - val_loss: 3.7797 - val_accuracy: 0.4079\n",
      "Epoch 53/100\n",
      "177/177 [==============================] - 0s 341us/step - loss: 0.1418 - accuracy: 0.9548 - val_loss: 3.7408 - val_accuracy: 0.4211\n",
      "Epoch 54/100\n",
      "177/177 [==============================] - 0s 354us/step - loss: 0.1488 - accuracy: 0.9548 - val_loss: 3.7387 - val_accuracy: 0.4211\n",
      "Epoch 55/100\n",
      "177/177 [==============================] - 0s 342us/step - loss: 0.1529 - accuracy: 0.9492 - val_loss: 3.8177 - val_accuracy: 0.4211\n",
      "Epoch 56/100\n",
      "177/177 [==============================] - 0s 344us/step - loss: 0.1360 - accuracy: 0.9492 - val_loss: 3.8368 - val_accuracy: 0.4211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "177/177 [==============================] - 0s 393us/step - loss: 0.1321 - accuracy: 0.9548 - val_loss: 3.7890 - val_accuracy: 0.4211\n",
      "Epoch 58/100\n",
      "177/177 [==============================] - 0s 376us/step - loss: 0.1302 - accuracy: 0.9605 - val_loss: 3.7672 - val_accuracy: 0.4211\n",
      "Epoch 59/100\n",
      "177/177 [==============================] - 0s 406us/step - loss: 0.1322 - accuracy: 0.9605 - val_loss: 3.7929 - val_accuracy: 0.4211\n",
      "Epoch 60/100\n",
      "177/177 [==============================] - 0s 355us/step - loss: 0.1250 - accuracy: 0.9605 - val_loss: 3.8179 - val_accuracy: 0.4211\n",
      "Epoch 61/100\n",
      "177/177 [==============================] - 0s 367us/step - loss: 0.1456 - accuracy: 0.9661 - val_loss: 3.8270 - val_accuracy: 0.4211\n",
      "Epoch 62/100\n",
      "177/177 [==============================] - 0s 338us/step - loss: 0.1317 - accuracy: 0.9605 - val_loss: 3.8854 - val_accuracy: 0.4211\n",
      "Epoch 63/100\n",
      "177/177 [==============================] - 0s 348us/step - loss: 0.1287 - accuracy: 0.9492 - val_loss: 3.8758 - val_accuracy: 0.4079\n",
      "Epoch 64/100\n",
      "177/177 [==============================] - 0s 343us/step - loss: 0.1353 - accuracy: 0.9661 - val_loss: 3.8906 - val_accuracy: 0.4211\n",
      "Epoch 65/100\n",
      "177/177 [==============================] - 0s 410us/step - loss: 0.1298 - accuracy: 0.9605 - val_loss: 3.8888 - val_accuracy: 0.4211\n",
      "Epoch 66/100\n",
      "177/177 [==============================] - 0s 330us/step - loss: 0.1219 - accuracy: 0.9548 - val_loss: 3.9079 - val_accuracy: 0.3947\n",
      "Epoch 67/100\n",
      "177/177 [==============================] - 0s 333us/step - loss: 0.1323 - accuracy: 0.9492 - val_loss: 3.9057 - val_accuracy: 0.4079\n",
      "Epoch 68/100\n",
      "177/177 [==============================] - 0s 347us/step - loss: 0.1278 - accuracy: 0.9548 - val_loss: 3.8729 - val_accuracy: 0.4211\n",
      "Epoch 69/100\n",
      "177/177 [==============================] - 0s 343us/step - loss: 0.1236 - accuracy: 0.9548 - val_loss: 3.8947 - val_accuracy: 0.4211\n",
      "Epoch 70/100\n",
      "177/177 [==============================] - 0s 373us/step - loss: 0.1211 - accuracy: 0.9661 - val_loss: 3.9125 - val_accuracy: 0.4211\n",
      "Epoch 71/100\n",
      "177/177 [==============================] - 0s 389us/step - loss: 0.1263 - accuracy: 0.9605 - val_loss: 3.9119 - val_accuracy: 0.4211\n",
      "Epoch 72/100\n",
      "177/177 [==============================] - 0s 450us/step - loss: 0.1290 - accuracy: 0.9661 - val_loss: 3.9450 - val_accuracy: 0.4211\n",
      "Epoch 73/100\n",
      "177/177 [==============================] - 0s 337us/step - loss: 0.1130 - accuracy: 0.9605 - val_loss: 3.9713 - val_accuracy: 0.4211\n",
      "Epoch 74/100\n",
      "177/177 [==============================] - 0s 356us/step - loss: 0.1137 - accuracy: 0.9605 - val_loss: 3.9490 - val_accuracy: 0.4211\n",
      "Epoch 75/100\n",
      "177/177 [==============================] - 0s 349us/step - loss: 0.1172 - accuracy: 0.9605 - val_loss: 3.9688 - val_accuracy: 0.4211\n",
      "Epoch 76/100\n",
      "177/177 [==============================] - 0s 346us/step - loss: 0.1105 - accuracy: 0.9605 - val_loss: 4.0086 - val_accuracy: 0.4211\n",
      "Epoch 77/100\n",
      "177/177 [==============================] - 0s 341us/step - loss: 0.1218 - accuracy: 0.9548 - val_loss: 3.9911 - val_accuracy: 0.4211\n",
      "Epoch 78/100\n",
      "177/177 [==============================] - 0s 349us/step - loss: 0.1176 - accuracy: 0.9548 - val_loss: 3.9717 - val_accuracy: 0.4211\n",
      "Epoch 79/100\n",
      "177/177 [==============================] - 0s 349us/step - loss: 0.1196 - accuracy: 0.9605 - val_loss: 4.0002 - val_accuracy: 0.4211\n",
      "Epoch 80/100\n",
      "177/177 [==============================] - 0s 347us/step - loss: 0.1423 - accuracy: 0.9548 - val_loss: 3.9993 - val_accuracy: 0.4211\n",
      "Epoch 81/100\n",
      "177/177 [==============================] - 0s 341us/step - loss: 0.1257 - accuracy: 0.9605 - val_loss: 4.0730 - val_accuracy: 0.4211\n",
      "Epoch 82/100\n",
      "177/177 [==============================] - 0s 328us/step - loss: 0.1250 - accuracy: 0.9605 - val_loss: 4.0352 - val_accuracy: 0.4211\n",
      "Epoch 83/100\n",
      "177/177 [==============================] - 0s 366us/step - loss: 0.1237 - accuracy: 0.9605 - val_loss: 3.9824 - val_accuracy: 0.4079\n",
      "Epoch 84/100\n",
      "177/177 [==============================] - 0s 615us/step - loss: 0.1139 - accuracy: 0.9661 - val_loss: 3.9980 - val_accuracy: 0.4079\n",
      "Epoch 85/100\n",
      "177/177 [==============================] - 0s 500us/step - loss: 0.1108 - accuracy: 0.9605 - val_loss: 4.0868 - val_accuracy: 0.4211\n",
      "Epoch 86/100\n",
      "177/177 [==============================] - 0s 488us/step - loss: 0.1202 - accuracy: 0.9605 - val_loss: 4.0738 - val_accuracy: 0.4211\n",
      "Epoch 87/100\n",
      "177/177 [==============================] - 0s 478us/step - loss: 0.1171 - accuracy: 0.9548 - val_loss: 4.0179 - val_accuracy: 0.4211\n",
      "Epoch 88/100\n",
      "177/177 [==============================] - 0s 452us/step - loss: 0.1139 - accuracy: 0.9661 - val_loss: 4.0589 - val_accuracy: 0.4342\n",
      "Epoch 89/100\n",
      "177/177 [==============================] - 0s 423us/step - loss: 0.1105 - accuracy: 0.9605 - val_loss: 4.0821 - val_accuracy: 0.4211\n",
      "Epoch 90/100\n",
      "177/177 [==============================] - 0s 454us/step - loss: 0.1189 - accuracy: 0.9605 - val_loss: 4.1344 - val_accuracy: 0.4079\n",
      "Epoch 91/100\n",
      "177/177 [==============================] - 0s 485us/step - loss: 0.1184 - accuracy: 0.9548 - val_loss: 4.1439 - val_accuracy: 0.4211\n",
      "Epoch 92/100\n",
      "177/177 [==============================] - 0s 1ms/step - loss: 0.1169 - accuracy: 0.9548 - val_loss: 4.1123 - val_accuracy: 0.4211\n",
      "Epoch 93/100\n",
      "177/177 [==============================] - 0s 542us/step - loss: 0.1100 - accuracy: 0.9605 - val_loss: 4.0937 - val_accuracy: 0.4211\n",
      "Epoch 94/100\n",
      "177/177 [==============================] - 0s 561us/step - loss: 0.1049 - accuracy: 0.9605 - val_loss: 4.0965 - val_accuracy: 0.4211\n",
      "Epoch 95/100\n",
      "177/177 [==============================] - 0s 639us/step - loss: 0.1080 - accuracy: 0.9605 - val_loss: 4.1631 - val_accuracy: 0.4211\n",
      "Epoch 96/100\n",
      "177/177 [==============================] - 0s 531us/step - loss: 0.1018 - accuracy: 0.9605 - val_loss: 4.2106 - val_accuracy: 0.3947\n",
      "Epoch 97/100\n",
      "177/177 [==============================] - 0s 420us/step - loss: 0.1171 - accuracy: 0.9605 - val_loss: 4.1529 - val_accuracy: 0.4342\n",
      "Epoch 98/100\n",
      "177/177 [==============================] - 0s 351us/step - loss: 0.1156 - accuracy: 0.9661 - val_loss: 4.1705 - val_accuracy: 0.4211\n",
      "Epoch 99/100\n",
      "177/177 [==============================] - 0s 334us/step - loss: 0.1110 - accuracy: 0.9661 - val_loss: 4.2542 - val_accuracy: 0.4079\n",
      "Epoch 100/100\n",
      "177/177 [==============================] - 0s 352us/step - loss: 0.1093 - accuracy: 0.9548 - val_loss: 4.2145 - val_accuracy: 0.4211\n"
     ]
    }
   ],
   "source": [
    "hist4 = model4.fit(X_train, y_train,\n",
    "          batch_size=64, epochs=100,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 95.37%\n"
     ]
    }
   ],
   "source": [
    "print('train accuracy: %.2f%%' % (np.mean(hist4.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba4 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_2.xlsx\",\n",
    "                        sheet_name=3,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>SR1129</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4.821690e-07</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>9.999983e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>CA105</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.652370e-03</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>9.972990e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NRS175</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.198157e-02</td>\n",
       "      <td>0.988018</td>\n",
       "      <td>5.232074e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>EUH25</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.388957e-01</td>\n",
       "      <td>0.735954</td>\n",
       "      <td>1.251503e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NRS070</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7.231966e-03</td>\n",
       "      <td>0.810317</td>\n",
       "      <td>1.824512e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>NRS247</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.957360e-02</td>\n",
       "      <td>0.385730</td>\n",
       "      <td>5.846961e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>NRS215</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.196635e-03</td>\n",
       "      <td>0.445057</td>\n",
       "      <td>5.517461e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>SR4152</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4.319404e-02</td>\n",
       "      <td>0.028984</td>\n",
       "      <td>9.278219e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>NRS035</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.902312e-03</td>\n",
       "      <td>0.680427</td>\n",
       "      <td>3.146706e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>SR4187</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.566210e-04</td>\n",
       "      <td>0.055815</td>\n",
       "      <td>9.439281e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>608 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     phage  strain  phenotype  prediction             0  \\\n",
       "0       p0017kpresabs_qual  SR1129          2           2  4.821690e-07   \n",
       "1       p0017kpresabs_qual   CA105          2           2  2.652370e-03   \n",
       "2       p0017kpresabs_qual  NRS175          1           1  1.198157e-02   \n",
       "3       p0017kpresabs_qual   EUH25          2           1  1.388957e-01   \n",
       "4       p0017kpresabs_qual  NRS070          2           1  7.231966e-03   \n",
       "..                     ...     ...        ...         ...           ...   \n",
       "603  p0040presabsSTCC_qual  NRS247          1           2  2.957360e-02   \n",
       "604  p0040presabsSTCC_qual  NRS215          1           2  3.196635e-03   \n",
       "605  p0040presabsSTCC_qual  SR4152          2           2  4.319404e-02   \n",
       "606  p0040presabsSTCC_qual  NRS035          1           1  4.902312e-03   \n",
       "607  p0040presabsSTCC_qual  SR4187          2           2  2.566210e-04   \n",
       "\n",
       "            1             2  \n",
       "0    0.000001  9.999983e-01  \n",
       "1    0.000049  9.972990e-01  \n",
       "2    0.988018  5.232074e-09  \n",
       "3    0.735954  1.251503e-01  \n",
       "4    0.810317  1.824512e-01  \n",
       "..        ...           ...  \n",
       "603  0.385730  5.846961e-01  \n",
       "604  0.445057  5.517461e-01  \n",
       "605  0.028984  9.278219e-01  \n",
       "606  0.680427  3.146706e-01  \n",
       "607  0.055815  9.439281e-01  \n",
       "\n",
       "[608 rows x 7 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.31287540e-03, 5.04513040e-03, 9.89641960e-01],\n",
       "       [3.17836100e-01, 6.06475440e-02, 6.21516350e-01],\n",
       "       [7.41557360e-01, 2.22812120e-01, 3.56304980e-02],\n",
       "       [9.99356800e-01, 6.24413600e-07, 6.42553400e-04],\n",
       "       [2.23217430e-05, 8.06595500e-06, 9.99969600e-01],\n",
       "       [6.75432800e-04, 1.52419580e-02, 9.84082640e-01],\n",
       "       [6.06920160e-02, 5.48378050e-01, 3.90929900e-01],\n",
       "       [9.95311740e-01, 7.11470140e-04, 3.97686330e-03],\n",
       "       [2.92135360e-01, 5.92035650e-01, 1.15829020e-01],\n",
       "       [2.95903080e-05, 9.99097000e-01, 8.73445400e-04],\n",
       "       [9.57156500e-03, 9.80777700e-01, 9.65080400e-03],\n",
       "       [5.52573500e-04, 9.99297740e-01, 1.49565650e-04],\n",
       "       [1.86405870e-01, 6.74111960e-01, 1.39482230e-01],\n",
       "       [2.41502320e-02, 9.74214550e-01, 1.63521020e-03],\n",
       "       [1.92317600e-02, 9.78346050e-01, 2.42219730e-03],\n",
       "       [1.92181570e-01, 7.66911570e-01, 4.09069600e-02],\n",
       "       [1.44074020e-05, 9.99985200e-01, 3.16928800e-07],\n",
       "       [1.32297320e-01, 1.48308900e-03, 8.66219600e-01],\n",
       "       [2.83926400e-01, 1.37405580e-02, 7.02333030e-01],\n",
       "       [4.02850430e-02, 9.59101200e-01, 6.13750100e-04],\n",
       "       [2.87708250e-01, 6.75551400e-01, 3.67404150e-02],\n",
       "       [3.87960300e-04, 1.86007740e-07, 9.99611900e-01],\n",
       "       [3.28437100e-02, 6.35580660e-01, 3.31575700e-01],\n",
       "       [5.77174700e-01, 3.54870080e-01, 6.79551700e-02],\n",
       "       [2.81277400e-03, 2.25897950e-07, 9.97186960e-01],\n",
       "       [9.99107300e-04, 6.52658200e-02, 9.33735130e-01],\n",
       "       [4.41881300e-07, 9.21430040e-10, 9.99999500e-01],\n",
       "       [9.95893500e-01, 1.14460420e-03, 2.96188660e-03],\n",
       "       [7.64445600e-04, 2.79552020e-03, 9.96440000e-01],\n",
       "       [2.84796570e-01, 1.68940100e-01, 5.46263340e-01],\n",
       "       [6.02053500e-01, 2.95161200e-01, 1.02785274e-01],\n",
       "       [1.07033085e-02, 1.82609620e-01, 8.06687060e-01],\n",
       "       [2.58554930e-02, 9.71014600e-01, 3.12982690e-03],\n",
       "       [7.75061670e-01, 2.21289260e-01, 3.64900330e-03],\n",
       "       [7.26101500e-07, 1.57728660e-09, 9.99999300e-01],\n",
       "       [3.92260770e-03, 9.94769400e-01, 1.30796200e-03],\n",
       "       [1.97384730e-02, 9.77479300e-01, 2.78224590e-03],\n",
       "       [3.28426270e-01, 5.21185200e-01, 1.50388520e-01],\n",
       "       [7.22930550e-01, 2.65465380e-01, 1.16040840e-02],\n",
       "       [9.67370330e-01, 4.81140750e-03, 2.78183350e-02],\n",
       "       [4.13161630e-02, 1.83456980e-03, 9.56849340e-01],\n",
       "       [5.67632100e-01, 2.94148300e-01, 1.38219620e-01],\n",
       "       [4.37360020e-03, 7.23550600e-01, 2.72075740e-01],\n",
       "       [9.94942960e-01, 3.54072360e-03, 1.51630180e-03],\n",
       "       [1.62205000e-05, 9.99926800e-01, 5.69991030e-05],\n",
       "       [3.87960300e-04, 1.86007740e-07, 9.99611900e-01],\n",
       "       [9.92547200e-01, 6.89303360e-03, 5.59719750e-04],\n",
       "       [7.90335100e-07, 9.99999170e-01, 3.13376940e-10],\n",
       "       [8.55505540e-02, 9.05516400e-01, 8.93306450e-03],\n",
       "       [7.57471470e-07, 2.51685980e-05, 9.99974130e-01],\n",
       "       [2.80108860e-06, 6.22083360e-09, 9.99997140e-01],\n",
       "       [3.70016110e-03, 7.82883700e-02, 9.18011500e-01],\n",
       "       [8.67355050e-01, 8.06678160e-02, 5.19771900e-02],\n",
       "       [2.07233980e-01, 2.07003670e-01, 5.85762300e-01],\n",
       "       [7.51624940e-01, 6.96634230e-04, 2.47678410e-01],\n",
       "       [3.83240170e-03, 9.96162400e-01, 5.25668250e-06],\n",
       "       [9.98288600e-01, 1.71139290e-03, 5.10463780e-08],\n",
       "       [7.32439000e-07, 9.39543000e-04, 9.99059740e-01],\n",
       "       [1.52468520e-03, 9.81993100e-01, 1.64822100e-02],\n",
       "       [6.05198900e-01, 8.72056600e-02, 3.07595460e-01],\n",
       "       [8.54377030e-01, 1.43089100e-01, 2.53380840e-03],\n",
       "       [9.59032360e-01, 1.05549440e-05, 4.09571380e-02],\n",
       "       [9.97040700e-01, 7.83950100e-05, 2.88085620e-03],\n",
       "       [9.94199630e-01, 1.56984570e-03, 4.23049930e-03],\n",
       "       [7.97185700e-09, 6.70204400e-11, 1.00000000e+00],\n",
       "       [7.46892530e-04, 8.20888360e-02, 9.17164270e-01],\n",
       "       [7.40220100e-01, 1.72543930e-01, 8.72359200e-02],\n",
       "       [4.47643040e-03, 8.88609500e-05, 9.95434700e-01],\n",
       "       [1.23358330e-04, 2.45141150e-08, 9.99876600e-01],\n",
       "       [3.22413730e-05, 1.77331620e-04, 9.99790500e-01],\n",
       "       [5.56106260e-03, 2.82112040e-04, 9.94156840e-01],\n",
       "       [9.60508000e-01, 4.69371630e-07, 3.94915340e-02],\n",
       "       [9.07018800e-03, 2.13535350e-01, 7.77394500e-01],\n",
       "       [4.07447700e-01, 5.21250400e-01, 7.13018250e-02],\n",
       "       [2.94109300e-02, 1.29270810e-02, 9.57662050e-01],\n",
       "       [6.64335970e-01, 4.92410900e-02, 2.86422970e-01]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob4 = df_proba4[df_proba4['phage']=='p0017kpresabsSTCC_qual'].iloc[:,-3:]\n",
    "y_prob4 = y_prob4.to_numpy()\n",
    "y_prob4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5960426258045306"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo4 = rocauc_ovo(y_test, y_prob4, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5960426258045306"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr4 = rocauc_ovr(y_test, y_prob4, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5662184486589248"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovos = [ovo1, ovo2, ovo3, ovo4]\n",
    "np.mean(ovos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.022445154653505908"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(ovos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5662184486589248"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovrs = [ovr1, ovr2, ovr3, ovr4]\n",
    "np.mean(ovrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.022445154653505908"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(ovrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs = [acc_test1, acc_test2, acc_test3, acc_test4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy mean: 43.42%\n"
     ]
    }
   ],
   "source": [
    "mean = np.mean(accs)\n",
    "print('test accuracy mean: %.2f%%' % (mean*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy standard deviation: 0.018608075961940144\n"
     ]
    }
   ],
   "source": [
    "std = np.std(accs)\n",
    "print('test accuracy standard deviation:', std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs_train = [np.mean(hist1.history['accuracy']), np.mean(hist2.history['accuracy']), np.mean(hist3.history['accuracy']),\n",
    "             np.mean(hist4.history['accuracy'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy mean: 93.34%\n"
     ]
    }
   ],
   "source": [
    "mean_train = np.mean(accs_train)\n",
    "print('train accuracy mean: %.2f%%' % (mean_train*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy standard deviation: 0.036008056\n"
     ]
    }
   ],
   "source": [
    "std_train = np.std(accs_train)\n",
    "print('train accuracy standard deviation:', std_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ Feature selection using lasso ##########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Retrieved from https://towardsdatascience.com/feature-selection-using-regularisation-a3678b71e499\n",
    "from sklearn.linear_model import Lasso, LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectFromModel(estimator=LogisticRegression(C=1, class_weight=None, dual=False,\n",
       "                                             fit_intercept=True,\n",
       "                                             intercept_scaling=1, l1_ratio=None,\n",
       "                                             max_iter=100, multi_class='auto',\n",
       "                                             n_jobs=None, penalty='l1',\n",
       "                                             random_state=None,\n",
       "                                             solver='liblinear', tol=0.0001,\n",
       "                                             verbose=0, warm_start=False),\n",
       "                max_features=None, norm_order=1, prefit=False, threshold=None)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selection = SelectFromModel(LogisticRegression(C=1, penalty='l1', solver='liblinear'))\n",
    "selection.fit(X.loc[:, X.columns != 'id'], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = np.array(df_clean.columns).tolist()\n",
    "names.remove('pheno')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_features = np.vstack((names, X.loc[:, X.columns != 'id']))\n",
    "X_train_features = pd.DataFrame(X_train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total features: 7080\n",
      "selected features: 765\n"
     ]
    }
   ],
   "source": [
    "sel_features = X_train_features.columns[(selection.get_support())]\n",
    "print('total features: {}'.format((X_train_features.shape[1])))\n",
    "print('selected features: {}'.format(len(sel_features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    9,   11,   18,   23,   38,   39,   40,   55,   56,   58,\n",
       "          60,   61,   64,   73,   79,   84,  107,  109,  130,  133,  149,\n",
       "         151,  159,  161,  164,  167,  168,  171,  182,  199,  202,  211,\n",
       "         225,  227,  267,  270,  273,  274,  276,  297,  310,  313,  320,\n",
       "         322,  323,  338,  347,  352,  355,  357,  374,  378,  389,  394,\n",
       "         395,  401,  412,  422,  430,  458,  459,  464,  471,  481,  487,\n",
       "         491,  498,  519,  533,  535,  537,  540,  541,  551,  556,  558,\n",
       "         586,  590,  601,  616,  626,  632,  637,  639,  641,  664,  667,\n",
       "         690,  697,  709,  742,  745,  759,  760,  761,  762,  779,  781,\n",
       "         785,  794,  796,  822,  833,  838,  850,  866,  874,  881,  885,\n",
       "         887,  933,  955,  969,  982,  983,  993,  994,  997, 1017, 1027,\n",
       "        1031, 1042, 1047, 1052, 1060, 1064, 1071, 1088, 1109, 1114, 1117,\n",
       "        1127, 1129, 1135, 1141, 1151, 1158, 1162, 1181, 1184, 1193, 1201,\n",
       "        1202, 1208, 1221, 1225, 1255, 1262, 1273, 1274, 1278, 1281, 1283,\n",
       "        1287, 1288, 1321, 1322, 1328, 1330, 1333, 1375, 1391, 1400, 1403,\n",
       "        1407, 1412, 1414, 1427, 1437, 1442, 1443, 1454, 1471, 1482, 1484,\n",
       "        1495, 1501, 1503, 1508, 1514, 1518, 1519, 1521, 1547, 1554, 1558,\n",
       "        1559, 1560, 1562, 1572, 1589, 1600, 1618, 1619, 1625, 1635, 1653,\n",
       "        1654, 1668, 1700, 1734, 1738, 1739, 1746, 1766, 1785, 1799, 1801,\n",
       "        1802, 1803, 1815, 1827, 1846, 1851, 1853, 1859, 1885, 1902, 1904,\n",
       "        1921, 1946, 1976, 1993, 1995, 2026, 2027, 2064, 2070, 2082, 2088,\n",
       "        2089, 2098, 2099, 2109, 2117, 2121, 2130, 2131, 2138, 2165, 2171,\n",
       "        2193, 2200, 2204, 2221, 2237, 2249, 2250, 2258, 2262, 2276, 2278,\n",
       "        2279, 2286, 2290, 2295, 2303, 2308, 2311, 2319, 2330, 2332, 2337,\n",
       "        2344, 2348, 2350, 2367, 2371, 2378, 2392, 2393, 2418, 2431, 2435,\n",
       "        2451, 2461, 2472, 2476, 2479, 2480, 2481, 2488, 2492, 2542, 2546,\n",
       "        2555, 2558, 2563, 2572, 2573, 2579, 2594, 2607, 2612, 2622, 2625,\n",
       "        2627, 2641, 2646, 2653, 2674, 2679, 2698, 2699, 2701, 2708, 2709,\n",
       "        2718, 2732, 2733, 2735, 2738, 2740, 2746, 2757, 2775, 2794, 2796,\n",
       "        2805, 2821, 2825, 2849, 2851, 2898, 2911, 2933, 2934, 2942, 2948,\n",
       "        2955, 2962, 2968, 2999, 3004, 3010, 3014, 3022, 3037, 3040, 3048,\n",
       "        3053, 3057, 3072, 3075, 3076, 3105, 3113, 3114, 3131, 3140, 3150,\n",
       "        3184, 3185, 3188, 3192, 3199, 3209, 3216, 3221, 3237, 3244, 3273,\n",
       "        3300, 3311, 3313, 3317, 3336, 3345, 3350, 3368, 3372, 3376, 3398,\n",
       "        3401, 3404, 3409, 3415, 3419, 3426, 3444, 3447, 3449, 3464, 3468,\n",
       "        3472, 3482, 3513, 3515, 3516, 3517, 3522, 3561, 3573, 3580, 3582,\n",
       "        3603, 3610, 3611, 3614, 3622, 3629, 3643, 3662, 3713, 3722, 3737,\n",
       "        3747, 3768, 3772, 3776, 3785, 3813, 3828, 3829, 3832, 3849, 3861,\n",
       "        3875, 3881, 3929, 3940, 3946, 3948, 3961, 3963, 3964, 3965, 3968,\n",
       "        3971, 3983, 4000, 4012, 4026, 4036, 4049, 4051, 4053, 4066, 4081,\n",
       "        4093, 4096, 4099, 4115, 4122, 4128, 4136, 4144, 4150, 4151, 4156,\n",
       "        4166, 4178, 4194, 4207, 4218, 4226, 4228, 4236, 4238, 4290, 4293,\n",
       "        4297, 4300, 4307, 4333, 4362, 4367, 4390, 4403, 4420, 4427, 4438,\n",
       "        4455, 4463, 4465, 4470, 4471, 4481, 4483, 4494, 4495, 4500, 4526,\n",
       "        4535, 4536, 4542, 4543, 4547, 4549, 4577, 4580, 4599, 4601, 4610,\n",
       "        4619, 4631, 4634, 4646, 4650, 4651, 4672, 4681, 4682, 4684, 4692,\n",
       "        4701, 4706, 4711, 4718, 4725, 4728, 4741, 4754, 4759, 4760, 4763,\n",
       "        4764, 4769, 4786, 4787, 4790, 4804, 4825, 4847, 4848, 4859, 4876,\n",
       "        4878, 4884, 4899, 4903, 4909, 4918, 4926, 4929, 4930, 4933, 4939,\n",
       "        4943, 4950, 4966, 4973, 4975, 4977, 4978, 4980, 5001, 5006, 5016,\n",
       "        5017, 5026, 5039, 5048, 5049, 5061, 5063, 5065, 5076, 5078, 5085,\n",
       "        5086, 5093, 5122, 5125, 5132, 5137, 5138, 5152, 5157, 5160, 5184,\n",
       "        5197, 5207, 5209, 5225, 5233, 5236, 5243, 5265, 5290, 5299, 5320,\n",
       "        5322, 5330, 5341, 5343, 5345, 5351, 5352, 5353, 5356, 5359, 5370,\n",
       "        5375, 5396, 5397, 5401, 5421, 5440, 5443, 5448, 5459, 5460, 5468,\n",
       "        5470, 5489, 5493, 5508, 5516, 5544, 5548, 5553, 5556, 5566, 5568,\n",
       "        5569, 5579, 5580, 5593, 5600, 5603, 5606, 5607, 5618, 5622, 5623,\n",
       "        5625, 5628, 5650, 5654, 5662, 5667, 5670, 5673, 5691, 5702, 5709,\n",
       "        5712, 5718, 5723, 5725, 5742, 5746, 5760, 5776, 5783, 5793, 5826,\n",
       "        5855, 5859, 5866, 5868, 5884, 5888, 5890, 5899, 5918, 5959, 5964,\n",
       "        5966, 5971, 5977, 6002, 6025, 6035, 6037, 6039, 6050, 6065, 6074,\n",
       "        6078, 6101, 6107, 6109, 6118, 6134, 6142, 6164, 6168, 6172, 6179,\n",
       "        6201, 6209, 6211, 6213, 6214, 6233, 6275, 6284, 6285, 6286, 6302,\n",
       "        6307, 6308, 6313, 6320, 6326, 6332, 6342, 6356, 6360, 6370, 6407,\n",
       "        6408, 6410, 6419, 6420, 6421, 6442, 6448, 6450, 6452, 6458, 6488,\n",
       "        6511, 6529, 6536, 6537, 6550, 6559, 6582, 6585, 6593, 6597, 6650,\n",
       "        6662, 6676, 6686, 6693, 6714, 6715, 6718, 6736, 6748, 6751, 6756,\n",
       "        6768, 6770, 6780, 6803, 6808, 6834, 6840, 6842, 6852, 6854, 6876,\n",
       "        6898, 6952, 6968, 6977, 6980, 6989, 6999, 7019, 7022, 7029, 7030,\n",
       "        7031, 7040, 7055, 7066, 7078, 7079]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = sel_features.values\n",
    "cols.reshape((1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['TTTTTTTTATTTTACTCACCTCTAAAGCATAATTCCATATAAACTTGTTATTATCCGAAATTTTTGTATAATAGATTATTTTTGTTGGAGTAATTATTAG',\n",
       "       'TTTTTTTAGGTAATGAATACGAAAATTTCGTATTTACGAACGATAAAAAGAAATCAATTATTTTAGCATTTAAAGAAAAACAAACATCTTAATAGGAGGA',\n",
       "       'TTTTTTTAAAATTAATAAAAAAGCACTTTCTACCCACGGCAAAAAGTGCTTGAAAGATCATAGATCATCACGTTCAAGTCAATTTTAGCCTCGGCAGGAT',\n",
       "       'TTTTTTGCCAATTTTGAGGAGGGAACACATGAAAACACGTTGTTACGATGGTAAAAAATGGCAATATGAGTTTAAGCATGAAGGAAAAAGATACCGTAAG',\n",
       "       'TTTTTTCGTAAAAAACTTTACTATGATATGAAAATTTCGTATAATAAGAAAAAAAGGAGGTAAGTAATATGAACAAAGAAAGAAATATTATTATAGCCAA',\n",
       "       'TTTTTTAGTTCCTACGAATAAGACTTGTCCACCATCTTCTGAAACTTGTTTCAAGAAGTTGTATGCCTCGTCTACTTTTTTCACTGTTTTTTGTAAGTCG',\n",
       "       'TTTTTTAGGTAATGAATACGAAAATTTCGTATTTACGAACGATAAAAAGAAATCAATTATTTTAGCATTTAAAGAAAAACAAACATCTTAATAGGAGGAA',\n",
       "       'TTTTTTAGCTTCAATGATAGCAGACATTCAGACACCTCCATTTAAATTTTTGGTGCTTTTTTTAAAATTAATAAAAAAGCACTTTCTACCCACGGCAAAA',\n",
       "       'TTTTTGGTGCTTTTTTTAAAATTAATAAAAAAGCACTTTCTACCCACGGCAAAAAGTGCTTGAAAGATCATAGATCATCACGTTCAAGTCAATTTTAGCC',\n",
       "       'TTTTTGGCTATAATAATATTTCTTTCTTTGTTCATATTACTTACCTCCTTTTTTTCTTATTATACGAAATTTTCATATCATAGTAAAGTTTTTTACGAAA',\n",
       "       'TTTTTGCCGTGGGTAGAAAGTGCTTTTTTATTAATTTTAAAAAAAGCACCAAAAATTTAAATGGAGGTGTCTGAATGTCTGCTATCATTGAAGCTAAAAA',\n",
       "       'TTTTTGCCAATTTTGAGGAGGGAACACATGAAAACACGTTGTTACGATGGTAAAAAATGGCAATATGAGTTTAAGCATGAAGGAAAAAGATACCGTAAGA',\n",
       "       'TTTTTGATGAATTCGAAAAATTACTCGATAAAAACCGACTATGAATACTATATTGTAGTCAACGATTTCGAGTCTAGCAATCATTTGTCAGTAAATAAAA',\n",
       "       'TTTTTCTTTAAATGCTAAAATAATTGATTTCTTTTTATCGTTCGTAAATACGAAATTTTCGTATTCATTACCTAAAAAAATATCATCATATTTAACATTA',\n",
       "       'TTTTTCGTAAAAAACTTTACTATGATATGAAAATTTCGTATAATAAGAAAAAAAGGAGGTAAGTAATATGAACAAAGAAAGAAATATTATTATAGCCAAA',\n",
       "       'TTTTTCATTTTCATTT',\n",
       "       'TTTTTATTTTCTACACTTCTGTGTTTTACTTTTGTTAAAATATATAGGATTTAAATTATTTATTTATTTAT',\n",
       "       'TTTTTAGTTCCTACGAATAAGACTTGTCCACCATCTTCTGAAACTTGTTTCAAGAAGTTGTATGCCTCGTCTACTTTTTTCACTGTTTTTTGTAAGTCGA',\n",
       "       'TTTTTAGGTAATGAATACGAAAATTTCGTATTTACGAACGATAAAAAGAAATCAATTATTTTAGCATTTAAAGAAAAACAAACATCTTAATAGGAGGAAT',\n",
       "       'TTTTGTTGGAGTA', 'TTTTGTTCCAAA',\n",
       "       'TTTTGGTGCTTTTTTTAAAATTAATAAAAAAGCACTTTCTACCCACGGCAAAAAGTGCTTGAAAGATCATAGATCATCACGTTCAAGTCAATTTTAGCCT',\n",
       "       'TTTTGGCTATAATAATATTTCTTTCTTTGTTCATATTACTTACCTCCTTTTTTTCTTATTATACGAAATTTTCATATCATAGTAAAGTTTTTTACGAAAA',\n",
       "       'TTTTGCCTACAAACCATAATTGAATTAAATTCCAAATTAACTGCACAGTACCTTTCAGTATCATTACAATGCCGTCCCAAACGCCTCGCCAGTTTCCTGT',\n",
       "       'TTTTGCCAATTTTGAGGAGGGAACACATGAAAACACGTTGTTACGATGGTAAAAAATGGCAATATGAGTTTAAGCATGAAGGAAAAAGATACCGTAAGAA',\n",
       "       'TTTTGCAAATAG',\n",
       "       'TTTTGATGAATTCGAAAAATTACTCGATAAAAACCGACTATGAATACTATATTGTAGTCAACGATTTCGAGTCTAGCAATCATTTGTCAGTAAATAAAAG',\n",
       "       'TTTTGAGGAGGGAACACATGAAAACACGTTGTTACGATGGTAAAAAATGGCAATATGAGTTTAAGCATGAAGGAAAAAGATACCGTAAGAAAGGTTTTAG',\n",
       "       'TTTTGAGACATATTTGAATCGTTGAGAAATTTTCTAATGTTTTTGGCTATAATAATATTTCTTTCTTTGTTCATATTACTTACCTCCTTTTTTTCTTATT',\n",
       "       'TTTTCTTTAAATGCTAAAATAATTGATTTCTTTTTATCGTTCGTAAATACGAAATTTTCGTATTCATTACCTAAAAAAATATCATCATATTTAACATTAA',\n",
       "       'TTTTCGTATTGTCAACATTAAATACGTTTTTTTCGTAAAAAACTTTACTATGATATGAAAATTTCGTATAATAAGAAAAAAAGGAGGTAAGTAATATGAA',\n",
       "       'TTTTCGCATTAAAATAAGCACCTTTTGACCATTTAAGGTTATAAGGTGCTTTACTTCCAACTGTTATTTTACTTGCAGATTTACCGACTGCTTTTTGAGC',\n",
       "       'TTTTCATTTTCATTT',\n",
       "       'TTTTCAATTATAGCACTTCCATTATGATAATAGGTTTGTCTAAGATTGCTTAAAGCAGTTCCCTGCAATTCAGACTTTTTTTGTAAATCTTTTCCATTTA',\n",
       "       'TTTTCAATAAAATCTAAAACATCGCCAACTTTATCGCCAAGCCATTTGGTACCTTTACCTATTTGATCTTTTGTCCAGTTAAATGCCGATGATGCACCGG',\n",
       "       'TTTTAGTTCCTACGAATAAGACTTGTCCACCATCTTCTGAAACTTGTTTCAAGAAGTTGTATGCCTCGTCTACTTTTTTCACTGTTTTTTGTAAGTCGAT',\n",
       "       'TTTTAGGTAATGAATACGAAAATTTCGTATTTACGAACGATAAAAAGAAATCAATTATTTTAGCATTTAAAGAAAAACAAACATCTTAATAGGAGGAATA',\n",
       "       'TTTTAGCTTCAATGATAGCAGACATTCAGACACCTCCATTTAAATTTTTGGTGCTTTTTTTAAAATTAATAAAAAAGCACTTTCTACCCACGGCAAAAAG',\n",
       "       'TTTTAGCAATCCGCCAAAGTACCTAACAACGCCAAGTATTTTGCCTACAAACCATAATTGAATTAAATTCCAAATTAACTGCACAGTACCTTTCAGTATC',\n",
       "       'TTTTAGATTCTGA',\n",
       "       'TTTTAATGTTAAATATGATGATATTTTTTTAGGTAATGAATACGAAAATTTCGTATTTACGAACGATAAAAAGAAATCAATTATTTTAGCATTTAAAGAA',\n",
       "       'TTTTAAACAATTAA',\n",
       "       'TTTGTTTTTCTTTAAATGCTAAAATAATTGATTTCTTTTTATCGTTCGTAAATACGAAATTTTCGTATTCATTACCTAAAAAAATATCATCATATTTAAC',\n",
       "       'TTTGTTCTAAAACCTTTCTTACGGTATCTTTTTCCTTCATGCTTAAACTCATATTGCCATTTTTTACCATCGTAACAACGTGTTTTCATGTGTTCCCTCC',\n",
       "       'TTTGTTCATATTACTTACCTCCTTTTTTTCTTATTATACGAAATTTTCATATCATAGTAAAGTTTTTTACGAAAAAAACGTATTTAATGTTGACAATACG',\n",
       "       'TTTGTTATTCCTCCTATTAAGATGTTTGTTTTTCTTTAAATGCTAAAATAATTGATTTCTTTTTATCGTTCGTAAATACGAAATTTTCGTATTCATTACC',\n",
       "       'TTTGTAGGCAAAATACTTGGCGTTGTTAGGTACTTTGGCGGATTGCTAAAAGGTTTAATAACTATTATATGGGTTGCTATAATAGGCGTTTTCAAGAAAT',\n",
       "       'TTTGGTGCTTTTTTTAAAATTAATAAAAAAGCACTTTCTACCCACGGCAAAAAGTGCTTGAAAGATCATAGATCATCACGTTCAAGTCAATTTTAGCCTC',\n",
       "       'TTTGGGACGGCATTGTAATGATACTGAAAGGTACTGTGCAGTTAATTTGGAATTTAATTCAATTATGGTTTGTAGGCAAAATACTTGGCGTTGTTAGGTA',\n",
       "       'TTTGGCAGACATTTCATAACTTGCCAAACCTTTATATATCTAATTATCAAACTGCACTAAACTTACCAAAACCGCTTATTCTATTACCTGCCTTGTCTAC',\n",
       "       'TTTGGAATTTAATTCAATTATGGTTTGTAGGCAAAATACTTGGCGTTGTTAGGTACTTTGGCGGATTGCTAAAAGGTTTAATAACTATTATATGGGTTGC',\n",
       "       'TTTGCCGTGGGTAGAAAGTGCTTTTTTATTAATTTTAAAAAAAGCACCAAAAATTTAAATGGAGGTGTCTGAATGTCTGCTATCATTGAAGCTAAAAAAC',\n",
       "       'TTTGCCAATTTTGAGGAGGGAACACATGAAAACACGTTGTTACGATGGTAAAAAATGGCAATATGAGTTTAAGCATGAAGGAAAAAGATACCGTAAGAAA',\n",
       "       'TTTGATGAATTCGAAAAATTACTCGATAAAAACCGACTATGAATACTATATTGTAGTCAACGATTTCGAGTCTAGCAATCATTTGTCAGTAAATAAAAGT',\n",
       "       'TTTGATAAGTTTA',\n",
       "       'TTTGAGGAGGGAACACATGAAAACACGTTGTTACGATGGTAAAAAATGGCAATATGAGTTTAAGCATGAAGGAAAAAGATACCGTAAGAAAGGTTTTAGA',\n",
       "       'TTTGAGACATATTTGAATCGTTGAGAAATTTTCTAATGTTTTTGGCTATAATAATATTTCTTTCTTTGTTCATATTACTTACCTCCTTTTTTTCTTATTA',\n",
       "       'TTTGAATCGTTGAGAAATTTTCTAATGTTTTTGGCTATAATAATATTTCTTTCTTTGTTCATATTACTTACCTCCTTTTTTTCTTATTATACGAAATTTT',\n",
       "       'TTTCTTTTTATCGTTCGTAAATACGAAATTTTCGTATTCATTACCTAAAAAAATATCATCATATTTAACATTAAAAGCACTCATATACTTAGAAAGTAAA',\n",
       "       'TTTCTTTAAATGCTAAAATAATTGATTTCTTTTTATCGTTCGTAAATACGAAATTTTCGTATTCATTACCTAAAAAAATATCATCATATTTAACATTAAA',\n",
       "       'TTTCTAATGTTTTTGGCTATAATAATATTTCTTTCTTTGTTCATATTACTTACCTCCTTTTTTTCTTATTATACGAAATTTTCATATCATAGTAAAGTTT',\n",
       "       'TTTCTAAGTATATGAGTGCTTTTAATGTTAAATATGATGATATTTTTTTAGGTAATGAATACGAAAATTTCGTATTTACGAACGATAAAAAGAAATCAAT',\n",
       "       'TTTCGTTTATAGTAGCAAAATATTGATTTCCTGTACTTTTATTTACTGACAAATGATTGCTAGACTCGAAATCGTTGACTACAATATAGTATTCATAGTC',\n",
       "       'TTTCGTATTGTCAACATTAAATACGTTTTTTTCGTAAAAAACTTTACTATGATATGAAAATTTCGTATAATAAGAAAAAAAGGAGGTAAGTAATATGAAC',\n",
       "       'TTTCGCATTAAAATAAGCACCTTTTGACCATTTAAGGTTATAAGGTGCTTTACTTCCAACTGTTATTTTACTTGCAGATTTACCGACTGCTTTTTGAGCA',\n",
       "       'TTTCCTGTACT',\n",
       "       'TTTCCTGTACTTTTATTTACTGACAAATGATTGCTAGACTCGAAATCGTTGACTACAATATAGTATTCATAGTCGGTTTTTATCGAGTAATTTTTCGAAT',\n",
       "       'TTTCCATTTATTTC',\n",
       "       'TTTCATCAACTAGTTGTTTTTTAGCTTCAATGATAGCAGACATTCAGACACCTCCATTTAAATTTTTGGTGCTTTTTTTAAAATTAATAAAAAAGCACTT',\n",
       "       'TTTCAATTATAGCACTTCCATTATGATAATAGGTTTGTCTAAGATTGCTTAAAGCAGTTCCCTGCAATTCAGACTTTTTTTGTAAATCTTTTCCATTTAT',\n",
       "       'TTTCAATATTAGCTGAAGCATATGAATCGATAATAATTCGATTGTAGTCAGATGTTAAAGCGACTACACCGCCATAAGAATTGATTGTTATGCCATTCAT',\n",
       "       'TTTCAATAAAATCTAAAACATCGCCAACTTTATCGCCAAGCCATTTGGTACCTTTACCTATTTGATCTTTTGTCCAGTTAAATGCCGATGATGCACCGGA',\n",
       "       'TTTCAAGCGTCATTTCAATAAAACGCTGGTCTATCATTAAGTCGTAGCCATCGTTGTATTGAATATTAACGGGTCGTCTATTACATTCTTCGTCATAGTA',\n",
       "       'TTTCAAGCACTTTTTGCCGTGGGTAGAAAGTGCTTTTTTATTAATTTTAAAAAAAGCACCAAAAATTTAAATGGAGGTGTCTGAATGTCTGCTATCATTG',\n",
       "       'TTTATTTTCAATTATAGCACTTCCATTATGATAATAGGTTTGTCTAAGATTGCTTAAAGCAGTTCCCTGCAATTCAGACTTTTTTTGTAAATCTTTTCCA',\n",
       "       'TTTATTTATTTATGAAGGGTGTGTATTGTTATTTACCTAATTTATAGTCTAATTGTCTATTTCATCTGCATTATAAATTTTTTCATAATGGCTGCACCAT',\n",
       "       'TTTATTTACTGACAAATGATTGCTAGACTCGAAATCGTTGACTACAATATAGTATTCATAGTCGGTTTTTATCGAGTAATTTTTCGAATTCATCAAAAAT',\n",
       "       'TTTATCTATATCA',\n",
       "       'TTTATCGCCAAGCCATTTGGTACCTTTACCTATTTGATCTTTTGTCCAGTTAAATGCCGATGATGCACCGGATTTAATATCTTTCCACATAGTACCTATG',\n",
       "       'TTTATATCATCGACTTACAAAAAACAGTGAAAAAAGTAGACGAGGCATACAACTTCTTGAAACAAGTTTCAGAAGATGGTGGACAAGTCTTATTCGTAGG',\n",
       "       'TTTATAAATTTCGTTTATAGTAGCAAAATATTGATTTCCTGTACTTTTATTTACTGACAAATGATTGCTAGACTCGAAATCGTTGACTACAATATAGTAT',\n",
       "       'TTTAGTTCCTACGAATAAGACTTGTCCACCATCTTCTGAAACTTGTTTCAAGAAGTTGTATGCCTCGTCTACTTTTTTCACTGTTTTTTGTAAGTCGATG',\n",
       "       'TTTAGGTAATGAATACGAAAATTTCGTATTTACGAACGATAAAAAGAAATCAATTATTTTAGCATTTAAAGAAAAACAAACATCTTAATAGGAGGAATAA',\n",
       "       'TTTAGCTTCAATGATAGCAGACATTCAGACACCTCCATTTAAATTTTTGGTGCTTTTTTTAAAATTAATAAAAAAGCACTTTCTACCCACGGCAAAAAGT',\n",
       "       'TTTAGCATAGGTACTATGTGGAAAGATATTAAATCCGGTGCATCATCGGCATTTAACTGGACAAAAGATCAAATAGGTAAAGGTACCAAATGGCTTGGCG',\n",
       "       'TTTAGCAATCCGCCAAAGTACCTAACAACGCCAAGTATTTTGCCTACAAACCATAATTGAATTAAATTCCAAATTAACTGCACAGTACCTTTCAGTATCA',\n",
       "       'TTTACTGACAAATGATTGCTAGACTCGAAATCGTTGACTACAATATAGTATTCATAGTCGGTTTTTATCGAGTAATTTTTCGAATTCATCAAAAATTCTA',\n",
       "       'TTTACTATGATATGAAAATTTCGTATAATAAGAAAAAAAGGAGGTAAGTAATATGAACAAAGAAAGAAATATTATTATAGCCAAAAACATTAGAAAATTT',\n",
       "       'TTTACAAAAAAAGTCTGAATTGCAGGGAACTGCTTTAAGCAATCTTAGACAAACCTATTATCATAATGGAAGTGCTATAATTGAAAATAAAGAGAGTAAT',\n",
       "       'TTTAATTCAATTATGGTTTGTAGGCAAAATACTTGGCGTTGTTAGGTACTTTGGCGGATTGCTAAAAGGTTTAATAACTATTATATGGGTTGCTATAATA',\n",
       "       'TTTAATATATAAAGT',\n",
       "       'TTTAAATTTTTGGTGCTTTTTTTAAAATTAATAAAAAAGCACTTTCTACCCACGGCAAAAAGTGCTTGAAAGATCATAGATCATCACGTTCAAGTCAATT',\n",
       "       'TTTAAATGCTAAAATAATTGATTTCTTTTTATCGTTCGTAAATACGAAATTTTCGTATTCATTACCTAAAAAAATATCATCATATTTAACATTAAAAGCA',\n",
       "       'TTGTTTTTTTTATTTTACTCACCTCTAAAGCATAATTCCATATAAACTTGTTATTATCCGAAATTTTTGTATAATAGATTATTTTTGTTGGAGTAATTAT',\n",
       "       'TTGTTTTTTAGTTCCTACGAATAAGACTTGTCCACCATCTTCTGAAACTTGTTTCAAGAAGTTGTATGCCTCGTCTACTTTTTTCACTGTTTTTTGTAAG',\n",
       "       'TTGTTTTTTAGCTTCAATGATAGCAGACATTCAGACACCTCCATTTAAATTTTTGGTGCTTTTTTTAAAATTAATAAAAAAGCACTTTCTACCCACGGCA',\n",
       "       'TTGTTTTTCTTTAAATGCTAAAATAATTGATTTCTTTTTATCGTTCGTAAATACGAAATTTTCGTATTCATTACCTAAAAAAATATCATCATATTTAACA',\n",
       "       'TTGTTCTAAAACCTTTCTTACGGTATCTTTTTCCTTCATGCTTAAACTCATATTGCCATTTTTTACCATCGTAACAACGTGTTTTCATGTGTTCCCTCCT',\n",
       "       'TTGTTCATATTACTTACCTCCTTTTTTTCTTATTATACGAAATTTTCATATCATAGTAAAGTTTTTTACGAAAAAAACGTATTTAATGTTGACAATACGA',\n",
       "       'TTGTTATTCCTCCTATTAAGATGTTTGTTTTTCTTTAAATGCTAAAATAATTGATTTCTTTTTATCGTTCGTAAATACGAAATTTTCGTATTCATTACCT',\n",
       "       'TTGTGCTTGTTTTTTAGTTCCTACGAATAAGACTTGTCCACCATCTTCTGAAACTTGTTTCAAGAAGTTGTATGCCTCGTCTACTTTTTTCACTGTTTTT',\n",
       "       'TTGTGCTACTGGTATCTGTGTTTGATTTACAAAATCTTCTAATTCTTGATGGAGGTGAAAACTGTTAATTTCATGTCCAGTAATGATGATAGGCTGCTTC',\n",
       "       'TTGTATATAAATATATATC',\n",
       "       'TTGTAGGCAAAATACTTGGCGTTGTTAGGTACTTTGGCGGATTGCTAAAAGGTTTAATAACTATTATATGGGTTGCTATAATAGGCGTTTTCAAGAAATC',\n",
       "       'TTGTAATGATACTGAAAGGTACTGTGCAGTTAATTTGGAATTTAATTCAATTATGGTTTGTAGGCAAAATACTTGGCGTTGTTAGGTACTTTGGCGGATT',\n",
       "       'TTGGTGCTTTTTTTAAAATTAATAAAAAAGCACTTTCTACCCACGGCAAAAAGTGCTTGAAAGATCATAGATCATCACGTTCAAGTCAATTTTAGCCTCG',\n",
       "       'TTGGGACGGCATTGTAATGATACTGAAAGGTACTGTGCAGTTAATTTGGAATTTAATTCAATTATGGTTTGTAGGCAAAATACTTGGCGTTGTTAGGTAC',\n",
       "       'TTGGCAGACATTTCATAACTTGCCAAACCTTTATATATCTAATTATCAAACTGCACTAAACTTACCAAAACCGCTTATTCTATTACCTGCCTTGTCTACC',\n",
       "       'TTGGAGTAATT',\n",
       "       'TTGGAATTTAATTCAATTATGGTTTGTAGGCAAAATACTTGGCGTTGTTAGGTACTTTGGCGGATTGCTAAAAGGTTTAATAACTATTATATGGGTTGCT',\n",
       "       'TTGGAAGTAAAGCACCTTATAACCTTAAATGGTCAAAAGGTGCTTATTTTAATGCGAAAATCGACGGCTTAGGTGCTACTTCAGCCACTAGATACGGTGA',\n",
       "       'TTGCCAATTTTGAGGAGGGAACACATGAAAACACGTTGTTACGATGGTAAAAAATGGCAATATGAGTTTAAGCATGAAGGAAAAAGATACCGTAAGAAAG',\n",
       "       'TTGATTTCCTGTACTTTTATTTACTGACAAATGATTGCTAGACTCGAAATCGTTGACTACAATATAGTATTCATAGTCGGTTTTTATCGAGTAATTTTTC',\n",
       "       'TTGATGAATTCGAAAAATTACTCGATAAAAACCGACTATGAATACTATATTGTAGTCAACGATTTCGAGTCTAGCAATCATTTGTCAGTAAATAAAAGTA',\n",
       "       'TTGATAACGCTGC', 'TTGATAACGCTGCA',\n",
       "       'TTGAGACATATTTGAATCGTTGAGAAATTTTCTAATGTTTTTGGCTATAATAATATTTCTTTCTTTGTTCATATTACTTACCTCCTTTTTTTCTTATTAT',\n",
       "       'TTGAGAAATTTTCTAATGTTTTTGGCTATAATAATATTTCTTTCTTTGTTCATATTACTTACCTCCTTTTTTTCTTATTATACGAAATTTTCATATCATA',\n",
       "       'TTGACTTGAACGTGATGATCTATGATCTTTCAAGCACTTTTTGCCGTGGGTAGAAAGTGCTTTTTTATTAATTTTAAAAAAAGCACCAAAAATTTAAATG',\n",
       "       'TTGAATCGTTGAGAAATTTTCTAATGTTTTTGGCTATAATAATATTTCTTTCTTTGTTCATATTACTTACCTCCTTTTTTTCTTATTATACGAAATTTTC',\n",
       "       'TTGAACTTTAATTTTT',\n",
       "       'TTGAACGTGATGATCTATGATCTTTCAAGCACTTTTTGCCGTGGGTAGAAAGTGCTTTTTTATTAATTTTAAAAAAAGCACCAAAAATTTAAATGGAGGT',\n",
       "       'TTGAAAACGCCTATTATAGCAACCCATATAATAGTTATTAAACCTTTTAGCAATCCGCCAAAGTACCTAACAACGCCAAGTATTTTGCCTACAAACCATA',\n",
       "       'TTCTTTTTATCGTTCGTAAATACGAAATTTTCGTATTCATTACCTAAAAAAATATCATCATATTTAACATTAAAAGCACTCATATACTTAGAAAGTAAAC',\n",
       "       'TTCTTTTGAGACATATTTGAATCGTTGAGAAATTTTCTAATGTTTTTGGCTATAATAATATTTCTTTCTTTGTTCATATTACTTACCTCCTTTTTTTCTT',\n",
       "       'TTCTTTCTTTGTTCATATTACTTACCTCCTTTTTTTCTTATTATACGAAATTTTCATATCATAGTAAAGTTTTTTACGAAAAAAACGTATTTAATGTTGA',\n",
       "       'TTCTTGTGCTTGTTTTTTAGTTCCTACGAATAAGACTTGTCCACCATCTTCTGAAACTTGTTTCAAGAAGTTGTATGCCTCGTCTACTTTTTTCACTGTT',\n",
       "       'TTCTTGAAAACGCCTATTATAGCAACCCATATAATAGTTATTAAACCTTTTAGCAATCCGCCAAAGTACCTAACAACGCCAAGTATTTTGCCTACAAACC',\n",
       "       'TTCTCTACTTTCAATATTAGCTGAAGCATATGAATCGATAATAATTCGATTGTAGTCAGATGTTAAAGCGACTACACCGCCATAAGAATTGATTGTTATG',\n",
       "       'TTCTAAGTATATGAGTGCTTTTAATGTTAAATATGATGATATTTTTTTAGGTAATGAATACGAAAATTTCGTATTTACGAACGATAAAAAGAAATCAATT',\n",
       "       'TTCGTTTTAAACA',\n",
       "       'TTCGTTTATAGTAGCAAAATATTGATTTCCTGTACTTTTATTTACTGACAAATGATTGCTAGACTCGAAATCGTTGACTACAATATAGTATTCATAGTCG',\n",
       "       'TTCGTATTGTCAACATTAAATACGTTTTTTTCGTAAAAAACTTTACTATGATATGAAAATTTCGTATAATAAGAAAAAAAGGAGGTAAGTAATATGAACA',\n",
       "       'TTCGTATAATAAGAAAAAAAGGAGGTAAGTAATATGAACAAAGAAAGAAATATTATTATAGCCAAAAACATTAGAAAATTTCTCAACGATTCAAATATGT',\n",
       "       'TTCGGGCTAGTTTATTAAATTTATTTTTGCGCTTTCCAAATCAATGTATATGTGTTATATTGT',\n",
       "       'TTCGCATTAAAATAAGCACCTTTTGACCATTTAAGGTTATAAGGTGCTTTACTTCCAACTGTTATTTTACTTGCAGATTTACCGACTGCTTTTTGAGCAG',\n",
       "       'TTCGAAAAATTACTCGATAAAAACCGACTATGAATACTATATTGTAGTCAACGATTTCGAGTCTAGCAATCATTTGTCAGTAAATAAAAGTACAGGAAAT',\n",
       "       'TTCCTGTACTTTTATTTACTGACAAATGATTGCTAGACTCGAAATCGTTGACTACAATATAGTATTCATAGTCGGTTTTTATCGAGTAATTTTTCGAATT',\n",
       "       'TTCCTACGAATAAGACTTGTCCACCATCTTCTGAAACTTGTTTCAAGAAGTTGTATGCCTCGTCTACTTTTTTCACTGTTTTTTGTAAGTCGATGATATA',\n",
       "       'TTCCATTTATTTC',\n",
       "       'TTCCATTATGATAATAGGTTTGTCTAAGATTGCTTAAAGCAGTTCCCTGCAATTCAGACTTTTTTTGTAAATCTTTTCCATTTATTTCTTCGCTTTTCTC',\n",
       "       'TTCCAAGATTTAGCATAGGTACTATGTGGAAAGATATTAAATCCGGTGCATCATCGGCATTTAACTGGACAAAAGATCAAATAGGTAAAGGTACCAAATG',\n",
       "       'TTCATTTTACTATT',\n",
       "       'TTCATTTGTTATTCCTCCTATTAAGATGTTTGTTTTTCTTTAAATGCTAAAATAATTGATTTCTTTTTATCGTTCGTAAATACGAAATTTTCGTATTCAT',\n",
       "       'TTCATTGATGTAT',\n",
       "       'TTCATCAACTAGTTGTTTTTTAGCTTCAATGATAGCAGACATTCAGACACCTCCATTTAAATTTTTGGTGCTTTTTTTAAAATTAATAAAAAAGCACTTT',\n",
       "       'TTCATATTTCATT',\n",
       "       'TTCAGACACCTCCATTTAAATTTTTGGTGCTTTTTTTAAAATTAATAAAAAAGCACTTTCTACCCACGGCAAAAAGTGCTTGAAAGATCATAGATCATCA',\n",
       "       'TTCACGCTTTGTTCTAAAACCTTTCTTACGGTATCTTTTTCCTTCATGCTTAAACTCATATTGCCATTTTTTACCATCGTAACAACGTGTTTTCATGTGT',\n",
       "       'TTCAATTATGGTTTGTAGGCAAAATACTTGGCGTTGTTAGGTACTTTGGCGGATTGCTAAAAGGTTTAATAACTATTATATGGGTTGCTATAATAGGCGT',\n",
       "       'TTCAATTATAGCACTTCCATTATGATAATAGGTTTGTCTAAGATTGCTTAAAGCAGTTCCCTGCAATTCAGACTTTTTTTGTAAATCTTTTCCATTTATT',\n",
       "       'TTCAATGATAGCAGACATTCAGACACCTCCATTTAAATTTTTGGTGCTTTTTTTAAAATTAATAAAAAAGCACTTTCTACCCACGGCAAAAAGTGCTTGA',\n",
       "       'TTCAATATTAGCTGAAGCATATGAATCGATAATAATTCGATTGTAGTCAGATGTTAAAGCGACTACACCGCCATAAGAATTGATTGTTATGCCATTCATA',\n",
       "       'TTCAATAAAATCTAAAACATCGCCAACTTTATCGCCAAGCCATTTGGTACCTTTACCTATTTGATCTTTTGTCCAGTTAAATGCCGATGATGCACCGGAT',\n",
       "       'TTCAAGCGTCATTTCAATAAAACGCTGGTCTATCATTAAGTCGTAGCCATCGTTGTATTGAATATTAACGGGTCGTCTATTACATTCTTCGTCATAGTAG',\n",
       "       'TTCAAGCACTTTTTGCCGTGGGTAGAAAGTGCTTTTTTATTAATTTTAAAAAAAGCACCAAAAATTTAAATGGAGGTGTCTGAATGTCTGCTATCATTGA',\n",
       "       'TTATTTTCAATTATAGCACTTCCATTATGATAATAGGTTTGTCTAAGATTGCTTAAAGCAGTTCCCTGCAATTCAGACTTTTTTTGTAAATCTTTTCCAT',\n",
       "       'TTATTTTATTACTA', 'TTATTTGCGACT',\n",
       "       'TTATTTATTTATTTATGAAGGGTGTGTATTGTTATTTACCTAATTTATAGTCTAATTGTCTATTTCATCTGCATTATAAATTTTTTCATAATGGCTGCAC',\n",
       "       'TTATTTACTGACAAATGATTGCTAGACTCGAAATCGTTGACTACAATATAGTATTCATAGTCGGTTTTTATCGAGTAATTTTTCGAATTCATCAAAAATT',\n",
       "       'TTATGGTTTGTAGGCAAAATACTTGGCGTTGTTAGGTACTTTGGCGGATTGCTAAAAGGTTTAATAACTATTATATGGGTTGCTATAATAGGCGTTTTCA',\n",
       "       'TTATCTTCATATTTC',\n",
       "       'TTATCGCCAAGCCATTTGGTACCTTTACCTATTTGATCTTTTGTCCAGTTAAATGCCGATGATGCACCGGATTTAATATCTTTCCACATAGTACCTATGC',\n",
       "       'TTATCGAGTAATT', 'TTATCCGAAATTT',\n",
       "       'TTATCACCGTATCTAGTGGCTGAAGTAGCACCTAAGCCGTCGATTTTCGCATTAAAATAAGCACCTTTTGACCATTTAAGGTTATAAGGTGCTTTACTTC',\n",
       "       'TTATCAATAGGT',\n",
       "       'TTATATCATCGACTTACAAAAAACAGTGAAAAAAGTAGACGAGGCATACAACTTCTTGAAACAAGTTTCAGAAGATGGTGGACAAGTCTTATTCGTAGGA',\n",
       "       'TTATAGTAGCAAAATATTGATTTCCTGTACTTTTATTTACTGACAAATGATTGCTAGACTCGAAATCGTTGACTACAATATAGTATTCATAGTCGGTTTT',\n",
       "       'TTATAGCACTTCCATTATGATAATAGGTTTGTCTAAGATTGCTTAAAGCAGTTCCCTGCAATTCAGACTTTTTTTGTAAATCTTTTCCATTTATTTCTTC',\n",
       "       'TTATAGCAACCCATATAATAGTTATTAAACCTTTTAGCAATCCGCCAAAGTACCTAACAACGCCAAGTATTTTGCCTACAAACCATAATTGAATTAAATT',\n",
       "       'TTATACAAAAATTTCGGATAATAACAAGTTTATATGGAATTATGCTTTAGAGGTGAGTAAAATAAAAAAAACAACATTTATACTACTTTCATTTATTGCC',\n",
       "       'TTATAAATTTCGTTTATAGTAGCAAAATATTGATTTCCTGTACTTTTATTTACTGACAAATGATTGCTAGACTCGAAATCGTTGACTACAATATAGTATT',\n",
       "       'TTAGTTCTGTAT',\n",
       "       'TTAGTTCCTACGAATAAGACTTGTCCACCATCTTCTGAAACTTGTTTCAAGAAGTTGTATGCCTCGTCTACTTTTTTCACTGTTTTTTGTAAGTCGATGA',\n",
       "       'TTAGTACGATTATCACCGTATCTAGTGGCTGAAGTAGCACCTAAGCCGTCGATTTTCGCATTAAAATAAGCACCTTTTGACCATTTAAGGTTATAAGGTG',\n",
       "       'TTAGGTAATGAATACGAAAATTTCGTATTTACGAACGATAAAAAGAAATCAATTATTTTAGCATTTAAAGAAAAACAAACATCTTAATAGGAGGAATAAC',\n",
       "       'TTAGGGCAATAAATGAAAGTAGTATAAATGTTGTTTTTTTTATTTTACTCACCTCTAAAGCATAATTCCATATAAACTTGTTATTATCCGAAATTTTTGT',\n",
       "       'TTAGCTTCAATGATAGCAGACATTCAGACACCTCCATTTAAATTTTTGGTGCTTTTTTTAAAATTAATAAAAAAGCACTTTCTACCCACGGCAAAAAGTG',\n",
       "       'TTAGCGTTTTCC',\n",
       "       'TTAGCATAGGTACTATGTGGAAAGATATTAAATCCGGTGCATCATCGGCATTTAACTGGACAAAAGATCAAATAGGTAAAGGTACCAAATGGCTTGGCGA',\n",
       "       'TTAGCAGTCGCATTTACAATTGCTTATAAGAAATCTGAAACATTTAGAAATTTTGTTAATGG',\n",
       "       'TTAGCAATCCGCCAAAGTACCTAACAACGCCAAGTATTTTGCCTACAAACCATAATTGAATTAAATTCCAAATTAACTGCACAGTACCTTTCAGTATCAT',\n",
       "       'TTACTTTCTAAGTATATGAGTGCTTTTAATGTTAAATATGATGATATTTTTTTAGGTAATGAATACGAAAATTTCGTATTTACGAACGATAAAAAGAAAT',\n",
       "       'TTACTTACCTCCTTTTTTTCTTATTATACGAAATTTTCATATCATAGTAAAGTTTTTTACGAAAAAAACGTATTTAATGTTGACAATACGAAAATTTCGT',\n",
       "       'TTACTGACAAATGATTGCTAGACTCGAAATCGTTGACTACAATATAGTATTCATAGTCGGTTTTTATCGAGTAATTTTTCGAATTCATCAAAAATTCTAT',\n",
       "       'TTACTCTCTTTATTTTCAATTATAGCACTTCCATTATGATAATAGGTTTGTCTAAGATTGCTTAAAGCAGTTCCCTGCAATTCAGACTTTTTTTGTAAAT',\n",
       "       'TTACTCGATAAAAACCGACTATGAATACTATATTGTAGTCAACGATTTCGAGTCTAGCAATCATTTGTCAGTAAATAAAAGTACAGGAAATCAATATTTT',\n",
       "       'TTACTCCAACAAAAATAATCTATTATACAAAAATTTCGGATAATAACAAGTTTATATGGAATTATGCTTTAGAGGTGAGTAAAATAAAAAAAACAACATT',\n",
       "       'TTACTACTATGACGAAGAATGTAATAGACGACCCGTTAATATTCAATACAACGATGGCTACGACTTAATGATAGACCAGCGTTTTATTGAAATGACGCTT',\n",
       "       'TTACCTCCTTTTTTTCTTATTATACGAAATTTTCATATCATAGTAAAGTTTTTTACGAAAAAAACGTATTTAATGTTGACAATACGAAAATTTCGTATTA',\n",
       "       'TTACATTATGCA',\n",
       "       'TTACAAAAAACAGTGAAAAAAGTAGACGAGGCATACAACTTCTTGAAACAAGTTTCAGAAGATGGTGGACAAGTCTTATTCGTAGGAACTAAAAAACAAG',\n",
       "       'TTACAAAAAAAGTCTGAATTGCAGGGAACTGCTTTAAGCAATCTTAGACAAACCTATTATCATAATGGAAGTGCTATAATTGAAAATAAAGAGAGTAATG',\n",
       "       'TTAATTTGGAATTTAATTCAATTATGGTTTGTAGGCAAAATACTTGGCGTTGTTAGGTACTTTGGCGGATTGCTAAAAGGTTTAATAACTATTATATGGG',\n",
       "       'TTAATTCAATTATGGTTTGTAGGCAAAATACTTGGCGTTGTTAGGTACTTTGGCGGATTGCTAAAAGGTTTAATAACTATTATATGGGTTGCTATAATAG',\n",
       "       'TTAATCTCCGC', 'TTAATCTCCGCTT', 'TTAATATATAAAGT',\n",
       "       'TTAAGATGTTTGTTTTTCTTTAAATGCTAAAATAATTGATTTCTTTTTATCGTTCGTAAATACGAAATTTTCGTATTCATTACCTAAAAAAATATCATCA',\n",
       "       'TTAAATTTTTGGTGCTTTTTTTAAAATTAATAAAAAAGCACTTTCTACCCACGGCAAAAAGTGCTTGAAAGATCATAGATCATCACGTTCAAGTCAATTT',\n",
       "       'TTAAATGCTAAAATAATTGATTTCTTTTTATCGTTCGTAAATACGAAATTTTCGTATTCATTACCTAAAAAAATATCATCATATTTAACATTAAAAGCAC',\n",
       "       'TTAAATGCGGATGTCTTTCAAGCGTCATTTCAATAAAACGCTGGTCTATCATTAAGTCGTAGCCATCGTTGTATTGAATATTAACGGGTCGTCTATTACA',\n",
       "       'TTAAATATGATGATATTTTTTTAGGTAATGAATACGAAAATTTCGTATTTACGAACGATAAAAAGAAATCAATTATTTTAGCATTTAAAGAAAAACAAAC',\n",
       "       'TTAAACCTTTTAGCAATCCGCCAAAGTACCTAACAACGCCAAGTATTTTGCCTACAAACCATAATTGAATTAAATTCCAAATTAACTGCACAGTACCTTT',\n",
       "       'TTAAAACACTTCTTT',\n",
       "       'TGTTTTTTTTATTTTACTCACCTCTAAAGCATAATTCCATATAAACTTGTTATTATCCGAAATTTTTGTATAATAGATTATTTTTGTTGGAGTAATTATT',\n",
       "       'TGTTTTTTAGTTCCTACGAATAAGACTTGTCCACCATCTTCTGAAACTTGTTTCAAGAAGTTGTATGCCTCGTCTACTTTTTTCACTGTTTTTTGTAAGT',\n",
       "       'TGTTTTTGGCTATAATAATATTTCTTTCTTTGTTCATATTACTTACCTCCTTTTTTTCTTATTATACGAAATTTTCATATCATAGTAAAGTTTTTTACGA',\n",
       "       'TGTTTTTCTTTAAATGCTAAAATAATTGATTTCTTTTTATCGTTCGTAAATACGAAATTTTCGTATTCATTACCTAAAAAAATATCATCATATTTAACAT',\n",
       "       'TGTTTGTTTTTCTTTAAATGCTAAAATAATTGATTTCTTTTTATCGTTCGTAAATACGAAATTTTCGTATTCATTACCTAAAAAAATATCATCATATTTA',\n",
       "       'TGTTGTTTTTTTTATTTTACTCACCTCTAAAGCATAATTCCATATAAACTTGTTATTATCCGAAATTTTTGTATAATAGATTATTTTTGTTGGAGTAATT',\n",
       "       'TGTTCTAAAACCTTTCTTACGGTATCTTTTTCCTTCATGCTTAAACTCATATTGCCATTTTTTACCATCGTAACAACGTGTTTTCATGTGTTCCCTCCTC',\n",
       "       'TGTTCCCTCCTC',\n",
       "       'TGTTCATTTGTTATTCCTCCTATTAAGATGTTTGTTTTTCTTTAAATGCTAAAATAATTGATTTCTTTTTATCGTTCGTAAATACGAAATTTTCGTATTC',\n",
       "       'TGTTATTCCTCCTATTAAGATGTTTGTTTTTCTTTAAATGCTAAAATAATTGATTTCTTTTTATCGTTCGTAAATACGAAATTTTCGTATTCATTACCTA',\n",
       "       'TGTTAAAACAAGATGCGAATGATATTGGCTTTGCTAAATTACTACAAAATGAGAATAATCGTATGAGTTATAACGAGTTAATGA',\n",
       "       'TGTGCTTGTTTTTTAGTTCCTACGAATAAGACTTGTCCACCATCTTCTGAAACTTGTTTCAAGAAGTTGTATGCCTCGTCTACTTTTTTCACTGTTTTTT',\n",
       "       'TGTGCTACTGGTATCTGTGTTTGATTTACAAAATCTTCTAATTCTTGATGGAGGTGAAAACTGTTAATTTCATGTCCAGTAATGATGATAGGCTGCTTCG',\n",
       "       'TGTCTTTCAAGCGTCATTTCAATAAAACGCTGGTCTATCATTAAGTCGTAGCCATCGTTGTATTGAATATTAACGGGTCGTCTATTACATTCTTCGTCAT',\n",
       "       'TGTATTGCTCCT',\n",
       "       'TGTAGGCAAAATACTTGGCGTTGTTAGGTACTTTGGCGGATTGCTAAAAGGTTTAATAACTATTATATGGGTTGCTATAATAGGCGTTTTCAAGAAATCA',\n",
       "       'TGTAATGATACTGAAAGGTACTGTGCAGTTAATTTGGAATTTAATTCAATTATGGTTTGTAGGCAAAATACTTGGCGTTGTTAGGTACTTTGGCGGATTG',\n",
       "       'TGTAATAGACGACC',\n",
       "       'TGGTGCTTTTTTTAAAATTAATAAAAAAGCACTTTCTACCCACGGCAAAAAGTGCTTGAAAGATCATAGATCATCACGTTCAAGTCAATTTTAGCCTCGG',\n",
       "       'TGGTGCAGCCATTATGAAAAAATTTATAATGCAGATGAAATAGACAATTAGACTATAAATTAGGTAAATAACAATACACACCCTTCATAAATAAATAAAT',\n",
       "       'TGGGACGGCATTGTAATGATACTGAAAGGTACTGTGCAGTTAATTTGGAATTTAATTCAATTATGGTTTGTAGGCAAAATACTTGGCGTTGTTAGGTACT',\n",
       "       'TGGCTGAAGTAGCACCTAAGCCGTCGATTTTCGCATTAAAATAAGCACCTTTTGACCATTTAAGGTTATAAGGTGCTTTACTTCCAACTGTTATTTTACT',\n",
       "       'TGGCGAGGCGTTTGGGACGGCATTGTAATGATACTGAAAGGTACTGTGCAGTTAATTTGGAATTTAATTCAATTATGGTTTGTAGGCAAAATACTTGGCG',\n",
       "       'TGGCATAACAATCAATTCTTATGGCGGTGTAGTCGCTTTAACATCTGACTACAATCGAATTATTATCGATTCATATGCTTCAGCTAATATTGAAAGTAGA',\n",
       "       'TGGCAGACATTTCATAACTTGCCAAACCTTTATATATCTAATTATCAAACTGCACTAAACTTACCAAAACCGCTTATTCTATTACCTGCCTTGTCTACCT',\n",
       "       'TGGATTTTCAATAAAATCTAAAACATCGCCAACTTTATCGCCAAGCCATTTGGTACCTTTACCTATTTGATCTTTTGTCCAGTTAAATGCCGATGATGCA',\n",
       "       'TGGATTTATATGG', 'TGGAGTAATTATTAGT',\n",
       "       'TGGAATTTAATTCAATTATGGTTTGTAGGCAAAATACTTGGCGTTGTTAGGTACTTTGGCGGATTGCTAAAAGGTTTAATAACTATTATATGGGTTGCTA',\n",
       "       'TGGAAGTAAAGCACCTTATAACCTTAAATGGTCAAAAGGTGCTTATTTTAATGCGAAAATCGACGGCTTAGGTGCTACTTCAGCCACTAGATACGGTGAT',\n",
       "       'TGCTTTTTTTAAAATTAATAAAAAAGCACTTTCTACCCACGGCAAAAAGTGCTTGAAAGATCATAGATCATCACGTTCAAGTCAATTTTAGCCTCGGCAG',\n",
       "       'TGCTTTTTTATTAATTTTAAAAAAAGCACCAAAAATTTAAATGGAGGTGTCTGAATGTCTGCTATCATTGAAGCTAAAAAACAACTAGTTGATGAAATTG',\n",
       "       'TGCTTGTTTTTTAGTTCCTACGAATAAGACTTGTCCACCATCTTCTGAAACTTGTTTCAAGAAGTTGTATGCCTCGTCTACTTTTTTCACTGTTTTTTGT',\n",
       "       'TGCTAAAATAATTGATTTCTTTTTATCGTTCGTAAATACGAAATTTTCGTATTCATTACCTAAAAAAATATCATCATATTTAACATTAAAAGCACTCATA',\n",
       "       'TGCGGATGTCTTTCAAGCGTCATTTCAATAAAACGCTGGTCTATCATTAAGTCGTAGCCATCGTTGTATTGAATATTAACGGGTCGTCTATTACATTCTT',\n",
       "       'TGCCGAGGCTAAAATTGACTTGAACGTGATGATCTATGATCTTTCAAGCACTTTTTGCCGTGGGTAGAAAGTGCTTTTTTATTAATTTTAAAAAAAGCAC',\n",
       "       'TGCCAGGATA',\n",
       "       'TGCCAATTTTGAGGAGGGAACACATGAAAACACGTTGTTACGATGGTAAAAAATGGCAATATGAGTTTAAGCATGAAGGAAAAAGATACCGTAAGAAAGG',\n",
       "       'TGCAGTTAATTTGGAATTTAATTCAATTATGGTTTGTAGGCAAAATACTTGGCGTTGTTAGGTACTTTGGCGGATTGCTAAAAGGTTTAATAACTATTAT',\n",
       "       'TGCAAGTAAAATAACAGTTGGAAGTAAAGCACCTTATAACCTTAAATGGTCAAAAGGTGCTTATTTTAATGCGAAAATCGACGGCTTAGGTGCTACTTCA',\n",
       "       'TGATTTCTTTTTATCGTTCGTAAATACGAAATTTTCGTATTCATTACCTAAAAAAATATCATCATATTTAACATTAAAAGCACTCATATACTTAGAAAGT',\n",
       "       'TGATTTCCTGTACTTTTATTTACTGACAAATGATTGCTAGACTCGAAATCGTTGACTACAATATAGTATTCATAGTCGGTTTTTATCGAGTAATTTTTCG',\n",
       "       'TGATTCTTGTGCTTGTTTTTTAGTTCCTACGAATAAGACTTGTCCACCATCTTCTGAAACTTGTTTCAAGAAGTTGTATGCCTCGTCTACTTTTTTCACT',\n",
       "       'TGATTAATAGCGCCTATGTGGCGCTTTAATATA',\n",
       "       'TGATGAATTCGAAAAATTACTCGATAAAAACCGACTATGAATACTATATTGTAGTCAACGATTTCGAGTCTAGCAATCATTTGTCAGTAAATAAAAGTAC',\n",
       "       'TGATCTTTCAAGCACTTTTTGCCGTGGGTAGAAAGTGCTTTTTTATTAATTTTAAAAAAAGCACCAAAAATTTAAATGGAGGTGTCTGAATGTCTGCTAT',\n",
       "       'TGATCTATGATCTTTCAAGCACTTTTTGCCGTGGGTAGAAAGTGCTTTTTTATTAATTTTAAAAAAAGCACCAAAAATTTAAATGGAGGTGTCTGAATGT',\n",
       "       'TGATATTTTTTTAGGTAATGAATACGAAAATTTCGTATTTACGAACGATAAAAAGAAATCAATTATTTTAGCATTTAAAGAAAAACAAACATCTTAATAG',\n",
       "       'TGATATGAAAATTTCGTATAATAAGAAAAAAAGGAGGTAAGTAATATGAACAAAGAAAGAAATATTATTATAGCCAAAAACATTAGAAAATTTCTCAACG',\n",
       "       'TGATAGCAGACATTCAGACACCTCCATTTAAATTTTTGGTGCTTTTTTTAAAATTAATAAAAAAGCACTTTCTACCCACGGCAAAAAGTGCTTGAAAGAT',\n",
       "       'TGATAAGTTTAG',\n",
       "       'TGAGTTTAAGCATGAAGGAAAAAGATACCGTAAGAAAGGTTTTAGAACAAAGCGTGAAGCTAATTCTGCTGGACTAGACAAGTTAAATGAGTTAAGAAGT',\n",
       "       'TGAGTGCTTTTAATGTTAAATATGATGATATTTTTTTAGGTAATGAATACGAAAATTTCGTATTTACGAACGATAAAAAGAAATCAATTATTTTAGCATT',\n",
       "       'TGAGGAGGGAACACATGAAAACACGTTGTTACGATGGTAAAAAATGGCAATATGAGTTTAAGCATGAAGGAAAAAGATACCGTAAGAAAGGTTTTAGAAC',\n",
       "       'TGAGACATATTTGAATCGTTGAGAAATTTTCTAATGTTTTTGGCTATAATAATATTTCTTTCTTTGTTCATATTACTTACCTCCTTTTTTTCTTATTATA',\n",
       "       'TGAGAAATTTTCTAATGTTTTTGGCTATAATAATATTTCTTTCTTTGTTCATATTACTTACCTCCTTTTTTTCTTATTATACGAAATTTTCATATCATAG',\n",
       "       'TGACTTGAACGTGATGATCTATGATCTTTCAAGCACTTTTTGCCGTGGGTAGAAAGTGCTTTTTTATTAATTTTAAAAAAAGCACCAAAAATTTAAATGG',\n",
       "       'TGACTACAATATA',\n",
       "       'TGACGAAGAATGTAATAGACGACCCGTTAATATTCAATACAACGATGGCTACGACTTAATGATAGACCAGCGTTTTATTGAAATGACGCTTGAAAGACAT',\n",
       "       'TGACCGTGTCT',\n",
       "       'TGAATTCGAAAAATTACTCGATAAAAACCGACTATGAATACTATATTGTAGTCAACGATTTCGAGTCTAGCAATCATTTGTCAGTAAATAAAAGTACAGG',\n",
       "       'TGAATGTTGTCCGCTTGAACCAAAGTAATGACTTAATGCGTCTTTTGAAAAATGGTCATTAAAGGCATCAGATTGCTTAAAGTCTTCGTA',\n",
       "       'TGAATGGCATAACAATCAATTCTTATGGCGGTGTAGTCGCTTTAACATCTGACTACAATCGAATTATTATCGATTCATATGCTTCAGCTAATATTGAAAG',\n",
       "       'TGAATACTATATTGTAGTCAACGATTTCGAGTCTAGCAATCATTTGTCAGTAAATAAAAGTACAGGAAATCAATATTTTGCTACTATAAACGAAATTTAT',\n",
       "       'TGAATACGAAAATTTCGTATTTACGAACGATAAAAAGAAATCAATTATTTTAGCATTTAAAGAAAAACAAACATCTTAATAGGAGGAATAACAAATGAAC',\n",
       "       'TGAACGTGATGATCTATGATCTTTCAAGCACTTTTTGCCGTGGGTAGAAAGTGCTTTTTTATTAATTTTAAAAAAAGCACCAAAAATTTAAATGGAGGTG',\n",
       "       'TGAAAGTAGTATAAATGTTGTTTTTTTTATTTTACTCACCTCTAAAGCATAATTCCATATAAACTTGTTATTATCCGAAATTTTTGTATAATAGATTATT',\n",
       "       'TGAAAGGTACTGTGCAGTTAATTTGGAATTTAATTCAATTATGGTTTGTAGGCAAAATACTTGGCGTTGTTAGGTACTTTGGCGGATTGCTAAAAGGTTT',\n",
       "       'TGAAAAAAGTAGACGAGGCATACAACTTCTTGAAACAAGTTTCAGAAGATGGTGGACAAGTCTTATTCGTAGGAACTAAAAAACAAGCACAAGAATCAGT',\n",
       "       'TCTTTTTATCGTTCGTAAATACGAAATTTTCGTATTCATTACCTAAAAAAATATCATCATATTTAACATTAAAAGCACTCATATACTTAGAAAGTAAACT',\n",
       "       'TCTTTGTTCATATTACTTACCTCCTTTTTTTCTTATTATACGAAATTTTCATATCATAGTAAAGTTTTTTACGAAAAAAACGTATTTAATGTTGACAATA',\n",
       "       'TCTTTCTTTGTTCATATTACTTACCTCCTTTTTTTCTTATTATACGAAATTTTCATATCATAGTAAAGTTTTTTACGAAAAAAACGTATTTAATGTTGAC',\n",
       "       'TCTTTCAAGCGTCATTTCAATAAAACGCTGGTCTATCATTAAGTCGTAGCCATCGTTGTATTGAATATTAACGGGTCGTCTATTACATTCTTCGTCATAG',\n",
       "       'TCTTTCAAGCACTTTTTGCCGTGGGTAGAAAGTGCTTTTTTATTAATTTTAAAAAAAGCACCAAAAATTTAAATGGAGGTGTCTGAATGTCTGCTATCAT',\n",
       "       'TCTTTATTTTCAATTATAGCACTTCCATTATGATAATAGGTTTGTCTAAGATTGCTTAAAGCAGTTCCCTGCAATTCAGACTTTTTTTGTAAATCTTTTC',\n",
       "       'TCTTTAAATGCTAAAATAATTGATTTCTTTTTATCGTTCGTAAATACGAAATTTTCGTATTCATTACCTAAAAAAATATCATCATATTTAACATTAAAAG',\n",
       "       'TCTTGTGCTTGTTTTTTAGTTCCTACGAATAAGACTTGTCCACCATCTTCTGAAACTTGTTTCAAGAAGTTGTATGCCTCGTCTACTTTTTTCACTGTTT',\n",
       "       'TCTGCAAGTAAAATAACAGTTGGAAGTAAAGCACCTTATAACCTTAAATGGTCAAAAGGTGCTTATTTTAATGCGAAAATCGACGGCTTAGGTGCTACTT',\n",
       "       'TCTGAGTCTCT',\n",
       "       'TCTCTTTATTTTCAATTATAGCACTTCCATTATGATAATAGGTTTGTCTAAGATTGCTTAAAGCAGTTCCCTGCAATTCAGACTTTTTTTGTAAATCTTT',\n",
       "       'TCTCTACTTTCAATATTAGCTGAAGCATATGAATCGATAATAATTCGATTGTAGTCAGATGTTAAAGCGACTACACCGCCATAAGAATTGATTGTTATGC',\n",
       "       'TCTCCTCTGA', 'TCTATTATACAT',\n",
       "       'TCTATTATACAAAAATTTCGGATAATAACAAGTTTATATGGAATTATGCTTTAGAGGTGAGTAAAATAAAAAAAACAACATTTATACTACTTTCATTTAT',\n",
       "       'TCTATGATCTTTCAAGCACTTTTTGCCGTGGGTAGAAAGTGCTTTTTTATTAATTTTAAAAAAAGCACCAAAAATTTAAATGGAGGTGTCTGAATGTCTG',\n",
       "       'TCTAGTGGCTGAAGTAGCACCTAAGCCGTCGATTTTCGCATTAAAATAAGCACCTTTTGACCATTTAAGGTTATAAGGTGCTTTACTTCCAACTGTTATT',\n",
       "       'TCTAATGTTTTTGGCTATAATAATATTTCTTTCTTTGTTCATATTACTTACCTCCTTTTTTTCTTATTATACGAAATTTTCATATCATAGTAAAGTTTTT',\n",
       "       'TCTAAGTATATGAGTGCTTTTAATGTTAAATATGATGATATTTTTTTAGGTAATGAATACGAAAATTTCGTATTTACGAACGATAAAAAGAAATCAATTA',\n",
       "       'TCTAAACGAAAAT', 'TCTAAACATTCT', 'TCTAAAAGAAC',\n",
       "       'TCGTTTATAGTAGCAAAATATTGATTTCCTGTACTTTTATTTACTGACAAATGATTGCTAGACTCGAAATCGTTGACTACAATATAGTATTCATAGTCGG',\n",
       "       'TCGTTGAGAAATTTTCTAATGTTTTTGGCTATAATAATATTTCTTTCTTTGTTCATATTACTTACCTCCTTTTTTTCTTATTATACGAAATTTTCATATC',\n",
       "       'TCGTGGTTTTAC',\n",
       "       'TCGGTAAATCTGCAAGTAAAATAACAGTTGGAAGTAAAGCACCTTATAACCTTAAATGGTCAAAAGGTGCTTATTTTAATGCGAAAATCGACGGCTTAGG',\n",
       "       'TCGGGTAGCTCGCCTACCCTTATTATTTTTTGCCAATTTTGAGGAGGGAAC',\n",
       "       'TCGCATTAAAATAAGCACCTTTTGACCATTTAAGGTTATAAGGTGCTTTACTTCCAACTGTTATTTTACTTGCAGATTTACCGACTGCTTTTTGAGCAGG',\n",
       "       'TCGCAATCTGG',\n",
       "       'TCGATTTTCGCATTAAAATAAGCACCTTTTGACCATTTAAGGTTATAAGGTGCTTTACTTCCAACTGTTATTTTACTTGCAGATTTACCGACTGCTTTTT',\n",
       "       'TCGATAAAAACCGACTATGAATACTATATTGTAGTCAACGATTTCGAGTCTAGCAATCATTTGTCAGTAAATAAAAGTACAGGAAATCAATATTTTGCTA',\n",
       "       'TCGAGTTAATGA',\n",
       "       'TCGAAAAATTACTCGATAAAAACCGACTATGAATACTATATTGTAGTCAACGATTTCGAGTCTAGCAATCATTTGTCAGTAAATAAAAGTACAGGAAATC',\n",
       "       'TCCTGTACTTT', 'TCCTGTACTTTT',\n",
       "       'TCCTGTACTTTTATTTACTGACAAATGATTGCTAGACTCGAAATCGTTGACTACAATATAGTATTCATAGTCGGTTTTTATCGAGTAATTTTTCGAATTC',\n",
       "       'TCCTGGCAATTG',\n",
       "       'TCCTGCCGAGGCTAAAATTGACTTGAACGTGATGATCTATGATCTTTCAAGCACTTTTTGCCGTGGGTAGAAAGTGCTTTTTTATTAATTTTAAAAAAAG',\n",
       "       'TCCTATTAAGATGTTTGTTTTTCTTTAAATGCTAAAATAATTGATTTCTTTTTATCGTTCGTAAATACGAAATTTTCGTATTCATTACCTAAAAAAATAT',\n",
       "       'TCCGCCAAAGTACCTAACAACGCCAAGTATTTTGCCTACAAACCATAATTGAATTAAATTCCAAATTAACTGCACAGTACCTTTCAGTATCATTACAATG',\n",
       "       'TCCATTTAAATTTTTGGTGCTTTTTTTAAAATTAATAAAAAAGCACTTTCTACCCACGGCAAAAAGTGCTTGAAAGATCATAGATCATCACGTTCAAGTC',\n",
       "       'TCCAAGATTTAGCATAGGTACTATGTGGAAAGATATTAAATCCGGTGCATCATCGGCATTTAACTGGACAAAAGATCAAATAGGTAAAGGTACCAAATGG',\n",
       "       'TCCAACAAAAATAATCTATTATACAAAAATTTCGGATAATAACAAGTTTATATGGAATTATGCTTTAGAGGTGAGTAAAATAAAAAAAACAACATTTATA',\n",
       "       'TCATTTGTTATTCCTCCTATTAAGATGTTTGTTTTTCTTTAAATGCTAAAATAATTGATTTCTTTTTATCGTTCGTAAATACGAAATTTTCGTATTCATT',\n",
       "       'TCATTCAAATGAC',\n",
       "       'TCATTACTCTCTTTATTTTCAATTATAGCACTTCCATTATGATAATAGGTTTGTCTAAGATTGCTTAAAGCAGTTCCCTGCAATTCAGACTTTTTTTGTA',\n",
       "       'TCATCAATAATAAT',\n",
       "       'TCATCAACTAGTTGTTTTTTAGCTTCAATGATAGCAGACATTCAGACACCTCCATTTAAATTTTTGGTGCTTTTTTTAAAATTAATAAAAAAGCACTTTC',\n",
       "       'TCAGACACCTCCATTTAAATTTTTGGTGCTTTTTTTAAAATTAATAAAAAAGCACTTTCTACCCACGGCAAAAAGTGCTTGAAAGATCATAGATCATCAC',\n",
       "       'TCACGCTTTGTTCTAAAACCTTTCTTACGGTATCTTTTTCCTTCATGCTTAAACTCATATTGCCATTTTTTACCATCGTAACAACGTGTTTTCATGTGTT',\n",
       "       'TCAATTATGGTTTGTAGGCAAAATACTTGGCGTTGTTAGGTACTTTGGCGGATTGCTAAAAGGTTTAATAACTATTATATGGGTTGCTATAATAGGCGTT',\n",
       "       'TCAATTATAGCACTTCCATTATGATAATAGGTTTGTCTAAGATTGCTTAAAGCAGTTCCCTGCAATTCAGACTTTTTTTGTAAATCTTTTCCATTTATTT',\n",
       "       'TCAATATTAGCTGAAGCATATGAATCGATAATAATTCGATTGTAGTCAGATGTTAAAGCGACTACACCGCCATAAGAATTGATTGTTATGCCATTCATAC',\n",
       "       'TCAATAAAATCTAAAACATCGCCAACTTTATCGCCAAGCCATTTGGTACCTTTACCTATTTGATCTTTTGTCCAGTTAAATGCCGATGATGCACCGGATT',\n",
       "       'TCAAGCGTCATTTCAATAAAACGCTGGTCTATCATTAAGTCGTAGCCATCGTTGTATTGAATATTAACGGGTCGTCTATTACATTCTTCGTCATAGTAGT',\n",
       "       'TCAACTTAGTTA',\n",
       "       'TCAACTAGTTGTTTTTTAGCTTCAATGATAGCAGACATTCAGACACCTCCATTTAAATTTTTGGTGCTTTTTTTAAAATTAATAAAAAAGCACTTTCTAC',\n",
       "       'TCAAAAAGCAGTCGGTAAATCTGCAAGTAAAATAACAGTTGGAAGTAAAGCACCTTATAACCTTAAATGGTCAAAAGGTGCTTATTTTAATGCGAAAATC',\n",
       "       'TATTTTTTTAGGTAATGAATACGAAAATTTCGTATTTACGAACGATAAAAAGAAATCAATTATTTTAGCATTTAAAGAAAAACAAACATCTTAATAGGAG',\n",
       "       'TATTTTGTCACT',\n",
       "       'TATTTTGCCTACAAACCATAATTGAATTAAATTCCAAATTAACTGCACAGTACCTTTCAGTATCATTACAATGCCGTCCCAAACGCCTCGCCAGTTTCCT',\n",
       "       'TATTTTCAATTATAGCACTTCCATTATGATAATAGGTTTGTCTAAGATTGCTTAAAGCAGTTCCCTGCAATTCAGACTTTTTTTGTAAATCTTTTCCATT',\n",
       "       'TATTTGAATCGTTGAGAAATTTTCTAATGTTTTTGGCTATAATAATATTTCTTTCTTTGTTCATATTACTTACCTCCTTTTTTTCTTATTATACGAAATT',\n",
       "       'TATTTCTTTCTTTGTTCATATTACTTACCTCCTTTTTTTCTTATTATACGAAATTTTCATATCATAGTAAAGTTTTTTACGAAAAAAACGTATTTAATGT',\n",
       "       'TATTTATTTATTTATGAAGGGTGTGTATTGTTATTTACCTAATTTATAGTCTAATTGTCTATTTCATCTGCATTATAAATTTTTTCATAATGGCTGCACC',\n",
       "       'TATTTATATCATCGACTTACAAAAAACAGTGAAAAAAGTAGACGAGGCATACAACTTCTTGAAACAAGTTTCAGAAGATGGTGGACAAGTCTTATTCGTA',\n",
       "       'TATTTACTGACAAATGATTGCTAGACTCGAAATCGTTGACTACAATATAGTATTCATAGTCGGTTTTTATCGAGTAATTTTTCGAATTCATCAAAAATTC',\n",
       "       'TATTGCTCCTTTT',\n",
       "       'TATTGATTTCCTGTACTTTTATTTACTGACAAATGATTGCTAGACTCGAAATCGTTGACTACAATATAGTATTCATAGTCGGTTTTTATCGAGTAATTTT',\n",
       "       'TATTGATTAATAGCGCCTATGTGGCG',\n",
       "       'TATTATACAAAAATTTCGGATAATAACAAGTTTATATGGAATTATGCTTTAGAGGTGAGTAAAATAAAAAAAACAACATTTATACTACTTTCATTTATTG',\n",
       "       'TATTACTTACCTCCTTTTTTTCTTATTATACGAAATTTTCATATCATAGTAAAGTTTTTTACGAAAAAAACGTATTTAATGTTGACAATACGAAAATTTC',\n",
       "       'TATTACTACTATGACGAAGAATGTAATAGACGACCCGTTAATATTCAATACAACGATGGCTACGACTTAATGATAGACCAGCGTTTTATTGAAATGACGC',\n",
       "       'TATTAAGATGTTTGTTTTTCTTTAAATGCTAAAATAATTGATTTCTTTTTATCGTTCGTAAATACGAAATTTTCGTATTCATTACCTAAAAAAATATCAT',\n",
       "       'TATTAAACCTTTTAGCAATCCGCCAAAGTACCTAACAACGCCAAGTATTTTGCCTACAAACCATAATTGAATTAAATTCCAAATTAACTGCACAGTACCT',\n",
       "       'TATGTTATAATTAAT',\n",
       "       'TATGATGATATTTTTTTAGGTAATGAATACGAAAATTTCGTATTTACGAACGATAAAAAGAAATCAATTATTTTAGCATTTAAAGAAAAACAAACATCTT',\n",
       "       'TATGATCTTTCAAGCACTTTTTGCCGTGGGTAGAAAGTGCTTTTTTATTAATTTTAAAAAAAGCACCAAAAATTTAAATGGAGGTGTCTGAATGTCTGCT',\n",
       "       'TATGACGAAGAATGTAATAGACGACCCGTTAATATTCAATACAACGATGGCTACGACTTAATGATAGACCAGCGTTTTATTGAAATGACGCTTGAAAGAC',\n",
       "       'TATGAATACTATATTGTAGTCAACGATTTCGAGTCTAGCAATCATTTGTCAGTAAATAAAAGTACAGGAAATCAATATTTTGCTACTATAAACGAAATTT',\n",
       "       'TATGAAAATTTCGTATAATAAGAAAAAAAGGAGGTAAGTAATATGAACAAAGAAAGAAATATTATTATAGCCAAAAACATTAGAAAATTTCTCAACGATT',\n",
       "       'TATCTGAGTCTCT',\n",
       "       'TATCTAGTGGCTGAAGTAGCACCTAAGCCGTCGATTTTCGCATTAAAATAAGCACCTTTTGACCATTTAAGGTTATAAGGTGCTTTACTTCCAACTGTTA',\n",
       "       'TATCGCCAAGCCATTTGGTACCTTTACCTATTTGATCTTTTGTCCAGTTAAATGCCGATGATGCACCGGATTTAATATCTTTCCACATAGTACCTATGCT',\n",
       "       'TATCATCGACTTACAAAAAACAGTGAAAAAAGTAGACGAGGCATACAACTTCTTGAAACAAGTTTCAGAAGATGGTGGACAAGTCTTATTCGTAGGAACT',\n",
       "       'TATCACCGTATCTAGTGGCTGAAGTAGCACCTAAGCCGTCGATTTTCGCATTAAAATAAGCACCTTTTGACCATTTAAGGTTATAAGGTGCTTTACTTCC',\n",
       "       'TATATGAGTGCTTTTAATGTTAAATATGATGATATTTTTTTAGGTAATGAATACGAAAATTTCGTATTTACGAACGATAAAAAGAAATCAATTATTTTAG',\n",
       "       'TATAGTAGCAAAATATTGATTTCCTGTACTTTTATTTACTGACAAATGATTGCTAGACTCGAAATCGTTGACTACAATATAGTATTCATAGTCGGTTTTT',\n",
       "       'TATAGCACTTCCATTATGATAATAGGTTTGTCTAAGATTGCTTAAAGCAGTTCCCTGCAATTCAGACTTTTTTTGTAAATCTTTTCCATTTATTTCTTCG',\n",
       "       'TATAGCAACCCATATAATAGTTATTAAACCTTTTAGCAATCCGCCAAAGTACCTAACAACGCCAAGTATTTTGCCTACAAACCATAATTGAATTAAATTC',\n",
       "       'TATAGAATTTTTGATGAATTCGAAAAATTACTCGATAAAAACCGACTATGAATACTATATTGTAGTCAACGATTTCGAGTCTAGCAATCATTTGTCAGTA',\n",
       "       'TATACAAAAATTTCGGATAATAACAAGTTTATATGGAATTATGCTTTAGAGGTGAGTAAAATAAAAAAAACAACATTTATACTACTTTCATTTATTGCCC',\n",
       "       'TATAATAGTTATTAAACCTTTTAGCAATCCGCCAAAGTACCTAACAACGCCAAGTATTTTGCCTACAAACCATAATTGAATTAAATTCCAAATTAACTGC',\n",
       "       'TATAATAATATTTCTTTCTTTGTTCATATTACTTACCTCCTTTTTTTCTTATTATACGAAATTTTCATATCATAGTAAAGTTTTTTACGAAAAAAACGTA',\n",
       "       'TATAAATTTCGTTTATAGTAGCAAAATATTGATTTCCTGTACTTTTATTTACTGACAAATGATTGCTAGACTCGAAATCGTTGACTACAATATAGTATTC',\n",
       "       'TATAAATATATATC',\n",
       "       'TATAAAGGTTTGGCAGACATTTCATAACTTGCCAAACCTTTATATATCTAATTATCAAACTGCACTAAACTTACCAAAACCGCTTATTCTATTACCTGCC',\n",
       "       'TAGTTGTTTTTTAGCTTCAATGATAGCAGACATTCAGACACCTCCATTTAAATTTTTGGTGCTTTTTTTAAAATTAATAAAAAAGCACTTTCTACCCACG',\n",
       "       'TAGTTCCTACGAATAAGACTTGTCCACCATCTTCTGAAACTTGTTTCAAGAAGTTGTATGCCTCGTCTACTTTTTTCACTGTTTTTTGTAAGTCGATGAT',\n",
       "       'TAGTTATTAAACCTTTTAGCAATCCGCCAAAGTACCTAACAACGCCAAGTATTTTGCCTACAAACCATAATTGAATTAAATTCCAAATTAACTGCACAGT',\n",
       "       'TAGTGTTCTTTTA',\n",
       "       'TAGTGGCTGAAGTAGCACCTAAGCCGTCGATTTTCGCATTAAAATAAGCACCTTTTGACCATTTAAGGTTATAAGGTGCTTTACTTCCAACTGTTATTTT',\n",
       "       'TAGTGACAAAAT', 'TAGTCTTGTGATT',\n",
       "       'TAGTATAAATGTTGTTTTTTTTATTTTACTCACCTCTAAAGCATAATTCCATATAAACTTGTTATTATCCGAAATTTTTGTATAATAGATTATTTTTGTT',\n",
       "       'TAGTAGCAAAATATTGATTTCCTGTACTTTTATTTACTGACAAATGATTGCTAGACTCGAAATCGTTGACTACAATATAGTATTCATAGTCGGTTTTTAT',\n",
       "       'TAGTACGATTATCACCGTATCTAGTGGCTGAAGTAGCACCTAAGCCGTCGATTTTCGCATTAAAATAAGCACCTTTTGACCATTTAAGGTTATAAGGTGC',\n",
       "       'TAGGTACTTTATTA',\n",
       "       'TAGGGCAATAAATGAAAGTAGTATAAATGTTGTTTTTTTTATTTTACTCACCTCTAAAGCATAATTCCATATAAACTTGTTATTATCCGAAATTTTTGTA',\n",
       "       'TAGGCAAAATACTTGGCGTTGTTAGGTACTTTGGCGGATTGCTAAAAGGTTTAATAACTATTATATGGGTTGCTATAATAGGCGTTTTCAAGAAATCATT',\n",
       "       'TAGCTTCAATGATAGCAGACATTCAGACACCTCCATTTAAATTTTTGGTGCTTTTTTTAAAATTAATAAAAAAGCACTTTCTACCCACGGCAAAAAGTGC',\n",
       "       'TAGCATAGGTACTATGTGGAAAGATATTAAATCCGGTGCATCATCGGCATTTAACTGGACAAAAGATCAAATAGGTAAAGGTACCAAATGGCTTGGCGAT',\n",
       "       'TAGCAGACATTCAGACACCTCCATTTAAATTTTTGGTGCTTTTTTTAAAATTAATAAAAAAGCACTTTCTACCCACGGCAAAAAGTGCTTGAAAGATCAT',\n",
       "       'TAGCACTTCCATTATGATAATAGGTTTGTCTAAGATTGCTTAAAGCAGTTCCCTGCAATTCAGACTTTTTTTGTAAATCTTTTCCATTTATTTCTTCGCT',\n",
       "       'TAGCACCTAAGCCGTCGATTTTCGCATTAAAATAAGCACCTTTTGACCATTTAAGGTTATAAGGTGCTTTACTTCCAACTGTTATTTTACTTGCAGATTT',\n",
       "       'TAGCAATCCGCCAAAGTACCTAACAACGCCAAGTATTTTGCCTACAAACCATAATTGAATTAAATTCCAAATTAACTGCACAGTACCTTTCAGTATCATT',\n",
       "       'TAGACAAGGCAGGTAATAGAATAAGCGGTTTTGGTAAGTTTAGTGCAGTTTGATAATTAGATATATAAAGGTTTGGCAAGTTATGAAATGTCTGCCAAAC',\n",
       "       'TAGAAAGTGCTTTTTTATTAATTTTAAAAAAAGCACCAAAAATTTAAATGGAGGTGTCTGAATGTCTGCTATCATTGAAGCTAAAAAACAACTAGTTGAT',\n",
       "       'TACTTTCTAAGTATATGAGTGCTTTTAATGTTAAATATGATGATATTTTTTTAGGTAATGAATACGAAAATTTCGTATTTACGAACGATAAAAAGAAATC',\n",
       "       'TACTTTCAATATTAGCTGAAGCATATGAATCGATAATAATTCGATTGTAGTCAGATGTTAAAGCGACTACACCGCCATAAGAATTGATTGTTATGCCATT',\n",
       "       'TACTGTGCAGTTAATTTGGAATTTAATTCAATTATGGTTTGTAGGCAAAATACTTGGCGTTGTTAGGTACTTTGGCGGATTGCTAAAAGGTTTAATAACT',\n",
       "       'TACTCTCTTTATTTTCAATTATAGCACTTCCATTATGATAATAGGTTTGTCTAAGATTGCTTAAAGCAGTTCCCTGCAATTCAGACTTTTTTTGTAAATC',\n",
       "       'TACTCGATAAAAACCGACTATGAATACTATATTGTAGTCAACGATTTCGAGTCTAGCAATCATTTGTCAGTAAATAAAAGTACAGGAAATCAATATTTTG',\n",
       "       'TACTCCAACAAAAATAATCTATTATACAAAAATTTCGGATAATAACAAGTTTATATGGAATTATGCTTTAGAGGTGAGTAAAATAAAAAAAACAACATTT',\n",
       "       'TACTATATTGTAGTCAACGATTTCGAGTCTAGCAATCATTTGTCAGTAAATAAAAGTACAGGAAATCAATATTTTGCTACTATAAACGAAATTTATAAAG',\n",
       "       'TACTACTATGACGAAGAATGTAATAGACGACCCGTTAATATTCAATACAACGATGGCTACGACTTAATGATAGACCAGCGTTTTATTGAAATGACGCTTG',\n",
       "       'TACGATTATCACCGTATCTAGTGGCTGAAGTAGCACCTAAGCCGTCGATTTTCGCATTAAAATAAGCACCTTTTGACCATTTAAGGTTATAAGGTGCTTT',\n",
       "       'TACCCTTTTTG',\n",
       "       'TACAAAAAACAGTGAAAAAAGTAGACGAGGCATACAACTTCTTGAAACAAGTTTCAGAAGATGGTGGACAAGTCTTATTCGTAGGAACTAAAAAACAAGC',\n",
       "       'TAATTTGGAATTTAATTCAATTATGGTTTGTAGGCAAAATACTTGGCGTTGTTAGGTACTTTGGCGGATTGCTAAAAGGTTTAATAACTATTATATGGGT',\n",
       "       'TAATTCAATTATGGTTTGTAGGCAAAATACTTGGCGTTGTTAGGTACTTTGGCGGATTGCTAAAAGGTTTAATAACTATTATATGGGTTGCTATAATAGG',\n",
       "       'TAATTACTCCAACAAAAATAATCTATTATACAAAAATTTCGGATAATAACAAGTTTATATGGAATTATGCTTTAGAGGTGAGTAAAATAAAAAAAACAAC',\n",
       "       'TAATGATTTCTTGAAAACGCCTATTATAGCAACCCATATAATAGTTATTAAACCTTTTAGCAATCCGCCAAAGTACCTAACAACGCCAAGTATTTTGCCT',\n",
       "       'TAATGATACTGAAAGGTACTGTGCAGTTAATTTGGAATTTAATTCAATTATGGTTTGTAGGCAAAATACTTGGCGTTGTTAGGTACTTTGGCGGATTGCT',\n",
       "       'TAATGAATACGAAAATTTCGTATTTACGAACGATAAAAAGAAATCAATTATTTTAGCATTTAAAGAAAAACAAACATCTTAATAGGAGGAATAACAAATG',\n",
       "       'TAATCTATTATACAAAAATTTCGGATAATAACAAGTTTATATGGAATTATGCTTTAGAGGTGAGTAAAATAAAAAAAACAACATTTATACTACTTTCATT',\n",
       "       'TAATAGTTATTAAACCTTTTAGCAATCCGCCAAAGTACCTAACAACGCCAAGTATTTTGCCTACAAACCATAATTGAATTAAATTCCAAATTAACTGCAC',\n",
       "       'TAATAATTACTC',\n",
       "       'TAATAATTACTCCAACAAAAATAATCTATTATACAAAAATTTCGGATAATAACAAGTTTATATGGAATTATGCTTTAGAGGTGAGTAAAATAAAAAAAAC',\n",
       "       'TAATAATATTTCTTTCTTTGTTCATATTACTTACCTCCTTTTTTTCTTATTATACGAAATTTTCATATCATAGTAAAGTTTTTTACGAAAAAAACGTATT',\n",
       "       'TAATAAAAAAGCACT',\n",
       "       'TAAGTATATGAGTGCTTTTAATGTTAAATATGATGATATTTTTTTAGGTAATGAATACGAAAATTTCGTATTTACGAACGATAAAAAGAAATCAATTATT',\n",
       "       'TAAGCCGTCGATTTTCGCATTAAAATAAGCACCTTTTGACCATTTAAGGTTATAAGGTGCTTTACTTCCAACTGTTATTTTACTTGCAGATTTACCGACT',\n",
       "       'TAAGATGTTTGTTTTTCTTTAAATGCTAAAATAATTGATTTCTTTTTATCGTTCGTAAATACGAAATTTTCGTATTCATTACCTAAAAAAATATCATCAT',\n",
       "       'TAACATCTTCATT',\n",
       "       'TAACAATCAATTCTTATGGCGGTGTAGTCGCTTTAACATCTGACTACAATCGAATTATTATCGATTCATATGCTTCAGCTAATATTGAAAGTAGAGAAGC',\n",
       "       'TAAATTTTTGGTGCTTTTTTTAAAATTAATAAAAAAGCACTTTCTACCCACGGCAAAAAGTGCTTGAAAGATCATAGATCATCACGTTCAAGTCAATTTT',\n",
       "       'TAAATTTCGTTTATAGTAGCAAAATATTGATTTCCTGTACTTTTATTTACTGACAAATGATTGCTAGACTCGAAATCGTTGACTACAATATAGTATTCAT',\n",
       "       'TAAATGTTGTTTTTTTTATTTTACTCACCTCTAAAGCATAATTCCATATAAACTTGTTATTATCCGAAATTTTTGTATAATAGATTATTTTTGTTGGAGT',\n",
       "       'TAAATGCTAAAATAATTGATTTCTTTTTATCGTTCGTAAATACGAAATTTTCGTATTCATTACCTAAAAAAATATCATCATATTTAACATTAAAAGCACT',\n",
       "       'TAAATGCGGATGTCTTTCAAGCGTCATTTCAATAAAACGCTGGTCTATCATTAAGTCGTAGCCATCGTTGTATTGAATATTAACGGGTCGTCTATTACAT',\n",
       "       'TAAATGAAAGTAGTATAAATGTTGTTTTTTTTATTTTACTCACCTCTAAAGCATAATTCCATATAAACTTGTTATTATCCGAAATTTTTGTATAATAGAT',\n",
       "       'TAAATCTGCAAGTAAAATAACAGTTGGAAGTAAAGCACCTTATAACCTTAAATGGTCAAAAGGTGCTTATTTTAATGCGAAAATCGACGGCTTAGGTGCT',\n",
       "       'TAAATCCGGTGCATCATCGGCATTTAACTGGACAAAAGATCAAATAGGTAAAGGTACCAAATGGCTTGGCGATAAAGTTGGCGATGTTTTAGATTTTATT',\n",
       "       'TAAATACGTTTTTTTCGTAAAAAACTTTACTATGATATGAAAATTTCGTATAATAAGAAAAAAAGGAGGTAAGTAATATGAACAAAGAAAGAAATATTAT',\n",
       "       'TAAAGGTTTGGCAGACATTTCATAACTTGCCAAACCTTTATATATCTAATTATCAAACTGCACTAAACTTACCAAAACCGCTTATTCTATTACCTGCCTT',\n",
       "       'TAAAGCACCTTATAACCTTAAATGGTCAAAAGGTGCTTATTTTAATGCGAAAATCGACGGCTTAGGTGCTACTTCAGCCACTAGATACGGTGATAATCGT',\n",
       "       'TAAACCTTTTAGCAATCCGCCAAAGTACCTAACAACGCCAAGTATTTTGCCTACAAACCATAATTGAATTAAATTCCAAATTAACTGCACAGTACCTTTC',\n",
       "       'TAAAATTGACTTGAACGTGATGATCTATGATCTTTCAAGCACTTTTTGCCGTGGGTAGAAAGTGCTTTTTTATTAATTTTAAAAAAAGCACCAAAAATTT',\n",
       "       'TAAAATCGAATG',\n",
       "       'TAAAATAATTGATTTCTTTTTATCGTTCGTAAATACGAAATTTTCGTATTCATTACCTAAAAAAATATCATCATATTTAACATTAAAAGCACTCATATAC',\n",
       "       'TAAAATAACAGTTGGAAGTAAAGCACCTTATAACCTTAAATGGTCAAAAGGTGCTTATTTTAATGCGAAAATCGACGGCTTAGGTGCTACTTCAGCCACT',\n",
       "       'TAAAACCTTTCTTACGGTATCTTTTTCCTTCATGCTTAAACTCATATTGCCATTTTTTACCATCGTAACAACGTGTTTTCATGTGTTCCCTCCTCAAAAT',\n",
       "       'TAAAAACCGACTATGAATACTATATTGTAGTCAACGATTTCGAGTCTAGCAATCATTTGTCAGTAAATAAAAGTACAGGAAATCAATATTTTGCTACTAT',\n",
       "       'GTTTTTTTCGTAAAAAACTTTACTATGATATGAAAATTTCGTATAATAAGAAAAAAAGGAGGTAAGTAATATGAACAAAGAAAGAAATATTATTATAGCC',\n",
       "       'GTTTTTTAGTTCCTACGAATAAGACTTGTCCACCATCTTCTGAAACTTGTTTCAAGAAGTTGTATGCCTCGTCTACTTTTTTCACTGTTTTTTGTAAGTC',\n",
       "       'GTTTTTCTTTAAATGCTAAAATAATTGATTTCTTTTTATCGTTCGTAAATACGAAATTTTCGTATTCATTACCTAAAAAAATATCATCATATTTAACATT',\n",
       "       'GTTTTATTATCTC',\n",
       "       'GTTTGGGACGGCATTGTAATGATACTGAAAGGTACTGTGCAGTTAATTTGGAATTTAATTCAATTATGGTTTGTAGGCAAAATACTTGGCGTTGTTAGGT',\n",
       "       'GTTTCTTTTGAGACATATTTGAATCGTTGAGAAATTTTCTAATGTTTTTGGCTATAATAATATTTCTTTCTTTGTTCATATTACTTACCTCCTTTTTTTC',\n",
       "       'GTTTATAGTAGCAAAATATTGATTTCCTGTACTTTTATTTACTGACAAATGATTGCTAGACTCGAAATCGTTGACTACAATATAGTATTCATAGTCGGTT',\n",
       "       'GTTTAAGCATGAAGGAAAAAGATACCGTAAGAAAGGTTTTAGAACAAAGCGTGAAGCTAATTCTGCTGGACTAGACAAGTTAAATGAGTTAAGAAGTGGT',\n",
       "       'GTTGTTTTTTAGCTTCAATGATAGCAGACATTCAGACACCTCCATTTAAATTTTTGGTGCTTTTTTTAAAATTAATAAAAAAGCACTTTCTACCCACGGC',\n",
       "       'GTTGTTTAACC',\n",
       "       'GTTGTGCTACTGGTATCTGTGTTTGATTTACAAAATCTTCTAATTCTTGATGGAGGTGAAAACTGTTAATTTCATGTCCAGTAATGATGATAGGCTGCTT',\n",
       "       'GTTGGAAGTAAAGCACCTTATAACCTTAAATGGTCAAAAGGTGCTTATTTTAATGCGAAAATCGACGGCTTAGGTGCTACTTCAGCCACTAGATACGGTG',\n",
       "       'GTTGAGAAATTTTCTAATGTTTTTGGCTATAATAATATTTCTTTCTTTGTTCATATTACTTACCTCCTTTTTTTCTTATTATACGAAATTTTCATATCAT',\n",
       "       'GTTCCTACGAATAAGACTTGTCCACCATCTTCTGAAACTTGTTTCAAGAAGTTGTATGCCTCGTCTACTTTTTTCACTGTTTTTTGTAAGTCGATGATAT',\n",
       "       'GTTATTAAACCTTTTAGCAATCCGCCAAAGTACCTAACAACGCCAAGTATTTTGCCTACAAACCATAATTGAATTAAATTCCAAATTAACTGCACAGTAC',\n",
       "       'GTTATAATTAATT',\n",
       "       'GTTAGTACGATTATCACCGTATCTAGTGGCTGAAGTAGCACCTAAGCCGTCGATTTTCGCATTAAAATAAGCACCTTTTGACCATTTAAGGTTATAAGGT',\n",
       "       'GTTAGGGCAATAAATGAAAGTAGTATAAATGTTGTTTTTTTTATTTTACTCACCTCTAAAGCATAATTCCATATAAACTTGTTATTATCCGAAATTTTTG',\n",
       "       'GTTAATTTTTTGT',\n",
       "       'GTTAATTTGGAATTTAATTCAATTATGGTTTGTAGGCAAAATACTTGGCGTTGTTAGGTACTTTGGCGGATTGCTAAAAGGTTTAATAACTATTATATGG',\n",
       "       'GTGGGTAGAAAGTGCTTTTTTATTAATTTTAAAAAAAGCACCAAAAATTTAAATGGAGGTGTCTGAATGTCTGCTATCATTGAAGCTAAAAAACAACTAG',\n",
       "       'GTGGCTGAAGTAGCACCTAAGCCGTCGATTTTCGCATTAAAATAAGCACCTTTTGACCATTTAAGGTTATAAGGTGCTTTACTTCCAACTGTTATTTTAC',\n",
       "       'GTGCTTTTTTATTAATTTTAAAAAAAGCACCAAAAATTTAAATGGAGGTGTCTGAATGTCTGCTATCATTGAAGCTAAAAAACAACTAGTTGATGAAATT',\n",
       "       'GTGCTTGTTTTTTAGTTCCTACGAATAAGACTTGTCCACCATCTTCTGAAACTTGTTTCAAGAAGTTGTATGCCTCGTCTACTTTTTTCACTGTTTTTTG',\n",
       "       'GTGCATCATCGGCATTTAACTGGACAAAAGATCAAATAGGTAAAGGTACCAAATGGCTTGGCGATAAAGTTGGCGATGTTTTAGATTTTATTGAAAATCC',\n",
       "       'GTGAAAAAAGTAGACGAGGCATACAACTTCTTGAAACAAGTTTCAGAAGATGGTGGACAAGTCTTATTCGTAGGAACTAAAAAACAAGCACAAGAATCAG',\n",
       "       'GTCGGTAAATCTGCAAGTAAAATAACAGTTGGAAGTAAAGCACCTTATAACCTTAAATGGTCAAAAGGTGCTTATTTTAATGCGAAAATCGACGGCTTAG',\n",
       "       'GTCGATTTTCGCATTAAAATAAGCACCTTTTGACCATTTAAGGTTATAAGGTGCTTTACTTCCAACTGTTATTTTACTTGCAGATTTACCGACTGCTTTT',\n",
       "       'GTATTTTTTGTG',\n",
       "       'GTATTTATATCATCGACTTACAAAAAACAGTGAAAAAAGTAGACGAGGCATACAACTTCTTGAAACAAGTTTCAGAAGATGGTGGACAAGTCTTATTCGT',\n",
       "       'GTATGTTAAG',\n",
       "       'GTATCTAGTGGCTGAAGTAGCACCTAAGCCGTCGATTTTCGCATTAAAATAAGCACCTTTTGACCATTTAAGGTTATAAGGTGCTTTACTTCCAACTGTT',\n",
       "       'GTATATAAATATATAT',\n",
       "       'GTATAAATGTTGTTTTTTTTATTTTACTCACCTCTAAAGCATAATTCCATATAAACTTGTTATTATCCGAAATTTTTGTATAATAGATTATTTTTGTTGG',\n",
       "       'GTAGTATAAATGTTGTTTTTTTTATTTTACTCACCTCTAAAGCATAATTCCATATAAACTTGTTATTATCCGAAATTTTTGTATAATAGATTATTTTTGT',\n",
       "       'GTAGGCAAAATACTTGGCGTTGTTAGGTACTTTGGCGGATTGCTAAAAGGTTTAATAACTATTATATGGGTTGCTATAATAGGCGTTTTCAAGAAATCAT',\n",
       "       'GTAGCACCTAAGCCGTCGATTTTCGCATTAAAATAAGCACCTTTTGACCATTTAAGGTTATAAGGTGCTTTACTTCCAACTGTTATTTTACTTGCAGATT',\n",
       "       'GTAGCAAAATATTGATTTCCTGTACTTTTATTTACTGACAAATGATTGCTAGACTCGAAATCGTTGACTACAATATAGTATTCATAGTCGGTTTTTATCG',\n",
       "       'GTACGATTTTAT',\n",
       "       'GTACGATTATCACCGTATCTAGTGGCTGAAGTAGCACCTAAGCCGTCGATTTTCGCATTAAAATAAGCACCTTTTGACCATTTAAGGTTATAAGGTGCTT',\n",
       "       'GTAATTCATAAT', 'GTAATTCATAATC',\n",
       "       'GTAATGATACTGAAAGGTACTGTGCAGTTAATTTGGAATTTAATTCAATTATGGTTTGTAGGCAAAATACTTGGCGTTGTTAGGTACTTTGGCGGATTGC',\n",
       "       'GTAAATCTGCAAGTAAAATAACAGTTGGAAGTAAAGCACCTTATAACCTTAAATGGTCAAAAGGTGCTTATTTTAATGCGAAAATCGACGGCTTAGGTGC',\n",
       "       'GTAAAGCACCTT',\n",
       "       'GTAAAGCACCTTATAACCTTAAATGGTCAAAAGGTGCTTATTTTAATGCGAAAATCGACGGCTTAGGTGCTACTTCAGCCACTAGATACGGTGATAATCG',\n",
       "       'GTAAAAAACTTTACTATGATATGAAAATTTCGTATAATAAGAAAAAAAGGAGGTAAGTAATATGAACAAAGAAAGAAATATTATTATAGCCAAAAACATT',\n",
       "       'GGTTTTTATAAATTGG', 'GGTTTTCGATTG',\n",
       "       'GGTTTGGCAGACATTTCATAACTTGCCAAACCTTTATATATCTAATTATCAAACTGCACTAAACTTACCAAAACCGCTTATTCTATTACCTGCCTTGTCT',\n",
       "       'GGTGCTTTTTTTAAAATTAATAAAAAAGCACTTTCTACCCACGGCAAAAAGTGCTTGAAAGATCATAGATCATCACGTTCAAGTCAATTTTAGCCTCGGC',\n",
       "       'GGTGCATCATCGGCATTTAACTGGACAAAAGATCAAATAGGTAAAGGTACCAAATGGCTTGGCGATAAAGTTGGCGATGTTTTAGATTTTATTGAAAATC',\n",
       "       'GGTATGAATGGCATAACAATCAATTCTTATGGCGGTGTAGTCGCTTTAACATCTGACTACAATCGAATTATTATCGATTCATATG',\n",
       "       'GGTATGAATGGCATAACAATCAATTCTTATGGCGGTGTAGTCGCTTTAACATCTGACTACAATCGAATTATTATCGATTCATATGCTTCAGCTAATATTG',\n",
       "       'GGTAGAAAGTGCTTTTTTATTAATTTTAAAAAAAGCACCAAAAATTTAAATGGAGGTGTCTGAATGTCTGCTATCATTGAAGCTAAAAAACAACTAGTTG',\n",
       "       'GGTAAATCTGCAAGTAAAATAACAGTTGGAAGTAAAGCACCTTATAACCTTAAATGGTCAAAAGGTGCTTATTTTAATGCGAAAATCGACGGCTTAGGTG',\n",
       "       'GGGTCAAAAAAATCAAAAGCGATCAAAATACTTGGGGAACGGGGAGGGGCTCGACTTCGCGATAATTTTAAAAATCCATGTATAACCCCCC',\n",
       "       'GGGTAGAAAGTGCTTTTTTATTAATTTTAAAAAAAGCACCAAAAATTTAAATGGAGGTGTCTGAATGTCTGCTATCATTGAAGCTAAAAAACAACTAGTT',\n",
       "       'GGGACGGCATTGTAATGATACTGAAAGGTACTGTGCAGTTAATTTGGAATTTAATTCAATTATGGTTTGTAGGCAAAATACTTGGCGTTGTTAGGTACTT',\n",
       "       'GGGAACACATGAAAACACGTTGTTACGATGGTAAAAAATGGCAATATGAGTTTAAGCATGAAGGAAAAAGATACCGTAAGAAAGGTTTTAGAACAAAGCG',\n",
       "       'GGCTTAAAAATG',\n",
       "       'GGCGAGGCGTTTGGGACGGCATTGTAATGATACTGAAAGGTACTGTGCAGTTAATTTGGAATTTAATTCAATTATGGTTTGTAGGCAAAATACTTGGCGT',\n",
       "       'GGCATCTATTT',\n",
       "       'GGCATAACAATCAATTCTTATGGCGGTGTAGTCGCTTTAACATCTGACTACAATCGAATTATTATCGATTCATATGCTTCAGCTAATATTGAAAGTAGAG',\n",
       "       'GGCAGACATTTCATAACTTGCCAAACCTTTATATATCTAATTATCAAACTGCACTAAACTTACCAAAACCGCTTATTCTATTACCTGCCTTGTCTACCTC',\n",
       "       'GGCAAAATACTTGGCGTTGTTAGGTACTTTGGCGGATTGCTAAAAGGTTTAATAACTATTATATGGGTTGCTATAATAGGCGTTTTCAAGAAATCATTAT',\n",
       "       'GGATGTCTTTCAAGCGTCATTTCAATAAAACGCTGGTCTATCATTAAGTCGTAGCCATCGTTGTATTGAATATTAACGGGTCGTCTATTACATTCTTCGT',\n",
       "       'GGAGTTGATAG', 'GGAGTAATTATT',\n",
       "       'GGAGAGGTAGACAAGGCAGGTAATAGAATAAGCGGTTTTGGTAAGTTTAGTGCAGTTTGATAATTAGATATATAAAGGTTTGGCAAGTTATGAAATGTCT',\n",
       "       'GGACGGCATTGTAATGATACTGAAAGGTACTGTGCAGTTAATTTGGAATTTAATTCAATTATGGTTTGTAGGCAAAATACTTGGCGTTGTTAGGTACTTT',\n",
       "       'GGAATTTAATTCAATTATGGTTTGTAGGCAAAATACTTGGCGTTGTTAGGTACTTTGGCGGATTGCTAAAAGGTTTAATAACTATTATATGGGTTGCTAT',\n",
       "       'GGAACACATGAAAACACGTTGTTACGATGGTAAAAAATGGCAATATGAGTTTAAGCATGAAGGAAAAAGATACCGTAAGAAAGGTTTTAGAACAAAGCGT',\n",
       "       'GGAAAAGATTTACAAAAAAAGTCTGAATTGCAGGGAACTGCTTTAAGCAATCTTAGACAAACCTATTATCATAATGGAAGTGCTATAATTGAAAATAAAG',\n",
       "       'GCTTTTTTTAAAATTAATAAAAAAGCACTTTCTACCCACGGCAAAAAGTGCTTGAAAGATCATAGATCATCACGTTCAAGTCAATTTTAGCCTCGGCAGG',\n",
       "       'GCTTTTTTATTAATTTTAAAAAAAGCACCAAAAATTTAAATGGAGGTGTCTGAATGTCTGCTATCATTGAAGCTAAAAAACAACTAGTTGATGAAATTGC',\n",
       "       'GCTTTTAATGTTAAATATGATGATATTTTTTTAGGTAATGAATACGAAAATTTCGTATTTACGAACGATAAAAAGAAATCAATTATTTTAGCATTTAAAG',\n",
       "       'GCTTTGTTCTAAAACCTTTCTTACGGTATCTTTTTCCTTCATGCTTAAACTCATATTGCCATTTTTTACCATCGTAACAACGTGTTTTCATGTGTTCCCT',\n",
       "       'GCTTTATAAATTTCGTTTATAGTAGCAAAATATTGATTTCCTGTACTTTTATTTACTGACAAATGATTGCTAGACTCGAAATCGTTGACTACAATATAGT',\n",
       "       'GCTTCACGCTTTGTTCTAAAACCTTTCTTACGGTATCTTTTTCCTTCATGCTTAAACTCATATTGCCATTTTTTACCATCGTAACAACGTGTTTTCATGT',\n",
       "       'GCTTCAATGATAGCAGACATTCAGACACCTCCATTTAAATTTTTGGTGCTTTTTTTAAAATTAATAAAAAAGCACTTTCTACCCACGGCAAAAAGTGCTT',\n",
       "       'GCTTATAAGAAATCTGAAACATTTAGAAATTTTGTTAATGG',\n",
       "       'GCTGAAGTAGCACCTAAGCCGTCGATTTTCGCATTAAAATAAGCACCTTTTGACCATTTAAGGTTATAAGGTGCTTTACTTCCAACTGTTATTTTACTTG',\n",
       "       'GCTATAATAATATTTCTTTCTTTGTTCATATTACTTACCTCCTTTTTTTCTTATTATACGAAATTTTCATATCATAGTAAAGTTTTTTACGAAAAAAACG',\n",
       "       'GCTAAAATTGACTTGAACGTGATGATCTATGATCTTTCAAGCACTTTTTGCCGTGGGTAGAAAGTGCTTTTTTATTAATTTTAAAAAAAGCACCAAAAAT',\n",
       "       'GCTAAAATAATTGATTTCTTTTTATCGTTCGTAAATACGAAATTTTCGTATTCATTACCTAAAAAAATATCATCATATTTAACATTAAAAGCACTCATAT',\n",
       "       'GCGGATGTCTTTCAAGCGTCATTTCAATAAAACGCTGGTCTATCATTAAGTCGTAGCCATCGTTGTATTGAATATTAACGGGTCGTCTATTACATTCTTC',\n",
       "       'GCGATAAATAGTG',\n",
       "       'GCGAGGCGTTTGGGACGGCATTGTAATGATACTGAAAGGTACTGTGCAGTTAATTTGGAATTTAATTCAATTATGGTTTGTAGGCAAAATACTTGGCGTT',\n",
       "       'GCGAAGAAATAAATGGAAAAGATTTACAAAAAAAGTCTGAATTGCAGGGAACTGCTTTAAGCAATCTTAGACAAACCTATTATCATAATGGAAGTGCTAT',\n",
       "       'GCCTATTATAGCAACCCATATAATAGTTATTAAACCTTTTAGCAATCCGCCAAAGTACCTAACAACGCCAAGTATTTTGCCTACAAACCATAATTGAATT',\n",
       "       'GCCGTCGATTTTCGCATTAAAATAAGCACCTTTTGACCATTTAAGGTTATAAGGTGCTTTACTTCCAACTGTTATTTTACTTGCAGATTTACCGACTGCT',\n",
       "       'GCCGATAATGATTTCTTGAAAACGCCTATTATAGCAACCCATATAATAGTTATTAAACCTTTTAGCAATCCGCCAAAGTACCTAACAACGCCAAGTATTT',\n",
       "       'GCCATTTGGTACCTTTACCTATTTGATCTTTTGTCCAGTTAAATGCCGATGATGCACCGGATTTAATATCTTTCCACATAGTACCTATGCTAAATCTTGG',\n",
       "       'GCCAATTTTGAGGAGGGAACACATGAAAACACGTTGTTACGATGGTAAAAAATGGCAATATGAGTTTAAGCATGAAGGAAAAAGATACCGTAAGAAAGGT',\n",
       "       'GCCAAGTATTTTGCCTACAAACCATAATTGAATTAAATTCCAAATTAACTGCACAGTACCTTTCAGTATCATTACAATGCCGTCCCAAACGCCTCGCCAG',\n",
       "       'GCCAAGCCATTTGGTACCTTTACCTATTTGATCTTTTGTCCAGTTAAATGCCGATGATGCACCGGATTTAATATCTTTCCACATAGTACCTATGCTAAAT',\n",
       "       'GCCAAAGTACCTAACAACGCCAAGTATTTTGCCTACAAACCATAATTGAATTAAATTCCAAATTAACTGCACAGTACCTTTCAGTATCATTACAATGCCG',\n",
       "       'GCATTGTAATGATACTGAAAGGTACTGTGCAGTTAATTTGGAATTTAATTCAATTATGGTTTGTAGGCAAAATACTTGGCGTTGTTAGGTACTTTGGCGG',\n",
       "       'GCATTAAAATAAGCACCTTTTGACCATTTAAGGTTATAAGGTGCTTTACTTCCAACTGTTATTTTACTTGCAGATTTACCGACTGCTTTTTGAGCAGGTG',\n",
       "       'GCATCATCGGCATTTAACTGGACAAAAGATCAAATAGGTAAAGGTACCAAATGGCTTGGCGATAAAGTTGGCGATGTTTTAGATTTTATTGAAAATCCAG',\n",
       "       'GCAGTCGGTAAATCTGCAAGTAAAATAACAGTTGGAAGTAAAGCACCTTATAACCTTAAATGGTCAAAAGGTGCTTATTTTAATGCGAAAATCGACGGCT',\n",
       "       'GCAGGTAATAGAATAAGCGGTTTTGGTAAGTTTAGTGCAGTTTGATAATTAGATATATAAAGGTTTGGCAAGTTATGAAATGTCTGCCAAACCTTTATAT',\n",
       "       'GCAGCCTATCATCATTACTGGACATGAAATTAACAGTTTTCACCTCCATCAAGAATTAGAAGATTTTGTAAATCAAACACAGATACCAGTAGCACAACTT',\n",
       "       'GCAGACATTTCATAACTTGCCAAACCTTTATATATCTAATTATCAAACTGCACTAAACTTACCAAAACCGCTTATTCTATTACCTGCCTTGTCTACCTCT',\n",
       "       'GCAGACATTCAGACACCTCCATTTAAATTTTTGGTGCTTTTTTTAAAATTAATAAAAAAGCACTTTCTACCCACGGCAAAAAGTGCTTGAAAGATCATAG',\n",
       "       'GCACTTCCATTATGATAATAGGTTTGTCTAAGATTGCTTAAAGCAGTTCCCTGCAATTCAGACTTTTTTTGTAAATCTTTTCCATTTATTTCTTCGCTTT',\n",
       "       'GCAATAAATGAAAGTAGTATAAATGTTGTTTTTTTTATTTTACTCACCTCTAAAGCATAATTCCATATAAACTTGTTATTATCCGAAATTTTTGTATAAT',\n",
       "       'GCAAGTAAAATAACAGTTGGAAGTAAAGCACCTTATAACCTTAAATGGTCAAAAGGTGCTTATTTTAATGCGAAAATCGACGGCTTAGGTGCTACTTCAG',\n",
       "       'GCAAAATATTGATTTCCTGTACTTTTATTTACTGACAAATGATTGCTAGACTCGAAATCGTTGACTACAATATAGTATTCATAGTCGGTTTTTATCGAGT',\n",
       "       'GCAAAATACTTGGCGTTGTTAGGTACTTTGGCGGATTGCTAAAAGGTTTAATAACTATTATATGGGTTGCTATAATAGGCGTTTTCAAGAAATCATTATC',\n",
       "       'GATTTAGCATAGGTACTATGTGGAAAGATATTAAATCCGGTGCATCATCGGCATTTAACTGGACAAAAGATCAAATAGGTAAAGGTACCAAATGGCTTGG',\n",
       "       'GATTCTTGTGCTTGTTTTTTAGTTCCTACGAATAAGACTTGTCCACCATCTTCTGAAACTTGTTTCAAGAAGTTGTATGCCTCGTCTACTTTTTTCACTG',\n",
       "       'GATTATGAAGTTG',\n",
       "       'GATTATCACCGTATCTAGTGGCTGAAGTAGCACCTAAGCCGTCGATTTTCGCATTAAAATAAGCACCTTTTGACCATTTAAGGTTATAAGGTGCTTTACT',\n",
       "       'GATGTTTGTTTTTCTTTAAATGCTAAAATAATTGATTTCTTTTTATCGTTCGTAAATACGAAATTTTCGTATTCATTACCTAAAAAAATATCATCATATT',\n",
       "       'GATGTCTTTCAAGCGTCATTTCAATAAAACGCTGGTCTATCATTAAGTCGTAGCCATCGTTGTATTGAATATTAACGGGTCGTCTATTACATTCTTCGTC',\n",
       "       'GATGGTTGGTGTCGCATTTATTGGAACAATCATAATGAGTGGATATGGCATGAGAGATTGATTGTGAAAGAAGTGTTTTAAT',\n",
       "       'GATGATCTATGATCTTTCAAGCACTTTTTGCCGTGGGTAGAAAGTGCTTTTTTATTAATTTTAAAAAAAGCACCAAAAATTTAAATGGAGGTGTCTGAAT',\n",
       "       'GATGATATTTTTTTAGGTAATGAATACGAAAATTTCGTATTTACGAACGATAAAAAGAAATCAATTATTTTAGCATTTAAAGAAAAACAAACATCTTAAT',\n",
       "       'GATCTTTCAAGCACTTTTTGCCGTGGGTAGAAAGTGCTTTTTTATTAATTTTAAAAAAAGCACCAAAAATTTAAATGGAGGTGTCTGAATGTCTGCTATC',\n",
       "       'GATCTATGATCTTTCAAGCACTTTTTGCCGTGGGTAGAAAGTGCTTTTTTATTAATTTTAAAAAAAGCACCAAAAATTTAAATGGAGGTGTCTGAATGTC',\n",
       "       'GATATTTTTTTAGGTAATGAATACGAAAATTTCGTATTTACGAACGATAAAAAGAAATCAATTATTTTAGCATTTAAAGAAAAACAAACATCTTAATAGG',\n",
       "       'GATAAAAACCGACTATGAATACTATATTGTAGTCAACGATTTCGAGTCTAGCAATCATTTGTCAGTAAATAAAAGTACAGGAAATCAATATTTTGCTACT',\n",
       "       'GAGTTTAAGCATGAAGGAAAAAGATACCGTAAGAAAGGTTTTAGAACAAAGCGTGAAGCTAATTCTGCTGGACTAGACAAGTTAAATGAGTTAAGAAGTG',\n",
       "       'GAGTGCTTTTAATGTTAAATATGATGATATTTTTTTAGGTAATGAATACGAAAATTTCGTATTTACGAACGATAAAAAGAAATCAATTATTTTAGCATTT',\n",
       "       'GAGGGAACACATGAAAACACGTTGTTACGATGGTAAAAAATGGCAATATGAGTTTAAGCATGAAGGAAAAAGATACCGTAAGAAAGGTTTTAGAACAAAG',\n",
       "       'GAGGCGTTTGGGACGGCATTGTAATGATACTGAAAGGTACTGTGCAGTTAATTTGGAATTTAATTCAATTATGGTTTGTAGGCAAAATACTTGGCGTTGT',\n",
       "       'GAGAGGTAGACAAGGCAGGTAATAGAATAAGCGGTTTTGGTAAGTTTAGTGCAGTTTGATAATTAGATATATAAAGGTTTGGCAAGTTATGAAATGTCTG',\n",
       "       'GAGAATAGATGTT',\n",
       "       'GAGAAATTTTCTAATGTTTTTGGCTATAATAATATTTCTTTCTTTGTTCATATTACTTACCTCCTTTTTTTCTTATTATACGAAATTTTCATATCATAGT',\n",
       "       'GACGGCATTGTAATGATACTGAAAGGTACTGTGCAGTTAATTTGGAATTTAATTCAATTATGGTTTGTAGGCAAAATACTTGGCGTTGTTAGGTACTTTG',\n",
       "       'GACATTTCATAACTTGCCAAACCTTTATATATCTAATTATCAAACTGCACTAAACTTACCAAAACCGCTTATTCTATTACCTGCCTTGTCTACCTCTCCT',\n",
       "       'GACACCTCCATTTAAATTTTTGGTGCTTTTTTTAAAATTAATAAAAAAGCACTTTCTACCCACGGCAAAAAGTGCTTGAAAGATCATAGATCATCACGTT',\n",
       "       'GACAAGGCAGGTAATAGAATAAGCGGTTTTGGTAAGTTTAGTGCAGTTTGATAATTAGATATATAAAGGTTTGGCAAGTTATGAAATGTCTGCCAAACCT',\n",
       "       'GAATTAATTATTAT',\n",
       "       'GAATGTAATAGACGACCCGTTAATATTCAATACAACGATGGCTACGACTTAATGATAGACCAGCGTTTTATTGAAATGACGCTTGAAAGACATCCGCATT',\n",
       "       'GAATGGCATAACAATCAATTCTTATGGCGGTGTAGTCGCTTTAACATCTGACTACAATCGAATTATTATCGATTCATATGCTTCAGCTAATATTGAAAGT',\n",
       "       'GAATCGTTGAGAAATTTTCTAATGTTTTTGGCTATAATAATATTTCTTTCTTTGTTCATATTACTTACCTCCTTTTTTTCTTATTATACGAAATTTTCAT',\n",
       "       'GAAGTAGCACCTAAGCCGTCGATTTTCGCATTAAAATAAGCACCTTTTGACCATTTAAGGTTATAAGGTGCTTTACTTCCAACTGTTATTTTACTTGCAG',\n",
       "       'GAACGTGATGATCTATGATCTTTCAAGCACTTTTTGCCGTGGGTAGAAAGTGCTTTTTTATTAATTTTAAAAAAAGCACCAAAAATTTAAATGGAGGTGT',\n",
       "       'GAACACATGAAAACACGTTGTTACGATGGTAAAAAATGGCAATATGAGTTTAAGCATGAAGGAAAAAGATACCGTAAGAAAGGTTTTAGAACAAAGCGTG',\n",
       "       'GAAATAAATGGAAAAGATTTACAAAAAAAGTCTGAATTGCAGGGAACTGCTTTAAGCAATCTTAGACAAACCTATTATCATAATGGAAGTGCTATAATTG',\n",
       "       'GAAAGTAGTATAAATGTTGTTTTTTTTATTTTACTCACCTCTAAAGCATAATTCCATATAAACTTGTTATTATCCGAAATTTTTGTATAATAGATTATTT',\n",
       "       'GAAACTGGCGAGGCGTTTGGGACGGCATTGTAATGATACTGAAAGGTACTGTGCAGTTAATTTGGAATTTAATTCAATTATGGTTTGTAGGCAAAATACT',\n",
       "       'GAAAATAAAAAATTG',\n",
       "       'GAAAAGCGAAGAAATAAATGGAAAAGATTTACAAAAAAAGTCTGAATTGCAGGGAACTGCTTTAAGCAATCTTAGACAAACCTATTATCATAATGGAAGT',\n",
       "       'GAAAACGCCTATTATAGCAACCCATATAATAGTTATTAAACCTTTTAGCAATCCGCCAAAGTACCTAACAACGCCAAGTATTTTGCCTACAAACCATAAT',\n",
       "       'GAAAAAAGTAGACGAGGCATACAACTTCTTGAAACAAGTTTCAGAAGATGGTGGACAAGTCTTATTCGTAGGAACTAAAAAACAAGCACAAGAATCAGTT',\n",
       "       'CTTTTTTTCTTATT',\n",
       "       'CTTTTTTTCTTATTATACGAAATTTTCATATCATAGTAAAGTTTTTTACGAAAAAAACGTATTTAATGTTGACAATACGAAAATTTCGTATTATATTAGG',\n",
       "       'CTTTTTTATTAATTTTAAAAAAAGCACCAAAAATTTAAATGGAGGTGTCTGAATGTCTGCTATCATTGAAGCTAAAAAACAACTAGTTGATGAAATTGCT',\n",
       "       'CTTTTTTAATTGTT',\n",
       "       'CTTTTGAGACATATTTGAATCGTTGAGAAATTTTCTAATGTTTTTGGCTATAATAATATTTCTTTCTTTGTTCATATTACTTACCTCCTTTTTTTCTTAT',\n",
       "       'CTTTTAGCAATCCGCCAAAGTACCTAACAACGCCAAGTATTTTGCCTACAAACCATAATTGAATTAAATTCCAAATTAACTGCACAGTACCTTTCAGTAT',\n",
       "       'CTTTCAAGCGTCATTTCAATAAAACGCTGGTCTATCATTAAGTCGTAGCCATCGTTGTATTGAATATTAACGGGTCGTCTATTACATTCTTCGTCATAGT',\n",
       "       'CTTTCAAGCACTTTTTGCCGTGGGTAGAAAGTGCTTTTTTATTAATTTTAAAAAAAGCACCAAAAATTTAAATGGAGGTGTCTGAATGTCTGCTATCATT',\n",
       "       'CTTTATCGCCAAGCCATTTGGTACCTTTACCTATTTGATCTTTTGTCCAGTTAAATGCCGATGATGCACCGGATTTAATATCTTTCCACATAGTACCTAT',\n",
       "       'CTTGTGCTTGTTTTTTAGTTCCTACGAATAAGACTTGTCCACCATCTTCTGAAACTTGTTTCAAGAAGTTGTATGCCTCGTCTACTTTTTTCACTGTTTT',\n",
       "       'CTTGAACGTGATGATCTATGATCTTTCAAGCACTTTTTGCCGTGGGTAGAAAGTGCTTTTTTATTAATTTTAAAAAAAGCACCAAAAATTTAAATGGAGG',\n",
       "       'CTTGAAAACGCCTATTATAGCAACCCATATAATAGTTATTAAACCTTTTAGCAATCCGCCAAAGTACCTAACAACGCCAAGTATTTTGCCTACAAACCAT',\n",
       "       'CTTCTCTACTTTCAATATTAGCTGAAGCATATGAATCGATAATAATTCGATTGTAGTCAGATGTTAAAGCGACTACACCGCCATAAGAATTGATTGTTAT',\n",
       "       'CTTCCATTATGATAATAGGTTTGTCTAAGATTGCTTAAAGCAGTTCCCTGCAATTCAGACTTTTTTTGTAAATCTTTTCCATTTATTTCTTCGCTTTTCT',\n",
       "       'CTTCCAAGATTTAGCATAGGTACTATGTGGAAAGATATTAAATCCGGTGCATCATCGGCATTTAACTGGACAAAAGATCAAATAGGTAAAGGTACCAAAT',\n",
       "       'CTTCACGCTTTGTTCTAAAACCTTTCTTACGGTATCTTTTTCCTTCATGCTTAAACTCATATTGCCATTTTTTACCATCGTAACAACGTGTTTTCATGTG',\n",
       "       'CTTCAATGATAGCAGACATTCAGACACCTCCATTTAAATTTTTGGTGCTTTTTTTAAAATTAATAAAAAAGCACTTTCTACCCACGGCAAAAAGTGCTTG',\n",
       "       'CTTACCTCCTTTTTTTCTTATTATACGAAATTTTCATATCATAGTAAAGTTTTTTACGAAAAAAACGTATTTAATGTTGACAATACGAAAATTTCGTATT',\n",
       "       'CTTAATCGTTTT',\n",
       "       'CTGTGCAGTTAATTTGGAATTTAATTCAATTATGGTTTGTAGGCAAAATACTTGGCGTTGTTAGGTACTTTGGCGGATTGCTAAAAGGTTTAATAACTAT',\n",
       "       'CTGTACTTTTATTTACTGACAAATGATTGCTAGACTCGAAATCGTTGACTACAATATAGTATTCATAGTCGGTTTTTATCGAGTAATTTTTCGAATTCAT',\n",
       "       'CTGACAAATGATTGCTAGACTCGAAATCGTTGACTACAATATAGTATTCATAGTCGGTTTTTATCGAGTAATTTTTCGAATTCATCAAAAATTCTATAGT',\n",
       "       'CTGAAAGGTACTGTGCAGTTAATTTGGAATTTAATTCAATTATGGTTTGTAGGCAAAATACTTGGCGTTGTTAGGTACTTTGGCGGATTGCTAAAAGGTT',\n",
       "       'CTCTTTATTTTCAATTATAGCACTTCCATTATGATAATAGGTTTGTCTAAGATTGCTTAAAGCAGTTCCCTGCAATTCAGACTTTTTTTGTAAATCTTTT',\n",
       "       'CTCTCTTTATTTTCAATTATAGCACTTCCATTATGATAATAGGTTTGTCTAAGATTGCTTAAAGCAGTTCCCTGCAATTCAGACTTTTTTTGTAAATCTT',\n",
       "       'CTCGCCTACCCTTATTATTTTTTGCCAATTTTGAGG',\n",
       "       'CTCGATAAAAACCGACTATGAATACTATATTGTAGTCAACGATTTCGAGTCTAGCAATCATTTGTCAGTAAATAAAAGTACAGGAAATCAATATTTTGCT',\n",
       "       'CTCCTTTTTTTCTTATTATACGAAATTTTCATATCATAGTAAAGTTTTTTACGAAAAAAACGTATTTAATGTTGACAATACGAAAATTTCGTATTATATT',\n",
       "       'CTCCATTTAAATTTTTGGTGCTTTTTTTAAAATTAATAAAAAAGCACTTTCTACCCACGGCAAAAAGTGCTTGAAAGATCATAGATCATCACGTTCAAGT',\n",
       "       'CTCCAACAAAAATAATCTATTATACAAAAATTTCGGATAATAACAAGTTTATATGGAATTATGCTTTAGAGGTGAGTAAAATAAAAAAAACAACATTTAT',\n",
       "       'CTCAAAAAGCAGTCGGTAAATCTGCAAGTAAAATAACAGTTGGAAGTAAAGCACCTTATAACCTTAAATGGTCAAAAGGTGCTTATTTTAATGCGAAAAT',\n",
       "       'CTATTATACAAAAATTTCGGATAATAACAAGTTTATATGGAATTATGCTTTAGAGGTGAGTAAAATAAAAAAAACAACATTTATACTACTTTCATTTATT',\n",
       "       'CTATTACTACTATGACGAAGAATGTAATAGACGACCCGTTAATATTCAATACAACGATGGCTACGACTTAATGATAGACCAGCGTTTTATTGAAATGACG',\n",
       "       'CTATGTGGCGCTT',\n",
       "       'CTATGAATACTATATTGTAGTCAACGATTTCGAGTCTAGCAATCATTTGTCAGTAAATAAAAGTACAGGAAATCAATATTTTGCTACTATAAACGAAATT',\n",
       "       'CTATAGAATTTTTGATGAATTCGAAAAATTACTCGATAAAAACCGACTATGAATACTATATTGTAGTCAACGATTTCGAGTCTAGCAATCATTTGTCAGT',\n",
       "       'CTATAATAATATTTCTTTCTTTGTTCATATTACTTACCTCCTTTTTTTCTTATTATACGAAATTTTCATATCATAGTAAAGTTTTTTACGAAAAAAACGT',\n",
       "       'CTATAACACTTT',\n",
       "       'CTAGTTTATTAAATTTATTTTTGCGCTTTCCAAATCAATGTATATGTGTTATATTGT',\n",
       "       'CTAGTGGCTGAAGTAGCACCTAAGCCGTCGATTTTCGCATTAAAATAAGCACCTTTTGACCATTTAAGGTTATAAGGTGCTTTACTTCCAACTGTTATTT',\n",
       "       'CTACTTTCAATATTAGCTGAAGCATATGAATCGATAATAATTCGATTGTAGTCAGATGTTAAAGCGACTACACCGCCATAAGAATTGATTGTTATGCCAT',\n",
       "       'CTACGAATAAGACTTGTCCACCATCTTCTGAAACTTGTTTCAAGAAGTTGTATGCCTCGTCTACTTTTTTCACTGTTTTTTGTAAGTCGATGATATAAAT',\n",
       "       'CTAATGTTTTTGGCTATAATAATATTTCTTTCTTTGTTCATATTACTTACCTCCTTTTTTTCTTATTATACGAAATTTTCATATCATAGTAAAGTTTTTT',\n",
       "       'CTAATATAATACGAAATTTTCGTATTGTCAACATTAAATACGTTTTTTTCGTAAAAAACTTTACTATGATATGAAAATTTCGTATAATAAGAAAAAAAGG',\n",
       "       'CTAAGTATATGAGTGCTTTTAATGTTAAATATGATGATATTTTTTTAGGTAATGAATACGAAAATTTCGTATTTACGAACGATAAAAAGAAATCAATTAT',\n",
       "       'CTAAGAATTAAAAT',\n",
       "       'CTAAAATTGACTTGAACGTGATGATCTATGATCTTTCAAGCACTTTTTGCCGTGGGTAGAAAGTGCTTTTTTATTAATTTTAAAAAAAGCACCAAAAATT',\n",
       "       'CGTTTATAGTAGCAAAATATTGATTTCCTGTACTTTTATTTACTGACAAATGATTGCTAGACTCGAAATCGTTGACTACAATATAGTATTCATAGTCGGT',\n",
       "       'CGTTAGGGCAATAAATGAAAGTAGTATAAATGTTGTTTTTTTTATTTTACTCACCTCTAAAGCATAATTCCATATAAACTTGTTATTATCCGAAATTTTT',\n",
       "       'CGTGATGATCTATGATCTTTCAAGCACTTTTTGCCGTGGGTAGAAAGTGCTTTTTTATTAATTTTAAAAAAAGCACCAAAAATTTAAATGGAGGTGTCTG',\n",
       "       'CGTCGATTTTCGCATTAAAATAAGCACCTTTTGACCATTTAAGGTTATAAGGTGCTTTACTTCCAACTGTTATTTTACTTGCAGATTTACCGACTGCTTT',\n",
       "       'CGTATCTAGTGGCTGAAGTAGCACCTAAGCCGTCGATTTTCGCATTAAAATAAGCACCTTTTGACCATTTAAGGTTATAAGGTGCTTTACTTCCAACTGT',\n",
       "       'CGTATAATAAGAAAAAAAGGAGGTAAGTAATATGAACAAAGAAAGAAATATTATTATAGCCAAAAACATTAGAAAATTTCTCAACGATTCAAATATGTCT',\n",
       "       'CGGTGCATCATCGGCATTTAACTGGACAAAAGATCAAATAGGTAAAGGTACCAAATGGCTTGGCGATAAAGTTGGCGATGTTTTAGATTTTATTGAAAAT',\n",
       "       'CGGTAAATCTGCAAGTAAAATAACAGTTGGAAGTAAAGCACCTTATAACCTTAAATGGTCAAAAGGTGCTTATTTTAATGCGAAAATCGACGGCTTAGGT',\n",
       "       'CGCTTCTCTACTTTCAATATTAGCTGAAGCATATGAATCGATAATAATTCGATTGTAGTCAGATGTTAAAGCGACTACACCGCCATAAGAATTGATTGTT',\n",
       "       'CGCATTAAAATAAGCACCTTTTGACCATTTAAGGTTATAAGGTGCTTTACTTCCAACTGTTATTTTACTTGCAGATTTACCGACTGCTTTTTGAGCAGGT',\n",
       "       'CGATTTTCGCATTAAAATAAGCACCTTTTGACCATTTAAGGTTATAAGGTGCTTTACTTCCAACTGTTATTTTACTTGCAGATTTACCGACTGCTTTTTG',\n",
       "       'CGATAATGATTTCTTGAAAACGCCTATTATAGCAACCCATATAATAGTTATTAAACCTTTTAGCAATCCGCCAAAGTACCTAACAACGCCAAGTATTTTG',\n",
       "       'CCTTTTCGGG', 'CCTGTACTTTT',\n",
       "       'CCTGGATTTTCAATAAAATCTAAAACATCGCCAACTTTATCGCCAAGCCATTTGGTACCTTTACCTATTTGATCTTTTGTCCAGTTAAATGCCGATGATG',\n",
       "       'CCTCCTTTTTTTCTT',\n",
       "       'CCTCCTATTAAGATGTTTGTTTTTCTTTAAATGCTAAAATAATTGATTTCTTTTTATCGTTCGTAAATACGAAATTTTCGTATTCATTACCTAAAAAAAT',\n",
       "       'CCGTGGGTAGAAAGTGCTTTTTTATTAATTTTAAAAAAAGCACCAAAAATTTAAATGGAGGTGTCTGAATGTCTGCTATCATTGAAGCTAAAAAACAACT',\n",
       "       'CCGTCGATTTTCGCATTAAAATAAGCACCTTTTGACCATTTAAGGTTATAAGGTGCTTTACTTCCAACTGTTATTTTACTTGCAGATTTACCGACTGCTT',\n",
       "       'CCGTATCTAGTGGCTGAAGTAGCACCTAAGCCGTCGATTTTCGCATTAAAATAAGCACCTTTTGACCATTTAAGGTTATAAGGTGCTTTACTTCCAACTG',\n",
       "       'CCGATAATGATTTCTTGAAAACGCCTATTATAGCAACCCATATAATAGTTATTAAACCTTTTAGCAATCCGCCAAAGTACCTAACAACGCCAAGTATTTT',\n",
       "       'CCCGGCAAGT',\n",
       "       'CCACTTCTTAACTCATTTAACTTGTCTAGTCCAGCAGAATTAGCTTCACGCTTTGTTCTAAAACCTTTCTTACGGTATCTTTTTCCTTCATGCTTAAACT',\n",
       "       'CCACCTGCTCAAAAAGCAGTCGGTAAATCTGCAAGTAAAATAACAGTTGGAAGTAAAGCACCTTATAACCTTAAATGGTCAAAAGGTGCTTATTTTAATG',\n",
       "       'CCAATTTTGAGGAGGGAACACATGAAAACACGTTGTTACGATGGTAAAAAATGGCAATATGAGTTTAAGCATGAAGGAAAAAGATACCGTAAGAAAGGTT',\n",
       "       'CCAAGTATTTTGCCTACAAACCATAATTGAATTAAATTCCAAATTAACTGCACAGTACCTTTCAGTATCATTACAATGCCGTCCCAAACGCCTCGCCAGT',\n",
       "       'CCAAAGTACCTAACAACGCCAAGTATTTTGCCTACAAACCATAATTGAATTAAATTCCAAATTAACTGCACAGTACCTTTCAGTATCATTACAATGCCGT',\n",
       "       'CATTTCATAACTTGCCAAACCTTTATATATCTAATTATCAAACTGCACTAAACTTACCAAAACCGCTTATTCTATTACCTGCCTTGTCTACCTCTCCTGT',\n",
       "       'CATTCAGACACCTCCATTTAAATTTTTGGTGCTTTTTTTAAAATTAATAAAAAAGCACTTTCTACCCACGGCAAAAAGTGCTTGAAAGATCATAGATCAT',\n",
       "       'CATTAACTCGT',\n",
       "       'CATTAAATACGTTTTTTTCGTAAAAAACTTTACTATGATATGAAAATTTCGTATAATAAGAAAAAAAGGAGGTAAGTAATATGAACAAAGAAAGAAATAT',\n",
       "       'CATGTGTTCCCTCCT', 'CATCTATTCT',\n",
       "       'CATCAACTAGTTGTTTTTTAGCTTCAATGATAGCAGACATTCAGACACCTCCATTTAAATTTTTGGTGCTTTTTTTAAAATTAATAAAAAAGCACTTTCT',\n",
       "       'CATATTACTTACCTCCTTTTTTTCTTATTATACGAAATTTTCATATCATAGTAAAGTTTTTTACGAAAAAAACGTATTTAATGTTGACAATACGAAAATT',\n",
       "       'CATAGTTCTGT',\n",
       "       'CAGTCGGTAAATCTGCAAGTAAAATAACAGTTGGAAGTAAAGCACCTTATAACCTTAAATGGTCAAAAGGTGCTTATTTTAATGCGAAAATCGACGGCTT',\n",
       "       'CAGGAGAGGTAGACAAGGCAGGTAATAGAATAAGCGGTTTTGGTAAGTTTAGTGCAGTTTGATAATTAGATATATAAAGGTTTGGCAAGTTATGAAATGT',\n",
       "       'CAGGAAACTGGCGAGGCGTTTGGGACGGCATTGTAATGATACTGAAAGGTACTGTGCAGTTAATTTGGAATTTAATTCAATTATGGTTTGTAGGCAAAAT',\n",
       "       'CAGCCTATCATCATTACTGGACATGAAATTAACAGTTTTCACCTCCATCAAGAATTAGAAGATTTTGTAAATCAAACACAGATACCAGTAGCACAACTTT',\n",
       "       'CACTTCCATTATGATAATAGGTTTGTCTAAGATTGCTTAAAGCAGTTCCCTGCAATTCAGACTTTTTTTGTAAATCTTTTCCATTTATTTCTTCGCTTTT',\n",
       "       'CACTCGATAAAT',\n",
       "       'CACATATTAATTACTATTAATAGAAAAATTATAGCGTTTTTTAGATCATTTCAATTTATCAAGACCAAATTCATCAAAACACTAATTGAACTTTAATTTT',\n",
       "       'CACACTTATTT',\n",
       "       'CAATTTTGAGGAGGGAACACATGAAAACACGTTGTTACGATGGTAAAAAATGGCAATATGAGTTTAAGCATGAAGGAAAAAGATACCGTAAGAAAGGTTT',\n",
       "       'CAATTATGGTTTGTAGGCAAAATACTTGGCGTTGTTAGGTACTTTGGCGGATTGCTAAAAGGTTTAATAACTATTATATGGGTTGCTATAATAGGCGTTT',\n",
       "       'CAATAAAATCTAAAACATCGCCAACTTTATCGCCAAGCCATTTGGTACCTTTACCTATTTGATCTTTTGTCCAGTTAAATGCCGATGATGCACCGGATTT',\n",
       "       'CAAGTATTTTGCCTACAAACCATAATTGAATTAAATTCCAAATTAACTGCACAGTACCTTTCAGTATCATTACAATGCCGTCCCAAACGCCTCGCCAGTT',\n",
       "       'CAAGGCAGGTAATAGAATAAGCGGTTTTGGTAAGTTTAGTGCAGTTTGATAATTAGATATATAAAGGTTTGGCAAGTTATGAAATGTCTGCCAAACCTTT',\n",
       "       'CAAGCCATTTGGTACCTTTACCTATTTGATCTTTTGTCCAGTTAAATGCCGATGATGCACCGGATTTAATATCTTTCCACATAGTACCTATGCTAAATCT',\n",
       "       'CAAGATTTAGCATAGGTACTATGTGGAAAGATATTAAATCCGGTGCATCATCGGCATTTAACTGGACAAAAGATCAAATAGGTAAAGGTACCAAATGGCT',\n",
       "       'CAACCCATATAATAGTTATTAAACCTTTTAGCAATCCGCCAAAGTACCTAACAACGCCAAGTATTTTGCCTACAAACCATAATTGAATTAAATTCCAAAT',\n",
       "       'ATTTTTGAAGATT',\n",
       "       'ATTTTCTAATGTTTTTGGCTATAATAATATTTCTTTCTTTGTTCATATTACTTACCTCCTTTTTTTCTTATTATACGAAATTTTCATATCATAGTAAAGT',\n",
       "       'ATTTTCGTTTAGAT',\n",
       "       'ATTTTCAATTATAGCACTTCCATTATGATAATAGGTTTGTCTAAGATTGCTTAAAGCAGTTCCCTGCAATTCAGACTTTTTTTGTAAATCTTTTCCATTT',\n",
       "       'ATTTGAATCGTTGAGAAATTTTCTAATGTTTTTGGCTATAATAATATTTCTTTCTTTGTTCATATTACTTACCTCCTTTTTTTCTTATTATACGAAATTT',\n",
       "       'ATTTCGTTTATAGTAGCAAAATATTGATTTCCTGTACTTTTATTTACTGACAAATGATTGCTAGACTCGAAATCGTTGACTACAATATAGTATTCATAGT',\n",
       "       'ATTTCGTATAATAAGAAAAAAAGGAGGTAAGTAATATGAACAAAGAAAGAAATATTATTATAGCCAAAAACATTAGAAAATTTCTCAACGATTCAAATAT',\n",
       "       'ATTTCATCAACTAGTTGTTTTTTAGCTTCAATGATAGCAGACATTCAGACACCTCCATTTAAATTTTTGGTGCTTTTTTTAAAATTAATAAAAAAGCACT',\n",
       "       'ATTTACTGACAAATGATTGCTAGACTCGAAATCGTTGACTACAATATAGTATTCATAGTCGGTTTTTATCGAGTAATTTTTCGAATTCATCAAAAATTCT',\n",
       "       'ATTTAATTCAATTATGGTTTGTAGGCAAAATACTTGGCGTTGTTAGGTACTTTGGCGGATTGCTAAAAGGTTTAATAACTATTATATGGGTTGCTATAAT',\n",
       "       'ATTTAAATTTTTGGTGCTTTTTTTAAAATTAATAAAAAAGCACTTTCTACCCACGGCAAAAAGTGCTTGAAAGATCATAGATCATCACGTTCAAGTCAAT',\n",
       "       'ATTGTAATGATACTGAAAGGTACTGTGCAGTTAATTTGGAATTTAATTCAATTATGGTTTGTAGGCAAAATACTTGGCGTTGTTAGGTACTTTGGCGGAT',\n",
       "       'ATTGATTTCCTGTACTTTTATTTACTGACAAATGATTGCTAGACTCGAAATCGTTGACTACAATATAGTATTCATAGTCGGTTTTTATCGAGTAATTTTT',\n",
       "       'ATTGATACCCTT',\n",
       "       'ATTCTTGTGCTTGTTTTTTAGTTCCTACGAATAAGACTTGTCCACCATCTTCTGAAACTTGTTTCAAGAAGTTGTATGCCTCGTCTACTTTTTTCACTGT',\n",
       "       'ATTATCACCGTATCTAGTGGCTGAAGTAGCACCTAAGCCGTCGATTTTCGCATTAAAATAAGCACCTTTTGACCATTTAAGGTTATAAGGTGCTTTACTT',\n",
       "       'ATTATCAATAGGT',\n",
       "       'ATTATAGCACTTCCATTATGATAATAGGTTTGTCTAAGATTGCTTAAAGCAGTTCCCTGCAATTCAGACTTTTTTTGTAAATCTTTTCCATTTATTTCTT',\n",
       "       'ATTACTCGATAAAAACCGACTATGAATACTATATTGTAGTCAACGATTTCGAGTCTAGCAATCATTTGTCAGTAAATAAAAGTACAGGAAATCAATATTT',\n",
       "       'ATTACTCCAACAAAAATAATCTATTATACAAAAATTTCGGATAATAACAAGTTTATATGGAATTATGCTTTAGAGGTGAGTAAAATAAAAAAAACAACAT',\n",
       "       'ATTACTACTATGACGAAGAATGTAATAGACGACCCGTTAATATTCAATACAACGATGGCTACGACTTAATGATAGACCAGCGTTTTATTGAAATGACGCT',\n",
       "       'ATTAAATACGTTTTTTTCGTAAAAAACTTTACTATGATATGAAAATTTCGTATAATAAGAAAAAAAGGAGGTAAGTAATATGAACAAAGAAAGAAATATT',\n",
       "       'ATTAAACCTTTTAGCAATCCGCCAAAGTACCTAACAACGCCAAGTATTTTGCCTACAAACCATAATTGAATTAAATTCCAAATTAACTGCACAGTACCTT',\n",
       "       'ATTAAAACACTTCTTTCACAATCAATCTCTCATGCCATATCCACTCATTAT',\n",
       "       'ATTAAAACACTTCTTTCACAATCAATCTCTCATGCCATATCCACTCATTATGATTGTTCCAATAAATGCGACACCAACCAT',\n",
       "       'ATGTTTGTTTTTCTTTAAATGCTAAAATAATTGATTTCTTTTTATCGTTCGTAAATACGAAATTTTCGTATTCATTACCTAAAAAAATATCATCATATTT',\n",
       "       'ATGCGGATGTCTTTCAAGCGTCATTTCAATAAAACGCTGGTCTATCATTAAGTCGTAGCCATCGTTGTATTGAATATTAACGGGTCGTCTATTACATTCT',\n",
       "       'ATGAAAGTAGTATAAATGTTGTTTTTTTTATTTTACTCACCTCTAAAGCATAATTCCATATAAACTTGTTATTATCCGAAATTTTTGTATAATAGATTAT',\n",
       "       'ATCTGCAAGTAAAATAACAGTTGGAAGTAAAGCACCTTATAACCTTAAATGGTCAAAAGGTGCTTATTTTAATGCGAAAATCGACGGCTTAGGTGCTACT',\n",
       "       'ATCTATGATCTTTCAAGCACTTTTTGCCGTGGGTAGAAAGTGCTTTTTTATTAATTTTAAAAAAAGCACCAAAAATTTAAATGGAGGTGTCTGAATGTCT',\n",
       "       'ATCTAGTGGCTGAAGTAGCACCTAAGCCGTCGATTTTCGCATTAAAATAAGCACCTTTTGACCATTTAAGGTTATAAGGTGCTTTACTTCCAACTGTTAT',\n",
       "       'ATCGAGTAATT',\n",
       "       'ATCATTACTCTCTTTATTTTCAATTATAGCACTTCCATTATGATAATAGGTTTGTCTAAGATTGCTTAAAGCAGTTCCCTGCAATTCAGACTTTTTTTGT',\n",
       "       'ATATTGATTTCCTGTACTTTTATTTACTGACAAATGATTGCTAGACTCGAAATCGTTGACTACAATATAGTATTCATAGTCGGTTTTTATCGAGTAATTT',\n",
       "       'ATATTACTTACCTCCTTTTTTTCTTATTATACGAAATTTTCATATCATAGTAAAGTTTTTTACGAAAAAAACGTATTTAATGTTGACAATACGAAAATTT',\n",
       "       'ATATGTATTCTTT',\n",
       "       'ATATGATGATATTTTTTTAGGTAATGAATACGAAAATTTCGTATTTACGAACGATAAAAAGAAATCAATTATTTTAGCATTTAAAGAAAAACAAACATCT',\n",
       "       'ATACGAAATTTTCGTATTGTCAACATTAAATACGTTTTTTTCGTAAAAAACTTTACTATGATATGAAAATTTCGTATAATAAGAAAAAAAGGAGGTAAGT',\n",
       "       'ATACAAAAATTTCGGATAATAACAAGTTTATATGGAATTATGCTTTAGAGGTGAGTAAAATAAAAAAAACAACATTTATACTACTTTCATTTATTGCCCT',\n",
       "       'ATAAGCGGTTTT', 'ATAAATTTACCTGTT',\n",
       "       'ATAAAGGTTTGGCAGACATTTCATAACTTGCCAAACCTTTATATATCTAATTATCAAACTGCACTAAACTTACCAAAACCGCTTATTCTATTACCTGCCT',\n",
       "       'AGTTTCTTTTGAGACATATTTGAATCGTTGAGAAATTTTCTAATGTTTTTGGCTATAATAATATTTCTTTCTTTGTTCATATTACTTACCTCCTTTTTTT',\n",
       "       'AGTTGTGCTACTGGTATCTGTGTTTGATTTACAAAATCTTCTAATTCTTGATGGAGGTGAAAACTGTTAATTTCATGTCCAGTAATGATGATAGGCTGCT',\n",
       "       'AGTTGGAAGTAAAGCACCTTATAACCTTAAATGGTCAAAAGGTGCTTATTTTAATGCGAAAATCGACGGCTTAGGTGCTACTTCAGCCACTAGATACGGT',\n",
       "       'AGTGATAGTGGT', 'AGTATTCATAGT',\n",
       "       'AGTATATGAGTGCTTTTAATGTTAAATATGATGATATTTTTTTAGGTAATGAATACGAAAATTTCGTATTTACGAACGATAAAAAGAAATCAATTATTTT',\n",
       "       'AGTACGATTATCACCGTATCTAGTGGCTGAAGTAGCACCTAAGCCGTCGATTTTCGCATTAAAATAAGCACCTTTTGACCATTTAAGGTTATAAGGTGCT',\n",
       "       'AGGCGTTTGGGACGGCATTGTAATGATACTGAAAGGTACTGTGCAGTTAATTTGGAATTTAATTCAATTATGGTTTGTAGGCAAAATACTTGGCGTTGTT',\n",
       "       'AGGCATCTATT',\n",
       "       'AGCTTCAATGATAGCAGACATTCAGACACCTCCATTTAAATTTTTGGTGCTTTTTTTAAAATTAATAAAAAAGCACTTTCTACCCACGGCAAAAAGTGCT',\n",
       "       'AGCACTTCCATTATGATAATAGGTTTGTCTAAGATTGCTTAAAGCAGTTCCCTGCAATTCAGACTTTTTTTGTAAATCTTTTCCATTTATTTCTTCGCTT',\n",
       "       'AGATTTACAAAAAAAGTCTGAATTGCAGGGAACTGCTTTAAGCAATCTTAGACAAACCTATTATCATAATGGAAGTGCTATAATTGAAAATAAAGAGAGT',\n",
       "       'AGACACCTCCATTTAAATTTTTGGTGCTTTTTTTAAAATTAATAAAAAAGCACTTTCTACCCACGGCAAAAAGTGCTTGAAAGATCATAGATCATCACGT',\n",
       "       'AGAATAGATGTT', 'AGAATAAGCAGTT',\n",
       "       'AGAAATAAATGGAAAAGATTTACAAAAAAAGTCTGAATTGCAGGGAACTGCTTTAAGCAATCTTAGACAAACCTATTATCATAATGGAAGTGCTATAATT',\n",
       "       'AGAAAAGTTGTTT',\n",
       "       'ACTGAAAGGTACTGTGCAGTTAATTTGGAATTTAATTCAATTATGGTTTGTAGGCAAAATACTTGGCGTTGTTAGGTACTTTGGCGGATTGCTAAAAGGT',\n",
       "       'ACGTTAGGGCAATAAATGAAAGTAGTATAAATGTTGTTTTTTTTATTTTACTCACCTCTAAAGCATAATTCCATATAAACTTGTTATTATCCGAAATTTT',\n",
       "       'ACAAGGCAGGTAATAGAATAAGCGGTTTTGGTAAGTTTAGTGCAGTTTGATAATTAGATATATAAAGGTTTGGCAAGTTATGAAATGTCTGCCAAACCTT',\n",
       "       'AATTTGGAATTTAATTCAATTATGGTTTGTAGGCAAAATACTTGGCGTTGTTAGGTACTTTGGCGGATTGCTAAAAGGTTTAATAACTATTATATGGGTT',\n",
       "       'AATTATGGTTTGTAGGCAAAATACTTGGCGTTGTTAGGTACTTTGGCGGATTGCTAAAAGGTTTAATAACTATTATATGGGTTGCTATAATAGGCGTTTT',\n",
       "       'AATTACTCGATAAAAACCGACTATGAATACTATATTGTAGTCAACGATTTCGAGTCTAGCAATCATTTGTCAGTAAATAAAAGTACAGGAAATCAATATT',\n",
       "       'AATGTAATAGACGACCCGTTAATATTCAATACAACGATGGCTACGACTTAATGATAGACCAGCGTTTTATTGAAATGACGCTTGAAAGACATCCGCATTT',\n",
       "       'AATCTATTATACAAAAATTTCGGATAATAACAAGTTTATATGGAATTATGCTTTAGAGGTGAGTAAAATAAAAAAAACAACATTTATACTACTTTCATTT',\n",
       "       'AATAATATTTCTTTCTTTGTTCATATTACTTACCTCCTTTTTTTCTTATTATACGAAATTTTCATATCATAGTAAAGTTTTTTACGAAAAAAACGTATTT',\n",
       "       'AATAAGCGGTT',\n",
       "       'AAGTATTTTGCCTACAAACCATAATTGAATTAAATTCCAAATTAACTGCACAGTACCTTTCAGTATCATTACAATGCCGTCCCAAACGCCTCGCCAGTTT',\n",
       "       'AAGTATATGAGTGCTTTTAATGTTAAATATGATGATATTTTTTTAGGTAATGAATACGAAAATTTCGTATTTACGAACGATAAAAAGAAATCAATTATTT',\n",
       "       'AAGTAGTATAAATGTTGTTTTTTTTATTTTACTCACCTCTAAAGCATAATTCCATATAAACTTGTTATTATCCGAAATTTTTGTATAATAGATTATTTTT',\n",
       "       'AAGCCATTTGGTACCTTTACCTATTTGATCTTTTGTCCAGTTAAATGCCGATGATGCACCGGATTTAATATCTTTCCACATAGTACCTATGCTAAATCTT',\n",
       "       'AACGTTAGGGCAATAAATGAAAGTAGTATAAATGTTGTTTTTTTTATTTTACTCACCTCTAAAGCATAATTCCATATAAACTTGTTATTATCCGAAATTT',\n",
       "       'AAATTTCGGGTAGCTCGCCTACCCTTATTATTTTTT', 'ST', 'CC'], dtype='<U100')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names_arr = np.array(names)\n",
    "names_arr[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###### keep selected variables as a new dataframe\n",
    "df_sel = df_clean.loc[:,names_arr[cols]].copy()\n",
    "df_sel['pheno'] = df_clean['pheno']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_sel['strain'] = X.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TTTTTTTTATTTTACTCACCTCTAAAGCATAATTCCATATAAACTTGTTATTATCCGAAATTTTTGTATAATAGATTATTTTTGTTGGAGTAATTATTAG</th>\n",
       "      <th>TTTTTTTAGGTAATGAATACGAAAATTTCGTATTTACGAACGATAAAAAGAAATCAATTATTTTAGCATTTAAAGAAAAACAAACATCTTAATAGGAGGA</th>\n",
       "      <th>TTTTTTTAAAATTAATAAAAAAGCACTTTCTACCCACGGCAAAAAGTGCTTGAAAGATCATAGATCATCACGTTCAAGTCAATTTTAGCCTCGGCAGGAT</th>\n",
       "      <th>TTTTTTGCCAATTTTGAGGAGGGAACACATGAAAACACGTTGTTACGATGGTAAAAAATGGCAATATGAGTTTAAGCATGAAGGAAAAAGATACCGTAAG</th>\n",
       "      <th>TTTTTTCGTAAAAAACTTTACTATGATATGAAAATTTCGTATAATAAGAAAAAAAGGAGGTAAGTAATATGAACAAAGAAAGAAATATTATTATAGCCAA</th>\n",
       "      <th>TTTTTTAGTTCCTACGAATAAGACTTGTCCACCATCTTCTGAAACTTGTTTCAAGAAGTTGTATGCCTCGTCTACTTTTTTCACTGTTTTTTGTAAGTCG</th>\n",
       "      <th>TTTTTTAGGTAATGAATACGAAAATTTCGTATTTACGAACGATAAAAAGAAATCAATTATTTTAGCATTTAAAGAAAAACAAACATCTTAATAGGAGGAA</th>\n",
       "      <th>TTTTTTAGCTTCAATGATAGCAGACATTCAGACACCTCCATTTAAATTTTTGGTGCTTTTTTTAAAATTAATAAAAAAGCACTTTCTACCCACGGCAAAA</th>\n",
       "      <th>TTTTTGGTGCTTTTTTTAAAATTAATAAAAAAGCACTTTCTACCCACGGCAAAAAGTGCTTGAAAGATCATAGATCATCACGTTCAAGTCAATTTTAGCC</th>\n",
       "      <th>TTTTTGGCTATAATAATATTTCTTTCTTTGTTCATATTACTTACCTCCTTTTTTTCTTATTATACGAAATTTTCATATCATAGTAAAGTTTTTTACGAAA</th>\n",
       "      <th>...</th>\n",
       "      <th>AAGTATTTTGCCTACAAACCATAATTGAATTAAATTCCAAATTAACTGCACAGTACCTTTCAGTATCATTACAATGCCGTCCCAAACGCCTCGCCAGTTT</th>\n",
       "      <th>AAGTATATGAGTGCTTTTAATGTTAAATATGATGATATTTTTTTAGGTAATGAATACGAAAATTTCGTATTTACGAACGATAAAAAGAAATCAATTATTT</th>\n",
       "      <th>AAGTAGTATAAATGTTGTTTTTTTTATTTTACTCACCTCTAAAGCATAATTCCATATAAACTTGTTATTATCCGAAATTTTTGTATAATAGATTATTTTT</th>\n",
       "      <th>AAGCCATTTGGTACCTTTACCTATTTGATCTTTTGTCCAGTTAAATGCCGATGATGCACCGGATTTAATATCTTTCCACATAGTACCTATGCTAAATCTT</th>\n",
       "      <th>AACGTTAGGGCAATAAATGAAAGTAGTATAAATGTTGTTTTTTTTATTTTACTCACCTCTAAAGCATAATTCCATATAAACTTGTTATTATCCGAAATTT</th>\n",
       "      <th>AAATTTCGGGTAGCTCGCCTACCCTTATTATTTTTT</th>\n",
       "      <th>ST</th>\n",
       "      <th>CC</th>\n",
       "      <th>pheno</th>\n",
       "      <th>strain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>120335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>120337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>SR4152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3812</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>SR4153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>SR4155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>SR4156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3812</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>SR4187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>253 rows × 767 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     TTTTTTTTATTTTACTCACCTCTAAAGCATAATTCCATATAAACTTGTTATTATCCGAAATTTTTGTATAATAGATTATTTTTGTTGGAGTAATTATTAG  \\\n",
       "0                                                    1                                                      \n",
       "1                                                    0                                                      \n",
       "2                                                    0                                                      \n",
       "3                                                    0                                                      \n",
       "4                                                    0                                                      \n",
       "..                                                 ...                                                      \n",
       "248                                                  1                                                      \n",
       "249                                                  1                                                      \n",
       "250                                                  0                                                      \n",
       "251                                                  1                                                      \n",
       "252                                                  1                                                      \n",
       "\n",
       "     TTTTTTTAGGTAATGAATACGAAAATTTCGTATTTACGAACGATAAAAAGAAATCAATTATTTTAGCATTTAAAGAAAAACAAACATCTTAATAGGAGGA  \\\n",
       "0                                                    1                                                      \n",
       "1                                                    0                                                      \n",
       "2                                                    0                                                      \n",
       "3                                                    0                                                      \n",
       "4                                                    0                                                      \n",
       "..                                                 ...                                                      \n",
       "248                                                  0                                                      \n",
       "249                                                  0                                                      \n",
       "250                                                  0                                                      \n",
       "251                                                  0                                                      \n",
       "252                                                  0                                                      \n",
       "\n",
       "     TTTTTTTAAAATTAATAAAAAAGCACTTTCTACCCACGGCAAAAAGTGCTTGAAAGATCATAGATCATCACGTTCAAGTCAATTTTAGCCTCGGCAGGAT  \\\n",
       "0                                                    0                                                      \n",
       "1                                                    1                                                      \n",
       "2                                                    0                                                      \n",
       "3                                                    0                                                      \n",
       "4                                                    0                                                      \n",
       "..                                                 ...                                                      \n",
       "248                                                  0                                                      \n",
       "249                                                  0                                                      \n",
       "250                                                  1                                                      \n",
       "251                                                  0                                                      \n",
       "252                                                  0                                                      \n",
       "\n",
       "     TTTTTTGCCAATTTTGAGGAGGGAACACATGAAAACACGTTGTTACGATGGTAAAAAATGGCAATATGAGTTTAAGCATGAAGGAAAAAGATACCGTAAG  \\\n",
       "0                                                    1                                                      \n",
       "1                                                    0                                                      \n",
       "2                                                    0                                                      \n",
       "3                                                    0                                                      \n",
       "4                                                    0                                                      \n",
       "..                                                 ...                                                      \n",
       "248                                                  1                                                      \n",
       "249                                                  1                                                      \n",
       "250                                                  0                                                      \n",
       "251                                                  1                                                      \n",
       "252                                                  1                                                      \n",
       "\n",
       "     TTTTTTCGTAAAAAACTTTACTATGATATGAAAATTTCGTATAATAAGAAAAAAAGGAGGTAAGTAATATGAACAAAGAAAGAAATATTATTATAGCCAA  \\\n",
       "0                                                    1                                                      \n",
       "1                                                    0                                                      \n",
       "2                                                    0                                                      \n",
       "3                                                    0                                                      \n",
       "4                                                    0                                                      \n",
       "..                                                 ...                                                      \n",
       "248                                                  1                                                      \n",
       "249                                                  0                                                      \n",
       "250                                                  0                                                      \n",
       "251                                                  1                                                      \n",
       "252                                                  0                                                      \n",
       "\n",
       "     TTTTTTAGTTCCTACGAATAAGACTTGTCCACCATCTTCTGAAACTTGTTTCAAGAAGTTGTATGCCTCGTCTACTTTTTTCACTGTTTTTTGTAAGTCG  \\\n",
       "0                                                    1                                                      \n",
       "1                                                    0                                                      \n",
       "2                                                    1                                                      \n",
       "3                                                    1                                                      \n",
       "4                                                    1                                                      \n",
       "..                                                 ...                                                      \n",
       "248                                                  1                                                      \n",
       "249                                                  1                                                      \n",
       "250                                                  0                                                      \n",
       "251                                                  1                                                      \n",
       "252                                                  1                                                      \n",
       "\n",
       "     TTTTTTAGGTAATGAATACGAAAATTTCGTATTTACGAACGATAAAAAGAAATCAATTATTTTAGCATTTAAAGAAAAACAAACATCTTAATAGGAGGAA  \\\n",
       "0                                                    1                                                      \n",
       "1                                                    0                                                      \n",
       "2                                                    0                                                      \n",
       "3                                                    0                                                      \n",
       "4                                                    0                                                      \n",
       "..                                                 ...                                                      \n",
       "248                                                  0                                                      \n",
       "249                                                  0                                                      \n",
       "250                                                  0                                                      \n",
       "251                                                  0                                                      \n",
       "252                                                  0                                                      \n",
       "\n",
       "     TTTTTTAGCTTCAATGATAGCAGACATTCAGACACCTCCATTTAAATTTTTGGTGCTTTTTTTAAAATTAATAAAAAAGCACTTTCTACCCACGGCAAAA  \\\n",
       "0                                                    0                                                      \n",
       "1                                                    1                                                      \n",
       "2                                                    0                                                      \n",
       "3                                                    0                                                      \n",
       "4                                                    0                                                      \n",
       "..                                                 ...                                                      \n",
       "248                                                  0                                                      \n",
       "249                                                  0                                                      \n",
       "250                                                  1                                                      \n",
       "251                                                  0                                                      \n",
       "252                                                  0                                                      \n",
       "\n",
       "     TTTTTGGTGCTTTTTTTAAAATTAATAAAAAAGCACTTTCTACCCACGGCAAAAAGTGCTTGAAAGATCATAGATCATCACGTTCAAGTCAATTTTAGCC  \\\n",
       "0                                                    0                                                      \n",
       "1                                                    1                                                      \n",
       "2                                                    0                                                      \n",
       "3                                                    0                                                      \n",
       "4                                                    0                                                      \n",
       "..                                                 ...                                                      \n",
       "248                                                  0                                                      \n",
       "249                                                  0                                                      \n",
       "250                                                  1                                                      \n",
       "251                                                  0                                                      \n",
       "252                                                  0                                                      \n",
       "\n",
       "     TTTTTGGCTATAATAATATTTCTTTCTTTGTTCATATTACTTACCTCCTTTTTTTCTTATTATACGAAATTTTCATATCATAGTAAAGTTTTTTACGAAA  \\\n",
       "0                                                    1                                                      \n",
       "1                                                    0                                                      \n",
       "2                                                    0                                                      \n",
       "3                                                    0                                                      \n",
       "4                                                    0                                                      \n",
       "..                                                 ...                                                      \n",
       "248                                                  1                                                      \n",
       "249                                                  0                                                      \n",
       "250                                                  0                                                      \n",
       "251                                                  1                                                      \n",
       "252                                                  0                                                      \n",
       "\n",
       "     ...  \\\n",
       "0    ...   \n",
       "1    ...   \n",
       "2    ...   \n",
       "3    ...   \n",
       "4    ...   \n",
       "..   ...   \n",
       "248  ...   \n",
       "249  ...   \n",
       "250  ...   \n",
       "251  ...   \n",
       "252  ...   \n",
       "\n",
       "     AAGTATTTTGCCTACAAACCATAATTGAATTAAATTCCAAATTAACTGCACAGTACCTTTCAGTATCATTACAATGCCGTCCCAAACGCCTCGCCAGTTT  \\\n",
       "0                                                    1                                                      \n",
       "1                                                    0                                                      \n",
       "2                                                    0                                                      \n",
       "3                                                    0                                                      \n",
       "4                                                    0                                                      \n",
       "..                                                 ...                                                      \n",
       "248                                                  1                                                      \n",
       "249                                                  1                                                      \n",
       "250                                                  0                                                      \n",
       "251                                                  1                                                      \n",
       "252                                                  1                                                      \n",
       "\n",
       "     AAGTATATGAGTGCTTTTAATGTTAAATATGATGATATTTTTTTAGGTAATGAATACGAAAATTTCGTATTTACGAACGATAAAAAGAAATCAATTATTT  \\\n",
       "0                                                    1                                                      \n",
       "1                                                    0                                                      \n",
       "2                                                    0                                                      \n",
       "3                                                    0                                                      \n",
       "4                                                    0                                                      \n",
       "..                                                 ...                                                      \n",
       "248                                                  0                                                      \n",
       "249                                                  0                                                      \n",
       "250                                                  0                                                      \n",
       "251                                                  0                                                      \n",
       "252                                                  0                                                      \n",
       "\n",
       "     AAGTAGTATAAATGTTGTTTTTTTTATTTTACTCACCTCTAAAGCATAATTCCATATAAACTTGTTATTATCCGAAATTTTTGTATAATAGATTATTTTT  \\\n",
       "0                                                    1                                                      \n",
       "1                                                    0                                                      \n",
       "2                                                    0                                                      \n",
       "3                                                    0                                                      \n",
       "4                                                    0                                                      \n",
       "..                                                 ...                                                      \n",
       "248                                                  1                                                      \n",
       "249                                                  1                                                      \n",
       "250                                                  0                                                      \n",
       "251                                                  1                                                      \n",
       "252                                                  1                                                      \n",
       "\n",
       "     AAGCCATTTGGTACCTTTACCTATTTGATCTTTTGTCCAGTTAAATGCCGATGATGCACCGGATTTAATATCTTTCCACATAGTACCTATGCTAAATCTT  \\\n",
       "0                                                    1                                                      \n",
       "1                                                    0                                                      \n",
       "2                                                    0                                                      \n",
       "3                                                    0                                                      \n",
       "4                                                    0                                                      \n",
       "..                                                 ...                                                      \n",
       "248                                                  1                                                      \n",
       "249                                                  1                                                      \n",
       "250                                                  0                                                      \n",
       "251                                                  1                                                      \n",
       "252                                                  1                                                      \n",
       "\n",
       "     AACGTTAGGGCAATAAATGAAAGTAGTATAAATGTTGTTTTTTTTATTTTACTCACCTCTAAAGCATAATTCCATATAAACTTGTTATTATCCGAAATTT  \\\n",
       "0                                                    1                                                      \n",
       "1                                                    0                                                      \n",
       "2                                                    0                                                      \n",
       "3                                                    0                                                      \n",
       "4                                                    0                                                      \n",
       "..                                                 ...                                                      \n",
       "248                                                  1                                                      \n",
       "249                                                  1                                                      \n",
       "250                                                  0                                                      \n",
       "251                                                  1                                                      \n",
       "252                                                  1                                                      \n",
       "\n",
       "     AAATTTCGGGTAGCTCGCCTACCCTTATTATTTTTT    ST  CC  pheno  strain  \n",
       "0                                       1     5   5      2     107  \n",
       "1                                       0     8   8      0     109  \n",
       "2                                       0     5   5      2     115  \n",
       "3                                       0     5   5      2  120335  \n",
       "4                                       0     5   5      2  120337  \n",
       "..                                    ...   ...  ..    ...     ...  \n",
       "248                                     1     5   5      2  SR4152  \n",
       "249                                     1  3812   5      1  SR4153  \n",
       "250                                     0     5   5      0  SR4155  \n",
       "251                                     1     5   5      2  SR4156  \n",
       "252                                     1  3812   5      2  SR4187  \n",
       "\n",
       "[253 rows x 767 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(253, 766) (253,) (253, 767)\n"
     ]
    }
   ],
   "source": [
    "X_sel = df_sel.loc[:, df_sel.columns != 'pheno']\n",
    "y_sel = df_sel['pheno']\n",
    "print(X_sel.shape, y_sel.shape, df_sel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    91\n",
       "0    88\n",
       "1    74\n",
       "Name: pheno, dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sel['pheno'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_sel_train, X_sel_test, y_sel_train, y_sel_test = train_test_split(X_sel, y_sel,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=567,\n",
    "                                                    stratify=y_sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat5 = pd.DataFrame(X_sel_test.iloc[:,-1])\n",
    "dat5['test'] = y_sel_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strain</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>NY360</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>NRS113</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120337</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>CFBREBSa127</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>GA27</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>SR1129</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>NRS152</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>CFBRSa66A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>BCH-SA-13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>SR4153</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          strain  test\n",
       "231        NY360     2\n",
       "139       NRS113     0\n",
       "4         120337     2\n",
       "59   CFBREBSa127     1\n",
       "96          GA27     2\n",
       "..           ...   ...\n",
       "236       SR1129     2\n",
       "145       NRS152     2\n",
       "86     CFBRSa66A     0\n",
       "28     BCH-SA-13     1\n",
       "249       SR4153     1\n",
       "\n",
       "[76 rows x 2 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sel_train = X_sel_train.drop(['strain'], axis=1)\n",
    "X_sel_test = X_sel_test.drop(['strain'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### neural network on over-sampling data\n",
    "model_sel = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_sel_train.shape[1],)),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sel.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 177 samples, validate on 76 samples\n",
      "Epoch 1/100\n",
      "177/177 [==============================] - 0s 633us/step - loss: 3.3655 - accuracy: 0.3729 - val_loss: 3.9710 - val_accuracy: 0.3684\n",
      "Epoch 2/100\n",
      "177/177 [==============================] - 0s 102us/step - loss: 2.2967 - accuracy: 0.4237 - val_loss: 3.5113 - val_accuracy: 0.4211\n",
      "Epoch 3/100\n",
      "177/177 [==============================] - 0s 139us/step - loss: 1.7892 - accuracy: 0.4407 - val_loss: 2.4204 - val_accuracy: 0.3816\n",
      "Epoch 4/100\n",
      "177/177 [==============================] - 0s 173us/step - loss: 1.4818 - accuracy: 0.4237 - val_loss: 1.9650 - val_accuracy: 0.3816\n",
      "Epoch 5/100\n",
      "177/177 [==============================] - 0s 183us/step - loss: 1.1147 - accuracy: 0.5311 - val_loss: 1.4581 - val_accuracy: 0.3684\n",
      "Epoch 6/100\n",
      "177/177 [==============================] - 0s 180us/step - loss: 0.9650 - accuracy: 0.5311 - val_loss: 1.4075 - val_accuracy: 0.3816\n",
      "Epoch 7/100\n",
      "177/177 [==============================] - 0s 178us/step - loss: 0.9002 - accuracy: 0.5650 - val_loss: 1.5142 - val_accuracy: 0.4079\n",
      "Epoch 8/100\n",
      "177/177 [==============================] - 0s 197us/step - loss: 0.9316 - accuracy: 0.5876 - val_loss: 1.4214 - val_accuracy: 0.4868\n",
      "Epoch 9/100\n",
      "177/177 [==============================] - 0s 178us/step - loss: 0.8702 - accuracy: 0.5706 - val_loss: 1.4411 - val_accuracy: 0.4342\n",
      "Epoch 10/100\n",
      "177/177 [==============================] - 0s 174us/step - loss: 0.9993 - accuracy: 0.5932 - val_loss: 1.4247 - val_accuracy: 0.3553\n",
      "Epoch 11/100\n",
      "177/177 [==============================] - 0s 138us/step - loss: 0.9216 - accuracy: 0.5989 - val_loss: 1.4549 - val_accuracy: 0.3684\n",
      "Epoch 12/100\n",
      "177/177 [==============================] - 0s 192us/step - loss: 0.8491 - accuracy: 0.6045 - val_loss: 1.3797 - val_accuracy: 0.4474\n",
      "Epoch 13/100\n",
      "177/177 [==============================] - 0s 208us/step - loss: 0.8136 - accuracy: 0.6384 - val_loss: 1.4131 - val_accuracy: 0.4474\n",
      "Epoch 14/100\n",
      "177/177 [==============================] - 0s 199us/step - loss: 0.7826 - accuracy: 0.6667 - val_loss: 1.3099 - val_accuracy: 0.4079\n",
      "Epoch 15/100\n",
      "177/177 [==============================] - 0s 151us/step - loss: 0.7850 - accuracy: 0.6667 - val_loss: 1.3055 - val_accuracy: 0.3947\n",
      "Epoch 16/100\n",
      "177/177 [==============================] - 0s 160us/step - loss: 0.7611 - accuracy: 0.6780 - val_loss: 1.3325 - val_accuracy: 0.4211\n",
      "Epoch 17/100\n",
      "177/177 [==============================] - 0s 177us/step - loss: 0.7390 - accuracy: 0.6949 - val_loss: 1.3264 - val_accuracy: 0.4474\n",
      "Epoch 18/100\n",
      "177/177 [==============================] - 0s 116us/step - loss: 0.7385 - accuracy: 0.6893 - val_loss: 1.3754 - val_accuracy: 0.4211\n",
      "Epoch 19/100\n",
      "177/177 [==============================] - 0s 147us/step - loss: 0.7624 - accuracy: 0.6949 - val_loss: 1.4782 - val_accuracy: 0.3816\n",
      "Epoch 20/100\n",
      "177/177 [==============================] - 0s 152us/step - loss: 0.8190 - accuracy: 0.6667 - val_loss: 1.4370 - val_accuracy: 0.3816\n",
      "Epoch 21/100\n",
      "177/177 [==============================] - 0s 142us/step - loss: 0.8279 - accuracy: 0.6836 - val_loss: 1.4367 - val_accuracy: 0.5000\n",
      "Epoch 22/100\n",
      "177/177 [==============================] - 0s 161us/step - loss: 0.7797 - accuracy: 0.6780 - val_loss: 1.4967 - val_accuracy: 0.5000\n",
      "Epoch 23/100\n",
      "177/177 [==============================] - 0s 166us/step - loss: 0.7083 - accuracy: 0.7119 - val_loss: 1.4166 - val_accuracy: 0.4211\n",
      "Epoch 24/100\n",
      "177/177 [==============================] - 0s 164us/step - loss: 0.7007 - accuracy: 0.7062 - val_loss: 1.4201 - val_accuracy: 0.4737\n",
      "Epoch 25/100\n",
      "177/177 [==============================] - 0s 161us/step - loss: 0.6713 - accuracy: 0.7062 - val_loss: 1.4021 - val_accuracy: 0.4474\n",
      "Epoch 26/100\n",
      "177/177 [==============================] - 0s 201us/step - loss: 0.6590 - accuracy: 0.7175 - val_loss: 1.3485 - val_accuracy: 0.4342\n",
      "Epoch 27/100\n",
      "177/177 [==============================] - 0s 190us/step - loss: 0.6535 - accuracy: 0.7232 - val_loss: 1.3402 - val_accuracy: 0.4474\n",
      "Epoch 28/100\n",
      "177/177 [==============================] - 0s 159us/step - loss: 0.6492 - accuracy: 0.7288 - val_loss: 1.3345 - val_accuracy: 0.4605\n",
      "Epoch 29/100\n",
      "177/177 [==============================] - 0s 144us/step - loss: 0.8136 - accuracy: 0.7288 - val_loss: 1.4706 - val_accuracy: 0.4737\n",
      "Epoch 30/100\n",
      "177/177 [==============================] - 0s 119us/step - loss: 0.7134 - accuracy: 0.7175 - val_loss: 1.4890 - val_accuracy: 0.4868\n",
      "Epoch 31/100\n",
      "177/177 [==============================] - 0s 134us/step - loss: 0.6463 - accuracy: 0.7175 - val_loss: 1.4308 - val_accuracy: 0.4474\n",
      "Epoch 32/100\n",
      "177/177 [==============================] - 0s 136us/step - loss: 0.6817 - accuracy: 0.7401 - val_loss: 1.4496 - val_accuracy: 0.4737\n",
      "Epoch 33/100\n",
      "177/177 [==============================] - 0s 142us/step - loss: 0.6341 - accuracy: 0.7232 - val_loss: 1.4696 - val_accuracy: 0.5000\n",
      "Epoch 34/100\n",
      "177/177 [==============================] - 0s 263us/step - loss: 0.6143 - accuracy: 0.7514 - val_loss: 1.4342 - val_accuracy: 0.4737\n",
      "Epoch 35/100\n",
      "177/177 [==============================] - 0s 217us/step - loss: 0.6057 - accuracy: 0.7571 - val_loss: 1.4518 - val_accuracy: 0.5000\n",
      "Epoch 36/100\n",
      "177/177 [==============================] - 0s 281us/step - loss: 0.6063 - accuracy: 0.7797 - val_loss: 1.4819 - val_accuracy: 0.4868\n",
      "Epoch 37/100\n",
      "177/177 [==============================] - 0s 205us/step - loss: 0.5862 - accuracy: 0.8023 - val_loss: 1.4445 - val_accuracy: 0.4211\n",
      "Epoch 38/100\n",
      "177/177 [==============================] - 0s 235us/step - loss: 0.5886 - accuracy: 0.7853 - val_loss: 1.4907 - val_accuracy: 0.5132\n",
      "Epoch 39/100\n",
      "177/177 [==============================] - 0s 269us/step - loss: 0.5786 - accuracy: 0.7740 - val_loss: 1.4687 - val_accuracy: 0.4868\n",
      "Epoch 40/100\n",
      "177/177 [==============================] - 0s 322us/step - loss: 0.5690 - accuracy: 0.8136 - val_loss: 1.4645 - val_accuracy: 0.4474\n",
      "Epoch 41/100\n",
      "177/177 [==============================] - 0s 272us/step - loss: 0.5676 - accuracy: 0.8023 - val_loss: 1.4493 - val_accuracy: 0.4211\n",
      "Epoch 42/100\n",
      "177/177 [==============================] - 0s 249us/step - loss: 0.5681 - accuracy: 0.8192 - val_loss: 1.4774 - val_accuracy: 0.4605\n",
      "Epoch 43/100\n",
      "177/177 [==============================] - 0s 251us/step - loss: 0.5488 - accuracy: 0.8079 - val_loss: 1.4447 - val_accuracy: 0.4605\n",
      "Epoch 44/100\n",
      "177/177 [==============================] - 0s 267us/step - loss: 0.5505 - accuracy: 0.7966 - val_loss: 1.4140 - val_accuracy: 0.4605\n",
      "Epoch 45/100\n",
      "177/177 [==============================] - 0s 244us/step - loss: 0.5582 - accuracy: 0.7910 - val_loss: 1.4470 - val_accuracy: 0.4474\n",
      "Epoch 46/100\n",
      "177/177 [==============================] - 0s 161us/step - loss: 0.5462 - accuracy: 0.8079 - val_loss: 1.5046 - val_accuracy: 0.4605\n",
      "Epoch 47/100\n",
      "177/177 [==============================] - 0s 175us/step - loss: 0.5397 - accuracy: 0.8079 - val_loss: 1.4681 - val_accuracy: 0.4474\n",
      "Epoch 48/100\n",
      "177/177 [==============================] - 0s 139us/step - loss: 0.5334 - accuracy: 0.8192 - val_loss: 1.4951 - val_accuracy: 0.4474\n",
      "Epoch 49/100\n",
      "177/177 [==============================] - 0s 135us/step - loss: 0.5244 - accuracy: 0.8249 - val_loss: 1.5124 - val_accuracy: 0.4605\n",
      "Epoch 50/100\n",
      "177/177 [==============================] - 0s 154us/step - loss: 0.5160 - accuracy: 0.8305 - val_loss: 1.4739 - val_accuracy: 0.4474\n",
      "Epoch 51/100\n",
      "177/177 [==============================] - 0s 183us/step - loss: 0.5164 - accuracy: 0.8192 - val_loss: 1.5094 - val_accuracy: 0.4737\n",
      "Epoch 52/100\n",
      "177/177 [==============================] - 0s 119us/step - loss: 0.5153 - accuracy: 0.8249 - val_loss: 1.5098 - val_accuracy: 0.4605\n",
      "Epoch 53/100\n",
      "177/177 [==============================] - 0s 118us/step - loss: 0.5039 - accuracy: 0.8136 - val_loss: 1.4901 - val_accuracy: 0.4474\n",
      "Epoch 54/100\n",
      "177/177 [==============================] - 0s 143us/step - loss: 0.5018 - accuracy: 0.8305 - val_loss: 1.5503 - val_accuracy: 0.4605\n",
      "Epoch 55/100\n",
      "177/177 [==============================] - 0s 129us/step - loss: 0.4985 - accuracy: 0.8475 - val_loss: 1.5368 - val_accuracy: 0.4605\n",
      "Epoch 56/100\n",
      "177/177 [==============================] - 0s 220us/step - loss: 0.4977 - accuracy: 0.8249 - val_loss: 1.5170 - val_accuracy: 0.4474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "177/177 [==============================] - 0s 542us/step - loss: 0.4910 - accuracy: 0.8362 - val_loss: 1.5102 - val_accuracy: 0.4605\n",
      "Epoch 58/100\n",
      "177/177 [==============================] - 0s 274us/step - loss: 0.4822 - accuracy: 0.8362 - val_loss: 1.5079 - val_accuracy: 0.4474\n",
      "Epoch 59/100\n",
      "177/177 [==============================] - 0s 232us/step - loss: 0.4813 - accuracy: 0.8305 - val_loss: 1.5170 - val_accuracy: 0.4211\n",
      "Epoch 60/100\n",
      "177/177 [==============================] - 0s 258us/step - loss: 0.4771 - accuracy: 0.8531 - val_loss: 1.5544 - val_accuracy: 0.4605\n",
      "Epoch 61/100\n",
      "177/177 [==============================] - 0s 148us/step - loss: 0.4758 - accuracy: 0.8531 - val_loss: 1.5402 - val_accuracy: 0.4342\n",
      "Epoch 62/100\n",
      "177/177 [==============================] - 0s 148us/step - loss: 0.5501 - accuracy: 0.8249 - val_loss: 1.5801 - val_accuracy: 0.4342\n",
      "Epoch 63/100\n",
      "177/177 [==============================] - 0s 153us/step - loss: 0.4769 - accuracy: 0.8362 - val_loss: 1.6114 - val_accuracy: 0.4605\n",
      "Epoch 64/100\n",
      "177/177 [==============================] - 0s 167us/step - loss: 0.4535 - accuracy: 0.8418 - val_loss: 1.6435 - val_accuracy: 0.4605\n",
      "Epoch 65/100\n",
      "177/177 [==============================] - 0s 175us/step - loss: 0.4672 - accuracy: 0.8305 - val_loss: 1.6213 - val_accuracy: 0.4342\n",
      "Epoch 66/100\n",
      "177/177 [==============================] - 0s 154us/step - loss: 0.4476 - accuracy: 0.8531 - val_loss: 1.6012 - val_accuracy: 0.4605\n",
      "Epoch 67/100\n",
      "177/177 [==============================] - 0s 183us/step - loss: 0.4576 - accuracy: 0.8249 - val_loss: 1.6485 - val_accuracy: 0.4737\n",
      "Epoch 68/100\n",
      "177/177 [==============================] - 0s 154us/step - loss: 0.4518 - accuracy: 0.8475 - val_loss: 1.6245 - val_accuracy: 0.4605\n",
      "Epoch 69/100\n",
      "177/177 [==============================] - 0s 167us/step - loss: 0.4358 - accuracy: 0.8531 - val_loss: 1.5706 - val_accuracy: 0.4474\n",
      "Epoch 70/100\n",
      "177/177 [==============================] - 0s 157us/step - loss: 0.4337 - accuracy: 0.8475 - val_loss: 1.6096 - val_accuracy: 0.4605\n",
      "Epoch 71/100\n",
      "177/177 [==============================] - 0s 117us/step - loss: 0.4395 - accuracy: 0.8305 - val_loss: 1.6083 - val_accuracy: 0.4474\n",
      "Epoch 72/100\n",
      "177/177 [==============================] - 0s 167us/step - loss: 0.4771 - accuracy: 0.8418 - val_loss: 1.7084 - val_accuracy: 0.4474\n",
      "Epoch 73/100\n",
      "177/177 [==============================] - 0s 167us/step - loss: 0.5475 - accuracy: 0.8305 - val_loss: 1.6642 - val_accuracy: 0.4474\n",
      "Epoch 74/100\n",
      "177/177 [==============================] - 0s 173us/step - loss: 0.6687 - accuracy: 0.8023 - val_loss: 2.0451 - val_accuracy: 0.4605\n",
      "Epoch 75/100\n",
      "177/177 [==============================] - 0s 159us/step - loss: 0.5910 - accuracy: 0.8249 - val_loss: 2.0363 - val_accuracy: 0.4737\n",
      "Epoch 76/100\n",
      "177/177 [==============================] - 0s 160us/step - loss: 0.6146 - accuracy: 0.7966 - val_loss: 1.7959 - val_accuracy: 0.4474\n",
      "Epoch 77/100\n",
      "177/177 [==============================] - 0s 156us/step - loss: 0.4886 - accuracy: 0.8249 - val_loss: 1.7409 - val_accuracy: 0.4342\n",
      "Epoch 78/100\n",
      "177/177 [==============================] - 0s 144us/step - loss: 0.5556 - accuracy: 0.8362 - val_loss: 1.8957 - val_accuracy: 0.4605\n",
      "Epoch 79/100\n",
      "177/177 [==============================] - 0s 144us/step - loss: 0.5395 - accuracy: 0.8305 - val_loss: 2.1698 - val_accuracy: 0.4474\n",
      "Epoch 80/100\n",
      "177/177 [==============================] - 0s 112us/step - loss: 0.6955 - accuracy: 0.8192 - val_loss: 1.8448 - val_accuracy: 0.4868\n",
      "Epoch 81/100\n",
      "177/177 [==============================] - 0s 112us/step - loss: 0.6141 - accuracy: 0.8023 - val_loss: 2.0171 - val_accuracy: 0.4737\n",
      "Epoch 82/100\n",
      "177/177 [==============================] - 0s 141us/step - loss: 0.3989 - accuracy: 0.8418 - val_loss: 1.8923 - val_accuracy: 0.4605\n",
      "Epoch 83/100\n",
      "177/177 [==============================] - 0s 162us/step - loss: 0.4767 - accuracy: 0.8362 - val_loss: 1.9035 - val_accuracy: 0.4605\n",
      "Epoch 84/100\n",
      "177/177 [==============================] - 0s 143us/step - loss: 0.4644 - accuracy: 0.8305 - val_loss: 2.0456 - val_accuracy: 0.4737\n",
      "Epoch 85/100\n",
      "177/177 [==============================] - 0s 185us/step - loss: 0.4986 - accuracy: 0.8192 - val_loss: 1.9157 - val_accuracy: 0.4737\n",
      "Epoch 86/100\n",
      "177/177 [==============================] - 0s 154us/step - loss: 0.4501 - accuracy: 0.8475 - val_loss: 1.9485 - val_accuracy: 0.4737\n",
      "Epoch 87/100\n",
      "177/177 [==============================] - 0s 144us/step - loss: 0.4331 - accuracy: 0.8475 - val_loss: 1.8631 - val_accuracy: 0.4211\n",
      "Epoch 88/100\n",
      "177/177 [==============================] - 0s 139us/step - loss: 0.4365 - accuracy: 0.8475 - val_loss: 1.9424 - val_accuracy: 0.4868\n",
      "Epoch 89/100\n",
      "177/177 [==============================] - 0s 130us/step - loss: 0.3773 - accuracy: 0.8588 - val_loss: 1.9109 - val_accuracy: 0.4474\n",
      "Epoch 90/100\n",
      "177/177 [==============================] - 0s 181us/step - loss: 0.3968 - accuracy: 0.8475 - val_loss: 1.8910 - val_accuracy: 0.4342\n",
      "Epoch 91/100\n",
      "177/177 [==============================] - 0s 124us/step - loss: 0.4022 - accuracy: 0.8644 - val_loss: 1.9187 - val_accuracy: 0.4474\n",
      "Epoch 92/100\n",
      "177/177 [==============================] - 0s 154us/step - loss: 0.3765 - accuracy: 0.8644 - val_loss: 1.9453 - val_accuracy: 0.4605\n",
      "Epoch 93/100\n",
      "177/177 [==============================] - 0s 152us/step - loss: 0.3932 - accuracy: 0.8588 - val_loss: 1.8788 - val_accuracy: 0.4474\n",
      "Epoch 94/100\n",
      "177/177 [==============================] - 0s 144us/step - loss: 0.4066 - accuracy: 0.8475 - val_loss: 1.9448 - val_accuracy: 0.4342\n",
      "Epoch 95/100\n",
      "177/177 [==============================] - 0s 138us/step - loss: 0.3662 - accuracy: 0.8531 - val_loss: 2.0505 - val_accuracy: 0.4605\n",
      "Epoch 96/100\n",
      "177/177 [==============================] - 0s 156us/step - loss: 0.3974 - accuracy: 0.8418 - val_loss: 2.0540 - val_accuracy: 0.4605\n",
      "Epoch 97/100\n",
      "177/177 [==============================] - 0s 142us/step - loss: 0.3958 - accuracy: 0.8475 - val_loss: 2.0967 - val_accuracy: 0.4474\n",
      "Epoch 98/100\n",
      "177/177 [==============================] - 0s 152us/step - loss: 0.3905 - accuracy: 0.8588 - val_loss: 2.0770 - val_accuracy: 0.4605\n",
      "Epoch 99/100\n",
      "177/177 [==============================] - 0s 141us/step - loss: 0.3835 - accuracy: 0.8588 - val_loss: 2.0037 - val_accuracy: 0.4474\n",
      "Epoch 100/100\n",
      "177/177 [==============================] - 0s 142us/step - loss: 0.3598 - accuracy: 0.8588 - val_loss: 2.0139 - val_accuracy: 0.4605\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a3ab4cc50>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sel.fit(X_sel_train, y_sel_train,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_sel_test, y_sel_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 0s 102us/step\n",
      "over-sampling test accuracy: 44.74%\n"
     ]
    }
   ],
   "source": [
    "acc_test_sel = model_sel.evaluate(X_sel_test, y_sel_test)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_sel*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 1, 2, 0, 1, 1, 0, 1, 0, 2, 0, 0, 2, 1, 2, 0, 2, 0, 0, 2,\n",
       "       2, 2, 0, 2, 0, 1, 1, 1, 1, 2, 0, 0, 1, 1, 1, 2, 2, 1, 1, 0, 0, 0,\n",
       "       1, 1, 2, 0, 2, 0, 2, 2, 0, 2, 1, 0, 1, 2, 2, 0, 1, 0, 1, 1, 2, 1,\n",
       "       0, 0, 0, 2, 2, 2, 2, 0, 0, 2])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred5 = model_sel.predict_classes(X_sel_test)\n",
    "pred5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strain</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>NY360</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>NRS113</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120337</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>CFBREBSa127</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>GA27</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>SR1129</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>NRS152</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>CFBRSa66A</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>BCH-SA-13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>SR4153</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          strain  test  pred\n",
       "231        NY360     2     1\n",
       "139       NRS113     0     0\n",
       "4         120337     2     2\n",
       "59   CFBREBSa127     1     1\n",
       "96          GA27     2     2\n",
       "..           ...   ...   ...\n",
       "236       SR1129     2     2\n",
       "145       NRS152     2     2\n",
       "86     CFBRSa66A     0     0\n",
       "28     BCH-SA-13     1     0\n",
       "249       SR4153     1     2\n",
       "\n",
       "[76 rows x 3 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat5['pred'] = pred5\n",
    "dat5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba5 = model_sel.predict_proba(X_sel_test)\n",
    "dat_proba5 = pd.DataFrame(proba5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.082175e-01</td>\n",
       "      <td>5.667442e-01</td>\n",
       "      <td>0.025038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.002990e-01</td>\n",
       "      <td>8.451332e-02</td>\n",
       "      <td>0.315188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.900149e-04</td>\n",
       "      <td>3.875969e-03</td>\n",
       "      <td>0.995434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.411632e-01</td>\n",
       "      <td>5.275964e-01</td>\n",
       "      <td>0.131240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.080659e-03</td>\n",
       "      <td>3.997216e-02</td>\n",
       "      <td>0.956947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>1.661970e-02</td>\n",
       "      <td>1.623360e-01</td>\n",
       "      <td>0.821044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>1.031432e-01</td>\n",
       "      <td>3.281982e-02</td>\n",
       "      <td>0.864037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>4.695159e-01</td>\n",
       "      <td>4.196791e-01</td>\n",
       "      <td>0.110805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>6.495815e-01</td>\n",
       "      <td>2.143886e-01</td>\n",
       "      <td>0.136030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>7.288357e-08</td>\n",
       "      <td>4.520205e-13</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0             1         2\n",
       "0   4.082175e-01  5.667442e-01  0.025038\n",
       "1   6.002990e-01  8.451332e-02  0.315188\n",
       "2   6.900149e-04  3.875969e-03  0.995434\n",
       "3   3.411632e-01  5.275964e-01  0.131240\n",
       "4   3.080659e-03  3.997216e-02  0.956947\n",
       "..           ...           ...       ...\n",
       "71  1.661970e-02  1.623360e-01  0.821044\n",
       "72  1.031432e-01  3.281982e-02  0.864037\n",
       "73  4.695159e-01  4.196791e-01  0.110805\n",
       "74  6.495815e-01  2.143886e-01  0.136030\n",
       "75  7.288357e-08  4.520205e-13  1.000000\n",
       "\n",
       "[76 rows x 3 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba5.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba5.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat5.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/5p17ST.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 177 samples, validate on 76 samples\n",
      "Epoch 1/100\n",
      "177/177 [==============================] - 0s 135us/step - loss: 0.3837 - accuracy: 0.8814 - val_loss: 1.8082 - val_accuracy: 0.4868\n",
      "Epoch 2/100\n",
      "177/177 [==============================] - 0s 145us/step - loss: 0.3817 - accuracy: 0.8814 - val_loss: 1.8500 - val_accuracy: 0.5132\n",
      "Epoch 3/100\n",
      "177/177 [==============================] - 0s 184us/step - loss: 0.3830 - accuracy: 0.8757 - val_loss: 1.9227 - val_accuracy: 0.4868\n",
      "Epoch 4/100\n",
      "177/177 [==============================] - 0s 169us/step - loss: 0.3832 - accuracy: 0.8701 - val_loss: 1.8923 - val_accuracy: 0.5132\n",
      "Epoch 5/100\n",
      "177/177 [==============================] - 0s 179us/step - loss: 0.3864 - accuracy: 0.8757 - val_loss: 1.9255 - val_accuracy: 0.5000\n",
      "Epoch 6/100\n",
      "177/177 [==============================] - 0s 159us/step - loss: 0.3685 - accuracy: 0.8814 - val_loss: 1.9057 - val_accuracy: 0.4474\n",
      "Epoch 7/100\n",
      "177/177 [==============================] - 0s 148us/step - loss: 0.3892 - accuracy: 0.8588 - val_loss: 1.9232 - val_accuracy: 0.5132\n",
      "Epoch 8/100\n",
      "177/177 [==============================] - 0s 163us/step - loss: 0.4441 - accuracy: 0.8531 - val_loss: 1.8930 - val_accuracy: 0.4868\n",
      "Epoch 9/100\n",
      "177/177 [==============================] - 0s 138us/step - loss: 0.4150 - accuracy: 0.8644 - val_loss: 1.8024 - val_accuracy: 0.4737\n",
      "Epoch 10/100\n",
      "177/177 [==============================] - 0s 173us/step - loss: 0.3731 - accuracy: 0.8814 - val_loss: 1.8561 - val_accuracy: 0.4605\n",
      "Epoch 11/100\n",
      "177/177 [==============================] - 0s 167us/step - loss: 0.3774 - accuracy: 0.8757 - val_loss: 1.8088 - val_accuracy: 0.4737\n",
      "Epoch 12/100\n",
      "177/177 [==============================] - 0s 155us/step - loss: 0.3577 - accuracy: 0.8757 - val_loss: 1.8680 - val_accuracy: 0.4737\n",
      "Epoch 13/100\n",
      "177/177 [==============================] - 0s 161us/step - loss: 0.3657 - accuracy: 0.8757 - val_loss: 1.9107 - val_accuracy: 0.5000\n",
      "Epoch 14/100\n",
      "177/177 [==============================] - 0s 184us/step - loss: 0.3506 - accuracy: 0.8870 - val_loss: 1.8761 - val_accuracy: 0.4342\n",
      "Epoch 15/100\n",
      "177/177 [==============================] - 0s 184us/step - loss: 0.3490 - accuracy: 0.8870 - val_loss: 1.9033 - val_accuracy: 0.4868\n",
      "Epoch 16/100\n",
      "177/177 [==============================] - 0s 158us/step - loss: 0.3450 - accuracy: 0.8814 - val_loss: 1.9421 - val_accuracy: 0.5000\n",
      "Epoch 17/100\n",
      "177/177 [==============================] - 0s 180us/step - loss: 0.3433 - accuracy: 0.8757 - val_loss: 1.9414 - val_accuracy: 0.4737\n",
      "Epoch 18/100\n",
      "177/177 [==============================] - 0s 173us/step - loss: 0.3505 - accuracy: 0.8814 - val_loss: 1.9757 - val_accuracy: 0.4737\n",
      "Epoch 19/100\n",
      "177/177 [==============================] - 0s 162us/step - loss: 0.3409 - accuracy: 0.8870 - val_loss: 1.9585 - val_accuracy: 0.4868\n",
      "Epoch 20/100\n",
      "177/177 [==============================] - 0s 166us/step - loss: 0.3412 - accuracy: 0.8814 - val_loss: 1.9527 - val_accuracy: 0.4605\n",
      "Epoch 21/100\n",
      "177/177 [==============================] - 0s 198us/step - loss: 0.3386 - accuracy: 0.8870 - val_loss: 1.9961 - val_accuracy: 0.4868\n",
      "Epoch 22/100\n",
      "177/177 [==============================] - 0s 167us/step - loss: 0.3333 - accuracy: 0.8927 - val_loss: 2.1454 - val_accuracy: 0.5263\n",
      "Epoch 23/100\n",
      "177/177 [==============================] - 0s 128us/step - loss: 0.3448 - accuracy: 0.8644 - val_loss: 1.9800 - val_accuracy: 0.4474\n",
      "Epoch 24/100\n",
      "177/177 [==============================] - 0s 124us/step - loss: 0.3306 - accuracy: 0.8870 - val_loss: 1.8964 - val_accuracy: 0.4868\n",
      "Epoch 25/100\n",
      "177/177 [==============================] - 0s 189us/step - loss: 0.3323 - accuracy: 0.8757 - val_loss: 1.9398 - val_accuracy: 0.4737\n",
      "Epoch 26/100\n",
      "177/177 [==============================] - 0s 135us/step - loss: 0.3296 - accuracy: 0.8870 - val_loss: 1.9200 - val_accuracy: 0.4605\n",
      "Epoch 27/100\n",
      "177/177 [==============================] - 0s 162us/step - loss: 0.3226 - accuracy: 0.8757 - val_loss: 1.9243 - val_accuracy: 0.4211\n",
      "Epoch 28/100\n",
      "177/177 [==============================] - 0s 135us/step - loss: 0.3282 - accuracy: 0.8870 - val_loss: 2.0399 - val_accuracy: 0.4474\n",
      "Epoch 29/100\n",
      "177/177 [==============================] - 0s 154us/step - loss: 0.3269 - accuracy: 0.8814 - val_loss: 2.0687 - val_accuracy: 0.4605\n",
      "Epoch 30/100\n",
      "177/177 [==============================] - 0s 143us/step - loss: 0.3218 - accuracy: 0.8870 - val_loss: 2.0596 - val_accuracy: 0.4868\n",
      "Epoch 31/100\n",
      "177/177 [==============================] - 0s 134us/step - loss: 0.3212 - accuracy: 0.8870 - val_loss: 2.0906 - val_accuracy: 0.4605\n",
      "Epoch 32/100\n",
      "177/177 [==============================] - 0s 138us/step - loss: 0.3387 - accuracy: 0.8814 - val_loss: 2.1756 - val_accuracy: 0.4474\n",
      "Epoch 33/100\n",
      "177/177 [==============================] - 0s 142us/step - loss: 0.4224 - accuracy: 0.8644 - val_loss: 2.0747 - val_accuracy: 0.4605\n",
      "Epoch 34/100\n",
      "177/177 [==============================] - 0s 145us/step - loss: 0.3367 - accuracy: 0.8757 - val_loss: 1.9682 - val_accuracy: 0.4605\n",
      "Epoch 35/100\n",
      "177/177 [==============================] - 0s 145us/step - loss: 0.3298 - accuracy: 0.8927 - val_loss: 2.0041 - val_accuracy: 0.4737\n",
      "Epoch 36/100\n",
      "177/177 [==============================] - 0s 177us/step - loss: 0.3252 - accuracy: 0.8870 - val_loss: 1.9839 - val_accuracy: 0.4737\n",
      "Epoch 37/100\n",
      "177/177 [==============================] - 0s 173us/step - loss: 0.3190 - accuracy: 0.8983 - val_loss: 1.9751 - val_accuracy: 0.4737\n",
      "Epoch 38/100\n",
      "177/177 [==============================] - 0s 162us/step - loss: 0.3180 - accuracy: 0.8757 - val_loss: 1.9565 - val_accuracy: 0.4605\n",
      "Epoch 39/100\n",
      "177/177 [==============================] - 0s 158us/step - loss: 0.3146 - accuracy: 0.8927 - val_loss: 2.0369 - val_accuracy: 0.4605\n",
      "Epoch 40/100\n",
      "177/177 [==============================] - 0s 126us/step - loss: 0.3377 - accuracy: 0.8757 - val_loss: 1.9829 - val_accuracy: 0.4474\n",
      "Epoch 41/100\n",
      "177/177 [==============================] - 0s 114us/step - loss: 0.3078 - accuracy: 0.8814 - val_loss: 2.0214 - val_accuracy: 0.4474\n",
      "Epoch 42/100\n",
      "177/177 [==============================] - 0s 113us/step - loss: 0.3148 - accuracy: 0.8757 - val_loss: 2.0149 - val_accuracy: 0.4342\n",
      "Epoch 43/100\n",
      "177/177 [==============================] - 0s 111us/step - loss: 0.3117 - accuracy: 0.8814 - val_loss: 2.0637 - val_accuracy: 0.4737\n",
      "Epoch 44/100\n",
      "177/177 [==============================] - 0s 122us/step - loss: 0.3025 - accuracy: 0.8927 - val_loss: 2.0325 - val_accuracy: 0.4342\n",
      "Epoch 45/100\n",
      "177/177 [==============================] - 0s 117us/step - loss: 0.2986 - accuracy: 0.8701 - val_loss: 2.0129 - val_accuracy: 0.4605\n",
      "Epoch 46/100\n",
      "177/177 [==============================] - 0s 128us/step - loss: 0.2963 - accuracy: 0.8870 - val_loss: 2.0470 - val_accuracy: 0.4474\n",
      "Epoch 47/100\n",
      "177/177 [==============================] - 0s 114us/step - loss: 0.3032 - accuracy: 0.8927 - val_loss: 2.0971 - val_accuracy: 0.4868\n",
      "Epoch 48/100\n",
      "177/177 [==============================] - 0s 117us/step - loss: 0.2943 - accuracy: 0.8927 - val_loss: 2.0564 - val_accuracy: 0.4211\n",
      "Epoch 49/100\n",
      "177/177 [==============================] - 0s 121us/step - loss: 0.2918 - accuracy: 0.8983 - val_loss: 2.1457 - val_accuracy: 0.4737\n",
      "Epoch 50/100\n",
      "177/177 [==============================] - 0s 111us/step - loss: 0.2828 - accuracy: 0.8927 - val_loss: 2.1914 - val_accuracy: 0.4737\n",
      "Epoch 51/100\n",
      "177/177 [==============================] - 0s 113us/step - loss: 0.2902 - accuracy: 0.9040 - val_loss: 2.1987 - val_accuracy: 0.4605\n",
      "Epoch 52/100\n",
      "177/177 [==============================] - 0s 142us/step - loss: 0.2869 - accuracy: 0.9096 - val_loss: 2.1951 - val_accuracy: 0.4342\n",
      "Epoch 53/100\n",
      "177/177 [==============================] - 0s 139us/step - loss: 0.2854 - accuracy: 0.9096 - val_loss: 2.2297 - val_accuracy: 0.4737\n",
      "Epoch 54/100\n",
      "177/177 [==============================] - 0s 148us/step - loss: 0.2920 - accuracy: 0.8983 - val_loss: 2.1742 - val_accuracy: 0.4605\n",
      "Epoch 55/100\n",
      "177/177 [==============================] - 0s 121us/step - loss: 0.2752 - accuracy: 0.9040 - val_loss: 2.1108 - val_accuracy: 0.4474\n",
      "Epoch 56/100\n",
      "177/177 [==============================] - 0s 136us/step - loss: 0.2873 - accuracy: 0.8983 - val_loss: 2.1076 - val_accuracy: 0.4605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "177/177 [==============================] - 0s 132us/step - loss: 0.2757 - accuracy: 0.9040 - val_loss: 2.0862 - val_accuracy: 0.4079\n",
      "Epoch 58/100\n",
      "177/177 [==============================] - 0s 123us/step - loss: 0.2770 - accuracy: 0.9040 - val_loss: 2.2006 - val_accuracy: 0.4605\n",
      "Epoch 59/100\n",
      "177/177 [==============================] - 0s 121us/step - loss: 0.2763 - accuracy: 0.9040 - val_loss: 2.2100 - val_accuracy: 0.4737\n",
      "Epoch 60/100\n",
      "177/177 [==============================] - 0s 124us/step - loss: 0.2764 - accuracy: 0.8983 - val_loss: 2.1566 - val_accuracy: 0.4342\n",
      "Epoch 61/100\n",
      "177/177 [==============================] - 0s 116us/step - loss: 0.2688 - accuracy: 0.9096 - val_loss: 2.1767 - val_accuracy: 0.4211\n",
      "Epoch 62/100\n",
      "177/177 [==============================] - 0s 144us/step - loss: 0.2676 - accuracy: 0.9040 - val_loss: 2.2519 - val_accuracy: 0.4605\n",
      "Epoch 63/100\n",
      "177/177 [==============================] - 0s 150us/step - loss: 0.2645 - accuracy: 0.8983 - val_loss: 2.2733 - val_accuracy: 0.4605\n",
      "Epoch 64/100\n",
      "177/177 [==============================] - 0s 125us/step - loss: 0.2652 - accuracy: 0.9153 - val_loss: 2.2288 - val_accuracy: 0.4605\n",
      "Epoch 65/100\n",
      "177/177 [==============================] - 0s 130us/step - loss: 0.2654 - accuracy: 0.9096 - val_loss: 2.2030 - val_accuracy: 0.4342\n",
      "Epoch 66/100\n",
      "177/177 [==============================] - 0s 145us/step - loss: 0.2660 - accuracy: 0.8983 - val_loss: 2.2825 - val_accuracy: 0.4474\n",
      "Epoch 67/100\n",
      "177/177 [==============================] - 0s 234us/step - loss: 0.2652 - accuracy: 0.9040 - val_loss: 2.2677 - val_accuracy: 0.4737\n",
      "Epoch 68/100\n",
      "177/177 [==============================] - 0s 184us/step - loss: 0.2820 - accuracy: 0.8870 - val_loss: 2.1746 - val_accuracy: 0.4474\n",
      "Epoch 69/100\n",
      "177/177 [==============================] - 0s 140us/step - loss: 0.3108 - accuracy: 0.8870 - val_loss: 2.1459 - val_accuracy: 0.4605\n",
      "Epoch 70/100\n",
      "177/177 [==============================] - 0s 134us/step - loss: 0.2744 - accuracy: 0.8870 - val_loss: 2.2099 - val_accuracy: 0.4474\n",
      "Epoch 71/100\n",
      "177/177 [==============================] - 0s 146us/step - loss: 0.2674 - accuracy: 0.9040 - val_loss: 2.2095 - val_accuracy: 0.4605\n",
      "Epoch 72/100\n",
      "177/177 [==============================] - 0s 193us/step - loss: 0.2789 - accuracy: 0.9096 - val_loss: 2.2533 - val_accuracy: 0.4605\n",
      "Epoch 73/100\n",
      "177/177 [==============================] - 0s 265us/step - loss: 0.2631 - accuracy: 0.9153 - val_loss: 2.2821 - val_accuracy: 0.4342\n",
      "Epoch 74/100\n",
      "177/177 [==============================] - 0s 173us/step - loss: 0.2676 - accuracy: 0.9040 - val_loss: 2.3748 - val_accuracy: 0.4737\n",
      "Epoch 75/100\n",
      "177/177 [==============================] - 0s 116us/step - loss: 0.2714 - accuracy: 0.9209 - val_loss: 2.4514 - val_accuracy: 0.4605\n",
      "Epoch 76/100\n",
      "177/177 [==============================] - 0s 215us/step - loss: 0.2690 - accuracy: 0.9096 - val_loss: 2.4258 - val_accuracy: 0.4737\n",
      "Epoch 77/100\n",
      "177/177 [==============================] - 0s 143us/step - loss: 0.2646 - accuracy: 0.9096 - val_loss: 2.4339 - val_accuracy: 0.4605\n",
      "Epoch 78/100\n",
      "177/177 [==============================] - 0s 125us/step - loss: 0.2512 - accuracy: 0.9153 - val_loss: 2.1717 - val_accuracy: 0.4211\n",
      "Epoch 79/100\n",
      "177/177 [==============================] - 0s 124us/step - loss: 0.2554 - accuracy: 0.9209 - val_loss: 2.1899 - val_accuracy: 0.4342\n",
      "Epoch 80/100\n",
      "177/177 [==============================] - 0s 154us/step - loss: 0.2688 - accuracy: 0.8927 - val_loss: 2.2269 - val_accuracy: 0.4737\n",
      "Epoch 81/100\n",
      "177/177 [==============================] - 0s 116us/step - loss: 0.2666 - accuracy: 0.9040 - val_loss: 2.1678 - val_accuracy: 0.4211\n",
      "Epoch 82/100\n",
      "177/177 [==============================] - 0s 132us/step - loss: 0.2540 - accuracy: 0.9153 - val_loss: 2.2713 - val_accuracy: 0.4868\n",
      "Epoch 83/100\n",
      "177/177 [==============================] - 0s 218us/step - loss: 0.2566 - accuracy: 0.9096 - val_loss: 2.2501 - val_accuracy: 0.4605\n",
      "Epoch 84/100\n",
      "177/177 [==============================] - 0s 208us/step - loss: 0.2544 - accuracy: 0.9209 - val_loss: 2.2353 - val_accuracy: 0.4342\n",
      "Epoch 85/100\n",
      "177/177 [==============================] - 0s 198us/step - loss: 0.3070 - accuracy: 0.8983 - val_loss: 2.2689 - val_accuracy: 0.4474\n",
      "Epoch 86/100\n",
      "177/177 [==============================] - 0s 233us/step - loss: 0.3301 - accuracy: 0.8870 - val_loss: 2.4762 - val_accuracy: 0.4342\n",
      "Epoch 87/100\n",
      "177/177 [==============================] - 0s 214us/step - loss: 0.3579 - accuracy: 0.8983 - val_loss: 2.5819 - val_accuracy: 0.4605\n",
      "Epoch 88/100\n",
      "177/177 [==============================] - 0s 287us/step - loss: 0.2926 - accuracy: 0.9096 - val_loss: 2.6560 - val_accuracy: 0.4342\n",
      "Epoch 89/100\n",
      "177/177 [==============================] - 0s 224us/step - loss: 0.2692 - accuracy: 0.8870 - val_loss: 2.6643 - val_accuracy: 0.4474\n",
      "Epoch 90/100\n",
      "177/177 [==============================] - 0s 175us/step - loss: 0.2484 - accuracy: 0.9040 - val_loss: 2.7738 - val_accuracy: 0.4605\n",
      "Epoch 91/100\n",
      "177/177 [==============================] - 0s 158us/step - loss: 0.2383 - accuracy: 0.9266 - val_loss: 2.8347 - val_accuracy: 0.4737\n",
      "Epoch 92/100\n",
      "177/177 [==============================] - 0s 162us/step - loss: 0.2444 - accuracy: 0.9266 - val_loss: 2.7486 - val_accuracy: 0.4605\n",
      "Epoch 93/100\n",
      "177/177 [==============================] - 0s 1ms/step - loss: 0.2341 - accuracy: 0.9040 - val_loss: 2.7674 - val_accuracy: 0.4605\n",
      "Epoch 94/100\n",
      "177/177 [==============================] - 0s 235us/step - loss: 0.2429 - accuracy: 0.9266 - val_loss: 2.8016 - val_accuracy: 0.4342\n",
      "Epoch 95/100\n",
      "177/177 [==============================] - 0s 212us/step - loss: 0.2275 - accuracy: 0.9266 - val_loss: 2.7664 - val_accuracy: 0.4211\n",
      "Epoch 96/100\n",
      "177/177 [==============================] - 0s 159us/step - loss: 0.2344 - accuracy: 0.9209 - val_loss: 2.9891 - val_accuracy: 0.4737\n",
      "Epoch 97/100\n",
      "177/177 [==============================] - 0s 165us/step - loss: 0.2483 - accuracy: 0.9209 - val_loss: 2.9494 - val_accuracy: 0.4605\n",
      "Epoch 98/100\n",
      "177/177 [==============================] - 0s 286us/step - loss: 0.2378 - accuracy: 0.9153 - val_loss: 2.7536 - val_accuracy: 0.4211\n",
      "Epoch 99/100\n",
      "177/177 [==============================] - 0s 177us/step - loss: 0.2329 - accuracy: 0.9153 - val_loss: 2.7355 - val_accuracy: 0.4211\n",
      "Epoch 100/100\n",
      "177/177 [==============================] - 0s 142us/step - loss: 0.2300 - accuracy: 0.9153 - val_loss: 2.7160 - val_accuracy: 0.4211\n"
     ]
    }
   ],
   "source": [
    "hist_sel = model_sel.fit(X_sel_train, y_sel_train,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_sel_test, y_sel_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 89.42%\n"
     ]
    }
   ],
   "source": [
    "print('train accuracy: %.2f%%' % (np.mean(hist_sel.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba5 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_lasso_2.xlsx\",\n",
    "                        sheet_name=0,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NY360</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.848032e-03</td>\n",
       "      <td>0.996096</td>\n",
       "      <td>0.000056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NRS113</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.441349e-01</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.155850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>120337</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.466081e-02</td>\n",
       "      <td>0.005713</td>\n",
       "      <td>0.979626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>CFBREBSa127</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9.985392e-01</td>\n",
       "      <td>0.000350</td>\n",
       "      <td>0.001111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>GA27</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.665667e-08</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.999995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>CFBREBSa131</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6.617341e-03</td>\n",
       "      <td>0.565843</td>\n",
       "      <td>0.427540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>NRS112</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.055758e-03</td>\n",
       "      <td>0.045611</td>\n",
       "      <td>0.953333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>BCH-SA-06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.747076e-01</td>\n",
       "      <td>0.071162</td>\n",
       "      <td>0.054130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>834N</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.593112e-06</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.999985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>CA9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.838999e-01</td>\n",
       "      <td>0.142659</td>\n",
       "      <td>0.473441</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>608 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     phage       strain  phenotype  prediction             0  \\\n",
       "0       p0017kpresabs_qual        NY360          2           1  3.848032e-03   \n",
       "1       p0017kpresabs_qual       NRS113          0           0  8.441349e-01   \n",
       "2       p0017kpresabs_qual       120337          2           2  1.466081e-02   \n",
       "3       p0017kpresabs_qual  CFBREBSa127          1           0  9.985392e-01   \n",
       "4       p0017kpresabs_qual         GA27          2           2  1.665667e-08   \n",
       "..                     ...          ...        ...         ...           ...   \n",
       "603  p0040presabsSTCC_qual  CFBREBSa131          2           1  6.617341e-03   \n",
       "604  p0040presabsSTCC_qual       NRS112          2           2  1.055758e-03   \n",
       "605  p0040presabsSTCC_qual    BCH-SA-06          0           0  8.747076e-01   \n",
       "606  p0040presabsSTCC_qual         834N          2           2  2.593112e-06   \n",
       "607  p0040presabsSTCC_qual          CA9          1           2  3.838999e-01   \n",
       "\n",
       "            1         2  \n",
       "0    0.996096  0.000056  \n",
       "1    0.000015  0.155850  \n",
       "2    0.005713  0.979626  \n",
       "3    0.000350  0.001111  \n",
       "4    0.000005  0.999995  \n",
       "..        ...       ...  \n",
       "603  0.565843  0.427540  \n",
       "604  0.045611  0.953333  \n",
       "605  0.071162  0.054130  \n",
       "606  0.000013  0.999985  \n",
       "607  0.142659  0.473441  \n",
       "\n",
       "[608 rows x 7 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.0821750e-01, 5.6674420e-01, 2.5038283e-02],\n",
       "       [6.0029900e-01, 8.4513320e-02, 3.1518772e-01],\n",
       "       [6.9001490e-04, 3.8759685e-03, 9.9543400e-01],\n",
       "       [3.4116316e-01, 5.2759635e-01, 1.3124049e-01],\n",
       "       [3.0806590e-03, 3.9972164e-02, 9.5694710e-01],\n",
       "       [8.4786296e-01, 4.2923980e-03, 1.4784463e-01],\n",
       "       [1.9999656e-01, 6.2002190e-01, 1.7998166e-01],\n",
       "       [4.2852017e-01, 5.4023160e-01, 3.1248229e-02],\n",
       "       [9.6596190e-01, 3.0850316e-03, 3.0953050e-02],\n",
       "       [4.3896747e-01, 5.1290360e-01, 4.8128980e-02],\n",
       "       [5.6695880e-01, 2.5329900e-01, 1.7974226e-01],\n",
       "       [3.3941576e-06, 9.5819590e-08, 9.9999654e-01],\n",
       "       [5.3895920e-01, 3.4594210e-01, 1.1509866e-01],\n",
       "       [4.8135006e-01, 1.9806825e-01, 3.2058170e-01],\n",
       "       [6.1941595e-04, 3.2777651e-03, 9.9610280e-01],\n",
       "       [2.5841850e-01, 6.9607740e-01, 4.5504045e-02],\n",
       "       [3.0063888e-01, 9.5712420e-02, 6.0364866e-01],\n",
       "       [9.9520420e-01, 1.3208898e-03, 3.4749506e-03],\n",
       "       [2.9688856e-01, 1.5525120e-01, 5.4786020e-01],\n",
       "       [9.7298010e-01, 3.1963037e-03, 2.3823617e-02],\n",
       "       [4.8939693e-01, 4.7545865e-01, 3.5144404e-02],\n",
       "       [3.6027905e-02, 1.3646360e-01, 8.2750857e-01],\n",
       "       [6.1941595e-04, 3.2777651e-03, 9.9610280e-01],\n",
       "       [2.5882694e-01, 2.4178806e-01, 4.9938490e-01],\n",
       "       [8.9112604e-01, 2.8025193e-02, 8.0848750e-02],\n",
       "       [1.5186059e-02, 1.3417092e-01, 8.5064304e-01],\n",
       "       [9.9704736e-01, 2.9084354e-03, 4.4208360e-05],\n",
       "       [4.3042612e-01, 5.2829564e-01, 4.1278303e-02],\n",
       "       [4.3896747e-01, 5.1290360e-01, 4.8128980e-02],\n",
       "       [4.5119172e-01, 5.2658700e-01, 2.2221312e-02],\n",
       "       [8.1687674e-02, 8.9990400e-01, 1.8408312e-02],\n",
       "       [6.5103140e-02, 3.9342150e-02, 8.9555470e-01],\n",
       "       [6.2119806e-01, 3.5886973e-01, 1.9932106e-02],\n",
       "       [6.4185470e-01, 2.6216236e-01, 9.5982954e-02],\n",
       "       [3.6504623e-01, 5.2821890e-01, 1.0673478e-01],\n",
       "       [1.2563238e-01, 7.7565370e-01, 9.8713890e-02],\n",
       "       [4.3896747e-01, 5.1290360e-01, 4.8128980e-02],\n",
       "       [3.1294014e-02, 3.0273820e-01, 6.6596776e-01],\n",
       "       [1.2074448e-03, 8.7689880e-06, 9.9878377e-01],\n",
       "       [3.0735790e-01, 4.4247046e-01, 2.5017160e-01],\n",
       "       [1.6938496e-01, 8.2122980e-01, 9.3852340e-03],\n",
       "       [7.3289007e-01, 1.4104113e-01, 1.2606871e-01],\n",
       "       [7.3919916e-01, 8.5453370e-02, 1.7534745e-01],\n",
       "       [4.3153092e-01, 2.5634640e-01, 3.1212273e-01],\n",
       "       [2.7297860e-01, 6.9060194e-01, 3.6419470e-02],\n",
       "       [4.2192590e-02, 7.5903000e-01, 1.9877740e-01],\n",
       "       [3.0988543e-03, 2.3037374e-03, 9.9459743e-01],\n",
       "       [4.1395930e-01, 4.0721104e-01, 1.7882968e-01],\n",
       "       [1.4126102e-06, 2.3281588e-08, 9.9999857e-01],\n",
       "       [5.0829170e-01, 2.0470590e-01, 2.8700238e-01],\n",
       "       [4.1365117e-02, 1.9362680e-02, 9.3927217e-01],\n",
       "       [4.1458484e-02, 2.4874770e-01, 7.0979380e-01],\n",
       "       [9.7444930e-01, 1.2543424e-03, 2.4296427e-02],\n",
       "       [1.7948137e-03, 1.0220208e-02, 9.8798496e-01],\n",
       "       [2.9925000e-01, 6.6120034e-01, 3.9549634e-02],\n",
       "       [9.2079496e-01, 6.6607860e-02, 1.2597074e-02],\n",
       "       [2.9598388e-01, 4.3942672e-01, 2.6458940e-01],\n",
       "       [2.2046883e-01, 2.2374694e-01, 5.5578420e-01],\n",
       "       [5.7231620e-04, 5.0216154e-03, 9.9440610e-01],\n",
       "       [6.2175536e-01, 4.5457292e-02, 3.3278733e-01],\n",
       "       [4.3896747e-01, 5.1290360e-01, 4.8128980e-02],\n",
       "       [7.3493650e-01, 1.1939094e-01, 1.4567263e-01],\n",
       "       [3.4831104e-01, 5.1710504e-01, 1.3458392e-01],\n",
       "       [5.6049568e-03, 9.9008790e-01, 4.3071510e-03],\n",
       "       [4.4120895e-03, 9.1058300e-02, 9.0452963e-01],\n",
       "       [2.8614786e-01, 5.5887120e-01, 1.5498097e-01],\n",
       "       [8.3815810e-01, 8.3954040e-02, 7.7887920e-02],\n",
       "       [9.4604740e-01, 8.9768350e-05, 5.3862866e-02],\n",
       "       [5.1838744e-01, 1.7584078e-01, 3.0577170e-01],\n",
       "       [4.0302363e-01, 1.3774495e-01, 4.5923138e-01],\n",
       "       [2.7282083e-01, 1.7376494e-01, 5.5341430e-01],\n",
       "       [1.6619703e-02, 1.6233598e-01, 8.2104430e-01],\n",
       "       [1.0314323e-01, 3.2819820e-02, 8.6403690e-01],\n",
       "       [4.6951592e-01, 4.1967908e-01, 1.1080499e-01],\n",
       "       [6.4958150e-01, 2.1438858e-01, 1.3602997e-01],\n",
       "       [7.2883570e-08, 4.5202047e-13, 9.9999990e-01]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob5 = df_proba5[df_proba5['phage']=='p0017kpresabsSTCC_qual'].iloc[:,-3:]\n",
    "y_prob5 = y_prob5.to_numpy()\n",
    "y_prob5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6160385029432649"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo5 = rocauc_ovo(y_sel_test, y_prob5, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6160385029432649"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr5 = rocauc_ovr(y_sel_test, y_prob5, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_sel_train, X_sel_test, y_sel_train, y_sel_test = train_test_split(X_sel, y_sel,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=678,\n",
    "                                                    stratify=y_sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat6 = pd.DataFrame(X_sel_test.iloc[:,-1])\n",
    "dat6['test'] = y_sel_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strain</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>CFBREBSa104</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>NRS199</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>NRS233</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>SR1746</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>NRS202</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>EUH25</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>NRS260</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>CFBRSa25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>NRS177</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>MN055</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          strain  test\n",
       "44   CFBREBSa104     1\n",
       "170       NRS199     2\n",
       "197       NRS233     1\n",
       "238       SR1746     0\n",
       "172       NRS202     2\n",
       "..           ...   ...\n",
       "92         EUH25     2\n",
       "217       NRS260     0\n",
       "75      CFBRSa25     0\n",
       "156       NRS177     1\n",
       "105        MN055     2\n",
       "\n",
       "[76 rows x 2 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sel_train = X_sel_train.drop(['strain'], axis=1)\n",
    "X_sel_test = X_sel_test.drop(['strain'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sel2 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_sel_train.shape[1],)),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sel2.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 177 samples, validate on 76 samples\n",
      "Epoch 1/100\n",
      "177/177 [==============================] - 0s 2ms/step - loss: 3.7129 - accuracy: 0.4068 - val_loss: 2.0674 - val_accuracy: 0.3421\n",
      "Epoch 2/100\n",
      "177/177 [==============================] - 0s 73us/step - loss: 1.8724 - accuracy: 0.4576 - val_loss: 1.5226 - val_accuracy: 0.3816\n",
      "Epoch 3/100\n",
      "177/177 [==============================] - 0s 74us/step - loss: 1.7144 - accuracy: 0.4181 - val_loss: 1.4585 - val_accuracy: 0.3684\n",
      "Epoch 4/100\n",
      "177/177 [==============================] - 0s 83us/step - loss: 1.6059 - accuracy: 0.3898 - val_loss: 1.3899 - val_accuracy: 0.4474\n",
      "Epoch 5/100\n",
      "177/177 [==============================] - 0s 101us/step - loss: 1.3971 - accuracy: 0.4350 - val_loss: 1.0841 - val_accuracy: 0.5000\n",
      "Epoch 6/100\n",
      "177/177 [==============================] - 0s 109us/step - loss: 1.1408 - accuracy: 0.4746 - val_loss: 1.2275 - val_accuracy: 0.3553\n",
      "Epoch 7/100\n",
      "177/177 [==============================] - 0s 91us/step - loss: 1.2663 - accuracy: 0.5141 - val_loss: 1.1977 - val_accuracy: 0.3947\n",
      "Epoch 8/100\n",
      "177/177 [==============================] - 0s 88us/step - loss: 1.1617 - accuracy: 0.5763 - val_loss: 1.1165 - val_accuracy: 0.4605\n",
      "Epoch 9/100\n",
      "177/177 [==============================] - 0s 88us/step - loss: 1.0882 - accuracy: 0.5876 - val_loss: 1.1137 - val_accuracy: 0.4605\n",
      "Epoch 10/100\n",
      "177/177 [==============================] - 0s 81us/step - loss: 1.0090 - accuracy: 0.5706 - val_loss: 1.1297 - val_accuracy: 0.4474\n",
      "Epoch 11/100\n",
      "177/177 [==============================] - 0s 133us/step - loss: 1.0219 - accuracy: 0.5819 - val_loss: 1.0901 - val_accuracy: 0.5000\n",
      "Epoch 12/100\n",
      "177/177 [==============================] - 0s 81us/step - loss: 0.9386 - accuracy: 0.5989 - val_loss: 1.0554 - val_accuracy: 0.5395\n",
      "Epoch 13/100\n",
      "177/177 [==============================] - 0s 105us/step - loss: 0.8866 - accuracy: 0.6215 - val_loss: 1.0753 - val_accuracy: 0.5263\n",
      "Epoch 14/100\n",
      "177/177 [==============================] - 0s 123us/step - loss: 0.9259 - accuracy: 0.6045 - val_loss: 1.0269 - val_accuracy: 0.5526\n",
      "Epoch 15/100\n",
      "177/177 [==============================] - 0s 114us/step - loss: 0.8565 - accuracy: 0.6215 - val_loss: 1.0314 - val_accuracy: 0.5526\n",
      "Epoch 16/100\n",
      "177/177 [==============================] - 0s 101us/step - loss: 0.8577 - accuracy: 0.6328 - val_loss: 1.0283 - val_accuracy: 0.5526\n",
      "Epoch 17/100\n",
      "177/177 [==============================] - 0s 114us/step - loss: 0.8284 - accuracy: 0.6497 - val_loss: 1.0382 - val_accuracy: 0.5526\n",
      "Epoch 18/100\n",
      "177/177 [==============================] - 0s 185us/step - loss: 0.8315 - accuracy: 0.6384 - val_loss: 1.0267 - val_accuracy: 0.5658\n",
      "Epoch 19/100\n",
      "177/177 [==============================] - 0s 101us/step - loss: 0.7972 - accuracy: 0.6723 - val_loss: 1.0316 - val_accuracy: 0.5658\n",
      "Epoch 20/100\n",
      "177/177 [==============================] - 0s 109us/step - loss: 0.7997 - accuracy: 0.6780 - val_loss: 1.0186 - val_accuracy: 0.5921\n",
      "Epoch 21/100\n",
      "177/177 [==============================] - 0s 87us/step - loss: 0.7735 - accuracy: 0.6667 - val_loss: 1.0157 - val_accuracy: 0.5921\n",
      "Epoch 22/100\n",
      "177/177 [==============================] - 0s 133us/step - loss: 0.7679 - accuracy: 0.6723 - val_loss: 1.0232 - val_accuracy: 0.5526\n",
      "Epoch 23/100\n",
      "177/177 [==============================] - 0s 109us/step - loss: 0.7699 - accuracy: 0.6723 - val_loss: 1.0197 - val_accuracy: 0.5658\n",
      "Epoch 24/100\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.7539 - accuracy: 0.6723 - val_loss: 1.0342 - val_accuracy: 0.5395\n",
      "Epoch 25/100\n",
      "177/177 [==============================] - 0s 85us/step - loss: 0.7411 - accuracy: 0.6780 - val_loss: 1.0292 - val_accuracy: 0.5658\n",
      "Epoch 26/100\n",
      "177/177 [==============================] - 0s 145us/step - loss: 0.7376 - accuracy: 0.6780 - val_loss: 1.0263 - val_accuracy: 0.5263\n",
      "Epoch 27/100\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.7247 - accuracy: 0.6836 - val_loss: 1.0286 - val_accuracy: 0.5263\n",
      "Epoch 28/100\n",
      "177/177 [==============================] - 0s 112us/step - loss: 0.7206 - accuracy: 0.6836 - val_loss: 1.0242 - val_accuracy: 0.5526\n",
      "Epoch 29/100\n",
      "177/177 [==============================] - 0s 161us/step - loss: 0.7422 - accuracy: 0.6723 - val_loss: 1.0349 - val_accuracy: 0.5395\n",
      "Epoch 30/100\n",
      "177/177 [==============================] - 0s 123us/step - loss: 0.7205 - accuracy: 0.6780 - val_loss: 1.0473 - val_accuracy: 0.5395\n",
      "Epoch 31/100\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.7054 - accuracy: 0.6949 - val_loss: 1.0223 - val_accuracy: 0.5658\n",
      "Epoch 32/100\n",
      "177/177 [==============================] - 0s 85us/step - loss: 0.7141 - accuracy: 0.6836 - val_loss: 1.0188 - val_accuracy: 0.5789\n",
      "Epoch 33/100\n",
      "177/177 [==============================] - 0s 200us/step - loss: 0.6890 - accuracy: 0.7345 - val_loss: 1.0465 - val_accuracy: 0.5526\n",
      "Epoch 34/100\n",
      "177/177 [==============================] - 0s 164us/step - loss: 0.7098 - accuracy: 0.7232 - val_loss: 1.0367 - val_accuracy: 0.5395\n",
      "Epoch 35/100\n",
      "177/177 [==============================] - 0s 127us/step - loss: 0.7072 - accuracy: 0.7062 - val_loss: 1.0399 - val_accuracy: 0.5526\n",
      "Epoch 36/100\n",
      "177/177 [==============================] - 0s 132us/step - loss: 0.6837 - accuracy: 0.7175 - val_loss: 1.0514 - val_accuracy: 0.5263\n",
      "Epoch 37/100\n",
      "177/177 [==============================] - 0s 104us/step - loss: 0.7083 - accuracy: 0.7288 - val_loss: 1.0286 - val_accuracy: 0.5263\n",
      "Epoch 38/100\n",
      "177/177 [==============================] - 0s 107us/step - loss: 0.7095 - accuracy: 0.7175 - val_loss: 1.0693 - val_accuracy: 0.5263\n",
      "Epoch 39/100\n",
      "177/177 [==============================] - 0s 152us/step - loss: 0.7258 - accuracy: 0.6836 - val_loss: 1.0444 - val_accuracy: 0.5395\n",
      "Epoch 40/100\n",
      "177/177 [==============================] - 0s 74us/step - loss: 0.6877 - accuracy: 0.7232 - val_loss: 1.0586 - val_accuracy: 0.5263\n",
      "Epoch 41/100\n",
      "177/177 [==============================] - 0s 87us/step - loss: 0.6457 - accuracy: 0.7345 - val_loss: 1.0523 - val_accuracy: 0.5263\n",
      "Epoch 42/100\n",
      "177/177 [==============================] - 0s 91us/step - loss: 0.7156 - accuracy: 0.7006 - val_loss: 1.0469 - val_accuracy: 0.5395\n",
      "Epoch 43/100\n",
      "177/177 [==============================] - 0s 137us/step - loss: 0.6563 - accuracy: 0.7345 - val_loss: 1.1251 - val_accuracy: 0.5132\n",
      "Epoch 44/100\n",
      "177/177 [==============================] - 0s 181us/step - loss: 0.7875 - accuracy: 0.7232 - val_loss: 1.1062 - val_accuracy: 0.5132\n",
      "Epoch 45/100\n",
      "177/177 [==============================] - 0s 95us/step - loss: 0.7035 - accuracy: 0.7458 - val_loss: 1.0551 - val_accuracy: 0.5263\n",
      "Epoch 46/100\n",
      "177/177 [==============================] - 0s 107us/step - loss: 0.6445 - accuracy: 0.7627 - val_loss: 1.0639 - val_accuracy: 0.5395\n",
      "Epoch 47/100\n",
      "177/177 [==============================] - 0s 131us/step - loss: 0.6396 - accuracy: 0.7571 - val_loss: 1.0628 - val_accuracy: 0.5263\n",
      "Epoch 48/100\n",
      "177/177 [==============================] - 0s 133us/step - loss: 0.6278 - accuracy: 0.7627 - val_loss: 1.0548 - val_accuracy: 0.5263\n",
      "Epoch 49/100\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.6582 - accuracy: 0.7514 - val_loss: 1.0552 - val_accuracy: 0.5395\n",
      "Epoch 50/100\n",
      "177/177 [==============================] - 0s 204us/step - loss: 0.6443 - accuracy: 0.7175 - val_loss: 1.0609 - val_accuracy: 0.5395\n",
      "Epoch 51/100\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.6746 - accuracy: 0.7401 - val_loss: 1.0811 - val_accuracy: 0.5132\n",
      "Epoch 52/100\n",
      "177/177 [==============================] - 0s 78us/step - loss: 0.6316 - accuracy: 0.7514 - val_loss: 1.0671 - val_accuracy: 0.5395\n",
      "Epoch 53/100\n",
      "177/177 [==============================] - 0s 139us/step - loss: 0.6144 - accuracy: 0.7514 - val_loss: 1.0589 - val_accuracy: 0.5395\n",
      "Epoch 54/100\n",
      "177/177 [==============================] - 0s 126us/step - loss: 0.6205 - accuracy: 0.7514 - val_loss: 1.0654 - val_accuracy: 0.5132\n",
      "Epoch 55/100\n",
      "177/177 [==============================] - 0s 120us/step - loss: 0.6118 - accuracy: 0.7571 - val_loss: 1.0672 - val_accuracy: 0.5526\n",
      "Epoch 56/100\n",
      "177/177 [==============================] - 0s 154us/step - loss: 0.5898 - accuracy: 0.7684 - val_loss: 1.0709 - val_accuracy: 0.5263\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177/177 [==============================] - 0s 114us/step - loss: 0.5876 - accuracy: 0.7797 - val_loss: 1.0799 - val_accuracy: 0.5132\n",
      "Epoch 58/100\n",
      "177/177 [==============================] - 0s 103us/step - loss: 0.6113 - accuracy: 0.7627 - val_loss: 1.0658 - val_accuracy: 0.5132\n",
      "Epoch 59/100\n",
      "177/177 [==============================] - 0s 138us/step - loss: 0.6001 - accuracy: 0.7571 - val_loss: 1.0763 - val_accuracy: 0.5132\n",
      "Epoch 60/100\n",
      "177/177 [==============================] - 0s 130us/step - loss: 0.5615 - accuracy: 0.8079 - val_loss: 1.0993 - val_accuracy: 0.4737\n",
      "Epoch 61/100\n",
      "177/177 [==============================] - 0s 94us/step - loss: 0.6144 - accuracy: 0.7910 - val_loss: 1.0779 - val_accuracy: 0.5263\n",
      "Epoch 62/100\n",
      "177/177 [==============================] - 0s 84us/step - loss: 0.5782 - accuracy: 0.7910 - val_loss: 1.0825 - val_accuracy: 0.5132\n",
      "Epoch 63/100\n",
      "177/177 [==============================] - 0s 177us/step - loss: 0.6180 - accuracy: 0.7740 - val_loss: 1.0831 - val_accuracy: 0.5000\n",
      "Epoch 64/100\n",
      "177/177 [==============================] - 0s 291us/step - loss: 0.5793 - accuracy: 0.7740 - val_loss: 1.0724 - val_accuracy: 0.4868\n",
      "Epoch 65/100\n",
      "177/177 [==============================] - 0s 170us/step - loss: 0.5700 - accuracy: 0.7571 - val_loss: 1.0626 - val_accuracy: 0.5263\n",
      "Epoch 66/100\n",
      "177/177 [==============================] - 0s 135us/step - loss: 0.5474 - accuracy: 0.7966 - val_loss: 1.0645 - val_accuracy: 0.5000\n",
      "Epoch 67/100\n",
      "177/177 [==============================] - 0s 201us/step - loss: 0.5380 - accuracy: 0.8023 - val_loss: 1.0777 - val_accuracy: 0.5132\n",
      "Epoch 68/100\n",
      "177/177 [==============================] - 0s 111us/step - loss: 0.5478 - accuracy: 0.7910 - val_loss: 1.0908 - val_accuracy: 0.4868\n",
      "Epoch 69/100\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.5279 - accuracy: 0.8136 - val_loss: 1.0931 - val_accuracy: 0.4737\n",
      "Epoch 70/100\n",
      "177/177 [==============================] - 0s 77us/step - loss: 0.5394 - accuracy: 0.8079 - val_loss: 1.0941 - val_accuracy: 0.4868\n",
      "Epoch 71/100\n",
      "177/177 [==============================] - 0s 140us/step - loss: 0.5262 - accuracy: 0.8023 - val_loss: 1.0837 - val_accuracy: 0.4868\n",
      "Epoch 72/100\n",
      "177/177 [==============================] - 0s 106us/step - loss: 0.5271 - accuracy: 0.7853 - val_loss: 1.0943 - val_accuracy: 0.5395\n",
      "Epoch 73/100\n",
      "177/177 [==============================] - 0s 97us/step - loss: 0.5356 - accuracy: 0.7910 - val_loss: 1.0931 - val_accuracy: 0.4868\n",
      "Epoch 74/100\n",
      "177/177 [==============================] - 0s 86us/step - loss: 0.5443 - accuracy: 0.8362 - val_loss: 1.1004 - val_accuracy: 0.5263\n",
      "Epoch 75/100\n",
      "177/177 [==============================] - 0s 93us/step - loss: 0.5551 - accuracy: 0.8079 - val_loss: 1.0883 - val_accuracy: 0.4868\n",
      "Epoch 76/100\n",
      "177/177 [==============================] - 0s 79us/step - loss: 0.5262 - accuracy: 0.8136 - val_loss: 1.1222 - val_accuracy: 0.4868\n",
      "Epoch 77/100\n",
      "177/177 [==============================] - 0s 85us/step - loss: 0.5446 - accuracy: 0.8305 - val_loss: 1.1154 - val_accuracy: 0.5132\n",
      "Epoch 78/100\n",
      "177/177 [==============================] - 0s 160us/step - loss: 0.5202 - accuracy: 0.7853 - val_loss: 1.1419 - val_accuracy: 0.5000\n",
      "Epoch 79/100\n",
      "177/177 [==============================] - 0s 160us/step - loss: 0.5598 - accuracy: 0.7966 - val_loss: 1.1084 - val_accuracy: 0.5000\n",
      "Epoch 80/100\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.5095 - accuracy: 0.8249 - val_loss: 1.0883 - val_accuracy: 0.5132\n",
      "Epoch 81/100\n",
      "177/177 [==============================] - 0s 96us/step - loss: 0.5183 - accuracy: 0.8023 - val_loss: 1.0877 - val_accuracy: 0.5132\n",
      "Epoch 82/100\n",
      "177/177 [==============================] - 0s 119us/step - loss: 0.5023 - accuracy: 0.8249 - val_loss: 1.1138 - val_accuracy: 0.5000\n",
      "Epoch 83/100\n",
      "177/177 [==============================] - 0s 77us/step - loss: 0.4980 - accuracy: 0.8249 - val_loss: 1.1101 - val_accuracy: 0.4868\n",
      "Epoch 84/100\n",
      "177/177 [==============================] - 0s 74us/step - loss: 0.5025 - accuracy: 0.8192 - val_loss: 1.1070 - val_accuracy: 0.5132\n",
      "Epoch 85/100\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.5066 - accuracy: 0.8249 - val_loss: 1.1205 - val_accuracy: 0.5000\n",
      "Epoch 86/100\n",
      "177/177 [==============================] - 0s 94us/step - loss: 0.4853 - accuracy: 0.8249 - val_loss: 1.1183 - val_accuracy: 0.5000\n",
      "Epoch 87/100\n",
      "177/177 [==============================] - 0s 107us/step - loss: 0.4960 - accuracy: 0.8249 - val_loss: 1.1055 - val_accuracy: 0.5000\n",
      "Epoch 88/100\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.5116 - accuracy: 0.8362 - val_loss: 1.1071 - val_accuracy: 0.5263\n",
      "Epoch 89/100\n",
      "177/177 [==============================] - 0s 75us/step - loss: 0.4870 - accuracy: 0.8418 - val_loss: 1.1074 - val_accuracy: 0.5263\n",
      "Epoch 90/100\n",
      "177/177 [==============================] - 0s 81us/step - loss: 0.4941 - accuracy: 0.8362 - val_loss: 1.1265 - val_accuracy: 0.5132\n",
      "Epoch 91/100\n",
      "177/177 [==============================] - 0s 77us/step - loss: 0.4793 - accuracy: 0.8305 - val_loss: 1.1180 - val_accuracy: 0.4737\n",
      "Epoch 92/100\n",
      "177/177 [==============================] - 0s 111us/step - loss: 0.4798 - accuracy: 0.8249 - val_loss: 1.1210 - val_accuracy: 0.5132\n",
      "Epoch 93/100\n",
      "177/177 [==============================] - 0s 89us/step - loss: 0.4744 - accuracy: 0.8362 - val_loss: 1.1258 - val_accuracy: 0.4868\n",
      "Epoch 94/100\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.4632 - accuracy: 0.8531 - val_loss: 1.1130 - val_accuracy: 0.5263\n",
      "Epoch 95/100\n",
      "177/177 [==============================] - 0s 87us/step - loss: 0.4547 - accuracy: 0.8644 - val_loss: 1.0975 - val_accuracy: 0.5132\n",
      "Epoch 96/100\n",
      "177/177 [==============================] - 0s 222us/step - loss: 0.4583 - accuracy: 0.8475 - val_loss: 1.1151 - val_accuracy: 0.5000\n",
      "Epoch 97/100\n",
      "177/177 [==============================] - 0s 279us/step - loss: 0.4451 - accuracy: 0.8588 - val_loss: 1.1302 - val_accuracy: 0.5000\n",
      "Epoch 98/100\n",
      "177/177 [==============================] - 0s 195us/step - loss: 0.4545 - accuracy: 0.8418 - val_loss: 1.1348 - val_accuracy: 0.4737\n",
      "Epoch 99/100\n",
      "177/177 [==============================] - 0s 213us/step - loss: 0.4586 - accuracy: 0.8531 - val_loss: 1.1314 - val_accuracy: 0.4868\n",
      "Epoch 100/100\n",
      "177/177 [==============================] - 0s 150us/step - loss: 0.4415 - accuracy: 0.8644 - val_loss: 1.1361 - val_accuracy: 0.4737\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a3afd85f8>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sel2.fit(X_sel_train, y_sel_train,\n",
    "          batch_size=64, epochs=100,\n",
    "          validation_data=(X_sel_test, y_sel_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 0s 110us/step\n",
      "test accuracy: 51.32%\n"
     ]
    }
   ],
   "source": [
    "acc_test_sel2 = model_sel2.evaluate(X_sel_test, y_sel_test)[1]\n",
    "print('test accuracy: %.2f%%' % (acc_test_sel2*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 0, 1, 2, 2, 2, 1, 2, 0, 1, 2, 0, 2, 1, 0, 1, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 2, 0, 1, 2, 2, 2, 2, 2, 0, 2, 2, 0, 0, 1, 0, 2,\n",
       "       1, 0, 0, 0, 0, 1, 2, 0, 1, 0, 2, 1, 0, 2, 0, 0, 0, 0, 2, 2, 2, 1,\n",
       "       2, 1, 0, 0, 2, 0, 0, 0, 1, 2])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred6 = model_sel2.predict_classes(X_sel_test)\n",
    "pred6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strain</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>CFBREBSa104</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>NRS199</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>NRS233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>SR1746</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>NRS202</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>EUH25</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>NRS260</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>CFBRSa25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>NRS177</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>MN055</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          strain  test  pred\n",
       "44   CFBREBSa104     1     2\n",
       "170       NRS199     2     0\n",
       "197       NRS233     1     0\n",
       "238       SR1746     0     1\n",
       "172       NRS202     2     2\n",
       "..           ...   ...   ...\n",
       "92         EUH25     2     0\n",
       "217       NRS260     0     0\n",
       "75      CFBRSa25     0     0\n",
       "156       NRS177     1     1\n",
       "105        MN055     2     2\n",
       "\n",
       "[76 rows x 3 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat6['pred'] = pred6\n",
    "dat6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba6 = model_sel2.predict_proba(X_sel_test)\n",
    "dat_proba6 = pd.DataFrame(proba6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.086054</td>\n",
       "      <td>0.142993</td>\n",
       "      <td>0.770953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.395020</td>\n",
       "      <td>0.367852</td>\n",
       "      <td>0.237128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.390421</td>\n",
       "      <td>0.324556</td>\n",
       "      <td>0.285023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.292312</td>\n",
       "      <td>0.414531</td>\n",
       "      <td>0.293156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.186511</td>\n",
       "      <td>0.156528</td>\n",
       "      <td>0.656961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.881564</td>\n",
       "      <td>0.110491</td>\n",
       "      <td>0.007945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.723630</td>\n",
       "      <td>0.223998</td>\n",
       "      <td>0.052371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.622915</td>\n",
       "      <td>0.221427</td>\n",
       "      <td>0.155658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.077259</td>\n",
       "      <td>0.808464</td>\n",
       "      <td>0.114277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.339849</td>\n",
       "      <td>0.230639</td>\n",
       "      <td>0.429512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2\n",
       "0   0.086054  0.142993  0.770953\n",
       "1   0.395020  0.367852  0.237128\n",
       "2   0.390421  0.324556  0.285023\n",
       "3   0.292312  0.414531  0.293156\n",
       "4   0.186511  0.156528  0.656961\n",
       "..       ...       ...       ...\n",
       "71  0.881564  0.110491  0.007945\n",
       "72  0.723630  0.223998  0.052371\n",
       "73  0.622915  0.221427  0.155658\n",
       "74  0.077259  0.808464  0.114277\n",
       "75  0.339849  0.230639  0.429512\n",
       "\n",
       "[76 rows x 3 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba6.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba6.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat6.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/6p17ST.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 177 samples, validate on 76 samples\n",
      "Epoch 1/100\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.4095 - accuracy: 0.8475 - val_loss: 1.2108 - val_accuracy: 0.4474\n",
      "Epoch 2/100\n",
      "177/177 [==============================] - 0s 87us/step - loss: 0.3981 - accuracy: 0.8418 - val_loss: 1.2094 - val_accuracy: 0.4474\n",
      "Epoch 3/100\n",
      "177/177 [==============================] - 0s 93us/step - loss: 0.3950 - accuracy: 0.8305 - val_loss: 1.2103 - val_accuracy: 0.4868\n",
      "Epoch 4/100\n",
      "177/177 [==============================] - 0s 147us/step - loss: 0.3912 - accuracy: 0.8362 - val_loss: 1.2156 - val_accuracy: 0.5000\n",
      "Epoch 5/100\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.4043 - accuracy: 0.8475 - val_loss: 1.2285 - val_accuracy: 0.4868\n",
      "Epoch 6/100\n",
      "177/177 [==============================] - 0s 133us/step - loss: 0.4132 - accuracy: 0.8418 - val_loss: 1.2289 - val_accuracy: 0.5132\n",
      "Epoch 7/100\n",
      "177/177 [==============================] - 0s 120us/step - loss: 0.4174 - accuracy: 0.8418 - val_loss: 1.2472 - val_accuracy: 0.4868\n",
      "Epoch 8/100\n",
      "177/177 [==============================] - 0s 117us/step - loss: 0.4124 - accuracy: 0.8475 - val_loss: 1.2314 - val_accuracy: 0.4737\n",
      "Epoch 9/100\n",
      "177/177 [==============================] - 0s 94us/step - loss: 0.3763 - accuracy: 0.8531 - val_loss: 1.2445 - val_accuracy: 0.5000\n",
      "Epoch 10/100\n",
      "177/177 [==============================] - 0s 128us/step - loss: 0.3949 - accuracy: 0.8588 - val_loss: 1.2329 - val_accuracy: 0.5132\n",
      "Epoch 11/100\n",
      "177/177 [==============================] - 0s 129us/step - loss: 0.3687 - accuracy: 0.8701 - val_loss: 1.2408 - val_accuracy: 0.5000\n",
      "Epoch 12/100\n",
      "177/177 [==============================] - 0s 95us/step - loss: 0.4091 - accuracy: 0.8588 - val_loss: 1.2473 - val_accuracy: 0.5000\n",
      "Epoch 13/100\n",
      "177/177 [==============================] - 0s 100us/step - loss: 0.3764 - accuracy: 0.8701 - val_loss: 1.2418 - val_accuracy: 0.5000\n",
      "Epoch 14/100\n",
      "177/177 [==============================] - 0s 116us/step - loss: 0.3935 - accuracy: 0.8418 - val_loss: 1.2526 - val_accuracy: 0.4605\n",
      "Epoch 15/100\n",
      "177/177 [==============================] - 0s 156us/step - loss: 0.4278 - accuracy: 0.8362 - val_loss: 1.2591 - val_accuracy: 0.5000\n",
      "Epoch 16/100\n",
      "177/177 [==============================] - 0s 104us/step - loss: 0.3886 - accuracy: 0.8475 - val_loss: 1.3045 - val_accuracy: 0.5132\n",
      "Epoch 17/100\n",
      "177/177 [==============================] - 0s 100us/step - loss: 0.4692 - accuracy: 0.8475 - val_loss: 1.2972 - val_accuracy: 0.5000\n",
      "Epoch 18/100\n",
      "177/177 [==============================] - 0s 87us/step - loss: 0.4233 - accuracy: 0.8249 - val_loss: 1.2599 - val_accuracy: 0.4474\n",
      "Epoch 19/100\n",
      "177/177 [==============================] - 0s 86us/step - loss: 0.3696 - accuracy: 0.8531 - val_loss: 1.3060 - val_accuracy: 0.4868\n",
      "Epoch 20/100\n",
      "177/177 [==============================] - 0s 101us/step - loss: 0.4191 - accuracy: 0.8362 - val_loss: 1.2759 - val_accuracy: 0.5263\n",
      "Epoch 21/100\n",
      "177/177 [==============================] - 0s 109us/step - loss: 0.3981 - accuracy: 0.8701 - val_loss: 1.2812 - val_accuracy: 0.5395\n",
      "Epoch 22/100\n",
      "177/177 [==============================] - 0s 118us/step - loss: 0.4268 - accuracy: 0.8531 - val_loss: 1.2777 - val_accuracy: 0.5132\n",
      "Epoch 23/100\n",
      "177/177 [==============================] - 0s 108us/step - loss: 0.3926 - accuracy: 0.8644 - val_loss: 1.3057 - val_accuracy: 0.4605\n",
      "Epoch 24/100\n",
      "177/177 [==============================] - 0s 94us/step - loss: 0.4202 - accuracy: 0.8588 - val_loss: 1.3104 - val_accuracy: 0.4737\n",
      "Epoch 25/100\n",
      "177/177 [==============================] - 0s 101us/step - loss: 0.3891 - accuracy: 0.8644 - val_loss: 1.2525 - val_accuracy: 0.4737\n",
      "Epoch 26/100\n",
      "177/177 [==============================] - 0s 101us/step - loss: 0.3691 - accuracy: 0.8701 - val_loss: 1.2742 - val_accuracy: 0.5263\n",
      "Epoch 27/100\n",
      "177/177 [==============================] - 0s 109us/step - loss: 0.3814 - accuracy: 0.8644 - val_loss: 1.2902 - val_accuracy: 0.4737\n",
      "Epoch 28/100\n",
      "177/177 [==============================] - 0s 107us/step - loss: 0.3841 - accuracy: 0.8701 - val_loss: 1.2954 - val_accuracy: 0.4737\n",
      "Epoch 29/100\n",
      "177/177 [==============================] - 0s 95us/step - loss: 0.3758 - accuracy: 0.8531 - val_loss: 1.2742 - val_accuracy: 0.4605\n",
      "Epoch 30/100\n",
      "177/177 [==============================] - 0s 114us/step - loss: 0.3744 - accuracy: 0.8701 - val_loss: 1.2636 - val_accuracy: 0.5132\n",
      "Epoch 31/100\n",
      "177/177 [==============================] - 0s 114us/step - loss: 0.3697 - accuracy: 0.8531 - val_loss: 1.2840 - val_accuracy: 0.4737\n",
      "Epoch 32/100\n",
      "177/177 [==============================] - 0s 122us/step - loss: 0.3499 - accuracy: 0.8644 - val_loss: 1.3164 - val_accuracy: 0.4737\n",
      "Epoch 33/100\n",
      "177/177 [==============================] - 0s 143us/step - loss: 0.3891 - accuracy: 0.8644 - val_loss: 1.3285 - val_accuracy: 0.4342\n",
      "Epoch 34/100\n",
      "177/177 [==============================] - 0s 96us/step - loss: 0.3605 - accuracy: 0.8701 - val_loss: 1.3040 - val_accuracy: 0.5000\n",
      "Epoch 35/100\n",
      "177/177 [==============================] - 0s 96us/step - loss: 0.3570 - accuracy: 0.8814 - val_loss: 1.2862 - val_accuracy: 0.5000\n",
      "Epoch 36/100\n",
      "177/177 [==============================] - 0s 127us/step - loss: 0.3462 - accuracy: 0.8814 - val_loss: 1.2768 - val_accuracy: 0.4868\n",
      "Epoch 37/100\n",
      "177/177 [==============================] - 0s 89us/step - loss: 0.3482 - accuracy: 0.8814 - val_loss: 1.2757 - val_accuracy: 0.4737\n",
      "Epoch 38/100\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.3386 - accuracy: 0.8757 - val_loss: 1.3116 - val_accuracy: 0.4737\n",
      "Epoch 39/100\n",
      "177/177 [==============================] - 0s 102us/step - loss: 0.3529 - accuracy: 0.8870 - val_loss: 1.3250 - val_accuracy: 0.4605\n",
      "Epoch 40/100\n",
      "177/177 [==============================] - 0s 113us/step - loss: 0.3412 - accuracy: 0.8870 - val_loss: 1.3216 - val_accuracy: 0.4605\n",
      "Epoch 41/100\n",
      "177/177 [==============================] - 0s 110us/step - loss: 0.3429 - accuracy: 0.8757 - val_loss: 1.3076 - val_accuracy: 0.5000\n",
      "Epoch 42/100\n",
      "177/177 [==============================] - 0s 107us/step - loss: 0.3250 - accuracy: 0.8757 - val_loss: 1.3118 - val_accuracy: 0.4737\n",
      "Epoch 43/100\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.3380 - accuracy: 0.8870 - val_loss: 1.3040 - val_accuracy: 0.4737\n",
      "Epoch 44/100\n",
      "177/177 [==============================] - 0s 92us/step - loss: 0.3362 - accuracy: 0.8757 - val_loss: 1.3063 - val_accuracy: 0.4737\n",
      "Epoch 45/100\n",
      "177/177 [==============================] - 0s 89us/step - loss: 0.3389 - accuracy: 0.8757 - val_loss: 1.3025 - val_accuracy: 0.4868\n",
      "Epoch 46/100\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.3465 - accuracy: 0.8814 - val_loss: 1.3062 - val_accuracy: 0.4868\n",
      "Epoch 47/100\n",
      "177/177 [==============================] - 0s 93us/step - loss: 0.3086 - accuracy: 0.9153 - val_loss: 1.3527 - val_accuracy: 0.4737\n",
      "Epoch 48/100\n",
      "177/177 [==============================] - 0s 103us/step - loss: 0.3670 - accuracy: 0.8983 - val_loss: 1.3346 - val_accuracy: 0.4868\n",
      "Epoch 49/100\n",
      "177/177 [==============================] - 0s 117us/step - loss: 0.3356 - accuracy: 0.9040 - val_loss: 1.3195 - val_accuracy: 0.5000\n",
      "Epoch 50/100\n",
      "177/177 [==============================] - 0s 128us/step - loss: 0.3698 - accuracy: 0.8757 - val_loss: 1.2994 - val_accuracy: 0.5000\n",
      "Epoch 51/100\n",
      "177/177 [==============================] - 0s 119us/step - loss: 0.3337 - accuracy: 0.8983 - val_loss: 1.3023 - val_accuracy: 0.4868\n",
      "Epoch 52/100\n",
      "177/177 [==============================] - 0s 134us/step - loss: 0.3247 - accuracy: 0.8983 - val_loss: 1.3001 - val_accuracy: 0.4868\n",
      "Epoch 53/100\n",
      "177/177 [==============================] - 0s 108us/step - loss: 0.3102 - accuracy: 0.8870 - val_loss: 1.3169 - val_accuracy: 0.4737\n",
      "Epoch 54/100\n",
      "177/177 [==============================] - 0s 121us/step - loss: 0.3202 - accuracy: 0.8814 - val_loss: 1.3192 - val_accuracy: 0.4737\n",
      "Epoch 55/100\n",
      "177/177 [==============================] - 0s 113us/step - loss: 0.3050 - accuracy: 0.8983 - val_loss: 1.3202 - val_accuracy: 0.4868\n",
      "Epoch 56/100\n",
      "177/177 [==============================] - 0s 96us/step - loss: 0.3166 - accuracy: 0.8927 - val_loss: 1.3225 - val_accuracy: 0.4868\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177/177 [==============================] - 0s 80us/step - loss: 0.3055 - accuracy: 0.9040 - val_loss: 1.3293 - val_accuracy: 0.4737\n",
      "Epoch 58/100\n",
      "177/177 [==============================] - 0s 102us/step - loss: 0.3016 - accuracy: 0.9040 - val_loss: 1.3260 - val_accuracy: 0.4605\n",
      "Epoch 59/100\n",
      "177/177 [==============================] - 0s 94us/step - loss: 0.3012 - accuracy: 0.9040 - val_loss: 1.3218 - val_accuracy: 0.5000\n",
      "Epoch 60/100\n",
      "177/177 [==============================] - 0s 107us/step - loss: 0.3037 - accuracy: 0.8927 - val_loss: 1.3152 - val_accuracy: 0.4868\n",
      "Epoch 61/100\n",
      "177/177 [==============================] - 0s 116us/step - loss: 0.2999 - accuracy: 0.8983 - val_loss: 1.3215 - val_accuracy: 0.5000\n",
      "Epoch 62/100\n",
      "177/177 [==============================] - 0s 108us/step - loss: 0.3054 - accuracy: 0.9096 - val_loss: 1.3385 - val_accuracy: 0.4737\n",
      "Epoch 63/100\n",
      "177/177 [==============================] - 0s 97us/step - loss: 0.3020 - accuracy: 0.8983 - val_loss: 1.3494 - val_accuracy: 0.4474\n",
      "Epoch 64/100\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.3266 - accuracy: 0.8983 - val_loss: 1.3403 - val_accuracy: 0.5000\n",
      "Epoch 65/100\n",
      "177/177 [==============================] - 0s 82us/step - loss: 0.2969 - accuracy: 0.9096 - val_loss: 1.3301 - val_accuracy: 0.4737\n",
      "Epoch 66/100\n",
      "177/177 [==============================] - 0s 89us/step - loss: 0.3401 - accuracy: 0.8927 - val_loss: 1.3401 - val_accuracy: 0.4605\n",
      "Epoch 67/100\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.3098 - accuracy: 0.9040 - val_loss: 1.3643 - val_accuracy: 0.4868\n",
      "Epoch 68/100\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.3854 - accuracy: 0.8870 - val_loss: 1.3794 - val_accuracy: 0.5132\n",
      "Epoch 69/100\n",
      "177/177 [==============================] - 0s 81us/step - loss: 0.3947 - accuracy: 0.8814 - val_loss: 1.3587 - val_accuracy: 0.4868\n",
      "Epoch 70/100\n",
      "177/177 [==============================] - 0s 82us/step - loss: 0.3552 - accuracy: 0.9040 - val_loss: 1.3356 - val_accuracy: 0.5000\n",
      "Epoch 71/100\n",
      "177/177 [==============================] - 0s 86us/step - loss: 0.3242 - accuracy: 0.9096 - val_loss: 1.3597 - val_accuracy: 0.4868\n",
      "Epoch 72/100\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.3081 - accuracy: 0.9096 - val_loss: 1.3538 - val_accuracy: 0.4868\n",
      "Epoch 73/100\n",
      "177/177 [==============================] - 0s 85us/step - loss: 0.2826 - accuracy: 0.9040 - val_loss: 1.3742 - val_accuracy: 0.4737\n",
      "Epoch 74/100\n",
      "177/177 [==============================] - 0s 105us/step - loss: 0.3153 - accuracy: 0.9040 - val_loss: 1.3791 - val_accuracy: 0.4737\n",
      "Epoch 75/100\n",
      "177/177 [==============================] - 0s 97us/step - loss: 0.2961 - accuracy: 0.9153 - val_loss: 1.3609 - val_accuracy: 0.4605\n",
      "Epoch 76/100\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.2962 - accuracy: 0.9096 - val_loss: 1.3602 - val_accuracy: 0.5000\n",
      "Epoch 77/100\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.3196 - accuracy: 0.8927 - val_loss: 1.3582 - val_accuracy: 0.4605\n",
      "Epoch 78/100\n",
      "177/177 [==============================] - ETA: 0s - loss: 0.3166 - accuracy: 0.85 - 0s 79us/step - loss: 0.3175 - accuracy: 0.9040 - val_loss: 1.3998 - val_accuracy: 0.4605\n",
      "Epoch 79/100\n",
      "177/177 [==============================] - 0s 102us/step - loss: 0.3094 - accuracy: 0.8983 - val_loss: 1.3749 - val_accuracy: 0.4868\n",
      "Epoch 80/100\n",
      "177/177 [==============================] - 0s 187us/step - loss: 0.2816 - accuracy: 0.8983 - val_loss: 1.3834 - val_accuracy: 0.4868\n",
      "Epoch 81/100\n",
      "177/177 [==============================] - ETA: 0s - loss: 0.2747 - accuracy: 0.89 - 0s 287us/step - loss: 0.3393 - accuracy: 0.8701 - val_loss: 1.3797 - val_accuracy: 0.5000\n",
      "Epoch 82/100\n",
      "177/177 [==============================] - ETA: 0s - loss: 0.2870 - accuracy: 0.90 - 0s 356us/step - loss: 0.2846 - accuracy: 0.9040 - val_loss: 1.3760 - val_accuracy: 0.4737\n",
      "Epoch 83/100\n",
      "177/177 [==============================] - 0s 116us/step - loss: 0.2929 - accuracy: 0.9096 - val_loss: 1.3890 - val_accuracy: 0.4605\n",
      "Epoch 84/100\n",
      "177/177 [==============================] - 0s 115us/step - loss: 0.2876 - accuracy: 0.8927 - val_loss: 1.3728 - val_accuracy: 0.4868\n",
      "Epoch 85/100\n",
      "177/177 [==============================] - 0s 116us/step - loss: 0.2767 - accuracy: 0.9096 - val_loss: 1.3826 - val_accuracy: 0.5000\n",
      "Epoch 86/100\n",
      "177/177 [==============================] - 0s 172us/step - loss: 0.3183 - accuracy: 0.8927 - val_loss: 1.3730 - val_accuracy: 0.5000\n",
      "Epoch 87/100\n",
      "177/177 [==============================] - 0s 163us/step - loss: 0.2892 - accuracy: 0.9153 - val_loss: 1.4198 - val_accuracy: 0.4868\n",
      "Epoch 88/100\n",
      "177/177 [==============================] - 0s 178us/step - loss: 0.3218 - accuracy: 0.8927 - val_loss: 1.4097 - val_accuracy: 0.4605\n",
      "Epoch 89/100\n",
      "177/177 [==============================] - ETA: 0s - loss: 0.3586 - accuracy: 0.89 - 0s 128us/step - loss: 0.3002 - accuracy: 0.9096 - val_loss: 1.3930 - val_accuracy: 0.5000\n",
      "Epoch 90/100\n",
      "177/177 [==============================] - 0s 185us/step - loss: 0.3043 - accuracy: 0.8983 - val_loss: 1.3819 - val_accuracy: 0.4868\n",
      "Epoch 91/100\n",
      "177/177 [==============================] - 0s 137us/step - loss: 0.2826 - accuracy: 0.9096 - val_loss: 1.3753 - val_accuracy: 0.5000\n",
      "Epoch 92/100\n",
      "177/177 [==============================] - 0s 105us/step - loss: 0.2914 - accuracy: 0.9153 - val_loss: 1.4064 - val_accuracy: 0.4737\n",
      "Epoch 93/100\n",
      "177/177 [==============================] - 0s 93us/step - loss: 0.3216 - accuracy: 0.9040 - val_loss: 1.3970 - val_accuracy: 0.4868\n",
      "Epoch 94/100\n",
      "177/177 [==============================] - 0s 226us/step - loss: 0.3059 - accuracy: 0.9153 - val_loss: 1.3891 - val_accuracy: 0.4868\n",
      "Epoch 95/100\n",
      "177/177 [==============================] - 0s 232us/step - loss: 0.2906 - accuracy: 0.9153 - val_loss: 1.4031 - val_accuracy: 0.4605\n",
      "Epoch 96/100\n",
      "177/177 [==============================] - 0s 636us/step - loss: 0.2852 - accuracy: 0.9153 - val_loss: 1.3876 - val_accuracy: 0.5000\n",
      "Epoch 97/100\n",
      "177/177 [==============================] - 0s 158us/step - loss: 0.2797 - accuracy: 0.9209 - val_loss: 1.3857 - val_accuracy: 0.4737\n",
      "Epoch 98/100\n",
      "177/177 [==============================] - 0s 412us/step - loss: 0.2734 - accuracy: 0.9040 - val_loss: 1.3960 - val_accuracy: 0.4605\n",
      "Epoch 99/100\n",
      "177/177 [==============================] - 0s 149us/step - loss: 0.2830 - accuracy: 0.8927 - val_loss: 1.4011 - val_accuracy: 0.5000\n",
      "Epoch 100/100\n",
      "177/177 [==============================] - 0s 174us/step - loss: 0.2621 - accuracy: 0.9209 - val_loss: 1.4155 - val_accuracy: 0.4474\n"
     ]
    }
   ],
   "source": [
    "hist_sel2 = model_sel2.fit(X_sel_train, y_sel_train,\n",
    "          batch_size=64, epochs=100,\n",
    "          validation_data=(X_sel_test, y_sel_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 88.28%\n"
     ]
    }
   ],
   "source": [
    "print('train accuracy: %.2f%%' % (np.mean(hist_sel2.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba6 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_lasso_2.xlsx\",\n",
    "                        sheet_name=1,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>CFBREBSa104</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.290039e-09</td>\n",
       "      <td>1.567630e-07</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NRS199</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.856965e-05</td>\n",
       "      <td>2.843749e-03</td>\n",
       "      <td>9.971277e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NRS233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9.999446e-01</td>\n",
       "      <td>4.541289e-06</td>\n",
       "      <td>5.090974e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>SR1746</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6.282367e-02</td>\n",
       "      <td>7.075194e-04</td>\n",
       "      <td>9.364688e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NRS202</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8.229589e-03</td>\n",
       "      <td>2.163908e-05</td>\n",
       "      <td>9.917488e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>GA27</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.964591e-03</td>\n",
       "      <td>9.959286e-01</td>\n",
       "      <td>1.068284e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>GA231</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.309226e-04</td>\n",
       "      <td>9.996691e-01</td>\n",
       "      <td>6.232397e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>SR1287</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.445997e-06</td>\n",
       "      <td>9.999915e-01</td>\n",
       "      <td>1.182947e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>506</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6.516150e-01</td>\n",
       "      <td>1.480882e-02</td>\n",
       "      <td>3.335762e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>NRS001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.841915e-04</td>\n",
       "      <td>9.994158e-01</td>\n",
       "      <td>6.525528e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>608 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     phage       strain  phenotype  prediction             0  \\\n",
       "0       p0017kpresabs_qual  CFBREBSa104          1           2  1.290039e-09   \n",
       "1       p0017kpresabs_qual       NRS199          2           2  2.856965e-05   \n",
       "2       p0017kpresabs_qual       NRS233          1           0  9.999446e-01   \n",
       "3       p0017kpresabs_qual       SR1746          0           2  6.282367e-02   \n",
       "4       p0017kpresabs_qual       NRS202          2           2  8.229589e-03   \n",
       "..                     ...          ...        ...         ...           ...   \n",
       "603  p0040presabsSTCC_qual         GA27          2           1  3.964591e-03   \n",
       "604  p0040presabsSTCC_qual        GA231          2           1  3.309226e-04   \n",
       "605  p0040presabsSTCC_qual       SR1287          0           1  8.445997e-06   \n",
       "606  p0040presabsSTCC_qual          506          2           0  6.516150e-01   \n",
       "607  p0040presabsSTCC_qual       NRS001          1           1  5.841915e-04   \n",
       "\n",
       "                1             2  \n",
       "0    1.567630e-07  9.999999e-01  \n",
       "1    2.843749e-03  9.971277e-01  \n",
       "2    4.541289e-06  5.090974e-05  \n",
       "3    7.075194e-04  9.364688e-01  \n",
       "4    2.163908e-05  9.917488e-01  \n",
       "..            ...           ...  \n",
       "603  9.959286e-01  1.068284e-04  \n",
       "604  9.996691e-01  6.232397e-10  \n",
       "605  9.999915e-01  1.182947e-13  \n",
       "606  1.480882e-02  3.335762e-01  \n",
       "607  9.994158e-01  6.525528e-08  \n",
       "\n",
       "[608 rows x 7 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.60537700e-02, 1.42993090e-01, 7.70953200e-01],\n",
       "       [3.95020370e-01, 3.67851530e-01, 2.37128170e-01],\n",
       "       [3.90420730e-01, 3.24556300e-01, 2.85022940e-01],\n",
       "       [2.92312440e-01, 4.14531230e-01, 2.93156300e-01],\n",
       "       [1.86510850e-01, 1.56528200e-01, 6.56960900e-01],\n",
       "       [1.59804400e-02, 2.01865700e-01, 7.82153840e-01],\n",
       "       [1.33841780e-01, 1.47130460e-01, 7.19027760e-01],\n",
       "       [7.79819800e-02, 8.24907660e-01, 9.71104300e-02],\n",
       "       [3.05521400e-03, 4.45698500e-01, 5.51246300e-01],\n",
       "       [4.39244960e-01, 4.20237930e-01, 1.40517100e-01],\n",
       "       [1.24578830e-01, 5.27910700e-01, 3.47510460e-01],\n",
       "       [1.68469100e-01, 2.80017050e-01, 5.51513900e-01],\n",
       "       [6.63150800e-01, 1.69104840e-01, 1.67744350e-01],\n",
       "       [5.31255600e-02, 1.10729300e-01, 8.36145160e-01],\n",
       "       [1.01157980e-02, 9.48802100e-01, 4.10821300e-02],\n",
       "       [6.06533350e-01, 1.99076850e-01, 1.94389780e-01],\n",
       "       [1.34231050e-01, 6.58513400e-01, 2.07255450e-01],\n",
       "       [2.54778560e-01, 3.91055880e-01, 3.54165460e-01],\n",
       "       [3.58126240e-02, 7.31973000e-01, 2.32214470e-01],\n",
       "       [4.89686730e-01, 1.77044440e-01, 3.33268820e-01],\n",
       "       [6.03100200e-01, 2.31995330e-01, 1.64904430e-01],\n",
       "       [6.18022700e-01, 2.45234370e-01, 1.36742920e-01],\n",
       "       [9.97174140e-01, 2.66260720e-03, 1.63204270e-04],\n",
       "       [4.74740480e-01, 1.59717110e-01, 3.65542440e-01],\n",
       "       [5.18931100e-01, 8.27915200e-02, 3.98277370e-01],\n",
       "       [6.05057360e-01, 2.50049440e-01, 1.44893200e-01],\n",
       "       [8.23673900e-01, 9.20603200e-02, 8.42658500e-02],\n",
       "       [1.06731810e-02, 6.15106300e-01, 3.74220500e-01],\n",
       "       [2.69029680e-02, 3.02899540e-01, 6.70197500e-01],\n",
       "       [4.90177570e-01, 4.56713440e-01, 5.31089570e-02],\n",
       "       [2.55446340e-01, 5.52700200e-01, 1.91853450e-01],\n",
       "       [1.75152170e-01, 2.06267150e-01, 6.18580640e-01],\n",
       "       [2.94053730e-01, 2.99322580e-01, 4.06623750e-01],\n",
       "       [1.57979340e-01, 1.69520810e-01, 6.72499900e-01],\n",
       "       [2.45818200e-01, 2.77700000e-01, 4.76481770e-01],\n",
       "       [6.40525300e-02, 1.94919360e-01, 7.41028100e-01],\n",
       "       [4.74508940e-01, 2.12103580e-01, 3.13387480e-01],\n",
       "       [2.54685160e-01, 2.68621470e-01, 4.76693330e-01],\n",
       "       [8.98510700e-02, 2.06258980e-01, 7.03889970e-01],\n",
       "       [5.77698200e-01, 1.16248920e-01, 3.06052980e-01],\n",
       "       [4.58481820e-01, 3.92359940e-01, 1.49158180e-01],\n",
       "       [1.83752760e-01, 4.73350600e-01, 3.42896670e-01],\n",
       "       [6.09276700e-01, 2.35958380e-01, 1.54765010e-01],\n",
       "       [3.06005150e-03, 1.36566350e-04, 9.96803400e-01],\n",
       "       [2.66797190e-02, 9.48736130e-01, 2.45841350e-02],\n",
       "       [6.12874000e-01, 2.06439300e-01, 1.80686680e-01],\n",
       "       [4.24557570e-01, 3.32531420e-01, 2.42911040e-01],\n",
       "       [4.62941380e-01, 3.16654260e-01, 2.20404340e-01],\n",
       "       [6.18022700e-01, 2.45234370e-01, 1.36742920e-01],\n",
       "       [3.93321960e-01, 5.05996760e-01, 1.00681290e-01],\n",
       "       [9.67317000e-02, 3.62543670e-01, 5.40724640e-01],\n",
       "       [5.97783800e-01, 3.70552840e-01, 3.16633400e-02],\n",
       "       [1.96104620e-01, 7.63865350e-01, 4.00299800e-02],\n",
       "       [6.31296500e-01, 2.06994650e-01, 1.61708850e-01],\n",
       "       [2.40165950e-02, 5.00991530e-02, 9.25884300e-01],\n",
       "       [3.22555870e-01, 5.74485700e-01, 1.02958456e-01],\n",
       "       [6.18022700e-01, 2.45234370e-01, 1.36742920e-01],\n",
       "       [2.00359780e-02, 1.34477200e-01, 8.45486800e-01],\n",
       "       [7.45904800e-01, 2.02036190e-01, 5.20590400e-02],\n",
       "       [3.48607330e-01, 3.12933360e-01, 3.38459250e-01],\n",
       "       [4.54198870e-01, 1.60587420e-01, 3.85213760e-01],\n",
       "       [4.58040570e-01, 3.61651300e-01, 1.80308150e-01],\n",
       "       [8.23402100e-03, 1.86746060e-02, 9.73091360e-01],\n",
       "       [1.87817840e-01, 1.25641970e-01, 6.86540200e-01],\n",
       "       [2.94053730e-01, 2.99322580e-01, 4.06623750e-01],\n",
       "       [2.57765680e-01, 4.13401870e-01, 3.28832450e-01],\n",
       "       [3.40718330e-01, 2.41916640e-01, 4.17365000e-01],\n",
       "       [4.05448000e-01, 4.50744100e-01, 1.43807920e-01],\n",
       "       [9.89071970e-01, 7.97923300e-03, 2.94886090e-03],\n",
       "       [9.91121400e-01, 5.86173100e-04, 8.29242600e-03],\n",
       "       [7.94369600e-04, 2.24425240e-04, 9.98981200e-01],\n",
       "       [8.81564400e-01, 1.10491090e-01, 7.94458100e-03],\n",
       "       [7.23630000e-01, 2.23998460e-01, 5.23714870e-02],\n",
       "       [6.22915100e-01, 2.21427050e-01, 1.55657840e-01],\n",
       "       [7.72591700e-02, 8.08463930e-01, 1.14276870e-01],\n",
       "       [3.39849080e-01, 2.30639250e-01, 4.29511640e-01]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob6 = df_proba6[df_proba6['phage']=='p0017kpresabsSTCC_qual'].iloc[:,-3:]\n",
    "y_prob6 = y_prob6.to_numpy()\n",
    "y_prob6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6597351061636776"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo6 = rocauc_ovo(y_sel_test, y_prob6, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6597351061636776"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr6 = rocauc_ovr(y_sel_test, y_prob6, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_sel_train, X_sel_test, y_sel_train, y_sel_test = train_test_split(X_sel, y_sel,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=789,\n",
    "                                                    stratify=y_sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat7 = pd.DataFrame(X_sel_test.iloc[:,-1])\n",
    "dat7['test'] = y_sel_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strain</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>NRS271</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>SR2852</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>CA39</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>NRS266</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>NY356</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>MN055</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>CFBRSa04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>SR1065</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>NRS224</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>NRS210</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       strain  test\n",
       "222    NRS271     1\n",
       "242    SR2852     2\n",
       "34       CA39     2\n",
       "221    NRS266     1\n",
       "230     NY356     2\n",
       "..        ...   ...\n",
       "105     MN055     2\n",
       "67   CFBRSa04     0\n",
       "235    SR1065     0\n",
       "190    NRS224     1\n",
       "178    NRS210     2\n",
       "\n",
       "[76 rows x 2 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sel_train = X_sel_train.drop(['strain'], axis=1)\n",
    "X_sel_test = X_sel_test.drop(['strain'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sel3 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_sel_train.shape[1],)),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sel3.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 177 samples, validate on 76 samples\n",
      "Epoch 1/100\n",
      "177/177 [==============================] - 0s 731us/step - loss: 5.9042 - accuracy: 0.4068 - val_loss: 2.5598 - val_accuracy: 0.4605\n",
      "Epoch 2/100\n",
      "177/177 [==============================] - 0s 110us/step - loss: 4.7050 - accuracy: 0.4633 - val_loss: 1.9082 - val_accuracy: 0.4079\n",
      "Epoch 3/100\n",
      "177/177 [==============================] - 0s 126us/step - loss: 3.5429 - accuracy: 0.4463 - val_loss: 1.5122 - val_accuracy: 0.3553\n",
      "Epoch 4/100\n",
      "177/177 [==============================] - 0s 179us/step - loss: 2.7681 - accuracy: 0.4237 - val_loss: 1.4511 - val_accuracy: 0.3816\n",
      "Epoch 5/100\n",
      "177/177 [==============================] - 0s 129us/step - loss: 2.1327 - accuracy: 0.4181 - val_loss: 1.2740 - val_accuracy: 0.4605\n",
      "Epoch 6/100\n",
      "177/177 [==============================] - 0s 183us/step - loss: 1.5930 - accuracy: 0.4463 - val_loss: 1.2814 - val_accuracy: 0.3684\n",
      "Epoch 7/100\n",
      "177/177 [==============================] - 0s 170us/step - loss: 1.1270 - accuracy: 0.4576 - val_loss: 1.6034 - val_accuracy: 0.3684\n",
      "Epoch 8/100\n",
      "177/177 [==============================] - 0s 134us/step - loss: 1.2212 - accuracy: 0.4520 - val_loss: 1.8909 - val_accuracy: 0.3289\n",
      "Epoch 9/100\n",
      "177/177 [==============================] - 0s 198us/step - loss: 1.2774 - accuracy: 0.4576 - val_loss: 1.8115 - val_accuracy: 0.3947\n",
      "Epoch 10/100\n",
      "177/177 [==============================] - 0s 162us/step - loss: 1.1450 - accuracy: 0.4915 - val_loss: 1.4623 - val_accuracy: 0.3684\n",
      "Epoch 11/100\n",
      "177/177 [==============================] - 0s 198us/step - loss: 1.0178 - accuracy: 0.5254 - val_loss: 1.2444 - val_accuracy: 0.4342\n",
      "Epoch 12/100\n",
      "177/177 [==============================] - 0s 110us/step - loss: 0.9349 - accuracy: 0.5311 - val_loss: 1.1163 - val_accuracy: 0.5263\n",
      "Epoch 13/100\n",
      "177/177 [==============================] - 0s 144us/step - loss: 0.9115 - accuracy: 0.5706 - val_loss: 1.1943 - val_accuracy: 0.5658\n",
      "Epoch 14/100\n",
      "177/177 [==============================] - 0s 185us/step - loss: 0.8779 - accuracy: 0.5819 - val_loss: 1.2746 - val_accuracy: 0.5395\n",
      "Epoch 15/100\n",
      "177/177 [==============================] - 0s 152us/step - loss: 0.8866 - accuracy: 0.6215 - val_loss: 1.3044 - val_accuracy: 0.5000\n",
      "Epoch 16/100\n",
      "177/177 [==============================] - 0s 83us/step - loss: 0.8660 - accuracy: 0.6610 - val_loss: 1.1720 - val_accuracy: 0.5132\n",
      "Epoch 17/100\n",
      "177/177 [==============================] - 0s 120us/step - loss: 0.8052 - accuracy: 0.6667 - val_loss: 1.0572 - val_accuracy: 0.4737\n",
      "Epoch 18/100\n",
      "177/177 [==============================] - 0s 153us/step - loss: 0.8196 - accuracy: 0.6497 - val_loss: 1.0583 - val_accuracy: 0.5132\n",
      "Epoch 19/100\n",
      "177/177 [==============================] - 0s 113us/step - loss: 0.7808 - accuracy: 0.6610 - val_loss: 1.1448 - val_accuracy: 0.4868\n",
      "Epoch 20/100\n",
      "177/177 [==============================] - 0s 181us/step - loss: 0.7710 - accuracy: 0.6723 - val_loss: 1.1799 - val_accuracy: 0.5263\n",
      "Epoch 21/100\n",
      "177/177 [==============================] - 0s 144us/step - loss: 0.7662 - accuracy: 0.6723 - val_loss: 1.1224 - val_accuracy: 0.5132\n",
      "Epoch 22/100\n",
      "177/177 [==============================] - 0s 161us/step - loss: 0.7471 - accuracy: 0.6893 - val_loss: 1.0863 - val_accuracy: 0.5000\n",
      "Epoch 23/100\n",
      "177/177 [==============================] - 0s 192us/step - loss: 0.7324 - accuracy: 0.7175 - val_loss: 1.0837 - val_accuracy: 0.4868\n",
      "Epoch 24/100\n",
      "177/177 [==============================] - 0s 136us/step - loss: 0.7261 - accuracy: 0.7232 - val_loss: 1.1166 - val_accuracy: 0.5000\n",
      "Epoch 25/100\n",
      "177/177 [==============================] - 0s 187us/step - loss: 0.7151 - accuracy: 0.7006 - val_loss: 1.1412 - val_accuracy: 0.5132\n",
      "Epoch 26/100\n",
      "177/177 [==============================] - 0s 100us/step - loss: 0.7085 - accuracy: 0.6893 - val_loss: 1.1295 - val_accuracy: 0.4737\n",
      "Epoch 27/100\n",
      "177/177 [==============================] - 0s 126us/step - loss: 0.6989 - accuracy: 0.7062 - val_loss: 1.1166 - val_accuracy: 0.5132\n",
      "Epoch 28/100\n",
      "177/177 [==============================] - 0s 128us/step - loss: 0.6896 - accuracy: 0.6949 - val_loss: 1.1279 - val_accuracy: 0.5132\n",
      "Epoch 29/100\n",
      "177/177 [==============================] - 0s 108us/step - loss: 0.6870 - accuracy: 0.7119 - val_loss: 1.1456 - val_accuracy: 0.5263\n",
      "Epoch 30/100\n",
      "177/177 [==============================] - 0s 117us/step - loss: 0.6770 - accuracy: 0.7062 - val_loss: 1.1877 - val_accuracy: 0.4605\n",
      "Epoch 31/100\n",
      "177/177 [==============================] - 0s 106us/step - loss: 0.6756 - accuracy: 0.7175 - val_loss: 1.1764 - val_accuracy: 0.4474\n",
      "Epoch 32/100\n",
      "177/177 [==============================] - 0s 110us/step - loss: 0.6640 - accuracy: 0.7288 - val_loss: 1.1394 - val_accuracy: 0.4868\n",
      "Epoch 33/100\n",
      "177/177 [==============================] - 0s 194us/step - loss: 0.6661 - accuracy: 0.7458 - val_loss: 1.1707 - val_accuracy: 0.4868\n",
      "Epoch 34/100\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.6503 - accuracy: 0.7288 - val_loss: 1.2315 - val_accuracy: 0.4474\n",
      "Epoch 35/100\n",
      "177/177 [==============================] - 0s 124us/step - loss: 0.6564 - accuracy: 0.7401 - val_loss: 1.2258 - val_accuracy: 0.4079\n",
      "Epoch 36/100\n",
      "177/177 [==============================] - 0s 99us/step - loss: 0.6413 - accuracy: 0.7345 - val_loss: 1.1761 - val_accuracy: 0.4474\n",
      "Epoch 37/100\n",
      "177/177 [==============================] - 0s 217us/step - loss: 0.6368 - accuracy: 0.7627 - val_loss: 1.1828 - val_accuracy: 0.4605\n",
      "Epoch 38/100\n",
      "177/177 [==============================] - 0s 112us/step - loss: 0.6362 - accuracy: 0.7458 - val_loss: 1.2408 - val_accuracy: 0.4474\n",
      "Epoch 39/100\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.6259 - accuracy: 0.7345 - val_loss: 1.2287 - val_accuracy: 0.4474\n",
      "Epoch 40/100\n",
      "177/177 [==============================] - 0s 91us/step - loss: 0.6218 - accuracy: 0.7345 - val_loss: 1.1905 - val_accuracy: 0.4079\n",
      "Epoch 41/100\n",
      "177/177 [==============================] - 0s 95us/step - loss: 0.6232 - accuracy: 0.7458 - val_loss: 1.1945 - val_accuracy: 0.4342\n",
      "Epoch 42/100\n",
      "177/177 [==============================] - 0s 103us/step - loss: 0.6096 - accuracy: 0.7514 - val_loss: 1.2996 - val_accuracy: 0.4474\n",
      "Epoch 43/100\n",
      "177/177 [==============================] - 0s 127us/step - loss: 0.6141 - accuracy: 0.7401 - val_loss: 1.2790 - val_accuracy: 0.4342\n",
      "Epoch 44/100\n",
      "177/177 [==============================] - 0s 174us/step - loss: 0.6047 - accuracy: 0.7458 - val_loss: 1.2211 - val_accuracy: 0.4079\n",
      "Epoch 45/100\n",
      "177/177 [==============================] - 0s 103us/step - loss: 0.5973 - accuracy: 0.7627 - val_loss: 1.2303 - val_accuracy: 0.4211\n",
      "Epoch 46/100\n",
      "177/177 [==============================] - 0s 106us/step - loss: 0.5901 - accuracy: 0.7684 - val_loss: 1.2432 - val_accuracy: 0.4342\n",
      "Epoch 47/100\n",
      "177/177 [==============================] - 0s 131us/step - loss: 0.5857 - accuracy: 0.7458 - val_loss: 1.2704 - val_accuracy: 0.4474\n",
      "Epoch 48/100\n",
      "177/177 [==============================] - 0s 183us/step - loss: 0.5819 - accuracy: 0.7571 - val_loss: 1.2541 - val_accuracy: 0.4605\n",
      "Epoch 49/100\n",
      "177/177 [==============================] - 0s 117us/step - loss: 0.5803 - accuracy: 0.7627 - val_loss: 1.2552 - val_accuracy: 0.4211\n",
      "Epoch 50/100\n",
      "177/177 [==============================] - 0s 184us/step - loss: 0.5729 - accuracy: 0.7740 - val_loss: 1.2578 - val_accuracy: 0.4474\n",
      "Epoch 51/100\n",
      "177/177 [==============================] - 0s 115us/step - loss: 0.5675 - accuracy: 0.7797 - val_loss: 1.2921 - val_accuracy: 0.4342\n",
      "Epoch 52/100\n",
      "177/177 [==============================] - 0s 105us/step - loss: 0.5700 - accuracy: 0.7740 - val_loss: 1.3046 - val_accuracy: 0.4342\n",
      "Epoch 53/100\n",
      "177/177 [==============================] - 0s 93us/step - loss: 0.5633 - accuracy: 0.7684 - val_loss: 1.2760 - val_accuracy: 0.4342\n",
      "Epoch 54/100\n",
      "177/177 [==============================] - 0s 164us/step - loss: 0.5592 - accuracy: 0.7740 - val_loss: 1.2453 - val_accuracy: 0.3947\n",
      "Epoch 55/100\n",
      "177/177 [==============================] - 0s 166us/step - loss: 0.5567 - accuracy: 0.7853 - val_loss: 1.2947 - val_accuracy: 0.4342\n",
      "Epoch 56/100\n",
      "177/177 [==============================] - 0s 115us/step - loss: 0.5519 - accuracy: 0.7740 - val_loss: 1.3097 - val_accuracy: 0.4079\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "177/177 [==============================] - 0s 136us/step - loss: 0.5476 - accuracy: 0.7797 - val_loss: 1.2773 - val_accuracy: 0.4474\n",
      "Epoch 58/100\n",
      "177/177 [==============================] - 0s 113us/step - loss: 0.5497 - accuracy: 0.7910 - val_loss: 1.2947 - val_accuracy: 0.4079\n",
      "Epoch 59/100\n",
      "177/177 [==============================] - 0s 140us/step - loss: 0.5395 - accuracy: 0.7797 - val_loss: 1.3499 - val_accuracy: 0.3947\n",
      "Epoch 60/100\n",
      "177/177 [==============================] - 0s 151us/step - loss: 0.5361 - accuracy: 0.7684 - val_loss: 1.3410 - val_accuracy: 0.3947\n",
      "Epoch 61/100\n",
      "177/177 [==============================] - 0s 99us/step - loss: 0.5327 - accuracy: 0.7910 - val_loss: 1.2984 - val_accuracy: 0.4211\n",
      "Epoch 62/100\n",
      "177/177 [==============================] - 0s 137us/step - loss: 0.5377 - accuracy: 0.7910 - val_loss: 1.3204 - val_accuracy: 0.3947\n",
      "Epoch 63/100\n",
      "177/177 [==============================] - 0s 152us/step - loss: 0.5270 - accuracy: 0.7966 - val_loss: 1.3381 - val_accuracy: 0.4079\n",
      "Epoch 64/100\n",
      "177/177 [==============================] - 0s 125us/step - loss: 0.5212 - accuracy: 0.8136 - val_loss: 1.3345 - val_accuracy: 0.4079\n",
      "Epoch 65/100\n",
      "177/177 [==============================] - 0s 78us/step - loss: 0.5191 - accuracy: 0.8136 - val_loss: 1.3727 - val_accuracy: 0.4079\n",
      "Epoch 66/100\n",
      "177/177 [==============================] - 0s 89us/step - loss: 0.5157 - accuracy: 0.7966 - val_loss: 1.4068 - val_accuracy: 0.4079\n",
      "Epoch 67/100\n",
      "177/177 [==============================] - 0s 104us/step - loss: 0.5128 - accuracy: 0.8079 - val_loss: 1.3519 - val_accuracy: 0.4079\n",
      "Epoch 68/100\n",
      "177/177 [==============================] - 0s 79us/step - loss: 0.5105 - accuracy: 0.7966 - val_loss: 1.3188 - val_accuracy: 0.4079\n",
      "Epoch 69/100\n",
      "177/177 [==============================] - 0s 76us/step - loss: 0.5083 - accuracy: 0.8136 - val_loss: 1.3765 - val_accuracy: 0.4079\n",
      "Epoch 70/100\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.5063 - accuracy: 0.8023 - val_loss: 1.4300 - val_accuracy: 0.4211\n",
      "Epoch 71/100\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.5013 - accuracy: 0.8023 - val_loss: 1.3788 - val_accuracy: 0.4079\n",
      "Epoch 72/100\n",
      "177/177 [==============================] - 0s 108us/step - loss: 0.4954 - accuracy: 0.8079 - val_loss: 1.3583 - val_accuracy: 0.4211\n",
      "Epoch 73/100\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.4958 - accuracy: 0.8136 - val_loss: 1.3708 - val_accuracy: 0.4211\n",
      "Epoch 74/100\n",
      "177/177 [==============================] - 0s 78us/step - loss: 0.4912 - accuracy: 0.7966 - val_loss: 1.4169 - val_accuracy: 0.4211\n",
      "Epoch 75/100\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.4913 - accuracy: 0.8136 - val_loss: 1.4132 - val_accuracy: 0.4079\n",
      "Epoch 76/100\n",
      "177/177 [==============================] - 0s 81us/step - loss: 0.4838 - accuracy: 0.8249 - val_loss: 1.3810 - val_accuracy: 0.4211\n",
      "Epoch 77/100\n",
      "177/177 [==============================] - 0s 117us/step - loss: 0.4887 - accuracy: 0.8192 - val_loss: 1.3964 - val_accuracy: 0.4079\n",
      "Epoch 78/100\n",
      "177/177 [==============================] - 0s 93us/step - loss: 0.4775 - accuracy: 0.8023 - val_loss: 1.4742 - val_accuracy: 0.3816\n",
      "Epoch 79/100\n",
      "177/177 [==============================] - 0s 82us/step - loss: 0.4866 - accuracy: 0.7910 - val_loss: 1.4603 - val_accuracy: 0.3684\n",
      "Epoch 80/100\n",
      "177/177 [==============================] - 0s 79us/step - loss: 0.4807 - accuracy: 0.8079 - val_loss: 1.3967 - val_accuracy: 0.3947\n",
      "Epoch 81/100\n",
      "177/177 [==============================] - 0s 168us/step - loss: 0.4705 - accuracy: 0.8192 - val_loss: 1.4102 - val_accuracy: 0.4079\n",
      "Epoch 82/100\n",
      "177/177 [==============================] - 0s 125us/step - loss: 0.4681 - accuracy: 0.8192 - val_loss: 1.4384 - val_accuracy: 0.3816\n",
      "Epoch 83/100\n",
      "177/177 [==============================] - 0s 208us/step - loss: 0.4673 - accuracy: 0.8418 - val_loss: 1.4327 - val_accuracy: 0.3947\n",
      "Epoch 84/100\n",
      "177/177 [==============================] - 0s 120us/step - loss: 0.4614 - accuracy: 0.8418 - val_loss: 1.4210 - val_accuracy: 0.4079\n",
      "Epoch 85/100\n",
      "177/177 [==============================] - 0s 94us/step - loss: 0.4604 - accuracy: 0.8475 - val_loss: 1.4295 - val_accuracy: 0.4079\n",
      "Epoch 86/100\n",
      "177/177 [==============================] - 0s 109us/step - loss: 0.4555 - accuracy: 0.8362 - val_loss: 1.4185 - val_accuracy: 0.4211\n",
      "Epoch 87/100\n",
      "177/177 [==============================] - 0s 214us/step - loss: 0.4532 - accuracy: 0.8362 - val_loss: 1.4396 - val_accuracy: 0.4079\n",
      "Epoch 88/100\n",
      "177/177 [==============================] - 0s 143us/step - loss: 0.4504 - accuracy: 0.8305 - val_loss: 1.4703 - val_accuracy: 0.3553\n",
      "Epoch 89/100\n",
      "177/177 [==============================] - 0s 162us/step - loss: 0.4517 - accuracy: 0.8362 - val_loss: 1.4861 - val_accuracy: 0.3684\n",
      "Epoch 90/100\n",
      "177/177 [==============================] - 0s 89us/step - loss: 0.4469 - accuracy: 0.8362 - val_loss: 1.4558 - val_accuracy: 0.3553\n",
      "Epoch 91/100\n",
      "177/177 [==============================] - 0s 129us/step - loss: 0.4466 - accuracy: 0.8475 - val_loss: 1.4817 - val_accuracy: 0.3421\n",
      "Epoch 92/100\n",
      "177/177 [==============================] - 0s 200us/step - loss: 0.4443 - accuracy: 0.8362 - val_loss: 1.4950 - val_accuracy: 0.3684\n",
      "Epoch 93/100\n",
      "177/177 [==============================] - 0s 133us/step - loss: 0.4407 - accuracy: 0.8362 - val_loss: 1.4518 - val_accuracy: 0.3816\n",
      "Epoch 94/100\n",
      "177/177 [==============================] - 0s 161us/step - loss: 0.4383 - accuracy: 0.8418 - val_loss: 1.4586 - val_accuracy: 0.3421\n",
      "Epoch 95/100\n",
      "177/177 [==============================] - 0s 190us/step - loss: 0.4355 - accuracy: 0.8644 - val_loss: 1.4942 - val_accuracy: 0.3421\n",
      "Epoch 96/100\n",
      "177/177 [==============================] - 0s 111us/step - loss: 0.4326 - accuracy: 0.8531 - val_loss: 1.4805 - val_accuracy: 0.3421\n",
      "Epoch 97/100\n",
      "177/177 [==============================] - 0s 187us/step - loss: 0.4266 - accuracy: 0.8588 - val_loss: 1.4788 - val_accuracy: 0.3553\n",
      "Epoch 98/100\n",
      "177/177 [==============================] - 0s 117us/step - loss: 0.4279 - accuracy: 0.8475 - val_loss: 1.4758 - val_accuracy: 0.3684\n",
      "Epoch 99/100\n",
      "177/177 [==============================] - 0s 186us/step - loss: 0.4264 - accuracy: 0.8531 - val_loss: 1.5023 - val_accuracy: 0.3553\n",
      "Epoch 100/100\n",
      "177/177 [==============================] - 0s 157us/step - loss: 0.4204 - accuracy: 0.8644 - val_loss: 1.4997 - val_accuracy: 0.3684\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a3b5f2358>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sel3.fit(X_sel_train, y_sel_train,\n",
    "          batch_size=64, epochs=100,\n",
    "          validation_data=(X_sel_test, y_sel_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 0s 120us/step\n",
      "test accuracy: 42.11%\n"
     ]
    }
   ],
   "source": [
    "acc_test_sel3 = model_sel3.evaluate(X_sel_test, y_sel_test)[1]\n",
    "print('test accuracy: %.2f%%' % (acc_test_sel3*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 0, 2, 1, 0, 1, 2, 2, 1, 0, 1, 2, 0, 0, 0, 2, 1, 1, 2, 2, 0,\n",
       "       0, 0, 1, 2, 0, 0, 1, 0, 1, 0, 0, 2, 1, 2, 2, 2, 0, 2, 2, 2, 2, 0,\n",
       "       2, 1, 0, 1, 0, 2, 1, 2, 2, 0, 1, 0, 1, 1, 2, 2, 0, 0, 0, 1, 1, 2,\n",
       "       2, 0, 1, 1, 0, 2, 1, 0, 0, 1])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred7 = model_sel3.predict_classes(X_sel_test)\n",
    "pred7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strain</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>NRS271</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>SR2852</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>CA39</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>NRS266</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>NY356</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>MN055</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>CFBRSa04</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>SR1065</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>NRS224</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>NRS210</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       strain  test  pred\n",
       "222    NRS271     1     1\n",
       "242    SR2852     2     2\n",
       "34       CA39     2     0\n",
       "221    NRS266     1     2\n",
       "230     NY356     2     1\n",
       "..        ...   ...   ...\n",
       "105     MN055     2     2\n",
       "67   CFBRSa04     0     1\n",
       "235    SR1065     0     0\n",
       "190    NRS224     1     0\n",
       "178    NRS210     2     1\n",
       "\n",
       "[76 rows x 3 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat7['pred'] = pred7\n",
    "dat7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba7 = model_sel3.predict_proba(X_sel_test)\n",
    "dat_proba7 = pd.DataFrame(proba7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.025803</td>\n",
       "      <td>0.933269</td>\n",
       "      <td>0.040928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.051309</td>\n",
       "      <td>0.398973</td>\n",
       "      <td>0.549717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.392121</td>\n",
       "      <td>0.360336</td>\n",
       "      <td>0.247543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.221286</td>\n",
       "      <td>0.216210</td>\n",
       "      <td>0.562504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.460525</td>\n",
       "      <td>0.474938</td>\n",
       "      <td>0.064536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.249112</td>\n",
       "      <td>0.327617</td>\n",
       "      <td>0.423271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.416233</td>\n",
       "      <td>0.551626</td>\n",
       "      <td>0.032140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.907585</td>\n",
       "      <td>0.000580</td>\n",
       "      <td>0.091835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.641654</td>\n",
       "      <td>0.018258</td>\n",
       "      <td>0.340088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.194852</td>\n",
       "      <td>0.533291</td>\n",
       "      <td>0.271857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2\n",
       "0   0.025803  0.933269  0.040928\n",
       "1   0.051309  0.398973  0.549717\n",
       "2   0.392121  0.360336  0.247543\n",
       "3   0.221286  0.216210  0.562504\n",
       "4   0.460525  0.474938  0.064536\n",
       "..       ...       ...       ...\n",
       "71  0.249112  0.327617  0.423271\n",
       "72  0.416233  0.551626  0.032140\n",
       "73  0.907585  0.000580  0.091835\n",
       "74  0.641654  0.018258  0.340088\n",
       "75  0.194852  0.533291  0.271857\n",
       "\n",
       "[76 rows x 3 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba7.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba7.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat7.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/7p17ST.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 177 samples, validate on 76 samples\n",
      "Epoch 1/100\n",
      "177/177 [==============================] - 0s 97us/step - loss: 0.4401 - accuracy: 0.8418 - val_loss: 1.4228 - val_accuracy: 0.4079\n",
      "Epoch 2/100\n",
      "177/177 [==============================] - 0s 85us/step - loss: 0.4439 - accuracy: 0.8362 - val_loss: 1.4283 - val_accuracy: 0.3947\n",
      "Epoch 3/100\n",
      "177/177 [==============================] - 0s 107us/step - loss: 0.4330 - accuracy: 0.8418 - val_loss: 1.4474 - val_accuracy: 0.3947\n",
      "Epoch 4/100\n",
      "177/177 [==============================] - 0s 124us/step - loss: 0.4353 - accuracy: 0.8418 - val_loss: 1.4709 - val_accuracy: 0.3947\n",
      "Epoch 5/100\n",
      "177/177 [==============================] - 0s 157us/step - loss: 0.4292 - accuracy: 0.8305 - val_loss: 1.4485 - val_accuracy: 0.4211\n",
      "Epoch 6/100\n",
      "177/177 [==============================] - 0s 94us/step - loss: 0.4320 - accuracy: 0.8418 - val_loss: 1.4680 - val_accuracy: 0.4211\n",
      "Epoch 7/100\n",
      "177/177 [==============================] - 0s 107us/step - loss: 0.4312 - accuracy: 0.8418 - val_loss: 1.4523 - val_accuracy: 0.4079\n",
      "Epoch 8/100\n",
      "177/177 [==============================] - 0s 104us/step - loss: 0.4303 - accuracy: 0.8418 - val_loss: 1.4362 - val_accuracy: 0.3947\n",
      "Epoch 9/100\n",
      "177/177 [==============================] - 0s 94us/step - loss: 0.4244 - accuracy: 0.8475 - val_loss: 1.4706 - val_accuracy: 0.3816\n",
      "Epoch 10/100\n",
      "177/177 [==============================] - 0s 111us/step - loss: 0.4217 - accuracy: 0.8362 - val_loss: 1.5231 - val_accuracy: 0.4211\n",
      "Epoch 11/100\n",
      "177/177 [==============================] - 0s 150us/step - loss: 0.4186 - accuracy: 0.8362 - val_loss: 1.4999 - val_accuracy: 0.4342\n",
      "Epoch 12/100\n",
      "177/177 [==============================] - 0s 100us/step - loss: 0.4206 - accuracy: 0.8362 - val_loss: 1.4678 - val_accuracy: 0.4079\n",
      "Epoch 13/100\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.4199 - accuracy: 0.8249 - val_loss: 1.5629 - val_accuracy: 0.3947\n",
      "Epoch 14/100\n",
      "177/177 [==============================] - 0s 131us/step - loss: 0.4186 - accuracy: 0.8418 - val_loss: 1.4527 - val_accuracy: 0.3816\n",
      "Epoch 15/100\n",
      "177/177 [==============================] - 0s 115us/step - loss: 0.4104 - accuracy: 0.8475 - val_loss: 1.4778 - val_accuracy: 0.3684\n",
      "Epoch 16/100\n",
      "177/177 [==============================] - 0s 105us/step - loss: 0.4077 - accuracy: 0.8418 - val_loss: 1.4995 - val_accuracy: 0.4211\n",
      "Epoch 17/100\n",
      "177/177 [==============================] - 0s 107us/step - loss: 0.4057 - accuracy: 0.8362 - val_loss: 1.5123 - val_accuracy: 0.4342\n",
      "Epoch 18/100\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.4026 - accuracy: 0.8305 - val_loss: 1.4700 - val_accuracy: 0.4079\n",
      "Epoch 19/100\n",
      "177/177 [==============================] - 0s 115us/step - loss: 0.4064 - accuracy: 0.8305 - val_loss: 1.4677 - val_accuracy: 0.3947\n",
      "Epoch 20/100\n",
      "177/177 [==============================] - 0s 125us/step - loss: 0.4063 - accuracy: 0.8418 - val_loss: 1.5745 - val_accuracy: 0.3947\n",
      "Epoch 21/100\n",
      "177/177 [==============================] - 0s 113us/step - loss: 0.4040 - accuracy: 0.8305 - val_loss: 1.5460 - val_accuracy: 0.3816\n",
      "Epoch 22/100\n",
      "177/177 [==============================] - 0s 107us/step - loss: 0.3975 - accuracy: 0.8418 - val_loss: 1.4597 - val_accuracy: 0.4079\n",
      "Epoch 23/100\n",
      "177/177 [==============================] - 0s 101us/step - loss: 0.4003 - accuracy: 0.8531 - val_loss: 1.5307 - val_accuracy: 0.4079\n",
      "Epoch 24/100\n",
      "177/177 [==============================] - 0s 125us/step - loss: 0.3909 - accuracy: 0.8418 - val_loss: 1.5726 - val_accuracy: 0.3947\n",
      "Epoch 25/100\n",
      "177/177 [==============================] - 0s 94us/step - loss: 0.3916 - accuracy: 0.8418 - val_loss: 1.5371 - val_accuracy: 0.4211\n",
      "Epoch 26/100\n",
      "177/177 [==============================] - 0s 100us/step - loss: 0.3897 - accuracy: 0.8531 - val_loss: 1.4657 - val_accuracy: 0.4211\n",
      "Epoch 27/100\n",
      "177/177 [==============================] - 0s 91us/step - loss: 0.3917 - accuracy: 0.8588 - val_loss: 1.5261 - val_accuracy: 0.3684\n",
      "Epoch 28/100\n",
      "177/177 [==============================] - 0s 104us/step - loss: 0.3869 - accuracy: 0.8644 - val_loss: 1.5937 - val_accuracy: 0.3947\n",
      "Epoch 29/100\n",
      "177/177 [==============================] - 0s 113us/step - loss: 0.3855 - accuracy: 0.8531 - val_loss: 1.5642 - val_accuracy: 0.4079\n",
      "Epoch 30/100\n",
      "177/177 [==============================] - 0s 96us/step - loss: 0.3812 - accuracy: 0.8531 - val_loss: 1.5032 - val_accuracy: 0.3816\n",
      "Epoch 31/100\n",
      "177/177 [==============================] - 0s 100us/step - loss: 0.3800 - accuracy: 0.8531 - val_loss: 1.5358 - val_accuracy: 0.4079\n",
      "Epoch 32/100\n",
      "177/177 [==============================] - 0s 95us/step - loss: 0.3779 - accuracy: 0.8588 - val_loss: 1.5755 - val_accuracy: 0.4211\n",
      "Epoch 33/100\n",
      "177/177 [==============================] - 0s 96us/step - loss: 0.3754 - accuracy: 0.8588 - val_loss: 1.5589 - val_accuracy: 0.3947\n",
      "Epoch 34/100\n",
      "177/177 [==============================] - 0s 110us/step - loss: 0.3717 - accuracy: 0.8644 - val_loss: 1.5494 - val_accuracy: 0.3816\n",
      "Epoch 35/100\n",
      "177/177 [==============================] - 0s 109us/step - loss: 0.3710 - accuracy: 0.8531 - val_loss: 1.5278 - val_accuracy: 0.3947\n",
      "Epoch 36/100\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.3704 - accuracy: 0.8588 - val_loss: 1.5637 - val_accuracy: 0.3947\n",
      "Epoch 37/100\n",
      "177/177 [==============================] - 0s 87us/step - loss: 0.3710 - accuracy: 0.8588 - val_loss: 1.5962 - val_accuracy: 0.4079\n",
      "Epoch 38/100\n",
      "177/177 [==============================] - 0s 99us/step - loss: 0.3679 - accuracy: 0.8475 - val_loss: 1.5902 - val_accuracy: 0.3684\n",
      "Epoch 39/100\n",
      "177/177 [==============================] - 0s 87us/step - loss: 0.3663 - accuracy: 0.8701 - val_loss: 1.5482 - val_accuracy: 0.3816\n",
      "Epoch 40/100\n",
      "177/177 [==============================] - 0s 96us/step - loss: 0.3636 - accuracy: 0.8475 - val_loss: 1.5777 - val_accuracy: 0.3684\n",
      "Epoch 41/100\n",
      "177/177 [==============================] - 0s 87us/step - loss: 0.3646 - accuracy: 0.8644 - val_loss: 1.6457 - val_accuracy: 0.4079\n",
      "Epoch 42/100\n",
      "177/177 [==============================] - 0s 84us/step - loss: 0.3621 - accuracy: 0.8644 - val_loss: 1.6491 - val_accuracy: 0.3947\n",
      "Epoch 43/100\n",
      "177/177 [==============================] - 0s 87us/step - loss: 0.3668 - accuracy: 0.8588 - val_loss: 1.5570 - val_accuracy: 0.3816\n",
      "Epoch 44/100\n",
      "177/177 [==============================] - 0s 89us/step - loss: 0.3608 - accuracy: 0.8701 - val_loss: 1.5805 - val_accuracy: 0.3947\n",
      "Epoch 45/100\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.3632 - accuracy: 0.8757 - val_loss: 1.6793 - val_accuracy: 0.4079\n",
      "Epoch 46/100\n",
      "177/177 [==============================] - 0s 158us/step - loss: 0.3651 - accuracy: 0.8588 - val_loss: 1.6777 - val_accuracy: 0.3816\n",
      "Epoch 47/100\n",
      "177/177 [==============================] - 0s 85us/step - loss: 0.3538 - accuracy: 0.8588 - val_loss: 1.5678 - val_accuracy: 0.4079\n",
      "Epoch 48/100\n",
      "177/177 [==============================] - 0s 114us/step - loss: 0.3510 - accuracy: 0.8757 - val_loss: 1.5819 - val_accuracy: 0.3947\n",
      "Epoch 49/100\n",
      "177/177 [==============================] - 0s 86us/step - loss: 0.3504 - accuracy: 0.8757 - val_loss: 1.6534 - val_accuracy: 0.3684\n",
      "Epoch 50/100\n",
      "177/177 [==============================] - 0s 96us/step - loss: 0.3509 - accuracy: 0.8644 - val_loss: 1.6659 - val_accuracy: 0.3816\n",
      "Epoch 51/100\n",
      "177/177 [==============================] - 0s 77us/step - loss: 0.3450 - accuracy: 0.8644 - val_loss: 1.6183 - val_accuracy: 0.3816\n",
      "Epoch 52/100\n",
      "177/177 [==============================] - 0s 93us/step - loss: 0.3450 - accuracy: 0.8644 - val_loss: 1.6064 - val_accuracy: 0.3816\n",
      "Epoch 53/100\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.3466 - accuracy: 0.8757 - val_loss: 1.6346 - val_accuracy: 0.3947\n",
      "Epoch 54/100\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.3405 - accuracy: 0.8814 - val_loss: 1.6796 - val_accuracy: 0.3553\n",
      "Epoch 55/100\n",
      "177/177 [==============================] - 0s 103us/step - loss: 0.3446 - accuracy: 0.8814 - val_loss: 1.6683 - val_accuracy: 0.3816\n",
      "Epoch 56/100\n",
      "177/177 [==============================] - 0s 96us/step - loss: 0.3367 - accuracy: 0.8814 - val_loss: 1.6078 - val_accuracy: 0.3947\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177/177 [==============================] - 0s 83us/step - loss: 0.3399 - accuracy: 0.8757 - val_loss: 1.6177 - val_accuracy: 0.3816\n",
      "Epoch 58/100\n",
      "177/177 [==============================] - 0s 92us/step - loss: 0.3386 - accuracy: 0.8701 - val_loss: 1.6827 - val_accuracy: 0.3684\n",
      "Epoch 59/100\n",
      "177/177 [==============================] - 0s 81us/step - loss: 0.3342 - accuracy: 0.8927 - val_loss: 1.6837 - val_accuracy: 0.3816\n",
      "Epoch 60/100\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.3398 - accuracy: 0.8814 - val_loss: 1.6628 - val_accuracy: 0.3684\n",
      "Epoch 61/100\n",
      "177/177 [==============================] - 0s 91us/step - loss: 0.3329 - accuracy: 0.8814 - val_loss: 1.7360 - val_accuracy: 0.3553\n",
      "Epoch 62/100\n",
      "177/177 [==============================] - 0s 91us/step - loss: 0.3413 - accuracy: 0.8870 - val_loss: 1.7151 - val_accuracy: 0.3684\n",
      "Epoch 63/100\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.3393 - accuracy: 0.8701 - val_loss: 1.6624 - val_accuracy: 0.3816\n",
      "Epoch 64/100\n",
      "177/177 [==============================] - 0s 84us/step - loss: 0.3300 - accuracy: 0.8870 - val_loss: 1.7593 - val_accuracy: 0.3947\n",
      "Epoch 65/100\n",
      "177/177 [==============================] - 0s 96us/step - loss: 0.3354 - accuracy: 0.8701 - val_loss: 1.7250 - val_accuracy: 0.3816\n",
      "Epoch 66/100\n",
      "177/177 [==============================] - 0s 96us/step - loss: 0.3261 - accuracy: 0.8927 - val_loss: 1.5965 - val_accuracy: 0.4211\n",
      "Epoch 67/100\n",
      "177/177 [==============================] - 0s 102us/step - loss: 0.3500 - accuracy: 0.8757 - val_loss: 1.6909 - val_accuracy: 0.3816\n",
      "Epoch 68/100\n",
      "177/177 [==============================] - 0s 107us/step - loss: 0.3364 - accuracy: 0.8644 - val_loss: 1.9701 - val_accuracy: 0.3553\n",
      "Epoch 69/100\n",
      "177/177 [==============================] - 0s 103us/step - loss: 0.3703 - accuracy: 0.8644 - val_loss: 1.7985 - val_accuracy: 0.3684\n",
      "Epoch 70/100\n",
      "177/177 [==============================] - 0s 99us/step - loss: 0.3279 - accuracy: 0.8870 - val_loss: 1.5768 - val_accuracy: 0.3947\n",
      "Epoch 71/100\n",
      "177/177 [==============================] - 0s 108us/step - loss: 0.3817 - accuracy: 0.8701 - val_loss: 1.6917 - val_accuracy: 0.3816\n",
      "Epoch 72/100\n",
      "177/177 [==============================] - 0s 84us/step - loss: 0.3566 - accuracy: 0.8814 - val_loss: 2.1953 - val_accuracy: 0.3947\n",
      "Epoch 73/100\n",
      "177/177 [==============================] - 0s 89us/step - loss: 0.4328 - accuracy: 0.8588 - val_loss: 1.9971 - val_accuracy: 0.3553\n",
      "Epoch 74/100\n",
      "177/177 [==============================] - 0s 93us/step - loss: 0.3466 - accuracy: 0.8870 - val_loss: 1.6679 - val_accuracy: 0.3816\n",
      "Epoch 75/100\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.3713 - accuracy: 0.8814 - val_loss: 1.6760 - val_accuracy: 0.3947\n",
      "Epoch 76/100\n",
      "177/177 [==============================] - 0s 81us/step - loss: 0.3103 - accuracy: 0.8814 - val_loss: 1.8904 - val_accuracy: 0.3553\n",
      "Epoch 77/100\n",
      "177/177 [==============================] - 0s 92us/step - loss: 0.3289 - accuracy: 0.8701 - val_loss: 1.9128 - val_accuracy: 0.3684\n",
      "Epoch 78/100\n",
      "177/177 [==============================] - 0s 109us/step - loss: 0.3247 - accuracy: 0.8870 - val_loss: 1.7344 - val_accuracy: 0.3947\n",
      "Epoch 79/100\n",
      "177/177 [==============================] - 0s 92us/step - loss: 0.3128 - accuracy: 0.8870 - val_loss: 1.6603 - val_accuracy: 0.3947\n",
      "Epoch 80/100\n",
      "177/177 [==============================] - 0s 101us/step - loss: 0.3331 - accuracy: 0.8814 - val_loss: 1.7665 - val_accuracy: 0.3684\n",
      "Epoch 81/100\n",
      "177/177 [==============================] - 0s 83us/step - loss: 0.3180 - accuracy: 0.8814 - val_loss: 2.1556 - val_accuracy: 0.3553\n",
      "Epoch 82/100\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.3863 - accuracy: 0.8531 - val_loss: 1.9642 - val_accuracy: 0.3421\n",
      "Epoch 83/100\n",
      "177/177 [==============================] - 0s 93us/step - loss: 0.3180 - accuracy: 0.8870 - val_loss: 1.6585 - val_accuracy: 0.3816\n",
      "Epoch 84/100\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.3540 - accuracy: 0.8870 - val_loss: 1.6817 - val_accuracy: 0.3816\n",
      "Epoch 85/100\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.3094 - accuracy: 0.8814 - val_loss: 1.9845 - val_accuracy: 0.3553\n",
      "Epoch 86/100\n",
      "177/177 [==============================] - 0s 89us/step - loss: 0.3434 - accuracy: 0.8757 - val_loss: 1.9814 - val_accuracy: 0.3553\n",
      "Epoch 87/100\n",
      "177/177 [==============================] - 0s 107us/step - loss: 0.3083 - accuracy: 0.8870 - val_loss: 1.7053 - val_accuracy: 0.4079\n",
      "Epoch 88/100\n",
      "177/177 [==============================] - 0s 110us/step - loss: 0.3113 - accuracy: 0.8757 - val_loss: 1.7106 - val_accuracy: 0.4079\n",
      "Epoch 89/100\n",
      "177/177 [==============================] - 0s 118us/step - loss: 0.3047 - accuracy: 0.8983 - val_loss: 1.8201 - val_accuracy: 0.3816\n",
      "Epoch 90/100\n",
      "177/177 [==============================] - 0s 86us/step - loss: 0.2986 - accuracy: 0.9096 - val_loss: 1.9328 - val_accuracy: 0.3947\n",
      "Epoch 91/100\n",
      "177/177 [==============================] - 0s 87us/step - loss: 0.3061 - accuracy: 0.8870 - val_loss: 1.8797 - val_accuracy: 0.3816\n",
      "Epoch 92/100\n",
      "177/177 [==============================] - 0s 70us/step - loss: 0.2946 - accuracy: 0.9040 - val_loss: 1.7705 - val_accuracy: 0.3947\n",
      "Epoch 93/100\n",
      "177/177 [==============================] - 0s 119us/step - loss: 0.2937 - accuracy: 0.9096 - val_loss: 1.7295 - val_accuracy: 0.3684\n",
      "Epoch 94/100\n",
      "177/177 [==============================] - 0s 346us/step - loss: 0.2945 - accuracy: 0.8870 - val_loss: 1.8164 - val_accuracy: 0.3684\n",
      "Epoch 95/100\n",
      "177/177 [==============================] - 0s 424us/step - loss: 0.2918 - accuracy: 0.8870 - val_loss: 1.8627 - val_accuracy: 0.3816\n",
      "Epoch 96/100\n",
      "177/177 [==============================] - 0s 127us/step - loss: 0.2939 - accuracy: 0.8983 - val_loss: 1.8475 - val_accuracy: 0.3816\n",
      "Epoch 97/100\n",
      "177/177 [==============================] - 0s 85us/step - loss: 0.2888 - accuracy: 0.8983 - val_loss: 1.7943 - val_accuracy: 0.3553\n",
      "Epoch 98/100\n",
      "177/177 [==============================] - 0s 106us/step - loss: 0.2872 - accuracy: 0.8983 - val_loss: 1.7838 - val_accuracy: 0.3816\n",
      "Epoch 99/100\n",
      "177/177 [==============================] - 0s 168us/step - loss: 0.2850 - accuracy: 0.9040 - val_loss: 1.8006 - val_accuracy: 0.3684\n",
      "Epoch 100/100\n",
      "177/177 [==============================] - 0s 140us/step - loss: 0.2857 - accuracy: 0.8983 - val_loss: 1.8319 - val_accuracy: 0.3684\n"
     ]
    }
   ],
   "source": [
    "hist_sel3 = model_sel3.fit(X_sel_train, y_sel_train,\n",
    "          batch_size=64, epochs=100,\n",
    "          validation_data=(X_sel_test, y_sel_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 86.64%\n"
     ]
    }
   ],
   "source": [
    "print('train accuracy: %.2f%%' % (np.mean(hist_sel3.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba7 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_lasso_2.xlsx\",\n",
    "                        sheet_name=2,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NRS271</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.854929</td>\n",
       "      <td>0.144940</td>\n",
       "      <td>0.000130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>SR2852</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.999923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>CA39</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.959992</td>\n",
       "      <td>0.013406</td>\n",
       "      <td>0.026602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NRS266</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.999980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NY356</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.009156</td>\n",
       "      <td>0.411991</td>\n",
       "      <td>0.578852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>CFBREBSa110</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.044135</td>\n",
       "      <td>0.010244</td>\n",
       "      <td>0.945621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>CFBRSa05</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.145032</td>\n",
       "      <td>0.408530</td>\n",
       "      <td>0.446439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>CFBREBSa123</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.994623</td>\n",
       "      <td>0.004152</td>\n",
       "      <td>0.001224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>NY360</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000795</td>\n",
       "      <td>0.948566</td>\n",
       "      <td>0.050639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>CFBREBSa118</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.999037</td>\n",
       "      <td>0.000934</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>608 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     phage       strain  phenotype  prediction         0  \\\n",
       "0       p0017kpresabs_qual       NRS271          1           0  0.854929   \n",
       "1       p0017kpresabs_qual       SR2852          2           2  0.000001   \n",
       "2       p0017kpresabs_qual         CA39          2           0  0.959992   \n",
       "3       p0017kpresabs_qual       NRS266          1           2  0.000018   \n",
       "4       p0017kpresabs_qual        NY356          2           2  0.009156   \n",
       "..                     ...          ...        ...         ...       ...   \n",
       "603  p0040presabsSTCC_qual  CFBREBSa110          2           2  0.044135   \n",
       "604  p0040presabsSTCC_qual     CFBRSa05          0           2  0.145032   \n",
       "605  p0040presabsSTCC_qual  CFBREBSa123          0           0  0.994623   \n",
       "606  p0040presabsSTCC_qual        NY360          1           1  0.000795   \n",
       "607  p0040presabsSTCC_qual  CFBREBSa118          2           1  0.000029   \n",
       "\n",
       "            1         2  \n",
       "0    0.144940  0.000130  \n",
       "1    0.000075  0.999923  \n",
       "2    0.013406  0.026602  \n",
       "3    0.000003  0.999980  \n",
       "4    0.411991  0.578852  \n",
       "..        ...       ...  \n",
       "603  0.010244  0.945621  \n",
       "604  0.408530  0.446439  \n",
       "605  0.004152  0.001224  \n",
       "606  0.948566  0.050639  \n",
       "607  0.999037  0.000934  \n",
       "\n",
       "[608 rows x 7 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.5803387e-02, 9.3326920e-01, 4.0927507e-02],\n",
       "       [5.1309418e-02, 3.9897350e-01, 5.4971720e-01],\n",
       "       [3.9212075e-01, 3.6033604e-01, 2.4754323e-01],\n",
       "       [2.2128580e-01, 2.1620992e-01, 5.6250435e-01],\n",
       "       [4.6052542e-01, 4.7493818e-01, 6.4536430e-02],\n",
       "       [8.2702476e-01, 4.3616660e-02, 1.2935860e-01],\n",
       "       [1.2552959e-01, 7.9958440e-01, 7.4885994e-02],\n",
       "       [2.4747360e-01, 1.1413598e-01, 6.3839040e-01],\n",
       "       [1.9762398e-01, 2.9876280e-01, 5.0361323e-01],\n",
       "       [2.5151002e-01, 7.2410260e-01, 2.4387326e-02],\n",
       "       [9.5353264e-01, 2.8650573e-04, 4.6180807e-02],\n",
       "       [1.9091031e-03, 9.4689300e-01, 5.1197970e-02],\n",
       "       [4.6845627e-04, 3.8345692e-01, 6.1607470e-01],\n",
       "       [9.4751570e-01, 1.5126044e-03, 5.0971690e-02],\n",
       "       [5.9009504e-01, 3.6448804e-01, 4.5416960e-02],\n",
       "       [6.0963714e-01, 3.0628765e-01, 8.4075265e-02],\n",
       "       [3.2645352e-02, 6.5103010e-02, 9.0225166e-01],\n",
       "       [3.1774396e-01, 4.9754880e-01, 1.8470727e-01],\n",
       "       [3.6089970e-01, 3.9869820e-01, 2.4040209e-01],\n",
       "       [6.5466700e-02, 2.4794386e-01, 6.8658950e-01],\n",
       "       [3.7656043e-02, 3.2013352e-06, 9.6234080e-01],\n",
       "       [5.1828370e-01, 4.1817155e-01, 6.3544735e-02],\n",
       "       [6.6352344e-01, 2.0716624e-01, 1.2931031e-01],\n",
       "       [6.6352344e-01, 2.0716624e-01, 1.2931031e-01],\n",
       "       [4.2691010e-01, 5.1178014e-01, 6.1309700e-02],\n",
       "       [9.1954050e-02, 1.2675006e-03, 9.0677840e-01],\n",
       "       [5.9839420e-01, 3.4219930e-01, 5.9406456e-02],\n",
       "       [6.2861127e-01, 3.2512823e-01, 4.6260487e-02],\n",
       "       [9.7965970e-02, 7.9172800e-01, 1.1030602e-01],\n",
       "       [4.6718845e-01, 2.6850644e-01, 2.6430510e-01],\n",
       "       [3.5641050e-01, 6.2452780e-01, 1.9061668e-02],\n",
       "       [3.5394752e-01, 3.3841574e-01, 3.0763677e-01],\n",
       "       [6.3818070e-01, 2.2270393e-01, 1.3911544e-01],\n",
       "       [3.9293650e-01, 2.0706289e-01, 4.0000060e-01],\n",
       "       [9.7643700e-02, 7.0804030e-01, 1.9431593e-01],\n",
       "       [4.4069022e-02, 1.0215023e-01, 8.5378070e-01],\n",
       "       [3.9885890e-01, 8.0608435e-02, 5.2053267e-01],\n",
       "       [1.7174028e-01, 4.0452820e-01, 4.2373154e-01],\n",
       "       [9.7973760e-01, 2.7547353e-03, 1.7507750e-02],\n",
       "       [2.5537116e-02, 7.7796990e-02, 8.9666590e-01],\n",
       "       [4.3776030e-01, 5.3990465e-03, 5.5684070e-01],\n",
       "       [5.8205640e-03, 6.4520600e-02, 9.2965883e-01],\n",
       "       [3.3830000e-02, 3.9105280e-01, 5.7511710e-01],\n",
       "       [6.7275100e-01, 2.7365306e-01, 5.3595940e-02],\n",
       "       [1.3768212e-01, 2.0547607e-03, 8.6026310e-01],\n",
       "       [1.6645761e-01, 7.4698570e-01, 8.6556725e-02],\n",
       "       [5.2919567e-01, 3.3569527e-01, 1.3510900e-01],\n",
       "       [4.7504312e-01, 4.8271567e-01, 4.2241156e-02],\n",
       "       [9.6510270e-01, 3.0181527e-02, 4.7157356e-03],\n",
       "       [3.7585440e-07, 5.9235460e-05, 9.9994040e-01],\n",
       "       [3.1774396e-01, 4.9754880e-01, 1.8470727e-01],\n",
       "       [8.4805535e-03, 8.1182440e-02, 9.1033703e-01],\n",
       "       [3.8663346e-02, 7.3421136e-02, 8.8791555e-01],\n",
       "       [3.5394752e-01, 3.3841574e-01, 3.0763677e-01],\n",
       "       [2.6369804e-01, 7.2044230e-01, 1.5859619e-02],\n",
       "       [5.0206155e-01, 4.6968502e-01, 2.8253542e-02],\n",
       "       [3.8078704e-01, 3.9439866e-01, 2.2481428e-01],\n",
       "       [6.7244634e-02, 9.2221410e-01, 1.0541224e-02],\n",
       "       [1.8904907e-01, 2.1581866e-01, 5.9513230e-01],\n",
       "       [1.5529096e-01, 3.0802673e-01, 5.3668225e-01],\n",
       "       [6.4739910e-01, 2.1443743e-01, 1.3816346e-01],\n",
       "       [4.3262392e-01, 2.2163147e-01, 3.4574464e-01],\n",
       "       [5.6130810e-01, 4.0575317e-01, 3.2938756e-02],\n",
       "       [3.8212020e-01, 4.7550738e-01, 1.4237243e-01],\n",
       "       [3.5017985e-01, 4.8559350e-01, 1.6422668e-01],\n",
       "       [1.5185405e-01, 1.3522127e-01, 7.1292466e-01],\n",
       "       [2.3117164e-01, 3.6813265e-01, 4.0069580e-01],\n",
       "       [9.5233005e-01, 4.2567210e-02, 5.1027030e-03],\n",
       "       [3.4964457e-01, 6.1085653e-01, 3.9498936e-02],\n",
       "       [3.1392310e-01, 5.5887630e-01, 1.2720057e-01],\n",
       "       [9.8420190e-01, 1.5725213e-03, 1.4225574e-02],\n",
       "       [2.4911216e-01, 3.2761705e-01, 4.2327080e-01],\n",
       "       [4.1623345e-01, 5.5162640e-01, 3.2140136e-02],\n",
       "       [9.0758530e-01, 5.8005740e-04, 9.1834580e-02],\n",
       "       [6.4165425e-01, 1.8258033e-02, 3.4008768e-01],\n",
       "       [1.9485246e-01, 5.3329050e-01, 2.7185714e-01]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob7 = df_proba7[df_proba7['phage']=='p0017kpresabsSTCC_qual'].iloc[:,-3:]\n",
    "y_prob7 = y_prob7.to_numpy()\n",
    "y_prob7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5956017086969468"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo7 = rocauc_ovo(y_sel_test, y_prob7, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5956017086969468"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr7 = rocauc_ovr(y_sel_test, y_prob7, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_sel_train, X_sel_test, y_sel_train, y_sel_test = train_test_split(X_sel, y_sel,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=890,\n",
    "                                                    stratify=y_sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat8 = pd.DataFrame(X_sel_test.iloc[:,-1])\n",
    "dat8['test'] = y_sel_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strain</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>NRS104</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>NRS071</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>NRS072</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>BCH-SA-12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>CFBREBSa125</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>NRS199</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>CA11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>NRS253</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>NRS119</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>NRS074</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          strain  test\n",
       "131       NRS104     0\n",
       "123       NRS071     0\n",
       "124       NRS072     1\n",
       "27     BCH-SA-12     0\n",
       "57   CFBREBSa125     2\n",
       "..           ...   ...\n",
       "170       NRS199     2\n",
       "32          CA11     2\n",
       "212       NRS253     1\n",
       "141       NRS119     2\n",
       "126       NRS074     1\n",
       "\n",
       "[76 rows x 2 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sel_train = X_sel_train.drop(['strain'], axis=1)\n",
    "X_sel_test = X_sel_test.drop(['strain'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sel4 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_sel_train.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sel4.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 177 samples, validate on 76 samples\n",
      "Epoch 1/100\n",
      "177/177 [==============================] - 0s 858us/step - loss: 1.6399 - accuracy: 0.4124 - val_loss: 1.4864 - val_accuracy: 0.2105\n",
      "Epoch 2/100\n",
      "177/177 [==============================] - 0s 193us/step - loss: 1.2767 - accuracy: 0.4237 - val_loss: 1.1999 - val_accuracy: 0.3947\n",
      "Epoch 3/100\n",
      "177/177 [==============================] - 0s 172us/step - loss: 1.1525 - accuracy: 0.5198 - val_loss: 1.1311 - val_accuracy: 0.3947\n",
      "Epoch 4/100\n",
      "177/177 [==============================] - 0s 184us/step - loss: 1.0484 - accuracy: 0.5480 - val_loss: 1.3379 - val_accuracy: 0.3553\n",
      "Epoch 5/100\n",
      "177/177 [==============================] - 0s 134us/step - loss: 1.1540 - accuracy: 0.5198 - val_loss: 1.2472 - val_accuracy: 0.4737\n",
      "Epoch 6/100\n",
      "177/177 [==============================] - 0s 134us/step - loss: 1.0906 - accuracy: 0.5367 - val_loss: 1.0422 - val_accuracy: 0.4868\n",
      "Epoch 7/100\n",
      "177/177 [==============================] - 0s 215us/step - loss: 0.9857 - accuracy: 0.5593 - val_loss: 1.1244 - val_accuracy: 0.4342\n",
      "Epoch 8/100\n",
      "177/177 [==============================] - 0s 137us/step - loss: 1.1489 - accuracy: 0.5424 - val_loss: 1.1283 - val_accuracy: 0.5263\n",
      "Epoch 9/100\n",
      "177/177 [==============================] - 0s 170us/step - loss: 0.9896 - accuracy: 0.5763 - val_loss: 1.1208 - val_accuracy: 0.5263\n",
      "Epoch 10/100\n",
      "177/177 [==============================] - 0s 99us/step - loss: 1.1781 - accuracy: 0.5819 - val_loss: 1.1321 - val_accuracy: 0.5263\n",
      "Epoch 11/100\n",
      "177/177 [==============================] - 0s 85us/step - loss: 1.0892 - accuracy: 0.6045 - val_loss: 1.0590 - val_accuracy: 0.4737\n",
      "Epoch 12/100\n",
      "177/177 [==============================] - 0s 91us/step - loss: 1.0231 - accuracy: 0.5989 - val_loss: 1.3829 - val_accuracy: 0.4211\n",
      "Epoch 13/100\n",
      "177/177 [==============================] - 0s 88us/step - loss: 1.0552 - accuracy: 0.5706 - val_loss: 1.0825 - val_accuracy: 0.5132\n",
      "Epoch 14/100\n",
      "177/177 [==============================] - 0s 85us/step - loss: 1.0562 - accuracy: 0.5989 - val_loss: 1.1168 - val_accuracy: 0.5263\n",
      "Epoch 15/100\n",
      "177/177 [==============================] - 0s 105us/step - loss: 1.0578 - accuracy: 0.6045 - val_loss: 1.0862 - val_accuracy: 0.5395\n",
      "Epoch 16/100\n",
      "177/177 [==============================] - 0s 79us/step - loss: 1.0301 - accuracy: 0.5989 - val_loss: 1.2242 - val_accuracy: 0.4079\n",
      "Epoch 17/100\n",
      "177/177 [==============================] - 0s 84us/step - loss: 0.9711 - accuracy: 0.5989 - val_loss: 1.1419 - val_accuracy: 0.5000\n",
      "Epoch 18/100\n",
      "177/177 [==============================] - 0s 134us/step - loss: 0.8704 - accuracy: 0.6158 - val_loss: 1.1634 - val_accuracy: 0.4605\n",
      "Epoch 19/100\n",
      "177/177 [==============================] - 0s 106us/step - loss: 0.9362 - accuracy: 0.6158 - val_loss: 1.0450 - val_accuracy: 0.5263\n",
      "Epoch 20/100\n",
      "177/177 [==============================] - 0s 123us/step - loss: 0.8316 - accuracy: 0.6158 - val_loss: 1.2540 - val_accuracy: 0.4474\n",
      "Epoch 21/100\n",
      "177/177 [==============================] - 0s 151us/step - loss: 0.9887 - accuracy: 0.6384 - val_loss: 1.1067 - val_accuracy: 0.4605\n",
      "Epoch 22/100\n",
      "177/177 [==============================] - 0s 107us/step - loss: 0.9037 - accuracy: 0.6045 - val_loss: 1.0760 - val_accuracy: 0.4868\n",
      "Epoch 23/100\n",
      "177/177 [==============================] - 0s 120us/step - loss: 0.9201 - accuracy: 0.6441 - val_loss: 1.1810 - val_accuracy: 0.4211\n",
      "Epoch 24/100\n",
      "177/177 [==============================] - 0s 145us/step - loss: 0.8867 - accuracy: 0.6497 - val_loss: 1.2284 - val_accuracy: 0.4211\n",
      "Epoch 25/100\n",
      "177/177 [==============================] - 0s 111us/step - loss: 0.9000 - accuracy: 0.6441 - val_loss: 1.1201 - val_accuracy: 0.5000\n",
      "Epoch 26/100\n",
      "177/177 [==============================] - 0s 112us/step - loss: 0.8104 - accuracy: 0.6610 - val_loss: 1.0789 - val_accuracy: 0.4868\n",
      "Epoch 27/100\n",
      "177/177 [==============================] - 0s 133us/step - loss: 0.7935 - accuracy: 0.6610 - val_loss: 1.1060 - val_accuracy: 0.4605\n",
      "Epoch 28/100\n",
      "177/177 [==============================] - 0s 99us/step - loss: 0.7272 - accuracy: 0.6780 - val_loss: 1.1156 - val_accuracy: 0.4474\n",
      "Epoch 29/100\n",
      "177/177 [==============================] - 0s 115us/step - loss: 0.7814 - accuracy: 0.7006 - val_loss: 1.0698 - val_accuracy: 0.4868\n",
      "Epoch 30/100\n",
      "177/177 [==============================] - 0s 101us/step - loss: 0.7749 - accuracy: 0.6667 - val_loss: 1.0864 - val_accuracy: 0.5000\n",
      "Epoch 31/100\n",
      "177/177 [==============================] - 0s 132us/step - loss: 0.7874 - accuracy: 0.6893 - val_loss: 1.0758 - val_accuracy: 0.5000\n",
      "Epoch 32/100\n",
      "177/177 [==============================] - 0s 84us/step - loss: 0.7391 - accuracy: 0.6949 - val_loss: 1.0845 - val_accuracy: 0.5132\n",
      "Epoch 33/100\n",
      "177/177 [==============================] - 0s 87us/step - loss: 0.7175 - accuracy: 0.7119 - val_loss: 1.0530 - val_accuracy: 0.5263\n",
      "Epoch 34/100\n",
      "177/177 [==============================] - 0s 132us/step - loss: 0.8102 - accuracy: 0.7006 - val_loss: 1.0521 - val_accuracy: 0.5132\n",
      "Epoch 35/100\n",
      "177/177 [==============================] - 0s 177us/step - loss: 0.8391 - accuracy: 0.6723 - val_loss: 1.0968 - val_accuracy: 0.4868\n",
      "Epoch 36/100\n",
      "177/177 [==============================] - 0s 153us/step - loss: 0.7206 - accuracy: 0.7006 - val_loss: 1.0713 - val_accuracy: 0.5132\n",
      "Epoch 37/100\n",
      "177/177 [==============================] - 0s 102us/step - loss: 0.6992 - accuracy: 0.7062 - val_loss: 1.0859 - val_accuracy: 0.5132\n",
      "Epoch 38/100\n",
      "177/177 [==============================] - 0s 131us/step - loss: 0.7330 - accuracy: 0.7119 - val_loss: 1.0575 - val_accuracy: 0.4868\n",
      "Epoch 39/100\n",
      "177/177 [==============================] - 0s 119us/step - loss: 0.6728 - accuracy: 0.7345 - val_loss: 1.0922 - val_accuracy: 0.4868\n",
      "Epoch 40/100\n",
      "177/177 [==============================] - 0s 149us/step - loss: 0.7295 - accuracy: 0.7288 - val_loss: 1.1028 - val_accuracy: 0.4605\n",
      "Epoch 41/100\n",
      "177/177 [==============================] - 0s 246us/step - loss: 0.6587 - accuracy: 0.7401 - val_loss: 1.0919 - val_accuracy: 0.4737\n",
      "Epoch 42/100\n",
      "177/177 [==============================] - 0s 115us/step - loss: 0.6695 - accuracy: 0.7288 - val_loss: 1.0668 - val_accuracy: 0.5132\n",
      "Epoch 43/100\n",
      "177/177 [==============================] - 0s 191us/step - loss: 0.6437 - accuracy: 0.7514 - val_loss: 1.1041 - val_accuracy: 0.4605\n",
      "Epoch 44/100\n",
      "177/177 [==============================] - 0s 139us/step - loss: 0.6509 - accuracy: 0.7514 - val_loss: 1.0854 - val_accuracy: 0.5132\n",
      "Epoch 45/100\n",
      "177/177 [==============================] - 0s 132us/step - loss: 0.6461 - accuracy: 0.7288 - val_loss: 1.0463 - val_accuracy: 0.5395\n",
      "Epoch 46/100\n",
      "177/177 [==============================] - 0s 178us/step - loss: 0.6331 - accuracy: 0.7288 - val_loss: 1.0936 - val_accuracy: 0.5000\n",
      "Epoch 47/100\n",
      "177/177 [==============================] - 0s 155us/step - loss: 0.6359 - accuracy: 0.7514 - val_loss: 1.0968 - val_accuracy: 0.4868\n",
      "Epoch 48/100\n",
      "177/177 [==============================] - 0s 100us/step - loss: 0.6762 - accuracy: 0.7458 - val_loss: 1.0923 - val_accuracy: 0.4737\n",
      "Epoch 49/100\n",
      "177/177 [==============================] - 0s 105us/step - loss: 0.6739 - accuracy: 0.7627 - val_loss: 1.1076 - val_accuracy: 0.4868\n",
      "Epoch 50/100\n",
      "177/177 [==============================] - 0s 95us/step - loss: 0.5967 - accuracy: 0.7627 - val_loss: 1.1103 - val_accuracy: 0.5132\n",
      "Epoch 51/100\n",
      "177/177 [==============================] - 0s 91us/step - loss: 0.6295 - accuracy: 0.7458 - val_loss: 1.1342 - val_accuracy: 0.4868\n",
      "Epoch 52/100\n",
      "177/177 [==============================] - 0s 103us/step - loss: 0.6054 - accuracy: 0.7740 - val_loss: 1.1089 - val_accuracy: 0.4868\n",
      "Epoch 53/100\n",
      "177/177 [==============================] - 0s 150us/step - loss: 0.5999 - accuracy: 0.7797 - val_loss: 1.0887 - val_accuracy: 0.5000\n",
      "Epoch 54/100\n",
      "177/177 [==============================] - 0s 108us/step - loss: 0.5937 - accuracy: 0.7853 - val_loss: 1.1302 - val_accuracy: 0.4737\n",
      "Epoch 55/100\n",
      "177/177 [==============================] - 0s 105us/step - loss: 0.5965 - accuracy: 0.7853 - val_loss: 1.1258 - val_accuracy: 0.4868\n",
      "Epoch 56/100\n",
      "177/177 [==============================] - 0s 177us/step - loss: 0.5867 - accuracy: 0.7797 - val_loss: 1.1125 - val_accuracy: 0.4737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "177/177 [==============================] - 0s 167us/step - loss: 0.5872 - accuracy: 0.8079 - val_loss: 1.0967 - val_accuracy: 0.5000\n",
      "Epoch 58/100\n",
      "177/177 [==============================] - 0s 105us/step - loss: 0.5767 - accuracy: 0.7910 - val_loss: 1.1103 - val_accuracy: 0.5000\n",
      "Epoch 59/100\n",
      "177/177 [==============================] - 0s 110us/step - loss: 0.5865 - accuracy: 0.7966 - val_loss: 1.1544 - val_accuracy: 0.4474\n",
      "Epoch 60/100\n",
      "177/177 [==============================] - 0s 84us/step - loss: 0.5796 - accuracy: 0.7966 - val_loss: 1.0954 - val_accuracy: 0.4737\n",
      "Epoch 61/100\n",
      "177/177 [==============================] - 0s 111us/step - loss: 0.5871 - accuracy: 0.7910 - val_loss: 1.1153 - val_accuracy: 0.4737\n",
      "Epoch 62/100\n",
      "177/177 [==============================] - 0s 152us/step - loss: 0.5822 - accuracy: 0.8079 - val_loss: 1.1891 - val_accuracy: 0.4342\n",
      "Epoch 63/100\n",
      "177/177 [==============================] - 0s 152us/step - loss: 0.5502 - accuracy: 0.8249 - val_loss: 1.1066 - val_accuracy: 0.5000\n",
      "Epoch 64/100\n",
      "177/177 [==============================] - 0s 94us/step - loss: 0.5642 - accuracy: 0.7910 - val_loss: 1.0846 - val_accuracy: 0.5263\n",
      "Epoch 65/100\n",
      "177/177 [==============================] - 0s 82us/step - loss: 0.5675 - accuracy: 0.8079 - val_loss: 1.1251 - val_accuracy: 0.4474\n",
      "Epoch 66/100\n",
      "177/177 [==============================] - 0s 93us/step - loss: 0.5300 - accuracy: 0.8192 - val_loss: 1.1094 - val_accuracy: 0.4605\n",
      "Epoch 67/100\n",
      "177/177 [==============================] - 0s 119us/step - loss: 0.5462 - accuracy: 0.8023 - val_loss: 1.1400 - val_accuracy: 0.4605\n",
      "Epoch 68/100\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.5637 - accuracy: 0.8079 - val_loss: 1.1427 - val_accuracy: 0.4737\n",
      "Epoch 69/100\n",
      "177/177 [==============================] - 0s 63us/step - loss: 0.5522 - accuracy: 0.8136 - val_loss: 1.1382 - val_accuracy: 0.4605\n",
      "Epoch 70/100\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.5104 - accuracy: 0.8305 - val_loss: 1.1547 - val_accuracy: 0.4737\n",
      "Epoch 71/100\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.5261 - accuracy: 0.8079 - val_loss: 1.1404 - val_accuracy: 0.4868\n",
      "Epoch 72/100\n",
      "177/177 [==============================] - 0s 83us/step - loss: 0.5459 - accuracy: 0.8136 - val_loss: 1.2295 - val_accuracy: 0.4474\n",
      "Epoch 73/100\n",
      "177/177 [==============================] - 0s 70us/step - loss: 0.5045 - accuracy: 0.8249 - val_loss: 1.1937 - val_accuracy: 0.4737\n",
      "Epoch 74/100\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.4953 - accuracy: 0.8249 - val_loss: 1.1576 - val_accuracy: 0.5000\n",
      "Epoch 75/100\n",
      "177/177 [==============================] - 0s 70us/step - loss: 0.5201 - accuracy: 0.8079 - val_loss: 1.1670 - val_accuracy: 0.4737\n",
      "Epoch 76/100\n",
      "177/177 [==============================] - 0s 120us/step - loss: 0.4919 - accuracy: 0.8192 - val_loss: 1.1531 - val_accuracy: 0.4737\n",
      "Epoch 77/100\n",
      "177/177 [==============================] - 0s 119us/step - loss: 0.4914 - accuracy: 0.8136 - val_loss: 1.1507 - val_accuracy: 0.4737\n",
      "Epoch 78/100\n",
      "177/177 [==============================] - 0s 183us/step - loss: 0.4684 - accuracy: 0.8418 - val_loss: 1.1976 - val_accuracy: 0.4737\n",
      "Epoch 79/100\n",
      "177/177 [==============================] - 0s 373us/step - loss: 0.4811 - accuracy: 0.8305 - val_loss: 1.1557 - val_accuracy: 0.5000\n",
      "Epoch 80/100\n",
      "177/177 [==============================] - 0s 187us/step - loss: 0.4975 - accuracy: 0.8362 - val_loss: 1.1428 - val_accuracy: 0.5000\n",
      "Epoch 81/100\n",
      "177/177 [==============================] - 0s 218us/step - loss: 0.5199 - accuracy: 0.8362 - val_loss: 1.1548 - val_accuracy: 0.5132\n",
      "Epoch 82/100\n",
      "177/177 [==============================] - 0s 135us/step - loss: 0.4749 - accuracy: 0.8136 - val_loss: 1.1782 - val_accuracy: 0.4868\n",
      "Epoch 83/100\n",
      "177/177 [==============================] - 0s 199us/step - loss: 0.5038 - accuracy: 0.8249 - val_loss: 1.1850 - val_accuracy: 0.4737\n",
      "Epoch 84/100\n",
      "177/177 [==============================] - 0s 125us/step - loss: 0.4858 - accuracy: 0.8192 - val_loss: 1.1808 - val_accuracy: 0.4737\n",
      "Epoch 85/100\n",
      "177/177 [==============================] - 0s 120us/step - loss: 0.4522 - accuracy: 0.8418 - val_loss: 1.2660 - val_accuracy: 0.3947\n",
      "Epoch 86/100\n",
      "177/177 [==============================] - 0s 187us/step - loss: 0.5069 - accuracy: 0.8249 - val_loss: 1.1808 - val_accuracy: 0.4474\n",
      "Epoch 87/100\n",
      "177/177 [==============================] - 0s 142us/step - loss: 0.5105 - accuracy: 0.8418 - val_loss: 1.2358 - val_accuracy: 0.4737\n",
      "Epoch 88/100\n",
      "177/177 [==============================] - 0s 128us/step - loss: 0.5481 - accuracy: 0.8418 - val_loss: 1.3982 - val_accuracy: 0.4605\n",
      "Epoch 89/100\n",
      "177/177 [==============================] - 0s 138us/step - loss: 0.5132 - accuracy: 0.8475 - val_loss: 1.2993 - val_accuracy: 0.5000\n",
      "Epoch 90/100\n",
      "177/177 [==============================] - 0s 122us/step - loss: 0.4760 - accuracy: 0.8588 - val_loss: 1.2081 - val_accuracy: 0.5000\n",
      "Epoch 91/100\n",
      "177/177 [==============================] - 0s 175us/step - loss: 0.4626 - accuracy: 0.8418 - val_loss: 1.3135 - val_accuracy: 0.4342\n",
      "Epoch 92/100\n",
      "177/177 [==============================] - 0s 177us/step - loss: 0.4928 - accuracy: 0.8588 - val_loss: 1.2569 - val_accuracy: 0.4474\n",
      "Epoch 93/100\n",
      "177/177 [==============================] - 0s 131us/step - loss: 0.4428 - accuracy: 0.8531 - val_loss: 1.2683 - val_accuracy: 0.4474\n",
      "Epoch 94/100\n",
      "177/177 [==============================] - 0s 146us/step - loss: 0.5274 - accuracy: 0.8305 - val_loss: 1.2493 - val_accuracy: 0.4868\n",
      "Epoch 95/100\n",
      "177/177 [==============================] - 0s 119us/step - loss: 0.4121 - accuracy: 0.8362 - val_loss: 1.4908 - val_accuracy: 0.4211\n",
      "Epoch 96/100\n",
      "177/177 [==============================] - 0s 137us/step - loss: 0.6460 - accuracy: 0.7853 - val_loss: 1.3338 - val_accuracy: 0.4079\n",
      "Epoch 97/100\n",
      "177/177 [==============================] - 0s 155us/step - loss: 0.4428 - accuracy: 0.8305 - val_loss: 1.3651 - val_accuracy: 0.4605\n",
      "Epoch 98/100\n",
      "177/177 [==============================] - 0s 121us/step - loss: 0.6363 - accuracy: 0.8418 - val_loss: 1.2932 - val_accuracy: 0.4737\n",
      "Epoch 99/100\n",
      "177/177 [==============================] - 0s 157us/step - loss: 0.6046 - accuracy: 0.8023 - val_loss: 1.3086 - val_accuracy: 0.4868\n",
      "Epoch 100/100\n",
      "177/177 [==============================] - 0s 224us/step - loss: 0.4140 - accuracy: 0.8588 - val_loss: 1.3760 - val_accuracy: 0.4474\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a3bdac630>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sel4.fit(X_sel_train, y_sel_train,\n",
    "          batch_size=64, epochs=100,\n",
    "          validation_data=(X_sel_test, y_sel_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 0s 98us/step\n",
      "over-sampling test accuracy: 55.26%\n"
     ]
    }
   ],
   "source": [
    "acc_test_sel4 = model_sel4.evaluate(X_sel_test, y_sel_test)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_sel4*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0, 1, 2, 0, 1, 2, 1, 0, 0, 1, 2, 1, 0, 2, 1, 2, 0, 1, 2, 0,\n",
       "       2, 1, 0, 2, 2, 1, 2, 2, 2, 0, 1, 1, 1, 0, 1, 0, 1, 2, 0, 1, 0, 0,\n",
       "       1, 2, 1, 0, 1, 2, 2, 0, 2, 2, 0, 2, 0, 0, 1, 0, 2, 1, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 1, 1, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred8 = model_sel4.predict_classes(X_sel_test)\n",
    "pred8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strain</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>NRS104</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>NRS071</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>NRS072</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>BCH-SA-12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>CFBREBSa125</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>NRS199</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>CA11</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>NRS253</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>NRS119</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>NRS074</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          strain  test  pred\n",
       "131       NRS104     0     2\n",
       "123       NRS071     0     1\n",
       "124       NRS072     1     0\n",
       "27     BCH-SA-12     0     1\n",
       "57   CFBREBSa125     2     2\n",
       "..           ...   ...   ...\n",
       "170       NRS199     2     1\n",
       "32          CA11     2     1\n",
       "212       NRS253     1     1\n",
       "141       NRS119     2     1\n",
       "126       NRS074     1     0\n",
       "\n",
       "[76 rows x 3 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat8['pred'] = pred8\n",
    "dat8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba8 = model_sel4.predict_proba(X_sel_test)\n",
    "dat_proba8 = pd.DataFrame(proba8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.045344</td>\n",
       "      <td>0.038492</td>\n",
       "      <td>0.916163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.005553</td>\n",
       "      <td>0.952853</td>\n",
       "      <td>0.041594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.750289</td>\n",
       "      <td>0.023561</td>\n",
       "      <td>0.226149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.232031</td>\n",
       "      <td>0.607860</td>\n",
       "      <td>0.160109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.387979</td>\n",
       "      <td>0.154933</td>\n",
       "      <td>0.457088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.160530</td>\n",
       "      <td>0.686465</td>\n",
       "      <td>0.153005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.289323</td>\n",
       "      <td>0.428511</td>\n",
       "      <td>0.282166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.042483</td>\n",
       "      <td>0.848594</td>\n",
       "      <td>0.108923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.066866</td>\n",
       "      <td>0.528038</td>\n",
       "      <td>0.405096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.637220</td>\n",
       "      <td>0.175090</td>\n",
       "      <td>0.187690</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2\n",
       "0   0.045344  0.038492  0.916163\n",
       "1   0.005553  0.952853  0.041594\n",
       "2   0.750289  0.023561  0.226149\n",
       "3   0.232031  0.607860  0.160109\n",
       "4   0.387979  0.154933  0.457088\n",
       "..       ...       ...       ...\n",
       "71  0.160530  0.686465  0.153005\n",
       "72  0.289323  0.428511  0.282166\n",
       "73  0.042483  0.848594  0.108923\n",
       "74  0.066866  0.528038  0.405096\n",
       "75  0.637220  0.175090  0.187690\n",
       "\n",
       "[76 rows x 3 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba8.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba8.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat8.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/8p17ST.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 177 samples, validate on 76 samples\n",
      "Epoch 1/100\n",
      "177/177 [==============================] - 0s 102us/step - loss: 0.4224 - accuracy: 0.8644 - val_loss: 1.2902 - val_accuracy: 0.5132\n",
      "Epoch 2/100\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.4583 - accuracy: 0.8418 - val_loss: 1.2461 - val_accuracy: 0.5000\n",
      "Epoch 3/100\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.4816 - accuracy: 0.8362 - val_loss: 1.3103 - val_accuracy: 0.4737\n",
      "Epoch 4/100\n",
      "177/177 [==============================] - 0s 111us/step - loss: 0.4068 - accuracy: 0.8475 - val_loss: 1.2924 - val_accuracy: 0.5263\n",
      "Epoch 5/100\n",
      "177/177 [==============================] - 0s 151us/step - loss: 0.4207 - accuracy: 0.8418 - val_loss: 1.2429 - val_accuracy: 0.5000\n",
      "Epoch 6/100\n",
      "177/177 [==============================] - 0s 124us/step - loss: 0.4034 - accuracy: 0.8531 - val_loss: 1.2574 - val_accuracy: 0.5000\n",
      "Epoch 7/100\n",
      "177/177 [==============================] - 0s 129us/step - loss: 0.3752 - accuracy: 0.8644 - val_loss: 1.3136 - val_accuracy: 0.5263\n",
      "Epoch 8/100\n",
      "177/177 [==============================] - 0s 111us/step - loss: 0.4237 - accuracy: 0.8588 - val_loss: 1.3186 - val_accuracy: 0.5132\n",
      "Epoch 9/100\n",
      "177/177 [==============================] - 0s 105us/step - loss: 0.4096 - accuracy: 0.8531 - val_loss: 1.2640 - val_accuracy: 0.5263\n",
      "Epoch 10/100\n",
      "177/177 [==============================] - 0s 121us/step - loss: 0.4002 - accuracy: 0.8531 - val_loss: 1.3753 - val_accuracy: 0.4605\n",
      "Epoch 11/100\n",
      "177/177 [==============================] - 0s 97us/step - loss: 0.4281 - accuracy: 0.8701 - val_loss: 1.2928 - val_accuracy: 0.5395\n",
      "Epoch 12/100\n",
      "177/177 [==============================] - 0s 106us/step - loss: 0.3892 - accuracy: 0.8531 - val_loss: 1.3151 - val_accuracy: 0.5263\n",
      "Epoch 13/100\n",
      "177/177 [==============================] - 0s 93us/step - loss: 0.3914 - accuracy: 0.8531 - val_loss: 1.2661 - val_accuracy: 0.5000\n",
      "Epoch 14/100\n",
      "177/177 [==============================] - 0s 101us/step - loss: 0.3913 - accuracy: 0.8531 - val_loss: 1.2987 - val_accuracy: 0.5132\n",
      "Epoch 15/100\n",
      "177/177 [==============================] - 0s 129us/step - loss: 0.3665 - accuracy: 0.8701 - val_loss: 1.3582 - val_accuracy: 0.4868\n",
      "Epoch 16/100\n",
      "177/177 [==============================] - 0s 140us/step - loss: 0.3859 - accuracy: 0.8475 - val_loss: 1.3034 - val_accuracy: 0.5263\n",
      "Epoch 17/100\n",
      "177/177 [==============================] - 0s 112us/step - loss: 0.3567 - accuracy: 0.8531 - val_loss: 1.2881 - val_accuracy: 0.5132\n",
      "Epoch 18/100\n",
      "177/177 [==============================] - 0s 120us/step - loss: 0.3728 - accuracy: 0.8531 - val_loss: 1.3409 - val_accuracy: 0.4868\n",
      "Epoch 19/100\n",
      "177/177 [==============================] - 0s 114us/step - loss: 0.3703 - accuracy: 0.8644 - val_loss: 1.3394 - val_accuracy: 0.5132\n",
      "Epoch 20/100\n",
      "177/177 [==============================] - 0s 105us/step - loss: 0.3634 - accuracy: 0.8757 - val_loss: 1.3154 - val_accuracy: 0.5263\n",
      "Epoch 21/100\n",
      "177/177 [==============================] - 0s 119us/step - loss: 0.3833 - accuracy: 0.8531 - val_loss: 1.3239 - val_accuracy: 0.5000\n",
      "Epoch 22/100\n",
      "177/177 [==============================] - 0s 113us/step - loss: 0.4031 - accuracy: 0.8588 - val_loss: 1.3426 - val_accuracy: 0.5263\n",
      "Epoch 23/100\n",
      "177/177 [==============================] - 0s 113us/step - loss: 0.3988 - accuracy: 0.8531 - val_loss: 1.3972 - val_accuracy: 0.4605\n",
      "Epoch 24/100\n",
      "177/177 [==============================] - 0s 99us/step - loss: 0.3672 - accuracy: 0.8644 - val_loss: 1.3290 - val_accuracy: 0.4868\n",
      "Epoch 25/100\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.3797 - accuracy: 0.8475 - val_loss: 1.3225 - val_accuracy: 0.4868\n",
      "Epoch 26/100\n",
      "177/177 [==============================] - 0s 105us/step - loss: 0.3364 - accuracy: 0.8757 - val_loss: 1.3877 - val_accuracy: 0.5000\n",
      "Epoch 27/100\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.3609 - accuracy: 0.8701 - val_loss: 1.3869 - val_accuracy: 0.4737\n",
      "Epoch 28/100\n",
      "177/177 [==============================] - 0s 103us/step - loss: 0.3529 - accuracy: 0.8644 - val_loss: 1.3387 - val_accuracy: 0.5000\n",
      "Epoch 29/100\n",
      "177/177 [==============================] - 0s 111us/step - loss: 0.3375 - accuracy: 0.8701 - val_loss: 1.3696 - val_accuracy: 0.4868\n",
      "Epoch 30/100\n",
      "177/177 [==============================] - 0s 104us/step - loss: 0.3690 - accuracy: 0.8757 - val_loss: 1.4438 - val_accuracy: 0.4737\n",
      "Epoch 31/100\n",
      "177/177 [==============================] - 0s 99us/step - loss: 0.3691 - accuracy: 0.8814 - val_loss: 1.4111 - val_accuracy: 0.4737\n",
      "Epoch 32/100\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.3432 - accuracy: 0.8814 - val_loss: 1.3816 - val_accuracy: 0.4737\n",
      "Epoch 33/100\n",
      "177/177 [==============================] - 0s 100us/step - loss: 0.3404 - accuracy: 0.8701 - val_loss: 1.3667 - val_accuracy: 0.4605\n",
      "Epoch 34/100\n",
      "177/177 [==============================] - 0s 118us/step - loss: 0.3771 - accuracy: 0.8757 - val_loss: 1.3990 - val_accuracy: 0.4474\n",
      "Epoch 35/100\n",
      "177/177 [==============================] - 0s 119us/step - loss: 0.3480 - accuracy: 0.8588 - val_loss: 1.4978 - val_accuracy: 0.3816\n",
      "Epoch 36/100\n",
      "177/177 [==============================] - 0s 103us/step - loss: 0.4286 - accuracy: 0.8475 - val_loss: 1.5101 - val_accuracy: 0.4605\n",
      "Epoch 37/100\n",
      "177/177 [==============================] - 0s 113us/step - loss: 0.3353 - accuracy: 0.8757 - val_loss: 1.4152 - val_accuracy: 0.5000\n",
      "Epoch 38/100\n",
      "177/177 [==============================] - 0s 115us/step - loss: 0.4587 - accuracy: 0.8644 - val_loss: 1.4084 - val_accuracy: 0.5000\n",
      "Epoch 39/100\n",
      "177/177 [==============================] - 0s 100us/step - loss: 0.4276 - accuracy: 0.8531 - val_loss: 1.4650 - val_accuracy: 0.4605\n",
      "Epoch 40/100\n",
      "177/177 [==============================] - 0s 105us/step - loss: 0.3397 - accuracy: 0.8870 - val_loss: 1.5191 - val_accuracy: 0.4211\n",
      "Epoch 41/100\n",
      "177/177 [==============================] - 0s 119us/step - loss: 0.3782 - accuracy: 0.8701 - val_loss: 1.4674 - val_accuracy: 0.4474\n",
      "Epoch 42/100\n",
      "177/177 [==============================] - 0s 102us/step - loss: 0.3305 - accuracy: 0.8870 - val_loss: 1.3937 - val_accuracy: 0.4605\n",
      "Epoch 43/100\n",
      "177/177 [==============================] - 0s 116us/step - loss: 0.3175 - accuracy: 0.8814 - val_loss: 1.4117 - val_accuracy: 0.4737\n",
      "Epoch 44/100\n",
      "177/177 [==============================] - 0s 117us/step - loss: 0.3255 - accuracy: 0.8927 - val_loss: 1.4403 - val_accuracy: 0.4737\n",
      "Epoch 45/100\n",
      "177/177 [==============================] - 0s 161us/step - loss: 0.3159 - accuracy: 0.8870 - val_loss: 1.4373 - val_accuracy: 0.4868\n",
      "Epoch 46/100\n",
      "177/177 [==============================] - 0s 118us/step - loss: 0.3182 - accuracy: 0.8814 - val_loss: 1.4237 - val_accuracy: 0.4605\n",
      "Epoch 47/100\n",
      "177/177 [==============================] - 0s 122us/step - loss: 0.3147 - accuracy: 0.8814 - val_loss: 1.4192 - val_accuracy: 0.4868\n",
      "Epoch 48/100\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.3085 - accuracy: 0.8927 - val_loss: 1.4471 - val_accuracy: 0.4605\n",
      "Epoch 49/100\n",
      "177/177 [==============================] - 0s 95us/step - loss: 0.3223 - accuracy: 0.8870 - val_loss: 1.4734 - val_accuracy: 0.4342\n",
      "Epoch 50/100\n",
      "177/177 [==============================] - 0s 97us/step - loss: 0.3135 - accuracy: 0.8701 - val_loss: 1.4581 - val_accuracy: 0.4737\n",
      "Epoch 51/100\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.3487 - accuracy: 0.8644 - val_loss: 1.4353 - val_accuracy: 0.4474\n",
      "Epoch 52/100\n",
      "177/177 [==============================] - 0s 111us/step - loss: 0.3358 - accuracy: 0.8870 - val_loss: 1.4454 - val_accuracy: 0.4868\n",
      "Epoch 53/100\n",
      "177/177 [==============================] - 0s 113us/step - loss: 0.3397 - accuracy: 0.8814 - val_loss: 1.4644 - val_accuracy: 0.4474\n",
      "Epoch 54/100\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.3536 - accuracy: 0.8757 - val_loss: 1.5369 - val_accuracy: 0.4605\n",
      "Epoch 55/100\n",
      "177/177 [==============================] - 0s 107us/step - loss: 0.3535 - accuracy: 0.8870 - val_loss: 1.5473 - val_accuracy: 0.4868\n",
      "Epoch 56/100\n",
      "177/177 [==============================] - 0s 100us/step - loss: 0.3625 - accuracy: 0.8757 - val_loss: 1.4714 - val_accuracy: 0.4868\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "177/177 [==============================] - 0s 99us/step - loss: 0.3552 - accuracy: 0.8531 - val_loss: 1.4919 - val_accuracy: 0.4342\n",
      "Epoch 58/100\n",
      "177/177 [==============================] - 0s 114us/step - loss: 0.3389 - accuracy: 0.8814 - val_loss: 1.5445 - val_accuracy: 0.4605\n",
      "Epoch 59/100\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.3583 - accuracy: 0.8814 - val_loss: 1.5132 - val_accuracy: 0.4605\n",
      "Epoch 60/100\n",
      "177/177 [==============================] - 0s 101us/step - loss: 0.3182 - accuracy: 0.8701 - val_loss: 1.5080 - val_accuracy: 0.4474\n",
      "Epoch 61/100\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.3006 - accuracy: 0.8927 - val_loss: 1.5104 - val_accuracy: 0.4474\n",
      "Epoch 62/100\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.3223 - accuracy: 0.9040 - val_loss: 1.5268 - val_accuracy: 0.4342\n",
      "Epoch 63/100\n",
      "177/177 [==============================] - 0s 111us/step - loss: 0.3181 - accuracy: 0.9153 - val_loss: 1.5321 - val_accuracy: 0.4737\n",
      "Epoch 64/100\n",
      "177/177 [==============================] - 0s 110us/step - loss: 0.3049 - accuracy: 0.8927 - val_loss: 1.5113 - val_accuracy: 0.4605\n",
      "Epoch 65/100\n",
      "177/177 [==============================] - 0s 84us/step - loss: 0.2989 - accuracy: 0.8927 - val_loss: 1.5438 - val_accuracy: 0.4474\n",
      "Epoch 66/100\n",
      "177/177 [==============================] - 0s 126us/step - loss: 0.2955 - accuracy: 0.8983 - val_loss: 1.5528 - val_accuracy: 0.4342\n",
      "Epoch 67/100\n",
      "177/177 [==============================] - 0s 111us/step - loss: 0.2995 - accuracy: 0.8983 - val_loss: 1.5179 - val_accuracy: 0.4474\n",
      "Epoch 68/100\n",
      "177/177 [==============================] - 0s 108us/step - loss: 0.3234 - accuracy: 0.8870 - val_loss: 1.5015 - val_accuracy: 0.4737\n",
      "Epoch 69/100\n",
      "177/177 [==============================] - 0s 93us/step - loss: 0.3127 - accuracy: 0.8814 - val_loss: 1.5372 - val_accuracy: 0.4474\n",
      "Epoch 70/100\n",
      "177/177 [==============================] - 0s 95us/step - loss: 0.3508 - accuracy: 0.8927 - val_loss: 1.5793 - val_accuracy: 0.4211\n",
      "Epoch 71/100\n",
      "177/177 [==============================] - 0s 95us/step - loss: 0.3245 - accuracy: 0.9153 - val_loss: 1.5409 - val_accuracy: 0.4737\n",
      "Epoch 72/100\n",
      "177/177 [==============================] - 0s 109us/step - loss: 0.3305 - accuracy: 0.8814 - val_loss: 1.5223 - val_accuracy: 0.4737\n",
      "Epoch 73/100\n",
      "177/177 [==============================] - 0s 107us/step - loss: 0.2801 - accuracy: 0.8870 - val_loss: 1.5690 - val_accuracy: 0.4605\n",
      "Epoch 74/100\n",
      "177/177 [==============================] - 0s 91us/step - loss: 0.3105 - accuracy: 0.8927 - val_loss: 1.5976 - val_accuracy: 0.4474\n",
      "Epoch 75/100\n",
      "177/177 [==============================] - 0s 101us/step - loss: 0.3084 - accuracy: 0.8814 - val_loss: 1.5313 - val_accuracy: 0.4474\n",
      "Epoch 76/100\n",
      "177/177 [==============================] - 0s 108us/step - loss: 0.3032 - accuracy: 0.8983 - val_loss: 1.5356 - val_accuracy: 0.4342\n",
      "Epoch 77/100\n",
      "177/177 [==============================] - 0s 109us/step - loss: 0.2998 - accuracy: 0.8983 - val_loss: 1.5776 - val_accuracy: 0.4342\n",
      "Epoch 78/100\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.2871 - accuracy: 0.8927 - val_loss: 1.5931 - val_accuracy: 0.4342\n",
      "Epoch 79/100\n",
      "177/177 [==============================] - 0s 123us/step - loss: 0.2831 - accuracy: 0.9040 - val_loss: 1.5493 - val_accuracy: 0.4474\n",
      "Epoch 80/100\n",
      "177/177 [==============================] - 0s 107us/step - loss: 0.2813 - accuracy: 0.8814 - val_loss: 1.5670 - val_accuracy: 0.4605\n",
      "Epoch 81/100\n",
      "177/177 [==============================] - 0s 87us/step - loss: 0.2890 - accuracy: 0.9153 - val_loss: 1.5976 - val_accuracy: 0.4474\n",
      "Epoch 82/100\n",
      "177/177 [==============================] - 0s 85us/step - loss: 0.2806 - accuracy: 0.9040 - val_loss: 1.5673 - val_accuracy: 0.4605\n",
      "Epoch 83/100\n",
      "177/177 [==============================] - 0s 130us/step - loss: 0.2834 - accuracy: 0.8927 - val_loss: 1.5728 - val_accuracy: 0.4474\n",
      "Epoch 84/100\n",
      "177/177 [==============================] - 0s 119us/step - loss: 0.2788 - accuracy: 0.8983 - val_loss: 1.5565 - val_accuracy: 0.4605\n",
      "Epoch 85/100\n",
      "177/177 [==============================] - 0s 141us/step - loss: 0.3040 - accuracy: 0.8983 - val_loss: 1.5676 - val_accuracy: 0.4605\n",
      "Epoch 86/100\n",
      "177/177 [==============================] - 0s 116us/step - loss: 0.2968 - accuracy: 0.9040 - val_loss: 1.6695 - val_accuracy: 0.3816\n",
      "Epoch 87/100\n",
      "177/177 [==============================] - 0s 93us/step - loss: 0.3255 - accuracy: 0.8927 - val_loss: 1.6559 - val_accuracy: 0.4474\n",
      "Epoch 88/100\n",
      "177/177 [==============================] - 0s 105us/step - loss: 0.2731 - accuracy: 0.8870 - val_loss: 1.5894 - val_accuracy: 0.4868\n",
      "Epoch 89/100\n",
      "177/177 [==============================] - 0s 112us/step - loss: 0.3526 - accuracy: 0.8701 - val_loss: 1.5929 - val_accuracy: 0.4605\n",
      "Epoch 90/100\n",
      "177/177 [==============================] - 0s 112us/step - loss: 0.2739 - accuracy: 0.9040 - val_loss: 1.6273 - val_accuracy: 0.4342\n",
      "Epoch 91/100\n",
      "177/177 [==============================] - 0s 92us/step - loss: 0.3322 - accuracy: 0.8983 - val_loss: 1.7075 - val_accuracy: 0.3816\n",
      "Epoch 92/100\n",
      "177/177 [==============================] - 0s 101us/step - loss: 0.3156 - accuracy: 0.8757 - val_loss: 1.6398 - val_accuracy: 0.4605\n",
      "Epoch 93/100\n",
      "177/177 [==============================] - 0s 132us/step - loss: 0.3453 - accuracy: 0.8814 - val_loss: 1.6065 - val_accuracy: 0.4737\n",
      "Epoch 94/100\n",
      "177/177 [==============================] - 0s 100us/step - loss: 0.2974 - accuracy: 0.8983 - val_loss: 1.6277 - val_accuracy: 0.4474\n",
      "Epoch 95/100\n",
      "177/177 [==============================] - 0s 101us/step - loss: 0.3398 - accuracy: 0.8701 - val_loss: 1.7765 - val_accuracy: 0.3816\n",
      "Epoch 96/100\n",
      "177/177 [==============================] - 0s 96us/step - loss: 0.3127 - accuracy: 0.8757 - val_loss: 1.7290 - val_accuracy: 0.4737\n",
      "Epoch 97/100\n",
      "177/177 [==============================] - 0s 81us/step - loss: 0.3336 - accuracy: 0.8814 - val_loss: 1.6210 - val_accuracy: 0.5000\n",
      "Epoch 98/100\n",
      "177/177 [==============================] - 0s 104us/step - loss: 0.2992 - accuracy: 0.8870 - val_loss: 1.7296 - val_accuracy: 0.3684\n",
      "Epoch 99/100\n",
      "177/177 [==============================] - 0s 97us/step - loss: 0.3462 - accuracy: 0.8757 - val_loss: 1.7505 - val_accuracy: 0.4605\n",
      "Epoch 100/100\n",
      "177/177 [==============================] - 0s 104us/step - loss: 0.2952 - accuracy: 0.8814 - val_loss: 1.6723 - val_accuracy: 0.4737\n"
     ]
    }
   ],
   "source": [
    "hist_sel4 = model_sel4.fit(X_sel_train, y_sel_train,\n",
    "          batch_size=64, epochs=100,\n",
    "          validation_data=(X_sel_test, y_sel_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 87.70%\n"
     ]
    }
   ],
   "source": [
    "print('train accuracy: %.2f%%' % (np.mean(hist_sel4.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba8 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_lasso_2.xlsx\",\n",
    "                        sheet_name=3,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NRS104</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.210638e-02</td>\n",
       "      <td>0.917809</td>\n",
       "      <td>8.477923e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NRS071</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.015229e-02</td>\n",
       "      <td>0.255327</td>\n",
       "      <td>7.345203e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NRS072</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.642946e-03</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>9.963547e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>BCH-SA-12</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.809318e-03</td>\n",
       "      <td>0.099188</td>\n",
       "      <td>8.980029e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>CFBREBSa125</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4.875667e-01</td>\n",
       "      <td>0.088657</td>\n",
       "      <td>4.237761e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>NRS113</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.686909e-07</td>\n",
       "      <td>0.093121</td>\n",
       "      <td>9.068785e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>BCH-SA-09</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5.529492e-07</td>\n",
       "      <td>0.999990</td>\n",
       "      <td>9.559324e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>NRS106</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.115902e-03</td>\n",
       "      <td>0.998816</td>\n",
       "      <td>6.852559e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>CFBREBSa131</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.708040e-07</td>\n",
       "      <td>0.156768</td>\n",
       "      <td>8.432316e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>GA51254</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.993569e-01</td>\n",
       "      <td>0.000643</td>\n",
       "      <td>1.816008e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>608 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     phage       strain  phenotype  prediction             0  \\\n",
       "0       p0017kpresabs_qual       NRS104          0           1  8.210638e-02   \n",
       "1       p0017kpresabs_qual       NRS071          0           2  1.015229e-02   \n",
       "2       p0017kpresabs_qual       NRS072          1           2  3.642946e-03   \n",
       "3       p0017kpresabs_qual    BCH-SA-12          0           2  2.809318e-03   \n",
       "4       p0017kpresabs_qual  CFBREBSa125          2           0  4.875667e-01   \n",
       "..                     ...          ...        ...         ...           ...   \n",
       "603  p0040presabsSTCC_qual       NRS113          1           2  2.686909e-07   \n",
       "604  p0040presabsSTCC_qual    BCH-SA-09          2           1  5.529492e-07   \n",
       "605  p0040presabsSTCC_qual       NRS106          2           1  1.115902e-03   \n",
       "606  p0040presabsSTCC_qual  CFBREBSa131          2           2  2.708040e-07   \n",
       "607  p0040presabsSTCC_qual      GA51254          0           0  9.993569e-01   \n",
       "\n",
       "            1             2  \n",
       "0    0.917809  8.477923e-05  \n",
       "1    0.255327  7.345203e-01  \n",
       "2    0.000002  9.963547e-01  \n",
       "3    0.099188  8.980029e-01  \n",
       "4    0.088657  4.237761e-01  \n",
       "..        ...           ...  \n",
       "603  0.093121  9.068785e-01  \n",
       "604  0.999990  9.559324e-06  \n",
       "605  0.998816  6.852559e-05  \n",
       "606  0.156768  8.432316e-01  \n",
       "607  0.000643  1.816008e-08  \n",
       "\n",
       "[608 rows x 7 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.53442300e-02, 3.84922800e-02, 9.16163440e-01],\n",
       "       [5.55331900e-03, 9.52852960e-01, 4.15936200e-02],\n",
       "       [7.50289500e-01, 2.35614010e-02, 2.26149110e-01],\n",
       "       [2.32030630e-01, 6.07860270e-01, 1.60109100e-01],\n",
       "       [3.87979360e-01, 1.54933040e-01, 4.57087550e-01],\n",
       "       [6.67779270e-01, 2.04682200e-01, 1.27538490e-01],\n",
       "       [4.35295800e-01, 5.59733150e-01, 4.97103950e-03],\n",
       "       [1.64425940e-01, 3.35121600e-01, 5.00452460e-01],\n",
       "       [6.60662100e-02, 7.86608900e-01, 1.47324900e-01],\n",
       "       [7.18242350e-01, 1.37364760e-01, 1.44392900e-01],\n",
       "       [4.58425250e-01, 3.15858270e-01, 2.25716460e-01],\n",
       "       [4.35333900e-02, 6.09235470e-01, 3.47231240e-01],\n",
       "       [2.44472300e-01, 2.49391570e-01, 5.06136200e-01],\n",
       "       [2.37668710e-01, 5.71613670e-01, 1.90717640e-01],\n",
       "       [5.57458460e-01, 2.19031870e-01, 2.23509620e-01],\n",
       "       [5.13955160e-03, 7.02447200e-02, 9.24615740e-01],\n",
       "       [1.57207430e-01, 7.52620200e-01, 9.01723500e-02],\n",
       "       [2.78767530e-01, 3.46911340e-01, 3.74321130e-01],\n",
       "       [3.47094180e-01, 3.24484940e-01, 3.28420850e-01],\n",
       "       [3.18967000e-02, 9.65896670e-01, 2.20657050e-03],\n",
       "       [4.29269760e-03, 3.92450000e-01, 6.03257300e-01],\n",
       "       [3.97809680e-01, 3.25755540e-01, 2.76434750e-01],\n",
       "       [2.49742460e-01, 2.95881660e-01, 4.54375900e-01],\n",
       "       [1.99465970e-03, 5.91442170e-01, 4.06563160e-01],\n",
       "       [6.72432070e-01, 2.27202420e-01, 1.00365560e-01],\n",
       "       [1.05433050e-02, 1.34802070e-02, 9.75976500e-01],\n",
       "       [2.25292450e-03, 1.37494960e-02, 9.83997600e-01],\n",
       "       [4.03536600e-01, 4.28878700e-01, 1.67584720e-01],\n",
       "       [3.40029740e-03, 1.01888140e-01, 8.94711550e-01],\n",
       "       [1.88921420e-01, 5.00321240e-02, 7.61046470e-01],\n",
       "       [2.48376060e-01, 3.47486230e-01, 4.04137670e-01],\n",
       "       [4.82700350e-01, 4.25319250e-01, 9.19804200e-02],\n",
       "       [9.39875900e-02, 5.57278300e-01, 3.48734100e-01],\n",
       "       [9.92377900e-02, 8.56331940e-01, 4.44303230e-02],\n",
       "       [1.66730840e-01, 4.72140760e-01, 3.61128450e-01],\n",
       "       [4.75438480e-01, 3.94015900e-01, 1.30545650e-01],\n",
       "       [2.05154100e-02, 9.78318870e-01, 1.16564550e-03],\n",
       "       [4.60772570e-01, 2.41876200e-01, 2.97351180e-01],\n",
       "       [2.25572180e-01, 4.92356300e-01, 2.82071530e-01],\n",
       "       [5.99173250e-04, 2.37254520e-03, 9.97028300e-01],\n",
       "       [6.86744870e-01, 3.06845040e-01, 6.41007540e-03],\n",
       "       [3.39985700e-01, 3.87620060e-01, 2.72394270e-01],\n",
       "       [8.78079200e-01, 7.38177080e-03, 1.14539000e-01],\n",
       "       [7.33877600e-01, 2.04037600e-01, 6.20847160e-02],\n",
       "       [2.32286360e-01, 7.48248500e-01, 1.94651650e-02],\n",
       "       [4.51405070e-03, 1.52915670e-03, 9.93956800e-01],\n",
       "       [3.98533370e-03, 9.49704500e-01, 4.63101120e-02],\n",
       "       [8.91660200e-01, 8.70936800e-02, 2.12461400e-02],\n",
       "       [1.33994300e-02, 9.26330700e-01, 6.02698100e-02],\n",
       "       [4.07982600e-04, 3.62364760e-03, 9.95968340e-01],\n",
       "       [9.10601000e-03, 4.15402580e-02, 9.49353700e-01],\n",
       "       [9.92583400e-01, 6.86655800e-03, 5.50058260e-04],\n",
       "       [2.28227480e-01, 3.30294600e-01, 4.41477950e-01],\n",
       "       [1.46131890e-04, 4.96108140e-04, 9.99357760e-01],\n",
       "       [6.29413960e-01, 8.37163000e-02, 2.86869620e-01],\n",
       "       [5.87735300e-02, 4.66694950e-01, 4.74531470e-01],\n",
       "       [4.98585600e-01, 2.18322840e-01, 2.83091550e-01],\n",
       "       [5.18072250e-01, 1.80247430e-02, 4.63902980e-01],\n",
       "       [2.40638920e-03, 7.35881600e-01, 2.61712070e-01],\n",
       "       [4.64734170e-01, 3.00797000e-01, 2.34468790e-01],\n",
       "       [1.10904590e-01, 2.11359220e-01, 6.77736200e-01],\n",
       "       [9.14703400e-02, 5.50348300e-01, 3.58181330e-01],\n",
       "       [8.79521130e-01, 1.18434764e-01, 2.04409750e-03],\n",
       "       [9.58096000e-01, 1.13751110e-02, 3.05288020e-02],\n",
       "       [3.98670140e-01, 3.23965370e-01, 2.77364430e-01],\n",
       "       [4.00684540e-04, 9.97642930e-01, 1.95634800e-03],\n",
       "       [2.69361560e-01, 5.81489600e-01, 1.49148790e-01],\n",
       "       [5.89897600e-01, 1.63844730e-01, 2.46257630e-01],\n",
       "       [4.91122840e-01, 1.75302300e-01, 3.33574920e-01],\n",
       "       [3.83952860e-01, 3.14003380e-01, 3.02043800e-01],\n",
       "       [6.50231600e-02, 9.31240200e-01, 3.73663240e-03],\n",
       "       [1.60530090e-01, 6.86464700e-01, 1.53005140e-01],\n",
       "       [2.89322820e-01, 4.28510960e-01, 2.82166120e-01],\n",
       "       [4.24832900e-02, 8.48593650e-01, 1.08923085e-01],\n",
       "       [6.68663900e-02, 5.28037600e-01, 4.05096050e-01],\n",
       "       [6.37220440e-01, 1.75089580e-01, 1.87689970e-01]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob8 = df_proba8[df_proba8['phage']=='p0017kpresabsSTCC_qual'].iloc[:,-3:]\n",
    "y_prob8 = y_prob8.to_numpy()\n",
    "y_prob8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6417806179710941"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo8 = rocauc_ovo(y_sel_test, y_prob8, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6417806179710941"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr8 = rocauc_ovr(y_sel_test, y_prob8, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6282889839437459"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovos2 = [ovo5, ovo6, ovo7, ovo8]\n",
    "np.mean(ovos2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.024440821586036797"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(ovos2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6282889839437459"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovrs2 = [ovr5, ovr6, ovr7, ovr8]\n",
    "np.mean(ovrs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.024440821586036797"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(ovrs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs_l= [acc_test_sel, acc_test_sel2, acc_test_sel3, acc_test_sel4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy mean after lasso: 48.36%\n"
     ]
    }
   ],
   "source": [
    "mean_l = np.mean(accs_l)\n",
    "print('test accuracy mean after lasso: %.2f%%' % (mean_l*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy standard deviation after lasso: 0.052115058683581295\n"
     ]
    }
   ],
   "source": [
    "std_l = np.std(accs_l)\n",
    "print('test accuracy standard deviation after lasso:', std_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs_train_l = [np.mean(hist_sel.history['accuracy']), np.mean(hist_sel2.history['accuracy']), np.mean(hist_sel3.history['accuracy']),\n",
    "             np.mean(hist_sel4.history['accuracy'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy mean after lasso: 88.01%\n"
     ]
    }
   ],
   "source": [
    "mean_train_l = np.mean(accs_train_l)\n",
    "print('train accuracy mean after lasso: %.2f%%' % (mean_train_l*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy standard deviation after lasso: 0.010038472\n"
     ]
    }
   ],
   "source": [
    "std_train_l = np.std(accs_train_l)\n",
    "print('train accuracy standard deviation after lasso:', std_train_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
