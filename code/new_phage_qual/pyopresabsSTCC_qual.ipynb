{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This file implements neural networks with/without dropout and regularizer for pyopresabsSTCC_qual with four replicates.\n",
    "## We compute the mean and standarad deviation of training and test accuracies.\n",
    "## We also compute the mean and standard deviation of AUC ROC values for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "import numpy as np\n",
    "seed(100)\n",
    "import tensorflow\n",
    "tensorflow.random.set_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(253, 614)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/pyopresabsSTCC_qual.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'Unnamed: 0':'id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "      ..\n",
       "248    0\n",
       "249    0\n",
       "250    0\n",
       "251    0\n",
       "252    0\n",
       "Name: pheno, Length: 253, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pheno']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>TTTTCCCCCAT</th>\n",
       "      <th>TTCAAATTACCCTCTCTTGTAAAATCAAATTCACATGATGTCCATGGTTC</th>\n",
       "      <th>TGGGTCTGAC</th>\n",
       "      <th>TCCTGATGGACCAAAACCTAATTTAATCCAATCTATATAATCAAACGATACTTTCAAATTACCCTCTCTTGTAAAATCAAATTCACATGATGTCCATGGT</th>\n",
       "      <th>TATATAGACTG</th>\n",
       "      <th>TAGTCGCACT</th>\n",
       "      <th>TAAGAATAATATATTAAATATTTATTAACAAATTATAGATAAAATATGAATAATTAATTAATGGTATTTACATATTCATAACC</th>\n",
       "      <th>GGGCTGAGG</th>\n",
       "      <th>GAGCAACCTT</th>\n",
       "      <th>...</th>\n",
       "      <th>group_8646</th>\n",
       "      <th>group_8815</th>\n",
       "      <th>group_8892</th>\n",
       "      <th>group_9007</th>\n",
       "      <th>group_9104</th>\n",
       "      <th>group_9110</th>\n",
       "      <th>group_9207</th>\n",
       "      <th>ST</th>\n",
       "      <th>CC</th>\n",
       "      <th>pheno</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>109</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>120335</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120337</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 614 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  TTTTCCCCCAT  TTCAAATTACCCTCTCTTGTAAAATCAAATTCACATGATGTCCATGGTTC  \\\n",
       "0     107            0                                                  1    \n",
       "1     109            0                                                  1    \n",
       "2     115            0                                                  0    \n",
       "3  120335            0                                                  1    \n",
       "4  120337            0                                                  1    \n",
       "\n",
       "   TGGGTCTGAC  \\\n",
       "0           1   \n",
       "1           0   \n",
       "2           0   \n",
       "3           0   \n",
       "4           0   \n",
       "\n",
       "   TCCTGATGGACCAAAACCTAATTTAATCCAATCTATATAATCAAACGATACTTTCAAATTACCCTCTCTTGTAAAATCAAATTCACATGATGTCCATGGT  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  1                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   TATATAGACTG  TAGTCGCACT  \\\n",
       "0            1           0   \n",
       "1            1           0   \n",
       "2            1           1   \n",
       "3            1           0   \n",
       "4            1           0   \n",
       "\n",
       "   TAAGAATAATATATTAAATATTTATTAACAAATTATAGATAAAATATGAATAATTAATTAATGGTATTTACATATTCATAACC  \\\n",
       "0                                                  1                                     \n",
       "1                                                  1                                     \n",
       "2                                                  1                                     \n",
       "3                                                  1                                     \n",
       "4                                                  1                                     \n",
       "\n",
       "   GGGCTGAGG  GAGCAACCTT  ...  group_8646  group_8815  group_8892  group_9007  \\\n",
       "0          0           0  ...           0           0           0           0   \n",
       "1          0           0  ...           0           0           0           0   \n",
       "2          1           1  ...           0           0           0           0   \n",
       "3          0           0  ...           0           0           0           0   \n",
       "4          0           0  ...           0           0           0           0   \n",
       "\n",
       "   group_9104  group_9110  group_9207  ST  CC  pheno  \n",
       "0           0           0           0   5   5      0  \n",
       "1           0           0           0   8   8      0  \n",
       "2           0           0           0   5   5      0  \n",
       "3           0           0           0   5   5      0  \n",
       "4           0           0           0   5   5      0  \n",
       "\n",
       "[5 rows x 614 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    217\n",
       "1     32\n",
       "2      4\n",
       "Name: pheno, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pheno'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.drop(columns=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(253, 613)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TTTTCCCCCAT</th>\n",
       "      <th>TTCAAATTACCCTCTCTTGTAAAATCAAATTCACATGATGTCCATGGTTC</th>\n",
       "      <th>TGGGTCTGAC</th>\n",
       "      <th>TCCTGATGGACCAAAACCTAATTTAATCCAATCTATATAATCAAACGATACTTTCAAATTACCCTCTCTTGTAAAATCAAATTCACATGATGTCCATGGT</th>\n",
       "      <th>TATATAGACTG</th>\n",
       "      <th>TAGTCGCACT</th>\n",
       "      <th>TAAGAATAATATATTAAATATTTATTAACAAATTATAGATAAAATATGAATAATTAATTAATGGTATTTACATATTCATAACC</th>\n",
       "      <th>GGGCTGAGG</th>\n",
       "      <th>GAGCAACCTT</th>\n",
       "      <th>GAACCATGGACATCATGTGAATTTGATTTTACAAGAGAGGGT</th>\n",
       "      <th>...</th>\n",
       "      <th>group_8646</th>\n",
       "      <th>group_8815</th>\n",
       "      <th>group_8892</th>\n",
       "      <th>group_9007</th>\n",
       "      <th>group_9104</th>\n",
       "      <th>group_9110</th>\n",
       "      <th>group_9207</th>\n",
       "      <th>ST</th>\n",
       "      <th>CC</th>\n",
       "      <th>pheno</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 613 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TTTTCCCCCAT  TTCAAATTACCCTCTCTTGTAAAATCAAATTCACATGATGTCCATGGTTC  \\\n",
       "0            0                                                  1    \n",
       "1            0                                                  1    \n",
       "2            0                                                  0    \n",
       "3            0                                                  1    \n",
       "4            0                                                  1    \n",
       "\n",
       "   TGGGTCTGAC  \\\n",
       "0           1   \n",
       "1           0   \n",
       "2           0   \n",
       "3           0   \n",
       "4           0   \n",
       "\n",
       "   TCCTGATGGACCAAAACCTAATTTAATCCAATCTATATAATCAAACGATACTTTCAAATTACCCTCTCTTGTAAAATCAAATTCACATGATGTCCATGGT  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  1                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   TATATAGACTG  TAGTCGCACT  \\\n",
       "0            1           0   \n",
       "1            1           0   \n",
       "2            1           1   \n",
       "3            1           0   \n",
       "4            1           0   \n",
       "\n",
       "   TAAGAATAATATATTAAATATTTATTAACAAATTATAGATAAAATATGAATAATTAATTAATGGTATTTACATATTCATAACC  \\\n",
       "0                                                  1                                     \n",
       "1                                                  1                                     \n",
       "2                                                  1                                     \n",
       "3                                                  1                                     \n",
       "4                                                  1                                     \n",
       "\n",
       "   GGGCTGAGG  GAGCAACCTT  GAACCATGGACATCATGTGAATTTGATTTTACAAGAGAGGGT  ...  \\\n",
       "0          0           0                                           1  ...   \n",
       "1          0           0                                           1  ...   \n",
       "2          1           1                                           0  ...   \n",
       "3          0           0                                           1  ...   \n",
       "4          0           0                                           1  ...   \n",
       "\n",
       "   group_8646  group_8815  group_8892  group_9007  group_9104  group_9110  \\\n",
       "0           0           0           0           0           0           0   \n",
       "1           0           0           0           0           0           0   \n",
       "2           0           0           0           0           0           0   \n",
       "3           0           0           0           0           0           0   \n",
       "4           0           0           0           0           0           0   \n",
       "\n",
       "   group_9207  ST  CC  pheno  \n",
       "0           0   5   5      0  \n",
       "1           0   8   8      0  \n",
       "2           0   5   5      0  \n",
       "3           0   5   5      0  \n",
       "4           0   5   5      0  \n",
       "\n",
       "[5 rows x 613 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(253, 613) (253,)\n"
     ]
    }
   ],
   "source": [
    "X = df.loc[:, df.columns != 'pheno']\n",
    "y = df['pheno']\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.ensemble.bagging module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.ensemble.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.ensemble.forest module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 217), (1, 217), (2, 217)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.utils.testing module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.utils. Anything that cannot be imported from sklearn.utils is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.metrics.classification module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# over-sampling\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "overS = RandomOverSampler(random_state=100)\n",
    "X_over, y_over = overS.fit_resample(X, y)\n",
    "print(sorted(Counter(y_over).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# Fully-Connected Neural Network ################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.regularizers import l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=123,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = pd.DataFrame(X_test_over[:,0])\n",
    "dat['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CFBRSa07</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CFBRSa66A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS112</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS211</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CFBRSa22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>NRS205</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>196 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0  test\n",
       "0     CFBRSa07     0\n",
       "1    CFBRSa66A     0\n",
       "2       NRS112     1\n",
       "3       NRS211     0\n",
       "4     CFBRSa22     0\n",
       "..         ...   ...\n",
       "191     NRS148     2\n",
       "192     NRS255     2\n",
       "193     NRS205     2\n",
       "194     NRS255     2\n",
       "195     NRS109     2\n",
       "\n",
       "[196 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### neural network on over-sampling data\n",
    "model1_over = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],)),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 455 samples, validate on 196 samples\n",
      "Epoch 1/100\n",
      "455/455 [==============================] - 0s 300us/step - loss: 3.0195 - accuracy: 0.5099 - val_loss: 1.0229 - val_accuracy: 0.5357\n",
      "Epoch 2/100\n",
      "455/455 [==============================] - 0s 101us/step - loss: 0.9292 - accuracy: 0.5451 - val_loss: 0.7798 - val_accuracy: 0.6378\n",
      "Epoch 3/100\n",
      "455/455 [==============================] - 0s 113us/step - loss: 0.5511 - accuracy: 0.7626 - val_loss: 0.4758 - val_accuracy: 0.7347\n",
      "Epoch 4/100\n",
      "455/455 [==============================] - 0s 114us/step - loss: 0.3975 - accuracy: 0.8527 - val_loss: 0.3731 - val_accuracy: 0.8724\n",
      "Epoch 5/100\n",
      "455/455 [==============================] - 0s 117us/step - loss: 0.3076 - accuracy: 0.9033 - val_loss: 0.3138 - val_accuracy: 0.9235\n",
      "Epoch 6/100\n",
      "455/455 [==============================] - 0s 115us/step - loss: 0.2573 - accuracy: 0.9297 - val_loss: 0.2655 - val_accuracy: 0.9337\n",
      "Epoch 7/100\n",
      "455/455 [==============================] - 0s 108us/step - loss: 0.2241 - accuracy: 0.9560 - val_loss: 0.2382 - val_accuracy: 0.9388\n",
      "Epoch 8/100\n",
      "455/455 [==============================] - 0s 99us/step - loss: 0.2001 - accuracy: 0.9538 - val_loss: 0.2145 - val_accuracy: 0.9388\n",
      "Epoch 9/100\n",
      "455/455 [==============================] - 0s 94us/step - loss: 0.1820 - accuracy: 0.9692 - val_loss: 0.1972 - val_accuracy: 0.9592\n",
      "Epoch 10/100\n",
      "455/455 [==============================] - 0s 97us/step - loss: 0.1645 - accuracy: 0.9648 - val_loss: 0.1813 - val_accuracy: 0.9592\n",
      "Epoch 11/100\n",
      "455/455 [==============================] - 0s 104us/step - loss: 0.1516 - accuracy: 0.9758 - val_loss: 0.1684 - val_accuracy: 0.9694\n",
      "Epoch 12/100\n",
      "455/455 [==============================] - 0s 100us/step - loss: 0.1364 - accuracy: 0.9758 - val_loss: 0.1586 - val_accuracy: 0.9694\n",
      "Epoch 13/100\n",
      "455/455 [==============================] - 0s 95us/step - loss: 0.1255 - accuracy: 0.9780 - val_loss: 0.1496 - val_accuracy: 0.9694\n",
      "Epoch 14/100\n",
      "455/455 [==============================] - 0s 95us/step - loss: 0.1175 - accuracy: 0.9780 - val_loss: 0.1499 - val_accuracy: 0.9592\n",
      "Epoch 15/100\n",
      "455/455 [==============================] - 0s 106us/step - loss: 0.1164 - accuracy: 0.9648 - val_loss: 0.1446 - val_accuracy: 0.9592\n",
      "Epoch 16/100\n",
      "455/455 [==============================] - 0s 106us/step - loss: 0.1156 - accuracy: 0.9758 - val_loss: 0.1362 - val_accuracy: 0.9643\n",
      "Epoch 17/100\n",
      "455/455 [==============================] - 0s 105us/step - loss: 0.0961 - accuracy: 0.9868 - val_loss: 0.1216 - val_accuracy: 0.9694\n",
      "Epoch 18/100\n",
      "455/455 [==============================] - 0s 105us/step - loss: 0.0896 - accuracy: 0.9802 - val_loss: 0.1184 - val_accuracy: 0.9694\n",
      "Epoch 19/100\n",
      "455/455 [==============================] - 0s 121us/step - loss: 0.0892 - accuracy: 0.9868 - val_loss: 0.1194 - val_accuracy: 0.9694\n",
      "Epoch 20/100\n",
      "455/455 [==============================] - 0s 121us/step - loss: 0.0799 - accuracy: 0.9868 - val_loss: 0.1102 - val_accuracy: 0.9694\n",
      "Epoch 21/100\n",
      "455/455 [==============================] - 0s 134us/step - loss: 0.0743 - accuracy: 0.9912 - val_loss: 0.1124 - val_accuracy: 0.9643\n",
      "Epoch 22/100\n",
      "455/455 [==============================] - 0s 144us/step - loss: 0.0693 - accuracy: 0.9802 - val_loss: 0.1016 - val_accuracy: 0.9694\n",
      "Epoch 23/100\n",
      "455/455 [==============================] - 0s 173us/step - loss: 0.0640 - accuracy: 0.9978 - val_loss: 0.1056 - val_accuracy: 0.9643\n",
      "Epoch 24/100\n",
      "455/455 [==============================] - 0s 154us/step - loss: 0.0629 - accuracy: 0.9890 - val_loss: 0.0977 - val_accuracy: 0.9745\n",
      "Epoch 25/100\n",
      "455/455 [==============================] - 0s 140us/step - loss: 0.0566 - accuracy: 0.9978 - val_loss: 0.0971 - val_accuracy: 0.9694\n",
      "Epoch 26/100\n",
      "455/455 [==============================] - 0s 134us/step - loss: 0.0540 - accuracy: 0.9912 - val_loss: 0.0912 - val_accuracy: 0.9745\n",
      "Epoch 27/100\n",
      "455/455 [==============================] - 0s 148us/step - loss: 0.0506 - accuracy: 0.9978 - val_loss: 0.0952 - val_accuracy: 0.9745\n",
      "Epoch 28/100\n",
      "455/455 [==============================] - 0s 151us/step - loss: 0.0472 - accuracy: 0.9978 - val_loss: 0.0907 - val_accuracy: 0.9745\n",
      "Epoch 29/100\n",
      "455/455 [==============================] - 0s 119us/step - loss: 0.0448 - accuracy: 0.9978 - val_loss: 0.0892 - val_accuracy: 0.9745\n",
      "Epoch 30/100\n",
      "455/455 [==============================] - 0s 107us/step - loss: 0.0431 - accuracy: 0.9978 - val_loss: 0.0869 - val_accuracy: 0.9745\n",
      "Epoch 31/100\n",
      "455/455 [==============================] - 0s 95us/step - loss: 0.0411 - accuracy: 0.9978 - val_loss: 0.0883 - val_accuracy: 0.9745\n",
      "Epoch 32/100\n",
      "455/455 [==============================] - 0s 95us/step - loss: 0.0401 - accuracy: 0.9978 - val_loss: 0.0872 - val_accuracy: 0.9745\n",
      "Epoch 33/100\n",
      "455/455 [==============================] - 0s 164us/step - loss: 0.0403 - accuracy: 0.9978 - val_loss: 0.0887 - val_accuracy: 0.9745\n",
      "Epoch 34/100\n",
      "455/455 [==============================] - 0s 186us/step - loss: 0.0369 - accuracy: 0.9978 - val_loss: 0.0841 - val_accuracy: 0.9745\n",
      "Epoch 35/100\n",
      "455/455 [==============================] - 0s 101us/step - loss: 0.0338 - accuracy: 0.9978 - val_loss: 0.0821 - val_accuracy: 0.9745\n",
      "Epoch 36/100\n",
      "455/455 [==============================] - 0s 90us/step - loss: 0.0320 - accuracy: 0.9978 - val_loss: 0.0849 - val_accuracy: 0.9745\n",
      "Epoch 37/100\n",
      "455/455 [==============================] - 0s 103us/step - loss: 0.0322 - accuracy: 0.9956 - val_loss: 0.0810 - val_accuracy: 0.9745\n",
      "Epoch 38/100\n",
      "455/455 [==============================] - 0s 107us/step - loss: 0.0346 - accuracy: 0.9978 - val_loss: 0.0859 - val_accuracy: 0.9694\n",
      "Epoch 39/100\n",
      "455/455 [==============================] - 0s 112us/step - loss: 0.0298 - accuracy: 0.9978 - val_loss: 0.0792 - val_accuracy: 0.9745\n",
      "Epoch 40/100\n",
      "455/455 [==============================] - 0s 147us/step - loss: 0.0284 - accuracy: 0.9978 - val_loss: 0.0823 - val_accuracy: 0.9745\n",
      "Epoch 41/100\n",
      "455/455 [==============================] - 0s 178us/step - loss: 0.0281 - accuracy: 0.9978 - val_loss: 0.0809 - val_accuracy: 0.9745\n",
      "Epoch 42/100\n",
      "455/455 [==============================] - 0s 169us/step - loss: 0.0250 - accuracy: 0.9978 - val_loss: 0.0804 - val_accuracy: 0.9745\n",
      "Epoch 43/100\n",
      "455/455 [==============================] - 0s 106us/step - loss: 0.0237 - accuracy: 0.9978 - val_loss: 0.0792 - val_accuracy: 0.9694\n",
      "Epoch 44/100\n",
      "455/455 [==============================] - 0s 99us/step - loss: 0.0229 - accuracy: 0.9978 - val_loss: 0.0797 - val_accuracy: 0.9694\n",
      "Epoch 45/100\n",
      "455/455 [==============================] - 0s 95us/step - loss: 0.0224 - accuracy: 1.0000 - val_loss: 0.0818 - val_accuracy: 0.9694\n",
      "Epoch 46/100\n",
      "455/455 [==============================] - 0s 101us/step - loss: 0.0215 - accuracy: 0.9978 - val_loss: 0.0776 - val_accuracy: 0.9694\n",
      "Epoch 47/100\n",
      "455/455 [==============================] - 0s 126us/step - loss: 0.0199 - accuracy: 0.9978 - val_loss: 0.0785 - val_accuracy: 0.9694\n",
      "Epoch 48/100\n",
      "455/455 [==============================] - 0s 128us/step - loss: 0.0184 - accuracy: 1.0000 - val_loss: 0.0774 - val_accuracy: 0.9694\n",
      "Epoch 49/100\n",
      "455/455 [==============================] - 0s 115us/step - loss: 0.0196 - accuracy: 1.0000 - val_loss: 0.0790 - val_accuracy: 0.9694\n",
      "Epoch 50/100\n",
      "455/455 [==============================] - 0s 91us/step - loss: 0.0177 - accuracy: 1.0000 - val_loss: 0.0786 - val_accuracy: 0.9694\n",
      "Epoch 51/100\n",
      "455/455 [==============================] - 0s 84us/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 0.0779 - val_accuracy: 0.9694\n",
      "Epoch 52/100\n",
      "455/455 [==============================] - 0s 83us/step - loss: 0.0159 - accuracy: 1.0000 - val_loss: 0.0777 - val_accuracy: 0.9694\n",
      "Epoch 53/100\n",
      "455/455 [==============================] - 0s 84us/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 0.0747 - val_accuracy: 0.9694\n",
      "Epoch 54/100\n",
      "455/455 [==============================] - 0s 83us/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 0.0757 - val_accuracy: 0.9694\n",
      "Epoch 55/100\n",
      "455/455 [==============================] - 0s 81us/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 0.0749 - val_accuracy: 0.9694\n",
      "Epoch 56/100\n",
      "455/455 [==============================] - 0s 90us/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 0.0740 - val_accuracy: 0.9694\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "455/455 [==============================] - 0s 89us/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 0.0763 - val_accuracy: 0.9694\n",
      "Epoch 58/100\n",
      "455/455 [==============================] - 0s 82us/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.0742 - val_accuracy: 0.9694\n",
      "Epoch 59/100\n",
      "455/455 [==============================] - 0s 83us/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.0748 - val_accuracy: 0.9694\n",
      "Epoch 60/100\n",
      "455/455 [==============================] - 0s 80us/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 0.0760 - val_accuracy: 0.9694\n",
      "Epoch 61/100\n",
      "455/455 [==============================] - 0s 84us/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.0749 - val_accuracy: 0.9694\n",
      "Epoch 62/100\n",
      "455/455 [==============================] - 0s 97us/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.0750 - val_accuracy: 0.9694\n",
      "Epoch 63/100\n",
      "455/455 [==============================] - 0s 83us/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.0765 - val_accuracy: 0.9694\n",
      "Epoch 64/100\n",
      "455/455 [==============================] - 0s 83us/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.0764 - val_accuracy: 0.9694\n",
      "Epoch 65/100\n",
      "455/455 [==============================] - 0s 117us/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.0741 - val_accuracy: 0.9694\n",
      "Epoch 66/100\n",
      "455/455 [==============================] - 0s 87us/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.0770 - val_accuracy: 0.9694\n",
      "Epoch 67/100\n",
      "455/455 [==============================] - 0s 89us/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.0776 - val_accuracy: 0.9694\n",
      "Epoch 68/100\n",
      "455/455 [==============================] - 0s 85us/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.0754 - val_accuracy: 0.9694\n",
      "Epoch 69/100\n",
      "455/455 [==============================] - 0s 81us/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.0792 - val_accuracy: 0.9694\n",
      "Epoch 70/100\n",
      "455/455 [==============================] - 0s 83us/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.0767 - val_accuracy: 0.9694\n",
      "Epoch 71/100\n",
      "455/455 [==============================] - 0s 82us/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.0761 - val_accuracy: 0.9694\n",
      "Epoch 72/100\n",
      "455/455 [==============================] - 0s 87us/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.0770 - val_accuracy: 0.9694\n",
      "Epoch 73/100\n",
      "455/455 [==============================] - 0s 88us/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.0784 - val_accuracy: 0.9745\n",
      "Epoch 74/100\n",
      "455/455 [==============================] - 0s 91us/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.0781 - val_accuracy: 0.9694\n",
      "Epoch 75/100\n",
      "455/455 [==============================] - 0s 82us/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.0768 - val_accuracy: 0.9745\n",
      "Epoch 76/100\n",
      "455/455 [==============================] - 0s 108us/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.0766 - val_accuracy: 0.9745\n",
      "Epoch 77/100\n",
      "455/455 [==============================] - 0s 182us/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.0784 - val_accuracy: 0.9745\n",
      "Epoch 78/100\n",
      "455/455 [==============================] - 0s 111us/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.0788 - val_accuracy: 0.9694\n",
      "Epoch 79/100\n",
      "455/455 [==============================] - 0s 101us/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.0770 - val_accuracy: 0.9745\n",
      "Epoch 80/100\n",
      "455/455 [==============================] - 0s 96us/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0788 - val_accuracy: 0.9694\n",
      "Epoch 81/100\n",
      "455/455 [==============================] - 0s 90us/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0772 - val_accuracy: 0.9694\n",
      "Epoch 82/100\n",
      "455/455 [==============================] - 0s 91us/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0787 - val_accuracy: 0.9694\n",
      "Epoch 83/100\n",
      "455/455 [==============================] - 0s 103us/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0769 - val_accuracy: 0.9745\n",
      "Epoch 84/100\n",
      "455/455 [==============================] - 0s 113us/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0779 - val_accuracy: 0.9745\n",
      "Epoch 85/100\n",
      "455/455 [==============================] - 0s 121us/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0802 - val_accuracy: 0.9694\n",
      "Epoch 86/100\n",
      "455/455 [==============================] - 0s 125us/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0784 - val_accuracy: 0.9745\n",
      "Epoch 87/100\n",
      "455/455 [==============================] - 0s 104us/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0778 - val_accuracy: 0.9694\n",
      "Epoch 88/100\n",
      "455/455 [==============================] - 0s 87us/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0772 - val_accuracy: 0.9745\n",
      "Epoch 89/100\n",
      "455/455 [==============================] - 0s 84us/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0788 - val_accuracy: 0.9745\n",
      "Epoch 90/100\n",
      "455/455 [==============================] - 0s 85us/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0796 - val_accuracy: 0.9745\n",
      "Epoch 91/100\n",
      "455/455 [==============================] - 0s 83us/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0787 - val_accuracy: 0.9745\n",
      "Epoch 92/100\n",
      "455/455 [==============================] - 0s 86us/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0777 - val_accuracy: 0.9745\n",
      "Epoch 93/100\n",
      "455/455 [==============================] - 0s 133us/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0835 - val_accuracy: 0.9745\n",
      "Epoch 94/100\n",
      "455/455 [==============================] - 0s 134us/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0822 - val_accuracy: 0.9745\n",
      "Epoch 95/100\n",
      "455/455 [==============================] - 0s 107us/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0847 - val_accuracy: 0.9745\n",
      "Epoch 96/100\n",
      "455/455 [==============================] - 0s 109us/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0840 - val_accuracy: 0.9745\n",
      "Epoch 97/100\n",
      "455/455 [==============================] - 0s 108us/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0857 - val_accuracy: 0.9745\n",
      "Epoch 98/100\n",
      "455/455 [==============================] - 0s 128us/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0858 - val_accuracy: 0.9745\n",
      "Epoch 99/100\n",
      "455/455 [==============================] - 0s 120us/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0840 - val_accuracy: 0.9745\n",
      "Epoch 100/100\n",
      "455/455 [==============================] - 0s 125us/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0843 - val_accuracy: 0.9694\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a37c29710>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196/196 [==============================] - 0s 86us/step\n",
      "over-sampling test accuracy: 96.94%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over = model1_over.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 0, 1, 1, 0, 2, 1, 0, 0, 1, 2, 0, 0, 1, 0, 0, 1, 1, 1,\n",
       "       0, 1, 0, 2, 0, 0, 0, 2, 2, 0, 2, 0, 0, 0, 2, 2, 1, 2, 1, 0, 0, 0,\n",
       "       0, 1, 0, 1, 1, 1, 2, 2, 2, 1, 1, 1, 0, 1, 1, 1, 2, 0, 0, 2, 0, 1,\n",
       "       0, 1, 2, 0, 0, 1, 0, 2, 2, 1, 1, 2, 0, 1, 0, 0, 0, 1, 0, 1, 2, 1,\n",
       "       0, 0, 0, 1, 1, 2, 2, 2, 2, 2, 1, 1, 2, 0, 0, 0, 1, 2, 1, 0, 2, 1,\n",
       "       1, 1, 0, 2, 1, 2, 2, 1, 1, 2, 1, 2, 2, 2, 2, 1, 1, 0, 2, 1, 0, 0,\n",
       "       0, 2, 2, 1, 2, 0, 0, 0, 2, 1, 0, 2, 1, 0, 1, 2, 2, 1, 1, 2, 2, 2,\n",
       "       2, 2, 2, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 2, 0, 2, 1, 2, 2, 2,\n",
       "       1, 1, 2, 1, 0, 2, 1, 2, 2, 2, 2, 1, 2, 1, 0, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model1_over.predict_classes(X_test_over)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CFBRSa07</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CFBRSa66A</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS112</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS211</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CFBRSa22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>NRS205</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>196 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0  test  pred\n",
       "0     CFBRSa07     0     0\n",
       "1    CFBRSa66A     0     0\n",
       "2       NRS112     1     1\n",
       "3       NRS211     0     1\n",
       "4     CFBRSa22     0     0\n",
       "..         ...   ...   ...\n",
       "191     NRS148     2     2\n",
       "192     NRS255     2     2\n",
       "193     NRS205     2     2\n",
       "194     NRS255     2     2\n",
       "195     NRS109     2     2\n",
       "\n",
       "[196 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat['pred'] = pred\n",
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba1 = model1_over.predict_proba(X_test_over)\n",
    "dat_proba1 = pd.DataFrame(proba1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.986537</td>\n",
       "      <td>1.338227e-02</td>\n",
       "      <td>8.061646e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.343655e-07</td>\n",
       "      <td>1.434302e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001014</td>\n",
       "      <td>9.989378e-01</td>\n",
       "      <td>4.854937e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.359725</td>\n",
       "      <td>6.401317e-01</td>\n",
       "      <td>1.429325e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.995003</td>\n",
       "      <td>4.996928e-03</td>\n",
       "      <td>5.317322e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>0.000007</td>\n",
       "      <td>9.932064e-05</td>\n",
       "      <td>9.998934e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>0.000257</td>\n",
       "      <td>2.048159e-03</td>\n",
       "      <td>9.976944e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>0.000011</td>\n",
       "      <td>4.546218e-05</td>\n",
       "      <td>9.999435e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>0.000257</td>\n",
       "      <td>2.048159e-03</td>\n",
       "      <td>9.976944e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.000097</td>\n",
       "      <td>9.292744e-04</td>\n",
       "      <td>9.989737e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>196 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0             1             2\n",
       "0    0.986537  1.338227e-02  8.061646e-05\n",
       "1    1.000000  1.343655e-07  1.434302e-10\n",
       "2    0.001014  9.989378e-01  4.854937e-05\n",
       "3    0.359725  6.401317e-01  1.429325e-04\n",
       "4    0.995003  4.996928e-03  5.317322e-08\n",
       "..        ...           ...           ...\n",
       "191  0.000007  9.932064e-05  9.998934e-01\n",
       "192  0.000257  2.048159e-03  9.976944e-01\n",
       "193  0.000011  4.546218e-05  9.999435e-01\n",
       "194  0.000257  2.048159e-03  9.976944e-01\n",
       "195  0.000097  9.292744e-04  9.989737e-01\n",
       "\n",
       "[196 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba1.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba1.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/1pyopST.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 455 samples, validate on 196 samples\n",
      "Epoch 1/100\n",
      "455/455 [==============================] - 0s 160us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0754 - val_accuracy: 0.9745\n",
      "Epoch 2/100\n",
      "455/455 [==============================] - 0s 147us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0764 - val_accuracy: 0.9745\n",
      "Epoch 3/100\n",
      "455/455 [==============================] - 0s 156us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0784 - val_accuracy: 0.9745\n",
      "Epoch 4/100\n",
      "455/455 [==============================] - 0s 153us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0784 - val_accuracy: 0.9745\n",
      "Epoch 5/100\n",
      "455/455 [==============================] - 0s 148us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0750 - val_accuracy: 0.9745\n",
      "Epoch 6/100\n",
      "455/455 [==============================] - 0s 143us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0760 - val_accuracy: 0.9745\n",
      "Epoch 7/100\n",
      "455/455 [==============================] - 0s 155us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0770 - val_accuracy: 0.9745\n",
      "Epoch 8/100\n",
      "455/455 [==============================] - 0s 156us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0762 - val_accuracy: 0.9745\n",
      "Epoch 9/100\n",
      "455/455 [==============================] - 0s 188us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0768 - val_accuracy: 0.9745\n",
      "Epoch 10/100\n",
      "455/455 [==============================] - 0s 171us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0776 - val_accuracy: 0.9745\n",
      "Epoch 11/100\n",
      "455/455 [==============================] - 0s 165us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0787 - val_accuracy: 0.9745\n",
      "Epoch 12/100\n",
      "455/455 [==============================] - 0s 156us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0765 - val_accuracy: 0.9745\n",
      "Epoch 13/100\n",
      "455/455 [==============================] - 0s 168us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0787 - val_accuracy: 0.9745\n",
      "Epoch 14/100\n",
      "455/455 [==============================] - 0s 182us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0768 - val_accuracy: 0.9745\n",
      "Epoch 15/100\n",
      "455/455 [==============================] - 0s 247us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0791 - val_accuracy: 0.9745\n",
      "Epoch 16/100\n",
      "455/455 [==============================] - 0s 619us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0805 - val_accuracy: 0.9745\n",
      "Epoch 17/100\n",
      "455/455 [==============================] - 0s 287us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0798 - val_accuracy: 0.9745\n",
      "Epoch 18/100\n",
      "455/455 [==============================] - 0s 265us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0801 - val_accuracy: 0.9745\n",
      "Epoch 19/100\n",
      "455/455 [==============================] - 0s 332us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0794 - val_accuracy: 0.9745\n",
      "Epoch 20/100\n",
      "455/455 [==============================] - 0s 187us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0786 - val_accuracy: 0.9745\n",
      "Epoch 21/100\n",
      "455/455 [==============================] - 0s 150us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0783 - val_accuracy: 0.9745\n",
      "Epoch 22/100\n",
      "455/455 [==============================] - 0s 140us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0805 - val_accuracy: 0.9694\n",
      "Epoch 23/100\n",
      "455/455 [==============================] - 0s 119us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0788 - val_accuracy: 0.9745\n",
      "Epoch 24/100\n",
      "455/455 [==============================] - 0s 123us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0803 - val_accuracy: 0.9745\n",
      "Epoch 25/100\n",
      "455/455 [==============================] - 0s 132us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0806 - val_accuracy: 0.9745\n",
      "Epoch 26/100\n",
      "455/455 [==============================] - 0s 138us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0820 - val_accuracy: 0.9745\n",
      "Epoch 27/100\n",
      "455/455 [==============================] - 0s 146us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0803 - val_accuracy: 0.9745\n",
      "Epoch 28/100\n",
      "455/455 [==============================] - 0s 135us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0809 - val_accuracy: 0.9745\n",
      "Epoch 29/100\n",
      "455/455 [==============================] - 0s 133us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0800 - val_accuracy: 0.9745\n",
      "Epoch 30/100\n",
      "455/455 [==============================] - 0s 150us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0818 - val_accuracy: 0.9745\n",
      "Epoch 31/100\n",
      "455/455 [==============================] - 0s 146us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0819 - val_accuracy: 0.9745\n",
      "Epoch 32/100\n",
      "455/455 [==============================] - 0s 145us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0826 - val_accuracy: 0.9745\n",
      "Epoch 33/100\n",
      "455/455 [==============================] - 0s 132us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0839 - val_accuracy: 0.9745\n",
      "Epoch 34/100\n",
      "455/455 [==============================] - 0s 142us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0825 - val_accuracy: 0.9745\n",
      "Epoch 35/100\n",
      "455/455 [==============================] - 0s 148us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0810 - val_accuracy: 0.9745\n",
      "Epoch 36/100\n",
      "455/455 [==============================] - 0s 154us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0814 - val_accuracy: 0.9745\n",
      "Epoch 37/100\n",
      "455/455 [==============================] - 0s 132us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0830 - val_accuracy: 0.9745\n",
      "Epoch 38/100\n",
      "455/455 [==============================] - 0s 123us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0829 - val_accuracy: 0.9745\n",
      "Epoch 39/100\n",
      "455/455 [==============================] - 0s 120us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0823 - val_accuracy: 0.9745\n",
      "Epoch 40/100\n",
      "455/455 [==============================] - 0s 111us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0837 - val_accuracy: 0.9745\n",
      "Epoch 41/100\n",
      "455/455 [==============================] - 0s 118us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0837 - val_accuracy: 0.9745\n",
      "Epoch 42/100\n",
      "455/455 [==============================] - 0s 119us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0840 - val_accuracy: 0.9745\n",
      "Epoch 43/100\n",
      "455/455 [==============================] - 0s 113us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0851 - val_accuracy: 0.9745\n",
      "Epoch 44/100\n",
      "455/455 [==============================] - 0s 115us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0843 - val_accuracy: 0.9745\n",
      "Epoch 45/100\n",
      "455/455 [==============================] - 0s 117us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0840 - val_accuracy: 0.9745\n",
      "Epoch 46/100\n",
      "455/455 [==============================] - 0s 117us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0849 - val_accuracy: 0.9745\n",
      "Epoch 47/100\n",
      "455/455 [==============================] - 0s 117us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0837 - val_accuracy: 0.9745\n",
      "Epoch 48/100\n",
      "455/455 [==============================] - 0s 116us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0877 - val_accuracy: 0.9745\n",
      "Epoch 49/100\n",
      "455/455 [==============================] - 0s 116us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0859 - val_accuracy: 0.9745\n",
      "Epoch 50/100\n",
      "455/455 [==============================] - 0s 118us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0841 - val_accuracy: 0.9745\n",
      "Epoch 51/100\n",
      "455/455 [==============================] - 0s 118us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0874 - val_accuracy: 0.9745\n",
      "Epoch 52/100\n",
      "455/455 [==============================] - 0s 113us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0864 - val_accuracy: 0.9745\n",
      "Epoch 53/100\n",
      "455/455 [==============================] - 0s 107us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0869 - val_accuracy: 0.9745\n",
      "Epoch 54/100\n",
      "455/455 [==============================] - 0s 107us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0863 - val_accuracy: 0.9745\n",
      "Epoch 55/100\n",
      "455/455 [==============================] - 0s 105us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0866 - val_accuracy: 0.9745\n",
      "Epoch 56/100\n",
      "455/455 [==============================] - 0s 108us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0845 - val_accuracy: 0.9745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "455/455 [==============================] - 0s 122us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0852 - val_accuracy: 0.9694\n",
      "Epoch 58/100\n",
      "455/455 [==============================] - 0s 111us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0867 - val_accuracy: 0.9694\n",
      "Epoch 59/100\n",
      "455/455 [==============================] - 0s 99us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0864 - val_accuracy: 0.9694\n",
      "Epoch 60/100\n",
      "455/455 [==============================] - 0s 101us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0868 - val_accuracy: 0.9694\n",
      "Epoch 61/100\n",
      "455/455 [==============================] - 0s 105us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0878 - val_accuracy: 0.9694\n",
      "Epoch 62/100\n",
      "455/455 [==============================] - 0s 98us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0878 - val_accuracy: 0.9694\n",
      "Epoch 63/100\n",
      "455/455 [==============================] - 0s 93us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0884 - val_accuracy: 0.9694\n",
      "Epoch 64/100\n",
      "455/455 [==============================] - 0s 101us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0878 - val_accuracy: 0.9694\n",
      "Epoch 65/100\n",
      "455/455 [==============================] - 0s 101us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0879 - val_accuracy: 0.9694\n",
      "Epoch 66/100\n",
      "455/455 [==============================] - 0s 97us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0884 - val_accuracy: 0.9694\n",
      "Epoch 67/100\n",
      "455/455 [==============================] - 0s 93us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0888 - val_accuracy: 0.9694\n",
      "Epoch 68/100\n",
      "455/455 [==============================] - 0s 92us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0883 - val_accuracy: 0.9694\n",
      "Epoch 69/100\n",
      "455/455 [==============================] - 0s 92us/step - loss: 9.9582e-04 - accuracy: 1.0000 - val_loss: 0.0887 - val_accuracy: 0.9694\n",
      "Epoch 70/100\n",
      "455/455 [==============================] - 0s 93us/step - loss: 9.8057e-04 - accuracy: 1.0000 - val_loss: 0.0896 - val_accuracy: 0.9694\n",
      "Epoch 71/100\n",
      "455/455 [==============================] - 0s 96us/step - loss: 9.6296e-04 - accuracy: 1.0000 - val_loss: 0.0893 - val_accuracy: 0.9694\n",
      "Epoch 72/100\n",
      "455/455 [==============================] - 0s 177us/step - loss: 9.5342e-04 - accuracy: 1.0000 - val_loss: 0.0883 - val_accuracy: 0.9694\n",
      "Epoch 73/100\n",
      "455/455 [==============================] - 0s 113us/step - loss: 9.3910e-04 - accuracy: 1.0000 - val_loss: 0.0880 - val_accuracy: 0.9694\n",
      "Epoch 74/100\n",
      "455/455 [==============================] - 0s 148us/step - loss: 9.3508e-04 - accuracy: 1.0000 - val_loss: 0.0905 - val_accuracy: 0.9694\n",
      "Epoch 75/100\n",
      "455/455 [==============================] - 0s 196us/step - loss: 9.1490e-04 - accuracy: 1.0000 - val_loss: 0.0911 - val_accuracy: 0.9694\n",
      "Epoch 76/100\n",
      "455/455 [==============================] - 0s 458us/step - loss: 8.9930e-04 - accuracy: 1.0000 - val_loss: 0.0902 - val_accuracy: 0.9694\n",
      "Epoch 77/100\n",
      "455/455 [==============================] - 0s 199us/step - loss: 9.3153e-04 - accuracy: 1.0000 - val_loss: 0.0894 - val_accuracy: 0.9694\n",
      "Epoch 78/100\n",
      "455/455 [==============================] - 0s 226us/step - loss: 8.8321e-04 - accuracy: 1.0000 - val_loss: 0.0915 - val_accuracy: 0.9694\n",
      "Epoch 79/100\n",
      "455/455 [==============================] - 0s 187us/step - loss: 8.8178e-04 - accuracy: 1.0000 - val_loss: 0.0903 - val_accuracy: 0.9694\n",
      "Epoch 80/100\n",
      "455/455 [==============================] - 0s 177us/step - loss: 8.5423e-04 - accuracy: 1.0000 - val_loss: 0.0908 - val_accuracy: 0.9694\n",
      "Epoch 81/100\n",
      "455/455 [==============================] - 0s 171us/step - loss: 8.3917e-04 - accuracy: 1.0000 - val_loss: 0.0902 - val_accuracy: 0.9694\n",
      "Epoch 82/100\n",
      "455/455 [==============================] - 0s 301us/step - loss: 8.2748e-04 - accuracy: 1.0000 - val_loss: 0.0911 - val_accuracy: 0.9694\n",
      "Epoch 83/100\n",
      "455/455 [==============================] - 0s 200us/step - loss: 8.1550e-04 - accuracy: 1.0000 - val_loss: 0.0906 - val_accuracy: 0.9694\n",
      "Epoch 84/100\n",
      "455/455 [==============================] - 0s 228us/step - loss: 7.9916e-04 - accuracy: 1.0000 - val_loss: 0.0908 - val_accuracy: 0.9694\n",
      "Epoch 85/100\n",
      "455/455 [==============================] - 0s 163us/step - loss: 7.9951e-04 - accuracy: 1.0000 - val_loss: 0.0905 - val_accuracy: 0.9694\n",
      "Epoch 86/100\n",
      "455/455 [==============================] - 0s 193us/step - loss: 7.8009e-04 - accuracy: 1.0000 - val_loss: 0.0893 - val_accuracy: 0.9694\n",
      "Epoch 87/100\n",
      "455/455 [==============================] - 0s 209us/step - loss: 7.8436e-04 - accuracy: 1.0000 - val_loss: 0.0897 - val_accuracy: 0.9694\n",
      "Epoch 88/100\n",
      "455/455 [==============================] - ETA: 0s - loss: 7.7247e-04 - accuracy: 1.00 - 0s 189us/step - loss: 7.6341e-04 - accuracy: 1.0000 - val_loss: 0.0919 - val_accuracy: 0.9694\n",
      "Epoch 89/100\n",
      "455/455 [==============================] - 0s 262us/step - loss: 7.4997e-04 - accuracy: 1.0000 - val_loss: 0.0925 - val_accuracy: 0.9694\n",
      "Epoch 90/100\n",
      "455/455 [==============================] - 0s 216us/step - loss: 7.4228e-04 - accuracy: 1.0000 - val_loss: 0.0927 - val_accuracy: 0.9694\n",
      "Epoch 91/100\n",
      "455/455 [==============================] - 0s 152us/step - loss: 7.5145e-04 - accuracy: 1.0000 - val_loss: 0.0915 - val_accuracy: 0.9694\n",
      "Epoch 92/100\n",
      "455/455 [==============================] - 0s 178us/step - loss: 7.2592e-04 - accuracy: 1.0000 - val_loss: 0.0929 - val_accuracy: 0.9694\n",
      "Epoch 93/100\n",
      "455/455 [==============================] - 0s 235us/step - loss: 7.1514e-04 - accuracy: 1.0000 - val_loss: 0.0906 - val_accuracy: 0.9694\n",
      "Epoch 94/100\n",
      "455/455 [==============================] - 0s 222us/step - loss: 7.0965e-04 - accuracy: 1.0000 - val_loss: 0.0903 - val_accuracy: 0.9694\n",
      "Epoch 95/100\n",
      "455/455 [==============================] - 0s 231us/step - loss: 6.9197e-04 - accuracy: 1.0000 - val_loss: 0.0919 - val_accuracy: 0.9694\n",
      "Epoch 96/100\n",
      "455/455 [==============================] - 0s 221us/step - loss: 6.8682e-04 - accuracy: 1.0000 - val_loss: 0.0922 - val_accuracy: 0.9694\n",
      "Epoch 97/100\n",
      "455/455 [==============================] - 0s 227us/step - loss: 6.7322e-04 - accuracy: 1.0000 - val_loss: 0.0916 - val_accuracy: 0.9694\n",
      "Epoch 98/100\n",
      "455/455 [==============================] - 0s 250us/step - loss: 6.6919e-04 - accuracy: 1.0000 - val_loss: 0.0928 - val_accuracy: 0.9694\n",
      "Epoch 99/100\n",
      "455/455 [==============================] - 0s 174us/step - loss: 6.5450e-04 - accuracy: 1.0000 - val_loss: 0.0925 - val_accuracy: 0.9694\n",
      "Epoch 100/100\n",
      "455/455 [==============================] - 0s 184us/step - loss: 6.4810e-04 - accuracy: 1.0000 - val_loss: 0.0932 - val_accuracy: 0.9694\n"
     ]
    }
   ],
   "source": [
    "hist1_over = model1_over.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_2.xlsx\",\n",
    "                        sheet_name=0,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>CFBRSa26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.758914</td>\n",
       "      <td>0.241086</td>\n",
       "      <td>4.638713e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.005361</td>\n",
       "      <td>0.016236</td>\n",
       "      <td>9.784034e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS112</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.726623</td>\n",
       "      <td>0.273376</td>\n",
       "      <td>1.520979e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS216</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.138322</td>\n",
       "      <td>0.861665</td>\n",
       "      <td>1.334123e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS021</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.882176</td>\n",
       "      <td>0.117824</td>\n",
       "      <td>1.414530e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4279</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>9.998934e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4280</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.002048</td>\n",
       "      <td>9.976944e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4281</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS205</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>9.999435e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4282</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.002048</td>\n",
       "      <td>9.976944e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4283</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.000929</td>\n",
       "      <td>9.989737e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4284 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    phage    strain  phenotype  prediction         0  \\\n",
       "0      p002ykpresabs_qual  CFBRSa26          0           0  0.758914   \n",
       "1      p002ykpresabs_qual    NRS109          2           2  0.005361   \n",
       "2      p002ykpresabs_qual    NRS112          0           0  0.726623   \n",
       "3      p002ykpresabs_qual    NRS216          1           1  0.138322   \n",
       "4      p002ykpresabs_qual    NRS021          0           0  0.882176   \n",
       "...                   ...       ...        ...         ...       ...   \n",
       "4279  pyopresabsSTCC_qual    NRS148          2           2  0.000007   \n",
       "4280  pyopresabsSTCC_qual    NRS255          2           2  0.000257   \n",
       "4281  pyopresabsSTCC_qual    NRS205          2           2  0.000011   \n",
       "4282  pyopresabsSTCC_qual    NRS255          2           2  0.000257   \n",
       "4283  pyopresabsSTCC_qual    NRS109          2           2  0.000097   \n",
       "\n",
       "             1             2  \n",
       "0     0.241086  4.638713e-07  \n",
       "1     0.016236  9.784034e-01  \n",
       "2     0.273376  1.520979e-06  \n",
       "3     0.861665  1.334123e-05  \n",
       "4     0.117824  1.414530e-10  \n",
       "...        ...           ...  \n",
       "4279  0.000099  9.998934e-01  \n",
       "4280  0.002048  9.976944e-01  \n",
       "4281  0.000045  9.999435e-01  \n",
       "4282  0.002048  9.976944e-01  \n",
       "4283  0.000929  9.989737e-01  \n",
       "\n",
       "[4284 rows x 7 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.86537100e-01, 1.33822650e-02, 8.06164600e-05],\n",
       "       [9.99999900e-01, 1.34365450e-07, 1.43430180e-10],\n",
       "       [1.01362180e-03, 9.98937800e-01, 4.85493700e-05],\n",
       "       [3.59725400e-01, 6.40131700e-01, 1.42932490e-04],\n",
       "       [9.95003040e-01, 4.99692800e-03, 5.31732240e-08],\n",
       "       [1.07127470e-02, 9.89278300e-01, 8.93336600e-06],\n",
       "       [2.95426680e-02, 9.68566100e-01, 1.89115150e-03],\n",
       "       [9.84435700e-01, 1.55543980e-02, 9.91228350e-06],\n",
       "       [1.10352210e-05, 4.54621800e-05, 9.99943500e-01],\n",
       "       [1.13115260e-03, 9.98444860e-01, 4.23919760e-04],\n",
       "       [9.99902500e-01, 9.75163000e-05, 3.20035230e-08],\n",
       "       [9.99900940e-01, 9.90262050e-05, 1.43656520e-08],\n",
       "       [4.58405380e-04, 9.98622800e-01, 9.18754300e-04],\n",
       "       [1.10352210e-05, 4.54621800e-05, 9.99943500e-01],\n",
       "       [1.00000000e+00, 7.75336700e-13, 8.94346700e-12],\n",
       "       [9.99954100e-01, 4.58226820e-05, 1.34741680e-07],\n",
       "       [1.63219780e-03, 9.98350260e-01, 1.76124690e-05],\n",
       "       [9.97122700e-01, 2.87675110e-03, 4.77795370e-07],\n",
       "       [9.99355400e-01, 6.39422700e-04, 5.21529050e-06],\n",
       "       [4.58405380e-04, 9.98622800e-01, 9.18754300e-04],\n",
       "       [1.68762110e-04, 9.95440240e-01, 4.39098240e-03],\n",
       "       [2.07844820e-03, 9.97868300e-01, 5.31473050e-05],\n",
       "       [9.99999760e-01, 2.32789190e-07, 6.48709530e-09],\n",
       "       [1.99700430e-02, 9.80007770e-01, 2.21942560e-05],\n",
       "       [1.00000000e+00, 4.29934000e-08, 1.93996480e-08],\n",
       "       [2.57443370e-04, 2.04815930e-03, 9.97694430e-01],\n",
       "       [9.81081200e-01, 1.87025520e-02, 2.16281570e-04],\n",
       "       [9.99090900e-01, 9.07870770e-04, 1.17273560e-06],\n",
       "       [9.99999400e-01, 5.76602700e-07, 2.21605530e-10],\n",
       "       [1.10352210e-05, 4.54621800e-05, 9.99943500e-01],\n",
       "       [2.57443370e-04, 2.04815930e-03, 9.97694430e-01],\n",
       "       [9.31055070e-01, 6.84417560e-02, 5.03067300e-04],\n",
       "       [1.10352210e-05, 4.54621800e-05, 9.99943500e-01],\n",
       "       [9.99902000e-01, 9.79841300e-05, 1.48995290e-10],\n",
       "       [9.99990100e-01, 9.93589000e-06, 3.68195800e-09],\n",
       "       [9.98332700e-01, 1.66693240e-03, 3.03544100e-07],\n",
       "       [9.70116500e-05, 9.29274400e-04, 9.98973700e-01],\n",
       "       [9.70116500e-05, 9.29274400e-04, 9.98973700e-01],\n",
       "       [2.12139330e-04, 9.99739600e-01, 4.82545150e-05],\n",
       "       [9.70116500e-05, 9.29274400e-04, 9.98973700e-01],\n",
       "       [1.82946760e-03, 9.98145600e-01, 2.50215290e-05],\n",
       "       [9.99989400e-01, 9.95860300e-06, 6.11296850e-07],\n",
       "       [9.82234400e-01, 1.77276120e-02, 3.79075280e-05],\n",
       "       [9.99999170e-01, 8.35264360e-07, 7.03071600e-10],\n",
       "       [9.88760650e-01, 1.12320370e-02, 7.32680600e-06],\n",
       "       [1.09727860e-02, 9.88423300e-01, 6.04029800e-04],\n",
       "       [1.00000000e+00, 4.16426720e-15, 8.88402050e-29],\n",
       "       [1.68762110e-04, 9.95440240e-01, 4.39098240e-03],\n",
       "       [4.55144820e-01, 5.44756000e-01, 9.92580100e-05],\n",
       "       [2.12139330e-04, 9.99739600e-01, 4.82545150e-05],\n",
       "       [9.70116500e-05, 9.29274400e-04, 9.98973700e-01],\n",
       "       [9.70116500e-05, 9.29274400e-04, 9.98973700e-01],\n",
       "       [7.24541360e-06, 9.93206400e-05, 9.99893400e-01],\n",
       "       [1.07127470e-02, 9.89278300e-01, 8.93336600e-06],\n",
       "       [1.66590460e-04, 9.99773100e-01, 6.03618830e-05],\n",
       "       [5.20469360e-02, 9.26453200e-01, 2.14998800e-02],\n",
       "       [9.99999900e-01, 1.17628060e-07, 1.83440650e-09],\n",
       "       [1.00845590e-02, 9.89904700e-01, 1.07433500e-05],\n",
       "       [1.99700430e-02, 9.80007770e-01, 2.21942560e-05],\n",
       "       [7.03184800e-05, 9.99878170e-01, 5.14969030e-05],\n",
       "       [2.57443370e-04, 2.04815930e-03, 9.97694430e-01],\n",
       "       [9.37028050e-01, 6.29562000e-02, 1.57571760e-05],\n",
       "       [9.99998100e-01, 1.86151060e-06, 1.96778430e-08],\n",
       "       [1.10352210e-05, 4.54621800e-05, 9.99943500e-01],\n",
       "       [8.32589500e-01, 1.65585400e-01, 1.82514470e-03],\n",
       "       [4.58405380e-04, 9.98622800e-01, 9.18754300e-04],\n",
       "       [9.99999640e-01, 3.15017500e-07, 1.92306460e-09],\n",
       "       [1.63219780e-03, 9.98350260e-01, 1.76124690e-05],\n",
       "       [7.24541360e-06, 9.93206400e-05, 9.99893400e-01],\n",
       "       [9.99882000e-01, 1.17990170e-04, 1.06696220e-08],\n",
       "       [1.00000000e+00, 2.62785780e-12, 1.49095960e-11],\n",
       "       [1.63219780e-03, 9.98350260e-01, 1.76124690e-05],\n",
       "       [9.99961400e-01, 3.82086840e-05, 3.04758120e-07],\n",
       "       [9.70116500e-05, 9.29274400e-04, 9.98973700e-01],\n",
       "       [9.70116500e-05, 9.29274400e-04, 9.98973700e-01],\n",
       "       [2.95426680e-02, 9.68566100e-01, 1.89115150e-03],\n",
       "       [1.01362180e-03, 9.98937800e-01, 4.85493700e-05],\n",
       "       [9.70116500e-05, 9.29274400e-04, 9.98973700e-01],\n",
       "       [9.91940200e-01, 6.66317000e-03, 1.39657710e-03],\n",
       "       [4.58405380e-04, 9.98622800e-01, 9.18754300e-04],\n",
       "       [9.97343960e-01, 2.65607200e-03, 1.41671930e-08],\n",
       "       [9.93581530e-01, 6.41725300e-03, 1.18793810e-06],\n",
       "       [9.37518060e-01, 6.24258030e-02, 5.61226080e-05],\n",
       "       [1.13115260e-03, 9.98444860e-01, 4.23919760e-04],\n",
       "       [9.99801460e-01, 1.94493300e-04, 4.04948900e-06],\n",
       "       [2.20391780e-03, 9.94537800e-01, 3.25838480e-03],\n",
       "       [9.70116500e-05, 9.29274400e-04, 9.98973700e-01],\n",
       "       [2.07844820e-03, 9.97868300e-01, 5.31473050e-05],\n",
       "       [9.99975700e-01, 2.43272770e-05, 2.01989410e-08],\n",
       "       [9.99917750e-01, 8.22335640e-05, 1.90397030e-08],\n",
       "       [9.99970800e-01, 2.91873000e-05, 2.81269370e-08],\n",
       "       [1.63219780e-03, 9.98350260e-01, 1.76124690e-05],\n",
       "       [1.82946760e-03, 9.98145600e-01, 2.50215290e-05],\n",
       "       [2.57443370e-04, 2.04815930e-03, 9.97694430e-01],\n",
       "       [9.70116500e-05, 9.29274400e-04, 9.98973700e-01],\n",
       "       [1.10352210e-05, 4.54621800e-05, 9.99943500e-01],\n",
       "       [9.70116500e-05, 9.29274400e-04, 9.98973700e-01],\n",
       "       [7.24541360e-06, 9.93206400e-05, 9.99893400e-01],\n",
       "       [2.20391780e-03, 9.94537800e-01, 3.25838480e-03],\n",
       "       [1.45733050e-05, 9.99430840e-01, 5.54564000e-04],\n",
       "       [2.57443370e-04, 2.04815930e-03, 9.97694430e-01],\n",
       "       [9.98863200e-01, 1.13649990e-03, 2.31319650e-07],\n",
       "       [9.99691000e-01, 3.05258150e-04, 3.87260100e-06],\n",
       "       [9.92501400e-01, 7.49575250e-03, 2.83541660e-06],\n",
       "       [7.03184800e-05, 9.99878170e-01, 5.14969030e-05],\n",
       "       [7.24541360e-06, 9.93206400e-05, 9.99893400e-01],\n",
       "       [3.18581080e-03, 9.96770140e-01, 4.40707660e-05],\n",
       "       [9.99900800e-01, 9.90805100e-05, 1.75539650e-07],\n",
       "       [2.57443370e-04, 2.04815930e-03, 9.97694430e-01],\n",
       "       [2.23911410e-03, 9.97369500e-01, 3.91321900e-04],\n",
       "       [1.23215720e-01, 8.76732050e-01, 5.22690930e-05],\n",
       "       [4.51632670e-07, 9.99505900e-01, 4.93654860e-04],\n",
       "       [9.78532850e-01, 2.09771450e-02, 4.90084500e-04],\n",
       "       [9.70116500e-05, 9.29274400e-04, 9.98973700e-01],\n",
       "       [7.03184800e-05, 9.99878170e-01, 5.14969030e-05],\n",
       "       [7.24541360e-06, 9.93206400e-05, 9.99893400e-01],\n",
       "       [9.70116500e-05, 9.29274400e-04, 9.98973700e-01],\n",
       "       [4.61537940e-04, 9.98810500e-01, 7.27946750e-04],\n",
       "       [4.58405380e-04, 9.98622800e-01, 9.18754300e-04],\n",
       "       [9.70116500e-05, 9.29274400e-04, 9.98973700e-01],\n",
       "       [1.13115260e-03, 9.98444860e-01, 4.23919760e-04],\n",
       "       [2.57443370e-04, 2.04815930e-03, 9.97694430e-01],\n",
       "       [1.10352210e-05, 4.54621800e-05, 9.99943500e-01],\n",
       "       [1.10352210e-05, 4.54621800e-05, 9.99943500e-01],\n",
       "       [2.57443370e-04, 2.04815930e-03, 9.97694430e-01],\n",
       "       [1.63219780e-03, 9.98350260e-01, 1.76124690e-05],\n",
       "       [1.07127470e-02, 9.89278300e-01, 8.93336600e-06],\n",
       "       [9.98555960e-01, 1.44160770e-03, 2.33744120e-06],\n",
       "       [7.24541360e-06, 9.93206400e-05, 9.99893400e-01],\n",
       "       [8.01930200e-04, 9.98928700e-01, 2.69347770e-04],\n",
       "       [9.98290960e-01, 1.70461980e-03, 4.45414340e-06],\n",
       "       [9.36923000e-01, 6.30674700e-02, 9.47061200e-06],\n",
       "       [9.99424800e-01, 5.75255900e-04, 5.00526000e-08],\n",
       "       [7.24541360e-06, 9.93206400e-05, 9.99893400e-01],\n",
       "       [1.10352210e-05, 4.54621800e-05, 9.99943500e-01],\n",
       "       [4.55964950e-02, 9.54353500e-01, 4.99336100e-05],\n",
       "       [9.70116500e-05, 9.29274400e-04, 9.98973700e-01],\n",
       "       [9.99771650e-01, 2.28250800e-04, 1.06765110e-07],\n",
       "       [9.99994640e-01, 5.38226600e-06, 2.64619600e-09],\n",
       "       [9.95493530e-01, 4.50430400e-03, 2.09387870e-06],\n",
       "       [7.24541360e-06, 9.93206400e-05, 9.99893400e-01],\n",
       "       [8.78365200e-03, 9.90822100e-01, 3.94288480e-04],\n",
       "       [9.99377550e-01, 6.22290600e-04, 2.69466850e-07],\n",
       "       [2.57443370e-04, 2.04815930e-03, 9.97694430e-01],\n",
       "       [8.78365200e-03, 9.90822100e-01, 3.94288480e-04],\n",
       "       [9.02401800e-01, 9.75905100e-02, 7.74736400e-06],\n",
       "       [6.10017600e-04, 9.99258940e-01, 1.30985340e-04],\n",
       "       [7.24541360e-06, 9.93206400e-05, 9.99893400e-01],\n",
       "       [2.57443370e-04, 2.04815930e-03, 9.97694430e-01],\n",
       "       [4.61537940e-04, 9.98810500e-01, 7.27946750e-04],\n",
       "       [4.11219600e-03, 9.95634730e-01, 2.53022940e-04],\n",
       "       [2.57443370e-04, 2.04815930e-03, 9.97694430e-01],\n",
       "       [2.57443370e-04, 2.04815930e-03, 9.97694430e-01],\n",
       "       [7.24541360e-06, 9.93206400e-05, 9.99893400e-01],\n",
       "       [1.10352210e-05, 4.54621800e-05, 9.99943500e-01],\n",
       "       [2.57443370e-04, 2.04815930e-03, 9.97694430e-01],\n",
       "       [9.70116500e-05, 9.29274400e-04, 9.98973700e-01],\n",
       "       [2.95426680e-02, 9.68566100e-01, 1.89115150e-03],\n",
       "       [1.00000000e+00, 4.98503640e-09, 7.82710730e-10],\n",
       "       [4.61537940e-04, 9.98810500e-01, 7.27946750e-04],\n",
       "       [3.48383960e-03, 9.96512830e-01, 3.38352380e-06],\n",
       "       [2.23911410e-03, 9.97369500e-01, 3.91321900e-04],\n",
       "       [1.09727860e-02, 9.88423300e-01, 6.04029800e-04],\n",
       "       [1.63219780e-03, 9.98350260e-01, 1.76124690e-05],\n",
       "       [1.88628440e-05, 9.99974600e-01, 6.58887000e-06],\n",
       "       [1.30719900e-03, 9.98675400e-01, 1.74194070e-05],\n",
       "       [1.01362180e-03, 9.98937800e-01, 4.85493700e-05],\n",
       "       [1.00000000e+00, 2.47885170e-14, 3.75730300e-12],\n",
       "       [4.61537940e-04, 9.98810500e-01, 7.27946750e-04],\n",
       "       [9.70116500e-05, 9.29274400e-04, 9.98973700e-01],\n",
       "       [9.85027300e-01, 1.47295715e-02, 2.43078260e-04],\n",
       "       [7.24541360e-06, 9.93206400e-05, 9.99893400e-01],\n",
       "       [4.51632670e-07, 9.99505900e-01, 4.93654860e-04],\n",
       "       [7.24541360e-06, 9.93206400e-05, 9.99893400e-01],\n",
       "       [2.57443370e-04, 2.04815930e-03, 9.97694430e-01],\n",
       "       [7.24541360e-06, 9.93206400e-05, 9.99893400e-01],\n",
       "       [2.12139330e-04, 9.99739600e-01, 4.82545150e-05],\n",
       "       [1.13115260e-03, 9.98444860e-01, 4.23919760e-04],\n",
       "       [1.10352210e-05, 4.54621800e-05, 9.99943500e-01],\n",
       "       [1.09727860e-02, 9.88423300e-01, 6.04029800e-04],\n",
       "       [1.00000000e+00, 2.11394270e-14, 2.33185930e-12],\n",
       "       [1.10352210e-05, 4.54621800e-05, 9.99943500e-01],\n",
       "       [3.31915470e-03, 9.96404300e-01, 2.76539400e-04],\n",
       "       [1.10352210e-05, 4.54621800e-05, 9.99943500e-01],\n",
       "       [9.70116500e-05, 9.29274400e-04, 9.98973700e-01],\n",
       "       [7.24541360e-06, 9.93206400e-05, 9.99893400e-01],\n",
       "       [7.24541360e-06, 9.93206400e-05, 9.99893400e-01],\n",
       "       [1.01362180e-03, 9.98937800e-01, 4.85493700e-05],\n",
       "       [1.10352210e-05, 4.54621800e-05, 9.99943500e-01],\n",
       "       [4.51632670e-07, 9.99505900e-01, 4.93654860e-04],\n",
       "       [9.99999760e-01, 2.07333120e-07, 3.71336240e-10],\n",
       "       [7.24541360e-06, 9.93206400e-05, 9.99893400e-01],\n",
       "       [2.57443370e-04, 2.04815930e-03, 9.97694430e-01],\n",
       "       [1.10352210e-05, 4.54621800e-05, 9.99943500e-01],\n",
       "       [2.57443370e-04, 2.04815930e-03, 9.97694430e-01],\n",
       "       [9.70116500e-05, 9.29274400e-04, 9.98973700e-01]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob = df_proba[df_proba['phage']=='pyopresabsSTCC_qual'].iloc[:,-3:]\n",
    "y_prob = y_prob.to_numpy()\n",
    "y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Retrieved from https://github.com/scikit-learn/scikit-learn/issues/3298\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "def rocauc_ovo(truth, pred, average=\"macro\", multi_class=\"ovo\"):\n",
    "\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(truth)\n",
    "\n",
    "    truth = lb.transform(truth)   \n",
    "    \n",
    "    return roc_auc_score(truth, pred, average=average, multi_class=multi_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9987473086709727"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo1 = rocauc_ovo(y_test_over, y_prob, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rocauc_ovr(truth, pred, average=\"macro\", multi_class=\"ovr\"):\n",
    "\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(truth)\n",
    "\n",
    "    truth = lb.transform(truth)   \n",
    "\n",
    "    return roc_auc_score(truth, pred, average=average, multi_class=multi_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9987473086709727"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr1 = rocauc_ovr(y_test_over, y_prob, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=234,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat2 = pd.DataFrame(X_test_over[:,0])\n",
    "dat2['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BCH-SA-04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS110</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS183</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BCH-SA-05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>NRS112</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>SR1065</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>NRS203</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>CFBREBSa129</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>CFBRSa25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>196 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test\n",
       "0      BCH-SA-04     0\n",
       "1         NRS110     1\n",
       "2         NRS109     2\n",
       "3         NRS183     1\n",
       "4      BCH-SA-05     0\n",
       "..           ...   ...\n",
       "191       NRS112     1\n",
       "192       SR1065     0\n",
       "193       NRS203     0\n",
       "194  CFBREBSa129     0\n",
       "195     CFBRSa25     0\n",
       "\n",
       "[196 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over2 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],)),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over2.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 455 samples, validate on 196 samples\n",
      "Epoch 1/100\n",
      "455/455 [==============================] - 0s 386us/step - loss: 9.8579 - accuracy: 0.5538 - val_loss: 3.5862 - val_accuracy: 0.6071\n",
      "Epoch 2/100\n",
      "455/455 [==============================] - 0s 196us/step - loss: 3.0661 - accuracy: 0.5846 - val_loss: 1.5635 - val_accuracy: 0.4694\n",
      "Epoch 3/100\n",
      "455/455 [==============================] - 0s 183us/step - loss: 1.0319 - accuracy: 0.6176 - val_loss: 0.5851 - val_accuracy: 0.6684\n",
      "Epoch 4/100\n",
      "455/455 [==============================] - 0s 161us/step - loss: 0.4823 - accuracy: 0.7758 - val_loss: 0.4528 - val_accuracy: 0.8163\n",
      "Epoch 5/100\n",
      "455/455 [==============================] - 0s 200us/step - loss: 0.3625 - accuracy: 0.8659 - val_loss: 0.3674 - val_accuracy: 0.8265\n",
      "Epoch 6/100\n",
      "455/455 [==============================] - 0s 226us/step - loss: 0.3052 - accuracy: 0.9011 - val_loss: 0.3299 - val_accuracy: 0.8980\n",
      "Epoch 7/100\n",
      "455/455 [==============================] - 0s 182us/step - loss: 0.2749 - accuracy: 0.9297 - val_loss: 0.3036 - val_accuracy: 0.9031\n",
      "Epoch 8/100\n",
      "455/455 [==============================] - 0s 133us/step - loss: 0.2502 - accuracy: 0.9341 - val_loss: 0.2857 - val_accuracy: 0.9031\n",
      "Epoch 9/100\n",
      "455/455 [==============================] - 0s 142us/step - loss: 0.2269 - accuracy: 0.9385 - val_loss: 0.2671 - val_accuracy: 0.9082\n",
      "Epoch 10/100\n",
      "455/455 [==============================] - 0s 116us/step - loss: 0.2086 - accuracy: 0.9495 - val_loss: 0.2516 - val_accuracy: 0.9082\n",
      "Epoch 11/100\n",
      "455/455 [==============================] - 0s 188us/step - loss: 0.1902 - accuracy: 0.9560 - val_loss: 0.2339 - val_accuracy: 0.9184\n",
      "Epoch 12/100\n",
      "455/455 [==============================] - 0s 138us/step - loss: 0.1735 - accuracy: 0.9648 - val_loss: 0.2168 - val_accuracy: 0.9388\n",
      "Epoch 13/100\n",
      "455/455 [==============================] - 0s 126us/step - loss: 0.1625 - accuracy: 0.9802 - val_loss: 0.2118 - val_accuracy: 0.9286\n",
      "Epoch 14/100\n",
      "455/455 [==============================] - 0s 151us/step - loss: 0.1488 - accuracy: 0.9780 - val_loss: 0.1930 - val_accuracy: 0.9388\n",
      "Epoch 15/100\n",
      "455/455 [==============================] - 0s 140us/step - loss: 0.1413 - accuracy: 0.9736 - val_loss: 0.1868 - val_accuracy: 0.9388\n",
      "Epoch 16/100\n",
      "455/455 [==============================] - 0s 173us/step - loss: 0.1251 - accuracy: 0.9780 - val_loss: 0.1748 - val_accuracy: 0.9439\n",
      "Epoch 17/100\n",
      "455/455 [==============================] - 0s 145us/step - loss: 0.1152 - accuracy: 0.9824 - val_loss: 0.1700 - val_accuracy: 0.9439\n",
      "Epoch 18/100\n",
      "455/455 [==============================] - 0s 190us/step - loss: 0.1083 - accuracy: 0.9868 - val_loss: 0.1653 - val_accuracy: 0.9439\n",
      "Epoch 19/100\n",
      "455/455 [==============================] - 0s 149us/step - loss: 0.0997 - accuracy: 0.9780 - val_loss: 0.1594 - val_accuracy: 0.9439\n",
      "Epoch 20/100\n",
      "455/455 [==============================] - 0s 169us/step - loss: 0.0942 - accuracy: 0.9824 - val_loss: 0.1497 - val_accuracy: 0.9490\n",
      "Epoch 21/100\n",
      "455/455 [==============================] - 0s 154us/step - loss: 0.0867 - accuracy: 0.9824 - val_loss: 0.1470 - val_accuracy: 0.9439\n",
      "Epoch 22/100\n",
      "455/455 [==============================] - 0s 97us/step - loss: 0.0811 - accuracy: 0.9824 - val_loss: 0.1447 - val_accuracy: 0.9439\n",
      "Epoch 23/100\n",
      "455/455 [==============================] - 0s 107us/step - loss: 0.0762 - accuracy: 0.9890 - val_loss: 0.1389 - val_accuracy: 0.9439\n",
      "Epoch 24/100\n",
      "455/455 [==============================] - 0s 86us/step - loss: 0.0716 - accuracy: 0.9868 - val_loss: 0.1311 - val_accuracy: 0.9541\n",
      "Epoch 25/100\n",
      "455/455 [==============================] - 0s 105us/step - loss: 0.0693 - accuracy: 0.9824 - val_loss: 0.1255 - val_accuracy: 0.9592\n",
      "Epoch 26/100\n",
      "455/455 [==============================] - 0s 161us/step - loss: 0.0655 - accuracy: 0.9934 - val_loss: 0.1426 - val_accuracy: 0.9439\n",
      "Epoch 27/100\n",
      "455/455 [==============================] - 0s 477us/step - loss: 0.0629 - accuracy: 0.9824 - val_loss: 0.1215 - val_accuracy: 0.9592\n",
      "Epoch 28/100\n",
      "455/455 [==============================] - 0s 234us/step - loss: 0.0554 - accuracy: 0.9934 - val_loss: 0.1291 - val_accuracy: 0.9439\n",
      "Epoch 29/100\n",
      "455/455 [==============================] - 0s 220us/step - loss: 0.0535 - accuracy: 0.9890 - val_loss: 0.1199 - val_accuracy: 0.9592\n",
      "Epoch 30/100\n",
      "455/455 [==============================] - 0s 259us/step - loss: 0.0493 - accuracy: 0.9912 - val_loss: 0.1196 - val_accuracy: 0.9541\n",
      "Epoch 31/100\n",
      "455/455 [==============================] - 0s 237us/step - loss: 0.0467 - accuracy: 0.9934 - val_loss: 0.1162 - val_accuracy: 0.9541\n",
      "Epoch 32/100\n",
      "455/455 [==============================] - 0s 218us/step - loss: 0.0452 - accuracy: 0.9934 - val_loss: 0.1062 - val_accuracy: 0.9643\n",
      "Epoch 33/100\n",
      "455/455 [==============================] - 0s 169us/step - loss: 0.0427 - accuracy: 0.9978 - val_loss: 0.1164 - val_accuracy: 0.9490\n",
      "Epoch 34/100\n",
      "455/455 [==============================] - 0s 171us/step - loss: 0.0396 - accuracy: 0.9956 - val_loss: 0.1084 - val_accuracy: 0.9643\n",
      "Epoch 35/100\n",
      "455/455 [==============================] - 0s 293us/step - loss: 0.0374 - accuracy: 0.9956 - val_loss: 0.1049 - val_accuracy: 0.9592\n",
      "Epoch 36/100\n",
      "455/455 [==============================] - 0s 222us/step - loss: 0.0367 - accuracy: 1.0000 - val_loss: 0.1043 - val_accuracy: 0.9592\n",
      "Epoch 37/100\n",
      "455/455 [==============================] - 0s 287us/step - loss: 0.0341 - accuracy: 0.9978 - val_loss: 0.1039 - val_accuracy: 0.9643\n",
      "Epoch 38/100\n",
      "455/455 [==============================] - 0s 310us/step - loss: 0.0321 - accuracy: 0.9978 - val_loss: 0.1006 - val_accuracy: 0.9592\n",
      "Epoch 39/100\n",
      "455/455 [==============================] - 0s 265us/step - loss: 0.0309 - accuracy: 0.9956 - val_loss: 0.1036 - val_accuracy: 0.9592\n",
      "Epoch 40/100\n",
      "455/455 [==============================] - 0s 136us/step - loss: 0.0292 - accuracy: 1.0000 - val_loss: 0.0990 - val_accuracy: 0.9592\n",
      "Epoch 41/100\n",
      "455/455 [==============================] - 0s 102us/step - loss: 0.0281 - accuracy: 0.9978 - val_loss: 0.1024 - val_accuracy: 0.9643\n",
      "Epoch 42/100\n",
      "455/455 [==============================] - 0s 85us/step - loss: 0.0264 - accuracy: 1.0000 - val_loss: 0.0990 - val_accuracy: 0.9592\n",
      "Epoch 43/100\n",
      "455/455 [==============================] - 0s 89us/step - loss: 0.0252 - accuracy: 0.9978 - val_loss: 0.0951 - val_accuracy: 0.9643\n",
      "Epoch 44/100\n",
      "455/455 [==============================] - 0s 83us/step - loss: 0.0240 - accuracy: 1.0000 - val_loss: 0.0984 - val_accuracy: 0.9592\n",
      "Epoch 45/100\n",
      "455/455 [==============================] - 0s 90us/step - loss: 0.0234 - accuracy: 1.0000 - val_loss: 0.0937 - val_accuracy: 0.9592\n",
      "Epoch 46/100\n",
      "455/455 [==============================] - 0s 88us/step - loss: 0.0219 - accuracy: 1.0000 - val_loss: 0.0970 - val_accuracy: 0.9643\n",
      "Epoch 47/100\n",
      "455/455 [==============================] - 0s 96us/step - loss: 0.0216 - accuracy: 0.9978 - val_loss: 0.0974 - val_accuracy: 0.9592\n",
      "Epoch 48/100\n",
      "455/455 [==============================] - 0s 126us/step - loss: 0.0201 - accuracy: 1.0000 - val_loss: 0.0961 - val_accuracy: 0.9592\n",
      "Epoch 49/100\n",
      "455/455 [==============================] - 0s 158us/step - loss: 0.0193 - accuracy: 1.0000 - val_loss: 0.0972 - val_accuracy: 0.9592\n",
      "Epoch 50/100\n",
      "455/455 [==============================] - 0s 166us/step - loss: 0.0188 - accuracy: 1.0000 - val_loss: 0.0930 - val_accuracy: 0.9592\n",
      "Epoch 51/100\n",
      "455/455 [==============================] - 0s 202us/step - loss: 0.0181 - accuracy: 1.0000 - val_loss: 0.0943 - val_accuracy: 0.9643\n",
      "Epoch 52/100\n",
      "455/455 [==============================] - 0s 157us/step - loss: 0.0172 - accuracy: 1.0000 - val_loss: 0.0917 - val_accuracy: 0.9592\n",
      "Epoch 53/100\n",
      "455/455 [==============================] - 0s 133us/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 0.0881 - val_accuracy: 0.9643\n",
      "Epoch 54/100\n",
      "455/455 [==============================] - 0s 108us/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 0.0916 - val_accuracy: 0.9592\n",
      "Epoch 55/100\n",
      "455/455 [==============================] - 0s 90us/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 0.0907 - val_accuracy: 0.9643\n",
      "Epoch 56/100\n",
      "455/455 [==============================] - 0s 93us/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 0.0896 - val_accuracy: 0.9643\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "455/455 [==============================] - 0s 102us/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 0.0890 - val_accuracy: 0.9592\n",
      "Epoch 58/100\n",
      "455/455 [==============================] - 0s 150us/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 0.0912 - val_accuracy: 0.9643\n",
      "Epoch 59/100\n",
      "455/455 [==============================] - 0s 154us/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.0898 - val_accuracy: 0.9643\n",
      "Epoch 60/100\n",
      "455/455 [==============================] - 0s 109us/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 0.0898 - val_accuracy: 0.9643\n",
      "Epoch 61/100\n",
      "455/455 [==============================] - 0s 92us/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 0.0878 - val_accuracy: 0.9643\n",
      "Epoch 62/100\n",
      "455/455 [==============================] - 0s 91us/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.0884 - val_accuracy: 0.9643\n",
      "Epoch 63/100\n",
      "455/455 [==============================] - 0s 113us/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.0845 - val_accuracy: 0.9643\n",
      "Epoch 64/100\n",
      "455/455 [==============================] - 0s 141us/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 0.0877 - val_accuracy: 0.9643\n",
      "Epoch 65/100\n",
      "455/455 [==============================] - 0s 95us/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 0.0812 - val_accuracy: 0.9643\n",
      "Epoch 66/100\n",
      "455/455 [==============================] - 0s 91us/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.0886 - val_accuracy: 0.9643\n",
      "Epoch 67/100\n",
      "455/455 [==============================] - 0s 87us/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.0876 - val_accuracy: 0.9643\n",
      "Epoch 68/100\n",
      "455/455 [==============================] - 0s 92us/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.0890 - val_accuracy: 0.9643\n",
      "Epoch 69/100\n",
      "455/455 [==============================] - 0s 95us/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.0865 - val_accuracy: 0.9643\n",
      "Epoch 70/100\n",
      "455/455 [==============================] - 0s 89us/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.0868 - val_accuracy: 0.9643\n",
      "Epoch 71/100\n",
      "455/455 [==============================] - 0s 87us/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.0852 - val_accuracy: 0.9643\n",
      "Epoch 72/100\n",
      "455/455 [==============================] - 0s 86us/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.0863 - val_accuracy: 0.9643\n",
      "Epoch 73/100\n",
      "455/455 [==============================] - 0s 86us/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.0863 - val_accuracy: 0.9643\n",
      "Epoch 74/100\n",
      "455/455 [==============================] - 0s 84us/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.0845 - val_accuracy: 0.9643\n",
      "Epoch 75/100\n",
      "455/455 [==============================] - 0s 87us/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.0824 - val_accuracy: 0.9643\n",
      "Epoch 76/100\n",
      "455/455 [==============================] - 0s 117us/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.0898 - val_accuracy: 0.9643\n",
      "Epoch 77/100\n",
      "455/455 [==============================] - ETA: 0s - loss: 0.0128 - accuracy: 1.00 - 0s 135us/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.0852 - val_accuracy: 0.9643\n",
      "Epoch 78/100\n",
      "455/455 [==============================] - 0s 98us/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.0821 - val_accuracy: 0.9643\n",
      "Epoch 79/100\n",
      "455/455 [==============================] - 0s 89us/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.0870 - val_accuracy: 0.9643\n",
      "Epoch 80/100\n",
      "455/455 [==============================] - 0s 89us/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.0819 - val_accuracy: 0.9643\n",
      "Epoch 81/100\n",
      "455/455 [==============================] - 0s 88us/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.0824 - val_accuracy: 0.9643\n",
      "Epoch 82/100\n",
      "455/455 [==============================] - 0s 151us/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.0872 - val_accuracy: 0.9643\n",
      "Epoch 83/100\n",
      "455/455 [==============================] - 0s 116us/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.0814 - val_accuracy: 0.9643\n",
      "Epoch 84/100\n",
      "455/455 [==============================] - 0s 94us/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.0779 - val_accuracy: 0.9643\n",
      "Epoch 85/100\n",
      "455/455 [==============================] - 0s 93us/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0844 - val_accuracy: 0.9643\n",
      "Epoch 86/100\n",
      "455/455 [==============================] - 0s 88us/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0840 - val_accuracy: 0.9643\n",
      "Epoch 87/100\n",
      "455/455 [==============================] - 0s 88us/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0835 - val_accuracy: 0.9643\n",
      "Epoch 88/100\n",
      "455/455 [==============================] - 0s 91us/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0848 - val_accuracy: 0.9643\n",
      "Epoch 89/100\n",
      "455/455 [==============================] - 0s 135us/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0843 - val_accuracy: 0.9643\n",
      "Epoch 90/100\n",
      "455/455 [==============================] - 0s 109us/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0850 - val_accuracy: 0.9643\n",
      "Epoch 91/100\n",
      "455/455 [==============================] - 0s 90us/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0853 - val_accuracy: 0.9643\n",
      "Epoch 92/100\n",
      "455/455 [==============================] - 0s 88us/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0848 - val_accuracy: 0.9643\n",
      "Epoch 93/100\n",
      "455/455 [==============================] - 0s 108us/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0837 - val_accuracy: 0.9643\n",
      "Epoch 94/100\n",
      "455/455 [==============================] - 0s 147us/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0855 - val_accuracy: 0.9643\n",
      "Epoch 95/100\n",
      "455/455 [==============================] - 0s 234us/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0860 - val_accuracy: 0.9643\n",
      "Epoch 96/100\n",
      "455/455 [==============================] - 0s 157us/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0826 - val_accuracy: 0.9643\n",
      "Epoch 97/100\n",
      "455/455 [==============================] - 0s 186us/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0862 - val_accuracy: 0.9643\n",
      "Epoch 98/100\n",
      "455/455 [==============================] - 0s 191us/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0837 - val_accuracy: 0.9643\n",
      "Epoch 99/100\n",
      "455/455 [==============================] - 0s 172us/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0852 - val_accuracy: 0.9643\n",
      "Epoch 100/100\n",
      "455/455 [==============================] - 0s 126us/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0851 - val_accuracy: 0.9643\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x6345c80f0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over2.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196/196 [==============================] - 0s 103us/step\n",
      "over-sampling test accuracy: 95.92%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over2 = model1_over2.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over2*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 1, 0, 0, 2, 2, 2, 2, 1, 0, 1, 2, 0, 0, 2, 1, 2, 1, 2, 1,\n",
       "       2, 1, 0, 1, 0, 1, 2, 2, 2, 1, 1, 0, 0, 2, 0, 2, 1, 1, 1, 1, 1, 2,\n",
       "       1, 2, 1, 1, 2, 1, 2, 0, 1, 0, 0, 1, 2, 1, 0, 1, 2, 0, 1, 1, 1, 1,\n",
       "       0, 2, 1, 2, 1, 2, 2, 0, 0, 0, 0, 1, 0, 1, 2, 1, 0, 2, 0, 1, 1, 1,\n",
       "       2, 1, 1, 0, 0, 1, 0, 2, 0, 2, 0, 1, 2, 0, 2, 1, 0, 0, 1, 0, 2, 2,\n",
       "       0, 2, 0, 2, 1, 2, 1, 2, 1, 2, 1, 1, 2, 1, 0, 1, 2, 1, 1, 1, 2, 2,\n",
       "       0, 2, 0, 2, 2, 0, 1, 2, 0, 0, 1, 2, 2, 1, 1, 0, 0, 2, 2, 2, 1, 1,\n",
       "       0, 2, 1, 2, 1, 0, 2, 0, 2, 1, 1, 1, 2, 1, 2, 0, 1, 0, 1, 2, 0, 2,\n",
       "       1, 0, 0, 0, 0, 1, 2, 2, 1, 0, 2, 1, 2, 0, 2, 1, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred2 = model1_over2.predict_classes(X_test_over)\n",
    "pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BCH-SA-04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS110</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS183</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BCH-SA-05</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>NRS112</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>SR1065</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>NRS203</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>CFBREBSa129</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>CFBRSa25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>196 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test  pred\n",
       "0      BCH-SA-04     0     0\n",
       "1         NRS110     1     1\n",
       "2         NRS109     2     2\n",
       "3         NRS183     1     1\n",
       "4      BCH-SA-05     0     0\n",
       "..           ...   ...   ...\n",
       "191       NRS112     1     1\n",
       "192       SR1065     0     0\n",
       "193       NRS203     0     0\n",
       "194  CFBREBSa129     0     0\n",
       "195     CFBRSa25     0     0\n",
       "\n",
       "[196 rows x 3 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat2['pred'] = pred2\n",
    "dat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba2 = model1_over2.predict_proba(X_test_over)\n",
    "dat_proba2 = pd.DataFrame(proba2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.999988</td>\n",
       "      <td>1.336353e-06</td>\n",
       "      <td>1.056695e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000292</td>\n",
       "      <td>9.997064e-01</td>\n",
       "      <td>1.785696e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000946</td>\n",
       "      <td>1.060771e-03</td>\n",
       "      <td>9.979930e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.009562</td>\n",
       "      <td>9.864492e-01</td>\n",
       "      <td>3.988570e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.999714</td>\n",
       "      <td>2.849912e-04</td>\n",
       "      <td>6.624472e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>0.001860</td>\n",
       "      <td>9.979747e-01</td>\n",
       "      <td>1.653396e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>0.982940</td>\n",
       "      <td>1.705227e-02</td>\n",
       "      <td>7.349168e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>0.997093</td>\n",
       "      <td>1.962516e-03</td>\n",
       "      <td>9.441347e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.031141e-13</td>\n",
       "      <td>3.208205e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.999833</td>\n",
       "      <td>1.669456e-04</td>\n",
       "      <td>4.411099e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>196 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0             1             2\n",
       "0    0.999988  1.336353e-06  1.056695e-05\n",
       "1    0.000292  9.997064e-01  1.785696e-06\n",
       "2    0.000946  1.060771e-03  9.979930e-01\n",
       "3    0.009562  9.864492e-01  3.988570e-03\n",
       "4    0.999714  2.849912e-04  6.624472e-07\n",
       "..        ...           ...           ...\n",
       "191  0.001860  9.979747e-01  1.653396e-04\n",
       "192  0.982940  1.705227e-02  7.349168e-06\n",
       "193  0.997093  1.962516e-03  9.441347e-04\n",
       "194  1.000000  3.031141e-13  3.208205e-09\n",
       "195  0.999833  1.669456e-04  4.411099e-08\n",
       "\n",
       "[196 rows x 3 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba2.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba2.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat2.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/2pyopST.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 455 samples, validate on 196 samples\n",
      "Epoch 1/100\n",
      "455/455 [==============================] - 0s 201us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0864 - val_accuracy: 0.9592\n",
      "Epoch 2/100\n",
      "455/455 [==============================] - 0s 125us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0834 - val_accuracy: 0.9592\n",
      "Epoch 3/100\n",
      "455/455 [==============================] - 0s 119us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0849 - val_accuracy: 0.9592\n",
      "Epoch 4/100\n",
      "455/455 [==============================] - 0s 104us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0862 - val_accuracy: 0.9592\n",
      "Epoch 5/100\n",
      "455/455 [==============================] - 0s 114us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0842 - val_accuracy: 0.9592\n",
      "Epoch 6/100\n",
      "455/455 [==============================] - 0s 140us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0844 - val_accuracy: 0.9592\n",
      "Epoch 7/100\n",
      "455/455 [==============================] - 0s 95us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0873 - val_accuracy: 0.9592\n",
      "Epoch 8/100\n",
      "455/455 [==============================] - 0s 101us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0864 - val_accuracy: 0.9592\n",
      "Epoch 9/100\n",
      "455/455 [==============================] - 0s 105us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0820 - val_accuracy: 0.9592\n",
      "Epoch 10/100\n",
      "455/455 [==============================] - 0s 124us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0843 - val_accuracy: 0.9592\n",
      "Epoch 11/100\n",
      "455/455 [==============================] - 0s 149us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0879 - val_accuracy: 0.9592\n",
      "Epoch 12/100\n",
      "455/455 [==============================] - 0s 123us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0858 - val_accuracy: 0.9592\n",
      "Epoch 13/100\n",
      "455/455 [==============================] - 0s 101us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0856 - val_accuracy: 0.9592\n",
      "Epoch 14/100\n",
      "455/455 [==============================] - 0s 99us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0885 - val_accuracy: 0.9592\n",
      "Epoch 15/100\n",
      "455/455 [==============================] - 0s 113us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0832 - val_accuracy: 0.9592\n",
      "Epoch 16/100\n",
      "455/455 [==============================] - 0s 108us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0883 - val_accuracy: 0.9541\n",
      "Epoch 17/100\n",
      "455/455 [==============================] - 0s 112us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0868 - val_accuracy: 0.9592\n",
      "Epoch 18/100\n",
      "455/455 [==============================] - 0s 100us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0874 - val_accuracy: 0.9592\n",
      "Epoch 19/100\n",
      "455/455 [==============================] - 0s 119us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0894 - val_accuracy: 0.9541\n",
      "Epoch 20/100\n",
      "455/455 [==============================] - 0s 107us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0874 - val_accuracy: 0.9592\n",
      "Epoch 21/100\n",
      "455/455 [==============================] - 0s 137us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0862 - val_accuracy: 0.9592\n",
      "Epoch 22/100\n",
      "455/455 [==============================] - 0s 255us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0859 - val_accuracy: 0.9592\n",
      "Epoch 23/100\n",
      "455/455 [==============================] - 0s 208us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0883 - val_accuracy: 0.9592\n",
      "Epoch 24/100\n",
      "455/455 [==============================] - 0s 139us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0891 - val_accuracy: 0.9592\n",
      "Epoch 25/100\n",
      "455/455 [==============================] - 0s 130us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0870 - val_accuracy: 0.9592\n",
      "Epoch 26/100\n",
      "455/455 [==============================] - 0s 200us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0880 - val_accuracy: 0.9592\n",
      "Epoch 27/100\n",
      "455/455 [==============================] - 0s 211us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0883 - val_accuracy: 0.9592\n",
      "Epoch 28/100\n",
      "455/455 [==============================] - 0s 409us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0892 - val_accuracy: 0.9592\n",
      "Epoch 29/100\n",
      "455/455 [==============================] - 0s 634us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0892 - val_accuracy: 0.9592\n",
      "Epoch 30/100\n",
      "455/455 [==============================] - 0s 195us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0900 - val_accuracy: 0.9592\n",
      "Epoch 31/100\n",
      "455/455 [==============================] - 0s 366us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0884 - val_accuracy: 0.9592\n",
      "Epoch 32/100\n",
      "455/455 [==============================] - 0s 175us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0914 - val_accuracy: 0.9592\n",
      "Epoch 33/100\n",
      "455/455 [==============================] - 0s 220us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0897 - val_accuracy: 0.9592\n",
      "Epoch 34/100\n",
      "455/455 [==============================] - 0s 267us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0899 - val_accuracy: 0.9592\n",
      "Epoch 35/100\n",
      "455/455 [==============================] - 0s 304us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0924 - val_accuracy: 0.9592\n",
      "Epoch 36/100\n",
      "455/455 [==============================] - 0s 294us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0889 - val_accuracy: 0.9592\n",
      "Epoch 37/100\n",
      "455/455 [==============================] - 0s 234us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0898 - val_accuracy: 0.9592\n",
      "Epoch 38/100\n",
      "455/455 [==============================] - 0s 348us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0920 - val_accuracy: 0.9592\n",
      "Epoch 39/100\n",
      "455/455 [==============================] - 0s 661us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0893 - val_accuracy: 0.9592\n",
      "Epoch 40/100\n",
      "455/455 [==============================] - 0s 563us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0926 - val_accuracy: 0.9592\n",
      "Epoch 41/100\n",
      "455/455 [==============================] - 0s 283us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0907 - val_accuracy: 0.9592\n",
      "Epoch 42/100\n",
      "455/455 [==============================] - 0s 279us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0845 - val_accuracy: 0.9592\n",
      "Epoch 43/100\n",
      "455/455 [==============================] - 0s 202us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0936 - val_accuracy: 0.9592\n",
      "Epoch 44/100\n",
      "455/455 [==============================] - 0s 177us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0927 - val_accuracy: 0.9592\n",
      "Epoch 45/100\n",
      "455/455 [==============================] - 0s 206us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0912 - val_accuracy: 0.9592\n",
      "Epoch 46/100\n",
      "455/455 [==============================] - 0s 199us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0933 - val_accuracy: 0.9592\n",
      "Epoch 47/100\n",
      "455/455 [==============================] - 0s 177us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0909 - val_accuracy: 0.9592\n",
      "Epoch 48/100\n",
      "455/455 [==============================] - 0s 186us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0936 - val_accuracy: 0.9592\n",
      "Epoch 49/100\n",
      "455/455 [==============================] - 0s 152us/step - loss: 9.8555e-04 - accuracy: 1.0000 - val_loss: 0.0923 - val_accuracy: 0.9592\n",
      "Epoch 50/100\n",
      "455/455 [==============================] - 0s 179us/step - loss: 9.6652e-04 - accuracy: 1.0000 - val_loss: 0.0922 - val_accuracy: 0.9592\n",
      "Epoch 51/100\n",
      "455/455 [==============================] - 0s 210us/step - loss: 9.5404e-04 - accuracy: 1.0000 - val_loss: 0.0936 - val_accuracy: 0.9592\n",
      "Epoch 52/100\n",
      "455/455 [==============================] - 0s 153us/step - loss: 9.3683e-04 - accuracy: 1.0000 - val_loss: 0.0924 - val_accuracy: 0.9592\n",
      "Epoch 53/100\n",
      "455/455 [==============================] - 0s 146us/step - loss: 9.2762e-04 - accuracy: 1.0000 - val_loss: 0.0914 - val_accuracy: 0.9592\n",
      "Epoch 54/100\n",
      "455/455 [==============================] - 0s 406us/step - loss: 9.1448e-04 - accuracy: 1.0000 - val_loss: 0.0925 - val_accuracy: 0.9592\n",
      "Epoch 55/100\n",
      "455/455 [==============================] - 0s 182us/step - loss: 8.9949e-04 - accuracy: 1.0000 - val_loss: 0.0928 - val_accuracy: 0.9592\n",
      "Epoch 56/100\n",
      "455/455 [==============================] - 0s 230us/step - loss: 8.8975e-04 - accuracy: 1.0000 - val_loss: 0.0921 - val_accuracy: 0.9592\n",
      "Epoch 57/100\n",
      "455/455 [==============================] - 0s 352us/step - loss: 8.7320e-04 - accuracy: 1.0000 - val_loss: 0.0937 - val_accuracy: 0.9592\n",
      "Epoch 58/100\n",
      "455/455 [==============================] - 0s 252us/step - loss: 8.5892e-04 - accuracy: 1.0000 - val_loss: 0.0930 - val_accuracy: 0.9592\n",
      "Epoch 59/100\n",
      "455/455 [==============================] - 0s 155us/step - loss: 8.4411e-04 - accuracy: 1.0000 - val_loss: 0.0940 - val_accuracy: 0.9592\n",
      "Epoch 60/100\n",
      "455/455 [==============================] - 0s 198us/step - loss: 8.3258e-04 - accuracy: 1.0000 - val_loss: 0.0932 - val_accuracy: 0.9592\n",
      "Epoch 61/100\n",
      "455/455 [==============================] - 0s 276us/step - loss: 8.2222e-04 - accuracy: 1.0000 - val_loss: 0.0949 - val_accuracy: 0.9592\n",
      "Epoch 62/100\n",
      "455/455 [==============================] - 0s 238us/step - loss: 8.3183e-04 - accuracy: 1.0000 - val_loss: 0.0913 - val_accuracy: 0.9643\n",
      "Epoch 63/100\n",
      "455/455 [==============================] - 0s 162us/step - loss: 8.0277e-04 - accuracy: 1.0000 - val_loss: 0.0947 - val_accuracy: 0.9541\n",
      "Epoch 64/100\n",
      "455/455 [==============================] - 0s 168us/step - loss: 7.8861e-04 - accuracy: 1.0000 - val_loss: 0.0963 - val_accuracy: 0.9541\n",
      "Epoch 65/100\n",
      "455/455 [==============================] - 0s 155us/step - loss: 7.9708e-04 - accuracy: 1.0000 - val_loss: 0.0917 - val_accuracy: 0.9592\n",
      "Epoch 66/100\n",
      "455/455 [==============================] - 0s 159us/step - loss: 7.8427e-04 - accuracy: 1.0000 - val_loss: 0.0975 - val_accuracy: 0.9541\n",
      "Epoch 67/100\n",
      "455/455 [==============================] - 0s 191us/step - loss: 7.5316e-04 - accuracy: 1.0000 - val_loss: 0.0941 - val_accuracy: 0.9592\n",
      "Epoch 68/100\n",
      "455/455 [==============================] - 0s 156us/step - loss: 7.4050e-04 - accuracy: 1.0000 - val_loss: 0.0948 - val_accuracy: 0.9541\n",
      "Epoch 69/100\n",
      "455/455 [==============================] - 0s 154us/step - loss: 7.3055e-04 - accuracy: 1.0000 - val_loss: 0.0948 - val_accuracy: 0.9592\n",
      "Epoch 70/100\n",
      "455/455 [==============================] - 0s 164us/step - loss: 7.2506e-04 - accuracy: 1.0000 - val_loss: 0.0970 - val_accuracy: 0.9541\n",
      "Epoch 71/100\n",
      "455/455 [==============================] - 0s 162us/step - loss: 7.2275e-04 - accuracy: 1.0000 - val_loss: 0.0951 - val_accuracy: 0.9541\n",
      "Epoch 72/100\n",
      "455/455 [==============================] - 0s 177us/step - loss: 7.0933e-04 - accuracy: 1.0000 - val_loss: 0.0968 - val_accuracy: 0.9592\n",
      "Epoch 73/100\n",
      "455/455 [==============================] - 0s 162us/step - loss: 6.9354e-04 - accuracy: 1.0000 - val_loss: 0.0941 - val_accuracy: 0.9592\n",
      "Epoch 74/100\n",
      "455/455 [==============================] - 0s 198us/step - loss: 6.8205e-04 - accuracy: 1.0000 - val_loss: 0.0946 - val_accuracy: 0.9592\n",
      "Epoch 75/100\n",
      "455/455 [==============================] - 0s 206us/step - loss: 6.7128e-04 - accuracy: 1.0000 - val_loss: 0.0953 - val_accuracy: 0.9592\n",
      "Epoch 76/100\n",
      "455/455 [==============================] - 0s 183us/step - loss: 6.5563e-04 - accuracy: 1.0000 - val_loss: 0.0967 - val_accuracy: 0.9592\n",
      "Epoch 77/100\n",
      "455/455 [==============================] - 0s 132us/step - loss: 6.5758e-04 - accuracy: 1.0000 - val_loss: 0.0958 - val_accuracy: 0.9592\n",
      "Epoch 78/100\n",
      "455/455 [==============================] - 0s 165us/step - loss: 6.4318e-04 - accuracy: 1.0000 - val_loss: 0.0952 - val_accuracy: 0.9592\n",
      "Epoch 79/100\n",
      "455/455 [==============================] - 0s 173us/step - loss: 6.3773e-04 - accuracy: 1.0000 - val_loss: 0.0949 - val_accuracy: 0.9592\n",
      "Epoch 80/100\n",
      "455/455 [==============================] - 0s 192us/step - loss: 6.2543e-04 - accuracy: 1.0000 - val_loss: 0.0969 - val_accuracy: 0.9541\n",
      "Epoch 81/100\n",
      "455/455 [==============================] - 0s 259us/step - loss: 6.2290e-04 - accuracy: 1.0000 - val_loss: 0.0970 - val_accuracy: 0.9541\n",
      "Epoch 82/100\n",
      "455/455 [==============================] - 0s 202us/step - loss: 6.0979e-04 - accuracy: 1.0000 - val_loss: 0.0953 - val_accuracy: 0.9592\n",
      "Epoch 83/100\n",
      "455/455 [==============================] - 0s 148us/step - loss: 6.0130e-04 - accuracy: 1.0000 - val_loss: 0.0965 - val_accuracy: 0.9592\n",
      "Epoch 84/100\n",
      "455/455 [==============================] - 0s 163us/step - loss: 5.9469e-04 - accuracy: 1.0000 - val_loss: 0.0967 - val_accuracy: 0.9541\n",
      "Epoch 85/100\n",
      "455/455 [==============================] - 0s 151us/step - loss: 5.8554e-04 - accuracy: 1.0000 - val_loss: 0.0951 - val_accuracy: 0.9643\n",
      "Epoch 86/100\n",
      "455/455 [==============================] - 0s 188us/step - loss: 5.7661e-04 - accuracy: 1.0000 - val_loss: 0.0975 - val_accuracy: 0.9541\n",
      "Epoch 87/100\n",
      "455/455 [==============================] - 0s 174us/step - loss: 5.7324e-04 - accuracy: 1.0000 - val_loss: 0.0988 - val_accuracy: 0.9541\n",
      "Epoch 88/100\n",
      "455/455 [==============================] - 0s 185us/step - loss: 5.7370e-04 - accuracy: 1.0000 - val_loss: 0.0957 - val_accuracy: 0.9592\n",
      "Epoch 89/100\n",
      "455/455 [==============================] - 0s 178us/step - loss: 5.5745e-04 - accuracy: 1.0000 - val_loss: 0.0959 - val_accuracy: 0.9643\n",
      "Epoch 90/100\n",
      "455/455 [==============================] - 0s 277us/step - loss: 5.4468e-04 - accuracy: 1.0000 - val_loss: 0.0981 - val_accuracy: 0.9592\n",
      "Epoch 91/100\n",
      "455/455 [==============================] - 0s 279us/step - loss: 5.3993e-04 - accuracy: 1.0000 - val_loss: 0.0978 - val_accuracy: 0.9592\n",
      "Epoch 92/100\n",
      "455/455 [==============================] - 0s 211us/step - loss: 5.3887e-04 - accuracy: 1.0000 - val_loss: 0.0992 - val_accuracy: 0.9541\n",
      "Epoch 93/100\n",
      "455/455 [==============================] - 0s 191us/step - loss: 5.2118e-04 - accuracy: 1.0000 - val_loss: 0.0956 - val_accuracy: 0.9643\n",
      "Epoch 94/100\n",
      "455/455 [==============================] - 0s 239us/step - loss: 5.2210e-04 - accuracy: 1.0000 - val_loss: 0.0968 - val_accuracy: 0.9592\n",
      "Epoch 95/100\n",
      "455/455 [==============================] - 0s 220us/step - loss: 5.1334e-04 - accuracy: 1.0000 - val_loss: 0.0977 - val_accuracy: 0.9592\n",
      "Epoch 96/100\n",
      "455/455 [==============================] - 0s 260us/step - loss: 5.0784e-04 - accuracy: 1.0000 - val_loss: 0.0998 - val_accuracy: 0.9541\n",
      "Epoch 97/100\n",
      "455/455 [==============================] - 0s 197us/step - loss: 5.0024e-04 - accuracy: 1.0000 - val_loss: 0.0974 - val_accuracy: 0.9592\n",
      "Epoch 98/100\n",
      "455/455 [==============================] - 0s 143us/step - loss: 4.9709e-04 - accuracy: 1.0000 - val_loss: 0.0968 - val_accuracy: 0.9592\n",
      "Epoch 99/100\n",
      "455/455 [==============================] - 0s 164us/step - loss: 4.8686e-04 - accuracy: 1.0000 - val_loss: 0.0978 - val_accuracy: 0.9592\n",
      "Epoch 100/100\n",
      "455/455 [==============================] - 0s 157us/step - loss: 4.8057e-04 - accuracy: 1.0000 - val_loss: 0.0994 - val_accuracy: 0.9541\n"
     ]
    }
   ],
   "source": [
    "hist1_over2 = model1_over2.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over2.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba2 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_2.xlsx\",\n",
    "                        sheet_name=1,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>1.748042e-03</td>\n",
       "      <td>9.981960e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>BCH-SA-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.712007</td>\n",
       "      <td>2.879924e-01</td>\n",
       "      <td>9.646217e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS218</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.006222</td>\n",
       "      <td>9.937732e-01</td>\n",
       "      <td>4.482882e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS036</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.882617</td>\n",
       "      <td>1.173831e-01</td>\n",
       "      <td>2.310933e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS386</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.571179</td>\n",
       "      <td>4.288184e-01</td>\n",
       "      <td>2.444667e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4279</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS112</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001860</td>\n",
       "      <td>9.979747e-01</td>\n",
       "      <td>1.653396e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4280</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>SR1065</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.982940</td>\n",
       "      <td>1.705227e-02</td>\n",
       "      <td>7.349168e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4281</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS203</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.997093</td>\n",
       "      <td>1.962516e-03</td>\n",
       "      <td>9.441347e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4282</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>CFBREBSa129</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.031141e-13</td>\n",
       "      <td>3.208205e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4283</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>CFBRSa25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999833</td>\n",
       "      <td>1.669456e-04</td>\n",
       "      <td>4.411099e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4284 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    phage       strain  phenotype  prediction         0  \\\n",
       "0      p002ykpresabs_qual       NRS148          2           2  0.000056   \n",
       "1      p002ykpresabs_qual    BCH-SA-03          1           0  0.712007   \n",
       "2      p002ykpresabs_qual       NRS218          1           1  0.006222   \n",
       "3      p002ykpresabs_qual       NRS036          0           0  0.882617   \n",
       "4      p002ykpresabs_qual       NRS386          1           0  0.571179   \n",
       "...                   ...          ...        ...         ...       ...   \n",
       "4279  pyopresabsSTCC_qual       NRS112          1           1  0.001860   \n",
       "4280  pyopresabsSTCC_qual       SR1065          0           0  0.982940   \n",
       "4281  pyopresabsSTCC_qual       NRS203          0           0  0.997093   \n",
       "4282  pyopresabsSTCC_qual  CFBREBSa129          0           0  1.000000   \n",
       "4283  pyopresabsSTCC_qual     CFBRSa25          0           0  0.999833   \n",
       "\n",
       "                 1             2  \n",
       "0     1.748042e-03  9.981960e-01  \n",
       "1     2.879924e-01  9.646217e-07  \n",
       "2     9.937732e-01  4.482882e-06  \n",
       "3     1.173831e-01  2.310933e-10  \n",
       "4     4.288184e-01  2.444667e-06  \n",
       "...            ...           ...  \n",
       "4279  9.979747e-01  1.653396e-04  \n",
       "4280  1.705227e-02  7.349168e-06  \n",
       "4281  1.962516e-03  9.441347e-04  \n",
       "4282  3.031141e-13  3.208205e-09  \n",
       "4283  1.669456e-04  4.411099e-08  \n",
       "\n",
       "[4284 rows x 7 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.99988100e-01, 1.33635260e-06, 1.05669490e-05],\n",
       "       [2.91759530e-04, 9.99706450e-01, 1.78569590e-06],\n",
       "       [9.46207150e-04, 1.06077140e-03, 9.97993000e-01],\n",
       "       [9.56231000e-03, 9.86449200e-01, 3.98856960e-03],\n",
       "       [9.99714300e-01, 2.84991230e-04, 6.62447200e-07],\n",
       "       [9.99937800e-01, 6.13005000e-05, 9.53952400e-07],\n",
       "       [9.70995050e-04, 8.63280000e-04, 9.98165800e-01],\n",
       "       [7.19664100e-05, 3.08167000e-05, 9.99897240e-01],\n",
       "       [9.46207150e-04, 1.06077140e-03, 9.97993000e-01],\n",
       "       [8.08099650e-05, 9.67242900e-06, 9.99909500e-01],\n",
       "       [2.78682070e-04, 9.95044700e-01, 4.67671000e-03],\n",
       "       [9.67313000e-01, 3.26792560e-02, 7.68869000e-06],\n",
       "       [8.36012400e-03, 9.91557500e-01, 8.23392000e-05],\n",
       "       [9.46207150e-04, 1.06077140e-03, 9.97993000e-01],\n",
       "       [6.56932500e-01, 3.42625440e-01, 4.42099300e-04],\n",
       "       [9.77757160e-01, 2.21037600e-02, 1.39100290e-04],\n",
       "       [7.19664100e-05, 3.08167000e-05, 9.99897240e-01],\n",
       "       [2.78682070e-04, 9.95044700e-01, 4.67671000e-03],\n",
       "       [9.70995050e-04, 8.63280000e-04, 9.98165800e-01],\n",
       "       [1.00290940e-04, 9.98900530e-01, 9.99154800e-04],\n",
       "       [9.46207150e-04, 1.06077140e-03, 9.97993000e-01],\n",
       "       [1.42717050e-03, 9.98571040e-01, 1.78003800e-06],\n",
       "       [8.08099650e-05, 9.67242900e-06, 9.99909500e-01],\n",
       "       [1.45427260e-01, 8.54492800e-01, 7.99269550e-05],\n",
       "       [9.99583900e-01, 3.25331840e-04, 9.08569500e-05],\n",
       "       [2.60472200e-03, 9.97395300e-01, 2.25060370e-11],\n",
       "       [1.00000000e+00, 3.90187930e-14, 2.56825580e-09],\n",
       "       [9.56231000e-03, 9.86449200e-01, 3.98856960e-03],\n",
       "       [7.19664100e-05, 3.08167000e-05, 9.99897240e-01],\n",
       "       [8.08099650e-05, 9.67242900e-06, 9.99909500e-01],\n",
       "       [8.08099650e-05, 9.67242900e-06, 9.99909500e-01],\n",
       "       [1.03965970e-05, 9.99841100e-01, 1.48562290e-04],\n",
       "       [2.60472200e-03, 9.97395300e-01, 2.25060370e-11],\n",
       "       [9.99969600e-01, 3.04121900e-05, 6.90540000e-09],\n",
       "       [9.99999760e-01, 2.14690770e-07, 1.53319210e-09],\n",
       "       [8.08099650e-05, 9.67242900e-06, 9.99909500e-01],\n",
       "       [9.99999900e-01, 1.06943574e-07, 3.16869230e-10],\n",
       "       [8.08099650e-05, 9.67242900e-06, 9.99909500e-01],\n",
       "       [5.86127100e-03, 9.94136700e-01, 2.02450800e-06],\n",
       "       [2.69236900e-02, 9.42170860e-01, 3.09054400e-02],\n",
       "       [4.86388570e-03, 9.95135840e-01, 1.94268580e-07],\n",
       "       [4.47888700e-03, 9.94634600e-01, 8.86603600e-04],\n",
       "       [5.52525670e-06, 9.99813400e-01, 1.81170250e-04],\n",
       "       [7.19664100e-05, 3.08167000e-05, 9.99897240e-01],\n",
       "       [3.23667500e-02, 9.67632100e-01, 1.11830130e-06],\n",
       "       [9.46207150e-04, 1.06077140e-03, 9.97993000e-01],\n",
       "       [3.01734030e-01, 6.98259700e-01, 6.26886870e-06],\n",
       "       [2.43621260e-02, 9.75637260e-01, 5.66338600e-07],\n",
       "       [7.19664100e-05, 3.08167000e-05, 9.99897240e-01],\n",
       "       [3.78447000e-03, 9.95418670e-01, 7.96858600e-04],\n",
       "       [7.19664100e-05, 3.08167000e-05, 9.99897240e-01],\n",
       "       [1.00000000e+00, 1.41938350e-13, 3.50205690e-09],\n",
       "       [5.25682630e-05, 9.99832500e-01, 1.14859950e-04],\n",
       "       [9.72346370e-01, 2.67083890e-02, 9.45218400e-04],\n",
       "       [9.91851030e-01, 7.00828200e-03, 1.14061110e-03],\n",
       "       [1.03965970e-05, 9.99841100e-01, 1.48562290e-04],\n",
       "       [7.19664100e-05, 3.08167000e-05, 9.99897240e-01],\n",
       "       [4.86388570e-03, 9.95135840e-01, 1.94268580e-07],\n",
       "       [9.71936700e-01, 2.47631610e-02, 3.30018760e-03],\n",
       "       [4.87648000e-03, 9.95077100e-01, 4.65541530e-05],\n",
       "       [7.19664100e-05, 3.08167000e-05, 9.99897240e-01],\n",
       "       [9.99917400e-01, 8.26516550e-05, 1.03599490e-10],\n",
       "       [2.08486360e-03, 9.97808040e-01, 1.07029050e-04],\n",
       "       [3.23667500e-02, 9.67632100e-01, 1.11830130e-06],\n",
       "       [4.87648000e-03, 9.95077100e-01, 4.65541530e-05],\n",
       "       [1.52111170e-01, 8.47886440e-01, 2.32883300e-06],\n",
       "       [9.99329900e-01, 1.17203210e-04, 5.52875600e-04],\n",
       "       [7.19664100e-05, 3.08167000e-05, 9.99897240e-01],\n",
       "       [4.47888700e-03, 9.94634600e-01, 8.86603600e-04],\n",
       "       [8.08099650e-05, 9.67242900e-06, 9.99909500e-01],\n",
       "       [4.86388570e-03, 9.95135840e-01, 1.94268580e-07],\n",
       "       [9.70995050e-04, 8.63280000e-04, 9.98165800e-01],\n",
       "       [7.19664100e-05, 3.08167000e-05, 9.99897240e-01],\n",
       "       [9.45716260e-01, 5.39888850e-02, 2.94894270e-04],\n",
       "       [9.99999900e-01, 2.91086570e-08, 1.14896200e-07],\n",
       "       [9.99996900e-01, 3.06352290e-06, 5.95342100e-09],\n",
       "       [9.99999900e-01, 6.74716300e-08, 3.04408910e-10],\n",
       "       [4.86388570e-03, 9.95135840e-01, 1.94268580e-07],\n",
       "       [9.90283550e-01, 6.58338000e-03, 3.13310530e-03],\n",
       "       [4.87648000e-03, 9.95077100e-01, 4.65541530e-05],\n",
       "       [9.46207150e-04, 1.06077140e-03, 9.97993000e-01],\n",
       "       [2.30493590e-01, 7.69475500e-01, 3.09141140e-05],\n",
       "       [9.50470270e-01, 4.95297760e-02, 9.02516900e-09],\n",
       "       [8.08099650e-05, 9.67242900e-06, 9.99909500e-01],\n",
       "       [9.99999760e-01, 2.30713210e-07, 1.57819840e-10],\n",
       "       [4.58917500e-04, 9.98334470e-01, 1.20659100e-03],\n",
       "       [2.08086500e-04, 9.99770700e-01, 2.12126800e-05],\n",
       "       [2.78682070e-04, 9.95044700e-01, 4.67671000e-03],\n",
       "       [9.70995050e-04, 8.63280000e-04, 9.98165800e-01],\n",
       "       [4.86388570e-03, 9.95135840e-01, 1.94268580e-07],\n",
       "       [5.52525670e-06, 9.99813400e-01, 1.81170250e-04],\n",
       "       [9.99998700e-01, 1.26649600e-06, 1.39582350e-09],\n",
       "       [7.86417660e-01, 2.12524440e-01, 1.05781880e-03],\n",
       "       [1.00290940e-04, 9.98900530e-01, 9.99154800e-04],\n",
       "       [7.51480900e-01, 2.44962480e-01, 3.55663480e-03],\n",
       "       [8.08099650e-05, 9.67242900e-06, 9.99909500e-01],\n",
       "       [9.99156000e-01, 8.44032500e-04, 7.64021000e-11],\n",
       "       [9.70995050e-04, 8.63280000e-04, 9.98165800e-01],\n",
       "       [1.00000000e+00, 6.52766100e-12, 4.77708540e-09],\n",
       "       [5.52525670e-06, 9.99813400e-01, 1.81170250e-04],\n",
       "       [9.46207150e-04, 1.06077140e-03, 9.97993000e-01],\n",
       "       [9.99998450e-01, 1.52321070e-06, 2.63974350e-09],\n",
       "       [9.46207150e-04, 1.06077140e-03, 9.97993000e-01],\n",
       "       [4.86388570e-03, 9.95135840e-01, 1.94268580e-07],\n",
       "       [9.99999900e-01, 1.16427080e-09, 1.25225280e-07],\n",
       "       [9.99947550e-01, 3.67961660e-06, 4.86957300e-05],\n",
       "       [8.36012400e-03, 9.91557500e-01, 8.23392000e-05],\n",
       "       [9.88414170e-01, 1.01935610e-02, 1.39230040e-03],\n",
       "       [8.08099650e-05, 9.67242900e-06, 9.99909500e-01],\n",
       "       [9.46207150e-04, 1.06077140e-03, 9.97993000e-01],\n",
       "       [9.93286300e-01, 6.58692650e-03, 1.26729340e-04],\n",
       "       [9.46207150e-04, 1.06077140e-03, 9.97993000e-01],\n",
       "       [9.67550900e-01, 3.24453150e-02, 3.76413400e-06],\n",
       "       [9.46207150e-04, 1.06077140e-03, 9.97993000e-01],\n",
       "       [2.60472200e-03, 9.97395300e-01, 2.25060370e-11],\n",
       "       [9.70995050e-04, 8.63280000e-04, 9.98165800e-01],\n",
       "       [2.27588750e-02, 9.77151930e-01, 8.91717500e-05],\n",
       "       [8.08099650e-05, 9.67242900e-06, 9.99909500e-01],\n",
       "       [3.78447000e-03, 9.95418670e-01, 7.96858600e-04],\n",
       "       [8.08099650e-05, 9.67242900e-06, 9.99909500e-01],\n",
       "       [4.47888700e-03, 9.94634600e-01, 8.86603600e-04],\n",
       "       [3.53391460e-04, 9.99257400e-01, 3.89116760e-04],\n",
       "       [8.08099650e-05, 9.67242900e-06, 9.99909500e-01],\n",
       "       [2.60472200e-03, 9.97395300e-01, 2.25060370e-11],\n",
       "       [1.00000000e+00, 7.83272600e-13, 4.27936120e-08],\n",
       "       [4.87648000e-03, 9.95077100e-01, 4.65541530e-05],\n",
       "       [7.19664100e-05, 3.08167000e-05, 9.99897240e-01],\n",
       "       [5.36192000e-03, 9.92832800e-01, 1.80530690e-03],\n",
       "       [5.31332400e-03, 9.94531100e-01, 1.55643440e-04],\n",
       "       [1.85996710e-03, 9.97974700e-01, 1.65339630e-04],\n",
       "       [8.08099650e-05, 9.67242900e-06, 9.99909500e-01],\n",
       "       [7.19664100e-05, 3.08167000e-05, 9.99897240e-01],\n",
       "       [9.99917400e-01, 8.26516550e-05, 1.03599490e-10],\n",
       "       [7.19664100e-05, 3.08167000e-05, 9.99897240e-01],\n",
       "       [6.20568600e-01, 3.78489550e-01, 9.41988430e-04],\n",
       "       [9.70995050e-04, 8.63280000e-04, 9.98165800e-01],\n",
       "       [8.08099650e-05, 9.67242900e-06, 9.99909500e-01],\n",
       "       [9.78875760e-01, 2.10805440e-02, 4.36497500e-05],\n",
       "       [7.12310400e-04, 9.78338840e-01, 2.09488120e-02],\n",
       "       [9.46207150e-04, 1.06077140e-03, 9.97993000e-01],\n",
       "       [9.99100800e-01, 8.98966000e-04, 2.28082290e-07],\n",
       "       [9.75150200e-01, 2.15590220e-02, 3.29070650e-03],\n",
       "       [4.86388570e-03, 9.95135840e-01, 1.94268580e-07],\n",
       "       [7.19664100e-05, 3.08167000e-05, 9.99897240e-01],\n",
       "       [9.46207150e-04, 1.06077140e-03, 9.97993000e-01],\n",
       "       [1.86034000e-01, 8.12502300e-01, 1.46371380e-03],\n",
       "       [5.31332400e-03, 9.94531100e-01, 1.55643440e-04],\n",
       "       [9.99959800e-01, 3.92466940e-05, 9.70034600e-07],\n",
       "       [9.99218100e-01, 6.18016200e-05, 7.20010100e-04],\n",
       "       [7.19664100e-05, 3.08167000e-05, 9.99897240e-01],\n",
       "       [8.08099650e-05, 9.67242900e-06, 9.99909500e-01],\n",
       "       [9.70995050e-04, 8.63280000e-04, 9.98165800e-01],\n",
       "       [7.12310400e-04, 9.78338840e-01, 2.09488120e-02],\n",
       "       [3.53391460e-04, 9.99257400e-01, 3.89116760e-04],\n",
       "       [9.99983900e-01, 1.25322640e-06, 1.47810500e-05],\n",
       "       [7.19664100e-05, 3.08167000e-05, 9.99897240e-01],\n",
       "       [5.52525670e-06, 9.99813400e-01, 1.81170250e-04],\n",
       "       [7.19664100e-05, 3.08167000e-05, 9.99897240e-01],\n",
       "       [1.10188160e-01, 8.82735400e-01, 7.07641100e-03],\n",
       "       [9.99934300e-01, 6.57351400e-05, 1.68526820e-10],\n",
       "       [9.70995050e-04, 8.63280000e-04, 9.98165800e-01],\n",
       "       [9.54115330e-01, 4.57938650e-02, 9.07083000e-05],\n",
       "       [9.46207150e-04, 1.06077140e-03, 9.97993000e-01],\n",
       "       [3.23667500e-02, 9.67632100e-01, 1.11830130e-06],\n",
       "       [9.56231000e-03, 9.86449200e-01, 3.98856960e-03],\n",
       "       [2.78682070e-04, 9.95044700e-01, 4.67671000e-03],\n",
       "       [8.08099650e-05, 9.67242900e-06, 9.99909500e-01],\n",
       "       [2.41755400e-03, 9.97381870e-01, 2.00619980e-04],\n",
       "       [7.19664100e-05, 3.08167000e-05, 9.99897240e-01],\n",
       "       [1.00000000e+00, 1.37079030e-08, 3.40869170e-10],\n",
       "       [7.12310400e-04, 9.78338840e-01, 2.09488120e-02],\n",
       "       [9.91919300e-01, 7.98476500e-03, 9.58388340e-05],\n",
       "       [5.31332400e-03, 9.94531100e-01, 1.55643440e-04],\n",
       "       [9.70995050e-04, 8.63280000e-04, 9.98165800e-01],\n",
       "       [9.99998450e-01, 1.51770630e-06, 3.65117600e-09],\n",
       "       [9.46207150e-04, 1.06077140e-03, 9.97993000e-01],\n",
       "       [7.12310400e-04, 9.78338840e-01, 2.09488120e-02],\n",
       "       [9.99668700e-01, 3.31335500e-04, 2.69532620e-10],\n",
       "       [7.17713650e-01, 2.78431480e-01, 3.85482840e-03],\n",
       "       [9.89495700e-01, 1.03695780e-02, 1.34690800e-04],\n",
       "       [9.98932660e-01, 1.06715250e-03, 2.34049680e-07],\n",
       "       [3.09806780e-03, 9.96794040e-01, 1.07945560e-04],\n",
       "       [7.19664100e-05, 3.08167000e-05, 9.99897240e-01],\n",
       "       [8.08099650e-05, 9.67242900e-06, 9.99909500e-01],\n",
       "       [1.03965970e-05, 9.99841100e-01, 1.48562290e-04],\n",
       "       [9.98264970e-01, 1.73508340e-03, 6.34599800e-09],\n",
       "       [9.70995050e-04, 8.63280000e-04, 9.98165800e-01],\n",
       "       [1.85996710e-03, 9.97974700e-01, 1.65339630e-04],\n",
       "       [9.70995050e-04, 8.63280000e-04, 9.98165800e-01],\n",
       "       [9.95355500e-01, 3.85564680e-03, 7.88970560e-04],\n",
       "       [9.70995050e-04, 8.63280000e-04, 9.98165800e-01],\n",
       "       [1.85996710e-03, 9.97974700e-01, 1.65339630e-04],\n",
       "       [9.82940400e-01, 1.70522720e-02, 7.34916800e-06],\n",
       "       [9.97093300e-01, 1.96251600e-03, 9.44134660e-04],\n",
       "       [1.00000000e+00, 3.03114140e-13, 3.20820500e-09],\n",
       "       [9.99833000e-01, 1.66945580e-04, 4.41109870e-08]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob2 = df_proba2[df_proba2['phage']=='pyopresabsSTCC_qual'].iloc[:,-3:]\n",
    "y_prob2 = y_prob2.to_numpy()\n",
    "y_prob2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9998834498834498"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo2 = rocauc_ovo(y_test_over, y_prob2, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9998834498834498"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr2 = rocauc_ovr(y_test_over, y_prob2, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=345,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat3 = pd.DataFrame(X_test_over[:,0])\n",
    "dat3['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS168</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS383</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS213</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>NRS266</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>NRS001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>NRS112</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>196 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0  test\n",
       "0    NRS168     1\n",
       "1    NRS383     1\n",
       "2    NRS148     2\n",
       "3    NRS109     2\n",
       "4    NRS213     0\n",
       "..      ...   ...\n",
       "191  NRS255     2\n",
       "192  NRS255     2\n",
       "193  NRS266     1\n",
       "194  NRS001     1\n",
       "195  NRS112     1\n",
       "\n",
       "[196 rows x 2 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over3 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],)),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over3.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 455 samples, validate on 196 samples\n",
      "Epoch 1/100\n",
      "455/455 [==============================] - 0s 358us/step - loss: 2.4737 - accuracy: 0.5165 - val_loss: 1.1082 - val_accuracy: 0.6327\n",
      "Epoch 2/100\n",
      "455/455 [==============================] - 0s 201us/step - loss: 0.7345 - accuracy: 0.6747 - val_loss: 0.6904 - val_accuracy: 0.7143\n",
      "Epoch 3/100\n",
      "455/455 [==============================] - 0s 203us/step - loss: 0.4872 - accuracy: 0.7912 - val_loss: 0.4596 - val_accuracy: 0.7908\n",
      "Epoch 4/100\n",
      "455/455 [==============================] - 0s 181us/step - loss: 0.3505 - accuracy: 0.8813 - val_loss: 0.3684 - val_accuracy: 0.8724\n",
      "Epoch 5/100\n",
      "455/455 [==============================] - 0s 205us/step - loss: 0.2803 - accuracy: 0.9231 - val_loss: 0.3025 - val_accuracy: 0.9133\n",
      "Epoch 6/100\n",
      "455/455 [==============================] - 0s 206us/step - loss: 0.2374 - accuracy: 0.9253 - val_loss: 0.2888 - val_accuracy: 0.8776\n",
      "Epoch 7/100\n",
      "455/455 [==============================] - 0s 190us/step - loss: 0.2115 - accuracy: 0.9516 - val_loss: 0.2414 - val_accuracy: 0.9184\n",
      "Epoch 8/100\n",
      "455/455 [==============================] - 0s 141us/step - loss: 0.1840 - accuracy: 0.9626 - val_loss: 0.2338 - val_accuracy: 0.9184\n",
      "Epoch 9/100\n",
      "455/455 [==============================] - 0s 150us/step - loss: 0.1711 - accuracy: 0.9582 - val_loss: 0.2015 - val_accuracy: 0.9388\n",
      "Epoch 10/100\n",
      "455/455 [==============================] - 0s 202us/step - loss: 0.1481 - accuracy: 0.9692 - val_loss: 0.1919 - val_accuracy: 0.9337\n",
      "Epoch 11/100\n",
      "455/455 [==============================] - 0s 153us/step - loss: 0.1353 - accuracy: 0.9692 - val_loss: 0.1831 - val_accuracy: 0.9388\n",
      "Epoch 12/100\n",
      "455/455 [==============================] - 0s 114us/step - loss: 0.1296 - accuracy: 0.9780 - val_loss: 0.1947 - val_accuracy: 0.9184\n",
      "Epoch 13/100\n",
      "455/455 [==============================] - 0s 130us/step - loss: 0.1178 - accuracy: 0.9736 - val_loss: 0.1598 - val_accuracy: 0.9490\n",
      "Epoch 14/100\n",
      "455/455 [==============================] - 0s 166us/step - loss: 0.1056 - accuracy: 0.9780 - val_loss: 0.1576 - val_accuracy: 0.9439\n",
      "Epoch 15/100\n",
      "455/455 [==============================] - 0s 137us/step - loss: 0.0985 - accuracy: 0.9846 - val_loss: 0.1482 - val_accuracy: 0.9490\n",
      "Epoch 16/100\n",
      "455/455 [==============================] - 0s 94us/step - loss: 0.0924 - accuracy: 0.9824 - val_loss: 0.1347 - val_accuracy: 0.9643\n",
      "Epoch 17/100\n",
      "455/455 [==============================] - 0s 115us/step - loss: 0.0827 - accuracy: 0.9890 - val_loss: 0.1313 - val_accuracy: 0.9745\n",
      "Epoch 18/100\n",
      "455/455 [==============================] - 0s 136us/step - loss: 0.0774 - accuracy: 0.9912 - val_loss: 0.1206 - val_accuracy: 0.9694\n",
      "Epoch 19/100\n",
      "455/455 [==============================] - 0s 187us/step - loss: 0.0736 - accuracy: 0.9912 - val_loss: 0.1255 - val_accuracy: 0.9643\n",
      "Epoch 20/100\n",
      "455/455 [==============================] - 0s 182us/step - loss: 0.0669 - accuracy: 0.9934 - val_loss: 0.1179 - val_accuracy: 0.9643\n",
      "Epoch 21/100\n",
      "455/455 [==============================] - 0s 178us/step - loss: 0.0621 - accuracy: 0.9934 - val_loss: 0.1158 - val_accuracy: 0.9694\n",
      "Epoch 22/100\n",
      "455/455 [==============================] - 0s 164us/step - loss: 0.0573 - accuracy: 0.9956 - val_loss: 0.1086 - val_accuracy: 0.9745\n",
      "Epoch 23/100\n",
      "455/455 [==============================] - 0s 221us/step - loss: 0.0530 - accuracy: 0.9956 - val_loss: 0.1073 - val_accuracy: 0.9643\n",
      "Epoch 24/100\n",
      "455/455 [==============================] - 0s 106us/step - loss: 0.0503 - accuracy: 0.9934 - val_loss: 0.1139 - val_accuracy: 0.9592\n",
      "Epoch 25/100\n",
      "455/455 [==============================] - 0s 90us/step - loss: 0.0473 - accuracy: 0.9934 - val_loss: 0.0958 - val_accuracy: 0.9796\n",
      "Epoch 26/100\n",
      "455/455 [==============================] - 0s 91us/step - loss: 0.0451 - accuracy: 0.9978 - val_loss: 0.1067 - val_accuracy: 0.9694\n",
      "Epoch 27/100\n",
      "455/455 [==============================] - 0s 101us/step - loss: 0.0448 - accuracy: 0.9934 - val_loss: 0.0874 - val_accuracy: 0.9796\n",
      "Epoch 28/100\n",
      "455/455 [==============================] - 0s 354us/step - loss: 0.0421 - accuracy: 0.9978 - val_loss: 0.1007 - val_accuracy: 0.9643\n",
      "Epoch 29/100\n",
      "455/455 [==============================] - 0s 181us/step - loss: 0.0385 - accuracy: 0.9978 - val_loss: 0.0964 - val_accuracy: 0.9745\n",
      "Epoch 30/100\n",
      "455/455 [==============================] - 0s 270us/step - loss: 0.0356 - accuracy: 0.9956 - val_loss: 0.0906 - val_accuracy: 0.9796\n",
      "Epoch 31/100\n",
      "455/455 [==============================] - 0s 215us/step - loss: 0.0331 - accuracy: 0.9956 - val_loss: 0.0873 - val_accuracy: 0.9796\n",
      "Epoch 32/100\n",
      "455/455 [==============================] - 0s 213us/step - loss: 0.0323 - accuracy: 0.9978 - val_loss: 0.0891 - val_accuracy: 0.9796\n",
      "Epoch 33/100\n",
      "455/455 [==============================] - 0s 297us/step - loss: 0.0305 - accuracy: 0.9934 - val_loss: 0.0834 - val_accuracy: 0.9796\n",
      "Epoch 34/100\n",
      "455/455 [==============================] - 0s 220us/step - loss: 0.0329 - accuracy: 1.0000 - val_loss: 0.0898 - val_accuracy: 0.9745\n",
      "Epoch 35/100\n",
      "455/455 [==============================] - 0s 314us/step - loss: 0.0269 - accuracy: 1.0000 - val_loss: 0.0889 - val_accuracy: 0.9745\n",
      "Epoch 36/100\n",
      "455/455 [==============================] - 0s 209us/step - loss: 0.0259 - accuracy: 0.9978 - val_loss: 0.0793 - val_accuracy: 0.9796\n",
      "Epoch 37/100\n",
      "455/455 [==============================] - 0s 134us/step - loss: 0.0242 - accuracy: 1.0000 - val_loss: 0.0881 - val_accuracy: 0.9745\n",
      "Epoch 38/100\n",
      "455/455 [==============================] - 0s 132us/step - loss: 0.0234 - accuracy: 1.0000 - val_loss: 0.0857 - val_accuracy: 0.9745\n",
      "Epoch 39/100\n",
      "455/455 [==============================] - 0s 200us/step - loss: 0.0221 - accuracy: 1.0000 - val_loss: 0.0792 - val_accuracy: 0.9796\n",
      "Epoch 40/100\n",
      "455/455 [==============================] - 0s 243us/step - loss: 0.0213 - accuracy: 1.0000 - val_loss: 0.0901 - val_accuracy: 0.9745\n",
      "Epoch 41/100\n",
      "455/455 [==============================] - 0s 273us/step - loss: 0.0209 - accuracy: 1.0000 - val_loss: 0.0773 - val_accuracy: 0.9796\n",
      "Epoch 42/100\n",
      "455/455 [==============================] - 0s 218us/step - loss: 0.0188 - accuracy: 1.0000 - val_loss: 0.0813 - val_accuracy: 0.9745\n",
      "Epoch 43/100\n",
      "455/455 [==============================] - 0s 161us/step - loss: 0.0190 - accuracy: 1.0000 - val_loss: 0.0859 - val_accuracy: 0.9745\n",
      "Epoch 44/100\n",
      "455/455 [==============================] - 0s 100us/step - loss: 0.0189 - accuracy: 0.9978 - val_loss: 0.0737 - val_accuracy: 0.9796\n",
      "Epoch 45/100\n",
      "455/455 [==============================] - 0s 93us/step - loss: 0.0175 - accuracy: 1.0000 - val_loss: 0.0787 - val_accuracy: 0.9796\n",
      "Epoch 46/100\n",
      "455/455 [==============================] - 0s 88us/step - loss: 0.0159 - accuracy: 1.0000 - val_loss: 0.0782 - val_accuracy: 0.9796\n",
      "Epoch 47/100\n",
      "455/455 [==============================] - 0s 87us/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 0.0755 - val_accuracy: 0.9796\n",
      "Epoch 48/100\n",
      "455/455 [==============================] - 0s 92us/step - loss: 0.0170 - accuracy: 1.0000 - val_loss: 0.0763 - val_accuracy: 0.9847\n",
      "Epoch 49/100\n",
      "455/455 [==============================] - 0s 86us/step - loss: 0.0194 - accuracy: 0.9956 - val_loss: 0.0867 - val_accuracy: 0.9745\n",
      "Epoch 50/100\n",
      "455/455 [==============================] - 0s 94us/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 0.0670 - val_accuracy: 0.9796\n",
      "Epoch 51/100\n",
      "455/455 [==============================] - 0s 193us/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 0.0783 - val_accuracy: 0.9796\n",
      "Epoch 52/100\n",
      "455/455 [==============================] - 0s 201us/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 0.0740 - val_accuracy: 0.9796\n",
      "Epoch 53/100\n",
      "455/455 [==============================] - 0s 229us/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 0.0769 - val_accuracy: 0.9796\n",
      "Epoch 54/100\n",
      "455/455 [==============================] - 0s 144us/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.0724 - val_accuracy: 0.9796\n",
      "Epoch 55/100\n",
      "455/455 [==============================] - 0s 95us/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 0.0721 - val_accuracy: 0.9796\n",
      "Epoch 56/100\n",
      "455/455 [==============================] - 0s 97us/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.0782 - val_accuracy: 0.9796\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "455/455 [==============================] - 0s 108us/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.0712 - val_accuracy: 0.9796\n",
      "Epoch 58/100\n",
      "455/455 [==============================] - 0s 102us/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.0737 - val_accuracy: 0.9796\n",
      "Epoch 59/100\n",
      "455/455 [==============================] - 0s 157us/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.0678 - val_accuracy: 0.9796\n",
      "Epoch 60/100\n",
      "455/455 [==============================] - 0s 151us/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.0804 - val_accuracy: 0.9745\n",
      "Epoch 61/100\n",
      "455/455 [==============================] - 0s 98us/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.0721 - val_accuracy: 0.9796\n",
      "Epoch 62/100\n",
      "455/455 [==============================] - 0s 86us/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.0780 - val_accuracy: 0.9745\n",
      "Epoch 63/100\n",
      "455/455 [==============================] - 0s 85us/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.0770 - val_accuracy: 0.9745\n",
      "Epoch 64/100\n",
      "455/455 [==============================] - 0s 105us/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.0777 - val_accuracy: 0.9745\n",
      "Epoch 65/100\n",
      "455/455 [==============================] - 0s 154us/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.0780 - val_accuracy: 0.9745\n",
      "Epoch 66/100\n",
      "455/455 [==============================] - 0s 126us/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.0703 - val_accuracy: 0.9796\n",
      "Epoch 67/100\n",
      "455/455 [==============================] - 0s 124us/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.0710 - val_accuracy: 0.9796\n",
      "Epoch 68/100\n",
      "455/455 [==============================] - 0s 106us/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.0753 - val_accuracy: 0.9796\n",
      "Epoch 69/100\n",
      "455/455 [==============================] - 0s 94us/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.0747 - val_accuracy: 0.9796\n",
      "Epoch 70/100\n",
      "455/455 [==============================] - 0s 85us/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.0746 - val_accuracy: 0.9796\n",
      "Epoch 71/100\n",
      "455/455 [==============================] - 0s 92us/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.0764 - val_accuracy: 0.9796\n",
      "Epoch 72/100\n",
      "455/455 [==============================] - 0s 83us/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.0769 - val_accuracy: 0.9745\n",
      "Epoch 73/100\n",
      "455/455 [==============================] - 0s 88us/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.0753 - val_accuracy: 0.9796\n",
      "Epoch 74/100\n",
      "455/455 [==============================] - 0s 84us/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.0750 - val_accuracy: 0.9796\n",
      "Epoch 75/100\n",
      "455/455 [==============================] - 0s 87us/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0727 - val_accuracy: 0.9796\n",
      "Epoch 76/100\n",
      "455/455 [==============================] - 0s 110us/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0800 - val_accuracy: 0.9745\n",
      "Epoch 77/100\n",
      "455/455 [==============================] - 0s 136us/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0723 - val_accuracy: 0.9796\n",
      "Epoch 78/100\n",
      "455/455 [==============================] - 0s 90us/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0771 - val_accuracy: 0.9745\n",
      "Epoch 79/100\n",
      "455/455 [==============================] - 0s 106us/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0761 - val_accuracy: 0.9796\n",
      "Epoch 80/100\n",
      "455/455 [==============================] - 0s 91us/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0704 - val_accuracy: 0.9796\n",
      "Epoch 81/100\n",
      "455/455 [==============================] - 0s 107us/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0800 - val_accuracy: 0.9745\n",
      "Epoch 82/100\n",
      "455/455 [==============================] - 0s 139us/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0741 - val_accuracy: 0.9796\n",
      "Epoch 83/100\n",
      "455/455 [==============================] - 0s 92us/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0805 - val_accuracy: 0.9745\n",
      "Epoch 84/100\n",
      "455/455 [==============================] - 0s 90us/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0717 - val_accuracy: 0.9796\n",
      "Epoch 85/100\n",
      "455/455 [==============================] - 0s 93us/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0747 - val_accuracy: 0.9796\n",
      "Epoch 86/100\n",
      "455/455 [==============================] - 0s 89us/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0768 - val_accuracy: 0.9796\n",
      "Epoch 87/100\n",
      "455/455 [==============================] - 0s 89us/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0728 - val_accuracy: 0.9796\n",
      "Epoch 88/100\n",
      "455/455 [==============================] - 0s 88us/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0801 - val_accuracy: 0.9745\n",
      "Epoch 89/100\n",
      "455/455 [==============================] - 0s 97us/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0755 - val_accuracy: 0.9796\n",
      "Epoch 90/100\n",
      "455/455 [==============================] - 0s 99us/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0712 - val_accuracy: 0.9796\n",
      "Epoch 91/100\n",
      "455/455 [==============================] - 0s 93us/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0803 - val_accuracy: 0.9745\n",
      "Epoch 92/100\n",
      "455/455 [==============================] - 0s 84us/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0715 - val_accuracy: 0.9796\n",
      "Epoch 93/100\n",
      "455/455 [==============================] - 0s 102us/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0772 - val_accuracy: 0.9796\n",
      "Epoch 94/100\n",
      "455/455 [==============================] - 0s 153us/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0780 - val_accuracy: 0.9796\n",
      "Epoch 95/100\n",
      "455/455 [==============================] - 0s 120us/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0715 - val_accuracy: 0.9796\n",
      "Epoch 96/100\n",
      "455/455 [==============================] - 0s 183us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0728 - val_accuracy: 0.9796\n",
      "Epoch 97/100\n",
      "455/455 [==============================] - 0s 157us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0752 - val_accuracy: 0.9796\n",
      "Epoch 98/100\n",
      "455/455 [==============================] - 0s 209us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0775 - val_accuracy: 0.9796\n",
      "Epoch 99/100\n",
      "455/455 [==============================] - 0s 146us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0753 - val_accuracy: 0.9796\n",
      "Epoch 100/100\n",
      "455/455 [==============================] - 0s 105us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0764 - val_accuracy: 0.9796\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x634ac8630>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over3.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196/196 [==============================] - 0s 77us/step\n",
      "over-sampling test accuracy: 97.96%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over3 = model1_over3.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over3*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 2, 2, 0, 0, 0, 2, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 2, 2, 1, 1,\n",
       "       0, 2, 0, 1, 2, 0, 1, 0, 0, 2, 1, 2, 1, 1, 0, 2, 1, 1, 1, 2, 1, 2,\n",
       "       0, 1, 2, 1, 1, 2, 0, 2, 1, 1, 0, 2, 0, 1, 2, 1, 2, 1, 0, 0, 2, 0,\n",
       "       1, 0, 2, 1, 0, 0, 1, 0, 0, 2, 0, 1, 0, 0, 2, 0, 0, 2, 0, 2, 1, 1,\n",
       "       2, 1, 2, 1, 0, 2, 0, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 0, 2, 0, 2, 0,\n",
       "       1, 2, 1, 1, 0, 1, 1, 2, 2, 1, 1, 2, 0, 2, 1, 1, 0, 1, 0, 2, 2, 0,\n",
       "       1, 2, 2, 1, 2, 2, 2, 0, 1, 0, 0, 2, 1, 1, 1, 2, 0, 2, 2, 0, 2, 1,\n",
       "       0, 1, 2, 0, 1, 1, 0, 0, 2, 0, 0, 0, 0, 2, 2, 0, 1, 1, 2, 0, 1, 2,\n",
       "       2, 0, 2, 1, 0, 2, 0, 2, 1, 1, 1, 1, 1, 0, 2, 2, 2, 1, 1, 1])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred3 = model1_over3.predict_classes(X_test_over)\n",
    "pred3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS168</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS383</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS213</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>NRS266</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>NRS001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>NRS112</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>196 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0  test  pred\n",
       "0    NRS168     1     1\n",
       "1    NRS383     1     1\n",
       "2    NRS148     2     2\n",
       "3    NRS109     2     2\n",
       "4    NRS213     0     0\n",
       "..      ...   ...   ...\n",
       "191  NRS255     2     2\n",
       "192  NRS255     2     2\n",
       "193  NRS266     1     1\n",
       "194  NRS001     1     1\n",
       "195  NRS112     1     1\n",
       "\n",
       "[196 rows x 3 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat3['pred'] = pred3\n",
    "dat3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba3 = model1_over3.predict_proba(X_test_over)\n",
    "dat_proba3 = pd.DataFrame(proba3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000219</td>\n",
       "      <td>0.999493</td>\n",
       "      <td>2.874555e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.006785</td>\n",
       "      <td>0.993205</td>\n",
       "      <td>1.003763e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>9.998719e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000269</td>\n",
       "      <td>0.000652</td>\n",
       "      <td>9.990788e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.996568</td>\n",
       "      <td>0.003003</td>\n",
       "      <td>4.286918e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>0.000633</td>\n",
       "      <td>0.000928</td>\n",
       "      <td>9.984396e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>0.000633</td>\n",
       "      <td>0.000928</td>\n",
       "      <td>9.984396e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>0.025932</td>\n",
       "      <td>0.974061</td>\n",
       "      <td>7.323514e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>0.000597</td>\n",
       "      <td>0.999403</td>\n",
       "      <td>3.675362e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.000537</td>\n",
       "      <td>0.999452</td>\n",
       "      <td>1.168620e-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>196 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1             2\n",
       "0    0.000219  0.999493  2.874555e-04\n",
       "1    0.006785  0.993205  1.003763e-05\n",
       "2    0.000005  0.000123  9.998719e-01\n",
       "3    0.000269  0.000652  9.990788e-01\n",
       "4    0.996568  0.003003  4.286918e-04\n",
       "..        ...       ...           ...\n",
       "191  0.000633  0.000928  9.984396e-01\n",
       "192  0.000633  0.000928  9.984396e-01\n",
       "193  0.025932  0.974061  7.323514e-06\n",
       "194  0.000597  0.999403  3.675362e-10\n",
       "195  0.000537  0.999452  1.168620e-05\n",
       "\n",
       "[196 rows x 3 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba3.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba3.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat3.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/3pyopST.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 455 samples, validate on 196 samples\n",
      "Epoch 1/100\n",
      "455/455 [==============================] - 0s 267us/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0752 - val_accuracy: 0.9796\n",
      "Epoch 2/100\n",
      "455/455 [==============================] - 0s 184us/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0775 - val_accuracy: 0.9745\n",
      "Epoch 3/100\n",
      "455/455 [==============================] - 0s 220us/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0685 - val_accuracy: 0.9847\n",
      "Epoch 4/100\n",
      "455/455 [==============================] - 0s 167us/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0802 - val_accuracy: 0.9745\n",
      "Epoch 5/100\n",
      "455/455 [==============================] - 0s 336us/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0761 - val_accuracy: 0.9796\n",
      "Epoch 6/100\n",
      "455/455 [==============================] - 0s 146us/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0713 - val_accuracy: 0.9796\n",
      "Epoch 7/100\n",
      "455/455 [==============================] - 0s 138us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0773 - val_accuracy: 0.9796\n",
      "Epoch 8/100\n",
      "455/455 [==============================] - 0s 117us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0743 - val_accuracy: 0.9796\n",
      "Epoch 9/100\n",
      "455/455 [==============================] - 0s 134us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0781 - val_accuracy: 0.9745\n",
      "Epoch 10/100\n",
      "455/455 [==============================] - 0s 104us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0702 - val_accuracy: 0.9796\n",
      "Epoch 11/100\n",
      "455/455 [==============================] - 0s 99us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0728 - val_accuracy: 0.9847\n",
      "Epoch 12/100\n",
      "455/455 [==============================] - 0s 99us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0779 - val_accuracy: 0.9796\n",
      "Epoch 13/100\n",
      "455/455 [==============================] - 0s 110us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0746 - val_accuracy: 0.9796\n",
      "Epoch 14/100\n",
      "455/455 [==============================] - 0s 301us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0752 - val_accuracy: 0.9796\n",
      "Epoch 15/100\n",
      "455/455 [==============================] - 0s 368us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0727 - val_accuracy: 0.9796\n",
      "Epoch 16/100\n",
      "455/455 [==============================] - 0s 286us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0765 - val_accuracy: 0.9796\n",
      "Epoch 17/100\n",
      "455/455 [==============================] - 0s 222us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0708 - val_accuracy: 0.9796\n",
      "Epoch 18/100\n",
      "455/455 [==============================] - 0s 377us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0789 - val_accuracy: 0.9796\n",
      "Epoch 19/100\n",
      "455/455 [==============================] - 0s 134us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0796 - val_accuracy: 0.9745\n",
      "Epoch 20/100\n",
      "455/455 [==============================] - 0s 145us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0736 - val_accuracy: 0.9796\n",
      "Epoch 21/100\n",
      "455/455 [==============================] - 0s 440us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0720 - val_accuracy: 0.9796\n",
      "Epoch 22/100\n",
      "455/455 [==============================] - 0s 214us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0771 - val_accuracy: 0.9796\n",
      "Epoch 23/100\n",
      " 32/455 [=>............................] - ETA: 0s - loss: 0.0028 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/keras/callbacks/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.100164). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "455/455 [==============================] - 0s 147us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0770 - val_accuracy: 0.9796\n",
      "Epoch 24/100\n",
      "455/455 [==============================] - 0s 181us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0756 - val_accuracy: 0.9796\n",
      "Epoch 25/100\n",
      "455/455 [==============================] - 0s 191us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0786 - val_accuracy: 0.9796\n",
      "Epoch 26/100\n",
      "455/455 [==============================] - 0s 127us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0750 - val_accuracy: 0.9796\n",
      "Epoch 27/100\n",
      "455/455 [==============================] - 0s 123us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0764 - val_accuracy: 0.9796\n",
      "Epoch 28/100\n",
      "455/455 [==============================] - 0s 134us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0794 - val_accuracy: 0.9796\n",
      "Epoch 29/100\n",
      "455/455 [==============================] - 0s 113us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0771 - val_accuracy: 0.9796\n",
      "Epoch 30/100\n",
      "455/455 [==============================] - 0s 110us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0737 - val_accuracy: 0.9796\n",
      "Epoch 31/100\n",
      "455/455 [==============================] - 0s 114us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0778 - val_accuracy: 0.9796\n",
      "Epoch 32/100\n",
      "455/455 [==============================] - 0s 226us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0771 - val_accuracy: 0.9796\n",
      "Epoch 33/100\n",
      "455/455 [==============================] - 0s 123us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0776 - val_accuracy: 0.9796\n",
      "Epoch 34/100\n",
      "455/455 [==============================] - 0s 209us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0781 - val_accuracy: 0.9796\n",
      "Epoch 35/100\n",
      "455/455 [==============================] - 0s 217us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0786 - val_accuracy: 0.9796\n",
      "Epoch 36/100\n",
      "455/455 [==============================] - 0s 477us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0768 - val_accuracy: 0.9796\n",
      "Epoch 37/100\n",
      "455/455 [==============================] - 0s 191us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0769 - val_accuracy: 0.9796\n",
      "Epoch 38/100\n",
      "455/455 [==============================] - 0s 198us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0788 - val_accuracy: 0.9796\n",
      "Epoch 39/100\n",
      "455/455 [==============================] - 0s 182us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0802 - val_accuracy: 0.9796\n",
      "Epoch 40/100\n",
      "455/455 [==============================] - 0s 145us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0751 - val_accuracy: 0.9796\n",
      "Epoch 41/100\n",
      "455/455 [==============================] - 0s 130us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0782 - val_accuracy: 0.9796\n",
      "Epoch 42/100\n",
      "455/455 [==============================] - 0s 221us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0765 - val_accuracy: 0.9796\n",
      "Epoch 43/100\n",
      "455/455 [==============================] - 0s 159us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0770 - val_accuracy: 0.9796\n",
      "Epoch 44/100\n",
      "455/455 [==============================] - 0s 254us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0770 - val_accuracy: 0.9796\n",
      "Epoch 45/100\n",
      "455/455 [==============================] - 0s 146us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0803 - val_accuracy: 0.9796\n",
      "Epoch 46/100\n",
      "455/455 [==============================] - 0s 185us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0769 - val_accuracy: 0.9796\n",
      "Epoch 47/100\n",
      "455/455 [==============================] - 0s 133us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0778 - val_accuracy: 0.9796\n",
      "Epoch 48/100\n",
      "455/455 [==============================] - 0s 155us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0791 - val_accuracy: 0.9796\n",
      "Epoch 49/100\n",
      "455/455 [==============================] - 0s 147us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0781 - val_accuracy: 0.9796\n",
      "Epoch 50/100\n",
      "455/455 [==============================] - 0s 183us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0776 - val_accuracy: 0.9796\n",
      "Epoch 51/100\n",
      "455/455 [==============================] - 0s 218us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0785 - val_accuracy: 0.9796\n",
      "Epoch 52/100\n",
      "455/455 [==============================] - 0s 344us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0760 - val_accuracy: 0.9796\n",
      "Epoch 53/100\n",
      "455/455 [==============================] - 0s 154us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0790 - val_accuracy: 0.9796\n",
      "Epoch 54/100\n",
      "455/455 [==============================] - 0s 274us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0799 - val_accuracy: 0.9796\n",
      "Epoch 55/100\n",
      "455/455 [==============================] - 0s 232us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0807 - val_accuracy: 0.9796\n",
      "Epoch 56/100\n",
      "455/455 [==============================] - 0s 213us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0789 - val_accuracy: 0.9796\n",
      "Epoch 57/100\n",
      "455/455 [==============================] - 0s 187us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0761 - val_accuracy: 0.9796\n",
      "Epoch 58/100\n",
      "455/455 [==============================] - 0s 233us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0785 - val_accuracy: 0.9796\n",
      "Epoch 59/100\n",
      "455/455 [==============================] - 0s 392us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0798 - val_accuracy: 0.9796\n",
      "Epoch 60/100\n",
      "455/455 [==============================] - 0s 155us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0775 - val_accuracy: 0.9847\n",
      "Epoch 61/100\n",
      "455/455 [==============================] - 0s 212us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0795 - val_accuracy: 0.9796\n",
      "Epoch 62/100\n",
      "455/455 [==============================] - 0s 181us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0805 - val_accuracy: 0.9796\n",
      "Epoch 63/100\n",
      "455/455 [==============================] - 0s 154us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0787 - val_accuracy: 0.9796\n",
      "Epoch 64/100\n",
      "455/455 [==============================] - 0s 144us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0795 - val_accuracy: 0.9796\n",
      "Epoch 65/100\n",
      "455/455 [==============================] - 0s 144us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0789 - val_accuracy: 0.9796\n",
      "Epoch 66/100\n",
      "455/455 [==============================] - 0s 135us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0830 - val_accuracy: 0.9796\n",
      "Epoch 67/100\n",
      "455/455 [==============================] - 0s 140us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0816 - val_accuracy: 0.9796\n",
      "Epoch 68/100\n",
      "455/455 [==============================] - 0s 186us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0785 - val_accuracy: 0.9796\n",
      "Epoch 69/100\n",
      "455/455 [==============================] - 0s 145us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0815 - val_accuracy: 0.9796\n",
      "Epoch 70/100\n",
      "455/455 [==============================] - 0s 145us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0819 - val_accuracy: 0.9796\n",
      "Epoch 71/100\n",
      "455/455 [==============================] - 0s 168us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0823 - val_accuracy: 0.9796\n",
      "Epoch 72/100\n",
      "455/455 [==============================] - 0s 142us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0818 - val_accuracy: 0.9796\n",
      "Epoch 73/100\n",
      "455/455 [==============================] - 0s 191us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0783 - val_accuracy: 0.9796\n",
      "Epoch 74/100\n",
      "455/455 [==============================] - 0s 172us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0812 - val_accuracy: 0.9796\n",
      "Epoch 75/100\n",
      "455/455 [==============================] - 0s 184us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0810 - val_accuracy: 0.9796\n",
      "Epoch 76/100\n",
      "455/455 [==============================] - 0s 154us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0811 - val_accuracy: 0.9796\n",
      "Epoch 77/100\n",
      "455/455 [==============================] - 0s 147us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0803 - val_accuracy: 0.9796\n",
      "Epoch 78/100\n",
      "455/455 [==============================] - 0s 168us/step - loss: 9.9671e-04 - accuracy: 1.0000 - val_loss: 0.0829 - val_accuracy: 0.9796\n",
      "Epoch 79/100\n",
      "455/455 [==============================] - 0s 142us/step - loss: 9.8479e-04 - accuracy: 1.0000 - val_loss: 0.0816 - val_accuracy: 0.9796\n",
      "Epoch 80/100\n",
      "455/455 [==============================] - 0s 130us/step - loss: 9.6650e-04 - accuracy: 1.0000 - val_loss: 0.0807 - val_accuracy: 0.9847\n",
      "Epoch 81/100\n",
      "455/455 [==============================] - 0s 154us/step - loss: 9.8808e-04 - accuracy: 1.0000 - val_loss: 0.0855 - val_accuracy: 0.9745\n",
      "Epoch 82/100\n",
      "455/455 [==============================] - 0s 168us/step - loss: 9.6057e-04 - accuracy: 1.0000 - val_loss: 0.0795 - val_accuracy: 0.9796\n",
      "Epoch 83/100\n",
      "455/455 [==============================] - 0s 179us/step - loss: 9.1680e-04 - accuracy: 1.0000 - val_loss: 0.0823 - val_accuracy: 0.9796\n",
      "Epoch 84/100\n",
      "455/455 [==============================] - 0s 149us/step - loss: 9.0810e-04 - accuracy: 1.0000 - val_loss: 0.0835 - val_accuracy: 0.9796\n",
      "Epoch 85/100\n",
      "455/455 [==============================] - 0s 203us/step - loss: 8.9450e-04 - accuracy: 1.0000 - val_loss: 0.0819 - val_accuracy: 0.9796\n",
      "Epoch 86/100\n",
      "455/455 [==============================] - 0s 204us/step - loss: 8.8034e-04 - accuracy: 1.0000 - val_loss: 0.0815 - val_accuracy: 0.9796\n",
      "Epoch 87/100\n",
      "455/455 [==============================] - 0s 213us/step - loss: 8.8163e-04 - accuracy: 1.0000 - val_loss: 0.0824 - val_accuracy: 0.9796\n",
      "Epoch 88/100\n",
      "455/455 [==============================] - 0s 165us/step - loss: 8.6795e-04 - accuracy: 1.0000 - val_loss: 0.0807 - val_accuracy: 0.9796\n",
      "Epoch 89/100\n",
      "455/455 [==============================] - 0s 142us/step - loss: 8.5012e-04 - accuracy: 1.0000 - val_loss: 0.0813 - val_accuracy: 0.9796\n",
      "Epoch 90/100\n",
      "455/455 [==============================] - 0s 138us/step - loss: 8.4407e-04 - accuracy: 1.0000 - val_loss: 0.0824 - val_accuracy: 0.9796\n",
      "Epoch 91/100\n",
      "455/455 [==============================] - 0s 186us/step - loss: 8.1811e-04 - accuracy: 1.0000 - val_loss: 0.0811 - val_accuracy: 0.9796\n",
      "Epoch 92/100\n",
      "455/455 [==============================] - 0s 153us/step - loss: 8.1143e-04 - accuracy: 1.0000 - val_loss: 0.0815 - val_accuracy: 0.9796\n",
      "Epoch 93/100\n",
      "455/455 [==============================] - 0s 155us/step - loss: 7.9962e-04 - accuracy: 1.0000 - val_loss: 0.0836 - val_accuracy: 0.9796\n",
      "Epoch 94/100\n",
      "455/455 [==============================] - 0s 162us/step - loss: 7.8920e-04 - accuracy: 1.0000 - val_loss: 0.0834 - val_accuracy: 0.9796\n",
      "Epoch 95/100\n",
      "455/455 [==============================] - 0s 168us/step - loss: 7.7708e-04 - accuracy: 1.0000 - val_loss: 0.0824 - val_accuracy: 0.9796\n",
      "Epoch 96/100\n",
      "455/455 [==============================] - 0s 183us/step - loss: 7.7257e-04 - accuracy: 1.0000 - val_loss: 0.0824 - val_accuracy: 0.9796\n",
      "Epoch 97/100\n",
      "455/455 [==============================] - 0s 322us/step - loss: 7.7487e-04 - accuracy: 1.0000 - val_loss: 0.0845 - val_accuracy: 0.9796\n",
      "Epoch 98/100\n",
      "455/455 [==============================] - 0s 188us/step - loss: 7.4658e-04 - accuracy: 1.0000 - val_loss: 0.0810 - val_accuracy: 0.9796\n",
      "Epoch 99/100\n",
      "455/455 [==============================] - 0s 278us/step - loss: 7.6100e-04 - accuracy: 1.0000 - val_loss: 0.0801 - val_accuracy: 0.9796\n",
      "Epoch 100/100\n",
      "455/455 [==============================] - 0s 350us/step - loss: 7.3681e-04 - accuracy: 1.0000 - val_loss: 0.0856 - val_accuracy: 0.9796\n"
     ]
    }
   ],
   "source": [
    "hist1_over3 = model1_over3.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over3.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba3 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_2.xlsx\",\n",
    "                        sheet_name=2,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>0.013518</td>\n",
       "      <td>9.820048e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>0.013518</td>\n",
       "      <td>9.820048e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS222</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.851725</td>\n",
       "      <td>0.148269</td>\n",
       "      <td>5.980786e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>0.013518</td>\n",
       "      <td>9.820048e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>GA50245</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.812055</td>\n",
       "      <td>0.187945</td>\n",
       "      <td>1.161034e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4279</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>0.000928</td>\n",
       "      <td>9.984396e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4280</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>0.000928</td>\n",
       "      <td>9.984396e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4281</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS266</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.025932</td>\n",
       "      <td>0.974061</td>\n",
       "      <td>7.323514e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4282</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000597</td>\n",
       "      <td>0.999403</td>\n",
       "      <td>3.675362e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4283</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS112</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>0.999452</td>\n",
       "      <td>1.168620e-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4284 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    phage   strain  phenotype  prediction         0         1  \\\n",
       "0      p002ykpresabs_qual   NRS109          2           2  0.004477  0.013518   \n",
       "1      p002ykpresabs_qual   NRS109          2           2  0.004477  0.013518   \n",
       "2      p002ykpresabs_qual   NRS222          0           0  0.851725  0.148269   \n",
       "3      p002ykpresabs_qual   NRS109          2           2  0.004477  0.013518   \n",
       "4      p002ykpresabs_qual  GA50245          0           0  0.812055  0.187945   \n",
       "...                   ...      ...        ...         ...       ...       ...   \n",
       "4279  pyopresabsSTCC_qual   NRS255          2           2  0.000633  0.000928   \n",
       "4280  pyopresabsSTCC_qual   NRS255          2           2  0.000633  0.000928   \n",
       "4281  pyopresabsSTCC_qual   NRS266          1           1  0.025932  0.974061   \n",
       "4282  pyopresabsSTCC_qual   NRS001          1           1  0.000597  0.999403   \n",
       "4283  pyopresabsSTCC_qual   NRS112          1           1  0.000537  0.999452   \n",
       "\n",
       "                 2  \n",
       "0     9.820048e-01  \n",
       "1     9.820048e-01  \n",
       "2     5.980786e-06  \n",
       "3     9.820048e-01  \n",
       "4     1.161034e-07  \n",
       "...            ...  \n",
       "4279  9.984396e-01  \n",
       "4280  9.984396e-01  \n",
       "4281  7.323514e-06  \n",
       "4282  3.675362e-10  \n",
       "4283  1.168620e-05  \n",
       "\n",
       "[4284 rows x 7 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.19203110e-04, 9.99493240e-01, 2.87455540e-04],\n",
       "       [6.78508000e-03, 9.93204830e-01, 1.00376340e-05],\n",
       "       [5.17537460e-06, 1.22981990e-04, 9.99871850e-01],\n",
       "       [2.68918000e-04, 6.52354600e-04, 9.99078750e-01],\n",
       "       [9.96567850e-01, 3.00334300e-03, 4.28691830e-04],\n",
       "       [9.96088400e-01, 3.91160230e-03, 2.38839760e-08],\n",
       "       [1.00000000e+00, 1.40458230e-09, 4.14733900e-10],\n",
       "       [2.68918000e-04, 6.52354600e-04, 9.99078750e-01],\n",
       "       [1.00000000e+00, 1.30167830e-08, 7.95353960e-13],\n",
       "       [9.31623570e-04, 9.99068440e-01, 1.19429160e-09],\n",
       "       [9.99931340e-01, 4.54846100e-05, 2.31257820e-05],\n",
       "       [9.66629270e-01, 3.33111550e-02, 5.96215070e-05],\n",
       "       [2.53201820e-02, 9.74666540e-01, 1.32349800e-05],\n",
       "       [9.34198560e-01, 6.56104500e-02, 1.90942850e-04],\n",
       "       [8.73373700e-03, 9.91241460e-01, 2.48719260e-05],\n",
       "       [1.91836470e-04, 9.99438700e-01, 3.69505200e-04],\n",
       "       [9.99762500e-01, 7.14951800e-05, 1.66035780e-04],\n",
       "       [9.99992600e-01, 6.57746160e-06, 8.66593200e-07],\n",
       "       [5.17537460e-06, 1.22981990e-04, 9.99871850e-01],\n",
       "       [6.32579900e-04, 9.27786500e-04, 9.98439600e-01],\n",
       "       [7.84288100e-04, 9.99209500e-01, 6.25347960e-06],\n",
       "       [2.53201820e-02, 9.74666540e-01, 1.32349800e-05],\n",
       "       [1.00000000e+00, 1.39864010e-08, 1.20977020e-21],\n",
       "       [2.68918000e-04, 6.52354600e-04, 9.99078750e-01],\n",
       "       [9.99999640e-01, 3.41544140e-07, 1.07590265e-11],\n",
       "       [1.91836470e-04, 9.99438700e-01, 3.69505200e-04],\n",
       "       [6.32579900e-04, 9.27786500e-04, 9.98439600e-01],\n",
       "       [5.62415240e-01, 4.37584800e-01, 8.23070900e-09],\n",
       "       [1.98938500e-03, 9.98010700e-01, 9.22717400e-11],\n",
       "       [9.83289060e-01, 1.66233260e-02, 8.76751500e-05],\n",
       "       [9.99412900e-01, 5.87101600e-04, 3.08072480e-10],\n",
       "       [5.17537460e-06, 1.22981990e-04, 9.99871850e-01],\n",
       "       [3.49135570e-04, 9.99637500e-01, 1.32982170e-05],\n",
       "       [5.17537460e-06, 1.22981990e-04, 9.99871850e-01],\n",
       "       [5.96786560e-04, 9.99403240e-01, 3.67536220e-10],\n",
       "       [1.42515080e-03, 9.98574850e-01, 2.29691090e-10],\n",
       "       [9.32536700e-01, 6.74630200e-02, 2.54163270e-07],\n",
       "       [2.68918000e-04, 6.52354600e-04, 9.99078750e-01],\n",
       "       [3.49135570e-04, 9.99637500e-01, 1.32982170e-05],\n",
       "       [2.32046240e-05, 9.99356300e-01, 6.20445470e-04],\n",
       "       [8.53677800e-03, 9.91437000e-01, 2.61833210e-05],\n",
       "       [9.67089800e-06, 1.49346770e-05, 9.99975440e-01],\n",
       "       [8.73373700e-03, 9.91241460e-01, 2.48719260e-05],\n",
       "       [9.67089800e-06, 1.49346770e-05, 9.99975440e-01],\n",
       "       [9.99860050e-01, 1.39970960e-04, 5.30352900e-11],\n",
       "       [5.89503160e-03, 9.93813900e-01, 2.91088950e-04],\n",
       "       [6.32579900e-04, 9.27786500e-04, 9.98439600e-01],\n",
       "       [2.53201820e-02, 9.74666540e-01, 1.32349800e-05],\n",
       "       [1.01580740e-03, 9.98963100e-01, 2.11241900e-05],\n",
       "       [6.32579900e-04, 9.27786500e-04, 9.98439600e-01],\n",
       "       [9.98453860e-01, 1.54609100e-03, 1.78892620e-10],\n",
       "       [2.68918000e-04, 6.52354600e-04, 9.99078750e-01],\n",
       "       [5.36775160e-04, 9.99451600e-01, 1.16862030e-05],\n",
       "       [2.03793610e-03, 9.97958660e-01, 3.48699300e-06],\n",
       "       [9.32291400e-01, 6.76718060e-02, 3.67753300e-05],\n",
       "       [2.68918000e-04, 6.52354600e-04, 9.99078750e-01],\n",
       "       [9.99999900e-01, 1.70451970e-07, 4.20839930e-11],\n",
       "       [9.31623570e-04, 9.99068440e-01, 1.19429160e-09],\n",
       "       [2.68918000e-04, 6.52354600e-04, 9.99078750e-01],\n",
       "       [3.53992430e-01, 6.45972130e-01, 3.53075770e-05],\n",
       "       [2.68918000e-04, 6.52354600e-04, 9.99078750e-01],\n",
       "       [5.96786560e-04, 9.99403240e-01, 3.67536220e-10],\n",
       "       [1.00000000e+00, 1.20902100e-09, 7.55918160e-10],\n",
       "       [1.00000000e+00, 1.71192560e-11, 1.62938840e-23],\n",
       "       [9.67089800e-06, 1.49346770e-05, 9.99975440e-01],\n",
       "       [9.66090800e-01, 3.38805000e-02, 2.86377940e-05],\n",
       "       [7.55373160e-04, 9.99244600e-01, 9.93486600e-08],\n",
       "       [9.91190700e-01, 8.80306100e-03, 6.29663900e-06],\n",
       "       [6.32579900e-04, 9.27786500e-04, 9.98439600e-01],\n",
       "       [9.31623570e-04, 9.99068440e-01, 1.19429160e-09],\n",
       "       [6.17849100e-01, 3.82093850e-01, 5.69880650e-05],\n",
       "       [9.87749900e-01, 1.22196110e-02, 3.04435100e-05],\n",
       "       [6.67141660e-03, 9.92797200e-01, 5.31398630e-04],\n",
       "       [9.97785100e-01, 2.21162100e-03, 3.16367410e-06],\n",
       "       [9.98812800e-01, 7.47317860e-04, 4.39960480e-04],\n",
       "       [9.67089800e-06, 1.49346770e-05, 9.99975440e-01],\n",
       "       [9.99325040e-01, 6.74999960e-04, 1.82079450e-09],\n",
       "       [1.02536250e-02, 9.89705900e-01, 4.04930580e-05],\n",
       "       [9.99769870e-01, 2.30078100e-04, 1.37226210e-07],\n",
       "       [9.96751400e-01, 3.22809190e-03, 2.05810560e-05],\n",
       "       [5.17537460e-06, 1.22981990e-04, 9.99871850e-01],\n",
       "       [1.00000000e+00, 5.52302600e-10, 2.16220870e-10],\n",
       "       [9.99972800e-01, 2.70101170e-05, 6.68892300e-08],\n",
       "       [2.68918000e-04, 6.52354600e-04, 9.99078750e-01],\n",
       "       [9.99773440e-01, 2.26613000e-04, 2.10360080e-08],\n",
       "       [5.17537460e-06, 1.22981990e-04, 9.99871850e-01],\n",
       "       [8.53677800e-03, 9.91437000e-01, 2.61833210e-05],\n",
       "       [2.18564880e-03, 9.97731860e-01, 8.25930040e-05],\n",
       "       [9.67089800e-06, 1.49346770e-05, 9.99975440e-01],\n",
       "       [1.60800560e-03, 9.97933750e-01, 4.58226700e-04],\n",
       "       [9.67089800e-06, 1.49346770e-05, 9.99975440e-01],\n",
       "       [2.74440620e-01, 7.25318600e-01, 2.40832800e-04],\n",
       "       [9.99985340e-01, 8.73662300e-06, 5.99033460e-06],\n",
       "       [6.32579900e-04, 9.27786500e-04, 9.98439600e-01],\n",
       "       [7.16598400e-01, 2.83401640e-01, 7.89770100e-10],\n",
       "       [6.78508000e-03, 9.93204830e-01, 1.00376340e-05],\n",
       "       [6.32579900e-04, 9.27786500e-04, 9.98439600e-01],\n",
       "       [6.32579900e-04, 9.27786500e-04, 9.98439600e-01],\n",
       "       [1.91836470e-04, 9.99438700e-01, 3.69505200e-04],\n",
       "       [9.67089800e-06, 1.49346770e-05, 9.99975440e-01],\n",
       "       [5.17537460e-06, 1.22981990e-04, 9.99871850e-01],\n",
       "       [1.94759490e-04, 9.98683750e-01, 1.12145040e-03],\n",
       "       [5.17537460e-06, 1.22981990e-04, 9.99871850e-01],\n",
       "       [2.68918000e-04, 6.52354600e-04, 9.99078750e-01],\n",
       "       [2.73296680e-03, 9.97262000e-01, 5.01319660e-06],\n",
       "       [9.99952300e-01, 4.71371530e-05, 5.39387940e-07],\n",
       "       [5.17537460e-06, 1.22981990e-04, 9.99871850e-01],\n",
       "       [9.92546140e-01, 6.86597960e-03, 5.87829400e-04],\n",
       "       [6.32579900e-04, 9.27786500e-04, 9.98439600e-01],\n",
       "       [8.41949400e-01, 6.63896500e-02, 9.16609800e-02],\n",
       "       [3.72705800e-03, 9.94042340e-01, 2.23056790e-03],\n",
       "       [5.17537460e-06, 1.22981990e-04, 9.99871850e-01],\n",
       "       [3.72705800e-03, 9.94042340e-01, 2.23056790e-03],\n",
       "       [1.36137810e-02, 9.86374740e-01, 1.15094460e-05],\n",
       "       [9.99604760e-01, 3.95242330e-04, 2.49459900e-09],\n",
       "       [3.49135570e-04, 9.99637500e-01, 1.32982170e-05],\n",
       "       [5.00118730e-03, 9.94980160e-01, 1.85745940e-05],\n",
       "       [5.17537460e-06, 1.22981990e-04, 9.99871850e-01],\n",
       "       [2.68918000e-04, 6.52354600e-04, 9.99078750e-01],\n",
       "       [7.55373160e-04, 9.99244600e-01, 9.93486600e-08],\n",
       "       [5.00118730e-03, 9.94980160e-01, 1.85745940e-05],\n",
       "       [9.67089800e-06, 1.49346770e-05, 9.99975440e-01],\n",
       "       [9.91263030e-01, 8.71797500e-03, 1.90754760e-05],\n",
       "       [9.67089800e-06, 1.49346770e-05, 9.99975440e-01],\n",
       "       [8.73373700e-03, 9.91241460e-01, 2.48719260e-05],\n",
       "       [5.89503160e-03, 9.93813900e-01, 2.91088950e-04],\n",
       "       [8.55041300e-01, 1.44958540e-01, 1.10372156e-07],\n",
       "       [1.01580740e-03, 9.98963100e-01, 2.11241900e-05],\n",
       "       [9.99937300e-01, 6.27174300e-05, 2.66907450e-11],\n",
       "       [2.68918000e-04, 6.52354600e-04, 9.99078750e-01],\n",
       "       [9.67089800e-06, 1.49346770e-05, 9.99975440e-01],\n",
       "       [9.96195900e-01, 3.78182530e-03, 2.23643870e-05],\n",
       "       [5.00118730e-03, 9.94980160e-01, 1.85745940e-05],\n",
       "       [2.68918000e-04, 6.52354600e-04, 9.99078750e-01],\n",
       "       [9.67089800e-06, 1.49346770e-05, 9.99975440e-01],\n",
       "       [7.84288100e-04, 9.99209500e-01, 6.25347960e-06],\n",
       "       [2.68918000e-04, 6.52354600e-04, 9.99078750e-01],\n",
       "       [5.17537460e-06, 1.22981990e-04, 9.99871850e-01],\n",
       "       [5.17537460e-06, 1.22981990e-04, 9.99871850e-01],\n",
       "       [9.99858740e-01, 1.41259470e-04, 1.22872380e-08],\n",
       "       [2.22336220e-03, 9.97613300e-01, 1.63268050e-04],\n",
       "       [9.97351770e-01, 1.12304840e-03, 1.52521910e-03],\n",
       "       [9.99998450e-01, 1.37933830e-06, 9.70956500e-08],\n",
       "       [6.32579900e-04, 9.27786500e-04, 9.98439600e-01],\n",
       "       [6.81360950e-04, 9.99182760e-01, 1.35892200e-04],\n",
       "       [1.01580740e-03, 9.98963100e-01, 2.11241900e-05],\n",
       "       [5.89503160e-03, 9.93813900e-01, 2.91088950e-04],\n",
       "       [5.17537460e-06, 1.22981990e-04, 9.99871850e-01],\n",
       "       [9.97215400e-01, 2.76810930e-03, 1.64907270e-05],\n",
       "       [2.68918000e-04, 6.52354600e-04, 9.99078750e-01],\n",
       "       [9.67089800e-06, 1.49346770e-05, 9.99975440e-01],\n",
       "       [9.99912740e-01, 6.31353100e-05, 2.40752900e-05],\n",
       "       [9.67089800e-06, 1.49346770e-05, 9.99975440e-01],\n",
       "       [8.73373700e-03, 9.91241460e-01, 2.48719260e-05],\n",
       "       [9.97578200e-01, 2.42177650e-03, 2.03614210e-08],\n",
       "       [1.59982110e-03, 9.96071800e-01, 2.32841630e-03],\n",
       "       [5.17537460e-06, 1.22981990e-04, 9.99871850e-01],\n",
       "       [9.99887470e-01, 1.11307990e-04, 1.15865680e-06],\n",
       "       [1.01580740e-03, 9.98963100e-01, 2.11241900e-05],\n",
       "       [8.73373700e-03, 9.91241460e-01, 2.48719260e-05],\n",
       "       [9.96789400e-01, 3.20848400e-03, 2.09333780e-06],\n",
       "       [9.99985340e-01, 1.46885095e-05, 7.82984100e-11],\n",
       "       [9.67089800e-06, 1.49346770e-05, 9.99975440e-01],\n",
       "       [9.99343700e-01, 5.28152570e-04, 1.28239340e-04],\n",
       "       [9.99713240e-01, 2.86724480e-04, 6.72217700e-11],\n",
       "       [9.99999900e-01, 9.97046200e-08, 1.79470430e-12],\n",
       "       [9.99638200e-01, 2.89584700e-04, 7.21620800e-05],\n",
       "       [2.68918000e-04, 6.52354600e-04, 9.99078750e-01],\n",
       "       [2.68918000e-04, 6.52354600e-04, 9.99078750e-01],\n",
       "       [9.84977960e-01, 1.47285955e-02, 2.93417720e-04],\n",
       "       [3.49135570e-04, 9.99637500e-01, 1.32982170e-05],\n",
       "       [6.81360950e-04, 9.99182760e-01, 1.35892200e-04],\n",
       "       [5.17537460e-06, 1.22981990e-04, 9.99871850e-01],\n",
       "       [9.99934700e-01, 6.53816000e-05, 6.07204400e-11],\n",
       "       [1.42515080e-03, 9.98574850e-01, 2.29691090e-10],\n",
       "       [6.32579900e-04, 9.27786500e-04, 9.98439600e-01],\n",
       "       [5.17537460e-06, 1.22981990e-04, 9.99871850e-01],\n",
       "       [9.99618300e-01, 3.81718360e-04, 2.41537680e-10],\n",
       "       [5.17537460e-06, 1.22981990e-04, 9.99871850e-01],\n",
       "       [2.18564880e-03, 9.97731860e-01, 8.25930040e-05],\n",
       "       [7.26192950e-01, 2.73724200e-01, 8.28361300e-05],\n",
       "       [6.32579900e-04, 9.27786500e-04, 9.98439600e-01],\n",
       "       [9.99999640e-01, 3.94388960e-07, 1.34766820e-11],\n",
       "       [6.32579900e-04, 9.27786500e-04, 9.98439600e-01],\n",
       "       [2.03793610e-03, 9.97958660e-01, 3.48699300e-06],\n",
       "       [2.32046240e-05, 9.99356300e-01, 6.20445470e-04],\n",
       "       [7.61889700e-03, 9.92357250e-01, 2.38407720e-05],\n",
       "       [2.19203110e-04, 9.99493240e-01, 2.87455540e-04],\n",
       "       [8.53677800e-03, 9.91437000e-01, 2.61833210e-05],\n",
       "       [9.99739470e-01, 2.57264970e-04, 3.17216020e-06],\n",
       "       [9.67089800e-06, 1.49346770e-05, 9.99975440e-01],\n",
       "       [6.32579900e-04, 9.27786500e-04, 9.98439600e-01],\n",
       "       [6.32579900e-04, 9.27786500e-04, 9.98439600e-01],\n",
       "       [2.59319700e-02, 9.74060700e-01, 7.32351400e-06],\n",
       "       [5.96786560e-04, 9.99403240e-01, 3.67536220e-10],\n",
       "       [5.36775160e-04, 9.99451600e-01, 1.16862030e-05]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob3 = df_proba3[df_proba3['phage']=='pyopresabsSTCC_qual'].iloc[:,-3:]\n",
    "y_prob3 = y_prob3.to_numpy()\n",
    "y_prob3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9977383939215999"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo3 = rocauc_ovo(y_test_over, y_prob3, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9977383939215999"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr3 = rocauc_ovr(y_test_over, y_prob3, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=456,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat4 = pd.DataFrame(X_test_over[:,0])\n",
    "dat4['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS178</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS073</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CFBREBSa119</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>NRS236</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>NRS029</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>CFBRSa28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>NRS205</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>196 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test\n",
       "0         NRS178     1\n",
       "1         NRS109     2\n",
       "2         NRS073     1\n",
       "3    CFBREBSa119     0\n",
       "4         NRS109     2\n",
       "..           ...   ...\n",
       "191       NRS236     1\n",
       "192       NRS029     0\n",
       "193       NRS148     2\n",
       "194     CFBRSa28     0\n",
       "195       NRS205     2\n",
       "\n",
       "[196 rows x 2 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over4 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],)),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over4.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 455 samples, validate on 196 samples\n",
      "Epoch 1/100\n",
      "455/455 [==============================] - 0s 426us/step - loss: 7.4481 - accuracy: 0.3582 - val_loss: 2.8016 - val_accuracy: 0.4184\n",
      "Epoch 2/100\n",
      "455/455 [==============================] - 0s 138us/step - loss: 1.1363 - accuracy: 0.6022 - val_loss: 0.9019 - val_accuracy: 0.6582\n",
      "Epoch 3/100\n",
      "455/455 [==============================] - 0s 147us/step - loss: 0.6060 - accuracy: 0.7670 - val_loss: 0.4790 - val_accuracy: 0.8316\n",
      "Epoch 4/100\n",
      "455/455 [==============================] - 0s 148us/step - loss: 0.3737 - accuracy: 0.8703 - val_loss: 0.4075 - val_accuracy: 0.8469\n",
      "Epoch 5/100\n",
      "455/455 [==============================] - 0s 151us/step - loss: 0.2942 - accuracy: 0.8945 - val_loss: 0.3572 - val_accuracy: 0.8776\n",
      "Epoch 6/100\n",
      "455/455 [==============================] - 0s 142us/step - loss: 0.2510 - accuracy: 0.9297 - val_loss: 0.3048 - val_accuracy: 0.8980\n",
      "Epoch 7/100\n",
      "455/455 [==============================] - 0s 176us/step - loss: 0.2195 - accuracy: 0.9363 - val_loss: 0.2982 - val_accuracy: 0.8980\n",
      "Epoch 8/100\n",
      "455/455 [==============================] - 0s 174us/step - loss: 0.1984 - accuracy: 0.9451 - val_loss: 0.2772 - val_accuracy: 0.8878\n",
      "Epoch 9/100\n",
      "455/455 [==============================] - 0s 156us/step - loss: 0.1738 - accuracy: 0.9560 - val_loss: 0.2606 - val_accuracy: 0.8878\n",
      "Epoch 10/100\n",
      "455/455 [==============================] - 0s 118us/step - loss: 0.1575 - accuracy: 0.9516 - val_loss: 0.2415 - val_accuracy: 0.8929\n",
      "Epoch 11/100\n",
      "455/455 [==============================] - 0s 113us/step - loss: 0.1452 - accuracy: 0.9758 - val_loss: 0.2248 - val_accuracy: 0.8878\n",
      "Epoch 12/100\n",
      "455/455 [==============================] - 0s 181us/step - loss: 0.1320 - accuracy: 0.9692 - val_loss: 0.2174 - val_accuracy: 0.9133\n",
      "Epoch 13/100\n",
      "455/455 [==============================] - 0s 175us/step - loss: 0.1192 - accuracy: 0.9736 - val_loss: 0.1998 - val_accuracy: 0.9184\n",
      "Epoch 14/100\n",
      "455/455 [==============================] - 0s 118us/step - loss: 0.1172 - accuracy: 0.9736 - val_loss: 0.2119 - val_accuracy: 0.9184\n",
      "Epoch 15/100\n",
      "455/455 [==============================] - 0s 99us/step - loss: 0.1016 - accuracy: 0.9868 - val_loss: 0.1857 - val_accuracy: 0.9337\n",
      "Epoch 16/100\n",
      "455/455 [==============================] - 0s 122us/step - loss: 0.0996 - accuracy: 0.9780 - val_loss: 0.1747 - val_accuracy: 0.9439\n",
      "Epoch 17/100\n",
      "455/455 [==============================] - 0s 141us/step - loss: 0.0846 - accuracy: 0.9912 - val_loss: 0.1656 - val_accuracy: 0.9337\n",
      "Epoch 18/100\n",
      "455/455 [==============================] - 0s 144us/step - loss: 0.0799 - accuracy: 0.9890 - val_loss: 0.1609 - val_accuracy: 0.9337\n",
      "Epoch 19/100\n",
      "455/455 [==============================] - 0s 197us/step - loss: 0.0747 - accuracy: 0.9934 - val_loss: 0.1501 - val_accuracy: 0.9490\n",
      "Epoch 20/100\n",
      "455/455 [==============================] - 0s 293us/step - loss: 0.0671 - accuracy: 0.9934 - val_loss: 0.1490 - val_accuracy: 0.9490\n",
      "Epoch 21/100\n",
      "455/455 [==============================] - 0s 260us/step - loss: 0.0643 - accuracy: 0.9934 - val_loss: 0.1431 - val_accuracy: 0.9439\n",
      "Epoch 22/100\n",
      "455/455 [==============================] - 0s 97us/step - loss: 0.0611 - accuracy: 0.9956 - val_loss: 0.1419 - val_accuracy: 0.9439\n",
      "Epoch 23/100\n",
      "455/455 [==============================] - 0s 86us/step - loss: 0.0565 - accuracy: 0.9890 - val_loss: 0.1311 - val_accuracy: 0.9541\n",
      "Epoch 24/100\n",
      "455/455 [==============================] - 0s 91us/step - loss: 0.0555 - accuracy: 0.9912 - val_loss: 0.1404 - val_accuracy: 0.9388\n",
      "Epoch 25/100\n",
      "455/455 [==============================] - 0s 90us/step - loss: 0.0506 - accuracy: 0.9890 - val_loss: 0.1280 - val_accuracy: 0.9541\n",
      "Epoch 26/100\n",
      "455/455 [==============================] - 0s 110us/step - loss: 0.0465 - accuracy: 0.9978 - val_loss: 0.1338 - val_accuracy: 0.9490\n",
      "Epoch 27/100\n",
      "455/455 [==============================] - 0s 515us/step - loss: 0.0441 - accuracy: 0.9956 - val_loss: 0.1184 - val_accuracy: 0.9592\n",
      "Epoch 28/100\n",
      "455/455 [==============================] - 0s 251us/step - loss: 0.0407 - accuracy: 0.9978 - val_loss: 0.1253 - val_accuracy: 0.9490\n",
      "Epoch 29/100\n",
      "455/455 [==============================] - 0s 214us/step - loss: 0.0383 - accuracy: 0.9978 - val_loss: 0.1191 - val_accuracy: 0.9541\n",
      "Epoch 30/100\n",
      "455/455 [==============================] - 0s 153us/step - loss: 0.0382 - accuracy: 0.9978 - val_loss: 0.1192 - val_accuracy: 0.9541\n",
      "Epoch 31/100\n",
      "455/455 [==============================] - 0s 105us/step - loss: 0.0352 - accuracy: 0.9978 - val_loss: 0.1119 - val_accuracy: 0.9592\n",
      "Epoch 32/100\n",
      "455/455 [==============================] - 0s 197us/step - loss: 0.0330 - accuracy: 1.0000 - val_loss: 0.1041 - val_accuracy: 0.9694\n",
      "Epoch 33/100\n",
      "455/455 [==============================] - 0s 245us/step - loss: 0.0313 - accuracy: 1.0000 - val_loss: 0.1143 - val_accuracy: 0.9541\n",
      "Epoch 34/100\n",
      "455/455 [==============================] - 0s 211us/step - loss: 0.0307 - accuracy: 0.9978 - val_loss: 0.1075 - val_accuracy: 0.9592\n",
      "Epoch 35/100\n",
      "455/455 [==============================] - 0s 195us/step - loss: 0.0286 - accuracy: 1.0000 - val_loss: 0.1099 - val_accuracy: 0.9592\n",
      "Epoch 36/100\n",
      "455/455 [==============================] - 0s 244us/step - loss: 0.0268 - accuracy: 1.0000 - val_loss: 0.1104 - val_accuracy: 0.9541\n",
      "Epoch 37/100\n",
      "455/455 [==============================] - 0s 147us/step - loss: 0.0249 - accuracy: 0.9978 - val_loss: 0.1053 - val_accuracy: 0.9592\n",
      "Epoch 38/100\n",
      "455/455 [==============================] - 0s 301us/step - loss: 0.0237 - accuracy: 1.0000 - val_loss: 0.1066 - val_accuracy: 0.9541\n",
      "Epoch 39/100\n",
      "455/455 [==============================] - 0s 273us/step - loss: 0.0230 - accuracy: 1.0000 - val_loss: 0.1025 - val_accuracy: 0.9592\n",
      "Epoch 40/100\n",
      "455/455 [==============================] - 0s 498us/step - loss: 0.0218 - accuracy: 1.0000 - val_loss: 0.1012 - val_accuracy: 0.9541\n",
      "Epoch 41/100\n",
      "455/455 [==============================] - 0s 157us/step - loss: 0.0205 - accuracy: 1.0000 - val_loss: 0.1011 - val_accuracy: 0.9592\n",
      "Epoch 42/100\n",
      "455/455 [==============================] - 0s 104us/step - loss: 0.0195 - accuracy: 1.0000 - val_loss: 0.1004 - val_accuracy: 0.9592\n",
      "Epoch 43/100\n",
      "455/455 [==============================] - 0s 89us/step - loss: 0.0179 - accuracy: 1.0000 - val_loss: 0.0996 - val_accuracy: 0.9592\n",
      "Epoch 44/100\n",
      "455/455 [==============================] - 0s 87us/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 0.1024 - val_accuracy: 0.9592\n",
      "Epoch 45/100\n",
      "455/455 [==============================] - 0s 85us/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 0.0989 - val_accuracy: 0.9592\n",
      "Epoch 46/100\n",
      "455/455 [==============================] - 0s 90us/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 0.1057 - val_accuracy: 0.9541\n",
      "Epoch 47/100\n",
      "455/455 [==============================] - 0s 110us/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 0.0952 - val_accuracy: 0.9643\n",
      "Epoch 48/100\n",
      "455/455 [==============================] - 0s 99us/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 0.0996 - val_accuracy: 0.9592\n",
      "Epoch 49/100\n",
      "455/455 [==============================] - 0s 85us/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.1012 - val_accuracy: 0.9541\n",
      "Epoch 50/100\n",
      "455/455 [==============================] - 0s 94us/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 0.0970 - val_accuracy: 0.9592\n",
      "Epoch 51/100\n",
      "455/455 [==============================] - 0s 87us/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.1015 - val_accuracy: 0.9541\n",
      "Epoch 52/100\n",
      "455/455 [==============================] - 0s 165us/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 0.1024 - val_accuracy: 0.9592\n",
      "Epoch 53/100\n",
      "455/455 [==============================] - 0s 188us/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 0.0922 - val_accuracy: 0.9592\n",
      "Epoch 54/100\n",
      "455/455 [==============================] - 0s 272us/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.1006 - val_accuracy: 0.9541\n",
      "Epoch 55/100\n",
      "455/455 [==============================] - 0s 431us/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 0.0956 - val_accuracy: 0.9592\n",
      "Epoch 56/100\n",
      "455/455 [==============================] - 0s 190us/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.0928 - val_accuracy: 0.9592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "455/455 [==============================] - 0s 128us/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.0958 - val_accuracy: 0.9592\n",
      "Epoch 58/100\n",
      "455/455 [==============================] - 0s 149us/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.0948 - val_accuracy: 0.9592\n",
      "Epoch 59/100\n",
      "455/455 [==============================] - 0s 223us/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.0945 - val_accuracy: 0.9592\n",
      "Epoch 60/100\n",
      "455/455 [==============================] - 0s 130us/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.0994 - val_accuracy: 0.9592\n",
      "Epoch 61/100\n",
      "455/455 [==============================] - 0s 102us/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.0939 - val_accuracy: 0.9592\n",
      "Epoch 62/100\n",
      "455/455 [==============================] - 0s 87us/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.0950 - val_accuracy: 0.9592\n",
      "Epoch 63/100\n",
      "455/455 [==============================] - 0s 123us/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.0948 - val_accuracy: 0.9592\n",
      "Epoch 64/100\n",
      "455/455 [==============================] - 0s 128us/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.0930 - val_accuracy: 0.9592\n",
      "Epoch 65/100\n",
      "455/455 [==============================] - 0s 161us/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.0942 - val_accuracy: 0.9592\n",
      "Epoch 66/100\n",
      "455/455 [==============================] - 0s 118us/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.1015 - val_accuracy: 0.9541\n",
      "Epoch 67/100\n",
      "455/455 [==============================] - 0s 137us/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.0924 - val_accuracy: 0.9592\n",
      "Epoch 68/100\n",
      "455/455 [==============================] - 0s 104us/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.0939 - val_accuracy: 0.9592\n",
      "Epoch 69/100\n",
      "455/455 [==============================] - 0s 89us/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.0921 - val_accuracy: 0.9592\n",
      "Epoch 70/100\n",
      "455/455 [==============================] - 0s 88us/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.0919 - val_accuracy: 0.9592\n",
      "Epoch 71/100\n",
      "455/455 [==============================] - 0s 90us/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0943 - val_accuracy: 0.9592\n",
      "Epoch 72/100\n",
      "455/455 [==============================] - 0s 100us/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0940 - val_accuracy: 0.9592\n",
      "Epoch 73/100\n",
      "455/455 [==============================] - 0s 87us/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0903 - val_accuracy: 0.9592\n",
      "Epoch 74/100\n",
      "455/455 [==============================] - 0s 91us/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0898 - val_accuracy: 0.9592\n",
      "Epoch 75/100\n",
      "455/455 [==============================] - 0s 85us/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0928 - val_accuracy: 0.9592\n",
      "Epoch 76/100\n",
      "455/455 [==============================] - 0s 93us/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0998 - val_accuracy: 0.9592\n",
      "Epoch 77/100\n",
      "455/455 [==============================] - 0s 90us/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0901 - val_accuracy: 0.9592\n",
      "Epoch 78/100\n",
      "455/455 [==============================] - 0s 153us/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0869 - val_accuracy: 0.9592\n",
      "Epoch 79/100\n",
      "455/455 [==============================] - 0s 118us/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0939 - val_accuracy: 0.9592\n",
      "Epoch 80/100\n",
      "455/455 [==============================] - 0s 88us/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0937 - val_accuracy: 0.9592\n",
      "Epoch 81/100\n",
      "455/455 [==============================] - 0s 97us/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0923 - val_accuracy: 0.9592\n",
      "Epoch 82/100\n",
      "455/455 [==============================] - 0s 194us/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0943 - val_accuracy: 0.9592\n",
      "Epoch 83/100\n",
      "455/455 [==============================] - 0s 111us/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0972 - val_accuracy: 0.9592\n",
      "Epoch 84/100\n",
      "455/455 [==============================] - 0s 95us/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.1005 - val_accuracy: 0.9541\n",
      "Epoch 85/100\n",
      "455/455 [==============================] - 0s 117us/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0912 - val_accuracy: 0.9592\n",
      "Epoch 86/100\n",
      "455/455 [==============================] - 0s 92us/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0905 - val_accuracy: 0.9592\n",
      "Epoch 87/100\n",
      "455/455 [==============================] - 0s 116us/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0943 - val_accuracy: 0.9592\n",
      "Epoch 88/100\n",
      "455/455 [==============================] - 0s 96us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0932 - val_accuracy: 0.9592\n",
      "Epoch 89/100\n",
      "455/455 [==============================] - 0s 93us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.1023 - val_accuracy: 0.9592\n",
      "Epoch 90/100\n",
      "455/455 [==============================] - 0s 98us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0931 - val_accuracy: 0.9592\n",
      "Epoch 91/100\n",
      "455/455 [==============================] - 0s 91us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0921 - val_accuracy: 0.9592\n",
      "Epoch 92/100\n",
      "455/455 [==============================] - 0s 90us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0953 - val_accuracy: 0.9592\n",
      "Epoch 93/100\n",
      "455/455 [==============================] - 0s 140us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0923 - val_accuracy: 0.9592\n",
      "Epoch 94/100\n",
      "455/455 [==============================] - 0s 143us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0938 - val_accuracy: 0.9592\n",
      "Epoch 95/100\n",
      "455/455 [==============================] - 0s 140us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0935 - val_accuracy: 0.9592\n",
      "Epoch 96/100\n",
      "455/455 [==============================] - 0s 132us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0935 - val_accuracy: 0.9592\n",
      "Epoch 97/100\n",
      "455/455 [==============================] - 0s 158us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0959 - val_accuracy: 0.9592\n",
      "Epoch 98/100\n",
      "455/455 [==============================] - 0s 143us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0919 - val_accuracy: 0.9592\n",
      "Epoch 99/100\n",
      "455/455 [==============================] - 0s 129us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0963 - val_accuracy: 0.9592\n",
      "Epoch 100/100\n",
      "455/455 [==============================] - 0s 133us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0963 - val_accuracy: 0.9592\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a383cbc18>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over4.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196/196 [==============================] - 0s 78us/step\n",
      "over-sampling test accuracy: 95.41%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over4 = model1_over4.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over4*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 1, 0, 2, 1, 1, 2, 2, 0, 2, 1, 1, 2, 0, 1, 0, 2, 2, 1, 2, 1,\n",
       "       1, 1, 1, 0, 2, 2, 1, 1, 2, 1, 1, 2, 2, 0, 0, 0, 0, 1, 1, 2, 1, 0,\n",
       "       1, 1, 2, 2, 0, 0, 2, 1, 2, 2, 1, 0, 1, 2, 0, 1, 1, 1, 2, 1, 2, 0,\n",
       "       0, 1, 1, 2, 0, 0, 1, 2, 0, 1, 2, 1, 1, 0, 0, 2, 1, 2, 0, 0, 1, 0,\n",
       "       0, 2, 2, 2, 2, 2, 1, 1, 1, 1, 0, 2, 0, 0, 2, 2, 1, 1, 1, 2, 0, 1,\n",
       "       2, 2, 2, 0, 2, 2, 2, 1, 1, 0, 0, 2, 0, 1, 0, 1, 2, 2, 2, 0, 1, 0,\n",
       "       2, 1, 2, 0, 1, 1, 1, 2, 2, 1, 0, 2, 0, 0, 1, 0, 0, 0, 1, 2, 2, 2,\n",
       "       1, 1, 1, 2, 2, 0, 1, 2, 1, 0, 1, 2, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "       0, 2, 1, 1, 1, 0, 2, 0, 0, 0, 0, 2, 0, 2, 2, 1, 1, 2, 0, 2])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred4 = model1_over4.predict_classes(X_test_over)\n",
    "pred4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS178</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS073</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CFBREBSa119</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>NRS236</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>NRS029</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>CFBRSa28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>NRS205</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>196 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test  pred\n",
       "0         NRS178     1     1\n",
       "1         NRS109     2     2\n",
       "2         NRS073     1     1\n",
       "3    CFBREBSa119     0     0\n",
       "4         NRS109     2     2\n",
       "..           ...   ...   ...\n",
       "191       NRS236     1     1\n",
       "192       NRS029     0     1\n",
       "193       NRS148     2     2\n",
       "194     CFBRSa28     0     0\n",
       "195       NRS205     2     2\n",
       "\n",
       "[196 rows x 3 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat4['pred'] = pred4\n",
    "dat4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba4 = model1_over4.predict_proba(X_test_over)\n",
    "dat_proba4 = pd.DataFrame(proba4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000591</td>\n",
       "      <td>0.999319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.004790</td>\n",
       "      <td>0.994912</td>\n",
       "      <td>0.000299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.997035</td>\n",
       "      <td>0.002957</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000591</td>\n",
       "      <td>0.999319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.999768</td>\n",
       "      <td>0.000180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>0.322350</td>\n",
       "      <td>0.677496</td>\n",
       "      <td>0.000153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.999968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>0.999288</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>0.000536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.999987</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>196 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2\n",
       "0    0.000003  0.999986  0.000011\n",
       "1    0.000089  0.000591  0.999319\n",
       "2    0.004790  0.994912  0.000299\n",
       "3    0.997035  0.002957  0.000008\n",
       "4    0.000089  0.000591  0.999319\n",
       "..        ...       ...       ...\n",
       "191  0.000052  0.999768  0.000180\n",
       "192  0.322350  0.677496  0.000153\n",
       "193  0.000006  0.000026  0.999968\n",
       "194  0.999288  0.000176  0.000536\n",
       "195  0.000007  0.000007  0.999987\n",
       "\n",
       "[196 rows x 3 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba4.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba4.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat4.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/4pyopST.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 455 samples, validate on 196 samples\n",
      "Epoch 1/100\n",
      "455/455 [==============================] - 0s 144us/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.1242 - val_accuracy: 0.9541\n",
      "Epoch 2/100\n",
      "455/455 [==============================] - 0s 133us/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.1253 - val_accuracy: 0.9541\n",
      "Epoch 3/100\n",
      "455/455 [==============================] - 0s 136us/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.1233 - val_accuracy: 0.9541\n",
      "Epoch 4/100\n",
      "455/455 [==============================] - 0s 125us/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.1267 - val_accuracy: 0.9541\n",
      "Epoch 5/100\n",
      "455/455 [==============================] - 0s 123us/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.1267 - val_accuracy: 0.9541\n",
      "Epoch 6/100\n",
      "455/455 [==============================] - 0s 120us/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.1208 - val_accuracy: 0.9541\n",
      "Epoch 7/100\n",
      "455/455 [==============================] - 0s 163us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.1278 - val_accuracy: 0.9541\n",
      "Epoch 8/100\n",
      "455/455 [==============================] - 0s 184us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.1268 - val_accuracy: 0.9541\n",
      "Epoch 9/100\n",
      "455/455 [==============================] - 0s 172us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.1274 - val_accuracy: 0.9541\n",
      "Epoch 10/100\n",
      "455/455 [==============================] - 0s 164us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.1250 - val_accuracy: 0.9541\n",
      "Epoch 11/100\n",
      "455/455 [==============================] - 0s 163us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.1170 - val_accuracy: 0.9592\n",
      "Epoch 12/100\n",
      "455/455 [==============================] - 0s 139us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.1259 - val_accuracy: 0.9541\n",
      "Epoch 13/100\n",
      "455/455 [==============================] - 0s 118us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.1326 - val_accuracy: 0.9541\n",
      "Epoch 14/100\n",
      "455/455 [==============================] - 0s 104us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.1294 - val_accuracy: 0.9541\n",
      "Epoch 15/100\n",
      "455/455 [==============================] - 0s 105us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.1247 - val_accuracy: 0.9541\n",
      "Epoch 16/100\n",
      "455/455 [==============================] - 0s 134us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.1284 - val_accuracy: 0.9541\n",
      "Epoch 17/100\n",
      "455/455 [==============================] - 0s 149us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.1273 - val_accuracy: 0.9541\n",
      "Epoch 18/100\n",
      "455/455 [==============================] - 0s 142us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.1273 - val_accuracy: 0.9541\n",
      "Epoch 19/100\n",
      "455/455 [==============================] - 0s 145us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.1273 - val_accuracy: 0.9541\n",
      "Epoch 20/100\n",
      "455/455 [==============================] - 0s 150us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.1305 - val_accuracy: 0.9541\n",
      "Epoch 21/100\n",
      "455/455 [==============================] - 0s 149us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.1265 - val_accuracy: 0.9541\n",
      "Epoch 22/100\n",
      "455/455 [==============================] - 0s 105us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.1265 - val_accuracy: 0.9541\n",
      "Epoch 23/100\n",
      "455/455 [==============================] - 0s 116us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.1283 - val_accuracy: 0.9541\n",
      "Epoch 24/100\n",
      "455/455 [==============================] - 0s 103us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.1286 - val_accuracy: 0.9541\n",
      "Epoch 25/100\n",
      "455/455 [==============================] - 0s 103us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.1276 - val_accuracy: 0.9541\n",
      "Epoch 26/100\n",
      "455/455 [==============================] - 0s 99us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1266 - val_accuracy: 0.9541\n",
      "Epoch 27/100\n",
      "455/455 [==============================] - 0s 101us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1273 - val_accuracy: 0.9541\n",
      "Epoch 28/100\n",
      "455/455 [==============================] - 0s 104us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1261 - val_accuracy: 0.9541\n",
      "Epoch 29/100\n",
      "455/455 [==============================] - 0s 116us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1287 - val_accuracy: 0.9541\n",
      "Epoch 30/100\n",
      "455/455 [==============================] - 0s 119us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1268 - val_accuracy: 0.9541\n",
      "Epoch 31/100\n",
      "455/455 [==============================] - 0s 116us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1280 - val_accuracy: 0.9541\n",
      "Epoch 32/100\n",
      "455/455 [==============================] - 0s 108us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1286 - val_accuracy: 0.9541\n",
      "Epoch 33/100\n",
      "455/455 [==============================] - 0s 116us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.1275 - val_accuracy: 0.9541\n",
      "Epoch 34/100\n",
      "455/455 [==============================] - 0s 103us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.1274 - val_accuracy: 0.9541\n",
      "Epoch 35/100\n",
      "455/455 [==============================] - 0s 98us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1249 - val_accuracy: 0.9541\n",
      "Epoch 36/100\n",
      "455/455 [==============================] - 0s 123us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1289 - val_accuracy: 0.9541\n",
      "Epoch 37/100\n",
      "455/455 [==============================] - 0s 97us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1274 - val_accuracy: 0.9541\n",
      "Epoch 38/100\n",
      "455/455 [==============================] - 0s 104us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1234 - val_accuracy: 0.9541\n",
      "Epoch 39/100\n",
      "455/455 [==============================] - 0s 95us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1260 - val_accuracy: 0.9541\n",
      "Epoch 40/100\n",
      "455/455 [==============================] - 0s 113us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1260 - val_accuracy: 0.9541\n",
      "Epoch 41/100\n",
      "455/455 [==============================] - 0s 124us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1296 - val_accuracy: 0.9541\n",
      "Epoch 42/100\n",
      "455/455 [==============================] - 0s 98us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1267 - val_accuracy: 0.9541\n",
      "Epoch 43/100\n",
      "455/455 [==============================] - 0s 92us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1274 - val_accuracy: 0.9541\n",
      "Epoch 44/100\n",
      "455/455 [==============================] - 0s 92us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1269 - val_accuracy: 0.9541\n",
      "Epoch 45/100\n",
      "455/455 [==============================] - 0s 91us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1301 - val_accuracy: 0.9541\n",
      "Epoch 46/100\n",
      "455/455 [==============================] - 0s 88us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1279 - val_accuracy: 0.9541\n",
      "Epoch 47/100\n",
      "455/455 [==============================] - 0s 102us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1272 - val_accuracy: 0.9541\n",
      "Epoch 48/100\n",
      "455/455 [==============================] - 0s 96us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1316 - val_accuracy: 0.9541\n",
      "Epoch 49/100\n",
      "455/455 [==============================] - 0s 95us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1301 - val_accuracy: 0.9541\n",
      "Epoch 50/100\n",
      "455/455 [==============================] - 0s 93us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1285 - val_accuracy: 0.9541\n",
      "Epoch 51/100\n",
      "455/455 [==============================] - 0s 98us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1304 - val_accuracy: 0.9541\n",
      "Epoch 52/100\n",
      "455/455 [==============================] - 0s 108us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1251 - val_accuracy: 0.9541\n",
      "Epoch 53/100\n",
      "455/455 [==============================] - 0s 112us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1287 - val_accuracy: 0.9541\n",
      "Epoch 54/100\n",
      "455/455 [==============================] - 0s 110us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1283 - val_accuracy: 0.9541\n",
      "Epoch 55/100\n",
      "455/455 [==============================] - 0s 111us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1285 - val_accuracy: 0.9541\n",
      "Epoch 56/100\n",
      "455/455 [==============================] - 0s 116us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1282 - val_accuracy: 0.9541\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "455/455 [==============================] - 0s 126us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1303 - val_accuracy: 0.9541\n",
      "Epoch 58/100\n",
      "455/455 [==============================] - 0s 123us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1284 - val_accuracy: 0.9541\n",
      "Epoch 59/100\n",
      "455/455 [==============================] - 0s 109us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1274 - val_accuracy: 0.9541\n",
      "Epoch 60/100\n",
      "455/455 [==============================] - 0s 98us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1278 - val_accuracy: 0.9541\n",
      "Epoch 61/100\n",
      "455/455 [==============================] - 0s 108us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1273 - val_accuracy: 0.9541\n",
      "Epoch 62/100\n",
      "455/455 [==============================] - 0s 91us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1325 - val_accuracy: 0.9541\n",
      "Epoch 63/100\n",
      "455/455 [==============================] - 0s 88us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1287 - val_accuracy: 0.9541\n",
      "Epoch 64/100\n",
      "455/455 [==============================] - 0s 88us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1278 - val_accuracy: 0.9541\n",
      "Epoch 65/100\n",
      "455/455 [==============================] - 0s 93us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1277 - val_accuracy: 0.9541\n",
      "Epoch 66/100\n",
      "455/455 [==============================] - 0s 103us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1302 - val_accuracy: 0.9541\n",
      "Epoch 67/100\n",
      "455/455 [==============================] - 0s 117us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1271 - val_accuracy: 0.9541\n",
      "Epoch 68/100\n",
      "455/455 [==============================] - 0s 108us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1281 - val_accuracy: 0.9541\n",
      "Epoch 69/100\n",
      "455/455 [==============================] - 0s 99us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1306 - val_accuracy: 0.9541\n",
      "Epoch 70/100\n",
      "455/455 [==============================] - 0s 95us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1328 - val_accuracy: 0.9541\n",
      "Epoch 71/100\n",
      "455/455 [==============================] - 0s 97us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1290 - val_accuracy: 0.9541\n",
      "Epoch 72/100\n",
      "455/455 [==============================] - 0s 91us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1273 - val_accuracy: 0.9541\n",
      "Epoch 73/100\n",
      "455/455 [==============================] - 0s 97us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1287 - val_accuracy: 0.9541\n",
      "Epoch 74/100\n",
      "455/455 [==============================] - 0s 92us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1266 - val_accuracy: 0.9541\n",
      "Epoch 75/100\n",
      "455/455 [==============================] - 0s 90us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1270 - val_accuracy: 0.9541\n",
      "Epoch 76/100\n",
      "455/455 [==============================] - 0s 92us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1298 - val_accuracy: 0.9541\n",
      "Epoch 77/100\n",
      "455/455 [==============================] - 0s 92us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1278 - val_accuracy: 0.9541\n",
      "Epoch 78/100\n",
      "455/455 [==============================] - 0s 93us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.1274 - val_accuracy: 0.9541\n",
      "Epoch 79/100\n",
      "455/455 [==============================] - 0s 104us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.1297 - val_accuracy: 0.9541\n",
      "Epoch 80/100\n",
      "455/455 [==============================] - 0s 188us/step - loss: 9.8970e-04 - accuracy: 1.0000 - val_loss: 0.1282 - val_accuracy: 0.9541\n",
      "Epoch 81/100\n",
      "455/455 [==============================] - 0s 213us/step - loss: 9.9773e-04 - accuracy: 1.0000 - val_loss: 0.1306 - val_accuracy: 0.9541\n",
      "Epoch 82/100\n",
      "455/455 [==============================] - 0s 123us/step - loss: 9.6295e-04 - accuracy: 1.0000 - val_loss: 0.1259 - val_accuracy: 0.9541\n",
      "Epoch 83/100\n",
      "455/455 [==============================] - 0s 119us/step - loss: 9.4852e-04 - accuracy: 1.0000 - val_loss: 0.1277 - val_accuracy: 0.9541\n",
      "Epoch 84/100\n",
      "455/455 [==============================] - 0s 137us/step - loss: 9.3368e-04 - accuracy: 1.0000 - val_loss: 0.1298 - val_accuracy: 0.9541\n",
      "Epoch 85/100\n",
      "455/455 [==============================] - 0s 126us/step - loss: 9.3069e-04 - accuracy: 1.0000 - val_loss: 0.1313 - val_accuracy: 0.9541\n",
      "Epoch 86/100\n",
      "455/455 [==============================] - 0s 133us/step - loss: 9.1147e-04 - accuracy: 1.0000 - val_loss: 0.1297 - val_accuracy: 0.9541\n",
      "Epoch 87/100\n",
      "455/455 [==============================] - 0s 135us/step - loss: 9.0943e-04 - accuracy: 1.0000 - val_loss: 0.1286 - val_accuracy: 0.9541\n",
      "Epoch 88/100\n",
      "455/455 [==============================] - 0s 151us/step - loss: 8.8522e-04 - accuracy: 1.0000 - val_loss: 0.1304 - val_accuracy: 0.9541\n",
      "Epoch 89/100\n",
      "455/455 [==============================] - 0s 405us/step - loss: 8.7723e-04 - accuracy: 1.0000 - val_loss: 0.1310 - val_accuracy: 0.9541\n",
      "Epoch 90/100\n",
      "455/455 [==============================] - 0s 193us/step - loss: 8.5724e-04 - accuracy: 1.0000 - val_loss: 0.1301 - val_accuracy: 0.9541\n",
      "Epoch 91/100\n",
      "455/455 [==============================] - 0s 107us/step - loss: 8.4496e-04 - accuracy: 1.0000 - val_loss: 0.1287 - val_accuracy: 0.9541\n",
      "Epoch 92/100\n",
      "455/455 [==============================] - 0s 142us/step - loss: 8.4819e-04 - accuracy: 1.0000 - val_loss: 0.1292 - val_accuracy: 0.9541\n",
      "Epoch 93/100\n",
      "455/455 [==============================] - 0s 332us/step - loss: 8.4059e-04 - accuracy: 1.0000 - val_loss: 0.1276 - val_accuracy: 0.9541\n",
      "Epoch 94/100\n",
      "455/455 [==============================] - 0s 216us/step - loss: 8.1278e-04 - accuracy: 1.0000 - val_loss: 0.1302 - val_accuracy: 0.9541\n",
      "Epoch 95/100\n",
      "455/455 [==============================] - 0s 181us/step - loss: 8.0181e-04 - accuracy: 1.0000 - val_loss: 0.1275 - val_accuracy: 0.9541\n",
      "Epoch 96/100\n",
      "455/455 [==============================] - 0s 187us/step - loss: 7.9071e-04 - accuracy: 1.0000 - val_loss: 0.1277 - val_accuracy: 0.9541\n",
      "Epoch 97/100\n",
      "455/455 [==============================] - 0s 181us/step - loss: 7.9114e-04 - accuracy: 1.0000 - val_loss: 0.1302 - val_accuracy: 0.9541\n",
      "Epoch 98/100\n",
      "455/455 [==============================] - 0s 164us/step - loss: 7.7539e-04 - accuracy: 1.0000 - val_loss: 0.1283 - val_accuracy: 0.9541\n",
      "Epoch 99/100\n",
      "455/455 [==============================] - 0s 133us/step - loss: 7.6085e-04 - accuracy: 1.0000 - val_loss: 0.1295 - val_accuracy: 0.9541\n",
      "Epoch 100/100\n",
      "455/455 [==============================] - 0s 576us/step - loss: 7.4945e-04 - accuracy: 1.0000 - val_loss: 0.1291 - val_accuracy: 0.9541\n"
     ]
    }
   ],
   "source": [
    "hist1_over4 = model1_over4.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over4.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba4 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_2.xlsx\",\n",
    "                        sheet_name=3,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS110</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>5.870196e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS216</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.039254</td>\n",
       "      <td>0.960745</td>\n",
       "      <td>9.078969e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS386</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.326752</td>\n",
       "      <td>0.673248</td>\n",
       "      <td>1.061032e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>CFBRSa25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.611084</td>\n",
       "      <td>0.388916</td>\n",
       "      <td>7.664974e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>BCH-SA-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.611084</td>\n",
       "      <td>0.388916</td>\n",
       "      <td>7.664974e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4279</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS236</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.999768</td>\n",
       "      <td>1.803156e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4280</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS029</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.322350</td>\n",
       "      <td>0.677496</td>\n",
       "      <td>1.533154e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4281</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>9.999682e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4282</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>CFBRSa28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999288</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>5.361527e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4283</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS205</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>9.999868e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4284 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    phage     strain  phenotype  prediction         0  \\\n",
       "0      p002ykpresabs_qual     NRS110          1           1  0.000003   \n",
       "1      p002ykpresabs_qual     NRS216          1           1  0.039254   \n",
       "2      p002ykpresabs_qual     NRS386          1           1  0.326752   \n",
       "3      p002ykpresabs_qual   CFBRSa25          0           0  0.611084   \n",
       "4      p002ykpresabs_qual  BCH-SA-03          1           0  0.611084   \n",
       "...                   ...        ...        ...         ...       ...   \n",
       "4279  pyopresabsSTCC_qual     NRS236          1           1  0.000052   \n",
       "4280  pyopresabsSTCC_qual     NRS029          0           1  0.322350   \n",
       "4281  pyopresabsSTCC_qual     NRS148          2           2  0.000006   \n",
       "4282  pyopresabsSTCC_qual   CFBRSa28          0           0  0.999288   \n",
       "4283  pyopresabsSTCC_qual     NRS205          2           2  0.000007   \n",
       "\n",
       "             1             2  \n",
       "0     0.999997  5.870196e-13  \n",
       "1     0.960745  9.078969e-07  \n",
       "2     0.673248  1.061032e-07  \n",
       "3     0.388916  7.664974e-07  \n",
       "4     0.388916  7.664974e-07  \n",
       "...        ...           ...  \n",
       "4279  0.999768  1.803156e-04  \n",
       "4280  0.677496  1.533154e-04  \n",
       "4281  0.000026  9.999682e-01  \n",
       "4282  0.000176  5.361527e-04  \n",
       "4283  0.000007  9.999868e-01  \n",
       "\n",
       "[4284 rows x 7 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.84750880e-06, 9.99986400e-01, 1.07121390e-05],\n",
       "       [8.90664450e-05, 5.91487700e-04, 9.99319430e-01],\n",
       "       [4.78956940e-03, 9.94911850e-01, 2.98612900e-04],\n",
       "       [9.97035400e-01, 2.95661090e-03, 7.90630000e-06],\n",
       "       [8.90664450e-05, 5.91487700e-04, 9.99319430e-01],\n",
       "       [1.34019960e-03, 9.97478900e-01, 1.18082520e-03],\n",
       "       [2.38043020e-03, 9.97093100e-01, 5.26401850e-04],\n",
       "       [8.90664450e-05, 5.91487700e-04, 9.99319430e-01],\n",
       "       [6.62489000e-06, 6.62595130e-06, 9.99986770e-01],\n",
       "       [1.00000000e+00, 1.39188890e-15, 7.66704000e-29],\n",
       "       [8.90664450e-05, 5.91487700e-04, 9.99319430e-01],\n",
       "       [1.34019960e-03, 9.97478900e-01, 1.18082520e-03],\n",
       "       [6.09711160e-04, 9.99390000e-01, 1.86577180e-07],\n",
       "       [6.62489000e-06, 6.62595130e-06, 9.99986770e-01],\n",
       "       [9.99939200e-01, 6.05122730e-05, 2.21072850e-07],\n",
       "       [1.65521990e-02, 9.83377000e-01, 7.07603000e-05],\n",
       "       [9.99999760e-01, 1.98321860e-07, 1.11691930e-08],\n",
       "       [5.76195800e-06, 2.60178990e-05, 9.99968200e-01],\n",
       "       [3.52007570e-04, 7.93922400e-04, 9.98854040e-01],\n",
       "       [3.23700800e-01, 6.65675460e-01, 1.06237060e-02],\n",
       "       [6.62489000e-06, 6.62595130e-06, 9.99986770e-01],\n",
       "       [8.01998300e-05, 9.99907600e-01, 1.22170130e-05],\n",
       "       [1.22603380e-03, 9.98748660e-01, 2.52517400e-05],\n",
       "       [6.09711160e-04, 9.99390000e-01, 1.86577180e-07],\n",
       "       [3.81349620e-04, 9.99618400e-01, 2.67239000e-07],\n",
       "       [9.99992000e-01, 7.94683200e-06, 3.36073560e-11],\n",
       "       [5.76195800e-06, 2.60178990e-05, 9.99968200e-01],\n",
       "       [6.62489000e-06, 6.62595130e-06, 9.99986770e-01],\n",
       "       [6.92196700e-03, 9.93056240e-01, 2.17502550e-05],\n",
       "       [1.49078120e-02, 9.85068140e-01, 2.41213750e-05],\n",
       "       [6.62489000e-06, 6.62595130e-06, 9.99986770e-01],\n",
       "       [1.32999640e-01, 8.66209270e-01, 7.91120750e-04],\n",
       "       [3.67082240e-03, 9.95871840e-01, 4.57240470e-04],\n",
       "       [5.76195800e-06, 2.60178990e-05, 9.99968200e-01],\n",
       "       [3.52007570e-04, 7.93922400e-04, 9.98854040e-01],\n",
       "       [9.99789660e-01, 2.10306550e-04, 1.39290620e-10],\n",
       "       [9.97109950e-01, 2.02856450e-03, 8.61511500e-04],\n",
       "       [9.99976900e-01, 1.15024680e-07, 2.30155910e-05],\n",
       "       [6.51404900e-01, 3.48153500e-01, 4.41603220e-04],\n",
       "       [1.22603380e-03, 9.98748660e-01, 2.52517400e-05],\n",
       "       [6.92196700e-03, 9.93056240e-01, 2.17502550e-05],\n",
       "       [8.90664450e-05, 5.91487700e-04, 9.99319430e-01],\n",
       "       [6.09711160e-04, 9.99390000e-01, 1.86577180e-07],\n",
       "       [9.99136150e-01, 7.45671450e-04, 1.18150350e-04],\n",
       "       [1.49078120e-02, 9.85068140e-01, 2.41213750e-05],\n",
       "       [1.63158980e-02, 9.83624100e-01, 6.00582680e-05],\n",
       "       [3.52007570e-04, 7.93922400e-04, 9.98854040e-01],\n",
       "       [5.76195800e-06, 2.60178990e-05, 9.99968200e-01],\n",
       "       [9.99999900e-01, 1.66914120e-07, 8.54308100e-09],\n",
       "       [9.99999640e-01, 3.42777900e-07, 2.56265840e-08],\n",
       "       [3.52007570e-04, 7.93922400e-04, 9.98854040e-01],\n",
       "       [1.65521990e-02, 9.83377000e-01, 7.07603000e-05],\n",
       "       [8.90664450e-05, 5.91487700e-04, 9.99319430e-01],\n",
       "       [3.52007570e-04, 7.93922400e-04, 9.98854040e-01],\n",
       "       [5.93672600e-03, 9.94052470e-01, 1.08416050e-05],\n",
       "       [9.99999760e-01, 1.11365450e-07, 7.30567040e-08],\n",
       "       [2.04979800e-01, 7.90116250e-01, 4.90396400e-03],\n",
       "       [1.81940440e-02, 2.29828160e-04, 9.81576100e-01],\n",
       "       [9.99997850e-01, 2.08807750e-06, 3.73455360e-08],\n",
       "       [2.43312730e-03, 9.97566940e-01, 2.80415960e-09],\n",
       "       [4.93375350e-03, 9.95005550e-01, 6.07636300e-05],\n",
       "       [6.92196700e-03, 9.93056240e-01, 2.17502550e-05],\n",
       "       [3.52007570e-04, 7.93922400e-04, 9.98854040e-01],\n",
       "       [4.82237430e-04, 9.94670800e-01, 4.84697470e-03],\n",
       "       [3.52007570e-04, 7.93922400e-04, 9.98854040e-01],\n",
       "       [9.99970800e-01, 1.79482980e-05, 1.12515260e-05],\n",
       "       [9.91583300e-01, 5.90123840e-03, 2.51559350e-03],\n",
       "       [2.90162190e-03, 9.97071740e-01, 2.66344720e-05],\n",
       "       [4.93375350e-03, 9.95005550e-01, 6.07636300e-05],\n",
       "       [6.62489000e-06, 6.62595130e-06, 9.99986770e-01],\n",
       "       [9.99983900e-01, 1.56842620e-05, 3.16882480e-07],\n",
       "       [1.00000000e+00, 1.09002670e-12, 2.66545940e-09],\n",
       "       [4.53715720e-03, 9.95462600e-01, 2.30233300e-07],\n",
       "       [6.62489000e-06, 6.62595130e-06, 9.99986770e-01],\n",
       "       [9.99998700e-01, 3.76784830e-08, 1.36946630e-06],\n",
       "       [1.49078120e-02, 9.85068140e-01, 2.41213750e-05],\n",
       "       [8.90664450e-05, 5.91487700e-04, 9.99319430e-01],\n",
       "       [2.41343190e-03, 9.97514250e-01, 7.22610900e-05],\n",
       "       [3.67082240e-03, 9.95871840e-01, 4.57240470e-04],\n",
       "       [9.99904160e-01, 9.57822000e-05, 1.09299195e-10],\n",
       "       [1.00000000e+00, 3.72830870e-14, 9.87848100e-09],\n",
       "       [5.76195800e-06, 2.60178990e-05, 9.99968200e-01],\n",
       "       [2.12946060e-04, 9.99001900e-01, 7.85182100e-04],\n",
       "       [5.76195800e-06, 2.60178990e-05, 9.99968200e-01],\n",
       "       [1.00000000e+00, 2.40426030e-09, 3.05360040e-08],\n",
       "       [9.99998700e-01, 9.60021400e-09, 1.32604680e-06],\n",
       "       [2.56136640e-04, 9.99717530e-01, 2.63091060e-05],\n",
       "       [1.00000000e+00, 5.73667230e-08, 8.29797700e-09],\n",
       "       [9.95988550e-01, 3.46519820e-03, 5.46263600e-04],\n",
       "       [6.62489000e-06, 6.62595130e-06, 9.99986770e-01],\n",
       "       [5.76195800e-06, 2.60178990e-05, 9.99968200e-01],\n",
       "       [6.62489000e-06, 6.62595130e-06, 9.99986770e-01],\n",
       "       [5.76195800e-06, 2.60178990e-05, 9.99968200e-01],\n",
       "       [5.76195800e-06, 2.60178990e-05, 9.99968200e-01],\n",
       "       [1.63158980e-02, 9.83624100e-01, 6.00582680e-05],\n",
       "       [8.01998300e-05, 9.99907600e-01, 1.22170130e-05],\n",
       "       [4.93375350e-03, 9.95005550e-01, 6.07636300e-05],\n",
       "       [4.53715720e-03, 9.95462600e-01, 2.30233300e-07],\n",
       "       [9.99989750e-01, 1.02850790e-05, 1.55635060e-08],\n",
       "       [3.52007570e-04, 7.93922400e-04, 9.98854040e-01],\n",
       "       [9.95329400e-01, 4.67047000e-03, 1.31584900e-07],\n",
       "       [9.99916550e-01, 8.27171900e-05, 7.24304900e-07],\n",
       "       [6.62489000e-06, 6.62595130e-06, 9.99986770e-01],\n",
       "       [5.76195800e-06, 2.60178990e-05, 9.99968200e-01],\n",
       "       [2.41343190e-03, 9.97514250e-01, 7.22610900e-05],\n",
       "       [6.92196700e-03, 9.93056240e-01, 2.17502550e-05],\n",
       "       [2.12946060e-04, 9.99001900e-01, 7.85182100e-04],\n",
       "       [6.62489000e-06, 6.62595130e-06, 9.99986770e-01],\n",
       "       [9.99073600e-01, 9.26329200e-04, 9.20426400e-09],\n",
       "       [2.84750880e-06, 9.99986400e-01, 1.07121390e-05],\n",
       "       [8.90664450e-05, 5.91487700e-04, 9.99319430e-01],\n",
       "       [5.76195800e-06, 2.60178990e-05, 9.99968200e-01],\n",
       "       [8.90664450e-05, 5.91487700e-04, 9.99319430e-01],\n",
       "       [9.55570600e-01, 4.09709800e-02, 3.45855400e-03],\n",
       "       [5.76195800e-06, 2.60178990e-05, 9.99968200e-01],\n",
       "       [6.62489000e-06, 6.62595130e-06, 9.99986770e-01],\n",
       "       [6.62489000e-06, 6.62595130e-06, 9.99986770e-01],\n",
       "       [1.22603380e-03, 9.98748660e-01, 2.52517400e-05],\n",
       "       [5.20650900e-05, 9.99767600e-01, 1.80315650e-04],\n",
       "       [9.84793300e-01, 1.51313070e-02, 7.53234560e-05],\n",
       "       [9.97410000e-01, 7.88260700e-04, 1.80168660e-03],\n",
       "       [3.52007570e-04, 7.93922400e-04, 9.98854040e-01],\n",
       "       [5.64692000e-01, 4.34938760e-01, 3.69241520e-04],\n",
       "       [5.20650900e-05, 9.99767600e-01, 1.80315650e-04],\n",
       "       [9.99984600e-01, 1.18717180e-05, 3.42875570e-06],\n",
       "       [3.67082240e-03, 9.95871840e-01, 4.57240470e-04],\n",
       "       [3.52007570e-04, 7.93922400e-04, 9.98854040e-01],\n",
       "       [3.52007570e-04, 7.93922400e-04, 9.98854040e-01],\n",
       "       [8.90664450e-05, 5.91487700e-04, 9.99319430e-01],\n",
       "       [1.00000000e+00, 5.73667230e-08, 8.29797700e-09],\n",
       "       [1.47139150e-03, 9.98528240e-01, 3.78363240e-07],\n",
       "       [9.95104100e-01, 3.51385910e-03, 1.38205140e-03],\n",
       "       [5.76195800e-06, 2.60178990e-05, 9.99968200e-01],\n",
       "       [2.38043020e-03, 9.97093100e-01, 5.26401850e-04],\n",
       "       [6.62489000e-06, 6.62595130e-06, 9.99986770e-01],\n",
       "       [1.00000000e+00, 5.02449120e-12, 5.10103430e-09],\n",
       "       [3.44202200e-01, 6.55686800e-01, 1.10971410e-04],\n",
       "       [1.65521990e-02, 9.83377000e-01, 7.07603000e-05],\n",
       "       [3.20579300e-03, 9.96722040e-01, 7.21059260e-05],\n",
       "       [6.62489000e-06, 6.62595130e-06, 9.99986770e-01],\n",
       "       [5.76195800e-06, 2.60178990e-05, 9.99968200e-01],\n",
       "       [2.15680600e-01, 7.70481940e-01, 1.38375545e-02],\n",
       "       [9.99998200e-01, 1.92875280e-08, 1.81020830e-06],\n",
       "       [3.52007570e-04, 7.93922400e-04, 9.98854040e-01],\n",
       "       [9.99546100e-01, 2.51787160e-04, 2.02115360e-04],\n",
       "       [9.00135600e-01, 8.83823800e-02, 1.14821745e-02],\n",
       "       [1.28982980e-04, 9.99820300e-01, 5.07987170e-05],\n",
       "       [9.99970440e-01, 2.93380700e-05, 2.09503820e-07],\n",
       "       [9.96317400e-01, 3.68023780e-03, 2.43125800e-06],\n",
       "       [6.27699900e-01, 3.71930750e-01, 3.69364480e-04],\n",
       "       [7.17543660e-06, 9.99954940e-01, 3.79286760e-05],\n",
       "       [5.76195800e-06, 2.60178990e-05, 9.99968200e-01],\n",
       "       [5.76195800e-06, 2.60178990e-05, 9.99968200e-01],\n",
       "       [8.90664450e-05, 5.91487700e-04, 9.99319430e-01],\n",
       "       [1.22603380e-03, 9.98748660e-01, 2.52517400e-05],\n",
       "       [2.43312730e-03, 9.97566940e-01, 2.80415960e-09],\n",
       "       [2.56136640e-04, 9.99717530e-01, 2.63091060e-05],\n",
       "       [3.52007570e-04, 7.93922400e-04, 9.98854040e-01],\n",
       "       [5.76195800e-06, 2.60178990e-05, 9.99968200e-01],\n",
       "       [9.99998570e-01, 8.28357600e-09, 1.48385450e-06],\n",
       "       [4.78956940e-03, 9.94911850e-01, 2.98612900e-04],\n",
       "       [8.90664450e-05, 5.91487700e-04, 9.99319430e-01],\n",
       "       [6.09711160e-04, 9.99390000e-01, 1.86577180e-07],\n",
       "       [8.61546460e-01, 1.38317870e-01, 1.35687570e-04],\n",
       "       [1.65521990e-02, 9.83377000e-01, 7.07603000e-05],\n",
       "       [6.62489000e-06, 6.62595130e-06, 9.99986770e-01],\n",
       "       [9.99703200e-01, 2.96260430e-04, 5.29780500e-07],\n",
       "       [6.92196700e-03, 9.93056240e-01, 2.17502550e-05],\n",
       "       [5.20650900e-05, 9.99767600e-01, 1.80315650e-04],\n",
       "       [1.82173660e-02, 9.80961740e-01, 8.20883200e-04],\n",
       "       [4.82237430e-04, 9.94670800e-01, 4.84697470e-03],\n",
       "       [1.34305520e-03, 9.98630940e-01, 2.59142600e-05],\n",
       "       [2.90162190e-03, 9.97071740e-01, 2.66344720e-05],\n",
       "       [1.00000000e+00, 2.47944440e-09, 3.49212480e-09],\n",
       "       [9.89563500e-01, 1.03650580e-02, 7.15453350e-05],\n",
       "       [7.94774350e-01, 3.38215820e-03, 2.01843520e-01],\n",
       "       [9.99999760e-01, 2.53824000e-07, 4.86476960e-08],\n",
       "       [5.76195800e-06, 2.60178990e-05, 9.99968200e-01],\n",
       "       [3.20579300e-03, 9.96722040e-01, 7.21059260e-05],\n",
       "       [1.34019960e-03, 9.97478900e-01, 1.18082520e-03],\n",
       "       [2.12946060e-04, 9.99001900e-01, 7.85182100e-04],\n",
       "       [9.99966600e-01, 3.13753600e-05, 2.01050330e-06],\n",
       "       [5.76195800e-06, 2.60178990e-05, 9.99968200e-01],\n",
       "       [9.99347400e-01, 5.65470550e-04, 8.70727300e-05],\n",
       "       [9.96493500e-01, 3.42296790e-03, 8.34520400e-05],\n",
       "       [9.99903200e-01, 9.67431000e-05, 9.68779640e-11],\n",
       "       [9.97750600e-01, 2.22447930e-03, 2.49727500e-05],\n",
       "       [6.62489000e-06, 6.62595130e-06, 9.99986770e-01],\n",
       "       [9.87446400e-01, 1.25535230e-02, 9.71548300e-08],\n",
       "       [6.62489000e-06, 6.62595130e-06, 9.99986770e-01],\n",
       "       [8.90664450e-05, 5.91487700e-04, 9.99319430e-01],\n",
       "       [5.20650900e-05, 9.99767600e-01, 1.80315650e-04],\n",
       "       [3.22350260e-01, 6.77496400e-01, 1.53315370e-04],\n",
       "       [5.76195800e-06, 2.60178990e-05, 9.99968200e-01],\n",
       "       [9.99287550e-01, 1.76289610e-04, 5.36152740e-04],\n",
       "       [6.62489000e-06, 6.62595130e-06, 9.99986770e-01]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob4 = df_proba4[df_proba4['phage']=='pyopresabsSTCC_qual'].iloc[:,-3:]\n",
    "y_prob4 = y_prob4.to_numpy()\n",
    "y_prob4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo4 = rocauc_ovo(y_test_over, y_prob4, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr4 = rocauc_ovr(y_test_over, y_prob4, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9990922881190056"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovos = [ovo1, ovo2, ovo3, ovo4]\n",
    "np.mean(ovos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0009222144698700393"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(ovos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9990922881190056"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovrs = [ovr1, ovr2, ovr3, ovr4]\n",
    "np.mean(ovrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0009222144698700393"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(ovrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs = [acc_test_over, acc_test_over2, acc_test_over3, acc_test_over4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling test accuracy mean: 96.56%\n"
     ]
    }
   ],
   "source": [
    "mean = np.mean(accs)\n",
    "print('over-sampling test accuracy mean: %.2f%%' % (mean*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling test accuracy standard deviation: 0.00979737510868992\n"
     ]
    }
   ],
   "source": [
    "std = np.std(accs)\n",
    "print('over-sampling test accuracy standard deviation:', std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs_train = [np.mean(hist1_over.history['accuracy']), np.mean(hist1_over2.history['accuracy']), np.mean(hist1_over3.history['accuracy']),\n",
    "             np.mean(hist1_over4.history['accuracy'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy mean: 100.00%\n"
     ]
    }
   ],
   "source": [
    "mean_train = np.mean(accs_train)\n",
    "print('over-sampling train accuracy mean: %.2f%%' % (mean_train*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy standard deviation: 0.0\n"
     ]
    }
   ],
   "source": [
    "std_train = np.std(accs_train)\n",
    "print('over-sampling train accuracy standard deviation:', std_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=567,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat5 = pd.DataFrame(X_test_over[:,0])\n",
    "dat5['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS386</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS205</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS205</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>BCH-SA-12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>NRS049</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>NRS022</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>NRS236</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>196 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0  test\n",
       "0       NRS255     2\n",
       "1       NRS255     2\n",
       "2       NRS386     1\n",
       "3       NRS205     2\n",
       "4       NRS205     2\n",
       "..         ...   ...\n",
       "191  BCH-SA-12     0\n",
       "192     NRS049     0\n",
       "193     NRS022     0\n",
       "194     NRS236     1\n",
       "195     NRS148     2\n",
       "\n",
       "[196 rows x 2 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### add regularizer and dropout\n",
    "model1_over5 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],), activity_regularizer=l1(0.001)),\n",
    "    Dense(3, activation='softmax'),\n",
    "    Dropout(0.2, ),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over5.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 455 samples, validate on 196 samples\n",
      "Epoch 1/100\n",
      "455/455 [==============================] - 0s 633us/step - loss: 9.5239 - accuracy: 0.4549 - val_loss: 6.0171 - val_accuracy: 0.6122\n",
      "Epoch 2/100\n",
      "455/455 [==============================] - 0s 180us/step - loss: 7.7914 - accuracy: 0.5846 - val_loss: 4.2569 - val_accuracy: 0.7551\n",
      "Epoch 3/100\n",
      "455/455 [==============================] - 0s 205us/step - loss: 6.7254 - accuracy: 0.6242 - val_loss: 3.2978 - val_accuracy: 0.7959\n",
      "Epoch 4/100\n",
      "455/455 [==============================] - 0s 221us/step - loss: 5.3537 - accuracy: 0.6352 - val_loss: 2.6666 - val_accuracy: 0.7857\n",
      "Epoch 5/100\n",
      "455/455 [==============================] - 0s 200us/step - loss: 4.5151 - accuracy: 0.6462 - val_loss: 2.0162 - val_accuracy: 0.8265\n",
      "Epoch 6/100\n",
      "455/455 [==============================] - 0s 138us/step - loss: 3.9507 - accuracy: 0.6593 - val_loss: 1.5635 - val_accuracy: 0.8112\n",
      "Epoch 7/100\n",
      "455/455 [==============================] - 0s 141us/step - loss: 3.8197 - accuracy: 0.6659 - val_loss: 1.2140 - val_accuracy: 0.8265\n",
      "Epoch 8/100\n",
      "455/455 [==============================] - 0s 194us/step - loss: 3.0351 - accuracy: 0.7143 - val_loss: 1.0700 - val_accuracy: 0.8367\n",
      "Epoch 9/100\n",
      "455/455 [==============================] - 0s 118us/step - loss: 3.1079 - accuracy: 0.7165 - val_loss: 1.0585 - val_accuracy: 0.8214\n",
      "Epoch 10/100\n",
      "455/455 [==============================] - 0s 109us/step - loss: 3.1826 - accuracy: 0.6725 - val_loss: 1.0695 - val_accuracy: 0.8214\n",
      "Epoch 11/100\n",
      "455/455 [==============================] - 0s 148us/step - loss: 2.8481 - accuracy: 0.7319 - val_loss: 1.0000 - val_accuracy: 0.8418\n",
      "Epoch 12/100\n",
      "455/455 [==============================] - 0s 186us/step - loss: 2.8911 - accuracy: 0.7077 - val_loss: 0.9639 - val_accuracy: 0.8265\n",
      "Epoch 13/100\n",
      "455/455 [==============================] - 0s 186us/step - loss: 3.1579 - accuracy: 0.6703 - val_loss: 1.0718 - val_accuracy: 0.8367\n",
      "Epoch 14/100\n",
      "455/455 [==============================] - 0s 211us/step - loss: 3.0323 - accuracy: 0.6901 - val_loss: 1.0282 - val_accuracy: 0.8316\n",
      "Epoch 15/100\n",
      "455/455 [==============================] - 0s 177us/step - loss: 2.7212 - accuracy: 0.6945 - val_loss: 1.0497 - val_accuracy: 0.8316\n",
      "Epoch 16/100\n",
      "455/455 [==============================] - 0s 105us/step - loss: 2.6599 - accuracy: 0.7231 - val_loss: 0.9657 - val_accuracy: 0.8163\n",
      "Epoch 17/100\n",
      "455/455 [==============================] - 0s 103us/step - loss: 2.8548 - accuracy: 0.6989 - val_loss: 0.9348 - val_accuracy: 0.8265\n",
      "Epoch 18/100\n",
      "455/455 [==============================] - 0s 111us/step - loss: 2.9711 - accuracy: 0.7099 - val_loss: 1.0007 - val_accuracy: 0.8571\n",
      "Epoch 19/100\n",
      "455/455 [==============================] - 0s 122us/step - loss: 2.8262 - accuracy: 0.7011 - val_loss: 0.9859 - val_accuracy: 0.8469\n",
      "Epoch 20/100\n",
      "455/455 [==============================] - 0s 317us/step - loss: 2.6510 - accuracy: 0.7055 - val_loss: 0.9337 - val_accuracy: 0.8571\n",
      "Epoch 21/100\n",
      "455/455 [==============================] - 0s 234us/step - loss: 2.3883 - accuracy: 0.7165 - val_loss: 0.9438 - val_accuracy: 0.8316\n",
      "Epoch 22/100\n",
      "455/455 [==============================] - 0s 216us/step - loss: 2.7869 - accuracy: 0.6857 - val_loss: 0.8686 - val_accuracy: 0.8724\n",
      "Epoch 23/100\n",
      "455/455 [==============================] - 0s 200us/step - loss: 2.2164 - accuracy: 0.7648 - val_loss: 0.8138 - val_accuracy: 0.9031\n",
      "Epoch 24/100\n",
      "455/455 [==============================] - 0s 177us/step - loss: 2.1551 - accuracy: 0.7692 - val_loss: 0.7635 - val_accuracy: 0.9286\n",
      "Epoch 25/100\n",
      "455/455 [==============================] - 0s 233us/step - loss: 2.0607 - accuracy: 0.7868 - val_loss: 0.7425 - val_accuracy: 0.9235\n",
      "Epoch 26/100\n",
      "455/455 [==============================] - 0s 222us/step - loss: 2.5947 - accuracy: 0.7407 - val_loss: 0.7692 - val_accuracy: 0.9082\n",
      "Epoch 27/100\n",
      "455/455 [==============================] - 0s 233us/step - loss: 2.4308 - accuracy: 0.7538 - val_loss: 0.7878 - val_accuracy: 0.9133\n",
      "Epoch 28/100\n",
      "455/455 [==============================] - 0s 296us/step - loss: 2.5560 - accuracy: 0.7516 - val_loss: 0.7806 - val_accuracy: 0.9082\n",
      "Epoch 29/100\n",
      "455/455 [==============================] - 0s 201us/step - loss: 2.3816 - accuracy: 0.7429 - val_loss: 0.8034 - val_accuracy: 0.8776\n",
      "Epoch 30/100\n",
      "455/455 [==============================] - 0s 220us/step - loss: 1.9101 - accuracy: 0.7890 - val_loss: 0.7830 - val_accuracy: 0.9133\n",
      "Epoch 31/100\n",
      "455/455 [==============================] - 0s 273us/step - loss: 1.9672 - accuracy: 0.7956 - val_loss: 0.7523 - val_accuracy: 0.9133\n",
      "Epoch 32/100\n",
      "455/455 [==============================] - 0s 214us/step - loss: 2.0276 - accuracy: 0.7692 - val_loss: 0.7399 - val_accuracy: 0.9184\n",
      "Epoch 33/100\n",
      "455/455 [==============================] - 0s 211us/step - loss: 2.0403 - accuracy: 0.7802 - val_loss: 0.7684 - val_accuracy: 0.9082\n",
      "Epoch 34/100\n",
      "455/455 [==============================] - ETA: 0s - loss: 1.7947 - accuracy: 0.79 - 0s 227us/step - loss: 1.7835 - accuracy: 0.7978 - val_loss: 0.7371 - val_accuracy: 0.9133\n",
      "Epoch 35/100\n",
      "455/455 [==============================] - 0s 218us/step - loss: 2.2738 - accuracy: 0.7429 - val_loss: 0.7367 - val_accuracy: 0.9133\n",
      "Epoch 36/100\n",
      "455/455 [==============================] - 0s 111us/step - loss: 2.1658 - accuracy: 0.7604 - val_loss: 0.7422 - val_accuracy: 0.9133\n",
      "Epoch 37/100\n",
      "455/455 [==============================] - 0s 101us/step - loss: 1.9959 - accuracy: 0.7714 - val_loss: 0.7135 - val_accuracy: 0.9082\n",
      "Epoch 38/100\n",
      "455/455 [==============================] - 0s 99us/step - loss: 1.9699 - accuracy: 0.7890 - val_loss: 0.7338 - val_accuracy: 0.9133\n",
      "Epoch 39/100\n",
      "455/455 [==============================] - 0s 101us/step - loss: 1.8344 - accuracy: 0.8022 - val_loss: 0.7234 - val_accuracy: 0.9184\n",
      "Epoch 40/100\n",
      "455/455 [==============================] - 0s 107us/step - loss: 1.9636 - accuracy: 0.7780 - val_loss: 0.7449 - val_accuracy: 0.9184\n",
      "Epoch 41/100\n",
      "455/455 [==============================] - 0s 215us/step - loss: 1.9965 - accuracy: 0.7516 - val_loss: 0.7309 - val_accuracy: 0.9286\n",
      "Epoch 42/100\n",
      "455/455 [==============================] - 0s 274us/step - loss: 2.0585 - accuracy: 0.7626 - val_loss: 0.7279 - val_accuracy: 0.9286\n",
      "Epoch 43/100\n",
      "455/455 [==============================] - 0s 260us/step - loss: 1.8653 - accuracy: 0.7846 - val_loss: 0.7213 - val_accuracy: 0.9235\n",
      "Epoch 44/100\n",
      "455/455 [==============================] - 0s 139us/step - loss: 1.9906 - accuracy: 0.7473 - val_loss: 0.7118 - val_accuracy: 0.9184\n",
      "Epoch 45/100\n",
      "455/455 [==============================] - 0s 100us/step - loss: 1.7139 - accuracy: 0.8264 - val_loss: 0.7095 - val_accuracy: 0.9388\n",
      "Epoch 46/100\n",
      "455/455 [==============================] - 0s 96us/step - loss: 1.8668 - accuracy: 0.7736 - val_loss: 0.7345 - val_accuracy: 0.9286\n",
      "Epoch 47/100\n",
      "455/455 [==============================] - 0s 97us/step - loss: 1.8382 - accuracy: 0.7780 - val_loss: 0.7445 - val_accuracy: 0.9286\n",
      "Epoch 48/100\n",
      "455/455 [==============================] - 0s 126us/step - loss: 2.0173 - accuracy: 0.7407 - val_loss: 0.7484 - val_accuracy: 0.9286\n",
      "Epoch 49/100\n",
      "455/455 [==============================] - 0s 150us/step - loss: 1.5871 - accuracy: 0.7868 - val_loss: 0.7087 - val_accuracy: 0.9337\n",
      "Epoch 50/100\n",
      "455/455 [==============================] - 0s 175us/step - loss: 1.8143 - accuracy: 0.7604 - val_loss: 0.7311 - val_accuracy: 0.9337\n",
      "Epoch 51/100\n",
      "455/455 [==============================] - 0s 143us/step - loss: 1.7528 - accuracy: 0.7824 - val_loss: 0.7308 - val_accuracy: 0.9337\n",
      "Epoch 52/100\n",
      "455/455 [==============================] - 0s 150us/step - loss: 1.7463 - accuracy: 0.7626 - val_loss: 0.7359 - val_accuracy: 0.9337\n",
      "Epoch 53/100\n",
      "455/455 [==============================] - 0s 181us/step - loss: 1.8146 - accuracy: 0.7824 - val_loss: 0.7292 - val_accuracy: 0.9388\n",
      "Epoch 54/100\n",
      "455/455 [==============================] - 0s 172us/step - loss: 1.7432 - accuracy: 0.7626 - val_loss: 0.7543 - val_accuracy: 0.9337\n",
      "Epoch 55/100\n",
      "455/455 [==============================] - 0s 179us/step - loss: 1.5603 - accuracy: 0.7802 - val_loss: 0.8100 - val_accuracy: 0.9184\n",
      "Epoch 56/100\n",
      "455/455 [==============================] - 0s 110us/step - loss: 1.6512 - accuracy: 0.7582 - val_loss: 0.8339 - val_accuracy: 0.9286\n",
      "Epoch 57/100\n",
      "455/455 [==============================] - 0s 99us/step - loss: 1.5256 - accuracy: 0.7670 - val_loss: 0.8190 - val_accuracy: 0.9439\n",
      "Epoch 58/100\n",
      "455/455 [==============================] - 0s 118us/step - loss: 1.5354 - accuracy: 0.7978 - val_loss: 0.7643 - val_accuracy: 0.9388\n",
      "Epoch 59/100\n",
      "455/455 [==============================] - 0s 136us/step - loss: 1.4799 - accuracy: 0.7912 - val_loss: 0.8239 - val_accuracy: 0.9337\n",
      "Epoch 60/100\n",
      "455/455 [==============================] - 0s 108us/step - loss: 1.5807 - accuracy: 0.7648 - val_loss: 0.8611 - val_accuracy: 0.9439\n",
      "Epoch 61/100\n",
      "455/455 [==============================] - 0s 110us/step - loss: 1.6831 - accuracy: 0.7341 - val_loss: 0.8458 - val_accuracy: 0.9490\n",
      "Epoch 62/100\n",
      "455/455 [==============================] - 0s 118us/step - loss: 1.3974 - accuracy: 0.7934 - val_loss: 0.7790 - val_accuracy: 0.9388\n",
      "Epoch 63/100\n",
      "455/455 [==============================] - 0s 127us/step - loss: 1.2317 - accuracy: 0.8176 - val_loss: 0.7462 - val_accuracy: 0.9541\n",
      "Epoch 64/100\n",
      "455/455 [==============================] - 0s 113us/step - loss: 1.3155 - accuracy: 0.7978 - val_loss: 0.7229 - val_accuracy: 0.9643\n",
      "Epoch 65/100\n",
      "455/455 [==============================] - 0s 219us/step - loss: 1.4981 - accuracy: 0.7890 - val_loss: 0.7396 - val_accuracy: 0.9541\n",
      "Epoch 66/100\n",
      "455/455 [==============================] - 0s 256us/step - loss: 1.3937 - accuracy: 0.7868 - val_loss: 0.7353 - val_accuracy: 0.9592\n",
      "Epoch 67/100\n",
      "455/455 [==============================] - 0s 300us/step - loss: 1.4794 - accuracy: 0.7626 - val_loss: 0.8166 - val_accuracy: 0.9541\n",
      "Epoch 68/100\n",
      "455/455 [==============================] - 0s 253us/step - loss: 1.3818 - accuracy: 0.7956 - val_loss: 0.7695 - val_accuracy: 0.9592\n",
      "Epoch 69/100\n",
      "455/455 [==============================] - 0s 246us/step - loss: 1.2589 - accuracy: 0.7956 - val_loss: 0.7627 - val_accuracy: 0.9592\n",
      "Epoch 70/100\n",
      "455/455 [==============================] - 0s 198us/step - loss: 1.1995 - accuracy: 0.8110 - val_loss: 0.7372 - val_accuracy: 0.9592\n",
      "Epoch 71/100\n",
      "455/455 [==============================] - 0s 123us/step - loss: 1.4462 - accuracy: 0.7868 - val_loss: 0.7701 - val_accuracy: 0.9643\n",
      "Epoch 72/100\n",
      "455/455 [==============================] - 0s 116us/step - loss: 1.3983 - accuracy: 0.7736 - val_loss: 0.7690 - val_accuracy: 0.9592\n",
      "Epoch 73/100\n",
      "455/455 [==============================] - 0s 147us/step - loss: 1.3787 - accuracy: 0.7780 - val_loss: 0.8806 - val_accuracy: 0.9490\n",
      "Epoch 74/100\n",
      "455/455 [==============================] - 0s 115us/step - loss: 1.2181 - accuracy: 0.8242 - val_loss: 0.8445 - val_accuracy: 0.9592\n",
      "Epoch 75/100\n",
      "455/455 [==============================] - 0s 124us/step - loss: 1.1606 - accuracy: 0.7824 - val_loss: 0.7749 - val_accuracy: 0.9592\n",
      "Epoch 76/100\n",
      "455/455 [==============================] - 0s 144us/step - loss: 1.2457 - accuracy: 0.8000 - val_loss: 0.7324 - val_accuracy: 0.9694\n",
      "Epoch 77/100\n",
      "455/455 [==============================] - 0s 131us/step - loss: 1.3514 - accuracy: 0.7824 - val_loss: 0.7946 - val_accuracy: 0.9592\n",
      "Epoch 78/100\n",
      "455/455 [==============================] - 0s 96us/step - loss: 1.0577 - accuracy: 0.8000 - val_loss: 0.7674 - val_accuracy: 0.9592\n",
      "Epoch 79/100\n",
      "455/455 [==============================] - 0s 103us/step - loss: 1.0916 - accuracy: 0.7978 - val_loss: 0.8122 - val_accuracy: 0.9592\n",
      "Epoch 80/100\n",
      "455/455 [==============================] - 0s 129us/step - loss: 1.1512 - accuracy: 0.7890 - val_loss: 0.7702 - val_accuracy: 0.9592\n",
      "Epoch 81/100\n",
      "455/455 [==============================] - 0s 127us/step - loss: 1.1481 - accuracy: 0.7868 - val_loss: 0.7686 - val_accuracy: 0.9592\n",
      "Epoch 82/100\n",
      "455/455 [==============================] - 0s 135us/step - loss: 1.1557 - accuracy: 0.7912 - val_loss: 0.8010 - val_accuracy: 0.9592\n",
      "Epoch 83/100\n",
      "455/455 [==============================] - 0s 175us/step - loss: 1.0623 - accuracy: 0.7956 - val_loss: 0.8280 - val_accuracy: 0.9592\n",
      "Epoch 84/100\n",
      "455/455 [==============================] - 0s 134us/step - loss: 1.1456 - accuracy: 0.7846 - val_loss: 0.7823 - val_accuracy: 0.9694\n",
      "Epoch 85/100\n",
      "455/455 [==============================] - 0s 104us/step - loss: 1.2793 - accuracy: 0.7714 - val_loss: 0.7858 - val_accuracy: 0.9643\n",
      "Epoch 86/100\n",
      "455/455 [==============================] - 0s 95us/step - loss: 1.2033 - accuracy: 0.7890 - val_loss: 0.7596 - val_accuracy: 0.9643\n",
      "Epoch 87/100\n",
      "455/455 [==============================] - 0s 97us/step - loss: 0.8994 - accuracy: 0.8330 - val_loss: 0.7469 - val_accuracy: 0.9643\n",
      "Epoch 88/100\n",
      "455/455 [==============================] - 0s 142us/step - loss: 1.0565 - accuracy: 0.8110 - val_loss: 0.7310 - val_accuracy: 0.9694\n",
      "Epoch 89/100\n",
      "455/455 [==============================] - 0s 124us/step - loss: 0.8638 - accuracy: 0.8110 - val_loss: 0.7470 - val_accuracy: 0.9694\n",
      "Epoch 90/100\n",
      "455/455 [==============================] - 0s 99us/step - loss: 0.9974 - accuracy: 0.7802 - val_loss: 0.7086 - val_accuracy: 0.9694\n",
      "Epoch 91/100\n",
      "455/455 [==============================] - 0s 96us/step - loss: 1.0599 - accuracy: 0.8088 - val_loss: 0.7186 - val_accuracy: 0.9694\n",
      "Epoch 92/100\n",
      "455/455 [==============================] - 0s 94us/step - loss: 1.0642 - accuracy: 0.8000 - val_loss: 0.7192 - val_accuracy: 0.9643\n",
      "Epoch 93/100\n",
      "455/455 [==============================] - 0s 101us/step - loss: 1.0499 - accuracy: 0.7846 - val_loss: 0.7156 - val_accuracy: 0.9694\n",
      "Epoch 94/100\n",
      "455/455 [==============================] - 0s 96us/step - loss: 1.0681 - accuracy: 0.7670 - val_loss: 0.7441 - val_accuracy: 0.9643\n",
      "Epoch 95/100\n",
      "455/455 [==============================] - 0s 96us/step - loss: 0.8848 - accuracy: 0.8374 - val_loss: 0.6852 - val_accuracy: 0.9694\n",
      "Epoch 96/100\n",
      "455/455 [==============================] - 0s 96us/step - loss: 1.0662 - accuracy: 0.7912 - val_loss: 0.7314 - val_accuracy: 0.9694\n",
      "Epoch 97/100\n",
      "455/455 [==============================] - 0s 95us/step - loss: 0.8786 - accuracy: 0.8286 - val_loss: 0.7290 - val_accuracy: 0.9694\n",
      "Epoch 98/100\n",
      "455/455 [==============================] - 0s 95us/step - loss: 1.0843 - accuracy: 0.7473 - val_loss: 0.7136 - val_accuracy: 0.9694\n",
      "Epoch 99/100\n",
      "455/455 [==============================] - 0s 115us/step - loss: 0.7259 - accuracy: 0.8440 - val_loss: 0.7087 - val_accuracy: 0.9694\n",
      "Epoch 100/100\n",
      "455/455 [==============================] - 0s 133us/step - loss: 0.9352 - accuracy: 0.8088 - val_loss: 0.7423 - val_accuracy: 0.9643\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a38b632e8>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over5.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196/196 [==============================] - 0s 115us/step\n",
      "over-sampling test accuracy: 96.94%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over5 = model1_over5.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over5*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 1, 2, 2, 1, 1, 0, 2, 2, 1, 2, 2, 1, 0, 0, 1, 0, 1, 2, 0, 1,\n",
       "       0, 2, 0, 0, 1, 0, 2, 2, 2, 0, 1, 1, 2, 1, 1, 2, 0, 2, 1, 1, 1, 0,\n",
       "       2, 0, 1, 0, 0, 1, 1, 1, 2, 2, 1, 0, 0, 2, 2, 2, 1, 0, 1, 2, 2, 1,\n",
       "       0, 1, 2, 0, 1, 1, 0, 0, 2, 0, 1, 1, 2, 2, 2, 0, 1, 2, 0, 2, 1, 0,\n",
       "       2, 0, 2, 0, 1, 1, 0, 1, 0, 2, 0, 1, 1, 0, 2, 1, 1, 1, 0, 1, 2, 2,\n",
       "       1, 2, 0, 0, 1, 0, 2, 1, 2, 1, 1, 1, 0, 1, 2, 1, 2, 1, 0, 1, 0, 2,\n",
       "       0, 0, 1, 1, 2, 0, 1, 0, 2, 1, 1, 2, 2, 0, 2, 0, 0, 0, 0, 2, 1, 2,\n",
       "       1, 1, 2, 2, 0, 0, 1, 0, 2, 1, 0, 1, 2, 2, 0, 2, 0, 2, 2, 2, 2, 2,\n",
       "       1, 1, 0, 1, 0, 1, 2, 1, 1, 2, 1, 0, 1, 1, 2, 0, 1, 0, 1, 2])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred5 = model1_over5.predict_classes(X_test_over)\n",
    "pred5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS386</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS205</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS205</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>BCH-SA-12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>NRS049</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>NRS022</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>NRS236</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>196 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0  test  pred\n",
       "0       NRS255     2     2\n",
       "1       NRS255     2     2\n",
       "2       NRS386     1     1\n",
       "3       NRS205     2     2\n",
       "4       NRS205     2     2\n",
       "..         ...   ...   ...\n",
       "191  BCH-SA-12     0     0\n",
       "192     NRS049     0     1\n",
       "193     NRS022     0     0\n",
       "194     NRS236     1     1\n",
       "195     NRS148     2     2\n",
       "\n",
       "[196 rows x 3 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat5['pred'] = pred5\n",
    "dat5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba5 = model1_over5.predict_proba(X_test_over)\n",
    "dat_proba5 = pd.DataFrame(proba5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.623269e-08</td>\n",
       "      <td>1.073980e-07</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.623269e-08</td>\n",
       "      <td>1.073980e-07</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.623193e-04</td>\n",
       "      <td>9.991296e-01</td>\n",
       "      <td>2.080995e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.763637e-08</td>\n",
       "      <td>2.140663e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.763637e-08</td>\n",
       "      <td>2.140663e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.152503e-09</td>\n",
       "      <td>1.898730e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>8.401357e-11</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.209735e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.755084e-10</td>\n",
       "      <td>1.974275e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>1.357345e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.293117e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>4.074704e-08</td>\n",
       "      <td>2.329201e-08</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>196 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0             1             2\n",
       "0    5.623269e-08  1.073980e-07  9.999999e-01\n",
       "1    5.623269e-08  1.073980e-07  9.999999e-01\n",
       "2    6.623193e-04  9.991296e-01  2.080995e-04\n",
       "3    3.763637e-08  2.140663e-08  1.000000e+00\n",
       "4    3.763637e-08  2.140663e-08  1.000000e+00\n",
       "..            ...           ...           ...\n",
       "191  1.000000e+00  1.152503e-09  1.898730e-09\n",
       "192  8.401357e-11  1.000000e+00  3.209735e-13\n",
       "193  1.000000e+00  4.755084e-10  1.974275e-10\n",
       "194  1.357345e-08  1.000000e+00  1.293117e-10\n",
       "195  4.074704e-08  2.329201e-08  9.999999e-01\n",
       "\n",
       "[196 rows x 3 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba5.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba5.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat5.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/5pyopST.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 455 samples, validate on 196 samples\n",
      "Epoch 1/100\n",
      "455/455 [==============================] - 0s 165us/step - loss: 1.0469 - accuracy: 0.7714 - val_loss: 0.6993 - val_accuracy: 0.9643\n",
      "Epoch 2/100\n",
      "455/455 [==============================] - 0s 155us/step - loss: 0.9741 - accuracy: 0.7912 - val_loss: 0.7155 - val_accuracy: 0.9694\n",
      "Epoch 3/100\n",
      "455/455 [==============================] - 0s 147us/step - loss: 0.8303 - accuracy: 0.8286 - val_loss: 0.7040 - val_accuracy: 0.9694\n",
      "Epoch 4/100\n",
      "455/455 [==============================] - 0s 133us/step - loss: 0.8342 - accuracy: 0.8044 - val_loss: 0.6916 - val_accuracy: 0.9694\n",
      "Epoch 5/100\n",
      "455/455 [==============================] - 0s 130us/step - loss: 0.8871 - accuracy: 0.8066 - val_loss: 0.6690 - val_accuracy: 0.9694\n",
      "Epoch 6/100\n",
      "455/455 [==============================] - 0s 129us/step - loss: 0.9368 - accuracy: 0.8176 - val_loss: 0.6588 - val_accuracy: 0.9643\n",
      "Epoch 7/100\n",
      "455/455 [==============================] - 0s 135us/step - loss: 0.8087 - accuracy: 0.8440 - val_loss: 0.6547 - val_accuracy: 0.9643\n",
      "Epoch 8/100\n",
      "455/455 [==============================] - 0s 170us/step - loss: 0.8561 - accuracy: 0.8022 - val_loss: 0.6453 - val_accuracy: 0.9643\n",
      "Epoch 9/100\n",
      "455/455 [==============================] - 0s 167us/step - loss: 1.0923 - accuracy: 0.7934 - val_loss: 0.6652 - val_accuracy: 0.9694\n",
      "Epoch 10/100\n",
      "455/455 [==============================] - 0s 146us/step - loss: 0.9873 - accuracy: 0.7692 - val_loss: 0.6852 - val_accuracy: 0.9643\n",
      "Epoch 11/100\n",
      "455/455 [==============================] - 0s 138us/step - loss: 0.9162 - accuracy: 0.7802 - val_loss: 0.7166 - val_accuracy: 0.9643\n",
      "Epoch 12/100\n",
      "455/455 [==============================] - 0s 125us/step - loss: 0.9693 - accuracy: 0.7978 - val_loss: 0.7745 - val_accuracy: 0.9592\n",
      "Epoch 13/100\n",
      "455/455 [==============================] - 0s 146us/step - loss: 0.8485 - accuracy: 0.8286 - val_loss: 0.7310 - val_accuracy: 0.9694\n",
      "Epoch 14/100\n",
      "455/455 [==============================] - 0s 130us/step - loss: 0.8375 - accuracy: 0.8198 - val_loss: 0.7172 - val_accuracy: 0.9694\n",
      "Epoch 15/100\n",
      "455/455 [==============================] - 0s 126us/step - loss: 0.9145 - accuracy: 0.7934 - val_loss: 0.7005 - val_accuracy: 0.9694\n",
      "Epoch 16/100\n",
      "455/455 [==============================] - 0s 156us/step - loss: 0.8429 - accuracy: 0.7912 - val_loss: 0.7132 - val_accuracy: 0.9694\n",
      "Epoch 17/100\n",
      "455/455 [==============================] - 0s 159us/step - loss: 0.7779 - accuracy: 0.8198 - val_loss: 0.6443 - val_accuracy: 0.9694\n",
      "Epoch 18/100\n",
      "455/455 [==============================] - 0s 150us/step - loss: 0.9236 - accuracy: 0.7934 - val_loss: 0.6432 - val_accuracy: 0.9694\n",
      "Epoch 19/100\n",
      "455/455 [==============================] - 0s 159us/step - loss: 0.8894 - accuracy: 0.8220 - val_loss: 0.6836 - val_accuracy: 0.9643\n",
      "Epoch 20/100\n",
      "455/455 [==============================] - 0s 144us/step - loss: 0.8759 - accuracy: 0.7934 - val_loss: 0.6313 - val_accuracy: 0.9694\n",
      "Epoch 21/100\n",
      "455/455 [==============================] - 0s 118us/step - loss: 0.8633 - accuracy: 0.7934 - val_loss: 0.6523 - val_accuracy: 0.9643\n",
      "Epoch 22/100\n",
      "455/455 [==============================] - 0s 112us/step - loss: 0.7603 - accuracy: 0.7978 - val_loss: 0.6206 - val_accuracy: 0.9694\n",
      "Epoch 23/100\n",
      "455/455 [==============================] - 0s 121us/step - loss: 0.7742 - accuracy: 0.7824 - val_loss: 0.5984 - val_accuracy: 0.9694\n",
      "Epoch 24/100\n",
      "455/455 [==============================] - 0s 109us/step - loss: 0.8479 - accuracy: 0.8066 - val_loss: 0.6333 - val_accuracy: 0.9694\n",
      "Epoch 25/100\n",
      "455/455 [==============================] - 0s 115us/step - loss: 0.7825 - accuracy: 0.7890 - val_loss: 0.6415 - val_accuracy: 0.9643\n",
      "Epoch 26/100\n",
      "455/455 [==============================] - 0s 114us/step - loss: 0.8032 - accuracy: 0.7824 - val_loss: 0.6353 - val_accuracy: 0.9694\n",
      "Epoch 27/100\n",
      "455/455 [==============================] - 0s 112us/step - loss: 0.7597 - accuracy: 0.7978 - val_loss: 0.6680 - val_accuracy: 0.9694\n",
      "Epoch 28/100\n",
      "455/455 [==============================] - 0s 122us/step - loss: 0.7949 - accuracy: 0.7604 - val_loss: 0.6327 - val_accuracy: 0.9643\n",
      "Epoch 29/100\n",
      "455/455 [==============================] - 0s 109us/step - loss: 0.7917 - accuracy: 0.7824 - val_loss: 0.6186 - val_accuracy: 0.9694\n",
      "Epoch 30/100\n",
      "455/455 [==============================] - 0s 104us/step - loss: 0.8475 - accuracy: 0.8044 - val_loss: 0.6325 - val_accuracy: 0.9694\n",
      "Epoch 31/100\n",
      "455/455 [==============================] - 0s 106us/step - loss: 0.9011 - accuracy: 0.7890 - val_loss: 0.7386 - val_accuracy: 0.9541\n",
      "Epoch 32/100\n",
      "455/455 [==============================] - 0s 108us/step - loss: 0.7474 - accuracy: 0.8374 - val_loss: 0.6131 - val_accuracy: 0.9694\n",
      "Epoch 33/100\n",
      "455/455 [==============================] - 0s 107us/step - loss: 0.7490 - accuracy: 0.8352 - val_loss: 0.6541 - val_accuracy: 0.9694\n",
      "Epoch 34/100\n",
      "455/455 [==============================] - 0s 114us/step - loss: 0.8108 - accuracy: 0.8044 - val_loss: 0.6923 - val_accuracy: 0.9643\n",
      "Epoch 35/100\n",
      "455/455 [==============================] - 0s 134us/step - loss: 0.8568 - accuracy: 0.8066 - val_loss: 0.7390 - val_accuracy: 0.9541\n",
      "Epoch 36/100\n",
      "455/455 [==============================] - 0s 165us/step - loss: 0.7725 - accuracy: 0.7868 - val_loss: 0.6642 - val_accuracy: 0.9643\n",
      "Epoch 37/100\n",
      "455/455 [==============================] - 0s 132us/step - loss: 0.7617 - accuracy: 0.8044 - val_loss: 0.5822 - val_accuracy: 0.9745\n",
      "Epoch 38/100\n",
      "455/455 [==============================] - 0s 98us/step - loss: 0.7030 - accuracy: 0.8176 - val_loss: 0.6647 - val_accuracy: 0.9643\n",
      "Epoch 39/100\n",
      "455/455 [==============================] - 0s 99us/step - loss: 0.7027 - accuracy: 0.8044 - val_loss: 0.5885 - val_accuracy: 0.9694\n",
      "Epoch 40/100\n",
      "455/455 [==============================] - 0s 103us/step - loss: 0.7998 - accuracy: 0.8022 - val_loss: 0.6180 - val_accuracy: 0.9694\n",
      "Epoch 41/100\n",
      "455/455 [==============================] - 0s 133us/step - loss: 0.7987 - accuracy: 0.8132 - val_loss: 0.6810 - val_accuracy: 0.9592\n",
      "Epoch 42/100\n",
      "455/455 [==============================] - 0s 260us/step - loss: 0.6534 - accuracy: 0.8308 - val_loss: 0.5894 - val_accuracy: 0.9745\n",
      "Epoch 43/100\n",
      "455/455 [==============================] - 0s 137us/step - loss: 0.7394 - accuracy: 0.8088 - val_loss: 0.6010 - val_accuracy: 0.9694\n",
      "Epoch 44/100\n",
      "455/455 [==============================] - 0s 130us/step - loss: 0.6912 - accuracy: 0.8022 - val_loss: 0.6109 - val_accuracy: 0.9694\n",
      "Epoch 45/100\n",
      "455/455 [==============================] - 0s 149us/step - loss: 0.7715 - accuracy: 0.7758 - val_loss: 0.6160 - val_accuracy: 0.9745\n",
      "Epoch 46/100\n",
      "455/455 [==============================] - 0s 170us/step - loss: 0.8007 - accuracy: 0.7934 - val_loss: 0.7056 - val_accuracy: 0.9541\n",
      "Epoch 47/100\n",
      "455/455 [==============================] - 0s 148us/step - loss: 0.6955 - accuracy: 0.8242 - val_loss: 0.5487 - val_accuracy: 0.9745\n",
      "Epoch 48/100\n",
      "455/455 [==============================] - 0s 142us/step - loss: 0.7739 - accuracy: 0.8242 - val_loss: 0.5590 - val_accuracy: 0.9694\n",
      "Epoch 49/100\n",
      "455/455 [==============================] - 0s 412us/step - loss: 0.7529 - accuracy: 0.7978 - val_loss: 0.6078 - val_accuracy: 0.9694\n",
      "Epoch 50/100\n",
      "455/455 [==============================] - 0s 196us/step - loss: 0.8042 - accuracy: 0.7780 - val_loss: 1.0420 - val_accuracy: 0.9439\n",
      "Epoch 51/100\n",
      "455/455 [==============================] - 0s 138us/step - loss: 0.7184 - accuracy: 0.8330 - val_loss: 0.5777 - val_accuracy: 0.9745\n",
      "Epoch 52/100\n",
      "455/455 [==============================] - 0s 455us/step - loss: 0.8098 - accuracy: 0.7604 - val_loss: 0.7501 - val_accuracy: 0.9490\n",
      "Epoch 53/100\n",
      "455/455 [==============================] - 0s 188us/step - loss: 0.7295 - accuracy: 0.7934 - val_loss: 0.6900 - val_accuracy: 0.9592\n",
      "Epoch 54/100\n",
      "455/455 [==============================] - 0s 185us/step - loss: 0.7105 - accuracy: 0.7890 - val_loss: 0.6313 - val_accuracy: 0.9592\n",
      "Epoch 55/100\n",
      "455/455 [==============================] - 0s 199us/step - loss: 0.6919 - accuracy: 0.8022 - val_loss: 0.5736 - val_accuracy: 0.9694\n",
      "Epoch 56/100\n",
      "455/455 [==============================] - 0s 158us/step - loss: 0.6617 - accuracy: 0.8088 - val_loss: 0.6020 - val_accuracy: 0.9694\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "455/455 [==============================] - 0s 132us/step - loss: 0.6246 - accuracy: 0.8330 - val_loss: 0.6515 - val_accuracy: 0.9643\n",
      "Epoch 58/100\n",
      "455/455 [==============================] - 0s 123us/step - loss: 0.6816 - accuracy: 0.7802 - val_loss: 0.6431 - val_accuracy: 0.9643\n",
      "Epoch 59/100\n",
      "455/455 [==============================] - 0s 116us/step - loss: 0.6772 - accuracy: 0.8044 - val_loss: 0.6174 - val_accuracy: 0.9694\n",
      "Epoch 60/100\n",
      "455/455 [==============================] - 0s 115us/step - loss: 0.6311 - accuracy: 0.8088 - val_loss: 0.6149 - val_accuracy: 0.9643\n",
      "Epoch 61/100\n",
      "455/455 [==============================] - 0s 118us/step - loss: 0.7442 - accuracy: 0.7956 - val_loss: 0.6138 - val_accuracy: 0.9694\n",
      "Epoch 62/100\n",
      "455/455 [==============================] - 0s 111us/step - loss: 0.6764 - accuracy: 0.8242 - val_loss: 0.5744 - val_accuracy: 0.9745\n",
      "Epoch 63/100\n",
      "455/455 [==============================] - 0s 111us/step - loss: 0.6771 - accuracy: 0.8088 - val_loss: 0.5708 - val_accuracy: 0.9745\n",
      "Epoch 64/100\n",
      "455/455 [==============================] - 0s 112us/step - loss: 0.6377 - accuracy: 0.8088 - val_loss: 0.5869 - val_accuracy: 0.9694\n",
      "Epoch 65/100\n",
      "455/455 [==============================] - 0s 119us/step - loss: 0.7975 - accuracy: 0.7692 - val_loss: 0.6527 - val_accuracy: 0.9694\n",
      "Epoch 66/100\n",
      "455/455 [==============================] - 0s 280us/step - loss: 0.6797 - accuracy: 0.8198 - val_loss: 0.6781 - val_accuracy: 0.9541\n",
      "Epoch 67/100\n",
      "455/455 [==============================] - 0s 207us/step - loss: 0.7275 - accuracy: 0.7934 - val_loss: 0.5625 - val_accuracy: 0.9796\n",
      "Epoch 68/100\n",
      "455/455 [==============================] - 0s 441us/step - loss: 0.6934 - accuracy: 0.8022 - val_loss: 0.5763 - val_accuracy: 0.9745\n",
      "Epoch 69/100\n",
      "455/455 [==============================] - 0s 249us/step - loss: 0.6350 - accuracy: 0.8000 - val_loss: 0.5740 - val_accuracy: 0.9694\n",
      "Epoch 70/100\n",
      "455/455 [==============================] - 0s 212us/step - loss: 0.6945 - accuracy: 0.7604 - val_loss: 0.5828 - val_accuracy: 0.9745\n",
      "Epoch 71/100\n",
      "455/455 [==============================] - 0s 204us/step - loss: 0.6158 - accuracy: 0.7934 - val_loss: 0.6014 - val_accuracy: 0.9643\n",
      "Epoch 72/100\n",
      "455/455 [==============================] - 0s 192us/step - loss: 0.6189 - accuracy: 0.8132 - val_loss: 0.5807 - val_accuracy: 0.9643\n",
      "Epoch 73/100\n",
      "455/455 [==============================] - 0s 158us/step - loss: 0.5766 - accuracy: 0.8330 - val_loss: 0.5312 - val_accuracy: 0.9694\n",
      "Epoch 74/100\n",
      "455/455 [==============================] - 0s 209us/step - loss: 0.6426 - accuracy: 0.7934 - val_loss: 0.5840 - val_accuracy: 0.9643\n",
      "Epoch 75/100\n",
      "455/455 [==============================] - 0s 155us/step - loss: 0.6836 - accuracy: 0.7956 - val_loss: 0.6143 - val_accuracy: 0.9592\n",
      "Epoch 76/100\n",
      "455/455 [==============================] - 0s 197us/step - loss: 0.6723 - accuracy: 0.7890 - val_loss: 0.5541 - val_accuracy: 0.9694\n",
      "Epoch 77/100\n",
      "455/455 [==============================] - 0s 258us/step - loss: 0.6408 - accuracy: 0.8022 - val_loss: 0.5518 - val_accuracy: 0.9694\n",
      "Epoch 78/100\n",
      "455/455 [==============================] - 0s 175us/step - loss: 0.6706 - accuracy: 0.7868 - val_loss: 0.5608 - val_accuracy: 0.9745\n",
      "Epoch 79/100\n",
      "455/455 [==============================] - 0s 175us/step - loss: 0.6006 - accuracy: 0.8220 - val_loss: 0.5293 - val_accuracy: 0.9745\n",
      "Epoch 80/100\n",
      "455/455 [==============================] - 0s 168us/step - loss: 0.5710 - accuracy: 0.8132 - val_loss: 0.5905 - val_accuracy: 0.9694\n",
      "Epoch 81/100\n",
      "455/455 [==============================] - 0s 155us/step - loss: 0.6326 - accuracy: 0.8198 - val_loss: 0.5547 - val_accuracy: 0.9694\n",
      "Epoch 82/100\n",
      "455/455 [==============================] - 0s 219us/step - loss: 0.6481 - accuracy: 0.7956 - val_loss: 0.5714 - val_accuracy: 0.9694\n",
      "Epoch 83/100\n",
      "455/455 [==============================] - 0s 177us/step - loss: 0.6481 - accuracy: 0.8000 - val_loss: 0.5624 - val_accuracy: 0.9643\n",
      "Epoch 84/100\n",
      "455/455 [==============================] - 0s 145us/step - loss: 0.6056 - accuracy: 0.8132 - val_loss: 0.5174 - val_accuracy: 0.9745\n",
      "Epoch 85/100\n",
      "455/455 [==============================] - 0s 209us/step - loss: 0.5928 - accuracy: 0.8066 - val_loss: 0.5268 - val_accuracy: 0.9694\n",
      "Epoch 86/100\n",
      "455/455 [==============================] - 0s 165us/step - loss: 0.6021 - accuracy: 0.7978 - val_loss: 0.5530 - val_accuracy: 0.9694\n",
      "Epoch 87/100\n",
      "455/455 [==============================] - 0s 384us/step - loss: 0.6561 - accuracy: 0.8022 - val_loss: 0.5462 - val_accuracy: 0.9694\n",
      "Epoch 88/100\n",
      "455/455 [==============================] - 0s 357us/step - loss: 0.6283 - accuracy: 0.8066 - val_loss: 0.5653 - val_accuracy: 0.9643\n",
      "Epoch 89/100\n",
      "455/455 [==============================] - 0s 177us/step - loss: 0.6086 - accuracy: 0.8022 - val_loss: 0.5409 - val_accuracy: 0.9745\n",
      "Epoch 90/100\n",
      "455/455 [==============================] - 0s 188us/step - loss: 0.6699 - accuracy: 0.8110 - val_loss: 0.5929 - val_accuracy: 0.9745\n",
      "Epoch 91/100\n",
      "455/455 [==============================] - 0s 213us/step - loss: 0.6162 - accuracy: 0.8000 - val_loss: 0.5534 - val_accuracy: 0.9694\n",
      "Epoch 92/100\n",
      "455/455 [==============================] - 0s 269us/step - loss: 0.6115 - accuracy: 0.8154 - val_loss: 0.5794 - val_accuracy: 0.9694\n",
      "Epoch 93/100\n",
      "455/455 [==============================] - 0s 241us/step - loss: 0.6153 - accuracy: 0.7956 - val_loss: 0.5424 - val_accuracy: 0.9643\n",
      "Epoch 94/100\n",
      "455/455 [==============================] - 0s 254us/step - loss: 0.5905 - accuracy: 0.7890 - val_loss: 0.5228 - val_accuracy: 0.9694\n",
      "Epoch 95/100\n",
      "455/455 [==============================] - 0s 200us/step - loss: 0.5945 - accuracy: 0.8044 - val_loss: 0.5172 - val_accuracy: 0.9694\n",
      "Epoch 96/100\n",
      "455/455 [==============================] - 0s 168us/step - loss: 0.6351 - accuracy: 0.7956 - val_loss: 0.5378 - val_accuracy: 0.9745\n",
      "Epoch 97/100\n",
      "455/455 [==============================] - 0s 143us/step - loss: 0.5693 - accuracy: 0.8154 - val_loss: 0.5354 - val_accuracy: 0.9745\n",
      "Epoch 98/100\n",
      "455/455 [==============================] - 0s 193us/step - loss: 0.6572 - accuracy: 0.7868 - val_loss: 0.5648 - val_accuracy: 0.9643\n",
      "Epoch 99/100\n",
      "455/455 [==============================] - 0s 200us/step - loss: 0.6218 - accuracy: 0.7780 - val_loss: 0.5942 - val_accuracy: 0.9592\n",
      "Epoch 100/100\n",
      "455/455 [==============================] - 0s 199us/step - loss: 0.5914 - accuracy: 0.7956 - val_loss: 0.5737 - val_accuracy: 0.9643\n"
     ]
    }
   ],
   "source": [
    "hist1_over5 = model1_over5.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 80.17%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over5.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba5 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_regularizor_dropout_2.xlsx\",\n",
    "                        sheet_name=0,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS241</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.342914e-03</td>\n",
       "      <td>9.986569e-01</td>\n",
       "      <td>2.348628e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5.170289e-08</td>\n",
       "      <td>1.017893e-07</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS255</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.780311e-07</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>2.544841e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS214</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.203547e-10</td>\n",
       "      <td>5.688883e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5.170289e-08</td>\n",
       "      <td>1.017893e-07</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>BCH-SA-12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.152503e-09</td>\n",
       "      <td>1.898730e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS049</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.401357e-11</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.209735e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS022</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.755084e-10</td>\n",
       "      <td>1.974275e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS236</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.357345e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.293117e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4.074704e-08</td>\n",
       "      <td>2.329201e-08</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1982 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       phage     strain  phenotype  prediction             0  \\\n",
       "0     p002ykpresabsSTCC_qual     NRS241          1           1  1.342914e-03   \n",
       "1     p002ykpresabsSTCC_qual     NRS148          2           2  5.170289e-08   \n",
       "2     p002ykpresabsSTCC_qual     NRS255          1           1  1.780311e-07   \n",
       "3     p002ykpresabsSTCC_qual     NRS214          0           0  1.000000e+00   \n",
       "4     p002ykpresabsSTCC_qual     NRS148          2           2  5.170289e-08   \n",
       "...                      ...        ...        ...         ...           ...   \n",
       "1977     pyopresabsSTCC_qual  BCH-SA-12          0           0  1.000000e+00   \n",
       "1978     pyopresabsSTCC_qual     NRS049          0           1  8.401357e-11   \n",
       "1979     pyopresabsSTCC_qual     NRS022          0           0  1.000000e+00   \n",
       "1980     pyopresabsSTCC_qual     NRS236          1           1  1.357345e-08   \n",
       "1981     pyopresabsSTCC_qual     NRS148          2           2  4.074704e-08   \n",
       "\n",
       "                 1             2  \n",
       "0     9.986569e-01  2.348628e-07  \n",
       "1     1.017893e-07  9.999999e-01  \n",
       "2     9.999999e-01  2.544841e-12  \n",
       "3     2.203547e-10  5.688883e-15  \n",
       "4     1.017893e-07  9.999999e-01  \n",
       "...            ...           ...  \n",
       "1977  1.152503e-09  1.898730e-09  \n",
       "1978  1.000000e+00  3.209735e-13  \n",
       "1979  4.755084e-10  1.974275e-10  \n",
       "1980  1.000000e+00  1.293117e-10  \n",
       "1981  2.329201e-08  9.999999e-01  \n",
       "\n",
       "[1982 rows x 7 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.62326860e-08, 1.07397980e-07, 9.99999900e-01],\n",
       "       [5.62326860e-08, 1.07397980e-07, 9.99999900e-01],\n",
       "       [6.62319300e-04, 9.99129600e-01, 2.08099470e-04],\n",
       "       [3.76363720e-08, 2.14066350e-08, 1.00000000e+00],\n",
       "       [3.76363720e-08, 2.14066350e-08, 1.00000000e+00],\n",
       "       [6.82506900e-08, 9.99999900e-01, 9.66216300e-10],\n",
       "       [5.57879700e-03, 9.94394900e-01, 2.63683940e-05],\n",
       "       [9.97977200e-01, 8.46653600e-04, 1.17607430e-03],\n",
       "       [4.84955800e-08, 9.32821100e-08, 9.99999900e-01],\n",
       "       [4.07470430e-08, 2.32920120e-08, 9.99999900e-01],\n",
       "       [2.39172070e-07, 9.99999760e-01, 2.77114180e-09],\n",
       "       [3.76363720e-08, 2.14066350e-08, 1.00000000e+00],\n",
       "       [4.07470430e-08, 2.32920120e-08, 9.99999900e-01],\n",
       "       [2.35414600e-06, 9.99997140e-01, 4.81304700e-07],\n",
       "       [9.99994900e-01, 3.51247330e-06, 1.69392060e-06],\n",
       "       [9.97303370e-01, 2.66711270e-03, 2.95380890e-05],\n",
       "       [4.91842700e-08, 1.00000000e+00, 3.30945900e-08],\n",
       "       [1.00000000e+00, 1.74692260e-11, 2.39192170e-11],\n",
       "       [2.58059220e-03, 9.96085640e-01, 1.33367140e-03],\n",
       "       [4.84955800e-08, 9.32821100e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 1.13861430e-08, 6.51092160e-09],\n",
       "       [2.65484630e-08, 1.00000000e+00, 1.15270630e-08],\n",
       "       [9.99999900e-01, 3.24143900e-08, 8.15530540e-08],\n",
       "       [3.76363720e-08, 2.14066350e-08, 1.00000000e+00],\n",
       "       [9.99711700e-01, 2.88256940e-04, 3.79957720e-08],\n",
       "       [1.00000000e+00, 1.25719120e-11, 5.69297600e-11],\n",
       "       [2.47360560e-03, 9.97498330e-01, 2.80129440e-05],\n",
       "       [1.00000000e+00, 3.06285000e-09, 6.17375300e-11],\n",
       "       [3.76363720e-08, 2.14066350e-08, 1.00000000e+00],\n",
       "       [5.62326860e-08, 1.07397980e-07, 9.99999900e-01],\n",
       "       [3.76363720e-08, 2.14066350e-08, 1.00000000e+00],\n",
       "       [9.94945000e-01, 5.04303000e-03, 1.19398110e-05],\n",
       "       [7.05194840e-08, 9.99999900e-01, 2.65383340e-08],\n",
       "       [6.82506900e-08, 9.99999900e-01, 9.66216300e-10],\n",
       "       [4.84955800e-08, 9.32821100e-08, 9.99999900e-01],\n",
       "       [4.63045640e-08, 1.00000000e+00, 6.46140800e-10],\n",
       "       [2.65484630e-08, 1.00000000e+00, 1.15270630e-08],\n",
       "       [4.07470430e-08, 2.32920120e-08, 9.99999900e-01],\n",
       "       [9.99988300e-01, 1.12439790e-05, 4.81093930e-07],\n",
       "       [5.62326860e-08, 1.07397980e-07, 9.99999900e-01],\n",
       "       [1.35734460e-08, 1.00000000e+00, 1.29311740e-10],\n",
       "       [6.93700500e-08, 9.99999900e-01, 1.08818370e-09],\n",
       "       [8.98650800e-07, 9.99998700e-01, 4.11246800e-07],\n",
       "       [9.99999170e-01, 3.29504050e-07, 4.33303370e-07],\n",
       "       [4.84955800e-08, 9.32821100e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 1.67722400e-10, 1.73432090e-10],\n",
       "       [2.35414600e-06, 9.99997140e-01, 4.81304700e-07],\n",
       "       [1.00000000e+00, 4.16601780e-10, 3.73971880e-10],\n",
       "       [9.99999900e-01, 7.69679150e-08, 2.41427790e-09],\n",
       "       [2.39172070e-07, 9.99999760e-01, 2.77114180e-09],\n",
       "       [2.58059220e-03, 9.96085640e-01, 1.33367140e-03],\n",
       "       [6.93700500e-08, 9.99999900e-01, 1.08818370e-09],\n",
       "       [4.07470430e-08, 2.32920120e-08, 9.99999900e-01],\n",
       "       [5.62326860e-08, 1.07397980e-07, 9.99999900e-01],\n",
       "       [2.27739040e-08, 1.00000000e+00, 1.17994740e-08],\n",
       "       [1.00000000e+00, 1.49352840e-09, 7.11373350e-10],\n",
       "       [1.00000000e+00, 1.50773270e-10, 1.48861600e-10],\n",
       "       [5.62326860e-08, 1.07397980e-07, 9.99999900e-01],\n",
       "       [5.62326860e-08, 1.07397980e-07, 9.99999900e-01],\n",
       "       [4.07470430e-08, 2.32920120e-08, 9.99999900e-01],\n",
       "       [1.55736330e-02, 9.84412600e-01, 1.37649710e-05],\n",
       "       [1.00000000e+00, 9.75428900e-13, 8.98843800e-13],\n",
       "       [2.39172070e-07, 9.99999760e-01, 2.77114180e-09],\n",
       "       [4.07470430e-08, 2.32920120e-08, 9.99999900e-01],\n",
       "       [3.76363720e-08, 2.14066350e-08, 1.00000000e+00],\n",
       "       [1.26259470e-02, 9.87374000e-01, 1.61147910e-07],\n",
       "       [1.00000000e+00, 1.18163925e-11, 8.99472000e-12],\n",
       "       [6.37425300e-06, 9.99989400e-01, 4.26630900e-06],\n",
       "       [5.62326860e-08, 1.07397980e-07, 9.99999900e-01],\n",
       "       [9.99169470e-01, 8.30593800e-04, 1.86487900e-08],\n",
       "       [4.63045640e-08, 1.00000000e+00, 6.46140800e-10],\n",
       "       [8.82022500e-08, 9.99999900e-01, 5.45159970e-08],\n",
       "       [8.45331800e-01, 1.54666920e-01, 1.23011560e-06],\n",
       "       [1.00000000e+00, 3.56712540e-13, 5.28776100e-13],\n",
       "       [4.07470430e-08, 2.32920120e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 8.18034460e-11, 7.91607500e-11],\n",
       "       [1.03996100e-03, 9.98954060e-01, 5.93590600e-06],\n",
       "       [2.27739040e-08, 1.00000000e+00, 1.17994740e-08],\n",
       "       [4.07470430e-08, 2.32920120e-08, 9.99999900e-01],\n",
       "       [5.62326860e-08, 1.07397980e-07, 9.99999900e-01],\n",
       "       [4.84955800e-08, 9.32821100e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 6.01287730e-15, 8.72595300e-15],\n",
       "       [2.91508310e-08, 1.00000000e+00, 3.10011100e-10],\n",
       "       [4.07470430e-08, 2.32920120e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 1.11344750e-13, 9.49735500e-14],\n",
       "       [5.62326860e-08, 1.07397980e-07, 9.99999900e-01],\n",
       "       [1.35734460e-08, 1.00000000e+00, 1.29311740e-10],\n",
       "       [9.83674900e-01, 1.63195800e-02, 5.50380670e-06],\n",
       "       [4.07470430e-08, 2.32920120e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 1.00269070e-12, 7.98832460e-13],\n",
       "       [3.76363720e-08, 2.14066350e-08, 1.00000000e+00],\n",
       "       [9.99999760e-01, 1.25894520e-07, 1.41730310e-07],\n",
       "       [2.81651040e-07, 9.99999760e-01, 1.01437450e-08],\n",
       "       [3.76320630e-08, 1.00000000e+00, 4.82172700e-10],\n",
       "       [9.99300960e-01, 6.98254100e-04, 8.88439730e-07],\n",
       "       [2.93032900e-05, 9.99962900e-01, 7.71532700e-06],\n",
       "       [9.99221100e-01, 7.76751600e-04, 2.16025700e-06],\n",
       "       [4.84955800e-08, 9.32821100e-08, 9.99999900e-01],\n",
       "       [9.99997850e-01, 1.06125840e-06, 1.02413480e-06],\n",
       "       [7.05194840e-08, 9.99999900e-01, 2.65383340e-08],\n",
       "       [7.05194840e-08, 9.99999900e-01, 2.65383340e-08],\n",
       "       [9.98455170e-01, 1.54483740e-03, 2.15929480e-08],\n",
       "       [4.07470430e-08, 2.32920120e-08, 9.99999900e-01],\n",
       "       [2.91508310e-08, 1.00000000e+00, 3.10011100e-10],\n",
       "       [8.82022500e-08, 9.99999900e-01, 5.45159970e-08],\n",
       "       [2.81651040e-07, 9.99999760e-01, 1.01437450e-08],\n",
       "       [9.99997400e-01, 2.65765130e-06, 2.91387900e-09],\n",
       "       [1.50666200e-08, 1.00000000e+00, 1.26056610e-09],\n",
       "       [4.84955800e-08, 9.32821100e-08, 9.99999900e-01],\n",
       "       [5.62326860e-08, 1.07397980e-07, 9.99999900e-01],\n",
       "       [4.91842700e-08, 1.00000000e+00, 3.30945900e-08],\n",
       "       [4.07470430e-08, 2.32920120e-08, 9.99999900e-01],\n",
       "       [9.93387700e-01, 6.61114980e-03, 1.18035770e-06],\n",
       "       [1.00000000e+00, 4.45051030e-12, 8.81348100e-12],\n",
       "       [1.05579294e-01, 8.94420700e-01, 3.27977650e-08],\n",
       "       [9.99977000e-01, 1.86717040e-05, 4.29914700e-06],\n",
       "       [4.84955800e-08, 9.32821100e-08, 9.99999900e-01],\n",
       "       [8.82022500e-08, 9.99999900e-01, 5.45159970e-08],\n",
       "       [4.07470430e-08, 2.32920120e-08, 9.99999900e-01],\n",
       "       [2.90534830e-05, 9.99968400e-01, 2.48848530e-06],\n",
       "       [1.03996100e-03, 9.98954060e-01, 5.93590600e-06],\n",
       "       [2.65495100e-07, 9.99999760e-01, 2.06525850e-08],\n",
       "       [1.00000000e+00, 4.89524200e-09, 3.97103060e-09],\n",
       "       [6.29130560e-03, 9.93708130e-01, 5.75465700e-07],\n",
       "       [3.76363720e-08, 2.14066350e-08, 1.00000000e+00],\n",
       "       [2.39172070e-07, 9.99999760e-01, 2.77114180e-09],\n",
       "       [4.84955800e-08, 9.32821100e-08, 9.99999900e-01],\n",
       "       [2.65495100e-07, 9.99999760e-01, 2.06525850e-08],\n",
       "       [1.00000000e+00, 8.51985960e-13, 7.95047570e-13],\n",
       "       [1.50666200e-08, 1.00000000e+00, 1.26056610e-09],\n",
       "       [1.00000000e+00, 5.07010200e-20, 1.82955920e-25],\n",
       "       [5.62326860e-08, 1.07397980e-07, 9.99999900e-01],\n",
       "       [1.00000000e+00, 2.02363060e-11, 1.18999645e-11],\n",
       "       [9.97295560e-01, 2.70446800e-03, 1.89949900e-08],\n",
       "       [4.79310940e-06, 9.99991300e-01, 3.98503900e-06],\n",
       "       [2.39172070e-07, 9.99999760e-01, 2.77114180e-09],\n",
       "       [5.62326860e-08, 1.07397980e-07, 9.99999900e-01],\n",
       "       [1.00000000e+00, 1.58675420e-12, 1.50038140e-12],\n",
       "       [1.50666200e-08, 1.00000000e+00, 1.26056610e-09],\n",
       "       [1.00000000e+00, 1.39407110e-10, 1.39752140e-10],\n",
       "       [5.62326860e-08, 1.07397980e-07, 9.99999900e-01],\n",
       "       [7.05194840e-08, 9.99999900e-01, 2.65383340e-08],\n",
       "       [6.62319300e-04, 9.99129600e-01, 2.08099470e-04],\n",
       "       [4.07470430e-08, 2.32920120e-08, 9.99999900e-01],\n",
       "       [3.76363720e-08, 2.14066350e-08, 1.00000000e+00],\n",
       "       [9.99995800e-01, 3.91304300e-06, 2.57805850e-07],\n",
       "       [4.84955800e-08, 9.32821100e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 4.37789630e-11, 2.23778130e-11],\n",
       "       [9.98231950e-01, 1.76743250e-03, 6.30207000e-07],\n",
       "       [6.29105800e-01, 3.70689300e-01, 2.04949700e-04],\n",
       "       [9.96835770e-01, 1.87253800e-03, 1.29166860e-03],\n",
       "       [4.07470430e-08, 2.32920120e-08, 9.99999900e-01],\n",
       "       [2.65484630e-08, 1.00000000e+00, 1.15270630e-08],\n",
       "       [4.07470430e-08, 2.32920120e-08, 9.99999900e-01],\n",
       "       [2.39172070e-07, 9.99999760e-01, 2.77114180e-09],\n",
       "       [2.47360560e-03, 9.97498330e-01, 2.80129440e-05],\n",
       "       [4.84955800e-08, 9.32821100e-08, 9.99999900e-01],\n",
       "       [4.07470430e-08, 2.32920120e-08, 9.99999900e-01],\n",
       "       [9.99995230e-01, 3.70335500e-06, 1.06590020e-06],\n",
       "       [1.00000000e+00, 5.54657300e-08, 3.18338600e-08],\n",
       "       [3.68718330e-07, 9.99999640e-01, 4.48207700e-09],\n",
       "       [9.99131600e-01, 7.74829200e-04, 9.36681750e-05],\n",
       "       [5.62326860e-08, 1.07397980e-07, 9.99999900e-01],\n",
       "       [5.91783460e-05, 9.99877900e-01, 6.29519050e-05],\n",
       "       [9.99998100e-01, 1.59203680e-06, 3.45362030e-07],\n",
       "       [4.91842700e-08, 1.00000000e+00, 3.30945900e-08],\n",
       "       [4.07470430e-08, 2.32920120e-08, 9.99999900e-01],\n",
       "       [5.62326860e-08, 1.07397980e-07, 9.99999900e-01],\n",
       "       [1.00000000e+00, 2.92318440e-08, 1.02998034e-10],\n",
       "       [5.62326860e-08, 1.07397980e-07, 9.99999900e-01],\n",
       "       [1.00000000e+00, 6.87541800e-10, 1.37836140e-09],\n",
       "       [4.84955800e-08, 9.32821100e-08, 9.99999900e-01],\n",
       "       [3.76363720e-08, 2.14066350e-08, 1.00000000e+00],\n",
       "       [3.76363720e-08, 2.14066350e-08, 1.00000000e+00],\n",
       "       [4.07470430e-08, 2.32920120e-08, 9.99999900e-01],\n",
       "       [3.76363720e-08, 2.14066350e-08, 1.00000000e+00],\n",
       "       [1.35734460e-08, 1.00000000e+00, 1.29311740e-10],\n",
       "       [5.57879700e-03, 9.94394900e-01, 2.63683940e-05],\n",
       "       [1.00000000e+00, 3.82079000e-09, 2.55867750e-09],\n",
       "       [2.65484630e-08, 1.00000000e+00, 1.15270630e-08],\n",
       "       [1.00000000e+00, 3.74578960e-16, 3.86291020e-16],\n",
       "       [4.79310940e-06, 9.99991300e-01, 3.98503900e-06],\n",
       "       [4.07470430e-08, 2.32920120e-08, 9.99999900e-01],\n",
       "       [6.80145650e-08, 9.99999900e-01, 1.25648280e-09],\n",
       "       [5.47064900e-02, 9.45226800e-01, 6.66502750e-05],\n",
       "       [5.62326860e-08, 1.07397980e-07, 9.99999900e-01],\n",
       "       [2.27739040e-08, 1.00000000e+00, 1.17994740e-08],\n",
       "       [1.00000000e+00, 1.06365880e-14, 1.66674150e-14],\n",
       "       [4.79310940e-06, 9.99991300e-01, 3.98503900e-06],\n",
       "       [4.91842700e-08, 1.00000000e+00, 3.30945900e-08],\n",
       "       [5.62326860e-08, 1.07397980e-07, 9.99999900e-01],\n",
       "       [1.00000000e+00, 1.15250340e-09, 1.89872960e-09],\n",
       "       [8.40135740e-11, 1.00000000e+00, 3.20973470e-13],\n",
       "       [1.00000000e+00, 4.75508350e-10, 1.97427490e-10],\n",
       "       [1.35734460e-08, 1.00000000e+00, 1.29311740e-10],\n",
       "       [4.07470430e-08, 2.32920120e-08, 9.99999900e-01]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob5 = df_proba5[df_proba5['phage']=='pyopresabsSTCC_qual'].iloc[:,-3:]\n",
    "y_prob5 = y_prob5.to_numpy()\n",
    "y_prob5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9902812624186671"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo5 = rocauc_ovo(y_test_over, y_prob5, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9902812624186671"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr5 = rocauc_ovr(y_test_over, y_prob5, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=678,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat6 = pd.DataFrame(X_test_over[:,0])\n",
    "dat6['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>120335</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS168</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS202</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BCH-SA-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>NRS272</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>NRS112</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>NRS064</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>BCH-SA-04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>196 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0  test\n",
       "0       120335     0\n",
       "1       NRS168     1\n",
       "2       NRS202     0\n",
       "3       NRS109     2\n",
       "4    BCH-SA-01     0\n",
       "..         ...   ...\n",
       "191     NRS272     0\n",
       "192     NRS112     1\n",
       "193     NRS064     1\n",
       "194  BCH-SA-04     0\n",
       "195     NRS148     2\n",
       "\n",
       "[196 rows x 2 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over6 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],), activity_regularizer=l1(0.001)),\n",
    "    Dense(3, activation='softmax'),\n",
    "    Dropout(0.2, ),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over6.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 455 samples, validate on 196 samples\n",
      "Epoch 1/100\n",
      "455/455 [==============================] - 0s 637us/step - loss: 9.6564 - accuracy: 0.4440 - val_loss: 5.5536 - val_accuracy: 0.5408\n",
      "Epoch 2/100\n",
      "455/455 [==============================] - 0s 141us/step - loss: 7.1253 - accuracy: 0.5363 - val_loss: 3.6687 - val_accuracy: 0.6786\n",
      "Epoch 3/100\n",
      "455/455 [==============================] - 0s 140us/step - loss: 5.9196 - accuracy: 0.5626 - val_loss: 2.7422 - val_accuracy: 0.6786\n",
      "Epoch 4/100\n",
      "455/455 [==============================] - 0s 215us/step - loss: 5.0933 - accuracy: 0.5802 - val_loss: 2.1373 - val_accuracy: 0.6633\n",
      "Epoch 5/100\n",
      "455/455 [==============================] - 0s 215us/step - loss: 4.4889 - accuracy: 0.6330 - val_loss: 1.6800 - val_accuracy: 0.7704\n",
      "Epoch 6/100\n",
      "455/455 [==============================] - 0s 179us/step - loss: 3.5551 - accuracy: 0.6549 - val_loss: 1.4166 - val_accuracy: 0.7653\n",
      "Epoch 7/100\n",
      "455/455 [==============================] - 0s 134us/step - loss: 3.4445 - accuracy: 0.6703 - val_loss: 1.1320 - val_accuracy: 0.8112\n",
      "Epoch 8/100\n",
      "455/455 [==============================] - 0s 123us/step - loss: 3.3004 - accuracy: 0.6967 - val_loss: 1.1613 - val_accuracy: 0.7908\n",
      "Epoch 9/100\n",
      "455/455 [==============================] - 0s 148us/step - loss: 2.8113 - accuracy: 0.7143 - val_loss: 1.0236 - val_accuracy: 0.8010\n",
      "Epoch 10/100\n",
      "455/455 [==============================] - 0s 214us/step - loss: 3.0460 - accuracy: 0.7055 - val_loss: 1.1391 - val_accuracy: 0.8163\n",
      "Epoch 11/100\n",
      "455/455 [==============================] - 0s 123us/step - loss: 3.1716 - accuracy: 0.6637 - val_loss: 0.9980 - val_accuracy: 0.8265\n",
      "Epoch 12/100\n",
      "455/455 [==============================] - 0s 131us/step - loss: 2.8726 - accuracy: 0.7099 - val_loss: 0.9506 - val_accuracy: 0.8112\n",
      "Epoch 13/100\n",
      "455/455 [==============================] - 0s 152us/step - loss: 3.0214 - accuracy: 0.7297 - val_loss: 0.9460 - val_accuracy: 0.8418\n",
      "Epoch 14/100\n",
      "455/455 [==============================] - 0s 193us/step - loss: 2.6435 - accuracy: 0.7209 - val_loss: 0.9094 - val_accuracy: 0.8316\n",
      "Epoch 15/100\n",
      "455/455 [==============================] - 0s 202us/step - loss: 2.7471 - accuracy: 0.7253 - val_loss: 0.8837 - val_accuracy: 0.8316\n",
      "Epoch 16/100\n",
      "455/455 [==============================] - 0s 229us/step - loss: 2.6120 - accuracy: 0.7363 - val_loss: 0.8877 - val_accuracy: 0.8316\n",
      "Epoch 17/100\n",
      "455/455 [==============================] - 0s 190us/step - loss: 2.8222 - accuracy: 0.6967 - val_loss: 0.8999 - val_accuracy: 0.8367\n",
      "Epoch 18/100\n",
      "455/455 [==============================] - 0s 205us/step - loss: 2.7685 - accuracy: 0.7121 - val_loss: 0.8966 - val_accuracy: 0.8265\n",
      "Epoch 19/100\n",
      "455/455 [==============================] - 0s 103us/step - loss: 2.5418 - accuracy: 0.7341 - val_loss: 0.8740 - val_accuracy: 0.8316\n",
      "Epoch 20/100\n",
      "455/455 [==============================] - 0s 101us/step - loss: 2.4913 - accuracy: 0.7451 - val_loss: 0.7814 - val_accuracy: 0.8316\n",
      "Epoch 21/100\n",
      "455/455 [==============================] - 0s 101us/step - loss: 2.4512 - accuracy: 0.7341 - val_loss: 0.8073 - val_accuracy: 0.8367\n",
      "Epoch 22/100\n",
      "455/455 [==============================] - 0s 115us/step - loss: 2.5252 - accuracy: 0.7253 - val_loss: 0.8954 - val_accuracy: 0.8418\n",
      "Epoch 23/100\n",
      "455/455 [==============================] - 0s 145us/step - loss: 2.6844 - accuracy: 0.7143 - val_loss: 0.8628 - val_accuracy: 0.8673\n",
      "Epoch 24/100\n",
      "455/455 [==============================] - 0s 151us/step - loss: 2.5006 - accuracy: 0.7407 - val_loss: 0.8338 - val_accuracy: 0.8622\n",
      "Epoch 25/100\n",
      "455/455 [==============================] - 0s 136us/step - loss: 2.2485 - accuracy: 0.7714 - val_loss: 0.7954 - val_accuracy: 0.8724\n",
      "Epoch 26/100\n",
      "455/455 [==============================] - 0s 165us/step - loss: 2.5858 - accuracy: 0.7165 - val_loss: 0.7857 - val_accuracy: 0.8776\n",
      "Epoch 27/100\n",
      "455/455 [==============================] - 0s 127us/step - loss: 2.3953 - accuracy: 0.7319 - val_loss: 0.7921 - val_accuracy: 0.8673\n",
      "Epoch 28/100\n",
      "455/455 [==============================] - 0s 116us/step - loss: 2.5504 - accuracy: 0.7385 - val_loss: 0.8178 - val_accuracy: 0.8673\n",
      "Epoch 29/100\n",
      "455/455 [==============================] - 0s 126us/step - loss: 2.4012 - accuracy: 0.7253 - val_loss: 0.8011 - val_accuracy: 0.8827\n",
      "Epoch 30/100\n",
      "455/455 [==============================] - 0s 311us/step - loss: 2.2783 - accuracy: 0.7341 - val_loss: 0.8215 - val_accuracy: 0.8673\n",
      "Epoch 31/100\n",
      "455/455 [==============================] - 0s 231us/step - loss: 1.9383 - accuracy: 0.7802 - val_loss: 0.7212 - val_accuracy: 0.9439\n",
      "Epoch 32/100\n",
      "455/455 [==============================] - 0s 122us/step - loss: 1.9884 - accuracy: 0.7846 - val_loss: 0.7069 - val_accuracy: 0.9235\n",
      "Epoch 33/100\n",
      "455/455 [==============================] - 0s 124us/step - loss: 2.1681 - accuracy: 0.7319 - val_loss: 0.7631 - val_accuracy: 0.8878\n",
      "Epoch 34/100\n",
      "455/455 [==============================] - 0s 99us/step - loss: 2.2100 - accuracy: 0.7341 - val_loss: 0.7851 - val_accuracy: 0.8776\n",
      "Epoch 35/100\n",
      "455/455 [==============================] - 0s 107us/step - loss: 2.0429 - accuracy: 0.7473 - val_loss: 0.7357 - val_accuracy: 0.8827\n",
      "Epoch 36/100\n",
      "455/455 [==============================] - 0s 104us/step - loss: 1.7893 - accuracy: 0.7736 - val_loss: 0.6800 - val_accuracy: 0.9439\n",
      "Epoch 37/100\n",
      "455/455 [==============================] - 0s 105us/step - loss: 1.8800 - accuracy: 0.7890 - val_loss: 0.7068 - val_accuracy: 0.9439\n",
      "Epoch 38/100\n",
      "455/455 [==============================] - 0s 316us/step - loss: 2.0508 - accuracy: 0.7626 - val_loss: 0.7506 - val_accuracy: 0.8980\n",
      "Epoch 39/100\n",
      "455/455 [==============================] - 0s 321us/step - loss: 2.0927 - accuracy: 0.7473 - val_loss: 0.7904 - val_accuracy: 0.9286\n",
      "Epoch 40/100\n",
      "455/455 [==============================] - 0s 224us/step - loss: 1.7456 - accuracy: 0.7692 - val_loss: 0.7554 - val_accuracy: 0.9235\n",
      "Epoch 41/100\n",
      "455/455 [==============================] - 0s 172us/step - loss: 1.9531 - accuracy: 0.7670 - val_loss: 0.7707 - val_accuracy: 0.9286\n",
      "Epoch 42/100\n",
      "455/455 [==============================] - 0s 131us/step - loss: 1.9450 - accuracy: 0.7692 - val_loss: 0.7902 - val_accuracy: 0.9235\n",
      "Epoch 43/100\n",
      "455/455 [==============================] - 0s 183us/step - loss: 1.6937 - accuracy: 0.7912 - val_loss: 0.7248 - val_accuracy: 0.9439\n",
      "Epoch 44/100\n",
      "455/455 [==============================] - 0s 233us/step - loss: 1.8950 - accuracy: 0.7802 - val_loss: 0.6871 - val_accuracy: 0.9388\n",
      "Epoch 45/100\n",
      "455/455 [==============================] - 0s 294us/step - loss: 2.0477 - accuracy: 0.7626 - val_loss: 0.7408 - val_accuracy: 0.9133\n",
      "Epoch 46/100\n",
      "455/455 [==============================] - 0s 211us/step - loss: 1.6087 - accuracy: 0.7912 - val_loss: 0.7024 - val_accuracy: 0.9388\n",
      "Epoch 47/100\n",
      "455/455 [==============================] - 0s 228us/step - loss: 1.9023 - accuracy: 0.7648 - val_loss: 0.7470 - val_accuracy: 0.9286\n",
      "Epoch 48/100\n",
      "455/455 [==============================] - 0s 284us/step - loss: 1.6916 - accuracy: 0.7868 - val_loss: 0.7129 - val_accuracy: 0.9592\n",
      "Epoch 49/100\n",
      "455/455 [==============================] - 0s 215us/step - loss: 1.5540 - accuracy: 0.8000 - val_loss: 0.7026 - val_accuracy: 0.9388\n",
      "Epoch 50/100\n",
      "455/455 [==============================] - 0s 161us/step - loss: 1.6386 - accuracy: 0.7824 - val_loss: 0.6749 - val_accuracy: 0.9541\n",
      "Epoch 51/100\n",
      "455/455 [==============================] - 0s 154us/step - loss: 1.6429 - accuracy: 0.7934 - val_loss: 0.6623 - val_accuracy: 0.9643\n",
      "Epoch 52/100\n",
      "455/455 [==============================] - 0s 316us/step - loss: 1.8328 - accuracy: 0.7648 - val_loss: 0.8162 - val_accuracy: 0.9388\n",
      "Epoch 53/100\n",
      "455/455 [==============================] - 0s 222us/step - loss: 1.5324 - accuracy: 0.7868 - val_loss: 0.6931 - val_accuracy: 0.9541\n",
      "Epoch 54/100\n",
      "455/455 [==============================] - 0s 208us/step - loss: 1.7972 - accuracy: 0.7736 - val_loss: 0.7088 - val_accuracy: 0.9439\n",
      "Epoch 55/100\n",
      "455/455 [==============================] - 0s 133us/step - loss: 1.4907 - accuracy: 0.7824 - val_loss: 0.7342 - val_accuracy: 0.9388\n",
      "Epoch 56/100\n",
      "455/455 [==============================] - 0s 108us/step - loss: 1.4383 - accuracy: 0.7978 - val_loss: 0.6891 - val_accuracy: 0.9490\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "455/455 [==============================] - 0s 104us/step - loss: 1.5534 - accuracy: 0.7890 - val_loss: 0.7059 - val_accuracy: 0.9439\n",
      "Epoch 58/100\n",
      "455/455 [==============================] - 0s 102us/step - loss: 1.4940 - accuracy: 0.7912 - val_loss: 0.6722 - val_accuracy: 0.9541\n",
      "Epoch 59/100\n",
      "455/455 [==============================] - 0s 96us/step - loss: 1.2856 - accuracy: 0.8022 - val_loss: 0.6419 - val_accuracy: 0.9490\n",
      "Epoch 60/100\n",
      "455/455 [==============================] - 0s 99us/step - loss: 1.5866 - accuracy: 0.7736 - val_loss: 0.6333 - val_accuracy: 0.9490\n",
      "Epoch 61/100\n",
      "455/455 [==============================] - 0s 91us/step - loss: 1.3710 - accuracy: 0.7736 - val_loss: 0.7000 - val_accuracy: 0.9439\n",
      "Epoch 62/100\n",
      "455/455 [==============================] - 0s 105us/step - loss: 1.3863 - accuracy: 0.7516 - val_loss: 0.6631 - val_accuracy: 0.9490\n",
      "Epoch 63/100\n",
      "455/455 [==============================] - 0s 93us/step - loss: 1.4764 - accuracy: 0.7758 - val_loss: 0.6765 - val_accuracy: 0.9337\n",
      "Epoch 64/100\n",
      "455/455 [==============================] - 0s 95us/step - loss: 1.3260 - accuracy: 0.7758 - val_loss: 0.6742 - val_accuracy: 0.9337\n",
      "Epoch 65/100\n",
      "455/455 [==============================] - 0s 92us/step - loss: 1.3412 - accuracy: 0.7802 - val_loss: 0.6138 - val_accuracy: 0.9592\n",
      "Epoch 66/100\n",
      "455/455 [==============================] - 0s 96us/step - loss: 1.2925 - accuracy: 0.7780 - val_loss: 0.6685 - val_accuracy: 0.9286\n",
      "Epoch 67/100\n",
      "455/455 [==============================] - 0s 135us/step - loss: 1.3070 - accuracy: 0.7802 - val_loss: 0.6687 - val_accuracy: 0.9388\n",
      "Epoch 68/100\n",
      "455/455 [==============================] - 0s 259us/step - loss: 1.4122 - accuracy: 0.7736 - val_loss: 0.6212 - val_accuracy: 0.9592\n",
      "Epoch 69/100\n",
      "455/455 [==============================] - 0s 286us/step - loss: 1.2869 - accuracy: 0.8088 - val_loss: 0.6661 - val_accuracy: 0.9490\n",
      "Epoch 70/100\n",
      "455/455 [==============================] - 0s 245us/step - loss: 1.5710 - accuracy: 0.7407 - val_loss: 0.5897 - val_accuracy: 0.9643\n",
      "Epoch 71/100\n",
      "455/455 [==============================] - 0s 147us/step - loss: 1.2470 - accuracy: 0.7758 - val_loss: 0.6100 - val_accuracy: 0.9694\n",
      "Epoch 72/100\n",
      "455/455 [==============================] - 0s 102us/step - loss: 1.4839 - accuracy: 0.7758 - val_loss: 0.6355 - val_accuracy: 0.9592\n",
      "Epoch 73/100\n",
      "455/455 [==============================] - 0s 92us/step - loss: 1.0983 - accuracy: 0.7890 - val_loss: 0.6692 - val_accuracy: 0.9541\n",
      "Epoch 74/100\n",
      "455/455 [==============================] - 0s 94us/step - loss: 1.2809 - accuracy: 0.8022 - val_loss: 0.6282 - val_accuracy: 0.9694\n",
      "Epoch 75/100\n",
      "455/455 [==============================] - 0s 95us/step - loss: 1.2514 - accuracy: 0.8000 - val_loss: 0.6122 - val_accuracy: 0.9745\n",
      "Epoch 76/100\n",
      "455/455 [==============================] - 0s 131us/step - loss: 1.3087 - accuracy: 0.7692 - val_loss: 0.6340 - val_accuracy: 0.9694\n",
      "Epoch 77/100\n",
      "455/455 [==============================] - 0s 171us/step - loss: 1.1374 - accuracy: 0.8110 - val_loss: 0.6826 - val_accuracy: 0.9643\n",
      "Epoch 78/100\n",
      "455/455 [==============================] - 0s 146us/step - loss: 1.1209 - accuracy: 0.8000 - val_loss: 0.6346 - val_accuracy: 0.9745\n",
      "Epoch 79/100\n",
      "455/455 [==============================] - 0s 149us/step - loss: 1.0800 - accuracy: 0.8132 - val_loss: 0.5973 - val_accuracy: 0.9745\n",
      "Epoch 80/100\n",
      "455/455 [==============================] - 0s 130us/step - loss: 1.1137 - accuracy: 0.8066 - val_loss: 0.6464 - val_accuracy: 0.9694\n",
      "Epoch 81/100\n",
      "455/455 [==============================] - 0s 122us/step - loss: 1.2312 - accuracy: 0.8044 - val_loss: 0.6426 - val_accuracy: 0.9694\n",
      "Epoch 82/100\n",
      "455/455 [==============================] - 0s 132us/step - loss: 1.2900 - accuracy: 0.7560 - val_loss: 0.6875 - val_accuracy: 0.9643\n",
      "Epoch 83/100\n",
      "455/455 [==============================] - 0s 330us/step - loss: 1.0387 - accuracy: 0.8330 - val_loss: 0.6114 - val_accuracy: 0.9694\n",
      "Epoch 84/100\n",
      "455/455 [==============================] - 0s 153us/step - loss: 1.1373 - accuracy: 0.8176 - val_loss: 0.5832 - val_accuracy: 0.9796\n",
      "Epoch 85/100\n",
      "455/455 [==============================] - 0s 104us/step - loss: 1.1447 - accuracy: 0.8154 - val_loss: 0.6517 - val_accuracy: 0.9694\n",
      "Epoch 86/100\n",
      "455/455 [==============================] - 0s 112us/step - loss: 1.1530 - accuracy: 0.7846 - val_loss: 0.6175 - val_accuracy: 0.9643\n",
      "Epoch 87/100\n",
      "455/455 [==============================] - 0s 120us/step - loss: 1.0355 - accuracy: 0.8110 - val_loss: 0.5551 - val_accuracy: 0.9847\n",
      "Epoch 88/100\n",
      "455/455 [==============================] - 0s 171us/step - loss: 1.2954 - accuracy: 0.7714 - val_loss: 0.5990 - val_accuracy: 0.9847\n",
      "Epoch 89/100\n",
      "455/455 [==============================] - 0s 140us/step - loss: 1.0073 - accuracy: 0.8132 - val_loss: 0.5752 - val_accuracy: 0.9694\n",
      "Epoch 90/100\n",
      "455/455 [==============================] - 0s 112us/step - loss: 1.0881 - accuracy: 0.7736 - val_loss: 0.5352 - val_accuracy: 0.9796\n",
      "Epoch 91/100\n",
      "455/455 [==============================] - 0s 153us/step - loss: 1.0483 - accuracy: 0.7802 - val_loss: 0.5380 - val_accuracy: 0.9796\n",
      "Epoch 92/100\n",
      "455/455 [==============================] - 0s 128us/step - loss: 1.0215 - accuracy: 0.7890 - val_loss: 0.5557 - val_accuracy: 0.9745\n",
      "Epoch 93/100\n",
      "455/455 [==============================] - 0s 99us/step - loss: 0.9993 - accuracy: 0.8220 - val_loss: 0.5437 - val_accuracy: 0.9796\n",
      "Epoch 94/100\n",
      "455/455 [==============================] - 0s 113us/step - loss: 1.0125 - accuracy: 0.7846 - val_loss: 0.5428 - val_accuracy: 0.9694\n",
      "Epoch 95/100\n",
      "455/455 [==============================] - 0s 129us/step - loss: 1.1953 - accuracy: 0.7626 - val_loss: 0.6072 - val_accuracy: 0.9592\n",
      "Epoch 96/100\n",
      "455/455 [==============================] - 0s 99us/step - loss: 0.9996 - accuracy: 0.8066 - val_loss: 0.5596 - val_accuracy: 0.9796\n",
      "Epoch 97/100\n",
      "455/455 [==============================] - 0s 160us/step - loss: 1.2514 - accuracy: 0.7670 - val_loss: 0.5837 - val_accuracy: 0.9796\n",
      "Epoch 98/100\n",
      "455/455 [==============================] - 0s 105us/step - loss: 0.9781 - accuracy: 0.8110 - val_loss: 0.6913 - val_accuracy: 0.9643\n",
      "Epoch 99/100\n",
      "455/455 [==============================] - 0s 97us/step - loss: 0.9884 - accuracy: 0.8044 - val_loss: 0.5635 - val_accuracy: 0.9796\n",
      "Epoch 100/100\n",
      "455/455 [==============================] - 0s 124us/step - loss: 1.0574 - accuracy: 0.8088 - val_loss: 0.5644 - val_accuracy: 0.9796\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a392ae470>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over6.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196/196 [==============================] - 0s 103us/step\n",
      "over-sampling test accuracy: 97.96%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over6 = model1_over6.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over6*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 2, 0, 2, 0, 1, 1, 1, 2, 1, 2, 0, 0, 0, 2, 2, 2, 1, 2, 1,\n",
       "       0, 1, 0, 0, 0, 1, 2, 1, 2, 1, 2, 2, 1, 2, 2, 2, 0, 2, 1, 2, 1, 1,\n",
       "       2, 2, 2, 1, 1, 1, 1, 2, 0, 0, 1, 0, 1, 0, 2, 0, 2, 1, 1, 0, 0, 1,\n",
       "       1, 2, 2, 1, 0, 2, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 2, 0, 0, 0, 1, 0,\n",
       "       1, 2, 1, 1, 2, 1, 1, 0, 0, 2, 0, 2, 1, 1, 2, 2, 1, 1, 1, 1, 0, 2,\n",
       "       2, 1, 0, 1, 2, 0, 0, 0, 2, 1, 2, 1, 1, 2, 2, 0, 0, 2, 2, 0, 1, 0,\n",
       "       1, 1, 0, 2, 0, 2, 1, 0, 2, 0, 2, 1, 2, 1, 2, 1, 0, 2, 0, 2, 2, 2,\n",
       "       2, 2, 0, 0, 2, 1, 0, 0, 0, 1, 2, 0, 0, 1, 1, 0, 0, 2, 1, 0, 1, 1,\n",
       "       1, 2, 2, 2, 1, 2, 0, 2, 1, 1, 2, 2, 1, 2, 1, 0, 1, 1, 0, 2])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred6 = model1_over6.predict_classes(X_test_over)\n",
    "pred6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>120335</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS168</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS202</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BCH-SA-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>NRS272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>NRS112</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>NRS064</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>BCH-SA-04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>196 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0  test  pred\n",
       "0       120335     0     0\n",
       "1       NRS168     1     1\n",
       "2       NRS202     0     0\n",
       "3       NRS109     2     2\n",
       "4    BCH-SA-01     0     0\n",
       "..         ...   ...   ...\n",
       "191     NRS272     0     0\n",
       "192     NRS112     1     1\n",
       "193     NRS064     1     1\n",
       "194  BCH-SA-04     0     0\n",
       "195     NRS148     2     2\n",
       "\n",
       "[196 rows x 3 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat6['pred'] = pred6\n",
    "dat6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba6 = model1_over6.predict_proba(X_test_over)\n",
    "dat_proba6 = pd.DataFrame(proba6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.999977e-01</td>\n",
       "      <td>1.597207e-06</td>\n",
       "      <td>7.331805e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.360944e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.874649e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.280388e-01</td>\n",
       "      <td>7.177861e-02</td>\n",
       "      <td>1.825427e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.097152e-08</td>\n",
       "      <td>7.371120e-08</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.999968e-01</td>\n",
       "      <td>2.608138e-06</td>\n",
       "      <td>5.698141e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>9.999607e-01</td>\n",
       "      <td>3.367024e-05</td>\n",
       "      <td>5.776848e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>8.275442e-08</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>3.739556e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>2.168245e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.603962e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.026408e-15</td>\n",
       "      <td>1.630406e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>2.120633e-08</td>\n",
       "      <td>1.998345e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>196 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0             1             2\n",
       "0    9.999977e-01  1.597207e-06  7.331805e-07\n",
       "1    4.360944e-08  1.000000e+00  1.874649e-08\n",
       "2    9.280388e-01  7.177861e-02  1.825427e-04\n",
       "3    8.097152e-08  7.371120e-08  9.999999e-01\n",
       "4    9.999968e-01  2.608138e-06  5.698141e-07\n",
       "..            ...           ...           ...\n",
       "191  9.999607e-01  3.367024e-05  5.776848e-06\n",
       "192  8.275442e-08  9.999999e-01  3.739556e-09\n",
       "193  2.168245e-08  1.000000e+00  9.603962e-09\n",
       "194  1.000000e+00  1.026408e-15  1.630406e-14\n",
       "195  2.120633e-08  1.998345e-08  1.000000e+00\n",
       "\n",
       "[196 rows x 3 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba6.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba6.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat6.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/6pyopST.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 455 samples, validate on 196 samples\n",
      "Epoch 1/100\n",
      "455/455 [==============================] - 0s 178us/step - loss: 1.1909 - accuracy: 0.8000 - val_loss: 0.5928 - val_accuracy: 0.9796\n",
      "Epoch 2/100\n",
      "455/455 [==============================] - 0s 181us/step - loss: 1.1061 - accuracy: 0.8110 - val_loss: 0.5806 - val_accuracy: 0.9796\n",
      "Epoch 3/100\n",
      "455/455 [==============================] - 0s 173us/step - loss: 1.0102 - accuracy: 0.8154 - val_loss: 0.6028 - val_accuracy: 0.9745\n",
      "Epoch 4/100\n",
      "455/455 [==============================] - 0s 178us/step - loss: 1.1831 - accuracy: 0.7846 - val_loss: 0.5946 - val_accuracy: 0.9796\n",
      "Epoch 5/100\n",
      "455/455 [==============================] - 0s 153us/step - loss: 0.9551 - accuracy: 0.8198 - val_loss: 0.5588 - val_accuracy: 0.9796\n",
      "Epoch 6/100\n",
      "455/455 [==============================] - 0s 163us/step - loss: 1.2769 - accuracy: 0.7714 - val_loss: 0.5739 - val_accuracy: 0.9796\n",
      "Epoch 7/100\n",
      "455/455 [==============================] - 0s 157us/step - loss: 1.0062 - accuracy: 0.7978 - val_loss: 0.5606 - val_accuracy: 0.9796\n",
      "Epoch 8/100\n",
      "455/455 [==============================] - 0s 214us/step - loss: 1.0010 - accuracy: 0.8132 - val_loss: 0.5452 - val_accuracy: 0.9796\n",
      "Epoch 9/100\n",
      "455/455 [==============================] - 0s 152us/step - loss: 0.9347 - accuracy: 0.8110 - val_loss: 0.5178 - val_accuracy: 0.9796\n",
      "Epoch 10/100\n",
      "455/455 [==============================] - 0s 139us/step - loss: 1.0376 - accuracy: 0.7846 - val_loss: 0.5302 - val_accuracy: 0.9796\n",
      "Epoch 11/100\n",
      "455/455 [==============================] - 0s 133us/step - loss: 1.1099 - accuracy: 0.8022 - val_loss: 0.5610 - val_accuracy: 0.9796\n",
      "Epoch 12/100\n",
      "455/455 [==============================] - 0s 148us/step - loss: 0.9837 - accuracy: 0.7758 - val_loss: 0.5811 - val_accuracy: 0.9796\n",
      "Epoch 13/100\n",
      "455/455 [==============================] - 0s 145us/step - loss: 1.0368 - accuracy: 0.7780 - val_loss: 0.5811 - val_accuracy: 0.9643\n",
      "Epoch 14/100\n",
      "455/455 [==============================] - 0s 147us/step - loss: 1.1146 - accuracy: 0.7516 - val_loss: 0.5872 - val_accuracy: 0.9643\n",
      "Epoch 15/100\n",
      "455/455 [==============================] - 0s 213us/step - loss: 0.9004 - accuracy: 0.8198 - val_loss: 0.5710 - val_accuracy: 0.9796\n",
      "Epoch 16/100\n",
      "455/455 [==============================] - 0s 366us/step - loss: 1.0350 - accuracy: 0.7604 - val_loss: 0.5865 - val_accuracy: 0.9745\n",
      "Epoch 17/100\n",
      "455/455 [==============================] - 0s 247us/step - loss: 0.9713 - accuracy: 0.7934 - val_loss: 0.5930 - val_accuracy: 0.9796\n",
      "Epoch 18/100\n",
      "455/455 [==============================] - 0s 261us/step - loss: 1.0419 - accuracy: 0.7758 - val_loss: 0.5769 - val_accuracy: 0.9796\n",
      "Epoch 19/100\n",
      "455/455 [==============================] - 0s 234us/step - loss: 0.8675 - accuracy: 0.8000 - val_loss: 0.5840 - val_accuracy: 0.9796\n",
      "Epoch 20/100\n",
      "455/455 [==============================] - 0s 538us/step - loss: 0.9366 - accuracy: 0.8154 - val_loss: 0.5783 - val_accuracy: 0.9796\n",
      "Epoch 21/100\n",
      "455/455 [==============================] - 0s 414us/step - loss: 0.9723 - accuracy: 0.7824 - val_loss: 0.5680 - val_accuracy: 0.9694\n",
      "Epoch 22/100\n",
      "455/455 [==============================] - 0s 275us/step - loss: 0.9153 - accuracy: 0.7956 - val_loss: 0.5649 - val_accuracy: 0.9796\n",
      "Epoch 23/100\n",
      "455/455 [==============================] - 0s 144us/step - loss: 0.9699 - accuracy: 0.7868 - val_loss: 0.5581 - val_accuracy: 0.9745\n",
      "Epoch 24/100\n",
      "455/455 [==============================] - 0s 243us/step - loss: 0.9220 - accuracy: 0.7736 - val_loss: 0.5513 - val_accuracy: 0.9796\n",
      "Epoch 25/100\n",
      "455/455 [==============================] - 0s 187us/step - loss: 0.9041 - accuracy: 0.7956 - val_loss: 0.5542 - val_accuracy: 0.9796\n",
      "Epoch 26/100\n",
      "455/455 [==============================] - 0s 189us/step - loss: 0.9303 - accuracy: 0.7912 - val_loss: 0.5389 - val_accuracy: 0.9796\n",
      "Epoch 27/100\n",
      "455/455 [==============================] - 0s 202us/step - loss: 0.9042 - accuracy: 0.7780 - val_loss: 0.5478 - val_accuracy: 0.9796\n",
      "Epoch 28/100\n",
      "455/455 [==============================] - 0s 154us/step - loss: 0.8659 - accuracy: 0.8022 - val_loss: 0.6102 - val_accuracy: 0.9694\n",
      "Epoch 29/100\n",
      "455/455 [==============================] - 0s 155us/step - loss: 0.8913 - accuracy: 0.7912 - val_loss: 0.5989 - val_accuracy: 0.9796\n",
      "Epoch 30/100\n",
      "455/455 [==============================] - 0s 147us/step - loss: 0.8531 - accuracy: 0.7956 - val_loss: 0.5747 - val_accuracy: 0.9796\n",
      "Epoch 31/100\n",
      "455/455 [==============================] - 0s 138us/step - loss: 0.8116 - accuracy: 0.8110 - val_loss: 0.5657 - val_accuracy: 0.9694\n",
      "Epoch 32/100\n",
      "455/455 [==============================] - 0s 338us/step - loss: 0.8684 - accuracy: 0.8110 - val_loss: 0.5558 - val_accuracy: 0.9745\n",
      "Epoch 33/100\n",
      "455/455 [==============================] - 0s 157us/step - loss: 0.7927 - accuracy: 0.7978 - val_loss: 0.5520 - val_accuracy: 0.9745\n",
      "Epoch 34/100\n",
      "455/455 [==============================] - 0s 394us/step - loss: 0.8934 - accuracy: 0.7868 - val_loss: 0.5333 - val_accuracy: 0.9745\n",
      "Epoch 35/100\n",
      "455/455 [==============================] - 0s 246us/step - loss: 0.9114 - accuracy: 0.7714 - val_loss: 0.5324 - val_accuracy: 0.9847\n",
      "Epoch 36/100\n",
      "455/455 [==============================] - 0s 223us/step - loss: 0.7887 - accuracy: 0.8286 - val_loss: 0.5202 - val_accuracy: 0.9796\n",
      "Epoch 37/100\n",
      "455/455 [==============================] - 0s 330us/step - loss: 0.8944 - accuracy: 0.7868 - val_loss: 0.5695 - val_accuracy: 0.9745\n",
      "Epoch 38/100\n",
      "455/455 [==============================] - 0s 264us/step - loss: 0.8573 - accuracy: 0.8022 - val_loss: 0.5659 - val_accuracy: 0.9796\n",
      "Epoch 39/100\n",
      "455/455 [==============================] - 0s 268us/step - loss: 0.7463 - accuracy: 0.8286 - val_loss: 0.5643 - val_accuracy: 0.9745\n",
      "Epoch 40/100\n",
      "455/455 [==============================] - 0s 264us/step - loss: 0.8929 - accuracy: 0.7780 - val_loss: 0.5468 - val_accuracy: 0.9745\n",
      "Epoch 41/100\n",
      "455/455 [==============================] - 0s 353us/step - loss: 0.8032 - accuracy: 0.8044 - val_loss: 0.5119 - val_accuracy: 0.9745\n",
      "Epoch 42/100\n",
      "455/455 [==============================] - 0s 229us/step - loss: 0.8613 - accuracy: 0.7604 - val_loss: 0.5497 - val_accuracy: 0.9745\n",
      "Epoch 43/100\n",
      "455/455 [==============================] - 0s 178us/step - loss: 0.8542 - accuracy: 0.7670 - val_loss: 0.5036 - val_accuracy: 0.9745\n",
      "Epoch 44/100\n",
      "455/455 [==============================] - 0s 257us/step - loss: 0.8795 - accuracy: 0.7780 - val_loss: 0.5785 - val_accuracy: 0.9745\n",
      "Epoch 45/100\n",
      "455/455 [==============================] - 0s 253us/step - loss: 0.9053 - accuracy: 0.7626 - val_loss: 0.6101 - val_accuracy: 0.9745\n",
      "Epoch 46/100\n",
      "455/455 [==============================] - 0s 278us/step - loss: 0.8806 - accuracy: 0.7758 - val_loss: 0.6101 - val_accuracy: 0.9745\n",
      "Epoch 47/100\n",
      "455/455 [==============================] - 0s 301us/step - loss: 0.6862 - accuracy: 0.8176 - val_loss: 0.5547 - val_accuracy: 0.9745\n",
      "Epoch 48/100\n",
      "455/455 [==============================] - 0s 411us/step - loss: 0.8089 - accuracy: 0.7912 - val_loss: 0.5337 - val_accuracy: 0.9745\n",
      "Epoch 49/100\n",
      "455/455 [==============================] - 0s 257us/step - loss: 0.8181 - accuracy: 0.7736 - val_loss: 0.5209 - val_accuracy: 0.9745\n",
      "Epoch 50/100\n",
      "455/455 [==============================] - 0s 267us/step - loss: 0.7577 - accuracy: 0.7736 - val_loss: 0.5308 - val_accuracy: 0.9745\n",
      "Epoch 51/100\n",
      "455/455 [==============================] - 0s 200us/step - loss: 0.7790 - accuracy: 0.7956 - val_loss: 0.4799 - val_accuracy: 0.9796\n",
      "Epoch 52/100\n",
      "455/455 [==============================] - 0s 216us/step - loss: 0.8159 - accuracy: 0.7824 - val_loss: 0.5283 - val_accuracy: 0.9847\n",
      "Epoch 53/100\n",
      "455/455 [==============================] - 0s 360us/step - loss: 0.8166 - accuracy: 0.7956 - val_loss: 0.5063 - val_accuracy: 0.9796\n",
      "Epoch 54/100\n",
      "455/455 [==============================] - 0s 143us/step - loss: 0.7240 - accuracy: 0.8132 - val_loss: 0.4811 - val_accuracy: 0.9796\n",
      "Epoch 55/100\n",
      "455/455 [==============================] - 0s 568us/step - loss: 0.7001 - accuracy: 0.8154 - val_loss: 0.4731 - val_accuracy: 0.9796\n",
      "Epoch 56/100\n",
      "455/455 [==============================] - 0s 328us/step - loss: 0.8112 - accuracy: 0.7736 - val_loss: 0.5008 - val_accuracy: 0.9745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "455/455 [==============================] - 0s 174us/step - loss: 0.7608 - accuracy: 0.7846 - val_loss: 0.5080 - val_accuracy: 0.9796\n",
      "Epoch 58/100\n",
      "455/455 [==============================] - 0s 220us/step - loss: 0.6826 - accuracy: 0.8286 - val_loss: 0.4018 - val_accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "455/455 [==============================] - 0s 158us/step - loss: 0.6888 - accuracy: 0.8132 - val_loss: 0.4042 - val_accuracy: 0.9949\n",
      "Epoch 60/100\n",
      "455/455 [==============================] - 0s 146us/step - loss: 0.6781 - accuracy: 0.8484 - val_loss: 0.4912 - val_accuracy: 0.9694\n",
      "Epoch 61/100\n",
      "455/455 [==============================] - 0s 149us/step - loss: 0.7741 - accuracy: 0.7802 - val_loss: 0.4826 - val_accuracy: 0.9745\n",
      "Epoch 62/100\n",
      "455/455 [==============================] - 0s 150us/step - loss: 0.7588 - accuracy: 0.8000 - val_loss: 0.5111 - val_accuracy: 0.9745\n",
      "Epoch 63/100\n",
      "455/455 [==============================] - 0s 142us/step - loss: 0.6445 - accuracy: 0.8132 - val_loss: 0.5071 - val_accuracy: 0.9745\n",
      "Epoch 64/100\n",
      "455/455 [==============================] - 0s 150us/step - loss: 0.6907 - accuracy: 0.8308 - val_loss: 0.4989 - val_accuracy: 0.9745\n",
      "Epoch 65/100\n",
      "455/455 [==============================] - 0s 141us/step - loss: 0.6794 - accuracy: 0.7956 - val_loss: 0.4345 - val_accuracy: 0.9745\n",
      "Epoch 66/100\n",
      "455/455 [==============================] - 0s 149us/step - loss: 0.7499 - accuracy: 0.7780 - val_loss: 0.4170 - val_accuracy: 0.9796\n",
      "Epoch 67/100\n",
      "455/455 [==============================] - 0s 199us/step - loss: 0.7452 - accuracy: 0.7736 - val_loss: 0.3979 - val_accuracy: 0.9847\n",
      "Epoch 68/100\n",
      "455/455 [==============================] - 0s 202us/step - loss: 0.6782 - accuracy: 0.7758 - val_loss: 0.5254 - val_accuracy: 0.9796\n",
      "Epoch 69/100\n",
      "455/455 [==============================] - 0s 183us/step - loss: 0.7662 - accuracy: 0.7648 - val_loss: 0.5139 - val_accuracy: 0.9745\n",
      "Epoch 70/100\n",
      "455/455 [==============================] - 0s 203us/step - loss: 0.6525 - accuracy: 0.8154 - val_loss: 0.4371 - val_accuracy: 0.9745\n",
      "Epoch 71/100\n",
      "455/455 [==============================] - 0s 191us/step - loss: 0.6416 - accuracy: 0.8176 - val_loss: 0.4495 - val_accuracy: 0.9745\n",
      "Epoch 72/100\n",
      "455/455 [==============================] - 0s 208us/step - loss: 0.6859 - accuracy: 0.8044 - val_loss: 0.4909 - val_accuracy: 0.9796\n",
      "Epoch 73/100\n",
      "455/455 [==============================] - 0s 257us/step - loss: 0.7174 - accuracy: 0.7846 - val_loss: 0.4652 - val_accuracy: 0.9847\n",
      "Epoch 74/100\n",
      "455/455 [==============================] - 0s 200us/step - loss: 0.6334 - accuracy: 0.8286 - val_loss: 0.3948 - val_accuracy: 0.9949\n",
      "Epoch 75/100\n",
      "455/455 [==============================] - 0s 226us/step - loss: 0.7933 - accuracy: 0.7758 - val_loss: 0.4160 - val_accuracy: 0.9694\n",
      "Epoch 76/100\n",
      "455/455 [==============================] - 0s 187us/step - loss: 0.6986 - accuracy: 0.7912 - val_loss: 0.3926 - val_accuracy: 0.9898\n",
      "Epoch 77/100\n",
      "455/455 [==============================] - 0s 195us/step - loss: 0.6358 - accuracy: 0.8132 - val_loss: 0.3962 - val_accuracy: 0.9847\n",
      "Epoch 78/100\n",
      "455/455 [==============================] - 0s 187us/step - loss: 0.7357 - accuracy: 0.7802 - val_loss: 0.5012 - val_accuracy: 0.9796\n",
      "Epoch 79/100\n",
      "455/455 [==============================] - 0s 210us/step - loss: 0.6061 - accuracy: 0.8088 - val_loss: 0.5189 - val_accuracy: 0.9796\n",
      "Epoch 80/100\n",
      "455/455 [==============================] - 0s 230us/step - loss: 0.7455 - accuracy: 0.7978 - val_loss: 0.4791 - val_accuracy: 0.9694\n",
      "Epoch 81/100\n",
      "455/455 [==============================] - 0s 383us/step - loss: 0.6693 - accuracy: 0.8044 - val_loss: 0.4097 - val_accuracy: 0.9796\n",
      "Epoch 82/100\n",
      "455/455 [==============================] - 0s 185us/step - loss: 0.6262 - accuracy: 0.8220 - val_loss: 0.4264 - val_accuracy: 0.9796\n",
      "Epoch 83/100\n",
      "455/455 [==============================] - 0s 357us/step - loss: 0.5937 - accuracy: 0.8066 - val_loss: 0.4476 - val_accuracy: 0.9745\n",
      "Epoch 84/100\n",
      "455/455 [==============================] - 0s 189us/step - loss: 0.6484 - accuracy: 0.8000 - val_loss: 0.4358 - val_accuracy: 0.9745\n",
      "Epoch 85/100\n",
      "455/455 [==============================] - 0s 249us/step - loss: 0.5950 - accuracy: 0.8242 - val_loss: 0.4030 - val_accuracy: 0.9796\n",
      "Epoch 86/100\n",
      "455/455 [==============================] - 0s 330us/step - loss: 0.6236 - accuracy: 0.8308 - val_loss: 0.4077 - val_accuracy: 0.9796\n",
      "Epoch 87/100\n",
      "455/455 [==============================] - 0s 234us/step - loss: 0.6049 - accuracy: 0.8132 - val_loss: 0.4371 - val_accuracy: 0.9796\n",
      "Epoch 88/100\n",
      "455/455 [==============================] - 0s 220us/step - loss: 0.6533 - accuracy: 0.7890 - val_loss: 0.4241 - val_accuracy: 0.9745\n",
      "Epoch 89/100\n",
      "455/455 [==============================] - 0s 187us/step - loss: 0.6217 - accuracy: 0.7824 - val_loss: 0.4600 - val_accuracy: 0.9745\n",
      "Epoch 90/100\n",
      "455/455 [==============================] - 0s 157us/step - loss: 0.5821 - accuracy: 0.8154 - val_loss: 0.4216 - val_accuracy: 0.9745\n",
      "Epoch 91/100\n",
      "455/455 [==============================] - 0s 239us/step - loss: 0.6081 - accuracy: 0.7802 - val_loss: 0.4238 - val_accuracy: 0.9745\n",
      "Epoch 92/100\n",
      "455/455 [==============================] - 0s 471us/step - loss: 0.5750 - accuracy: 0.8044 - val_loss: 0.4055 - val_accuracy: 0.9745\n",
      "Epoch 93/100\n",
      "455/455 [==============================] - 0s 198us/step - loss: 0.5775 - accuracy: 0.8022 - val_loss: 0.3987 - val_accuracy: 0.9796\n",
      "Epoch 94/100\n",
      "455/455 [==============================] - 0s 158us/step - loss: 0.6112 - accuracy: 0.7868 - val_loss: 0.4059 - val_accuracy: 0.9796\n",
      "Epoch 95/100\n",
      "455/455 [==============================] - 0s 151us/step - loss: 0.5931 - accuracy: 0.8374 - val_loss: 0.4188 - val_accuracy: 0.9745\n",
      "Epoch 96/100\n",
      "455/455 [==============================] - 0s 151us/step - loss: 0.5543 - accuracy: 0.8286 - val_loss: 0.3798 - val_accuracy: 0.9745\n",
      "Epoch 97/100\n",
      "455/455 [==============================] - 0s 177us/step - loss: 0.5862 - accuracy: 0.8176 - val_loss: 0.4027 - val_accuracy: 0.9745\n",
      "Epoch 98/100\n",
      "455/455 [==============================] - 0s 192us/step - loss: 0.6562 - accuracy: 0.7956 - val_loss: 0.3741 - val_accuracy: 0.9847\n",
      "Epoch 99/100\n",
      "455/455 [==============================] - 0s 171us/step - loss: 0.6184 - accuracy: 0.7978 - val_loss: 0.4390 - val_accuracy: 0.9745\n",
      "Epoch 100/100\n",
      "455/455 [==============================] - 0s 192us/step - loss: 0.6142 - accuracy: 0.8066 - val_loss: 0.3800 - val_accuracy: 0.9847\n"
     ]
    }
   ],
   "source": [
    "hist1_over6 = model1_over6.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 79.71%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over6.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba6 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_regularizor_dropout_2.xlsx\",\n",
    "                        sheet_name=1,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.790400e-08</td>\n",
       "      <td>4.141849e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS386</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.739934e-04</td>\n",
       "      <td>9.994259e-01</td>\n",
       "      <td>6.773014e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5.286934e-09</td>\n",
       "      <td>1.269109e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS178</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.494936e-12</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.537080e-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS237</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.701098e-02</td>\n",
       "      <td>9.399204e-01</td>\n",
       "      <td>3.068583e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.999607e-01</td>\n",
       "      <td>3.367024e-05</td>\n",
       "      <td>5.776848e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS112</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.275442e-08</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>3.739556e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS064</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.168245e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.603962e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>BCH-SA-04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.026408e-15</td>\n",
       "      <td>1.630406e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.120633e-08</td>\n",
       "      <td>1.998346e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1982 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       phage     strain  phenotype  prediction             0  \\\n",
       "0     p002ykpresabsSTCC_qual     NRS209          2           2  1.790400e-08   \n",
       "1     p002ykpresabsSTCC_qual     NRS386          1           1  5.739934e-04   \n",
       "2     p002ykpresabsSTCC_qual     NRS148          2           2  5.286934e-09   \n",
       "3     p002ykpresabsSTCC_qual     NRS178          0           1  6.494936e-12   \n",
       "4     p002ykpresabsSTCC_qual     NRS237          0           1  5.701098e-02   \n",
       "...                      ...        ...        ...         ...           ...   \n",
       "1977     pyopresabsSTCC_qual     NRS272          0           0  9.999607e-01   \n",
       "1978     pyopresabsSTCC_qual     NRS112          1           1  8.275442e-08   \n",
       "1979     pyopresabsSTCC_qual     NRS064          1           1  2.168245e-08   \n",
       "1980     pyopresabsSTCC_qual  BCH-SA-04          0           0  1.000000e+00   \n",
       "1981     pyopresabsSTCC_qual     NRS148          2           2  2.120633e-08   \n",
       "\n",
       "                 1             2  \n",
       "0     4.141849e-08  1.000000e+00  \n",
       "1     9.994259e-01  6.773014e-08  \n",
       "2     1.269109e-08  1.000000e+00  \n",
       "3     1.000000e+00  2.537080e-25  \n",
       "4     9.399204e-01  3.068583e-03  \n",
       "...            ...           ...  \n",
       "1977  3.367024e-05  5.776848e-06  \n",
       "1978  9.999999e-01  3.739556e-09  \n",
       "1979  1.000000e+00  9.603962e-09  \n",
       "1980  1.026408e-15  1.630406e-14  \n",
       "1981  1.998346e-08  1.000000e+00  \n",
       "\n",
       "[1982 rows x 7 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.99997740e-01, 1.59720680e-06, 7.33180500e-07],\n",
       "       [4.36094360e-08, 1.00000000e+00, 1.87464920e-08],\n",
       "       [9.28038840e-01, 7.17786100e-02, 1.82542660e-04],\n",
       "       [8.09715200e-08, 7.37112000e-08, 9.99999900e-01],\n",
       "       [9.99996800e-01, 2.60813840e-06, 5.69814060e-07],\n",
       "       [8.09715200e-08, 7.37112000e-08, 9.99999900e-01],\n",
       "       [9.99999760e-01, 2.50527820e-07, 2.58507920e-08],\n",
       "       [1.46019660e-02, 9.85232500e-01, 1.65560920e-04],\n",
       "       [2.71841870e-06, 9.99996200e-01, 1.01948390e-06],\n",
       "       [4.69290070e-04, 9.99520900e-01, 9.77271900e-06],\n",
       "       [8.09715200e-08, 7.37112000e-08, 9.99999900e-01],\n",
       "       [3.69294750e-07, 9.99999640e-01, 4.03836000e-09],\n",
       "       [2.55030800e-08, 2.42283190e-08, 1.00000000e+00],\n",
       "       [1.00000000e+00, 2.09545130e-30, 1.29175110e-26],\n",
       "       [9.99958300e-01, 3.80289130e-05, 3.70608000e-06],\n",
       "       [1.00000000e+00, 1.20991610e-09, 2.60884300e-10],\n",
       "       [2.55030800e-08, 2.42283190e-08, 1.00000000e+00],\n",
       "       [2.55030800e-08, 2.42283190e-08, 1.00000000e+00],\n",
       "       [2.12063260e-08, 1.99834550e-08, 1.00000000e+00],\n",
       "       [2.93595320e-07, 9.99999760e-01, 1.59696400e-09],\n",
       "       [2.12063260e-08, 1.99834550e-08, 1.00000000e+00],\n",
       "       [5.52394300e-02, 9.44334150e-01, 4.26449000e-04],\n",
       "       [9.99995800e-01, 3.81051800e-06, 3.68969860e-07],\n",
       "       [1.07366760e-06, 9.99998570e-01, 3.88543040e-07],\n",
       "       [1.00000000e+00, 9.36776300e-11, 1.05446596e-10],\n",
       "       [1.00000000e+00, 2.35917430e-13, 2.03970240e-13],\n",
       "       [1.00000000e+00, 3.37283870e-09, 7.81290800e-10],\n",
       "       [2.71841870e-06, 9.99996200e-01, 1.01948390e-06],\n",
       "       [7.28111800e-08, 7.24399460e-08, 9.99999900e-01],\n",
       "       [1.53226720e-07, 9.99999900e-01, 2.41303930e-09],\n",
       "       [7.28111800e-08, 7.24399460e-08, 9.99999900e-01],\n",
       "       [1.96792460e-03, 9.97842300e-01, 1.89720670e-04],\n",
       "       [2.55030800e-08, 2.42283190e-08, 1.00000000e+00],\n",
       "       [2.12063260e-08, 1.99834550e-08, 1.00000000e+00],\n",
       "       [8.27544200e-08, 9.99999900e-01, 3.73955600e-09],\n",
       "       [2.12063260e-08, 1.99834550e-08, 1.00000000e+00],\n",
       "       [2.55030800e-08, 2.42283190e-08, 1.00000000e+00],\n",
       "       [8.09715200e-08, 7.37112000e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 1.36379460e-10, 6.77041540e-13],\n",
       "       [2.55030800e-08, 2.42283190e-08, 1.00000000e+00],\n",
       "       [1.46019660e-02, 9.85232500e-01, 1.65560920e-04],\n",
       "       [9.77189000e-03, 2.36528670e-06, 9.90225730e-01],\n",
       "       [2.92106780e-01, 5.47784000e-01, 1.60109300e-01],\n",
       "       [3.17568400e-08, 1.00000000e+00, 1.56697780e-10],\n",
       "       [2.55030800e-08, 2.42283190e-08, 1.00000000e+00],\n",
       "       [7.28111800e-08, 7.24399460e-08, 9.99999900e-01],\n",
       "       [2.55030800e-08, 2.42283190e-08, 1.00000000e+00],\n",
       "       [3.79417870e-02, 9.61026900e-01, 1.03131300e-03],\n",
       "       [6.79566000e-08, 9.99999900e-01, 4.30029900e-08],\n",
       "       [1.47281400e-03, 9.98411900e-01, 1.15270800e-04],\n",
       "       [4.69286200e-09, 1.00000000e+00, 1.60775820e-10],\n",
       "       [2.12063260e-08, 1.99834550e-08, 1.00000000e+00],\n",
       "       [1.00000000e+00, 8.53696000e-12, 5.57101400e-11],\n",
       "       [1.00000000e+00, 1.60829360e-08, 8.00530200e-09],\n",
       "       [1.07366760e-06, 9.99998570e-01, 3.88543040e-07],\n",
       "       [7.67716770e-01, 2.32282440e-01, 7.58564060e-07],\n",
       "       [3.54631570e-01, 5.78788400e-01, 6.65800000e-02],\n",
       "       [9.99999760e-01, 1.29583260e-07, 1.18425866e-07],\n",
       "       [8.09715200e-08, 7.37112000e-08, 9.99999900e-01],\n",
       "       [9.99997850e-01, 2.18275250e-06, 9.21263900e-09],\n",
       "       [7.28111800e-08, 7.24399460e-08, 9.99999900e-01],\n",
       "       [2.93595320e-07, 9.99999760e-01, 1.59696400e-09],\n",
       "       [2.86718340e-01, 5.43212230e-01, 1.70069460e-01],\n",
       "       [9.99996540e-01, 2.78709760e-06, 7.38917300e-07],\n",
       "       [9.99997740e-01, 1.95212420e-06, 3.41639580e-07],\n",
       "       [4.36094360e-08, 1.00000000e+00, 1.87464920e-08],\n",
       "       [2.16824460e-08, 1.00000000e+00, 9.60396200e-09],\n",
       "       [2.12063260e-08, 1.99834550e-08, 1.00000000e+00],\n",
       "       [8.09715200e-08, 7.37112000e-08, 9.99999900e-01],\n",
       "       [3.17568400e-08, 1.00000000e+00, 1.56697780e-10],\n",
       "       [9.99452200e-01, 5.47881530e-04, 1.95320740e-08],\n",
       "       [8.09715200e-08, 7.37112000e-08, 9.99999900e-01],\n",
       "       [9.99779760e-01, 2.20028420e-04, 2.10868890e-07],\n",
       "       [2.62090100e-07, 9.99999760e-01, 2.44529200e-08],\n",
       "       [1.00000000e+00, 2.29655450e-14, 1.37685490e-14],\n",
       "       [9.04679900e-01, 9.12156800e-02, 4.10438240e-03],\n",
       "       [1.00000000e+00, 2.06204330e-08, 1.19897470e-08],\n",
       "       [4.69286200e-09, 1.00000000e+00, 1.60775820e-10],\n",
       "       [2.62090100e-07, 9.99999760e-01, 2.44529200e-08],\n",
       "       [5.82721800e-01, 4.15870220e-01, 1.40795670e-03],\n",
       "       [2.90375700e-08, 1.00000000e+00, 1.10304990e-09],\n",
       "       [1.00000000e+00, 4.81186700e-11, 3.69846100e-11],\n",
       "       [2.12063260e-08, 1.99834550e-08, 1.00000000e+00],\n",
       "       [1.00000000e+00, 4.68045200e-10, 1.04196050e-10],\n",
       "       [1.00000000e+00, 4.71914700e-15, 1.24508040e-15],\n",
       "       [1.00000000e+00, 5.37343130e-12, 6.61177500e-13],\n",
       "       [4.69290070e-04, 9.99520900e-01, 9.77271900e-06],\n",
       "       [1.00000000e+00, 1.30409990e-10, 2.78382200e-11],\n",
       "       [1.09933320e-07, 9.99999900e-01, 1.55231280e-09],\n",
       "       [7.28111800e-08, 7.24399460e-08, 9.99999900e-01],\n",
       "       [2.86718340e-01, 5.43212230e-01, 1.70069460e-01],\n",
       "       [4.36094360e-08, 1.00000000e+00, 1.87464920e-08],\n",
       "       [2.55030800e-08, 2.42283190e-08, 1.00000000e+00],\n",
       "       [3.69294750e-07, 9.99999640e-01, 4.03836000e-09],\n",
       "       [3.54631570e-01, 5.78788400e-01, 6.65800000e-02],\n",
       "       [1.00000000e+00, 1.64856400e-15, 1.27232830e-15],\n",
       "       [9.99963400e-01, 3.25067450e-05, 4.06486060e-06],\n",
       "       [8.09715200e-08, 7.37112000e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 6.30512960e-12, 3.92360240e-11],\n",
       "       [2.12063260e-08, 1.99834550e-08, 1.00000000e+00],\n",
       "       [2.44077530e-03, 9.97559200e-01, 4.56737760e-08],\n",
       "       [3.54631570e-01, 5.78788400e-01, 6.65800000e-02],\n",
       "       [8.09715200e-08, 7.37112000e-08, 9.99999900e-01],\n",
       "       [7.28111800e-08, 7.24399460e-08, 9.99999900e-01],\n",
       "       [1.07366760e-06, 9.99998570e-01, 3.88543040e-07],\n",
       "       [4.61110660e-07, 9.99999500e-01, 4.30641000e-09],\n",
       "       [4.69286200e-09, 1.00000000e+00, 1.60775820e-10],\n",
       "       [2.62090100e-07, 9.99999760e-01, 2.44529200e-08],\n",
       "       [1.00000000e+00, 7.79070600e-10, 9.02631200e-11],\n",
       "       [7.28111800e-08, 7.24399460e-08, 9.99999900e-01],\n",
       "       [2.12063260e-08, 1.99834550e-08, 1.00000000e+00],\n",
       "       [2.14750920e-08, 1.00000000e+00, 4.23725450e-09],\n",
       "       [1.00000000e+00, 9.80545300e-10, 1.41613800e-10],\n",
       "       [7.54097940e-04, 9.99046150e-01, 1.99770050e-04],\n",
       "       [8.09715200e-08, 7.37112000e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 1.46521570e-10, 2.55593610e-09],\n",
       "       [9.99997400e-01, 2.38895100e-06, 2.47296530e-07],\n",
       "       [1.00000000e+00, 1.49116350e-12, 3.64068930e-12],\n",
       "       [8.09715200e-08, 7.37112000e-08, 9.99999900e-01],\n",
       "       [1.75496720e-08, 1.00000000e+00, 3.15493370e-08],\n",
       "       [2.55030800e-08, 2.42283190e-08, 1.00000000e+00],\n",
       "       [6.79566000e-08, 9.99999900e-01, 4.30029900e-08],\n",
       "       [3.54631570e-01, 5.78788400e-01, 6.65800000e-02],\n",
       "       [2.55030800e-08, 2.42283190e-08, 1.00000000e+00],\n",
       "       [2.12063260e-08, 1.99834550e-08, 1.00000000e+00],\n",
       "       [1.00000000e+00, 1.73790470e-09, 1.52736590e-10],\n",
       "       [1.00000000e+00, 3.24565700e-09, 2.74095320e-09],\n",
       "       [8.09715200e-08, 7.37112000e-08, 9.99999900e-01],\n",
       "       [8.09715200e-08, 7.37112000e-08, 9.99999900e-01],\n",
       "       [9.99879960e-01, 9.88906800e-05, 2.11000880e-05],\n",
       "       [4.69286200e-09, 1.00000000e+00, 1.60775820e-10],\n",
       "       [1.00000000e+00, 3.83801350e-16, 1.96753900e-17],\n",
       "       [4.69290070e-04, 9.99520900e-01, 9.77271900e-06],\n",
       "       [1.75022620e-07, 9.99999900e-01, 9.98368300e-09],\n",
       "       [9.99632600e-01, 2.55451160e-04, 1.11848516e-04],\n",
       "       [2.12063260e-08, 1.99834550e-08, 1.00000000e+00],\n",
       "       [1.00000000e+00, 1.24862300e-09, 5.87591200e-10],\n",
       "       [8.09715200e-08, 7.37112000e-08, 9.99999900e-01],\n",
       "       [1.40527820e-05, 9.99980200e-01, 5.68622600e-06],\n",
       "       [9.99999900e-01, 7.88384040e-08, 3.42355050e-08],\n",
       "       [7.28111800e-08, 7.24399460e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 5.73229940e-11, 2.88569670e-12],\n",
       "       [8.09715200e-08, 7.37112000e-08, 9.99999900e-01],\n",
       "       [2.14750920e-08, 1.00000000e+00, 4.23725450e-09],\n",
       "       [8.09715200e-08, 7.37112000e-08, 9.99999900e-01],\n",
       "       [4.36094360e-08, 1.00000000e+00, 1.87464920e-08],\n",
       "       [2.55030800e-08, 2.42283190e-08, 1.00000000e+00],\n",
       "       [2.14750920e-08, 1.00000000e+00, 4.23725450e-09],\n",
       "       [1.00000000e+00, 2.82706760e-11, 3.87382300e-12],\n",
       "       [8.09715200e-08, 7.37112000e-08, 9.99999900e-01],\n",
       "       [9.99985000e-01, 1.35559285e-05, 1.38211660e-06],\n",
       "       [8.09715200e-08, 7.37112000e-08, 9.99999900e-01],\n",
       "       [8.09715200e-08, 7.37112000e-08, 9.99999900e-01],\n",
       "       [7.28111800e-08, 7.24399460e-08, 9.99999900e-01],\n",
       "       [2.55030800e-08, 2.42283190e-08, 1.00000000e+00],\n",
       "       [8.09715200e-08, 7.37112000e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 2.44424870e-15, 3.00984950e-16],\n",
       "       [9.99999760e-01, 1.96107440e-07, 8.77460700e-10],\n",
       "       [7.28111800e-08, 7.24399460e-08, 9.99999900e-01],\n",
       "       [8.27544200e-08, 9.99999900e-01, 3.73955600e-09],\n",
       "       [1.00000000e+00, 3.27720320e-12, 2.74292960e-13],\n",
       "       [9.99999900e-01, 1.31850060e-07, 1.41199360e-12],\n",
       "       [1.00000000e+00, 2.66689680e-14, 1.66456440e-15],\n",
       "       [1.96792460e-03, 9.97842300e-01, 1.89720670e-04],\n",
       "       [8.09715200e-08, 7.37112000e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 2.17591610e-09, 7.33269170e-10],\n",
       "       [1.00000000e+00, 7.95095000e-12, 6.21348700e-13],\n",
       "       [4.61110660e-07, 9.99999500e-01, 4.30641000e-09],\n",
       "       [4.36094360e-08, 1.00000000e+00, 1.87464920e-08],\n",
       "       [9.99997260e-01, 2.71081560e-06, 1.37748770e-09],\n",
       "       [1.00000000e+00, 5.12768340e-17, 3.50762430e-17],\n",
       "       [2.55030800e-08, 2.42283190e-08, 1.00000000e+00],\n",
       "       [1.53226720e-07, 9.99999900e-01, 2.41303930e-09],\n",
       "       [9.99999640e-01, 3.27344340e-07, 1.53000850e-08],\n",
       "       [1.46019660e-02, 9.85232500e-01, 1.65560920e-04],\n",
       "       [2.93595320e-07, 9.99999760e-01, 1.59696400e-09],\n",
       "       [7.83688100e-09, 1.00000000e+00, 1.47513260e-08],\n",
       "       [7.28111800e-08, 7.24399460e-08, 9.99999900e-01],\n",
       "       [7.28111800e-08, 7.24399460e-08, 9.99999900e-01],\n",
       "       [2.12063260e-08, 1.99834550e-08, 1.00000000e+00],\n",
       "       [2.90375700e-08, 1.00000000e+00, 1.10304990e-09],\n",
       "       [7.28111800e-08, 7.24399460e-08, 9.99999900e-01],\n",
       "       [7.73593370e-01, 2.26275650e-01, 1.30942300e-04],\n",
       "       [2.55030800e-08, 2.42283190e-08, 1.00000000e+00],\n",
       "       [7.83688100e-09, 1.00000000e+00, 1.47513260e-08],\n",
       "       [8.27544200e-08, 9.99999900e-01, 3.73955600e-09],\n",
       "       [8.09715200e-08, 7.37112000e-08, 9.99999900e-01],\n",
       "       [2.55030800e-08, 2.42283190e-08, 1.00000000e+00],\n",
       "       [3.54631570e-01, 5.78788400e-01, 6.65800000e-02],\n",
       "       [2.12063260e-08, 1.99834550e-08, 1.00000000e+00],\n",
       "       [1.75496720e-08, 1.00000000e+00, 3.15493370e-08],\n",
       "       [9.99960660e-01, 3.36702430e-05, 5.77684750e-06],\n",
       "       [8.27544200e-08, 9.99999900e-01, 3.73955600e-09],\n",
       "       [2.16824460e-08, 1.00000000e+00, 9.60396200e-09],\n",
       "       [1.00000000e+00, 1.02640850e-15, 1.63040610e-14],\n",
       "       [2.12063260e-08, 1.99834550e-08, 1.00000000e+00]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob6 = df_proba6[df_proba6['phage']=='pyopresabsSTCC_qual'].iloc[:,-3:]\n",
    "y_prob6 = y_prob6.to_numpy()\n",
    "y_prob6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9972294880691828"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo6 = rocauc_ovo(y_test_over, y_prob6, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9972294880691828"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr6 = rocauc_ovr(y_test_over, y_prob6, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=789,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat7 = pd.DataFrame(X_test_over[:,0])\n",
    "dat7['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS253</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS105</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS265</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS211</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>NRS035</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>NRS260</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>CA9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>NRS183</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>196 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0  test\n",
       "0    NRS253     1\n",
       "1    NRS148     2\n",
       "2    NRS105     1\n",
       "3    NRS265     1\n",
       "4    NRS211     0\n",
       "..      ...   ...\n",
       "191  NRS035     0\n",
       "192  NRS260     1\n",
       "193     CA9     0\n",
       "194  NRS183     1\n",
       "195  NRS148     2\n",
       "\n",
       "[196 rows x 2 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over7 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],), activity_regularizer=l1(0.001)),\n",
    "    Dense(3, activation='softmax'),\n",
    "    Dropout(0.2, ),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over7.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 455 samples, validate on 196 samples\n",
      "Epoch 1/100\n",
      "455/455 [==============================] - 0s 764us/step - loss: 9.5469 - accuracy: 0.4286 - val_loss: 6.6782 - val_accuracy: 0.6224\n",
      "Epoch 2/100\n",
      "455/455 [==============================] - 0s 183us/step - loss: 7.0803 - accuracy: 0.5319 - val_loss: 4.2874 - val_accuracy: 0.6480\n",
      "Epoch 3/100\n",
      "455/455 [==============================] - 0s 247us/step - loss: 4.9401 - accuracy: 0.6044 - val_loss: 2.6827 - val_accuracy: 0.6480\n",
      "Epoch 4/100\n",
      "455/455 [==============================] - 0s 182us/step - loss: 4.2103 - accuracy: 0.6330 - val_loss: 1.9076 - val_accuracy: 0.6939\n",
      "Epoch 5/100\n",
      "455/455 [==============================] - 0s 234us/step - loss: 3.9589 - accuracy: 0.6220 - val_loss: 1.1853 - val_accuracy: 0.7806\n",
      "Epoch 6/100\n",
      "455/455 [==============================] - 0s 232us/step - loss: 3.3772 - accuracy: 0.6813 - val_loss: 1.0761 - val_accuracy: 0.7857\n",
      "Epoch 7/100\n",
      "455/455 [==============================] - 0s 121us/step - loss: 3.2764 - accuracy: 0.6857 - val_loss: 1.0288 - val_accuracy: 0.7755\n",
      "Epoch 8/100\n",
      "455/455 [==============================] - 0s 121us/step - loss: 2.9367 - accuracy: 0.6967 - val_loss: 0.9747 - val_accuracy: 0.7653\n",
      "Epoch 9/100\n",
      "455/455 [==============================] - 0s 180us/step - loss: 2.9167 - accuracy: 0.7055 - val_loss: 0.9796 - val_accuracy: 0.8010\n",
      "Epoch 10/100\n",
      "455/455 [==============================] - 0s 301us/step - loss: 2.9655 - accuracy: 0.6989 - val_loss: 1.0097 - val_accuracy: 0.7908\n",
      "Epoch 11/100\n",
      "455/455 [==============================] - 0s 163us/step - loss: 2.8040 - accuracy: 0.6879 - val_loss: 0.9527 - val_accuracy: 0.7959\n",
      "Epoch 12/100\n",
      "455/455 [==============================] - 0s 207us/step - loss: 2.4957 - accuracy: 0.7516 - val_loss: 0.8984 - val_accuracy: 0.8367\n",
      "Epoch 13/100\n",
      "455/455 [==============================] - 0s 124us/step - loss: 2.7216 - accuracy: 0.7560 - val_loss: 0.8579 - val_accuracy: 0.8163\n",
      "Epoch 14/100\n",
      "455/455 [==============================] - 0s 111us/step - loss: 2.4637 - accuracy: 0.7143 - val_loss: 0.9589 - val_accuracy: 0.7908\n",
      "Epoch 15/100\n",
      "455/455 [==============================] - 0s 149us/step - loss: 2.7078 - accuracy: 0.7077 - val_loss: 0.9010 - val_accuracy: 0.8571\n",
      "Epoch 16/100\n",
      "455/455 [==============================] - 0s 127us/step - loss: 2.4570 - accuracy: 0.7209 - val_loss: 0.9084 - val_accuracy: 0.8163\n",
      "Epoch 17/100\n",
      "455/455 [==============================] - 0s 113us/step - loss: 2.5325 - accuracy: 0.7033 - val_loss: 0.8850 - val_accuracy: 0.8163\n",
      "Epoch 18/100\n",
      "455/455 [==============================] - 0s 118us/step - loss: 2.4434 - accuracy: 0.7451 - val_loss: 0.8768 - val_accuracy: 0.8520\n",
      "Epoch 19/100\n",
      "455/455 [==============================] - 0s 191us/step - loss: 2.6318 - accuracy: 0.7429 - val_loss: 0.8165 - val_accuracy: 0.8316\n",
      "Epoch 20/100\n",
      "455/455 [==============================] - 0s 139us/step - loss: 2.0997 - accuracy: 0.7802 - val_loss: 0.8045 - val_accuracy: 0.8520\n",
      "Epoch 21/100\n",
      "455/455 [==============================] - 0s 132us/step - loss: 2.4866 - accuracy: 0.7363 - val_loss: 0.8286 - val_accuracy: 0.8571\n",
      "Epoch 22/100\n",
      "455/455 [==============================] - 0s 124us/step - loss: 2.1197 - accuracy: 0.7495 - val_loss: 0.8059 - val_accuracy: 0.8622\n",
      "Epoch 23/100\n",
      "455/455 [==============================] - 0s 439us/step - loss: 2.1309 - accuracy: 0.7626 - val_loss: 0.7625 - val_accuracy: 0.8622\n",
      "Epoch 24/100\n",
      "455/455 [==============================] - 0s 347us/step - loss: 2.0069 - accuracy: 0.7824 - val_loss: 0.7622 - val_accuracy: 0.8980\n",
      "Epoch 25/100\n",
      "455/455 [==============================] - 0s 226us/step - loss: 2.2452 - accuracy: 0.7670 - val_loss: 0.7704 - val_accuracy: 0.8827\n",
      "Epoch 26/100\n",
      "455/455 [==============================] - 0s 250us/step - loss: 2.5497 - accuracy: 0.7143 - val_loss: 0.7557 - val_accuracy: 0.8673\n",
      "Epoch 27/100\n",
      "455/455 [==============================] - 0s 302us/step - loss: 1.9258 - accuracy: 0.7956 - val_loss: 0.7801 - val_accuracy: 0.8827\n",
      "Epoch 28/100\n",
      "455/455 [==============================] - 0s 265us/step - loss: 1.8534 - accuracy: 0.7912 - val_loss: 0.7551 - val_accuracy: 0.8878\n",
      "Epoch 29/100\n",
      "455/455 [==============================] - 0s 359us/step - loss: 2.0486 - accuracy: 0.7934 - val_loss: 0.7775 - val_accuracy: 0.8878\n",
      "Epoch 30/100\n",
      "455/455 [==============================] - 0s 284us/step - loss: 1.9261 - accuracy: 0.7912 - val_loss: 0.7757 - val_accuracy: 0.8929\n",
      "Epoch 31/100\n",
      "455/455 [==============================] - 0s 338us/step - loss: 1.7484 - accuracy: 0.7780 - val_loss: 0.7507 - val_accuracy: 0.8980\n",
      "Epoch 32/100\n",
      "455/455 [==============================] - 0s 276us/step - loss: 1.9244 - accuracy: 0.7648 - val_loss: 0.8167 - val_accuracy: 0.8827\n",
      "Epoch 33/100\n",
      "455/455 [==============================] - 0s 294us/step - loss: 1.8188 - accuracy: 0.7934 - val_loss: 0.8086 - val_accuracy: 0.8929\n",
      "Epoch 34/100\n",
      "455/455 [==============================] - 0s 158us/step - loss: 1.9285 - accuracy: 0.7363 - val_loss: 0.8869 - val_accuracy: 0.8776\n",
      "Epoch 35/100\n",
      "455/455 [==============================] - 0s 271us/step - loss: 1.7269 - accuracy: 0.7956 - val_loss: 0.7202 - val_accuracy: 0.8878\n",
      "Epoch 36/100\n",
      "455/455 [==============================] - 0s 515us/step - loss: 1.8790 - accuracy: 0.7626 - val_loss: 0.7396 - val_accuracy: 0.8878\n",
      "Epoch 37/100\n",
      "455/455 [==============================] - 0s 223us/step - loss: 1.5529 - accuracy: 0.7890 - val_loss: 0.7728 - val_accuracy: 0.9031\n",
      "Epoch 38/100\n",
      "455/455 [==============================] - 0s 160us/step - loss: 1.5676 - accuracy: 0.7934 - val_loss: 0.7355 - val_accuracy: 0.8980\n",
      "Epoch 39/100\n",
      "455/455 [==============================] - 0s 143us/step - loss: 1.7064 - accuracy: 0.7824 - val_loss: 0.9582 - val_accuracy: 0.8776\n",
      "Epoch 40/100\n",
      "455/455 [==============================] - 0s 194us/step - loss: 1.6525 - accuracy: 0.7604 - val_loss: 0.7727 - val_accuracy: 0.8929\n",
      "Epoch 41/100\n",
      "455/455 [==============================] - 0s 179us/step - loss: 1.4791 - accuracy: 0.7912 - val_loss: 0.7149 - val_accuracy: 0.8929\n",
      "Epoch 42/100\n",
      "455/455 [==============================] - 0s 164us/step - loss: 1.5336 - accuracy: 0.8132 - val_loss: 0.8721 - val_accuracy: 0.8878\n",
      "Epoch 43/100\n",
      "455/455 [==============================] - 0s 148us/step - loss: 1.5836 - accuracy: 0.7824 - val_loss: 0.8420 - val_accuracy: 0.8827\n",
      "Epoch 44/100\n",
      "455/455 [==============================] - 0s 120us/step - loss: 1.4622 - accuracy: 0.7582 - val_loss: 0.8163 - val_accuracy: 0.8776\n",
      "Epoch 45/100\n",
      "455/455 [==============================] - 0s 193us/step - loss: 1.3394 - accuracy: 0.7868 - val_loss: 0.8684 - val_accuracy: 0.8724\n",
      "Epoch 46/100\n",
      "455/455 [==============================] - 0s 193us/step - loss: 1.3347 - accuracy: 0.7868 - val_loss: 0.7931 - val_accuracy: 0.9031\n",
      "Epoch 47/100\n",
      "455/455 [==============================] - 0s 149us/step - loss: 1.4069 - accuracy: 0.7758 - val_loss: 0.8742 - val_accuracy: 0.8929\n",
      "Epoch 48/100\n",
      "455/455 [==============================] - 0s 130us/step - loss: 1.4629 - accuracy: 0.7934 - val_loss: 0.8954 - val_accuracy: 0.8929\n",
      "Epoch 49/100\n",
      "455/455 [==============================] - 0s 110us/step - loss: 1.4548 - accuracy: 0.7473 - val_loss: 0.9956 - val_accuracy: 0.8878\n",
      "Epoch 50/100\n",
      "455/455 [==============================] - 0s 123us/step - loss: 1.2643 - accuracy: 0.7824 - val_loss: 0.8758 - val_accuracy: 0.9031\n",
      "Epoch 51/100\n",
      "455/455 [==============================] - 0s 151us/step - loss: 1.0216 - accuracy: 0.8242 - val_loss: 0.9058 - val_accuracy: 0.9031\n",
      "Epoch 52/100\n",
      "455/455 [==============================] - 0s 153us/step - loss: 1.4112 - accuracy: 0.7890 - val_loss: 0.8868 - val_accuracy: 0.8980\n",
      "Epoch 53/100\n",
      "455/455 [==============================] - 0s 115us/step - loss: 1.3518 - accuracy: 0.7714 - val_loss: 1.0798 - val_accuracy: 0.8878\n",
      "Epoch 54/100\n",
      "455/455 [==============================] - 0s 155us/step - loss: 1.3725 - accuracy: 0.7692 - val_loss: 0.9175 - val_accuracy: 0.8929\n",
      "Epoch 55/100\n",
      "455/455 [==============================] - 0s 177us/step - loss: 1.2574 - accuracy: 0.7824 - val_loss: 1.0228 - val_accuracy: 0.8878\n",
      "Epoch 56/100\n",
      "455/455 [==============================] - 0s 144us/step - loss: 1.3492 - accuracy: 0.7495 - val_loss: 1.0958 - val_accuracy: 0.8878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "455/455 [==============================] - 0s 153us/step - loss: 1.1855 - accuracy: 0.7692 - val_loss: 1.0664 - val_accuracy: 0.8878\n",
      "Epoch 58/100\n",
      "455/455 [==============================] - 0s 141us/step - loss: 1.2389 - accuracy: 0.7604 - val_loss: 1.1040 - val_accuracy: 0.8827\n",
      "Epoch 59/100\n",
      "455/455 [==============================] - 0s 137us/step - loss: 1.1830 - accuracy: 0.7802 - val_loss: 0.9404 - val_accuracy: 0.9031\n",
      "Epoch 60/100\n",
      "455/455 [==============================] - 0s 132us/step - loss: 1.3767 - accuracy: 0.7846 - val_loss: 0.9908 - val_accuracy: 0.9031\n",
      "Epoch 61/100\n",
      "455/455 [==============================] - 0s 115us/step - loss: 1.1689 - accuracy: 0.8132 - val_loss: 0.7894 - val_accuracy: 0.9082\n",
      "Epoch 62/100\n",
      "455/455 [==============================] - 0s 110us/step - loss: 1.2635 - accuracy: 0.8022 - val_loss: 0.9391 - val_accuracy: 0.9031\n",
      "Epoch 63/100\n",
      "455/455 [==============================] - 0s 180us/step - loss: 1.1363 - accuracy: 0.7868 - val_loss: 1.0220 - val_accuracy: 0.8929\n",
      "Epoch 64/100\n",
      "455/455 [==============================] - 0s 168us/step - loss: 1.0074 - accuracy: 0.7890 - val_loss: 0.9310 - val_accuracy: 0.9031\n",
      "Epoch 65/100\n",
      "455/455 [==============================] - 0s 170us/step - loss: 1.2012 - accuracy: 0.7692 - val_loss: 0.9724 - val_accuracy: 0.8980\n",
      "Epoch 66/100\n",
      "455/455 [==============================] - 0s 234us/step - loss: 1.0036 - accuracy: 0.7978 - val_loss: 0.8773 - val_accuracy: 0.9082\n",
      "Epoch 67/100\n",
      "455/455 [==============================] - 0s 162us/step - loss: 1.0033 - accuracy: 0.7758 - val_loss: 0.9260 - val_accuracy: 0.8980\n",
      "Epoch 68/100\n",
      "455/455 [==============================] - 0s 159us/step - loss: 1.1045 - accuracy: 0.8022 - val_loss: 0.8250 - val_accuracy: 0.9031\n",
      "Epoch 69/100\n",
      "455/455 [==============================] - 0s 139us/step - loss: 0.9560 - accuracy: 0.8220 - val_loss: 0.7773 - val_accuracy: 0.9082\n",
      "Epoch 70/100\n",
      "455/455 [==============================] - 0s 166us/step - loss: 1.0579 - accuracy: 0.7780 - val_loss: 0.8816 - val_accuracy: 0.9031\n",
      "Epoch 71/100\n",
      "455/455 [==============================] - 0s 184us/step - loss: 0.9886 - accuracy: 0.7934 - val_loss: 0.8770 - val_accuracy: 0.9031\n",
      "Epoch 72/100\n",
      "455/455 [==============================] - 0s 256us/step - loss: 1.0549 - accuracy: 0.7780 - val_loss: 0.8911 - val_accuracy: 0.9031\n",
      "Epoch 73/100\n",
      "455/455 [==============================] - 0s 131us/step - loss: 0.9509 - accuracy: 0.7824 - val_loss: 0.9854 - val_accuracy: 0.8929\n",
      "Epoch 74/100\n",
      "455/455 [==============================] - 0s 131us/step - loss: 0.9850 - accuracy: 0.7912 - val_loss: 0.7637 - val_accuracy: 0.9082\n",
      "Epoch 75/100\n",
      "455/455 [==============================] - 0s 202us/step - loss: 0.9031 - accuracy: 0.8198 - val_loss: 0.9392 - val_accuracy: 0.9082\n",
      "Epoch 76/100\n",
      "455/455 [==============================] - 0s 201us/step - loss: 1.0768 - accuracy: 0.7670 - val_loss: 0.8284 - val_accuracy: 0.9082\n",
      "Epoch 77/100\n",
      "455/455 [==============================] - 0s 240us/step - loss: 0.9629 - accuracy: 0.8110 - val_loss: 0.7174 - val_accuracy: 0.9286\n",
      "Epoch 78/100\n",
      "455/455 [==============================] - 0s 195us/step - loss: 0.8458 - accuracy: 0.8505 - val_loss: 0.8976 - val_accuracy: 0.9082\n",
      "Epoch 79/100\n",
      "455/455 [==============================] - 0s 210us/step - loss: 0.9377 - accuracy: 0.7626 - val_loss: 1.0149 - val_accuracy: 0.8980\n",
      "Epoch 80/100\n",
      "455/455 [==============================] - 0s 218us/step - loss: 0.9765 - accuracy: 0.7912 - val_loss: 0.7676 - val_accuracy: 0.9235\n",
      "Epoch 81/100\n",
      "455/455 [==============================] - 0s 204us/step - loss: 0.9688 - accuracy: 0.7956 - val_loss: 0.8675 - val_accuracy: 0.9184\n",
      "Epoch 82/100\n",
      "455/455 [==============================] - 0s 180us/step - loss: 0.9137 - accuracy: 0.7890 - val_loss: 0.8659 - val_accuracy: 0.9184\n",
      "Epoch 83/100\n",
      "455/455 [==============================] - 0s 135us/step - loss: 1.0204 - accuracy: 0.7934 - val_loss: 0.7581 - val_accuracy: 0.9235\n",
      "Epoch 84/100\n",
      "455/455 [==============================] - 0s 156us/step - loss: 0.8717 - accuracy: 0.8088 - val_loss: 0.8233 - val_accuracy: 0.9235\n",
      "Epoch 85/100\n",
      "455/455 [==============================] - 0s 342us/step - loss: 0.9212 - accuracy: 0.8044 - val_loss: 0.8506 - val_accuracy: 0.9235\n",
      "Epoch 86/100\n",
      "455/455 [==============================] - 0s 328us/step - loss: 0.9742 - accuracy: 0.7560 - val_loss: 0.6869 - val_accuracy: 0.9286\n",
      "Epoch 87/100\n",
      "455/455 [==============================] - 0s 240us/step - loss: 0.8786 - accuracy: 0.7956 - val_loss: 0.7710 - val_accuracy: 0.9184\n",
      "Epoch 88/100\n",
      "455/455 [==============================] - 0s 183us/step - loss: 1.0360 - accuracy: 0.7802 - val_loss: 0.7104 - val_accuracy: 0.9286\n",
      "Epoch 89/100\n",
      "455/455 [==============================] - 0s 209us/step - loss: 0.7975 - accuracy: 0.7868 - val_loss: 0.6779 - val_accuracy: 0.9388\n",
      "Epoch 90/100\n",
      "455/455 [==============================] - 0s 204us/step - loss: 0.7238 - accuracy: 0.8132 - val_loss: 0.8028 - val_accuracy: 0.9235\n",
      "Epoch 91/100\n",
      "455/455 [==============================] - 0s 168us/step - loss: 0.8073 - accuracy: 0.8220 - val_loss: 0.7684 - val_accuracy: 0.9235\n",
      "Epoch 92/100\n",
      "455/455 [==============================] - 0s 124us/step - loss: 0.8958 - accuracy: 0.7956 - val_loss: 0.6984 - val_accuracy: 0.9235\n",
      "Epoch 93/100\n",
      "455/455 [==============================] - 0s 174us/step - loss: 0.7290 - accuracy: 0.8286 - val_loss: 0.7120 - val_accuracy: 0.9286\n",
      "Epoch 94/100\n",
      "455/455 [==============================] - 0s 144us/step - loss: 0.7797 - accuracy: 0.7890 - val_loss: 0.7219 - val_accuracy: 0.9286\n",
      "Epoch 95/100\n",
      "455/455 [==============================] - 0s 151us/step - loss: 0.7358 - accuracy: 0.8176 - val_loss: 0.7269 - val_accuracy: 0.9337\n",
      "Epoch 96/100\n",
      "455/455 [==============================] - 0s 152us/step - loss: 0.8816 - accuracy: 0.7978 - val_loss: 0.9126 - val_accuracy: 0.9133\n",
      "Epoch 97/100\n",
      "455/455 [==============================] - 0s 150us/step - loss: 0.8721 - accuracy: 0.7868 - val_loss: 0.5593 - val_accuracy: 0.9592\n",
      "Epoch 98/100\n",
      "455/455 [==============================] - 0s 161us/step - loss: 0.8693 - accuracy: 0.8066 - val_loss: 0.8190 - val_accuracy: 0.9388\n",
      "Epoch 99/100\n",
      "455/455 [==============================] - 0s 149us/step - loss: 0.7750 - accuracy: 0.8022 - val_loss: 0.8824 - val_accuracy: 0.9082\n",
      "Epoch 100/100\n",
      "455/455 [==============================] - 0s 158us/step - loss: 0.7016 - accuracy: 0.8264 - val_loss: 0.7301 - val_accuracy: 0.9286\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a39a8c6a0>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over7.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196/196 [==============================] - 0s 92us/step\n",
      "over-sampling test accuracy: 92.35%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over7 = model1_over7.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over7*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 1, 1, 0, 2, 0, 1, 2, 1, 0, 0, 0, 1, 1, 0, 2, 1, 0, 1, 1, 0,\n",
       "       1, 0, 2, 1, 2, 2, 1, 1, 1, 0, 1, 2, 0, 2, 2, 0, 1, 1, 2, 1, 1, 2,\n",
       "       2, 0, 1, 2, 2, 1, 1, 2, 0, 1, 2, 2, 1, 1, 2, 0, 0, 1, 2, 2, 2, 1,\n",
       "       1, 1, 2, 0, 0, 0, 0, 0, 2, 1, 0, 1, 2, 0, 2, 1, 1, 1, 1, 0, 2, 2,\n",
       "       2, 2, 2, 1, 1, 2, 2, 1, 0, 2, 1, 0, 2, 0, 2, 1, 1, 1, 0, 1, 0, 0,\n",
       "       2, 2, 1, 2, 0, 0, 2, 2, 2, 0, 1, 1, 2, 2, 0, 1, 1, 0, 2, 0, 1, 2,\n",
       "       1, 2, 1, 0, 1, 0, 2, 0, 0, 2, 1, 0, 2, 1, 1, 1, 1, 0, 2, 2, 0, 0,\n",
       "       0, 2, 2, 1, 1, 2, 1, 2, 1, 1, 2, 2, 1, 1, 1, 2, 1, 2, 2, 2, 1, 2,\n",
       "       2, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 2, 0, 1, 0, 1, 2])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred7 = model1_over7.predict_classes(X_test_over)\n",
    "pred7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS253</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS105</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS265</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS211</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>NRS035</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>NRS260</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>CA9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>NRS183</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>196 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0  test  pred\n",
       "0    NRS253     1     1\n",
       "1    NRS148     2     2\n",
       "2    NRS105     1     1\n",
       "3    NRS265     1     1\n",
       "4    NRS211     0     0\n",
       "..      ...   ...   ...\n",
       "191  NRS035     0     0\n",
       "192  NRS260     1     1\n",
       "193     CA9     0     0\n",
       "194  NRS183     1     1\n",
       "195  NRS148     2     2\n",
       "\n",
       "[196 rows x 3 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat7['pred'] = pred7\n",
    "dat7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba7 = model1_over7.predict_proba(X_test_over)\n",
    "dat_proba7 = pd.DataFrame(proba7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.812649e-10</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>5.528847e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.386493e-08</td>\n",
       "      <td>2.366233e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.804154e-06</td>\n",
       "      <td>9.999962e-01</td>\n",
       "      <td>1.350957e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.566996e-08</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>8.425955e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.995899e-01</td>\n",
       "      <td>4.056348e-04</td>\n",
       "      <td>4.490389e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>9.354528e-01</td>\n",
       "      <td>6.414209e-02</td>\n",
       "      <td>4.051120e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>4.808470e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>7.364639e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.361323e-08</td>\n",
       "      <td>2.871247e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>2.755864e-07</td>\n",
       "      <td>9.999998e-01</td>\n",
       "      <td>5.310879e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>2.386493e-08</td>\n",
       "      <td>2.366233e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>196 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0             1             2\n",
       "0    8.812649e-10  1.000000e+00  5.528847e-09\n",
       "1    2.386493e-08  2.366233e-08  1.000000e+00\n",
       "2    3.804154e-06  9.999962e-01  1.350957e-08\n",
       "3    4.566996e-08  9.999999e-01  8.425955e-08\n",
       "4    9.995899e-01  4.056348e-04  4.490389e-06\n",
       "..            ...           ...           ...\n",
       "191  9.354528e-01  6.414209e-02  4.051120e-04\n",
       "192  4.808470e-08  1.000000e+00  7.364639e-09\n",
       "193  1.000000e+00  2.361323e-08  2.871247e-08\n",
       "194  2.755864e-07  9.999998e-01  5.310879e-08\n",
       "195  2.386493e-08  2.366233e-08  1.000000e+00\n",
       "\n",
       "[196 rows x 3 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba7.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba7.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat7.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/7pyopST.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 455 samples, validate on 196 samples\n",
      "Epoch 1/100\n",
      "455/455 [==============================] - 0s 161us/step - loss: 0.9064 - accuracy: 0.7934 - val_loss: 0.9681 - val_accuracy: 0.9133\n",
      "Epoch 2/100\n",
      "455/455 [==============================] - 0s 141us/step - loss: 0.9563 - accuracy: 0.8154 - val_loss: 0.9837 - val_accuracy: 0.9133\n",
      "Epoch 3/100\n",
      "455/455 [==============================] - 0s 132us/step - loss: 1.0675 - accuracy: 0.7868 - val_loss: 1.0689 - val_accuracy: 0.9184\n",
      "Epoch 4/100\n",
      "455/455 [==============================] - 0s 130us/step - loss: 0.9615 - accuracy: 0.8044 - val_loss: 0.9408 - val_accuracy: 0.9133\n",
      "Epoch 5/100\n",
      "455/455 [==============================] - 0s 138us/step - loss: 0.9252 - accuracy: 0.8352 - val_loss: 0.7681 - val_accuracy: 0.9439\n",
      "Epoch 6/100\n",
      "455/455 [==============================] - 0s 145us/step - loss: 1.0736 - accuracy: 0.7912 - val_loss: 0.9733 - val_accuracy: 0.9388\n",
      "Epoch 7/100\n",
      "455/455 [==============================] - 0s 143us/step - loss: 1.0410 - accuracy: 0.7912 - val_loss: 0.9118 - val_accuracy: 0.9286\n",
      "Epoch 8/100\n",
      "455/455 [==============================] - 0s 179us/step - loss: 0.9497 - accuracy: 0.8242 - val_loss: 0.8632 - val_accuracy: 0.9286\n",
      "Epoch 9/100\n",
      "455/455 [==============================] - 0s 190us/step - loss: 0.9946 - accuracy: 0.8000 - val_loss: 0.9145 - val_accuracy: 0.9337\n",
      "Epoch 10/100\n",
      "455/455 [==============================] - 0s 126us/step - loss: 0.8780 - accuracy: 0.8242 - val_loss: 0.8850 - val_accuracy: 0.9286\n",
      "Epoch 11/100\n",
      "455/455 [==============================] - 0s 110us/step - loss: 0.9579 - accuracy: 0.8198 - val_loss: 0.7361 - val_accuracy: 0.9337\n",
      "Epoch 12/100\n",
      "455/455 [==============================] - 0s 111us/step - loss: 0.8402 - accuracy: 0.8176 - val_loss: 0.8293 - val_accuracy: 0.9337\n",
      "Epoch 13/100\n",
      "455/455 [==============================] - 0s 106us/step - loss: 0.9142 - accuracy: 0.8044 - val_loss: 0.8168 - val_accuracy: 0.9286\n",
      "Epoch 14/100\n",
      "455/455 [==============================] - 0s 113us/step - loss: 0.8738 - accuracy: 0.7890 - val_loss: 0.8795 - val_accuracy: 0.9133\n",
      "Epoch 15/100\n",
      "455/455 [==============================] - 0s 106us/step - loss: 1.1294 - accuracy: 0.7846 - val_loss: 0.7902 - val_accuracy: 0.9133\n",
      "Epoch 16/100\n",
      "455/455 [==============================] - 0s 224us/step - loss: 1.0200 - accuracy: 0.8088 - val_loss: 0.9561 - val_accuracy: 0.9286\n",
      "Epoch 17/100\n",
      "455/455 [==============================] - 0s 540us/step - loss: 0.7735 - accuracy: 0.8374 - val_loss: 0.8053 - val_accuracy: 0.9337\n",
      "Epoch 18/100\n",
      "455/455 [==============================] - 0s 260us/step - loss: 0.9033 - accuracy: 0.7934 - val_loss: 0.7067 - val_accuracy: 0.9286\n",
      "Epoch 19/100\n",
      "455/455 [==============================] - 0s 188us/step - loss: 0.9065 - accuracy: 0.7978 - val_loss: 0.7339 - val_accuracy: 0.9388\n",
      "Epoch 20/100\n",
      "455/455 [==============================] - 0s 257us/step - loss: 0.9125 - accuracy: 0.8000 - val_loss: 0.9682 - val_accuracy: 0.9133\n",
      "Epoch 21/100\n",
      "455/455 [==============================] - 0s 245us/step - loss: 0.9355 - accuracy: 0.7868 - val_loss: 0.8289 - val_accuracy: 0.9388\n",
      "Epoch 22/100\n",
      "455/455 [==============================] - 0s 405us/step - loss: 0.9480 - accuracy: 0.7846 - val_loss: 0.7817 - val_accuracy: 0.9439\n",
      "Epoch 23/100\n",
      "455/455 [==============================] - 0s 353us/step - loss: 1.0297 - accuracy: 0.7890 - val_loss: 0.7981 - val_accuracy: 0.9439\n",
      "Epoch 24/100\n",
      "455/455 [==============================] - 0s 199us/step - loss: 0.8478 - accuracy: 0.8154 - val_loss: 0.8126 - val_accuracy: 0.9490\n",
      "Epoch 25/100\n",
      "455/455 [==============================] - 0s 304us/step - loss: 0.8378 - accuracy: 0.7868 - val_loss: 0.7510 - val_accuracy: 0.9490\n",
      "Epoch 26/100\n",
      "455/455 [==============================] - 0s 254us/step - loss: 0.8787 - accuracy: 0.7868 - val_loss: 0.7745 - val_accuracy: 0.9490\n",
      "Epoch 27/100\n",
      "455/455 [==============================] - 0s 211us/step - loss: 0.8084 - accuracy: 0.8374 - val_loss: 0.7401 - val_accuracy: 0.9388\n",
      "Epoch 28/100\n",
      "455/455 [==============================] - 0s 247us/step - loss: 0.8056 - accuracy: 0.8154 - val_loss: 0.6911 - val_accuracy: 0.9337\n",
      "Epoch 29/100\n",
      "455/455 [==============================] - 0s 161us/step - loss: 0.8595 - accuracy: 0.8132 - val_loss: 0.8008 - val_accuracy: 0.9490\n",
      "Epoch 30/100\n",
      "455/455 [==============================] - 0s 172us/step - loss: 0.8100 - accuracy: 0.7824 - val_loss: 0.9149 - val_accuracy: 0.9388\n",
      "Epoch 31/100\n",
      "455/455 [==============================] - 0s 149us/step - loss: 0.8246 - accuracy: 0.7912 - val_loss: 0.8679 - val_accuracy: 0.9388\n",
      "Epoch 32/100\n",
      "455/455 [==============================] - 0s 158us/step - loss: 0.7591 - accuracy: 0.8264 - val_loss: 0.7786 - val_accuracy: 0.9439\n",
      "Epoch 33/100\n",
      "455/455 [==============================] - 0s 336us/step - loss: 0.8831 - accuracy: 0.7736 - val_loss: 0.6668 - val_accuracy: 0.9592\n",
      "Epoch 34/100\n",
      "455/455 [==============================] - 0s 169us/step - loss: 0.8039 - accuracy: 0.8022 - val_loss: 0.7680 - val_accuracy: 0.9541\n",
      "Epoch 35/100\n",
      "455/455 [==============================] - 0s 581us/step - loss: 0.8922 - accuracy: 0.7956 - val_loss: 0.8459 - val_accuracy: 0.9184\n",
      "Epoch 36/100\n",
      "455/455 [==============================] - 0s 386us/step - loss: 0.7868 - accuracy: 0.7846 - val_loss: 0.8461 - val_accuracy: 0.9235\n",
      "Epoch 37/100\n",
      "455/455 [==============================] - 0s 315us/step - loss: 0.8143 - accuracy: 0.7802 - val_loss: 0.8845 - val_accuracy: 0.9337\n",
      "Epoch 38/100\n",
      "455/455 [==============================] - 0s 245us/step - loss: 0.8344 - accuracy: 0.8088 - val_loss: 0.8063 - val_accuracy: 0.9490\n",
      "Epoch 39/100\n",
      "455/455 [==============================] - 0s 197us/step - loss: 0.8000 - accuracy: 0.7802 - val_loss: 0.7928 - val_accuracy: 0.9490\n",
      "Epoch 40/100\n",
      "455/455 [==============================] - 0s 173us/step - loss: 0.7743 - accuracy: 0.8000 - val_loss: 0.7596 - val_accuracy: 0.9490\n",
      "Epoch 41/100\n",
      "455/455 [==============================] - 0s 137us/step - loss: 0.7174 - accuracy: 0.8132 - val_loss: 0.7947 - val_accuracy: 0.9337\n",
      "Epoch 42/100\n",
      "455/455 [==============================] - 0s 217us/step - loss: 0.7949 - accuracy: 0.7846 - val_loss: 0.8942 - val_accuracy: 0.9337\n",
      "Epoch 43/100\n",
      "455/455 [==============================] - 0s 298us/step - loss: 0.7549 - accuracy: 0.8110 - val_loss: 0.8734 - val_accuracy: 0.9490\n",
      "Epoch 44/100\n",
      "455/455 [==============================] - 0s 230us/step - loss: 0.7937 - accuracy: 0.7978 - val_loss: 0.6972 - val_accuracy: 0.9490\n",
      "Epoch 45/100\n",
      "455/455 [==============================] - 0s 178us/step - loss: 0.7539 - accuracy: 0.7912 - val_loss: 0.8202 - val_accuracy: 0.9439\n",
      "Epoch 46/100\n",
      "455/455 [==============================] - 0s 179us/step - loss: 0.7083 - accuracy: 0.7912 - val_loss: 0.7930 - val_accuracy: 0.9439\n",
      "Epoch 47/100\n",
      "455/455 [==============================] - 0s 186us/step - loss: 0.7472 - accuracy: 0.8176 - val_loss: 0.7200 - val_accuracy: 0.9490\n",
      "Epoch 48/100\n",
      "455/455 [==============================] - 0s 169us/step - loss: 0.7978 - accuracy: 0.7934 - val_loss: 0.7386 - val_accuracy: 0.9490\n",
      "Epoch 49/100\n",
      "455/455 [==============================] - 0s 140us/step - loss: 0.7999 - accuracy: 0.7670 - val_loss: 0.6842 - val_accuracy: 0.9490\n",
      "Epoch 50/100\n",
      "455/455 [==============================] - 0s 250us/step - loss: 0.7792 - accuracy: 0.7956 - val_loss: 0.7214 - val_accuracy: 0.9490\n",
      "Epoch 51/100\n",
      "455/455 [==============================] - 0s 227us/step - loss: 0.7354 - accuracy: 0.8132 - val_loss: 0.6759 - val_accuracy: 0.9490\n",
      "Epoch 52/100\n",
      "455/455 [==============================] - 0s 155us/step - loss: 0.9094 - accuracy: 0.7824 - val_loss: 0.8134 - val_accuracy: 0.9439\n",
      "Epoch 53/100\n",
      "455/455 [==============================] - 0s 350us/step - loss: 0.7386 - accuracy: 0.7824 - val_loss: 0.6210 - val_accuracy: 0.9541\n",
      "Epoch 54/100\n",
      "455/455 [==============================] - 0s 357us/step - loss: 0.6423 - accuracy: 0.8110 - val_loss: 0.7838 - val_accuracy: 0.9490\n",
      "Epoch 55/100\n",
      "455/455 [==============================] - 0s 640us/step - loss: 0.6723 - accuracy: 0.8264 - val_loss: 0.6993 - val_accuracy: 0.9490\n",
      "Epoch 56/100\n",
      "455/455 [==============================] - 0s 180us/step - loss: 0.6774 - accuracy: 0.8044 - val_loss: 0.7820 - val_accuracy: 0.9286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "455/455 [==============================] - 0s 156us/step - loss: 0.7899 - accuracy: 0.7758 - val_loss: 0.7271 - val_accuracy: 0.9541\n",
      "Epoch 58/100\n",
      "455/455 [==============================] - 0s 155us/step - loss: 0.7595 - accuracy: 0.7736 - val_loss: 0.7561 - val_accuracy: 0.9490\n",
      "Epoch 59/100\n",
      "455/455 [==============================] - 0s 221us/step - loss: 0.7253 - accuracy: 0.8044 - val_loss: 0.6881 - val_accuracy: 0.9490\n",
      "Epoch 60/100\n",
      "455/455 [==============================] - 0s 328us/step - loss: 0.6304 - accuracy: 0.8242 - val_loss: 0.8055 - val_accuracy: 0.9439\n",
      "Epoch 61/100\n",
      "455/455 [==============================] - 0s 302us/step - loss: 0.7349 - accuracy: 0.7934 - val_loss: 0.6969 - val_accuracy: 0.9490\n",
      "Epoch 62/100\n",
      "455/455 [==============================] - 0s 159us/step - loss: 0.6984 - accuracy: 0.8286 - val_loss: 0.6729 - val_accuracy: 0.9388\n",
      "Epoch 63/100\n",
      "455/455 [==============================] - 0s 236us/step - loss: 0.6705 - accuracy: 0.8220 - val_loss: 0.7065 - val_accuracy: 0.9439\n",
      "Epoch 64/100\n",
      "455/455 [==============================] - 0s 302us/step - loss: 0.7677 - accuracy: 0.8110 - val_loss: 0.7862 - val_accuracy: 0.9286\n",
      "Epoch 65/100\n",
      "455/455 [==============================] - 0s 172us/step - loss: 0.7274 - accuracy: 0.7890 - val_loss: 0.6967 - val_accuracy: 0.9388\n",
      "Epoch 66/100\n",
      "455/455 [==============================] - 0s 184us/step - loss: 0.6515 - accuracy: 0.8418 - val_loss: 0.7999 - val_accuracy: 0.9388\n",
      "Epoch 67/100\n",
      "455/455 [==============================] - 0s 196us/step - loss: 0.6474 - accuracy: 0.8308 - val_loss: 0.6079 - val_accuracy: 0.9490\n",
      "Epoch 68/100\n",
      "455/455 [==============================] - 0s 201us/step - loss: 0.7043 - accuracy: 0.7780 - val_loss: 0.6740 - val_accuracy: 0.9490\n",
      "Epoch 69/100\n",
      "455/455 [==============================] - 0s 196us/step - loss: 0.6704 - accuracy: 0.8022 - val_loss: 0.6565 - val_accuracy: 0.9541\n",
      "Epoch 70/100\n",
      "455/455 [==============================] - 0s 170us/step - loss: 0.6511 - accuracy: 0.8066 - val_loss: 0.7060 - val_accuracy: 0.9439\n",
      "Epoch 71/100\n",
      "455/455 [==============================] - 0s 186us/step - loss: 0.5959 - accuracy: 0.8264 - val_loss: 0.6526 - val_accuracy: 0.9541\n",
      "Epoch 72/100\n",
      "455/455 [==============================] - 0s 245us/step - loss: 0.7099 - accuracy: 0.7648 - val_loss: 0.6408 - val_accuracy: 0.9541\n",
      "Epoch 73/100\n",
      "455/455 [==============================] - 0s 207us/step - loss: 0.6171 - accuracy: 0.8132 - val_loss: 0.6659 - val_accuracy: 0.9541\n",
      "Epoch 74/100\n",
      "455/455 [==============================] - 0s 152us/step - loss: 0.6304 - accuracy: 0.8286 - val_loss: 0.5799 - val_accuracy: 0.9694\n",
      "Epoch 75/100\n",
      "455/455 [==============================] - 0s 213us/step - loss: 0.6826 - accuracy: 0.7956 - val_loss: 0.7256 - val_accuracy: 0.9439\n",
      "Epoch 76/100\n",
      "455/455 [==============================] - 0s 218us/step - loss: 0.6189 - accuracy: 0.8132 - val_loss: 0.6381 - val_accuracy: 0.9439\n",
      "Epoch 77/100\n",
      "455/455 [==============================] - 0s 259us/step - loss: 0.6694 - accuracy: 0.7912 - val_loss: 0.6052 - val_accuracy: 0.9541\n",
      "Epoch 78/100\n",
      "455/455 [==============================] - 0s 192us/step - loss: 0.6187 - accuracy: 0.7956 - val_loss: 0.6439 - val_accuracy: 0.9490\n",
      "Epoch 79/100\n",
      "455/455 [==============================] - 0s 155us/step - loss: 0.6580 - accuracy: 0.7956 - val_loss: 0.7448 - val_accuracy: 0.9490\n",
      "Epoch 80/100\n",
      "455/455 [==============================] - 0s 175us/step - loss: 0.6102 - accuracy: 0.8088 - val_loss: 0.7011 - val_accuracy: 0.9490\n",
      "Epoch 81/100\n",
      "455/455 [==============================] - 0s 196us/step - loss: 0.5915 - accuracy: 0.8176 - val_loss: 0.5896 - val_accuracy: 0.9592\n",
      "Epoch 82/100\n",
      "455/455 [==============================] - 0s 150us/step - loss: 0.6156 - accuracy: 0.8132 - val_loss: 0.6940 - val_accuracy: 0.9439\n",
      "Epoch 83/100\n",
      "455/455 [==============================] - 0s 345us/step - loss: 0.6674 - accuracy: 0.8044 - val_loss: 0.6767 - val_accuracy: 0.9439\n",
      "Epoch 84/100\n",
      "455/455 [==============================] - 0s 206us/step - loss: 0.6404 - accuracy: 0.8088 - val_loss: 0.6096 - val_accuracy: 0.9490\n",
      "Epoch 85/100\n",
      "455/455 [==============================] - 0s 192us/step - loss: 0.6596 - accuracy: 0.7956 - val_loss: 0.6906 - val_accuracy: 0.9439\n",
      "Epoch 86/100\n",
      "455/455 [==============================] - 0s 212us/step - loss: 0.5936 - accuracy: 0.7978 - val_loss: 0.6660 - val_accuracy: 0.9439\n",
      "Epoch 87/100\n",
      "455/455 [==============================] - 0s 372us/step - loss: 0.5091 - accuracy: 0.8462 - val_loss: 0.6472 - val_accuracy: 0.9439\n",
      "Epoch 88/100\n",
      "455/455 [==============================] - 0s 219us/step - loss: 0.5416 - accuracy: 0.8571 - val_loss: 0.6947 - val_accuracy: 0.9388\n",
      "Epoch 89/100\n",
      "455/455 [==============================] - 0s 357us/step - loss: 0.6715 - accuracy: 0.8110 - val_loss: 0.5883 - val_accuracy: 0.9541\n",
      "Epoch 90/100\n",
      "455/455 [==============================] - 0s 206us/step - loss: 0.6405 - accuracy: 0.7758 - val_loss: 0.5777 - val_accuracy: 0.9643\n",
      "Epoch 91/100\n",
      "455/455 [==============================] - 0s 240us/step - loss: 0.5751 - accuracy: 0.8220 - val_loss: 0.5667 - val_accuracy: 0.9490\n",
      "Epoch 92/100\n",
      "455/455 [==============================] - 0s 349us/step - loss: 0.5666 - accuracy: 0.8242 - val_loss: 0.6307 - val_accuracy: 0.9490\n",
      "Epoch 93/100\n",
      "455/455 [==============================] - 0s 273us/step - loss: 0.5029 - accuracy: 0.8462 - val_loss: 0.6071 - val_accuracy: 0.9490\n",
      "Epoch 94/100\n",
      "455/455 [==============================] - 0s 196us/step - loss: 0.6138 - accuracy: 0.7846 - val_loss: 0.5811 - val_accuracy: 0.9490\n",
      "Epoch 95/100\n",
      "455/455 [==============================] - 0s 176us/step - loss: 0.6190 - accuracy: 0.8066 - val_loss: 0.5855 - val_accuracy: 0.9490\n",
      "Epoch 96/100\n",
      "455/455 [==============================] - 0s 173us/step - loss: 0.5692 - accuracy: 0.8066 - val_loss: 0.7117 - val_accuracy: 0.9490\n",
      "Epoch 97/100\n",
      "455/455 [==============================] - 0s 224us/step - loss: 0.6531 - accuracy: 0.8154 - val_loss: 0.6134 - val_accuracy: 0.9541\n",
      "Epoch 98/100\n",
      "455/455 [==============================] - 0s 260us/step - loss: 0.6307 - accuracy: 0.8022 - val_loss: 0.5757 - val_accuracy: 0.9592\n",
      "Epoch 99/100\n",
      "455/455 [==============================] - 0s 179us/step - loss: 0.6335 - accuracy: 0.7758 - val_loss: 0.7689 - val_accuracy: 0.9388\n",
      "Epoch 100/100\n",
      "455/455 [==============================] - 0s 240us/step - loss: 0.5976 - accuracy: 0.8154 - val_loss: 0.6239 - val_accuracy: 0.9541\n"
     ]
    }
   ],
   "source": [
    "hist1_over7 = model1_over7.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 80.38%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over7.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba7 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_regularizor_dropout_2.xlsx\",\n",
    "                        sheet_name=2,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8.300497e-12</td>\n",
       "      <td>1.036520e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>BCH-SA-09</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.137139e-06</td>\n",
       "      <td>9.999988e-01</td>\n",
       "      <td>2.067601e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS224</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.093110e-31</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8.300497e-12</td>\n",
       "      <td>1.036520e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS235</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.243513e-02</td>\n",
       "      <td>9.774035e-01</td>\n",
       "      <td>1.615106e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS035</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.354528e-01</td>\n",
       "      <td>6.414209e-02</td>\n",
       "      <td>4.051121e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS260</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.808470e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>7.364639e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>CA9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.361323e-08</td>\n",
       "      <td>2.871247e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS183</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.755864e-07</td>\n",
       "      <td>9.999998e-01</td>\n",
       "      <td>5.310879e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.386494e-08</td>\n",
       "      <td>2.366233e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1982 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       phage     strain  phenotype  prediction             0  \\\n",
       "0     p002ykpresabsSTCC_qual     NRS209          2           2  8.300497e-12   \n",
       "1     p002ykpresabsSTCC_qual  BCH-SA-09          1           1  1.137139e-06   \n",
       "2     p002ykpresabsSTCC_qual     NRS224          0           0  1.000000e+00   \n",
       "3     p002ykpresabsSTCC_qual     NRS209          2           2  8.300497e-12   \n",
       "4     p002ykpresabsSTCC_qual     NRS235          1           1  2.243513e-02   \n",
       "...                      ...        ...        ...         ...           ...   \n",
       "1977     pyopresabsSTCC_qual     NRS035          0           0  9.354528e-01   \n",
       "1978     pyopresabsSTCC_qual     NRS260          1           1  4.808470e-08   \n",
       "1979     pyopresabsSTCC_qual        CA9          0           0  1.000000e+00   \n",
       "1980     pyopresabsSTCC_qual     NRS183          1           1  2.755864e-07   \n",
       "1981     pyopresabsSTCC_qual     NRS148          2           2  2.386494e-08   \n",
       "\n",
       "                 1             2  \n",
       "0     1.036520e-09  1.000000e+00  \n",
       "1     9.999988e-01  2.067601e-09  \n",
       "2     2.093110e-31  0.000000e+00  \n",
       "3     1.036520e-09  1.000000e+00  \n",
       "4     9.774035e-01  1.615106e-04  \n",
       "...            ...           ...  \n",
       "1977  6.414209e-02  4.051121e-04  \n",
       "1978  1.000000e+00  7.364639e-09  \n",
       "1979  2.361323e-08  2.871247e-08  \n",
       "1980  9.999998e-01  5.310879e-08  \n",
       "1981  2.366233e-08  1.000000e+00  \n",
       "\n",
       "[1982 rows x 7 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.81264950e-10, 1.00000000e+00, 5.52884670e-09],\n",
       "       [2.38649350e-08, 2.36623300e-08, 1.00000000e+00],\n",
       "       [3.80415420e-06, 9.99996200e-01, 1.35095730e-08],\n",
       "       [4.56699600e-08, 9.99999900e-01, 8.42595500e-08],\n",
       "       [9.99589860e-01, 4.05634780e-04, 4.49038900e-06],\n",
       "       [6.32779160e-08, 6.94916300e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 2.82767450e-09, 5.89077230e-09],\n",
       "       [3.59974340e-08, 1.00000000e+00, 2.42576700e-09],\n",
       "       [1.04225000e-07, 8.56667840e-08, 9.99999760e-01],\n",
       "       [1.25662545e-02, 9.86555930e-01, 8.77843400e-04],\n",
       "       [9.59701000e-01, 4.02983200e-02, 6.71130860e-07],\n",
       "       [1.00000000e+00, 1.92279180e-11, 3.69313200e-11],\n",
       "       [9.45684130e-01, 5.42763100e-02, 3.95623060e-05],\n",
       "       [2.75586420e-07, 9.99999760e-01, 5.31087900e-08],\n",
       "       [2.00877430e-08, 1.00000000e+00, 1.43348300e-08],\n",
       "       [6.53481960e-01, 3.44687220e-01, 1.83084850e-03],\n",
       "       [2.38649350e-08, 2.36623300e-08, 1.00000000e+00],\n",
       "       [1.61404840e-05, 9.99978800e-01, 5.13485000e-06],\n",
       "       [9.99918700e-01, 4.66083300e-05, 3.46922400e-05],\n",
       "       [6.94506800e-08, 9.99999760e-01, 7.01005300e-08],\n",
       "       [2.75309460e-08, 1.00000000e+00, 4.87842940e-08],\n",
       "       [1.00000000e+00, 1.04738910e-12, 7.03535620e-12],\n",
       "       [3.80544480e-01, 6.19411600e-01, 4.39654320e-05],\n",
       "       [9.99991400e-01, 6.86342360e-06, 1.67731060e-06],\n",
       "       [6.32779160e-08, 6.94916300e-08, 9.99999900e-01],\n",
       "       [2.75586420e-07, 9.99999760e-01, 5.31087900e-08],\n",
       "       [2.38649350e-08, 2.36623300e-08, 1.00000000e+00],\n",
       "       [2.38649350e-08, 2.36623300e-08, 1.00000000e+00],\n",
       "       [1.53901130e-09, 1.00000000e+00, 6.17076250e-11],\n",
       "       [2.35808480e-03, 9.97641200e-01, 7.71611550e-07],\n",
       "       [2.75309460e-08, 1.00000000e+00, 4.87842940e-08],\n",
       "       [1.00000000e+00, 1.78307720e-11, 5.50421960e-11],\n",
       "       [1.01066010e-03, 9.98319900e-01, 6.69472040e-04],\n",
       "       [2.39430360e-08, 2.37409910e-08, 1.00000000e+00],\n",
       "       [9.99919400e-01, 5.81146230e-05, 2.23953360e-05],\n",
       "       [6.32779160e-08, 6.94916300e-08, 9.99999900e-01],\n",
       "       [6.32779160e-08, 6.94916300e-08, 9.99999900e-01],\n",
       "       [8.10204700e-01, 1.89778700e-01, 1.66151000e-05],\n",
       "       [4.21146560e-02, 9.57747500e-01, 1.37822530e-04],\n",
       "       [1.24276380e-03, 9.98701330e-01, 5.58554020e-05],\n",
       "       [1.04225000e-07, 8.56667840e-08, 9.99999760e-01],\n",
       "       [5.30425870e-08, 9.99999900e-01, 7.47219000e-08],\n",
       "       [4.20940120e-08, 9.99999900e-01, 6.12701400e-08],\n",
       "       [2.39430360e-08, 2.37409910e-08, 1.00000000e+00],\n",
       "       [1.04225000e-07, 8.56667840e-08, 9.99999760e-01],\n",
       "       [9.99999760e-01, 1.12046180e-07, 8.70888900e-08],\n",
       "       [4.05597870e-08, 1.00000000e+00, 3.92577950e-08],\n",
       "       [2.39430360e-08, 2.37409910e-08, 1.00000000e+00],\n",
       "       [2.39430360e-08, 2.37409910e-08, 1.00000000e+00],\n",
       "       [4.80847040e-08, 1.00000000e+00, 7.36463870e-09],\n",
       "       [2.05088800e-08, 1.00000000e+00, 2.79270780e-08],\n",
       "       [6.32779160e-08, 6.94916300e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 2.01397800e-14, 2.32626530e-13],\n",
       "       [4.05597870e-08, 1.00000000e+00, 3.92577950e-08],\n",
       "       [2.38649350e-08, 2.36623300e-08, 1.00000000e+00],\n",
       "       [6.32779160e-08, 6.94916300e-08, 9.99999900e-01],\n",
       "       [3.62164400e-07, 9.99999640e-01, 3.62310680e-08],\n",
       "       [1.25363840e-03, 9.98715040e-01, 3.13394340e-05],\n",
       "       [2.38649350e-08, 2.36623300e-08, 1.00000000e+00],\n",
       "       [9.83360900e-01, 1.52191130e-02, 1.42004990e-03],\n",
       "       [1.00000000e+00, 3.73305740e-09, 6.15692000e-09],\n",
       "       [2.11766590e-02, 9.78265600e-01, 5.57735200e-04],\n",
       "       [2.39430360e-08, 2.37409910e-08, 1.00000000e+00],\n",
       "       [6.32779160e-08, 6.94916300e-08, 9.99999900e-01],\n",
       "       [2.38649350e-08, 2.36623300e-08, 1.00000000e+00],\n",
       "       [1.25363840e-03, 9.98715040e-01, 3.13394340e-05],\n",
       "       [4.20940120e-08, 9.99999900e-01, 6.12701400e-08],\n",
       "       [1.25363840e-03, 9.98715040e-01, 3.13394340e-05],\n",
       "       [1.04225000e-07, 8.56667840e-08, 9.99999760e-01],\n",
       "       [1.00000000e+00, 2.76254940e-10, 2.29229660e-10],\n",
       "       [1.00000000e+00, 2.54742040e-08, 2.03702890e-08],\n",
       "       [1.00000000e+00, 1.66632040e-27, 1.91207150e-27],\n",
       "       [1.00000000e+00, 3.87706840e-12, 1.02900590e-11],\n",
       "       [1.00000000e+00, 1.73115970e-12, 3.91703550e-12],\n",
       "       [2.39430360e-08, 2.37409910e-08, 1.00000000e+00],\n",
       "       [3.59974340e-08, 1.00000000e+00, 2.42576700e-09],\n",
       "       [9.99943600e-01, 5.30194560e-05, 3.32925000e-06],\n",
       "       [6.94506800e-08, 9.99999760e-01, 7.01005300e-08],\n",
       "       [2.38649350e-08, 2.36623300e-08, 1.00000000e+00],\n",
       "       [1.00000000e+00, 1.41865840e-09, 1.16152490e-09],\n",
       "       [2.38649350e-08, 2.36623300e-08, 1.00000000e+00],\n",
       "       [1.76666470e-08, 1.00000000e+00, 1.08436740e-09],\n",
       "       [3.59974340e-08, 1.00000000e+00, 2.42576700e-09],\n",
       "       [2.41178530e-07, 9.99999760e-01, 6.03000670e-09],\n",
       "       [1.24994640e-03, 9.98685400e-01, 6.46457200e-05],\n",
       "       [9.99998900e-01, 5.50924600e-07, 4.24346580e-07],\n",
       "       [2.39430360e-08, 2.37409910e-08, 1.00000000e+00],\n",
       "       [2.38649350e-08, 2.36623300e-08, 1.00000000e+00],\n",
       "       [6.32779160e-08, 6.94916300e-08, 9.99999900e-01],\n",
       "       [2.39430360e-08, 2.37409910e-08, 1.00000000e+00],\n",
       "       [2.39430360e-08, 2.37409910e-08, 1.00000000e+00],\n",
       "       [1.76666470e-08, 1.00000000e+00, 1.08436740e-09],\n",
       "       [4.05597870e-08, 1.00000000e+00, 3.92577950e-08],\n",
       "       [2.38649350e-08, 2.36623300e-08, 1.00000000e+00],\n",
       "       [2.38649350e-08, 2.36623300e-08, 1.00000000e+00],\n",
       "       [2.35808480e-03, 9.97641200e-01, 7.71611550e-07],\n",
       "       [9.99999760e-01, 7.62302400e-08, 7.74082500e-08],\n",
       "       [1.04225000e-07, 8.56667840e-08, 9.99999760e-01],\n",
       "       [2.05088800e-08, 1.00000000e+00, 2.79270780e-08],\n",
       "       [9.99955800e-01, 4.41546040e-05, 6.45135100e-08],\n",
       "       [2.38649350e-08, 2.36623300e-08, 1.00000000e+00],\n",
       "       [9.99992250e-01, 6.97611500e-06, 6.63346440e-07],\n",
       "       [1.04225000e-07, 8.56667840e-08, 9.99999760e-01],\n",
       "       [7.66855450e-08, 9.99999900e-01, 5.45351360e-08],\n",
       "       [1.36704620e-08, 1.00000000e+00, 1.64597470e-08],\n",
       "       [3.58103250e-01, 6.41857500e-01, 3.91684370e-05],\n",
       "       [9.99992500e-01, 6.88082450e-06, 5.99670160e-07],\n",
       "       [6.86508500e-08, 9.99999760e-01, 9.10522500e-08],\n",
       "       [9.99990100e-01, 8.28467200e-06, 1.66862430e-06],\n",
       "       [1.00000000e+00, 4.03788340e-09, 3.35058270e-09],\n",
       "       [2.38649350e-08, 2.36623300e-08, 1.00000000e+00],\n",
       "       [2.38649350e-08, 2.36623300e-08, 1.00000000e+00],\n",
       "       [4.41161670e-08, 1.00000000e+00, 9.55080500e-09],\n",
       "       [2.39430360e-08, 2.37409910e-08, 1.00000000e+00],\n",
       "       [1.00000000e+00, 1.21779300e-12, 2.55525960e-12],\n",
       "       [1.00000000e+00, 1.03206040e-11, 1.07523010e-11],\n",
       "       [2.39430360e-08, 2.37409910e-08, 1.00000000e+00],\n",
       "       [6.32779160e-08, 6.94916300e-08, 9.99999900e-01],\n",
       "       [2.39430360e-08, 2.37409910e-08, 1.00000000e+00],\n",
       "       [1.00000000e+00, 1.46779800e-13, 3.18138070e-13],\n",
       "       [2.35808480e-03, 9.97641200e-01, 7.71611550e-07],\n",
       "       [3.80415420e-06, 9.99996200e-01, 1.35095730e-08],\n",
       "       [6.32779160e-08, 6.94916300e-08, 9.99999900e-01],\n",
       "       [2.39430360e-08, 2.37409910e-08, 1.00000000e+00],\n",
       "       [9.99999400e-01, 1.98433780e-07, 3.08789820e-07],\n",
       "       [7.92120200e-02, 9.16439700e-01, 4.34834560e-03],\n",
       "       [8.12990900e-05, 9.99909300e-01, 9.40259400e-06],\n",
       "       [1.00000000e+00, 9.19828900e-14, 2.08408570e-13],\n",
       "       [2.38649350e-08, 2.36623300e-08, 1.00000000e+00],\n",
       "       [1.00000000e+00, 3.24886370e-10, 5.21612640e-10],\n",
       "       [4.56699600e-08, 9.99999900e-01, 8.42595500e-08],\n",
       "       [1.04225000e-07, 8.56667840e-08, 9.99999760e-01],\n",
       "       [2.41178530e-07, 9.99999760e-01, 6.03000670e-09],\n",
       "       [1.04225000e-07, 8.56667840e-08, 9.99999760e-01],\n",
       "       [2.66527780e-08, 1.00000000e+00, 4.72198900e-09],\n",
       "       [9.99999300e-01, 5.75884940e-07, 1.04213230e-07],\n",
       "       [3.80415420e-06, 9.99996200e-01, 1.35095730e-08],\n",
       "       [7.59936800e-01, 2.40033060e-01, 3.01761760e-05],\n",
       "       [1.04225000e-07, 8.56667840e-08, 9.99999760e-01],\n",
       "       [1.00000000e+00, 2.05216670e-09, 3.08894530e-09],\n",
       "       [9.99999900e-01, 6.93761400e-08, 7.78190200e-09],\n",
       "       [6.32779160e-08, 6.94916300e-08, 9.99999900e-01],\n",
       "       [2.00877430e-08, 1.00000000e+00, 1.43348300e-08],\n",
       "       [1.00000000e+00, 5.07408140e-15, 5.54884170e-14],\n",
       "       [2.38649350e-08, 2.36623300e-08, 1.00000000e+00],\n",
       "       [2.66527780e-08, 1.00000000e+00, 4.72198900e-09],\n",
       "       [3.80415420e-06, 9.99996200e-01, 1.35095730e-08],\n",
       "       [2.00877430e-08, 1.00000000e+00, 1.43348300e-08],\n",
       "       [1.76666470e-08, 1.00000000e+00, 1.08436740e-09],\n",
       "       [9.99876500e-01, 1.15971980e-04, 7.52502770e-06],\n",
       "       [6.32779160e-08, 6.94916300e-08, 9.99999900e-01],\n",
       "       [1.04225000e-07, 8.56667840e-08, 9.99999760e-01],\n",
       "       [9.68308750e-01, 3.14426050e-02, 2.48595100e-04],\n",
       "       [9.99989750e-01, 8.83820500e-06, 1.38903530e-06],\n",
       "       [9.99999900e-01, 6.66080200e-08, 1.30993390e-09],\n",
       "       [1.04225000e-07, 8.56667840e-08, 9.99999760e-01],\n",
       "       [2.39430360e-08, 2.37409910e-08, 1.00000000e+00],\n",
       "       [1.01066010e-03, 9.98319900e-01, 6.69472040e-04],\n",
       "       [2.37188050e-03, 9.97548760e-01, 7.92749560e-05],\n",
       "       [6.32779160e-08, 6.94916300e-08, 9.99999900e-01],\n",
       "       [2.05088800e-08, 1.00000000e+00, 2.79270780e-08],\n",
       "       [6.32779160e-08, 6.94916300e-08, 9.99999900e-01],\n",
       "       [8.12990900e-05, 9.99909300e-01, 9.40259400e-06],\n",
       "       [7.66855450e-08, 9.99999900e-01, 5.45351360e-08],\n",
       "       [2.38649350e-08, 2.36623300e-08, 1.00000000e+00],\n",
       "       [2.38649350e-08, 2.36623300e-08, 1.00000000e+00],\n",
       "       [7.66855450e-08, 9.99999900e-01, 5.45351360e-08],\n",
       "       [3.56003400e-03, 9.96261060e-01, 1.78847740e-04],\n",
       "       [1.53901130e-09, 1.00000000e+00, 6.17076250e-11],\n",
       "       [2.38649350e-08, 2.36623300e-08, 1.00000000e+00],\n",
       "       [6.86508500e-08, 9.99999760e-01, 9.10522500e-08],\n",
       "       [2.38649350e-08, 2.36623300e-08, 1.00000000e+00],\n",
       "       [1.04225000e-07, 8.56667840e-08, 9.99999760e-01],\n",
       "       [2.39430360e-08, 2.37409910e-08, 1.00000000e+00],\n",
       "       [1.13324250e-07, 9.99999760e-01, 1.50506820e-07],\n",
       "       [6.32779160e-08, 6.94916300e-08, 9.99999900e-01],\n",
       "       [1.04225000e-07, 8.56667840e-08, 9.99999760e-01],\n",
       "       [4.56699600e-08, 9.99999900e-01, 8.42595500e-08],\n",
       "       [9.99992970e-01, 4.00122640e-06, 2.99072140e-06],\n",
       "       [1.00000000e+00, 2.39522030e-13, 1.41135290e-12],\n",
       "       [3.59974340e-08, 1.00000000e+00, 2.42576700e-09],\n",
       "       [4.10567080e-02, 9.58265900e-01, 6.77425900e-04],\n",
       "       [1.00000000e+00, 7.40059850e-10, 2.74825580e-09],\n",
       "       [5.30425870e-08, 9.99999900e-01, 7.47219000e-08],\n",
       "       [1.13324250e-07, 9.99999760e-01, 1.50506820e-07],\n",
       "       [1.71058370e-07, 9.99999760e-01, 1.35359630e-07],\n",
       "       [1.53901130e-09, 1.00000000e+00, 6.17076250e-11],\n",
       "       [1.37872700e-01, 8.53335440e-01, 8.79198200e-03],\n",
       "       [2.10430890e-01, 7.89519370e-01, 4.96664470e-05],\n",
       "       [7.96977760e-01, 1.98767570e-01, 4.25459700e-03],\n",
       "       [2.39430360e-08, 2.37409910e-08, 1.00000000e+00],\n",
       "       [9.35452760e-01, 6.41420900e-02, 4.05112050e-04],\n",
       "       [4.80847040e-08, 1.00000000e+00, 7.36463870e-09],\n",
       "       [1.00000000e+00, 2.36132320e-08, 2.87124690e-08],\n",
       "       [2.75586420e-07, 9.99999760e-01, 5.31087900e-08],\n",
       "       [2.38649350e-08, 2.36623300e-08, 1.00000000e+00]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob7 = df_proba7[df_proba7['phage']=='pyopresabsSTCC_qual'].iloc[:,-3:]\n",
    "y_prob7 = y_prob7.to_numpy()\n",
    "y_prob7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9916422000391466"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo7 = rocauc_ovo(y_test_over, y_prob7, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9916422000391466"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr7 = rocauc_ovr(y_test_over, y_prob7, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=890,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat8 = pd.DataFrame(X_test_over[:,0])\n",
    "dat8['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS205</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CFBREBSa131</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS177</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>NRS205</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>CFBREBSa122</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>NRS001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>NRS265</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>196 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test\n",
       "0         NRS205     2\n",
       "1         NRS109     2\n",
       "2    CFBREBSa131     0\n",
       "3         NRS148     2\n",
       "4         NRS177     1\n",
       "..           ...   ...\n",
       "191       NRS205     2\n",
       "192  CFBREBSa122     0\n",
       "193       NRS001     1\n",
       "194       NRS148     2\n",
       "195       NRS265     1\n",
       "\n",
       "[196 rows x 2 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over8 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],), activity_regularizer=l1(0.001)),\n",
    "    Dense(3, activation='softmax'),\n",
    "    Dropout(0.2, ),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over8.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 455 samples, validate on 196 samples\n",
      "Epoch 1/100\n",
      "455/455 [==============================] - 0s 575us/step - loss: 8.2351 - accuracy: 0.4857 - val_loss: 5.2661 - val_accuracy: 0.6276\n",
      "Epoch 2/100\n",
      "455/455 [==============================] - 0s 202us/step - loss: 6.5525 - accuracy: 0.5978 - val_loss: 4.2852 - val_accuracy: 0.7041\n",
      "Epoch 3/100\n",
      "455/455 [==============================] - 0s 173us/step - loss: 5.9755 - accuracy: 0.6484 - val_loss: 3.2508 - val_accuracy: 0.7347\n",
      "Epoch 4/100\n",
      "455/455 [==============================] - 0s 143us/step - loss: 4.9492 - accuracy: 0.6505 - val_loss: 2.6467 - val_accuracy: 0.7857\n",
      "Epoch 5/100\n",
      "455/455 [==============================] - 0s 124us/step - loss: 4.4478 - accuracy: 0.7033 - val_loss: 2.1783 - val_accuracy: 0.8061\n",
      "Epoch 6/100\n",
      "455/455 [==============================] - 0s 144us/step - loss: 3.8689 - accuracy: 0.7363 - val_loss: 1.8009 - val_accuracy: 0.8061\n",
      "Epoch 7/100\n",
      "455/455 [==============================] - 0s 122us/step - loss: 4.0106 - accuracy: 0.7143 - val_loss: 1.5731 - val_accuracy: 0.7755\n",
      "Epoch 8/100\n",
      "455/455 [==============================] - 0s 146us/step - loss: 3.4021 - accuracy: 0.7165 - val_loss: 1.3464 - val_accuracy: 0.8112\n",
      "Epoch 9/100\n",
      "455/455 [==============================] - 0s 215us/step - loss: 3.3610 - accuracy: 0.7011 - val_loss: 1.2055 - val_accuracy: 0.8367\n",
      "Epoch 10/100\n",
      "455/455 [==============================] - 0s 117us/step - loss: 2.9366 - accuracy: 0.7451 - val_loss: 1.1112 - val_accuracy: 0.8418\n",
      "Epoch 11/100\n",
      "455/455 [==============================] - 0s 126us/step - loss: 2.6058 - accuracy: 0.7582 - val_loss: 0.9938 - val_accuracy: 0.8214\n",
      "Epoch 12/100\n",
      "455/455 [==============================] - 0s 198us/step - loss: 2.4737 - accuracy: 0.7626 - val_loss: 0.9408 - val_accuracy: 0.8367\n",
      "Epoch 13/100\n",
      "455/455 [==============================] - 0s 224us/step - loss: 2.6565 - accuracy: 0.7429 - val_loss: 0.9119 - val_accuracy: 0.8316\n",
      "Epoch 14/100\n",
      "455/455 [==============================] - 0s 207us/step - loss: 2.3804 - accuracy: 0.7407 - val_loss: 0.9769 - val_accuracy: 0.8418\n",
      "Epoch 15/100\n",
      "455/455 [==============================] - 0s 219us/step - loss: 2.6406 - accuracy: 0.7538 - val_loss: 0.9461 - val_accuracy: 0.8367\n",
      "Epoch 16/100\n",
      "455/455 [==============================] - 0s 185us/step - loss: 2.3196 - accuracy: 0.7560 - val_loss: 0.8877 - val_accuracy: 0.8622\n",
      "Epoch 17/100\n",
      "455/455 [==============================] - 0s 130us/step - loss: 2.6376 - accuracy: 0.7341 - val_loss: 0.9095 - val_accuracy: 0.8827\n",
      "Epoch 18/100\n",
      "455/455 [==============================] - 0s 100us/step - loss: 2.6691 - accuracy: 0.7253 - val_loss: 0.9371 - val_accuracy: 0.8316\n",
      "Epoch 19/100\n",
      "455/455 [==============================] - 0s 112us/step - loss: 2.4794 - accuracy: 0.7473 - val_loss: 0.9200 - val_accuracy: 0.9031\n",
      "Epoch 20/100\n",
      "455/455 [==============================] - 0s 106us/step - loss: 2.6778 - accuracy: 0.7253 - val_loss: 0.9726 - val_accuracy: 0.8673\n",
      "Epoch 21/100\n",
      "455/455 [==============================] - 0s 109us/step - loss: 2.3336 - accuracy: 0.7385 - val_loss: 0.9341 - val_accuracy: 0.8929\n",
      "Epoch 22/100\n",
      "455/455 [==============================] - 0s 374us/step - loss: 2.3009 - accuracy: 0.7385 - val_loss: 0.9827 - val_accuracy: 0.8827\n",
      "Epoch 23/100\n",
      "455/455 [==============================] - 0s 300us/step - loss: 2.3016 - accuracy: 0.7209 - val_loss: 1.0330 - val_accuracy: 0.8571\n",
      "Epoch 24/100\n",
      "455/455 [==============================] - 0s 197us/step - loss: 2.1880 - accuracy: 0.7648 - val_loss: 0.9303 - val_accuracy: 0.8827\n",
      "Epoch 25/100\n",
      "455/455 [==============================] - 0s 199us/step - loss: 2.2791 - accuracy: 0.7495 - val_loss: 0.9699 - val_accuracy: 0.9133\n",
      "Epoch 26/100\n",
      "455/455 [==============================] - 0s 142us/step - loss: 2.3211 - accuracy: 0.7451 - val_loss: 0.8941 - val_accuracy: 0.9082\n",
      "Epoch 27/100\n",
      "455/455 [==============================] - 0s 223us/step - loss: 1.6777 - accuracy: 0.8022 - val_loss: 0.9035 - val_accuracy: 0.9031\n",
      "Epoch 28/100\n",
      "455/455 [==============================] - 0s 272us/step - loss: 1.9911 - accuracy: 0.7538 - val_loss: 0.8523 - val_accuracy: 0.9031\n",
      "Epoch 29/100\n",
      "455/455 [==============================] - 0s 225us/step - loss: 2.2363 - accuracy: 0.7604 - val_loss: 0.8678 - val_accuracy: 0.9082\n",
      "Epoch 30/100\n",
      "455/455 [==============================] - 0s 229us/step - loss: 2.0205 - accuracy: 0.7758 - val_loss: 1.0247 - val_accuracy: 0.8827\n",
      "Epoch 31/100\n",
      "455/455 [==============================] - 0s 133us/step - loss: 1.9375 - accuracy: 0.7714 - val_loss: 0.8133 - val_accuracy: 0.8929\n",
      "Epoch 32/100\n",
      "455/455 [==============================] - 0s 290us/step - loss: 1.6966 - accuracy: 0.7912 - val_loss: 0.7883 - val_accuracy: 0.9337\n",
      "Epoch 33/100\n",
      "455/455 [==============================] - 0s 317us/step - loss: 2.1070 - accuracy: 0.7626 - val_loss: 0.8110 - val_accuracy: 0.9235\n",
      "Epoch 34/100\n",
      "455/455 [==============================] - 0s 282us/step - loss: 1.9569 - accuracy: 0.8022 - val_loss: 0.8044 - val_accuracy: 0.9286\n",
      "Epoch 35/100\n",
      "455/455 [==============================] - 0s 273us/step - loss: 1.6846 - accuracy: 0.7890 - val_loss: 0.9137 - val_accuracy: 0.8929\n",
      "Epoch 36/100\n",
      "455/455 [==============================] - 0s 356us/step - loss: 1.6109 - accuracy: 0.7846 - val_loss: 0.8582 - val_accuracy: 0.8980\n",
      "Epoch 37/100\n",
      "455/455 [==============================] - 0s 282us/step - loss: 1.8107 - accuracy: 0.7538 - val_loss: 0.8410 - val_accuracy: 0.9133\n",
      "Epoch 38/100\n",
      "455/455 [==============================] - 0s 371us/step - loss: 2.0635 - accuracy: 0.7582 - val_loss: 0.8688 - val_accuracy: 0.9184\n",
      "Epoch 39/100\n",
      "455/455 [==============================] - 0s 293us/step - loss: 2.1268 - accuracy: 0.7363 - val_loss: 0.9124 - val_accuracy: 0.9133\n",
      "Epoch 40/100\n",
      "455/455 [==============================] - 0s 223us/step - loss: 1.8413 - accuracy: 0.7714 - val_loss: 0.8459 - val_accuracy: 0.9133\n",
      "Epoch 41/100\n",
      "455/455 [==============================] - 0s 471us/step - loss: 1.7688 - accuracy: 0.7692 - val_loss: 0.9033 - val_accuracy: 0.9235\n",
      "Epoch 42/100\n",
      "455/455 [==============================] - 0s 254us/step - loss: 1.7843 - accuracy: 0.7934 - val_loss: 0.8894 - val_accuracy: 0.9184\n",
      "Epoch 43/100\n",
      "455/455 [==============================] - 0s 282us/step - loss: 1.6668 - accuracy: 0.7846 - val_loss: 0.9057 - val_accuracy: 0.9031\n",
      "Epoch 44/100\n",
      "455/455 [==============================] - 0s 213us/step - loss: 1.9280 - accuracy: 0.7692 - val_loss: 0.9233 - val_accuracy: 0.9133\n",
      "Epoch 45/100\n",
      "455/455 [==============================] - 0s 186us/step - loss: 1.5591 - accuracy: 0.7956 - val_loss: 0.8163 - val_accuracy: 0.9082\n",
      "Epoch 46/100\n",
      "455/455 [==============================] - 0s 597us/step - loss: 1.6845 - accuracy: 0.7692 - val_loss: 0.9221 - val_accuracy: 0.9235\n",
      "Epoch 47/100\n",
      "455/455 [==============================] - 0s 182us/step - loss: 1.4584 - accuracy: 0.7934 - val_loss: 0.8820 - val_accuracy: 0.9286\n",
      "Epoch 48/100\n",
      "455/455 [==============================] - 0s 169us/step - loss: 1.5597 - accuracy: 0.7824 - val_loss: 0.8312 - val_accuracy: 0.9337\n",
      "Epoch 49/100\n",
      "455/455 [==============================] - 0s 170us/step - loss: 1.5900 - accuracy: 0.7956 - val_loss: 0.9364 - val_accuracy: 0.9235\n",
      "Epoch 50/100\n",
      "455/455 [==============================] - 0s 221us/step - loss: 1.5223 - accuracy: 0.7802 - val_loss: 0.9955 - val_accuracy: 0.9286\n",
      "Epoch 51/100\n",
      "455/455 [==============================] - 0s 181us/step - loss: 1.5278 - accuracy: 0.7868 - val_loss: 0.8657 - val_accuracy: 0.9337\n",
      "Epoch 52/100\n",
      "455/455 [==============================] - 0s 137us/step - loss: 1.4524 - accuracy: 0.7758 - val_loss: 0.9405 - val_accuracy: 0.9133\n",
      "Epoch 53/100\n",
      "455/455 [==============================] - 0s 127us/step - loss: 1.3550 - accuracy: 0.7890 - val_loss: 0.9070 - val_accuracy: 0.9082\n",
      "Epoch 54/100\n",
      "455/455 [==============================] - 0s 171us/step - loss: 1.5624 - accuracy: 0.7538 - val_loss: 0.9621 - val_accuracy: 0.9082\n",
      "Epoch 55/100\n",
      "455/455 [==============================] - 0s 171us/step - loss: 1.2965 - accuracy: 0.7846 - val_loss: 0.8595 - val_accuracy: 0.9337\n",
      "Epoch 56/100\n",
      "455/455 [==============================] - 0s 156us/step - loss: 1.3903 - accuracy: 0.7956 - val_loss: 0.8510 - val_accuracy: 0.9439\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "455/455 [==============================] - 0s 145us/step - loss: 1.1703 - accuracy: 0.8220 - val_loss: 0.8837 - val_accuracy: 0.9439\n",
      "Epoch 58/100\n",
      "455/455 [==============================] - 0s 149us/step - loss: 1.3728 - accuracy: 0.7582 - val_loss: 0.9150 - val_accuracy: 0.9337\n",
      "Epoch 59/100\n",
      "455/455 [==============================] - 0s 145us/step - loss: 1.1771 - accuracy: 0.7736 - val_loss: 0.8678 - val_accuracy: 0.9439\n",
      "Epoch 60/100\n",
      "455/455 [==============================] - 0s 133us/step - loss: 1.2649 - accuracy: 0.8044 - val_loss: 0.8690 - val_accuracy: 0.9439\n",
      "Epoch 61/100\n",
      "455/455 [==============================] - 0s 128us/step - loss: 1.1060 - accuracy: 0.7912 - val_loss: 0.8825 - val_accuracy: 0.9541\n",
      "Epoch 62/100\n",
      "455/455 [==============================] - 0s 163us/step - loss: 1.2150 - accuracy: 0.8088 - val_loss: 0.8602 - val_accuracy: 0.9541\n",
      "Epoch 63/100\n",
      "455/455 [==============================] - 0s 175us/step - loss: 1.1494 - accuracy: 0.8066 - val_loss: 0.8675 - val_accuracy: 0.9337\n",
      "Epoch 64/100\n",
      "455/455 [==============================] - 0s 133us/step - loss: 1.2880 - accuracy: 0.7626 - val_loss: 0.8904 - val_accuracy: 0.9592\n",
      "Epoch 65/100\n",
      "455/455 [==============================] - 0s 130us/step - loss: 1.2631 - accuracy: 0.7736 - val_loss: 0.8415 - val_accuracy: 0.9439\n",
      "Epoch 66/100\n",
      "455/455 [==============================] - 0s 128us/step - loss: 1.1902 - accuracy: 0.7758 - val_loss: 0.8661 - val_accuracy: 0.9439\n",
      "Epoch 67/100\n",
      "455/455 [==============================] - 0s 123us/step - loss: 1.0208 - accuracy: 0.7956 - val_loss: 0.8737 - val_accuracy: 0.9439\n",
      "Epoch 68/100\n",
      "455/455 [==============================] - 0s 115us/step - loss: 1.1392 - accuracy: 0.8066 - val_loss: 0.9024 - val_accuracy: 0.9439\n",
      "Epoch 69/100\n",
      "455/455 [==============================] - 0s 101us/step - loss: 1.1003 - accuracy: 0.7912 - val_loss: 0.8497 - val_accuracy: 0.9439\n",
      "Epoch 70/100\n",
      "455/455 [==============================] - 0s 108us/step - loss: 1.1676 - accuracy: 0.7560 - val_loss: 0.8921 - val_accuracy: 0.9643\n",
      "Epoch 71/100\n",
      "455/455 [==============================] - 0s 102us/step - loss: 0.9884 - accuracy: 0.8154 - val_loss: 0.8870 - val_accuracy: 0.9439\n",
      "Epoch 72/100\n",
      "455/455 [==============================] - 0s 104us/step - loss: 1.1051 - accuracy: 0.7890 - val_loss: 0.8885 - val_accuracy: 0.9643\n",
      "Epoch 73/100\n",
      "455/455 [==============================] - 0s 111us/step - loss: 0.9612 - accuracy: 0.7956 - val_loss: 0.8208 - val_accuracy: 0.9439\n",
      "Epoch 74/100\n",
      "455/455 [==============================] - 0s 101us/step - loss: 1.0127 - accuracy: 0.8088 - val_loss: 0.8030 - val_accuracy: 0.9439\n",
      "Epoch 75/100\n",
      "455/455 [==============================] - 0s 120us/step - loss: 1.0390 - accuracy: 0.7824 - val_loss: 0.7752 - val_accuracy: 0.9439\n",
      "Epoch 76/100\n",
      "455/455 [==============================] - 0s 163us/step - loss: 1.0268 - accuracy: 0.8066 - val_loss: 0.7251 - val_accuracy: 0.9643\n",
      "Epoch 77/100\n",
      "455/455 [==============================] - 0s 141us/step - loss: 0.9365 - accuracy: 0.8022 - val_loss: 0.7203 - val_accuracy: 0.9643\n",
      "Epoch 78/100\n",
      "455/455 [==============================] - 0s 160us/step - loss: 1.0064 - accuracy: 0.8330 - val_loss: 0.6835 - val_accuracy: 0.9643\n",
      "Epoch 79/100\n",
      "455/455 [==============================] - 0s 130us/step - loss: 0.8509 - accuracy: 0.8396 - val_loss: 0.7724 - val_accuracy: 0.9439\n",
      "Epoch 80/100\n",
      "455/455 [==============================] - 0s 189us/step - loss: 0.9618 - accuracy: 0.7868 - val_loss: 0.7532 - val_accuracy: 0.9643\n",
      "Epoch 81/100\n",
      "455/455 [==============================] - 0s 177us/step - loss: 0.8618 - accuracy: 0.8154 - val_loss: 0.7725 - val_accuracy: 0.9643\n",
      "Epoch 82/100\n",
      "455/455 [==============================] - 0s 137us/step - loss: 0.9802 - accuracy: 0.7846 - val_loss: 0.7582 - val_accuracy: 0.9439\n",
      "Epoch 83/100\n",
      "455/455 [==============================] - 0s 169us/step - loss: 0.9583 - accuracy: 0.8044 - val_loss: 0.7542 - val_accuracy: 0.9439\n",
      "Epoch 84/100\n",
      "455/455 [==============================] - 0s 148us/step - loss: 0.9465 - accuracy: 0.7956 - val_loss: 0.7592 - val_accuracy: 0.9439\n",
      "Epoch 85/100\n",
      "455/455 [==============================] - 0s 143us/step - loss: 0.8669 - accuracy: 0.8044 - val_loss: 0.6928 - val_accuracy: 0.9643\n",
      "Epoch 86/100\n",
      "455/455 [==============================] - 0s 126us/step - loss: 0.8564 - accuracy: 0.8154 - val_loss: 0.6628 - val_accuracy: 0.9643\n",
      "Epoch 87/100\n",
      "455/455 [==============================] - 0s 142us/step - loss: 0.9936 - accuracy: 0.7758 - val_loss: 0.7602 - val_accuracy: 0.9643\n",
      "Epoch 88/100\n",
      "455/455 [==============================] - 0s 172us/step - loss: 0.9473 - accuracy: 0.7956 - val_loss: 0.7877 - val_accuracy: 0.9439\n",
      "Epoch 89/100\n",
      "455/455 [==============================] - 0s 147us/step - loss: 0.8281 - accuracy: 0.8110 - val_loss: 0.7322 - val_accuracy: 0.9643\n",
      "Epoch 90/100\n",
      "455/455 [==============================] - 0s 120us/step - loss: 0.9522 - accuracy: 0.7780 - val_loss: 0.6974 - val_accuracy: 0.9439\n",
      "Epoch 91/100\n",
      "455/455 [==============================] - 0s 218us/step - loss: 0.8671 - accuracy: 0.7846 - val_loss: 0.7550 - val_accuracy: 0.9643\n",
      "Epoch 92/100\n",
      "455/455 [==============================] - 0s 141us/step - loss: 0.9720 - accuracy: 0.7890 - val_loss: 0.7353 - val_accuracy: 0.9643\n",
      "Epoch 93/100\n",
      "455/455 [==============================] - 0s 240us/step - loss: 1.0189 - accuracy: 0.7978 - val_loss: 0.7506 - val_accuracy: 0.9439\n",
      "Epoch 94/100\n",
      "455/455 [==============================] - 0s 144us/step - loss: 0.8459 - accuracy: 0.8022 - val_loss: 0.7851 - val_accuracy: 0.9643\n",
      "Epoch 95/100\n",
      "455/455 [==============================] - 0s 181us/step - loss: 0.8598 - accuracy: 0.8066 - val_loss: 0.8286 - val_accuracy: 0.9592\n",
      "Epoch 96/100\n",
      "455/455 [==============================] - 0s 166us/step - loss: 0.8333 - accuracy: 0.8044 - val_loss: 0.7292 - val_accuracy: 0.9439\n",
      "Epoch 97/100\n",
      "455/455 [==============================] - 0s 241us/step - loss: 0.8456 - accuracy: 0.7802 - val_loss: 0.6935 - val_accuracy: 0.9643\n",
      "Epoch 98/100\n",
      "455/455 [==============================] - 0s 197us/step - loss: 0.8210 - accuracy: 0.8286 - val_loss: 0.6542 - val_accuracy: 0.9694\n",
      "Epoch 99/100\n",
      "455/455 [==============================] - 0s 232us/step - loss: 0.9650 - accuracy: 0.8088 - val_loss: 0.6798 - val_accuracy: 0.9643\n",
      "Epoch 100/100\n",
      "455/455 [==============================] - 0s 238us/step - loss: 0.7940 - accuracy: 0.8022 - val_loss: 0.7372 - val_accuracy: 0.9643\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a3a516f28>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over8.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196/196 [==============================] - 0s 99us/step\n",
      "over-sampling test accuracy: 96.94%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over8 = model1_over8.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over8*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 1, 1, 1, 1, 0, 2, 2, 1, 1, 0, 2, 1, 1, 2, 1, 0, 1, 2,\n",
       "       0, 1, 1, 0, 2, 0, 0, 2, 0, 0, 2, 2, 2, 0, 1, 1, 1, 2, 2, 2, 2, 1,\n",
       "       0, 1, 2, 1, 2, 1, 1, 1, 0, 0, 0, 1, 1, 0, 2, 2, 1, 1, 1, 2, 0, 1,\n",
       "       2, 0, 0, 1, 0, 1, 1, 2, 0, 0, 2, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 2,\n",
       "       0, 1, 1, 2, 0, 1, 2, 0, 0, 1, 2, 2, 2, 2, 1, 0, 2, 2, 2, 1, 0, 1,\n",
       "       2, 1, 1, 2, 1, 2, 2, 1, 2, 0, 0, 1, 1, 0, 2, 2, 1, 2, 1, 0, 1, 1,\n",
       "       0, 1, 1, 2, 0, 0, 2, 1, 0, 0, 0, 2, 2, 2, 2, 2, 1, 1, 1, 1, 0, 0,\n",
       "       1, 2, 2, 2, 0, 1, 2, 0, 1, 2, 2, 2, 0, 2, 1, 0, 0, 1, 2, 1, 0, 0,\n",
       "       1, 2, 0, 1, 2, 0, 2, 0, 2, 1, 1, 0, 0, 2, 0, 2, 1, 1, 2, 1])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred8 = model1_over8.predict_classes(X_test_over)\n",
    "pred8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS205</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CFBREBSa131</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS177</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>NRS205</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>CFBREBSa122</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>NRS001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>NRS265</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>196 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test  pred\n",
       "0         NRS205     2     2\n",
       "1         NRS109     2     2\n",
       "2    CFBREBSa131     0     2\n",
       "3         NRS148     2     2\n",
       "4         NRS177     1     1\n",
       "..           ...   ...   ...\n",
       "191       NRS205     2     2\n",
       "192  CFBREBSa122     0     1\n",
       "193       NRS001     1     1\n",
       "194       NRS148     2     2\n",
       "195       NRS265     1     1\n",
       "\n",
       "[196 rows x 3 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat8['pred'] = pred8\n",
    "dat8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba8 = model1_over8.predict_proba(X_test_over)\n",
    "dat_proba8 = pd.DataFrame(proba8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.691095e-08</td>\n",
       "      <td>3.571927e-08</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.775979e-08</td>\n",
       "      <td>3.876033e-08</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.982608e-04</td>\n",
       "      <td>1.134029e-06</td>\n",
       "      <td>9.993006e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.234670e-08</td>\n",
       "      <td>3.121212e-08</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.723448e-05</td>\n",
       "      <td>9.999820e-01</td>\n",
       "      <td>6.711543e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>3.691095e-08</td>\n",
       "      <td>3.571927e-08</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>9.261665e-02</td>\n",
       "      <td>9.073822e-01</td>\n",
       "      <td>1.162373e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>4.174278e-07</td>\n",
       "      <td>9.999995e-01</td>\n",
       "      <td>3.254023e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>3.234670e-08</td>\n",
       "      <td>3.121212e-08</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>5.250178e-08</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>6.719974e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>196 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0             1             2\n",
       "0    3.691095e-08  3.571927e-08  9.999999e-01\n",
       "1    2.775979e-08  3.876033e-08  9.999999e-01\n",
       "2    6.982608e-04  1.134029e-06  9.993006e-01\n",
       "3    3.234670e-08  3.121212e-08  9.999999e-01\n",
       "4    1.723448e-05  9.999820e-01  6.711543e-07\n",
       "..            ...           ...           ...\n",
       "191  3.691095e-08  3.571927e-08  9.999999e-01\n",
       "192  9.261665e-02  9.073822e-01  1.162373e-06\n",
       "193  4.174278e-07  9.999995e-01  3.254023e-09\n",
       "194  3.234670e-08  3.121212e-08  9.999999e-01\n",
       "195  5.250178e-08  9.999999e-01  6.719974e-08\n",
       "\n",
       "[196 rows x 3 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba8.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba8.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat8.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/8pyopST.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 455 samples, validate on 196 samples\n",
      "Epoch 1/100\n",
      "455/455 [==============================] - 0s 196us/step - loss: 0.8263 - accuracy: 0.8154 - val_loss: 0.6263 - val_accuracy: 0.9694\n",
      "Epoch 2/100\n",
      "455/455 [==============================] - 0s 172us/step - loss: 0.7974 - accuracy: 0.7912 - val_loss: 0.6440 - val_accuracy: 0.9694\n",
      "Epoch 3/100\n",
      "455/455 [==============================] - 0s 152us/step - loss: 0.7721 - accuracy: 0.7868 - val_loss: 0.6841 - val_accuracy: 0.9694\n",
      "Epoch 4/100\n",
      "455/455 [==============================] - 0s 154us/step - loss: 0.7511 - accuracy: 0.7802 - val_loss: 0.6534 - val_accuracy: 0.9694\n",
      "Epoch 5/100\n",
      "455/455 [==============================] - 0s 143us/step - loss: 0.8151 - accuracy: 0.7824 - val_loss: 0.6307 - val_accuracy: 0.9541\n",
      "Epoch 6/100\n",
      "455/455 [==============================] - 0s 284us/step - loss: 0.7349 - accuracy: 0.8176 - val_loss: 0.6579 - val_accuracy: 0.9694\n",
      "Epoch 7/100\n",
      "455/455 [==============================] - 0s 189us/step - loss: 0.7972 - accuracy: 0.7714 - val_loss: 0.6043 - val_accuracy: 0.9745\n",
      "Epoch 8/100\n",
      "455/455 [==============================] - 0s 139us/step - loss: 0.8122 - accuracy: 0.7890 - val_loss: 0.6731 - val_accuracy: 0.9694\n",
      "Epoch 9/100\n",
      "455/455 [==============================] - 0s 123us/step - loss: 0.7092 - accuracy: 0.8000 - val_loss: 0.6518 - val_accuracy: 0.9796\n",
      "Epoch 10/100\n",
      "455/455 [==============================] - 0s 120us/step - loss: 0.7368 - accuracy: 0.8044 - val_loss: 0.6119 - val_accuracy: 0.9745\n",
      "Epoch 11/100\n",
      "455/455 [==============================] - 0s 220us/step - loss: 0.7425 - accuracy: 0.8066 - val_loss: 0.6253 - val_accuracy: 0.9745\n",
      "Epoch 12/100\n",
      "455/455 [==============================] - 0s 142us/step - loss: 0.7547 - accuracy: 0.7978 - val_loss: 0.6330 - val_accuracy: 0.9745\n",
      "Epoch 13/100\n",
      "455/455 [==============================] - 0s 108us/step - loss: 0.6895 - accuracy: 0.8505 - val_loss: 0.6427 - val_accuracy: 0.9439\n",
      "Epoch 14/100\n",
      "455/455 [==============================] - 0s 109us/step - loss: 0.8079 - accuracy: 0.7956 - val_loss: 0.7206 - val_accuracy: 0.9643\n",
      "Epoch 15/100\n",
      "455/455 [==============================] - 0s 108us/step - loss: 0.7757 - accuracy: 0.7824 - val_loss: 0.6385 - val_accuracy: 0.9745\n",
      "Epoch 16/100\n",
      "455/455 [==============================] - 0s 116us/step - loss: 0.7090 - accuracy: 0.7890 - val_loss: 0.6368 - val_accuracy: 0.9796\n",
      "Epoch 17/100\n",
      "455/455 [==============================] - 0s 147us/step - loss: 0.7337 - accuracy: 0.7780 - val_loss: 0.6682 - val_accuracy: 0.9745\n",
      "Epoch 18/100\n",
      "455/455 [==============================] - 0s 135us/step - loss: 0.6896 - accuracy: 0.8044 - val_loss: 0.6058 - val_accuracy: 0.9796\n",
      "Epoch 19/100\n",
      "455/455 [==============================] - 0s 117us/step - loss: 0.7426 - accuracy: 0.7868 - val_loss: 0.6002 - val_accuracy: 0.9745\n",
      "Epoch 20/100\n",
      "455/455 [==============================] - 0s 115us/step - loss: 0.7252 - accuracy: 0.7978 - val_loss: 0.6148 - val_accuracy: 0.9745\n",
      "Epoch 21/100\n",
      "455/455 [==============================] - 0s 112us/step - loss: 0.6818 - accuracy: 0.8022 - val_loss: 0.5902 - val_accuracy: 0.9745\n",
      "Epoch 22/100\n",
      "455/455 [==============================] - 0s 124us/step - loss: 0.6528 - accuracy: 0.8088 - val_loss: 0.6183 - val_accuracy: 0.9745\n",
      "Epoch 23/100\n",
      "455/455 [==============================] - 0s 126us/step - loss: 0.7431 - accuracy: 0.7912 - val_loss: 0.5982 - val_accuracy: 0.9745\n",
      "Epoch 24/100\n",
      "455/455 [==============================] - 0s 134us/step - loss: 0.7353 - accuracy: 0.7802 - val_loss: 0.5642 - val_accuracy: 0.9745\n",
      "Epoch 25/100\n",
      "455/455 [==============================] - 0s 125us/step - loss: 0.7307 - accuracy: 0.7912 - val_loss: 0.6152 - val_accuracy: 0.9745\n",
      "Epoch 26/100\n",
      "455/455 [==============================] - 0s 128us/step - loss: 0.7108 - accuracy: 0.7890 - val_loss: 0.6359 - val_accuracy: 0.9643\n",
      "Epoch 27/100\n",
      "455/455 [==============================] - 0s 127us/step - loss: 0.6424 - accuracy: 0.8242 - val_loss: 0.5927 - val_accuracy: 0.9745\n",
      "Epoch 28/100\n",
      "455/455 [==============================] - 0s 112us/step - loss: 0.6800 - accuracy: 0.8088 - val_loss: 0.6146 - val_accuracy: 0.9745\n",
      "Epoch 29/100\n",
      "455/455 [==============================] - 0s 117us/step - loss: 0.7338 - accuracy: 0.8088 - val_loss: 0.5902 - val_accuracy: 0.9694\n",
      "Epoch 30/100\n",
      "455/455 [==============================] - 0s 132us/step - loss: 0.7390 - accuracy: 0.7868 - val_loss: 0.6044 - val_accuracy: 0.9694\n",
      "Epoch 31/100\n",
      "455/455 [==============================] - 0s 149us/step - loss: 0.6704 - accuracy: 0.8154 - val_loss: 0.6206 - val_accuracy: 0.9694\n",
      "Epoch 32/100\n",
      "455/455 [==============================] - 0s 173us/step - loss: 0.6016 - accuracy: 0.8176 - val_loss: 0.5783 - val_accuracy: 0.9745\n",
      "Epoch 33/100\n",
      "455/455 [==============================] - 0s 170us/step - loss: 0.7514 - accuracy: 0.7912 - val_loss: 0.5844 - val_accuracy: 0.9745\n",
      "Epoch 34/100\n",
      "455/455 [==============================] - 0s 161us/step - loss: 0.6433 - accuracy: 0.8198 - val_loss: 0.6398 - val_accuracy: 0.9643\n",
      "Epoch 35/100\n",
      "455/455 [==============================] - 0s 141us/step - loss: 0.7740 - accuracy: 0.7714 - val_loss: 0.6571 - val_accuracy: 0.9643\n",
      "Epoch 36/100\n",
      "455/455 [==============================] - 0s 135us/step - loss: 0.7900 - accuracy: 0.7538 - val_loss: 0.5875 - val_accuracy: 0.9643\n",
      "Epoch 37/100\n",
      "455/455 [==============================] - 0s 144us/step - loss: 0.6751 - accuracy: 0.7824 - val_loss: 0.5292 - val_accuracy: 0.9694\n",
      "Epoch 38/100\n",
      "455/455 [==============================] - 0s 143us/step - loss: 0.6489 - accuracy: 0.7978 - val_loss: 0.5568 - val_accuracy: 0.9694\n",
      "Epoch 39/100\n",
      "455/455 [==============================] - 0s 156us/step - loss: 0.6646 - accuracy: 0.8088 - val_loss: 0.5976 - val_accuracy: 0.9694\n",
      "Epoch 40/100\n",
      "455/455 [==============================] - 0s 145us/step - loss: 0.6908 - accuracy: 0.7846 - val_loss: 0.5908 - val_accuracy: 0.9694\n",
      "Epoch 41/100\n",
      "455/455 [==============================] - 0s 170us/step - loss: 0.6648 - accuracy: 0.8132 - val_loss: 0.5817 - val_accuracy: 0.9694\n",
      "Epoch 42/100\n",
      "455/455 [==============================] - 0s 161us/step - loss: 0.6453 - accuracy: 0.7978 - val_loss: 0.5435 - val_accuracy: 0.9694\n",
      "Epoch 43/100\n",
      "455/455 [==============================] - 0s 125us/step - loss: 0.6462 - accuracy: 0.7934 - val_loss: 0.5698 - val_accuracy: 0.9643\n",
      "Epoch 44/100\n",
      "455/455 [==============================] - 0s 127us/step - loss: 0.6977 - accuracy: 0.7758 - val_loss: 0.5256 - val_accuracy: 0.9694\n",
      "Epoch 45/100\n",
      "455/455 [==============================] - 0s 135us/step - loss: 0.6588 - accuracy: 0.7934 - val_loss: 0.6202 - val_accuracy: 0.9643\n",
      "Epoch 46/100\n",
      "455/455 [==============================] - 0s 145us/step - loss: 0.6830 - accuracy: 0.7758 - val_loss: 0.5899 - val_accuracy: 0.9694\n",
      "Epoch 47/100\n",
      "455/455 [==============================] - 0s 153us/step - loss: 0.6423 - accuracy: 0.8198 - val_loss: 0.6107 - val_accuracy: 0.9745\n",
      "Epoch 48/100\n",
      "455/455 [==============================] - 0s 185us/step - loss: 0.6103 - accuracy: 0.8330 - val_loss: 0.5584 - val_accuracy: 0.9745\n",
      "Epoch 49/100\n",
      "455/455 [==============================] - 0s 138us/step - loss: 0.5774 - accuracy: 0.8374 - val_loss: 0.5656 - val_accuracy: 0.9745\n",
      "Epoch 50/100\n",
      "455/455 [==============================] - 0s 164us/step - loss: 0.6299 - accuracy: 0.8044 - val_loss: 0.5633 - val_accuracy: 0.9745\n",
      "Epoch 51/100\n",
      "455/455 [==============================] - 0s 145us/step - loss: 0.5855 - accuracy: 0.8176 - val_loss: 0.5959 - val_accuracy: 0.9745\n",
      "Epoch 52/100\n",
      "455/455 [==============================] - 0s 144us/step - loss: 0.6087 - accuracy: 0.8198 - val_loss: 0.5858 - val_accuracy: 0.9796\n",
      "Epoch 53/100\n",
      "455/455 [==============================] - 0s 100us/step - loss: 0.6156 - accuracy: 0.8110 - val_loss: 0.5287 - val_accuracy: 0.9745\n",
      "Epoch 54/100\n",
      "455/455 [==============================] - 0s 99us/step - loss: 0.6442 - accuracy: 0.7868 - val_loss: 0.5683 - val_accuracy: 0.9745\n",
      "Epoch 55/100\n",
      "455/455 [==============================] - 0s 112us/step - loss: 0.6332 - accuracy: 0.8000 - val_loss: 0.5740 - val_accuracy: 0.9745\n",
      "Epoch 56/100\n",
      "455/455 [==============================] - 0s 150us/step - loss: 0.6102 - accuracy: 0.8198 - val_loss: 0.5667 - val_accuracy: 0.9796\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "455/455 [==============================] - 0s 334us/step - loss: 0.6835 - accuracy: 0.7846 - val_loss: 0.5597 - val_accuracy: 0.9745\n",
      "Epoch 58/100\n",
      "455/455 [==============================] - 0s 243us/step - loss: 0.6172 - accuracy: 0.8110 - val_loss: 0.5496 - val_accuracy: 0.9745\n",
      "Epoch 59/100\n",
      "455/455 [==============================] - 0s 255us/step - loss: 0.6218 - accuracy: 0.8066 - val_loss: 0.5646 - val_accuracy: 0.9745\n",
      "Epoch 60/100\n",
      "455/455 [==============================] - 0s 255us/step - loss: 0.6812 - accuracy: 0.8110 - val_loss: 0.5773 - val_accuracy: 0.9694\n",
      "Epoch 61/100\n",
      "455/455 [==============================] - 0s 441us/step - loss: 0.6136 - accuracy: 0.8154 - val_loss: 0.5392 - val_accuracy: 0.9745\n",
      "Epoch 62/100\n",
      "455/455 [==============================] - 0s 260us/step - loss: 0.6656 - accuracy: 0.7429 - val_loss: 0.5211 - val_accuracy: 0.9745\n",
      "Epoch 63/100\n",
      "455/455 [==============================] - 0s 145us/step - loss: 0.6256 - accuracy: 0.8044 - val_loss: 0.5304 - val_accuracy: 0.9694\n",
      "Epoch 64/100\n",
      "455/455 [==============================] - 0s 654us/step - loss: 0.5663 - accuracy: 0.8088 - val_loss: 0.5312 - val_accuracy: 0.9694\n",
      "Epoch 65/100\n",
      "455/455 [==============================] - 0s 261us/step - loss: 0.6019 - accuracy: 0.7758 - val_loss: 0.6443 - val_accuracy: 0.9745\n",
      "Epoch 66/100\n",
      "455/455 [==============================] - 0s 149us/step - loss: 0.6422 - accuracy: 0.7824 - val_loss: 0.6449 - val_accuracy: 0.9745\n",
      "Epoch 67/100\n",
      "455/455 [==============================] - 0s 179us/step - loss: 0.6527 - accuracy: 0.7670 - val_loss: 0.6000 - val_accuracy: 0.9694\n",
      "Epoch 68/100\n",
      "455/455 [==============================] - 0s 144us/step - loss: 0.6256 - accuracy: 0.8088 - val_loss: 0.5609 - val_accuracy: 0.9745\n",
      "Epoch 69/100\n",
      "455/455 [==============================] - 0s 131us/step - loss: 0.6699 - accuracy: 0.7714 - val_loss: 0.5010 - val_accuracy: 0.9745\n",
      "Epoch 70/100\n",
      "455/455 [==============================] - 0s 147us/step - loss: 0.5141 - accuracy: 0.8440 - val_loss: 0.4969 - val_accuracy: 0.9745\n",
      "Epoch 71/100\n",
      "455/455 [==============================] - 0s 134us/step - loss: 0.5482 - accuracy: 0.8198 - val_loss: 0.5259 - val_accuracy: 0.9694\n",
      "Epoch 72/100\n",
      "455/455 [==============================] - 0s 114us/step - loss: 0.5906 - accuracy: 0.8066 - val_loss: 0.4976 - val_accuracy: 0.9745\n",
      "Epoch 73/100\n",
      "455/455 [==============================] - 0s 285us/step - loss: 0.5766 - accuracy: 0.8066 - val_loss: 0.5398 - val_accuracy: 0.9745\n",
      "Epoch 74/100\n",
      "455/455 [==============================] - 0s 142us/step - loss: 0.5915 - accuracy: 0.8110 - val_loss: 0.5677 - val_accuracy: 0.9745\n",
      "Epoch 75/100\n",
      "455/455 [==============================] - 0s 147us/step - loss: 0.5926 - accuracy: 0.8154 - val_loss: 0.4848 - val_accuracy: 0.9745\n",
      "Epoch 76/100\n",
      "455/455 [==============================] - 0s 194us/step - loss: 0.6066 - accuracy: 0.7780 - val_loss: 0.4703 - val_accuracy: 0.9796\n",
      "Epoch 77/100\n",
      "455/455 [==============================] - 0s 434us/step - loss: 0.5658 - accuracy: 0.8374 - val_loss: 0.5132 - val_accuracy: 0.9745\n",
      "Epoch 78/100\n",
      "455/455 [==============================] - 0s 254us/step - loss: 0.6190 - accuracy: 0.7846 - val_loss: 0.5011 - val_accuracy: 0.9745\n",
      "Epoch 79/100\n",
      "455/455 [==============================] - 0s 239us/step - loss: 0.5763 - accuracy: 0.7846 - val_loss: 0.4896 - val_accuracy: 0.9745\n",
      "Epoch 80/100\n",
      "455/455 [==============================] - 0s 503us/step - loss: 0.5099 - accuracy: 0.8264 - val_loss: 0.4559 - val_accuracy: 0.9796\n",
      "Epoch 81/100\n",
      "455/455 [==============================] - 0s 257us/step - loss: 0.4949 - accuracy: 0.8462 - val_loss: 0.4840 - val_accuracy: 0.9745\n",
      "Epoch 82/100\n",
      "455/455 [==============================] - 0s 153us/step - loss: 0.5918 - accuracy: 0.8242 - val_loss: 0.4508 - val_accuracy: 0.9796\n",
      "Epoch 83/100\n",
      "455/455 [==============================] - 0s 216us/step - loss: 0.5350 - accuracy: 0.8374 - val_loss: 0.5511 - val_accuracy: 0.9745\n",
      "Epoch 84/100\n",
      "455/455 [==============================] - 0s 222us/step - loss: 0.6020 - accuracy: 0.7978 - val_loss: 0.5634 - val_accuracy: 0.9694\n",
      "Epoch 85/100\n",
      "455/455 [==============================] - 0s 159us/step - loss: 0.5681 - accuracy: 0.7978 - val_loss: 0.5741 - val_accuracy: 0.9694\n",
      "Epoch 86/100\n",
      "455/455 [==============================] - 0s 171us/step - loss: 0.5803 - accuracy: 0.8000 - val_loss: 0.5412 - val_accuracy: 0.9745\n",
      "Epoch 87/100\n",
      "455/455 [==============================] - 0s 191us/step - loss: 0.5187 - accuracy: 0.8527 - val_loss: 0.5080 - val_accuracy: 0.9745\n",
      "Epoch 88/100\n",
      "455/455 [==============================] - 0s 147us/step - loss: 0.5929 - accuracy: 0.7912 - val_loss: 0.5114 - val_accuracy: 0.9745\n",
      "Epoch 89/100\n",
      "455/455 [==============================] - 0s 159us/step - loss: 0.5631 - accuracy: 0.7890 - val_loss: 0.4732 - val_accuracy: 0.9745\n",
      "Epoch 90/100\n",
      "455/455 [==============================] - 0s 187us/step - loss: 0.5342 - accuracy: 0.8132 - val_loss: 0.4745 - val_accuracy: 0.9745\n",
      "Epoch 91/100\n",
      "455/455 [==============================] - 0s 167us/step - loss: 0.5439 - accuracy: 0.8198 - val_loss: 0.5489 - val_accuracy: 0.9745\n",
      "Epoch 92/100\n",
      "455/455 [==============================] - 0s 160us/step - loss: 0.6244 - accuracy: 0.7604 - val_loss: 0.5345 - val_accuracy: 0.9745\n",
      "Epoch 93/100\n",
      "455/455 [==============================] - 0s 155us/step - loss: 0.5414 - accuracy: 0.7978 - val_loss: 0.5161 - val_accuracy: 0.9745\n",
      "Epoch 94/100\n",
      "455/455 [==============================] - 0s 177us/step - loss: 0.5152 - accuracy: 0.8154 - val_loss: 0.5019 - val_accuracy: 0.9745\n",
      "Epoch 95/100\n",
      "455/455 [==============================] - 0s 276us/step - loss: 0.5446 - accuracy: 0.8022 - val_loss: 0.5008 - val_accuracy: 0.9745\n",
      "Epoch 96/100\n",
      "455/455 [==============================] - 0s 258us/step - loss: 0.5758 - accuracy: 0.7802 - val_loss: 0.4909 - val_accuracy: 0.9745\n",
      "Epoch 97/100\n",
      "455/455 [==============================] - 0s 284us/step - loss: 0.5490 - accuracy: 0.7978 - val_loss: 0.4738 - val_accuracy: 0.9745\n",
      "Epoch 98/100\n",
      "455/455 [==============================] - 0s 192us/step - loss: 0.5511 - accuracy: 0.8022 - val_loss: 0.5213 - val_accuracy: 0.9745\n",
      "Epoch 99/100\n",
      "455/455 [==============================] - 0s 282us/step - loss: 0.5485 - accuracy: 0.8110 - val_loss: 0.5127 - val_accuracy: 0.9745\n",
      "Epoch 100/100\n",
      "455/455 [==============================] - 0s 238us/step - loss: 0.5650 - accuracy: 0.7978 - val_loss: 0.4631 - val_accuracy: 0.9745\n"
     ]
    }
   ],
   "source": [
    "hist1_over8 = model1_over8.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 80.10%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over8.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba8 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_regularizor_dropout_2.xlsx\",\n",
    "                        sheet_name=3,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>CFBREBSa116</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.676203e-01</td>\n",
       "      <td>3.237956e-02</td>\n",
       "      <td>1.480166e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS214</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>6.534852e-11</td>\n",
       "      <td>2.250731e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.948571e-11</td>\n",
       "      <td>2.839096e-07</td>\n",
       "      <td>9.999998e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.948571e-11</td>\n",
       "      <td>2.839096e-07</td>\n",
       "      <td>9.999998e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.948571e-11</td>\n",
       "      <td>2.839096e-07</td>\n",
       "      <td>9.999998e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS205</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.691095e-08</td>\n",
       "      <td>3.571927e-08</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>CFBREBSa122</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.261665e-02</td>\n",
       "      <td>9.073822e-01</td>\n",
       "      <td>1.162373e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.174278e-07</td>\n",
       "      <td>9.999995e-01</td>\n",
       "      <td>3.254024e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.234670e-08</td>\n",
       "      <td>3.121212e-08</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS265</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.250178e-08</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>6.719974e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1982 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       phage       strain  phenotype  prediction  \\\n",
       "0     p002ykpresabsSTCC_qual  CFBREBSa116          0           0   \n",
       "1     p002ykpresabsSTCC_qual       NRS214          0           0   \n",
       "2     p002ykpresabsSTCC_qual       NRS148          2           2   \n",
       "3     p002ykpresabsSTCC_qual       NRS148          2           2   \n",
       "4     p002ykpresabsSTCC_qual       NRS148          2           2   \n",
       "...                      ...          ...        ...         ...   \n",
       "1977     pyopresabsSTCC_qual       NRS205          2           2   \n",
       "1978     pyopresabsSTCC_qual  CFBREBSa122          0           1   \n",
       "1979     pyopresabsSTCC_qual       NRS001          1           1   \n",
       "1980     pyopresabsSTCC_qual       NRS148          2           2   \n",
       "1981     pyopresabsSTCC_qual       NRS265          1           1   \n",
       "\n",
       "                 0             1             2  \n",
       "0     9.676203e-01  3.237956e-02  1.480166e-07  \n",
       "1     1.000000e+00  6.534852e-11  2.250731e-18  \n",
       "2     3.948571e-11  2.839096e-07  9.999998e-01  \n",
       "3     3.948571e-11  2.839096e-07  9.999998e-01  \n",
       "4     3.948571e-11  2.839096e-07  9.999998e-01  \n",
       "...            ...           ...           ...  \n",
       "1977  3.691095e-08  3.571927e-08  9.999999e-01  \n",
       "1978  9.261665e-02  9.073822e-01  1.162373e-06  \n",
       "1979  4.174278e-07  9.999995e-01  3.254024e-09  \n",
       "1980  3.234670e-08  3.121212e-08  9.999999e-01  \n",
       "1981  5.250178e-08  9.999999e-01  6.719974e-08  \n",
       "\n",
       "[1982 rows x 7 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.69109470e-08, 3.57192700e-08, 9.99999900e-01],\n",
       "       [2.77597860e-08, 3.87603340e-08, 9.99999900e-01],\n",
       "       [6.98260850e-04, 1.13402870e-06, 9.99300600e-01],\n",
       "       [3.23467000e-08, 3.12121200e-08, 9.99999900e-01],\n",
       "       [1.72344840e-05, 9.99982000e-01, 6.71154340e-07],\n",
       "       [7.32489840e-08, 9.99999900e-01, 1.02121380e-08],\n",
       "       [2.71599800e-05, 9.99972700e-01, 1.46475060e-07],\n",
       "       [1.07752820e-04, 9.99878900e-01, 1.34077460e-05],\n",
       "       [1.00000000e+00, 2.92587400e-11, 3.97843680e-13],\n",
       "       [3.69109470e-08, 3.57192700e-08, 9.99999900e-01],\n",
       "       [2.77597860e-08, 3.87603340e-08, 9.99999900e-01],\n",
       "       [4.78420900e-08, 1.00000000e+00, 2.14936140e-08],\n",
       "       [4.17427830e-07, 9.99999500e-01, 3.25402350e-09],\n",
       "       [1.00000000e+00, 4.12077800e-12, 7.81269150e-12],\n",
       "       [6.59789600e-08, 7.48123100e-08, 9.99999900e-01],\n",
       "       [5.20418660e-08, 1.00000000e+00, 9.96792400e-10],\n",
       "       [3.60579730e-08, 1.00000000e+00, 9.31788500e-11],\n",
       "       [3.23467000e-08, 3.12121200e-08, 9.99999900e-01],\n",
       "       [3.69015200e-08, 1.00000000e+00, 8.27395500e-09],\n",
       "       [9.99990200e-01, 5.21880250e-06, 4.56064570e-06],\n",
       "       [1.49148860e-07, 9.99999900e-01, 1.59217100e-09],\n",
       "       [3.69109470e-08, 3.57192700e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 2.99329030e-10, 5.89290450e-10],\n",
       "       [9.19040700e-08, 9.99999900e-01, 6.16701200e-10],\n",
       "       [4.87463380e-06, 9.99995000e-01, 6.79567800e-08],\n",
       "       [1.00000000e+00, 3.33537230e-11, 1.99022140e-11],\n",
       "       [3.23467000e-08, 3.12121200e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 2.08586350e-09, 1.29256570e-09],\n",
       "       [9.99901900e-01, 9.50157560e-05, 3.13829170e-06],\n",
       "       [3.69109470e-08, 3.57192700e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 1.08687130e-08, 4.75926900e-09],\n",
       "       [1.00000000e+00, 3.17676370e-11, 5.40573300e-11],\n",
       "       [2.77597860e-08, 3.87603340e-08, 9.99999900e-01],\n",
       "       [2.77597860e-08, 3.87603340e-08, 9.99999900e-01],\n",
       "       [3.69109470e-08, 3.57192700e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 2.17926500e-08, 7.40875140e-09],\n",
       "       [1.51830570e-06, 9.99998450e-01, 8.73932500e-09],\n",
       "       [3.29579520e-05, 9.99964950e-01, 2.10991360e-06],\n",
       "       [8.80670800e-08, 9.99999760e-01, 7.54393400e-08],\n",
       "       [2.77597860e-08, 3.87603340e-08, 9.99999900e-01],\n",
       "       [3.69109470e-08, 3.57192700e-08, 9.99999900e-01],\n",
       "       [3.23467000e-08, 3.12121200e-08, 9.99999900e-01],\n",
       "       [6.59789600e-08, 7.48123100e-08, 9.99999900e-01],\n",
       "       [2.86468000e-01, 7.13199140e-01, 3.32919330e-04],\n",
       "       [9.99993440e-01, 6.58066700e-06, 2.38264820e-08],\n",
       "       [4.17427830e-07, 9.99999500e-01, 3.25402350e-09],\n",
       "       [6.59789600e-08, 7.48123100e-08, 9.99999900e-01],\n",
       "       [2.86468000e-01, 7.13199140e-01, 3.32919330e-04],\n",
       "       [3.23467000e-08, 3.12121200e-08, 9.99999900e-01],\n",
       "       [4.17427830e-07, 9.99999500e-01, 3.25402350e-09],\n",
       "       [1.75156700e-07, 9.99999900e-01, 2.35419060e-08],\n",
       "       [4.12395500e-08, 1.00000000e+00, 3.27500400e-08],\n",
       "       [9.99793600e-01, 2.05457560e-04, 9.25424400e-07],\n",
       "       [9.99771060e-01, 2.27257190e-04, 1.70457270e-06],\n",
       "       [9.99998700e-01, 3.13198000e-07, 9.08445600e-07],\n",
       "       [1.22577080e-02, 9.87726870e-01, 1.54582360e-05],\n",
       "       [4.17427830e-07, 9.99999500e-01, 3.25402350e-09],\n",
       "       [9.39205800e-01, 6.05323720e-02, 2.61742530e-04],\n",
       "       [6.59789600e-08, 7.48123100e-08, 9.99999900e-01],\n",
       "       [3.69109470e-08, 3.57192700e-08, 9.99999900e-01],\n",
       "       [1.07752820e-04, 9.99878900e-01, 1.34077460e-05],\n",
       "       [5.25017750e-08, 9.99999900e-01, 6.71997360e-08],\n",
       "       [1.72344840e-05, 9.99982000e-01, 6.71154340e-07],\n",
       "       [2.77597860e-08, 3.87603340e-08, 9.99999900e-01],\n",
       "       [9.99986900e-01, 1.27955220e-05, 3.39378630e-07],\n",
       "       [8.05026100e-08, 9.99999900e-01, 5.77330900e-09],\n",
       "       [3.23467000e-08, 3.12121200e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 1.65200760e-15, 3.41320630e-14],\n",
       "       [1.00000000e+00, 9.57869800e-09, 1.13252370e-08],\n",
       "       [4.17427830e-07, 9.99999500e-01, 3.25402350e-09],\n",
       "       [1.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [4.07682500e-05, 9.99958900e-01, 3.91674970e-07],\n",
       "       [1.72344840e-05, 9.99982000e-01, 6.71154340e-07],\n",
       "       [2.77597860e-08, 3.87603340e-08, 9.99999900e-01],\n",
       "       [9.99999400e-01, 3.15371500e-07, 1.78985530e-07],\n",
       "       [9.99998800e-01, 1.22645720e-06, 4.41944370e-08],\n",
       "       [2.77597860e-08, 3.87603340e-08, 9.99999900e-01],\n",
       "       [2.28144000e-04, 9.99409700e-01, 3.62216500e-04],\n",
       "       [9.99999500e-01, 5.04158000e-07, 9.77620400e-10],\n",
       "       [6.55847360e-08, 9.99999900e-01, 7.15804860e-10],\n",
       "       [1.00000000e+00, 1.70285830e-12, 1.71180140e-11],\n",
       "       [9.99871400e-01, 1.28563290e-04, 1.95098390e-08],\n",
       "       [9.99999640e-01, 2.54256400e-07, 1.60114840e-07],\n",
       "       [2.52283830e-06, 9.99997400e-01, 7.98643500e-08],\n",
       "       [1.00000000e+00, 1.87689300e-11, 3.33647280e-11],\n",
       "       [3.52128850e-08, 1.00000000e+00, 7.59851900e-09],\n",
       "       [9.99995230e-01, 1.93466240e-06, 2.89164770e-06],\n",
       "       [6.59789600e-08, 7.48123100e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 2.10836800e-08, 3.25536430e-10],\n",
       "       [2.28430630e-09, 1.00000000e+00, 9.05341700e-11],\n",
       "       [5.61015630e-08, 1.00000000e+00, 2.11542130e-08],\n",
       "       [3.23467000e-08, 3.12121200e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [6.55847360e-08, 9.99999900e-01, 7.15804860e-10],\n",
       "       [6.59789600e-08, 7.48123100e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 1.57874380e-10, 7.99894460e-11],\n",
       "       [9.99999400e-01, 1.82741620e-07, 3.07578350e-07],\n",
       "       [1.07752820e-04, 9.99878900e-01, 1.34077460e-05],\n",
       "       [6.59789600e-08, 7.48123100e-08, 9.99999900e-01],\n",
       "       [3.69109470e-08, 3.57192700e-08, 9.99999900e-01],\n",
       "       [2.77597860e-08, 3.87603340e-08, 9.99999900e-01],\n",
       "       [3.69109470e-08, 3.57192700e-08, 9.99999900e-01],\n",
       "       [1.72344840e-05, 9.99982000e-01, 6.71154340e-07],\n",
       "       [1.00000000e+00, 4.35373560e-09, 3.75657800e-09],\n",
       "       [3.69109470e-08, 3.57192700e-08, 9.99999900e-01],\n",
       "       [3.69109470e-08, 3.57192700e-08, 9.99999900e-01],\n",
       "       [3.23467000e-08, 3.12121200e-08, 9.99999900e-01],\n",
       "       [2.28430630e-09, 1.00000000e+00, 9.05341700e-11],\n",
       "       [1.00000000e+00, 5.59312130e-17, 8.31765600e-17],\n",
       "       [3.60579730e-08, 1.00000000e+00, 9.31788500e-11],\n",
       "       [3.23467000e-08, 3.12121200e-08, 9.99999900e-01],\n",
       "       [2.37605190e-07, 9.99999640e-01, 8.51651550e-08],\n",
       "       [9.26679100e-07, 9.99998330e-01, 7.52449860e-07],\n",
       "       [3.23467000e-08, 3.12121200e-08, 9.99999900e-01],\n",
       "       [9.26679100e-07, 9.99998330e-01, 7.52449860e-07],\n",
       "       [3.69109470e-08, 3.57192700e-08, 9.99999900e-01],\n",
       "       [2.77597860e-08, 3.87603340e-08, 9.99999900e-01],\n",
       "       [1.72344840e-05, 9.99982000e-01, 6.71154340e-07],\n",
       "       [3.69109470e-08, 3.57192700e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 1.01107700e-09, 3.42117980e-09],\n",
       "       [9.99999500e-01, 2.38829220e-07, 2.58732940e-07],\n",
       "       [2.37605190e-07, 9.99999640e-01, 8.51651550e-08],\n",
       "       [1.20250900e-03, 9.98796940e-01, 4.69817200e-07],\n",
       "       [1.00000000e+00, 2.00253960e-11, 1.17086150e-11],\n",
       "       [6.59789600e-08, 7.48123100e-08, 9.99999900e-01],\n",
       "       [3.23467000e-08, 3.12121200e-08, 9.99999900e-01],\n",
       "       [1.31400910e-07, 9.99999900e-01, 2.60402190e-09],\n",
       "       [3.23467000e-08, 3.12121200e-08, 9.99999900e-01],\n",
       "       [2.86468000e-01, 7.13199140e-01, 3.32919330e-04],\n",
       "       [1.00000000e+00, 3.12486960e-08, 5.00718500e-08],\n",
       "       [4.12395500e-08, 1.00000000e+00, 3.27500400e-08],\n",
       "       [1.20250900e-03, 9.98796940e-01, 4.69817200e-07],\n",
       "       [9.99996200e-01, 3.31899500e-06, 5.03555600e-07],\n",
       "       [7.10662470e-06, 9.99992850e-01, 4.36628050e-08],\n",
       "       [5.61015630e-08, 1.00000000e+00, 2.11542130e-08],\n",
       "       [6.59789600e-08, 7.48123100e-08, 9.99999900e-01],\n",
       "       [9.99993100e-01, 6.85643500e-06, 7.64204100e-09],\n",
       "       [9.99999900e-01, 3.32082770e-08, 6.38934000e-08],\n",
       "       [3.23467000e-08, 3.12121200e-08, 9.99999900e-01],\n",
       "       [2.28144000e-04, 9.99409700e-01, 3.62216500e-04],\n",
       "       [9.86482800e-01, 1.35172110e-02, 5.48984080e-08],\n",
       "       [1.00000000e+00, 2.94700600e-11, 1.71899960e-11],\n",
       "       [9.99805400e-01, 1.43254700e-04, 5.13250900e-05],\n",
       "       [6.59789600e-08, 7.48123100e-08, 9.99999900e-01],\n",
       "       [3.23467000e-08, 3.12121200e-08, 9.99999900e-01],\n",
       "       [2.77597860e-08, 3.87603340e-08, 9.99999900e-01],\n",
       "       [3.23467000e-08, 3.12121200e-08, 9.99999900e-01],\n",
       "       [2.77597860e-08, 3.87603340e-08, 9.99999900e-01],\n",
       "       [1.07752820e-04, 9.99878900e-01, 1.34077460e-05],\n",
       "       [1.75156700e-07, 9.99999900e-01, 2.35419060e-08],\n",
       "       [5.25017750e-08, 9.99999900e-01, 6.71997360e-08],\n",
       "       [8.05026100e-08, 9.99999900e-01, 5.77330900e-09],\n",
       "       [1.00000000e+00, 4.89622450e-12, 2.24825000e-11],\n",
       "       [9.99998700e-01, 1.27933830e-06, 4.27202800e-10],\n",
       "       [1.02465670e-01, 8.97533000e-01, 1.38126540e-06],\n",
       "       [3.23467000e-08, 3.12121200e-08, 9.99999900e-01],\n",
       "       [3.23467000e-08, 3.12121200e-08, 9.99999900e-01],\n",
       "       [6.59789600e-08, 7.48123100e-08, 9.99999900e-01],\n",
       "       [9.99966140e-01, 3.36810900e-05, 9.99487800e-08],\n",
       "       [4.87463380e-06, 9.99995000e-01, 6.79567800e-08],\n",
       "       [6.59789600e-08, 7.48123100e-08, 9.99999900e-01],\n",
       "       [9.99999760e-01, 1.40737780e-07, 7.73321000e-08],\n",
       "       [9.26679100e-07, 9.99998330e-01, 7.52449860e-07],\n",
       "       [2.77597860e-08, 3.87603340e-08, 9.99999900e-01],\n",
       "       [2.77597860e-08, 3.87603340e-08, 9.99999900e-01],\n",
       "       [3.69109470e-08, 3.57192700e-08, 9.99999900e-01],\n",
       "       [9.99816240e-01, 1.83452910e-04, 3.48596400e-07],\n",
       "       [6.59789600e-08, 7.48123100e-08, 9.99999900e-01],\n",
       "       [2.86468000e-01, 7.13199140e-01, 3.32919330e-04],\n",
       "       [1.00000000e+00, 1.30561620e-13, 3.52863500e-13],\n",
       "       [9.99999500e-01, 1.61350630e-07, 3.34683530e-07],\n",
       "       [2.11613600e-05, 9.99978660e-01, 1.17481170e-07],\n",
       "       [3.23467000e-08, 3.12121200e-08, 9.99999900e-01],\n",
       "       [1.75156700e-07, 9.99999900e-01, 2.35419060e-08],\n",
       "       [1.00000000e+00, 6.98811760e-09, 7.13425500e-09],\n",
       "       [1.00000000e+00, 6.25338800e-09, 3.14555420e-08],\n",
       "       [7.32489840e-08, 9.99999900e-01, 1.02121380e-08],\n",
       "       [6.59789600e-08, 7.48123100e-08, 9.99999900e-01],\n",
       "       [9.99992850e-01, 4.65180600e-06, 2.46429610e-06],\n",
       "       [8.80670800e-08, 9.99999760e-01, 7.54393400e-08],\n",
       "       [2.77597860e-08, 3.87603340e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 8.67019440e-11, 8.35173300e-11],\n",
       "       [6.59789600e-08, 7.48123100e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 4.44778440e-09, 1.64665210e-09],\n",
       "       [3.69109470e-08, 3.57192700e-08, 9.99999900e-01],\n",
       "       [4.12395500e-08, 1.00000000e+00, 3.27500400e-08],\n",
       "       [1.22577080e-02, 9.87726870e-01, 1.54582360e-05],\n",
       "       [1.00000000e+00, 2.26016840e-11, 1.10644174e-10],\n",
       "       [1.00000000e+00, 2.31617130e-09, 4.61769200e-09],\n",
       "       [6.59789600e-08, 7.48123100e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 6.10122160e-11, 9.87621000e-11],\n",
       "       [3.69109470e-08, 3.57192700e-08, 9.99999900e-01],\n",
       "       [9.26166500e-02, 9.07382250e-01, 1.16237270e-06],\n",
       "       [4.17427830e-07, 9.99999500e-01, 3.25402350e-09],\n",
       "       [3.23467000e-08, 3.12121200e-08, 9.99999900e-01],\n",
       "       [5.25017750e-08, 9.99999900e-01, 6.71997360e-08]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob8 = df_proba8[df_proba8['phage']=='pyopresabsSTCC_qual'].iloc[:,-3:]\n",
    "y_prob8 = y_prob8.to_numpy()\n",
    "y_prob8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9931493442943825"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo8 = rocauc_ovo(y_test_over, y_prob8, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9931493442943825"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr8 = rocauc_ovr(y_test_over, y_prob8, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9930755737053448"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovos2 = [ovo5, ovo6, ovo7, ovo8]\n",
    "np.mean(ovos2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0026039960769801106"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(ovos2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9930755737053448"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovrs2 = [ovr5, ovr6, ovr7, ovr8]\n",
    "np.mean(ovrs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0026039960769801106"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(ovrs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs_reg = [acc_test_over5, acc_test_over6, acc_test_over7, acc_test_over8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling test accuracy regularization mean: 96.05%\n"
     ]
    }
   ],
   "source": [
    "mean_reg = np.mean(accs_reg)\n",
    "print('over-sampling test accuracy regularization mean: %.2f%%' % (mean_reg*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling test accuracy regularization standard deviation: 0.021758589075746893\n"
     ]
    }
   ],
   "source": [
    "std_reg = np.std(accs_reg)\n",
    "print('over-sampling test accuracy regularization standard deviation:', std_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs_train_reg = [np.mean(hist1_over5.history['accuracy']), np.mean(hist1_over6.history['accuracy']), np.mean(hist1_over7.history['accuracy']),\n",
    "             np.mean(hist1_over8.history['accuracy'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy regularization mean: 80.09%\n"
     ]
    }
   ],
   "source": [
    "mean_train_reg = np.mean(accs_train_reg)\n",
    "print('over-sampling train accuracy regularization mean: %.2f%%' % (mean_train_reg*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy regularization standard deviation: 0.0024480254\n"
     ]
    }
   ],
   "source": [
    "std_train_reg = np.std(accs_train_reg)\n",
    "print('over-sampling train accuracy regularization standard deviation:', std_train_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
